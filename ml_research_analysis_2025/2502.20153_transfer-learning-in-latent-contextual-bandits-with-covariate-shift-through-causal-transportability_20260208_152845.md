---
ver: rpa2
title: Transfer Learning in Latent Contextual Bandits with Covariate Shift Through
  Causal Transportability
arxiv_id: '2502.20153'
source_url: https://arxiv.org/abs/2502.20153
tags:
- causal
- domain
- transfer
- target
- latent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses negative transfer in latent contextual bandits,
  where a high-dimensional proxy variable is observed instead of the true context,
  and the context distribution differs across domains (covariate shift). The authors
  leverage causal transportability theory to derive a transport formula that explicitly
  determines what knowledge can be transferred between environments.
---

# Transfer Learning in Latent Contextual Bandits with Covariate Shift Through Causal Transportability

## Quick Facts
- arXiv ID: 2502.20153
- Source URL: https://arxiv.org/abs/2502.20153
- Reference count: 32
- Key outcome: This paper addresses negative transfer in latent contextual bandits, where a high-dimensional proxy variable is observed instead of the true context, and the context distribution differs across domains (covariate shift). The authors leverage causal transportability theory to derive a transport formula that explicitly determines what knowledge can be transferred between environments.

## Executive Summary
This paper tackles the challenge of negative transfer in latent contextual bandits where a high-dimensional proxy variable is observed instead of the true context, and the context distribution differs across domains. The authors leverage causal transportability theory to develop algorithms that explicitly transfer effective knowledge while avoiding negative transfer. They derive a transport formula showing what knowledge can be transferred and develop two algorithms: one for binary models using Bayesian inference, and another for high-dimensional proxies using Variational Autoencoders (VAEs) with a modified objective. Experiments on synthetic and semi-synthetic datasets demonstrate that their causal approach successfully avoids negative transfer compared to naive knowledge transfer methods.

## Method Summary
The method addresses transfer learning in latent contextual bandits where only a high-dimensional proxy W is observed instead of the true latent context Z, with covariate shift between source and target domains. The core insight is to leverage causal transportability theory to decompose the joint distribution via a transport formula that isolates invariant causal mechanisms from domain-specific components. For binary models, they analytically restore the unknown posterior using Bayesian inference. For high-dimensional proxies, they use β-VAEs with a modified objective (β < 1) that prioritizes reconstruction over latent regularization, allowing the encoder to approximate the shifted latent prior in the target domain. The key innovation is transferring only the decoder components (invariant causal mechanisms) while re-training the encoder in the target domain.

## Key Results
- The causal approach successfully avoids negative transfer compared to naive knowledge transfer methods, achieving sub-linear regret growth versus linear regret in baseline methods
- On IHDP and MNIST experiments, the method consistently achieves higher sample efficiency than agents without access to prior data
- The modified β-VAE objective with β < 1 enables better approximation of shifted latent distributions in the target domain compared to standard VAE approaches

## Why This Works (Mechanism)

### Mechanism 1
If conditional mechanisms are invariant, decomposing the joint distribution via a transport formula prevents negative transfer caused by naive mapping transfer. The method avoids transferring the observational policy P(Y|W,X) directly. Instead, it utilizes the transport formula p^*(y|w, do(x)) = Σ_z p(y|z, x) p^*(z|w). This isolates the invariant causal mechanism P(Y|Z,X) (transferable) from the context posterior P^*(Z|W) (domain-specific), allowing the agent to "correct" the context inference while keeping the reward mechanism stable. Core assumption: Assumption 1 (Covariate shift): P^π_{W|Z} = P^{π^*}_{W|Z} and P^π_{Y|Z,X} = P^{π^*}_{Y|Z,X}. The mechanism generating the proxy and reward remains constant; only the latent context distribution shifts.

### Mechanism 2
Transferring only the decoder components of a Variational Autoencoder (VAE) while re-training the encoder reduces the adaptation burden in the target domain. The architecture transfers the parameters θ_1 (Proxy generation) and θ_2 (Reward generation) but initializes and trains the encoder φ (Posterior estimation) in the target domain. Because the decoders capture the invariant physics of the environment, they provide a stable reconstruction target for the encoder to learn the new latent distribution P^*(Z|W). Core assumption: The decoder parameters θ learned in the source domain are sufficiently close to the optimal parameters in the target domain (local optima alignment).

### Mechanism 3
Reducing the weight of the KL-divergence term in the VAE loss function (β < 1) enables the encoder to approximate shifted latent priors. Standard VAEs (β=1) force the aggregated posterior to match a standard Gaussian prior. In transfer learning, the target latent distribution P^*(Z) may differ significantly from P(Z). By setting β < 1, the objective prioritizes reconstruction accuracy over latent regularization, allowing the encoder to output latent codes matching the shifted P^*(Z) rather than collapsing to the source prior. Core assumption: The reconstruction loss (log-likelihood) provides a sufficiently strong signal to shape the posterior without heavy regularization.

## Foundational Learning

- **Concept: Structural Causal Models (SCMs) & Transportability**
  - **Why needed here:** The paper relies on "selection diagrams" to formally encode what differs between the source and target domains. Without understanding d-separation and the *do*-calculus, the derivation of the transport formula (Proposition 4) is opaque.
  - **Quick check question:** Can you explain why P(Y|W, do(X)) ≠ P(Y|W, X) in the presence of a latent confounder Z?

- **Concept: Variational Inference & ELBO**
  - **Why needed here:** The high-dimensional proxy solution replaces analytic integration with a VAE. Understanding the Evidence Lower Bound (ELBO) is required to grasp why minimizing reconstruction loss + KL divergence approximates the posterior P(Z|W).
  - **Quick check question:** In the standard ELBO, what does the KL divergence term force the latent distribution to look like, and why is this problematic under covariate shift?

- **Concept: Contextual Bandits & Regret**
  - **Why needed here:** The evaluation metric is cumulative regret. Understanding the exploration-exploitation trade-off (specifically Thompson Sampling or UCB used in experiments) is necessary to interpret the "negative transfer" results (linear vs. sub-linear regret).
  - **Quick check question:** If an algorithm suffers "linear regret," what does that imply about its ability to learn the optimal policy?

## Architecture Onboarding

- **Component map:**
  - Source Training: VAE training on Dataset D → Decoders Dec_W (Context → Proxy) and Dec_Y (Context + Action → Reward)
  - Target Agent: Encoder (Enc) maps Proxy (W) → Latent Context (Z), initialized randomly; Transferred Decoders (frozen/fine-tuned copies of Dec_W and Dec_Y); Buffer (replay buffer storing target tuples (w, x, y))
  - Loss Function: Modified β-VAE objective (Eq 9): Reconstruction of W + Prediction of Y - (β × KL Divergence)

- **Critical path:**
  1. Pre-train full VAE on Source Domain → Save Decoder weights
  2. Initialize Target Agent: Load Decoder weights, re-initialize Encoder weights
  3. Online Loop: Observe W → Enc(Z) → Dec_Y(Ŷ) → Select Action
  4. Update: Store transition, sample batch, calculate Eq 9, update all networks (or Encoder only depending on strictness of transfer)

- **Design tradeoffs:**
  - Partial vs. Full Transfer: The paper proves (Corollary 7) that transferring the whole VAE creates non-zero expected gradients for the decoder, requiring more data to fix. Transferring only decoders sets the expected gradient to zero (optimal assumption holds), maximizing sample efficiency.
  - Identifiability: The method admits (Remark 6) that without inductive biases, restoring the exact latent distribution is impossible. The tradeoff is accepting an approximation sufficient for reward prediction rather than exact causal recovery.

- **Failure signatures:**
  - Linear Regret: If the agent performs worse than random, check if the prior knowledge (decoder) is being applied incorrectly or if the shift is too extreme (e.g., non-overlapping support)
  - Posterior Mismatch: If the learned P(Z|W) stays close to the source prior despite β < 1, the encoder is failing to adapt
  - Gradient Instability: If training the decoder in the target domain leads to divergence, the Assumption 1 (invariance) may be violated

- **First 3 experiments:**
  1. **Binary Sanity Check:** Implement Algorithm 1 on a simple binary bandit. Verify that the analytic posterior restoration (Eq 6) converges to the true target distribution P^*(Z).
  2. **IHDP Proxy Test:** Train the VAE architecture on the IHDP dataset. Plot the "Total Cumulative Regret" vs. Gradient Steps. Compare the "Causal" agent vs. "VAE (prior)" (naive transfer) to visually confirm the avoidance of negative transfer.
  3. **Ablation on β:** On the MNIST proxy setup, sweep β (e.g., 1.0 vs. 0.1 vs. 0.01). Observe if the encoder successfully shifts the latent distribution to match the target domain, specifically checking the posterior plots as shown in Figure 5.

## Open Questions the Paper Calls Out

- **Open Question 1:** Can the causal transportability framework be extended to sequential decision-making settings governed by Markov Decision Processes (MDPs)?
  - **Basis in paper:** The Conclusion states, "Extending this framework to reinforcement learning, where a Markov decision process is considered to govern the data-generating process, could be an intriguing avenue for future work."
  - **Why unresolved:** The current paper focuses solely on the single-step bandit setting; extending to temporal sequences requires handling state transitions and delayed rewards within the transportability logic.
  - **What evidence would resolve it:** Derivation of a transport formula for MDPs and demonstration of sample efficiency gains in a standard RL benchmark under covariate shift.

- **Open Question 2:** How can the unidentifiability of Variational Autoencoders (VAEs) be mitigated to ensure the recovered latent posterior matches the true target distribution in high-dimensional settings?
  - **Basis in paper:** In Section 4.2.2 (MNIST experiments), the authors note the learned posterior often fails to converge to the true target distribution, attributing this to the unidentifiability of VAEs discussed in Remark 6.
  - **Why unresolved:** The transferred decoder serves as an inductive bias, but the paper shows it is insufficient to force the encoder to approximate the true P*_Z in complex visual domains.
  - **What evidence would resolve it:** Integration of identifiability constraints (e.g., identifiable VAEs) into the algorithm, resulting in empirical convergence of the latent distribution to the ground truth in image-based tasks.

- **Open Question 3:** Is the framework robust to violations of the assumption that conditional mechanisms (P_{W|Z} and P_{Y|Z,X}) remain invariant across domains?
  - **Basis in paper:** Assumption 1 explicitly requires that conditional distributions generating the proxy and reward remain the same across domains. This is a strict constraint often violated in real-world transfer learning (e.g., sensor drift changing P_{W|Z}).
  - **Why unresolved:** The transport formula (Eq. 4) relies on these invariances; if they break, the estimated causal effect in the target domain may be biased, potentially re-introducing negative transfer.
  - **What evidence would resolve it:** A theoretical analysis or empirical test showing how the algorithm degrades as the noise in P_{W|Z} or the parameters of P_{Y|Z,X} diverge between source and target domains.

## Limitations

- The approach relies heavily on the assumption that conditional mechanisms (P(Y|Z,X) and P(W|Z)) are invariant across domains, which may break down in cases of concept drift or when the proxy generation mechanism itself changes
- The method requires the proxy to be high-dimensional (d1 ≪ d2), which may not hold in all practical applications
- The identifiability issue remains a fundamental limitation, as exact recovery of the latent distribution is generally impossible without additional inductive biases

## Confidence

- **High Confidence**: The theoretical foundation based on causal transportability theory is sound, and the derived transport formula (Proposition 4) is mathematically correct. The empirical demonstration that the method avoids negative transfer compared to naive approaches is convincing.
- **Medium Confidence**: The practical effectiveness of the β-VAE modification (β < 1) for approximating shifted latent distributions is supported by experiments, but the specific choice of β and its sensitivity to different problem settings warrants further investigation.
- **Low Confidence**: The scalability of the approach to very high-dimensional proxies or extremely complex latent spaces is not thoroughly explored, and the method's performance in non-stationary environments remains an open question.

## Next Checks

1. **Ablation on Prior Strength**: Conduct experiments systematically varying the strength of the KL divergence term (β) across a wider range (e.g., 0.01 to 1.0) to understand its impact on adaptation speed and final performance. Monitor the shift in the learned posterior distribution relative to the source prior and target truth.

2. **Robustness to Prior Misspecification**: Test the algorithm's performance when the transferred decoders are imperfect approximations of the target domain's mechanisms. Introduce controlled noise or perturbations to the decoder parameters during transfer to simulate model misspecification.

3. **Generalization to Non-Stationary Shifts**: Evaluate the method's ability to handle non-stationary environments where the latent context distribution changes over time. Design experiments where P*(Z) evolves gradually during the target domain interaction, and assess whether the agent can continuously adapt without catastrophic forgetting.