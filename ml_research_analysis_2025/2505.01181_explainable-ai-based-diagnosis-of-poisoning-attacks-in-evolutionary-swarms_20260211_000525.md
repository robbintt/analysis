---
ver: rpa2
title: Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms
arxiv_id: '2505.01181'
source_url: https://arxiv.org/abs/2505.01181
tags:
- data
- poisoning
- swarm
- evolutionary
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PADEX, a framework for detecting data poisoning
  attacks in evolutionary swarm systems using explainable AI (XAI) methods. The framework
  models swarm behavior through evolutionary game theory to form optimal coalitions
  for cooperative tasks, then trains a surrogate ML model to predict these strategies.
---

# Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms

## Quick Facts
- **arXiv ID**: 2505.01181
- **Source URL**: https://arxiv.org/abs/2505.01181
- **Reference count**: 19
- **Key outcome**: Proposes PADEX framework using SHAP-based XAI to detect data poisoning attacks in evolutionary swarm systems, showing poisoning above 10% causes significant deviations in feature importance and reduces model accuracy from 91% to 63%.

## Executive Summary
This paper introduces PADEX, a framework for detecting data poisoning attacks in evolutionary swarm systems through explainable AI methods. The approach models swarm behavior using evolutionary game theory to form optimal coalitions for cooperative tasks, then employs a surrogate ML model to predict these strategies. By systematically introducing feature perturbation attacks (fake GPS coordinates) at varying severity levels, the authors demonstrate how poisoning affects swarm coordination and model performance. The framework leverages SHAP analysis to quantify deviations in feature importance, enabling detection of compromised swarm models through comparison with benign versions.

## Method Summary
The PADEX framework operates by first modeling swarm behavior through evolutionary game theory to establish optimal coalition formations for cooperative tasks. A surrogate machine learning model is trained to predict these strategies based on swarm state features. The system then introduces feature perturbation attacks (specifically fake GPS coordinates) at controlled severity levels ranging from 10% to 40%. Using SHAP (SHapley Additive exPlanations) for explainable AI analysis, the framework evaluates how poisoning affects both the model's accuracy and the distribution of feature importance scores. The key insight is that deviations in SHAP values between poisoned and benign models can serve as indicators of successful attack detection, with the severity of poisoning directly correlating to degradation in both coalition formation quality and predictive accuracy.

## Key Results
- Poisoning above 10% severity causes significant deviations in feature importance distributions as measured by SHAP values
- Model accuracy degrades substantially with increased poisoning, dropping from 91% (benign) to 63% (40% poisoning)
- SHAP analysis successfully identifies compromised swarm models by comparing feature importance patterns against benign baselines

## Why This Works (Mechanism)
The framework works by establishing a baseline of normal swarm behavior through evolutionary game theory modeling, then using explainable AI to monitor for deviations that indicate poisoning. The surrogate ML model learns to predict optimal coalition strategies based on swarm state features, creating a reference point for normal operation. When poisoning attacks introduce fake GPS coordinates, they corrupt the feature space that the model relies on for decision-making. SHAP values, which quantify each feature's contribution to model predictions, capture these corruption effects by showing altered importance distributions. Since the framework compares current SHAP patterns against the benign baseline, any significant deviation (particularly above the 10% threshold observed in experiments) signals a potential poisoning attack. This approach effectively bridges the gap between the abstract concept of swarm optimization and concrete, interpretable metrics that can detect malicious interference.

## Foundational Learning

**Evolutionary Game Theory**
*Why needed*: Provides mathematical framework for modeling strategic interactions and coalition formation in multi-agent systems
*Quick check*: Verify payoff matrices correctly represent agent incentives and lead to Nash equilibrium strategies

**Explainable AI (XAI) - SHAP**
*Why needed*: Enables interpretation of black-box ML models to identify feature importance changes caused by poisoning
*Quick check*: Confirm SHAP values sum to model output margin and feature contributions remain consistent across similar inputs

**Surrogate ML Modeling**
*Why needed*: Creates predictive model of swarm strategies that can be monitored for poisoning-induced deviations
*Quick check*: Validate model accuracy against ground truth coalition formations in both benign and poisoned scenarios

**Feature Perturbation Attacks**
*Why needed*: Simulates realistic attack vectors (e.g., GPS spoofing) that compromise swarm coordination
*Quick check*: Ensure perturbation magnitude and distribution match expected real-world attack characteristics

## Architecture Onboarding

**Component Map**
Surrogate ML Model <- Evolutionary Game Theory Solver <- Swarm State Monitor -> SHAP Analyzer -> Anomaly Detector

**Critical Path**
Swarm State Monitor captures real-time agent positions and states → Evolutionary Game Theory Solver computes optimal coalitions → Surrogate ML Model predicts strategies → SHAP Analyzer computes feature importance → Anomaly Detector compares against baseline to identify poisoning

**Design Tradeoffs**
- Computational overhead vs detection accuracy: More frequent SHAP analysis improves detection but increases latency
- Sensitivity threshold selection: Lower thresholds catch subtle attacks but increase false positives
- Feature selection: Including too many features may obscure poisoning signals, while too few may miss attack indicators

**Failure Signatures**
- Gradual degradation in model accuracy without corresponding changes in swarm environment
- Sudden shifts in SHAP value distributions for specific features (particularly GPS coordinates)
- Inconsistent coalition formation patterns that don't align with evolutionary game theory predictions

**First 3 Experiments**
1. Baseline validation: Run swarm without poisoning to establish SHAP value distributions and model accuracy
2. Controlled poisoning: Introduce 10-40% fake GPS coordinates systematically and measure accuracy degradation
3. Cross-validation: Test detection framework with different attack vectors beyond GPS spoofing to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Simulated environments may not capture real-world complexities like communication constraints and environmental unpredictability
- 10-40% poisoning range represents limited attack scenarios; effectiveness against sophisticated poisoning remains untested
- SHAP-based detection may not fully capture complex feature interactions in high-dimensional swarm state spaces

## Confidence

**High confidence**: The systematic relationship between poisoning severity and model accuracy degradation is well-supported by experimental results (91% to 63% accuracy drop).

**Medium confidence**: The claim that SHAP values effectively detect compromised models is supported but could benefit from additional validation across different XAI methods.

**Medium confidence**: The framework's ability to prevent suboptimal coalition formation is demonstrated within controlled experimental settings but may face challenges in dynamic real-world deployments.

## Next Checks

1. Test the framework's robustness against adaptive poisoning strategies that target SHAP-based detection mechanisms specifically.

2. Evaluate performance in heterogeneous swarm environments with varying agent capabilities and communication constraints.

3. Implement the framework in a real-world swarm robotics testbed to assess practical deployment challenges and scalability.