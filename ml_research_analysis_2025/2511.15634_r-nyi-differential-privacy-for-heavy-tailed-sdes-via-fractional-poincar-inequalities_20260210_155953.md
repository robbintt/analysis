---
ver: rpa2
title: "R\xE9nyi Differential Privacy for Heavy-Tailed SDEs via Fractional Poincar\xE9\
  \ Inequalities"
arxiv_id: '2511.15634'
source_url: https://arxiv.org/abs/2511.15634
tags:
- heavy-tailed
- poincar
- differential
- privacy
- enyi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper addresses the problem of characterizing the R\xE9nyi\
  \ Differential Privacy (RDP) of stochastic learning algorithms that exhibit heavy-tailed\
  \ noise, specifically those modeled by L\xE9vy-driven Stochastic Differential Equations\
  \ (SDEs) with \u03B1-stable noise. Prior DP bounds for such heavy-tailed settings\
  \ have strong dimensional dependencies and cannot be extended to well-established\
  \ RDP notions."
---

# Rényi Differential Privacy for Heavy-Tailed SDEs via Fractional Poincaré Inequalities

## Quick Facts
- **arXiv ID:** 2511.15634
- **Source URL:** https://arxiv.org/abs/2511.15634
- **Reference count:** 14
- **Key outcome:** New RDP bounds for heavy-tailed algorithms that reduce dimension dependence to $d^{1-\alpha/2}$ for pure α-stable noise and are dimension-independent for multifractal noise, under finite sensitivity and fractional Poincaré inequality assumptions.

## Executive Summary
This paper establishes Rényi Differential Privacy (RDP) guarantees for stochastic learning algorithms driven by heavy-tailed Lévy noise, specifically α-stable processes. The key innovation is leveraging fractional Poincaré inequalities instead of traditional logarithmic Sobolev inequalities, which are more suitable for heavy-tailed settings. Under assumptions of finite gradient sensitivity and fractional Poincaré inequalities, the authors derive RDP bounds that significantly reduce the dependence on dimension compared to prior work. The bounds improve from exponential in dimension for prior methods to polynomial scaling of $d^{1-\alpha/2}$ for pure α-stable noise and dimension-independent for multifractal noise.

## Method Summary
The paper analyzes stochastic differential equations with Lévy noise of the form $dW_t = -\nabla \hat{R}_S(W_t)dt + \sigma_\alpha dL^\alpha_t + \sigma_2\sqrt{2}dB_t$, where $L^\alpha_t$ is an α-stable Lévy process. The key technical innovation is computing Rényi divergence flows for general Lévy-driven SDEs using fractional Poincaré inequalities, which are more suitable for heavy-tailed distributions than classical logarithmic Sobolev inequalities. The method involves establishing stability properties of fractional Poincaré inequalities under various operations and deriving new bounds that depend on the stability parameter α. For discrete-time algorithms, the paper shows that heavy-tailed SGD with α-stable noise satisfies similar RDP guarantees with appropriate discretization.

## Key Results
- **Multifractal noise (Gaussian + α-stable):** (β, κ)-RDP with $\kappa = O(\beta^2 S_g^2/(n^2 \sigma_2^2))$, dimension-independent under FPI
- **Pure α-stable noise:** (β, κ)-RDP with $\kappa = O(\beta^2 d^{1-\alpha/2} S_g^2/(n^2 \sigma_\alpha^\alpha))$, dimension dependence reduced from exponential to polynomial
- **Discrete algorithms:** Heavy-tailed SGD with symmetric α-stable noise satisfies similar RDP bounds with proper discretization

## Why This Works (Mechanism)
The paper leverages fractional Poincaré inequalities (FPI) which are more appropriate for heavy-tailed distributions than classical logarithmic Sobolev inequalities. FPI provides a way to control the Rényi divergence between probability measures in settings where the noise has heavy tails. The mechanism works by establishing that under FPI, the Rényi divergence between solutions of neighboring SDEs can be bounded in terms of the sensitivity of the gradients and the parameters of the noise. The fractional Laplacian in the FPI captures the heavy-tailed nature of the noise, allowing for tighter bounds than traditional methods.

## Foundational Learning
- **Rényi Differential Privacy:** Generalization of DP that characterizes privacy loss for all orders β simultaneously, needed because traditional DP is too restrictive for continuous noise distributions
- **Fractional Poincaré Inequalities:** Generalization of Poincaré inequalities using fractional Laplacians, required because standard Poincaré inequalities fail for heavy-tailed distributions
- **α-stable Lévy processes:** Heavy-tailed noise distributions with stability parameter α ∈ (1,2), chosen because they model realistic heavy-tailed phenomena in learning
- **Rényi divergence flows:** Technique to bound the evolution of Rényi divergence along SDE trajectories, essential for establishing RDP guarantees
- **Sensitivity of gradients:** Measure of how much the gradient changes between neighboring datasets, critical parameter controlling privacy loss
- **Fokker-Planck equations:** Describe evolution of probability densities for SDEs, used to analyze the continuous-time behavior

## Architecture Onboarding
**Component map:** SDEs with Lévy noise -> Rényi divergence flow -> Fractional Poincaré inequality -> RDP bound
**Critical path:** Algorithm (discrete SGD) -> Continuous approximation (SDE) -> Rényi divergence computation -> FPI application -> Final RDP guarantee
**Design tradeoffs:** FPI provides better bounds for heavy-tailed noise but requires stronger assumptions than classical methods; finite sensitivity assumption trades off generality for dimension-independent bounds
**Failure signatures:** If FPI doesn't hold, bounds become time-dependent (linear growth in T); if sensitivity is unbounded, dimension dependence explodes
**3 first experiments:**
1. Implement discrete heavy-tailed SGD with α-stable noise and verify α-stable sampling using CMS method
2. Test FPI condition for logistic regression with ℓ₂ regularization by computing fractional Poincaré constant
3. Measure empirical Rényi divergence between outputs from neighboring datasets to validate theoretical bounds

## Open Questions the Paper Calls Out
- **Open Question 1:** Can the regularity conditions (Assumption 2) required for rigorous Rényi flow computations be relaxed or explicitly verified using fractional heat kernel estimates? The authors note this might be related to recent fractional heat kernel estimates.
- **Open Question 2:** Can the stability lemmas for fractional Poincaré inequalities be improved to yield better constant estimates and recover the Gaussian limit as α → 2? Current dimension-dependent quantities prevent recovery of Gaussian behavior.
- **Open Question 3:** Is it possible to derive RDP guarantees for heavy-tailed algorithms with weak dimension dependence without requiring finite gradient sensitivity? Current framework relies on finite sensitivity to control drift differences.

## Limitations
- **Fractional Poincaré inequality assumption:** The bounds rely on FPI holding for the specific loss function, which is not always satisfied and difficult to verify
- **Non-constructive constants:** The dimension-dependent constants R and γ are not explicitly computable in general, limiting practical application
- **Initial distribution unspecified:** The paper assumes "same initial distribution" for both SDEs but doesn't specify which distribution to use

## Confidence
- **High confidence:** Theoretical framework for Rényi divergence flows for Lévy-driven SDEs is sound and follows established stochastic calculus
- **Medium confidence:** Application of fractional Poincaré inequalities to heavy-tailed settings is novel and theoretically justified, but practical verification remains challenging
- **Low confidence:** Exact values of dimension-dependent constants (R, γ) are not specified, making it difficult to predict actual privacy parameters

## Next Checks
1. Verify FPI condition for a specific regularized loss function (e.g., logistic regression with ℓ₂ regularization) by computing or estimating the fractional Poincaré constant γ
2. Implement discrete heavy-tailed SGD with α-stable noise and empirically measure the Rényi divergence between outputs from neighboring datasets to validate theoretical bounds
3. Test the robustness of the bounds under varying initial conditions to confirm the stability of the RDP guarantees across different starting distributions