---
ver: rpa2
title: 'WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving
  at the Edge via Dynamic Drafting and SLO-Aware Batching'
arxiv_id: '2601.11652'
source_url: https://arxiv.org/abs/2601.11652
tags:
- verification
- edge
- speculative
- tokens
- draft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'WISP addresses inefficiency and SLO violations in distributed
  speculative LLM serving at the edge by identifying two bottlenecks: Wasted Drafting
  Time and Verification Interference. It introduces an intelligent drafting controller
  using a lightweight rejection predictor to reduce wasted drafting, and an SLO-aware
  scheduler that batches verification requests to avoid interference and meet deadlines.'
---

# WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching

## Quick Facts
- arXiv ID: 2601.11652
- Source URL: https://arxiv.org/abs/2601.11652
- Reference count: 39
- Key outcome: WISP improves system capacity by up to 2.1x and 4.1x, and system goodput by up to 1.94x and 3.7x, compared to centralized serving and SLED respectively, while significantly reducing SLO violations.

## Executive Summary
WISP addresses two critical bottlenecks in distributed speculative LLM serving at the edge: Wasted Drafting Time (WDT) from rejected tokens and Verification Interference from heterogeneous request batching. It introduces a lightweight rejection predictor that dynamically triggers verification to minimize WDT, and an SLO-aware scheduler that batches verification requests to meet deadlines and avoid interference. A fine-grained verification-time estimator supports online feasibility checks. Evaluations show WISP significantly improves system capacity and goodput while reducing SLO violations compared to both centralized serving and SLED.

## Method Summary
WISP modifies speculative decoding by introducing dynamic drafting control via a lightweight MLP rejection predictor that stops drafting upon predicting likely rejection, reducing wasted computation. The SLO-aware scheduler uses a greedy knapsack approach to batch verification requests based on utility scoring and feasibility checks using a fine-grained latency estimator. The system architecture consists of edge clients running draft models with predictors, a verification server with utility queues, and a scheduler using latency estimation to ensure SLO compliance. The approach is evaluated against SLED and centralized serving baselines using simulated edge-to-cloud workloads.

## Key Results
- System capacity improvements of 2.1x and 4.1x over centralized serving and SLED respectively
- System goodput improvements of 1.94x and 3.7x over centralized serving and SLED respectively
- Significant reduction in SLO violations compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1
The intelligent drafting controller uses a lightweight MLP classifier to observe draft-side logits and stop drafting at the first token predicted to be rejected, reducing wasted drafting time. The classifier monitors confidence, entropy, margin, and standard deviation of draft outputs. Theorem 1 proves that reducing the false alarm rate of the predictor monotonically reduces expected WDT. The mechanism fails if draft logits have low predictive power for rejection or if predictor overhead exceeds latency savings.

### Mechanism 2
The SLO-aware scheduler batches verification requests using a deadline-aware knapsack formulation to suppress SLO violations. The scheduler prioritizes critical requests (earliest deadline first) and fills remaining capacity with high-utility requests, avoiding head-of-line blocking where long verifications inflate latency for short, urgent requests. The mechanism fails if aggressive preemption causes starvation or if scheduler overhead dominates batch formation time.

### Mechanism 3
The verification-time estimator decomposes batch latency into linear, attention, and memory-access components (T = a·N_linear + b_compute·N_interactions + b_read·N_cached + c), enabling online SLO feasibility checks. The model assumes GPU kernel execution time scales predictably with these three proxy metrics across different request lengths and cache states. The mechanism fails if extreme memory fragmentation or system-level jitter violates the linear assumptions.

## Foundational Learning

- **Concept**: Speculative Decoding (Draft-then-Verify)
  - **Why needed here**: WISP modifies the standard speculative loop by introducing adaptive stopping. Understanding the baseline loop (draft → verify → accept/reject) clarifies the value of the rejection predictor.
  - **Quick check question**: How does the latency of verifying K draft tokens in parallel compare to autoregressively generating K tokens on the target model?

- **Concept**: KV-Caching & PageAttention
  - **Why needed here**: The paper relies on "Verification Interference" analysis, which hinges on the cost of attending to history. PageAttention allows WISP to manage memory cost efficiently and reduce cold-start penalties.
  - **Quick check question**: Why does a "cold start" verification (no cached history) cost more in compute/attention interactions than a "warm" follow-up verification?

- **Concept**: Knapsack Problem & Greedy Algorithms
  - **Why needed here**: The SLO-aware scheduler frames batch construction as a knapsack problem (maximizing value/utility within a time/memory budget). Understanding this explains why the scheduler uses a greedy approach rather than exhaustive search.
  - **Quick check question**: In the context of WISP, what represents the "weight" and what represents the "value" in the scheduling knapsack problem?

## Architecture Onboarding

- **Component map**: Edge Client (Draft Model + Rejection Predictor) -> Verification Server (Gateway with Utility/Urgent Queues) -> Scheduler (Greedy Knapsack algorithm) -> Verification Engine (Target Model + PageAttention + Prefix Cache)

- **Critical path**: The latency-critical path is the server-side dispatch loop: Receive Request → Calculate Utility/LST → Feasibility Check (Estimator) → Batch Dispatch → GPU Execution. If the Estimator under-predicts here, the entire batch misses the SLO.

- **Design tradeoffs**: The paper selects an MLP over Trees to minimize False Positives (over-drafting), accepting slightly lower recall on accepted tokens to optimize for waste reduction over speculative coverage. The estimator uses aggregate "interaction" counts rather than exact tensor shapes to reduce overhead but may lose precision on irregular batch shapes.

- **Failure signatures**:
  1. Batch Meltdown: SLO violations spike suddenly due to insufficient guard time δ in LST calculation for current system jitter
  2. Edge Starvation: Edge devices rarely send verification requests due to overly conservative predictor (high false negatives)
  3. Goodput Collapse: Goodput drops despite high token acceptance due to Verification Interference from improper batching

- **First 3 experiments**:
  1. Latency Profiler Calibration: Validate estimator coefficients (a, b, c) against target model with synthetic batches varying N_linear and N_cached
  2. Predictor Ablation: Disable rejection predictor (use fixed K) to measure shift in Wasted Drafting Time and confirm Theorem 1 bounds
  3. Stress Test Interference: Generate mixed workload with cold starts and follow-ups to compare WISP's SLO violation rate against FCFS scheduler

## Open Questions the Paper Calls Out

### Open Question 1
Does the additive verification-time estimator generalize to Mixture-of-Experts (MoE) models where computational cost is driven by routing sparsity rather than dense token counts? The paper validates only on dense Qwen models, and MoE execution patterns could break the linear scaling assumptions. Empirical validation on MoE architectures like Mixtral would resolve this.

### Open Question 2
How does WISP perform under high network latency variance given that the scheduler assumes fixed, known transmission time when calculating server-side deadlines? Real-world network jitter could cause actual transmission times to exceed the subtracted budget, leading to SLO violations the scheduler cannot predict. Sensitivity analysis under simulated network conditions would resolve this.

### Open Question 3
What is the net energy impact on battery-constrained edge devices when trading reduced drafting time against predictor computational overhead? The paper doesn't quantify energy consumption, and predictor overhead might outweigh savings if acceptance rates are naturally high. Profiling Joules per committed token on actual edge hardware would resolve this.

### Open Question 4
Does the lightweight rejection predictor transfer effectively to diverse application domains (e.g., coding vs. creative writing) without retraining? The predictor may learn domain-specific correlations between logits and acceptance, potentially leading to high false alarm rates in unseen domains. Cross-domain evaluation would resolve this.

## Limitations
- Underspecified architectural details including complete MLP architecture and guard time δ value for SLO feasibility checks
- Reliance on synthetic workload generation and unreleased simulator implementation for evaluation
- Assumptions about predictable GPU kernel execution times that may be violated by real-world factors like PCIe congestion and memory fragmentation

## Confidence

**High Confidence**: The theoretical foundation for reducing Wasted Drafting Time through rejection prediction is sound (Theorem 1 provides monotonic bounds), and the SLO-aware scheduling approach using utility-based knapsack formulation is well-grounded in prior literature.

**Medium Confidence**: The latency estimator's accuracy (R² > 0.99, MAE 13.24ms) appears strong based on 173 profiling configurations, but real-world deployment may face greater variance. The claim that MLP outperforms tree-based models due to lower False Positive Rate is well-supported.

**Low Confidence**: The practical scalability of the SLO-aware scheduler under extreme load conditions is uncertain, as starvation risks from aggressive prioritization are not thoroughly explored.

## Next Checks

1. **Predictor Robustness Test**: Evaluate the rejection predictor on out-of-distribution draft outputs (different styles, lengths, topics) to measure performance degradation and validate the MLP vs tree-based architectural choice.

2. **Estimator Validation Under Load**: Deploy the latency estimator on production GPU hardware with concurrent workloads to measure real-world prediction error compared to controlled profiling environment, specifically testing linear model assumptions under memory fragmentation.

3. **Starvation Analysis**: Stress-test the SLO-aware scheduler with extreme request heterogeneity (99% critical requests, 1% long-running jobs) to quantify starvation risk and measure actual vs predicted system goodput under these conditions.