---
ver: rpa2
title: 'Decoding Listeners Identity: Person Identification from EEG Signals Using
  a Lightweight Spiking Transformer'
arxiv_id: '2510.17879'
source_url: https://arxiv.org/abs/2510.17879
tags:
- spiking
- transformer
- identification
- neural
- person
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a lightweight spiking transformer for EEG-based\
  \ person identification, achieving 100% accuracy on a 26-subject dataset with only\
  \ 3.91 million parameters and 760.7 \xB5J energy consumption per inference\u2014\
  under 10% of conventional ANN models. The approach combines Conv-based and Transformer-based\
  \ spiking neural network blocks to efficiently capture temporal and spatial EEG\
  \ features."
---

# Decoding Listeners Identity: Person Identification from EEG Signals Using a Lightweight Spiking Transformer

## Quick Facts
- **arXiv ID**: 2510.17879
- **Source URL**: https://arxiv.org/abs/2510.17879
- **Reference count**: 0
- **Primary result**: Achieves 100% accuracy on 26-subject EEG dataset using 3.91M parameters and 760.7 µJ energy per inference

## Executive Summary
This paper introduces a lightweight spiking transformer for EEG-based person identification, achieving 100% accuracy on a 26-subject dataset with only 3.91 million parameters and 760.7 µJ energy consumption per inference—under 10% of conventional ANN models. The approach combines Conv-based and Transformer-based spiking neural network blocks to efficiently capture temporal and spatial EEG features. The model leverages spike-driven self-attention and a Leaky Integrate-and-Fire neuron model to balance computational efficiency with high performance. Ablation studies show the trade-offs between parameter reduction and accuracy. Results highlight SNNs' potential for low-power, high-performance biometric recognition in resource-constrained brain-computer interface applications.

## Method Summary
The method employs a two-stage architecture: first, Conv-based SNN blocks (SepConv and ChannelConv) extract spatial and temporal features from raw EEG signals; second, Transformer-based SNN blocks with spike-driven self-attention capture long-range dependencies. LIF neurons enable temporal integration, while spike-driven attention replaces dense matrix multiplication with sparse additions for energy efficiency. The model is trained using surrogate gradient learning and evaluated on a music-listening EEG dataset with 26 subjects.

## Key Results
- Achieves 100% classification accuracy on held-out test set
- Uses only 3.91 million parameters (vs. 30.9M for full-size model)
- Consumes 760.7 µJ energy per inference, under 10% of ANN baseline
- Ablation shows 2.03% accuracy drop when reducing Conv blocks (to 2.85M parameters)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LIF neurons enable temporal integration of EEG dynamics through membrane potential accumulation.
- **Mechanism**: The membrane potential V[n+1] = βV[n] + Σ(wⱼ·S_inⱼ[n]) - Reset[n] integrates inputs over time steps, with β controlling decay. This accumulation captures temporal dependencies in EEG signals before spike generation.
- **Core assumption**: EEG person identity signatures exhibit temporal coherence that accumulates meaningfully across time steps within the 10-second window.
- **Evidence anchors**:
  - [Section 2.1]: "its membrane potential inherently performs temporal integration, crucial for capturing the dynamics of EEG data"
  - [Section 5]: "SNNs offer distinct advantages for EEG-based classification tasks due to their ability to capture the temporal dynamics inherent in neural signals"
  - [Corpus]: Weak direct evidence—S²M-Former paper addresses spiking architectures for EEG auditory tasks but doesn't validate temporal integration specifically for identity.
- **Break condition**: If β (leakage factor) is set too high, temporal information decays before integration; if too low, the model cannot distinguish recent from old inputs.

### Mechanism 2
- **Claim**: Spike-Driven Self-Attention (SDSA) reduces energy by replacing dense matrix multiplication with sparse spike additions.
- **Mechanism**: Q, K, V are converted to spike tensors via LIF neurons. The attention computation Q_s(K_s^T·V_s) uses spike-form matrix multiplication, which can be converted to additions using addressing algorithms rather than multiply-accumulate operations. The average firing rate of 7.18% means most neurons remain inactive.
- **Core assumption**: The binary spike representation preserves sufficient discriminative information for identity classification despite 92.82% of activations being suppressed.
- **Evidence anchors**:
  - [Section 2.2.3]: "computes interactions between tokens using sparse additions instead of the dense, computationally expensive dot products"
  - [Section 4.2]: "average firing rate of just 7.18%, meaning that only a small fraction of the network's spiking neurons are active at any given time"
  - [Corpus]: AFPM and Transformer-based EEG Decoding Survey discuss transformer efficiency but don't specifically validate spike-based attention trade-offs.
- **Break condition**: If firing threshold V_th is too high, insufficient spikes are generated for attention computation; if too low, the network operates like a conventional ANN with no energy savings.

### Mechanism 3
- **Claim**: Two-stage Conv-based SNN blocks extract hierarchical spatial features that Transformer blocks cannot efficiently capture alone.
- **Mechanism**: SepConv (depthwise + pointwise) first extracts per-channel temporal patterns, then ChannelConv merges spatial information across channels. Ablation shows removing one Conv block drops accuracy 2.03% while reducing parameters by 27%.
- **Core assumption**: EEG identity information requires both local spatial patterns (channel-wise) and global temporal dependencies (transformer attention).
- **Evidence anchors**:
  - [Section 4.3]: "tested a variant with only one Conv-based block... resulted in a 03% drop in accuracy"
  - [Section 2.2.2]: "combines spatial and channel-wise information, allowing the model to learn deeper, more abstract features"
  - [Corpus]: No direct corpus validation of Conv-then-Transformer staging for EEG identity tasks.
- **Break condition**: If the downsampling dimensions are reduced beyond the 3.91M configuration, "severe accuracy degradation" occurs (Section 4.3).

## Foundational Learning

- **Concept: Surrogate Gradient Learning**
  - **Why needed here**: LIF spike generation uses a non-differentiable Heaviside step function θ(V - V_th). Surrogate gradients approximate gradients during backpropagation to enable training.
  - **Quick check question**: Can you explain why standard backpropagation fails at the spike generation step, and what function a surrogate gradient typically substitutes?

- **Concept: Energy Estimation in Neuromorphic Systems**
  - **Why needed here**: The 760.7 µJ claim depends on understanding that spike-based accumulation (AC) operations consume less energy than MAC operations, and that inactive neurons enter low-power states.
  - **Quick check question**: How does the 7.18% firing rate translate to energy savings, and what assumptions does the 45nm CMOS process model make about sparse activation?

- **Concept: EEG Preprocessing Pipeline for Cross-Subject Consistency**
  - **Why needed here**: The paper uses FIR filtering (0.5-40 Hz), ICA artifact removal, and per-trial normalization. These steps affect whether the model learns identity vs. artifact features.
  - **Quick check question**: Why might per-trial normalization within subjects help or harm cross-subject identity discrimination?

## Architecture Onboarding

- **Component map**: Input (C×T) → Conv-SNN Block 1 (SepConv + ChannelConv) → Conv-SNN Block 2 → Feature Map F → Transformer-SNN Block 1 (SDSA + MLP) → Transformer-SNN Block 2 → Feature Map G → Linear Classifier → 26-class output
- **Critical path**: Input EEG window → SepConv extracts temporal patterns → ChannelConv merges spatial info → SDSA captures long-range dependencies via spike attention → Linear layer outputs identity logits. The membrane potential state propagates through all stages.
- **Design tradeoffs**:
  - **Parameter vs. accuracy**: 3.91M params achieves 100%; reducing to 2.85M drops accuracy to ~97.97%
  - **Conv blocks vs. pure Transformer**: Removing Conv blocks degrades performance, suggesting local feature extraction is necessary
  - **Downsampling dimensions**: Further reduction beyond current configuration causes "severe accuracy degradation"
- **Failure signatures**:
  - **Firing rate too low (<5%)**: Information bottleneck—insufficient gradients propagate
  - **Firing rate too high (>20%)**: Approaches ANN behavior, loses energy efficiency
  - **Validation accuracy plateaus early**: Check learning rate scheduler; ReduceLROnPlateau should trigger after plateau detection
  - **Class imbalance in predictions**: Verify CrossEntropyLoss class count balancing is applied
- **First 3 experiments**:
  1. **Baseline reproduction**: Train on 294 trials with reported hyperparameters (300 epochs, Adam, surrogate gradient). Verify 100% accuracy on held-out 104 trials. Log firing rates per layer to confirm ~7% average.
  2. **Ablation validation**: Remove one Conv-SNN block and retrain. Confirm ~2% accuracy drop and parameter reduction to ~2.85M. Document which layer's firing patterns change most.
  3. **Energy measurement**: Profile inference energy on actual hardware or simulator using 45nm CMOS assumptions. Compare measured µJ against reported 760.7 µJ, accounting for firing rate differences.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the lightweight spiking transformer's person identification accuracy scale with substantially larger and more diverse subject populations (e.g., hundreds or thousands of individuals across different demographics)?
- **Basis in paper**: [explicit] "While the model performed well on the 26-subject dataset used in this study, its generalizability to larger and more diverse populations remains uncertain. To fully assess the robustness and scalability of the model, further testing with more extensive datasets that incorporate a wider range of demographic and physiological variability is needed."
- **Why unresolved**: The study only evaluated 26 subjects, which is insufficient to establish scalability claims for real-world biometric applications requiring larger identification pools.
- **What evidence would resolve it**: Systematic evaluation on EEG datasets with 100+ subjects spanning diverse age groups, ethnicities, and physiological conditions, with accuracy trends reported as population size increases.

### Open Question 2
- **Question**: How robust is the spiking transformer's identification performance to variations in EEG signal quality, including different noise levels, artifact contamination, and electrode impedance fluctuations?
- **Basis in paper**: [explicit] "Future research should... explore their performance in environments with varying noise levels and signal quality. This would provide a more comprehensive understanding of the potential of SNNs in real-world EEG applications."
- **Why unresolved**: The dataset used preprocessed, controlled laboratory recordings with standard artifact removal (ICA); real-world deployment faces variable signal conditions that were not systematically tested.
- **What evidence would resolve it**: Controlled experiments adding synthetic noise at varying SNR levels, comparisons of performance with/without artifacts, and evaluation on datasets collected under less controlled conditions.

### Open Question 3
- **Question**: To what extent can the proposed architecture transfer to other EEG-based tasks (e.g., emotion recognition, motor imagery classification, cognitive load assessment) without substantial architectural modifications?
- **Basis in paper**: [explicit] "Additionally, future research should investigate the adaptability of SNNs to other EEG-based applications."
- **Why unresolved**: The architecture was optimized specifically for person identification using music-evoked EEG; its task-agnostic utility for other BCI paradigms remains unexplored.
- **What evidence would resolve it**: Cross-task transfer learning experiments evaluating the same architecture on established EEG benchmarks for emotion, motor imagery, and other classification tasks.

## Limitations
- The 100% accuracy claim rests on a relatively small test set (104 trials from 26 subjects), making statistical significance unclear.
- Energy consumption figures rely on theoretical CMOS models at 45nm rather than measured neuromorphic hardware performance.
- The model's perfect accuracy may indicate overfitting to the specific EEG music-listening task rather than generalizable identity features.

## Confidence

- **High confidence**: The architectural framework combining Conv-SNN and Transformer-SNN blocks with LIF neurons is technically sound and well-described.
- **Medium confidence**: The reported 3.91M parameter count and 760.7 µJ energy consumption are plausible based on the described architecture, though unverified empirically.
- **Low confidence**: The 100% accuracy claim requires independent verification due to the small test set size and lack of statistical validation.

## Next Checks

1. **Statistical validation**: Perform k-fold cross-validation (k=5 or k=10) on the 26 subjects and report confidence intervals for accuracy to establish statistical significance of the 100% claim.
2. **Hardware measurement**: Implement the model on actual neuromorphic hardware (e.g., Intel Loihi or BrainChip Akida) to measure real-world energy consumption rather than relying on theoretical CMOS estimates.
3. **Generalization test**: Evaluate the model on a different EEG dataset (e.g., motor imagery or resting-state) to verify that identity features learned from music listening generalize beyond the training domain.