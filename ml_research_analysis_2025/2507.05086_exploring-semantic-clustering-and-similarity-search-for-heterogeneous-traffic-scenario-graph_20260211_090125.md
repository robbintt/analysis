---
ver: rpa2
title: Exploring Semantic Clustering and Similarity Search for Heterogeneous Traffic
  Scenario Graph
arxiv_id: '2507.05086'
source_url: https://arxiv.org/abs/2507.05086
tags:
- scenarios
- scenario
- graph
- clustering
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a self-supervised method to learn vector representations
  of traffic scenarios for clustering and similarity search. Scenarios are represented
  as heterogeneous spatio-temporal graphs, capturing object states, map context, and
  temporal dynamics.
---

# Exploring Semantic Clustering and Similarity Search for Heterogeneous Traffic Scenario Graph

## Quick Facts
- **arXiv ID:** 2507.05086
- **Source URL:** https://arxiv.org/abs/2507.05086
- **Reference count:** 23
- **Primary result:** Self-supervised graph embeddings (BGRL) achieve 59.9% multi-label classification accuracy and enable interpretable clustering of traffic scenarios

## Executive Summary
This paper proposes a self-supervised method to learn vector representations of traffic scenarios for clustering and similarity search. Scenarios are represented as heterogeneous spatio-temporal graphs, capturing object states, map context, and temporal dynamics. Two graph embedding models—based on bootstrapping (BGRL) and contrastive learning (GraphCL)—are trained to produce embeddings where distances reflect semantic similarity. The BGRL variant outperforms GraphCL in downstream classification accuracy (59.9% vs 44.7%) and shows good generalization across unseen locations. HDBSCAN clustering of embeddings yields interpretable scenario groups (e.g., left turns, traffic-light stops) with a silhouette score of 0.375 and multi-label accuracy of 0.442, though a large fraction of samples remain unclustered. The approach enables scalable, label-free scenario organization for efficient simulation-based testing of automated vehicles.

## Method Summary
The method constructs heterogeneous spatio-temporal graphs from nuPlan traffic data, where nodes represent obstacles and road segments with various attributes, connected by four types of edges encoding spatial and temporal relationships. Two self-supervised GNN models—BGRL (bootstrapping) and GraphCL (contrastive)—are trained on these graphs to produce 128-dimensional embeddings. The BGRL model uses an online encoder, EMA-updated target encoder, and predictor MLP with cosine similarity loss, while GraphCL employs contrastive loss with in-batch negatives. After training, HDBSCAN clustering with min_cluster_size=25 is applied to the embeddings, and performance is evaluated via downstream multi-label classification and clustering metrics across nuPlan's boston, pittsburgh, and singapore splits.

## Key Results
- BGRL model achieves 59.9% multi-label classification accuracy, outperforming GraphCL's 44.7%
- HDBSCAN clustering yields a silhouette score of 0.375 and multi-label accuracy of 0.442
- 81.5% of samples remain unclustered, indicating significant variance or conservative clustering parameters
- Cross-dataset evaluation shows BGRL generalizes well to unseen locations (pittsburgh, singapore)

## Why This Works (Mechanism)
The approach works by learning embeddings where graph distances reflect semantic similarity through self-supervised training on augmented views. BGRL's bootstrapping objective encourages consistent representations across augmentations without requiring negative samples, while GraphCL's contrastive loss explicitly pulls similar scenarios together and pushes dissimilar ones apart. The heterogeneous graph structure captures both dynamic object states and static map context, enabling rich representations that encode complex traffic scenarios. The use of temporal reach and positional encoding preserves spatio-temporal relationships crucial for semantic similarity.

## Foundational Learning
- **Heterogeneous Graph Representation**: Traffic scenarios modeled as graphs with multiple node/edge types (obstacles, road segments, spatial/temporal links). *Why needed:* Captures complex multi-modal relationships in traffic scenes. *Quick check:* Verify all edge types are correctly instantiated with proper attributes.
- **Self-Supervised Learning**: BGRL and GraphCL train without labels by maximizing agreement between augmented views or contrasting positives/negatives. *Why needed:* Enables large-scale learning from unlabeled scenario data. *Quick check:* Monitor training loss curves for convergence patterns.
- **Graph Neural Networks**: Message passing over heterogeneous graphs aggregates information across node types and edges. *Why needed:* Learns context-aware representations from graph structure. *Quick check:* Inspect embedding dimensions after each GNN layer.
- **HDBSCAN Clustering**: Density-based clustering that handles varying densities and noise. *Why needed:* Groups semantically similar scenarios without assuming fixed cluster count. *Quick check:* Visualize embedding space with t-SNE/UMAP to verify cluster separation.
- **Augmentation Strategies**: Edge/attribute dropping and perturbation create diverse views for self-supervised training. *Why needed:* Prevents overfitting and encourages robust representations. *Quick check:* Compare embedding variance with/without augmentations.
- **Multi-Label Classification**: Scenarios belong to multiple semantic categories simultaneously. *Why needed:* Reflects real-world complexity where scenarios exhibit multiple behaviors. *Quick check:* Evaluate per-class precision/recall to identify systematic errors.

## Architecture Onboarding
- **Component Map**: Raw nuPlan data -> Graph construction -> GNN encoder -> 128-dim embedding -> HDBSCAN clustering
- **Critical Path**: Graph construction → GNN encoder training → Embedding generation → Clustering evaluation
- **Design Tradeoffs**: BGRL vs GraphCL (no negatives vs explicit contrastive loss), augmentation strength (robustness vs information loss), min_cluster_size (coverage vs purity)
- **Failure Signatures**: Poor downstream accuracy (<30%) suggests graph construction issues; high unclustered ratio (>85%) indicates embedding quality or clustering parameter problems
- **First Experiments**: 1) Verify graph construction with small dataset and visualize node/edge distributions, 2) Train BGRL on minimal data and check embedding variance, 3) Run HDBSCAN with varying min_cluster_size on pre-trained embeddings to assess clustering sensitivity

## Open Questions the Paper Calls Out
None

## Limitations
- 59.9% multi-label accuracy remains below theoretical maximum, suggesting incomplete semantic capture
- 81.5% of samples remain unclustered, potentially due to embedding variance or conservative clustering parameters
- Cross-dataset generalization tested only on two additional locations, limiting claims about broader applicability

## Confidence
- **Medium**: Methodology is clearly specified with strong downstream validation, but critical preprocessing and augmentation details are underspecified, preventing exact reproduction. Cross-dataset results are encouraging but limited in scope.

## Next Checks
1. Perform ablation on augmentation strength and types to determine impact on embedding semantic alignment
2. Visualize t-SNE/UMAP projections of learned embeddings to qualitatively assess cluster separation and outlier distribution
3. Test HDBSCAN sensitivity by varying min_cluster_size and min_samples to quantify trade-off between clustering coverage and purity