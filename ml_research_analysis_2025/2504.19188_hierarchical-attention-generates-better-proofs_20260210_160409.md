---
ver: rpa2
title: Hierarchical Attention Generates Better Proofs
arxiv_id: '2504.19188'
source_url: https://arxiv.org/abs/2504.19188
tags:
- proof
- arxiv
- hierarchical
- theorem
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Hierarchical Attention Generates Better Proofs

## Quick Facts
- arXiv ID: 2504.19188
- Source URL: https://arxiv.org/abs/2504.19188
- Authors: Jianlong Chen; Chao Li; Yang Yuan; Andrew C Yao
- Reference count: 32
- Key outcome: Hierarchical attention regularization improves proof success rates by 2% and reduces proof complexity

## Executive Summary
This paper introduces a hierarchical attention mechanism for formal theorem proving that imposes structured information flow constraints on transformer attention patterns. By defining a five-level hierarchy (context → case → type → instance → goal) and regularizing attention to respect these dependencies, the method achieves a 2% improvement in proof success rates while generating more concise proofs. The approach is evaluated on miniF2F and ProofNet benchmarks using a fine-tuned Pythia-2.8B model, demonstrating that structural regularization can enhance mathematical reasoning without sacrificing flexibility.

## Method Summary
The method imposes hierarchical attention constraints on transformer models through a five-level structure where tokens at higher levels can attend to same or lower levels, but not vice versa. A flow loss term penalizes invalid attention patterns, with layer-wise adaptation factors gradually relaxing constraints in deeper layers. The model is fine-tuned on LeanDojo Benchmark 4 with dataset-specific hyperparameters for λ (0.1-0.2) and constrained layers (4-16). Proofs are generated using best-first search with trajectory log-probability ranking.

## Key Results
- 2% improvement in pass@K accuracy on miniF2F and ProofNet benchmarks
- Proof complexity ratio Ravg of 0.76-0.78, indicating more concise proofs
- Attention visualization shows reduced invalid flows (0.5%-3.2% vs 5.5%-27.8% baseline)
- Ablation studies confirm the importance of layer-wise adaptation and flow loss

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Attention Flow Constraints
- Claim: Constraining attention to respect hierarchical dependencies improves proof generation by reducing invalid information flows.
- Mechanism: A five-level hierarchy (context → case → type → instance → goal) is imposed. Tokens at higher levels may attend to same or lower levels; reverse flows are penalized via attention masking and loss terms.
- Core assumption: Mathematical proofs have a natural partial order where foundational elements should inform goals, but not vice versa.
- Evidence anchors:
  - [abstract]: "establishes a five-level hierarchy from foundational elements to high-level concepts, ensuring structured information flow"
  - [section 4.1]: Flow types defined as unrestricted (same level), guided (lower→higher), limited (higher→lower)
  - [corpus]: Weak direct evidence; related work on structured representations exists but does not test this specific regularization.

### Mechanism 2: Layer-wise Adaptation Factor
- Claim: Gradually relaxing hierarchical constraints in deeper layers balances structural learning with reasoning flexibility.
- Mechanism: αl = 1 − l/L applies stronger regularization in early layers, weaker in later layers.
- Core assumption: Early layers should encode structural relationships; later layers need flexibility for complex reasoning.
- Evidence anchors:
  - [section 4.2]: Equation defines αl explicitly; Section 5.3.3 notes patterns persist even in unconstrained layers
  - [appendix A.3.1]: Ablation shows adaptation improves pass rates (e.g., miniF2F test: 30.74% → 31.56%) at cost of slightly longer proofs
  - [corpus]: No direct corpus evidence for this specific adaptation scheme.

### Mechanism 3: Flow Loss as Auxiliary Regularization
- Claim: Penalizing hierarchy-violating attention patterns induces internalization of structure beyond direct constraint enforcement.
- Mechanism: L_flow = (1/|T|) Σ αl · ReLU(attl(ti,tj) · (1-Mij)) added to cross-entropy loss.
- Core assumption: The model can learn to generalize hierarchical attention patterns from penalized examples to unconstrained layers.
- Evidence anchors:
  - [section 4.2, Equation 2-3]: Loss formulation and λ weighting
  - [section 5.3]: Attention patterns in unconstrained layers show reduced invalid flows (0.5%-3.2%) vs baseline (5.5%-27.8%)
  - [corpus]: Related work on attention regularization exists but not tested for theorem proving specifically.

## Foundational Learning

- **Concept: Causal masking in transformers**
  - Why needed here: Hierarchical attention builds on standard attention masking; understanding baseline masking is prerequisite.
  - Quick check question: Can you explain how causal masking prevents attending to future tokens?

- **Concept: Partial orders in mathematical logic**
  - Why needed here: The hierarchy (context ≺ case ≺ type ≺ instance ≺ goal) is a partial order; intuition about dependencies is essential.
  - Quick check question: In a proof, why should a "goal" depend on "context" but not the reverse?

- **Concept: Regularization trade-offs (λ selection)**
  - Why needed here: Flow loss weight λ controls constraint strength; understanding bias-variance tradeoff helps interpret ablation results.
  - Quick check question: What happens if λ → 0? What if λ → ∞?

## Architecture Onboarding

- **Component map**:
  Input Parser -> Attention Mask Builder -> Flow Loss Calculator -> Training Loop

- **Critical path**:
  1. Parse theorem text → assign levels {T0,...,T4}
  2. Build attention mask per layer
  3. Compute flow loss per batch
  4. Backpropagate combined loss (LLM + λ·L_flow)

- **Design tradeoffs**:
  - λ (0.1–0.2 per dataset): Higher values enforce stricter hierarchy but may reduce flexibility
  - Constrained layers L (4–16): More constrained layers = stronger structural induction
  - Fine-grained vs coarse-grained hierarchy: 5-level improves pass rates; 3-level may improve complexity ratios

- **Failure signatures**:
  - Pass rates drop below baseline → λ too high or L too large
  - Proof length increases without pass improvement → hierarchy too rigid
  - Explicit tags baseline fails (Table 12) → adding tags directly is harmful; use attention guidance instead

- **First 3 experiments**:
  1. Replicate miniF2F best-first search (K=64) with λ=0.1, L=4; verify ~31.56% pass rate and Ravg ~0.76
  2. Ablate layer-wise adaptation (set αl=1 for all layers); expect lower pass rates but shorter proofs
  3. Test on non-mathematical domain (e.g., code generation) to probe break condition; monitor for degraded performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed five-level hierarchy be effectively adapted to other proof assistants like Coq or Isabelle?
- Basis: [explicit] The authors state in the Limitations section that "the hierarchy definition is specific to Lean’s semantics and may require adaptation for other proof languages."
- Why unresolved: The current implementation relies on parsing Lean-specific syntax (e.g., turnstile `⊢` or specific keywords) which may not map one-to-one with the type theories or syntax of Coq or Isabelle.
- Evidence: Successful application of the method to standard benchmarks in Coq or Isabelle (e.g., Isabelle/Pisa) with comparable improvements in proof success rates.

### Open Question 2
- Question: Would a dynamic or learned hierarchy improve performance over the fixed five-level structure?
- Basis: [explicit] The paper notes that "the fixed hierarchy structure may limit dynamic reasoning patterns" and suggests future work should "explore adaptive hierarchies."
- Why unresolved: A rigid hierarchy imposes a static information flow that might not align with non-linear mathematical dependencies or diverse problem types.
- Evidence: A comparative study where the hierarchy constraints are learned end-to-end or dynamically adjusted per problem, showing superior pass rates over the static model.

### Open Question 3
- Question: Does the regularization effect of Hierarchical Attention scale to larger, state-of-the-art models?
- Basis: [explicit] The authors note "data constraints prevented evaluation on advanced models like DeepSeek-Prover (Xin et al., 2024) and InternLM-Math (Ying et al., 2024b)."
- Why unresolved: The experiments were limited to Pythia-2.8B; it is unclear if larger models already possess sufficient capacity to internalize these structures without explicit regularization.
- Evidence: Evaluating the method on models with >7B parameters (e.g., DeepSeek-Prover) to observe if the 2% improvement margin holds or diminishes.

### Open Question 4
- Question: How robust is the rule-based parsing algorithm against syntactic variations in complex Lean 4 code?
- Basis: [inferred] Algorithm 2 relies on "lightweight pattern-matching" (e.g., checking for "case" or `⊢`) to assign levels.
- Why unresolved: Simple string matching is brittle and may misclassify levels in proofs using heavy macros, custom tactics, or non-standard formatting, leading to incorrect attention masking.
- Evidence: An analysis of misclassified tokens on a diverse dataset like Mathlib, or a comparison against a syntax-tree-based parser.

## Limitations

- The five-level hierarchy is specific to Lean's syntax and may require adaptation for other proof assistants
- The rule-based parsing algorithm may struggle with complex or non-standard Lean code structures
- The relationship between hierarchical depth and reasoning quality remains underexplored

## Confidence

**High Confidence**: The core empirical claims regarding pass@K improvements on miniF2F and ProofNet datasets are well-supported by the experimental results. The ablation studies and attention visualization provide robust evidence for the hierarchical attention mechanism's effectiveness.

**Medium Confidence**: The mechanism explanations linking hierarchical attention constraints to improved proof generation are plausible but not definitively proven. The connection between reduced invalid attention flows and better reasoning could be influenced by other factors in the training process.

**Low Confidence**: Claims about the generalizability of the five-level hierarchy to other mathematical domains or proof assistants remain speculative. The break condition analysis suggests potential limitations in non-hierarchical domains, but this is not empirically tested.

## Next Checks

1. **Parser robustness test**: Apply the hierarchical attention framework to a subset of proofs with complex nested structures or alternative Lean syntax. Compare level assignment accuracy and downstream proof success rates to validate parser generalizability.

2. **Attention flow visualization**: Generate attention heatmaps for both baseline and hierarchical models on identical proof steps. Quantify the reduction in invalid flows (context→goal, goal→context) and correlate with proof success to strengthen the causal mechanism claim.

3. **Cross-domain transfer**: Evaluate the model on non-mathematical formal reasoning tasks (e.g., program verification or logical inference) to test the break condition. Measure whether hierarchical constraints help or hinder performance compared to baseline.