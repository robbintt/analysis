---
ver: rpa2
title: 'Comparative Study of Large Language Models on Chinese Film Script Continuation:
  An Empirical Analysis Based on GPT-5.2 and Qwen-Max'
arxiv_id: '2601.14826'
source_url: https://arxiv.org/abs/2601.14826
tags:
- gpt-5
- format
- qwen-max
- evaluation
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study compares GPT-5.2 and Qwen-Max on Chinese film script
  continuation, introducing the first Chinese script benchmark and multi-dimensional
  evaluation framework. GPT-5.2 significantly outperforms Qwen-Max in structural preservation
  (0.93 vs 0.75, d=0.46) and overall quality (44.79 vs 25.72, d=1.04), though Qwen-Max
  shows slightly higher ROUGE-L scores.
---

# Comparative Study of Large Language Models on Chinese Film Script Continuation: An Empirical Analysis Based on GPT-5.2 and Qwen-Max

## Quick Facts
- arXiv ID: 2601.14826
- Source URL: https://arxiv.org/abs/2601.14826
- Reference count: 29
- GPT-5.2 significantly outperforms Qwen-Max in structural preservation (0.93 vs 0.75) and overall quality (44.79 vs 25.72)

## Executive Summary
This study introduces the first Chinese film script benchmark and evaluates GPT-5.2 against Qwen-Max on script continuation tasks. The research employs a multi-dimensional evaluation framework combining human judgment and automated metrics. Results demonstrate that GPT-5.2 substantially outperforms Qwen-Max in structural preservation, character consistency, tone-style matching, and format preservation, with large effect sizes (d=0.46 for structure, d=1.04 for overall quality).

## Method Summary
The study establishes a comprehensive evaluation framework for Chinese film script continuation, combining automated metrics with human evaluation across multiple dimensions including structural preservation, character consistency, and tone-style matching. The research introduces a novel Chinese film script benchmark dataset and compares two large language models - GPT-5.2 and Qwen-Max - on their ability to generate coherent, contextually appropriate script continuations. The evaluation methodology integrates ROUGE-L scores with multi-dimensional human assessment to capture both lexical overlap and qualitative aspects of script generation.

## Key Results
- GPT-5.2 achieves significantly higher structural preservation scores (0.93) compared to Qwen-Max (0.75), with large effect size (d=0.46)
- GPT-5.2 demonstrates superior overall quality (44.79) versus Qwen-Max (25.72), with very large effect size (d=1.04)
- Despite GPT-5.2's overall superiority, Qwen-Max shows slightly higher ROUGE-L scores, revealing dissociation between lexical overlap metrics and quality judgment

## Why This Works (Mechanism)
The superior performance of GPT-5.2 in Chinese film script continuation can be attributed to its advanced understanding of narrative structure, character development, and genre-specific conventions. The model likely leverages more sophisticated attention mechanisms and larger context windows to maintain coherence across longer script segments. GPT-5.2's training on diverse multilingual data, including Chinese creative writing, enables better character consistency and tone-style matching, while its architectural optimizations support more stable generation patterns.

## Foundational Learning
- **Chinese linguistic patterns**: Understanding of Chinese syntax, idioms, and cultural references essential for authentic script generation
- **Film script formatting conventions**: Knowledge of proper screenplay structure, character cues, and dialogue formatting specific to Chinese cinema
- **Narrative coherence**: Ability to maintain plot consistency, character development, and thematic continuity across script continuations
- **Cross-modal understanding**: Integration of visual, auditory, and narrative elements typical in film scripts
- **Genre-specific knowledge**: Familiarity with conventions of different Chinese film genres (comedy, drama, action, etc.)
- **Creative writing principles**: Understanding of dramatic tension, pacing, and character arc development

## Architecture Onboarding
Component map: Input text -> Context encoder -> Narrative understanding module -> Character consistency checker -> Style matching layer -> Format preservation unit -> Output generator
Critical path: Context encoding → Narrative understanding → Character consistency → Output generation
Design tradeoffs: Larger context windows improve coherence but increase computational cost; emphasis on character consistency may reduce creative flexibility; format preservation can constrain stylistic innovation
Failure signatures: Inconsistent character behavior, abrupt tone shifts, formatting errors, logical plot inconsistencies, cultural reference mismatches
First experiments:
1. Generate continuations for simple two-character dialogue scenes and evaluate character voice consistency
2. Test continuation quality across different Chinese film genres (comedy, drama, action)
3. Compare performance on short versus long script continuation tasks to assess context window effectiveness

## Open Questions the Paper Calls Out
None

## Limitations
- Unclear model specifications for GPT-5.2 (potentially mislabeling or custom variant)
- Unclear dataset size despite described as "comprehensive"
- Human evaluation methodology lacks detail on rater training and inter-rater reliability

## Confidence
- High confidence: GPT-5.2's superior performance in structural preservation and overall quality metrics
- Medium confidence: Claims about Qwen-Max's lower generation stability and specific weaknesses in character consistency
- Low confidence: The dissociation between lexical overlap metrics and quality judgment

## Next Checks
1. Independent replication with verified model access: Obtain access to the specific GPT-5.2 and Qwen-Max models used, or equivalent versions, to reproduce the benchmark results on the Chinese film script dataset
2. Statistical validation of human evaluation: Conduct inter-rater reliability analysis (e.g., Cohen's kappa, Krippendorff's alpha) on the multi-dimensional quality assessment to verify the consistency and objectivity of human judgments
3. Expanded evaluation framework validation: Test whether the observed dissociation between ROUGE-L and quality scores persists across different creative writing domains and with alternative lexical overlap metrics to determine if this reflects fundamental limitations of ROUGE or specific characteristics of the dataset