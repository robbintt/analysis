---
ver: rpa2
title: Reinforcement Learning Closures for Underresolved Partial Differential Equations
  using Synthetic Data
arxiv_id: '2505.11308'
source_url: https://arxiv.org/abs/2505.11308
tags:
- equation
- solution
- burgers
- training
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel framework for developing closure models
  for coarse-grained PDEs using synthetic data generated via the method of manufactured
  solutions (MMS) and reinforcement learning (RL). The approach trains RL-based closures
  on synthetic data without requiring costly fine-grid simulations during training.
---

# Reinforcement Learning Closures for Underresolved Partial Differential Equations using Synthetic Data

## Quick Facts
- arXiv ID: 2505.11308
- Source URL: https://arxiv.org/abs/2505.11308
- Reference count: 18
- Key outcome: RL-based closures trained on synthetic MMS data achieve ~80% error reduction for underresolved PDEs, generalizing from forced to unforced cases without costly fine-grid simulations during training.

## Executive Summary
This work introduces a framework for developing closure models for coarse-grained PDEs using synthetic data generated via the method of manufactured solutions (MMS) and reinforcement learning (RL). The approach trains RL-based closures on synthetic data without requiring costly fine-grid simulations during training. The method is demonstrated on 1D and 2D Burgers' equations and 2D advection equation, showing significant error reduction for both in-distribution (inhomogeneous PDEs) and out-of-distribution (homogeneous PDEs) predictions. For the 1D Burgers' equation, the RL closures achieved a median cumulative error reduction of approximately 80% over the entire simulation. The results also show that RL closures generalize better than a Fourier Neural Operator-based approach for out-of-distribution tasks, highlighting their potential for accurate and computationally efficient closure modeling in systems with scarce data.

## Method Summary
The framework trains RL-based closure models on synthetic data generated via the Method of Manufactured Solutions (MMS). MMS prescribes analytical solutions ψ_MMS and computes exact forcing terms L(ψ_MMS) to satisfy the PDE, creating labeled training pairs without high-resolution simulation. The RL policy observes coarse solution states and outputs per-grid-point forcing corrections, trained via PPO to minimize deviation from subsampled fine solutions. The approach is demonstrated on 1D/2D Burgers' equations and 2D advection equation, achieving significant error reduction for both in-distribution (forced PDEs) and out-of-distribution (unforced PDEs) predictions.

## Key Results
- RL closures achieved ~80% median cumulative error reduction for in-distribution 1D Burgers' equation predictions.
- Closures generalized to homogeneous PDEs, reducing median error by ~80% despite training only on forced cases.
- RL closures outperformed Fourier Neural Operator approach for out-of-distribution homogeneous PDE predictions.

## Why This Works (Mechanism)

### Mechanism 1
- Synthetic data generated via MMS can substitute for expensive fine-grid simulation data when training closure models.
- MMS prescribes analytical solutions ψ_MMS, computes exact forcing L(ψ_MMS) required to satisfy the PDE, producing labeled training pairs without high-resolution simulation.
- Core assumption: manufactured solution family spans relevant solution manifold for target problems.
- Evidence anchors: Section 2.1 explains MMS approach; Section 3.1 details parameterized solutions; weak direct corpus support.

### Mechanism 2
- Reinforcement learning can learn corrective forcing terms that compensate for coarse-grid discretization errors.
- RL policy observes coarse solution state and outputs per-grid-point actions added to coarse update: ψ̃^{n+1} = F(ψ̃^n, C̃^n) + A^n.
- Reward R = [error_before]^2 - [error_after]^2 encourages actions that reduce deviation from fine solution.
- Core assumption: reward signal provides sufficient gradient for learning meaningful corrections.
- Evidence anchors: Section 2.3 details action-modified update and reward formulation; Figure 2 shows >80% error reduction; corpus suggests alternative closure strategies.

### Mechanism 3
- Closures trained on inhomogeneous PDEs generalize to homogeneous cases.
- Closure learns to model unresolved spatiotemporal interactions and numerical dissipation from coarse discretization that persist regardless of external forcing.
- Training with lower-magnitude forcing eases extrapolation to zero-forcing limit.
- Core assumption: unresolved-scale dynamics are structurally similar across forced and unforced regimes.
- Evidence anchors: Section 3.1.2 shows ~80% error reduction on homogeneous 1D Burgers'; Section 4 states generalization to homogeneous PDEs; no direct corpus validation.

## Foundational Learning

- **Coarse-graining and Closure Modeling**
  - Why needed here: Addresses trade-off between computational cost and accuracy when solving PDEs on coarse grids.
  - Quick check question: Can you explain why a coarse-grid simulation of Burgers' equation produces excessive diffusion compared to a fine-grid reference?

- **Proximal Policy Optimization (PPO)**
  - Why needed here: Closure model trained via PPO; understanding policy gradients and clipping objective helps diagnose training dynamics.
  - Quick check question: What does the entropy coefficient hyperparameter control in PPO, and why might a value of 0.02 be chosen?

- **Method of Manufactured Solutions (MMS)**
  - Why needed here: Data generation strategy; understanding how MMS constructs forced PDEs from prescribed solutions is essential.
  - Quick check question: Given ψ_MMS = t·cos(x), derive the forcing term L for the 1D Burgers' equation with ν=0.01.

## Architecture Onboarding

- **Component map:**
  - MMS Generator → produces (ψ_MMS, L) pairs with randomized parameters
  - Coarse-Grid Simulator (CGS) → upwind/central differences + explicit Euler
  - RL Environment → wraps CGS; state = (ψ̃^n, ψ̃^{n-1}, normalized L, C̃); action = per-point forcing correction
  - Policy Network → 6 Conv2D layers (dilated) with shared backbone for policy and value heads
  - PPO Trainer → updates policy using collected transitions

- **Critical path:**
  1. Sample MMS parameters → generate episode trajectory
  2. Run CGS forward; at each step, policy observes state and outputs action
  3. Compute reward via comparison to subsampled ψ_MMS
  4. Collect transitions; update policy via PPO after each epoch
  5. Validate on held-out homogeneous PDEs; select checkpoint

- **Design tradeoffs:**
  - Grid coarseness (d): More aggressive coarsening increases closure burden but reduces compute.
  - Episode length: Longer episodes provide more reward signal but risk blow-ups; MAE threshold enforces early termination.
  - MMS solution family: Broader parameter ranges improve coverage but may dilute learning signal.

- **Failure signatures:**
  - Episodes terminate early during training (MAE threshold exceeded) → policy not learning corrections; check learning rate or reward scaling.
  - In-distribution error low but homogeneous error high → MMS solutions may not span relevant dynamics; add diversity or reduce forcing magnitude.
  - Training reward plateaus at negative values → reward formulation may be misaligned; verify subsampling operator and reward sign.

- **First 3 experiments:**
  1. Reproduce 1D Burgers' results with identical hyperparameters; confirm ~80% error reduction on held-out MMS samples.
  2. Ablate MMS design: train with only homogeneous solutions (no forcing) and compare generalization to forced cases.
  3. Vary coarse-to-fine ratio (d): test d=8, 16, 32 to characterize trade-off between closure difficulty and computational savings.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does an optimal set of manufactured solutions exist that ensures robust training outcomes and strong extrapolative capabilities for the closure models?
- **Basis in paper:** [explicit] The authors state that future research will focus on the "optimal selection of MMS solutions" to determine if specific sets of solutions yield better training results.
- **Why unresolved:** The paper manually selected parameterized trigonometric functions for the synthetic data but did not systematically analyze the information content or diversity of solutions required for optimality.
- **What evidence would resolve it:** A comparative study of models trained on distinct MMS distributions, identifying specific solution characteristics (e.g., frequency content, gradient steepness) that correlate with lower generalization error on benchmark tests.

### Open Question 2
- **Question:** Can the computational efficiency and accuracy of the RL closure framework be sustained when applied to complex, higher-dimensional PDE systems?
- **Basis in paper:** [explicit] The conclusion acknowledges that while results are promising, efficiency gains "should be further evaluated against more complex, higher-dimensional PDE systems."
- **Why unresolved:** The current demonstrations are limited to 1D and 2D cases (Burgers and advection equations); the performance of the specific RL architecture in high-dimensional state spaces (e.g., 3D turbulence) remains untested.
- **What evidence would resolve it:** Successful application of the method to a 3D Navier-Stokes simulation, demonstrating that the RL closure maintains error reduction without prohibitive increases in training time or memory usage.

### Open Question 3
- **Question:** Can the framework be adapted for systems with partially unknown dynamics where analytical source terms cannot be derived?
- **Basis in paper:** [inferred] The paper lists a key limitation: "complete knowledge of the underlying PDE is required," making the method currently inapplicable to systems with uncertain governing equations.
- **Why unresolved:** The Method of Manufactured Solutions relies on analytically differentiating a known solution to create a source term; this process fails if the governing equations are not fully known.
- **What evidence would resolve it:** A modified methodology (e.g., combining MMS with sparse identification or Bayesian inference) that successfully trains a closure model on a system where parts of the governing physics are obscured or missing.

### Open Question 4
- **Question:** Does integrating synthetic data generation with differentiable solvers enable the effective training of alternative data-driven closure models?
- **Basis in paper:** [explicit] The authors identify "integrating our approach... with differentiable solvers" as a promising direction for broadening the applicability of the methodology.
- **Why unresolved:** The current framework uses a standard coarse-grid simulation; it is unknown if providing gradient information through a differentiable solver would improve convergence or accuracy for other model classes.
- **What evidence would resolve it:** A comparative analysis showing that gradient-based models (e.g., neural operators) trained via differentiable solvers on MMS data achieve comparable or superior performance to the RL agent.

## Limitations
- MMS approach assumes manufactured solutions capture relevant dynamics; if solutions miss critical phenomena like shocks or boundary layers, closures may not generalize effectively.
- Generalization to homogeneous PDEs is demonstrated but relies on structural similarity between forced and unforced regimes; cross-PDE generalization remains untested.
- PPO hyperparameters and training stability are not fully characterized; performance may be sensitive to learning rate, entropy coefficient, or episode length choices.

## Confidence

- **High Confidence**: The RL framework can learn corrective forcing terms that reduce coarse-grid errors for in-distribution PDEs when trained on synthetic data; error reductions of ~80% are reproducible.
- **Medium Confidence**: Closures generalize from forced to unforced PDEs due to shared unresolved-scale dynamics; this claim is supported but not extensively validated across diverse PDE types.
- **Low Confidence**: The RL approach consistently outperforms all alternative closure strategies (e.g., FNO, SINDy) across all tested scenarios; the paper only compares to one alternative method.

## Next Checks
1. **Robustness to MMS design**: Systematically vary the manufactured solution family (e.g., include non-periodic solutions, different forcing profiles) and measure impact on generalization performance.
2. **Cross-PDE generalization**: Train closures on one PDE type (e.g., Burgers) and test on structurally different PDEs (e.g., Navier-Stokes, Kuramoto-Sivashinsky) to assess domain transfer capability.
3. **Computational efficiency benchmark**: Quantify wall-clock time and memory usage for RL-trained closures versus fine-grid simulations and alternative closure methods across 2D problems.