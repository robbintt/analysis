---
ver: rpa2
title: 'orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation
  of Surgical Images and Ground Truth Labels'
arxiv_id: '2506.14303'
source_url: https://arxiv.org/abs/2506.14303
tags:
- image
- surgical
- images
- organ
- bleeding
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces orGAN, a GAN-based pipeline that generates
  synthetic surgical images annotated with precise bleeding coordinates. The approach
  leverages StyleGAN3 with Relational Positional Learning (RPL) to embed bleeding
  locations, then extracts them via a custom Surgical Label Detection Algorithm (SLDA)
  and removes the markers using LaMa-based inpainting to produce clean images.
---

# orGAN: A Synthetic Data Augmentation Pipeline for Simultaneous Generation of Surgical Images and Ground Truth Labels

## Quick Facts
- arXiv ID: 2506.14303
- Source URL: https://arxiv.org/abs/2506.14303
- Reference count: 40
- Primary result: orGAN generates synthetic surgical images annotated with precise bleeding coordinates, achieving 90% detection accuracy when blended 50:50 with real data.

## Executive Summary
orGAN introduces a GAN-based pipeline that generates synthetic surgical images annotated with precise bleeding coordinates. The approach leverages StyleGAN3 with Relational Positional Learning (RPL) to embed bleeding locations, then extracts them via a custom Surgical Label Detection Algorithm (SLDA) and removes the markers using LaMa-based inpainting to produce clean images. This enables scalable, ethically sourced training data for bleeding detection. Evaluations show that a balanced mix of orGAN-generated and real mimicking-organ images yields 90% detection accuracy in surgical settings and up to 99% frame-level accuracy. The method advances surgical AI by providing realistic, annotated data without relying on patient-derived sources.

## Method Summary
orGAN uses StyleGAN3 with RPL to embed black "X" markers at bleeding locations during image generation. These markers are extracted via SLDA (thresholding, morphology, contour detection, centroid calculation) to obtain ground truth coordinates. LaMa inpainting removes markers to produce clean synthetic images. The pipeline outputs synthetic surgical images + pixel-level bleeding coordinate annotations. A downstream Bleeding Alert Map (BAM) model trained on a 50:50 blend of orGAN and mimicking-organ images achieves high bleeding detection accuracy on real surgical video datasets.

## Key Results
- Balanced mix of orGAN-generated and real mimicking-organ images yields 90% detection accuracy in surgical settings
- Frame-level bleeding detection accuracy reaches up to 99%
- SLDA achieves >99% accuracy in label extraction via manual validation
- Best blend ratio is 50:50 (orGAN:mimicking), outperforming pure synthetic or pure real datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Embedding positional coordinates during GAN generation enables automatic label extraction without manual annotation.
- Mechanism: Relational Positional Learning (RPL) augments each pixel's intensity with its (x, y) coordinates, forcing the generator to learn spatial relationships. Black "X" markers are visually embedded at bleeding locations. The discriminator evaluates both realism and positional correctness via a modified loss: L = LGAN1 + λLGAN2.
- Core assumption: The GAN can simultaneously learn realistic texture synthesis and precise spatial marker placement without degradation to either objective.
- Evidence anchors:
  - [section 4.5.2] "We augment each pixel by appending (x, y), forming: I'(x, y) = (I(x, y), x, y)"
  - [section 4.5.5] "Switching to black (RGB: 0,0,0) significantly improved label contrast and reduced pixel interference"
  - [corpus] GAUDA paper similarly addresses joint synthesis of (image, mask) pairs for segmentation, confirming this as an active research direction.
- Break condition: Dense labeling (>3–4 markers per image) degrades RPL performance; color leakage occurs with red/green markers due to tissue tone overlap.

### Mechanism 2
- Claim: Automated extraction of embedded labels via computer vision yields accurate ground truth coordinates for supervised training.
- Mechanism: SLDA applies thresholding, morphological operations (dilation then erosion), contour detection, and centroid calculation to locate "X" markers. Outputs are 2D bleeding coordinates.
- Core assumption: Markers are sufficiently distinct from background after preprocessing, and centroid calculation approximates true bleeding location.
- Evidence anchors:
  - [section 4.6.3] Full algorithmic specification with mathematical formulation for centroid: (xc, yc) = (1/N Σxi, 1/N Σyi)
  - [section 4.6.1] Claims ">99% accuracy" validated via manual inspection
  - [corpus] No direct corroboration found; corpus focuses on segmentation masks rather than point-coordinate extraction.
- Break condition: Low-contrast markers, overlapping labels, or heavy image artifacts cause detection failures; automated heuristics discard such images.

### Mechanism 3
- Claim: Blending synthetic orGAN images with mimicking-organ images at 1:1 ratio optimizes downstream bleeding detection on real surgical video.
- Mechanism: Synthetic data expands diversity while mimicking-organ data anchors domain realism. The combination improves generalization: the 50:50 blend achieved 0.858 accuracy on Hamlyn 1 and 0.999 on Hamlyn 2, versus 0.586/0.924 (original only) and near-zero (orGAN only).
- Core assumption: Synthetic images capture relevant bleeding features without introducing distribution shift that harms real-domain transfer.
- Evidence anchors:
  - [abstract] "balanced mix of orGAN-generated and real mimicking-organ images yields 90% detection accuracy in surgical settings"
  - [section 5.6.2, Tables 1–2] Quantitative breakdown showing 50:50 blend outperforms both extremes
  - [corpus] Generative data augmentation for biliary tract detection reports similar augmentation benefits for intraoperative imaging.
- Break condition: Pure synthetic data (orGAN 100%) fails on real surgical scenes—domain gap too large without real-data anchoring.

## Foundational Learning

- **Generative Adversarial Networks (GANs)**
  - Why needed here: orGAN builds on StyleGAN3; understanding generator-discriminator dynamics, mode collapse, and training instability is prerequisite.
  - Quick check question: Can you explain why the discriminator must not dominate training, and what symptoms indicate mode collapse?

- **Style Transfer / StyleGAN Architecture**
  - Why needed here: StyleGAN3 provides the base generator; phase training (PI → PII) and style-based synthesis are central to image quality.
  - Quick check question: What does "style-based generation" mean in contrast to traditional GAN generators, and why does StyleGAN3 reduce aliasing artifacts?

- **Image Inpainting with Fourier Convolutions**
  - Why needed here: LaMa uses Fast Fourier Convolution (FFC) layers to inpaint large masked regions while preserving texture.
  - Quick check question: How do FFC layers differ from standard convolutions in capturing global context for inpainting?

## Architecture Onboarding

- **Component map:**
  Input: Mimicking-organ images with bleeding events
  Generator: StyleGAN3 Phase II → RPL-modified generator (embeds black "X" markers at bleeding coordinates)
  Label Extraction: SLDA (threshold → morphology → contours → centroids)
  Post-processing: LaMa inpainting (mask markers → restore clean tissue)
  Output: Synthetic surgical images + pixel-level bleeding coordinate annotations
  Downstream: Pix2PixHD-trained Bleeding Alert Map (BAM) model

- **Critical path:**
  1. Train StyleGAN3 on mimicking-organ dataset (two-phase training for stability)
  2. Apply RPL with transfer learning from SG3 PII weights
  3. Generate images with embedded markers
  4. Run SLDA to extract coordinates
  5. Inpaint markers via LaMa to produce clean images
  6. Train BAM model on 50:50 blend (orGAN + mimicking-organ)

- **Design tradeoffs:**
  - Black vs. colored markers: Black maximizes contrast but requires inpainting; red/green leak into tissue tones.
  - Blend ratio: Pure synthetic fails on real data; pure original has limited diversity; 50:50 empirically optimal.
  - IS vs. clinical relevance: Inception Score is out-of-domain for surgical images; use as relative comparator only.

- **Failure signatures:**
  - orGAN-only BAM produces near-zero accuracy on real surgical video → domain shift too severe
  - Red/green markers → color bleeding into tissue, SLDA extraction errors
  - Dense labels (>3–4 markers) → RPL performance degradation
  - Low SSIM after inpainting (<0.95) → LaMa not fine-tuned on surgical domain

- **First 3 experiments:**
  1. Replicate StyleGAN3 training on mimicking-organ data; compare PI vs. PII Inception Scores and visual coherence.
  2. Ablate marker color (black, green, red, dotted green); measure IS, training time, and SLDA extraction accuracy.
  3. Train BAM models on three dataset compositions (100% original, 100% orGAN, 50:50 blend); evaluate SSIM on held-out mimicking-organ images and frame-level accuracy on Hamlyn datasets.

## Open Questions the Paper Calls Out

- **Generalization across surgical environments**: The authors note that generalization to diverse surgical environments remains uncertain due to limited dataset coverage of lighting conditions, organ textures, and surgical artifacts.

- **Optimal marker characteristics**: Future work will explore the impact of marker shape and size on SLDA and RPL performance beyond the color configurations already tested.

- **Dense labeling performance**: The authors acknowledge that RPL performance degrades with dense labeling (>3–4 markers per image) but do not demonstrate successful multi-bleeding-point synthesis scenarios.

- **Domain-specific evaluation metrics**: The authors plan to incorporate CFID, KID, and CMMD metrics to provide more nuanced evaluation of generative quality and label reliability than Inception Score.

## Limitations

- The mimicking organ dataset is not publicly available, limiting reproducibility and external validation.
- Domain-specific metrics like CFID, KID, and CMMD are not used, though the authors acknowledge Inception Score is out-of-domain for surgical images.
- RPL performance degrades with dense labeling (>3–4 markers per image), limiting scalability to complex bleeding scenarios.

## Confidence

- **orGAN pipeline generates realistic surgical images with precise bleeding coordinates**: **High** — Core ablation studies (marker colors, blend ratios) support this.
- **SLDA extracts >99% accurate labels automatically**: **Medium** — Based on manual validation; no independent replication possible without access to data.
- **50:50 blend of orGAN:mimicking images optimizes BAM performance**: **High** — Quantitative results show clear superiority over pure synthetic or pure real.
- **Inception Score is a valid proxy for surgical image quality**: **Low** — Out-of-domain metric; relative comparisons only meaningful.

## Next Checks

1. Replicate StyleGAN3 + RPL training on a publicly available surgical endoscopy dataset (e.g., Kvasir) with synthetic bleeding annotations. Compare IS, visual quality, and SLDA extraction accuracy against the mimicking organ results.

2. Ablate the marker color space beyond black/red/green (e.g., blue, magenta, dotted variants) and measure impact on GAN stability, SLDA accuracy, and LaMa inpainting SSIM. Report the trade-off frontier.

3. Evaluate BAM generalization by training on orGAN+mimicking blend and testing on a third, held-out surgical video dataset (e.g., Cholec80 or EndoVis). Report both frame-level and pixel-level bleeding detection accuracy, and compare against models trained on original data only.