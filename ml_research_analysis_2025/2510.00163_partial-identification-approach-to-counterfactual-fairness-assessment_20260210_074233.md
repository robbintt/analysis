---
ver: rpa2
title: Partial Identification Approach to Counterfactual Fairness Assessment
arxiv_id: '2510.00163'
source_url: https://arxiv.org/abs/2510.00163
tags:
- counterfactual
- fairness
- causal
- algorithm
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the challenge of assessing counterfactual fairness
  when the true causal model is unknown or partially known. It introduces a partial
  identification approach that computes informative bounds on counterfactual fairness
  measures (direct, indirect, and spurious effects) using only observational data
  and a learned causal diagram.
---

# Partial Identification Approach to Counterfactual Fairness Assessment

## Quick Facts
- arXiv ID: 2510.00163
- Source URL: https://arxiv.org/abs/2510.00163
- Reference count: 13
- Primary result: Partial identification computes bounds on counterfactual fairness measures (DE, IE, SE) from observational data when the causal model is unknown

## Executive Summary
This paper introduces a partial identification approach to assess counterfactual fairness when the true causal model is unknown or partially known. The method computes informative bounds on counterfactual fairness measures using only observational data and a learned causal diagram, eliminating the need for strong parametric assumptions. Applied to the COMPAS recidivism dataset, the algorithm reveals a 25.5% spurious effect when race changes to African-American, a negative direct effect for age over 30, and inconclusive results for sex.

## Method Summary
The algorithm takes observational data and a causal diagram as inputs, then uses Bayesian sampling (Gibbs) to explore the space of possible structural models consistent with the data. It computes bounds on counterfactual fairness measures by sampling from posterior distributions over exogenous variables and structural functions. The method leverages discrete latent variables with bounded cardinality based on c-component structure, and iteratively updates beliefs about the causal structure through a Markov chain Monte Carlo approach.

## Key Results
- Algorithm bounds counterfactual fairness measures (direct, indirect, spurious effects) from observational data
- Applied to COMPAS dataset: 25.5% spurious effect when race changes to African-American
- Negative direct effect (-2.3%) for age over 30, inconclusive results for sex
- Validated on synthetic data where bounds contain true counterfactual values

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Partial identification can bound counterfactual fairness measures when exact identification is impossible
- Mechanism: The algorithm explores the space of all structural causal models consistent with observational data and causal diagram, sampling from posterior distributions over exogenous variables P(U) and structural functions f_V to generate bounds rather than point estimates
- Core assumption: The true causal diagram G is known or can be learned from data via causal discovery
- Evidence anchors:
  - [abstract] "It introduces a partial identification approach that computes informative bounds on counterfactual fairness measures... using only observational data and a learned causal diagram"
  - [Section 3] "Our goal in this paper is to address these challenges. We introduce a novel partial identification algorithm that could bound any counterfactual fairness measure from observational data"
  - [corpus] Related work on counterfactual testing (CST framework) addresses similar identification challenges but for individual discrimination detection
- Break condition: If the causal diagram is misspecified, bounds may not contain the true counterfactual value; domain knowledge must correctly constrain equivalence classes

### Mechanism 2
- Claim: Discrete latent variables with bounded cardinality are sufficient to represent both observational and counterfactual quantities
- Mechanism: The algorithm bounds exogenous variable cardinality K_i by d_i + 1 where d_i = Π_{V∈Pa(C(U_i))}|V|, based on c-component structure; this discretization preserves all relevant probability mass
- Core assumption: Endogenous variables are discrete and finite
- Evidence anchors:
  - [Section 3.1] "Ki = d_i + 1, where d_i = Π_{V∈Pa(C(U_i))}|V|" with Theorem 3.2 proving existence of equivalent discrete SCM
  - [Section 4] Simulation validation: "The results consistently contained the ground truth within the (1−δ)% confidence interval for all three quantities with δ=0.05"
  - [corpus] No direct corpus evidence on cardinality bounds; this is a novel contribution
- Break condition: If endogenous variables are continuous or infinite, discretization may introduce approximation error beyond theoretical guarantees

### Mechanism 3
- Claim: Gibbs sampling over exogenous distributions and structural functions yields valid posterior counterfactual bounds
- Mechanism: SampleCTF alternates between (1) sampling U^t given observations and current q, (2) updating Dirichlet posterior over P(U), (3) drawing new q from posterior; after burn-in, computes counterfactual measures from sampled parameters
- Core assumption: The Markov chain converges to the true posterior distribution
- Evidence anchors:
  - [Section 3.1] "It is a Bayesian sampling algorithm that takes three elements as inputs" with Theorem 3.3 proving "SampleCTF(D,G,µ) draws a posterior sample of the target counterfactual measure µ"
  - [Section 4, Fig. 2] Histograms show sampled distributions contain ground truth values
  - [corpus] Corpus papers discuss fairness measures but not partial identification methodology
- Break condition: If burn-in period M is insufficient or chain doesn't mix well (as seen in A=Sex case with wide confidence intervals), bounds become uninformative

## Foundational Learning

- Concept: **Structural Causal Models (SCMs) and counterfactuals**
  - Why needed here: The entire framework depends on understanding interventions do(x), potential responses Y_x(u), and how counterfactual distributions differ from observational ones
  - Quick check question: Given an SCM with A→Y and unobserved U→Y, can you write P(y_{a'}|a) in terms of the structural functions?

- Concept: **C-components and identifiability**
  - Why needed here: Determining exogenous cardinality K requires identifying c-components (clusters connected by bi-directed paths)
  - Quick check question: In a graph A←U₁→Y←U₂→W, how many c-components exist and what variables belong to each?

- Concept: **Dirichlet distributions and conjugate priors**
  - Why needed here: The Gibbs sampler uses Dirichlet posteriors to sample probability vectors over discrete latent states
  - Quick check question: If you observe counts [3, 5, 2] for a 3-state discrete variable with Dirichlet(α,α,α) prior, what is the posterior?

## Architecture Onboarding

- Component map:
  1. **IDFair (Algorithm 1)**: Main entry point; orchestrates causal discovery → graph filtering → bound computation
  2. **FCI (external)**: Causal discovery producing equivalence class of DAGs from observational data
  3. **SampleCTF (Algorithm 2)**: Core sampling engine for posterior counterfactual bounds given a specific causal graph
  4. **Cardinality computation**: Determines K_i for each U_i based on c-component parent product (Eq. 6)
  5. **Counterfactual measure evaluator**: Computes DE, IE, SE, or other measures from sampled (q, f_V)

- Critical path:
  1. Load observational data D and specify target measure µ
  2. Run FCI to get equivalence class E
  3. Apply domain knowledge to filter E → E*
  4. For each G_i in E*: compute cardinalities, run SampleCTF with burn-in M and samples N
  5. Aggregate samples across graphs, sort, return (1-δ)% confidence interval

- Design tradeoffs:
  - Higher K (exogenous cardinality) → more expressive but slower convergence and higher variance
  - Larger M (burn-in) → better convergence but more computation
  - More graphs in E* → more robust but wider bounds
  - Smaller δ → wider intervals but higher confidence

- Failure signatures:
  - Bounds don't contain known ground truth (synthetic validation): K too low or graph misspecified
  - Confidence intervals extremely wide (>50%): Insufficient burn-in, poor mixing, or fundamentally unidentifiable structure
  - Convergence plots show oscillation without settling: Increase M or check for model misspecification
  - All samples cluster at boundary values: Prior too informative or data inconsistent with graph

- First 3 experiments:
  1. **Synthetic validation**: Generate data from known SCM (as in Section 4), run full pipeline, verify ground truth falls within 95% CI for DE/IE/SE
  2. **Cardinality sensitivity**: On same synthetic data, vary K from minimum (d_i+1) to 3×minimum; plot bound width vs. K to find sweet spot
  3. **Burn-in diagnostics**: Track convergence of recoverable quantity (e.g., P(Y|A)) during sampling; plot trace to determine adequate M for new datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the partial identification approach be extended to handle continuous or mixed-type variables without relying on discrete cardinality bounds?
- Basis in paper: [explicit] The paper states in Section 2, "Throughout this paper, we assume that domains of endogenous variables V are discrete and finite," and notes in Section 1 that the algorithm applies to "any categorical data."
- Why unresolved: The current method (Theorem 3.2) relies on bounding exogenous cardinality ($K$) based on the finite states of endogenous variables, which does not translate directly to continuous domains.
- What evidence would resolve it: A theoretical extension of the canonical parameterization (Eq. 6) for continuous variables or a demonstration of the algorithm on non-categorical data.

### Open Question 2
- Question: How should auditors resolve contradictions between different counterfactual fairness measures (e.g., Counterfactual Effect vs. Spurious Effect) when they yield divergent conclusions?
- Basis in paper: [explicit] Section 6 notes that "consensus on its precise definition remains elusive" and highlights that "observing CE=0 does not guarantee [no] DE, IE, or SE," leading to instances where "certain definitions are deemed inadmissible."
- Why unresolved: The paper shows that for Race, CE was zero while SE was significant (25.5%), leaving the decision of which metric defines "unfairness" in a real-world audit open to interpretation.
- What evidence would resolve it: A principled framework or theoretical guidance on selecting appropriate counterfactual metrics for specific regulatory or ethical contexts.

### Open Question 3
- Question: How robust are the derived fairness bounds to the granularity of variable definitions, specifically the binarization of protected attributes?
- Basis in paper: [explicit] Section 6 states, "In our analysis, race is defined as a binary variable: Black versus Others... if we had defined the Race variable as Hispanic versus Others, the results would have been entirely different."
- Why unresolved: The method relies on the specific definitions of variables used in the causal discovery and sampling phases, but the sensitivity of the bounds to these subjective definitions remains unquantified.
- What evidence would resolve it: A sensitivity analysis showing the variance in bounds (DE, IE, SE) across different valid variable discretizations or groupings.

## Limitations
- The method assumes discrete and finite endogenous variables, limiting application to continuous data
- Results depend heavily on the correctness of the learned causal diagram from observational data
- Binarization of protected attributes (e.g., race) can significantly affect fairness conclusions

## Confidence
- **High confidence** in partial identification approach validity and theoretical guarantees
- **Medium confidence** in empirical results due to missing implementation details (α, initialization)
- **Medium confidence** in COMPAS analysis conclusions pending exact DAG specification

## Next Checks
1. **Synthetic Ground Truth Verification**: Run the full pipeline on the known SCM from Section 4 with 95% confidence intervals; verify all three ground truth values (DE=0.2, IE=0.1, SE=0.3) fall within bounds

2. **Cardinality Sensitivity Analysis**: On same synthetic data, systematically vary K from d_i+1 to 3×(d_i+1); plot resulting CI width and check for diminishing returns to determine optimal K

3. **Burn-in Convergence Diagnostics**: Implement trace plots for P(Y=1|A=0) during sampling; formally test for stationarity using statistical convergence diagnostics (e.g., Gelman-Rubin) to determine minimum adequate M for new datasets