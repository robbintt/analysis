---
ver: rpa2
title: Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal
  Transfer
arxiv_id: '2511.15741'
source_url: https://arxiv.org/abs/2511.15741
tags:
- multimodal
- learning
- uncertainty
- cross-modal
- page
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis tackles the challenge of building robust multimodal
  learning systems under conditions of noisy data, low-quality labels, and modality
  heterogeneity, especially in brain-computer interfaces and human-computer interaction
  contexts. It introduces a framework for uncertainty-resilient multimodal learning
  based on consistency-guided cross-modal transfer, where semantic consistency across
  heterogeneous modalities is leveraged to stabilize representation learning and enhance
  robustness.
---

# Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer

## Quick Facts
- **arXiv ID:** 2511.15741
- **Source URL:** https://arxiv.org/abs/2511.15741
- **Reference count:** 0
- **Primary result:** Introduces uncertainty-resilient multimodal learning framework combining cross-modal knowledge distillation with uncertainty-aware sample selection for EEG-based emotion recognition

## Executive Summary
This thesis addresses the challenge of building robust multimodal learning systems under noisy data, low-quality labels, and modality heterogeneity. The proposed framework leverages semantic consistency across heterogeneous modalities to stabilize representation learning and enhance robustness. By combining knowledge distillation from semantically richer modalities with uncertainty-aware sample selection, the approach enables effective learning even under imperfect supervision. Experiments on multimodal affect recognition benchmarks demonstrate significant improvements in model stability, discriminative ability, and robustness compared to both unimodal and multimodal baselines.

## Method Summary
The framework introduces uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. It employs prototype-based similarity alignment between EEG and visual modalities using cosine similarity and InfoNCE contrastive loss. Student features are injected into the teacher's task-specific head at an intermediate layer rather than the input, enabling semantic-level alignment. Dirichlet-based uncertainty estimation derived from prototype similarity enables sample-wise reweighting, reducing influence of ambiguous or mislabeled samples. The approach also incorporates cross-modal consistency-guided active learning, using disagreement between modalities as an uncertainty signal for sample acquisition to improve label efficiency.

## Key Results
- Significant improvements in model stability, discriminative ability, and robustness compared to unimodal and multimodal baselines
- Feature space analyses confirm the framework's ability to capture reliable cross-modal structure under challenging conditions
- Active learning experiments show the proposed method matches full-supervision performance with only 50% of labels
- Ablation studies demonstrate synergy between uncertainty loss and knowledge distillation components

## Why This Works (Mechanism)

### Mechanism 1: Cross-Modal Knowledge Distillation via Prototype Alignment
- **Claim:** Transferring semantic knowledge from visually richer modality to noisier EEG modality stabilizes representation learning under label noise
- **Mechanism:** Prototype-based similarity module aligns EEG and visual embeddings using cosine similarity and InfoNCE contrastive loss. Student features injected into teacher head at intermediate layer forces alignment at higher semantic levels
- **Core assumption:** Visual modality provides semantically richer, more reliable representations than EEG for affective states
- **Evidence anchors:** Abstract states framework "combines knowledge distillation from semantically richer modalities with uncertainty-aware sample selection"; Section 3.1.2 details student feature injection at intermediate layer

### Mechanism 2: Dirichlet-Based Uncertainty Estimation for Adaptive Reweighting
- **Claim:** Aleatoric uncertainty from prototype similarity enables sample-wise reweighting, reducing influence of ambiguous or mislabeled samples
- **Mechanism:** Similarity to class prototypes used to compute Dirichlet concentration parameters, then derive evidence-based uncertainty for adaptive training influence
- **Core assumption:** High cross-modal disagreement indicates genuine label noise or semantic ambiguity rather than valid boundary cases
- **Evidence anchors:** Section 3.1.1 describes Dirichlet concentration parameter computation; Table 4.3 shows L_unc + L_kd synergy

### Mechanism 3: Cross-Modal Consistency-Guided Active Learning
- **Claim:** Using cross-modal disagreement as uncertainty signal for sample acquisition improves label efficiency vs. unimodal entropy-based selection
- **Mechanism:** Cross-modal reliability target from average similarity of EEG embeddings to non-matched face embeddings; low reliability → high uncertainty → prioritize for annotation
- **Core assumption:** Cross-modal disagreement indicates genuine model uncertainty rather than modality-specific noise
- **Evidence anchors:** Section 4.6 shows proposed method matches full-supervision at 50% labels; Figure 4.2 demonstrates uncertainty reduction over AL iterations

## Foundational Learning

- **Concept: Knowledge Distillation (KD)**
  - **Why needed here:** Framework transfers from visual→EEG modalities; understanding logit-based vs. feature-based vs. adaptive KD is prerequisite
  - **Quick check question:** Can you explain why directly matching output logits between EEG and visual models may fail, and why intermediate feature alignment is preferred?

- **Concept: Dirichlet Distribution for Uncertainty Quantification**
  - **Why needed here:** Uncertainty module uses Dirichlet concentration parameters to derive evidence-based confidence scores
  - **Quick check question:** How does the Dirichlet distribution differ from Gaussian-based uncertainty estimation, and why is it suitable for classification-style evidence aggregation?

- **Concept: Contrastive Learning (InfoNCE)**
  - **Why needed here:** Prototype similarity module uses InfoNCE-style contrastive loss to align matched EEG-visual pairs
  - **Quick check question:** In InfoNCE loss, what happens to the gradient signal when off-diagonal similarities (non-matching pairs) are very high?

## Architecture Onboarding

- **Component map:** EEG Input → EEG Encoder → Feature f_s → [branch 1] Student Head → Task Loss; [branch 2] Teacher Head (from layer l) → KL Loss with teacher output; Visual Input → Visual Encoder → Feature f_t → Teacher Head → Output ŷ_t; Prototype Module: Both embeddings → Cosine Similarity → L_sim + L_unc; Active Learning Loop: Labeled Pool → Train → Predict on Unlabeled → Compute Entropy → Query top-τ → Annotate

- **Critical path:** Prototype-based similarity module (L_sim + L_unc) → feature alignment → task-specific distillation head (L_kd) → task loss (L_task). If L_sim fails to align embeddings, subsequent uncertainty estimates and distillation become unreliable.

- **Design tradeoffs:**
  - Teacher head injection layer l: Earlier injection → stronger alignment but risks forcing EEG into visual feature structure; later injection → weaker supervision but preserves EEG-specific patterns
  - Temperature parameters (β, τ): Control sharpness of similarity distributions; not ablated in paper
  - Acquisition ratio τ (active learning): Paper doesn't report what fraction is queried per iteration

- **Failure signatures:**
  - Feature space visualization shows overlapping clusters: L_sim not converging; check embedding norms and temperature scaling
  - Uncertainty remains high after multiple AL iterations: Cross-modal disagreement may be driven by systematic noise; inspect per-modality quality
  - Student outperforms teacher on task: Possible overfitting to noisy labels; verify label quality in ground truth

- **First 3 experiments:**
  1. Reproduce ablation (Table 4.3) with single-loss baselines: Train L_sim only, L_unc only, L_kd only on DEC task. Confirm L_kd dominates, L_unc + L_kd synergy
  2. Visualize uncertainty distributions before/after alignment: Plot uncertainty histograms for raw EEG embeddings vs. prototype-aligned embeddings. Verify compression effect
  3. Active learning curve at 10/30/50/70/100% budgets: Reproduce Table 4.5 curves; if "Ours" doesn't beat "Random" by >5% at 50%, check cross-modal reliability target computation

## Open Questions the Paper Calls Out

- **How does the framework scale to more than two modalities, and does cross-modal consistency remain tractable with increasing modality heterogeneity?** The framework is demonstrated only with EEG and visual modalities. The pairwise similarity computation and contrastive alignment scale quadratically, and the paper does not address how consistency signals would be aggregated or reconciled across three or more modalities with potentially conflicting semantic cues.

- **How robust is the framework to missing modalities at training time, given the reliance on paired multimodal samples for consistency learning?** The dataset contains paired EEG and visual samples, and the contrastive similarity loss explicitly requires synchronized EEG-visual pairs. No ablation or discussion addresses scenarios where one modality is partially or fully unavailable.

- **Can bidirectional or cyclic knowledge transfer improve upon the unidirectional visual→EEG distillation, particularly when the teacher modality itself is noisy?** The paper assumes visual modality is semantically richer and more reliable. If visual quality degrades (e.g., poor lighting, occlusion), the unidirectional transfer may propagate noise rather than reduce it.

## Limitations

- The framework relies on visual modality being semantically richer than EEG, which may not hold in all affective computing contexts
- Dirichlet-based uncertainty estimation for EEG-affect tasks lacks direct external validation
- Several critical hyperparameters (λ weights, temperature scaling, intermediate layer choice) are not ablated, creating reproduction uncertainty

## Confidence

- Cross-modal knowledge distillation mechanism: **Medium** - validated in related work but specific layer injection details unclear
- Dirichlet uncertainty estimation: **Low** - novel application to this domain without external validation
- Active learning efficacy: **Medium** - independent validation exists but ablation on τ ratio missing
- Overall robustness claims: **Medium** - strong results on MAHNOB-HCI but dataset-specific

## Next Checks

1. **Ablation on intermediate injection layer:** Systematically vary teacher head injection layer l (early/mid/late) and measure impact on both alignment quality and task performance

2. **Hyperparameter sensitivity analysis:** Grid search λ₁, λ₂, λ₃, λ₄ and temperature parameters to identify stable operating regions and quantify uncertainty in performance claims

3. **Modality quality degradation study:** Artificially corrupt visual modality (occlusion, blur) and measure framework performance degradation vs. unimodal baselines to test visual-richness assumption