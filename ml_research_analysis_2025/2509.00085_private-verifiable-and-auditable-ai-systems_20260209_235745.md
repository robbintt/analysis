---
ver: rpa2
title: Private, Verifiable, and Auditable AI Systems
arxiv_id: '2509.00085'
source_url: https://arxiv.org/abs/2509.00085
tags:
- data
- privacy
- these
- systems
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis addresses the critical challenge of building trustworthy
  AI systems by examining how to balance AI's utility with the needs for privacy,
  verifiability, and auditability. The research introduces technical solutions to
  enable verifiable and auditable claims about AI systems using zero-knowledge cryptography
  (zkSNARKs), allowing third parties to confirm model performance or fairness metrics
  without direct model access.
---

# Private, Verifiable, and Auditable AI Systems

## Quick Facts
- arXiv ID: 2509.00085
- Source URL: https://arxiv.org/abs/2509.00085
- Authors: Tobin South
- Reference count: 40
- Primary result: Technical solutions for balancing AI utility with privacy, verifiability, and auditability using zkSNARKs, MPC, TEEs, and credential delegation systems

## Executive Summary
This thesis tackles the fundamental challenge of building trustworthy AI systems by addressing the tension between AI utility and the requirements for privacy, verifiability, and auditability. It proposes technical solutions grounded in security and cryptography to enable verifiable model evaluations, private retrieval augmented generation, and authenticated delegation for autonomous agents. The research demonstrates that through rigorous application of these methods, foundation model-based AI systems can reconcile competing demands while maintaining accountability and data protection.

## Method Summary
The thesis employs zero-knowledge cryptography (zkSNARKs) to create verifiable evaluation attestations for AI models without revealing weights, uses multi-party computation and trusted execution environments for secure and private retrieval augmented generation, and extends OAuth/OpenID Connect protocols with delegation tokens and agent-specific credentials for authenticated AI agent interactions. The methods are implemented through proof circuits, secret-sharing protocols, and credential frameworks that establish verifiable chains of accountability while protecting sensitive data through cryptographic means.

## Key Results
- Introduces zkSNARK-based verifiable model evaluations that prove performance claims without model weight disclosure
- Develops MPC and TEE protocols for private retrieval augmented generation that protect sensitive data while enabling auditability
- Presents authenticated delegation frameworks using extended OAuth/OpenID Connect for securing AI agent interactions with clear accountability chains

## Why This Works (Mechanism)

### Mechanism 1: Zero-Knowledge Proofs for Verifiable Model Evaluations
- **Claim:** zkSNARKs enable verification of computational claims about AI systems without revealing private data
- **Mechanism:** Model providers compile trained models into proof circuits generating proving and verification keys. Inference on benchmark datasets produces zero-knowledge proofs binding model weight hashes to outputs, creating verifiable evaluation attestations
- **Core assumption:** zkSNARK cryptographic assumptions hold (trusted setup not compromised, hardness assumptions valid)
- **Evidence anchors:** Abstract states zkSNARKs enable verifiable model evaluations without revealing weights; section 2.1.2 describes proof circuit workflow
- **Break condition:** Proving time and key size become impractical for large models; trusted setup compromise breaks security

### Mechanism 2: Multi-Party Computation for Private Retrieval Augmented Generation
- **Claim:** Secret-shared vector databases enable approximate nearest-neighbor search without servers observing query or database contents
- **Mechanism:** Query vectors and document embeddings secret-shared across servers using Shamir sharing. Protocol computes distances between query and cluster centroids in MPC, identifies candidates obliviously, and performs final top-k selection without plaintext reconstruction
- **Core assumption:** Honest-majority setting (t < n/2 servers corrupted) and semi-honest adversary model
- **Evidence anchors:** Abstract mentions MPC and TEEs for secure RAG; section 3.2.1.4 provides communication complexity analysis
- **Break condition:** Communication overhead prohibitive at large scales; honest-majority assumption violated; MPC numerical precision errors affect ranking accuracy

### Mechanism 3: Authenticated Delegation via Extended OAuth/OpenID Connect
- **Claim:** Extending OAuth 2.0 and OpenID Connect with delegation tokens enables verifiable, scoping-controlled authorization for AI agents
- **Mechanism:** Users authenticate to OpenID Provider, register AI agents, and issue delegation tokens referencing user and agent tokens. Third-party services verify delegation chains by validating signatures against OP's public keys
- **Core assumption:** OpenID Provider is trustworthy and signing keys remain secure
- **Evidence anchors:** Abstract mentions enhanced delegation mechanisms; section 4.1.2.3 describes delegation token structure and validation
- **Break condition:** OpenID Provider becomes single point of failure; natural-language-to-policy translation introduces ambiguities; delegation token revocation mechanisms ineffective

## Foundational Learning

- **Concept: Zero-Knowledge Proofs (zkSNARKs)**
  - **Why needed here:** Primary cryptographic primitive for verifiable computation; essential for understanding model evaluation mechanism
  - **Quick check question:** Can you explain why a zkSNARK proof size does not depend on the size of the secret input being proved about?

- **Concept: Secret-Sharing and MPC Fundamentals**
  - **Why needed here:** PRAG mechanism relies on distributing data across servers; understanding Shamir secret sharing and MPC communication complexity necessary for security assessment
  - **Quick check question:** If 2 out of 3 secret-sharing servers collude in a 3-server threshold scheme designed to tolerate 1 corruption, what can they learn?

- **Concept: OAuth 2.0 / OpenID Connect Flow**
  - **Why needed here:** Authenticated delegation mechanism extends these protocols; understanding token types and authorization flows prerequisite for comprehension
  - **Quick check question:** In OAuth 2.0, what entity issues access tokens, and what entity validates them?

## Architecture Onboarding

- **Component map:**
  - Data Layer: Federated/secret-shared databases, encrypted vector stores, privacy-preserving transformations
  - Computation Layer: TEE enclaves, MPC protocols, zkSNARK proving systems
  - Identity/Authorization Layer: OpenID Provider, delegation token issuer, Agent-ID registration
  - Audit/Verification Layer: Proof aggregation circuits, attestation publishing infrastructure

- **Critical path:**
  1. Establish root of trust (Trusted Data Source signing, TEE attestation, or identity provider)
  2. Configure privacy-preserving computation environment (deploy MPC servers, provision TEE enclaves, or set up zkSNARK proving infrastructure)
  3. Register AI agent identity and issue delegation credentials with explicit scope restrictions
  4. Execute auditable inference/retrieval with proof generation
  5. Publish attestations and enable third-party verification

- **Design tradeoffs:**
  - zkSNARKs vs. TEEs vs. MPC: Cryptographic guarantees vs. near-native performance vs. distributed trust
  - Privacy vs. Auditability granularity: Aggregated proofs protect more information but reduce audit detail
  - Centralized vs. Federated Identity: Single OpenID Provider simplifies integration but creates concentration of trust
  - Exact vs. Approximate Search in MPC: Exact search has higher communication complexity O(N); IVF approximation achieves O(√N) at accuracy cost

- **Failure signatures:**
  - zkSNARK proving OOM: Proving key exceeds available RAM for large models
  - MPC timeout: Inter-server communication latency causes protocol abortion
  - Delegation scope drift: Agent accumulates permissions across contexts without review
  - Numerical precision degradation in MPC: Fixed-point arithmetic errors cause ranking discrepancies
  - Attestation chain break: Model weight hash mismatch between evaluation attestation and inference proof

- **First 3 experiments:**
  1. zkSNARK baseline: Compile small neural network (MLP on MNIST) to Halo2 circuit using ezkl; measure proving time, proof size, and verification time across constraint counts
  2. MPC retrieval simulation: Implement 3-party secret-shared dot product and top-k selection using CrypTen; benchmark communication rounds and latency on synthetic embedding data
  3. Delegation token flow: Set up minimal OIDC mock server; implement delegation token issuance with scope encoding; verify agent access to permitted resources

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can proof splitting and parallelization optimize zkSNARKs for real-time verification of frontier-scale foundation models?
- Basis in paper: Chapter 2 states slow proof times limit utility in synchronous contexts for large models and suggests future work on proof splitting and parallelization
- Why unresolved: Current proving systems face high computational overhead (linear scaling with constraints) making real-time verification infeasible for billions of parameters
- What evidence would resolve it: Demonstration of zkSNARK implementation on GPT-4 class model achieving sub-second or near-real-time latency using chunking or parallelization techniques

### Open Question 2
- Question: How can PRAG protocol be extended to provide security guarantees against malicious adversaries rather than just semi-honest ones?
- Basis in paper: Chapter 3 notes future work should explore expanding beyond semi-honest adversary, acknowledging current limitation of honest-but-curious participant assumption
- Why unresolved: Current MPC implementation assumes honest-but-curious participants; real-world deployments may face active attackers who deviate from protocol
- What evidence would resolve it: Formal security proof or implementation robust against malicious adversaries without prohibitive performance penalties

### Open Question 3
- Question: How can Oblivious RAM be effectively integrated into TEE-based RAG systems to obscure access patterns for datasets exceeding enclave memory?
- Basis in paper: Chapter 3 states ORAM could be integrated for datasets larger than enclave memory to obscure access patterns, albeit with performance overhead
- Why unresolved: While TEEs protect data at rest and in use, access patterns can leak information; integrating ORAM is theoretically possible but untested due to high performance costs
- What evidence would resolve it: Benchmarks from TEE-based RAG system utilizing ORAM demonstrating feasible trade-off between added latency and security of access pattern obfuscation

## Limitations
- zkSNARK proving key sizes and generation times become impractical for frontier-scale models, creating economic barriers to deployment
- MPC-based PRAG protocol assumes honest-majority and semi-honest adversaries, leaving gaps against active attacks and collusion
- Authenticated delegation mechanism relies on single OpenID Provider as trust anchor, creating potential centralization and surveillance vulnerabilities

## Confidence

- **High Confidence**: Fundamental cryptographic principles underlying zkSNARKs, MPC, and OAuth/OpenID Connect are well-established and mathematically proven
- **Medium Confidence**: Specific architectural integrations and protocol extensions are technically feasible but lack empirical validation at production scale
- **Low Confidence**: Claims about reconciling privacy, verifiability, and auditability in practical deployments remain largely theoretical without demonstrated implementation results

## Next Checks
1. **Scalability Benchmarking**: Implement ezkl-based zkSNARK pipeline on progression of models (MLP → CNN → Transformer) and measure proving time, proof size, and verification time to determine practical model size threshold

2. **Security Model Stress Testing**: Design and execute active adversary simulations against MPC PRAG protocol to measure vulnerability to Byzantine behavior, collusion attacks, and side-channel leakage; compare MPC performance against TEE-based alternatives

3. **Delegation Chain Resilience**: Implement OIDC delegation token extension and test under conditions of provider compromise, token revocation race conditions, and cross-context permission escalation; measure effectiveness of natural-language-to-policy translation against adversarial prompt injection attempts