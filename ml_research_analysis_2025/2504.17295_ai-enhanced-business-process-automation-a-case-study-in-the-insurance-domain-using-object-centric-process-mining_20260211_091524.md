---
ver: rpa2
title: 'AI-Enhanced Business Process Automation: A Case Study in the Insurance Domain
  Using Object-Centric Process Mining'
arxiv_id: '2504.17295'
source_url: https://arxiv.org/abs/2504.17295
tags:
- claim
- process
- business
- parts
- part
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses scalability bottlenecks in insurance claim
  processing by automating claim part identification using AI. The core method employs
  Large Language Models (LLMs) to automate claim part identification while using Object-Centric
  Process Mining (OCPM) to evaluate process transformation.
---

# AI-Enhanced Business Process Automation: A Case Study in the Insurance Domain Using Object-Centric Process Mining

## Quick Facts
- arXiv ID: 2504.17295
- Source URL: https://arxiv.org/abs/2504.17295
- Reference count: 28
- Primary result: AI automation scaled claim part identification from 1.82% to 27.62% of claims (1,420% improvement) while achieving 81% recall, surpassing human baseline of 70%

## Executive Summary
This paper addresses scalability bottlenecks in insurance claim processing by automating claim part identification using AI. The core method employs Large Language Models (LLMs) to automate claim part identification while using Object-Centric Process Mining (OCPM) to evaluate process transformation. The LLM achieved 81% recall (surpassing human baseline of 70%) and scaled identification from 1.82% to 27.62% of claims containing claim parts (1,420% improvement). OCPM enabled comprehensive analysis of AI-human collaboration, revealing that while AI significantly improved identification capacity, it created new bottlenecks in downstream investigation processes. The study demonstrates OCPM's value in analyzing complex process transformations but identifies visualization challenges for stakeholder communication.

## Method Summary
The study employed GPT-4o-0806 via Azure OpenAI Service to automate claim part identification in insurance claims using Chain-of-Thought prompting with few-shot examples and Structured Outputs for JSON schema enforcement. The system processed both Finnish and English claim descriptions in parallel pipelines after PII masking. Object-Centric Process Mining using OCEL 2.0 format captured events related to multiple object types (Claim, AI Model, Employee, Claim Part), enabling drill-down analysis of AI-human collaboration patterns. The OCPM approach revealed that while AI scaled identification from 68 to 1,034 identified parts, downstream investigation capacity remained fixed at ~23-26 cases, creating a bottleneck.

## Key Results
- AI automation scaled claim part identification from 1.82% to 27.62% of claims (1,420% improvement)
- LLM achieved 81% recall, surpassing human baseline of 70%
- OCPM revealed that AI-created bottlenecks in downstream investigation processes despite upstream success
- Stakeholder communication required flattening OC-DFG models to simpler DFGs due to complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured LLM outputs with Chain-of-Thought prompting can surpass human recall in claim part identification.
- Mechanism: GPT-4o-0806 processes claim descriptions/notes with few-shot CoT prompts, using OpenAI's Structured Outputs feature to enforce a strict JSON schema, enabling consistent extraction of claim parts from unstructured Finnish/English text.
- Core assumption: Claim part identification depends primarily on textual understanding and context recognition rather than tacit expert intuition.
- Evidence anchors:
  - [abstract] "The LLM achieved 81% recall (surpassing human baseline of 70%)"
  - [section 3.2, Table 1] v5 English model achieved 0.81 recall vs. human 0.70 baseline; Structured Outputs resolved output variation issues
  - [corpus] Weak direct evidence—corpus neighbors focus on OCPM methodology, not LLM task automation
- Break condition: When claim descriptions lack sufficient contextual cues or contain ambiguous terminology not covered in training/few-shot examples.

### Mechanism 2
- Claim: Object-Centric Process Mining enables simultaneous analysis of coexisting traditional and AI-enhanced process variants.
- Mechanism: OCEL 2.0 format captures events related to multiple object types (Claim, AI Model, Employee, Claim Part), enabling drill-down, unfolding, and filtering without repeated log extraction. This allows comparing human-only vs. AI-only vs. hybrid identification paths.
- Core assumption: Process transformation involves parallel variant execution long enough to generate comparative data.
- Evidence anchors:
  - [abstract] "OCPM enabled comprehensive analysis of AI-human collaboration"
  - [section 3.3] OCEL 2.0 eliminated need for repeated data extraction; filtering on sc/pCP vs. rCP enabled Q1-Q4 analysis
  - [corpus] OCPM² paper (arXiv:2503.10735) extends methodology for OCED extraction, validating the approach
- Break condition: When stakeholders require simplified visualizations—OC-DFG/OCPN proved too complex; flattened DFGs were needed for communication.

### Mechanism 3
- Claim: AI-driven automation can shift bottlenecks to downstream process stages rather than eliminating them.
- Mechanism: AI scaled claim part identification from 68 → 1,034 identified parts (1,420% increase), but investigation capacity remained fixed (~23-26 cases), creating a backlog. OCPM revealed the mismatch via end-to-end flow analysis.
- Core assumption: Downstream process capacity is not automatically scaled when upstream automation succeeds.
- Evidence anchors:
  - [abstract] "AI significantly improved identification capacity, it created new bottlenecks in downstream investigation processes"
  - [section 3.3, Fig. 4-6] cCPi (investigation creation) stayed at 21-23 despite pCP jumping to 1,034; stakeholders confirmed investigator shortage
  - [corpus] Weak corpus evidence—no bottleneck migration studies found in neighbors
- Break condition: When downstream capacity is elastic (automated, outsourced, or staffed to match AI throughput).

## Foundational Learning

- **Concept: Object-Centric Event Logs (OCEL)**
  - Why needed here: Traditional event logs flatten to one case notion; OCEL retains multi-object relationships essential for analyzing AI-human collaboration where events relate to Claims, Employees, and AI Models simultaneously.
  - Quick check question: Does your analysis require tracking how the same event affects multiple entity types (e.g., a claim scan affecting both the Claim and AI Model objects)?

- **Concept: Flattening in Process Mining**
  - Why needed here: OC-DFG/OCPN models were too complex for stakeholders; flattening OCEL to a single object type (Claim) produced DFGs that business users could interpret.
  - Quick check question: Which object type is the primary "case" notion for your stakeholder audience, and what relationships are lost by flattening?

- **Concept: Recall vs. Precision Trade-offs in Business Contexts**
  - Why needed here: Claim processing prioritizes recall (minimize missed parts with financial impact) over precision; false positives can be filtered downstream by investigators.
  - Quick check question: In your domain, what is the relative cost of false negatives vs. false positives, and does F1-score obscure this trade-off?

## Architecture Onboarding

- **Component map:**
  - Claim registered (rc) -> Claim notes created (cn) -> AI scans (sc) -> Predicts claim part (pCP) -> Investigator creates investigation (cCPi)
  - Parallel: Claim handler reports (rCP) -> Investigator creates investigation (cCPi)

- **Critical path:**
  1. Claim registered (rc) → notes created (cn) → AI scans (sc) → predicts claim part (pCP) → investigator creates investigation (cCPi)
  2. Parallel: claim handler reports (rCP) → investigator creates investigation (cCPi)
  3. Bottleneck: cCPi capacity limits realized value from pCP scale

- **Design tradeoffs:**
  - JSON mode vs. Structured Outputs API → Structured Outputs chosen for schema enforcement (v5)
  - Finnish vs. English processing → Both run for robustness; GPT-4o showed similar performance
  - OC-DFG analysis vs. DFG visualization → OC-DFG for depth, flattened DFG for stakeholder comprehension
  - Message queues for scalability → Introduced duplicate prediction risk on timeout

- **Failure signatures:**
  - PII leakage if masking fails before LLM inference
  - Duplicate predictions when message queue timeouts trigger retries (observed in pCP loop)
  - Stakeholder disengagement when presented with full OC models
  - Downstream backlog when AI throughput exceeds investigator capacity

- **First 3 experiments:**
  1. **Baseline validation:** Compare human-only (rCP), AI-only (pCP), and hybrid identification on the same claim set; measure recall, precision, and investigation yield (cCPi per identified part).
  2. **Bottleneck quantification:** Use OCEL filtering to plot pCP volume vs. cCPi capacity over time; identify the throughput ratio at which backlog forms.
  3. **Visualization comprehension test:** Present OC-DFG and flattened DFG to 3+ stakeholders; measure time-to-insight and decision confidence to validate communication strategy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can object-centric process mining visualizations be adapted to improve interpretability for non-technical business stakeholders?
- Basis in paper: [explicit] The authors note that stakeholders found full object-centric models like OC-DFG "too complex to interpret," forcing the use of flattened Directly-Follows Graphs (DFG).
- Why unresolved: Current open-source tools lack the necessary customization and simplification features for seamless stakeholder engagement.
- What evidence would resolve it: Development of visualization frameworks that maintain object-centric nuance while remaining intuitive for business users.

### Open Question 2
- Question: How can organizations predict and manage downstream bottlenecks that emerge from scaling upstream tasks via AI automation?
- Basis in paper: [explicit] The paper states that AI "successfully eliminated bottlenecks in claim identification but created a backlog in claim investigation."
- Why unresolved: Scaling a single step does not guarantee overall efficiency; the resulting workload growth exceeded human capacity in downstream phases.
- What evidence would resolve it: A holistic evaluation framework that assesses end-to-end process capacity before deploying AI automation in isolated steps.

### Open Question 3
- Question: How can OCEL 2.0 be extended to support the validity period of object-to-object relations to handle data expiration?
- Basis in paper: [explicit] The authors note that OCEL 2.0 "cannot distinguish whether related claim notes have expired," requiring complex pre-filtering.
- Why unresolved: The current standard lacks a native mechanism to define validity periods for relations, complicating log extraction.
- What evidence would resolve it: An extension of the OCEL 2.0 specification that includes temporal validity for relations, removing the need for manual filtering.

## Limitations
- Study relies on single enterprise dataset with confidential prompt structures and schema definitions
- Recall results cannot be independently verified without access to exact few-shot examples
- Downstream bottleneck analysis assumes fixed investigator capacity without exploring solutions
- Findings may not generalize beyond this specific insurance domain

## Confidence
- **High Confidence:** The OCPM methodology for analyzing AI-human collaboration (proven through OCEL extraction and filtering capabilities)
- **Medium Confidence:** The 81% recall achievement (based on single comparison to human baseline; lacks cross-validation)
- **Medium Confidence:** The bottleneck migration claim (observational; no intervention tested)
- **Low Confidence:** The generalizability of findings beyond this specific insurance domain (no comparative studies)

## Next Checks
1. **Replicate recall results** on a held-out test set with blind human evaluation to confirm the 81% vs 70% baseline gap.
2. **Test bottleneck elasticity** by simulating increased downstream capacity (automated triage, temporary staffing) and measuring the impact on overall process throughput.
3. **Stakeholder comprehension validation** with 5+ additional business users to verify that flattened DFGs provide sufficient insight compared to OC-DFG complexity.