---
ver: rpa2
title: 'Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis'
arxiv_id: '2601.11789'
source_url: https://arxiv.org/abs/2601.11789
tags:
- loss
- alignment
- step
- page
- size
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a fine-grained analysis of the suspicious alignment
  phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization.
  The phenomenon describes how gradient alignment with the dominant Hessian subspace
  initially decreases, then rises, and eventually stabilizes at high alignment during
  training.
---

# Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis

## Quick Facts
- arXiv ID: 2601.11789
- Source URL: https://arxiv.org/abs/2601.11789
- Reference count: 40
- This paper provides a fine-grained analysis of the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization.

## Executive Summary
This paper presents a comprehensive theoretical analysis of the suspicious alignment phenomenon observed in SGD optimization. The authors establish that gradient alignment with the dominant Hessian subspace follows a distinct pattern: initially decreasing, then rising, and eventually stabilizing at high alignment during training. Through rigorous mathematical analysis, they derive step-size conditions that determine whether alignment increases or decreases during optimization. The work reveals that under sufficient ill-conditioning, specific step-size intervals exist where projecting updates to different subspaces has opposing effects on loss minimization.

## Method Summary
The authors develop a fine-grained theoretical framework to analyze SGD's alignment behavior through the lens of quadratic optimization. They establish step-size conditions that govern the alignment dynamics by examining the interaction between learning rate, Hessian conditioning, and projection onto dominant versus bulk subspaces. The analysis reveals a critical adaptive step-size that separates alignment-decreasing from alignment-increasing regimes, with the behavior becoming self-correcting in high-alignment regimes. The theoretical framework is built upon examining the evolution of alignment metrics throughout the optimization trajectory.

## Key Results
- A critical step size exists that separates alignment-decreasing from alignment-increasing regimes in low-alignment phases
- In high-alignment regimes, alignment behavior becomes self-correcting and decreases regardless of step size
- Under sufficient ill-conditioning, there exists a step-size interval where bulk-space projection decreases loss while dominant-space projection increases loss
- SGD exhibits a distinct two-phase behavior with initial alignment decrease followed by stabilization at high alignment for constant step size and large initialization

## Why This Works (Mechanism)
The analysis reveals that SGD's alignment behavior is governed by the interplay between step size, Hessian conditioning, and subspace projections. The critical step size emerges from the balance between the learning rate and the curvature information encoded in the Hessian. When the step size crosses this threshold, the optimization dynamics shift from reducing to increasing alignment with the dominant subspace. The self-correcting nature in high-alignment regimes stems from the inherent properties of gradient descent dynamics under strong ill-conditioning.

## Foundational Learning

**Ill-conditioning**: Understanding the ratio between largest and smallest eigenvalues of the Hessian, which determines optimization difficulty and alignment behavior. Why needed: Forms the basis for analyzing how SGD interacts with different curvature regimes. Quick check: Compute condition number of a matrix and verify it matches theoretical expectations.

**Subspace Projection**: The mathematical operation of projecting gradients onto dominant versus bulk subspaces. Why needed: Central to understanding how different components of the gradient contribute to alignment and loss reduction. Quick check: Verify that projection onto orthogonal subspaces preserves vector length.

**Alignment Metrics**: Quantitative measures of how aligned gradients are with specific subspaces. Why needed: Provides the diagnostic tool for tracking alignment dynamics throughout optimization. Quick check: Compute alignment between random vectors and verify calculation matches geometric intuition.

## Architecture Onboarding

Component Map: SGD updates -> Alignment metric computation -> Step-size condition evaluation -> Loss projection analysis

Critical Path: The theoretical framework establishes that alignment evolution depends critically on the relationship between step size and Hessian conditioning. The critical path involves computing alignment metrics, evaluating step-size conditions, and determining the effect of subspace projections on loss.

Design Tradeoffs: The analysis trades computational tractability (quadratic loss assumption) for theoretical insight into alignment dynamics. While limiting real-world applicability, this choice enables rigorous mathematical analysis that would be intractable for general neural network loss surfaces.

Failure Signatures: When step size exceeds critical thresholds, alignment-increasing behavior emerges instead of the desired alignment-decreasing regime. In highly ill-conditioned settings, poor alignment can lead to slow convergence or stagnation.

First Experiments:
1. Verify the two-phase alignment behavior on simple quadratic objectives with controlled conditioning
2. Test the critical step-size prediction by measuring alignment dynamics across a range of learning rates
3. Validate the opposing effects of subspace projections on loss under different step-size regimes

## Open Questions the Paper Calls Out
None

## Limitations
- The analysis is restricted to quadratic loss functions, which may not capture the complexity of deep neural network optimization landscapes
- Assumptions about Hessian structure and eigenvalue distribution may not reflect real-world neural network scenarios
- Step-size conditions derived for quadratic settings may not directly translate to practical deep learning scenarios with complex loss surfaces

## Confidence
High: The mathematical derivation of step-size conditions and theoretical framework for analyzing alignment behavior in quadratic settings.
Medium: The extension of quadratic analysis insights to general deep learning optimization scenarios.
Low: The precise quantitative predictions of alignment dynamics in real neural networks based on the theoretical framework.

## Next Checks
1. Empirically validate the predicted alignment-decreasing and alignment-increasing regimes on standard deep learning benchmarks, measuring the critical step size that separates these regimes.

2. Test the hypothesis that SGD exhibits distinct two-phase behavior (alignment-decreasing followed by high alignment stabilization) on multiple neural network architectures and datasets.

3. Investigate whether the loss-increasing property of dominant subspace projection under specific step sizes can be observed in practice, and whether this property can be exploited for optimization purposes.