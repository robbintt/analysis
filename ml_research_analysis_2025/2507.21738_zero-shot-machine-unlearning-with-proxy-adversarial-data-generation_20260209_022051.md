---
ver: rpa2
title: Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation
arxiv_id: '2507.21738'
source_url: https://arxiv.org/abs/2507.21738
tags:
- unlearning
- samples
- remaining
- zs-pag
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ZS-PAG introduces a zero-shot machine unlearning method that addresses
  the challenge of over-unlearning by approximating inaccessible remaining data with
  adversarial samples and performing unlearning in a subspace orthogonal to that of
  the remaining classes. It further optimizes pseudo-labels for unlearning samples
  using an influence-based strategy to maximize positive effects on the remaining
  data.
---

# Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation

## Quick Facts
- **arXiv ID**: 2507.21738
- **Source URL**: https://arxiv.org/abs/2507.21738
- **Reference count**: 17
- **Primary result**: On CIFAR-100, improves accuracy on remaining classes by 6.03% compared to best baseline in zero-shot settings.

## Executive Summary
ZS-PAG introduces a zero-shot machine unlearning method that addresses the challenge of over-unlearning by approximating inaccessible remaining data with adversarial samples and performing unlearning in a subspace orthogonal to that of the remaining classes. It further optimizes pseudo-labels for unlearning samples using an influence-based strategy to maximize positive effects on the remaining data. The method includes theoretical guarantees and demonstrates superior performance over existing baselines, improving accuracy on remaining classes by 6.03% on CIFAR-100 while maintaining low membership inference attack accuracy.

## Method Summary
ZS-PAG is a three-stage framework for zero-shot class-level machine unlearning. First, it generates adversarial samples from the unlearning set by perturbing them across decision boundaries to approximate the distribution of remaining classes. Second, it optimizes pseudo-labels for these samples using influence functions to maximize positive effects on remaining data. Finally, it performs unlearning by updating model weights using gradients projected into a subspace orthogonal to the remaining classes, theoretically preventing over-unlearning while removing target class information.

## Key Results
- Improves accuracy on remaining classes by 6.03% compared to best baseline on CIFAR-100 in zero-shot settings
- Effectively mitigates membership inference attack risks, with attack accuracy approaching that of retrained models
- Shows robustness to variations in adversarial attack methods and success rates

## Why This Works (Mechanism)

### Mechanism 1: Proxy Adversarial Data Generation
The method perturbs unlearning samples to cross decision boundaries, generating adversarial samples that approximate the distribution of inaccessible remaining data. This proxy assumption enables subspace estimation without access to remaining classes.

### Mechanism 2: Orthogonal Subspace Projection
Unlearning gradients are projected into a subspace orthogonal to the remaining classes' feature space, reducing over-unlearning by theoretically leaving remaining class features intact while updating parameters for unlearning.

### Mechanism 3: Influence-Based Pseudo-Label Optimization
The method assigns optimized pseudo-labels to unlearning samples using influence functions to search for labels that maximize positive influence on remaining data, turning unlearning into beneficial regularization.

## Foundational Learning

- **Concept**: Adversarial Attacks (PGD/FGSM)
  - **Why needed here**: Used to generate proxy data by perturbing inputs to cross decision boundaries
  - **Quick check question**: Can you explain the difference between targeted and untargeted adversarial attacks, and why ZS-PAG uses the second-highest logit as the target?

- **Concept**: Singular Value Decomposition (SVD)
  - **Why needed here**: Essential for extracting the principal subspace of proxy features to construct orthogonal projection matrix
  - **Quick check question**: What do the columns of $U$ in $U \Sigma V^T$ represent in the context of feature maps?

- **Concept**: Influence Functions
  - **Why needed here**: Provides theoretical basis for estimating how upweighting/removing a sample changes model loss without retraining
  - **Quick check question**: Why is computing inverse Hessian vector product typically expensive, and what approximation does ZS-PAG likely rely on?

## Architecture Onboarding

- **Component map**: Input (unlearning set, original model) -> Proxy Generator (PGD adversarial attack) -> Subspace Estimator (SVD on features) -> Label Optimizer (influence functions) -> Unlearner (gradient descent with projection)

- **Critical path**: The accuracy of Proxy Generator is the linchpin. If proxy samples don't approximate remaining data, subspace estimation fails and orthogonal projection will be ineffective or destructive.

- **Design tradeoffs**:
  - Complexity vs. Quality: Higher number of proxy samples improves subspace estimation but increases SVD computation time
  - Attack Strength: Stronger attacks ensure boundary crossing but risk pushing samples off data manifold

- **Failure signatures**:
  - Over-unlearning: Remaining class accuracy drops significantly
  - Under-unlearning: Unlearning class accuracy remains high
  - MIA vulnerability: Membership inference attack accuracy remains high

- **First 3 experiments**:
  1. Proxy Distribution Visualisation: t-SNE plot of proxy samples vs real remaining data to validate proxy assumption
  2. Ablation on Subspace vs Pseudo-labels: Compare subspace projection only vs full pipeline to isolate influence-based labels contribution
  3. Hyperparameter Sensitivity: Test robustness of remaining class accuracy across different perturbation budgets and number of proxy samples

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided text. The limitations section discusses potential challenges but does not frame them as open questions.

## Limitations

- The proxy assumption that adversarial samples reliably span remaining class feature space is untested and critical to the method's validity
- The method's computational complexity scales poorly with parameter count due to Hessian approximations and SVD operations
- Limited evaluation to vision benchmarks (CIFAR, SVHN) raises questions about applicability to other data types

## Confidence

- **High Confidence**: The orthogonality mechanism and theoretical framework are mathematically sound given proxy assumption holds; 6.03% accuracy improvement is a concrete empirical result
- **Medium Confidence**: Proxy adversarial data generation approach is novel but relies on unproven assumptions about decision boundary structure; influence-based pseudo-label optimization shows promise but lacks extensive validation
- **Low Confidence**: Robustness claims to various attack methods and success rates need more systematic exploration across diverse datasets and model architectures

## Next Checks

1. **Proxy Distribution Fidelity Test**: Generate t-SNE visualizations comparing proxy adversarial samples against actual remaining class samples on CIFAR-100, quantifying overlap using Wasserstein distance or KL divergence

2. **Subspace vs. Pseudo-label Ablation**: Run controlled experiments isolating contributions of orthogonal projection versus full ZS-PAG pipeline to measure marginal improvement from influence-based labeling

3. **Robustness Across Attack Parameters**: Systematically vary perturbation budget and number of PGD steps to test if method maintains accuracy improvements across range of adversarial attack strengths