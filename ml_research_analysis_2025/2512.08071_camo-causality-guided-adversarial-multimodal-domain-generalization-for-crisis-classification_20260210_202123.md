---
ver: rpa2
title: 'CAMO: Causality-Guided Adversarial Multimodal Domain Generalization for Crisis
  Classification'
arxiv_id: '2512.08071'
source_url: https://arxiv.org/abs/2512.08071
tags:
- domain
- multimodal
- generalization
- causal
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generalizing crisis classification
  models to unseen disaster types in social media, where models often rely on spurious
  correlations that fail to transfer across domains. The authors propose CAMO, a causality-guided
  multimodal domain generalization framework that combines adversarial disentanglement
  with unified representation learning.
---

# CAMO: Causality-Guided Adversarial Multimodal Domain Generalization for Crisis Classification

## Quick Facts
- arXiv ID: 2512.08071
- Source URL: https://arxiv.org/abs/2512.08071
- Reference count: 22
- Key outcome: CAMO achieves 4-21% performance improvement over strong baselines for generalizing crisis classification to unseen disaster types.

## Executive Summary
This paper addresses the challenge of generalizing crisis classification models to unseen disaster types in social media, where models often rely on spurious correlations that fail to transfer across domains. The authors propose CAMO, a causality-guided multimodal domain generalization framework that combines adversarial disentanglement with unified representation learning. CAMO explicitly separates domain-invariant causal features from spurious domain-specific cues using an adversarial objective, and aligns multimodal representations into a shared latent space to enable single-modality DG techniques to be extended to multimodal settings. Experiments on CrisisMMD and DMD datasets show that CAMO achieves 4-21% performance improvement over strong baselines, demonstrating its effectiveness in improving generalization across unseen disaster domains.

## Method Summary
CAMO uses a two-stage alternating optimization framework that explicitly disentangles domain-invariant causal features from spurious domain-specific cues. The method employs adversarial training with a domain discriminator that uses gradient reversal to prevent learning domain-specific information. A unified representation learning module aligns multimodal features (images and text) into a shared latent space through modal-specific and modal-general projection heads. The training combines supervised contrastive loss for feature alignment, Mixup augmentation on modal-general features, and orthogonal regularization to ensure distinctness between causal and spurious representations. The framework is evaluated using a leave-one-domain-out protocol on CrisisMMD and DMD datasets, where the model is trained on multiple disaster types and tested on an unseen disaster type.

## Key Results
- CAMO achieves 4-21% performance improvement over strong baselines on CrisisMMD and DMD datasets
- Outperforms single-modality DG methods (Mixup, SupCon, RSC) when adapted to multimodal settings
- Ablation studies show each component (adversarial loss, SupCon, Mixup, orthogonal regularization) contributes positively to performance

## Why This Works (Mechanism)
CAMO addresses the core challenge of domain generalization in crisis classification by explicitly modeling the causal structure of the data. The key insight is that traditional models learn spurious correlations between domain-specific features (like visual patterns of specific disaster types) and labels, which fail to generalize to unseen domains. By using adversarial training with a domain discriminator and gradient reversal, CAMO forces the model to learn domain-invariant representations that capture the true causal relationships between social media content and crisis informativeness. The unified representation learning module ensures that both image and text modalities contribute to learning these invariant features, while the supervised contrastive loss aligns representations across modalities to strengthen the causal signal.

## Foundational Learning
- **Domain Generalization (DG)**: Learning models that generalize to unseen domains; needed because crisis classification models must work on new disaster types not seen during training; quick check: model performance on held-out domains should exceed standard ERM approaches.
- **Adversarial Disentanglement**: Using adversarial training to separate causal from spurious features; needed to prevent models from relying on domain-specific cues that won't transfer; quick check: domain discriminator accuracy should hover near chance level.
- **Unified Representation Learning**: Aligning multimodal features into shared latent space; needed to enable single-modality DG techniques to work on multimodal inputs; quick check: modal-general features should show strong inter-modal alignment in t-SNE visualization.
- **Gradient Reversal Layer**: A technique to implement domain adversarial training by reversing gradients during backpropagation; needed to implement the adversarial objective without complex architecture changes; quick check: domain discriminator loss should increase while classifier loss decreases during training.
- **Supervised Contrastive Loss**: A loss function that pulls together representations of the same class while pushing apart different classes; needed to strengthen class-level alignment beyond simple classification loss; quick check: contrastive loss should decrease steadily during training.

## Architecture Onboarding
- **Component Map**: CLIP encoders -> Projection heads (modal-specific + modal-general) -> Disentanglement MLP -> Classifier, with Domain Discriminator receiving modal-general features via adversarial path
- **Critical Path**: Image/text encoder → projection heads → modal-general features → disentanglement MLP → classifier, with adversarial gradient flow from domain discriminator
- **Design Tradeoffs**: The unified representation approach allows leveraging single-modality DG techniques but requires careful balance between modality-specific and shared representations; adversarial training improves generalization but can be unstable
- **Failure Signatures**: If domain discriminator accuracy is too high (>70%), causal features haven't been properly disentangled; if contrastive loss doesn't decrease, modal alignment is failing; if overall performance is poor, the adversarial schedule may be incorrect
- **First Experiments**: 1) Train with only supervised classification loss to establish baseline, 2) Add domain discriminator with gradient reversal to test adversarial disentanglement, 3) Add supervised contrastive loss to evaluate modal alignment contribution

## Open Questions the Paper Calls Out
None

## Limitations
- Critical hyperparameters are underspecified, including projection head dimensions, adversarial training schedule, and exact CLIP encoder fine-tuning strategy
- Comparisons to single-modality DG methods on multimodal tasks are somewhat indirect since baselines weren't originally designed for multimodal inputs
- The paper doesn't address potential domain overlap or temporal shifts between domains that could affect generalization claims

## Confidence
- High Confidence: The overall framework design combining adversarial disentanglement with unified representation learning is coherent and methodologically sound
- Medium Confidence: The specific implementation details for the alternating optimization protocol and the exact Mixup augmentation strategy for multimodal features

## Next Checks
1. Systematically vary the adversarial training schedule (γ warmup pace, alternation frequency) and Mixup β parameters to determine robustness of the reported performance gains
2. Implement and compare against properly extended versions of single-modality DG methods (Mixup, SupCon, RSC) that are specifically adapted for multimodal fusion
3. Conduct controlled experiments comparing CAMO performance when using frozen CLIP encoders versus fine-tuned encoders