---
ver: rpa2
title: Discrete optimal transport is a strong audio adversarial attack
arxiv_id: '2509.14959'
source_url: https://arxiv.org/abs/2509.14959
tags:
- attack
- asvspoof2019
- embeddings
- speech
- audio
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Discrete optimal transport (DOT) is an effective black-box adversarial
  attack against modern audio anti-spoofing countermeasures. The method aligns frame-level
  WavLM embeddings of generated speech to an unpaired bona fide pool via entropic
  OT and a top-k barycentric projection, then reconstructs audio using a neural vocoder.
---

# Discrete optimal transport is a strong audio adversarial attack

## Quick Facts
- arXiv ID: 2509.14959
- Source URL: https://arxiv.org/abs/2509.14959
- Reference count: 0
- Discrete optimal transport (DOT) achieves high equal error rates (EER) as a black-box adversarial attack against audio anti-spoofing countermeasures.

## Executive Summary
Discrete optimal transport (DOT) is an effective black-box adversarial attack against modern audio anti-spoofing countermeasures. The method aligns frame-level WavLM embeddings of generated speech to an unpaired bona fide pool via entropic OT and a top-k barycentric projection, then reconstructs audio using a neural vocoder. Evaluated on ASVspoof2019 and ASVspoof5 datasets with AASIST baselines, DOT achieves consistently high equal error rates (EER) across datasets and remains competitive after countermeasure fine-tuning. It outperforms several conventional attacks in cross-dataset transfer scenarios. Ablation analysis shows that vocoder overlap with countermeasure training data modulates attack strength. Results demonstrate that distribution-level alignment via DOT is a powerful and stable attack surface for deployed audio anti-spoofing systems.

## Method Summary
The attack transforms generated audio into bona fide-like speech without gradient access to the countermeasure. It extracts WavLM Large embeddings from the 6th transformer layer, solves entropic discrete optimal transport to align the generated distribution to a target bona fide pool, applies a top-k barycentric projection to obtain transported embeddings, and reconstructs audio using a HiFi-GAN vocoder. The Sinkhorn algorithm with cosine cost and ε=0.1 regularizes the transport. Evaluation uses Equal Error Rate (EER) against AASIST-based countermeasures.

## Key Results
- DOT achieves consistently high EER across ASVspoof2019 and ASVspoof5 datasets with AASIST baselines
- DOT remains competitive after countermeasure fine-tuning, outperforming SMIA, FGSM, PGD, and CW attacks in cross-dataset transfer
- Ablation analysis shows vocoder overlap with countermeasure training data modulates attack strength

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distributional alignment of generated speech toward bona fide regions reduces countermeasure detection performance.
- Mechanism: Discrete optimal transport computes a coupling matrix γ under cosine cost between source (generated) and target (bona fide) embedding distributions. The barycentric projection maps each source frame to a weighted combination of target frames, shifting the empirical distribution of generated speech closer to real speech. Countermeasures trained to reject synthetic distributions and accept real speech thus experience higher false acceptance rates on the transformed audio.
- Core assumption: Countermeasures rely on distributional discrepancies between synthetic and bona fide embeddings; closing this gap degrades detection without requiring gradient access.
- Evidence anchors:
  - [abstract] "frame-level WavLM embeddings of generated speech are aligned to an unpaired bona fide pool via entropic OT and a top-k barycentric projection"
  - [section 3.2] "the approximate map T̂ shifts the empirical distribution of generated speech toward the target (real) distribution"
  - [corpus] Discrete Optimal Transport and Voice Conversion demonstrates related VC quality improvements but does not directly validate the adversarial transfer claim.
- Break condition: If countermeasures detect based on features orthogonal to the aligned embedding space (e.g., phase artifacts, vocoder fingerprints not captured by WavLM), distributional alignment alone may be insufficient.

### Mechanism 2
- Claim: Top-k barycentric projection stabilizes voice conversion and limits quality degradation.
- Mechanism: For each source embedding x_i, target embeddings are sorted by coupling weight γ_ij. The transport uses only the top-k neighbors (k=5) rather than all N targets, computing a normalized weighted average. This prevents over-smoothing from low-probability matches and maintains perceptual quality.
- Core assumption: The optimal k lies in a narrow range (3–10); larger k degrades conversion quality.
- Evidence anchors:
  - [section 3.2] "k=5, as it was shown in [4], the quality of conversion does not change much for 3≤k≤10, but it degradates for large k"
  - [abstract] "top-k barycentric projection"
  - [corpus] No direct validation of k-sensitivity in adversarial context; claim relies on prior VC work.
- Break condition: If the target pool Y is small or non-representative, top-k selection may amplify outliers or fail to find acoustically plausible matches.

### Mechanism 3
- Claim: Vocoder overlap with countermeasure training data modulates attack strength.
- Mechanism: AASIST5 (trained on ASVspoof5 with HiFi-GAN synthesized data) shows lower EER against DOT attacks than AASIST2019, because the same vocoder artifacts are present in training. When the attack vocoder differs from CM training data, transferability increases.
- Core assumption: Countermeasures learn vocoder-specific artifacts; vocoder alignment between attack and training reduces attack potency.
- Evidence anchors:
  - [section 5.2] "Most of the ASVspoof5 training data are generated with the HiFi-GAN vocoder, which is also used in our attack"
  - [table 2] ASVspoof2019 attacks (different vocoders) achieve much higher EER on AASIST5 than ASVspoof5-native attacks
  - [corpus] Codecfake dataset explores vocoder-based detection but does not validate the vocoder-overlap modulation mechanism directly.
- Break condition: If countermeasures generalize across vocoders (e.g., through data augmentation or vocoder-agnostic features), vocoder overlap effects diminish.

## Foundational Learning

- Concept: **Discrete Optimal Transport (Sinkhorn Algorithm)**
  - Why needed here: Core attack mechanism requires solving entropic-regularized OT between source and target embedding sets.
  - Quick check question: Can you explain why entropic regularization (ε=0.1) stabilizes the Sinkhorn algorithm compared to unregularized OT?

- Concept: **WavLM Frame-Level Embeddings**
  - Why needed here: Attack operates on 1024-dim embeddings extracted every 20ms from WavLM Large (layer 6), not raw audio.
  - Quick check question: What is the relationship between hop size, frame length, and the temporal resolution of the transport map?

- Concept: **Equal Error Rate (EER) in Binary Detection**
  - Why needed here: Primary evaluation metric; EER is the operating point where false acceptance equals false rejection.
  - Quick check question: Why is EER preferred over accuracy for evaluating spoofing countermeasures?

## Architecture Onboarding

- Component map: Input -> WavLM Embedder -> OT Solver -> Top-k Projection -> HiFi-GAN Vocoder -> Output
- Critical path:
  1. Extract WavLM embeddings from x_gen
  2. Load pre-extracted bona fide pool Y
  3. Solve discrete OT → coupling matrix γ
  4. Apply top-k barycentric projection → transported embeddings Ŷ
  5. Decode Ŷ via HiFi-GAN → attacked audio x̃
  6. Score x̃ with target CM, compute EER

- Design tradeoffs:
  - Target pool size vs. compute: Longer target recordings improve quality but increase OT solve time (O(MN) per sample).
  - k selection: Lower k preserves speaker identity; higher k smooths artifacts but may degrade naturalness.
  - Vocoder choice: Matching target-domain vocoder improves perceptual quality but may reduce attack potency if CM was trained on that vocoder.

- Failure signatures:
  - Low EER on fine-tuned CMs: Indicates target pool distribution diverges from CM's bona fide training distribution (see Figure 3, Table 3 FAD analysis).
  - Perceptual degradation: Excessive smoothing from large k or poorly matched target speakers.
  - Cross-dataset transfer failure: Vocoder mismatch between attack and CM training (e.g., ASVspoof5-native attacks failing on AASIST2019).

- First 3 experiments:
  1. **Baseline replication**: Run OT2 attack on ASVspoof2019 eval set with AASIST2019, confirm EER ~7.9% matches Table 1.
  2. **Target pool ablation**: Compare LibriSpeech (OT2) vs. VCTK (OT1) target pools; measure FAD and EER delta.
  3. **k-sensitivity sweep**: Test k ∈ {1, 3, 5, 10, 20} on a held-out subset; plot EER vs. perceptual quality (e.g., MOS or speaker similarity score).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can adversarial attacks be designed to remain effective against countermeasures that have been explicitly fine-tuned on attack samples?
- Basis in paper: [explicit] The authors state that "DOT remains competitive after CM fine-tuning" and show in Table 1 (column AASIST FT 2019) that OT2 attacks drop from 7.925% EER to 0.216% after fine-tuning, noting "OT2 attacks are easily detected after fine-tuning."
- Why unresolved: The paper demonstrates the vulnerability to fine-tuning but does not propose mechanisms to achieve robustness against adaptive defenders who retrain on observed attacks.
- What evidence would resolve it: Experiments showing attacks that maintain high EER (>5%) even after CM fine-tuning with attack samples, potentially through adversarial training or distributional diversity in the attack generation.

### Open Question 2
- Question: To what extent does vocoder choice and overlap with CM training data determine attack transferability across different spoofing detection systems?
- Basis in paper: [inferred] The paper notes "vocoder overlap with CM training data modulates attack strength" and uses only HiFi-GAN. The high EER for ASVspoof2019 methods evaluated with AASIST5 is attributed to vocoder differences: "Most of the ASVspoof5 training data are generated with the HiFi-GAN vocoder, which is also used in our attack."
- Why unresolved: No systematic ablation across multiple vocoders is conducted, and the interaction between vocoder artifacts and OT-based distribution alignment remains unexplored.
- What evidence would resolve it: Controlled experiments varying the vocoder (e.g., WaveNet, WaveGlow, HiFi-GAN) while holding other factors constant, with separate evaluation on CMs trained with and without each vocoder's outputs.

### Open Question 3
- Question: Does the DOT attack preserve sufficient perceptual quality and speaker identity to evade human detection in realistic deployment scenarios?
- Basis in paper: [inferred] The threat model states the adversary goal includes preserving "intelligibility/naturalness to avoid human suspicion," but no perceptual evaluation (e.g., MOS scores, speaker similarity metrics, or human listening tests) is reported.
- Why unresolved: Success is measured purely by CM evasion (EER), leaving the practical viability of these attacks in human-in-the-loop systems unvalidated.
- What evidence would resolve it: Mean Opinion Score (MOS) evaluations, speaker verification equal error rates between original and attacked samples, and/or ABX human listening tests demonstrating indistinguishability from bona fide speech.

### Open Question 4
- Question: How does the effectiveness of DOT-based attacks generalize beyond the AASIST architecture to other countermeasure designs (e.g., RawNet2, Wav2Vec2-based systems, or ensemble methods)?
- Basis in paper: [inferred] All experiments use AASIST variants as the evaluation CM. The introduction acknowledges AASIST as one architecture among many, but no cross-architecture evaluation is performed.
- Why unresolved: The distributional alignment strategy may exploit architecture-specific vulnerabilities rather than fundamental limitations in spoofing detection.
- What evidence would resolve it: Systematic evaluation across diverse CM architectures with different inductive biases (end-to-end raw waveform, spectral-based, self-supervised representations), reporting consistent EER degradation patterns.

## Limitations
- The top-k barycentric projection stability claim relies on prior voice conversion literature rather than direct adversarial evaluation; sensitivity to target pool size and acoustic diversity is not quantified.
- Vocoder overlap effects are inferred from cross-dataset results but lack controlled ablation where the same attack vocoder is used against both CMs trained with/without it.
- Sinkhorn solver hyperparameters (ε=0.1) are fixed without sensitivity analysis; numerical stability across diverse utterance lengths is unverified.

## Confidence
- **High Confidence**: EER-based attack efficacy (Table 1–3) and cross-dataset transfer advantage over baseline attacks (SMIA, FGSM, PGD, CW) are well-supported by experimental results.
- **Medium Confidence**: Distributional alignment mechanism is plausible but not directly validated; FAD differences (Figure 3) support but do not conclusively prove that OT alignment reduces CM discriminability.
- **Low Confidence**: Claims about top-k projection quality preservation and vocoder overlap modulation lack dedicated ablation studies within the adversarial attack context.

## Next Checks
1. **k-sensitivity validation**: Systematically sweep k ∈ {1, 3, 5, 10, 20} on a held-out subset; measure EER vs. perceptual quality (e.g., MOS or speaker similarity) to confirm the narrow optimal range claim.
2. **Vocoder ablation study**: Repeat OT attacks using a vocoder not present in either CM training set; compare EER to HiFi-GAN attacks to isolate vocoder contribution from distributional alignment.
3. **Target pool composition test**: Construct target pools from varying speaker counts and durations (e.g., 10 vs. 40 speakers, short vs. long utterances); measure FAD and EER to quantify impact on distributional alignment and attack success.