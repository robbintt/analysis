---
ver: rpa2
title: 'How to use score-based diffusion in earth system science: A satellite nowcasting
  example'
arxiv_id: '2505.10432'
source_url: https://arxiv.org/abs/2505.10432
tags:
- diffusion
- image
- https
- data
- forecast
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'Diffusion models were applied to geostationary satellite infrared
  nowcasting, with three variants tested: a plain diffusion model, a residual correction
  diffusion model, and a latent diffusion model. The plain U-Net, serving as a baseline,
  showed smooth but blurry predictions, while diffusion models generated sharper,
  more realistic imagery and outperformed the U-Net and persistence forecasts in pixel-based
  metrics.'
---

# How to use score-based diffusion in earth system science: A satellite nowcasting example

## Quick Facts
- arXiv ID: 2505.10432
- Source URL: https://arxiv.org/abs/2505.10432
- Authors: Randy J. Chase; Katherine Haynes; Lander Ver Hoef; Imme Ebert-Uphoff
- Reference count: 37
- Key outcome: Diffusion models were applied to geostationary satellite infrared nowcasting, with three variants tested: a plain diffusion model, a residual correction diffusion model, and a latent diffusion model.

## Executive Summary
This paper presents the first application of score-based diffusion models to geostationary satellite infrared nowcasting. The authors tested three diffusion model variants alongside a U-Net baseline, finding that diffusion models generated sharper, more realistic imagery and outperformed both the U-Net and persistence forecasts in pixel-based metrics. The residual correction diffusion model achieved the best performance with the lowest root mean squared error and mean absolute error across the test set. All diffusion models demonstrated the ability to advect existing clouds and initiate convective clouds despite limited inputs, with ensemble generation providing skillful uncertainty quantification.

## Method Summary
The study applied score-based diffusion models to geostationary satellite infrared nowcasting, testing three variants: a plain diffusion model, a residual correction diffusion model, and a latent diffusion model. A U-Net baseline was included for comparison. The models were trained and evaluated on GOES-R satellite infrared imagery, with performance assessed using pixel-based metrics including root mean squared error and mean absolute error. The study also examined ensemble generation capabilities for uncertainty quantification and compared model performance across different meteorological conditions.

## Key Results
- The plain U-Net baseline showed smooth but blurry predictions, while diffusion models generated sharper, more realistic imagery
- The residual correction diffusion model achieved the best performance, with approximately 1 K lower RMSE than other diffusion models
- Diffusion models outperformed both the U-Net baseline and persistence forecasts in pixel-based metrics
- All diffusion models demonstrated ability to advect existing clouds and initiate convective clouds despite limited inputs

## Why This Works (Mechanism)
Diffusion models excel at satellite nowcasting because they can learn the joint probability distribution of weather evolution rather than just pixel-to-pixel mappings. This probabilistic approach allows the models to generate multiple plausible future states, capturing the inherent uncertainty in weather evolution. The score-based training procedure enables the model to understand both the overall cloud patterns and fine-scale details, producing sharper images than deterministic models like U-Nets. The ability to reverse a noising process means the model can effectively learn both the advection of existing features and the initiation of new convective activity.

## Foundational Learning
**Geostationary satellite infrared imagery**: Essential for capturing cloud-top temperatures and atmospheric moisture patterns at high temporal resolution. Why needed: Provides the primary observational data for nowcasting applications. Quick check: Understanding temporal resolution (5-15 minutes) and spatial resolution (2-4 km).

**Score-based diffusion models**: Generative models that learn to reverse a gradual noising process. Why needed: Enables probabilistic forecasting and produces sharper, more realistic imagery than deterministic approaches. Quick check: Understanding the relationship between noise schedule, score network, and sampling steps.

**U-Net architecture**: Encoder-decoder neural network with skip connections. Why needed: Serves as the baseline deterministic model for comparison. Quick check: Recognizing the U-Net's limitations in producing blurry outputs for image-to-image translation tasks.

## Architecture Onboarding

**Component Map**: Satellite imagery → Pre-processing → Diffusion model (score network) → Sampling → Forecast output

**Critical Path**: The core diffusion sampling process is critical - starting from pure noise and iteratively denoising to generate the forecast. This requires both the trained score network and appropriate noise schedule parameters.

**Design Tradeoffs**: The study balanced model complexity (plain vs. residual correction vs. latent diffusion) against training stability and forecast quality. The latent diffusion offered faster training but introduced artifacts from the pre-trained VAE.

**Failure Signatures**: Models can produce under-dispersive or over-dispersive ensembles, introduce reconstruction artifacts (especially with latent diffusion), and may struggle with extreme weather events not well-represented in training data.

**First Experiments**:
1. Compare U-Net baseline against diffusion model on a small validation set to observe qualitative differences in output sharpness
2. Test ensemble spread-skill relationship on a subset of forecasts to assess uncertainty quantification
3. Evaluate computational requirements for diffusion sampling versus direct prediction approaches

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can a variational autoencoder (VAE) trained specifically on satellite data eliminate the reconstruction artifacts and cold biases observed when using off-the-shelf VAEs for latent diffusion models?
- Basis in paper: The authors note that the off-the-shelf VAE introduced artifacts and that "tuning the pre-trained VAE or training a VAE from scratch on satellite data specifically are both topics of future research."
- Why unresolved: The authors only tested pre-trained VAEs available on HuggingFace, which were trained on natural images rather than meteorological data, leading to suboptimal encoding/decoding.
- What evidence would resolve it: A comparison of latent diffusion performance using a meteorologically-trained VAE versus a general-purpose VAE, specifically measuring reconstruction error (RMSE) and the presence of edge artifacts.

### Open Question 2
- Question: Does a hybrid approach, utilizing optical flow for advection and diffusion models solely for cloud generation and decay, improve accuracy or efficiency compared to end-to-end diffusion?
- Basis in paper: Section 5b suggests, "One could simplify the task further by breaking the task into two parts, advection and alteration. Advection could be handled well by known tools like optical flow..."
- Why unresolved: The current study tasks the diffusion model with handling both advection and evolution simultaneously, which may be computationally inefficient or unnecessarily complex for the advection component.
- What evidence would resolve it: A study benchmarking a hybrid optical-flow/diffusion model against the "Diff" and "CorrDiff" models presented, evaluating both forecast skill (RMSE) and computational cost.

### Open Question 3
- Question: How does the ensemble calibration (spread-skill relationship) of diffusion models vary across specific weather regimes, such as convective events versus frontal systems?
- Basis in paper: The authors state, "An area of future research is to isolate if the ensembles are under-dispersive/over-dispersive for specific weather regimes (e.g., convection, frontal)."
- Why unresolved: The bulk analysis showed that models could be under- or over-dispersive depending on the error magnitude, but the paper did not categorize performance by the type of meteorological phenomena occurring in the patch.
- What evidence would resolve it: A regime-dependent evaluation of the spread-skill ratio, segmenting the test set into distinct categories (e.g., convective initiation, stratiform clouds) rather than aggregating by RMSE bins.

## Limitations
- The best-performing residual correction diffusion model showed only modest improvements over the plain diffusion model (approximately 1 K lower RMSE)
- The latent diffusion model's training speed advantage was offset by quality artifacts from the pre-trained autoencoder
- Results are specific to geostationary satellite infrared nowcasting and may not generalize to other earth system applications

## Confidence
**High**: Diffusion models' superiority over U-Net baselines and persistence forecasts in pixel-based metrics
**Medium**: Ensemble uncertainty quantification, as some models showed under- or over-dispersion issues
**Low**: Generalizability of these results to other earth system applications beyond geostationary satellite infrared nowcasting

## Next Checks
1. Test diffusion models across diverse meteorological conditions and geographical regions to assess robustness beyond the current dataset
2. Compare computational efficiency and operational costs of diffusion models against traditional approaches in real-time forecasting scenarios
3. Evaluate model performance using domain-specific meteorological metrics beyond pixel-based error measures, including cloud feature tracking and convective initiation accuracy