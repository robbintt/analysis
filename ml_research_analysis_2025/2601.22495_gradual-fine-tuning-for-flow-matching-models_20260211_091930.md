---
ver: rpa2
title: Gradual Fine-Tuning for Flow Matching Models
arxiv_id: '2601.22495'
source_url: https://arxiv.org/abs/2601.22495
tags:
- fine-tuning
- path
- flow
- matching
- target
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Gradual Fine-Tuning (GFT), a principled framework
  for fine-tuning flow matching generative models. GFT defines a temperature-controlled
  sequence of intermediate objectives that smoothly interpolate between pretrained
  and target dynamics, approaching the true target as temperature approaches zero.
---

# Gradual Fine-Tuning for Flow Matching Models

## Quick Facts
- arXiv ID: 2601.22495
- Source URL: https://arxiv.org/abs/2601.22495
- Reference count: 40
- Proposes GFT framework for stable fine-tuning of flow matching models

## Executive Summary
This paper introduces Gradual Fine-Tuning (GFT), a principled framework for fine-tuning pretrained flow matching generative models to new target distributions. GFT defines a temperature-controlled sequence of intermediate objectives that smoothly interpolate between pretrained and target dynamics, enabling the use of arbitrary source-target couplings while preserving correctness. The method achieves more stable convergence and consistently shorter probability paths compared to standard fine-tuning without sacrificing generation quality.

## Method Summary
GFT implements fine-tuning through a temperature-controlled objective that interpolates between the pretrained and target dynamics. The framework defines a sequence of intermediate objectives parameterized by temperature β_s, which anneals from high to zero during training. This creates a smooth transition from the pretrained distribution to the target distribution, avoiding the sharp distributional shift that causes instability in standard fine-tuning. The method supports arbitrary source-target couplings, including optimal transport, and can be applied with full fine-tuning or LoRA. Empirically, GFT demonstrates improved stability through better Spearman correlation between epochs and FID, while maintaining or improving path efficiency.

## Key Results
- GFT achieves more stable convergence with Spearman correlation approaching -1 versus standard fine-tuning
- Consistently shorter probability paths without sacrificing generation quality on WILDS datasets
- Maintains correctness guarantees while enabling arbitrary source-target couplings including optimal transport

## Why This Works (Mechanism)
GFT works by avoiding the abrupt distributional shift inherent in standard fine-tuning. Instead of jumping directly from the pretrained distribution to the target distribution, GFT creates a smooth interpolation through temperature-controlled intermediate objectives. As temperature β_s decreases from high to zero during training, the model gradually adapts from the pretrained dynamics to the target dynamics. This gradual transition prevents the optimization instability that occurs when the model must simultaneously learn a completely new distribution and maintain generation quality.

## Foundational Learning
**Optimal Transport Couplings**: Mathematical framework for measuring distance between probability distributions by finding minimal cost mappings between them. Needed for establishing rigorous connections between source and target distributions. Quick check: Verify OT implementation produces valid couplings with correct marginal constraints.

**Stochastic Differential Equations**: Mathematical description of continuous-time generative processes where noise drives the evolution from simple to complex distributions. Essential for the flow matching formulation. Quick check: Confirm numerical SDE solver stability across different time discretizations.

**Girsanov Theorem**: Mathematical tool for changing probability measures in continuous-time stochastic processes, used here to establish equivalence between different drift formulations. Required for theoretical analysis of path transformations. Quick check: Validate Girsanov transformation preserves measure equivalence in numerical experiments.

**Regularization Path Theory**: Framework for understanding how solutions evolve as regularization parameters change, directly applicable to the temperature annealing in GFT. Provides theoretical grounding for gradual adaptation. Quick check: Plot solution trajectories as function of regularization strength to verify smooth evolution.

## Architecture Onboarding

**Component Map**: Pretrained U-Net -> GFT Loss Function -> Temperature Annealing Scheduler -> OT Coupling Module -> Target Distribution

**Critical Path**: Sampling from target distribution → Compute OT coupling → Evaluate GFT loss with current temperature → Backpropagate with temperature-dependent regularization → Update model parameters

**Design Tradeoffs**: 
- Temperature schedule vs convergence speed: Slower annealing provides stability but requires more training
- OT coupling quality vs computational cost: Higher-quality couplings improve adaptation but increase runtime
- Regularization strength vs adaptation fidelity: Stronger regularization preserves pretrained knowledge but may limit target adaptation

**Failure Signatures**: 
- Sharp FID increases during training indicate temperature schedule too aggressive
- Oscillating path lengths suggest regularization insufficient for the coupling used
- Poor OT coupling quality manifests as suboptimal adaptation despite stable training

**3 First Experiments**:
1. Compare GFT with standard fine-tuning on a simple domain shift (e.g., CIFAR-10 to CIFAR-10 corrupted)
2. Vary temperature annealing schedules to identify optimal cooling rate for stability
3. Test different OT coupling qualities (approximate vs exact) to quantify impact on adaptation

## Open Questions the Paper Calls Out
The paper explicitly leaves comparison against reward-based stochastic optimal control fine-tuning methods for future work, noting that the reward function corresponding to GFT is intractable under a memoryless noise schedule. The authors also suggest that extending GFT to diffusion models and other continuous normalizing flow variants while preserving theoretical convergence guarantees remains an open direction. Additionally, the theoretically optimal cooling schedule for GFT and its impact on convergence speed versus final distribution accuracy is not analyzed theoretically, though empirical results show minimum β controls the FID-path length tradeoff.

## Limitations
- Does not compare against reward-based stochastic optimal control fine-tuning methods
- Theoretical analysis of optimal cooling schedules is absent
- All experiments focus on unconditional generation, leaving conditional generation extension open

## Confidence
High: Claims about consistently shorter probability paths based on quantitative path length comparisons
Medium: Claims about more stable convergence given reported Spearman correlation results but lack of variance estimates
Medium: Claims about no sacrifice in generation quality based on FID comparisons without statistical significance testing

## Next Checks
1. Implement inverse sigmoid cooling schedule with multiple initial β values (1, 5, 10) and monitor path length trajectories to identify optimal annealing rates
2. Conduct ablation studies comparing GFT with standard fine-tuning across at least 3 random seeds to establish statistical significance of stability improvements
3. Test GFT on additional domain shift scenarios beyond WILDS datasets (different image resolutions or modalities) to validate generalizability claims