---
ver: rpa2
title: 'QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate
  Optimization Algorithm Circuits'
arxiv_id: '2504.16350'
source_url: https://arxiv.org/abs/2504.16350
tags:
- quantum
- training
- graph
- circuits
- qaoa-gpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces QAOA-GPT, a generative framework using GPT
  models to directly synthesize quantum circuits for quadratic unconstrained binary
  optimization problems, demonstrated on the MaxCut problem. The approach leverages
  ADAPT-QAOA to generate a diverse dataset of high-quality circuits, which is then
  used to train a GPT model to generate compact, problem-specific circuits without
  iterative optimization.
---

# QAOA-GPT: Efficient Generation of Adaptive and Quantum Approximate Optimization Algorithm Circuits

## Quick Facts
- **arXiv ID**: 2504.16350
- **Source URL**: https://arxiv.org/abs/2504.16350
- **Reference count**: 36
- **Primary result**: QAOA-GPT generates compact, problem-specific quantum circuits for MaxCut problems with comparable or better approximation ratios than ADAPT-QAOA and standard QAOA, while maintaining nearly constant inference time as problem size increases.

## Executive Summary
QAOA-GPT introduces a generative framework that uses GPT models to directly synthesize quantum circuits for quadratic unconstrained binary optimization (QUBO) problems, demonstrated on the MaxCut problem. The approach leverages ADAPT-QAOA to generate a diverse dataset of high-quality circuits, which is then used to train a GPT model to generate compact, problem-specific circuits without iterative optimization. By incorporating graph embeddings to capture structural features, QAOA-GPT achieves high approximation ratios comparable to or exceeding ADAPT-QAOA and standard QAOA across various graph sizes and densities, with inference times remaining nearly constant as problem size increases, significantly improving scalability.

## Method Summary
QAOA-GPT employs a two-stage process: first, it generates a training dataset using ADAPT-QAOA, an adaptive algorithm that iteratively selects optimal quantum gates for each problem instance. This dataset captures diverse circuit structures optimized for different graph configurations. Second, a GPT model is trained on this dataset to learn the mapping from graph embeddings to quantum circuit sequences. The graph embeddings encode structural features of the problem graphs, enabling the model to generate circuits tailored to specific instances. During inference, QAOA-GPT takes a new graph as input, generates its embedding, and produces a quantum circuit sequence directly, bypassing the iterative optimization required by traditional QAOA methods.

## Key Results
- QAOA-GPT achieves approximation ratios (AR) comparable to or exceeding ADAPT-QAOA and standard QAOA across various graph sizes and densities
- Inference time remains nearly constant as problem size increases, while ADAPT-QAOA scales polynomially
- Ablation studies confirm graph embeddings and diverse training data are critical for robust generalization
- Training data quality directly impacts model performance, with stricter approximation ratio targets requiring more extensive training

## Why This Works (Mechanism)
The approach works by leveraging the representational power of transformer models to learn the complex mapping between graph structures and optimal quantum circuit sequences. By training on high-quality circuits generated by ADAPT-QAOA, the model captures patterns in circuit construction that generalize across different problem instances. The graph embeddings provide the model with structural information about the optimization problem, enabling it to generate circuits specifically adapted to each instance rather than using a one-size-fits-all approach.

## Foundational Learning
- **Quantum Approximate Optimization Algorithm (QAOA)**: Hybrid quantum-classical algorithm for combinatorial optimization problems; needed to understand the baseline method being improved upon
- **ADAPT-QAOA**: Adaptive version of QAOA that iteratively selects optimal quantum gates; needed to generate the high-quality training data
- **Graph Embeddings**: Vector representations capturing structural features of graphs; needed to provide the GPT model with meaningful problem representations
- **Transformer Models**: Neural network architecture using self-attention mechanisms; needed to learn the mapping from graph embeddings to circuit sequences
- **Quadratic Unconstrained Binary Optimization (QUBO)**: Mathematical formulation for many combinatorial optimization problems; needed to understand the problem class being addressed
- **MaxCut Problem**: Classic NP-hard graph partitioning problem; used as the primary benchmark for evaluating the approach

## Architecture Onboarding

**Component Map**: Graph Input -> Graph Embedding Layer -> Transformer Encoder -> Transformer Decoder -> Circuit Sequence Output

**Critical Path**: The critical path involves generating graph embeddings, processing them through the transformer layers, and producing a valid quantum circuit sequence. The quality of the graph embedding and the transformer's ability to map embeddings to optimal circuits determines overall performance.

**Design Tradeoffs**: The approach trades the iterative optimization of ADAPT-QAOA for a one-shot generation process, sacrificing some potential optimality for significant gains in speed and scalability. The use of pre-trained transformers versus training from scratch involves balancing computational cost against model performance.

**Failure Signatures**: Poor performance may manifest as low approximation ratios compared to baseline methods, indicating the model failed to capture the optimal circuit structure. Runtime errors or invalid circuit outputs suggest issues with the sequence generation or embedding process.

**First Experiments**:
1. Verify that the graph embedding layer correctly captures structural features by visualizing embeddings for different graph types
2. Test the transformer's ability to generate valid quantum circuit sequences on a small, known dataset
3. Compare approximation ratios on small MaxCut instances against ADAPT-QAOA to validate performance gains

## Open Questions the Paper Calls Out
None identified in the provided materials.

## Limitations
- Training data generation relies on ADAPT-QAOA, which has computational overhead and may introduce bias toward certain circuit structures
- The claim of constant inference time across problem sizes is not fully validated, as transformer inference scales with sequence length
- The approach is primarily validated on MaxCut problems, leaving generalizability to other QUBO formulations uncertain

## Confidence

**High confidence in:**
- QAOA-GPT successfully generates valid quantum circuits for MaxCut problems
- The approach achieves comparable approximation ratios to ADAPT-QAOA and standard QAOA
- Graph embeddings contribute meaningfully to performance

**Medium confidence in:**
- The constant inference time claim across problem sizes
- The approach's scalability to significantly larger problem instances
- Performance consistency across diverse QUBO problem types beyond MaxCut

**Low confidence in:**
- The quality of automatically generated training data from ADAPT-QAOA
- The robustness of the approach to noise in real quantum hardware
- The sensitivity to hyperparameter choices in the transformer architecture

## Next Checks
1. Test inference time scaling empirically on problem sizes beyond those reported, including both synthetic and real-world MaxCut instances
2. Evaluate QAOA-GPT performance on other QUBO problems (e.g., portfolio optimization, facility location) to assess generalizability
3. Benchmark against alternative quantum circuit synthesis approaches on the same MaxCut instances to establish relative performance