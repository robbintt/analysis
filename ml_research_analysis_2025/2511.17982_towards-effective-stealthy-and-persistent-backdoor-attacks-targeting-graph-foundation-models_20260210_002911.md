---
ver: rpa2
title: Towards Effective, Stealthy, and Persistent Backdoor Attacks Targeting Graph
  Foundation Models
arxiv_id: '2511.17982'
source_url: https://arxiv.org/abs/2511.17982
tags:
- graph
- backdoor
- trigger
- uni00000013
- downstream
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies backdoor attacks against Graph Foundation Models
  (GFMs), which can introduce malicious behaviors into downstream applications. The
  authors propose GFM-BA, a novel attack method that addresses three key challenges:
  effectiveness (lack of downstream task knowledge), stealthiness (variability in
  node features across domains), and persistence (backdoor forgetting during fine-tuning).'
---

# Towards Effective, Stealthy, and Persistent Backdoor Attacks Targeting Graph Foundation Models

## Quick Facts
- arXiv ID: 2511.17982
- Source URL: https://arxiv.org/abs/2511.17982
- Authors: Jiayi Luo; Qingyun Sun; Lingjuan Lyu; Ziwei Zhang; Haonan Yuan; Xingcheng Fu; Jianxin Li
- Reference count: 21
- Key outcome: Proposed GFM-BA achieves 100% attack success rate while maintaining high accuracy on clean data and demonstrating strong persistence against fine-tuning

## Executive Summary
This paper addresses the critical security challenge of backdoor attacks on Graph Foundation Models (GFMs), which serve as pre-trained models for various downstream graph-based applications. The authors identify three key challenges in attacking GFMs: effectiveness (lack of downstream task knowledge), stealthiness (variability in node features across domains), and persistence (backdoor forgetting during fine-tuning). To address these challenges, they propose GFM-BA, a novel attack framework that introduces a label-free trigger association module using prototype embeddings, a node-adaptive trigger generator for stealthy attacks, and a persistent backdoor anchoring module to maintain backdoor effectiveness across fine-tuning scenarios.

## Method Summary
GFM-BA employs a sophisticated three-pronged approach to backdoor attacks on GFMs. The label-free trigger association module eliminates the need for labeled training data by using prototype embeddings to associate triggers with target classes. The node-adaptive trigger generator creates stealthy triggers that blend with the natural variability in node features across different domains, making them difficult to detect. The persistent backdoor anchoring module ensures that injected backdoors remain effective even after the GFM undergoes fine-tuning on downstream tasks, addressing the challenge of backdoor forgetting. This comprehensive framework enables successful attacks while maintaining high performance on clean data and persistence across fine-tuning scenarios.

## Key Results
- Achieves 100% attack success rate on targeted node misclassification
- Maintains high accuracy on clean data (minimal performance degradation)
- Demonstrates strong persistence against fine-tuning across multiple datasets and victim GFMs

## Why This Works (Mechanism)
The effectiveness of GFM-BA stems from its innovative approach to addressing the unique challenges of backdoor attacks on graph foundation models. By leveraging prototype embeddings for label-free trigger association, the attack eliminates dependency on labeled data while ensuring robust target class association. The node-adaptive trigger generation mechanism creates stealthy perturbations that naturally blend with domain-specific feature variations, making detection difficult. The persistent backdoor anchoring technique maintains attack effectiveness through fine-tuning by strategically embedding triggers that survive parameter updates during downstream adaptation.

## Foundational Learning

**Graph Foundation Models (GFMs)**
*Why needed:* Understanding pre-trained graph models that serve as foundations for downstream tasks
*Quick check:* GFMs learn universal graph representations that can be fine-tuned for specific tasks

**Backdoor Attack Mechanisms**
*Why needed:* Core concept of injecting hidden triggers that cause misclassification during inference
*Quick check:* Triggers are typically small perturbations that activate malicious behavior when present

**Prototype Embeddings**
*Why needed:* Enable label-free association between triggers and target classes
*Quick check:* Prototypes represent class centers in embedding space, allowing trigger-class mapping without labels

**Fine-tuning Dynamics**
*Why needed:* Understanding how pre-trained models adapt to downstream tasks and potential backdoor forgetting
*Quick check:* Fine-tuning updates model parameters, which can potentially erase injected backdoors if not properly anchored

## Architecture Onboarding

**Component Map**
GFM-BA consists of three main modules connected in sequence: Trigger Association -> Trigger Generation -> Backdoor Anchoring

**Critical Path**
The attack pipeline flows from prototype-based trigger association, through node-adaptive trigger generation, to persistent backdoor anchoring during fine-tuning

**Design Tradeoffs**
The framework balances attack effectiveness with stealthiness and persistence, requiring careful calibration of trigger strength and persistence mechanisms to avoid detection while maintaining attack capability

**Failure Signatures**
Attack failure manifests as reduced success rates on trigger-embedded samples, increased detection by defense mechanisms, or loss of backdoor effectiveness during fine-tuning

**First Experiments**
1. Effectiveness evaluation on clean data accuracy preservation
2. Attack success rate measurement on trigger-embedded samples
3. Persistence testing through controlled fine-tuning scenarios

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- Assumes access to pre-trained GFM parameters, which may not be realistic in all deployment scenarios
- Focuses primarily on node classification tasks, limiting generalizability to other GFM applications
- Evaluation primarily considers white-box settings with limited analysis of black-box or defense-aware scenarios

## Confidence

**Effectiveness claims:** High confidence based on consistent experimental results across multiple datasets and GFMs

**Stealthiness claims:** Medium confidence - quantitative results are strong but qualitative assessment is limited

**Persistence claims:** High confidence for the evaluated fine-tuning scenarios, though generalizability to extreme fine-tuning conditions remains uncertain

## Next Checks
1. Evaluate GFM-BA's performance under realistic black-box attack scenarios where the attacker has limited knowledge of the GFM architecture and parameters
2. Conduct extensive human evaluation studies to assess the perceptual stealthiness of the node-adaptive triggers across different application domains
3. Test the persistence mechanism under extreme fine-tuning conditions, including scenarios with large-scale, domain-shifted downstream data and extended fine-tuning durations