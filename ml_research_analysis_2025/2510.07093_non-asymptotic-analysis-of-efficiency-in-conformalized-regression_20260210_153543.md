---
ver: rpa2
title: Non-Asymptotic Analysis of Efficiency in Conformalized Regression
arxiv_id: '2510.07093'
source_url: https://arxiv.org/abs/2510.07093
tags:
- regression
- length
- prediction
- training
- then
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper analyzes the efficiency of conformalized quantile regression\
  \ (CQR) and conformalized median regression (CMR) by establishing non-asymptotic\
  \ bounds on the expected deviation of prediction set length from the oracle interval.\
  \ The key result is a bound of order O(1/\u221An + 1/(\u03B1\xB2n) + 1/\u221Am +\
  \ exp(-\u03B1\xB2m)), capturing the joint dependence on training set size n, calibration\
  \ set size m, and miscoverage level \u03B1."
---

# Non-Asymptotic Analysis of Efficiency in Conformalized Regression
## Quick Facts
- arXiv ID: 2510.07093
- Source URL: https://arxiv.org/abs/2510.07093
- Reference count: 40
- Primary result: Establishes non-asymptotic bounds of order O(1/√n + 1/(α²n) + 1/√m + exp(-α²m)) on prediction set length deviation from oracle interval

## Executive Summary
This paper provides the first non-asymptotic analysis of efficiency in conformalized regression, specifically for conformalized quantile regression (CQR) and conformalized median regression (CMR). The authors derive bounds on the expected deviation of prediction set length from the oracle interval, capturing the joint dependence on training set size n, calibration set size m, and miscoverage level α. The analysis reveals phase transitions in convergence rates across different α regimes and provides practical guidance for data allocation between training and calibration. Unlike prior work, the theoretical analysis makes assumptions on the data distribution rather than on intermediate quantities like the quantile regression estimator.

## Method Summary
The authors analyze conformalized quantile regression (CQR) and conformalized median regression (CMR) under a split conformal framework. They assume a linear quantile regression model trained via stochastic gradient descent (SGD) on the pinball loss, with the resulting model used to construct prediction intervals. The analysis decomposes the prediction error into model estimation error (converging at O(1/√n) under strong convexity) and calibration error (converging via Dvoretzky-Kiefer-Wolfowitz concentration). The key theoretical contribution is bounding the expected prediction set length deviation from the oracle interval, revealing how efficiency depends on sample sizes n and m, and the miscoverage level α.

## Key Results
- Establishes non-asymptotic bounds of order O(1/√n + 1/(α²n) + 1/√m + exp(-α²m)) on prediction set length deviation
- Reveals phase transitions in convergence rates: when α decreases faster than n^(-1/4), efficiency degrades quadratically in 1/α
- Provides practical guidance: n and m should be of the same order (e.g., 50/50 split) unless α is extremely small
- Analysis assumes bounded conditional density f_min > 0 and positive definite covariance, rather than assumptions on the quantile regression estimator

## Why This Works (Mechanism)

### Mechanism 1: Stochastic Quantile Regression Error Decomposition
The prediction set length deviation is partly driven by the estimation error of the underlying quantile regression model, which converges at a rate of O(1/√n) for SGD training under strong convexity. The analysis treats the model training as a stochastic optimization process. By assuming the pinball loss is strongly convex and smooth (bounded Hessian), the SGD parameter error ||θ_n - θ*||₂ is bounded. This parameter error propagates linearly to the prediction interval boundaries via the feature norms.

### Mechanism 2: Finite-Sample Calibration Concentration
The "correction factor" (nonconformity score quantile) added to the interval converges to the oracle correction via concentration inequalities dependent on calibration size m and miscoverage α. The algorithm computes an empirical quantile q̂_{1-α} from m calibration scores. The deviation of this empirical quantile from the population quantile is bounded using the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality. The term exp(-α²m) captures the tail probability of extreme quantiles missing the support.

### Mechanism 3: Phase Transition in Miscoverage Level α
The efficiency (set size) exhibits phase transitions based on the relationship between α, n, and m, meaning "low miscoverage" is fundamentally harder than "high miscoverage." The bound contains terms 1/(α²n) and exp(-α²m). If α decreases faster than n^(-1/2), the term 1/(α²n) dominates the standard statistical rate 1/√n, causing the prediction sets to grow excessively large (inefficient) unless sample sizes are scaled up quadratically with 1/α.

## Foundational Learning

**Concept: Split Conformal Prediction (SCP)**
- Why needed here: This is the architectural base. You must understand the distinction between the "proper training set" (used for model fitting) and the "calibration set" (used for score normalization).
- Quick check question: Can you explain why we don't compute the nonconformity scores on the training set? (Answer: To ensure exchangeability/valid coverage)

**Concept: Pinball Loss (Quantile Loss)**
- Why needed here: The paper analyzes models trained via SGD on this specific loss function, not standard MSE. The slope of the loss changes at the threshold.
- Quick check question: Why is the loss asymmetric for a quantile level γ ≠ 0.5?

**Concept: Non-Asymptotic Analysis**
- Why needed here: Unlike asymptotic analysis (limits as n → ∞), this paper provides bounds for finite n. Understanding "Big O" notation in this context (constants matter) is crucial.
- Quick check question: Does O(1/n) imply convergence is faster or slower than O(1/√n)?

## Architecture Onboarding

**Component map:**
Data Splitter -> SGD Trainer (on pinball loss) -> Score Computer (on calibration set) -> Quantile Estimator (via DKW) -> Set Builder (constructs interval)

**Critical path:** The interaction between α and n. The term 1/(α²n) implies that if you want to lower the miscoverage rate (make α smaller), you must increase n quadratically to maintain the same "efficiency gap" from the oracle.

**Design tradeoffs:**
- Data Allocation: The paper suggests n and m should generally be of the same order (e.g., 50/50 split) unless α is extremely small
- Alpha Selection: Do not choose α arbitrarily small. There is an "elbow" in the efficiency curve (Figure 13) where lowering α further causes massive set inflation without sufficient data

**Failure signatures:**
- Exploding Intervals: If n is small and α is small, the term (1/α²n) dominates, resulting in trivially wide intervals
- Quantile Crossing: The lower quantile prediction exceeds the upper quantile prediction. The paper notes this occurs with low probability if n is large enough (Remark 3.1), but is a risk in low-data regimes

**First 3 experiments:**
1. Log-Log Regression: Fix m as large, vary n, and plot Log(Length Deviation) vs Log(n). Verify the slope transitions from -1 to -0.5 as α increases (Figure 3)
2. Alpha Sensitivity Sweep: For a fixed n and m, sweep α from 0.2 down to 0.01. Identify the "elbow" where the interval length starts to skyrocket (Figure 13)
3. Optimizer Substitution: Swap SGD for AdamW (as done in Appendix C.3). Confirm that while absolute values change, the phase transition structure of the bounds holds

## Open Questions the Paper Calls Out
- Can the non-asymptotic efficiency bounds be extended to non-linear quantile regression models while maintaining tractable assumptions on the data distribution?
- Are the 1/(α²n) and exp(-α²m) terms in the bounds minimax optimal, or can they be improved?
- How do efficiency guarantees degrade when Assumption 3.3 (bounded conditional density) is violated, such as with heavy-tailed or multimodal conditional distributions?
- Can parameterized nonconformity scores achieve better efficiency than CQR/CMR for distributions where the oracle quantile interval is not optimal?

## Limitations
- The bounded conditional density assumption (f_min > 0) may not hold in many real-world regression problems
- The analysis assumes independent and identically distributed data, limiting applicability to time series
- The SGD convergence analysis relies on specific learning rate schedules and may not capture modern adaptive optimizers precisely

## Confidence
- High confidence: The decomposition of prediction error into model estimation and calibration error components is theoretically sound
- Medium confidence: The phase transition analysis across different α regimes is mathematically rigorous but sensitive to distributional assumptions
- Medium confidence: Experimental validation supports theoretical claims, though real-world datasets may not capture full practical breadth

## Next Checks
1. Test the framework on heavy-tailed distributions and correlated feature settings to evaluate robustness to the bounded density assumption
2. Implement experiments with time series data to assess performance under dependence
3. Compare the proposed allocation strategy between training and calibration sets against data-driven allocation methods across diverse dataset sizes and α values