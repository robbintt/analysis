---
ver: rpa2
title: 'Probing Gender Bias in Multilingual LLMs: A Case Study of Stereotypes in Persian'
arxiv_id: '2509.20168'
source_url: https://arxiv.org/abs/2509.20168
tags:
- gender
- english
- bias
- llms
- persian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a template-based method to probe gender stereotypes
  in multilingual LLMs, validated on real-world data, and introduces the Domain-Specific
  Gender Skew Index (DS-GSI) to quantify gender imbalances. Evaluated on four prominent
  models (GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, Qwen QwQ 32B) across four domains
  (academic disciplines, professions, colors, sports) in Persian (a low-resource language)
  and English, the results show that all models exhibit gender stereotypes, with Persian
  showing greater disparities than English.
---

# Probing Gender Bias in Multilingual LLMs: A Case Study of Stereotypes in Persian

## Quick Facts
- **arXiv ID**: 2509.20168
- **Source URL**: https://arxiv.org/abs/2509.20168
- **Reference count**: 11
- **Primary result**: Template-based method to probe gender stereotypes in multilingual LLMs, validated on real-world data, and introduces the Domain-Specific Gender Skew Index (DS-GSI) to quantify gender imbalances.

## Executive Summary
This study introduces a template-based method to probe gender stereotypes in multilingual LLMs, validated on real-world data, and introduces the Domain-Specific Gender Skew Index (DS-GSI) to quantify gender imbalances. Evaluated on four prominent models (GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, Qwen QwQ 32B) across four domains (academic disciplines, professions, colors, sports) in Persian (a low-resource language) and English, the results show that all models exhibit gender stereotypes, with Persian showing greater disparities than English. Sports showed the strongest gender bias, and Gemini 2.0 Flash had the highest DS-GSI across domains. English prompts yielded more balanced and consistent results across models compared to Persian. The study highlights the need for inclusive NLP practices and provides a framework for bias assessment in low-resource languages.

## Method Summary
The study employs a template-based probing methodology to assess gender stereotypes in multilingual LLMs. Researchers generated 96 unique prompts across four domains (academic disciplines, professions, colors, sports) in both Persian and English, running each prompt 100 times per model. The Domain-Specific Gender Skew Index (DS-GSI) quantifies gender imbalances by calculating the average absolute deviation from gender parity across all categories. Model outputs were processed through gender classification APIs (Genderize.io and Namsor), with manual verification for 13-14% of disputed cases using Iran's official name repository. The approach systematically compares bias patterns between high-resource (English) and low-resource (Persian) languages.

## Key Results
- All four evaluated models exhibited gender stereotypes, with Persian showing greater disparities than English
- Sports domain showed the strongest gender bias across all models and languages
- Gemini 2.0 Flash had the highest DS-GSI values across all domains, indicating the most pronounced gender bias
- English prompts yielded more balanced and consistent results across models compared to Persian

## Why This Works (Mechanism)
The template-based approach provides controlled, reproducible prompts that isolate gender associations from contextual variables. By using underspecified scenarios that only differ in domain context, the method reveals implicit gender stereotypes encoded in LLM representations. The DS-GSI metric effectively quantifies these biases by measuring deviation from gender parity across multiple categories, providing a single comparable score that captures both magnitude and direction of bias.

## Foundational Learning
- **Template-based probing**: Why needed - Provides controlled input to isolate specific bias patterns; Quick check - Verify prompt templates match domain specifications
- **Domain-Specific Gender Skew Index (DS-GSI)**: Why needed - Quantifies gender imbalance with single comparable metric; Quick check - Confirm DS-GSI calculation matches formula (1/N) × Σ|2p_i - 1|
- **Multilingual bias comparison**: Why needed - Reveals how resource availability affects bias patterns; Quick check - Compare Persian vs English results for same domains
- **Gender classification resolution**: Why needed - Ensures accurate ground truth for bias measurement; Quick check - Validate disagreement resolution process matches reported methodology
- **Low-resource language assessment**: Why needed - Addresses gap in bias evaluation for non-English contexts; Quick check - Confirm all Persian prompts use appropriate vocabulary and cultural context

## Architecture Onboarding
- **Component map**: Template generation -> LLM prompt execution -> Name generation -> Gender classification (dual API) -> Disagreement resolution -> DS-GSI calculation
- **Critical path**: Prompt template → LLM generation → Gender classification → DS-GSI computation
- **Design tradeoffs**: Template-based control vs. naturalistic input diversity; binary classification simplicity vs. gender spectrum representation
- **Failure signatures**: Models generating explanations instead of names; API classification failures on rare names; inconsistent results across language pairs
- **3 first experiments**: 1) Run single prompt across all models to verify basic functionality, 2) Test gender classification tools on known Persian names to establish baseline accuracy, 3) Execute 10-prompt subset to validate end-to-end pipeline before full-scale execution

## Open Questions the Paper Calls Out
- **Open Question 1**: How do alternative probing methods, such as naturally-sourced or LLM-generated inputs, compare to template-based probing in identifying gender bias within low-resource, gender-neutral languages like Persian?
- **Open Question 2**: How can gender bias evaluation frameworks be effectively modified to capture non-binary and gender-neutral identities, particularly in multilingual contexts where automated gender inference tools are limited?
- **Open Question 3**: To what extent is the observed gender bias in Persian LLM outputs driven by the dominance of Western-centric training data rather than local Iranian demographic realities?

## Limitations
- Study relies solely on template-based probing method, leaving efficacy of alternative probing strategies untested
- Constrained by binary gender classification tools, potentially overlooking non-binary gender representations
- 13-14% gender classification disagreement rate introduces uncertainty in ground truth labels

## Confidence
- **High confidence**: Template-based methodology is well-documented and reproducible; DS-GSI metric is mathematically sound and clearly defined
- **Medium confidence**: Finding that Persian shows greater gender disparities than English is robust but may be influenced by classification tool limitations
- **Medium confidence**: Observation that sports domains exhibit strongest gender bias is consistent but could benefit from additional domains for validation

## Next Checks
1. Reproduce the study using controlled sampling parameters (fixed temperature/top_p) to verify that reported DS-GSI values remain stable across multiple experimental runs
2. Conduct error analysis on the 13-14% classification disagreements to quantify potential impact on DS-GSI scores and test sensitivity to labeling choices
3. Extend validation to additional low-resource languages with different cultural contexts to determine whether Persian-specific patterns generalize across language communities