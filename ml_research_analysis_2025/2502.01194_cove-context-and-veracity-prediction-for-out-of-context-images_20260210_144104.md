---
ver: rpa2
title: 'COVE: COntext and VEracity prediction for out-of-context images'
arxiv_id: '2502.01194'
source_url: https://arxiv.org/abs/2502.01194
tags:
- context
- image
- captions
- caption
- veracity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: COVE is a new method for detecting out-of-context misinformation
  in images by first predicting the true context of the image and then using that
  context to predict the veracity of its caption. It leverages a diverse set of evidence
  including web captions, Wikipedia entities, and automated captions to outperform
  the SOTA context prediction model on all context items by 0.3 to 18.9 percentage
  points.
---

# COVE: COntext and VEracity prediction for out-of-context images

## Quick Facts
- arXiv ID: 2502.01194
- Source URL: https://arxiv.org/abs/2502.01194
- Authors: Jonathan Tonglet; Gabriel Thiem; Iryna Gurevych
- Reference count: 34
- Primary result: COVE outperforms state-of-the-art context prediction models by 0.3 to 18.9 percentage points and achieves up to 4.5 percentage points higher Macro F1 on real-world out-of-context image detection.

## Executive Summary
COVE addresses the challenge of detecting out-of-context (OOC) misinformation in images by introducing a two-stage approach: first predicting the true context of an image, then using that context to assess the veracity of its caption. The method aggregates diverse evidence sources including web captions, Wikipedia entities, and automated captions to generate structured context items (source, date, location, motivation, people, things, event). By leveraging a frozen LLM for context prediction and a few-shot or fine-tuned LLM for veracity prediction, COVE demonstrates competitive performance on synthetic data and superior robustness on real-world datasets, particularly for non-Western contexts where other methods fail.

## Method Summary
COVE operates through a six-step pipeline: (1) retrieve web captions via reverse image search and filter using CLIP similarity; (2) extract visual entities using Google Vision API; (3) auto-generate captions with LlavaNext; (4) synthesize structured context items using Llama-3-8B-Instruct; (5) fill knowledge gaps by querying Wikipedia for unknown dates/locations; and (6) predict veracity by comparing the caption against the predicted context using either a few-shot Llama-3 or fine-tuned DebertaV3 model. The method handles seven context items and uses thresholds (t_match=0.92, t_wiki_text=0.23) to filter evidence quality, with knowledge gap completion significantly improving date and location prediction accuracy.

## Key Results
- COVE outperforms SOTA context prediction models by 0.3 to 18.9 percentage points across all context items
- Achieves up to 4.5 percentage points higher Macro F1 than best veracity prediction models on real-world data
- Sequential context-then-veracity approach shows greater robustness on real-world datasets compared to direct classification methods
- Knowledge gap completion more than doubles date prediction accuracy from 3.3% to 7.0%

## Why This Works (Mechanism)

### Mechanism 1
Sequentially predicting context before veracity improves robustness on real-world data compared to direct classification. By generating structured context artifacts first, the veracity step compares captions against a reliable reference rather than relying on shallow heuristics. This decouples image understanding from caption judgment, reducing false positives when captions are factually correct but mismatched to the image context.

### Mechanism 2
Aggregating heterogeneous evidence mitigates sparsity and noise in single-source retrieval. Web captions provide immediate journalistic context, Wikipedia entities offer canonical identity, and automated captions deliver raw visual data. This synthesis fills specific slots in the context template, with each source compensating for others' limitations. The approach reduces reliance on any single potentially biased or incomplete evidence source.

### Mechanism 3
Explicit knowledge gap completion improves recall for difficult context items like Date and Location. When web evidence is missing, COVE generates questions based on partial context and retrieves answers from Wikipedia. This secondary LLM loop bridges implicit metadata gaps that direct retrieval often misses, significantly improving accuracy for temporal and spatial context items.

## Foundational Learning

- **Concept:** Multimodal Embeddings (CLIP/SigLIP)
  - **Why needed here:** COVE relies on vector similarity to match images to web results and Wikipedia entities, projecting images and text into a shared geometric space for threshold-based filtering.
  - **Quick check question:** Can you explain why a high cosine similarity score (e.g., 0.92) is required for "visual entities" but a lower score might suffice for general web captions?

- **Concept:** LLM-based Question Answering (RAG)
  - **Why needed here:** The core Context Prediction step uses Retrieval-Augmented Generation to extract structured JSON data from unstructured text evidence.
  - **Quick check question:** If retrieved web captions contain conflicting dates, how does the LLM (specifically Llama 3) typically resolve the conflict in a zero-shot or few-shot setting?

- **Concept:** Veracity Rules & Heuristics
  - **Why needed here:** COVE includes rule-based layers (exact string matches, similarity thresholds) that bypass the LLM for obvious cases, improving efficiency and handling clear mismatches.
  - **Quick check question:** What is the risk of setting t_match (image similarity threshold) too low when filtering web evidence for veracity checks?

## Architecture Onboarding

- **Component map:** Google Vision API (Web/Entities) -> OVEN Index (Wikipedia) -> LlavaNext (Auto-captions) -> Llama 3 (Context QA Agent) -> WikiChat/ColBERT (Knowledge Gap Retriever) -> Llama 3/DebertaV3 (Veracity Classifier)

- **Critical path:**
  1. **Retrieval:** Image -> APIs -> Raw Evidence (Web captions, Entities)
  2. **Filtering:** CLIP similarity scoring -> Thresholding -> Clean Evidence
  3. **Synthesis:** Llama 3 -> Structured Context (JSON)
  4. **Gap Filling:** Check for "Unknown" -> Query Wiki -> Update Context
  5. **Classification:** Context + Caption -> Veracity Label

- **Design tradeoffs:**
  - **Frozen vs. Fine-tuned:** Llama 3 (frozen) generalizes better on real-world data, while DebertaV3 (fine-tuned) excels on synthetic data
  - **Cost vs. Context:** Knowledge gap completion significantly improves Date/Location scores but requires multiple LLM inference calls
  - **Granularity:** Visual entities help "People" prediction but hurt "Source" prediction due to noise in entity detection

- **Failure signatures:**
  - **Western Bias:** Performance drops on 5Pils-OOC due to CLIP/Wikipedia entity recognition failures for non-Western contexts
  - **Rule Leakage:** High false positive rates if t_non_match is not carefully tuned
  - **Context Hallucination:** Llama 3 may output "Unknown" for context items even when evidence exists if retrieval ranking is poor

- **First 3 experiments:**
  1. **Threshold Sensitivity:** Run validation set varying t_match (0.90-0.95) to observe trade-off between Context Precision and Veracity Recall
  2. **Ablation on Gap Completion:** Disable Knowledge Gap module and measure drop in Date/Location accuracy for images with missing web captions
  3. **Cross-Domain Veracity:** Train DebertaV3 on NewsCLIPpings and test on 5Pils-OOC to reproduce finding that frozen Llama 3 generalizes better

## Open Questions the Paper Calls Out

- **Open Question 1:** How can visual entity recognition be adapted to reduce high error rates for non-Western images, where current CLIP-based similarity matching frequently retrieves irrelevant Wikipedia entities? (Basis: 33% of context errors in 5Pils-OOC stemmed from this issue; requires region-specific embeddings or fine-tuned visual encoders)

- **Open Question 2:** Can an advanced filtering mechanism be developed to assess web caption reliability without the performance drop observed with simple domain allow-lists? (Basis: Simple domain filtering decreased Macro F1 by 2.8 percentage points; needs dynamic weighting model)

- **Open Question 3:** Can COVE's sequential six-step architecture be streamlined or distilled into a more efficient model to reduce computational overhead without degrading diverse evidence integration? (Basis: Method is "computationally expensive" due to multiple LLM inference steps; needs ablation study demonstrating reduced-step architecture)

## Limitations
- Reliance on external APIs (Google Vision, Custom Search) creates reproducibility and scalability challenges
- Geographic and cultural bias in retrieval systems leads to performance degradation on non-Western datasets
- Knowledge gap completion effectiveness depends heavily on Wikipedia coverage completeness for global events
- Few-shot prompting strategy requires manual demonstration selection, introducing potential experimenter bias

## Confidence
- **High Confidence:** Sequential context-then-veracity approach works better on real-world data than direct classification methods
- **Medium Confidence:** Heterogeneous evidence aggregation improves context prediction robustness, though contribution varies by context item type
- **Low Confidence:** Fine-tuned DebertaV3's superior performance on synthetic data translates to real-world generalization (paper notes opposite trend)

## Next Checks
1. **Geographic Bias Validation:** Test COVE on additional non-Western image datasets to quantify and address the geographic bias observed in 5Pils-OOC
2. **Knowledge Gap Coverage Analysis:** Measure Wikipedia entity coverage rates for events in NewsCLIPpings vs. 5Pils-OOC to quantify knowledge base limitations
3. **Threshold Sensitivity Analysis:** Systematically vary CLIP similarity thresholds across their full range to map precision-recall trade-offs for context prediction and veracity classification