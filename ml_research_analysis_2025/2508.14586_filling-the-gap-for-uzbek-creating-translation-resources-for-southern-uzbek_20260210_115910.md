---
ver: rpa2
title: 'Filling the Gap for Uzbek: Creating Translation Resources for Southern Uzbek'
arxiv_id: '2508.14586'
source_url: https://arxiv.org/abs/2508.14586
tags:
- uzbek
- southern
- language
- translation
- half-space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the first comprehensive machine translation
  resources for Southern Uzbek, a low-resource Turkic language variety spoken in Afghanistan.
  The authors create a 997-sentence FLORES+ development dataset and compile 39,994
  parallel sentences from dictionary, literary, and web sources.
---

# Filling the Gap for Uzbek: Creating Translation Resources for Southern Uzbek

## Quick Facts
- arXiv ID: 2508.14586
- Source URL: https://arxiv.org/abs/2508.14586
- Reference count: 7
- First comprehensive machine translation resources for Southern Uzbek with 34.31 BLEU on uzn-uzs translation

## Executive Summary
This work introduces the first comprehensive machine translation resources for Southern Uzbek, a low-resource Turkic language variety spoken in Afghanistan. The authors create a 997-sentence FLORES+ development dataset and compile 39,994 parallel sentences from dictionary, literary, and web sources. They fine-tune the NLLB-200 model and develop a post-processing method to restore Arabic-script half-space characters for morphological boundaries. Evaluation shows their model achieves 34.31 BLEU and 71.11 chrF++ on uzn-uzs translation, outperforming existing baselines.

## Method Summary
The approach combines multilingual transfer learning with targeted fine-tuning and orthographic normalization. The authors transliterate Arabic-script Southern Uzbek to Latin script, use LaBSE embeddings for sentence alignment (yielding 40% more pairs than direct Arabic processing), and fine-tune the nllb-200-distilled-600M model with Adafactor optimizer. A character-level n-gram post-processor restores morphological half-space characters that the tokenizer strips, achieving substantial BLEU improvements. The pipeline processes dictionary, literary, and web-sourced parallel data into a comprehensive translation system.

## Key Results
- 34.31 BLEU and 71.11 chrF++ on uzn-uzs translation
- 40% more sentence pairs extracted through Latin-script transliteration preprocessing
- 32% relative BLEU improvement from half-space post-processing (25.99 to 34.31)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning a multilingual model pretrained on related Turkic languages enables effective Southern Uzbek translation despite limited parallel data.
- Mechanism: The NLLB-200 model contains Northern Uzbek (uzn) and other Turkic languages in its training distribution. Southern Uzbek shares vocabulary, morphology, and syntactic structures with these languages. Fine-tuning on ~40K parallel sentences transfers learned representations (subword tokenization patterns, morphological awareness) to the underrepresented variety.
- Core assumption: The tokenizer's coverage of Northern Uzbek sufficiently overlaps with Southern Uzbek to provide meaningful subword units.
- Evidence anchors:
  - [abstract] "We present new resources for Southern Uzbek machine translation, including...a fine-tuned NLLB-200 model (lutfiy)."
  - [section 5.1.2] "Our model called lutfiy maintains the original NLLB tokenizer and vocabulary, relying on existing Turkic language representations for Southern Uzbek processing."
  - [corpus] TUMLU benchmark paper confirms shared linguistic structures across Turkic languages, supporting transfer hypothesis.
- Break condition: If Southern Uzbek diverges significantly in vocabulary or script encoding from NLLB's Turkic representations, transfer gains would diminish.

### Mechanism 2
- Claim: Transliteration to Latin script before embedding-based alignment improves sentence pair extraction from bilingual texts.
- Mechanism: LaBSE embeddings were trained primarily on Latin-script languages. Converting Arabic-script Southern Uzbek to Latin script via rule-based transliteration aligns better with LaBSE's embedding space, increasing successful alignments by 40%.
- Core assumption: Rule-based transliteration preserves semantic content and morphological boundaries sufficiently for embedding similarity.
- Evidence anchors:
  - [section 4.3] "This transliteration approach yielded a 40% more successfully aligned sentence pairs compared to direct Arabic script processing."
  - [section 4.3] "We utilize LaBSE to generate embeddings for each potential sentence pair, calculate cosine similarity between embeddings, and adjust similarity scores using length ratios."
  - [corpus] No direct corpus evidence for transliteration-as-preprocessing mechanism in low-resource MT; this appears novel.
- Break condition: If transliteration introduces systematic errors (e.g., ambiguous vowel mappings), alignment quality degrades.

### Mechanism 3
- Claim: Character-level n-gram post-processing restores morphological boundary markers that the tokenizer strips, improving BLEU substantially.
- Mechanism: The SentencePiece tokenizer normalizes half-space characters (U+200C) to regular spaces, preventing the model from learning proper morphological boundaries. A character-level n-gram model trained on corrected text predicts where half-spaces should be inserted based on vowel-final stem patterns and suffix attachment rules.
- Core assumption: Half-space placement follows learnable statistical patterns from character context.
- Evidence anchors:
  - [section 5.1.3] "The NLLB SentencePiece tokenizer normalizes half-space characters (U+200C) to regular spaces during preprocessing, preventing the model from learning proper morphological boundary representation."
  - [section 6] "BLEU scores increase dramatically (from 25.99 to 34.31), representing a 32% relative improvement."
  - [corpus] Persian half-space recognition work (Doostmohammadi et al., 2020, cited in paper) supports plausibility for Arabic-script languages.
- Break condition: If morphological boundaries are ambiguous or inconsistent in training data, the n-gram model will over- or under-insert half-spaces.

## Foundational Learning

- Concept: Agglutinative morphology and suffixation
  - Why needed here: Southern Uzbek builds words through extensive suffix chains (nominalizers, tense markers, etc.). The half-space orthography rule depends on whether stems end in vowels or consonants. Understanding this is essential for interpreting why tokenization and post-processing matter.
  - Quick check question: Given a suffix "-chi" attached to a vowel-final stem, should a half-space separator appear between them according to Southern Uzbek orthography?

- Concept: Zero-width non-joiner (ZWNJ, U+200C) in Arabic script
  - Why needed here: This character marks morphological boundaries in Southern Uzbek (and Persian). Tokenizers often normalize or strip it, which is the core orthographic challenge this paper addresses.
  - Quick check question: What happens to U+200C when processed by a typical SentencePiece tokenizer trained on Unicode-normalized text?

- Concept: Transfer learning from related languages in multilingual models
  - Why needed here: The approach depends on NLLB-200's existing Turkic language coverage. Understanding what linguistic knowledge transfers—and what doesn't—explains why fine-tuning works with only ~40K sentences.
  - Quick check question: If NLLB-200 had no Turkic languages in pretraining, would you expect the same fine-tuning results? Why or why not?

## Architecture Onboarding

- Component map:
  Data pipeline -> LaBSE alignment with transliteration -> NLLB-200 fine-tuning -> Half-space post-processing -> Evaluation

- Critical path:
  1. Transliterate Arabic-script Southern Uzbek to Latin script
  2. Run LaBSE alignment to extract parallel sentence pairs
  3. Fine-tune NLLB-200 on aligned pairs
  4. Apply half-space post-processor to model outputs
  5. Evaluate on FLORES+ dev set

- Design tradeoffs:
  - **Tokenizer vs. post-processing**: Authors chose to keep NLLB's tokenizer (compatibility, existing Turkic coverage) and fix half-spaces externally rather than retraining tokenizer with ZWNJ preservation (more complex, requires vocabulary extension)
  - **Data diversity vs. quality**: Literary corpus dominates (90%); may bias toward formal registers; authors acknowledge this limitation
  - **Model size**: 600M distilled variant chosen for resource efficiency; larger NLLB variants might improve quality but increase inference cost

- Failure signatures:
  - Low BLEU but reasonable chrF++: Indicates tokenization boundary issues (half-space problems), not semantic translation failures
  - Poor performance on conversational/technical text: Likely literary corpus bias
  - Inconsistent half-space insertion: N-gram post-processor encountering unseen morphological patterns

- First 3 experiments:
  1. Replicate fine-tuning without half-space post-processing on uzn-uzs to isolate the 32% BLEU improvement claim
  2. Test lutfiy on out-of-domain text (e.g., news, medical) to assess generalization beyond literary registers
  3. Compare alignment quality: LaBSE on Arabic script directly vs. transliterated text on a held-out sample to validate the 40% extraction improvement claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would modifying the NLLB tokenizer to preserve half-space characters (U+200C) outperform the current post-processing workaround?
- Basis in paper: [explicit] The half-space post-processing "represents a workaround rather than addressing the underlying tokenizer limitations."
- Why unresolved: The authors implemented post-processing instead of fixing the tokenizer; this issue also affects Persian and other Arabic-script languages.
- What evidence would resolve it: A/B comparison between post-processing and modified tokenizer approaches on BLEU/chrF++ for Southern Uzbek and Persian.

### Open Question 2
- Question: Do human evaluations reveal quality differences that automatic metrics miss for morphologically complex Southern Uzbek?
- Basis in paper: [explicit] "Evaluation relies primarily on automatic metrics, which may not fully capture translation quality nuances for morphologically complex languages."
- Why unresolved: No human evaluation was conducted despite being explicitly identified as needed.
- What evidence would resolve it: Human judgments on adequacy, fluency, and morphological accuracy comparing lutfiy against baselines.

### Open Question 3
- Question: Can LLM-based data augmentation expand the parallel corpus effectively while maintaining translation quality?
- Basis in paper: [explicit] Future work will include "exploring data augmentation techniques using large language models."
- Why unresolved: Current work used only 40K mined pairs; LLM augmentation was not tested.
- What evidence would resolve it: Experiments adding LLM-generated synthetic pairs with quality filtering, measuring BLEU/chrF++ improvements.

## Limitations

- Dataset Composition Bias: The parallel corpus is dominated by literary text (35,865 sentences from 27 books represent 90% of data), which may limit the model's performance on conversational, technical, or domain-specific language.
- Post-processing Complexity: The character-level n-gram model for half-space restoration is a critical component that achieved a 32% relative BLEU improvement, but implementation details are not fully specified.
- Transliteration Assumptions: The 40% improvement claim from Latin-script transliteration relies on LaBSE embeddings being optimized for Latin scripts, which is not empirically validated with direct comparison data.

## Confidence

- High Confidence: The fundamental approach of fine-tuning multilingual models for low-resource languages, and the general architecture (NLLB-200 + post-processing) are sound and well-documented.
- Medium Confidence: The specific hyperparameters, training duration, and dataset composition are clearly specified. However, the literary corpus bias and the critical role of the half-space post-processor introduce uncertainty about real-world performance.
- Low Confidence: The exact implementation details of the n-gram post-processor, the specific literary sources, and the complete validation methodology for the transliteration improvement are not fully disclosed.

## Next Checks

1. **Domain Generalization Test**: Evaluate lutfiy on out-of-domain text (news articles, technical documentation, social media) to assess whether the literary corpus bias affects practical usability.

2. **Component Isolation Experiment**: Fine-tune NLLB-200 on the same data without the half-space post-processor to quantify the exact contribution of this component to the 34.31 BLEU score.

3. **Alignment Quality Comparison**: Conduct a controlled experiment comparing LaBSE alignment quality on Arabic-script Southern Uzbek directly versus transliterated Latin script using a held-out sample to independently verify the 40% improvement claim.