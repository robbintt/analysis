---
ver: rpa2
title: 'SpurBreast: A Curated Dataset for Investigating Spurious Correlations in Real-world
  Breast MRI Classification'
arxiv_id: '2510.02109'
source_url: https://arxiv.org/abs/2510.02109
tags:
- spurious
- correlations
- dataset
- datasets
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SpurBreast addresses the challenge of spurious correlations in
  deep learning models for breast MRI classification, which can lead to models relying
  on non-clinical features instead of meaningful medical patterns. The dataset is
  curated from the DUKE Breast Cancer Dataset and includes well-documented spurious
  correlations such as magnetic field strength (1.5T vs 3T) and image orientation.
---

# SpurBreast: A Curated Dataset for Investigating Spurious Correlations in Real-world Breast MRI Classification

## Quick Facts
- arXiv ID: 2510.02109
- Source URL: https://arxiv.org/abs/2510.02109
- Reference count: 30
- Models trained on spurious datasets achieve near-perfect validation accuracy but drop to around 50% on unbiased test sets

## Executive Summary
SpurBreast is a dataset designed to study how deep learning models exploit spurious correlations in medical imaging, leading to high validation accuracy but poor generalization. The dataset introduces controlled spurious correlations between diagnostic labels and non-clinical features like magnetic field strength (1.5T vs 3T) and image orientation in breast MRI scans. Experiments demonstrate that models achieve near-perfect accuracy on training and validation data but fail catastrophically on unbiased test sets, confirming their reliance on these non-clinical shortcuts rather than meaningful medical patterns.

## Method Summary
The dataset is curated from the DUKE Breast Cancer Dataset and includes controlled spurious correlations through patient-level splits. Researchers can use ResNet-50 and ViT-B/16 models with ImageNet pretraining to investigate how these models exploit shortcuts. The dataset provides both baseline variants (without spurious correlations) and spurious variants (with magnetic field strength, vertical orientation, and other features) to compare performance and study generalization strategies.

## Key Results
- Models trained on spurious datasets achieve ~99% validation accuracy but ~50% test accuracy on unbiased data
- Strong spurious correlations (magnetic field strength, vertical alignment) cause complete failure on unbiased test sets
- Weak spurious correlations (ethnicity, menopause, surgery type) result in moderate degradation (~70% test accuracy)
- The dataset enables controlled evaluation of clinically relevant vs irrelevant features

## Why This Works (Mechanism)

### Mechanism 1: Deliberate Spurious Correlation Injection via Controlled Dataset Splits
When non-clinical features are perfectly correlated with diagnostic labels in training data, DNNs exploit these as shortcuts rather than learning clinically meaningful patterns. The dataset construction assigns tumor-positive labels exclusively to images with one property (e.g., 1.5T scanner) and tumor-negative labels to images with another (e.g., 3T scanner). Models learn this simple decision boundary, achieving near-perfect validation accuracy while ignoring actual tumor features.

### Mechanism 2: Global vs. Local Spurious Feature Exploitability
Spurious features operate through different mechanisms depending on whether they are global (affecting entire image) or local (affecting spatial arrangement). Global features like magnetic field strength alter image-wide properties creating exploitable patterns. Local features like vertical orientation only change spatial arrangement without modifying tissue characteristics. Both can be learned as decision shortcuts.

### Mechanism 3: Validation-Test Gap as Spurious Correlation Detector
A large gap between validation accuracy and unbiased test accuracy indicates reliance on spurious features rather than generalizable clinical patterns. When spurious correlations exist in both training and validation splits, validation accuracy remains high. When test data removes this correlation, performance collapses to chance level (~50% for binary classification).

## Foundational Learning

- **Spurious Correlations (Shortcut Learning)**
  - Why needed here: The entire paper investigates how models learn non-clinical features instead of meaningful patterns
  - Quick check question: Can you explain why a model achieving 99% validation accuracy might still fail completely in deployment?

- **Distribution Shift**
  - Why needed here: The paper frames spurious correlations as a cause of distribution shift problems
  - Quick check question: What happens to model predictions when the correlation between a learned shortcut feature and the target label reverses at test time?

- **Transfer Learning from ImageNet Pretraining**
  - Why needed here: Both ResNet-50 and ViT-B/16 are initialized with ImageNet weights
  - Quick check question: Why might ImageNet pretraining help or hinder learning of domain-specific spurious features in medical images?

## Architecture Onboarding

- **Component map**: DUKE Breast Cancer Dataset (922+ patients, 3D MRI scans) -> Dataset variants (Baseline vs Spurious) -> Models (ResNet-50, ViT-B/16) -> Evaluation (Training/Validation/Test accuracy) -> Repository (github.com/utkuozbulak/spurbreast)

- **Critical path**: 1. Load baseline dataset → establish reference performance (expect ~77-83% test accuracy) 2. Load spurious dataset (magnetic field strength or vertical alignment) → observe validation accuracy approach 100% 3. Evaluate on unbiased test set → confirm collapse to ~50% accuracy 4. Compare weak spurious features (ethnicity, menopause) → observe intermediate degradation (~70% test accuracy)

- **Design tradeoffs**: Using real medical images vs. synthetic data trades realism for controlled variability; Patient-level splits prevent data leakage but reduce available training samples; Binary classification simplifies analysis but may miss nuanced clinical patterns

- **Failure signatures**: Validation accuracy ≈ 100% with test accuracy ≈ 50% indicates model learned spurious shortcut; Model predicts based on scanner type rather than tumor presence; PPV and NPV show extreme asymmetry suggesting systematic bias

- **First 3 experiments**: 1. Train ResNet-50 on medium-data baseline dataset with grid search over learning rates and optimizers; confirm test accuracy ≥75% 2. Train on magnetic field strength spurious dataset; verify validation → test accuracy gap (target: 99% → 50%) 3. Train on ethnicity dataset; observe moderate degradation (target: test accuracy ~70%)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mitigation strategies can effectively prevent models from relying on magnetic field strength and image orientation without degrading the learning of clinical features?
- Basis in paper: The authors state the dataset is designed to allow researchers to "investigate... generalization strategies" and develop methods to "improve model generalization."
- Why unresolved: The paper quantifies the failure of standard models (ResNet, ViT) which drop to ~50% accuracy, but does not propose or test algorithmic solutions to prevent this shortcut learning.
- What evidence would resolve it: A training methodology that maintains high validation accuracy while achieving >80% accuracy on the unbiased test sets for the magnetic field strength and vertical alignment splits.

### Open Question 2
- Question: Can uncertainty estimation techniques reliably flag instances where a model is relying on spurious correlations rather than clinical pathology?
- Basis in paper: The abstract explicitly lists "uncertainty estimation" as a primary research area the dataset is intended to facilitate.
- Why unresolved: The current work focuses on classification accuracy metrics (PPV, NPV) and does not evaluate whether the models exhibit higher uncertainty when making predictions based on spurious features.
- What evidence would resolve it: Demonstrating that predictive entropy or other uncertainty metrics are significantly higher for samples where the model utilizes spurious features compared to those where it utilizes clinical features.

### Open Question 3
- Question: Do self-supervised or foundation models exhibit the same susceptibility to the magnetic field strength shortcut as the ImageNet pre-trained models tested?
- Basis in paper: The methodology is restricted to ResNet-50 and ViT-B/16 with supervised ImageNet initialization; generalization to other pre-training paradigms is unstated.
- Why unresolved: Models trained on domain-specific data via self-supervision might learn different feature representations that do not latch onto global texture differences (1.5T vs 3T) as shortcuts.
- What evidence would resolve it: Evaluation of self-supervised medical foundation models on the SpurBreast splits, showing a reduced performance gap between validation and test sets.

## Limitations
- The exact patient split assignments and random seeds are not specified, making exact reproduction of results difficult
- Limited evaluation of alternative spurious features beyond the six documented in the dataset
- No analysis of how different medical imaging modalities (beyond MRI) might exhibit spurious correlations

## Confidence
- **High confidence**: The core finding that models exploit spurious correlations when present (validation accuracy ~99% vs test accuracy ~50%) is well-supported by experimental results
- **Medium confidence**: Claims about the difference between global (magnetic field strength) and local (vertical orientation) spurious features
- **Low confidence**: Generalization claims to other medical imaging domains without empirical validation across different imaging types

## Next Checks
1. Verify spurious correlation introduction by computing label distribution across magnetic field strength values in training vs test sets
2. Test model robustness to different random seeds and patient split assignments to confirm reproducibility
3. Conduct ablation study removing one patient from each spurious correlation pair to assess model sensitivity to individual cases