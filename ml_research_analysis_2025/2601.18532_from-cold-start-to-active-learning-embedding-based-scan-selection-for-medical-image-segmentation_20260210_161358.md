---
ver: rpa2
title: 'From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical
  Image Segmentation'
arxiv_id: '2601.18532'
source_url: https://arxiv.org/abs/2601.18532
tags:
- selection
- active
- learning
- cold-start
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of reducing annotation costs in
  medical image segmentation by proposing an active learning framework that combines
  a diversity-based cold-start phase with uncertainty-driven sample selection. The
  core method uses foundation model embeddings, dimensionality reduction via t-SNE,
  and automatic cluster selection to initialize training with a representative, diverse
  subset of images.
---

# From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation

## Quick Facts
- arXiv ID: 2601.18532
- Source URL: https://arxiv.org/abs/2601.18532
- Reference count: 40
- Reduces annotation costs in medical image segmentation by combining foundation model embeddings with clustering and uncertainty-driven active learning, achieving up to 2.1 percentage points improvement in Dice score.

## Executive Summary
This paper introduces a two-stage active learning framework for medical image segmentation that reduces annotation costs while maintaining or improving segmentation quality. The approach begins with a diversity-based cold-start phase that uses foundation model embeddings and clustering to select a representative initial training set, then iteratively expands this set using an uncertainty-diversity trade-off during active learning. Evaluated across three medical imaging datasets, the method consistently outperforms random selection and other baselines, particularly in low-data regimes.

## Method Summary
The framework operates in two phases: (1) cold-start selection uses RadImageNet embeddings reduced to 2D via t-SNE, clustering with automatically selected k via silhouette score, and medoid-based sampling to create a diverse initial training set; (2) active learning iteratively selects samples by combining prediction entropy with spatial diversity in embedding space using a weighted sum. The segmentation model is retrained from scratch each round using an Attention U-Net architecture. The method was evaluated on SynthStrip brain MRI, Montgomery chest X-rays, and CheXmask-300 datasets.

## Key Results
- Consistently outperforms random selection across all three datasets (brain MRI, chest X-rays)
- Achieves up to 2.1 percentage points improvement in Dice score
- Substantially reduces 95th percentile Hausdorff distance, especially in low-data regimes
- Diversity-based cold-start initialization reduces performance variance compared to random sampling

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Diversity-based cold-start initialization using foundation model embeddings yields a more representative training set than random sampling, reducing performance variance in low-data regimes.
- **Mechanism**: High-dimensional image features are extracted via a pre-trained encoder (RadImageNet) and projected to 2D. Clustering identifies structural modes in the data, and medoid selection ensures these modes are covered proportionally rather than randomly.
- **Core assumption**: The pre-trained encoder captures semantic similarity relevant to the target medical imaging domain, such that distance in the embedding space correlates with anatomical similarity.
- **Evidence anchors**:
  - [abstract]: "...cold-start sampling strategy that combines foundation-model embeddings with clustering... to construct a diverse and representative initial training."
  - [section 3.1.4]: "The medoids form the initial seeds... [proportional allocation] ensures that the total is equal to R."
  - [corpus]: Weak direct evidence; related work focuses on general cold-start clustering but not specifically on foundation embeddings for medical segmentation.
- **Break condition**: If the domain shift between the encoder's pre-training data (e.g., general radiology) and the target dataset is too large, embeddings may not cluster by anatomical structure, rendering medoid selection arbitrary.

### Mechanism 2
- **Claim**: Combining uncertainty (entropy) with spatial diversity (distance in embedding space) during active learning prevents the redundant selection of similar uncertain samples.
- **Mechanism**: The acquisition function scores candidates by a weighted sum of normalized prediction entropy and their minimum distance to already selected samples. This forces the model to explore distinct regions of the feature space while exploiting uncertainty.
- **Core assumption**: The 2D projection preserves enough global structure to meaningfully distinguish between "diverse" and "redundant" samples.
- **Evidence anchors**:
  - [abstract]: "...uncertainty-based AL framework that integrates spatial diversity to guide sample selection."
  - [section 3.2.3]: "S(i) = αD̃(i) + (1-α)H̃(xi)... favoring informative yet non-redundant samples."
  - [corpus]: No direct evidence; corpus focuses on preference learning and recommendation cold-starts, lacking this specific spatial-uncertainty trade-off.
- **Break condition**: If the segmentation model is miscalibrated, entropy scores may not reflect true uncertainty, causing the diversity term to dominate or fail to select the most informative boundaries.

### Mechanism 3
- **Claim**: Automatically selecting the number of clusters ($k$) via silhouette score prevents coverage gaps caused by arbitrary fixed-$k$ clustering.
- **Mechanism**: Instead of setting $k$ equal to the budget (which can merge distinct modes), the method scans a range of $k$ values and picks the one maximizing cluster cohesion and separation, ensuring the sampling budget is distributed across naturally occurring data groups.
- **Core assumption**: The optimal $k$ for clustering quality corresponds to a granularity suitable for the annotation budget.
- **Evidence anchors**:
  - [abstract]: "...including automatic selection of the number of clusters..."
  - [section 3.1.3]: "We select the one that maximizes the mean silhouette score... ˆk = arg max S(k)."
  - [corpus]: Missing.
- **Break condition**: In datasets with a smooth manifold rather than distinct clusters, the silhouette score may be unstable, leading to inconsistent initializations across different runs.

## Foundational Learning

- **Concept**: **Foundation Models & Transfer Learning**
  - **Why needed here**: The method relies on RadImageNet embeddings to represent images before any segmentation training begins. Without understanding that these features are pre-learned semantic representations, the clustering step appears unmotivated.
  - **Quick check question**: Can you explain why features from a model trained on classification might be useful for a segmentation sampling task?

- **Concept**: **t-SNE (t-Distributed Stochastic Neighbor Embedding)**
  - **Why needed here**: The paper explicitly projects features to 2D t-SNE space for visualization and distance computation. Understanding that t-SNE prioritizes local neighborhood preservation over global distance is critical for interpreting the "diversity" mechanism.
  - **Quick check question**: Why would calculating distance in 2D t-SNE space be risky for global structure, and how does the paper justify using it?

- **Concept**: **Active Learning Cycles**
  - **Why needed here**: The framework is iterative: Train → Predict → Score → Select → Retrain. Understanding the "human-in-the-loop" concept is necessary to see why reducing annotation cost is the primary metric of success.
  - **Quick check question**: What is the "cold-start" problem in active learning, and how does the proposed method solve it differently than standard approaches?

## Architecture Onboarding

- **Component map**: Embedding Generator -> Projection Head -> Cold-Start Selector -> Segmentation Engine -> Active Scorer
- **Critical path**: The quality of the RadImageNet embeddings dictates the quality of the cold start. If the encoder fails to separate distinct pathologies in the 2D projection, subsequent sampling (both cold and active) will be sub-optimal.
- **Design tradeoffs**:
  - 2D vs. High-Dim Selection: The authors trade the mathematical rigor of high-dimensional distance for the computational efficiency and interpretability of 2D t-SNE.
  - Static vs. Dynamic α: The paper fixes α=0.3 for the entropy-diversity trade-off. This is simpler but may not be optimal across all training rounds (early rounds might need more diversity, later rounds more uncertainty).
- **Failure signatures**:
  - High Variance: If random selection outperforms the cold start, check the domain alignment of the RadImageNet encoder.
  - Cluster Collapse: If silhouette scores are low, the dataset may lack distinct clusters; fallback to pure farthest-point traversal.
  - Redundant Acquisitions: If visualized samples bunch up in one area despite the diversity term, the t-SNE projection may have distorted the global layout.
- **First 3 experiments**:
  1. Cold Start Validation: Run the cold-start selector vs. random sampling on a held-out 20% subset with a small budget (e.g., 10 samples). Plot the 2D t-SNE map to verify clusters match known anatomical variations.
  2. Ablation on α: Sweep α ∈ [0.0, 0.3, 0.5, 0.7, 1.0] to find the optimal balance between uncertainty and diversity for the specific target dataset.
  3. Encoder Swap: Replace RadImageNet embeddings with a generic ImageNet encoder or a randomly initialized encoder to quantify the impact of domain-specific pre-training on sampling quality.

## Open Questions the Paper Calls Out

- **Open Question 1**: Does the proposed framework generalize effectively to 3D volumetric segmentation tasks?
  - Basis in paper: [explicit] The authors note that "computational constraints related to GPU memory and runtime precluded extensive experimentation with full 3D training" and that the 2D setting "may not fully reflect the behavior... in three-dimensional scenarios."
  - Why unresolved: The t-SNE projection and clustering pipeline were only validated on 2D slices; 3D volumes introduce different memory constraints and spatial context requirements that were not tested.
  - What evidence would resolve it: Evaluation of the cold-start and active learning pipeline on standard 3D medical segmentation datasets (e.g., BTCV or MSD) using a 3D encoder.

- **Open Question 2**: Can dynamic adaptation of the uncertainty-diversity trade-off parameter (α) improve selection performance over fixed values?
  - Basis in paper: [explicit] The authors fixed α at 0.3 rather than "exploring a wider parameter sweep or dynamically adapting this balance across rounds or datasets."
  - Why unresolved: A static trade-off assumes the optimal balance between exploration (diversity) and exploitation (uncertainty) is constant throughout training, which is often untrue in active learning cycles.
  - What evidence would resolve it: Experiments comparing the fixed α against strategies that adjust α based on training epoch, model convergence, or validation loss.

- **Open Question 3**: How robust is the cold-start selection to the choice of foundation model embeddings?
  - Basis in paper: [explicit] The authors acknowledge the method depends on feature space quality but "did not evaluate alternative representations" beyond RadImageNet–ResNet50.
  - Why unresolved: Different pre-trained encoders (e.g., self-supervised vs. supervised, or different modalities) capture different semantic features, potentially altering cluster validity and silhouette scores.
  - What evidence would resolve it: Benchmarking the pipeline using alternative backbones such as MedSAM, ViT, or self-supervised models (e.g., SimCLR) on the same datasets.

## Limitations
- Relies heavily on RadImageNet embeddings, with no exploration of alternative foundation models or self-supervised representations
- Limited to 2D slices due to computational constraints, leaving 3D volumetric segmentation performance unverified
- Fixed α=0.3 for uncertainty-diversity trade-off without exploration of dynamic adaptation or parameter sensitivity

## Confidence
- **High**: The combined framework improves Dice scores and reduces HD95 compared to random selection in the tested datasets.
- **Medium**: The diversity-driven cold start consistently reduces performance variance in low-data regimes.
- **Low**: The method's robustness to domain shift in the encoder or to non-clusterable data manifolds is not established.

## Next Checks
1. **Encoder Domain Alignment**: Replace RadImageNet with a generic ImageNet encoder and measure the drop in cold-start performance to quantify reliance on domain-specific features.
2. **α Sweep**: Run the active learning loop with α ∈ {0.0, 0.3, 0.5, 0.7, 1.0} to identify the optimal uncertainty-diversity balance for each dataset.
3. **t-SNE Sensitivity**: Vary t-SNE perplexity (e.g., 5, 15, 30, 50) and measure the stability of medoid selection and active sample acquisition to assess projection robustness.