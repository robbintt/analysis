---
ver: rpa2
title: Feature Attribution from First Principles
arxiv_id: '2505.24729'
source_url: https://arxiv.org/abs/2505.24729
tags:
- attribution
- feature
- where
- given
- apnq
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper addresses the problem of evaluating and comparing feature\
  \ attribution methods in machine learning, where the lack of reliable evaluation\
  \ metrics and overly restrictive axioms hinder progress. The authors argue that\
  \ common axioms like Completeness, Sensitivity, and Linearity, while intuitive,\
  \ are too restrictive and produce attributions similar to Gradient\xD7Input, limiting\
  \ the diversity of explanations."
---

# Feature Attribution from First Principles

## Quick Facts
- arXiv ID: 2505.24729
- Source URL: https://arxiv.org/abs/2505.24729
- Reference count: 40
- One-line primary result: The paper proposes a measure-theoretic framework for constructing feature attributions from first principles, showing that common axioms force attributions to resemble Gradient×Input and recovering several existing methods as special cases.

## Executive Summary
This paper addresses the problem of evaluating and comparing feature attribution methods in machine learning, where the lack of reliable evaluation metrics and overly restrictive axioms hinder progress. The authors argue that common axioms like Completeness, Sensitivity, and Linearity, while intuitive, are too restrictive and produce attributions similar to Gradient×Input, limiting the diversity of explanations. They propose a constructivist framework that builds feature attributions from the ground up, starting with simple indicator functions and extending to complex models using measure theory. This approach allows for a flexible yet well-defined attribution method that naturally integrates with existing XAI techniques.

## Method Summary
The framework defines atomic attributions for indicator functions, then extends to complex models via integration against measures using the Riesz–Markov representation theorem. For deep ReLU networks, the attribution integral simplifies to a weighted sum over linear regions. The method allows closed-form computation for ReLU networks and recovers existing methods (e.g., Partial Dependence, Shapley values) as special cases by varying measure choices. The framework also introduces a theoretical approach for optimizing evaluation metrics with respect to feature attributions.

## Key Results
- Any feature attribution method satisfying Completeness, Sensitivity, and Linearity is mathematically constrained to approximate Gradient×Input
- The framework provides closed-form feature attributions for deep ReLU networks, enabling efficient computation
- Several existing attribution methods (Partial Dependence, Shapley values) emerge as special cases under different measure choices
- The theoretical framework allows optimizing evaluation metrics with respect to feature attributions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If an attribution method strictly enforces Completeness, Sensitivity, and Linearity, it is mathematically constrained to approximate Gradient × Input, limiting its expressive flexibility.
- **Mechanism:** The paper demonstrates (Theorem 2.1) that these axioms force the attribution φ(x, f) to equal ∇f(x₀) ⊙ (x - x') plus a remainder term. If the model is approximately linear (small Hessian norm M), the remainder vanishes, collapsing the attribution to Gradient × Input.
- **Core assumption:** The attribution method φ is Lipschitz continuous in its function argument, and the model f is twice continuously differentiable (C²) or approximated via smoothing (Section 2.2).
- **Evidence anchors:**
  - [section 2.2]: "Any feature attribution method satisfying Completeness, Sensitivity, and Linearity is a perturbation of the feature attribution method Gradient × Input."
  - [theorem 2.1]: Bounds the remainder term ‖φ(x, R_{x₀})‖₂ based on the model's non-linearity M.
  - [corpus]: Neighbors like "Using the Path of Least Resistance..." critique rigid path methods, supporting the need for flexibility.
- **Break condition:** The mechanism fails (attribution diverges from Gradient × Input) only if the model is highly non-linear (large M) or the Lipschitz continuity of φ is violated.

### Mechanism 2
- **Claim:** A general attribution method can be constructed from "first principles" by defining attribution for atomic indicator functions and extending via integration, rather than imposing global axioms.
- **Mechanism:** The framework uses a constructivist approach: define φ(x, 1_R) for hyperrectangles (atomic units), approximate complex models as sums of these indicators, and use the Riesz–Markov representation theorem to represent the final attribution as a Lebesgue–Stieltjes integral over a chosen measure μ (Theorem 3.2).
- **Core assumption:** The attribution method must be Linear and Functionally Supremum Continuous (FSC)—meaning the attribution converges as the model approximation converges uniformly.
- **Evidence anchors:**
  - [section 3]: "Start by defining attributions for the simplest possible models... and use these as building blocks."
  - [theorem 3.2]: "Attribution of a continuous model... is the following Lebesgue-Stieltjes integral."
  - [corpus]: "Distribution-Based Feature Attribution" neighbor aligns with the idea of defining attributions via integration over distributions.
- **Break condition:** If the FSC property is not satisfied, the limit of the sum of atomic attributions may not equal the attribution of the continuous model limit.

### Mechanism 3
- **Claim:** For Deep ReLU networks, the general integral form collapses into a weighted sum over the network's linear regions, enabling closed-form optimization of attributions.
- **Mechanism:** Deep ReLU networks partition input space into polytopes where the model is locally affine. By applying the measure-theoretic framework, the attribution integral simplifies to a sum over these regions (Corollary 4.1). This allows mapping the attribution to the "center of mass" of the measure in each region.
- **Core assumption:** The network is a piecewise affine continuous function (Definition 4.1), and the measures are positive Borel measures.
- **Evidence anchors:**
  - [corollary 4.1]: Attribution is a weighted sum of local linear models evaluated at the center of mass of the measure.
  - [table 1]: Shows how specific measures recover existing methods like PDP.
  - [section 4.1]: "This class of functions corresponds exactly to the deep ReLU networks."
- **Break condition:** In very deep networks, the number of linear regions grows exponentially, making the exact summation over all regions P ∈ R computationally intractable without approximation (Monte Carlo).

## Foundational Learning

- **Concept: Riesz–Markov Representation Theorem**
  - **Why needed here:** This theorem is the theoretical bridge that allows the authors to equate a "Linear + Continuous" attribution mapping to an integral measure. Without this, moving from atomic definitions to general models lacks rigor.
  - **Quick check question:** Can you explain why a linear functional on the space of continuous functions implies the existence of a representing measure?

- **Concept: Borel Measures and Lebesgue-Stieltjes Integration**
  - **Why needed here:** The framework unifies attribution methods by defining them as integrals against measures μ_{j,x}. Understanding how choice of measure (e.g., Dirac delta vs. Lebesgue) changes the output is central to using this framework.
  - **Quick check question:** If you set the measure μ to be a Dirac delta at the input x, what simple attribution method does the integral resemble?

- **Concept: Polytope Partitions of ReLU Networks**
  - **Why needed here:** The closed-form solution relies on the geometric interpretation of ReLU networks as piecewise linear functions dividing space into convex polytopes. Computing attributions requires understanding these regions.
  - **Quick check question:** How does the activation pattern of a ReLU layer define a boundary in the input space?

## Architecture Onboarding

- **Component map:** Atomic Attribution -> Measure Selector -> Model Approximator -> Integrator
- **Critical path:** The definition of the measure family {μ_{j,x}} is the single point of control. The paper proves that once this is set, the entire attribution method is defined (Theorem 3.2).
- **Design tradeoffs:**
  - **Exactness vs. Speed:** Using the closed-form ReLU solution (Corollary 4.1) is exact but requires iterating over linear regions; Monte Carlo integration (Appendix B.3) is faster but adds variance.
  - **Axiomatic Rigor vs. Flexibility:** The authors trade rigid axioms (Completeness) for the flexibility of measure choice, arguing that axioms restrict methods to Gradient × Input.
- **Failure signatures:**
  - **Gradient*Input Collapse:** If you inadvertently enforce Completeness + Sensitivity + Linearity + Lipschitz, you will recover Gradient × Input regardless of your measure choice (Theorem 2.1).
  - **Curse of Dimensionality:** For deep networks, explicitly enumerating linear regions for the closed-form solution will hang; requires approximation.
- **First 3 experiments:**
  1. Verify Gradient Collapse: Implement an attribution method with the axioms in Section 2.2 and verify on a simple MLP that the output matches Gradient × Input up to the Hessian-bound error.
  2. Measure Recovery: Implement the integrator and verify that setting the measure to δ_x ⊗ L recovers the Partial Dependence Plot (PDP) values as claimed in Table 1.
  3. Optimization via Measures: Implement the "Recall" optimization (Section 4.3) on a linear model to visualize how shifting the measure's center of mass maximizes the metric, confirming Theorem 4.1.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can closed-form solutions be derived for feature attributions that optimize a given evaluation metric?
- Basis in paper: [explicit] "As future work... we aim to better characterize the properties of attributions that optimize a given evaluation metric, and, if possible, derive closed-form solutions."
- Why unresolved: Theorem 4.1 only characterizes optimal solutions through projections onto [0,1]^d (centers of mass), not directly in the space of measures. The projection is not bijective, making it difficult to recover all optimal measures.
- What evidence would resolve it: Derivation of explicit formulas for optimal measures given specific evaluation metrics, or proof that closed-form solutions do not exist for certain metric classes.

### Open Question 2
- Question: Can gradient ascent algorithms in measure space effectively construct optimal feature attribution methods empirically?
- Basis in paper: [explicit] "On the empirical side, we plan to apply the gradient ascent algorithm of [33] in the context of feature attribution, providing a way of empirically constructing optimal feature attribution methods."
- Why unresolved: The paper provides only theoretical characterization of optimal solutions. Optimization in measure space is noted as "generally difficult and cannot be performed in closed form."
- What evidence would resolve it: Empirical demonstration showing gradient ascent converges to measures achieving high evaluation metric scores, with comparison to analytically derived optima where available.

### Open Question 3
- Question: How should one choose appropriate atomic attributions (measures) for specific practical applications?
- Basis in paper: [inferred] The paper shows that different measures recover different existing methods (Table 1), but provides no guidance on which choice is preferable. Section 3.1 presents one "possible definition" for indicator functions but doesn't justify it uniquely.
- Why unresolved: The framework offers flexibility but lacks criteria for selecting among the infinite family of possible measures.
- What evidence would resolve it: Systematic comparison of different measure choices across tasks (e.g., feature selection, debugging, recourse) showing which measures perform best for each application.

### Open Question 4
- Question: How can attribution methods be optimized when ground-truth feature importance is unavailable?
- Basis in paper: [explicit] "First, it relies on the availability of a ground-truth for the features, which is not always the case." The Recall metric in Section 4.3 assumes known important features D_{1,w}.
- Why unresolved: Real-world applications rarely have ground-truth feature importance. The optimization framework depends critically on this assumption.
- What evidence would resolve it: Development of evaluation metrics that do not require ground truth but still meaningfully characterize attribution quality, with theoretical guarantees connecting these metrics to the ground-truth-based ones.

## Limitations

- The central claim that axiomatic approaches collapse to Gradient×Input rests on the Lipschitz continuity of attribution methods—a property not all attribution methods satisfy
- The closed-form solution for ReLU networks faces exponential complexity in deep networks, limiting direct application
- The framework's practical utility depends on selecting appropriate measures for real-world applications, which the paper does not extensively explore

## Confidence

- **High confidence:** The mathematical framework and Theorem 2.1 (axioms → Gradient×Input) are rigorously proven
- **Medium confidence:** Practical implementation details, as the code repository is referenced but not provided
- **Low confidence:** Empirical validation section, as specific datasets, models, and hyperparameter details are not included

## Next Checks

1. **Validate Gradient Collapse:** Implement an attribution method enforcing Completeness, Sensitivity, and Linearity on a simple MLP and verify it approximates Gradient×Input within the theoretical bound
2. **Reconstruct Measure-Based Methods:** Implement the integrator and verify that specific measure choices (e.g., product of Dirac and Lebesgue) recover known methods like PDP as claimed in Table 1
3. **Test Closed-Form Attribution:** Implement Corollary 4.1 for a small ReLU network (2-3 layers) and compare the exact attribution against Monte Carlo integration to confirm computational feasibility