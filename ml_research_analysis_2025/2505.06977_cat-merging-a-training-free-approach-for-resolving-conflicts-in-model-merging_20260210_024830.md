---
ver: rpa2
title: 'CAT Merging: A Training-Free Approach for Resolving Conflicts in Model Merging'
arxiv_id: '2505.06977'
source_url: https://arxiv.org/abs/2505.06977
tags:
- merging
- task
- uni00000014
- knowledge
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "CAT Merging introduces a training-free approach for resolving\
  \ knowledge conflicts during multi-task model merging. The method selectively trims\
  \ conflict-prone components from task vectors using parameter-specific strategies\u2014\
  projection for linear weights and masking for normalization scalers and shifts\u2014\
  based on a lightweight forward pass with unlabeled exemplars."
---

# CAT Merging: A Training-Free Approach for Resolving Conflicts in Model Merging

## Quick Facts
- arXiv ID: 2505.06977
- Source URL: https://arxiv.org/abs/2505.06977
- Authors: Wenju Sun; Qingyong Li; Yangli-ao Geng; Boyang Li
- Reference count: 40
- Achieves 2.5% average accuracy improvement over state-of-the-art on vision tasks with ViT-B/32

## Executive Summary
CAT Merging introduces a training-free approach for resolving knowledge conflicts during multi-task model merging. The method selectively trims conflict-prone components from task vectors using parameter-specific strategies—projection for linear weights and masking for normalization scalers and shifts—based on a lightweight forward pass with unlabeled exemplars. Extensive experiments on vision, language, and vision-language tasks demonstrate that CAT Merging achieves average accuracy improvements of up to 2.5% (ViT-B/32) and 2.0% (ViT-L/14) over state-of-the-art methods, while also maintaining robustness with limited exemplars and reducing knowledge conflict compared to existing approaches.

## Method Summary
CAT Merging resolves conflicts in multi-task model merging through a training-free approach that leverages forward passes with unlabeled exemplars to identify conflict directions. For each task, the method computes conflict-specific removal bases for linear weights using eigen decomposition and binary masks for normalization parameters. These are then applied to edit task vectors before merging, preserving task knowledge while eliminating interference. The approach requires only 2-3 unlabeled exemplars per task and works across vision, language, and vision-language architectures.

## Key Results
- Achieves 2.5% average accuracy improvement over PCB Merging on 8 vision tasks with ViT-B/32
- Maintains strong performance with only 2-3 unlabeled exemplars per task
- Demonstrates effectiveness across vision, language, and vision-language tasks
- Reduces knowledge conflict more effectively than existing methods

## Why This Works (Mechanism)

### Mechanism 1: Projection-Based Conflict Removal for Linear Weights
- Claim: Projecting task vectors onto conflict-free subspaces reduces interference while preserving task-specific knowledge
- Mechanism: For each task k, compute a removal basis Bk from top-c eigenvectors of matrix Σ_{i≠k} Ti^T(Xk^T Xk - λXi^T Xi)Ti. Apply Φk(Ti) = Ti - TiBkBk^T to remove components aligned with task k's conflict directions.
- Core assumption: (Assumption 4.1) Lipschitz continuity of network layers allows bounding knowledge conflict propagation through the network
- Evidence anchors:
  - [section 5.1] "The optimal removal basis Bk is constructed from the top-c eigenvectors of the matrix: Σ_{i≠k} Ti^⊤(Xk^⊤ Xk - λXi^⊤ Xi)Ti"
  - [section 4] "Theorem 4.4 suggests that to reduce the upper bound on knowledge conflict, we can directly minimize the layer-wise perturbations"
  - [corpus] "Task Arithmetic in Trust Region" confirms knowledge conflict as central challenge in model merging
- Break condition: When λ=0 (ignoring knowledge preservation), accuracy drops sharply to 65.33% (ViT-B/32) from 78.3%

### Mechanism 2: Mask-Based Conflict Removal for Normalization Parameters
- Claim: Element-wise masking of scale/shift parameters reduces conflict while maintaining representational integrity
- Mechanism: For normalization scalers, compute binary mask mk selecting top-c dimensions maximizing: Σ_{i≠k}[Σ_{xk}(xk ◦ Ti ◦ mk)^2 - λΣ_{xi}(xi ◦ Ti ◦ mk)^2]. Apply as Φk(Ti) = Ti - Ti ◦ mk.
- Core assumption: Normalization parameters have element-wise effects that can be selectively neutralized without breaking network stability
- Evidence anchors:
  - [section 5.2] "This motivates selecting the top-c dimensions in mk corresponding to the largest components"
  - [Table 5] Removing scaler/shift trimming causes 1.5-3.9% accuracy degradation across ViT architectures
  - [corpus] Weak direct corpus support for normalization-specific conflict handling
- Break condition: When c is set too large (>128), excessive knowledge is discarded, degrading ViT-B/32 to 69.89%

### Mechanism 3: Data-Efficient Feature Extraction via Exemplar Forward Pass
- Claim: Only 2-3 unlabeled exemplars per task suffice to estimate conflict directions accurately
- Mechanism: Forward pass unlabeled exemplars through task-specific models to collect layer inputs Xk. ViT's patch-based processing ensures diversity even with limited samples.
- Core assumption: Feature statistics from few samples generalize to represent task-specific representations
- Evidence anchors:
  - [section 5] "relying solely on a lightweight forward pass with few unlabeled exemplars"
  - [Figure 2a] Stable performance with 1-5 exemplars per task (76.61% to 78.8% for ViT-B/32)
  - [corpus] "Training-free LLM Merging" also uses exemplar-based approaches
- Break condition: Performance degrades if λ=0, suggesting exemplar-based conflict estimation alone insufficient without knowledge preservation term

## Foundational Learning

- **Concept: Task Vectors (Task Arithmetic)**
  - Why needed here: CAT Merging builds on the fundamental definition of task vectors as Wk - W0; understanding this subtraction operation is prerequisite
  - Quick check question: Can you explain why adding task vectors directly causes knowledge conflict rather than simple knowledge accumulation?

- **Concept: Lipschitz Continuity and Feature Perturbation Bounds**
  - Why needed here: The theoretical justification relies on bounding how perturbations propagate layer-by-layer through the network
  - Quick check question: How does Theorem 4.4 connect layer-wise feature perturbations ||Δf̂^l_{k|i}|| to overall knowledge conflict |ΔL_{k|i}|?

- **Concept: Eigen Decomposition for Subspace Identification**
  - Why needed here: Finding conflict directions requires computing eigenvectors of the conflict matrix G = Σ_{i≠k} Ti^T(Xk^T Xk - λXi^T Xi)Ti
  - Quick check question: Why are top-c eigenvectors selected rather than all eigenvectors, and what happens if c is set too high?

## Architecture Onboarding

- **Component map:**
```
Input: Pretrained W0, Task vectors {T1...TK}, Exemplars {M1...MK}

[Feature Extraction Phase]
For each task k: Forward pass exemplars → Collect layer inputs Xk^l

[Conflict Analysis Phase]
For each task k, layer l:
  Linear weights: Eigen decomposition → Bk^l (removal basis)
  Norm scalers/shifts: Compute mk^l from conflict scores

[Vector Editing Phase]
For each task i, all other tasks k:
  Apply Φk^l(Ti^l) using basis/masks

[Merging Phase]
Wmtl = W0 + Σk Tk
```

- **Critical path:** Feature extraction (forward pass) → Eigen decomposition for linear layers → Mask computation for normalization → Sequential vector editing → Final merge

- **Design tradeoffs:**
  - **c (subspace dimension):** Higher c removes more conflict but risks discarding useful knowledge; recommend c=2-3 for low-sample regimes
  - **λ (knowledge preservation):** Higher λ preserves task knowledge but may retain conflicts; stable for λ>0
  - **Exemplar count:** More samples improve estimation but reduce practicality

- **Failure signatures:**
  - Sharp accuracy drop when λ=0: Knowledge preservation term critical
  - Instability across different α scaling values: Incomplete conflict removal
  - High variance across individual task performance: Imbalanced conflict handling

- **First 3 experiments:**
  1. Replicate Table 1 results with ViT-B/32 on 8 vision tasks; verify 78.3% average accuracy vs PCB Merging's 75.8%
  2. Ablation study following Table 5 protocol: systematically disable linear projection, scaler masking, shift masking
  3. Hyperparameter sweep: c∈{1,2,3,4,8,16,32} and λ∈{0,0.1,0.5,1.0,2.0} on held-out validation tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the critical hyperparameters, specifically the removal basis dimensionality ($c$) and the trade-off weight ($\lambda$), be determined adaptively per layer or task rather than manually tuned?
- Basis in paper: [inferred] The methodology explicitly sets $c$ as a "manually defined dimensionality parameter" and $\lambda$ as a hyperparameter. While the sensitivity analysis (Figure 4) demonstrates that these values significantly impact performance (e.g., performance dropping at $c=128$ or $\lambda=0$), the paper provides no automated mechanism for selecting them.
- Why unresolved: The paper establishes the importance of these parameters through ablation but leaves the optimal selection process to manual tuning or grid search.
- What evidence would resolve it: A theoretical derivation for optimal $c$ based on eigenvalue decay or an adaptive algorithm that adjusts $\lambda$ based on the measured conflict intensity at each layer.

### Open Question 2
- Question: Can CAT Merging be extended to a strictly zero-shot setting where unlabeled exemplars are unavailable?
- Basis in paper: [inferred] The method relies on a "lightweight forward pass with unlabeled exemplars" to extract the input features ($X_k$) necessary for computing the conflict metrics (Equations 10-17). The sensitivity analysis (Figure 2a) tests low-data regimes but does not address the complete absence of exemplars.
- Why unresolved: The current formulation depends on computing feature statistics from real data inputs; it is unclear if the "removal basis" can be accurately estimated using only the model weights or synthetic data.
- What evidence would resolve it: A modification of the framework that utilizes synthetic data (e.g., noise inputs or pre-training statistics) to approximate feature distributions, achieving comparable performance to the exemplar-based approach.

### Open Question 3
- Question: Does minimizing the derived layer-wise perturbation upper bound guarantee the minimization of actual knowledge conflict ($\Delta L_{k|i}$) in non-linear, deep networks?
- Basis in paper: [inferred] The theoretical justification (Theorem 4.4) relies on Lipschitz continuity assumptions (Assumptions 4.1 and 4.3) to establish an upper bound on knowledge conflict. The algorithm minimizes the term $\|\Delta \hat{f}^l_{k|i}\|$ from this bound.
- Why unresolved: The paper does not empirically validate the tightness of this bound; minimizing a loose upper bound might not effectively minimize the actual performance degradation caused by conflict.
- What evidence would resolve it: An empirical correlation analysis showing that minimizing the proposed objective function directly correlates with a reduction in the actual task-specific loss increase ($\Delta L_{k|i}$) across various model architectures.

## Limitations

- The method requires unlabeled exemplars for conflict analysis, though only 2-3 per task are needed
- Performance is sensitive to hyperparameter selection (λ, α, c), requiring grid search for optimal values
- Theoretical bounds rely on Lipschitz continuity assumptions that may not hold uniformly across all layer types

## Confidence

- **High Confidence:** The core mechanism of using projection-based removal for linear weights and masking for normalization parameters is well-supported by both theory and experimental evidence. The 2-3 exemplar sufficiency claim is empirically validated.
- **Medium Confidence:** The reported average accuracy improvements (2.5% for ViT-B/32, 2.0% for ViT-L/14) are credible given the ablation studies and sensitivity analyses, though exact replication requires hyperparameter tuning.
- **Low Confidence:** The theoretical bounds on knowledge conflict propagation rely on Assumption 4.1 (Lipschitz continuity), which may not hold uniformly across all layer types and network architectures beyond the tested ViT variants.

## Next Checks

1. **Hyperparameter Sensitivity Verification:** Replicate the λ and α sensitivity analysis (Figures 2b, 4a) on a held-out validation task to confirm the stability ranges reported in the paper.

2. **Conflict Reduction Quantification:** Measure the actual reduction in knowledge conflict (using the conflict metric defined in the paper) between CAT Merging and baseline methods on the same task sets to validate the "more effective conflict reduction" claim.

3. **Exemplar Efficiency Test:** Systematically vary exemplar count from 1 to 10 per task and measure performance degradation to verify the 2-3 exemplar sufficiency claim holds across different task distributions and model scales.