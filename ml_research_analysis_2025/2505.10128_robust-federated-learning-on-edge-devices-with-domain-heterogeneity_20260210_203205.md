---
ver: rpa2
title: Robust Federated Learning on Edge Devices with Domain Heterogeneity
arxiv_id: '2505.10128'
source_url: https://arxiv.org/abs/2505.10128
tags:
- learning
- prototypes
- global
- local
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses domain heterogeneity in federated learning
  by proposing FedAPC (Federated Augmented Prototype Contrastive Learning), a framework
  that improves model generalization through augmented prototype generation and contrastive
  alignment. The core idea involves creating augmented prototypes by computing mean
  features across multiple augmented views of local data, then aligning local features
  with global prototypes via a contrastive loss function.
---

# Robust Federated Learning on Edge Devices with Domain Heterogeneity

## Quick Facts
- arXiv ID: 2505.10128
- Source URL: https://arxiv.org/abs/2505.10128
- Reference count: 22
- The paper proposes FedAPC, a federated learning framework that improves model generalization by 1.67% on Digits and 1.98% on Office-10 over state-of-the-art methods.

## Executive Summary
This paper addresses domain heterogeneity in federated learning by proposing FedAPC (Federated Augmented Prototype Contrastive Learning). The framework improves model generalization through augmented prototype generation and contrastive alignment. By creating augmented prototypes from multiple views of local data and aligning local features with global prototypes via a contrastive loss, FedAPC enhances feature diversity and reduces overfitting to specific domains. Experiments on Office-10 and Digits datasets demonstrate superior performance compared to FedAvg, FedProto, and MOON, with faster convergence and greater stability across diverse domains.

## Method Summary
FedAPC introduces a two-stage approach to federated learning with domain heterogeneity. First, it generates augmented prototypes by computing mean features across multiple augmented views of local data, creating more robust global representations. Second, it employs a contrastive alignment mechanism where local features are aligned with these global prototypes through a contrastive loss function. This dual approach enhances feature diversity and reduces overfitting to specific domains. The method maintains communication efficiency by sharing only prototype representations rather than full model parameters, while achieving improved generalization across heterogeneous client data distributions.

## Key Results
- FedAPC achieves 1.67% improvement in average accuracy on Digits dataset compared to state-of-the-art baselines
- FedAPC achieves 1.98% improvement in average accuracy on Office-10 dataset over competing methods
- Demonstrates faster convergence and greater stability compared to FedAvg, FedProto, and MOON, particularly in challenging domains like SYN and DSLR

## Why This Works (Mechanism)
The mechanism works by addressing the core challenge of domain heterogeneity through dual representation learning. The augmented prototype generation creates more robust global representations by computing mean features across multiple augmented views of local data, which helps the model capture invariant features across domains. The contrastive alignment mechanism then ensures that local features from each client are properly aligned with these global prototypes, forcing the model to learn domain-agnostic representations. This two-pronged approach simultaneously increases feature diversity (through augmentation) and enforces consistency (through contrastive alignment), resulting in better generalization across heterogeneous data distributions.

## Foundational Learning
- Federated Learning: Distributed ML approach where clients collaboratively train a global model while keeping data local; needed for edge computing scenarios with privacy constraints; quick check: verify understanding of FedAvg as baseline
- Domain Adaptation: Techniques to adapt models trained on one distribution to perform well on different distributions; needed to handle heterogeneity across client devices; quick check: identify domain shift examples in Office-31 dataset
- Contrastive Learning: Self-supervised learning technique that learns representations by contrasting similar and dissimilar pairs; needed to align features across domains; quick check: understand how contrastive loss encourages feature similarity
- Data Augmentation: Technique of creating modified versions of training data to improve generalization; needed to generate diverse prototypes; quick check: list augmentation methods used (cropping, rotation, color jitter)
- Prototype-based Learning: Using representative examples or feature centroids to guide learning; needed for efficient global representation sharing; quick check: compare prototype sharing vs full model parameter sharing
- Domain Heterogeneity: Variation in data distribution across different clients or sources; needed to understand the problem being solved; quick check: identify which domains are most challenging in Office-10

## Architecture Onboarding

Component Map:
Data Augmentation -> Prototype Generation -> Contrastive Alignment -> Global Model Update

Critical Path:
Local client augmentation → Prototype computation → Prototype sharing → Contrastive loss computation → Global model aggregation → Parameter broadcast

Design Tradeoffs:
- Communication efficiency vs. accuracy: Prototype sharing reduces communication overhead but may limit model capacity compared to full parameter sharing
- Augmentation diversity vs. computational cost: More augmentation views improve prototype quality but increase local computation
- Contrastive margin tuning: Larger margins improve separation but may slow convergence
- Client participation: Full participation ensures better alignment but may be impractical in real deployments

Failure Signatures:
- Poor performance on specific domains despite good overall accuracy indicates insufficient prototype diversity
- Slow convergence suggests suboptimal contrastive margin or insufficient augmentation
- Large variance across runs indicates sensitivity to initialization or client sampling
- Performance degradation with fewer clients suggests reliance on large client participation

First Experiments:
1. Baseline comparison: Run FedAvg on same datasets to establish minimum performance threshold
2. Prototype ablation: Test FedAPC without augmentation to isolate the contribution of prototype generation
3. Contrastive ablation: Test FedAPC without contrastive loss to measure its impact on stability

## Open Questions the Paper Calls Out
None identified in the provided material.

## Limitations
- Evaluation scope limited to two vision datasets (Office-10 and Digits) with shallow CNN backbones, which may not reflect performance on complex architectures or non-vision domains
- Convergence analysis lacks statistical rigor with no confidence intervals or variance metrics across runs
- Theoretical grounding is weak with no formal convergence guarantees or bounds on expected improvements

## Confidence

| Claim | Confidence |
|-------|------------|
| Accuracy improvements | High |
| Convergence behavior | Medium |
| Theoretical guarantees | Low |

## Next Checks

1. Evaluate FedAPC on a larger, more diverse dataset (e.g., ImageNet-21K subsets) with deeper backbones (e.g., ResNet-50) to test scalability and robustness
2. Conduct statistical analysis across multiple random seeds and heterogeneous client distributions to quantify stability and variance
3. Perform ablation studies isolating the contributions of augmented prototype generation versus contrastive alignment to assess the relative importance of each component