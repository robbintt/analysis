---
ver: rpa2
title: Causal Abstractions, Categorically Unified
arxiv_id: '2510.05033'
source_url: https://arxiv.org/abs/2510.05033
tags:
- causal
- abstractions
- abstraction
- definition
- markov
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a categorical framework for causal abstractions,
  defining them as natural transformations between Markov functors. This approach
  unifies and generalizes existing methods for relating causal models at different
  levels of abstraction, handling deterministic and probabilistic models with discrete,
  continuous, or mixed variables.
---

# Causal Abstractions, Categorically Unified

## Quick Facts
- **arXiv ID**: 2510.05033
- **Source URL**: https://arxiv.org/abs/2510.05033
- **Reference count**: 6
- **One-line primary result**: Introduces categorical framework defining causal abstractions as natural transformations between Markov functors, unifying and generalizing existing methods.

## Executive Summary
This paper introduces a categorical framework for causal abstractions, defining them as natural transformations between Markov functors. The approach unifies and generalizes existing methods for relating causal models at different levels of abstraction, handling deterministic and probabilistic models with discrete, continuous, or mixed variables. The framework relaxes strict monoidal functor assumptions to lax monoidal functors, enabling modeling of interventions that don't align with individual variable domains. Using string diagrams, the authors explicitly describe consistent abstractions under interventions and show how do-calculus applied on high-level ADMG abstractions yields valid results on low-level graphs with unobserved confounders.

## Method Summary
The method defines causal abstractions categorically as deterministic natural transformations τ between Markov functors (F_L ∘ ι ⇒ F_H). The framework models causal structures using Markov categories and string diagrams, with interventions represented as morphisms. The key innovation is relaxing strict monoidal functor constraints to lax monoidal functors for handling non-aligned interventions, particularly relevant for neural network superposition cases. The authors prove this categorical definition generalizes existing interventional consistency conditions and show validity of do-calculus rules transfers from high-level to low-level abstractions under specific graphical conditions.

## Key Results
- Categorical definition of causal abstractions as natural transformations generalizes existing interventional-abstracted CBNs (Theorem 3.1)
- String-diagrammatic characterization proves do-calculus rules valid on low-level graphs when applied to high-level ADMG abstractions (Theorem 4.1)
- Lax monoidal functors successfully model interventions on concepts that don't align with individual variables (Examples 3.1-3.2)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Causal abstractions ensure high-level models are valid by enforcing commutativity between low-level mechanisms and high-level clustering maps.
- **Mechanism**: A causal abstraction is defined as a deterministic natural transformation τ between Markov functors (F_L ι ⇒ F_H). This requires that processing data through low-level mechanisms then abstracting yields the same result as abstracting first then processing through high-level mechanisms.
- **Core assumption**: Causal systems can be represented as Markov categories, and high-level graph structure is a valid graphical abstraction of low-level graph.
- **Evidence anchors**: Definition 3.1 requires deterministic components; Theorem 3.1 proves equivalence to interventional distribution consistency.
- **Break condition**: If low-level mechanisms change such that clustering τ no longer preserves factorization properties, natural transformation condition fails.

### Mechanism 2
- **Claim**: Interventions on non-aligned concepts (e.g., superposition) are modeled by relaxing strict to lax monoidal functors.
- **Mechanism**: Standard causal models assume F(A ⊗ B) = F(A) × F(B). Lax monoidal functors allow coherence maps F(A) × F(B) → F(A ⊗ B), capturing inability to intervene on orthogonal concepts independently.
- **Core assumption**: System involves non-aligned interventionals where desired intervention targets map many-to-one or partially to observable variables.
- **Evidence anchors**: Section 3.3 discusses relaxing strict to lax monoidal functors; Examples 3.1-3.2 demonstrate application to neural superposition.
- **Break condition**: Forcing strict monoidal functor on system with superposition fails to represent valid interventions on underlying concepts.

### Mechanism 3
- **Claim**: Validity of do-calculus on high-level ADMGs transfers to low-level graphs because graphical abstraction preserves d-separation properties.
- **Mechanism**: String diagrams represent causal structure. If d-separation holds in high-level diagram, monoidality ensures it holds in low-level diagram, allowing Pearl's rules to apply generically.
- **Core assumption**: High-level graph H must be graphical abstraction of L according to specific operations (merging/deleting non-confounders).
- **Evidence anchors**: Theorem 4.1 proves 3 rules of do-calculus hold on low-level graph if applied on high-level ADMG abstraction.
- **Break condition**: If graphical abstraction operation violates constraints (e.g., deleting confounder), embedding fails and high-level do-calculus results may not transfer validity.

## Foundational Learning

- **Concept: Natural Transformations**
  - **Why needed here**: Core mathematical object defining causal abstraction (Definition 3.1). Essential for understanding how low-level and high-level causal models relate.
  - **Quick check question**: Given functors F, G mapping categories C → D, what structure must family of morphisms τ satisfy to be a natural transformation?

- **Concept: Markov Categories**
  - **Why needed here**: Frames causal models as Markov functors Free_L → M. Understanding "copy" and "discard" operations is essential for string diagram notation and deterministic morphisms.
  - **Quick check question**: In a Markov category, what two operations define comonoid structure on object X, and what do they represent probabilistically?

- **Concept: Lax vs. Strict Monoidal Functors**
  - **Why needed here**: Framework argues standard abstractions fail for neural networks with superposition. Understanding relaxation to lax monoidal functors is critical for mechanistic interpretability application.
  - **Quick check question**: What is the difference between strict monoidal functor and lax monoidal functor regarding map F(A) ⊗ F(B) → F(A ⊗ B)?

## Architecture Onboarding

- **Component map**: Low-Level Model (F_L) -> Graph Embedding (ι) -> High-Level Model (F_H) -> Abstraction Transformation (τ)

- **Critical path**:
  1. Define low-level causal structure (DAG/ADMG)
  2. Construct high-level graph via allowed merging/deleting operations
  3. Define functor F_L (mechanisms) and embedding ι
  4. Verify valid natural transformation τ exists that commutes with mechanisms

- **Design tradeoffs**:
  - **Strict vs. Lax Abstraction**: Strict abstractions are easier to reason about but fail in superposition; lax abstractions are more expressive but mathematically complex
  - **Effect-focused vs. Cause-focused**: Definition 3.1 clusters by effect on children; Definition 3.4 clusters by response to parents

- **Failure signatures**:
  - **Interventional Inconsistency**: High-level intervention do(ã) does not result in same distribution as corresponding low-level intervention
  - **Broken Commutativity**: Diagram in Section 3.1 fails to commute, meaning τ is not natural transformation for chosen mechanisms
  - **Superposition Mismatch**: Attempting to intervene on concept in strict framework when underlying representation requires lax framework

- **First 3 experiments**:
  1. **Sanity Check**: Implement 3-node SCM. Define clustering τ. Verify Theorem 3.1 by checking if interventional distributions match between concrete and abstracted models
  2. **Superposition Test**: Create synthetic dataset where two concepts stored in non-orthogonal directions in 2D space. Demonstrate strict monoidal functor fails for interventions on these concepts
  3. **ADMG Abstraction**: Take known ADMG with unobserved confounders. Apply clustering rules to generate high-level ADMG. Verify Theorem 4.1 by applying do-calculus rule on high-level graph and confirming validity on low-level structure

## Open Questions the Paper Calls Out

- **Open Question 1**: Can framework of "exact transformations" introduced by Rubenstein et al. (2017) be formally characterized within this categorical definition of causal abstractions?
  - **Basis**: Conclusion explicitly asks about fitting exact transformations into categorical framework
  - **Why unresolved**: Paper defines abstractions generally as natural transformations but does not prove equivalence with specific "exact transformation" criteria
  - **What evidence would resolve it**: Formal proof demonstrating exact transformation conditions correspond to specific natural transformation between associated Markov functors

- **Open Question 2**: How can categorical framework be extended to handle cyclic causal models?
  - **Basis**: Conclusion lists "Including cyclic causal models within our framework" as future direction
  - **Why unresolved**: Current framework relies on constructing Free Markov categories from DAGs, which excludes cyclic structures
  - **What evidence would resolve it**: Modification of Free category construction to allow cycles while preserving validity of causal abstractions as natural transformations

- **Open Question 3**: Does validity of Pearl's do-calculus on high-level abstractions (Theorem 4.1) hold for general Markov categories?
  - **Basis**: Conclusion states "one may try to prove Theorem 4.1 for general Markov categories"
  - **Why unresolved**: Proof uses string diagrammatical tools tailored to specific setting, unverified if result generalizes to abstract categorical level
  - **What evidence would resolve it**: Generalized categorical proof showing do-calculus rules hold in any Markov category, not just specific instances

## Limitations
- Framework relies heavily on abstract categorical machinery with limited concrete computational examples
- Transition from lax monoidal functors to specific neural network interventions remains largely conceptual without explicit algorithmic implementations
- Proofs assume well-behaved clustering maps and embeddings without addressing potential degeneracies in real-world data

## Confidence
- **High Confidence**: Categorical definition of causal abstractions as natural transformations (Theorem 3.1 equivalence with interventional consistency)
- **Medium Confidence**: Generalization of do-calculus validity on ADMG abstractions (Theorem 4.1) - relies on string diagram embeddings requiring careful verification
- **Medium Confidence**: Lax monoidal relaxation for superposition cases - conceptually sound but with limited empirical validation

## Next Checks
1. **Explicit Computation Validation**: For 3-variable SCM with known mechanisms, explicitly construct natural transformation τ, verify all naturality squares commute, and confirm interventional distributions match between low-level and high-level models as required by Theorem 3.1.

2. **Superposition Implementation**: Implement synthetic 2D superposition example (Example 3.1) with two non-orthogonal concepts. Demonstrate strict monoidal functors fail to model interventions on these concepts while lax monoidal functors succeed, explicitly computing coherence maps.

3. **ADMG Transfer Test**: Take published ADMG with unobserved confounders from causal inference literature. Apply graphical abstraction operations to create high-level ADMG. Apply do-calculus rules on high-level graph and verify resulting expressions are valid on low-level structure according to Theorem 4.1.