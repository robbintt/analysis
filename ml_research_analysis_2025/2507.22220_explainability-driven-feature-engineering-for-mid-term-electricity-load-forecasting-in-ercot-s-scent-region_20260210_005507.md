---
ver: rpa2
title: Explainability-Driven Feature Engineering for Mid-Term Electricity Load Forecasting
  in ERCOT's SCENT Region
arxiv_id: '2507.22220'
source_url: https://arxiv.org/abs/2507.22220
tags:
- load
- shap
- forecasting
- feature
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comparative analysis of machine learning
  models for mid-term electricity load forecasting in ERCOT's SCENT region. The authors
  employed SHAP (SHapley Additive Explanations) to improve model explainability and
  guide feature engineering, particularly for peak load prediction.
---

# Explainability-Driven Feature Engineering for Mid-Term Electricity Load Forecasting in ERCOT's SCENT Region

## Quick Facts
- arXiv ID: 2507.22220
- Source URL: https://arxiv.org/abs/2507.22220
- Authors: Abhiram Bhupatiraju; Sung Bum Ahn
- Reference count: 5
- Primary result: SHAP-informed feature engineering improved XGBoost MAPE to 0.79% for peak load forecasting

## Executive Summary
This paper presents a comparative analysis of machine learning models for mid-term electricity load forecasting in ERCOT's SCENT region. The authors employed SHAP (SHapley Additive Explanations) to improve model explainability and guide feature engineering, particularly for peak load prediction. Four models were evaluated: Linear Regression, XGBoost, LightGBM, and LSTM. SHAP analysis revealed that traditional features were insufficient for peak events, leading to consistent underprediction. To address this, the authors engineered new features like load_spike_vs_mean, temp_spike_vs_mean, and CDD_x_hour, guided by SHAP diagnostics. The improved XGBoost model achieved a MAPE of just 0.79% on 2024 data, with similar performance from LightGBM. The study demonstrates that SHAP-informed feature engineering significantly improves both accuracy and transparency, especially for extreme load forecasting scenarios.

## Method Summary
The study employed SHAP analysis to identify feature importance and guide feature engineering for mid-term electricity load forecasting in ERCOT's SCENT region. Four machine learning models were evaluated: Linear Regression, XGBoost, LightGBM, and LSTM. The authors initially found that traditional features were insufficient for peak load prediction, leading to consistent underprediction. To address this, they engineered new features (load_spike_vs_mean, temp_spike_vs_mean, and CDD_x_hour) based on SHAP diagnostics. The models were trained on historical data from 2014-2024 and evaluated on 2024 data. XGBoost with engineered features achieved the best performance with MAPE of 0.79%, closely followed by LightGBM. The study emphasizes the importance of model interpretability in identifying shortcomings and guiding feature development for improved forecasting accuracy.

## Key Results
- SHAP analysis revealed traditional features were insufficient for peak load prediction, leading to consistent underprediction
- Engineered features (load_spike_vs_mean, temp_spike_vs_mean, and CDD_x_hour) significantly improved model performance
- XGBoost model with engineered features achieved MAPE of 0.79% on 2024 data, with similar performance from LightGBM

## Why This Works (Mechanism)
SHAP-based feature engineering works by providing granular, instance-level explanations of model predictions. This allows identification of specific feature weaknesses during extreme events like peak loads. The mechanism involves using SHAP values to understand which features contribute most to prediction errors, then engineering new features that capture missing patterns. For electricity load forecasting, this approach is particularly effective because peak events involve complex interactions between temperature, time, and historical load patterns that traditional features may not capture. By creating features that explicitly model load spikes and temperature anomalies in relation to historical baselines, the model gains better representation of extreme scenarios.

## Foundational Learning
- SHAP (SHapley Additive exPlanations): Why needed - provides model-agnostic interpretability; Quick check - verify SHAP values align with known feature importance
- Mid-term forecasting challenges: Why needed - different from short-term with distinct data patterns; Quick check - compare error distributions across forecasting horizons
- Feature engineering for extreme events: Why needed - traditional features often fail during anomalies; Quick check - test engineered features specifically on peak days
- Cross-regional grid differences: Why needed - ERCOT has unique characteristics affecting load patterns; Quick check - validate approach on different ISO data

## Architecture Onboarding
Component map: Historical data -> Preprocessing -> Feature engineering (SHAP-guided) -> Model training (XGBoost/LightGBM/LSTM/Linear) -> Prediction -> SHAP analysis -> Iterate
Critical path: Feature engineering guided by SHAP analysis is the critical path for improving peak load prediction accuracy
Design tradeoffs: Simplicity of Linear Regression vs performance of ensemble methods; computational cost of SHAP analysis vs interpretability gains
Failure signatures: Consistent underprediction of peak loads indicates missing features for extreme events
Three first experiments:
1. Compare SHAP analysis results across different model architectures to validate feature importance consistency
2. Test engineered features in isolation to quantify their individual contributions to model performance
3. Validate the approach on a different time period or region to assess generalizability

## Open Questions the Paper Calls Out
None

## Limitations
- Results based on single regional grid (ERCOT SCENT) may not generalize to other regions
- Model performance relies heavily on quality and completeness of historical data
- Study focuses primarily on XGBoost and LightGBM, with less detailed analysis of LSTM and Linear Regression performance

## Confidence
High confidence: The overall methodology of using SHAP for feature importance analysis and subsequent feature engineering is sound and well-documented. The improvement in peak load prediction through engineered features is convincingly demonstrated.

Medium confidence: The generalizability of results to other regions or different time periods, as well as the robustness of the approach under varying data quality conditions.

Low confidence: The comparative performance analysis between different model architectures (XGBoost vs LightGBM vs LSTM vs Linear Regression) could be more comprehensive, and the study's implications for operational deployment are not fully explored.

## Next Checks
1. Test the SHAP-informed feature engineering approach on data from other regional grids (e.g., PJM, MISO) to assess generalizability and identify any region-specific adjustments needed.

2. Conduct a thorough computational efficiency analysis comparing the proposed approach with baseline models, including training time, inference latency, and resource requirements for real-time deployment.

3. Perform an ablation study to quantify the individual contributions of each engineered feature (load_spike_vs_mean, temp_spike_vs_mean, CDD_x_hour) to model performance, particularly for peak load prediction accuracy.