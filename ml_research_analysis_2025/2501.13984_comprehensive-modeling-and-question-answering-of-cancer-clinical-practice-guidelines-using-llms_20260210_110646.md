---
ver: rpa2
title: Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines
  using LLMs
arxiv_id: '2501.13984'
source_url: https://arxiv.org/abs/2501.13984
tags:
- indicates
- followed
- node
- knowledge
- disease
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ''
---

# Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs

## Quick Facts
- arXiv ID: 2501.13984
- Source URL: https://arxiv.org/abs/2501.13984
- Reference count: 40
- Primary result: Graph-based KG QA system with 66.10% valid Cypher generation, reducing hallucination risk

## Executive Summary
This paper presents a system for modeling and querying cancer clinical practice guidelines using knowledge graphs and LLMs. The approach extracts NCCN guidelines into a graph structure, enriches it with LLM-based node classification, and enables natural language question answering through LLM-generated Cypher queries. By constraining the LLM to retrieve answers from a verified subgraph rather than generating from memory, the system significantly reduces hallucination risk while maintaining factual accuracy. The methodology demonstrates strong performance on Non-Small Cell Lung Cancer guidelines with potential for expansion to other cancer types.

## Method Summary
The system transforms NCCN cancer guidelines into a knowledge graph with three node types (Disease Condition, Treatment Option, Evaluation) and three relationship types (requires, indicates, is_followed_by). Node classification is performed using few-shot learning with GPT-3.5-turbo, improving accuracy from 80.86% to 88.47%. For question answering, the LLM generates Cypher queries to retrieve subgraphs, which are then translated into natural language answers using deterministic templates. This graph-retrieval approach constrains the LLM's output to verified knowledge, mitigating hallucination risk. The system uses Neo4j for graph storage and requires manual schema definition as a critical initial step.

## Key Results
- Node classification accuracy improved from 80.86% (zero-shot) to 88.47% (few-shot)
- QA system achieved 66.10% valid Cypher generation rate
- Hallucination risk significantly reduced by confining LLM to verified subgraph retrieval
- Type-I/II/III error analysis provides clear framework for debugging failures

## Why This Works (Mechanism)

### Mechanism 1: Few-shot Learning for Semantic Classification
Providing specific node context and labeled examples to an LLM significantly improves semantic classification accuracy over context-free labeling. The LLM uses "few-shot learning" to map unstructured medical text and surrounding metadata to a fixed schema (Disease Condition, Treatment Option, Evaluation). By observing 23 correct examples, the model infers implicit rules for categorization, disambiguating terms that might otherwise overlap. This works because the LLM has sufficient pre-trained medical knowledge to understand nuances of terms like "resection" or "staging" when provided with context.

### Mechanism 2: Constrained Decoding for Hallucination Mitigation
Constrained decoding (forcing the LLM to generate a database query rather than a direct answer) mitigates hallucination by grounding the final output in a verified subgraph. Instead of asking the LLM to recall medical facts (risk of hallucination), the system asks the LLM to translate a natural language question into a Cypher query. This query retrieves a specific "subgraph" from the knowledge base. The final answer is generated by deterministically traversing this subgraph using a template, ensuring every claim is backed by a graph relationship.

### Mechanism 3: Graph Topology for Deterministic Translation
Graph topology (relationship types) allows for deterministic translation of complex medical pathways into natural language. The system uses a lookup table that maps specific graph patterns (Source Node -> Relation -> Destination Node) to natural language templates (e.g., "If the disease condition is X, use the treatment Y"). This works because the underlying graph relationships (requires, indicates, is followed by) are accurate and the path represents a clinically valid flow.

## Foundational Learning

- **Knowledge Graphs (KG) & Property Graphs**: The entire system relies on representing NCCN guidelines not as text, but as a network of nodes (medical entities) and edges (relationships). Understanding that data is stored as `(:Treatment {content: "..."})-[:requires]->(:Evaluation)` is step one.
  - Quick check: If you have a node "Surgery" and a node "PET Scan", which relationship type from the paper (requires, indicates, is followed by) would likely connect them?

- **Zero-Shot vs. Few-Shot Prompting**: The paper uses these distinct LLM techniques to automate data labeling. You must understand that "Zero-shot" means "classify this without examples" and "Few-shot" means "classify this based on these 5 examples I just gave you."
  - Quick check: Why did the paper's authors see a ~7% accuracy boost when switching from zero-shot to few-shot learning for node classification?

- **Retrieval-Augmented Generation (RAG) / GraphRAG**: The QA system is a form of GraphRAG. It retrieves structured data (a subgraph) to augment the LLM's generation context, preventing the LLM from making things up.
  - Quick check: In this architecture, does the LLM generate the final medical answer directly from its "memory," or does it assemble it from the query results?

## Architecture Onboarding

- **Component map**: Source Data (NCCN PDF Guidelines) -> Extraction Layer (converts PDF to JSON-LD) -> Storage Layer (Neo4j Graph Database) -> Enrichment Layer (OpenAI GPT-3.5 classifies nodes) -> QA Interface (NeoDash/LLM accepts query -> generates Cypher -> retrieves subgraph -> maps to text)

- **Critical path**: The Schema Definition (Manual Labeling) is the bottleneck. If the definitions of "Disease Condition" or "Treatment Option" are ambiguous, the LLM enrichment fails, and the subsequent Cypher queries (which filter by these labels) return empty results.

- **Design tradeoffs**:
  - Manual vs. Automated Enrichment: Manual is 100% accurate but slow; LLM automated is ~88% accurate but scalable
  - Direct LLM Answer vs. Graph-Retrieval: Direct LLM is fluid but hallucinates; Graph-Retrieval is rigid but factual (66% query success rate in paper)

- **Failure signatures**:
  - Type-I Error: LLM generates Cypher with syntax errors (e.g., wrong brackets)
  - Type-II Error: LLM queries for a substring that doesn't exist in the node (e.g., searching "Stage I, central" when the node says "Stage I (central)")
  - Type-III Error: LLM selects the wrong path length (depth) in the query, retrieving too much or too little context

- **First 3 experiments**:
  1. Reproduce Node Classification: Take 50 nodes from the JSON-LD, run Zero-Shot classification with GPT-3.5/4, and verify if accuracy matches the paper's 80% baseline
  2. Test Cypher Robustness: Input the 13 training questions into the system and measure how often the generated Cypher matches the "Ground Truth" Cypher provided in the paper
  3. Error Analysis: Induce a "Type-II" content mismatch error by slightly altering a medical term in a question (e.g., changing "mediastinal" to "media") and observe if the system fails gracefully or returns an empty graph

## Open Questions the Paper Calls Out

- Can the proposed knowledge modeling framework generalize to the remaining 60+ NCCN cancer types and effectively integrate heterogeneous data formats like tables and evidence blocks? The authors state they plan to expand this work to include over 60 additional types of cancer Clinical Practice Guidelines and integrate tables/evidence blocks into their existing knowledge base.

- How does the performance of the proprietary GPT-3.5 model compare to open-source Large Language Models for this specific knowledge graph enrichment and querying task? The conclusion notes they plan to evaluate their work by comparing its performance with other open-source LLMs.

- Can the question-answering system be evolved to address complex queries that require reasoning beyond the strict constraints of the guideline text? The authors identify that the limitation of guideline text-restrictive question answering needs to be addressed.

## Limitations
- Dataset availability: The underlying KG dataset and 72-question evaluation set are not provided, preventing direct replication
- Extraction pipeline opacity: The automated PDF-to-graph conversion tool referenced in the paper is not publicly available
- LLM dependency: Results are tied to specific OpenAI models (GPT-3.5/4) and their version-specific behaviors

## Confidence
- **High Confidence**: The core architectural insight (using LLM-generated Cypher to mitigate hallucination) is clearly described and logically sound
- **Medium Confidence**: Reported accuracy improvements (80.86% â†’ 88.47%) are plausible given the few-shot methodology, but exact reproducibility is blocked by missing dataset
- **Low Confidence**: The 66.10% QA success rate depends heavily on the quality of the external extraction tool and the specific LLM model version used

## Next Checks
1. Dataset Release Request: Contact authors to obtain the 72-question evaluation set with ground truth Cypher queries
2. Manual Graph Construction: Recreate a small subset of the KG (e.g., Figure 1) from NCCN PDFs and verify node classification accuracy
3. Cypher Generation Robustness: Test the QA pipeline with paraphrased medical questions to measure Type-I/II error rates and assess the system's tolerance for linguistic variation