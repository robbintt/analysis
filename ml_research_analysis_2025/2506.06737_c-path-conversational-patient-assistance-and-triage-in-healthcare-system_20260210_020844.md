---
ver: rpa2
title: 'C-PATH: Conversational Patient Assistance and Triage in Healthcare System'
arxiv_id: '2506.06737'
source_url: https://arxiv.org/abs/2506.06737
tags:
- medical
- patient
- data
- conversational
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: C-PATH is an LLM-based conversational system designed to assist
  patients in symptom recognition and triage to appropriate medical departments. It
  employs a three-stage fine-tuning pipeline (medical knowledge injection, dialogue
  tuning, summarization) using LLaMA3 and a novel GPT-augmented dataset construction
  approach that transforms clinical cases into patient-friendly dialogues.
---

# C-PATH: Conversational Patient Assistance and Triage in Healthcare System

## Quick Facts
- **arXiv ID**: 2506.06737
- **Source URL**: https://arxiv.org/abs/2506.06737
- **Reference count**: 40
- **Primary result**: LLM-based conversational triage system using three-stage fine-tuning and GPT-augmented dataset construction

## Executive Summary
C-PATH is an innovative LLM-based conversational system designed to assist patients in symptom recognition and triage to appropriate medical departments. The system employs a three-stage fine-tuning pipeline (medical knowledge injection, dialogue tuning, summarization) using LLaMA3, along with a novel GPT-augmented dataset construction approach that transforms clinical cases into patient-friendly dialogues. C-PATH also features scalable conversation history management to maintain coherence within context limits. Evaluations using GPTScore show strong performance in understandability, informativeness, and accuracy, with the GPT-rewritten dataset outperforming baselines.

## Method Summary
C-PATH uses a three-stage fine-tuning pipeline to create a healthcare-specific conversational agent. The first stage injects medical knowledge into the base LLaMA3 model, followed by dialogue tuning to improve conversational capabilities, and finally summarization training to generate concise outputs. A key innovation is the GPT-augmented dataset construction approach, which transforms existing clinical cases into patient-friendly dialogues by rewriting medical terminology and complex language into accessible formats. The system also implements scalable conversation history management to maintain context coherence within the model's context window limitations, allowing for extended patient interactions without losing track of previous exchanges.

## Key Results
- GPTScore evaluations demonstrate strong performance in understandability, informativeness, and accuracy
- GPT-rewritten dataset construction approach outperforms baseline datasets in understandability metrics
- Three-stage fine-tuning pipeline improves triage performance compared to single-stage alternatives

## Why This Works (Mechanism)
The three-stage fine-tuning approach works by progressively building specialized capabilities: medical knowledge injection provides the clinical foundation, dialogue tuning enables natural patient interaction, and summarization ensures clear communication of triage recommendations. The GPT-augmented dataset construction is effective because it transforms clinical jargon into patient-accessible language while preserving medical accuracy, addressing the key challenge of making healthcare information understandable to non-experts. The conversation history management maintains context coherence through intelligent summarization and selective retention of relevant information, allowing the system to handle extended interactions within context window constraints.

## Foundational Learning
- **LLM Fine-tuning Pipelines**: Why needed - to specialize general models for healthcare tasks; Quick check - can the model accurately answer medical queries after fine-tuning
- **Dataset Construction for Healthcare**: Why needed - clinical data is often too technical for patient consumption; Quick check - do patient surveys find the rewritten content understandable
- **Context Window Management**: Why needed - LLMs have fixed context limits but healthcare conversations can be lengthy; Quick check - can the system maintain coherence after 10+ turns
- **Medical-Triage Integration**: Why needed - accurate symptom-to-department mapping is critical for healthcare efficiency; Quick check - do triage recommendations match clinical guidelines
- **GPTScore Evaluation**: Why needed - standard metrics may not capture conversational quality in healthcare; Quick check - do GPTScore results correlate with human expert assessments
- **Patient-Provider Communication**: Why needed - healthcare access depends on clear communication between patients and systems; Quick check - can patients successfully complete triage using the system

## Architecture Onboarding

### Component Map
Patient Interface -> Conversation Manager -> LLaMA3 Core -> Medical Knowledge Base -> Output Generator

### Critical Path
Patient query -> Context retrieval -> Symptom extraction -> Triage logic -> Department recommendation

### Design Tradeoffs
- **Context vs. Performance**: Using summarization to maintain context within window limits vs. potential information loss
- **Medical Accuracy vs. Patient Understandability**: Balancing clinical precision with accessible language
- **Model Size vs. Response Time**: Larger models provide better accuracy but slower responses
- **Fine-tuning Depth vs. Generalization**: Extensive fine-tuning improves task performance but may reduce flexibility

### Failure Signatures
- Incorrect triage recommendations due to ambiguous symptom descriptions
- Loss of conversation coherence when context is aggressively summarized
- Over-reliance on pattern matching rather than true symptom understanding
- Inability to handle rare conditions outside training distribution

### First 3 Experiments
1. Test basic symptom-to-department mapping accuracy with standardized clinical cases
2. Evaluate conversation coherence maintenance over 5, 10, and 15-turn dialogues
3. Compare GPTScore metrics between C-PATH and baseline triage systems on identical patient scenarios

## Open Questions the Paper Calls Out
None

## Limitations
- External validity concerns due to lack of clinical validation with actual patients or healthcare providers
- Real-world stress testing of conversation history management with extended interactions not demonstrated
- Broader claims about reducing provider burden and improving patient accessibility lack empirical deployment evidence

## Confidence
- Three-stage fine-tuning pipeline improves triage performance: **High confidence** (supported by internal metrics and comparative results)
- GPT-rewritten dataset construction approach is novel and effective: **High confidence** (clear methodology and improved understandability scores)
- Scalable conversation history management maintains coherence: **Medium confidence** (technically sound but lacks real-world stress testing)
- System reduces provider burden and improves patient accessibility: **Low confidence** (no deployment or user studies provided)

## Next Checks
1. Conduct a randomized controlled trial comparing C-PATH's triage recommendations against standard care pathways
2. Perform a longitudinal study measuring actual impact on provider workload and patient outcomes
3. Implement stress testing with extended conversation histories to validate scalability claims under real-world usage patterns