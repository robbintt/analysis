---
ver: rpa2
title: 'Memory-DD: A Low-Complexity Dendrite-Inspired Neuron for Temporal Prediction
  Tasks'
arxiv_id: '2512.04094'
source_url: https://arxiv.org/abs/2512.04094
tags:
- uni00000013
- memory-dd
- uni00000011
- neuron
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Memory-DD, a low-complexity dendrite-inspired
  neuron model for temporal prediction tasks. The model integrates the Hadamard product
  gating mechanism of biological dendrites with recurrent memory functionality to
  capture temporal dependencies in sequential data.
---

# Memory-DD: A Low-Complexity Dendrite-Inspired Neuron for Temporal Prediction Tasks

## Quick Facts
- arXiv ID: 2512.04094
- Source URL: https://arxiv.org/abs/2512.04094
- Reference count: 40
- Memory-DD achieves 89.41% average accuracy on 18 time-series classification datasets, outperforming LSTM by 4.25% while using 50% fewer parameters

## Executive Summary
Memory-DD is a dendrite-inspired neuron model that extends low-complexity advantages to temporal prediction tasks. The model integrates Hadamard product gating mechanisms with recurrent memory functionality to capture temporal dependencies in sequential data. Through two dendrite-inspired neuron groups that extract logical relationships between features without nonlinear activation functions, Memory-DD achieves competitive performance while significantly reducing computational complexity.

## Method Summary
Memory-DD implements a novel recurrent architecture that uses element-wise multiplicative interactions (Hadamard product) as gating mechanisms without complex activation functions. The model computes an intermediate state $D_t$ through linear projection of the previous hidden state and current input, then uses this to update a cell state $C_t$ and generate a hidden state $H_t$ through two specialized dendritic neuron groups. Both groups share the same weight matrix, with Group 1 updating memory and Group 2 generating outputs. The architecture includes residual connections that add $D_t$ directly to both outputs, and uses only tanh activation in the dendritic groups.

## Key Results
- Memory-DD achieves 89.41% average accuracy on 18 time-series classification datasets, outperforming LSTM (85.16%) by 4.25%
- The model uses only 50% of LSTM parameters while reducing computational complexity (FLOPs) by 27.7%
- In regression tasks, Memory-DD achieves comparable performance to LSTM on 9 benchmark datasets
- Performance degrades noticeably at longer prediction horizons (24 steps), particularly on Exchange-Rate and Traffic datasets

## Why This Works (Mechanism)

### Mechanism 1
Element-wise multiplicative interactions (Hadamard product) may suffice for non-linear temporal gating without complex activation functions. The model computes a gating vector $W^{D_t}$ derived from context, which is multiplied element-wise with previous state $C_{t-1}$ (or current context $D_t$). Values near zero suppress information while values greater than one amplify it, capturing logical relationships (AND/OR/XOR) for temporal dependencies without heavier non-linearities.

### Mechanism 2
Decoupling memory storage ($C_t$) from output generation ($H_t$) via specialized neuron groups stabilizes learning. Group 1 updates the cell state using current context to filter history, while Group 2 generates the hidden state using updated history to filter current context. This separation reduces internal interference compared to standard coupled LSTM gates.

### Mechanism 3
Weight sharing between memory and output modules preserves performance while drastically reducing parameter count. Both groups use the exact same weight matrix $W$ for their Hadamard operations, forcing the model to learn a shared representation for both retaining history and deciding current output.

## Foundational Learning

- **Concept: Hadamard Product (Element-wise Multiplication)**
  - Why needed: This is the fundamental operation replacing complex activation functions, serving as a "filter" or "gate" where values close to zero suppress information
  - Quick check: If vector $A = [1, 0.5, 2]$ and vector $B = [0, 1, 0.1]$, what is $A \odot B$ and what does this imply about the information in $A$?

- **Concept: LSTM Cell State vs. Hidden State**
  - Why needed: Memory-DD explicitly mimics LSTM structure ($C_t$ and $H_t$). Understanding that $C_t$ is "long-term memory" and $H_t$ is "short-term working memory/output" is required to see why groups have different functional roles
  - Quick check: In a standard LSTM, which state is typically passed to the next time step's gates, and which is passed to the prediction layer? How does Memory-DD modify or preserve this flow?

- **Concept: Residual Connections**
  - Why needed: The Memory-DD formulas include residual connections adding $D_t$ directly to outputs, which is important for gradient flow during backpropagation
  - Quick check: Why is adding $D_t$ (the current processed input) directly to the output $H_t$ important for gradient flow during backpropagation?

## Architecture Onboarding

- **Component map:** Input Fusion Layer $[H_{t-1}, X_t] \to D_t$ -> Shared Weights $W$ -> Group 1 (Memory Update) -> $C_t$ AND Group 2 (Decision Output) -> $H_t$ -> Output Head (LayerNorm + FC)

- **Critical path:** The calculation of $D_t$ is the "hub." If the Input Fusion Layer fails to create a meaningful representation of the current context, both the memory update (Group 1) and the decision output (Group 2) receive garbage inputs. Unlike an LSTM which has distinct weights for forget/input/output gates, Memory-DD relies entirely on $D_t$ and the shared $W$ to derive all gating signals.

- **Design tradeoffs:** Efficiency vs. Long-term Dependency: The model uses only 50% of LSTM parameters but performance drops on 24-step regression tasks (e.g., Exchange-Rate), suggesting simplified gating may struggle with very long or non-stationary horizons. Simplicity vs. Feature Depth: A single linear layer projects inputs to $D_t$, which might be insufficient for complex datasets compared to multi-layer LSTM projections.

- **Failure signatures:** Sudden Collapse: Removing the Hadamard product causes accuracy to plummet (e.g., to 25% or 8%). If your model predicts random classes, check implementation of the $\odot$ operation. Long-horizon Drift: If regression error explodes as prediction horizon increases (beyond 12 steps), the fixed memory update mechanism may be "forgetting" critical long-term stationary features.

- **First 3 experiments:** 1) Implement the cell and verify parameter count is exactly $(2d_h^2 + d_h d_x + d_h)$. Compare this with a baseline LSTM to confirm the 50% reduction. 2) Run the model on a simple dataset (e.g., ItalyPowerDemand) with the Hadamard product replaced by addition. Confirm that performance collapses to random guessing to validate the core mechanism. 3) Train on a regression dataset (e.g., Electricity) for horizons $P=\{3, 12, 24\}$. Plot the MSE gap between Memory-DD and LSTM as $P$ increases to identify the "break point" where the low-complexity tradeoff becomes significant.

## Open Questions the Paper Calls Out

### Open Question 1
Can the fixed memory update mechanism in Memory-DD be replaced with an adaptive mechanism to improve performance on long-horizon forecasting tasks (e.g., >24 steps)? The current design relies on static Hadamard product gating, which may struggle to retain relevant information over extended time lags compared to adaptive gates in LSTMs or attention mechanisms.

### Open Question 2
How can the Memory-DD architecture be modified to better handle non-stationarity and high-frequency noise in financial time-series data? The dendritic logical operations (Hadamard product) may lack the complexity required to filter stochastic noise or capture the random walk characteristics prevalent in financial markets.

### Open Question 3
Do the theoretical reductions in FLOPs and parameters translate into proportional latency and energy improvements on actual resource-constrained edge hardware? The paper claims "significant application potential" for edge computing but validates computational efficiency solely through theoretical FLOPs counts on an NVIDIA RTX 4060 GPU.

## Limitations

- The element-wise gating hypothesis is only validated on tabular time-series and may not generalize to high-dimensional sequences where hierarchical feature extraction is critical
- Training procedure details are sparse (epochs, LR schedule, normalization), making it difficult to assess whether performance gains are architecture-specific or implementation-dependent
- Regression results degrade at longer horizons (24 steps), suggesting gating simplicity may be insufficient for capturing long-term non-stationarity

## Confidence

- **High confidence**: Parameter reduction (50%) and computational efficiency (27.7% FLOPs reduction) claims are directly measurable from model specification
- **Medium confidence**: Classification accuracy improvements (89.41% vs LSTM 85.16%) are well-supported by 18 dataset experiments, though implementation details remain unclear
- **Low confidence**: Regression performance claims are less robust due to fewer datasets and observed degradation at longer horizons

## Next Checks

1. **Long-horizon stress test**: Systematically evaluate Memory-DD on regression tasks across horizons P=3, 6, 12, 24 to quantify the exact break point where gating simplicity becomes limiting

2. **Feature complexity probe**: Test Memory-DD on high-dimensional time-series (e.g., multivariate sensor data with >10 features) to assess whether single linear projection to D_t is sufficient for complex feature interactions

3. **Mechanism isolation**: Implement controlled ablation studies removing either the Hadamard product, residual connections, or weight sharing individually to confirm which components are essential vs. optional for performance