---
ver: rpa2
title: Amputation-imputation based generation of synthetic tabular data for ratemaking
arxiv_id: '2509.02171'
source_url: https://arxiv.org/abs/2509.02171
tags:
- data
- synthetic
- variables
- mice
- variable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating high-quality synthetic
  actuarial data for ratemaking when access to real data is limited due to privacy
  concerns or cost. The authors propose amputation-imputation methods based on Multiple
  Imputation by Chained Equations (MICE) with Random Forests (RFs) as imputation models.
---

# Amputation-imputation based generation of synthetic tabular data for ratemaking
## Quick Facts
- arXiv ID: 2509.02171
- Source URL: https://arxiv.org/abs/2509.02171
- Authors: Yevhen Havrylenko; Meelis Käärik; Artur Tuttar
- Reference count: 11
- Primary result: MICE with Random Forests shows competitive performance in generating actuarial data for ratemaking while offering superior ease of use compared to deep generative models

## Executive Summary
This paper addresses the challenge of generating high-quality synthetic actuarial data for ratemaking when access to real data is limited due to privacy concerns or cost. The authors propose amputation-imputation methods based on Multiple Imputation by Chained Equations (MICE) with Random Forests (RFs) as imputation models. They compare these MICE-based approaches against other generative models like Variational Autoencoders (VAEs) and Conditional Tabular GANs (CTGANs) using the freMTPL2freq dataset.

The primary results show that MICE-based methods, particularly MICE with RFs, achieve competitive performance in preserving marginal distributions and multivariate relationships among covariates. The MICE approach demonstrates superior ease of use compared to deep generative models and shows better performance in capturing univariate distributions of numeric variables. While no method outperforms training data, MICE and CTGAN show the most balanced performance across evaluation metrics. The study also finds that augmenting original data with synthetic data does not generally improve GLM performance for predicting claim counts, with only one exception observed where a small proportion of synthetic data slightly improved coefficient estimation.

## Method Summary
The paper proposes amputation-imputation methods based on Multiple Imputation by Chained Equations (MICE) with Random Forests as imputation models. The approach works by randomly removing values from the original dataset (amputation) and then using MICE with RFs to impute these missing values, creating synthetic data. This method is compared against other generative models including Variational Autoencoders (VAEs) and Conditional Tabular GANs (CTGANs). The evaluation uses the freMTPL2freq dataset and assesses performance across multiple metrics including marginal distribution preservation, multivariate relationship capture, and GLM coefficient recovery. The study also examines whether augmenting original data with synthetic data can improve actuarial modeling performance.

## Key Results
- MICE with Random Forests achieves competitive performance in preserving marginal distributions and multivariate relationships among covariates
- MICE-based methods demonstrate superior ease of use compared to deep generative models like VAEs and CTGANs
- MICE shows better performance in capturing univariate distributions of numeric variables compared to other methods
- Data augmentation with synthetic data does not generally improve GLM performance for predicting claim counts, with only one exception observed

## Why This Works (Mechanism)
The amputation-imputation approach works by leveraging the well-established MICE framework, which iteratively imputes missing values by modeling each variable conditional on others. When Random Forests are used as the underlying imputation models, they can capture complex non-linear relationships and interactions between variables without requiring extensive hyperparameter tuning. This combination allows the method to preserve both univariate distributions and multivariate dependencies in the data while being more straightforward to implement than deep learning alternatives. The amputation step introduces randomness that helps generate diverse synthetic samples while maintaining the overall data structure.

## Foundational Learning
- Multiple Imputation by Chained Equations (MICE): A sequential imputation technique that models each variable conditional on others; needed to handle missing data and generate synthetic samples while preserving relationships
- Random Forests for imputation: Tree-based ensemble methods that capture non-linear patterns without extensive tuning; required for robust relationship modeling in actuarial variables
- Actuarial data characteristics: High-dimensional, mixed-type variables with specific distributional properties; understanding these is crucial for appropriate synthetic data generation
- Evaluation metrics for synthetic data: Measures of distributional similarity and model performance preservation; needed to assess whether synthetic data maintains utility for ratemaking
- Data augmentation strategies: Methods for combining real and synthetic data; important for determining whether synthetic data can enhance model training

## Architecture Onboarding
**Component Map:** Original Data -> Amputation -> MICE with RFs -> Synthetic Data -> Evaluation Metrics -> Performance Assessment
**Critical Path:** The core workflow involves amputating values from real data, applying MICE with RFs for imputation, and evaluating the synthetic output against multiple criteria including marginal distributions, multivariate relationships, and GLM coefficient recovery.
**Design Tradeoffs:** MICE with RFs trades some potential performance gains from deep learning models for significantly easier implementation and fewer hyperparameters to tune. The amputation-imputation approach prioritizes simplicity and interpretability over potentially more sophisticated but harder-to-implement deep generative models.
**Failure Signatures:** Poor performance typically manifests as distorted univariate distributions, weak capture of multivariate dependencies, or GLM coefficients that deviate significantly from those estimated on real data. Failure may also occur if the amputation step removes too much information or if the imputation models fail to converge.
**First Experiments:** 1) Apply amputation-imputation to a small subset of the freMTPL2freq dataset and visually inspect marginal distributions; 2) Compare GLM coefficients from models trained on real vs. synthetic data for a single predictor; 3) Test different amputation rates to find the optimal balance between diversity and fidelity.

## Open Questions the Paper Calls Out
The paper acknowledges that its comparison of generative models relies on a single dataset (freMTPL2freq), which limits generalizability to other actuarial contexts with different variable distributions and relationships. The performance metrics used focus primarily on distributional similarity and GLM coefficient recovery, potentially missing other important aspects of data utility such as model calibration or out-of-sample prediction accuracy. The study also does not address potential temporal or spatial dependencies that may exist in real actuarial datasets. Additionally, the computational efficiency comparisons between methods are not systematically quantified, making it difficult to assess trade-offs between performance and resource requirements.

## Limitations
- Results based on a single dataset (freMTPL2freq), limiting generalizability to other actuarial contexts
- Performance metrics focus primarily on distributional similarity and GLM coefficient recovery, potentially missing other aspects of data utility
- Study does not address temporal or spatial dependencies that may exist in real actuarial datasets
- Computational efficiency comparisons between methods are not systematically quantified

## Confidence
**High Confidence:** MICE with RFs preserves univariate distributions well; CTGAN shows balanced performance across metrics
**Medium Confidence:** No single method consistently outperforms training data; MICE offers superior ease of use
**Low Confidence:** Data augmentation benefits; generalizability across different actuarial contexts

## Next Checks
1. Test the proposed methods on multiple actuarial datasets with different variable types, distributions, and dependency structures to assess generalizability
2. Evaluate synthetic data utility beyond GLM coefficient recovery, including model calibration, out-of-sample prediction, and performance on non-linear modeling approaches
3. Conduct systematic usability testing with actuarial practitioners of varying technical backgrounds to quantify the claimed ease-of-use advantage of MICE-based methods