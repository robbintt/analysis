---
ver: rpa2
title: 'Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet
  Transform'
arxiv_id: '2512.18791'
source_url: https://arxiv.org/abs/2512.18791
tags:
- watermark
- audio
- diffusion
- smark
- quality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Smark, a universal watermarking framework for
  TTS diffusion models. The key idea is to embed watermarks into the low-frequency
  LL sub-band of Mel spectrograms via Discrete Wavelet Transform (DWT) during the
  reverse diffusion process, leveraging the shared mathematical paradigm across different
  TTS models.
---

# Smark: A Watermark for Text-to-Speech Diffusion Models via Discrete Wavelet Transform

## Quick Facts
- **arXiv ID**: 2512.18791
- **Source URL**: https://arxiv.org/abs/2512.18791
- **Reference count**: 34
- **Primary result**: Universal watermarking framework for TTS diffusion models achieving high audio quality and perfect watermark extraction accuracy under various attacks

## Executive Summary
This paper proposes Smark, a universal watermarking framework for TTS diffusion models that embeds watermarks into the low-frequency LL sub-band of Mel spectrograms using Discrete Wavelet Transform (DWT) during the reverse diffusion process. The method leverages the shared mathematical paradigm across different TTS models and uses a lightweight neural network to fuse watermarks into the LL sub-band, with post-generation extraction capabilities. Extensive experiments on multiple datasets and models demonstrate superior performance in both fidelity and robustness compared to existing methods.

## Method Summary
Smark embeds watermarks into TTS diffusion models by operating on the LL sub-band of Mel spectrograms during the reverse diffusion process. The framework consists of a watermark embedder and extractor, where the embedder uses a lightweight neural network to fuse the watermark into the LL sub-band obtained via DWT. The approach exploits the shared mathematical structure of TTS diffusion models, allowing universal application across different architectures. The watermark is retrieved post-generation using the extractor component, maintaining high audio quality while providing robust copyright protection and source tracing capabilities.

## Key Results
- High audio quality maintained with PESQ ≥ 3.5 and STOI ≥ 0.88
- Perfect watermark extraction accuracy (ACC = 1.0) under various attacks
- Superior performance compared to existing methods in both fidelity and robustness

## Why This Works (Mechanism)
The method exploits the low-frequency nature of watermarks in the LL sub-band, which is less perceptible to human hearing while being robust to common audio transformations. By embedding during the reverse diffusion process, the watermark becomes intrinsically integrated into the generated speech signal rather than being an external addition. The DWT decomposition allows selective manipulation of frequency bands, with the LL sub-band providing optimal balance between imperceptibility and robustness.

## Foundational Learning

**Discrete Wavelet Transform (DWT)**: Mathematical tool for decomposing signals into frequency sub-bands. Why needed: Enables selective manipulation of frequency components for watermark embedding. Quick check: Verify that LL sub-band decomposition preserves essential speech characteristics while allowing watermark insertion.

**Mel Spectrogram Processing**: Time-frequency representation of audio signals on a perceptually motivated scale. Why needed: Standard intermediate representation in TTS models that captures essential acoustic features. Quick check: Confirm that watermark embedding in Mel domain maintains temporal and spectral coherence.

**Diffusion Model Reverse Process**: Iterative denoising procedure that generates audio from random noise. Why needed: Provides natural integration point for watermark embedding during generation. Quick check: Ensure watermark fusion doesn't disrupt the denoising trajectory or final audio quality.

## Architecture Onboarding

**Component Map**: TTS Model -> Mel Spectrogram -> DWT -> Watermark Embedder -> LL Sub-band Fusion -> Inverse DWT -> Watermark Extractor

**Critical Path**: The reverse diffusion process with watermark embedding occurs between the DWT decomposition and inverse DWT reconstruction stages, making this the critical timing path for implementation.

**Design Tradeoffs**: Low-frequency embedding provides better robustness but may slightly reduce imperceptibility compared to high-frequency approaches. The lightweight embedder adds computational overhead but maintains real-time feasibility.

**Failure Signatures**: Poor watermark extraction typically indicates either insufficient watermark strength or excessive audio degradation from attacks. Quality degradation suggests improper LL sub-band manipulation or integration timing issues.

**First Experiments**:
1. Baseline quality assessment: Generate speech with and without watermark embedding to measure PESQ/STOI degradation
2. Attack resilience test: Apply single attack types (clipping, noise, filtering) to verify extraction accuracy
3. Cross-model validation: Test watermark extraction across different TTS architectures to confirm universality

## Open Questions the Paper Calls Out
None identified in the provided content.

## Limitations
- Perfect watermark extraction accuracy (ACC = 1.0) claims may indicate overfitting to specific attack types
- Limited evaluation of real-world adversarial conditions and multi-source audio environments
- Computational overhead during reverse diffusion process not quantified for practical deployment assessment

## Confidence
**High confidence**: Technical approach using DWT for low-frequency embedding is well-established and theoretically sound
**Medium confidence**: Reported robustness results, though perfect accuracy claims warrant skepticism given limited attack diversity
**Low confidence**: Practical deployment viability without additional real-world validation and performance characterization

## Next Checks
1. Test watermark extraction accuracy under sequential attacks (e.g., compression followed by noise addition followed by filtering) to evaluate robustness in realistic multi-stage processing pipelines
2. Conduct subjective listening tests with diverse human raters to verify that objective quality metrics (PESQ/STOI) correspond to perceptual audio quality across different content types
3. Measure the computational overhead and memory requirements of the watermark embedder during the reverse diffusion process to quantify practical deployment costs and identify potential bottlenecks for real-time applications