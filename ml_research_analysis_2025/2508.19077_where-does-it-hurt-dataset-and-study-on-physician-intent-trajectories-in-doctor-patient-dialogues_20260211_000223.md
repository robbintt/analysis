---
ver: rpa2
title: '"Where does it hurt?" -- Dataset and Study on Physician Intent Trajectories
  in Doctor Patient Dialogues'
arxiv_id: '2508.19077'
source_url: https://arxiv.org/abs/2508.19077
tags:
- intent
- medical
- dialogue
- dialogues
- phase
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the first study of physician intent trajectories
  in doctor-patient dialogues, annotating the Aci-bench dataset with a fine-grained
  SOAP-based taxonomy. The authors develop a taxonomy of 20 intent classes across
  five categories, annotate over 5,000 doctor-patient turns using medical experts
  recruited via Prolific, and create a valuable resource for studying clinical reasoning
  patterns.
---

# "Where does it hurt?" -- Dataset and Study on Physician Intent Trajectories in Doctor Patient Dialogues

## Quick Facts
- arXiv ID: 2508.19077
- Source URL: https://arxiv.org/abs/2508.19077
- Reference count: 40
- Primary result: Introduces SOAP-based taxonomy of 20 physician intent classes, achieving AUROC 0.93 and AP 0.69 on intent classification

## Executive Summary
This paper presents the first study of physician intent trajectories in doctor-patient dialogues, introducing a fine-grained taxonomy based on the SOAP framework and annotating the Aci-bench dataset with over 5,000 turns. The authors develop a 20-class intent taxonomy spanning five SOAP categories, annotate data using medical experts recruited via Prolific, and create a resource for studying clinical reasoning patterns. Experiments demonstrate that encoder-based models (GatorTronS) significantly outperform decoder-only models in both intent classification and next intent prediction tasks. The study also shows that intent-based filtering improves downstream medical dialogue summarization, though models struggle with non-linear dialogue transitions and class imbalance.

## Method Summary
The study develops a 20-class taxonomy of physician intents aligned with the SOAP framework (Subjective, Objective, Assessment, Plan, Others) and annotates 5,541 doctor-patient turns from the Aci-bench dataset using medical experts recruited via Prolific. The intent classification task uses multi-label fine-tuning of BiomedBERT and GatorTronS encoders, while next intent prediction models predict the physician's next intent from up to 5 preceding turns. The dataset is split into stratified train (3,886), validation (646), and test (760) sets. Decoder-only models (Llama-3.1-8B, Qwen2.5-7B, Phi-4-14B) are evaluated zero-shot and few-shot with guided decoding. Code and data are available at https://github.com/DATEXIS/medical-intent-classification.

## Key Results
- Encoder-based models (GatorTronS) achieve AUROC 0.93 and AP 0.69 on intent classification, significantly outperforming decoder-only models (best AP 0.33)
- Intent filtering improves downstream medical dialogue summarization performance, particularly for section-specific tasks
- Physicians spend most turns on subjective symptom-taking but speak most during treatment-planning
- Models show "linear bias" in next intent prediction, defaulting to standard S→O→A→P trajectories and failing to identify non-linear transitions
- Class imbalance challenges persist, with Assessment intents being rare and semantic overlap between related classes

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Aligning dialogue annotations with the SOAP framework creates a bridge between conversational flow and structured clinical reasoning
- **Mechanism:** The taxonomy maps unstructured physician utterances to 20 distinct intent classes (e.g., "Acute Symptoms" vs. "Therapeutic History"). By enforcing this structure, the model learns to identify the functional role of each sentence in the diagnostic process
- **Core assumption:** Physician intent in dialogues consistently maps to the theoretical phases of the SOAP standard used in clinical notes
- **Evidence anchors:**
  - [abstract] Mentions the development of a "fine-grained taxonomy of physician intents based on the SOAP framework"
  - [section 3.1] Describes taxonomy design to align with SOAP, breaking dialogues into phases crucial for differential diagnosis
  - [corpus] Related work (like MEDIQA-OE) similarly relies on structured extraction for clinical utility

### Mechanism 2
- **Claim:** Intent-based filtering acts as a noise-reduction layer that improves downstream summarization by isolating relevant clinical content
- **Mechanism:** A classifier first identifies and removes low-information turns (e.g., "Chitchat") or non-relevant SOAP sections. The summarization model then processes a "dense" input containing only information pertinent to the target note section
- **Core assumption:** The intent classifier has high precision; misclassification leads to information loss which degrades summary quality
- **Evidence anchors:**
  - [abstract] Reports that "intent filtering significantly improves downstream medical dialogue summarization performance"
  - [section 6] Shows filtering improved subjective summarization performance (GPT-4o avg score 0.50 -> 0.55) by removing noise
  - [corpus] Weak direct corpus evidence for this specific filtering mechanism

### Mechanism 3
- **Claim:** Sequence modeling of intents relies on the linearity of clinical interviews, causing failure in non-linear dialogues
- **Mechanism:** Models predict the next intent based on the trajectory of previous turns. They learn the high-probability path S → O → A → P. When dialogues follow standard patterns (linear), the model predicts transitions accurately. When conversations loop back (non-linear), the model defaults to the statistically dominant linear path
- **Core assumption:** Most training dialogues follow a standard differential diagnosis flow, reinforcing linear transition weights
- **Evidence anchors:**
  - [abstract] Notes models "often fail to identify transitions between SOAP categories"
  - [section 5.3] Explicitly shows the model "fails to predict anomalies for the non-linear dialogue" and "defaults to predicting a linear trajectory"

## Foundational Learning

- **Concept:** **SOAP Framework (Subjective, Objective, Assessment, Plan)**
  - **Why needed here:** The entire taxonomy and dataset annotation are built upon this standard clinical documentation structure
  - **Quick check question:** If a doctor asks, "How long have you had this pain?", is this Subjective or Objective intent? (Answer: Subjective)

- **Concept:** **Encoder vs. Decoder Architectures**
  - **Why needed here:** The paper benchmarks BiomedBERT (Encoder) against Llama/Qwen (Decoders). Understanding that Encoders typically excel at discrimination/classification tasks while Decoders excel at generation is key to interpreting results
  - **Quick check question:** Which architecture would you choose for the specific task of labeling a sentence with one of 20 intents? (Answer: Encoder)

- **Concept:** **Class Imbalance & Macro-Averaging**
  - **Why needed here:** The dataset is heavily skewed toward "Subjective" intents. The paper uses macro-AUROC and macro-AP to ensure the model isn't just optimizing for the majority class
  - **Quick check question:** Why might accuracy be a misleading metric if 80% of the dialogue turns are "Symptom Taking"? (Answer: A model guessing only "Symptom Taking" would achieve 80% accuracy but fail all other classes)

## Architecture Onboarding

- **Component map:** Input Layer -> Intent Classifier (GatorTronS) -> Trajectory Analyzer -> Filtering Layer -> Summarization Module
- **Critical path:** The Intent Classifier is the linchpin. High precision on the Intent Classifier is prerequisite for the Filtering Layer to be effective
- **Design tradeoffs:**
  - Encoder vs. Decoder for Intent: Encoders (GatorTronS) outperform Decoders (Llama-3) significantly (AP 0.69 vs 0.33) in classification. However, Decoders are more flexible for few-shot summarization
  - Taxonomy Granularity: 20 classes provide excellent insight but suffer from data scarcity (Assessment intents are rare). Coarser categories would be easier to model but lose nuance needed for specific section filtering
- **Failure signatures:**
  - "Linear Bias": The model predicts a transition to "Plan" even when the doctor loops back to "Subjective" questioning
  - "Semantic Confusion": Mislabeling "Lab Examination" as "Radiology" or "Physical" due to shared semantic features
  - "Verbosity Hallucination": Without filtering, summarizers include "Chitchat" in clinical notes; with aggressive filtering, they might miss edge-case medical details
- **First 3 experiments:**
  1. Reproduce the Classification Baseline: Fine-tune BiomedBERT on the provided dataset to validate the AUROC > 0.90 claim
  2. Ablation on Filtering Intensity: Run summarization tasks with "Chitchat only" removal vs. "Strict SOAP-section" filtering
  3. Transition Error Analysis: Train the Next-Intent Prediction model and specifically isolate "non-linear" dialogue transitions

## Open Questions the Paper Calls Out
- **Open Question 1:** What architectural or training modifications would enable models to accurately predict SOAP category transitions in physician intent trajectories?
  - Basis: Authors state models learn trajectories but fail to identify category transitions
  - Why unresolved: Error analysis reveals models predict transitions either one turn too late or prematurely
  - Evidence needed: A model architecture that explicitly models phase boundaries and achieves higher transition prediction accuracy

- **Open Question 2:** Would fine-tuning decoder-only models on the intent classification dataset close the performance gap with encoder-based models?
  - Basis: The Limitations section states decoder models weren't fine-tuned due to computational constraints
  - Why unresolved: Encoder models achieved 0.69 AP while the best decoder-only model achieved only 0.33 AP without equivalent fine-tuning
  - Evidence needed: Fine-tuned decoder-only model results showing comparable or superior performance to GatorTronS

- **Open Question 3:** How do physician intent trajectories differ between role-played dialogues and authentic clinical encounters?
  - Basis: The Limitations section acknowledges Aci-bench dialogues are role-played and may not properly reflect real-world scenarios
  - Why unresolved: The taxonomy and trajectory patterns were derived exclusively from simulated interactions
  - Evidence needed: Annotation and analysis of real-world doctor-patient dialogue data

## Limitations
- The dataset consists of role-played dialogues rather than authentic clinical encounters, potentially limiting real-world applicability
- Class imbalance significantly affects model performance, with Assessment intents being particularly underrepresented
- The taxonomy shows semantic overlap between related classes (e.g., Lab Examination vs Physical Examination confusion)
- Next intent prediction models exhibit "linear bias," defaulting to standard S→O→A→P trajectories and failing on non-linear dialogues

## Confidence
- **High Confidence:** Encoder-based intent classification performance (AUROC 0.93, AP 0.69) and the fundamental claim that SOAP-based structure improves medical dialogue analysis
- **Medium Confidence:** The downstream summarization improvements from intent filtering, as the evaluation uses GPT-4o rather than clinical benchmarks
- **Low Confidence:** The generality of the taxonomy to other medical specialties and the model's ability to handle truly non-linear clinical reasoning patterns

## Next Checks
1. Test the taxonomy on dialogues from different specialties (e.g., cardiology vs primary care) to assess domain generalizability
2. Evaluate the intent classifier on a held-out set of complex, non-linear dialogues (follow-ups, multi-condition cases) to measure the "linear bias" failure mode
3. Conduct expert review of filtered summaries to quantify the precision-recall tradeoff of the intent filtering approach, specifically measuring information loss in the Assessment and Plan sections