---
ver: rpa2
title: Data-centric Prompt Tuning for Dynamic Graphs
arxiv_id: '2601.11954'
source_url: https://arxiv.org/abs/2601.11954
tags:
- node
- dynamic
- prompt
- graph
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'DDGPrompt is a data-centric prompting framework for dynamic graphs
  that addresses performance degradation when adapting pre-trained models to downstream
  tasks, particularly under few-shot settings. The method defines a unified node expression
  feature matrix that aggregates temporal and structural information, then refines
  it using three complementary prompts: temporal bias, edge weight, and feature mask.'
---

# Data-centric Prompt Tuning for Dynamic Graphs

## Quick Facts
- arXiv ID: 2601.11954
- Source URL: https://arxiv.org/abs/2601.11954
- Reference count: 40
- Primary result: DDGPrompt achieves up to 18.37% improvement on LastFM link prediction and 8.23% on node classification tasks in few-shot settings

## Executive Summary
DDGPrompt introduces a data-centric prompting framework for dynamic graphs that addresses performance degradation when adapting pre-trained models to downstream tasks. The method defines a unified node expression feature matrix that aggregates temporal and structural information, then refines it using three complementary prompts: temporal bias, edge weight, and feature mask. Unlike existing approaches that focus solely on node or temporal features, DDGPrompt comprehensively adjusts the entire feature matrix while maintaining compatibility with various dynamic graph architectures. Extensive experiments on four public datasets demonstrate significant performance improvements over traditional methods and prompting approaches, with particular robustness in sparse interaction scenarios and cold-start conditions.

## Method Summary
DDGPrompt operates through a two-stage process: first, self-supervised pretraining via contrastive link prediction to learn transferable representations; second, fine-tuning of three prompt matrices (temporal bias, edge weight, feature mask) while keeping the backbone frozen. The core innovation is a unified node expression feature matrix that standardizes heterogeneous temporal and structural inputs across different dynamic graph architectures. This matrix aggregates projected neighbor features, edge features, and time features, enabling task-specific adjustments through prompt learning. The framework shows compatibility with multiple backbone architectures including TGN, GraphMixer, TCL, and DyGFormer, making it model-agnostic.

## Key Results
- Up to 18.37% improvement on LastFM link prediction task
- 8.23% improvement on node classification tasks
- Significant performance gains in few-shot settings (K=70 shots)
- Robust performance in sparse interaction scenarios and cold-start conditions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A unified node expression feature matrix enables model-agnostic prompting by standardizing heterogeneous temporal and structural inputs.
- **Mechanism:** The matrix Z_t^u concatenates projected neighbor features, edge features, and time features into a single |S_t^u| × 3d tensor per node. This abstraction decouples prompt design from specific backbone architectures, allowing the same prompt infrastructure to operate across TGN, GraphMixer, TCL, and DyGFormer without modification.
- **Core assumption:** First-order neighborhood interactions capture sufficient signal for downstream task adaptation; higher-order structure is redundant.
- **Evidence anchors:**
  - [abstract] "We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models."
  - [Section 4.2] "Previous works have shown that it is sufficient to capture the general characteristics of a node through its first-order interactions in its recent history."
- **Break condition:** If downstream tasks require multi-hop reasoning (e.g., community-level classification), the first-order assumption fails.

### Mechanism 2
- **Claim:** Temporal bias prompts enable task-adaptive time recalibration by learning per-neighbor time offsets that reflect behavioral relevance.
- **Mechanism:** A linear layer generates bias δt from time features, which is added to original time intervals (Δt + δt) and passed through a frozen pre-trained time encoder. This effectively shifts each neighbor's interaction timestamp closer to or further from the current time based on learned task relevance, without retraining the backbone.
- **Core assumption:** The pre-trained time encoder's functional form can accommodate shifted inputs; task-relevant temporal patterns can be captured through monotonic time adjustments.
- **Evidence anchors:**
  - [abstract] "temporal bias prompt... dynamically adjusts the temporal features of each neighbor"
  - [Section 4.4.1] "adjusting a neighbor's interaction timestamp to be closer to the current time may indicate a stronger preference or relevance to that neighbor."
- **Break condition:** If pre-training time encoder was trained with narrow time distributions, shifted inputs may fall outside its effective range.

### Mechanism 3
- **Claim:** Edge weight prompts capture spatial structure relevance by assigning learnable importance scores to neighbors, addressing uniform aggregation limitations.
- **Mechanism:** Edge weights w_t^uv are computed via linear projection of concatenated neighbor and edge features, then element-wise multiplied with the full feature matrix. This enables task-specific emphasis on certain neighbors (e.g., frequent interactors for link prediction, recent interactors for classification).
- **Core assumption:** Task-relevant neighbor importance can be determined from local neighbor and edge features without global graph context.
- **Evidence anchors:**
  - [Section 4.4.2] "Previous traditional and prompt methods overlook the varying importance of different neighbors when aggregating neighborhood information."
- **Break condition:** If optimal neighbor weighting depends on graph-level properties (e.g., node degree distribution, community structure), local features alone will be insufficient.

## Foundational Learning

- **Continuous-Time Dynamic Graphs (CTDG)**
  - **Why needed here:** The entire framework operates on CTDG representations where interactions are timestamped triples (u, v, t). Understanding the difference between discrete-time snapshots and continuous event streams is essential for interpreting the time encoding and neighborhood extraction logic.
  - **Quick check question:** Given a sequence of edges (A,B,1.5), (A,C,2.3), (A,B,2.7), can you extract node A's neighborhood at time t=3.0 and explain why time encoding uses Δt = t - t'?

- **Contrastive Pre-training for Graphs**
  - **Why needed here:** The pre-training stage uses link prediction as a self-supervised objective via contrastive loss. Understanding why maximizing similarity for positive pairs (linked nodes) and minimizing for negative pairs creates transferable representations is critical for diagnosing adaptation failures.
  - **Quick check question:** If pre-training only optimizes link prediction, why might node classification performance degrade when using frozen embeddings directly?

- **Prompt Tuning Paradigm**
  - **Why needed here:** The core innovation is applying NLP-style prompt tuning to graph inputs. Distinguishing between "pre-prompt" (input modification) and "post-prompt" (embedding modification) clarifies why DDGPrompt's data-centric approach differs from prior work like DyGPrompt.
  - **Quick check question:** Why does modifying input features (data-centric) provide better model-agnostic compatibility than modifying output embeddings (model-centric)?

## Architecture Onboarding

- **Component map:**
  Raw features → Projection layers → Node Expression Matrix Z_t^u → Temporal Bias Prompt + Edge Weight Prompt + Feature Mask Prompt → Modified Z'_t^u → Frozen Pre-trained Backbone → Task-specific MLP Classifier

- **Critical path:**
  1. Extract first-order neighbor sequences for each target node (requires efficient temporal windowing)
  2. Construct node expression matrix with correct dimensionality (|S_t^u| × 3d)
  3. Initialize and apply three prompt matrices with appropriate scaling (α, β, γ hyperparameters)
  4. Forward through frozen backbone, train only prompt parameters and classifier

- **Design tradeoffs:**
  - **Prompt weight balancing:** α, β, γ are dataset-specific. Paper shows temporal bias (α) helps more on Wikipedia (large time gaps) but hurts on MOOC. Tuning required per dataset.
  - **Projection dimension d:** Larger d increases expressiveness but also prompt parameter count. Paper uses default dimensions from backbone models.
  - **Time encoder freezing:** Reusing pre-trained time encoder ensures compatibility but limits temporal adaptation. Unfreezing would break the efficiency claim.

- **Failure signatures:**
  - AP/AUC below backbone baseline: Prompt weights may be over-powering original features; reduce α, β, γ
  - Large gap between link prediction and node classification: Task-specific prompts are not differentiating; increase edge weight prompt influence
  - Performance collapse on LastFM (no features): Feature mask prompt has nothing to enhance; this prompt may add noise in zero-feature settings

- **First 3 experiments:**
  1. **Sanity check on single backbone:** Run DDGPrompt vs. frozen DyGFormer on Wikipedia link prediction with K=70 shots. Expect 5-10% AP improvement per Table 2. If degradation occurs, check projection dimensions match backbone.
  2. **Prompt ablation:** Remove each prompt individually (w/o t.b., w/o e.w., w/o f.m.) to identify which component drives gains for your target dataset. Replicate Figure 3 pattern.
  3. **Sparse interaction stress test:** Filter nodes with <100 interactions, verify robustness gains persist. Per Table 3, DDGPrompt should maintain 85%+ AP on Wikipedia vs. 75% for baselines.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can higher-order neighborhood information beyond first-order neighbors improve prompt tuning effectiveness for dynamic graphs?
- **Basis in paper:** [explicit] The authors state "it is sufficient to capture the general characteristics of a node through its first-order interactions in its recent history," citing prior work, but do not validate whether capturing multi-hop neighborhoods could further enhance performance.
- **Why unresolved:** The node expression feature matrix explicitly encodes only first-order neighborhood information, leaving the potential benefits of higher-order structural patterns unexplored.
- **What evidence would resolve it:** Ablation experiments comparing first-order versus k-hop neighborhood encodings across the same datasets and tasks.

### Open Question 2
- **Question:** Would alternative pretraining objectives (e.g., masked feature reconstruction, temporal contrastive learning) yield better transferability than link-prediction-based contrastive learning?
- **Basis in paper:** [inferred] The pretraining phase relies solely on contrastive loss for link prediction, but the paper notes that "supervised pretraining" may encode task-biased information. Self-supervised signals beyond link prediction are suggested but not implemented.
- **Why unresolved:** The current framework does not compare multiple pretraining strategies, leaving open whether the choice of pretraining objective affects downstream task adaptation quality.
- **What evidence would resolve it:** Systematic comparison of DDGPrompt with identical prompt mechanisms but different pretraining objectives on the same downstream tasks.

### Open Question 3
- **Question:** Can the prompt weighting hyperparameters (α, β, γ) be learned automatically rather than manually tuned?
- **Basis in paper:** [explicit] The three prompt matrices are combined with fixed weight hyperparameters α, β, γ, and ablation studies show their effects vary significantly across datasets (e.g., temporal bias helps Wikipedia but hurts MOOC).
- **Why unresolved:** Manual hyperparameter tuning may not scale well to new domains, and dataset-specific optimal weights suggest a need for adaptive mechanisms.
- **What evidence would resolve it:** Comparison of manually tuned versus learned (e.g., via attention or gradient-based optimization) prompt weights across multiple datasets.

## Limitations

- Model-agnostic compatibility claims are limited to five specific architectures, leaving generalization to other dynamic graph models untested.
- Temporal bias prompt mechanism's effectiveness depends on the pre-trained time encoder's ability to handle shifted inputs, which may not hold for all time encoding schemes.
- Edge weight prompt's reliance on local neighbor features may fail when optimal neighbor importance depends on global graph properties like community structure.

## Confidence

- **High confidence:** Performance improvements on tested datasets (AP/AUC gains of 5-18% across Wikipedia, Reddit, MOOC, LastFM). Experimental methodology is rigorous with 5 random seeds and ablation studies.
- **Medium confidence:** Model-agnostic compatibility claims. While theoretical formulation supports multiple architectures, validation is limited to five models from one framework (DyGLib).
- **Low confidence:** Temporal bias prompt mechanism's ability to capture complex temporal patterns. Limited analysis of learned δt values and their relationship to task-relevant time intervals.

## Next Checks

1. **Temporal bias analysis:** Extract and visualize learned δt values across datasets to verify they align with expected temporal patterns (e.g., recent interactions weighted higher for classification tasks).

2. **Graph position dependency test:** Create synthetic dynamic graphs with known community structure and evaluate whether edge weight prompts maintain performance when optimal neighbor weights depend on global graph position rather than local features.

3. **Architecture stress test:** Implement DDGPrompt with a fundamentally different dynamic graph architecture (e.g., attention-based memory with non-local temporal dependencies) to validate true model-agnostic compatibility beyond the five tested models.