---
ver: rpa2
title: Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework
arxiv_id: '2510.03282'
source_url: https://arxiv.org/abs/2510.03282
tags:
- arxiv
- circuit
- attribution
- circuits
- pruning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the computational trade-off between speed
  and faithfulness in transformer circuit discovery. The authors propose a hybrid
  framework (HAP) that combines Edge Attribution Patching (EAP) for rapid global edge
  importance scoring with Edge Pruning (EP) for faithful, fine-grained circuit extraction.
---

# Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework
## Quick Facts
- arXiv ID: 2510.03282
- Source URL: https://arxiv.org/abs/2510.03282
- Authors: Hao Gu; Vibhas Nair; Amrithaa Ashok Kumar; Jayvart Sharma; Ryan Lagasse
- Reference count: 12
- Key outcome: Proposed HAP framework achieves 46% speedup over pure EP while preserving circuit fidelity on GPT-2 Small IOI task

## Executive Summary
This paper addresses the fundamental trade-off between speed and faithfulness in transformer circuit discovery. The authors propose HAP (Hybrid Attribution and Pruning), a framework that strategically combines Edge Attribution Patching (EAP) for rapid global importance scoring with Edge Pruning (EP) for faithful, fine-grained circuit extraction. By using EAP to identify high-potential edges that initialize EP, HAP accelerates convergence while maintaining the faithfulness that pure pruning provides. The method demonstrates that the speed-faithfulness trade-off can be mitigated through intelligent algorithm sequencing, offering a scalable solution for mechanistic interpretability research.

## Method Summary
The HAP framework operates in two phases: first, EAP rapidly scores edge importance across the transformer using attribution patching, identifying high-potential edges for circuit discovery. Second, EP performs faithful circuit extraction using these EAP-identified edges as initialization, significantly reducing the number of iterations needed to converge on the circuit. This hybrid approach leverages the speed of attribution methods while preserving the faithfulness guarantees of pruning-based techniques. The framework is evaluated on the IOI (Indirect Object Identification) task with GPT-2 Small, where it successfully recovers complete circuits including S-inhibition heads that EAP alone misses at high sparsity levels.

## Key Results
- HAP achieves 46% speedup compared to pure EP while maintaining circuit fidelity and KL divergence metrics
- Successfully recovers complete IOI circuits including S-inhibition heads that EAP misses at high sparsity
- Demonstrates that speed-faithfulness trade-off can be mitigated through strategic algorithm sequencing

## Why This Works (Mechanism)
The HAP framework works by strategically sequencing two complementary approaches. EAP provides rapid global importance scores by measuring how much each edge contributes to overall model behavior, but sacrifices fine-grained faithfulness. EP then takes these high-potential edges as initialization, dramatically reducing the search space and iteration count needed to converge on faithful circuits. This hybrid approach exploits the complementary strengths: EAP's speed for global scanning and EP's precision for local refinement, while avoiding their respective weaknesses.

## Foundational Learning
- **Edge Attribution Patching**: A method for rapidly scoring edge importance by measuring attribution changes when edges are patched. Needed for global importance scoring; check by verifying attribution scores correlate with known important edges.
- **Edge Pruning**: A faithful circuit extraction method that iteratively removes edges while monitoring performance degradation. Needed for fine-grained circuit discovery; check by ensuring pruned circuits maintain task performance.
- **KL Divergence for Circuit Fidelity**: Measures distributional similarity between original and pruned models. Needed to quantify faithfulness; check by comparing KL divergence across different sparsity levels.
- **Hybrid Algorithm Design**: Strategic sequencing of complementary algorithms. Needed to balance speed and faithfulness; check by comparing convergence rates with and without hybrid initialization.
- **Transformer Circuit Discovery**: The broader goal of identifying mechanistic pathways in transformer models. Needed context for understanding the problem; check by mapping how individual components contribute to overall behavior.
- **IOI Task Mechanics**: Understanding how transformers solve indirect object identification. Needed baseline for evaluation; check by verifying recovered circuits match known IOI mechanisms.

## Architecture Onboarding
**Component Map**: Input Model -> EAP (Global Scoring) -> EP (Circuit Extraction) -> Output Circuit
**Critical Path**: Model Input → Transformer Layers → Attention Heads → MLP Layers → Output
**Design Tradeoffs**: Speed (EAP) vs Faithfulness (EP) balanced through hybrid initialization; global scanning vs local refinement; rapid iteration vs precise discovery
**Failure Signatures**: EAP misses important edges at high sparsity; EP gets stuck in local minima without good initialization; KL divergence increases without corresponding circuit quality improvement
**First Experiments**:
1. Compare KL divergence and circuit recovery rate between HAP and pure EP at various sparsity levels
2. Ablation study: test EP starting from random vs EAP-initialized edges
3. Measure convergence iteration count reduction when using EAP initialization

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to GPT-2 Small on IOI task, making generalization claims uncertain
- KL divergence metric doesn't fully capture whether discovered circuits reflect true mechanistic understanding
- Potential initialization bias toward certain circuit structures not addressed
- Scalability to larger models remains to be demonstrated

## Confidence
- **High confidence**: Basic algorithmic approach and speedup measurements on GPT-2 Small IOI task
- **Medium confidence**: Claims about maintaining faithfulness across sparsity levels
- **Low confidence**: Generalizability to other tasks, model architectures, and scaling claims

## Next Checks
1. Test HAP on diverse tasks beyond IOI (e.g., sentiment analysis, mathematical reasoning) and larger models (GPT-2 Medium/Large, LLaMA variants) to assess scalability
2. Compare discovered circuits against ground truth where available (synthetic tasks) or through ablation studies that test causal importance of identified components
3. Conduct ablation studies on the hybrid approach itself - test whether starting EP from random initialization versus EAP-identified edges yields different final circuits, and whether the speed gains persist across different sparsity thresholds