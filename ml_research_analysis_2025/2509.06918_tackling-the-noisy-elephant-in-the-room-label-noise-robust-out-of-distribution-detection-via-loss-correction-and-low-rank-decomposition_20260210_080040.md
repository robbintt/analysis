---
ver: rpa2
title: 'Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution
  Detection via Loss Correction and Low-rank Decomposition'
arxiv_id: '2509.06918'
source_url: https://arxiv.org/abs/2509.06918
tags:
- detection
- label
- fpr95
- noise
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of robust out-of-distribution (OOD)
  detection under noisy training labels, which is a critical challenge for real-world
  deployment of AI systems. The authors propose NOODLE, a novel framework that integrates
  loss correction techniques with low-rank and sparse decomposition methods to address
  this challenge.
---

# Tackling the Noisy Elephant in the Room: Label Noise-robust Out-of-Distribution Detection via Loss Correction and Low-rank Decomposition

## Quick Facts
- arXiv ID: 2509.06918
- Source URL: https://arxiv.org/abs/2509.06918
- Authors: Tarhib Al Azad; Shahana Ibrahim
- Reference count: 40
- Achieves significant improvements in OOD detection under noisy labels, with up to 12.5% FPR@95 reduction on CIFAR-10 with 50% noise

## Executive Summary
This paper addresses the critical challenge of robust out-of-distribution (OOD) detection under noisy training labels, a fundamental problem for real-world AI deployment. The authors propose NOODLE, a novel framework that combines loss correction techniques with low-rank and sparse matrix decomposition to disentangle in-distribution (ID) and OOD components in feature space. By leveraging a power iteration-based low-rank approximation and enforcing column sparsity on the OOD component, NOODLE creates a noise-robust model that significantly outperforms existing OOD detection methods, particularly under severe label noise conditions. Extensive experiments on synthetic and real-world datasets demonstrate consistent improvements across various noise settings and dataset complexities.

## Method Summary
NOODLE tackles the problem of OOD detection under noisy labels by integrating loss correction with low-rank and sparse decomposition techniques. The framework uses a power iteration-based low-rank approximation to decompose the latent feature matrix into ID and OOD components, while enforcing column sparsity on the OOD component. This approach is combined with various loss correction strategies including Co-teaching, Forward Correction, and Symmetric Cross Entropy to train a noise-robust model. The method assumes that ID features exhibit low-rank structure while OOD features are sparse, allowing for effective separation and improved detection performance even when training labels are corrupted.

## Key Results
- On CIFAR-10 with 50% synthetic label noise, NOODLE achieves an average FPR@95 of 27.34%, up to 12.5% improvement over best baseline
- Consistent improvements across real-world noisy datasets including CIFAR-10N, Animal-10N, and CIFAR-100N
- SCE-based NOODLE variants show superior performance on fine-grained classification tasks
- NOODLE demonstrates robustness across different noise ratios and dataset complexities

## Why This Works (Mechanism)
The effectiveness of NOODLE stems from its ability to exploit the inherent structure of ID and OOD features under noisy conditions. The low-rank decomposition captures the clusterable nature of ID features, while the sparse component isolates OOD samples. This separation is particularly effective under label noise because noisy labels tend to create outliers that manifest as sparse components in the feature space. By combining this decomposition with loss correction techniques, the framework can train on noisy data while maintaining the ability to distinguish OOD samples effectively.

## Foundational Learning
- **Low-rank matrix decomposition**: Needed to separate clusterable ID features from scattered OOD features; quick check: verify singular value spectrum shows clear gap
- **Column sparsity enforcement**: Required to isolate OOD components in feature space; quick check: examine sparsity patterns in decomposed matrices
- **Loss correction techniques**: Essential for handling noisy labels during training; quick check: compare performance with and without correction
- **Power iteration method**: Used for efficient low-rank approximation; quick check: verify convergence of top-K singular vectors
- **Symmetric Cross Entropy**: Alternative loss that handles noisy labels better than standard CE; quick check: compare SCE vs CE performance
- **Transition matrix estimation**: Needed for label noise correction; quick check: validate estimated transition matrix accuracy

## Architecture Onboarding
**Component Map:** Data → Backbone (DenseNet-101) → Feature Extraction → Low-rank Decomposition → ID/OOD Separation → Loss Correction → Model Training → OOD Detection

**Critical Path:** The core pipeline involves extracting features from the backbone, applying low-rank decomposition to separate ID and OOD components, and training with corrected loss functions. The power iteration step for rank estimation is critical for performance.

**Design Tradeoffs:** The method balances computational overhead (from decomposition) against robustness gains. Rank selection (K) directly impacts both performance and efficiency. Using CNNs vs Transformers affects the low-rank assumption validity.

**Failure Signatures:** Poor rank selection leads to inadequate separation. Symmetric noise assumptions may break down with structured noise. High computational cost for large K values. Transition matrix estimation becomes difficult with many classes.

**First Experiments:** 1) Test rank selection sensitivity on CIFAR-10 with varying noise levels, 2) Compare CNN vs Transformer backbones for low-rank assumption validity, 3) Benchmark against SCE-only baseline to isolate decomposition benefits

## Open Questions the Paper Calls Out
### Open Question 1
- Question: How does NOODLE perform under asymmetric or instance-dependent label noise, compared to the symmetric and real-world noise settings tested?
- Basis in paper: The experimental section explicitly utilizes "class-independent symmetric noise" for synthetic evaluation, but is not benchmarked against structured or asymmetric synthetic noise.
- Why unresolved: Structured noise creates specific decision boundary distortions that might respond differently to low-rank decomposition than the random scatter of symmetric noise.
- What evidence would resolve it: Evaluation of NOODLE on datasets specifically synthesized with asymmetric transition matrices or instance-dependent noise models.

### Open Question 2
- Question: Does the assumption of low-rank ID features hold effectively for Transformer-based architectures (e.g., ViTs), and does NOODLE generalize to them?
- Basis in paper: Implementation details explicitly state: "We use a CNN-based architecture, DenseNet-101... as the backbone model for all datasets."
- Why unresolved: Vision Transformers learn different embedding geometries and attention patterns compared to CNNs. It is unclear if the "clusterability" and low-rank assumptions hold true for Transformer layers.
- What evidence would resolve it: Experiments replacing the DenseNet backbone with a standard Vision Transformer (ViT) on the same noisy OOD benchmarks.

### Open Question 3
- Question: How does NOODLE scale to datasets with extremely large label spaces (e.g., >1000 classes) regarding computational efficiency and rank selection?
- Basis in paper: The paper mentions selecting rank $K$ "according to the number of classes" and notes CIFAR-100N (100 classes) is "more challenging," suggesting sensitivity to label space size.
- Why unresolved: The power iteration method estimates top-$K$ singular vectors. As $K$ grows to thousands, computational cost and rank enforcement may become prohibitive.
- What evidence would resolve it: Benchmarking on a large-scale dataset like ImageNet-1k with noisy labels, analyzing computational overhead vs detection performance.

### Open Question 4
- Question: Can the transition matrix estimation in the NOODLE(CM) variant be improved for fine-grained classification where class confusion is high?
- Basis in paper: The authors observe in the Ablation Study regarding CIFAR-100N that "estimating transition matrices for CM-based methods becomes increasingly difficult as the number of classes grows," leading to SCE outperforming CM in that setting.
- Why unresolved: This suggests a specific failure mode of the loss correction component within NOODLE for fine-grained tasks, indicating the current estimation method struggles with increased complexity.
- What evidence would resolve it: Incorporating an anchor-point-free or clustering-based transition matrix estimator into the NOODLE framework to compare against current CE-based estimation on fine-grained noisy datasets.

## Limitations
- Effectiveness relies on assumptions about low-rank ID features and sparse OOD features that may not hold universally across all dataset types
- Computational overhead from low-rank decomposition and power iteration steps is not thoroughly evaluated for large-scale datasets
- Performance on extremely high noise levels (>60%) remains unexplored, which could be critical for certain real-world scenarios

## Confidence
- **High confidence**: Performance improvements on synthetic CIFAR-10 with 50% noise and real-world noisy datasets (CIFAR-10N, Animal-10N, CIFAR-100N)
- **Medium confidence**: Generalization to other dataset architectures beyond those tested (CIFAR-10, CIFAR-100, SVHN)
- **Low confidence**: Scalability to extremely high noise ratios and computational efficiency claims

## Next Checks
1. Test NOODLE's performance on extremely high noise levels (>60%) to establish the upper bounds of its robustness
2. Conduct comprehensive computational efficiency analysis comparing NOODLE's runtime and memory usage against baselines on large-scale datasets
3. Validate the method's effectiveness on diverse domain-specific datasets (e.g., medical imaging, autonomous driving) with different data distributions and noise characteristics