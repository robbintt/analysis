---
ver: rpa2
title: 'GS_DravidianLangTech@2025: Women Targeted Abusive Texts Detection on Social
  Media'
arxiv_id: '2504.02863'
source_url: https://arxiv.org/abs/2504.02863
tags:
- abusive
- language
- tamil
- languages
- social
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the detection of abusive texts targeting women
  on social media in Tamil and Malayalam languages. The authors developed machine
  learning models using logistic regression and BERT to classify comments as either
  abusive or non-abusive.
---

# GS_DravidianLangTech@2025: Women Targeted Abusive Texts Detection on Social Media

## Quick Facts
- arXiv ID: 2504.02863
- Source URL: https://arxiv.org/abs/2504.02863
- Reference count: 13
- Primary result: BERT achieved 0.729 macro F1 score for Tamil abusive text detection

## Executive Summary
This paper addresses the challenge of detecting abusive texts targeting women on social media platforms in Tamil and Malayalam languages. The authors developed machine learning models using both traditional logistic regression and modern BERT transformer approaches to classify comments as abusive or non-abusive. The study demonstrates the effectiveness of transformer-based models in handling low-resource Dravidian languages, with BERT showing particularly strong performance on Tamil data.

## Method Summary
The authors employed a binary classification approach using two distinct machine learning models. Logistic regression served as a traditional baseline, while BERT provided a transformer-based deep learning approach. The models were trained on social media comments in Tamil and Malayalam, focusing specifically on detecting abusive content targeting women. Data preprocessing and feature extraction were performed, though specific technical details are limited in the paper. The models were evaluated using macro F1 scores to assess their performance in identifying abusive content across both languages.

## Key Results
- BERT model achieved 0.729 macro F1 score for Tamil abusive text detection
- Logistic regression achieved 0.6279 macro F1 score for Malayalam classification
- Transformer-based approaches demonstrated superior performance in low-resource Dravidian language settings

## Why This Works (Mechanism)
The transformer-based approach works effectively because BERT can capture contextual relationships and semantic nuances in low-resource languages through pre-training on large corpora. The self-attention mechanism allows the model to identify abusive patterns even in morphologically rich Dravidian languages where word order and inflections carry significant meaning. The binary classification simplifies the task while maintaining practical utility for social media moderation systems.

## Foundational Learning
- Binary classification: Simplifies complex abuse detection into manageable categories; check: ensure clear definition of abusive vs non-abusive
- Macro F1 score: Balances precision and recall across classes; check: verify equal weighting of both classes
- Transformer architecture: Captures bidirectional context; check: confirm pre-training on relevant language data
- Logistic regression: Provides interpretable baseline; check: validate feature selection process
- Dravidian language characteristics: Morphological complexity affects model design; check: assess language-specific preprocessing needs

## Architecture Onboarding

Component map:
Data -> Preprocessing -> Model Training -> Evaluation -> Deployment

Critical path: Data collection and preprocessing directly impact model performance, with BERT's contextual understanding providing the strongest classification capability.

Design tradeoffs: Binary classification simplifies the problem but may miss nuanced abuse types. Limited preprocessing steps reduce computational overhead but may affect performance. Choice of Tamil vs Malayalam models reflects language-specific challenges.

Failure signatures: Low F1 scores indicate poor distinction between abusive and non-abusive content. High false positives suggest over-sensitivity to certain words or patterns. Language-specific failures point to insufficient training data or inadequate handling of linguistic features.

Three first experiments:
1. Compare BERT performance with additional baseline models (SVM, random forest)
2. Test multi-class classification for different abuse types
3. Evaluate impact of expanded preprocessing (lemmatization, stemming) on classification accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Small dataset size may limit generalizability of results
- Binary classification approach oversimplifies nuanced abusive language
- Limited preprocessing steps may affect model performance
- Focus on only two Dravidian languages restricts broader applicability

## Confidence
- Dataset size and quality: Medium confidence - insufficient details on training examples and collection methodology
- Model comparison comprehensiveness: Medium confidence - limited baseline models tested without comprehensive state-of-the-art comparisons
- Preprocessing methodology: Low confidence - lack of detailed explanation of text preprocessing steps

## Next Checks
1. Conduct ablation studies to isolate the impact of different preprocessing steps and model architectures on performance
2. Expand the dataset collection across more Dravidian languages and include multi-class labels for different types of abusive content
3. Perform cross-validation with hyperparameter optimization to establish more robust performance benchmarks