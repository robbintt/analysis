---
ver: rpa2
title: Challenges in interpretability of additive models
arxiv_id: '2504.10169'
source_url: https://arxiv.org/abs/2504.10169
tags:
- additive
- functions
- feature
- shape
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper critically examines the interpretability claims of generalized
  additive models (GAMs) and their neural variants (NAMs). While these models are
  often presented as "transparent" or "interpretable" alternatives to black-box methods,
  the authors demonstrate that nonidentifiability issues can undermine their interpretability.
---

# Challenges in interpretability of additive models

## Quick Facts
- arXiv ID: 2504.10169
- Source URL: https://arxiv.org/abs/2504.10169
- Authors: Xinyu Zhang; Julien Martinelli; ST John
- Reference count: 11
- Key outcome: Demonstrates nonidentifiability issues in GAMs/NAMs from observing only sums of shape functions and from concurvity among covariates

## Executive Summary
This paper critically examines the interpretability claims of generalized additive models (GAMs) and neural additive models (NAMs). While often presented as transparent alternatives to black-box methods, these models suffer from nonidentifiability issues that can produce multiple models with equivalent predictive performance but different interpretations. The authors identify two main sources: (1) the inability to observe individual shape functions separately, and (2) concurvity (nonlinear correlation) among covariates. They argue that orthogonality constraints can help with some nonidentifiability but not concurvity, and that ensemble approaches examining multiple plausible solutions may be more appropriate than seeking a single interpretable model.

## Method Summary
The paper uses two synthetic experiments to demonstrate nonidentifiability issues in additive models. First, a dataset with 7 features following specific structural relationships is created where Y = 2X1² + X5³ + 2sin(X6) + noise, showing that different feature subsets achieve similar RMSE despite different interpretations. Second, a correlated bivariate example demonstrates how regularization strength affects shape function correlation. NAMs are trained with separate subnetworks per feature and concurvity regularization penalizing Pearson correlation between shape functions. Results are averaged over 5 random seeds with λ values swept from 0.0 to 0.1.

## Key Results
- Orthogonality constraints resolve nonidentifiability from observing only sums of shape functions by constraining constant offsets between components
- Concurvity (nonlinear correlation among covariates) creates nonidentifiability that persists even with orthogonality constraints, allowing redistribution of feature effects without changing predictions
- Concurvity regularizers using Pearson correlation reduce linear correlation between shape functions but fail to eliminate nonlinear dependencies, which can remain even when Pearson correlation approaches zero

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Orthogonality constraints can resolve nonidentifiability caused by observing only the sum of additive terms.
- Mechanism: By enforcing that the integral of each additive component equals zero with respect to the input measure (∫fp(xp)dμ(xi) = 0 ∀i ∈ p), the constant offset ∆ that could be arbitrarily shifted between shape functions becomes constrained, yielding a unique decomposition.
- Core assumption: The input measure μ is well-defined and the shape functions are integrable; the orthogonality constraint does not interfere with the underlying data-generating process.
- Evidence anchors:
  - [section 3.1]: "Orthogonality constraints were suggested as a solution... the proposed kernels enforce the integral of each additive component to be zero"
  - [section 4]: "orthogonality constraints effectively allow one to distinguish between f1(·) + f2(·) and (f1(·) − ∆) + (f2(·) − ∆)"
  - [corpus]: Weak direct corpus support; neighboring papers focus on transparency broadly rather than orthogonality specifically.
- Break condition: When concurvity exists among covariates, orthogonality constraints alone are insufficient (see Mechanism 2).

### Mechanism 2
- Claim: Concurvity (nonlinear correlation among covariates) creates nonidentifiability that persists even with orthogonality constraints.
- Mechanism: When hi(xi) can be approximated by a combination of other shape functions (hi(xi) ≈ Σj≠i hj(xj)), the effect of any single feature can be redistributed across correlated features without changing predictions. For any constant ∆: Σfd(xd) = fi(xi) + ∆hi(xi) + Σj≠i[fj(xj) − ∆hj(xj)].
- Core assumption: The concurvity relationship is approximate rather than exact; the paper demonstrates this empirically rather than proving it theoretically.
- Evidence anchors:
  - [section 3.2]: "Concurvity extends this notion by considering the shape functions fi... indicating redundancy in the feature set"
  - [section 3.2, Equation 6 and Table 1]: The Kovács example shows {X1, X5, X6} and {X1, X3, X6} achieve similar RMSE despite different interpretations
  - [corpus]: No direct corpus support for concurvity-specific nonidentifiability.
- Break condition: When features are truly independent (no multicollinearity or concurvity), this nonidentifiability source disappears.

### Mechanism 3
- Claim: Concurvity regularizers that penalize linear correlation between shape functions do not guarantee interpretability because nonlinear dependencies persist.
- Mechanism: The concurvity regularizer R⊥ penalizes average Pearson correlation between shape functions. While increasing regularization strength λ reduces linear correlation, nonlinear dependencies remain—shape functions can be uncorrelated (Pearson r ≈ 0) yet still be dependent in nonlinear ways.
- Core assumption: Pearson correlation is used as a proxy for independence, which is mathematically insufficient for capturing nonlinear dependence.
- Evidence anchors:
  - [section 3.2, Figure 2]: "NAMs fitted using the objective eq. (9) give rise to gradually less correlated shape functions as λ increases. However, they remain dependent in a nonlinear manner"
  - [section 3.2]: "suggests employing other penalties like HSIC to handle nonlinear dependencies"
  - [corpus]: Neighboring paper "Multiplicative-Additive Constrained Models" addresses interaction effects but not concurvity regularization directly.
- Break condition: If using a nonlinear independence measure (e.g., HSIC) as the regularizer, this particular failure mode may be mitigated—though the paper does not test this.

## Foundational Learning

- Concept: **Identifiability vs. Interpretability**
  - Why needed here: The paper critiques conflation of these concepts. Identifiability means a unique parameterization exists; interpretability concerns human understanding. A model can be identifiable but still produce misleading interpretations under concurvity.
  - Quick check question: If two GAMs with different shape functions produce identical predictions on all inputs, is the model identifiable?

- Concept: **Sobol Indices / Variance-Based Sensitivity**
  - Why needed here: Referenced as importance measures for additive models with orthogonality constraints. Understanding variance decomposition helps contextualize why the paper discusses sensitivity analysis approaches.
  - Quick check question: In a first-order Sobol index, what portion of output variance does Si capture?

- Concept: **Rashomon Set**
  - Why needed here: The paper argues for examining multiple plausible models rather than seeking a single "interpretable" solution. The Rashomon set represents all models within ε of optimal performance.
  - Quick check question: If the Rashomon set is large, what does this imply about the uniqueness of feature importance rankings?

## Architecture Onboarding

- Component map:
  - Input features → each feature processed independently by its shape function fd
  - Shape outputs aggregated additively: f(x) = β0 + Σfd(xd)
  - Link function applied: g(f(x)) for final prediction
  - Regularization terms added to loss: orthogonality constraints and/or concurvity penalties

- Critical path:
  1. Input x → each feature processed independently by its shape function fd
  2. Shape outputs aggregated additively
  3. Link function applied for final prediction
  4. During training: regularization terms added to loss to constrain nonidentifiability

- Design tradeoffs:
  - **Expressivity vs. identifiability**: More flexible shape functions (neural networks vs. splines) worsen concurvity nonidentifiability
  - **Regularization strength vs. accuracy**: Higher concurvity regularization (λ) stabilizes interpretations but may degrade predictive performance
  - **Single model vs. Rashomon ensemble**: Computing multiple models increases robustness of interpretations at computational cost

- Failure signatures:
  - **Unstable shape functions across random seeds**: Indicates sum-of-terms nonidentifiability; add orthogonality constraints
  - **Different feature subsets with similar RMSE**: Indicates concurvity; domain expertise required for selection
  - **Shape functions appear interpretable but are nonlinearly dependent**: Linear correlation regularizers insufficient; consider HSIC-based penalties

- First 3 experiments:
  1. **Identifiability stress test**: Fit NAM on data with known concurvity (e.g., Eq. 6 synthetic data) across 5+ random seeds; measure variance in learned shape functions and compare feature subsets selected.
  2. **Regularization ablation**: Vary concurvity regularization strength λ ∈ {0, 0.001, 0.01, 0.1} on correlated features; compute both Pearson correlation and HSIC between resulting shape functions to verify nonlinear dependence persists.
  3. **Rashomon set characterization**: For a given tolerance ε, enumerate all feature subsets achieving RMSE within ε of optimal; report size of Rashomon set and variance in feature importance rankings across the set.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can nonlinear dependence measures (e.g., HSIC-based penalties) effectively resolve concurvity-induced nonidentifiability in additive models where Pearson correlation regularization fails?
- Basis in paper: [explicit] The authors demonstrate that concurvity regularization using Pearson correlation reduces linear but not nonlinear dependencies among shape functions, and briefly suggest that "employing other penalties like HSIC to handle nonlinear dependencies" may be necessary.
- Why unresolved: The paper only briefly mentions HSIC as a potential solution; no experiments or theoretical analysis are provided to validate whether HSIC-based penalties would actually resolve the nonlinear dependency problem.
- What evidence would resolve it: Empirical evaluation of HSIC-regularized NAMs on benchmark datasets with known nonlinear concurvity, showing stable shape function recovery across random initializations.

### Open Question 2
- Question: How should "Rashomon set" approaches be concretely implemented and presented to domain experts for additive models under concurvity?
- Basis in paper: [explicit] The authors argue that "providing experts with an ensemble of solutions rather than a unique candidate set, as proposed by Rashomon-set-based approaches, currently seems like the best tradeoff" but provide no implementation details.
- Why unresolved: The paper references Rashomon-set approaches conceptually but does not develop methodology for constructing, visualizing, or communicating such ensembles to practitioners.
- What evidence would resolve it: A framework defining how to enumerate, filter, and present multiple equally-performing additive models with different feature attributions, validated through user studies with domain experts.

### Open Question 3
- Question: What formal criteria distinguish when a single identifiable additive model suffices versus when multiple solutions must be considered?
- Basis in paper: [explicit] The authors state that "an identifiable algorithm might be sufficient when the main task is to automate decision-making processes" but "if the goal is to gain comprehensive insight into the data, relying on one single feature subset... might not be a safe choice."
- Why unresolved: The paper provides no quantitative threshold or diagnostic measure to determine which scenario applies in practice.
- What evidence would resolve it: Development of a concurvity severity metric or identifiability index that predicts when Rashomon effects will substantially impact interpretation, validated across real-world datasets.

## Limitations
- The paper focuses on synthetic datasets where ground truth shape functions are known, but the severity of identifiability issues on real-world data with complex concurvity remains unquantified
- While the authors suggest HSIC-based penalties for nonlinear dependencies, they don't implement or validate this approach, leaving the practical solution incomplete
- The computational complexity of Rashomon set exploration for real datasets is not discussed, making it unclear when this approach becomes tractable

## Confidence

- High confidence in Mechanism 1 (orthogonality constraints): The mathematical foundation is well-established in the GAM literature
- Medium confidence in Mechanism 2 (concurvity nonidentifiability): Empirical demonstrations are convincing but lack theoretical bounds on the magnitude of the problem
- Low confidence in Mechanism 3 (regularization insufficiency): The paper shows Pearson correlation reduction but doesn't rigorously prove nonlinear dependencies persist across all function classes

## Next Checks

1. Test nonidentifiability on real-world datasets with known concurvity (e.g., housing price data with correlated features like square footage and lot size)
2. Implement HSIC-based concurvity regularizer and compare against Pearson correlation regularizer on synthetic datasets with nonlinear dependencies
3. Quantify the Rashomon set size and interpretation variance for a real regression problem with ≥10 features to assess practical feasibility