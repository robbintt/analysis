---
ver: rpa2
title: 'SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis'
arxiv_id: '2508.07944'
source_url: https://arxiv.org/abs/2508.07944
tags:
- deepfake
- speech
- speaker
- detection
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The SCDF dataset is introduced to address the lack of bias evaluation
  resources in deepfake speech detection. It contains over 237,000 utterances across
  five languages and balanced male/female speaker representation, with detailed demographic
  annotations (sex, age, language).
---

# SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis

## Quick Facts
- arXiv ID: 2508.07944
- Source URL: https://arxiv.org/abs/2508.07944
- Reference count: 40
- The SCDF dataset reveals significant demographic bias in deepfake speech detection systems, with lower accuracy for male speakers, older age groups, and non-English languages.

## Executive Summary
The SCDF dataset is introduced to address the lack of bias evaluation resources in deepfake speech detection. It contains over 237,000 utterances across five languages with balanced male/female speaker representation and detailed demographic annotations. Evaluations on state-of-the-art detectors reveal statistically significant performance disparities across sex, language, age, and synthesizer type. These findings highlight the need for bias-aware development and more diverse training data to ensure fair, non-discriminatory deepfake detection systems.

## Method Summary
The SCDF dataset was constructed using VoxPopuli as source material, generating deepfakes across five languages (Czech, German, English, Spanish, French) using four synthesizers (XTTSv2, F5-TTS, OpenVoice v2, DDDM-VC). The dataset includes over 237,000 utterances with balanced male/female representation across 50 speakers. Pretrained detectors (AASIST, MHFA, SLS with XLSR-300M backbone) were evaluated, with performance disaggregated by sex, language, age groups, and synthesizer type. Statistical significance was tested using Mann-Whitney U-test and Kruskal-Wallis H-test.

## Key Results
- Detection accuracy is lower for male speakers and older age groups (70+)
- German language presents the biggest challenge, with significantly higher EERs than other languages
- TTS-based deepfakes are harder to detect than VC-based ones
- Statistical tests confirm performance disparities are significant (p<0.01)

## Why This Works (Mechanism)

### Mechanism 1: Disaggregated Bias Revelation via Demographic Stratification
Standard pooled evaluation metrics mask significant performance disparities that only emerge when detector scores are stratified by speaker demographics. By isolating variables such as age or sex, the analysis decouples generalization failures from specific demographic blind spots. Statistical tests confirm that the distribution of detection scores differs significantly between groups, invalidating the assumption of uniform detector performance.

### Mechanism 2: Synthesizer Architecture Impact on Artifact Fidelity
TTS systems generate deepfakes that are significantly harder to detect than VC systems, likely due to differences in how artifacts are introduced during waveform generation. TTS models generate speech from scratch, potentially creating more coherent spectral temporal structures than VC models, which must map existing acoustic features to a new voice. Detectors relying on specific artifacts fail when these are absent or more refined in modern TTS.

### Mechanism 3: Language-Specific Generalization Gaps
Detectors exhibit statistically significant performance variance across languages, often correlating with the language's representation in the training data. Self-supervised learning backbones and subsequent classifiers may overfit to phonotactic patterns dominant in their pre-training or fine-tuning data. When evaluating on languages like German, the acoustic features might align differently with the decision boundary, leading to higher false negatives/positives.

## Foundational Learning

- **Concept: Equal Error Rate (EER)**
  - Why needed here: This is the primary metric used to quantify "detection difficulty." Understanding that a higher EER means the detector is failing more often is required to interpret the bias results.
  - Quick check question: If a detector has an EER of 20% for "Male" and 10% for "Female," which group is the model biased against (performing worse on)?

- **Concept: Zero-Shot Synthesis**
  - Why needed here: The deepfakes in SCDF are generated in a "zero-shot" setting, meaning the synthesizer clones a voice from a short reference without retraining. This implies the detector must handle infinite voice variations.
  - Quick check question: Does zero-shot synthesis require the TTS model to be re-trained on the target speaker's data to generate the deepfake?

- **Concept: Statistical Hypothesis Testing (p-value)**
  - Why needed here: The authors use Mann-Whitney U and Kruskal-Wallis tests (and p-values < 0.01) to prove that the observed performance differences are statistically significant and not just random noise.
  - Quick check question: A p-value of 0.001 indicates strong evidence that the observed performance difference is due to random chanceâ€”True or False?

## Architecture Onboarding

- **Component map:** VoxPopuli -> Preprocessing (OGG to WAV, 16kHz) -> 4 Synthesizers (XTTSv2, F5-TTS, OpenVoice v2, DDDM-VC) -> Detectors (XLSR-300M + AASIST/MHFA/SLS) -> Evaluation (score disaggregation + statistical testing)

- **Critical path:**
  1. Extract 250 bona-fide utterances per language from VoxPopuli
  2. Generate deepfakes using the 4 synthesizers (creating the 236k deepfake set)
  3. Run inference using pre-trained detectors trained on ASVspoof
  4. Tag every output score with corresponding metadata (sex, age, lang, synthesizer)
  5. Apply statistical tests to these tagged score distributions

- **Design tradeoffs:**
  - Controlled Bias vs. Real-World Noise: Uses European Parliament speeches (high-quality, experienced speakers) reducing noise but limiting ecological validity
  - Dataset Balance: Balanced for Sex and Language but not perfectly for Age (skewed towards middle age)
  - Synthesizer Coverage: Only 4 synthesizers used, not covering the entire threat model of legacy or proprietary systems

- **Failure signatures:**
  - High False Negative Rate for 70+ Age Group: Deepfakes of elderly speakers classified as "bona-fide"
  - German Language Collapse: Significant spike in EER specifically for German deepfakes
  - TTS Evasion: Drastic performance drop on TTS attacks vs. VC attacks

- **First 3 experiments:**
  1. Baseline Disaggregation: Run ASVspoof19-trained AASIST model on SCDF and calculate EER specifically for Male vs. Female and each Age bin
  2. Language Ablation: Fine-tune the detector on a single language subset of SCDF and evaluate if cross-lingual bias persists
  3. Synthesizer Transfer: Train a detector on VC-generated deepfakes and test it on TTS-generated deepfakes to quantify the "Synthesizer Gap"

## Open Questions the Paper Calls Out

- Do speaker ethnicity and level of education introduce systematic performance disparities in deepfake speech detectors that are currently unaccounted for? The authors state that while annotations for ethnicity and education were collected, they "are not analyzed in this paper due to insufficient sample sizes in certain categories."

- To what extent do native versus non-native speaker status and vocal characteristics (e.g., fundamental frequency F0) influence the detection error rates of state-of-the-art models? The paper notes that the dataset annotations "could also be easily extended with additional attributes such as native/non-native speaker status... or vocal characteristics (e.g., fundamental frequency F0) in the future."

- Does the "experienced speaker" profile inherent in the VoxPopuli source data limit the generalizability of these bias findings to spontaneous or conversational speech? The paper specifies that data is sourced from European Parliament recordings, meaning "only speeches of experienced speakers are included."

## Limitations
- The dataset relies on a limited set of 4 synthesizer architectures, which may not represent the full diversity of real-world deepfake generation methods
- Statistical significance testing assumes independence of samples, but overlapping speaker characteristics may introduce correlation effects
- The source corpus consists of professional speech recordings, which may not generalize to casual speech domains where deepfakes are more likely to appear

## Confidence
- **High Confidence**: The existence of measurable performance disparities across demographic groups (p<0.01 in statistical tests provides strong evidence)
- **Medium Confidence**: The specific attribution of these disparities to demographic factors rather than synthesis quality or other confounds (requires further ablation studies)
- **Medium Confidence**: The practical significance of the TTS vs VC detection gap (though statistically significant, real-world implications depend on deployment context)

## Next Checks
1. Replicate the bias analysis using an independent deepfake corpus (e.g., ASVspoof or Frontier) to verify findings are not dataset-specific
2. Conduct a controlled experiment varying only the reference audio quality (not speaker identity) to isolate demographic bias from technical artifacts
3. Test whether domain adaptation techniques can reduce observed disparities, establishing whether biases are fundamental or addressable through training methodology