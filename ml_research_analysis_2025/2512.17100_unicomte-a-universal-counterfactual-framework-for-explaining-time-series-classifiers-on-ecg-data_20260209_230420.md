---
ver: rpa2
title: 'UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series
  Classifiers on ECG Data'
arxiv_id: '2512.17100'
source_url: https://arxiv.org/abs/2512.17100
tags:
- unicomte
- explanations
- counterfactual
- samples
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the lack of interpretability in deep learning
  models for ECG classification, which limits their clinical adoption. The authors
  introduce UniCoMTE, a model-agnostic counterfactual explanation framework that generates
  actionable explanations by identifying minimal changes to ECG signals that would
  alter model predictions.
---

# UniCoMTE: A Universal Counterfactual Framework for Explaining Time-Series Classifiers on ECG Data

## Quick Facts
- arXiv ID: 2512.17100
- Source URL: https://arxiv.org/abs/2512.17100
- Reference count: 40
- Primary result: Model-agnostic counterfactual framework generating 2-4 lead-time segment explanations for ECG classification with 43-58% coverage and 3.69/5 expert ratings

## Executive Summary
This study addresses the critical interpretability gap in deep learning models for ECG classification, which limits their clinical adoption. UniCoMTE introduces a model-agnostic counterfactual explanation framework that generates actionable explanations by identifying minimal changes to ECG signals that would alter model predictions. The framework is evaluated on a state-of-the-art CNN trained on 12-lead ECG data from the CODE-15 dataset, demonstrating superior clarity compared to SHAP and LIME while maintaining clinical relevance.

## Method Summary
UniCoMTE operates through a three-component architecture: data and model wrappers that standardize inputs and predictions across different ML backends, a distractor selection module using class-specific KD-trees to retrieve similar target-class samples, and a counterfactual generation module employing discrete hill-climbing search to identify minimal lead-time segments whose substitution flips model predictions. The framework works directly on raw time series data and produces sparse explanations (average 2.93 segments) that are both interpretable and clinically actionable.

## Key Results
- Generates concise explanations involving only 2-4 lead-time segments compared to thousands of point-level attributions from SHAP/LIME
- Achieves 43-58% coverage in generalizing explanations across misclassified samples across six diagnostic conditions
- Expert evaluation shows explanations are clinically relevant and interpretable with mean ratings of 3.69/5
- Outperforms baseline methods in clarity while maintaining physiological plausibility

## Why This Works (Mechanism)

### Mechanism 1: Distractor-Based Segment Substitution
UniCoMTE retrieves distractors—samples from the target class that are maximally similar to the input—using class-specific KD-trees. It then identifies the smallest subset of lead-time segments whose substitution changes the model output, producing a counterfactual that directly shows which features matter and how they must change. This approach assumes the model's decision boundary can be crossed via discrete temporal segment swaps rather than continuous perturbations.

### Mechanism 2: Discrete Hill-Climbing for Sparse Feature Discovery
The framework performs discrete random hill-climbing to find the smallest set of variable-time pairs that flip classification with maximal confidence. This greedy search strategy identifies actionable counterfactuals with only 2-4 lead-time segments, outperforming point-level attribution methods in comprehensibility. The approach assumes the search space permits local improvements to reach valid counterfactuals.

### Mechanism 3: Model-Agnostic Wrapper Abstraction
Unified data and model wrapper interfaces enable counterfactual generation across TensorFlow, PyTorch, and scikit-learn without algorithm modification. The model wrapper standardizes prediction queries regardless of backend; the data wrapper reformats time series into MultiIndex DataFrames indexed by entity and time. This abstraction isolates counterfactual logic from implementation specifics.

## Foundational Learning

- Concept: Counterfactual vs. Attribution-Based Explanations
  - Why needed here: SHAP and LIME produce thousands of point-level attribution scores requiring manual thresholding; counterfactuals directly answer "what minimal change flips the prediction?"—critical for clinical actionability.
  - Quick check question: For a 12-lead ECG with 4,096 time samples, why would a 3-segment counterfactual be more clinically useful than 49,152 SHAP coefficients?

- Concept: Nearest-Neighbor Retrieval in High-Dimensional Time Series
  - Why needed here: Distractor selection scales to 345,779 training samples via KD-trees; understanding this enables debugging poor counterfactual quality (e.g., insufficient similar target-class samples).
  - Quick check question: If the target class has only 50 training samples, how might distractor quality degrade compared to a class with 10,000 samples?

- Concept: Sparsity-Interpretability Tradeoff
  - Why needed here: UniCoMTE optimizes for minimal segments (2-4 average) at potential cost of physiological plausibility; expert evaluation revealed cases where counterfactuals were sparse but clinically misleading.
  - Quick check question: Why might a 2-segment counterfactual for sinus bradycardia receive lower expert ratings than a 4-segment counterfactual that produces more coherent waveforms?

## Architecture Onboarding

- Component map: Data Wrapper -> Distractor Selection (KD-tree query) -> Hill-Climbing Search (iterative Model Wrapper calls) -> Counterfactual Output
- Critical path: Input ECG → Data Wrapper formatting → Distractor Selection (KD-tree query) → Hill-Climbing Search (iterative Model Wrapper calls) → Counterfactual Output
- Design tradeoffs:
  - Sparsity vs. Plausibility: Fewer segments improve comprehensibility but may produce physiologically incoherent signals
  - Search efficiency vs. optimality: Hill-climbing is faster than exhaustive search but may miss globally minimal solutions
  - Data quality dependency: Counterfactual quality is directly proportional to training data quality—no generative smoothing
- Failure signatures:
  - Flatlined counterfactual regions: Distractor samples contain sensor faults; apply std < 0.1 filter to training data
  - Bimodal expert ratings: Condition-specific label inconsistency or diagnostic ambiguity (observed in sinus bradycardia)
  - Coverage < 45%: Model decision boundary is sample-specific rather than pattern-based; explanations don't generalize
  - Introduced abnormalities: Segment substitution disrupts cross-lead dependencies (e.g., PR interval corruption when correcting LBBB)
- First 3 experiments:
  1. Backend consistency test: Apply UniCoMTE to the same 20 ECG samples using TensorFlow and PyTorch model wrappers; verify counterfactual segments match within tolerance (implementation validation).
  2. Coverage stratification: For each of 6 diagnostic conditions, compute coverage across misclassified samples; identify lowest-performing conditions and manually inspect failure patterns.
  3. Data quality ablation: Generate counterfactuals before and after applying the std < 0.1 filter; quantify reduction in "unhelpful" expert ratings.

## Open Questions the Paper Calls Out
None

## Limitations
- Condition-specific coverage rates vary significantly (43-58%), limiting generalizability across clinical conditions
- Dependence on training data quality creates vulnerability to artifacts, with the std < 0.1 filter being a blunt instrument
- Hill-climbing search lacks documented hyperparameter tuning, raising concerns about reproducibility and optimization quality
- Cross-lead physiological dependencies are not explicitly modeled, potentially generating counterfactuals that violate known cardiac constraints

## Confidence

- **High Confidence**: Model-agnostic wrapper abstraction (clearly specified interfaces, tested across TensorFlow/PyTorch), KD-tree distractor retrieval (standard technique with explicit implementation), segment-level sparsity metrics (directly observable)
- **Medium Confidence**: Hill-climbing search effectiveness (results shown but hyperparameters unspecified), clinical expert evaluation (single-study ratings without inter-rater reliability metrics), coverage generalizability (condition-specific variation not fully explained)
- **Low Confidence**: Physiological plausibility guarantees (no explicit cardiac constraint validation), decision boundary crossing mechanism (discrete vs. continuous perturbations not theoretically grounded), explanation actionability claims (clinical utility not validated beyond ratings)

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary hill-climbing iterations, restart counts, and convergence thresholds; measure impact on coverage rates and explanation quality across all six diagnostic conditions.

2. **Physiological Constraint Validation**: Implement cross-lead dependency checking (PR interval consistency, QRS morphology coherence); quantify proportion of counterfactuals that violate known cardiac constraints.

3. **Multi-Backend Consistency Test**: Apply UniCoMTE to identical ECG samples using scikit-learn, PyTorch, and TensorFlow model wrappers; verify counterfactual segments match within tolerance and evaluate wrapper abstraction robustness.