---
ver: rpa2
title: 'Optimized projection-free algorithms for online learning: construction and
  worst-case analysis'
arxiv_id: '2506.05855'
source_url: https://arxiv.org/abs/2506.05855
tags:
- regret
- algorithm
- online
- bound
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies projection-free online learning algorithms based
  on linear optimization oracles (Frank-Wolfe) for handling constraint sets. The authors
  develop an improved variant of an online Frank-Wolfe algorithm with a conceptually
  simple potential-based proof, and show how to use semidefinite programming to jointly
  design and analyze online Frank-Wolfe-type algorithms numerically across various
  settings.
---

# Optimized projection-free algorithms for online learning: construction and worst-case analysis

## Quick Facts
- arXiv ID: 2506.05855
- Source URL: https://arxiv.org/abs/2506.05855
- Reference count: 40
- The authors develop an improved Online Frank-Wolfe algorithm achieving O(T^{3/4}) regret through potential-based analysis and semidefinite programming optimization.

## Executive Summary
This paper addresses the fundamental question of whether projection-free online learning algorithms using only linear optimization oracles (Frank-Wolfe variants) are inherently limited to O(T^{3/4}) regret. The authors develop an improved Online Frank-Wolfe algorithm with optimized parameters derived via semidefinite programming, achieving O(T^{3/4}) regret bounds. They provide strong numerical evidence that this rate is tight for the model class by computing worst-case regret bounds up to T=100, while also demonstrating that current algorithms have suboptimal constants and that multiple linear optimization rounds don't generally improve performance.

## Method Summary
The core method uses a potential-based approach to analyze and optimize online Frank-Wolfe algorithms, where the key idea is to construct appropriate potential functions that relate the Frank-Wolfe iterates to the iterates of Follow-The-Regularized-Leader (FTRL). This allows obtaining tight regret bounds and optimized algorithm parameters. The authors use semidefinite programming techniques to compute tight numerical regret bounds up to horizon T=100, providing strong evidence for their claims about the fundamental limitations of online Frank-Wolfe algorithms.

## Key Results
- An optimized online Frank-Wolfe algorithm achieving regret O(T^{3/4}), improving upon previous bounds
- Numerical evidence suggesting no pure online Frank-Wolfe algorithm within their model class can have regret better than O(T^{3/4}) without additional assumptions
- Findings that current algorithms don't have optimal constants and that multiple linear optimization rounds don't generally help obtain better regret bounds
- An anytime variant achieving O(t^{3/4}) regret without requiring knowledge of T in advance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm achieves O(T^{3/4}) regret through optimized parameter tuning derived via semidefinite programming.
- Mechanism: A potential function φ_t relates OFW iterates to FTRL iterates. Bounding the per-iteration potential difference φ_t - φ_{t-1} enables global regret bounds via telescoping sums. The parameters η and σ are chosen to minimize this bound.
- Core assumption: Loss functions are convex and L-Lipschitz; the domain K has bounded diameter D.
- Evidence anchors:
  - [abstract] "improved version of the Online Frank-Wolfe algorithm with an optimized parameter tuning derived through a constructive semidefinite programming approach"
  - [Section 2, Lemma 2.2] Potential function definition and decomposition
  - [corpus] Weak—no direct corpus matches for this specific SDP-based proof construction
- Break condition: Non-convex losses, unbounded gradients, or domains without finite diameter.

### Mechanism 2
- Claim: Replacing projections with linear optimization oracles maintains tractability while reducing computational cost.
- Mechanism: Each iteration solves min_{v∈K} ⟨dirt, v⟩ where dirt = η·Σ gs + (xt - x1). This is cheaper than projection when K has combinatorial structure (e.g., nuclear norm balls, polytopes).
- Core assumption: The constraint set K admits an efficient linear optimization oracle.
- Evidence anchors:
  - [abstract] "projection-free algorithms...that use linear optimization oracles instead of projections"
  - [Section 1, Algorithmic setup] Definition of the linear oracle call vt = arg min_{v∈K} ⟨dirt, v⟩
  - [corpus] "BAGEL: Projection-Free Algorithm" (arXiv:2502.16744) confirms LOO utility for constrained OCO
- Break condition: Constraint sets where linear optimization is NP-hard (arbitrary convex sets without exploitable structure).

### Mechanism 3
- Claim: The algorithm achieves O(t^{3/4}) regret without knowing T by substituting t for T in parameter choices.
- Mechanism: Parameters η = D/(2L)·(3/T)^{3/4} and σ = min(1, √(3/T)) can be made anytime by replacing T with current time t, preserving sublinear regret.
- Core assumption: The regret analysis remains valid with time-varying parameters; the Schur complement condition for Q(λ) holds.
- Evidence anchors:
  - [abstract] "algorithm benefits from anytime properties O(t^{3/4}) that don't require knowing the time horizon T in advance"
  - [Section 3.3, Figure 1 discussion] Anytime variant has ~1.17× overhead vs. fixed-horizon
  - [corpus] No direct corpus support for this specific anytime construction
- Break condition: Highly non-stationary environments where loss characteristics change dramatically.

## Foundational Learning

- Concept: **Online Convex Optimization (OCO)**
  - Why needed here: This is the fundamental framework. You must understand regret, adversarial loss sequences, and the sequential decision structure.
  - Quick check question: Can you write down the definition of regret R_T and explain why we seek o(T) rates?

- Concept: **Frank-Wolfe Algorithm (Conditional Gradient Method)**
  - Why needed here: The paper builds directly on Frank-Wolfe's core idea of using linear optimization over the constraint set.
  - Quick check question: What is the computational advantage of Frank-Wolfe over projected gradient descent when K is a nuclear norm ball?

- Concept: **Semidefinite Programming (SDP) and Performance Estimation Problems (PEP)**
  - Why needed here: The paper uses SDP for constructive algorithm design and worst-case analysis via Gram matrix lifting.
  - Quick check question: How does the change of variables in Section 3.1 transform the infinite-dimensional problem (4) into a tractable SDP?

## Architecture Onboarding

- Component map:
  - **Algorithm 1 (OFW)** -> **Linear Optimization Oracle** -> **PEP Solver (SDP)** -> **Parameter Optimizer**
  - Core update with parameters η, σ; iterate xt+1 = (1-σ)xt + σvt
  - Solves min_{v∈K} ⟨dirt, v⟩ per iteration
  - Computes worst-case regret bounds via problem (4) and dual (13); implemented with CVXPY + MOSEK
  - Jointly optimizes η_{t,s}, β_{t,s}, γ_{t,s} via problem (5)/(16)

- Critical path:
  1. Implement Algorithm 1 with tunable parameters from Eq. (2)
  2. Build SDP formulation using PEPit or CVXPY (as in Section 3.3)
  3. Solve dual SDP to extract potential-based proof certificates
  4. Validate numerical bounds against theoretical guarantees

- Design tradeoffs:
  - **η vs. σ**: Larger η increases gradient influence; σ controls step conservatism—theorem gives η ∝ T^{-3/4}, σ ∝ T^{-1/2}
  - **Regularization (β_{t,s})**: Setting β_{t,s} = 0 yields dimension-independent parameters but worsens rate to O(T^{7/8}) per Section 3.3
  - **Multiple LOO rounds (r > 1)**: Does not improve rate beyond O(T^{3/4})—only constant factors

- Failure signatures:
  - Regret scaling as O(T) or worse → likely incorrect parameter initialization or oracle bug
  - Numerical instability for large T → SDP solver precision limits; use smaller T and extrapolate
  - Anytime variant degrading → verify parameter substitution preserves sum-of-squares condition for Q(λ)

- First 3 experiments:
  1. **Sanity check**: Implement Algorithm 1 on K = [-1, 1] with linear losses; compare empirical regret to bound 1.76·L·D·T^{3/4}
  2. **Worst-case extraction**: Solve SDP (4) for T = 10 with L = D = 1; extract worst-case loss sequence and verify regret matches SDP objective
  3. **Anytime comparison**: Run fixed-T and anytime variants on same adversarial sequence for T = 100; plot regret curves to confirm ~1.17× overhead

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Are Online Frank-Wolfe variants that rely solely on linear oracle calls inherently limited to a regret rate of $\Omega(T^{3/4})$, or are improved rates possible without additional assumptions?
- Basis in paper: [explicit] The introduction states, "Despite these advancements, it remains an open question whether Online Frank-Wolfe variants that solely use linear oracle calls are inherently limited to a regret rate of Ω(T^3/4) or if improved rates are possible in this setting."
- Why unresolved: While the paper provides strong numerical evidence via semidefinite programming suggesting the $O(T^{3/4})$ bound is tight for the model class, a rigorous analytical lower bound proof remains absent.
- What evidence would resolve it: A formal mathematical proof establishing a lower bound of $\Omega(T^{3/4})$ for this class, or the discovery of a novel algorithm that provably achieves a lower rate (e.g., $O(T^{1/2})$) using only linear oracles.

### Open Question 2
- Question: Can a tighter theoretical analysis of the proposed OFW algorithm be found to close the constant-factor gap between the analytical bound and the numerically computed tight worst-case bound?
- Basis in paper: [explicit] The conclusion lists "can we find a tighter analysis of the OFW algorithm?" as a motivation for future work.
- Why unresolved: The paper's potential-based proof yields a regret bound that is approximately 1.5 times larger than the numerically computed tight bound (Section 3.3), indicating slack in the current analysis.
- What evidence would resolve it: A new analytical proof (potentially using a different potential function) that matches the constants observed in the numerical semidefinite programming results.

### Open Question 3
- Question: Can a closed-form expression be derived for the parameters of the optimal OFW-type method?
- Basis in paper: [explicit] The conclusion explicitly asks "can we find a closed-form for the optimal OFW-type method?" as a primary avenue for future work.
- Why unresolved: The optimal parameters in this work were obtained numerically through semidefinite programming, and translating these numerical solutions into closed-form algebraic expressions proved challenging.
- What evidence would resolve it: An analytical derivation of the step-size parameters ($\eta, \sigma$) and weightings ($\gamma_{t,s}$) that minimizes the worst-case regret.

### Open Question 4
- Question: What is the exact regret rate and optimal closed-form solution for the unregularized OFW-type method (where $\beta_{t,s} = 0$)?
- Basis in paper: [explicit] The conclusion lists "can we find a closed-form solution and the corresponding regret bound for the optimal unregularized OFW-type method?" as a future research opportunity.
- Why unresolved: Numerical experiments suggest the regret scales as $O(T^{7/8})$ for this dimension-independent variant, but this rate has not been confirmed analytically.
- What evidence would resolve it: A rigorous proof determining the exact rate (verifying if it is indeed $O(T^{7/8})$) and providing the corresponding optimal parameter tuning in closed form.

## Limitations
- The paper's numerical evidence up to T=100 suggests O(T^{3/4}) is a fundamental lower bound, but this remains a conjecture without formal analytical proof for all T.
- The anytime variant shows a 17% performance penalty compared to the fixed-horizon version, indicating a potential gap between fixed-horizon and anytime optimality.
- The analysis assumes convex losses and doesn't address non-convex settings where different techniques might apply.

## Confidence
- **High Confidence**: The O(T^{3/4}) regret upper bound for Algorithm 1 is mathematically proven via the potential-based analysis and supported by numerical validation.
- **Medium Confidence**: The claim that no online Frank-Wolfe algorithm in their model class can achieve better than O(T^{3/4}) regret is strongly suggested by numerical evidence but not formally proven for all T.
- **Low Confidence**: The assertion that multiple linear optimization rounds don't improve regret bounds beyond constant factors requires broader validation across diverse constraint sets.

## Next Checks
1. **Lower Bound Verification**: Implement Algorithm 1 with varying parameters on K = simplex and K = nuclear norm ball; measure empirical regret against the claimed O(T^{3/4}) bound across T ∈ [10, 100] to confirm consistent scaling.
2. **Anytime Gap Analysis**: Compare fixed-horizon Algorithm 1 against the anytime variant on the same adversarial sequences for T = 50, 100, 200; plot regret curves to precisely quantify the 1.17× overhead and test whether it diminishes for larger T.
3. **Constraint Set Robustness**: Test Algorithm 1 on K = Birkhoff polytope and K = ℓ₁-ball; verify whether the O(T^{3/4}) rate holds and whether multiple LOO rounds (r > 1) consistently fail to improve beyond constant factors across these different geometries.