---
ver: rpa2
title: 'C-SWAP: Explainability-Aware Structured Pruning for Efficient Neural Networks
  Compression'
arxiv_id: '2510.18636'
source_url: https://arxiv.org/abs/2510.18636
tags:
- pruning
- c-sw
- neurons
- structured
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces C-SWAP, a one-shot structured pruning framework
  that leverages causal explainability to compress neural networks without fine-tuning.
  Unlike traditional methods requiring iterative pruning-retraining, C-SWAP uses causal
  inference to classify neurons as critical, neutral, or detrimental based on their
  effect on model predictions.
---

# C-SWAP: Explainability-Aware Structured Pruning for Efficient Neural Networks Compression

## Quick Facts
- arXiv ID: 2510.18636
- Source URL: https://arxiv.org/abs/2510.18636
- Authors: Baptiste Bauvin; Loïc Baret; Ola Ahmad
- Reference count: 40
- Primary result: One-shot structured pruning framework using causal explainability that outperforms traditional methods without fine-tuning

## Executive Summary
C-SWAP introduces a novel one-shot structured pruning framework that leverages causal explainability to compress neural networks without iterative pruning-retraining cycles. The method classifies neurons as critical, neutral, or detrimental by measuring their causal effect on model predictions through path interventions. By progressively pruning non-critical neurons layer-by-layer from output to input, C-SWAP achieves superior accuracy-pruning trade-offs compared to baselines like OMP, DeepLIFT, and iLRP across CNNs and vision transformers. The approach also extends to semantic segmentation tasks.

## Method Summary
C-SWAP performs one-shot structured pruning by computing causal effects of individual neurons through path interventions. For each neuron, it measures the change in model predictions when cutting outgoing connections, uses paired t-tests to assess statistical significance per class, and classifies neurons via a voting mechanism. The method then progressively prunes non-critical neurons layer-by-layer from output to input, avoiding the ranking degradation problem of bulk removal approaches. This causal approach enables pruning without fine-tuning while maintaining high accuracy.

## Key Results
- Outperforms OMP, DeepLIFT, and iLRP baselines on ResNet-18/50, MobileNetV2 across pruning ratios
- Maintains >95% accuracy at 50% pruning on CIFAR-10 where traditional methods degrade
- Extends to semantic segmentation with competitive mIoU performance
- SAUCE metric consistently higher than ranking-based C-BP variant

## Why This Works (Mechanism)

### Mechanism 1: Causal Effect Computation via Path Interventions
C-SWAP classifies neurons by measuring causal effects through interventions - cutting outgoing connections and measuring prediction changes. The global causal effect ξ_n = (1/M) Σ (σ*_n(x) - σ(x)) / σ(x) quantifies each neuron's impact. Positive values indicate detrimental neurons, negative values indicate beneficial ones. This intervention-based approach captures true causal importance rather than mere correlation.

### Mechanism 2: Progressive Bottom-Up Pruning Avoids Ranking Degradation
By processing layers from output to input and immediately removing non-critical neurons, C-SWAP avoids the ranking quality degradation problem where global rankings become stale after significant removal. This bottom-up approach ensures that neurons closest to the output - which have more direct impact on predictions - are classified more reliably early in the process.

### Mechanism 3: Per-Class Statistical Testing with Voting Aggregation
The method assesses neuron importance per-class using paired t-tests with α=0.05, then aggregates via voting to prevent removing class-specific information. A neuron is neutral only if statistically insignificant across all classes; critical if significant and beneficial for any class. This conservative approach prioritizes safety over maximum sparsity.

## Foundational Learning

- **Structured vs. Unstructured Pruning:**
  - Why needed here: C-SWAP targets structured pruning (removing entire channels/filters) which enables actual hardware acceleration, unlike unstructured (individual weight) pruning
  - Quick check question: Can you explain why removing 50% of individual weights doesn't guarantee 50% speedup on GPU?

- **Causal Inference via Intervention:**
  - Why needed here: C-SWAP uses "do-calculus" style interventions (cutting connections) rather than observational correlation to determine neuron importance
  - Quick check question: What's the difference between observing that neuron activations correlate with class predictions vs. intervening to remove the neuron?

- **Statistical Hypothesis Testing (Paired t-test):**
  - Why needed here: The method uses t-tests to determine if the difference σ*_n - σ_n is statistically significant, controlling the false positive rate at α=0.05
  - Quick check question: Why use a paired t-test instead of comparing means directly? What does the pairing capture?

## Architecture Onboarding

- **Component map:**
  - Causal Explainer -> Progressive Pruner -> Critical Buffer -> ViT Adapter

- **Critical path:**
  1. Prepare data manifold S (128 samples per class, balanced)
  2. For each layer l from L-1 to 1:
     - For each neuron n in layer l:
       - Perturb: cut connections {n → ν} for ν in layer l+1
       - Compute σ and σ*_n across all samples
       - Run paired t-test per class → π_n^(k)
       - Aggregate via voting → classify as critical/neutral/detrimental
       - If neutral or detrimental: remove immediately
  3. If target pruning ratio not met: prune lowest-ξ_n critical neurons

- **Design tradeoffs:**
  - Sample size (M_k): More samples → more reliable significance tests, but longer computation
  - Significance level (α): Lower α → more neurons classified as neutral (more aggressive pruning)
  - Scoring function σ: Classification uses softmax probability; segmentation uses mIoU
  - Progressive vs. ranking: Progressive is O(N); ideal greedy is O(m×N)

- **Failure signatures:**
  - Early accuracy cliff: indicates critical neurons being removed → increase α or check voting logic
  - Per-class performance variance: class imbalance in manifold S; rebalance sample selection
  - ViT shape mismatches: verify only MLP/attention inner dimensions are pruned
  - Memory OOM: wide layers require batching the perturbation analysis

- **First 3 experiments:**
  1. Baseline comparison on ResNet-18/CIFAR-10: Run C-SWAP vs. OMP vs. random pruning across 0-80% pruning ratios without fine-tuning
  2. Ablation on voting strategy: Compare Definition 2's voting scheme vs. "general inference" on ResNet-50
  3. Sample size sensitivity: Run C-SWAP with M_k ∈ {16, 32, 64, 128, 256} on MobileNetV2

## Open Questions the Paper Calls Out

- **Group-wise relevance scoring:** Can block/channel-level causal relevance replace per-unit analysis to reduce computational overhead in very wide layers? The current implementation is computationally demanding for layers with >2048 neurons.

- **Object detection extension:** How to define effective scoring functions for object detection or instance segmentation? The current scalar outputs (class probability, IoU) don't capture bounding boxes and multiple classes.

- **Voting strategy conservatism:** Does the voting strategy introduce excessive false positives in datasets with high class correlation? The method may overestimate criticality compared to brute-force removal.

## Limitations
- Model-specific applicability: Effectiveness on recurrent architectures and complex skip connections remains untested
- Sample efficiency: Requires 128 samples per class without rigorous optimization of this number
- Computational overhead: Per-neuron perturbation analysis scales quadratically with model width

## Confidence
- High confidence: Core causal intervention mechanism and mathematical definitions are well-founded
- Medium confidence: Progressive bottom-up pruning shows consistent gains but limited statistical testing
- Low confidence: Per-class statistical testing with voting aggregation has minimal corpus support

## Next Checks
1. Ablation on statistical significance thresholds: Systematically vary α across ResNet-18/CIFAR-10 to quantify pruning-accuracy trade-off
2. Cross-architecture generalization test: Apply C-SWAP to LSTM on text classification to test feedforward assumption
3. Sample size sensitivity analysis: Run C-SWAP with M_k ∈ {8, 16, 32, 64, 128, 256} on MobileNetV2 to identify diminishing returns point