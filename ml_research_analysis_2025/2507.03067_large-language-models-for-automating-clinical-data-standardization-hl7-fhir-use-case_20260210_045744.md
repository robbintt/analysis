---
ver: rpa2
title: 'Large Language Models for Automating Clinical Data Standardization: HL7 FHIR
  Use Case'
arxiv_id: '2507.03067'
source_url: https://arxiv.org/abs/2507.03067
tags:
- data
- fhir
- each
- table
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a semi-automated approach using large language
  models (LLMs) to transform structured clinical data into HL7 FHIR format. By integrating
  embedding techniques, clustering algorithms, and semantic retrieval, the method
  maps tabular fields to corresponding FHIR resources.
---

# Large Language Models for Automating Clinical Data Standardization: HL7 FHIR Use Case

## Quick Facts
- arXiv ID: 2507.03067
- Source URL: https://arxiv.org/abs/2507.03067
- Authors: Alvaro Riquelme; Pedro Costa; Catalina Martinez
- Reference count: 40
- The study introduces a semi-automated approach using large language models (LLMs) to transform structured clinical data into HL7 FHIR format

## Executive Summary
This study presents a semi-automated approach using large language models to transform structured clinical data into HL7 FHIR format. The method combines embedding techniques, clustering algorithms, and semantic retrieval to map tabular fields to corresponding FHIR resources. Tested on the MIMIC-IV dataset with GPT-4o and Llama 3.2 405b, the approach achieved 100% resource-level identification and up to 73.88% attribute-level mapping accuracy under ideal conditions, with GPT-4o outperforming Llama 3.2.

## Method Summary
The proposed method employs a hybrid architecture that combines semantic retrieval with LLM-based mapping to transform clinical data into HL7 FHIR format. The approach uses embeddings to cluster similar fields, then applies semantic search to retrieve relevant FHIR definitions. LLMs are then used to map tabular fields to FHIR resources and attributes. The system was evaluated on the MIMIC-IV dataset using both GPT-4o and Llama 3.2 405b models, with performance measured through resource-level and attribute-level accuracy metrics.

## Key Results
- Achieved 100% accuracy in resource-level identification across both models
- GPT-4o achieved up to 73.88% attribute-level mapping accuracy in ideal conditions
- In simulated real-world scenarios, GPT-4o maintained robust accuracy at 95% CI (67.74%-69.86%)
- GPT-4o outperformed Llama 3.2 405b in all tested scenarios

## Why This Works (Mechanism)
The approach leverages LLMs' natural language understanding capabilities to bridge the semantic gap between clinical data schemas and FHIR resource definitions. By combining semantic retrieval with contextual understanding, the system can identify appropriate FHIR resources and map corresponding attributes even when field names don't perfectly match. The embedding-based clustering helps group semantically similar fields, reducing the search space for the LLM and improving mapping accuracy.

## Foundational Learning
- **HL7 FHIR Standard**: Healthcare data interoperability framework; needed to understand target format for transformation
- **Semantic Retrieval**: Method for finding relevant information based on meaning rather than exact keywords; needed to match clinical fields with FHIR definitions
- **Embedding Techniques**: Mathematical representations of data that capture semantic relationships; needed for clustering similar clinical fields
- **Resource Mapping**: Process of linking data fields to standardized healthcare resources; needed to ensure data interoperability
- **Attribute-Level Accuracy**: Metric measuring how well individual data fields are mapped to FHIR attributes; needed to assess mapping quality
- **Hallucination Detection**: Methods for identifying when LLMs generate incorrect or fabricated information; needed to ensure data reliability

## Architecture Onboarding

**Component Map**: Clinical Data -> Embedding/Clustering -> Semantic Retrieval -> LLM Mapping -> FHIR Output

**Critical Path**: Data preprocessing → Embedding generation → Field clustering → FHIR definition retrieval → LLM mapping → Validation

**Design Tradeoffs**: The study chose to use GPT-4o for its superior accuracy despite higher costs, while Llama 3.2 offers a more cost-effective alternative with lower performance. The decision to use semantic retrieval before LLM mapping reduces computational load and improves accuracy by narrowing the context window.

**Failure Signatures**: Performance degrades significantly when metadata is incomplete or inconsistent. Hallucinations occur when the LLM cannot find appropriate FHIR mappings or when field semantics are ambiguous. The system struggles with datasets containing novel or highly specialized clinical terminology not well-represented in the training data.

**First Experiments**:
1. Test resource-level mapping accuracy on a small, well-defined clinical dataset with complete metadata
2. Evaluate attribute-level mapping accuracy with progressively degraded metadata quality
3. Compare hallucination rates between GPT-4o and Llama 3.2 on ambiguous field mappings

## Open Questions the Paper Calls Out
The study highlights several areas for future research, including fine-tuning models for improved performance, extending support to additional clinical data standards beyond FHIR, and developing expert validation interfaces to improve accuracy and reliability.

## Limitations
- Accuracy metrics rely heavily on manually curated metadata, which may not reflect real-world conditions
- The evaluation framework depends on manually curated ground truth mappings, introducing potential bias
- The study focuses on MIMIC-IV data structure without validation on diverse clinical datasets
- Absence of systematic error analysis limits understanding of model weaknesses and failure modes

## Confidence
- **High confidence**: The core methodology of combining semantic retrieval with LLM-based mapping is technically sound and the overall approach is feasible
- **Medium confidence**: The reported accuracy metrics are valid within the study's controlled conditions but may not generalize to broader clinical data contexts
- **Medium confidence**: The comparative advantage of GPT-4o over Llama 3.2 is demonstrated, though cost-effectiveness considerations remain unclear

## Next Checks
1. Deploy the system on clinical datasets with incomplete or inconsistent metadata to measure performance degradation and identify failure patterns
2. Evaluate the approach on multiple heterogeneous clinical datasets beyond MIMIC-IV to assess robustness across different data structures and terminologies
3. Compare GPT-4o and fine-tuned smaller models (including Llama 3.2 with domain-specific training) on accuracy, latency, and operational costs to determine optimal trade-offs for production use