---
ver: rpa2
title: '"Just in Time" World Modeling Supports Human Planning and Reasoning'
arxiv_id: '2601.14514'
source_url: https://arxiv.org/abs/2601.14514
tags:
- objects
- world
- object
- simulation
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a "Just-in-Time" (JIT) framework for efficient
  mental simulation that incrementally builds representations during planning and
  reasoning, rather than pre-computing them. The model uses simulation, visual search,
  and representation modification to selectively encode objects relevant to immediate
  simulation steps, achieving high utility predictions while representing fewer objects
  than alternative approaches.
---

# "Just in Time" World Modeling Supports Human Planning and Reasoning

## Quick Facts
- arXiv ID: 2601.14514
- Source URL: https://arxiv.org/abs/2601.14514
- Reference count: 40
- Primary result: JIT model achieved higher correlations with human behavior (r=0.87-0.96) than value-guided construal while representing fewer objects

## Executive Summary
This paper proposes a "Just-in-Time" (JIT) framework for efficient mental simulation that incrementally builds representations during planning rather than pre-computing them. The model uses simulation, visual search, and representation modification to selectively encode objects relevant to immediate simulation steps, achieving high utility predictions while representing fewer objects than alternative approaches. The JIT model outperformed value-guided construal (VGC) in explaining human behavior across grid-world planning and physical prediction tasks.

## Method Summary
The JIT model uses three components: a stochastic simulator (noisy A* for planning or Pymunk physics engine for reasoning), a perceptual lookahead that queries the visual scene based on simulated trajectories, and an encoding mechanism with power-law decay for memory management. The model was validated through re-analysis of Ho et al. 2022 behavioral data and new experiments with over 220 participants. Parameters were fit via grid search to maximize correlation with human recall, confidence, and hover behavior.

## Key Results
- JIT achieved higher correlations with human behavior (r=0.87-0.96) than VGC across both planning and reasoning tasks
- The model demonstrated computational efficiency by representing approximately half the objects of VGC without performance loss
- JIT showed lower RMSE values in predicting human memory patterns compared to alternative approaches

## Why This Works (Mechanism)

### Mechanism 1: Simulation-Guided Perceptual Lookahead
The system uses simulated future states to guide visual attention, querying the environment for potential collisions and encoding objects only when the simulated path intersects them. This treats the environment as external memory rather than storing everything internally.

### Mechanism 2: Path-Contingent Encoding (vs. Outcome-Contingent)
Unlike VGC which encodes objects that change optimal policy, JIT encodes objects relevant to the currently simulated path, even if those objects are irrelevant to the optimal outcome. This allows ignoring obstacles that block other paths but not the current one.

### Mechanism 3: Stochastic Memory Decay
Working memory load is minimized by probabilistically forgetting objects not recently utilized in the simulation trace, with probability proportional to t^(-Î³). This implements a "need probability" heuristic where distant simulation objects are assumed irrelevant.

## Foundational Learning

- **Concept: Resource Rationality & Construals**
  - Why needed: The paper frames mental simulation as cost-benefit trade-off where construal is selecting a simplified subset of the world to simulate
  - Quick check: Why does the paper argue that pre-computing the "optimal construal" is a paradox?

- **Concept: Probabilistic / Stochastic Simulation**
  - Why needed: The JIT model relies on sampling trajectories, not deterministic optimization
  - Quick check: How does the stochastic nature of the A* planner differ from standard A*?

- **Concept: Visual Search as External Memory Query**
  - Why needed: The model treats eye/mouse movements as mechanisms to "load" data into working memory
  - Quick check: In the JIT loop, what triggers the visual search to "load" an object?

## Architecture Onboarding

- **Component map:** Representational Sketchpad -> Simulator -> Perceptual Lookahead
- **Critical path:** Init Sparse Rep -> Sample Step (Simulate) -> Query Scene (Lookahead) -> Update Sketchpad (Encode/Forget) -> Repeat
- **Design tradeoffs:** JIT is computationally cheaper (represents ~half objects of VGC) but sacrifices optimality guarantees; VGC guarantees better global plans but incurs higher pre-computation costs
- **Failure signatures:** Catastrophic Forgetting if decay parameter too high; Attentional Blindness if simulation noise too low
- **First 3 experiments:**
  1. Implement lookahead function in grid world, verify wall encoding only when stochastic A* samples path through it
  2. Compare "Average Object Count" in sketchpad for JIT vs VGC across 40 mazes
  3. Run Experiment 2B (Plinko), check if model recalls "Counterfactually Irrelevant" objects better than VGC

## Open Questions the Paper Calls Out
- How can local JIT lookahead be combined with pre-computed value-guided construals for familiar environments?
- Does incremental representation building generalize to abstract cognitive domains like logical reasoning?
- How are representations initialized in arbitrary, unstructured real-world scenes without explicit instructions?

## Limitations
- The framework assumes static environments where visual lookahead reliably captures relevant objects
- Stochastic simulation introduces variance that could affect reliability in critical decision-making
- Behavioral evidence for humans using path-contingent encoding remains correlational rather than causal

## Confidence
- High confidence: Computational efficiency advantage (representing ~half objects of VGC)
- Medium confidence: Behavioral correlation claims within tested domains
- Medium confidence: Path-contingent encoding mechanism validity

## Next Checks
1. Apply JIT model to novel planning domain (e.g., multi-agent coordination) to verify generalization
2. Test model in scenarios with moving obstacles or partial occlusion to identify failure modes
3. Conduct fMRI studies to measure neural signatures during planning against JIT lookahead predictions