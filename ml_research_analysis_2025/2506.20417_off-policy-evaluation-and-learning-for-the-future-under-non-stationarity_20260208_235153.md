---
ver: rpa2
title: Off-Policy Evaluation and Learning for the Future under Non-Stationarity
arxiv_id: '2506.20417'
source_url: https://arxiv.org/abs/2506.20417
tags:
- time
- opfv
- policy
- feature
- estimator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of estimating and optimizing future
  policy values in non-stationary environments where distributions change over time.
  The key challenge is that future data is not available in historical logs, making
  standard off-policy evaluation methods biased.
---

# Off-Policy Evaluation and Learning for the Future under Non-Stationarity

## Quick Facts
- arXiv ID: 2506.20417
- Source URL: https://arxiv.org/abs/2506.20417
- Reference count: 40
- Primary result: Proposed OPFV method achieves up to 1.67 average reward versus 1.48-1.39 for baselines in real-world recommendation settings.

## Executive Summary
This paper addresses the challenge of estimating and optimizing future policy values in non-stationary environments where distributions change over time. Standard off-policy evaluation methods fail because future data is unavailable in historical logs, creating bias. The authors propose OPFV (Off-Policy Estimator for the Future Value), which leverages time-series structure like seasonal, weekly, or holiday effects to unbiasedly estimate future policy values using historical data. The method applies importance weighting based on time features and uses regression to handle residual effects. Theoretical analysis shows OPFV has low bias when time features are fine-grained or the regression accurately estimates pairwise differences. Experiments demonstrate substantial improvements over existing methods.

## Method Summary
The OPFV method decomposes expected rewards into time-feature effects and residual effects. It applies importance weighting to samples sharing the target time's feature, then uses regression to estimate the remaining non-stationary components. The estimator combines these elements to provide unbiased future value estimates. The approach extends to policy-gradient methods for future off-policy learning, where OPFV serves as the objective function. Time feature selection acts as a tunable hyperparameter controlling the bias-variance tradeoff, with finer features reducing bias but increasing variance.

## Key Results
- OPFV achieves up to 1.67 average reward versus 1.48-1.39 for baselines in real-world recommendation settings
- The method substantially outperforms existing approaches in both synthetic and real-world experiments
- OPFV provides computationally efficient estimation compared to regression-based baselines
- Theoretical analysis confirms low bias when time features are appropriate or regression is accurate

## Why This Works (Mechanism)

### Mechanism 1: Time-Feature Importance Weighting
The estimator achieves low bias by isolating the "time feature effect" (e.g., weekly seasonality) shared between historical logs and future target times via importance weighting. OPFV decomposes the expected reward $q(x,t,a)$ into a time-feature effect and a residual. It introduces a specific importance weight $\frac{\mathbb{I}_{\phi}(t, t')}{p(\phi(t'))}$ which selectively up-weights historical samples where the time feature $\phi(t)$ matches the target time's feature $\phi(t')$. The core assumption is that the time feature support condition holds, meaning there is at least some historical data sharing the feature of the future target time. If the target time feature $\phi(t')$ is unique to the future (e.g., a new holiday never seen in logs), $p(\phi(t')) = 0$, and the mechanism fails.

### Mechanism 2: Residual Effect Regression
A regression model $\hat{f}$ reduces the bias caused by non-stationary "residual effects" (variations not captured by fixed time features) by modeling the difference between historical and target times. After weighting captures the periodic effect, the estimator uses a regressor $\hat{f}$ in a Doubly Robust-style structure to estimate the remaining "residual effect" $\Delta h$. Theorem 3.3 shows bias depends on the error of $\hat{f}$ in estimating this pairwise difference. The core assumption is that the regression model $\hat{f}$ has sufficient capacity to estimate the relative difference in rewards $\Delta q(x, t, t', a)$ between time steps sharing the same feature. If the residual non-stationarity is highly irregular or high-dimensional relative to data size, the regression error remains high, and bias is not eliminated.

### Mechanism 3: Granularity-Dependent Bias-Variance Tradeoff
The selection of the time feature function $\phi$ acts as a tunable hyperparameter controlling the tradeoff between estimator bias and variance. Fine-grained features (e.g., "hour-of-day") reduce bias (residual effect is smaller) but increase variance (fewer historical samples match the feature). Coarse features (e.g., "season") increase bias but lower variance. The practitioner can define a candidate set $\Phi$ of time features and estimate the marginal probability $p(\phi)$. If the chosen feature $\phi$ is too fine, variance explodes; if too coarse, the residual bias dominates, rendering the estimate useless.

## Foundational Learning

- **Concept: Off-Policy Evaluation (OPE) & Importance Sampling (IPS)**
  - **Why needed here:** The paper builds directly upon standard IPS and Doubly Robust (DR) estimators. You must understand that OPE typically estimates $V(\pi_e) = \mathbb{E}[r]$ and IPS re-weights rewards by $\frac{\pi_e(a|x)}{\pi_0(a|x)}$.
  - **Quick check question:** Why does standard IPS fail when the distribution shifts from time $t$ to $t'$?

- **Concept: Non-Stationarity (Stationary vs. Non-Stationary Context)**
  - **Why needed here:** The paper distinguishes between "smooth" (gradual drift) and "abrupt" (sudden shift) non-stationarity. The method relies on finding *consistent* structures (like seasonality) amidst this drift.
  - **Quick check question:** If the environment changes drastically every minute with no repeating patterns, can OPFV work? (Hint: Check the "Time Feature Effect" decomposition).

- **Concept: Bias-Variance Decomposition of MSE**
  - **Why needed here:** The core theoretical contribution (Theorem 3.3 and Prop 3.4) formalizes the error of OPFV in terms of bias (from the regression/residual) and variance (from the time-feature weights).
  - **Quick check question:** Does increasing the granularity of the time feature increase or decrease the variance of the estimator?

## Architecture Onboarding

- **Component map:** Logged data $D = \{(x_i, t_i, a_i, r_i)\}$ -> Time Feature Encoder (maps $t$ to $\phi(t)$) -> Residual Regressor ($\hat{f}$ predicts $r$ from $(x, t, a)$) -> OPFV Estimator (combines weighted sampling and regression) -> (Optional) Policy Gradient Optimizer
- **Critical path:** The definition of the **Time Feature Function $\phi$**. This is not learned end-to-end initially but selected/optimized (Section 3.3). If $\phi$ is chosen poorly, the system falls back to high-bias or high-variance regimes.
- **Design tradeoffs:** $\phi$ Granularity: Fine-grained features → Low Bias, High Variance. Coarse features → High Bias, Low Variance. Regressor $\hat{f}$ complexity: A complex model may overfit the residual noise; a simple model may underfit the residual effect, leaving high bias.
- **Failure signatures:** Zero Support Warning: If you query a future time $t'$ with a feature never seen in logs (e.g., a leap-year specific event in a 1-year log), the estimator may crash or return NaN due to the denominator $p(\phi(t'))$. High Variance Spikes: If the chosen time feature partitions the data too finely (e.g., "second-of-day"), you will see massive variance spikes in the MSE plots.
- **First 3 experiments:**
  1. Synthetic Validation (Synthetic Data, Sec 4): Generate data with a known seasonal component (e.g., 8 seasons) and a residual drift. Compare OPFV against IPS/DR to verify that OPFV tracks the ground truth curve while baselines flatten or diverge.
  2. Feature Granularity Ablation (Fig 4): Run OPFV with varying cardinalities of $\phi$ (e.g., from 2 bins to 16 bins). Plot the decomposition of MSE into Squared Bias and Variance to confirm the theoretical tradeoff.
  3. Real-world Stress Test (KuaiRec, Sec 4): Apply OPFV-PG to the recommendation dataset. Compare the "Future Policy Value" learned by OPFV against Prognosticator to see if the method handles real-world noise better than regression-based baselines.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical bound for the finite sample suboptimality gap between the oracle time feature function ($\phi^*$) and the data-driven optimized function ($\hat{\phi}$)?
- Basis in paper: Appendix E notes that "the finite sample suboptimality gap between $\phi^*$ and $\hat{\phi}$ is considered an independent area of interest" regarding the optimization of the time feature.
- Why unresolved: The paper introduces a procedure to optimize $\phi$ but leaves the theoretical quantification of the gap between the true MSE minimizer and the estimated one for future work.
- What evidence would resolve it: A theoretical derivation providing a high-probability bound on $|\text{MSE}(\hat{\phi}) - \text{MSE}(\phi^*)|$.

### Open Question 2
- Question: How does the OPFV estimator perform when the context distribution shifts non-stationarily in a manner that violates the "Conditional Stationarity for Context" condition?
- Basis in paper: Appendix C.2 defines Condition C.1, which assumes the portion of context distribution not explained by time features ($p_2(x|t)$) is stationary across identical time features.
- Why unresolved: The theoretical unbiasedness of the extended OPFV estimator depends strictly on this condition, but real-world data may violate it.
- What evidence would resolve it: Empirical results on synthetic data where $p_2(x|t)$ varies for timestamps sharing the same time feature, measuring the resulting bias.

### Open Question 3
- Question: How does the variance of the OPFV estimator scale in environments with large action spaces compared to the subsampled settings used in the experiments?
- Basis in paper: Section 4 and Appendix J.1 mention that the real-world experiment uniformly subsampled 100 actions from 3327 unique videos due to computational efficiency.
- Why unresolved: Importance weighting estimators often suffer from high variance in large action spaces, and it is unclear if OPFV's additional weighting terms exacerbate this.
- What evidence would resolve it: Experiments evaluating OPFV on the full KuaiRec dataset (3327 actions) or synthetic data with high cardinality $|\mathcal{A}|$, reporting variance metrics.

## Limitations
- **Time feature selection dependency:** The method's performance critically depends on choosing an appropriate time feature function φ, which the paper's optimization procedure provides a framework for but doesn't fully resolve.
- **Common support requirement:** The method requires that the evaluation policy's action distribution at the future time has support within the historical data for times sharing the same feature, which is a strict assumption that may not hold in practice.
- **Residual effect assumptions:** The bias guarantee relies on the regression model accurately estimating pairwise differences in the residual effect, which may not hold in highly non-stationary environments with complex residual patterns.

## Confidence

- **High Confidence:** The core theoretical framework (Theorem 3.3) showing OPFV's bias-variance decomposition is well-founded. The experimental results demonstrating superior performance over baselines are reproducible and consistent across synthetic and real-world datasets.
- **Medium Confidence:** The claim that OPFV handles "abrupt" non-stationarity through time-feature structure is supported but not extensively validated. The experiments focus on synthetic settings with controlled shifts.
- **Low Confidence:** The specific claims about computational efficiency relative to regression-based baselines lack detailed timing measurements or complexity analysis in the main text.

## Next Checks

1. **Feature Sensitivity Analysis:** Systematically test OPFV with a broader range of time features (varying granularity from hourly to seasonal) on real-world datasets to quantify the bias-variance tradeoff empirically.

2. **Support Violation Study:** Design experiments where the common support condition is deliberately violated (e.g., by restricting historical data) to measure the impact on OPFV's bias and variance.

3. **Scalability Benchmark:** Measure the computational time of OPFV versus regression-based baselines (Prognosticator) on datasets of varying sizes (n=1K, 10K, 100K samples) to verify the claimed efficiency advantage.