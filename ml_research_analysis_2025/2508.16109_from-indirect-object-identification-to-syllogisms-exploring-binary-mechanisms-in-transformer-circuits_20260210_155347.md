---
ver: rpa2
title: 'From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms
  in Transformer Circuits'
arxiv_id: '2508.16109'
source_url: https://arxiv.org/abs/2508.16109
tags:
- truth
- heads
- statement
- logit
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work investigates how GPT-2 small processes syllogisms requiring\
  \ binary truth value reasoning. The authors introduce three prompt formats\u2014\
  simple, opposite, and complex syllogisms\u2014to probe the model's logical reasoning\
  \ capabilities."
---

# From Indirect Object Identification to Syllogisms: Exploring Binary Mechanisms in Transformer Circuits

## Quick Facts
- **arXiv ID**: 2508.16109
- **Source URL**: https://arxiv.org/abs/2508.16109
- **Reference count**: 40
- **Key outcome**: GPT-2 small uses truth heads for copying truth values in simple syllogisms and negative truth heads plus MLP logit rescalers for negation in opposite syllogisms.

## Executive Summary
This paper investigates how GPT-2 small processes syllogisms requiring binary truth value reasoning through three prompt formats: simple, opposite, and complex. Using path patching and logit lens analyses, the authors identify task-specific circuits where truth heads copy truth values in simple syllogisms while negative truth heads plus MLPs enable negation in opposite syllogisms. A five-head circuit achieves over 90% of GPT-2 small's performance on simple syllogisms, while a five-head and four-MLP circuit recovers approximately 85% on opposite syllogisms. The study reveals that components critical for one binary task often have corresponding negative counterparts crucial for the inverse task, providing new insights into how language models process and represent binary pairs of tokens.

## Method Summary
The paper employs mechanistic interpretability techniques to reverse-engineer GPT-2 small's reasoning circuits for syllogisms involving binary truth values. Using path patching to measure component contributions, the authors decompose attention heads into QK and OV circuits and apply logit lens to track truth value propagation through the model. They construct three syllogism datasets (simple, opposite, complex) and identify specific attention heads and MLPs that drive performance on each task. The methodology involves iterative ablation and patching experiments to isolate circuit components and measure their individual contributions to logit differences between correct and incorrect predictions.

## Key Results
- Five Truth Heads (7.2, 9.1, 9.9, 10.1, 10.4) achieve 90% performance on simple syllogisms through truth value copying
- Five Negative Truth Heads plus four MLPs achieve 85% performance on opposite syllogisms through attention-MLP negation pathways
- The same heads that harm simple syllogism performance become essential for opposite syllogisms, revealing component reversal across tasks
- MLP dependency introduces asymmetry: negation from true→false is more reliable than false→true
- Circuit components show limited transfer to other binary pairs beyond the trained true/false tasks

## Why This Works (Mechanism)

### Mechanism 1: Truth Head Copying for Direct Syllogisms
Certain attention heads identify and copy truth values from premise statements to the conclusion position without MLP involvement. Truth Heads (7.2, 9.1, 9.9, 10.1, 10.4) use QK circuits to attend to truth-related token pairs like (S, matches) and (is, true), establishing logical equivalence between statements. Their OV circuits then copy the attended truth value directly into the residual stream at the final token position. This mechanism assumes the model has learned induction-like patterns that map logical equivalence keywords to truth value retrieval.

### Mechanism 2: Attention-MLP Negation Pathway for Opposite Syllogisms
Producing a negated token not present in the input requires a two-stage mechanism: attention-based suppression followed by MLP-based logit rescaling. Negative Truth Heads (7.3, 8.10, 9.7, 10.7, 11.10) attend to truth tokens but suppress them into bottom logits via their OV projection. Adjacent MLPs (layers 8-10) then rescale the residual stream to elevate the opposite token. This attention-then-MLP sequence enables learned negation without explicit token copying, assuming the model encodes binary opposition relationships where suppressing one truth token activates its counterpart in logit space.

### Mechanism 3: Component Reversal Across Semantically Opposed Tasks
Components that harm performance on one binary task become essential for its inverse, suggesting heads encode directional logit modulation rather than fixed functional roles. Heads like 10.7 that are classified as "negative" in Simple Syllogism (mean-ablating improves performance) become causally necessary in Opposite Syllism. The same head suppresses the attended truth value; whether this helps or hurts depends on whether the task requires direct copying or negation. This reversal pattern may not generalize beyond binary token pairs.

## Foundational Learning

- **Path Patching**: The primary causal intervention method for identifying which components contribute to task performance. Without understanding path patching, you cannot replicate the circuit discovery methodology. Quick check: Given an original prompt "Statement A is true" and corrupted prompt "Statement A is false," what would patching Head 7.2's activation from corrupted to original reveal about that head's role?

- **QK and OV Circuit Decomposition**: The paper interprets attention heads by analyzing their QK circuits (what they attend to) and OV circuits (what information they transfer). This decomposition is essential for distinguishing Truth Heads from Negative Truth Heads. Quick check: If a head's QK circuit strongly scores (is, true) pairs but its OV output suppresses 'true' logits, what functional role does this head play?

- **Logit Difference as Faithfulness Metric**: The paper quantifies circuit completeness using logit difference between correct and incorrect tokens. Understanding this metric is necessary to evaluate whether a subcircuit captures the full model's behavior. Quick check: A circuit achieves 1.9286 average logit difference while the full model achieves 1.8575. Is this circuit faithful? What does the faithfulness formula yield?

## Architecture Onboarding

- **Component map**: Input tokens → residual stream x₀ → Early layers (0-5): Statement identification and induction routing → Mid-to-late layers (7-11): Task-specific truth value processing → For negation tasks: Attention suppression → MLP rescaling → output logits → Final: Logit difference computed between true/false tokens

- **Critical path**: Layer 0 (Duplicate Statement Identifiers) and Layer 5 (Induction Heads) feed into task-specific heads, which process through attention and MLP layers to produce final logits.

- **Design tradeoffs**: Simple syllogism circuits use only attention (faster, more interpretable) but cannot handle negation; Opposite syllogism requires MLPs (adds complexity and asymmetry: true→false more reliable than false→true).

- **Failure signatures**: Ablating MLPs in opposite syllogisms causes catastrophic performance drop; Complex syllogisms with distractors may trigger wrong attention targets; False→true negation is less reliable than true→false.

- **First 3 experiments**:
  1. Replicate path patching for Head 10.7: Run corrupted/original distributions for simple vs. opposite syllogisms; verify that mean-ablating 10.7 helps SS but hurts OS.
  2. Logit lens trace through negation: Apply logit lens at (a) after Negative Truth Head OV output, (b) after MLP layer; confirm truth tokens move from bottom to top logits.
  3. Binary pair generalization test: Construct simple/opposite syllogisms with (right/wrong), measure whether CSS and COS circuits transfer without modification.

## Open Questions the Paper Calls Out

- What mechanistic factors explain the observed asymmetry in negation reliability, where flipping "true" to "false" is more robust than "false" to "true"?
- Why does simple syllogism performance degrade in larger models (GPT-2 XL, Qwen3-1.7B, LLaMA3.2-1B) despite their greater capacity?
- What computational components account for the remaining 10–15% performance gap between the identified circuits and full model behavior?

## Limitations

- Circuit generality is limited, with mixed results when transferring to other binary pairs beyond true/false
- Asymmetry in negation performance suggests the model may be using directional representations rather than symmetric logical operations
- MLP dependency for negation introduces complexity that may not generalize to more complex reasoning tasks
- Path patching methodology depends on how corrupted distributions are constructed, which is not explicitly specified

## Confidence

- **High Confidence**: Identification of Truth Heads and their copying mechanism for simple syllogisms (supported by clear logit lens trajectories and high faithfulness scores)
- **Medium Confidence**: Attention-MLP negation pathway for opposite syllogisms (mechanism is plausible but MLP localization is less precise)
- **Low Confidence**: Claims about component reversal across tasks and generalization to arbitrary binary pairs (limited empirical validation beyond presented cases)

## Next Checks

1. Apply the identified CSS and COS circuits to syllogisms using different binary pairs (right/wrong, good/bad) and measure faithfulness degradation to test circuit generality.

2. Design prompts that can be solved using only attention mechanisms and verify whether the same circuit components are used, isolating the necessity of MLPs for negation.

3. Analyze GPT-2's training corpus for frequency patterns of "Statement X is true/false" constructions and their negations to determine whether circuits reflect learned logical reasoning or surface-level pattern matching.