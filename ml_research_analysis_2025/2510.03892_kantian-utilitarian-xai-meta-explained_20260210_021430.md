---
ver: rpa2
title: 'Kantian-Utilitarian XAI: Meta-Explained'
arxiv_id: '2510.03892'
source_url: https://arxiv.org/abs/2510.03892
tags:
- kantian
- utilitarian
- welfare
- coffee
- option
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study introduces a gamified XAI system that supports ethically
  aware consumer decision-making in the coffee domain. The system employs two symbolic
  engines: a Kantian module that flags deontic rule violations (e.g., child labor,
  deforestation risk, opaque supply chains) and a utilitarian module that scores options
  using weighted multi-criteria aggregation over normalized ethical attributes.'
---

# Kantian-Utilitarian XAI: Meta-Explained

## Quick Facts
- arXiv ID: 2510.03892
- Source URL: https://arxiv.org/abs/2510.03892
- Reference count: 13
- This study introduces a gamified XAI system that supports ethically aware consumer decision-making in the coffee domain.

## Executive Summary
This study introduces a gamified XAI system that supports ethically aware consumer decision-making in the coffee domain. The system employs two symbolic engines: a Kantian module that flags deontic rule violations (e.g., child labor, deforestation risk, opaque supply chains) and a utilitarian module that scores options using weighted multi-criteria aggregation over normalized ethical attributes. A meta-explainable, operating with a 0.2 regret bound, detects and resolves conflicts between Kantian and utilitarian recommendations by switching to a deontically clean option when welfare loss is small. Across six coffee rounds with three options each, the combined Kantian-utilitarian meta-explanation condition achieved 75% violation-free selections and preserved near-utilitarian welfare (0.702 vs. price baseline), resolving 25% of Kantian-utilitarian conflicts.

## Method Summary
The study employs a gamified XAI system with two symbolic reasoning engines: a Kantian module detecting deontic rule violations and a utilitarian module scoring options through weighted multi-criteria aggregation. A meta-explainable agent with 0.2 regret bound resolves conflicts between these approaches by selecting deontically compliant options when welfare loss is minimal. The experiment involved 120 participants making coffee purchasing decisions across six rounds, with three options per round, comparing conditions: Kantian-only, utilitarian-only, and combined Kantian-utilitarian meta-explanation.

## Key Results
- Combined Kantian-utilitarian meta-explanation achieved 75% violation-free selections
- Preserved near-utilitarian welfare (0.702 vs. price baseline)
- Resolved 25% of Kantian-utilitarian conflicts

## Why This Works (Mechanism)
The dual-logic XAI approach makes normative tensions explicit and actionable for consumers by combining deontic reasoning (Kantian) with consequentialist evaluation (utilitarian) through a meta-explainable agent that can switch between logics based on minimal welfare loss.

## Foundational Learning
- **Deontic Logic**: Necessary for representing ethical rules and constraints (e.g., child labor prohibitions). Quick check: Can the system formally represent "must not" versus "should" rules?
- **Multi-Criteria Decision Making**: Required for utilitarian welfare aggregation across normalized ethical attributes. Quick check: Are attribute weights empirically validated or assumed?
- **Regret Bound Optimization**: Enables the meta-explainable to switch logics with bounded performance loss. Quick check: Does 0.2 regret bound hold across different decision domains?
- **Conflict Resolution in Ethical AI**: Critical for handling tensions between rule-based and outcome-based ethics. Quick check: How does the system handle conflicts with multiple equally valid resolutions?

## Architecture Onboarding
- **Component Map**: Kantian Engine -> Utilitarian Engine -> Meta-Explainable -> Consumer Interface
- **Critical Path**: Rule violation detection → Welfare scoring → Conflict detection → Resolution selection → Explanation generation
- **Design Tradeoffs**: Kantian-only ensures 100% compliance but may sacrifice welfare; utilitarian-only maximizes welfare but tolerates violations; meta-explanation balances both at the cost of added complexity
- **Failure Signatures**: Systematic violations indicate faulty deontic rules; consistently low welfare suggests poor weight calibration; high conflict rates may reveal ambiguous ethical priorities
- **First Experiments**: 1) Validate synthetic rules against expert-annotated real-world violations 2) Test meta-explanation with dynamically adjusted user weights 3) Replicate across multiple ethical decision domains

## Open Questions the Paper Calls Out
None

## Limitations
- Sample size (n=120) and coffee domain specificity limit generalizability
- Synthetic rule set may not capture real-world ethical complexity
- Weight aggregation could mask underlying trade-offs

## Confidence
- Welfare comparison: Medium (depends on assumed attribute weights)
- Conflict resolution mechanism: High (controlled setting), Low (real-world deployment)

## Next Checks
1. Replicate the study with a larger, more diverse participant pool across multiple ethical decision domains
2. Validate the synthetic deontic rules against expert-annotated real-world ethical violations
3. Test the meta-explanation framework's performance when attribute weights are dynamically adjusted by different user segments