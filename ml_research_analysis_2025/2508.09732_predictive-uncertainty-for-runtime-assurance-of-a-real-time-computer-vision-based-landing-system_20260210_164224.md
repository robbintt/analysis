---
ver: rpa2
title: Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based
  Landing System
arxiv_id: '2508.09732'
source_url: https://arxiv.org/abs/2508.09732
tags:
- uncertainty
- runway
- pose
- systems
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of ensuring safety and robustness
  in data-driven vision systems for aviation, specifically for real-time pose estimation
  during aircraft landing approaches. The authors propose a practical vision-based
  pipeline that leverages a spatial Soft Argmax operator for efficient, sub-pixel
  precision keypoint regression from runway images, enabling real-time inference with
  diverse CNN backbones.
---

# Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System

## Quick Facts
- arXiv ID: 2508.09732
- Source URL: https://arxiv.org/abs/2508.09732
- Reference count: 40
- Primary result: Vision-based pipeline with spatial Soft Argmax achieves sub-pixel precision (0.5px) and calibrated uncertainty for aircraft landing pose estimation, with RAIM-based runtime integrity monitoring.

## Executive Summary
This work addresses safety-critical pose estimation for aircraft landing by combining a spatial Soft Argmax operator with calibrated uncertainty estimation and runtime integrity monitoring. The approach enables real-time inference (30-60 Hz) with diverse CNN backbones while achieving sub-pixel precision on runway keypoint detection. A principled negative log-likelihood loss function produces well-calibrated uncertainty estimates, which are validated through sharpness and calibration metrics. The system adapts RAIM (originally developed for GPS) to detect and reject faulty predictions by checking geometric consistency with runway constraints, enhancing reliability for aviation applications.

## Method Summary
The method employs a spatial Soft Argmax (SAM) operator to extract sub-pixel keypoint coordinates from CNN feature maps without requiring complex decoder architectures. The model predicts both keypoint locations (μ) and heteroscedastic uncertainties (σ²) per coordinate, trained jointly with a negative log-likelihood loss that balances accuracy and calibration. Runtime assurance is provided by adapting RAIM to check geometric consistency: after pose estimation, known 3D runway points are reprojected to image space, and the weighted residual norm is tested against a chi-squared distribution to detect faults. The system was evaluated on the LARD dataset using ResNet18/50 and EfficientNet backbones, achieving mean absolute pixel errors as low as 0.5 pixels with well-calibrated uncertainty estimates.

## Key Results
- Sub-pixel precision achieved: mean absolute pixel error as low as 0.5 pixels (SAM vs 1.46-10.59 pixels for FC baselines)
- Well-calibrated uncertainty estimates validated through calibration curves approaching identity function
- RAIM-based integrity monitoring effectively detects artificially mispredicted keypoints through chi-squared residual analysis
- Real-time performance: 30-60 Hz inference across different CNN backbones

## Why This Works (Mechanism)

### Mechanism 1: Soft Argmax for Sub-Pixel Keypoint Regression
- Claim: The spatial Soft Argmax operator enables efficient, sub-pixel precision coordinate regression from low-resolution CNN feature maps without requiring complex decoder architectures.
- Mechanism: SAM converts CNN feature map activations into a probability distribution via spatial softmax, then computes the expected coordinate as a weighted average of grid positions. This provides differentiable, continuous outputs that bypass quantization limits of the feature map resolution.
- Core assumption: The CNN backbone produces spatially-organized feature maps where activation patterns encode keypoint locations with sufficient spatial precision.
- Evidence anchors:
  - [abstract] "efficient, flexible neural architecture based on a spatial Soft Argmax operator for probabilistic keypoint regression...enabling real-time inference"
  - [section IV-A] Equations 3-5 formalize the SAM computation; Table I shows SAM achieving 0.50-0.80 pixel error vs 1.46-10.59 for fully-connected baselines
  - [corpus] Limited direct validation; neighbor papers focus on conformal prediction (33291) rather than SAM-based regression

### Mechanism 2: Negative Log-Likelihood Loss for Calibrated Uncertainty
- Claim: Optimizing the heteroscedastic Gaussian NLL loss produces predictive uncertainty estimates that are calibrated to actual error frequencies.
- Mechanism: The loss function (Equation 6) combines an accuracy term (weighted squared error) with a penalty term (log variance), forcing the network to output large uncertainties for difficult predictions while penalizing overconfident errors.
- Core assumption: Keypoint localization errors follow a Gaussian distribution, motivated by the Central Limit Theorem applied to multiple independent error sources (camera noise, discretization, lighting, model approximation).
- Evidence anchors:
  - [abstract] "principled loss function producing calibrated predictive uncertainties, which are evaluated via sharpness and calibration metrics"
  - [section IV-B] Figure 4a shows calibration curve approaching identity function; section notes "good calibration results...justify the Gaussian model assumption"
  - [corpus] Paper 41731 discusses uncertainty quantification enhancement using environmental conditions; complementary but not directly validating NLL approach

### Mechanism 3: RAIM-Based Integrity Monitoring via Geometric Consistency
- Claim: Residual-based RAIM can detect faulty keypoint predictions by identifying geometric inconsistencies between predicted keypoints and known runway geometry.
- Mechanism: After pose estimation, known 3D runway points are reprojected into image space. The weighted residual norm (corrected by predicted uncertainties and projection sensitivity) follows a chi-squared distribution under nominal conditions. Off-nominal predictions produce residuals exceeding the theoretical distribution.
- Core assumption: Prediction errors follow predicted Gaussian distributions in nominal cases; faulty predictions create geometric inconsistencies that no physically plausible pose can simultaneously satisfy.
- Evidence anchors:
  - [abstract] "adaptation of Residual-based Receiver Autonomous Integrity Monitoring (RAIM), enabling runtime detection and rejection of faulty model outputs"
  - [section IV-C] Algorithm 1 formalizes the chi-squared test; Figure 5 shows clear separation between nominal and artificially mispredicted cases
  - [corpus] Paper 33291 applies conformal prediction to runway detection—alternative statistical approach with different guarantees

## Foundational Learning

- Concept: Pose-from-N-Points (PnP) optimization
  - Why needed here: The integrity monitoring mechanism requires understanding how 2D keypoint correspondences map to 3D pose estimation, and why inconsistent predictions create large reprojection residuals.
  - Quick check question: If you have four runway corners detected in an image but one is mislocalized by 50 pixels, will the PnP solution perfectly fit all four points?

- Concept: Calibration vs. Sharpness trade-off in probabilistic prediction
  - Why needed here: The paper optimizes for both calibrated uncertainties (predicted probability matches empirical frequency) and sharp predictions (narrow confidence intervals); understanding this distinction is essential for interpreting Figure 4.
  - Quick check question: A model predicts "50% chance of rain" every day of the year and it rains exactly 50% of days. Is this model calibrated? Is it sharp?

- Concept: Chi-squared distribution for residual-based hypothesis testing
  - Why needed here: RAIM relies on the statistical property that sum-of-squared Gaussian residuals follows χ²; understanding this enables proper threshold selection for fault detection.
  - Quick check question: If predicted uncertainties are systematically 2× too small, what happens to the chi-squared test statistic and false alarm rate?

## Architecture Onboarding

- Component map:
  - Input: 224×224 cropped runway image → CNN backbone (ResNet18/50, EfficientNet) → feature tensor F ∈ R^(H'×W'×C')
  - Head 1 (coordinates): 1×1 conv → K heatmaps → SAM operator → μ_k = (x̂_k, ŷ_k) for each keypoint
  - Head 2 (uncertainties): Global pool → Linear layer → exp() → σ_x,k, σ_y,k
  - Runtime assurance: PnP solver → reprojection → residual computation → χ² test → ACCEPT/REJECT

- Critical path:
  1. Image preprocessing (cropping strategy is essential—runway must fit in crop)
  2. SAM coordinate extraction (parameter-free, but depends on feature map quality)
  3. NLL training (joint optimization of accuracy and calibration)
  4. RAIM threshold selection (trade-off between false alarms and fault detection sensitivity)

- Design tradeoffs:
  - Backbone choice: ResNet18 (fastest, 60 Hz) vs EfficientNet B5 (best accuracy, 0.50 px error)
  - Calibration post-processing: Paper suggests 20% variance scaling for conservative safety margins
  - RAIM threshold τ: Lower values increase sensitivity but raise false alarm rate

- Failure signatures:
  - Correlated keypoint errors: RAIM cannot detect faults if all keypoints are biased similarly
  - Out-of-distribution inputs: Uncertainty estimates only reliable for in-distribution data; off-nominal conditions may produce confident but wrong predictions
  - Low altitude/approach angles: PnP problem becomes numerically sensitive to small localization errors

- First 3 experiments:
  1. Reproduce Table I: Train ResNet18+SAM vs FC baseline on LARD subset, verify sub-pixel precision and NLL improvement
  2. Calibration analysis: Plot calibration curves (Figure 4a style) and implement 20% variance scaling; verify improved coverage
  3. RAIM fault injection: Implement Algorithm 1, inject systematic keypoint shifts (e.g., 184m offset per Figure 5), measure detection rate vs threshold τ

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the pipeline's calibration and integrity monitoring performance translate to real-world flight data compared to the simulated LARD dataset?
- Basis in paper: [explicit] The authors state in the conclusion that "further studies are necessary to validate the success of our model in real-world images" despite testing on LARD.
- Why unresolved: The current validation relies on a dataset that may not capture the full complexity of physical sensors and environmental conditions.
- What evidence would resolve it: Evaluation results showing calibration curves and RAIM detection rates on data collected from actual aircraft landing approaches.

### Open Question 2
- Question: How can the integrity monitoring approach be adapted to remain effective when pixel errors across different keypoints are highly correlated?
- Basis in paper: [explicit] The authors note that the performance of the RAIM algorithm "degrades as the correlation in the pixel errors of each keypoint increases," potentially allowing faulty measurements to go undetected.
- Why unresolved: The current method relies on statistical independence assumptions that break down in the presence of systematic errors affecting multiple keypoints simultaneously.
- What evidence would resolve it: A modified algorithm or detection metric that successfully identifies faulty predictions even when errors are perfectly correlated.

### Open Question 3
- Question: Can this architecture and assurance methodology generalize effectively to other perception-based safety-critical domains beyond aviation runway detection?
- Basis in paper: [explicit] The conclusion calls for "further work investigating the interplay of the proposed prediction and integrity monitoring approaches with other types of prediction models and real-world problem settings."
- Why unresolved: The method is tailored to the geometric constraints of runway approaches; its utility in less structured or dynamically different environments is unproven.
- What evidence would resolve it: Successful application of the Soft Argmax and RAIM adaptation pipeline to domains like autonomous driving or maritime navigation.

## Limitations
- The RAIM integrity monitoring degrades with correlated keypoint errors, potentially missing systematic faults affecting multiple points simultaneously
- Performance relies on accurate camera intrinsics and runway geometry that are not publicly available, limiting reproducibility
- The Gaussian error assumption for NLL loss is not empirically validated across diverse error distributions and lighting conditions

## Confidence
- **High Confidence**: SAM operator enabling sub-pixel regression (supported by Table I comparisons showing 0.5-0.8px vs 1.46-10.59px for FC baselines)
- **Medium Confidence**: Gaussian NLL loss producing calibrated uncertainties (calibration curves show good results but limited distribution testing)
- **Medium Confidence**: RAIM fault detection effectiveness (clear separation in Figure 5 but limited to injected faults)
- **Low Confidence**: Runtime performance claims (60 Hz with ResNet18 not independently verified)

## Next Checks
1. **Error Distribution Analysis**: Perform Kolmogorov-Smirnov tests comparing keypoint localization errors against Gaussian distribution across different lighting/altitude conditions in LARD dataset to validate the NLL loss assumption.

2. **Correlation Sensitivity Test**: Inject synthetic keypoint errors with varying correlation structures (independent vs. perfectly correlated) and measure RAIM detection rates to quantify the impact of error correlation on integrity monitoring effectiveness.

3. **Cross-Dataset Generalization**: Evaluate the trained model on a different runway dataset (e.g., public airport imagery) without fine-tuning to assess robustness to domain shifts and verify uncertainty calibration holds for out-of-distribution inputs.