---
ver: rpa2
title: 'QDeepGR4J: Quantile-based ensemble of deep learning and GR4J hybrid rainfall-runoff
  models for extreme flow prediction with uncertainty quantification'
arxiv_id: '2510.05453'
source_url: https://arxiv.org/abs/2510.05453
tags:
- flood
- https
- learning
- ensemble
- quantile
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes QDeepGR4J, a quantile-based ensemble framework
  that combines a hybrid rainfall-runoff model with quantile regression to improve
  extreme flow prediction and uncertainty quantification. The approach extends DeepGR4J
  by integrating the GR4J conceptual model's production storage with quantile regression-based
  deep neural networks (LSTM) to predict multiple streamflow quantiles, enabling the
  construction of 90% confidence intervals.
---

# QDeepGR4J: Quantile-based ensemble of deep learning and GR4J hybrid rainfall-runoff models for extreme flow prediction with uncertainty quantification

## Quick Facts
- arXiv ID: 2510.05453
- Source URL: https://arxiv.org/abs/2510.05453
- Reference count: 40
- Primary result: LSTM-based QDeepGR4J ensemble outperforms baseline deep learning models in predictive accuracy and interval score for extreme flow prediction with uncertainty quantification

## Executive Summary
QDeepGR4J introduces a quantile-based ensemble framework that combines the GR4J conceptual rainfall-runoff model with quantile regression-based deep neural networks (LSTM) to improve extreme flow prediction and uncertainty quantification. The approach extends DeepGR4J by integrating the GR4J production storage's physically-interpretable features with quantile regression to predict multiple streamflow quantiles, enabling the construction of 90% confidence intervals. Evaluated on the CAMELS-Aus dataset across Australian catchments, the framework demonstrates superior performance over baseline deep learning models in terms of predictive accuracy (RMSE/NSE) and interval score, while providing better flood risk indicator performance. The model is particularly suitable for early flood warning systems by capturing uncertainty in multi-step streamflow forecasts.

## Method Summary
QDeepGR4J employs a two-stage optimization approach: first calibrating GR4J parameters (X1-X4) via differential evolution, then training quantile-based LSTM networks on hybrid features that combine meteorological inputs with GR4J production storage states. The model generates three quantile predictions (τ=0.05, 0.50, 0.95) using tilted loss functions, creating 90% confidence intervals. The framework uses a 7-day sliding window on normalized CAMELS-Aus data, with 60% training and 40% test splits. This hybrid approach leverages physics-guided feature engineering through GR4J while capturing aleatoric uncertainty through quantile regression, outperforming pure data-driven approaches in both accuracy and uncertainty quantification.

## Key Results
- LSTM-based QDeepGR4J achieves NSE of 0.6650 on SA stations vs. 0.4660 for baseline LSTM
- Interval score of 0.4198 for LSTM-based QDeepGR4J vs. 0.4247 for CNN baseline
- 90% confidence intervals successfully capture extreme flow events while providing uncertainty quantification
- Flood risk indicator performance demonstrates practical utility for early warning systems

## Why This Works (Mechanism)

### Mechanism 1: Physics-Guided Feature Engineering via GR4J Production Storage
Hybridizing conceptual model outputs with deep learning improves extreme flow prediction over pure data-driven approaches. The GR4J production storage computes intermediate hydrological states (net precipitation P_n, effective precipitation P_s, percolation Perc) that encode catchment water balance dynamics. These physically-interpretable features are concatenated with raw meteorological inputs before being passed to the neural network, providing inductive bias toward hydrologically plausible predictions.

### Mechanism 2: Quantile Regression with Tilted Loss for Distributional Prediction
Training separate neural networks for different quantiles enables construction of calibrated prediction intervals that capture aleatoric uncertainty. Rather than predicting the conditional mean, each network minimizes the tilted (pinball) loss that asymmetrically penalizes over- and under-prediction based on quantile τ. Three networks (τ ∈ {0.05, 0.50, 0.95}) are trained independently, yielding lower bound, median, and upper bound predictions for a 90% confidence interval.

### Mechanism 3: Hierarchical Two-Stage Optimization (Evolutionary + Gradient-Based)
Separating conceptual model calibration from neural network training enables efficient optimization of heterogeneous parameter types. Stage 1 uses differential evolution (gradient-free) to optimize GR4J's four parameters against historical streamflow. Stage 2 freezes these parameters and trains neural network weights via Adam optimizer with backpropagation. This avoids mixing discrete evolutionary search with continuous gradient descent.

## Foundational Learning

- **Quantile regression vs. mean regression**: Understanding why asymmetric loss functions enable tail behavior modeling is essential for interpreting the three-network ensemble design. Quick check: If τ=0.95 and prediction underestimates the true value, does the loss increase or decrease compared to τ=0.50?

- **LSTM memory cells for multi-step temporal dependencies**: The paper finds LSTM outperforms CNN for quantile prediction due to better long-term dependency capture. Quick check: Why would an LSTM retain information about a precipitation event from 7 days ago better than a CNN?

- **GR4J production storage water balance**: The hybrid features derive from production storage equations. Quick check: What happens to percolation (Perc) when production storage S approaches capacity X1?

## Architecture Onboarding

- **Component map**: Meteorological inputs -> GR4J production storage -> Hybrid features -> 7-day windowing -> Three parallel LSTM networks (τ=0.05, 0.50, 0.95) -> Streamflow quantiles -> 90% confidence interval -> Flood risk indicator

- **Critical path**: 1) Calibrate GR4J (X1-X4) via differential evolution on training period, 2) Generate production storage features and concatenate with meteorological data, 3) Train three quantile networks with tilted loss using Adam, 4) Evaluate via RMSE/NSE (median) and interval score (bounds)

- **Design tradeoffs**: LSTM vs CNN - LSTM better for multi-step quantile prediction (long-term memory); CNN was superior in prior single-step mean prediction work. Quantile count - Three quantiles balance computational cost with uncertainty resolution; more quantiles increase training overhead. Window size - 7 days chosen empirically; longer windows increase memory but may capture antecedent moisture conditions

- **Failure signatures**: Overestimated upper bounds - Figure 5 shows Q̂_0.95 peaks significantly above observations, causing false-positive flood alerts. Widening intervals in multi-step - Uncertainty bounds expand for t+2, t+3 predictions, reducing operational utility. Poor extreme event TPR - 10-year flood detection drops sharply, indicating limited extrapolation to rare events

- **First 3 experiments**: 1) Baseline comparison - Replicate Table 1 results on SA stations with MLP, RNN, CNN, LSTM architectures; verify LSTM achieves lowest interval score (~0.42), 2) Ablation on hybrid features - Train quantile LSTM with only meteorological inputs vs. full hybrid feature set; quantify NSE degradation to isolate production storage contribution, 3) Quantile crossing analysis - On held-out test set, count instances where Q̂_0.95 < Q̂_0.05 or Q̂_0.50; if >1% of predictions cross, implement non-crossing constraint from Bondell et al. (2010)

## Open Questions the Paper Calls Out

- **Ungauged basins extension**: Can the QDeepGR4J framework be effectively extended to ungauged basins to provide reliable flood risk assessment without local streamflow records? The current methodology relies on catchment-specific training where GR4J parameters are calibrated and neural networks are trained on observed streamflow data.

- **Advanced architectures**: Would incorporating attention mechanisms into the deep learning component improve the capture of long-term temporal dependencies compared to the current LSTM implementation? The study evaluated CNN and LSTM architectures but did not assess attention-based models.

- **Hybrid uncertainty quantification**: Can a hybrid approach combining Bayesian inference for parameter uncertainty with quantile regression for data variability provide a more complete uncertainty quantification? The current quantile regression approach captures aleatoric (data) uncertainty but fails to explicitly model epistemic (model/parameter) uncertainty.

## Limitations

- Quantile crossing: The model lacks explicit handling for cases where predicted upper bounds fall below median predictions, invalidating confidence intervals.
- Extreme event overestimation: Systematic overestimation of upper quantile peaks leads to false-positive flood alerts, with substantial performance gaps for 10-year flood detection.
- Empirical window size: The 7-day window size is chosen without sensitivity analysis, and the multi-step strategy remains unspecified.

## Confidence

**High Confidence**: The hybrid feature engineering mechanism (GR4J production storage) demonstrably improves median accuracy (NSE increases from 0.4660 to 0.6650 on SA stations). The quantile regression framework with tilted loss is theoretically sound and correctly implemented for interval construction.

**Medium Confidence**: The differential evolution + gradient descent optimization strategy is plausible but lacks ablation studies to isolate the contribution of the two-stage approach. The claim that LSTM outperforms CNN specifically for quantile prediction needs direct comparison on the same dataset.

**Low Confidence**: The flood risk indicator performance claims are not independently verified, and the mechanism explaining why quantile ensembles capture aleatoric uncertainty better than point prediction methods is underspecified.

## Next Checks

1. **Quantile Crossing Analysis**: On the test set, systematically count instances where Q̂₀.₉₅ < Q̂₀.₀₅ or Q̂₀.₅₀. Implement non-crossing constraints (Bondell et al., 2010) and measure impact on interval score and calibration.

2. **Extreme Event Sensitivity**: Extract top 1% flow events from the test set. Compare detection rates and prediction accuracy for these events between QDeepGR4J and baseline models. Analyze whether overestimation stems from quantile regression or GR4J feature limitations.

3. **Window Size Sensitivity**: Re-run experiments with window sizes α ∈ {3, 5, 7, 10, 14}. Plot NSE and interval score as functions of window length to identify optimal temporal context for Australian catchments.