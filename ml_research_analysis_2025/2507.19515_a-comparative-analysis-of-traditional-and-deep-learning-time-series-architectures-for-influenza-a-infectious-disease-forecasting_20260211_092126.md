---
ver: rpa2
title: A Comparative Analysis of Traditional and Deep Learning Time Series Architectures
  for Influenza A Infectious Disease Forecasting
arxiv_id: '2507.19515'
source_url: https://arxiv.org/abs/2507.19515
tags:
- influenza
- arima
- cases
- time
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study presents a comparative analysis of traditional statistical
  and deep learning models for forecasting Influenza A outbreaks using historical
  data from January 2009 to December 2023. The research compares ARIMA and Exponential
  Smoothing (ETS) models against six deep learning architectures: Simple RNN, LSTM,
  GRU, BiLSTM, BiGRU, and Transformer.'
---

# A Comparative Analysis of Traditional and Deep Learning Time Series Architectures for Influenza A Infectious Disease Forecasting

## Quick Facts
- **arXiv ID:** 2507.19515
- **Source URL:** https://arxiv.org/abs/2507.19515
- **Reference count:** 40
- **Primary result:** Transformer architecture achieved average testing MSE of 0.0433 ± 0.0020 and MAE of 0.1126 ± 0.0016, outperforming traditional ARIMA and ETS models for Influenza A forecasting

## Executive Summary
This study compares traditional statistical models (ARIMA and Exponential Smoothing) against six deep learning architectures for forecasting Influenza A outbreaks using historical data from January 2009 to December 2023. The research finds clear superiority of deep learning models, particularly the Transformer, which demonstrates significantly better predictive accuracy. The findings indicate that state-of-the-art deep learning architectures can better capture the temporal complexities and non-linear dynamics of infectious disease data compared to traditional methods. The study recommends incorporating Transformer models into real-time forecasting and preparedness systems for epidemic-level surveillance.

## Method Summary
The study utilizes monthly Influenza A data from Our World in Data spanning January 2009 to December 2023. Models are trained on 168 months (2009-2022) and tested on 12 months (2023). Traditional baselines include SARIMA(0,1,3)(0,0,1)[12] and Holt-Winters ETS. Deep learning architectures include Simple RNN, LSTM, GRU, BiLSTM, BiGRU, and Transformer. The Transformer uses 4 layers, 3 attention heads, embedding size 64, feed-forward dimension 128, and 30% dropout. All models are trained with Adam optimizer (learning rate 0.001), batch size 32, for 50 epochs.

## Key Results
- Transformer achieved the lowest average testing MSE (0.0433) and MAE (0.1126) among all models tested
- Traditional ARIMA and ETS models failed diagnostic tests for residual independence and constant variance
- Gated architectures (LSTM, GRU) significantly outperformed Simple RNN, demonstrating the importance of gradient flow preservation
- Deep learning models better captured non-linear anomalies and heteroscedasticity in recent Influenza A trends

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Transformer architectures capture long-range seasonal dependencies and non-linear dynamics in Influenza A data more effectively than recurrent or autoregressive baselines
- **Mechanism:** The self-attention mechanism allows the model to weigh the importance of specific historical months (e.g., previous seasonal peaks) regardless of their distance in the time window, bypassing the sequential processing bottleneck of RNNs
- **Core assumption:** The superior performance stems from the architectural capacity to model global interactions rather than just local sequential patterns
- **Evidence anchors:**
  - Transformer achieved the lowest average testing MSE (0.0433) and MAE (0.1126)
  - The study notes the Transformer "generalizes well on unseen data" and attributes deep learning success to better processing of "sequential information"
- **Break condition:** Performance degrades significantly if the dataset is too small for the attention mechanism to learn meaningful global weights, or if the seasonal patterns shift radically beyond the historical distribution

### Mechanism 2
- **Claim:** Gated architectures (LSTM/GRU) mitigate the vanishing gradient problem, allowing for effective learning over the 168-month training sequence compared to Simple RNNs
- **Mechanism:** The specific gate structures (update/reset gates in GRU; forget/input gates in LSTM) regulate the flow of information, allowing the network to "remember" relevant long-term trends while "forgetting" irrelevant noise
- **Core assumption:** The improvement is due to gradient flow preservation during backpropagation through time, rather than just increased parameter count
- **Evidence anchors:**
  - Table 13 shows Simple RNN has higher training MSE (0.0065) compared to LSTM (0.0039) and GRU (0.0044)
  - The text defines the gate equations, noting LSTMs offer a "robust solution to the notorious vanishing / gradient issue"
- **Break condition:** If the inference horizon exceeds the effective memory span of the gates, or if the gating mechanism becomes saturated due to unnormalized inputs

### Mechanism 3
- **Claim:** Traditional statistical models (ARIMA/ETS) fail to capture the heteroscedasticity and non-linear anomalies present in recent Influenza A trends
- **Mechanism:** ARIMA and ETS rely on rigid assumptions of stationarity and constant variance. The Influenza data contains extreme outliers and non-normal residuals, violating these assumptions
- **Core assumption:** The poor performance is a result of model misspecification regarding the variance structure of the residuals
- **Evidence anchors:**
  - Table 5 shows the ETS model failing the Ljung-Box and Goldfeld-Quandt tests (p-value 0.000), indicating non-independent residuals and non-constant variance
  - Table 10 confirms the best ARIMA model also violates normality and constant variance assumptions
- **Break condition:** If the data were pre-processed to remove anomalies or transformed to enforce stationarity and homoscedasticity, traditional models might serve as viable baselines

## Foundational Learning

- **Concept: Stationarity vs. Seasonality**
  - **Why needed here:** The study explicitly tests for stationarity using the KPSS test and seasonality using Kruskal-Wallis. Understanding that deep learning models often handle non-stationary data better than ARIMA (which requires differencing) is crucial for interpreting the results
  - **Quick check question:** If a time series has a changing variance over time (heteroscedasticity), would an ARIMA model still be theoretically appropriate without transformation?

- **Concept: Teacher Forcing & Sequence Generation**
  - **Why needed here:** Section 4.5 mentions converting data into sequences (e.g., 12 months input → 1 month output) for the Transformer. This "sliding window" approach is how deep learning models frame time series as a supervised learning problem
  - **Quick check question:** How does creating overlapping sequences of length 12 change the effective size of the training dataset compared to using the raw time series directly?

- **Concept: Hyperparameter Sensitivity**
  - **Why needed here:** The authors tuned units (16-512), batch size, and optimizers. The "superiority" of the Transformer is conditional on this extensive tuning; a default Transformer might underperform a tuned ARIMA
  - **Quick check question:** Why might a larger batch size (e.g., 128) hinder the model's ability to converge compared to a smaller batch size (e.g., 16/32) for this specific monthly dataset?

## Architecture Onboarding

- **Component map:** MinMaxScaler (0-1) → Sequence Generator (Lookback=12) → Deep Learning Core (RNN/Transformer Track) → TimeDistributed Dense Layer → Inverse Transform (Rescaling)

- **Critical path:**
  1. **Data Integrity:** Address the 2020-2021 missing data gap and 2022 anomalies
  2. **Differencing (ARIMA only):** Apply first-order differencing to satisfy stationarity
  3. **Scaling (DL only):** Apply MinMaxScaler to ensure gradient stability
  4. **Sequence Creation:** Transform series into [X_t, ..., X_t+11] → X_t+12 tensors

- **Design tradeoffs:**
  - **Interpretability vs. Accuracy:** ARIMA provides clear coefficients and statistical significance; Transformers offer high accuracy but act as "black boxes"
  - **Forward vs. Bidirectional:** BiLSTM/BiGRU captures context from both past and future (within the training window), potentially learning patterns unidirectional models miss, at the cost of double computation
  - **Data Efficiency:** Transformers typically require more data than RNNs; this study uses 168 training months, which is on the lower end for Transformer stability, necessitating the rigorous hyperparameter tuning

- **Failure signatures:**
  - **ARIMA Failure:** High AIC values or failed Ljung-Box/Goldfeld-Quandt tests, indicating the model cannot explain the variance (residuals are not white noise)
  - **Simple RNN Failure:** Validation loss plateaus early or "forgets" long-term trends
  - **Overfitting:** Training MSE is near zero while Testing MSE is high; the study mitigates this with 30% Dropout

- **First 3 experiments:**
  1. **Baseline Establishment:** Fit SARIMA(0,1,3)(0,0,1)[12] to the differenced data to confirm the "floor" for performance and check residual diagnostics
  2. **Gated Model Comparison:** Train LSTM vs. GRU with identical window sizes (12 months) and units (64). Compare training speed and MAE to see if the extra complexity of LSTM is justified over the simpler GRU
  3. **Transformer Validation:** Implement the Transformer with the paper's specified hyperparameters (Heads=3, Layers=4). Run predictions on the specific 2023 test set and verify if MSE ≈ 0.0433

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can Transformer architectures be effectively incorporated into real-time forecasting and epidemic preparedness systems?
- **Basis in paper:** The abstract and conclusion explicitly state that "Future work should focus on how these models can be incorporated into real-time forecasting and preparedness systems"
- **Why unresolved:** The current study validates the model's predictive accuracy on historical datasets but does not address the operational deployment or latency requirements of a live forecasting system
- **What evidence would resolve it:** A successful pilot study where the model operates in a live environment, providing actionable forecasts with low latency for public health decision-making

### Open Question 2
- **Question:** How can these deep learning models be integrated with existing surveillance systems like the CDC's ILI network?
- **Basis in paper:** The authors explicitly recommend investigating how these models can be "integrated into existing surveillance systems"
- **Why unresolved:** The paper focuses on model architecture and performance metrics rather than the technical or logistical challenges of interoperating with legacy public health databases
- **What evidence would resolve it:** Demonstration of a software pipeline that automatically ingests surveillance data and outputs forecasts directly into existing public health dashboards

### Open Question 3
- **Question:** Does the inclusion of exogenous variables (e.g., temperature, humidity, air pollution) improve the forecasting accuracy of the Transformer model beyond the univariate approach?
- **Basis in paper:** Page 9 notes that the residual component of the time series may be influenced by "external factors (such as temperature, humidity, air pollution, etc) not included in the analysis"
- **Why unresolved:** The study utilized a univariate time series approach, leaving the potential performance gains from including environmental or demographic covariates untested
- **What evidence would resolve it:** A comparative study where a multivariate Transformer model is trained and tested against the univariate baseline using the same dataset

## Limitations
- Small test set (12 months) and lack of external validation on out-of-sample years limit generalizability
- 2020-2021 data gap is not addressed in the methodology, potentially introducing bias
- Computational cost of Transformer models versus simpler baselines is not discussed, which could impact real-world deployment feasibility

## Confidence
- **High Confidence:** Transformer's superior MSE/MAE performance compared to ARIMA/ETS on the given dataset
- **Medium Confidence:** The claim that deep learning architectures better capture "temporal complexities" is supported by results but lacks ablation studies isolating specific architectural advantages
- **Low Confidence:** The assertion that these findings represent a "broader trend" toward deep learning for public health forecasting, as this requires longitudinal studies across multiple diseases and institutions

## Next Checks
1. **External Validation:** Apply the trained Transformer to influenza data from a different geographical region or time period (e.g., 2024 data) to test generalization
2. **Ablation Study:** Compare Transformer performance with and without positional encoding, and with reduced attention heads, to isolate the contribution of self-attention to the accuracy gains
3. **Cost-Benefit Analysis:** Measure the computational resources (training time, GPU memory) required for the Transformer versus ARIMA to assess practical deployment viability