---
ver: rpa2
title: Street-Level Geolocalization Using Multimodal Large Language Models and Retrieval-Augmented
  Generation
arxiv_id: '2509.01341'
source_url: https://arxiv.org/abs/2509.01341
tags:
- image
- images
- geolocation
- wang
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates that open-weight multimodal large language
  models, when integrated with retrieval-augmented generation and a hybrid vector
  database of user-generated and street-view imagery, can achieve state-of-the-art
  street-level geolocalization accuracy without the need for fine-tuning. By combining
  the SigLIP encoder with the Qwen2-VL-72B-Instruct model, the approach retrieves
  both similar and dissimilar geolocation information from a database of over 10 million
  images to enhance prompts for location estimation.
---

# Street-Level Geolocalization Using Multimodal Large Language Models and Retrieval-Augmented Generation

## Quick Facts
- **arXiv ID:** 2509.01341
- **Source URL:** https://arxiv.org/abs/2509.01341
- **Authors:** Yunus Serhat Bicakci; Joseph Shingleton; Anahid Basiri
- **Reference count:** 40
- **Primary result:** Open-weight MLLMs with RAG achieve state-of-the-art street-level geolocalization accuracy without fine-tuning.

## Executive Summary
This paper presents a novel approach to street-level geolocalization that leverages frozen multimodal large language models (MLLMs) augmented with retrieval-augmented generation (RAG). By combining the SigLIP image encoder with Qwen2-VL-72B-Instruct, the system retrieves both similar and dissimilar geolocation information from a hybrid vector database of over 10 million images to enhance prompts for location estimation. The method achieves superior street-level accuracy on benchmark datasets (IM2GPS, IM2GPS3k, YFCC4k) without requiring fine-tuning or external APIs, demonstrating that MLLMs can perform precise geolocation tasks through context alone.

## Method Summary
The approach constructs a hybrid vector database by encoding 4.6M user-generated photos (EMP-16) and 5.2M street-view images (OSV-5M) using the SigLIP encoder, stored in a Faiss index. For each query image, the system retrieves 16 most similar and 16 most dissimilar geolocations based on L2 distance in embedding space. These coordinates are incorporated into a structured prompt fed to a frozen Qwen2-VL-72B-Instruct or InternVL2-76B MLLM running inference via vLLM/LMDeploy. The model predicts GPS coordinates without fine-tuning, which are evaluated against ground truth using GeoPy to calculate distance-based accuracy thresholds.

## Key Results
- Achieves state-of-the-art street-level accuracy on YFCC4k (24.3%) and competitive results on IM2GPS (23.2%) and IM2GPS3k (17.1%)
- Eliminates need for expensive fine-tuning or external APIs like GPT-4V
- Demonstrates superior performance through hybrid database and contrastive retrieval approach
- Maintains high accuracy across multiple distance thresholds (1km to continent level)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Retrieving both similar and dissimilar images from a vector database improves geolocation estimation by providing contrastive context to the MLLM.
- **Mechanism:** The system retrieves 16 nearest and 16 farthest neighbors in SigLIP embedding space (L2 distance). Similar images offer positive location cues (landmarks, architecture); dissimilar images provide negative context, helping the model exclude visually distinct regions. This contrastive prompting aligns with how contrastive vision-language models are trained.
- **Core assumption:** MLLMs can reason over juxtaposed geographic coordinates to narrow down probable locations more effectively than with similar-only retrieval.
- **Evidence anchors:** [abstract] "Query images are augmented with prompts containing both similar and dissimilar geolocation information retrieved from this database"; [section III] "The rationale for including both similar and dissimilar geolocations is twofold... dissimilar geolocations serve as negative contexts, helping to clarify which visual or geographic features are absent"

### Mechanism 2
- **Claim:** A hybrid vector database combining user-generated and street-view imagery broadens geographic and environmental coverage, improving retrieval relevance for diverse query types.
- **Mechanism:** The authors merge EMP-16 (4.6M user photos) with OSV-5M (5.2M street-view images), encoding all with SigLIP into a unified embedding space. This hybrid gallery addresses the domain gap between curated street-view and spontaneous user photography, offering more retrieval options for varied scenes.
- **Core assumption:** The combined dataset sufficiently covers the geographic and visual diversity of benchmark queries; embedding quality translates directly to retrieval usefulness.
- **Evidence anchors:** [section III.A] "By merging everyday user-generated photos with structured street-view imagery, we build a hybrid vector database that offers broader coverage of real-world environments"

### Mechanism 3
- **Claim:** Large frozen MLLMs can perform precise geolocation without fine-tuning when augmented with retrieved geographic context.
- **Mechanism:** Frozen Qwen2-VL-72B-Instruct and InternVL2-76B receive the query image plus a prompt with 32 retrieved coordinates (16 similar, 16 dissimilar). The MLLM uses its pretrained visual-linguistic reasoning to integrate these cues and predict coordinates. No gradient updates occur; adaptation is purely via context.
- **Core assumption:** The MLLM's pretrained world knowledge and reasoning capabilities are sufficient to interpret geographic prompts accurately; quantization (AWQ/GPTQ) does not critically degrade this ability.
- **Evidence anchors:** [abstract] "eliminates the need for expensive fine-tuning or retraining"; [section IV] Results show state-of-the-art street-level accuracy on YFCC4k (24.3%) and competitive results on IM2GPS (23.2%) and IM2GPS3k (17.1%)

## Foundational Learning

- **Concept:** Vector similarity search and embedding spaces
  - **Why needed here:** The system relies on SigLIP embeddings and Faiss L2-distance retrieval; understanding how embeddings encode visual-semantic similarity is essential for debugging retrieval quality.
  - **Quick check question:** Can you explain why two images of the same landmark might have a larger L2 distance than two images of different landmarks, and how this would affect retrieval?

- **Concept:** Retrieval-Augmented Generation (RAG)
  - **Why needed here:** The core pipeline is RAG-based—retrieved coordinates augment the MLLM prompt. Understanding RAG helps diagnose whether failures stem from retrieval or generation.
  - **Quick check question:** What happens to RAG system output if the retrieval step returns irrelevant documents? How would you detect this failure mode?

- **Concept:** Multimodal Large Language Model (MLLM) inference
  - **Why needed here:** Implementation uses vLLM/LMDeploy with quantized 70B+ parameter models; understanding inference constraints (memory, token limits, temperature) is critical for reproduction.
  - **Quick check question:** Why might a low temperature (0.1) be preferred for a geolocation task versus an open-ended creative task?

## Architecture Onboarding

- **Component map:** Query image → SigLIP embedding → Faiss retrieval (16 nearest + 16 farthest) → Prompt construction → MLLM inference → Coordinate extraction → Distance evaluation
- **Critical path:** The pipeline flows from image encoding through retrieval, prompt assembly, MLLM inference, and post-processing. Latency is dominated by MLLM inference and Faiss search over 10M vectors.
- **Design tradeoffs:** Retrieving 16+16 neighbors balances context richness vs. prompt length/compute; fewer neighbors reduce contrastive signal, more increase overhead without proportional gains (empirically tested). Quantized models reduce GPU memory but may slightly reduce accuracy vs. full-precision. Hybrid database improves coverage but introduces potential label noise from user-generated images.
- **Failure signatures:** Very low street-level accuracy with high country-level accuracy suggests retrieval is finding correct regions but not precise locations—check embedding quality or database density. Predictions cluster around database coordinates without adaptation may indicate over-reliance on retrieved prompts rather than image content. Inconsistent outputs across runs may indicate temperature/top-p too high for deterministic tasks.
- **First 3 experiments:**
  1. Retrieval ablation: Compare accuracy with (a) 16 similar only, (b) 16 similar + 16 dissimilar, (c) varying neighbor counts (1, 5, 10, 20). Verify the 16+16 design choice on a held-out subset.
  2. Encoder comparison: Benchmark SigLIP vs. CLIP vs. StreetCLIP on retrieval relevance and downstream geolocation accuracy to validate encoder selection.
  3. Database coverage test: Evaluate performance on benchmark subsets stratified by geographic region to identify underrepresented areas where retrieval fails.

## Open Questions the Paper Calls Out

- **Question:** To what extent could fine-tuning the open-weight MLLMs on geospatial data improve accuracy compared to the current RAG-only approach, and does it justify the computational cost?
- **Basis in paper:** [explicit] The conclusion states, "while fine-tuning such large models is perceived to be highly resource-intensive and costly, attempting it could yield intriguing results."
- **Why unresolved:** The authors explicitly prioritized a no-training, inference-time approach to demonstrate cost-efficiency, leaving the potential performance ceiling of supervised fine-tuning untested.

## Limitations

- **Prompt template ambiguity:** The paper lacks explicit details on the exact prompt format used to present 32 retrieved coordinates to the MLLM, making exact reproduction challenging.
- **Dissimilar retrieval implementation:** The mechanism for efficiently retrieving "most dissimilar" (farthest L2 distance) images from a 10M+ vector database is not fully specified, suggesting potential approximation or custom implementation.
- **Geographic coverage validation:** While the hybrid database is claimed to improve coverage, there is no systematic evaluation of which geographic regions or environmental contexts are underrepresented.

## Confidence

- **High Confidence:** The core mechanism of using RAG with both similar and dissimilar retrievals is technically sound and supported by reasonable evidence. The implementation details for the SigLIP encoder and Faiss database are sufficiently specified for reproduction.
- **Medium Confidence:** The claim of state-of-the-art street-level accuracy is supported by benchmark results, but the ablation studies are limited. The superiority over fine-tuned models is demonstrated but not thoroughly explored across different query distributions.
- **Low Confidence:** The specific prompt engineering choices and their impact on performance remain uncertain due to lack of template disclosure and prompt ablation studies.

## Next Checks

1. **Prompt Template Ablation:** Systematically test variations in coordinate presentation format (JSON vs. natural language, decimal vs. DMS, ordering of similar/dissimilar pairs) to quantify sensitivity and optimize prompt design.
2. **Dissimilar Retrieval Validation:** Implement and compare multiple strategies for "most dissimilar" retrieval (true farthest neighbors, random sampling, centroid-based selection) and measure their impact on geolocation accuracy across different benchmark subsets.
3. **Geographic Coverage Analysis:** Stratify benchmark performance by geographic region and environmental context to identify systematic coverage gaps in the hybrid database, then measure whether targeted database expansion in underrepresented areas improves accuracy.