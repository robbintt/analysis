---
ver: rpa2
title: 'Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation
  and Human-in-the-Loop Refinement'
arxiv_id: '2508.04025'
source_url: https://arxiv.org/abs/2508.04025
tags:
- agent
- input
- arxiv
- wang
- decision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: RecAgent addresses perceptual and decision uncertainty in GUI agents
  by employing a component recommendation mechanism to filter relevant UI elements
  and an interactive module for user feedback in ambiguous scenarios. The agent integrates
  Planning, Decision, Reflection, and Interaction agents with a Component Recommendation
  Module and Memory Unit.
---

# Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement

## Quick Facts
- arXiv ID: 2508.04025
- Source URL: https://arxiv.org/abs/2508.04025
- Authors: Chao Hao; Shuai Wang; Kaiwen Zhou
- Reference count: 9
- Primary result: 47.8% task success rate on AndroidWorld, 69.3% on ComplexAction benchmarks

## Executive Summary
RecAgent addresses perceptual and decision uncertainty in GUI agents by employing a component recommendation mechanism to filter relevant UI elements and an interactive module for user feedback in ambiguous scenarios. The agent integrates Planning, Decision, Reflection, and Interaction agents with a Component Recommendation Module and Memory Unit. It uses multiple recommendation pathways (keyword, semantic, and LLM-based) to reduce input redundancy and a retrospection mechanism to handle failed actions. Experiments show RecAgent achieves 47.8% task success rate on AndroidWorld and 69.3% on ComplexAction, outperforming state-of-the-art methods.

## Method Summary
RecAgent employs a hierarchical agent architecture with Planning, Decision, Reflection, and Interaction agents, supported by a Component Recommendation Module (CRM) and Memory Unit. The CRM uses three pathways - Keyword Matching, Semantic Matching, and LLM-based - to filter relevant UI elements from screen data, reducing LLM input length and improving action accuracy. When uncertainty remains, the Interaction Agent engages users through a Human-in-the-Loop refinement mechanism. The Reflection Agent performs retrospection to analyze failed actions and guide recovery strategies. The system was evaluated on AndroidWorld and a newly introduced ComplexAction dataset for single-step action accuracy in complex GUI environments.

## Key Results
- RecAgent achieves 47.8% task success rate on AndroidWorld benchmark, outperforming existing GUI agents
- On ComplexAction dataset, RecAgent reaches 69.3% single-step action accuracy
- CRM significantly improves performance by filtering relevant components and reducing LLM input length
- Retrospection mechanism effectively handles failed actions through recovery strategies

## Why This Works (Mechanism)
RecAgent addresses fundamental limitations in GUI agents where high-dimensional screen data and ambiguous UI elements create decision uncertainty. The component recommendation module acts as a perception filter, reducing the search space for the Decision Agent and improving action accuracy. Multiple recommendation pathways provide redundancy and context-aware filtering, while the Human-in-the-Loop mechanism allows for interactive refinement when automated perception fails. The retrospection mechanism creates a feedback loop for learning from failures, enabling continuous improvement in complex GUI environments.

## Foundational Learning
- Component recommendation filtering: Reduces input dimensionality for LLMs by identifying relevant UI elements; quick check: measure input token reduction and correlation with accuracy gains
- Multi-pathway recommendation: Combines keyword, semantic, and LLM-based approaches for robust UI element selection; quick check: compare performance of individual pathways vs. combined approach
- Human-in-the-Loop refinement: Allows user intervention when automated perception is uncertain; quick check: measure query frequency and response quality impact on success rates
- Retrospection mechanism: Analyzes failed actions to generate recovery strategies; quick check: track failure types and recovery success rates
- Hierarchical agent architecture: Separates planning, decision, reflection, and interaction functions for modularity; quick check: measure inter-agent communication overhead and coordination efficiency

## Architecture Onboarding

Component Map: Planning Agent -> Decision Agent -> Component Recommendation Module -> Action Execution -> Memory Unit <- Reflection Agent <- Interaction Agent

Critical Path: User Task → Planning Agent (task decomposition) → Decision Agent (action selection) → CRM (component filtering) → Action Execution → Memory Unit (state tracking) → Reflection Agent (retrospection on failure)

Design Tradeoffs: Multiple LLM calls for component recommendation increase accuracy but add computational overhead; Human-in-the-Loop mechanism improves reliability but requires user involvement; three recommendation pathways provide redundancy but increase complexity.

Failure Signatures: High decision uncertainty when CRM cannot filter relevant components; action failures when UI metadata is incomplete or inconsistent; reduced performance when recommendation pathways conflict; user query fatigue when interaction frequency is too high.

First Experiments:
1. Measure CRM's impact on input token reduction and correlation with decision accuracy across different UI complexities
2. Evaluate individual recommendation pathway performance across various UI element types and task categories
3. Test system robustness with incomplete or inconsistent UI metadata and measure impact on component recommendation accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the quantitative impact of the human-in-the-loop Interaction Agent on task success rates, and how does it compare to autonomous decision-making with uncertainty?
- Basis in paper: The paper states that "evaluation of RecAgent using these datasets does not require the involvement of the Interaction Agent," meaning the interactive module's effectiveness in reducing decision uncertainty is only demonstrated through qualitative visualization (Figure 5), not through controlled experiments.
- Why unresolved: Without quantitative evaluation of the interaction mechanism, it remains unclear whether the overhead of user queries is justified by performance gains, or how often users should be engaged.
- What evidence would resolve it: Controlled experiments comparing task success rates with and without the Interaction Agent, measuring query frequency, response quality, and overall task completion efficiency.

### Open Question 2
- Question: Why do individual recommendation pathways (KMP, SMP) decrease performance when used alone, and under what conditions would each pathway be most effective?
- Basis in paper: Table 5 shows that using only the Keyword Matching Pathway (53.2%) or Semantic Matching Pathway (56.4%) actually underperforms the baseline without CRM (64.5%), yet the full system (69.3%) outperforms all alternatives.
- Why unresolved: The paper does not analyze failure modes of individual pathways, limiting understanding of when the recommendation module might introduce errors versus benefits.
- What evidence would resolve it: Per-pathway error analysis across different UI element types and task categories, identifying scenarios where each pathway excels or fails.

### Open Question 3
- Question: How does the component recommendation module perform on non-Chinese applications or interfaces with different design patterns and density characteristics?
- Basis in paper: The ComplexAction dataset is collected exclusively from popular mobile applications in China (e.g., Pinduoduo, Tencent Video, Xiaohongshu), and generalization to other app ecosystems is not validated.
- Why unresolved: UI design patterns, information density, and interaction conventions vary across regions and app categories, potentially affecting recommendation pathway effectiveness.
- What evidence would resolve it: Cross-cultural evaluation on diverse app datasets (e.g., Western apps, productivity tools, games) with comparative performance analysis.

## Limitations
- Reliance on multiple LLM calls for component recommendation introduces computational overhead that may limit real-world deployment efficiency
- ComplexAction dataset contains only 2,500 samples, which may not fully capture the diversity of real-world GUI interactions
- Component recommendation mechanism assumes access to comprehensive UI metadata, but performance in scenarios with incomplete or dynamically changing UI structures remains unclear

## Confidence
- Task success rate claims (47.8% AndroidWorld, 69.3% ComplexAction): Medium
- Component recommendation effectiveness: Medium
- Human-in-the-Loop refinement utility: Low (lacks quantitative validation)
- Generalizability to non-Chinese applications: Low (not validated)

## Next Checks
1. Evaluate RecAgent's performance on a larger, more diverse dataset with varying UI complexity and dynamic content
2. Conduct user studies to measure the effectiveness and efficiency of the Human-in-the-Loop refinement mechanism, including time costs and user satisfaction
3. Test RecAgent's robustness in scenarios with incomplete or inconsistent UI metadata and measure the impact on component recommendation accuracy