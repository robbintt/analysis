---
ver: rpa2
title: Cascading Bandits Robust to Adversarial Corruptions
arxiv_id: '2502.08077'
source_url: https://arxiv.org/abs/2502.08077
tags:
- uni00000026
- uni00000044
- bandits
- uni00000048
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the Cascading Bandits with Adversarial Corruptions
  (CBAC) problem, where an adaptive adversary can manipulate user feedback in online
  learning to rank systems. The authors propose two robust algorithms, CascadeRKC
  and CascadeRAC, designed to handle known and agnostic corruption levels, respectively.
---

# Cascading Bandits Robust to Adversarial Corruptions

## Quick Facts
- **arXiv ID:** 2502.08077
- **Source URL:** https://arxiv.org/abs/2502.08077
- **Authors:** Jize Xie; Cheng Chen; Zhiyong Wang; Shuai Li
- **Reference count:** 16
- **Primary result:** Propose CascadeRKC and CascadeRAC algorithms achieving logarithmic regret under no attacks and robust to adversarial corruptions in cascading bandits.

## Executive Summary
This paper addresses the Cascading Bandits with Adversarial Corruptions (CBAC) problem, where an adaptive adversary can manipulate user feedback in online learning to rank systems. The authors propose two robust algorithms, CascadeRKC and CascadeRAC, designed to handle known and agnostic corruption levels respectively. These algorithms are based on a novel position-based elimination method that maintains separate elimination sets for each position in the recommended list, ensuring more efficient identification of optimal items. CascadeRKC leverages knowledge of the corruption level by maintaining two instances with different confidence radii, while CascadeRAC maintains multiple instances to handle agnostic corruption. Both algorithms achieve logarithmic regret when not under attack, with regret increasing linearly with the corruption level.

## Method Summary
The paper proposes two robust algorithms for cascading bandits under adversarial corruptions. CascadeRKC uses a dual-instance approach where a "fast" instance with standard confidence radius and a "slow" instance with enlarged radius are maintained. The slow instance is sampled with probability 1/C to limit its exposure to corruption. CascadeRAC extends this to agnostic settings by maintaining log(T) instances with exponentially decreasing sampling probabilities (2^{-ℓ}). Both algorithms use position-based elimination, maintaining separate elimination sets for each position rather than global elimination. This allows for more efficient identification of optimal items while resisting adversarial corruption.

## Key Results
- CascadeRKC and CascadeRAC achieve logarithmic regret when not under attack, with regret increasing linearly with corruption level C.
- Theoretical analysis shows CascadeRKC and CascadeRAC outperform existing methods, achieving tighter regret bounds.
- Experimental results on synthetic and real-world datasets confirm the robustness and effectiveness of the proposed algorithms under various corruption mechanisms and levels.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Position-based elimination with per-position elimination sets achieves tighter regret bounds than global elimination in cascading bandits.
- Mechanism: Each position k maintains its own elimination set M^k. An item is eliminated from position k only when there exist k distinct items whose lower confidence bound exceeds this item's upper confidence bound.
- Core assumption: Attraction probabilities w(a) are static and item-independent; users click the first attractive item and stop browsing (cascade model).
- Evidence anchors: [abstract] "novel position-based elimination method that maintains separate elimination sets for each position in the recommended list"; [Section 4.1] "The key idea of the PBE algorithm is to maintain one set M^k for each position k to track the eliminated items".
- Break condition: If attraction probabilities drift over time or user behavior violates cascade model (e.g., multiple clicks), per-position elimination may incorrectly eliminate optimal items.

### Mechanism 2
- Claim: Sampling a "slow" instance with probability 1/C bounds expected corruption seen by that instance to O(log(T)), enabling robust elimination.
- Mechanism: CascadeRKC maintains two PBE instances: Fast (F) with standard confidence radius and Slow (S) with enlarged radius wd^S(a) = O(√(log(T)/T^S(a)) + log(T)/T^S(a)). The S instance is sampled with probability 1/C.
- Core assumption: Total corruption budget C is known and bounded; adversary is adaptive but cannot see future random seeds.
- Evidence anchors: [abstract] "CascadeRKC leverages knowledge of the corruption level by maintaining two instances with different confidence radii"; [Section 4.2] "the expected amount of corruption that falls in the slower instance S will be a constant"; [Lemma 1] "with probability at least 1-δ, when sampled with probability 1/C, the corruption C_S of S instance...bounded by log(1/δ) + 3".
- Break condition: If actual corruption exceeds declared C significantly, S instance receives too much corruption and may eliminate optimal items.

### Mechanism 3
- Claim: Hierarchical log(T)-instance cascade with exponential sampling probabilities achieves agnostic robustness without knowing C.
- Mechanism: CascadeRAC maintains log(T) instances with progressively enlarged confidence radii. Instance ℓ is sampled with probability 2^{-ℓ}.
- Core assumption: Corruption level C ≤ T (implicitly, since only log(T) layers exist); sub-optimal gaps Δ_{e,K} are not vanishingly small.
- Evidence anchors: [abstract] "CascadeRAC maintains multiple instances to handle agnostic corruption"; [Section 4.3] "if the total corruption level is C, then the layers ℓ > log(C) will suffer a constant corruption in expectation"; [Theorem 4] Regret bound: O(∑_{e=K+1}^L K(LC log(LT/δ) + log(T)) log(LT/δ) / Δ_{e,K}).
- Break condition: If C approaches T, the required layer depth exceeds log(T) and no layer remains nearly uncorrupted.

## Foundational Learning

- **Concept: Cascade Model in Learning-to-Rank**
  - Why needed here: All algorithm design assumes users browse sequentially and click only the first attractive item; regret definition depends on this.
  - Quick check question: Can you explain why the reward function f(A_t, R_t) = 1 - ∏(1 - R_t(a_k)) captures the cascade assumption?

- **Concept: Active Arm Elimination (AAE) for Multi-Armed Bandits**
  - Why needed here: PBE extends AAE from single-arm selection to K-item ranking; understanding AAE's elimination rule is prerequisite.
  - Quick check question: In standard AAE, when does an arm get eliminated? How does this generalize to per-position elimination?

- **Concept: Corruption-Level Robustness in Bandits (Lykouris et al. 2018)**
  - Why needed here: CascadeRKC/RAC directly adapt the multi-instance defense mechanism from robust MAB literature.
  - Quick check question: Why does sampling a "slow" learner with probability 1/C bound the corruption it observes?

## Architecture Onboarding

- **Component map:**
  PBE Core -> CascadeRKC Layer -> CascadeRAC Layer -> Feedback Processor

- **Critical path:**
  1. Initialize all elimination sets M^k = ∅ and counters T(a) = 0
  2. For each round: sample instance, select K items (greedy by T(a), respecting elimination sets)
  3. Observe click → update empirical means for examined positions
  4. Check elimination conditions for all active items
  5. Propagate eliminations across instances (CascadeRKC: S→F; CascadeRAC: ℓ→all ℓ'≤ℓ)

- **Design tradeoffs:**
  - **Known vs Agnostic:** CascadeRKC achieves O(C log²(LT)/Δ) regret; CascadeRAC adds O(log(T)²) overhead but requires no C knowledge
  - **Exploration efficiency vs Robustness:** Larger confidence radii resist corruption but delay sub-optimal elimination
  - **Memory vs Simplicity:** Per-position elimination sets require O(KL) space vs O(L) for global elimination

- **Failure signatures:**
  - Regret grows linearly with T instead of logarithmically → check if confidence radius scaling is correct
  - Optimal items eliminated early → confidence radius too tight or corruption underestimated
  - Sub-optimal items never eliminated → elimination threshold too loose or gap Δ too small
  - CascadeRAC uses all instances equally → sampling probabilities not implemented as 2^{-ℓ}

- **First 3 experiments:**
  1. **Sanity check on stochastic data (C=0):** Run CascadeRKC with C=1 (minimum valid) on synthetic data with L=50, K=3, T=10,000. Verify regret is O(log(T)) and matches CascadeUCB1 approximately.
  2. **Known corruption robustness test:** Inject periodic corruption (target lowest-probability item) with total C=5,000 over T=100,000. Compare CascadeRKC (with true C) vs CascadeUCB1. Expect >2x regret reduction.
  3. **Agnostic corruption stress test:** Run CascadeRAC on MovieLens dataset with early-phase corruption (all C budget in first 10% of rounds). Vary C ∈ {1000, 5000, 20000}. Verify regret scales linearly with C and CascadeRAC outperforms RBA in stochastic-dominated regime.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What are the gap-dependent lower bounds for the Cascading Bandits with Adversarial Corruptions (CBAC) problem?
- **Basis in paper:** [explicit] Section 5.3 states, "In addition, the lower bound of this problem is still unknown."
- **Why unresolved:** The authors derive upper bounds for CascadeRKC and CascadeRAC and argue they are tight by degenerating them to the Multi-Armed Bandit (MAB) setting, but they do not provide a specific lower bound proof for the general cascading structure.
- **What evidence would resolve it:** A formal theoretical proof establishing the minimum achievable regret for any algorithm within the CBAC setting, confirming if the linear dependence on corruption C and logarithmic dependence on T are optimal.

### Open Question 2
- **Question:** Can robust algorithms be designed for online learning to rank under adversarial corruptions using click models other than the cascade model?
- **Basis in paper:** [explicit] The Conclusion states, "In the future, we will study how to design robust algorithms for online learning to rank with other click models such as position-based models."
- **Why unresolved:** The current work relies heavily on the cascade model assumption (user clicks the first attractive item), but real-world user behavior often follows more complex patterns like the Position-Based Model (PBM).
- **What evidence would resolve it:** The formulation of a robust algorithm for a different click model (e.g., PBM) that maintains logarithmic regret in stochastic environments while resisting adversarial corruption.

### Open Question 3
- **Question:** How does the performance of CascadeRKC degrade if the assumed corruption level C is significantly misspecified?
- **Basis in paper:** [inferred] The CascadeRKC algorithm requires the corruption level C as a known input to set confidence radii and sampling probabilities, but the paper does not analyze the consequences of an incorrect estimate.
- **Why unresolved:** While CascadeRAC is proposed for agnostic settings, the tighter bounds of CascadeRKC rely on precise knowledge of C, which is a strong assumption in adversarial environments where the attack budget is unknown.
- **What evidence would resolve it:** A theoretical analysis or empirical study showing the regret bounds of CascadeRKC when the input parameter C is either an over-estimate or under-estimate of the true corruption budget.

## Limitations

- The position-based elimination requires Ω(1/Δ²) samples per item for reliable elimination, which becomes prohibitive for very small gaps Δ.
- CascadeRKC's performance under C larger than available horizon T is not well-characterized and may degrade significantly.
- The paper assumes static attraction probabilities and does not address temporal drift or non-cascade click patterns that may occur in real-world scenarios.

## Confidence

- **High:** CascadeRKC's dual-instance mechanism and regret bound O(C log²(LT)/Δ) when C is known; CascadeRAC's agnostic robustness with O(C log²(LT) log(T)/Δ) regret; experimental superiority over CascadeUCB1 and RBA in adversarial regimes.
- **Medium:** Position-based elimination achieves tighter bounds than global elimination; hierarchical instance sampling in CascadeRAC correctly isolates uncorrupted layers.
- **Low:** CascadeRKC's performance under C larger than available horizon T; practical effectiveness of random item selection when elimination sets are exhausted.

## Next Checks

1. **Known C stress test:** Run CascadeRKC on synthetic data with C approaching T/10. Measure whether regret scales as O(C log²(T)) or explodes due to insufficient uncorrupted samples.
2. **Gap sensitivity analysis:** Vary Δ = min_{e>K} Δ_{e,K} across {0.01, 0.1, 0.5}. Verify regret bounds follow O(log²(T)/Δ) scaling and identify the threshold where O(1/Δ²) samples become impractical.
3. **Early corruption recovery:** Implement CascadeRAC with all C corruption budget in first 10% of rounds. Test whether the exponential sampling successfully isolates corruption to upper layers and allows recovery, or if early elimination cascades permanently degrade performance.