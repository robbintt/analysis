---
ver: rpa2
title: On the Problem of Best Arm Retention
arxiv_id: '2504.11866'
source_url: https://arxiv.org/abs/2504.11866
tags:
- algorithm
- nright
- brack
- alt1
- arms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes tight sample complexity bounds for Best\
  \ Arm Retention (BAR) and its variant r-BAR in stochastic multi-armed bandits. For\
  \ (\u03B5,\u03B4)-PAC BAR, it derives a lower bound of \u03A9((n-m)/\u03B5\xB2 \xB7\
  \ log(n-m)/(n\u03B4)) using refined likelihood ratio arguments that remove the \u03B4\
  \ < 0.5 restriction from prior BAI results."
---

# On the Problem of Best Arm Retention

## Quick Facts
- arXiv ID: 2504.11866
- Source URL: https://arxiv.org/abs/2504.11866
- Reference count: 12
- Primary result: Establishes tight sample complexity bounds for Best Arm Retention (BAR) and r-BAR in stochastic multi-armed bandits

## Executive Summary
This paper establishes tight sample complexity bounds for Best Arm Retention (BAR) and its variant r-BAR in stochastic multi-armed bandits. For (ε,δ)-PAC BAR, it derives a lower bound of Ω((n-m)/ε² · log(n-m)/(nδ)) using refined likelihood ratio arguments that remove the δ < 0.5 restriction from prior BAI results. For r-BAR, which seeks to minimize the expected gap to the best arm, it shows the sample complexity is Θ((n-m)³/(nr)²). The paper also studies regret minimization for r-BAR, proving a regret bound of O((n-m)²/nr · (1 + √(m/(n-m)))) and conjectures this is tight. The key insight is that BAR algorithms require different sample complexities than pure regret minimization, and optimal regret requires instance-adaptive sampling rather than uniform treatment.

## Method Summary
The paper proposes algorithms using Median Elimination and Online Stochastic Mirror Descent (OSMD) as subroutines. For (ε,δ)-BAR, Algorithm 3 randomly samples n-m+1 arms then runs Median Elimination with adjusted confidence. For r-BAR pure exploration, Algorithm 5 runs FindBest (OSMD-based) on the sampled subset. For r-BAR regret minimization, Algorithm 6 uses a two-phase OSMD approach: first FindBest on all n arms, then on subsampled arms. The OSMD uses potential F(q) = -2∑√q(i) to achieve √(2nT) regret. Key technical contributions include refined likelihood ratio arguments via KL-divergence that remove δ < 0.5 restrictions from prior bounds.

## Key Results
- (ε,δ)-PAC BAR sample complexity: Θ((n-m)/ε² · log((n-m)/(nδ)))
- r-BAR pure exploration sample complexity: Θ((n-m)³/(nr)²)
- r-BAR regret bound: O((n-m)²/nr · (1 + √(m/(n-m))))
- Random subsampling achieves optimal BAR sample complexity
- Optimal regret requires instance-adaptive sampling, not uniform treatment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The likelihood ratio argument via KL-divergence (Lemma 9) removes the δ < 0.5 restriction from prior BAI lower bounds, extending to nearly all feasible δ values for BAR.
- **Mechanism**: The proof uses log-likelihood ratios between instances H₁ and Hᵢ. By applying Wald's lemma to ∑Tᵢ log(Pμ/Pμ') and combining with the log-sum inequality, we get Eμ[LT] ≥ d(Pμ[E], Pμ'[E]) for any event E. This captures information from all samples rather than requiring δ < 0.5 to guarantee 1-δ > δ.
- **Core assumption**: Stopping time T is almost-surely finite; Bernoulli reward distributions.
- **Evidence anchors**:
  - [abstract]: "we adapt the classical KL-divergence argument to derive optimal bounds for (ε,δ)-PAC algorithms for BAR"
  - [section 3.2, pages 10-12]: Full derivation of Lemma 9 and comparison to Bretagnolle-Huber inequality
  - [corpus]: Related work on streaming MAB bounds (arxiv 2502.01067, 2503.02428) use similar KL arguments but for different objectives
- **Break condition**: When δ approaches boundary (n-m)/n such that (n-m)/n - δ = o(1/n), the bound becomes loose because log term shrinks faster than linear.

### Mechanism 2
- **Claim**: Randomly subsampling n-m+1 arms then running median elimination achieves optimal sample complexity O((n-m+1)/ε² · log((n-m+1)/(nδ))) for (ε,δ)-BAR.
- **Mechanism**: The algorithm (Algorithm 3) exploits the observation that BAR only requires one ε-optimal arm in the retained set, not identifying which arms are top-m. By uniformly sampling n-m+1 arms, the best arm is excluded with probability only (m-1)/n. Median elimination on this subset finds an ε-optimal arm with confidence nδ/(n-m+1).
- **Core assumption**: ε ≤ 1/8; uniform random selection is unbiased with respect to arm ordering.
- **Evidence anchors**:
  - [abstract]: "goal is to retain m arms with the best arm included from n after some trials"
  - [section 3.1, page 8-9]: Algorithm 3 specification and failure probability analysis
  - [corpus]: Weak direct corpus support; most related work focuses on pure exploration or regret minimization, not retention
- **Break condition**: If ε > 1/8, median elimination guarantees degrade; if the subset S' happens to have all bad arms (rare but possible), median elimination still outputs one of them.

### Mechanism 3
- **Claim**: Regret minimization for r-BAR requires instance-adaptive sampling; uniform treatment across instances yields suboptimal regret by factor (1 + √(m/(n-m))).
- **Mechanism**: Algorithm 6 uses two-phase OSMD: first FindBest on all n arms (L₁ rounds), then on subsampled n-m+2 arms (L₂ rounds). The gap between upper bound O((n-m)²/nr·(1+√(m/(n-m)))) and lower bound Ω((n-m)²/nr) arises because "hard" instances (like H₁ with specific ε) don't require T = Θ((n-m)³/(nr)²) samples—optimal algorithms should adaptively stop earlier on easier instances.
- **Core assumption**: Subgaussian rewards; regret measured as expected gap to best arm.
- **Evidence anchors**:
  - [abstract]: "optimal regret requires instance-adaptive sampling rather than uniform treatment"
  - [section 4.3, page 20]: Explicit discussion of why Algorithm 6 is not optimal and the conjecture
  - [corpus]: Related streaming MAB work (arxiv 2503.02428) on gap-dependent bounds addresses similar adaptivity challenges
- **Break condition**: When m is very close to n, the √(m/(n-m)) term blows up, making bounds vacuous. Instance-adaptive algorithms would need more sophisticated stopping criteria not specified here.

## Foundational Learning

- **Concept: KL-divergence and likelihood ratios in hypothesis testing**
  - **Why needed here**: The core lower bound technique hinges on relating sample complexity to distinguishability between MAB instances via d(Pμ[E], Pμ'[E]).
  - **Quick check question**: Given two Bernoulli(0.5) and Bernoulli(0.5+2ε) arms, what's the minimum pulls to distinguish them with confidence 1-δ?

- **Concept: PAC-learning framework for bandits**
  - **Why needed here**: The (ε,δ)-PAC formulation defines what "solving BAR" means—retaining an ε-optimal arm with probability ≥ 1-δ.
  - **Quick check question**: Why does BAR with m=n-1 have sample complexity Ω(1/(ε²n)) even though no arms are "eliminated"?

- **Concept: Online Stochastic Mirror Descent (OSMD) / Follow-the Regularized Leader**
  - **Why needed here**: The FindBest subroutine (Algorithm 1/4) uses OSMD with potential F(q) = -2∑√q(i) to achieve √(2nT) regret, which bounds the expected gap.
  - **Quick check question**: In OSMD, why does the Bregman divergence term BF(q, Qt) matter for regret bounds?

## Architecture Onboarding

- **Component map**:
  Input: n arms, parameters m, ε/r, δ
  ↓
  [Subsampler] → selects n-m+1 arms uniformly
  ↓
  [MedianElimination OR FindBest(OSMD)] → identifies good arm
  ↓
  [Retainer] → outputs m arms (selected arm + m-1 unselected)
  ↓
  Output: subset of size m containing (near-)optimal arm

- **Critical path**:
  1. For (ε,δ)-BAR: Algorithm 3 → MedianElimination → O((n-m)/ε² log((n-m)/(nδ))) samples
  2. For r-BAR (pure exploration): Algorithm 5 → FindBest → O((n-m)³/(nr)²) samples
  3. For r-BAR (regret minimization): Algorithm 6 → two-phase FindBest → O((n-m)²/nr) regret

- **Design tradeoffs**:
  - **MedianElimination vs. OSMD**: MedianElimination is simpler, achieves PAC guarantees, but incurs high regret. OSMD minimizes regret but requires tuning learning rate η and more careful implementation.
  - **m vs. sample complexity**: Larger m → easier problem (fewer arms to eliminate) → lower sample complexity. But regret bounds have √(m/(n-m)) term that hurts when m ≈ n.
  - **Uniform vs. adaptive sampling**: Uniform treatment (Algorithms 3, 5, 6) is implementable but leaves gap to lower bound. Adaptive requires instance-dependent stopping (open problem).

- **Failure signatures**:
  - If δ ≥ (n-m)/n, random selection works and sample complexity is 0—no exploration needed.
  - If returned arm has empirical mean far from best, either ε/r too aggressive or sample budget insufficient.
  - If regret >> O((n-m)²/nr) in practice, check whether L₁ = (m-2)/(n-1) · L₂ causes integer underflow for small m.

- **First 3 experiments**:
  1. **Sanity check (BAI case)**: Set m=1, n=10, ε=0.1, δ=0.1. Verify Algorithm 3 outputs ε-optimal arm ≥ 90% of runs. Compare to theoretical sample bound.
  2. **Regime sweep**: Vary m from 1 to n-1 for fixed n=100, ε=0.05, δ=0.05. Plot sample complexity vs. m; should see Θ((n-m)/ε²) scaling.
  3. **r-BAR vs (ε,δ)-BAR**: Set r=0.1, equivalent ε=2r, δ=r. Run Algorithms 3 and 5. Compare expected gaps—Algorithm 5 should achieve lower expected gap with similar or fewer samples for small r.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Is the regret complexity of r-BAR tight at Θ((n-m)²/nr)?
- **Basis in paper**: [explicit] Conjecture 17 states this conjecture directly. The paper provides upper bound O((n-m)²/nr · (1 + √(m/(n-m)))) and lower bound Ω((n-m)²/nr).
- **Why unresolved**: The gap between bounds is (1 + √(m/(n-m))). The paper explains that different instances require different sample sizes, so optimal regret requires instance-adaptive sampling rather than uniform treatment, making algorithm design challenging.
- **What evidence would resolve it**: An algorithm achieving O((n-m)²/nr) regret for all m, or a refined lower bound construction showing the √(m/(n-m)) factor is necessary when m is close to n.

### Open Question 2
- **Question**: Can instance-dependent bounds for BAR be established beyond the worst-case PAC analysis?
- **Basis in paper**: [explicit] The conclusion explicitly states: "Another interesting direction is to establish instance-dependent bounds for BAR, rather than focusing on the PAC algorithm of BAR as we do in this work."
- **Why unresolved**: The paper focuses on worst-case (minimax) analysis; instance-dependent bounds typically require different techniques that account for the specific gap structure between arms.
- **What evidence would resolve it**: Bounds that depend on the arm gaps Δᵢ rather than just n, m, ε, δ parameters, analogous to gap-dependent bounds in standard BAI literature.

### Open Question 3
- **Question**: What is the optimal sample complexity when δ is very close to the boundary (n-m)/n, specifically when (n-m)/n - δ = o(1/n)?
- **Basis in paper**: [inferred] Section 3.2.2 explicitly notes the approach encounters limitations near this boundary, providing an example where the derived lower bound may not be tight and stating the result is paradoxical for certain parameter ranges.
- **Why unresolved**: The KL-divergence argument using Lemma 12 produces bounds that become weak near the boundary. The paper's remark provides an example where the lower bound suggests Ω(1/(ε²n)) samples, but the upper bound is O(1/ε²), creating a potential gap.
- **What evidence would resolve it**: Either a refined lower bound technique that handles the boundary case, or an algorithm achieving improved sample complexity when δ is extremely close to (n-m)/n.

## Limitations

- The exact constant β in the sample complexity bounds is unspecified, leaving ambiguity in the precise lower bound for small δ values.
- The gap between the regret upper bound O((n-m)²/(nr)·(1+√(m/(n-m)))) and lower bound Ω((n-m)²/(nr)) for r-BAR remains open, with conjecture that adaptivity is the key differentiator but no concrete algorithm proposed.
- The analysis assumes Bernoulli rewards throughout; while extensions to subgaussian rewards are mentioned as possible, no explicit treatment or verification is provided.

## Confidence

- **High**: The (ε,δ)-PAC BAR lower bound using KL-divergence (Ω((n−m)/ε²·log((n−m)/(nδ)))) and the r-BAR pure exploration bound (Θ((n−m)³/(nr)²)) are well-established via classical information-theoretic arguments and hold across all δ values.
- **Medium**: The regret bound for r-BAR (O((n−m)²/(nr)·(1+√(m/(n−m))))) is proven for the proposed algorithm but conjectured to be suboptimal by the stated factor; the conjecture is reasonable but unproven.
- **Medium**: The random subsampling strategy for (ε,δ)-BAR achieving optimal bounds is correct but relies on the specific choice n−m+1 arms, which may not be tight for all parameter regimes.

## Next Checks

1. **Bound tightness test**: Implement Algorithms 3 and 5 on hard instance H₁ with varying n, m, ε, δ. Measure empirical sample complexity vs theoretical bounds, particularly near δ ≈ (n−m)/n where the log term becomes critical.

2. **Regret adaptivity gap**: Compare Algorithm 6's regret performance on "hard" vs "easy" instances (H₁ vs Hⱼ with small j). Quantify the actual regret gap and verify it aligns with the conjectured factor (1+√(m/(n−m))).

3. **Extension to subgaussian rewards**: Modify Algorithm 3 to use Hoeffding bounds instead of KL divergence for subgaussian rewards. Test on Gaussian arms and verify sample complexity matches the Bernoulli case.