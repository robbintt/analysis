---
ver: rpa2
title: 'ADORE: Autonomous Domain-Oriented Relevance Engine for E-commerce'
arxiv_id: '2512.02555'
source_url: https://arxiv.org/abs/2512.02555
tags:
- relevance
- online
- adore
- data
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces ADORE, a framework addressing two key challenges
  in e-commerce search relevance modeling: the scarcity of domain-specific hard samples
  and the limited reasoning capabilities of lightweight online models. The framework
  integrates three modules: a rule-aware relevance discrimination module using Chain-of-Thought
  LLMs with Kahneman-Tversky Optimization for intent-aligned data generation, an error-type-aware
  data synthesis module for automated adversarial example generation, and a key-attribute-enhanced
  knowledge distillation module that injects domain-specific attributes into a deployable
  student model.'
---

# ADORE: Autonomous Domain-Oriented Relevance Engine for E-commerce

## Quick Facts
- arXiv ID: 2512.02555
- Source URL: https://arxiv.org/abs/2512.02555
- Reference count: 40
- Primary result: 85.45% F1 score (vs. 84.07% BERT baseline), +1.24% CTR and +1.58% ad revenue online

## Executive Summary
ADORE is a framework for e-commerce search relevance modeling that addresses two key challenges: scarcity of domain-specific hard samples and limited reasoning capabilities of lightweight online models. The system uses Chain-of-Thought large language models with Kahneman-Tversky Optimization for intent-aligned data generation, an error-type-aware data synthesis module for automated adversarial example generation, and a key-attribute-enhanced knowledge distillation module to inject domain-specific attributes into a deployable student model. Experiments on a large-scale real-world dataset and online A/B testing show significant improvements in both offline F1 score (85.45% vs 84.07% for standard BERT) and online metrics (CTR +1.24%, ad revenue +1.58%).

## Method Summary
ADORE addresses e-commerce search relevance through a three-stage pipeline. First, it generates Chain-of-Thought reasoning data using GPT-4o with domain-specific annotation guidelines, then fine-tunes LLaMA-3 with this data and aligns it via Kahneman-Tversky Optimization using purchased pairs as preference signals. Second, it trains an error-type-aware generator to create adversarial query-product pairs by perturbing attributes identified in failed cases, filtering generated pairs through the relevance discrimination model. Third, it performs knowledge distillation from a BERT-CoT teacher (which takes query + product + CoT attributes as input) to a BERT-Mini student using a combined binary cross-entropy and mean squared error loss on [CLS] representations, with α balancing the two terms.

## Key Results
- Full ADORE system achieves 85.45% F1 score compared to 84.07% for standard BERT
- Online A/B testing shows +1.24% CTR and +1.58% ad revenue improvements
- Each module contributes incrementally: KD alone improves F1 by 0.31%, full system adds 1.38% beyond baseline

## Why This Works (Mechanism)
The framework works by systematically addressing the dual challenges of data scarcity and model limitations. Chain-of-Thought reasoning enables explicit extraction of domain-specific attributes and compatibility analysis, while KTO alignment ensures the model captures user purchase intent beyond surface-level relevance. Error-type-aware generation creates hard samples that expose model weaknesses, and attribute-enhanced KD injects this reasoning capability into a lightweight model that can deploy at scale without sacrificing performance.

## Foundational Learning
- **Chain-of-Thought reasoning**: Sequential reasoning steps for attribute extraction and compatibility analysis; needed to make LLM reasoning transparent and domain-specific; quick check: verify CoT outputs contain explicit attribute mentions and compatibility judgments
- **Kahneman-Tversky Optimization**: Preference-based alignment using behavioral economics principles; needed to align model predictions with user purchase behavior rather than just relevance labels; quick check: monitor preference pair accuracy during alignment
- **Error-type-aware generation**: Targeted perturbation of attributes based on failure analysis; needed to create challenging synthetic samples that expose model weaknesses; quick check: ensure generated pairs are diverse but still filterable by RD model
- **Knowledge distillation with attribute injection**: Teacher-student training with combined loss on labels and representations; needed to transfer CoT reasoning capability to lightweight model; quick check: verify [CLS] representation similarity improves during training

## Architecture Onboarding

### Component Map
RD Module (CoT LLMs + KTO) -> Data Synthesis Module (Error-type generator) -> KD Module (BERT-CoT -> BERT-Mini)

### Critical Path
CoT data generation → KTO alignment → error-type generator training → adversarial pair synthesis → KD training → deployment

### Design Tradeoffs
- **LLM size vs inference speed**: Large CoT models for data generation but lightweight student for deployment
- **Synthetic data quality vs quantity**: Error-type generator creates many samples but must be filtered to maintain quality
- **Loss weighting in KD**: α balances label matching vs representation alignment, affecting student's reasoning capability

### Failure Signatures
- KTO over-alignment: precision drops below 82% while recall spikes
- Noisy synthetic data: RD model filters <90% of generated pairs
- Poor KD transfer: student F1 < 83% despite teacher >85%

### First 3 Experiments
1. Fine-tune LLaMA-3 on GPT-4o-generated CoT data and evaluate label consistency
2. Train error-type generator and manually inspect 200 generated pairs for quality
3. Perform KD with α=0.5 and compare student performance with and without attribute injection

## Open Questions the Paper Calls Out
- **Multi-modal integration**: How to incorporate product images into the framework for non-textual attribute enhancement
- **User preference personalization**: Extending relevance modeling to include user-specific preferences and historical interactions
- **Hallucination robustness**: Impact of GPT-4o reasoning chain hallucinations on student model performance

## Limitations
- Missing critical hyperparameters (CoT prompts, KTO parameters, KD α value)
- Heavy reliance on proprietary JD.com data and GPT-4o for data generation
- No reported variance or statistical significance for claimed improvements
- Potential label noise from synthetic adversarial data generation

## Confidence

### High confidence
- Three-stage pipeline architecture is clearly described and logically sound
- Domain-specific attribute reasoning approach is well-justified

### Medium confidence
- Offline F1 improvement (85.45% vs 84.07%) and online gains are reported without variance analysis

### Low confidence
- Exact implementation details for KTO and KD modules are not specified
- Prompt templates and hyperparameters are missing

## Next Checks
1. Replicate KTO alignment sensitivity by varying alignment steps and monitoring precision/recall tradeoff
2. Validate synthetic data quality by manually inspecting 200 adversarial examples
3. Test KD loss weighting by experimenting with different α values (0.3, 0.5, 0.7)