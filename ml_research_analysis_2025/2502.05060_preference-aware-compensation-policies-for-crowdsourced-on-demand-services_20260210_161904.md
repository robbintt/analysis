---
ver: rpa2
title: Preference-aware compensation policies for crowdsourced on-demand services
arxiv_id: '2502.05060'
source_url: https://arxiv.org/abs/2502.05060
tags:
- worker
- workers
- performance
- utility
- request
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses dynamic pricing for on-demand platforms using
  gig workers, focusing on setting compensation policies that balance worker attractiveness
  and platform profitability. The authors formalize the problem as a Markov Decision
  Process and derive an analytical solution using a Multinomial Logit model to represent
  worker acceptance probabilities.
---

# Preference-aware compensation policies for crowdsourced on-demand services

## Quick Facts
- arXiv ID: 2502.05060
- Source URL: https://arxiv.org/abs/2502.05060
- Reference count: 15
- One-line primary result: Dynamic pricing algorithm for on-demand platforms achieves 2.5-7.5% higher performance in homogeneous worker populations, 9% in heterogeneous populations, and 8-20% on real-world data over benchmarks.

## Executive Summary
This paper addresses dynamic pricing for on-demand platforms using gig workers, focusing on setting compensation policies that balance worker attractiveness and platform profitability. The authors formalize the problem as a Markov Decision Process and derive an analytical solution using a Multinomial Logit model to represent worker acceptance probabilities. They develop a scalable approximate dynamic programming algorithm incorporating learned worker preferences. Experiments on synthetic and real-world data (NYC taxi rides) show consistent improvements over benchmark policies, with the algorithm achieving 2.5-7.5% higher performance in homogeneous worker populations, 9% in heterogeneous populations, and 8-20% on real-world data. The approach effectively balances compensation and utilization while avoiding overpayment.

## Method Summary
The paper formulates dynamic compensation as an MDP with post-decision states, enabling analytical optimization of compensation levels. Worker acceptance is modeled using a Multinomial Logit distribution, and a neural network with attention mechanism approximates the value function. The algorithm learns worker preferences offline and uses them to compute optimal compensation via a Lambert W function. Training uses approximate value iteration with Adam optimizer, Huber loss, and attention-based neural networks to handle variable-sized request sets. The method is evaluated on synthetic data and real NYC taxi data, showing consistent improvements over benchmark policies.

## Key Results
- 2.5-7.5% higher performance in homogeneous worker populations
- 9% improvement in heterogeneous populations over benchmarks
- 8-20% performance gains on real-world NYC taxi data
- Successfully avoids overpayment while maintaining worker acceptance rates
- Segmented modeling of heterogeneous workers prevents averaging errors

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Incorporating gig worker preference models (Multinomial Logit) allows the system to calibrate compensation to the minimum level required for acceptance, maximizing platform margin.
- **Mechanism:** The system estimates a worker's utility $u_{ij}$ for a request. Instead of a flat rate, it solves for the optimal compensation $c_i$ where the marginal cost of increasing pay balances against the marginal gain in acceptance probability. This avoids the "overpayment" inefficiency seen in formula-based benchmarks.
- **Core assumption:** Worker acceptance behavior follows a Multinomial Logit (MNL) distribution, meaning the noise in their utility function is Gumbel-distributed.
- **Evidence anchors:**
  - [abstract] "Our approach introduces compensation strategies that explicitly account for gig worker request preferences... using the Multinomial Logit model."
  - [section 5.3] "Our algorithm... effectively avoiding overcompensation," specifically noting mean differences in offered compensation were significantly lower than benchmarks (e.g., 3.3 vs 9.8 monetary units).
  - [corpus] Indirect support; related papers like "FareShare" and "Understanding... Vulnerabilities" highlight the precarity of gig work, reinforcing why precise compensation modeling is critical, though they do not validate the MNL mechanism itself.
- **Break condition:** If worker utility is systematically overestimated (e.g., assuming they will accept low pay), the acceptance probability drops to near zero, and performance collapses (see Section 5.1 Sensitivity Analysis).

### Mechanism 2
- **Claim:** Formulating the problem using post-decision states allows for an analytical solution to the compensation optimization problem, bypassing the need for expensive combinatorial search.
- **Mechanism:** The algorithm splits the Bellman equation. It calculates the value of the state *after* the worker decides but *before* new stochastic arrivals. This reduces the optimization to a convex problem solvable via first-order conditions (Lambert W function), ensuring the compensation $c^*$ is theoretically optimal for the estimated value function.
- **Core assumption:** The "opportunity cost" (future value) of a request can be accurately approximated by the value function network.
- **Evidence anchors:**
  - [section 3.1] "By separating the transition dynamics in this manner, the complexity of the Bellman equation is reduced... depending only on the transition into the post-decision states."
  - [section 3.2] "We demonstrate that there exists an alternative formulation... which uses acceptance probabilities as decision variables and is concave."
  - [corpus] Not applicable; this is a domain-specific optimization technique not covered in the sociologically-focused neighbor papers.
- **Break condition:** If the state space features (request characteristics) do not capture the factors driving worker utility, the post-decision value approximation will be noisy, leading to erratic pricing.

### Mechanism 3
- **Claim:** Segmented modeling of heterogeneous worker populations prevents the "averaging" error that causes revenue loss in diverse workforces.
- **Mechanism:** A single MNL model on a heterogeneous population conflates different utility functions. By identifying subgroups (e.g., by age or employment status) and training separate MNL parameters ($\hat{w}_d$) for each, the system avoids overpaying high-utility groups or underpaying low-utility groups.
- **Core assumption:** The platform can identify or infer which worker group a specific worker belongs to at the time of decision-making.
- **Evidence anchors:**
  - [section 5.2] "When employing a single MNL model, the average performance ratio drops significantly to 75.5%... underscoring the importance of accurate utility estimation."
  - [abstract] "...improvements of... 9% in heterogeneous populations over benchmarks."
  - [corpus] Neighbor papers like "Invisible Labour in India's Gig-Economy" support the premise that worker demographics and constraints (marginalized communities) significantly impact labor behavior.
- **Break condition:** If group labels are noisy or misassigned, the specific MNL model will apply the wrong utility function, potentially performing worse than a robust "average" model.

## Foundational Learning

- **Concept: Markov Decision Processes (MDPs)**
  - **Why needed here:** The core mathematical framework. You must understand state transitions (requests expiring/workers arriving) and the Bellman equation to grasp *why* the algorithm estimates "future value" to make a decision *now*.
  - **Quick check question:** Can you explain why the "value" of a request today depends on the probability of finding a worker for it tomorrow?

- **Concept: Discrete Choice Models (specifically Multinomial Logit)**
  - **Why needed here:** This is the behavioral model. The entire algorithm's logic relies on the mathematical link between offered compensation and the probability of acceptance.
  - **Quick check question:** If you increase compensation by $\mu$ (the scale parameter), how much does the log-odds of acceptance increase?

- **Concept: Approximate Dynamic Programming (ADP)**
  - **Why needed here:** The state space is too large to solve exactly. ADP (specifically Approximate Value Iteration) is the technique used to train the neural network to estimate values.
  - **Quick check question:** In Algorithm 1, why is the target for the neural network update $v^*_t$ instead of the immediate reward $R_t$?

## Architecture Onboarding

- **Component map:** MNL Estimator -> Value Function Approximator (VFA) with Attention -> Pricing Optimizer (Lambert W function)
- **Critical path:**
  1. **Training:** Run simulations → Collect (State, Action, Reward, Next State) tuples → Train MNL → Train VFA using Algorithm 1
  2. **Inference:** Observe State ($R_t, G_t$) → Query VFA for opportunity cost $\Delta V$ → Solve for $c^*$ → Offer compensation
- **Design tradeoffs:**
  - **MNL vs. Complex Models:** The authors chose MNL because it offers a closed-form solution for the gradient. A more complex model (e.g., deep net for choice) might fit data better but would make the optimization in Lemma 3 intractable.
  - **Deterministic vs. Stochastic Policy:** The paper uses a deterministic policy for consistency. A stochastic policy might explore more but confuses workers.
- **Failure signatures:**
  - **"Zero Acceptance" Loop:** If the MNL estimator has a strong positive bias (thinks workers love tasks when they don't), the algorithm will offer \$0 compensation, resulting in 0% acceptance and immediate penalties.
  - **Overpayment Stall:** If the value function underestimates the future value of requests, the system acts desperately, offering high compensation that eats all profit.
  - **Fairness Skew:** In "Strong Preference" scenarios, the algorithm may effectively "redline" certain locations (e.g., drop-offs in region 1) where worker utility is structurally lower, leading to unbalanced service coverage.
- **First 3 experiments:**
  1. **Validation of Lemma 3:** Implement the analytical solver and verify it matches brute-force optimization on a tiny state space (e.g., 2 requests, 1 worker).
  2. **Ablation on Heterogeneity:** Run the system on Synthetic Scenario II (3 worker groups) comparing a single global MNL vs. 3 specialized MNLs to replicate the 9% performance gap.
  3. **Robustness Check:** Perturb the utility estimates (as in Section 5.1) and plot the performance degradation curve to determine the "safe operating margin" for the MNL estimator's error.

## Open Questions the Paper Calls Out
- **Question:** How can fairness in compensation strategies be formally defined and guaranteed for different gig worker groups?
  - **Basis in paper:** [explicit] "Future work could investigate fairness issues in compensation strategies, especially concerning important gig worker groups."
  - **Why unresolved:** The paper demonstrates that strong location preferences lead to unbalanced acceptance rates across pickup/dropoff locations (CV 23% vs 10.3% for optimal), raising fairness concerns that were not addressed.
  - **What evidence would resolve it:** Experiments showing defined fairness metrics (e.g., Gini coefficient of acceptance rates) can be optimized alongside revenue without significant performance loss.

- **Question:** Would alternative discrete choice models (e.g., Mixed Logit, Nested Logit) improve performance over the MNL assumption, particularly when IIA violations are present?
  - **Basis in paper:** [inferred] The authors acknowledge the MNL model "assumes a specific mathematical structure (e.g., independence of irrelevant alternatives), which may not fully reflect real-world decision-making."
  - **Why unresolved:** The paper relies entirely on MNL and does not compare against models that relax IIA.
  - **What evidence would resolve it:** Comparative experiments using alternative choice models on the same NYC taxi dataset, measuring both utility estimation accuracy and resulting policy performance.

- **Question:** How would extending the model to offer bundles of requests to gig workers affect compensation decisions and platform revenue?
  - **Basis in paper:** [explicit] "An alternative approach could involve offering bundles of requests to gig workers... handling bundles of requests could be a feasible extension."
  - **Why unresolved:** The combinatorial complexity of bundle offers was noted but not explored.
  - **What evidence would resolve it:** A modified MDP formulation handling request bundles with experiments showing revenue impact and computational tractability.

- **Question:** Can priority-based gig worker queue management strategies outperform the FIFO approach used in this work?
  - **Basis in paper:** [explicit] "Exploring priority-based gig worker queue management strategies as alternatives to FIFO could enhance decision-making."
  - **Why unresolved:** The paper queues multiple arriving workers using FIFO but does not test alternatives.
  - **What evidence would resolve it:** Simulations comparing FIFO against priority schemes (e.g., by worker skill, location proximity, or historical acceptance rate) on total platform reward.

## Limitations
- Utility Estimation Sensitivity: The algorithm hinges on accurate MNL parameter estimation; small errors can compound into significant overpayment or under-acceptance issues.
- Synthetic Data Realism: Synthetic scenarios may not capture the full complexity of real-world worker preferences and platform dynamics.
- Group Assignment Assumption: The benefit of segmented modeling assumes the platform can accurately identify which worker group a specific worker belongs to.

## Confidence
- **High Confidence:** The MDP formulation with post-decision states and the resulting analytical solution via the Lambert W function.
- **Medium Confidence:** The performance improvements on real-world NYC taxi data (8-20%), due to experiment setup ambiguities.
- **Medium Confidence:** The 9% improvement in heterogeneous populations, as it relies on the assumption that worker groups are known and stable.

## Next Checks
1. **Robustness to Utility Estimation Error:** Systematically perturb the MNL parameters (μ_j) within ±20% of their true values and measure the degradation in performance ratio.
2. **Group Assignment Sensitivity:** On Synthetic Scenario II, simulate noisy group labels (e.g., 5-20% of workers misclassified) and measure the performance loss.
3. **Cross-City Generalization:** Apply the trained model from NYC data to another city's ride data (e.g., Chicago or San Francisco) without retraining the MNL.