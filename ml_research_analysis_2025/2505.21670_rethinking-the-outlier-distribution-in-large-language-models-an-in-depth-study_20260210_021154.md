---
ver: rpa2
title: 'Rethinking the Outlier Distribution in Large Language Models: An In-depth
  Study'
arxiv_id: '2505.21670'
source_url: https://arxiv.org/abs/2505.21670
tags:
- outliers
- quantization
- arxiv
- outlier
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts an in-depth empirical investigation into the
  formation mechanisms of outliers in large language models (LLMs), specifically massive
  activations (MAs) and channel-wise outliers (COs). The authors discover that most
  MAs are generated in the initial layers and propagated via residual connections,
  while TMAs (true MAs not caused by residuals) can be safely eliminated without impacting
  model accuracy.
---

# Rethinking the Outlier Distribution in Large Language Models: An In-depth Study

## Quick Facts
- **arXiv ID**: 2505.21670
- **Source URL**: https://arxiv.org/abs/2505.21670
- **Reference count**: 12
- **Primary result**: Novel empirical insights into outlier formation mechanisms in LLMs, proposing efficient strategies to eliminate most MAs and COs with minimal accuracy impact

## Executive Summary
This paper presents a comprehensive empirical investigation into outlier distributions in large language models, focusing on massive activations (MAs) and channel-wise outliers (COs). Through systematic analysis across multiple model families, the authors identify that most MAs originate in initial layers and propagate through residual connections, while channel-wise outliers primarily arise from normalization layer rescaling and specific weight channels termed Outlier Triggering Channels (OTCs). Based on these findings, they propose targeted strategies to eliminate outliers efficiently, significantly reducing quantization complexity while maintaining model accuracy. The study provides actionable insights for improving LLM quantization efficiency and offers practical solutions for deployment optimization.

## Method Summary
The authors conducted extensive empirical analysis across multiple transformer-based language models, systematically examining activation patterns, residual connections, and normalization layer behaviors. They developed diagnostic tools to distinguish between residual-caused and true massive activations, identified Outlier Triggering Channels in weight matrices, and proposed targeted elimination strategies. The methodology involved quantitative measurements of outlier distributions across layers, correlation analysis between residual flows and activation magnitudes, and ablation studies to assess the impact of outlier removal on model accuracy and quantization efficiency.

## Key Results
- Most massive activations (MAs) are generated in initial layers and propagated via residual connections
- True MAs (TMAs) not caused by residuals can be safely eliminated without impacting model accuracy
- Channel-wise outliers primarily arise from normalization layer rescaling operations and Outlier Triggering Channels (OTCs) in weight matrices

## Why This Works (Mechanism)

## Foundational Learning
- **Residual Connections**: Skip connections that bypass layers to enable gradient flow; needed for understanding outlier propagation, quick check: trace residual paths in model architecture
- **Normalization Layers**: Rescale activations to stabilize training; critical for understanding CO formation, quick check: examine layer normalization parameters
- **Outlier Triggering Channels (OTCs)**: Specific weight matrix channels that induce outliers; essential for targeted elimination, quick check: analyze weight statistics per channel
- **Quantization**: Process of reducing numerical precision; context for outlier impact, quick check: understand bit-width reduction effects
- **Massive Activations (MAs)**: Large activation values that cause quantization challenges; primary focus of analysis, quick check: identify activation magnitude distributions
- **Channel-wise Outliers (COs)**: Activation outliers occurring in specific channels; secondary focus of analysis, quick check: examine channel activation distributions

## Architecture Onboarding
- **Component Map**: Input -> Embedding -> Transformer Blocks (LN, Attention, MLP, Residuals) -> Output
- **Critical Path**: Residual connections enable outlier propagation from initial layers through subsequent layers
- **Design Tradeoffs**: Model accuracy vs. quantization efficiency, complexity of outlier elimination strategies
- **Failure Signatures**: Increased quantization error, accuracy degradation when outliers are improperly handled
- **First Experiments**: 1) Analyze residual connection contributions to MAs, 2) Identify OTCs in weight matrices, 3) Test TMA elimination impact on accuracy

## Open Questions the Paper Calls Out
None

## Limitations
- Claims about residual connections propagating outliers rely on specific threshold values that may vary across architectures
- Analysis focuses on transformer-based models without examining other neural network types
- Proposed solutions primarily validated on specific quantization targets, limiting generalizability

## Confidence
- **Residual connection outlier propagation**: High confidence
- **TMA elimination strategy generalizability**: Medium confidence
- **Universal applicability of quantization solutions**: Medium confidence

## Next Checks
1. Validate the TMA elimination strategy across multiple model families (GPT, BERT, OPT variants) and diverse datasets to assess generalizability
2. Investigate the interaction between outlier formation mechanisms and different training regimes, including pre-training and fine-tuning dynamics
3. Test the proposed quantization solutions under varying bit-width targets (beyond the studied configurations) and measure impact on model robustness metrics