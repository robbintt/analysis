---
ver: rpa2
title: Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala,
  English, and Code-Mixed Content
arxiv_id: '2504.13545'
source_url: https://arxiv.org/abs/2504.13545
tags:
- sentiment
- sinhala
- english
- banking
- mixed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This research addresses the challenge of multilingual sentiment
  analysis for Sinhala, English, and code-mixed content in banking, particularly for
  low-resource languages. The authors developed a hybrid aspect-based sentiment analysis
  framework combining BERT-base-uncased for English, XLM-RoBERTa with domain-specific
  lexicon correction for Sinhala and code-mixed text, and integrated SHAP and LIME
  for explainability.
---

# Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content

## Quick Facts
- **arXiv ID:** 2504.13545
- **Source URL:** https://arxiv.org/abs/2504.13545
- **Reference count:** 0
- **Primary result:** 92.3% accuracy and 0.89 F1-score for English; 88.4% accuracy and 0.84 F1-score for Sinhala and code-mixed content on banking reviews

## Executive Summary
This research presents a hybrid aspect-based sentiment analysis framework designed for multilingual and code-mixed content in the banking domain, focusing on Sinhala, English, and their code-mixed variants. The system combines BERT-base-uncased for English with XLM-RoBERTa enhanced by domain-specific lexicon correction for Sinhala and code-mixed text. SHAP and LIME tools are integrated to provide interpretable sentiment insights. Evaluated on 15,000 banking customer reviews, the approach achieves high accuracy and F1-scores while improving transparency and trust through explainability features.

## Method Summary
The authors developed a hybrid multilingual sentiment analysis framework combining BERT-base-uncased for English and XLM-RoBERTa with domain-specific lexicon correction for Sinhala and code-mixed content. The model integrates SHAP and LIME for explainability, enabling interpretable sentiment insights. The framework was evaluated on a dataset of 15,000 banking customer reviews, demonstrating strong performance in both accuracy and F1-score across the three language types.

## Key Results
- 92.3% accuracy and 0.89 F1-score for English sentiment analysis
- 88.4% accuracy and 0.84 F1-score for Sinhala and code-mixed content
- Integration of SHAP and LIME provides interpretable sentiment insights

## Why This Works (Mechanism)
The framework leverages pre-trained multilingual models (BERT and XLM-RoBERTa) fine-tuned for domain-specific banking content, with lexicon correction addressing the unique challenges of Sinhala morphology and code-mixed syntax. The combination of strong language understanding with explainability tools allows both accurate classification and transparent decision-making, critical for financial applications where trust and interpretability are essential.

## Foundational Learning
- **BERT-base-uncased:** Pre-trained transformer model for English text; needed for strong baseline performance on monolingual English reviews; quick check: validate on standard English sentiment benchmarks
- **XLM-RoBERTa:** Multilingual transformer supporting over 100 languages; needed to handle Sinhala and code-mixed content; quick check: test on multilingual sentiment datasets
- **Domain-specific lexicon correction:** Custom vocabulary adaptation for banking terminology and Sinhala morphological features; needed to improve accuracy on low-resource languages; quick check: measure impact of lexicon updates on F1-score
- **SHAP (SHapley Additive exPlanations):** Game-theoretic method for feature importance; needed to provide trustworthy explanations; quick check: compare explanation consistency across multiple runs
- **LIME (Local Interpretable Model-agnostic Explanations):** Perturbation-based interpretability tool; needed for local instance explanations; quick check: verify stability of feature weights for similar inputs

## Architecture Onboarding

**Component map:** BERT-base-uncased -> Sentiment Classifier (English) | XLM-RoBERTa + Lexicon Correction -> Sentiment Classifier (Sinhala/Code-mixed) -> SHAP/LIME Explainers

**Critical path:** Text preprocessing → Model inference (BERT/XLM-RoBERTa) → Aspect-based sentiment classification → Explainability generation (SHAP/LIME)

**Design tradeoffs:** BERT-base-uncased offers strong English performance but limited multilingual coverage; XLM-RoBERTa provides broader language support but requires lexicon correction for low-resource languages; SHAP and LIME add interpretability but may exhibit inconsistency on code-mixed inputs.

**Failure signatures:** Performance degradation on out-of-domain banking terminology; unstable explanations for code-mixed text; reduced accuracy for rare Sinhala morphological forms.

**Three first experiments:**
1. Benchmark BERT-base-uncased and XLM-RoBERTa separately on a held-out validation set
2. Test lexicon correction impact by comparing with and without domain-specific vocabulary
3. Evaluate SHAP and LIME consistency by generating multiple explanations for the same input

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Can the hybrid XLM-RoBERTa framework be effectively generalized to other low-resource languages like Tamil?
- Basis in paper: [explicit] The conclusion explicitly suggests "extending the approach to other low-resource languages like Tamil."
- Why unresolved: The current model is fine-tuned specifically for Sinhala morphology; Tamil possesses distinct linguistic features that require specific validation.
- What evidence would resolve it: Performance metrics (Accuracy/F1-score) derived from testing the model on a Tamil banking review dataset.

### Open Question 2
- Question: Does incorporating multimodal cues (audio/video) significantly improve sentiment classification accuracy over the text-only model?
- Basis in paper: [explicit] Future work proposes "incorporating multimodal sentiment analysis using audio and video cues."
- Why unresolved: The current architecture is strictly text-based; the impact of audio-visual features on the specific banking domain remains untested.
- What evidence would resolve it: Comparative benchmarking of a multimodal version against the text baseline on the same customer interaction data.

### Open Question 3
- Question: How can the consistency of LIME and SHAP explanations be stabilized for code-mixed inputs?
- Basis in paper: [inferred] The limitations section notes that explainability tools "exhibited reduced consistency when applied to low-resource, code-mixed inputs."
- Why unresolved: Standard perturbation techniques often disrupt the fragile syntax of code-mixed text, causing unstable feature weighting.
- What evidence would resolve it: A code-mix-aware perturbation method that yields consistent explanation weights across multiple runs on Singlish samples.

## Limitations
- Absence of independent dataset validation; evaluation limited to the authors' own 15,000-review dataset
- No comparison with baseline models or state-of-the-art approaches to assess relative effectiveness
- Exclusive focus on banking domain raises concerns about domain-specific bias and generalizability
- Lack of empirical evidence for practical utility of explainability features in improving stakeholder trust

## Confidence
- **High confidence:** Technical feasibility of combining BERT-base-uncased with XLM-RoBERTa for multilingual sentiment analysis
- **Medium confidence:** Reported performance metrics due to lack of external validation and benchmark comparisons
- **Low confidence:** Practical utility of explainability features without user study evidence

## Next Checks
1. Conduct cross-dataset evaluation using publicly available sentiment analysis benchmarks for Sinhala, English, and code-mixed content to verify generalizability.
2. Perform ablation studies comparing the hybrid framework against single-model baselines (BERT-only, XLM-RoBERTa-only) and state-of-the-art multilingual sentiment analysis systems.
3. Design user studies with banking domain experts to assess whether SHAP and LIME explanations meaningfully improve trust, interpretability, and decision-making compared to black-box models.