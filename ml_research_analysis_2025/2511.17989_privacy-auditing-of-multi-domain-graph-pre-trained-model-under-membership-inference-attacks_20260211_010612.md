---
ver: rpa2
title: Privacy Auditing of Multi-domain Graph Pre-trained Model under Membership Inference
  Attacks
arxiv_id: '2511.17989'
source_url: https://arxiv.org/abs/2511.17989
tags:
- graph
- shadow
- membership
- target
- multi-domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses privacy risks in multi-domain graph pre-trained
  models under membership inference attacks (MIAs). It proposes MGP-MIA, a novel framework
  that overcomes three key challenges: reduced overfitting signals due to improved
  generalization, lack of representative shadow datasets, and weak membership signals
  in embedding-based outputs.'
---

# Privacy Auditing of Multi-domain Graph Pre-trained Model under Membership Inference Attacks

## Quick Facts
- arXiv ID: 2511.17989
- Source URL: https://arxiv.org/abs/2511.17989
- Reference count: 17
- Primary result: Proposes MGP-MIA framework achieving up to 26.6% higher accuracy and 25.0% higher F1-score on contrastive learning-based models

## Executive Summary
This paper addresses privacy risks in multi-domain graph pre-trained models under membership inference attacks (MIAs). The authors identify three key challenges: reduced overfitting signals due to improved generalization, lack of representative shadow datasets, and weak membership signals in embedding-based outputs. To overcome these challenges, they propose MGP-MIA, a novel framework that introduces membership signal amplification using machine unlearning, incremental shadow model construction with parameter regularization, and a similarity-based inference mechanism that extracts membership signals from embeddings.

## Method Summary
The paper presents MGP-MIA, a comprehensive framework for auditing privacy in multi-domain graph pre-trained models. The approach addresses three critical challenges: reduced overfitting signals from improved generalization, absence of representative shadow datasets, and weak membership signals in embedding-based outputs. MGP-MIA incorporates three key mechanisms: machine unlearning-based membership signal amplification to enhance attack effectiveness, incremental shadow model construction with parameter regularization to create representative shadow datasets, and similarity-based inference that extracts membership signals from embeddings rather than relying on traditional overfitting patterns.

## Key Results
- MGP-MIA achieves up to 26.6% higher accuracy and 25.0% higher F1-score on contrastive learning-based models
- Performance gains reach up to 16.3% higher accuracy and 10.8% higher F1-score on link-prediction-based models
- Extensive experiments demonstrate significant improvement over baseline methods across four representative multi-domain graph pre-trained models

## Why This Works (Mechanism)
The effectiveness of MGP-MIA stems from its multi-faceted approach to addressing the unique challenges of privacy auditing in multi-domain graph pre-trained models. The membership signal amplification mechanism counteracts the reduced overfitting signals by deliberately creating membership-relevant patterns through machine unlearning. The incremental shadow model construction with parameter regularization addresses the lack of representative shadow datasets by building them progressively while maintaining domain-specific characteristics. The similarity-based inference mechanism extracts membership signals from embeddings, which are more robust and informative than traditional outputs in graph-based models.

## Foundational Learning
1. **Membership Inference Attacks (MIAs)**: Privacy attacks that determine whether a specific data sample was used in training a machine learning model. Needed because understanding model privacy vulnerabilities is crucial for deployment in sensitive applications. Quick check: Can distinguish between training and non-training samples with statistical significance.

2. **Graph Pre-trained Models**: Models trained on large-scale graph data that learn transferable representations across multiple domains. Required understanding as the target of the privacy audit. Quick check: Model can perform transfer learning across different graph domains.

3. **Machine Unlearning**: The process of removing the influence of specific data points from a trained model. Essential for the membership signal amplification mechanism. Quick check: Successfully removes specific training examples' influence while maintaining overall model performance.

4. **Shadow Model Technique**: Creating surrogate models that mimic the behavior of target models for attack purposes. Critical for constructing representative shadow datasets. Quick check: Shadow models exhibit similar decision boundaries to target models.

## Architecture Onboarding

Component Map: Shadow Models -> Machine Unlearning -> Similarity Inference -> Membership Signal Extraction

Critical Path: Data Preparation -> Shadow Model Construction -> Membership Signal Amplification -> Inference Phase -> Attack Evaluation

Design Tradeoffs:
- Computational overhead vs. attack accuracy (machine unlearning adds processing time)
- Shadow model representativeness vs. resource constraints (incremental construction balances these)
- Inference granularity vs. false positive rates (similarity-based approach offers tunable sensitivity)

Failure Signatures:
- Poor shadow model performance indicates insufficient representation of target model behavior
- Low membership signal amplification suggests ineffective unlearning implementation
- High false positive rates may indicate overly aggressive similarity thresholds

First Experiments:
1. Baseline MIA performance comparison without MGP-MIA enhancements
2. Incremental shadow model construction validation across different regularization strengths
3. Machine unlearning effectiveness assessment on membership signal strength

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation limited to four specific multi-domain graph pre-trained models, potentially missing broader architectural diversity
- No discussion of potential defense mechanisms against the proposed MGP-MIA framework
- Machine unlearning-based membership signal amplification has known limitations regarding effectiveness and computational overhead

## Confidence

High confidence:
- Framework design and methodology are well-articulated with clear descriptions of each component
- Identification of three key challenges appears logically sound based on established privacy research principles

Medium confidence:
- Reported performance improvements are based on specific experimental setups and datasets
- Generalizability of results to different domains or larger-scale implementations requires further validation

Low confidence:
- Insufficient discussion of potential countermeasures or practical implications for real-world deployment
- Long-term effectiveness against evolving defense strategies remains uncertain

## Next Checks
1. Test MGP-MIA against a broader range of graph pre-trained model architectures, including those not specifically designed for multi-domain scenarios
2. Evaluate computational overhead and practical feasibility of machine unlearning-based membership signal amplification on large-scale graph datasets
3. Implement and benchmark potential defense strategies against MGP-MIA, such as differential privacy mechanisms or adversarial training techniques