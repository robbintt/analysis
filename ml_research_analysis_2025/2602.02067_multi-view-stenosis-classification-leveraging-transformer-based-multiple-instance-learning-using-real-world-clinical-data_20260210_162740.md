---
ver: rpa2
title: Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance
  Learning Using Real-World Clinical Data
arxiv_id: '2602.02067'
source_url: https://arxiv.org/abs/2602.02067
tags:
- stenosis
- segmentmil
- views
- view
- artery
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We propose SegmentMIL, a transformer-based multi-view multiple-instance
  learning framework for patient-level coronary stenosis classification. Our method
  jointly predicts the presence of stenosis and localizes the affected anatomical
  region, distinguishing between the right and left coronary arteries and their respective
  segments.
---

# Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data

## Quick Facts
- arXiv ID: 2602.02067
- Source URL: https://arxiv.org/abs/2602.02067
- Authors: Nikola Cenikj; Özgün Turgut; Alexander Müller; Alexander Steger; Jan Kehrer; Marcus Brugger; Daniel Rueckert; Eimo Martens; Philip Müller
- Reference count: 40
- We propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level coronary stenosis classification. Our method jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. Trained on real-world clinical data using only patient-level supervision without any view-level annotations, SegmentMIL outperforms both view-level models and classical MIL baselines. On internal and external evaluations, our best configuration achieves patient-level AUCs of 0.845 and 0.878, respectively, demonstrating significant improvements over existing approaches and underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis.

## Executive Summary
This paper presents SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level coronary artery stenosis classification. The method processes multiple angiography views per patient to jointly predict stenosis presence and localize affected anatomical regions without requiring segment-level annotations during training. The hierarchical prediction architecture operates at patient, artery (RCA/LCA), and segment levels, using a ViT encoder with learned temporal embeddings and a transformer decoder with 11 query tokens. Trained on real-world clinical data with only patient-level supervision, SegmentMIL demonstrates superior performance compared to both view-level models and classical MIL baselines.

## Method Summary
The proposed SegmentMIL framework addresses coronary stenosis classification as a multi-instance learning problem where multiple angiography views serve as instances for patient-level diagnosis. The method employs a ViT-S/14 encoder initialized with DinoV2 weights to process key frames extracted from each view using an ArterySeg model. A transformer decoder with 11 learned query tokens (1 patient, 2 artery, 8 segment) performs hierarchical predictions, where segment predictions are multiplied by artery predictions and artery predictions by patient predictions. The model uses multi-frame inputs with learned temporal embeddings, sampling 3 frames around the detected key frame. Training employs a weighted BCE loss (P=0.4, A=0.4, S=0.2) over 100 epochs with AdamW optimizer and cosine-annealing learning rate schedule.

## Key Results
- SegmentMIL achieves patient-level AUC of 0.845 on internal clinical dataset and 0.878 on external CADICA dataset
- Outperforms both view-level models and classical MIL baselines by 2-3% in AUC
- Multi-frame temporal modeling provides 1.6-2% performance gain over single-frame approach
- Hierarchical prediction structure enables joint stenosis detection and anatomical localization

## Why This Works (Mechanism)
The transformer-based architecture leverages self-attention mechanisms to capture complex spatial and temporal relationships across multiple angiography views. By using learned query tokens for different anatomical levels, the model can attend to relevant features at each hierarchy level while maintaining explicit anatomical correspondence. The hierarchical prediction multiplication enforces consistency between segment, artery, and patient-level predictions, effectively regularizing the learning process when only patient-level labels are available.

## Foundational Learning
- **Multiple Instance Learning (MIL)**: Allows training on patient-level labels while making segment-level predictions, crucial for medical imaging where fine-grained annotations are expensive
  - Why needed: Segment-level stenosis annotations require expert review of each view
  - Quick check: Verify model can predict segment-level probabilities despite only patient-level supervision

- **Transformer decoder with learned queries**: Enables explicit anatomical correspondence through structured query tokens
  - Why needed: Different coronary artery segments require different diagnostic features
  - Quick check: Confirm query tokens specialize to different anatomical regions

- **Hierarchical prediction multiplication**: Enforces consistency across prediction levels while allowing credit assignment
  - Why needed: Patient-level labels need to be decomposed into segment-level predictions
  - Quick check: Verify multiplication preserves probability interpretation

- **Temporal modeling with learned embeddings**: Captures dynamic features across multiple frames per view
  - Why needed: Stenosis appearance changes with cardiac motion and contrast flow
  - Quick check: Compare 1-frame vs 3-frame performance

## Architecture Onboarding

**Component Map**: Raw angiography video -> ArterySeg key frame detection -> ViT-S/14 encoder -> Learned temporal embeddings -> Transformer decoder -> Hierarchical MLP heads -> Segment/artery/patient predictions

**Critical Path**: The model processes each view independently through the encoder, then aggregates across views using the decoder's query tokens. The hierarchical multiplication (Eq. 1) is critical for propagating segment-level information to patient-level predictions.

**Design Tradeoffs**: 
- Uses image-based encoder with learned temporal embeddings rather than native video transformer (partially captures dynamics)
- Restricts to major segments (8/16) for reliable supervision, limiting anatomical coverage
- Employs hierarchical prediction instead of end-to-end fine-tuning (simplifies training but may lose some information)

**Failure Signatures**: 
- Poor key frame detection leads to degraded performance across all levels
- Class imbalance at segment level causes unstable training and unreliable minor segment predictions
- Temporal embeddings may not capture meaningful dynamics if frame sampling is suboptimal

**3 First Experiments**:
1. Implement single-frame baseline (K=1) to establish performance floor
2. Test different temporal sampling strategies (e.g., uniform vs centered around key frame)
3. Vary the hierarchical loss weights (P/A/S) to assess sensitivity

## Open Questions the Paper Calls Out
- Can employing video-based encoders improve the modeling of temporal dynamics and stenosis detection performance compared to the current image-based encoder with learned temporal embeddings?
- Does the integration of additional patient context, such as medical history and clinical symptoms, significantly improve the diagnostic accuracy of the model?
- Can the model effectively learn to recognize stenosis in smaller, non-major coronary artery segments if the supervision is expanded beyond the current subset?

## Limitations
- Internal clinical dataset not publicly available, preventing direct validation
- External validation on very small CADICA dataset (42 patients) limits generalizability conclusions
- Method relies on ArterySeg model for key frame detection, adding dependency on external model performance

## Confidence

- **High confidence**: Core methodological contribution (transformer-based MIL with hierarchical prediction) is well-defined and evaluation framework is clearly specified
- **Medium confidence**: Key frame detection approach and multi-frame temporal modeling show reasonable performance gains, but generalizability depends on ArterySeg model
- **Low confidence**: Exact implementation details (transformer decoder architecture, MLP heads, training hyperparameters) are not fully specified

## Next Checks
1. Reimplement the ArterySeg key frame detection pipeline using the ARCADE dataset and evaluate its performance on a held-out subset of angiography views, comparing detected key frames against expert annotations
2. Conduct ablation studies on the hierarchical prediction weighting scheme by systematically varying the P/A/S weights (0.4/0.4/0.2) and evaluating the impact on patient-level AUC across different artery and segment categories
3. Validate the multi-frame temporal modeling approach by implementing the learned temporal embeddings and comparing performance across different frame sampling strategies (1-frame, 2-frame, 3-frame) on a publicly available coronary angiography dataset with segment-level annotations