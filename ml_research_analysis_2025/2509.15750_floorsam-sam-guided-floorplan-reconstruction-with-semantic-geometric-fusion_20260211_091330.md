---
ver: rpa2
title: 'FloorSAM: SAM-Guided Floorplan Reconstruction with Semantic-Geometric Fusion'
arxiv_id: '2509.15750'
source_url: https://arxiv.org/abs/2509.15750
tags:
- point
- room
- cloud
- segmentation
- mask
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FloorSAM integrates density maps and SAM for indoor floorplan reconstruction
  from LiDAR point clouds, achieving high accuracy across diverse layouts. It addresses
  noise sensitivity, limited generalization, and geometric detail loss by using grid-based
  filtering, adaptive resolution projection, and image enhancement to create robust
  top-down density maps.
---

# FloorSAM: SAM-Guided Floorplan Reconstruction with Semantic-Geometric Fusion

## Quick Facts
- **arXiv ID:** 2509.15750
- **Source URL:** https://arxiv.org/abs/2509.15750
- **Reference count:** 40
- **Primary result:** Achieves precision above 0.90 and recall above 0.94 on Giblayout and ISPRS datasets

## Executive Summary
FloorSAM integrates density maps and the Segment Anything Model (SAM) for indoor floorplan reconstruction from LiDAR point clouds. It addresses noise sensitivity, limited generalization, and geometric detail loss by using grid-based filtering, adaptive resolution projection, and image enhancement to create robust top-down density maps. Leveraging SAM's zero-shot learning, it generates high-quality room masks via adaptive prompt points, followed by multistage filtering and joint mask-point cloud contour extraction. Experiments show precision above 0.90 and recall above 0.94, outperforming traditional methods and state-of-the-art deep learning approaches in noisy environments and complex layouts.

## Method Summary
FloorSAM reconstructs 2D floorplans with room topological relationships from 3D LiDAR point clouds using a zero-shot learning approach. The method projects filtered ceiling-point clouds into bird's-eye-view density maps, extracts adaptive prompt points from density peaks, and uses SAM to generate room masks. These masks undergo coarse and fine filtering, then are regularized by fusing with point cloud boundary points. The approach requires no training and operates on standard indoor LiDAR datasets like Giblayout and ISPRS.

## Key Results
- Precision above 0.90 and recall above 0.94 on Giblayout and ISPRS datasets
- Outperforms traditional methods and state-of-the-art deep learning approaches in noisy environments
- Successfully recovers topological relationships and enables applications in indoor navigation, BIM, and precise measurements

## Why This Works (Mechanism)

### Mechanism 1: Ceiling-Point Density Map Generation with Adaptive Resolution
Projecting filtered ceiling-point clouds into bird's-eye-view density maps creates robust spatial representations that suppress furniture/occlusion noise while preserving wall boundaries. Grid-based filtering retains points within 0.1m of maximum z-height per grid cell, eliminating low objects. Adaptive resolution scales with point cloud density. Logarithmic transformation + Gaussian blur (σ=5) + CLAHE enhancement boosts contrast for weak density regions.

### Mechanism 2: SAM Zero-Shot Segmentation with Adaptive Prompt Points
SAM's zero-shot capability, guided by density-derived prompt points, segments rooms without domain-specific training, generalizing across layouts that would degrade Mask R-CNN. Local density peaks detected via max-pooling on enhanced density map; threshold τ = 0.9·mean(D'). Minimum 10-pixel spacing ensures uniform coverage. SAM generates multi-scale candidate masks per prompt point.

### Mechanism 3: Joint Mask-Point Cloud Contour Regularization
Fusing SAM's semantic masks with geometric point cloud boundary points corrects over-regularization and preserves non-Manhattan features. RDP algorithm simplifies mask contours with dynamic ε. Main direction θ_main determined from longest segment. Point cloud boundary points (detected via KD-Tree angular gap >30°) correct mask contours when distance exceeds τ=0.05m.

## Foundational Learning

- **Concept: Bird's-Eye-View (BEV) Projection**
  - Why needed here: Converts 3D point cloud to 2D density map for SAM input; preserves spatial topology while reducing dimensionality
  - Quick check question: Can you explain why BEV projection preserves room adjacency but loses wall height information?

- **Concept: Zero-Shot Segmentation**
  - Why needed here: SAM segments unseen room layouts without floorplan-specific training, overcoming Mask R-CNN's generalization limits (>30% accuracy drop on novel layouts)
  - Quick check question: What distinguishes zero-shot learning from transfer learning in the context of SAM?

- **Concept: Ramer-Douglas-Peucker (RDP) Algorithm**
  - Why needed here: Simplifies mask contours while preserving key vertices; dynamic ε adapts to point cloud density
  - Quick check question: How does RDP decide which points to keep vs. discard, and what's the tradeoff in ε selection?

## Architecture Onboarding

- **Component map:**
  ```
  Point Cloud → [Grid Filter] → [Adaptive Projection] → [Image Enhancement] → Density Map
                                                                              ↓
  Density Map → [Peak Detection] → Prompt Points → [SAM] → Candidate Masks
                                                              ↓
  Candidate Masks → [Coarse Filter: connectivity/IoU/area] → [Fine Filter: grouping/inclusion/combinatorial] → Room Masks
                                                                                                              ↓
  Room Masks + Point Cloud → [Contour Extraction + RDP] → [Joint Correction] → [Topology Recovery] → Floorplan
  ```

- **Critical path:** Density map quality → Prompt point coverage → Mask filtering accuracy → Contour correction precision. Each stage is sequential dependency.

- **Design tradeoffs:**
  - Grid size γ=0.1m: Smaller preserves detail but increases noise; larger smooths but may miss narrow walls
  - Prompt point spacing 10px: Denser improves coverage but increases SAM computation; sparser risks missed rooms
  - Coverage threshold 95% (Eq. 5): Higher ensures completeness but may retain lower-quality masks

- **Failure signatures:**
  - Missing rooms → Check ceiling point cloud availability in density map
  - Over-segmented rooms → Examine IoU threshold in coarse filtering (0.8 may be too permissive)
  - Jagged contours → Verify point cloud boundary detection (angular gap threshold may be too sensitive)
  - Merged adjacent rooms → Check fine filtering inclusion analysis (90% overlap threshold may be too strict)

- **First 3 experiments:**
  1. **Density map ablation:** Test with/without CLAHE enhancement and log transform on Giblayout scene with furniture occlusion. Measure mask IoU vs. ground truth
  2. **Prompt point density sweep:** Vary minimum spacing from 5px to 20px on ISPRS corridor scene. Record room recall and SAM inference time
  3. **Contour correction threshold:** Vary τ from 0.02m to 0.10m on non-Manhattan layout. Measure precision/recall of boundary edges vs. manually drawn ground truth

## Open Questions the Paper Calls Out

- **Open Question 1:** How can ground-level geometric features be effectively integrated with ceiling density maps to improve reconstruction robustness in environments with partial or missing ceiling data?
- **Open Question 2:** Can image-based segmentation be fused with the current LiDAR pipeline to accurately recover window structures without degrading the geometric regularity of wall contours?
- **Open Question 3:** How can the projection-based methodology be adapted to handle multi-story buildings while maintaining distinct room topologies for overlapping floors?

## Limitations
- Ceiling point dependence limits applicability in open atriums or ground-level scans
- SAM generalization risk on LiDAR-derived density maps remains unproven
- Parameter sensitivity with empirically chosen thresholds lacking sensitivity analysis

## Confidence
- **High confidence:** Grid-based ceiling filtering mechanism and density map generation
- **Medium confidence:** SAM integration for zero-shot segmentation
- **Medium confidence:** Joint mask-point cloud contour regularization

## Next Checks
1. **Cross-dataset generalization test:** Apply FloorSAM to Matterport3D or Stanford2D-3D with different point cloud densities
2. **Ablation study on density map components:** Systematically disable CLAHE enhancement and log transform
3. **Real-time performance evaluation:** Measure SAM inference time per prompt point and total pipeline latency on commodity hardware