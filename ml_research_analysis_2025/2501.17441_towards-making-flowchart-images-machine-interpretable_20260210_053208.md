---
ver: rpa2
title: Towards Making Flowchart Images Machine Interpretable
arxiv_id: '2501.17441'
source_url: https://arxiv.org/abs/2501.17441
tags:
- flowchart
- code
- images
- dataset
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FloCo, the first large-scale dataset for
  the Flow2Code task, containing 11,884 flowchart images and corresponding Python
  codes. The authors propose FloCo-T5, a transformer-based framework that converts
  flowchart images to executable Python code.
---

# Towards Making Flowchart Images Machine Interpretable

## Quick Facts
- **arXiv ID**: 2501.17441
- **Source URL**: https://arxiv.org/abs/2501.17441
- **Authors**: Shreya Shukla; Prajwal Gatti; Yogesh Kumar; Vikash Yadav; Anand Mishra
- **Reference count**: 35
- **Primary Result**: FloCo-T5 achieves BLEU 67.4, CodeBLEU 75.7, and Exact Match 20.0 on Flow2Code task

## Executive Summary
This paper introduces FloCo, the first large-scale dataset for the Flow2Code task, containing 11,884 flowchart images and corresponding Python codes. The authors propose FloCo-T5, a transformer-based framework that converts flowchart images to executable Python code. Their approach involves converting flowchart images into sequence encodings using OCR and shape detection, pre-training CodeT5 with logic-preserving augmented code samples using masked token modeling, and fine-tuning for code generation. Experiments show that FloCo-T5 outperforms competitive baselines like BART, PLBART, and CodeT5.

## Method Summary
The authors propose FloCo-T5, a transformer-based framework for converting flowchart images to executable Python code. The approach converts flowchart images into sequence encodings using EasyOCR for text detection and OpenCV Hough transforms for shape detection, creating "modified string encodings" that map text to flowchart shapes. The model uses CodeT5-base as the architecture, pre-trained with Masked Token Modeling on logic-preserving augmented data (40,408 samples after augmentation), then fine-tuned for sequence-to-sequence generation. The model achieves BLEU 67.4, CodeBLEU 75.7, and Exact Match 20.0 on the FloCo dataset.

## Key Results
- FloCo-T5 achieves BLEU 67.4, CodeBLEU 75.7, and Exact Match 20.0 on test set
- Outperforms BART, PLBART, and CodeT5 baselines on Flow2Code task
- Demonstrates reasonable generalization to hand-drawn flowcharts
- Performance degrades significantly on longer programs (>15 lines): BLEU drops to 16.7, CodeBLEU to 37.3

## Why This Works (Mechanism)
The approach works by converting visual flowchart elements into structured text representations that transformers can process. The modified string encoding preserves spatial relationships between shapes and their associated text, allowing the model to learn the logical flow of programs. Pre-training with masked token modeling on augmented data (randomized function/variable names) helps the model generalize beyond specific naming patterns. The transformer architecture effectively captures the sequential dependencies in program logic from the encoded flowchart structure.

## Foundational Learning
- **Flowchart-to-text encoding**: Converting visual flowchart elements into structured text format is essential for making the visual information machine-interpretable. Quick check: Verify that all flowchart shapes are correctly detected and mapped to their associated text.
- **Masked language modeling**: Pre-training with masked tokens helps the model learn robust representations by forcing it to predict missing information. Quick check: Monitor reconstruction accuracy during pre-training.
- **Sequence-to-sequence generation**: The transformer learns to map encoded flowchart representations to executable code by capturing sequential dependencies. Quick check: Evaluate generation quality using BLEU and CodeBLEU metrics.

## Architecture Onboarding

**Component Map**: Flowchart Image → OCR + Shape Detection → Modified String Encoding → CodeT5 Encoder → Decoder → Python Code

**Critical Path**: The most critical components are the shape detection and text-to-shape matching algorithm, as errors here propagate directly to code generation quality. The pre-training phase with logic-preserving augmentation is also crucial for generalization.

**Design Tradeoffs**: Using modified string encoding instead of raw image inputs trades some spatial information for better sequence processing by transformers. The choice of CodeT5 over other architectures leverages its code-specific pretraining while maintaining manageable parameter count (222.9M).

**Failure Signatures**: 
- Incorrect encoding format drops BLEU from 67.4 to ~16.7
- Poor logic preservation causes large gaps between BLEU and CodeBLEU scores
- Performance degradation on longer programs (>15 lines) indicates dataset bias

**First Experiments**:
1. Validate modified string encoding generation on sample flowcharts
2. Test pre-training impact by comparing with randomly initialized CodeT5
3. Evaluate different augmentation strategies on model generalization

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- Severe performance degradation on longer programs (>15 lines) with BLEU dropping to 16.7
- Lack of detailed specifications for shape detection and text-to-shape matching algorithm
- No systematic ablation studies on key design choices or input encoding alternatives

## Confidence

**High Confidence**: Baseline comparisons and dataset creation methodology are well-documented and methodologically sound.

**Medium Confidence**: Generalization claims to hand-drawn flowcharts lack quantitative metrics and detailed evaluation methodology.

**Low Confidence**: Long-term practical utility given severe performance drop on longer programs and limited evaluation across diverse flowchart complexities.

## Next Checks
1. Implement and validate the coordinate matching algorithm using the linked code repository to ensure consistent modified string encoding generation.
2. Conduct systematic ablation studies to quantify the contribution of pre-training, augmentation strategy, and encoding format to final performance.
3. Evaluate on longer and more complex flowcharts (20+ lines, multiple nested functions) to assess scalability beyond current dataset limitations.