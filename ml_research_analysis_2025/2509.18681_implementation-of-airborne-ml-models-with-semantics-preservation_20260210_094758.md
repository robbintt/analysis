---
ver: rpa2
title: Implementation of airborne ML models with semantics preservation
arxiv_id: '2509.18681'
source_url: https://arxiv.org/abs/2509.18681
tags:
- mlmd
- onnx
- metric
- which
- semantics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to verify that an ML model replicated
  in a target environment (TIM) preserves the same properties as the original model
  (TFM) verified during training. The approach defines semantic levels of ML model
  representation and uses metrics with associated error margins to ensure properties
  like accuracy and generalization are maintained despite differences in numerical
  precision or hardware.
---

# Implementation of airborne ML models with semantics preservation

## Quick Facts
- arXiv ID: 2509.18681
- Source URL: https://arxiv.org/abs/2509.18681
- Reference count: 40
- Method verifies ML model replication preserves properties through metrics with error margins

## Executive Summary
This paper addresses the challenge of verifying that a target implementation model (TIM) running on embedded airborne hardware preserves the same safety properties as the original training framework model (TFM). The authors define semantic levels of ML model representation and use metrics with associated error margins to ensure properties like accuracy and generalization are maintained despite differences in numerical precision or hardware. The approach allows ML models to be certified for airborne applications by demonstrating exact replication on target systems through comparison against defined metrics and error bounds.

## Method Summary
The method implements a W-shaped development lifecycle (ED-324) where TFM is verified during training, then a target implementation model (TIM) is created and validated against the TFM using semantic levels and error margins. The approach defines four semantic levels from pure mathematics (SL0) to hardware execution (SL3), uses ONNX as an unambiguous intermediary representation, and calculates allowable error budgets based on the difference between actual model performance and safety requirements. The TIM is generated from the ONNX MLMD and verified by ensuring prediction deviations stay within calculated error margins.

## Key Results
- C code generated from ONNX models running on embedded platforms can replicate TFM behavior within acceptable error bounds for FP32 and INT16 precision
- The method successfully validates that safety properties are preserved when the TFM performance has sufficient slack above safety requirements
- Very low precision formats like BF16 failed to maintain required error margins, demonstrating the method's sensitivity to precision tradeoffs

## Why This Works (Mechanism)

### Mechanism 1: Error Budgeting via Metric Slack
The method creates a "budget" (g_M) as the difference between TFM's actual performance and the required safety bound (R_M), then calculates a maximum allowable error margin (ε_M) for implementation deviation. If L_∞(f̂_1, f̂_2) ≤ ε_M, the TIM is compliant without needing bit-exact replication. This works when the verification dataset is representative and the metric captures all relevant safety properties. The break condition occurs when TFM performance is too close to the safety limit, forcing bit-exact implementation or a better model.

### Mechanism 2: Semantic Level (SL) Abstraction
Decomposing model replication into SL0 (math) through SL3 (hardware execution) isolates sources of numerical discrepancies, allowing controlled relaxation of precision requirements. By defining the MLMD at an intermediate level, the implementation process can tolerate hardware-level variances as long as they don't violate higher-level semantic constraints. This assumes code generators correctly translate MLMD operations without introducing untracked drift. Break occurs if aggressive optimizations violate SL2 operational semantics.

### Mechanism 3: ONNX as the Unambiguous Intermediary
Using standardized ONNX format as MLMD decouples training framework quirks from embedded deployment, reducing risk of propagating framework-specific implementation bugs. The TFM is exported to ONNX capturing weights and architecture while discarding training-only metadata. This assumes the exporter correctly captures TFM logic without semantic drift during translation. Break occurs if custom operators must be approximated during export.

## Foundational Learning

- **Concept: W-Shaped Development Lifecycle (ED-324)**
  - Why needed: The paper is built entirely around complying with ED-324, which splits development into "Design intended function" (V1) and "Replication in Target Model" (V2).
  - Quick check: Does TIM verification require re-verifying generalization against full test dataset, or only verifying consistency against TFM outputs?

- **Concept: Floating Point Arithmetic and IEEE 754**
  - Why needed: Semantic Levels and Error Margins exist because floating-point math varies between GPUs (training) and PowerPCs (airborne).
  - Quick check: Why might (a + b) + c ≠ a + (b + c) in FP32, and how does SL2 semantics attempt to fix this?

- **Concept: Regression Metrics (R², MAE, L∞)**
  - Why needed: The paper reduces "safety" to mathematical bounds on these metrics.
  - Quick check: If required R² is 0.8 and your TFM achieves 0.82, what is your safety budget g_R²?

## Architecture Onboarding

- **Component map:** Keras Model (TFM) -> ONNX MLMD -> Code Generators (ACETONE/Scade) -> C Code -> Embedded Binary (TIM) on NXP T1042/PowerPC -> Verifier script computing L∞(f̂_1, f̂_2)

- **Critical path:**
  1. Define Requirements: Set safety bounds R_M (e.g., R² ≥ 0.8)
  2. Train & Verify TFM: Confirm TFM has slack (e.g., TFM R² = 0.84, so g_M = 0.04)
  3. Calculate ε_M: Derive max allowed error between TFM and TIM (e.g., ε ≤ 0.015)
  4. Generate TIM: Export ONNX → C Code → Compile
  5. Validate TIM: Run test vectors on target hardware; ensure prediction deviation < ε_M

- **Design tradeoffs:**
  - Precision vs. Margin: Lower precision increases speed/efficiency but increases error ε_i. If ε_i > ε_M, design is invalid.
  - Toolchain Lock-in: Relying on specific code generators ties certification evidence to that tool's behavior (SL3 semantics).

- **Failure signatures:**
  - Margin Breach: L∞ error between TFM and TIM exceeds ε_M (e.g., due to overflow in INT8)
  - Semantic Drift: Classification accuracy drops because Argmax logic differs between frameworks

- **First 3 experiments:**
  1. Baseline Slack Calculation: Train model and compute g_M for all metrics to ensure room for implementation error
  2. SL3 Drift Test: Run inference on x86 (TFM) vs. PowerPC (TIM) using FP32; verify L∞ error within ε_M
  3. Precision Stress Test: Force INT16/INT12 quantization and measure increase in error ε_i to find lowest precision satisfying safety margin

## Open Questions the Paper Calls Out
None

## Limitations
- The approach assumes numerical precision errors are the dominant source of TIM-TFM deviation, potentially missing compiler optimization effects
- Certification relies heavily on representativeness of verification dataset without statistical coverage analysis
- The method assumes ONNX exporter perfectly preserves model semantics, but custom operators might not translate cleanly

## Confidence

- **High Confidence:** Mathematical framework for calculating error budgets and margins is sound and internally consistent
- **Medium Confidence:** Experimental results for FP32 and INT16 formats appear robust, but limited precision testing leaves gaps
- **Low Confidence:** Assumption that ONNX serves as perfect semantic intermediary is stated but not empirically validated

## Next Checks
1. Conduct statistical coverage analysis of verification dataset to quantify representativeness, including KL divergence between training, verification, and real-world input distributions

2. Implement end-to-end testing across complete precision spectrum (FP32, FP16, BF16, INT8, INT4) on representative airborne hardware to map precision-performance tradeoff

3. Perform comparative analysis of different code generators (ACETONE, Scade, ONNX2C) on identical models to identify whether semantic drift originates from MLMD format or code generation process