---
ver: rpa2
title: Provably Secure Retrieval-Augmented Generation
arxiv_id: '2508.01084'
source_url: https://arxiv.org/abs/2508.01084
tags:
- knowledge
- data
- security
- answer
- private
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SAG, the first provably secure framework for
  Retrieval-Augmented Generation (RAG) systems. SAG addresses privacy and security
  risks in RAG, such as data leakage and poisoning, by using pre-storage encryption
  to protect both retrieved content and vector embeddings.
---

# Provably Secure Retrieval-Augmented Generation

## Quick Facts
- **arXiv ID:** 2508.01084
- **Source URL:** https://arxiv.org/abs/2508.01084
- **Reference count:** 40
- **Primary result:** First provably secure framework for RAG systems with 0% attack success rates against prompt injection, membership inference, and poisoning attacks.

## Executive Summary
This paper introduces SAG (Secure Augmented Generation), the first provably secure framework for Retrieval-Augmented Generation (RAG) systems. SAG addresses critical privacy and security vulnerabilities in RAG by employing pre-storage encryption to protect both retrieved content and vector embeddings. The framework ensures that only authorized entities can access data through formal security guarantees proven under a computational security model, effectively defending against state-of-the-art attacks including prompt injection, membership inference, and data poisoning.

## Method Summary
SAG implements a pre-storage full-encryption scheme that protects both text chunks and their corresponding vector embeddings before they enter the vector database. The framework offers two encryption strategies: Chained Dynamic Key Derivation for forward security and tamper resistance, and Isolated AES Scheme for efficiency. During query processing, a Validator authenticates users and releases entry keys to a TEE-based Decryptor, which reconstructs the private knowledge base for authorized users only. The system then performs standard vector retrieval over the decrypted combined database (private + public) and generates responses through an LLM.

## Key Results
- Achieves 0% Attack Success Rate (LASR/PASR) against prompt injection, membership inference, and poisoning attacks across all tested scenarios
- Demonstrates zero knowledge leakage while maintaining competitive retrieval performance
- Provides formal security proofs under computational security model with rigorous mathematical guarantees
- Offers two encryption strategies balancing security (Chained Dynamic Key Derivation) and efficiency (Isolated AES Scheme)

## Why This Works (Mechanism)

### Mechanism 1: Knowledge Isolation via Pre-Storage Encryption
Encrypting data and embeddings before storage prevents unauthorized access and poisoning by isolating private knowledge bases. The system applies symmetric encryption ($E_{key}$) to both raw content ($C^U_i$) and vector embeddings ($E^U_i$) on the client side before they reach the database. Upon query, a Validator checks user identity ($ID^U$), allowing the Decryptor to reconstruct the private DB ($DB^U_{priv}$) only for authorized users. Public data is protected by HMAC integrity checks. The isolation fails if the server-side Decryption environment is compromised (TEE breach) or keys are exfiltrated.

### Mechanism 2: Forward Security via Chained Key Derivation
The Chained Dynamic Key Derivation scheme uses HKDF to derive the key for node $i+1$ based on the key for node $i$ ($key^U_{i+1} \leftarrow HKDF(key^U_i)$). Because the derivation function is one-way, an attacker obtaining $key^U_i$ cannot compute $key^U_{i-1}$. This ensures that compromising a current encryption key does not allow an adversary to decrypt historical data nodes. The mechanism breaks if the cryptographic hash collision resistance is broken or the master key is compromised during initial derivation.

### Mechanism 3: Authenticated Retrieval Gateway (Authdoor)
The Authdoor prevents unauthorized users from deriving the entry point to the private knowledge chain using a verification token $Authdoor^U = H(ID^U || key_{master}) \oplus (ID^U || key_1 || Addr_1)$. The server validates identity by checking the hash output against the XORed plaintext ID. Only upon a match are the first key and address released to the Decryptor. The mechanism breaks if an adversary solves the PRF distinction problem or finds collisions in $H$.

## Foundational Learning

- **Concept: IND-CPA (Indistinguishability under Chosen-Plaintext Attack)**
  - **Why needed here:** The paper claims "provably secure" confidentiality. This relies on the standard cryptographic definition (IND-CPA) of the underlying AES-CBC encryption mode used for the nodes.
  - **Quick check question:** If an adversary asks the system to encrypt two specific messages and sees the ciphertext, can they guess which message was encrypted with probability > 50%? (Answer should be no).

- **Concept: Trusted Execution Environments (TEEs)**
  - **Why needed here:** The security proofs explicitly assume runtime secrets (keys, decrypted states) reside in TEEs (e.g., Intel SGX). Without understanding TEEs, one might assume the system defends against physical memory access, which it does not.
  - **Quick check question:** Does the SAG framework protect data if the server administrator can dump the RAM of the decryption process? (Answer: Only if the RAM is inside the TEE secure enclave).

- **Concept: Embedding Inversion**
  - **Why needed here:** A specific motivation for SAG is protecting vector embeddings ($E^U_i$), not just text. Learners must understand that embeddings can be "inverted" to reveal semantic information, necessitating their encryption.
  - **Quick check question:** Why isn't encrypting the text chunks sufficient? (Answer: Adversaries can query the vector database directly to extract semantic meaning from unencrypted embeddings).

## Architecture Onboarding

- **Component map:** Client/Encryptor -> Validator -> TEE-based Decryptor -> Retriever -> LLM
- **Critical path:** Ingest: Chunk Data → Embed → Encrypt → Store. Query: Authenticate → Decrypt Private Nodes → Merge with Public → Retrieve → Generate.
- **Design tradeoffs:**
  - Chained Dynamic Key: Higher security/integrity (tamper-proof chaining) but higher latency (~6.4s for 10 chunks) and complexity
  - Isolated AES: Lower latency (~2.3s for 10 chunks) and simpler integration, but relies solely on AES-CBC security without the chained integrity benefits
- **Failure signatures:**
  - Decryption Error: "Hash mismatch" during chain traversal (indicates tampering or corruption)
  - Auth Failure: Validator returns ⊥ (indicates invalid $ID^U$ or $key_{master}$)
  - Hallucination/Leak: If $DB^U_{priv}$ is empty for an authorized user, LLM relies solely on $DB_{pub}$
- **First 3 experiments:**
  1. Latency Profile: Ingest 100 documents using both "Chained" and "Isolated" schemes to replicate the total time overhead difference
  2. Integrity Test: Implement the "Chained" scheme, manually flip a bit in an intermediate node in the VectorDB, and verify that the decryption process detects the hash mismatch and halts (Algorithm 2)
  3. Isolation Validation: Authenticate as User A, query for data explicitly belonging to User B (if User B's data is in the same physical DB), and confirm zero retrieval (LASR = 0.00)

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the SAG framework be extended to provide provable security for Knowledge-Augmented Generation (KAG) systems that utilize structured graph-based reasoning?
- **Basis in paper:** [explicit] The authors explicitly state that their current design "does not explicitly address security protection for knowledge-augmented RAG systems (KAG), where structured graph-based reasoning and multi-hop entity traversal introduce new attack surfaces."
- **Why unresolved:** The current SAG architecture encrypts independent document chunks, whereas KAG systems rely on traversing relationships between entities in a knowledge graph, requiring a security model that protects the graph structure and relational integrity during multi-hop reasoning.
- **What evidence would resolve it:** A modified SAG protocol applied to a graph-based RAG system that formally proves the confidentiality of node/relation attributes and the integrity of traversal paths during the reasoning process.

### Open Question 2
- **Question:** How can strict pre-storage encryption and user-level isolation be adapted to support open-domain collaborative retrieval without compromising security?
- **Basis in paper:** [explicit] The authors acknowledge the framework is "less effective in open-domain recommendation scenarios, where user-uploaded content is directly incorporated into a shared vector index for collaborative retrieval," noting that strict isolation conflicts with cross-user similarity computation.
- **Why unresolved:** Collaborative filtering requires the ability to compute similarity across the encrypted vectors of multiple users, which is currently prevented by the framework's strict isolation and lack of support for operations over encrypted data (like homomorphic encryption).
- **What evidence would resolve it:** An extension of SAG that allows for secure multi-party computation or privacy-preserving similarity search across the encrypted private knowledge bases of multiple users.

### Open Question 3
- **Question:** Can the Chained Dynamic Key Derivation mechanism be optimized to reduce its computational overhead to levels comparable with the Isolated AES Scheme?
- **Basis in paper:** [inferred] The authors analyze time-related limitations in Section E.4, revealing that the Chained scheme incurs significantly higher latency (approx. 6.4s for 10 chunks) compared to the Isolated AES Scheme (approx. 2.3s) due to the complexity of sequential key management.
- **Why unresolved:** The Chained scheme offers superior tamper resistance through linked integrity verification, but the computational cost of dynamic key derivation and chained decryption limits its deployment in latency-sensitive applications.
- **What evidence would resolve it:** An optimized version of the Chained scheme that reduces decryption overhead (e.g., through parallelization or more efficient key derivation functions) while maintaining the same IND-CPA security proofs.

## Limitations
- The framework's reliance on TEEs is a significant limitation not fully validated in the experimental evaluation
- The evaluation focuses on controlled attack scenarios using predefined prompts, which may not capture the full spectrum of real-world adversarial behaviors
- Scalability analysis is limited to moderate-sized datasets, leaving questions about performance in enterprise-scale deployments

## Confidence

**High Confidence:** The cryptographic mechanisms for data encryption and authentication (AES-CBC, HMAC) are well-established and the proofs for confidentiality and integrity properties are mathematically rigorous. The zero attack success rates against the specific attacks tested (LASR/PASR metrics) are directly measurable from the experimental results.

**Medium Confidence:** The forward security guarantees via chained key derivation are theoretically sound based on HKDF assumptions, but the practical implications of key management overhead and potential implementation vulnerabilities require further validation. The security isolation between users is convincingly demonstrated for the tested scenarios but may face challenges in more complex multi-tenant environments.

**Low Confidence:** The TEE-based runtime protection claims lack empirical validation in the experiments. The framework's behavior against adaptive, real-world attacks that could potentially bypass the authentication gateway remains speculative. The scalability guarantees for large-scale deployments are not empirically verified.

## Next Checks

1. **TEE Vulnerability Assessment:** Conduct a formal security analysis of the TEE assumptions by attempting to extract runtime keys through side-channel attacks or enclave escape techniques. This should include testing with realistic adversary models that have partial system access.

2. **Adaptive Attack Evaluation:** Design and execute adaptive attack campaigns that combine multiple attack vectors (e.g., prompt injection combined with membership inference) to test whether the framework's security degrades under sophisticated, multi-stage attacks.

3. **Scalability and Performance Benchmarking:** Implement the framework with datasets containing millions of documents and measure the impact on encryption/decryption latency, memory usage, and retrieval performance. Validate that the security guarantees hold under high-load conditions with concurrent user access.