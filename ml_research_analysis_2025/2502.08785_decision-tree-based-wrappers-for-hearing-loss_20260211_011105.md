---
ver: rpa2
title: Decision Tree Based Wrappers for Hearing Loss
arxiv_id: '2502.08785'
source_url: https://arxiv.org/abs/2502.08785
tags:
- features
- fedora
- feature
- methods
- experiment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work evaluates an evolutionary feature engineering wrapper,
  FEDORA, for hearing loss detection using decision tree-based models as proxies.
  Applied to a dataset with 60 features, the framework reduces dimensionality while
  maintaining or improving classification performance.
---

# Decision Tree Based Wrappers for Hearing Loss

## Quick Facts
- arXiv ID: 2502.08785
- Source URL: https://arxiv.org/abs/2502.08785
- Reference count: 0
- Primary result: FEDORA wrapper with decision tree proxies reduced hearing loss dataset from 60 to 1 feature while maintaining 72.8% balanced accuracy

## Executive Summary
This work introduces FEDORA, an evolutionary feature engineering wrapper using decision tree-based models as proxies for hearing loss detection. Applied to a 60-feature audiology dataset, FEDORA achieved dimensionality reduction while maintaining or improving classification performance. The framework outperformed traditional methods including PCA, UMAP, SOMs, and autoencoders across three experiments using different proxy models. The approach demonstrated that simpler proxy models like decision trees create stronger evolutionary pressure for meaningful feature reduction compared to more complex ensemble methods.

## Method Summary
FEDORA uses Structured Grammatical Evolution (SGE) to evolve feature transformation programs via a context-free grammar. The framework employs a 40/40/20 train/validation/test split, with fitness defined as 1 minus balanced accuracy on validation data computed using a proxy model. Three experiments tested decision trees, random forests (n_estimators=5, max_depth=5), and XGBoost as proxies. The grammar supports original feature selection, engineered features (combining two features with one operator), and complex features (multiple operators). Evolution runs for 100 generations with population size 200, using tournament selection, 0.9 crossover rate, 0.1 mutation rate, and 10% elitism.

## Key Results
- Best individual achieved 76.2% balanced accuracy using 57 features
- One individual reached 72.8% accuracy using only a single constructed feature
- DT proxy experiments showed decreasing feature counts over generations (from ~60 to ~20)
- RF and XGB proxy experiments stabilized around 50-60 features, selecting nearly all available features
- Statistical analysis confirmed FEDORA significantly outperformed PCA, UMAP, SOM, and autoencoders with large effect sizes

## Why This Works (Mechanism)

### Mechanism 1
Evolutionary wrapper optimization using decision-tree proxies can reduce dimensionality while maintaining classification performance. FEDORA uses SGE to evolve individuals that transform the original dataset through a context-free grammar. Each individual encodes a feature transformation pipeline. The fitness function is 1 minus balanced accuracy on the validation set, computed by training a proxy model on transformed training data and evaluating on validation data. The core assumption is that the proxy model's validation accuracy is a reliable proxy for downstream classifier generalization on held-out test data.

### Mechanism 2
Simpler proxy models induce stronger feature reduction pressure during evolution. Decision trees create axis-parallel splits only and cannot construct complex internal representations. When used as proxies, they cannot achieve good fitness without well-engineered features from evolution, driving feature reduction and construction. In contrast, RF and XGB build ensemble representations internally, so evolution retains more original features with less construction. The proxy's representational limits create discriminative fitness gradients that steer evolution toward meaningful feature engineering.

### Mechanism 3
Constructed features can achieve competitive accuracy with dramatically fewer dimensions than baseline. The grammar allows three feature types—original, engineered (one operator combining two features), and complex (multiple operators). Evolution discovers compact representations; one individual achieved 72.8% balanced accuracy using a single complex feature. The discovered algebraic combinations capture meaningful interactions in the hearing loss domain. Statistical tests (Kruskal-Wallis, Dunn's posthoc with Bonferroni, Cliff's δ) confirm FEDORA significantly outperforms traditional methods with large effect sizes.

## Foundational Learning

- Concept: Grammatical Evolution (GE) and Structured GE (SGE)
  - Why needed here: FEDORA's evolutionary engine is SGE, which maps variable-length genotype to phenotype via a grammar. Understanding genotype-phenotype mapping is essential for debugging evolution behavior.
  - Quick check question: Given a simple grammar with operators (+, -, *) and terminals (x1, x2), can you trace how a genotype [2, 0, 1, 3] maps to an expression?

- Concept: Wrapper vs. Filter vs. Embedded Feature Engineering
  - Why needed here: The paper explicitly positions FEDORA as a wrapper method (uses model performance as feedback). This distinguishes it from filter methods (statistical metrics) and embedded methods (model-internal selection).
  - Quick check question: If you had no access to model training (only raw statistics), which FE paradigm could you still use?

- Concept: Balanced Accuracy for Class-Imbalanced Data
  - Why needed here: The fitness function uses balanced accuracy (average of per-class recall), not raw accuracy. Medical screening datasets often have class imbalance, making this metric critical.
  - Quick check question: On a dataset with 90% negative and 10% positive cases, why would a model predicting "always negative" have high accuracy but 50% balanced accuracy?

## Architecture Onboarding

- Component map:
  Data splitter -> SGE engine -> Grammar -> Proxy model -> Fitness evaluator -> Best individual selector

- Critical path:
  1. Initialize random population of genotypes
  2. For each generation: map genotypes to phenotypes (feature transformations via grammar)
  3. Apply transformations to train/validation data
  4. Train proxy on transformed train, evaluate on transformed validation
  5. Assign fitness (1 - balanced accuracy)
  6. Select, crossover, mutate to create next generation
  7. Return best individual (lowest validation error)
  8. Evaluate best individual on test set with multiple testing models

- Design tradeoffs:
  - Proxy simplicity vs. feature reduction: DT proxy → aggressive reduction; RF/XGB proxy → retains more features
  - Population/generations vs. compute budget: 200 × 100 = 20,000 fitness evaluations per run
  - Grammar expressiveness vs. interpretability: more operators enable complex features but reduce explainability

- Failure signatures:
  - Validation fitness improving but test performance degrading → overfitting to validation split
  - Feature count not decreasing (RF/XGB experiments) → insufficient evolutionary pressure; may need grammar constraints or fitness penalty
  - Best individual contains only original features → grammar may not incentivize construction, or construction offers no benefit for this dataset

- First 3 experiments:
  1. Replicate DT proxy experiment on the hearing loss dataset: log fitness curves, feature counts, and final test accuracy. Compare to paper's ~29% validation error and decreasing feature trend.
  2. Ablate the grammar: disable constructed features (allow only selection) and measure performance gap vs. full grammar to quantify construction contribution.
  3. Proxy comparison: run identical configuration with DT, RF, and XGB proxies on the same folds; verify that DT produces fewer features and RF/XGB produce similar feature counts (~50+) as reported.

## Open Questions the Paper Calls Out

### Open Question 1
Does FEDORA generalize its superior performance and dimensionality reduction capabilities to datasets outside of the specific hearing loss domain? The authors state the framework still needs to be analyzed with different datasets to properly assess its generalization capabilities. The current study is restricted to a single, private dataset of 60 features related to audiology.

### Open Question 2
Can modifying the fitness function to penalize feature count or restricting the grammar successfully induce Random Forest (RF) and XGBoost (XGB) proxies to achieve aggressive dimensionality reduction similar to Decision Trees? The authors note that RF and XGB proxies maintained high feature counts and suggest ways to bias the evolution may be required, such as adding a fitness component that penalizes individuals with many features.

### Open Question 3
Does the inclusion of logical operators for boolean features and the selection of simpler proxy algorithms improve the explainability of the evolved feature transformations? The authors suggest researching meaningful grammar operators might prove useful, having logical operators for the boolean features, which may increase explainability.

## Limitations

- The primary dataset is unavailable due to patient confidentiality, preventing direct replication of the core experiments
- The core mechanisms rely on specific interactions between SGE grammar and proxy model representational capacity, which have not been externally validated
- The claim that decision trees as proxies create stronger feature reduction pressure is supported only by internal experimental comparison without theoretical grounding

## Confidence

- Mechanism 1 (proxy accuracy as reliable fitness signal): Medium
- Mechanism 2 (proxy simplicity drives feature reduction): Low
- Mechanism 3 (constructed features generalize): Medium
- Statistical significance claims: High (methods clearly specified)

## Next Checks

1. Apply FEDORA to a publicly available medical classification dataset with similar dimensionality (30-100 features) to verify the dimensionality reduction pattern holds beyond the hearing loss domain
2. Conduct ablation studies removing constructed features from the grammar to quantify their contribution to performance gains
3. Perform cross-validation stability analysis by running multiple train/validation/test splits to assess whether the 72.8% single-feature result is reproducible or a validation-set artifact