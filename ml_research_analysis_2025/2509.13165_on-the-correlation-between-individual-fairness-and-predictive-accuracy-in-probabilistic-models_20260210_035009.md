---
ver: rpa2
title: On the Correlation between Individual Fairness and Predictive Accuracy in Probabilistic
  Models
arxiv_id: '2509.13165'
source_url: https://arxiv.org/abs/2509.13165
tags:
- accuracy
- fairness
- predictive
- features
- probabilistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between individual fairness
  and predictive accuracy in probabilistic classifiers, particularly focusing on Bayesian
  networks. The authors hypothesize that instances exhibiting greater robustness to
  perturbations in private features are more likely to be classified accurately.
---

# On the Correlation between Individual Fairness and Predictive Accuracy in Probabilistic Models

## Quick Facts
- **arXiv ID:** 2509.13165
- **Source URL:** https://arxiv.org/abs/2509.13165
- **Reference count:** 16
- **Primary result:** Empirical evidence that instances with greater robustness to private feature perturbations are more likely to be classified accurately in Bayesian network classifiers.

## Executive Summary
This paper investigates the relationship between individual fairness and predictive accuracy in probabilistic classifiers, particularly focusing on Bayesian networks. The authors hypothesize that instances exhibiting greater robustness to perturbations in private features are more likely to be classified accurately. To test this, they analyze fourteen fairness-related datasets, computing a fairness robustness level (FRL) for each test instance. The FRL is defined as the maximum dissimilarity between posterior distributions over the target variable when private features are perturbed. Experimental results confirm the hypothesis, showing a clear decline in prediction accuracy as FRL increases.

## Method Summary
The study uses Bayesian networks trained via tabu local search on 14 fairness-related datasets. For each test instance, the authors compute a Fairness Robustness Level (FRL) that measures maximum dissimilarity between posterior distributions when private features are perturbed. To handle computational complexity, they reformulate the problem as a most probable explanation task in an auxiliary Markov random field. The framework uses discrete variables with quantile-based discretization, and evaluates performance using Brier scores and classification accuracy across 10-fold stratified cross-validation.

## Key Results
- A clear decline in prediction accuracy as FRL increases across all 14 tested datasets
- Reformulation of FRL computation as an MPE task in an auxiliary MRF reduces computational complexity
- Instances where private features lie outside the Markov blanket of the target achieve "fairness by design" with FRL=0

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** If an instance exhibits high robustness (low sensitivity to private feature perturbations), it is statistically more likely to be classified accurately.
- **Mechanism:** The paper hypothesizes that "robust" instances represent "easy" classification cases where the posterior distribution over the target $Y$ is stable regardless of the private features $X$. Conversely, high Fairness Robustness Level (FRL) indicates that $X$ significantly shifts the posterior, which the authors empirically associate with higher Brier scores (lower accuracy).
- **Core assumption:** Assuming that feature perturbations reflect meaningful counterfactuals and that instability in the posterior correlates with classification difficulty (uncertainty).
- **Evidence anchors:**
  - [abstract]: "instances exhibiting greater robustness are more likely to be classified accurately."
  - [section 6]: "results reveal a clear decline in prediction accuracy as FRL increase."
  - [corpus]: Neighbor papers discuss fairness/accuracy trade-offs generally (e.g., FairTTTS), but specific corpus evidence for a *positive* correlation between robustness and accuracy is not directly cited; this is the paper's novel contribution.
- **Break condition:** The correlation breaks if the model is misspecified or if private features are causal determinants of the target that are removed in "robust" calculations, potentially destroying signal.

### Mechanism 2
- **Claim:** Computing the Fairness Robustness Level (FRL) in a Bayesian Network (BN) can be mapped to a Most Probable Explanation (MPE) task in an auxiliary Markov Random Field (MRF) to reduce complexity.
- **Mechanism:** Instead of a brute-force search over all private feature configurations $X$, the optimization problem (maximizing the distance between posteriors) is reformulated. By exploiting the monotonicity of probability ratios (Eq. A.7), the task becomes finding the configuration $x$ that maximizes a product of potentials in an MRF.
- **Core assumption:** The target variable $Y$ is discrete (specifically binary in the core derivation), and the Manhattan distance is used for the dissimilarity measure to allow linear decomposition.
- **Evidence anchors:**
  - [section 4]: "we reformulate the problem as a most probable explanation task in an auxiliary Markov random field."
  - [appendix a]: Proof showing the equivalence between the BN maximization and the MRF product of ratios.
  - [corpus]: General MPE/MAP inference in graphical models is standard, but this specific mapping for fairness metrics is distinct.

### Mechanism 3
- **Claim:** A model achieves "fairness by design" for an instance if the private features lie outside the Markov Blanket of the target.
- **Mechanism:** In a BN, only features in the Markov Blanket (parents, children, spouses) of $Y$ affect the posterior $P(Y|evidence)$. If all private features $X$ fall outside this set, $P(Y|x,z) = P(Y|z)$, resulting in FRL = 0 regardless of the perturbation.
- **Core assumption:** The structural learning algorithm correctly identifies conditional independencies.
- **Evidence anchors:**
  - [section 4]: "It is a trivial exercise to notice that... the BN can be equivalently restricted to the BN over the Markov blanket of Y."
  - [section 6]: "When private features are entirely irrelevant to the target, the classifier achieves fairness by design... and the FRL is trivially zero."
  - [corpus]: Standard property of Bayesian Networks (Koller & Friedman cited in paper).

## Foundational Learning

- **Concept: Markov Blanket**
  - **Why needed here:** Determines the computational boundary. Features outside the Markov blanket of the target $Y$ are mathematically irrelevant to the FRL calculation and can be pruned.
  - **Quick check question:** If a private feature is a "spouse" of the target (shared child), does it affect the posterior? (Answer: Yes, it is in the blanket).

- **Concept: Brier Score**
  - **Why needed here:** The paper uses this strictly proper scoring rule (instead of simple accuracy) to measure the quality of probabilistic predictions against the FRL.
  - **Quick check question:** Does a Brier score of 0 imply a correct or incorrect classification? (Answer: Correct, with perfect confidence).

- **Concept: Variable Elimination**
  - **Why needed here:** The primary inference algorithm used to solve the MPE task in the auxiliary MRF, determining the practical tractability of the FRL calculation.
  - **Quick check question:** What parameter determines the complexity of Variable Elimination? (Answer: Treewidth).

## Architecture Onboarding

- **Component map:** Input (Discrete dataset $D$) -> Model (Bayesian Network) -> Auxiliary Engine (MRF Constructor) -> Inference (Variable Elimination) -> Output (FRL value per instance $\rho(\hat{x}, \hat{z})$ correlated with Brier Score)

- **Critical path:**
  1. Learn BN structure from data
  2. Identify Private ($X$) vs Public ($Z$) features
  3. Check if $X$ intersects with Markov Blanket of $Y$ (if no, FRL=0 instantly)
  4. Construct MRF potentials: $\phi_Y$ (parents) and $\phi_X$ (children)
  5. Run MPE inference to find $x^*$ that maximizes divergence

- **Design tradeoffs:**
  - **Metric Choice:** Using Manhattan distance allows linear reformulation (MPE); KL divergence would likely be intractable
  - **Model Type:** Restricted to discrete variables; hybrid/continuous models require Linear-Gaussian assumptions or new derivations
  - **Complexity:** MRF approach is efficient only if the induced treewidth is smaller than the brute-force search space ($|X|$)

- **Failure signatures:**
  - **Zero FRL on Biased Data:** Indicates structural learning failed to connect sensitive attributes to $Y$ (potentially ignoring real bias to achieve "fairness by design")
  - **High FRL on Accurate Instances:** Violates the paper's hypothesis; suggests the model is using private features as strong, legitimate signal (high dependence)
  - **Computational Blowup:** If the Markov blanket is dense, the MRF treewidth explodes, making FRL calculation intractable

- **First 3 experiments:**
  1. **Baseline Check:** Train BN on the *Adult* dataset, compute FRL using brute-force vs. MRF method to validate equivalence
  2. **Feature Ablation:** Remove all private features from the Markov Blanket manually and verify FRL drops to 0 (fairness by design)
  3. **Correlation Plot:** Reproduce Figure 3 (Brier Score vs FRL scatter) to confirm the decaying accuracy trend on a held-out test set

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the identified robustness-accuracy link be harnessed to actively control fairness during the model training process?
- **Basis:** [explicit] The Introduction states future work will investigate using this link to actively control fairness during training and compare it to existing methods.
- **Why unresolved:** This study establishes a correlation on pre-trained Bayesian networks but does not implement or test training procedures that optimize for this specific robustness.
- **Evidence:** A training algorithm that minimizes predictive loss while explicitly maximizing the Fairness Robustness Level (FRL), resulting in fairer models without sacrificing accuracy.

### Open Question 2
- **Question:** Does a selective modeling approach—using standard models for robust instances and constrained models for others—effectively mitigate fairness-accuracy trade-offs?
- **Basis:** [explicit] The Conclusion describes exploring this targeted approach, where standard models are applied to robust instances, as a necessary direction for future research.
- **Why unresolved:** The authors observe the correlation but do not test a system that dynamically switches between standard and fairness-constrained models based on an instance's FRL.
- **Evidence:** Empirical results from a dual-model system showing improved overall fairness and accuracy trade-offs compared to single-model baselines.

### Open Question 3
- **Question:** Does the correlation between FRL and predictive accuracy persist when extending the framework to hybrid models with continuous features or targets?
- **Basis:** [explicit] Section 7 notes that assessing whether the discriminative power of the FRL remains stable under hybrid models constitutes a necessary future investigation.
- **Why unresolved:** The current formulation relies on discrete variables and classification tasks, whereas continuous targets (regression) require a substantial reformulation of the robustness concepts.
- **Evidence:** Experiments on datasets with continuous variables (e.g., using linear-Gaussian BNs) showing a consistent decline in prediction accuracy as instance robustness decreases.

## Limitations
- **Structural validity:** The positive correlation relies on the assumption that low robustness indicates hard-to-classify instances; may mask true bias if private features are systematically irrelevant but correlated through unobserved confounders.
- **Generalizability:** The formulation assumes discrete variables and Manhattan distance; extension to continuous features requires additional approximations that may not preserve the correlation property.
- **Causality:** The paper does not explicitly model causal relationships; the observed correlation could reflect statistical associations rather than causal effects of private features on target uncertainty.

## Confidence
- **High confidence:** The mathematical reformulation of FRL as an MPE problem in an MRF (Mechanism 2) is sound, given standard graphical model theory and the provided proofs.
- **Medium confidence:** The empirical correlation between FRL and accuracy across 14 datasets appears robust, but the datasets and private feature designations are not fully specified, limiting independent verification.
- **Low confidence:** The hypothesis that robustness universally implies accuracy across all possible data distributions and model classes is not proven; it is an empirical observation within the studied scope.

## Next Checks
1. **Causal validation:** Use a synthetic dataset with known causal structure where private features are direct causes of the target. Verify whether the FRL-accuracy correlation persists or breaks down as expected.
2. **Continuous extension:** Implement the Linear-Gaussian approximation for continuous features and test whether the FRL calculation and its correlation with accuracy remain stable.
3. **Feature ablation study:** Systematically remove private features from the Markov blanket of the target in the learned BN and measure the impact on FRL and accuracy to quantify the structural contribution of each private feature.