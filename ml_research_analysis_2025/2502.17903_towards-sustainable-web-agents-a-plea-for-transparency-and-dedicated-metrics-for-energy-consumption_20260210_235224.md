---
ver: rpa2
title: 'Towards Sustainable Web Agents: A Plea for Transparency and Dedicated Metrics
  for Energy Consumption'
arxiv_id: '2502.17903'
source_url: https://arxiv.org/abs/2502.17903
tags:
- energy
- agents
- arxiv
- consumption
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the sustainability concerns of web agents,
  autonomous systems powered by large language models (LLMs) that interact with the
  internet. The authors estimate the energy consumption of two popular web agents:
  MindAct, which uses small open-source models with extensive preprocessing, and LASER,
  which relies on the larger GPT-4 model with minimal preprocessing.'
---

# Towards Sustainable Web Agents: A Plea for Transparency and Dedicated Metrics for Energy Consumption

## Quick Facts
- arXiv ID: 2502.17903
- Source URL: https://arxiv.org/abs/2502.17903
- Authors: Lars Krupp; Daniel Geißler; Paul Lukowicz; Jakob Karolus
- Reference count: 7
- Primary result: Hierarchical web agents consume ~1500x less energy than monolithic ones by using smaller models for preprocessing

## Executive Summary
This paper addresses the sustainability concerns of web agents, autonomous systems powered by large language models (LLMs) that interact with the internet. The authors estimate the energy consumption of two popular web agents: MindAct, which uses small open-source models with extensive preprocessing, and LASER, which relies on the larger GPT-4 model with minimal preprocessing. Their analysis reveals a stark difference in energy efficiency, with LASER consuming approximately 1500 times more energy per task than MindAct. This disparity highlights the significant impact of design choices on energy consumption. The paper advocates for standardized metrics to report energy usage per token for each LLM in a web agent's pipeline, promoting transparency and enabling comparison of environmental impact. It also emphasizes the benefits of using smaller, more efficient models for preprocessing tasks and adopting a modular design to enhance sustainability.

## Method Summary
The authors estimate energy consumption for two web agents (MindAct and LASER) on the Mind2Web benchmark using a two-pronged approach. For open-source models (DeBERTa, flan-T5 XL), they measure energy consumption directly using carbontracker on an NVIDIA RTX 3080Ti across multiple runs. For proprietary GPT-4, they estimate energy via token pricing, using the formula e_GPT-4 = 0.5 × (token_cost / energy_cost), assuming 50% of token price represents energy expenditure. They calculate energy per action by multiplying token counts (averaging 118,798 tokens/page for DeBERTa tokenizer, 93,778 for GPT-4) by energy per token for each model in the pipeline.

## Key Results
- LASER consumes approximately 1500 times more energy per task than MindAct
- MindAct achieves 0.997-1.948 Wh/action versus LASER's ~2930 Wh/action
- Hierarchical design with small models for preprocessing drastically reduces energy consumption
- Standardized metrics (tokens/action, energy/token) enable fair comparison across different energy mixes

## Why This Works (Mechanism)

### Mechanism 1: Hierarchical Filtering for Inference Efficiency
Web agents utilizing a two-stage pipeline (candidate generation followed by action prediction) can significantly reduce energy consumption compared to single-stage monolithic approaches. A small model (e.g., DeBERTa) filters a massive input space (thousands of HTML elements) into a manageable subset (top 50 candidates) before involving a larger model for final decision-making. This reduces the token count processed by the energy-intensive model. The core assumption is that the smaller "candidate generation" model retains sufficient accuracy to prevent the exclusion of correct actions during the filtering phase.

### Mechanism 2: Cost-Based Energy Proxy
Energy consumption of proprietary models (e.g., GPT-4) can be estimated via token pricing and energy rates when direct hardware access is unavailable. The authors derive energy per token ($e_{GPT-4}$) by converting API token costs to kWh using a fixed ratio of energy cost to total operational price ($k=50\%$). The core assumption is that the operational cost structure of the API provider assigns 50% of the token price to energy, and this proportion remains stable across different utilization rates.

### Mechanism 3: Standardized Metrics for Comparative Sustainability
Reporting tokens per action and energy per token enables fair comparison of web agents independent of local energy mixes. By isolating energy consumption (Wh) rather than just CO2, comparisons remain valid across different geographic regions with varying grid carbon intensities. The core assumption is that researchers and providers will adopt a modular reporting standard for these specific metrics.

## Foundational Learning

- **Concept: Token-to-Energy Ratio**
  - Why needed here: The paper reduces web agent sustainability to a function of tokens processed. Understanding that different models have vastly different energy costs per token (e.g., DeBERTa vs. GPT-4) is critical for architectural decisions.
  - Quick check question: If Model A costs 10x more energy per token than Model B, how much must you reduce the context window size in Model A to break even with Model B processing a full HTML page?

- **Concept: Context Window vs. HTML DOM**
  - Why needed here: Web agents face "exploded" context windows due to raw HTML size. The paper highlights that processing ~94k tokens per action (LASER) is the primary driver of inefficiency.
  - Quick check question: Why does feeding raw HTML directly to an LLM differ significantly from feeding a summarized DOM in terms of energy?

- **Concept: Modular Agent Pipelines**
  - Why needed here: The 1500x efficiency gap is not just about model size but pipeline design. Separating "candidate generation" from "action prediction" is the core strategy for sustainable design.
  - Quick check question: In a modular pipeline, which module prioritizes *recall* (finding all possible options) and which prioritizes *precision* (selecting the best option)?

## Architecture Onboarding

- **Component map:** Input Layer (Raw HTML/DOM elements) -> Preprocessing (Optional: smaller LLMs for ranking/filtering) -> Core LLM (Primary decision engine) -> State/Memory (Buffers for previous actions)
- **Critical path:** The "Input Format Selection" and "Preprocessing" stages determine the token count fed to the Core LLM. This is the primary lever for energy control.
- **Design tradeoffs:**
  - LASER-style (Monolithic): Simple architecture, high capability, massive energy cost (~2930 Wh/action)
  - MindAct-style (Hierarchical): Complex architecture, requires managing two models, extremely low energy cost (~1-2 Wh/action)
- **Failure signatures:**
  - Context Overflow: Monolithic agents hitting token limits on complex pages
  - Premature Filtering: Hierarchical agents failing tasks because the preprocessing model discarded the correct HTML element
- **First 3 experiments:**
  1. Measure Baseline: Use a tool like `carbontracker` to measure the energy per token of a local small model (e.g., DeBERTa or similar) on your specific hardware.
  2. Implement Filtering: Build a simple ranker that reduces a 100k token HTML input to a 5k token summary. Compare the theoretical energy cost using the paper's formula ($E_{action} = N \cdot e$).
  3. Cost Comparison: Select a standard web task (e.g., "Find contact us page"). Run it using a "raw HTML" approach vs. a "filtered" approach and calculate the estimated CO2 difference using the US energy mix ($0.453 \text{ g/Wh}$).

## Open Questions the Paper Calls Out
None

## Limitations
- The 50% energy cost assumption for GPT-4 pricing is unverified and may vary with API pricing models
- The paper does not provide empirical evidence that hierarchical design maintains task completion rates comparable to monolithic approaches
- Token count variability based on DOM structure (1-3× multiplier) lacks detailed methodology for handling across different websites

## Confidence

- **High Confidence**: The fundamental observation that web agents processing raw HTML (~94k tokens/page) consume significantly more energy than those using hierarchical filtering
- **Medium Confidence**: The specific energy consumption values for MindAct (0.997-1.948 Wh/action) and LASER (~2930 Wh/action) are methodologically sound but rely on assumptions about GPU efficiency and API pricing
- **Low Confidence**: The assumption that 50% of GPT-4 token pricing represents energy cost is not validated against actual energy usage data from the provider

## Next Checks

1. **Empirical Energy Verification**: Run a small-scale experiment comparing energy consumption of a monolithic web agent (raw HTML → GPT-4) versus a hierarchical version (filtered HTML → GPT-4) on identical tasks, measuring actual GPU/CPU energy usage rather than relying on pricing proxies.

2. **Task Success Rate Comparison**: Implement both monolithic and hierarchical architectures on a subset of Mind2Web tasks and measure not just energy consumption but also task completion rates to verify that efficiency gains don't come at the cost of capability.

3. **Token Count Validation**: Sample 50 HTML pages from Mind2Web, tokenize them using both DeBERTa and GPT-4 tokenizers, and verify the reported token counts (118,798 and 93,778 respectively) to establish the accuracy of the foundational measurements.