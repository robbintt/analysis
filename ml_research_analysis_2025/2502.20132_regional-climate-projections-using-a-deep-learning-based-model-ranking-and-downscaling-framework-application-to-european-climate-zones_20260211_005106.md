---
ver: rpa2
title: 'Regional climate projections using a deep-learning-based model-ranking and
  downscaling framework: Application to European climate zones'
arxiv_id: '2502.20132'
source_url: https://arxiv.org/abs/2502.20132
tags:
- climate
- downscaling
- zones
- temperature
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study addresses the challenge of high-resolution regional\
  \ climate projections by proposing a two-stage framework that combines deep-learning-based\
  \ CMIP6 model ranking and advanced deep-learning-based statistical downscaling.\
  \ The DL-TOPSIS approach dynamically ranks 32 CMIP6 models using nine performance\
  \ metrics across five K\xF6ppen-Geiger climate zones in Europe, identifying NorESM2-LM,\
  \ GISS-E2-1-G, and HadGEM3-GC31-LL as top performers."
---

# Regional climate projections using a deep-learning-based model-ranking and downscaling framework: Application to European climate zones

## Quick Facts
- **arXiv ID**: 2502.20132
- **Source URL**: https://arxiv.org/abs/2502.20132
- **Reference count**: 19
- **Primary result**: Deep-learning framework achieves 20% RMSE reduction in regional climate downscaling using CMIP6 model ranking and GeoSTANet architecture

## Executive Summary
This study addresses the challenge of high-resolution regional climate projections by proposing a two-stage framework that combines deep-learning-based CMIP6 model ranking and advanced deep-learning-based statistical downscaling. The DL-TOPSIS approach dynamically ranks 32 CMIP6 models using nine performance metrics across five Köppen-Geiger climate zones in Europe, identifying NorESM2-LM, GISS-E2-1-G, and HadGEM3-GC31-LL as top performers. These top-ranked models are then downscaled using four deep-learning architectures (CNN-LSTM, ConvLSTM, ViT, and GeoSTANet) to 0.1° resolution.

The GeoSTANet architecture, leveraging geospatial encoding and attention mechanisms, achieves the highest accuracy (RMSE = 1.57°C, KGE = 0.89, NSE = 0.85, r = 0.92) and reduces RMSE by 20% compared to ConvLSTM, particularly excelling in capturing temperature extremes. The results demonstrate that multi-criteria model ranking and transformer-based downscaling significantly improve regional climate projections, supporting informed adaptation and impact assessments.

## Method Summary
The study employs a two-stage framework: first, DL-TOPSIS dynamically ranks 32 CMIP6 models using nine performance metrics (correlation, RMSE, BIAS, KGE, NSE, CRPS, RMSESS, MAE, MD) across five European climate zones (Cfb, Dfb, Dfc, BSk, Csa). The top three models are selected for downscaling to 0.1° resolution. Four deep-learning architectures are evaluated: CNN-LSTM, ConvLSTM, Vision Transformer (ViT), and GeoSTANet. GeoSTANet incorporates geospatial encoding and attention mechanisms to capture spatiotemporal dependencies. The framework is trained on 1985-2014 historical data and validated on 2015-2020 data, demonstrating superior performance in capturing temperature extremes while reducing RMSE by 20% compared to traditional methods.

## Key Results
- DL-TOPSIS ranks NorESM2-LM, GISS-E2-1-G, and HadGEM3-GC31-LL as top CMIP6 models across European climate zones
- GeoSTANet achieves highest accuracy with RMSE = 1.57°C, KGE = 0.89, NSE = 0.85, r = 0.92
- 20% RMSE reduction compared to ConvLSTM baseline in downscaling performance
- Superior extreme event capture compared to other deep-learning architectures

## Why This Works (Mechanism)
The framework's effectiveness stems from combining multi-criteria model ranking with advanced spatiotemporal deep-learning architectures. DL-TOPSIS dynamically evaluates CMIP6 models using comprehensive metrics across climate zones, ensuring robust selection. GeoSTANet's attention mechanisms and geospatial encoding capture complex spatial dependencies and extreme events more effectively than traditional CNNs or LSTMs. The two-stage approach isolates model quality assessment from downscaling, allowing specialized optimization of each component while maintaining physical consistency through the use of top-performing CMIP6 models.

## Foundational Learning
- **DL-TOPSIS methodology**: Why needed - for objective, multi-criteria model ranking; Quick check - verify weight normalization and TOPSIS consistency
- **CMIP6 performance metrics**: Why needed - comprehensive evaluation beyond single metrics; Quick check - ensure metric selection covers bias, skill, and uncertainty
- **Köppen-Geiger climate classification**: Why needed - ensures regional specificity and physical relevance; Quick check - verify climate zone boundaries match observational data
- **Geospatial encoding in deep learning**: Why needed - captures spatial dependencies beyond grid coordinates; Quick check - validate encoding preserves physical distances
- **Attention mechanisms for climate downscaling**: Why needed - identifies relevant spatial patterns for extreme events; Quick check - analyze attention weight distributions across regions
- **Transformer architectures in climate science**: Why needed - handles long-range dependencies better than RNNs; Quick check - compare computational efficiency with LSTMs

## Architecture Onboarding

**Component Map**: CMIP6 models → DL-TOPSIS ranking → Top 3 selection → Deep-learning downscaling (GeoSTANet/ViT/CNN-LSTM/ConvLSTM) → 0.1° resolution output

**Critical Path**: DL-TOPSIS ranking (9 metrics × 5 climate zones) → GeoSTANet downscaling (geospatial encoding + attention) → Validation (RMSE/KGE/NSE/correlation)

**Design Tradeoffs**: Model ranking comprehensiveness vs. computational cost; attention mechanism complexity vs. interpretability; resolution enhancement vs. physical consistency

**Failure Signatures**: Poor ranking if metrics are imbalanced; downscaling failures with insufficient training data; attention collapse indicating model instability

**3 First Experiments**:
1. Test DL-TOPSIS ranking sensitivity to metric weight variations
2. Compare GeoSTANet attention patterns across climate zones
3. Evaluate downscaling performance on held-out extreme events

## Open Questions the Paper Calls Out
None

## Limitations
- Temperature-only downscaling limits applicability to comprehensive climate impact assessments
- Historical data (1985-2014) may not capture non-stationary climate dynamics under future warming
- Deep-learning models may struggle with unprecedented climate extremes beyond historical range
- Standard validation metrics lack comprehensive uncertainty quantification through ensemble approaches

## Confidence
- **High Confidence**: Model ranking methodology using DL-TOPSIS, deep-learning downscaling architecture comparisons, performance metrics across climate zones
- **Medium Confidence**: Spatial generalization across Europe, extreme event representation, model transferability to future scenarios
- **Low Confidence**: Performance under non-stationary climate conditions, applicability to other climate variables beyond temperature

## Next Checks
1. Implement ensemble downscaling approaches combining multiple top-ranked models to quantify uncertainty bounds and improve robustness
2. Validate model performance on precipitation and other essential climate variables to assess framework generalizability
3. Conduct cross-validation using different historical periods and climate zones to test model stability and transferability under varying conditions