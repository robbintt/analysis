---
ver: rpa2
title: 'New Money: A Systematic Review of Synthetic Data Generation for Finance'
arxiv_id: '2510.26076'
source_url: https://arxiv.org/abs/2510.26076
tags:
- data
- synthetic
- generative
- studies
- financial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic review analyzed 72 studies published since 2018
  to synthesize the current landscape of synthetic financial data generation. The
  primary finding is that GAN-based approaches dominate the field, especially for
  generating time-series market data and tabular credit data.
---

# New Money: A Systematic Review of Synthetic Data Generation for Finance

## Quick Facts
- arXiv ID: 2510.26076
- Source URL: https://arxiv.org/abs/2510.26076
- Reference count: 20
- Primary result: GAN-based approaches dominate synthetic financial data generation, with significant gaps in privacy evaluation and standardization

## Executive Summary
This systematic review analyzes 72 studies published since 2018 to synthesize the current landscape of synthetic financial data generation. The primary finding is that GAN-based approaches, particularly TimeGAN, dominate the field for generating both time-series market data and tabular credit data. While these methods show promise in preserving statistical properties and supporting downstream machine learning tasks, the review reveals a critical gap: only 12% of studies explicitly evaluate privacy preservation, despite privacy being a key motivation for synthetic data use in finance. The authors call for standardized evaluation frameworks that rigorously assess both utility and privacy guarantees to ensure robust, compliant synthetic data solutions for the financial domain.

## Method Summary
The review employed a systematic literature search across five databases (ACM Digital Library, IEEE Xplore, Scopus, SpringerLink, Web of Science) using specific keyword combinations for synthetic data generation and financial applications. Following PRISMA guidelines, 72 studies published since 2018 were identified through two-stage screening (title/abstract → full-text) and snowballing. Data extraction categorized studies by financial data type, generative model, and evaluation methods, with synthesis performed using Python (Pandas, Matplotlib, Plotly) and Excel to analyze patterns and visualize results.

## Key Results
- GAN-based approaches represent 73.8% of generative methods used, with TimeGAN appearing most frequently for time-series data
- Only 12.3% of studies explicitly evaluated privacy preservation despite this being a primary motivation for synthetic data in finance
- The Train on Synthetic, Test on Real (TSTR) protocol dominates evaluation, used in 65.8% of studies to assess downstream ML task performance

## Why This Works (Mechanism)

### Mechanism 1: Temporal Dependency Capture in Financial Time-Series
GAN-based architectures, particularly TimeGAN, capture temporal dependencies more effectively than static methods by using a generator network that creates sequences while a discriminator network distinguishes real from synthetic, forcing the generator to learn conditional probability distributions of next time steps. TimeGAN incorporates supervised loss to minimize embedding space error, converging to a Nash equilibrium where synthetic data captures stylized facts like volatility clustering.

### Mechanism 2: TSTR Protocol as Utility Proxy
The Train on Synthetic, Test on Real protocol acts as a proxy for data utility by training downstream models exclusively on generated data and validating against real data holdouts. When TSTR accuracy approaches Train on Real, Test on Real accuracy, synthetic data is deemed high-fidelity, assuming statistical similarity implies functional equivalence for downstream tasks.

### Mechanism 3: Distance-Based Privacy Heuristics
Privacy preservation relies on distance-based heuristics like Nearest Neighbor Distance Ratio (NNDR), where synthetic samples too close to real training data are rejected. This assumes statistical distance correlates negatively with re-identification risk, though only 12.3% of studies explicitly evaluate this approach.

## Foundational Learning

- **Generative Adversarial Networks (GANs) vs. VAEs**: GANs dominate (73.8% usage) due to their ability to produce sharper samples for financial data, though they're harder to train than VAEs. If your primary goal is strictly tabular credit data with stable convergence, should you default to a Vanilla GAN, or investigate the VAE/TimeVAE alternatives?

- **Stylized Facts of Financial Data**: Synthetic data must preserve specific financial properties like heavy tails and volatility clustering. Does your generator produce a normal distribution of returns, or does it capture the fat-tailed distribution characteristic of real market crashes?

- **Differential Privacy (DP)**: DP provides mathematical privacy guarantees necessary for regulatory compliance, but achieving lower ε typically degrades statistical utility. Can you explain why lower ε values in DP typically reduce synthetic data quality for ML tasks?

## Architecture Onboarding

- **Component map**: Real Financial Time-Series → Preprocessing → Generator (TimeGAN/CTGAN) → Discriminator → Evaluator (Statistical + ML Efficacy)
- **Critical path**: 1) Data segmentation of time-series windows, 2) Adversarial training with embedding supervision, 3) TSTR validation against 90% of TRTR baseline
- **Design tradeoffs**: Fidelity vs. Privacy (optimizing statistical similarity increases memorization risk), Complexity vs. Convergence (CTGAN requires more tuning than Vanilla GANs)
- **Failure signatures**: Mode collapse (single trend generation), Identity leakage (near-identical synthetic records), Artifacting (missing volatility clustering)
- **First 3 experiments**: 1) Implement TimeGAN on S&P 500 data, evaluate with KS statistic, 2) Train LSTM trading bot on synthetic data, compare TSTR vs TRTR performance, 3) Calculate NNDR to identify suspiciously close synthetic points

## Open Questions the Paper Calls Out

- **Standardized evaluation frameworks**: What frameworks can comprehensively assess both utility and privacy preservation for synthetic financial data? Only 12.3% of studies evaluate privacy, while 79.5% evaluate statistical similarity. Resolution requires cross-domain benchmarks comparing multiple privacy assessment methods on identical datasets.

- **Non-GAN alternatives**: Can VAEs, transformers, or diffusion models achieve comparable or superior performance to GANs for financial synthesis? GANs dominate despite training instabilities, with alternatives appearing in only 1-2 papers each. Resolution requires controlled experiments on standardized financial benchmarks.

- **Privacy-utility trade-offs**: What trade-offs exist when applying differential privacy to synthetic financial generation? Only 2 studies tested DP, leaving the relationship between privacy budget (ε), data quality, and downstream ML performance uncharacterized. Resolution requires systematic experiments varying ε across architectures and data types.

## Limitations
- Publication bias may underrepresent industry practices where proprietary methods dominate
- Privacy analysis relies on stated metrics rather than empirical attack demonstrations
- Review does not address specific regulatory compliance requirements or operational constraints

## Confidence
- **High Confidence**: GAN dominance (73.8% usage), TimeGAN frequency for time-series, TSTR protocol prevalence
- **Medium Confidence**: Privacy-preservation gap and need for standardized frameworks
- **Low Confidence**: Specific performance thresholds and relative architecture superiority claims

## Next Checks
1. Conduct membership inference attacks on top 5 GAN approaches to test NNDR correlation with actual re-identification risk
2. Evaluate cross-domain transferability of synthetic data from credit scoring to fraud detection tasks
3. Survey financial institutions implementing synthetic data solutions to document real-world performance and compliance challenges