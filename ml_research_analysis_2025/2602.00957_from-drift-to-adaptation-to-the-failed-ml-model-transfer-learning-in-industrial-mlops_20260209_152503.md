---
ver: rpa2
title: 'From drift to adaptation to the failed ml model: Transfer Learning in Industrial
  MLOps'
arxiv_id: '2602.00957'
source_url: https://arxiv.org/abs/2602.00957
tags:
- data
- batch
- update
- days
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates transfer learning-based strategies to update
  a failed feedforward artificial neural network (ANN) model under data drift, focusing
  on industrial process monitoring. The study compares ensemble transfer learning
  (ETL), all-layers transfer learning (ALTL), and last-layer transfer learning (LLTL)
  for updating the model using data from a 660 MW thermal power plant's air preheater
  unit, which exhibits batch process characteristics due to load cycling.
---

# From drift to adaptation to the failed ml model: Transfer Learning in Industrial MLOps

## Quick Facts
- arXiv ID: 2602.00957
- Source URL: https://arxiv.org/abs/2602.00957
- Reference count: 6
- One-line primary result: Ensemble transfer learning (ETL) achieves higher predictive accuracy for smaller batch sizes (5 days) while all-layers transfer learning (ALTL) is more effective for larger batch sizes (8 days) in updating a failed feedforward ANN under data drift.

## Executive Summary
This paper investigates transfer learning-based strategies to update a failed feedforward artificial neural network (ANN) model under data drift, focusing on industrial process monitoring. The study compares ensemble transfer learning (ETL), all-layers transfer learning (ALTL), and last-layer transfer learning (LLTL) for updating the model using data from a 660 MW thermal power plant's air preheater unit, which exhibits batch process characteristics due to load cycling. Results show that ETL achieves higher predictive accuracy for smaller batch sizes (5 days), while ALTL is more effective for larger batch sizes (8 days). The weight space analysis reveals that ETL tends to widen layer-wise weight distributions, whereas ALTL compresses them, contributing to improved generalization. Feature importance remains stable across updates, with secondary air outlet temperature consistently being the most influential feature. Computational requirements vary with batch size and update technique, with ETL generally requiring more time for smaller batches. These findings provide insights for selecting appropriate model update strategies in MLOps, balancing accuracy, stability, and computational efficiency when adapting to data drift in industrial settings.

## Method Summary
The study trains a baseline feedforward ANN on historical data from a thermal power plant's air preheater, using 8 operating variables to predict flue gas differential pressure. Model failure is detected when daily RMSE/MAE exceeds 2× test error for 3 consecutive periods. Failed models are updated using ETL (ensemble averaging across models), ALTL (full-network fine-tuning), or LLTL (output layer only) on the failed batch plus a buffer of previous data. Hyperparameter optimization is limited to learning rate ranges during updates. Performance is evaluated using R², RMSE, and MAE, with additional analysis of weight space distributions and SHAP-derived feature importance.

## Key Results
- ETL provides higher predictive accuracy for 5-day batch sizes compared to ALTL and LLTL
- ALTL is more effective for 8-day batch sizes despite increased forgetting risk
- Weight space compression in hidden layers with ALTL correlates with improved generalization
- Feature importance remains stable across updates, with secondary air outlet temperature consistently most influential
- Computational requirements vary with batch size and technique, with ETL requiring more time for smaller batches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensemble Transfer Learning (ETL) achieves higher predictive accuracy for smaller batch sizes (5 days) compared to ALTL and LLTL.
- Mechanism: ETL averages predictive responses across multiple models, reducing variance when limited data is available for adaptation. The ensemble structure provides stability by aggregating diverse weight configurations, which compensates for sparse information in small batches.
- Core assumption: The diversity of ensemble members captures complementary aspects of the drifted distribution when individual models would underfit.
- Evidence anchors:
  - [abstract] "ETL provides relatively higher predictive accuracy for the batch size of 5 days than those of LLTL and ALTL"
  - [section 3.2] "ETL approach seems to monitor flue gas DP with relatively more accuracy in comparison with ALTL and LLTL for the model trained on batch size of 5 days... For small batch sizes, ensemble may average out the predictive responses and provide stable performance"
  - [corpus] Related work on continual test-time adaptation (FoCTTA) emphasizes memory-efficient adaptation, but does not directly validate ensemble benefits for small batches—this remains context-specific.
- Break condition: When batch size increases substantially (>8 days in this study), ensemble averaging may dilute signal and ALTL becomes superior.

### Mechanism 2
- Claim: All-Layers Transfer Learning (ALTL) is more effective for larger batch sizes (8 days) despite higher risk of forgetting historical dynamics.
- Mechanism: ALTL updates weights across all network layers, enabling comprehensive adaptation to new data distributions when sufficient samples exist. The paper reports weight space compression in hidden layers, which the authors associate with improved generalization under drift.
- Core assumption: Larger batches provide enough representative samples to justify full-network parameter updates without catastrophic interference.
- Evidence anchors:
  - [abstract] "ALTL is more effective for larger batch sizes (8 days)"
  - [section 3.2] "when batch size increases, ALTL updates the model parameters across all layers and model is adapted with the recent data stream. This increases the risk of 'forgetting' the operation history"
  - [section 3.3] "For ALTL, the weight space of hidden layers seems to be compressed than those of reference distribution... that can explain the improved generalization capability"
  - [corpus] Test-Time Adaptation literature (FoCTTA, arXiv:2502.20677) discusses layer-selective updates but does not confirm compression-generalization links—this is inferred from the current study's visualizations.
- Break condition: If historical data contains critical rare events that must be retained, ALTL's comprehensive updates may cause unacceptable forgetting.

### Mechanism 3
- Claim: Last-layer weight distributions consistently widen across update techniques, while feature importance rankings remain stable despite drift.
- Mechanism: Backpropagation initiates error signal correction at the output layer, causing larger weight perturbations near the network's terminus. The stability of SHAP-derived feature importance (particularly secondary air outlet temperature) suggests that while distribution shifts occur, the underlying physical relationships governing the process remain partially preserved.
- Core assumption: Stable feature importance indicates meaningful physical relationships rather than spurious correlations that would shift under drift.
- Evidence anchors:
  - [abstract] "Feature importance remains stable across updates, with secondary air outlet temperature consistently being the most influential feature"
  - [section 3.3] "In general, it is found that weight space distribution for last-layer of ANN gets widened for the models trained on batch sizes of 5 days and 8 days. This can be attributed to back-propagation of error signal"
  - [section 3.4] "After the model update, secondary air outlet temperature remains the most significant feature... The consistent significant order of features... depicts the accuracy of feature importance analysis as well as stability of the trained models"
  - [corpus] No direct corpus validation for SHAP stability under transfer learning; this finding is specific to the current study.
- Break condition: If concept drift (relationship changes) rather than just data drift (distribution changes) dominates, feature importance stability cannot be assumed.

## Foundational Learning

- Concept: **Data drift vs. Concept drift**
  - Why needed here: The paper distinguishes between distribution shifts (data drift) and relationship changes (concept drift). Model failure triggers differ—data drift may be addressable via transfer learning, while concept drift may require architectural changes.
  - Quick check question: Are your input variable distributions shifting, or have the functional relationships between inputs and outputs fundamentally changed?

- Concept: **Catastrophic forgetting**
  - Why needed here: Sequential model updates can overwrite previously learned patterns. The paper explicitly discusses the plasticity-stability tradeoff and how ALTL increases forgetting risk compared to more constrained approaches.
  - Quick check question: After updating your model on recent data, does performance degrade on earlier held-out test sets?

- Concept: **Batch size as an adaptation parameter**
  - Why needed here: This study treats batch size not merely as a training hyperparameter but as a decision variable affecting which update strategy succeeds. Smaller batches favor ensemble methods; larger batches favor full-network fine-tuning.
  - Quick check question: What is the effective window of data needed to represent your process's operating regime? How does this align with your update frequency?

## Architecture Onboarding

- Component map:
  Baseline ANN -> Drift Detection -> Buffer Data Store -> Update Strategy Selector -> ETL/ALTL/LLTL -> SHAP Explainer -> Updated Model

- Critical path:
  1. Deploy trained ANN → 2. Monitor prediction error continuously → 3. Detect failure (threshold breach) → 4. Retrieve buffer + failure batch → 5. Apply selected transfer learning technique → 6. Validate on remaining data → 7. Redeploy updated model

- Design tradeoffs:
  - **ETL**: Higher accuracy for small batches, longer compute time, more stable predictions through averaging
  - **ALTL**: Best for large batches, lowest training time after hyperparameter optimization, highest forgetting risk
  - **LLTL**: Middle-ground approach; constrains updates to output layer, limiting both adaptation capacity and forgetting

- Failure signatures:
  - Model predictions deviate from actual values beyond 2× test error threshold
  - RMSE/MAE elevation sustained for 3+ consecutive monitoring periods
  - Sampling frequency changes (paper notes failure when moving from 10-min to 8-min intervals)
  - PSI (Population Stability Index) > 0.2 or significant Cramér-von Mises statistics indicating distribution shift

- First 3 experiments:
  1. **Baseline drift detection**: Deploy the trained ANN on new data without updates; log when and where error thresholds are breached to quantify failure patterns specific to your process.
  2. **Batch size sensitivity**: For the same failure window, apply ETL, ALTL, and LLTL at both 5-day and 8-day batch sizes; compare RMSE, MAE, and computational time to replicate the paper's finding that optimal strategy depends on batch size.
  3. **Weight space and feature stability**: After each update technique, extract layer-wise weight distributions and SHAP feature importance; verify whether ETL widens weights while ALTL compresses them, and whether top features remain consistent as observed in the air preheater case.

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the choice of transfer learning strategy (ETL vs. ALTL) quantitatively impact the stability-plasticity balance and catastrophic forgetting of historical operating regimes?
  - Basis in paper: [inferred] The Introduction highlights catastrophic forgetting as a key risk, and the Results note that ALTL "increases the risk of 'forgetting' the operation history," yet the evaluation focuses primarily on accuracy in the new (target) domain rather than retention of the old (source) domain.
  - Why unresolved: The paper evaluates updated models only on the "rest of April data" (new drift data) and does not report metrics on the original January data to measure knowledge retention.
  - What evidence would resolve it: A comparative evaluation of the updated models' performance (RMSE/R²) on the original historical dataset (January) to measure the degree of interference.

- **Open Question 2**: Is there a specific batch-size threshold or data-volume inflection point that dictates the optimal switch from Ensemble Transfer Learning (ETL) to All-Layers Transfer Learning (ALTL)?
  - Basis in paper: [inferred] The study compares only two static windows (5 days and 8 days), finding ETL superior for the former and ALTL for the latter, but does not define the boundary condition or continuity of this trend.
  - Why unresolved: The discrete nature of the batch size comparison (5 vs. 8 days) leaves a gap in understanding the transition dynamics for intermediate or larger batch sizes.
  - What evidence would resolve it: A sensitivity analysis across a continuous range of batch sizes (e.g., 3 to 12 days) to map the performance crossover point.

- **Open Question 3**: Do the observed widening (ETL) and compression (ALTL) of layer-wise weight distributions generalize to other neural network architectures, such as LSTMs or Transformers, commonly used in time-series forecasting?
  - Basis in paper: [inferred] The study relies exclusively on a simple feedforward ANN architecture, leaving the interaction between these weight-space dynamics and more complex, state-aware architectures unexplored.
  - Why unresolved: The weight space analysis is currently tied to the specific properties of the feedforward architecture used in the case study.
  - What evidence would resolve it: Replication of the update framework using recurrent or attention-based models to observe if ALTL still compresses weights to achieve generalization.

## Limitations

- Core findings based on a single industrial dataset (660 MW thermal power plant air preheater) with specific temporal characteristics
- Mechanism linking weight space compression to generalization is inferred from visualizations rather than rigorous statistical tests
- Ensemble size and aggregation method for ETL are not specified, limiting reproducibility
- No evaluation of knowledge retention on historical data to measure catastrophic forgetting

## Confidence

- **High**: Feature importance stability (SHAP analysis shows secondary air outlet temperature remains dominant); weight distribution widening in output layers (backpropagation mechanism is well-established)
- **Medium**: ETL accuracy advantage for small batches (5 days); ALTL effectiveness for larger batches (8 days); computational time differences between strategies
- **Low**: The generalization improvement attributed to ALTL's weight compression; the ensemble diversity benefits for ETL in small-batch scenarios

## Next Checks

1. **Cross-domain validation**: Test the ETL/ALTL/LLTL framework on a non-thermal power dataset (e.g., chemical process or manufacturing) to verify if batch size-dependent strategy selection holds beyond the air preheater case.

2. **Generalization quantification**: Conduct k-fold cross-validation on the April data to measure whether ALTL's weight compression statistically correlates with improved out-of-distribution performance compared to ETL.

3. **Ensemble sensitivity analysis**: Vary ETL ensemble size (N=2, 5, 10) and aggregation method (median, weighted average) to determine if accuracy gains persist across configurations or are artifacts of specific implementation choices.