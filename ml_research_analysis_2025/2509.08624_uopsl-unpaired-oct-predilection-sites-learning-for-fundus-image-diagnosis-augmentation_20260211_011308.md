---
ver: rpa2
title: 'UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image Diagnosis
  Augmentation'
arxiv_id: '2509.08624'
source_url: https://arxiv.org/abs/2509.08624
tags:
- images
- fundus
- disease
- image
- predilection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces UOPSL, a framework that enhances fundus image
  disease diagnosis by leveraging unpaired OCT-derived spatial priors. It addresses
  the challenge of limited paired multimodal ophthalmic data by learning a predilection
  sites matrix in the OCT latent space through contrastive learning, then using this
  matrix during fundus-only inference to improve classification.
---

# UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image Diagnosis Augmentation

## Quick Facts
- arXiv ID: 2509.08624
- Source URL: https://arxiv.org/abs/2509.08624
- Reference count: 40
- Introduces UOPSL framework that improves fundus image disease diagnosis using unpaired OCT-derived spatial priors

## Executive Summary
UOPSL presents a novel framework that enhances fundus image disease diagnosis by leveraging spatial priors learned from unpaired OCT data. The method addresses the critical challenge of limited paired multimodal ophthalmic data by learning a predilection sites matrix in the OCT latent space through contrastive learning, then applying this knowledge during fundus-only inference. This approach enables dynamic identification of disease-specific lesion locations without requiring paired OCT data, achieving consistent performance gains across 9 datasets spanning 28 disease categories.

## Method Summary
UOPSL employs a contrastive learning framework to extract spatial priors from unpaired OCT and fundus images. The core innovation is learning a predilection sites matrix in the OCT latent space that captures disease-specific lesion locations. During training, the model learns spatial relationships from OCT data while simultaneously learning to map fundus images to these spatial patterns. At inference time, only fundus images are needed, with the model using the learned predilection sites matrix to enhance classification accuracy. The framework dynamically identifies disease-specific lesion locations without requiring paired OCT data, making it practical for real-world deployment where multimodal paired data is scarce.

## Key Results
- Consistent performance gains across 9 datasets spanning 28 disease categories
- Outperforms existing methods in both transferability and generalization
- Successfully applies to unseen disease categories not present in training data
- Achieves improved classification accuracy without requiring paired OCT data during inference

## Why This Works (Mechanism)
The framework leverages the complementary information between OCT and fundus imaging modalities. OCT provides high-resolution cross-sectional views that reveal specific disease predilection sites, while fundus imaging captures the overall retinal structure. By learning spatial priors from OCT data and transferring this knowledge to fundus image analysis, the model gains a more comprehensive understanding of disease patterns. The contrastive learning approach allows the model to align these modalities without requiring direct pairing, making the method scalable and practical.

## Foundational Learning
- **Contrastive Learning**: Needed to learn meaningful representations from unpaired data by pulling similar samples together and pushing dissimilar ones apart. Quick check: Verify that learned representations cluster by disease category rather than by imaging modality.
- **Multimodal Learning**: Required to leverage complementary information from OCT and fundus images. Quick check: Confirm that model performance degrades when using only one modality.
- **Spatial Prior Learning**: Essential for identifying disease-specific lesion locations without explicit annotations. Quick check: Validate that learned predilection sites align with clinical knowledge of disease patterns.
- **Domain Adaptation**: Necessary for transferring knowledge from OCT to fundus domain. Quick check: Test performance on datasets from different clinical centers or imaging protocols.

## Architecture Onboarding
- **Component Map**: OCT Encoder -> Predilection Sites Matrix -> Fundus Encoder -> Classification Head
- **Critical Path**: The contrastive learning between OCT and fundus encoders, mediated by the predilection sites matrix, forms the core of the framework. This path enables knowledge transfer from OCT to fundus analysis.
- **Design Tradeoffs**: The framework sacrifices the need for paired data (which is scarce) in exchange for potentially less precise spatial alignment compared to paired approaches. This tradeoff enables practical deployment in real-world settings.
- **Failure Signatures**: Performance degradation when OCT acquisition protocols vary significantly, or when disease presentations don't follow learned spatial patterns. The model may also struggle with rare diseases that have atypical predilection sites.
- **3 First Experiments**:
  1. Ablation study removing the predilection sites matrix to quantify its contribution
  2. Cross-device validation on OCT data from different manufacturers
  3. Visualization of learned predilection sites compared to clinical annotations

## Open Questions the Paper Calls Out
None

## Limitations
- Generalization capability across different OCT acquisition protocols and devices remains uncertain
- Performance heavily depends on the quality and representativeness of the 9 datasets used
- Limited discussion of clinical utility factors such as false positive/negative rates and their impact on patient outcomes

## Confidence
- **Technical Implementation**: High confidence in the contrastive learning framework and mathematical formulation
- **Performance Improvements**: Medium confidence in reported gains, dependent on dataset representativeness
- **Clinical Relevance**: Low confidence in biological plausibility of learned spatial relationships without expert validation

## Next Checks
1. Cross-device validation: Test the framework on OCT data from multiple manufacturers and imaging protocols to assess robustness of learned predilection sites matrix
2. Clinical expert validation: Have ophthalmologists verify whether automatically learned predilection sites align with known disease-specific lesion patterns
3. Temporal stability analysis: Evaluate performance consistency when applied to longitudinal OCT data across disease progression stages and time intervals