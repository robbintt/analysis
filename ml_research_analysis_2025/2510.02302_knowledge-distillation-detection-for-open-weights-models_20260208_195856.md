---
ver: rpa2
title: Knowledge Distillation Detection for Open-weights Models
arxiv_id: '2510.02302'
source_url: https://arxiv.org/abs/2510.02302
tags:
- student
- teacher
- distillation
- should
- inproc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces knowledge distillation detection, a new task
  to determine if a student model has been distilled from a specific teacher model,
  given only the student's weights and the teacher's API. The proposed solution is
  a model-agnostic framework combining data-free input synthesis with statistical
  score computation.
---

# Knowledge Distillation Detection for Open-weights Models

## Quick Facts
- arXiv ID: 2510.02302
- Source URL: https://arxiv.org/abs/2510.02302
- Authors: Qin Shi; Amber Yijia Zheng; Qifan Song; Raymond A. Yeh
- Reference count: 40
- Primary result: Introduces knowledge distillation detection to determine if a student model was distilled from a specific teacher using only student weights and teacher API.

## Executive Summary
This paper introduces knowledge distillation detection, a new task to determine if a student model has been distilled from a specific teacher model, given only the student's weights and the teacher's API. The proposed solution is a model-agnostic framework combining data-free input synthesis with statistical score computation. The framework works for both classification and generative models. Experiments show strong performance: on CIFAR-10, accuracy improves by 59.6% over baselines; on ImageNet, by 71.2%; and for text-to-image generation, by 20.0%. The method requires no access to the teacher's weights or training data and can generalize to detect distillation in diverse architectures and settings.

## Method Summary
The framework trains a generator to synthesize inputs optimized for the student model, then computes statistical scores comparing student and teacher outputs on these inputs. For classification, it uses Aligned Cosine Similarity (ACS) to measure logit subspace alignment. For text-to-image models, it leverages unconditional generation behavior from classifier-free guidance. The method requires no access to teacher weights or training data, only the teacher's API.

## Key Results
- On CIFAR-10, achieves 59.6% improvement over baselines
- On ImageNet, achieves 71.2% improvement over baselines
- For text-to-image generation, achieves 20.0% improvement
- Works across different model architectures (CNN, Transformer)
- Successfully detects distillation in both classification and generative models

## Why This Works (Mechanism)

### Mechanism 1: Confidence-Aligned Synthetic Probing
The method synthesizes inputs optimized to maximize student confidence, then compares teacher outputs on these inputs. If the student was distilled from the teacher, their outputs will statistically align; independent models will show divergent behaviors. The core assumption is that distillation transfers decision boundaries such that high-confidence regions correspond to high teacher likelihood.

### Mechanism 2: Linear Subspace Alignment (ACS)
Knowledge distillation creates a linearly alignable relationship between teacher and student logit subspaces. The Aligned Cosine Similarity computes average cosine similarity between student logits and teacher logits after applying optimal orthogonal transformation. This captures the rotated version of the teacher's representational geometry preserved in the student.

### Mechanism 3: Unconditional Diffusion Probing
In text-to-image models, distillation is detectable by comparing outputs from "empty" prompts, exploiting classifier-free guidance training dependency. Distilled students inherit specific unconditional generation behavior from teachers. The method uses LPIPS or CKA to compare student and teacher generations on null inputs.

## Foundational Learning

- **Knowledge Distillation (KD)**: The transfer of knowledge from a teacher model to a student model through soft labels or feature alignments. Why needed: The detection logic relies on understanding what signals are transferred during KD to distinguish distilled students from independently trained models. Quick check: If a student is trained purely on hard labels without a soft-label loss term, will the proposed detection method work? (Answer: No)

- **Batch Normalization Statistics (BNS)**: Running mean and variance statistics stored in BatchNorm layers. Why needed: The input generator relies on matching these statistics to synthesize "realistic" inputs without real data. Quick check: Why does the generator minimize the distance between synthesized image activations and the stored running statistics of the student model?

- **Centered Kernel Alignment (CKA) & HSIC**: Set-level score functions for detecting similarity in representations between teacher and student. Why needed: These metrics compare high-dimensional embeddings, particularly for generative models. Quick check: Why is CKA preferred over simple Cosine Similarity for high-dimensional text-to-image embeddings? (Answer: Robustness to high dimensionality and complex distributions)

## Architecture Onboarding

- **Component map**: Synthesizer -> Prober -> Scorer -> Decision Engine
- **Critical path**: The convergence of the Synthesizer. If the generator produces out-of-distribution artifacts that trigger undefined behavior in the Teacher API, the scores will be noisy. The BNS loss is the stabilization anchor here.
- **Design tradeoffs**:
  - Input Size (N): Low N (1-5) is fast but relies heavily on Point-wise scores. High N (50-100) allows Set-level scores to converge but requires more API queries.
  - Score Selection: KL/LPIPS are better for single inputs. ACS/CKA require batch statistics but offer better generalization across architectures.
- **Failure signatures**:
  - Low λ Students: Students trained mostly on hard labels yield scores indistinguishable from independent models.
  - API Rate Limits: The method requires N × K queries (Inputs × Candidates). Large K may timeout standard APIs.
  - Architecture Drift: If student architecture is radically different from teacher, ACS may fail to find valid orthogonal mapping.
- **First 3 experiments**:
  1. Sanity Check (Oracle vs. Random): Verify real data performs best, random inputs worst, and synthetic inputs close the gap.
  2. Lambda Sweep: Train students with λ ∈ [0.1, 0.9] and plot detection accuracy vs. λ to find the "detectability floor".
  3. Cross-Architecture Check: Distill ResNet50 teacher into MobileNet student and verify ACS outperforms simple KL divergence.

## Open Questions the Paper Calls Out
- Can the framework be adapted to detect distillation in Large Language Models (LLMs) using free-form text inputs? The paper identifies extending to free-form inputs in diffusion and LLMs as a promising next step.
- Is robust detection possible when the student inherits only limited behavioral influence (low λ) from the teacher? The paper notes detection may be less reliable when λ < 0.5.
- How can the method be effectively calibrated for binary detection (yes/no) without relying on a set of candidate teachers? The binary setting can be recovered by applying a calibrated score function, but the main evaluation uses multiple-choice to avoid threshold calibration.

## Limitations
- Detection accuracy degrades significantly when distillation weight λ < 0.5, making it ineffective for students trained primarily on hard labels
- The method requires multiple API queries (N × K) which can be costly or hit rate limits with large candidate sets
- While ACS claims to generalize across architectures, the linear subspace alignment assumption may not hold for radically different architectures (e.g., CNN to Transformer)

## Confidence
- **High Confidence**: The synthetic input generation process using BNS alignment is well-grounded and experimentally validated for classification tasks
- **Medium Confidence**: The ACS score computation and its claimed superiority over KL divergence are demonstrated, but lack of comparison to alternative alignment metrics introduces uncertainty
- **Medium Confidence**: The T2I detection strategy leveraging classifier-free guidance is novel and shows high accuracy, but generalizability to other generative model types is not explored

## Next Checks
1. **Lambda Sweep Experiment**: Reproduce the ablation showing detection accuracy vs. λ to confirm the empirically observed "detectability floor" at λ = 0.5
2. **Cross-Architecture Ablation**: Distill a CNN teacher into a Transformer student and compare ACS, KL, and CKA scores to quantify the impact of architectural mismatch
3. **Generative Model Generalization**: Apply the proposed framework to a GAN student (e.g., distilled from a BigGAN teacher) and evaluate if the BNS alignment and ACS strategies transfer or require modification