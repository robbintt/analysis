---
ver: rpa2
title: 'Gender Inequality in English Textbooks Around the World: an NLP Approach'
arxiv_id: '2506.02425'
source_url: https://arxiv.org/abs/2506.02425
tags:
- cultural
- names
- gender
- male
- textbooks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study applies NLP methods to quantify gender inequality in
  English textbooks across 22 countries in 7 cultural spheres. It measures character
  count, firstness (which gender is mentioned first), and TF-IDF word associations
  by gender.
---

# Gender Inequality in English Textbooks Around the World: an NLP Approach

## Quick Facts
- arXiv ID: 2506.02425
- Source URL: https://arxiv.org/abs/2506.02425
- Reference count: 0
- One-line primary result: Consistent overrepresentation of male characters in terms of count, firstness, and named entities across 22 countries

## Executive Summary
This study applies NLP methods to quantify gender inequality in English textbooks across 22 countries in 7 cultural spheres. It measures character count, firstness (which gender is mentioned first), and TF-IDF word associations by gender. Results show consistent overrepresentation of male characters in terms of count, firstness, and named entities. Large language models successfully distinguished between male and female word lists. GloVe embeddings revealed some keywords (like "pretty," "baby," "love," "nurse") are closer to female-associated words while "death" is closer to male-associated words. All regions exhibited gender inequality, with the Latin cultural sphere showing the least disparity.

## Method Summary
The study extracted text from 7th-9th grade English textbooks across 22 countries, grouped into 7 cultural spheres. Text was segmented into 100-character windows and classified as male or female context based on 22 gendered keyword pairs. The analysis computed gender occurrence counts, firstness ordering, TF-IDF associations, and named entity distributions. Validation included LLM recognition of gender associations and GloVe embedding distance calculations to predefined keywords.

## Key Results
- Significant male overrepresentation across all cultural spheres (p = 1.19 * 10^-28 for overall count differences)
- Male-firstness observed in overall dataset (p = 0.00234) though some cultural spheres showed no significant firstness difference
- GloVe embeddings showed "pretty," "baby," "love," "nurse" closer to female cluster; "death" closer to male cluster
- TF-IDF analysis revealed more male names (62) than female names (23) overall

## Why This Works (Mechanism)

### Mechanism 1: Statistical Imbalance Detection via Frequency and Ordering
- **Claim:** Systemic gender bias manifests quantifiably through the raw disparity in gendered keyword occurrences and the sequential ordering of gender pairs.
- **Mechanism:** By treating the appearance of male vs. female keywords as a Bernoulli process (expected p=0.5), significant deviations in count and "firstness" serve as proxy signals for cultural prioritization.
- **Core assumption:** The frequency and order of words in educational texts accurately reflect the intent or cultural bias of the creators, rather than random noise.
- **Evidence anchors:**
  - [abstract] Results show consistent overrepresentation of male characters in terms of count, firstness, and named entities.
  - [results, Table 4 & 5] The study reports a significant p-value (1.19 * 10^-28) for overall count differences and significant male-firstness in the overall dataset (p=0.00234).
  - [corpus] Related work (e.g., *Relating Word Embedding Gender Biases to Gender Gaps*) supports the premise that statistical language patterns correlate with real-world gender gaps.
- **Break condition:** If textbook content is strictly regulated by an external stylistic guide that enforces equality artificially, the statistical signal would detach from the underlying cultural bias.

### Mechanism 2: Semantic Context Segregation via TF-IDF
- **Claim:** Distinct vocabularies and social roles are associated with specific genders, revealing role segregation through unique keyword extraction.
- **Mechanism:** Text segments containing gendered keywords are segregated into "male context" and "female context" corpora. Term Frequency-Inverse Document Frequency (TF-IDF) then identifies words unique to each corpus.
- **Core assumption:** Words with high TF-IDF scores are representative of the thematic content associated with that gender, rather than incidental co-occurrences.
- **Evidence anchors:**
  - [methods] "TF IDF is adopted... so that words that have high frequency in both documents can be crossed out, leaving behind the words that are representative."
  - [results, Image 3/4] The analysis of names in TF-IDF lists showed more male names (62) than female names (23) overall, with specific patterns of interaction varying by cultural sphere.
  - [corpus] *Colombian Waitresses y Jueces canadienses* illustrates how LLMs and NLP methods can isolate occupation-related gender biases, validating the focus on word associations.
- **Break condition:** If the text segments are too short or generic (e.g., grammar exercises with random word lists), TF-IDF will fail to capture meaningful thematic associations.

### Mechanism 3: Embedding-Based Stereotype Validation
- **Claim:** Gender associations in textbooks align with broader societal biases embedded in large-scale pre-trained language models.
- **Mechanism:** The unique word lists generated via TF-IDF are projected into a pre-trained vector space (GloVe). Cosine distance measures the proximity of these word clusters to specific "bias keywords."
- **Core assumption:** The pre-trained GloVe embeddings accurately represent the "real-world" gender bias that the study aims to detect in textbooks.
- **Evidence anchors:**
  - [results, Table 8] "Pretty," "baby," and "love" were closer to the female cluster, while "death" was closer to the male cluster.
  - [discussion] "GloVe proves to us that some words that are closer to some gender in the world... are also closer to the TF IDF words... textbooks are biased in the same way as the general corpus."
  - [corpus] *Relating Word Embedding Gender Biases to Gender Gaps* provides external validation that embedding distances correlate with empirical societal metrics.
- **Break condition:** If the textbook uses highly specialized or archaic vocabulary not well-represented in the standard GloVe training corpus, the vector spatial relationships may become noisy or invalid.

## Foundational Learning

- **Concept: Term Frequency-Inverse Document Frequency (TF-IDF)**
  - **Why needed here:** This statistic reflects how important a word is to a document in a collection. It is the core technique used to isolate the specific vocabulary associated with male vs. female contexts, filtering out common English words.
  - **Quick check question:** If the word "the" appeared frequently in both male and female contexts, would it have a high TF-IDF score? (Answer: No, because the IDF component would lower the weight).

- **Concept: GloVe (Global Vectors for Word Representation)**
  - **Why needed here:** Understanding word embeddings is necessary to grasp how the study quantifies "distance" between concepts to prove bias exists on a semantic level, not just a frequency level.
  - **Quick check question:** In a GloVe vector space, if "king" is to "man" as "queen" is to "woman," what mathematical operation might represent this relationship? (Answer: Vector subtraction/addition, e.g., King - Man + Woman â‰ˆ Queen).

- **Concept: Firstness (Linguistic Ordering)**
  - **Why needed here:** This is a specific metric used in the paper to measure status or primacy. It assumes that the order of appearance in binary pairs indicates cultural priority.
  - **Quick check question:** In the phrase "Mr. and Mrs. Smith," which gender exhibits "firstness" according to the paper's protocol? (Answer: Male, because "Mr." appears before "Mrs.").

## Architecture Onboarding

- **Component map:** PDF extraction (PyMuPDF/OCR) -> Text preprocessing (NLTK) -> Language detection -> 100-char context segmentation -> Gender classification -> Counter analysis -> TF-IDF extraction -> Name filtering -> LLM validation -> GloVe embedding analysis

- **Critical path:** The **Context Segmentation** step is the most critical. If the 100-character window or the keyword list is flawed, the resulting "Male" and "Female" documents will be contaminated, invalidating all downstream TF-IDF and GloVe analyses.

- **Design tradeoffs:**
  - **Strict Firstness vs. Recall:** The system only counts "firstness" if words are immediate or separated by one stopword. This avoids false positives but likely underestimates total ordering bias.
  - **English-Only:** Controlling for language simplifies NLP but limits the study's ability to analyze gender bias in cultures where English is not the primary educational language.

- **Failure signatures:**
  - **Sparse Data:** Small cultural spheres lead to statistically insignificant p-values, causing the system to fail to detect bias even if it is visually present.
  - **Keyword Overlap:** If TF-IDF lists for male and female contexts are nearly identical, it suggests the segmentation logic failed to isolate gendered contexts effectively.

- **First 3 experiments:**
  1. **Validation of Segmentation:** Run the context segmentation pipeline on a synthetic textbook with known gender ratios to verify that the "Counter" module accurately reflects the input.
  2. **Sensitivity Analysis on Window Size:** Re-run the TF-IDF analysis using 50-character and 200-character context windows to see if the extracted vocabulary shifts significantly.
  3. **GloVe Stability Check:** Map the extracted TF-IDF lists to different embedding models (e.g., Word2Vec vs. GloVe) to ensure the distance metrics for keywords like "nurse" or "death" are consistent across vector spaces.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the observed gender inequality persist in non-language textbooks, such as math or history?
- **Basis in paper:** [explicit] The author states, "future work... can be done... other textbooks can be analyzed as well, such as math and history."
- **Why unresolved:** The study isolated English textbooks to control for language as a confounding variable, leaving other subjects unexamined.
- **What evidence would resolve it:** Applying the same NLP metrics (count, firstness, TF-IDF) to math and history textbooks across the same cultural spheres.

### Open Question 2
- **Question:** Would a larger sample of countries per cultural sphere yield statistically significant results for firstness metrics?
- **Basis in paper:** [explicit] The author notes that "only three countries accounted for per cultural sphere" might have caused the "insignificant differences in... firstness" observed in some spheres.
- **Why unresolved:** The low occurrence of firstness events (e.g., only 12 in Sinosphere) limited the statistical power to detect bias in individual spheres.
- **What evidence would resolve it:** A replication of the study with a denser dataset of textbooks from a wider variety of countries within each cultural sphere.

### Open Question 3
- **Question:** Is the gender bias detected in textbooks more strongly correlated with the cultural sphere of the target audience or the origin of the publishing house?
- **Basis in paper:** [inferred] The paper hypothesizes that the Latin sphere's low inequality might be because textbooks were "adapted from the western cultural sphere," implying publisher origin may be a stronger driver of content bias than the local culture.
- **Why unresolved:** The study aggregates data by the country of usage, without performing a comparative analysis based on the publisher's country of origin.
- **What evidence would resolve it:** A statistical comparison grouping textbooks by publisher origin rather than the country where they are used.

## Limitations
- Cultural sphere aggregation may mask country-specific variations in gender representation
- English-language restriction prevents analysis of native language educational materials
- Keyword list completeness may miss implied or pronoun-based gender references

## Confidence
- **High confidence:** Overall finding of male overrepresentation across all metrics (count, firstness, named entities) is robust with statistically significant results (p < 0.05)
- **Medium confidence:** Regional variations in gender inequality are credible but require cautious interpretation due to smaller sample sizes
- **Low confidence:** Specific TF-IDF associations and their semantic interpretations are less certain due to context segmentation quality assumptions

## Next Checks
1. **Sensitivity analysis of segmentation window:** Test whether the 100-character context window is optimal by comparing results using 50-character and 200-character windows to assess stability of TF-IDF associations
2. **Cross-linguistic validation:** Replicate the analysis on textbooks from the same countries in their native languages to determine if English-medium bias differs from native language patterns
3. **Ground truth comparison:** Manually code a subset of textbook passages to verify that the NLP-identified gender contexts accurately reflect human judgment about gendered content