---
ver: rpa2
title: 'LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors'
arxiv_id: '2505.11352'
source_url: https://arxiv.org/abs/2505.11352
tags:
- speech
- legoslm
- encoder
- performance
- trained
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes LegoSLM, a method to connect speech encoders
  with large language models (LLMs) using Connectionist Temporal Classification (CTC)
  posteriors. The speech encoder is fine-tuned to generate CTC posteriors over the
  LLM vocabulary, which are then used to reconstruct pseudo-audio embeddings by computing
  a weighted sum of the LLM input embeddings.
---

# LegoSLM: Connecting LLM with Speech Encoder using CTC Posteriors

## Quick Facts
- **arXiv ID:** 2505.11352
- **Source URL:** https://arxiv.org/abs/2505.11352
- **Reference count:** 27
- **Primary result:** 49% average WERR over USM-CTC baseline on 8 MLS testsets

## Executive Summary
LegoSLM proposes a modular approach to connect pre-trained speech encoders with large language models (LLMs) for automatic speech recognition (ASR) and speech translation (AST). The method uses Connectionist Temporal Classification (CTC) posteriors from a speech encoder as an intermediate representation, which are then used to reconstruct pseudo-audio embeddings through weighted summation of LLM input embeddings. This enables the LLM to process both text and speech inputs in a unified manner while maintaining modularity that allows different speech encoders to be swapped and combined with the LLM in a zero-shot fashion after fine-tuning.

## Method Summary
LegoSLM bridges speech encoders and LLMs by fine-tuning a speech encoder to generate CTC posteriors over the LLM's vocabulary, then reconstructing pseudo-audio embeddings from these posterions through a weighted sum of the LLM's input embeddings. The USM-CTC speech encoder (300M parameters, 24 Conformer layers) is fine-tuned with CTC loss on a 256K vocabulary matching Gemma's tokenizer. Only the Gemma 2B LLM is fine-tuned, with the speech encoder frozen. During inference, the pseudo-speech embeddings are concatenated with text embeddings, and a softmax temperature parameter controls the decode-time influence of the speech and LLM components. The approach achieves 49% average WERR improvement over the USM-CTC baseline on 8 MLS testsets while exhibiting modularity for zero-shot encoder switching.

## Key Results
- 49% average WERR improvement over USM-CTC baseline on 8 MLS testsets
- Achieves 4.4 WER on MLS-en with USM encoder and 3.6 WER with Whisper encoder
- Demonstrates effective domain adaptation through temperature control (τ) parameter

## Why This Works (Mechanism)
LegoSLM works by using CTC posteriors as a bridge between speech encoders and LLMs, avoiding the need for complex cross-modal alignment. The CTC output provides a probability distribution over the LLM vocabulary for each time step, which can be directly converted into pseudo-speech embeddings by computing a weighted sum of the LLM's input embeddings. This creates a representation that the LLM can process naturally alongside text. The modularity emerges because the CTC-based connection is vocabulary-aligned, allowing different speech encoders to be swapped as long as they produce compatible CTC posteriors. The temperature parameter provides fine-grained control over the relative influence of speech and language models during decoding.

## Foundational Learning
- **CTC (Connectionist Temporal Classification)**: Needed to align variable-length speech sequences with fixed vocabulary outputs without requiring frame-level alignments. Quick check: Verify CTC loss computes correct gradient through blank token handling.
- **Weighted embedding reconstruction**: Converts probability distributions (CTC posteriors) into meaningful embeddings by computing E · o_t. Quick check: Ensure reconstructed embeddings preserve semantic information from posteriors.
- **Modularity through vocabulary alignment**: Requires speech encoder CTC vocabulary to match LLM tokenizer vocabulary exactly. Quick check: Confirm blank token is properly handled and doesn't dominate embeddings.

## Architecture Onboarding
**Component map:** USM-CTC encoder -> CTC posteriors -> Weighted sum of Gemma embeddings -> Concatenated with text embeddings -> Gemma LLM

**Critical path:** Speech encoder → CTC layer → Embedding reconstruction → LLM input space

**Design tradeoffs:** Freezing speech encoder maximizes modularity but may limit optimal adaptation; using CTC posteriors simplifies alignment but requires vocabulary compatibility; temperature control adds flexibility but introduces hyperparameter tuning.

**Failure signatures:** High temperature (τ→1e4) causes repetitive LLM hallucination ("the united states of america..."); poor zero-shot transfer indicates vocabulary misalignment; excessive insertions/deletions suggest blank token dominance.

**First experiments:** 1) Verify CTC posterior generation matches expected vocabulary distribution; 2) Test embedding reconstruction with synthetic CTC outputs; 3) Validate temperature control by measuring WER variation across τ values.

## Open Questions the Paper Calls Out
None specified in the paper.

## Limitations
- Relies on proprietary USM BEST-RQ speech encoder weights trained on YouTube data, creating reproducibility barriers
- Exact vocabulary alignment procedure between USM CTC outputs and Gemma's 256K tokenizer is not fully specified
- Training setup uses TPU pods, making it inaccessible to most research groups without equivalent infrastructure

## Confidence
- **High confidence** in core architectural innovation and modularity claims (clearly demonstrated through controlled experiments)
- **Medium confidence** in WERR improvements (dependent on proprietary models and specific training configurations)
- **Low confidence** in zero-shot encoder switching claims (without independent verification across different speech encoder architectures)

## Next Checks
1. Replicate the LegoSLM architecture using publicly available wav2vec 2.0 or Whisper encoders with CTC fine-tuning to verify if similar WERR improvements can be achieved without proprietary components.
2. Implement ablation studies removing the pseudo-embedding reconstruction step to isolate its contribution to the reported performance gains.
3. Test the temperature control mechanism (τ) across different domain adaptation scenarios beyond MLS to validate its effectiveness in handling out-of-domain data.