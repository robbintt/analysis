---
ver: rpa2
title: Domain Adversarial Training for Mitigating Gender Bias in Speech-based Mental
  Health Detection
arxiv_id: '2505.03359'
source_url: https://arxiv.org/abs/2505.03359
tags:
- gender
- speech
- depression
- detection
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses gender bias in speech-based mental health
  detection models for depression and PTSD. The proposed domain adversarial training
  (DAT) approach treats gender as distinct domains and integrates this information
  into pretrained speech foundation models to learn domain-invariant features.
---

# Domain Adversarial Training for Mitigating Gender Bias in Speech-based Mental Health Detection

## Quick Facts
- **arXiv ID**: 2505.03359
- **Source URL**: https://arxiv.org/abs/2505.03359
- **Reference count**: 37
- **Primary result**: Domain adversarial training improves F1-scores by up to 13.29 percentage points and reduces gender-based performance disparities in speech-based mental health detection

## Executive Summary
This study addresses gender bias in speech-based mental health detection models for depression and PTSD. The proposed domain adversarial training (DAT) approach treats gender as distinct domains and integrates this information into pretrained speech foundation models to learn domain-invariant features. Experimental results on the E-DAIC dataset show that DAT improves F1-scores by up to 13.29 percentage points compared to baseline fine-tuning methods. The approach successfully mitigates gender-based performance disparities while maintaining high classification accuracy, with HuBERT achieving the best overall performance (F1-score of 68.03% for depression detection). Qualitative analysis confirms that DAT reduces gender-specific clustering in feature representations, demonstrating its effectiveness in creating more fair and generalizable models for clinical applications.

## Method Summary
The study applies domain adversarial training to pretrained speech foundation models (wav2vec 2.0, HuBERT, WavLM) for mental health detection from audio. The approach treats gender as a domain and adds a gender discriminator branch with gradient reversal to learn domain-invariant features. The encoder is trained to minimize mental health classification loss while maximizing gender classification loss through the reversed gradients. The domain adaptation parameter λ is progressively increased from 0.0096 to 1.0 over 200 training steps. The model is fine-tuned on E-DAIC dataset with 10-second audio segments, using weighted cross-entropy loss and Adam optimizer (lr=5e-5, batch size 8, 50 epochs).

## Key Results
- DAT improves F1-scores by up to 13.29 percentage points compared to baseline fine-tuning methods
- HuBERT achieves the best overall performance with 68.03% F1-score for depression detection
- The approach successfully reduces gender-based performance disparities while maintaining high classification accuracy
- Qualitative analysis shows DAT reduces gender-specific clustering in feature representations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Gradient reversal layer creates domain-invariant representations that preserve mental health signals while suppressing gender-specific acoustic patterns
- **Mechanism**: A gender discriminator branch predicts gender from encoder outputs, but its gradients are multiplied by -1 during backpropagation. This forces the speech encoder to maximize gender classification error (making features gender-ambiguous) while simultaneously minimizing mental health classification error via standard gradients
- **Core assumption**: Mental health indicators can be disentangled from gender-specific acoustic features in the learned representation space
- **Evidence anchors**: Abstract mentions learning "domain-invariant features"; Section IV.C describes gradient reversal; Section V.D shows intermixed male/female distributions

### Mechanism 2
- **Claim**: Pretrained speech foundation models provide transferable acoustic representations that enable effective learning despite limited clinical data
- **Mechanism**: Self-supervised models pretrained on LibriSpeech learn general acoustic encodings. Fine-tuning adapts these representations to mental health tasks without requiring large labeled clinical datasets
- **Core assumption**: Representations learned from read speech transfer to conversational clinical interview speech
- **Evidence anchors**: Section IV.A states pretraining on large-scale speech datasets is pivotal; mentions using base models pretrained on LibriSpeech 960 hours

### Mechanism 3
- **Claim**: Progressive lambda scheduling prevents early training instability by gradually increasing domain adversarial pressure
- **Mechanism**: The domain adaptation parameter λ starts at 0.0096 and increases to 1.0 over 200 steps. Early training focuses on learning mental health classification; adversarial pressure increases only after useful features emerge
- **Core assumption**: A warmup period allows stable mental health feature learning before domain confusion pressure disrupts optimization
- **Evidence anchors**: Section III.C specifies λ initialization and progression; abstract mentions F1-score improvements

## Foundational Learning

- **Concept**: Gradient Reversal Layer (Ganin et al., 2016)
  - **Why needed here**: Core technique enabling domain-invariant learning; without understanding it, the dual-loss optimization appears contradictory
  - **Quick check question**: If you removed the negative sign from gradient multiplication, would the model learn more or less gender-specific features?

- **Concept**: Self-Supervised Speech Representation Learning (wav2vec 2.0 family)
  - **Why needed here**: Understanding what pretrained encoders capture helps diagnose transfer failures and select appropriate foundation models
  - **Quick check question**: Why might a model pretrained on audiobooks struggle with clinical interview speech containing interruptions and disfluencies?

- **Concept**: F1-Score Decomposition by Subgroup
  - **Why needed here**: Overall F1 can mask severe subgroup failures; Tables III-IV reveal that baseline models had 10.79% F1 for female PTSD vs. 49.5% for male PTSD
  - **Quick check question**: A model achieves 70% overall F1 but 85% on male samples and 30% on female samples. Is this acceptable for clinical deployment?

## Architecture Onboarding

- **Component map**: Input (10s audio) -> Pretrained speech foundation model (768-dim) -> Mental Health Classifier (2-class softmax) + Gender Discriminator (2-class softmax with GRL) -> Loss aggregation
- **Critical path**: The λ scheduling and gradient reversal implementation. A bug in the reversal sign or λ schedule will cause the model to either ignore domain adaptation or collapse representations to gender-agnostic noise
- **Design tradeoffs**: Higher λ → stronger debiasing but risks discarding task-relevant signal; longer warmup → more stable but may embed gender bias before adversarial pressure activates
- **Failure signatures**: Gender discriminator accuracy drops to ~50% but mental health F1 also drops significantly → λ too high; gender discriminator accuracy remains high (>80%) → λ too low or warmup too long; large performance gap between male/female subgroups persists → domain adaptation not converging
- **First 3 experiments**:
  1. **Baseline sanity check**: Fine-tune HuBERT on E-DAIC without DAT; replicate Table II fine-tuning results (F1 ~54-58%) to verify data pipeline
  2. **Lambda sweep**: Train DAT with λ ∈ {0.1, 0.3, 0.5, 0.7, 1.0} (fixed, no warmup); plot gender discriminator accuracy vs. mental health F1 to find stable operating region before implementing progressive scheduling
  3. **Gender-stratified evaluation**: On best checkpoint, compute F1 separately for male/female subgroups (replicating Tables III-IV); verify that the gender gap narrows compared to baseline

## Open Questions the Paper Calls Out
- **Open Question 1**: How does domain adversarial training perform when extended to demographic factors beyond binary gender, such as age or accent variations?
  - **Basis in paper**: The authors state in the conclusion that "Future work should be considered for other demographic factors (e.g., age, accent variations)"
  - **Why unresolved**: The current study isolated gender as the primary domain for bias mitigation
  - **What evidence would resolve it**: Experimental results applying the same DAT methodology to datasets annotated with age groups and diverse accent labels

- **Open Question 2**: Can more advanced debiasing techniques completely eliminate the residual gender-specific clustering observed in the feature representations?
  - **Basis in paper**: The qualitative analysis notes that "some degree of gender clustering remains" and suggests "future work could explore more advanced debiasing techniques"
  - **Why unresolved**: The t-SNE visualization showed that while DAT reduces bias, it does not render features entirely domain-invariant
  - **What evidence would resolve it**: Comparative studies showing alternative adversarial architectures or regularization methods that result in fully intermixed feature distributions

- **Open Question 3**: Does the proposed approach maintain its efficacy in improving fairness and accuracy when applied to significantly larger and more diverse datasets?
  - **Basis in paper**: The authors recommend validation on "larger datasets" to further improve clinical applicability
  - **Why unresolved**: The experiments were restricted to the E-DAIC dataset, which consists of only 275 interview recordings
  - **What evidence would resolve it**: Replication of the DAT framework on large-scale, multi-institutional speech corpora with higher sample densities

## Limitations
- The effectiveness of gradient reversal depends on the assumption that mental health indicators are independent of gender-specific acoustic features
- Transfer from read speech (LibriSpeech) to conversational clinical speech may be imperfect, potentially limiting the representational quality of pretrained models for this domain
- The paper does not specify the exact architecture of the gender discriminator branch, making exact reproduction challenging

## Confidence
- **High**: DAT improves overall F1-scores and reduces gender performance gaps (supported by quantitative metrics in Tables III-IV)
- **Medium**: DAT successfully learns domain-invariant representations (supported by qualitative visualization but not ablation studies)
- **Low**: The specific architectural details of the gender discriminator branch (insufficient specification in paper)

## Next Checks
1. **Reproduce baseline results**: Fine-tune HuBERT on E-DAIC without DAT to verify data pipeline and replicate Table II fine-tuning results (F1 ~54-58%)
2. **Lambda sweep experiment**: Train DAT with fixed λ ∈ {0.1, 0.3, 0.5, 0.7, 1.0} to find stable operating region before implementing progressive scheduling
3. **Gender-stratified evaluation**: On best checkpoint, compute F1 separately for male/female subgroups to verify that the gender gap narrows compared to baseline