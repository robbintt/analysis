---
ver: rpa2
title: Internal states before wait modulate reasoning patterns
arxiv_id: '2510.04128'
source_url: https://arxiv.org/abs/2510.04128
tags:
- features
- reasoning
- steering
- wait
- crosscoder
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates how reasoning models like DeepSeek-R1-Distill-Llama-8B
  decide when to engage in reasoning behaviors, particularly when they output the
  token "wait" which signals self-reflection or backtracking. To understand this,
  the authors train sparse crosscoders between the reasoning model and its base version
  to discover latent features influencing wait token prediction.
---

# Internal states before wait modulate reasoning patterns

## Quick Facts
- arXiv ID: 2510.04128
- Source URL: https://arxiv.org/abs/2510.04128
- Reference count: 14
- Primary result: Reasoning models decide when to "wait" through both wait-promoting and wait-suppressing features, with the latter enabling diverse reasoning transitions.

## Executive Summary
This work investigates how reasoning models like DeepSeek-R1-Distill-Llama-8B decide when to engage in reasoning behaviors, particularly when they output the token "wait" which signals self-reflection or backtracking. To understand this, the authors train sparse crosscoders between the reasoning model and its base version to discover latent features influencing wait token prediction. They introduce a novel latent attribution technique in the crosscoder setting to identify the top and bottom 50 features most strongly promoting or suppressing wait tokens. Through analysis of max-activating examples and targeted feature steering experiments, they show that these features correspond to distinct reasoning patterns: top features relate to backtracking and self-verification, while bottom features trigger behaviors like restarting reasoning, expressing uncertainty, or concluding. Steering experiments validate these interpretations, demonstrating that feature interventions can shift reasoning behavior in predictable ways. Notably, many reasoning-relevant features fall in the bottom category, suggesting that suppressing wait is as important as promoting it for effective reasoning.

## Method Summary
The authors train crosscoders at layer 15 of DeepSeek-R1-Distill-Llama-8B and its base version to decompose activations into interpretable sparse features. They use latent attribution via gradient-based approximation to identify features that causally influence "wait" token generation without exhaustive ablation. Top-50 and bottom-50 features are selected based on their contribution to wait probability, and their behaviors are validated through steering experiments and analysis of max-activating examples. The approach reveals that both promoting and suppressing "wait" tokens are critical for effective reasoning, with bottom features enabling diverse reasoning transitions.

## Key Results
- Crosscoder latent attribution identifies 32,768 features at layer 15, with top-50 promoting wait and bottom-50 suppressing it
- Top features primarily trigger backtracking and self-verification behaviors
- Bottom features surprisingly correspond to rich reasoning behaviors: restarting, recalling knowledge, expressing uncertainty, or concluding
- Steering experiments validate interpretations: steering top features reduces characters-to-next-wait, while steering bottom features can cause excessive backtracking or early conclusions
- Many reasoning-relevant features fall in bottom category, indicating wait suppression is as important as promotion for effective reasoning

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Sparse crosscoders can isolate reasoning-specific features by jointly decomposing activations from a base model and its reasoning-tuned variant.
- **Mechanism:** The crosscoder learns separate encoder/decoder weight matrices for each model while sharing latent features. Features are classified as base-only, shared, or reasoning-finetuned based on the relative norm contribution each model's decoder makes to reconstructing that feature.
- **Core assumption:** The reasoning behavior arises from modifications to the base model's representations that can be captured as additive feature directions in activation space.
- **Evidence anchors:** [abstract] "We train crosscoders at multiple layers of DeepSeek-R1-Distill-Llama-8B and its base version"; [section 2.1] Equations (1) and (2) define the encoder/decoder structure; [corpus] Related work by Venhoff et al. uses steering vectors for similar reasoning behavior analysis, but crosscoders provide more granular feature-level decomposition.

### Mechanism 2
- **Claim:** Latent attribution via gradient-based approximation efficiently identifies features that causally influence "wait" token generation.
- **Mechanism:** Rather than exhaustively ablating each feature, the method computes: m̃(x) = W_dec^R^T ∇_a M(x) ⊙ f(x). This linear approximation exploits the fact that the metric's gradient with respect to the residual stream, projected through the decoder and multiplied by feature activations, approximates each feature's contribution to the wait token probability.
- **Core assumption:** The relationship between feature activation and logit change is approximately linear near the operating point.
- **Evidence anchors:** [section 2.3] Equation (5) defines the attribution computation explicitly; [section 2.3] "We average our scores over a dataset of 620 rollouts ending right before the first wait occurrence."

### Mechanism 3
- **Claim:** Both promoting AND suppressing "wait" tokens are critical for effective reasoning—bottom features (suppressors) enable diverse reasoning transitions.
- **Mechanism:** Top features increase wait probability and primarily trigger backtracking/self-verification. Bottom features decrease wait probability but surprisingly correspond to rich reasoning behaviors: restarting from scratch, recalling prior knowledge, expressing uncertainty, or concluding. The steering experiments show that negatively steering bottom features causes excessive backtracking, while positive steering leads to early conclusions.
- **Core assumption:** Reasoning requires strategic pauses (wait) but also requires knowing when NOT to pause—to proceed, conclude, or restart.
- **Evidence anchors:** [section 3] "Most interestingly, the bottom features contain a larger number for finetuned-only, i.e., reasoning features"; [figure 3] Feature 744 (bottom) steering causes "go back to original problem" behavior; Feature 188 causes uncertainty expression.

## Foundational Learning

- **Concept: Sparse Autoencoders (SAEs)**
  - **Why needed here:** Crosscoders are an extension of SAEs. Understanding that SAEs decompose activations into interpretable sparse features by balancing reconstruction loss with L1 sparsity penalty is prerequisite.
  - **Quick check question:** Can you explain why sparsity (L1 penalty) helps make features interpretable rather than just using reconstruction error?

- **Concept: Activation Steering / Intervention**
  - **Why needed here:** The paper validates feature interpretations by steering—adding scaled feature vectors to activations during generation. Understanding how and why steering works is essential.
  - **Quick check question:** If you add a feature direction v_k scaled by α to the residual stream, what behavior change would you expect if α > 0 vs α < 0?

- **Concept: Attribution / Gradient-based Causal Analysis**
  - **Why needed here:** The latent attribution technique uses gradients to approximate feature importance without exhaustive ablation.
  - **Quick check question:** Why does ∇_a M(x) (gradient of metric w.r.t. activations) tell us how sensitive the "wait" probability is to perturbations at that layer?

## Architecture Onboarding

- **Component map:**
  Base Model (Llama-3.1-8B) -> Crosscoder -> Feature Activations f(x) -> Decoder W_dec^(R) -> Feature Directions v_k -> Attribution: W_dec^T ∇_a M ⊙ f(x) -> Feature Scores

- **Critical path:**
  1. Train crosscoder on paired activations from base + reasoning models at layer 15
  2. Compute latent attribution scores for all 32,768 features w.r.t. wait tokens
  3. Select top-50 and bottom-50 features
  4. Validate via max-activating examples + steering interventions

- **Design tradeoffs:**
  - Layer selection: Layer 15 chosen (mid-network)—earlier layers may lack semantic abstraction, later layers may be too output-focused
  - Crosscoder width (32,768 features): Larger = more granular but more expensive to analyze
  - Steering strength (α = 0.5 to 1.5): Too high causes degenerate outputs ("WaitWaitWait..."), too low shows no effect
  - First 100 tokens steering vs full-sequence: Full-sequence degraded quality (Table 1 notes)

- **Failure signatures:**
  - Degenerate repetition when over-steering top features: "wait wait wait..."
  - Excessive uncertainty loops when steering bottom features negatively
  - Accuracy drop (81% → 61% for feature 31748) indicates some features are brittle
  - LLM-judge systematically underestimates adherence (scores are lower bounds)

- **First 3 experiments:**
  1. **Reproduce the attribution ranking:** Train crosscoder (or use provided weights), compute attribution scores for wait tokens on a held-out dataset, verify top/bottom feature separation matches paper
  2. **Steering sanity check:** Pick one top feature, steer with α = 1.5 starting before first wait token, measure characters-until-next-wait; expect significant decrease for top features
  3. **Cross-layer analysis:** Train crosscoders at layers 7, 15, 23; compare which layer's features are most interpretable and causally effective—hypothesis: layer 15 balances semantic richness and behavioral control

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can complete multi-layer circuits be constructed that show how the identified reasoning features causally depend on each other across layers?
- **Basis in paper:** [explicit] Limitations section states: "fully constructing a circuit that also shows latent-to-latent dependency across layers for these reasoning behaviors remains an open area for future work."
- **Why unresolved:** Current crosscoder analysis operates at single layers (layer 15), capturing features in isolation without tracing how information flows between features at different depths during reasoning.
- **What evidence would resolve it:** Training cross-layer crosscoders or performing causal mediation analysis across layers to map feature-to-feature dependencies during wait decisions.

### Open Question 2
- **Question:** Do wait-modulating features and their associated reasoning patterns generalize across different reasoning model architectures (e.g., OpenAI o1, Claude 3.7 Sonnet)?
- **Basis in paper:** [explicit] Limitations section notes: "it is currently limited to a specific model family and may not generalize across architectures without adaptation."
- **Why unresolved:** Only DeepSeek-R1-Distill-Llama-8B was studied; the features identified may be artifacts of this specific distillation process or architecture rather than universal reasoning mechanisms.
- **What evidence would resolve it:** Applying the same crosscoder latent attribution methodology to other reasoning models and comparing whether analogous features with similar reasoning behaviors emerge.

### Open Question 3
- **Question:** What other tokens or internal markers beyond "wait" signal reasoning transitions, and do they share features with wait-modulating ones?
- **Basis in paper:** [inferred] Limitations states the analysis "focuses on a narrow slice of reasoning behavior, potentially missing out other important markers or mechanisms."
- **Why unresolved:** The study intentionally restricts scope to wait tokens, but reasoning involves diverse behaviors (Venhoff et al. identified patterns like example testing, uncertainty estimation) that may use different internal signals.
- **What evidence would resolve it:** Extending latent attribution to other reasoning-associated tokens (e.g., "actually," "let me reconsider") and testing whether identified features overlap or are distinct.

### Open Question 4
- **Question:** Why does reasoning fine-tuning allocate substantial capacity to suppressing wait tokens rather than solely promoting them?
- **Basis in paper:** [inferred] Results show bottom features (suppressing wait) contain more reasoning-finetuned-only features than top features, and exhibit greater behavioral diversity (restarting, concluding, uncertainty).
- **Why unresolved:** The asymmetry between promotion and suppression is noted as surprising but not explained; it may reflect that effective reasoning requires knowing when to stop reflecting as much as when to start.
- **What evidence would resolve it:** Analyzing training dynamics during reasoning fine-tuning to observe when suppression features emerge, or ablating suppression features to measure downstream reasoning quality effects.

## Limitations

- Training protocol opacity: Crosscoder training hyperparameters (learning rate, optimizer, batch size, sparsity regularization strength, L2 penalty weight) are not specified, which is critical for feature quality and attribution accuracy.
- Attribution approximation validity: The gradient-based linear attribution assumes locally linear relationships between feature activation and wait-token probability, potentially missing important non-linear interactions.
- Steering interpretation assumptions: Behavioral interpretations (backtracking, uncertainty expression, restarting) rely on subjective judgment about what constitutes specific reasoning behaviors.

## Confidence

**High confidence:** The core technical methodology of using crosscoders for model diffing and latent attribution for feature selection is sound and well-established. The observation that reasoning-relevant features exist in both top (wait-promoting) and bottom (wait-suppressing) categories is directly verifiable from the data and steering results.

**Medium confidence:** The interpretation that bottom features correspond to specific reasoning behaviors (restarting, uncertainty expression, concluding) is supported by steering experiments but relies on qualitative analysis. The claim that "wait-suppressing features are as important as wait-promoting features for effective reasoning" is plausible but requires more systematic evaluation across diverse tasks.

**Low confidence:** The generalizability of findings to other reasoning models or reasoning tasks beyond the 500-sample dataset used. The specific feature rankings and interpretations may be dataset-dependent or specific to the DeepSeek-R1-Distill architecture.

## Next Checks

1. **Cross-task generalization:** Apply the same crosscoder and attribution pipeline to a different reasoning dataset (e.g., GSM8K, MATH) and verify whether the same top/bottom feature patterns emerge. Compare feature rankings across datasets to assess generalizability.

2. **Ablation validation:** Systematically ablate individual top and bottom features (using exact zero-masking, not linear approximation) to verify that attribution scores correctly predict causal importance. Measure accuracy degradation and wait-token frequency changes.

3. **Alternative attribution methods:** Compare the gradient-based attribution against other causal analysis techniques (e.g., causal tracing, integrated gradients, Shapley values) to assess robustness of feature rankings and identify potential artifacts in the current approach.