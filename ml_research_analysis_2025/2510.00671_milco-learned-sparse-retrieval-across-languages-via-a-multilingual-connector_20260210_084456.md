---
ver: rpa2
title: 'Milco: Learned Sparse Retrieval Across Languages via a Multilingual Connector'
arxiv_id: '2510.00671'
source_url: https://arxiv.org/abs/2510.00671
tags:
- milco
- sparse
- multilingual
- retrieval
- english
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MILCO, a multilingual learned sparse retrieval
  architecture that maps queries and documents from multiple languages into a shared
  English lexical space via a multilingual connector. It employs a two-stage training
  approach combining Sparse Alignment Pretraining with contrastive training to avoid
  semantic collapse while maintaining transparency.
---

# Milco: Learned Sparse Retrieval Across Languages via a Multilingual Connector

## Quick Facts
- **arXiv ID**: 2510.00671
- **Source URL**: https://arxiv.org/abs/2510.00671
- **Reference count**: 40
- **Primary result**: MILCO achieves state-of-the-art multilingual and cross-lingual retrieval performance across 39 languages, outperforming Qwen3-Embed and BGE-M3 by up to +34.1% nDCG@10 on MIRACL.

## Executive Summary
This paper introduces MILCO, a multilingual learned sparse retrieval architecture that maps queries and documents from 39 languages into a shared English lexical space via a multilingual connector. It employs a two-stage training approach combining Sparse Alignment Pretraining (SAP) with contrastive training to avoid semantic collapse while maintaining transparency. A novel LexEcho head augments the English lexical view with a source-language view via an [ECHO] token to preserve uncommon entities. MILCO achieves state-of-the-art multilingual and cross-lingual retrieval performance, outperforming leading baselines including Qwen3-Embed and BGE-M3 by significant margins (e.g., +34.1% nDCG@10 on MIRACL). It also supports dynamic efficiency through post-hoc pruning, maintaining high effectiveness with only 30 active dimensions per document.

## Method Summary
MILCO is a multilingual learned sparse retrieval (LSR) architecture that projects multilingual inputs into a shared English lexical space using a multilingual connector. The two-stage training approach first uses Sparse Alignment Pretraining (SAP) to align non-English sparse representations to SPLADE-v3 outputs of English translations, preventing semantic collapse. This is followed by Structured Contrastive Training (SCT) with knowledge distillation from a reranker. The architecture consists of a BAAI/bge-m3-unsupervised encoder, an MLP connector, and a LexEcho head that produces dual views: an English view via max-pooled MLM logits and a source view via an [ECHO] token. The model is trained on 594M bitext pairs for SAP and 1.4M queries for SCT, achieving state-of-the-art performance across 39 languages.

## Key Results
- Achieves +34.1% nDCG@10 on MIRACL compared to Qwen3-Embed
- Maintains high effectiveness with only 30 active dimensions per document through post-hoc pruning
- Improves non-Latin language retrieval by up to 8.09% (Chinese) through LexEcho's source view preservation
- Unifies multilingual and cross-lingual retrieval in a single model without language-specific components

## Why This Works (Mechanism)

### Mechanism 1: English Pivot Space via Multilingual Connector
Projecting multilingual inputs into a shared English lexical space enables cross-lingual and multilingual retrieval within a single model. A lightweight MLP connector transforms hidden states from the multilingual encoder into the English embedding space, allowing an English MLM head to operate on inputs from 39+ languages. This creates vocabulary alignment without requiring language-specific models. The approach assumes English provides sufficiently rich lexical coverage and alignment resources to serve as an effective pivot for all target languages.

### Mechanism 2: Sparse Alignment Pretraining Prevents Semantic Collapse
SAP is a prerequisite for stable contrastive training—without it, representations become uninterpretable and ineffective. SAP aligns non-English inputs to English lexical targets using parallel corpora and a sparse-aware MSE loss focused on active coordinates. This grounds representations in the English vocabulary before retrieval-specific fine-tuning. Contrastive training alone produces semantically meaningless tokens (e.g., "governing", "match", "sky" for an input about Tesla's net worth).

### Mechanism 3: LexEcho Dual-View Preserves Tail Entities
The LexEcho head's source view recovers uncommon entities lost in English projection, improving robustness especially for non-Latin scripts. It produces two views: (1) English view via max-pooling over MLM logits, capturing translated concepts and expansions; (2) Source view via a dedicated [ECHO] token that assigns importance weights to original input tokens. When English lacks coverage (e.g., "Momo" 陌陌), the source view provides fallback matching. Final scoring combines both views additively.

## Foundational Learning

- **Concept: Learned Sparse Retrieval (LSR)**
  - Why needed here: MILCO is an LSR architecture—understanding why sparse representations matter (inverted index compatibility, transparency, dynamic pruning) is prerequisite to evaluating its tradeoffs versus dense/multi-vector methods.
  - Quick check question: Can you explain why LSR supports post-hoc pruning without additional training objectives, unlike Matryoshka representations?

- **Concept: Semantic Collapse in Multilingual Models**
  - Why needed here: The paper's central training innovation addresses semantic collapse—a failure mode where representations lose interpretable lexical semantics. Understanding this phenomenon is critical for diagnosing why naive multilingual LSR fails.
  - Quick check question: What observable symptoms indicate semantic collapse in a trained LSR model?

- **Concept: Cross-lingual vs. Multilingual Retrieval**
  - Why needed here: MILCO unifies both paradigms—cross-lingual (query and document in different languages) and multilingual (corpus contains multiple languages)—within a single English lexical space. Understanding the vocabulary mismatch problem in cross-lingual settings explains why source-view preservation matters.
  - Quick check question: Why do sparse methods like BM25 fail at cross-lingual retrieval, and how does MILCO's shared English space address this?

## Architecture Onboarding

- **Component map**: BAAI/bge-m3-unsupervised encoder -> MLP connector -> LexEcho head (English view + Source view)
- **Critical path**: SAP training (594M bitext pairs, 2 epochs, LR 2e-5) -> SCT-KD training (1.4M queries with distillation, 8 epochs, LR 2e-5). Skipping SAP causes semantic collapse; distillation outperforms InfoNCE by ~2.2 nDCG@10.
- **Design tradeoffs**:
  - English pivot vs. full multilingual vocabulary: Reduces memory/computation but risks entity loss—mitigated by LexEcho
  - Max-pooling vs. other aggregations: Chosen for sparse representation generation; may lose token position information
  - Simple MLP connector vs. deeper architecture: Lightweight but may limit projection capacity for distant language pairs
- **Failure signatures**:
  - Semantic collapse: Output tokens semantically unrelated to input (e.g., "governing", "match", "sky" for Tesla query) -> missing SAP stage
  - Entity loss: Rare named entities not retrieved correctly -> LexEcho source view may not activate; check [ECHO] token weights
  - Cross-lingual mismatch: Zero-shot cross-lingual retrieval fails -> verify connector alignment quality; check bitext coverage for source language
- **First 3 experiments**:
  1. Ablate SAP: Train MILCO with contrastive-only training (no SAP) on a single language pair; inspect output tokens for semantic collapse against SAP-trained baseline
  2. LexEcho contribution: Compare full MILCO against English-view-only variant on a non-Latin language (e.g., Chinese) with emphasis on tail entity queries; measure nDCG gap
  3. Pruning tradeoffs: Apply mass-based pruning at p=95 (≈30 tokens/doc) and evaluate retrieval effectiveness vs. latency on MIRACL; compare against Qwen3-Embed 0.6B at 1024 dimensions

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several important questions emerge from the work:

- Would non-English pivot languages (e.g., Chinese or Spanish) yield better cross-lingual retrieval for specific language families?
- Can native long-context training improve multilingual long-document retrieval beyond the passage-splitting workaround?
- What factors explain the substantial performance variance across languages (e.g., +4.5% vs. +34.1% improvements over baselines)?
- Would more sophisticated connector architectures (e.g., attention-based or transformer layers) improve alignment quality beyond the MLP connector?

## Limitations
- The English pivot assumption risks poor coverage for low-resource languages with limited bitext alignment to English or for rare entities lacking English equivalents
- The MLP connector's simplicity may constrain representation capacity for distant language pairs
- The max-pooling operation loses positional information that could be valuable for certain query types

## Confidence
- **High Confidence**: The empirical superiority claims (MIRACL nDCG@10 +34.1% over Qwen3-Embed, +19.8% over BGE-M3, post-hoc pruning effectiveness at 30 dimensions) are well-supported by the reported experiments across multiple benchmarks and language groups
- **Medium Confidence**: The SAP necessity claim is strongly evidenced by the semantic collapse demonstration, but the paper doesn't explore whether alternative pretraining strategies might achieve similar stability
- **Medium Confidence**: The LexEcho mechanism's effectiveness is demonstrated through ablation and language-specific analysis, but the paper doesn't provide ablation studies isolating the source view's contribution from the overall dual-view architecture

## Next Checks
1. **Zero-shot transfer validation**: Test MILCO's cross-lingual retrieval performance on language pairs with minimal bitext resources in the pretraining data (e.g., low-resource African or indigenous languages) to quantify the English pivot limitation

2. **Connector capacity analysis**: Systematically vary the MLP connector depth and width to identify performance saturation points and establish whether the current architecture is over- or under-parameterized for specific language families

3. **Source view contribution isolation**: Design an experiment that disables the source view ([ECHO] token contribution) while maintaining the English view, then measure the specific degradation for tail entities versus common vocabulary queries across multiple languages