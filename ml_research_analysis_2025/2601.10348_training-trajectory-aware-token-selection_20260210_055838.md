---
ver: rpa2
title: Training-Trajectory-Aware Token Selection
arxiv_id: '2601.10348'
source_url: https://arxiv.org/abs/2601.10348
tags:
- tokens
- training
- token
- distillation
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of continual reasoning distillation
  in language models, where standard fine-tuning often leads to performance degradation.
  The authors identify a phenomenon called "Imitation Shock," where training accuracy
  drops sharply early in training and then recovers, despite monotonically decreasing
  loss.
---

# Training-Trajectory-Aware Token Selection

## Quick Facts
- arXiv ID: 2601.10348
- Source URL: https://arxiv.org/abs/2601.10348
- Reference count: 40
- With only hundreds of examples, Qwen3-8B surpasses its teacher DeepSeek-R1 on competitive reasoning benchmarks

## Executive Summary
This paper addresses continual reasoning distillation challenges where standard fine-tuning causes performance degradation. The authors identify "Imitation Shock" - a phenomenon where training accuracy drops sharply early in training despite monotonically decreasing loss. They discover this is caused by "Imitation-Anchor Tokens" that dominate early optimization and suppress learning of other important tokens. To solve this, they propose Training-Trajectory-Aware Token Selection (T3S), which uses training trajectory signals to identify and mask these anchor tokens during optimization, enabling better reasoning token learning. T3S consistently improves performance across autoregressive and diffusion language models.

## Method Summary
T3S addresses continual reasoning distillation by identifying and masking "Imitation-Anchor Tokens" that suppress learning of other tokens. The method saves every checkpoint during standard SFT, identifies the Imitation Bottleneck (minimum training accuracy), computes token confidence changes from initialization to bottleneck, and masks anchor tokens (those with positive confidence change) during retraining. For diffusion models, it masks yet-to-learn tokens (those with confidence drops below threshold). The approach enables students to surpass teachers on reasoning benchmarks with minimal data.

## Key Results
- With only hundreds of examples, Qwen3-8B surpasses its teacher DeepSeek-R1 on competitive reasoning benchmarks
- Qwen3-32B approaches Qwen3-235B in performance using T3S
- LLaDA-2.0-Mini, trained with T3S, exceeds its autoregressive baseline and achieves state-of-the-art among 16B-scale no-think models
- T3S yields consistent gains across autoregressive and diffusion language models

## Why This Works (Mechanism)

### Mechanism 1: Anchor-Induced Suppression of Yet-to-Learn Tokens
Tokens with rapidly increasing confidence during early training ("Imitation-Anchor Tokens") actively suppress learning of other tokens, causing the "crash-then-recover" pattern. Anchor tokens dominate early gradient updates, creating a suppression effect that only weakens after anchors are sufficiently learned. This delays reasoning transfer. Core assumption: Token-level learning dynamics are coupled—progress on one subset can inhibit another.

### Mechanism 2: Gradient Incompatibility Between Token Groups
Anchor tokens and yet-to-learn tokens form a "separable two-way partition whose gradients do not coexist benignly." Gradients from one token subset harm the other—training on anchors increases reasoning-token losses and vice versa. Core assumption: The loss-transfer asymmetry observed in controlled experiments reflects actual training dynamics under full supervision.

### Mechanism 3: Trajectory Signals Are Necessary (Static Signals Insufficient)
The anchor/non-anchor partition cannot be recovered from base-model confidence, entropy, or gradient geometry alone—trajectory-aware profiling is required. Tokens across a broad range of initial confidence exhibit different learning behaviors; only confidence evolution around the bottleneck discriminates anchors. Core assumption: The bottleneck-referenced confidence change captures a meaningful functional split, not a spurious correlation.

## Foundational Learning

- **Token-level confidence/probability in autoregressive models**: T3S relies on tracking p_θ(y_t | y_{<t}, x) across checkpoints to identify confidence changes. You must understand how log-probabilities are computed and aggregated per-token. Quick check: Can you compute the token-level log-probability for position t given a model and a target sequence?

- **Gradient masking / loss weighting**: T3S masks anchor tokens by excluding them from the loss (setting zero weight). This requires understanding how to construct per-token masks and apply them during backpropagation. Quick check: How would you modify a standard cross-entropy loss to ignore specific token positions during gradient computation?

- **Checkpoint-wise analysis and intervention studies**: The paper's core evidence comes from logging every checkpoint and performing controlled interventions (e.g., one-step gradient updates on subsets). You need to design similar diagnostic experiments. Quick check: How would you measure the effect of a single gradient step on token subset A to the loss on token subset B?

## Architecture Onboarding

- **Component map**: Checkpoint logger -> Bottleneck detector -> Token profiler -> Mask generator -> Masked loss
- **Critical path**: 1) Run standard SFT with checkpoint logging 2) Identify bottleneck checkpoint via training accuracy minimum 3) Compute per-token confidence changes from θ_0 to θ_b 4) Reconstruct training objective with token-level masking 5) Retrain from θ_0 with modified objective
- **Design tradeoffs**: Self-select vs. cross-model selector (self-selection yields best results but cross-model works within tokenizer-sharing families); Threshold τ=0.2 for dLLMs selects ~5% most dropped tokens; Bottleneck detection uses training accuracy requiring gold answers or verifiers
- **Failure signatures**: 1) No bottleneck found - training accuracy never drops 2) T3S shows no improvement - static-confidence baselines also improve 3) Catastrophic forgetting increases - anchor masking too aggressive
- **First 3 experiments**: 1) Reproduce Imitation Shock - log checkpoints during SFT, plot training loss vs accuracy vs benchmark 2) Validate RRT - train to completion, extract post-bottleneck updates only, compare to standard SFT 3) Loss-transfer matrix - split tokens into anchor/reasoning groups, train on each subset separately, measure cross-group loss changes

## Open Questions the Paper Calls Out

### Open Question 1
Can a small selector model reliably identify yet-to-learn tokens for much larger tokenizer-sharing flagship models (100B+ parameters)? Cross-model selection experiments were limited to 8B→32B transfer within Qwen3 family; scaling to 100B+ models was not tested due to resource constraints.

### Open Question 2
What semantic or structural properties distinguish Imitation-Anchor Tokens from yet-to-learn tokens? The paper establishes that anchors dominate early optimization and suppress other tokens, but does not characterize what linguistic or reasoning-relevant features determine whether a token becomes an anchor.

### Open Question 3
Can T3S be adapted for settings where gold-answer verification is unavailable or unreliable? Section 3.6 notes bottleneck selection "uses training accuracy, which assumes access to gold answers (or an automatic verifier)." Domains lacking reliable verification remain unaddressed.

### Open Question 4
Would native dLLM trajectory signals outperform the AR-selector proxy for identifying yet-to-learn tokens in diffusion language models? Since dLLMs do not provide a clean AR-style token-wise likelihood interface, we use an AR selector as a practical proxy, but potential dLLM-native signals were not explored.

## Limitations

- Bottleneck detection sensitivity: Different checkpoint selections can yield substantially different T3S results, suggesting the bottleneck detector is a critical but potentially fragile component
- Generalizability to non-reasoning tasks: All experiments focus on mathematical reasoning benchmarks; whether T3S generalizes to other NLP tasks remains untested
- Computational overhead: T3S requires saving every checkpoint during training, increasing storage requirements and potentially slowing training

## Confidence

- High confidence: The existence of "Imitation Shock" phenomenon and basic T3S methodology are well-supported by multiple experiments and ablation studies
- Medium confidence: The trajectory signals (confidence change around bottleneck) are necessary and sufficient for identifying anchor tokens
- Low confidence: The mechanism generalizes to non-reasoning domains and computational overhead is acceptable for practical deployment

## Next Checks

1. **Cross-task generalization study**: Apply T3S to a non-reasoning task (e.g., summarization or translation) using the same methodology. Verify whether the anchor-suppression mechanism and T3S improvements replicate in these domains.

2. **Bottleneck sensitivity analysis**: Systematically vary the checkpoint selection criteria (training loss minimum, validation accuracy minimum, random checkpoints near the minimum) and measure how T3S performance varies. This quantifies the method's robustness to bottleneck detection.

3. **Alternative trajectory signals**: Test whether other dynamic metrics (gradient norm evolution, attention entropy change, or KL divergence between checkpoints) can identify anchor tokens as effectively as confidence change. This validates whether the specific trajectory signal is essential or if the approach is more generally applicable to training dynamics.