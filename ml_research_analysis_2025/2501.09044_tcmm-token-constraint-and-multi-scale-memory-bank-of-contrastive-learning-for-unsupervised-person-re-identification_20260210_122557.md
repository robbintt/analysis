---
ver: rpa2
title: 'TCMM: Token Constraint and Multi-Scale Memory Bank of Contrastive Learning
  for Unsupervised Person Re-identification'
arxiv_id: '2501.09044'
source_url: https://arxiv.org/abs/2501.09044
tags:
- samples
- features
- memory
- learning
- contrastive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses unsupervised person re-identification by
  proposing the Token Constraint and Multi-scale Memory Bank (TCMM) method. The approach
  tackles two key challenges: patch noises in Vision Transformer (ViT) features and
  feature inconsistency in memory bank-based contrastive learning.'
---

# TCMM: Token Constraint and Multi-Scale Memory Bank of Contrastive Learning for Unsupervised Person Re-identification

## Quick Facts
- **arXiv ID**: 2501.09044
- **Source URL**: https://arxiv.org/abs/2501.09044
- **Reference count**: 40
- **Primary result**: State-of-the-art unsupervised Re-ID on Market-1501 (90.5% mAP, 96.0% Rank-1) and MSMT17 (52.0% mAP, 78.4% Rank-1)

## Executive Summary
This paper addresses unsupervised person re-identification by proposing the Token Constraint and Multi-scale Memory Bank (TCMM) method. The approach tackles two key challenges: patch noises in Vision Transformer (ViT) features and feature inconsistency in memory bank-based contrastive learning. TCMM introduces a ViT Token Constraint module to mitigate patch noise effects and a multi-scale memory bank that combines prototype-level and instance-level memory modules. The prototype memory addresses feature inconsistency using cluster prototypes, while the instance memory explores outlier sample value through anchor contrastive loss. Experimental results demonstrate state-of-the-art performance on Market-1501 and MSMT17 datasets, outperforming previous methods by significant margins.

## Method Summary
TCMM combines token-level constraints with multi-scale memory banks for unsupervised person Re-ID. The method first applies a ViT encoder to generate [CLS] and [PART] tokens, then uses Token Constraint to filter patch noises by selecting top similar tokens as positives and bottom tokens as negatives. The multi-scale memory bank consists of a prototype memory module (using cluster prototypes from DBSCAN) and an instance memory module (storing all training samples). The prototype memory addresses feature inconsistency through cluster-based contrastive learning, while the instance memory captures outlier information via anchor contrastive loss. The final loss combines three components: Token Constraint loss, Prototype Memory loss, and Instance Memory loss.

## Key Results
- Achieves 90.5% mAP and 96.0% Rank-1 on Market-1501, outperforming previous methods by significant margins
- Achieves 52.0% mAP and 78.4% Rank-1 on MSMT17
- Ablation studies show that combining Token Constraint with multi-scale memory banks provides substantial performance gains over individual components
- Performance is robust to moderate changes in patch noise rate (α) and memory bank parameters

## Why This Works (Mechanism)
The method works by addressing two fundamental challenges in unsupervised Re-ID: patch noise in ViT features and feature inconsistency in memory bank approaches. The Token Constraint module filters out noisy patches by leveraging the self-attention mechanism to identify and downweight irrelevant tokens. The multi-scale memory bank combines global cluster-level information (prototype memory) with local instance-level details (instance memory), allowing the model to benefit from both cluster consistency and outlier exploration. This dual approach ensures stable learning from clusters while maintaining sensitivity to diverse individual samples.

## Foundational Learning
- **Vision Transformer (ViT) token processing**: Understanding how ViT splits images into patches and generates token representations is crucial for implementing the Token Constraint module. Quick check: Verify that the ViT encoder outputs [CLS] and [PART] tokens with the correct dimensions.
- **Contrastive learning with memory banks**: The method builds on memory bank-based contrastive learning frameworks, requiring understanding of how positive and negative samples are selected and how temperature scaling affects the loss. Quick check: Confirm that the temperature parameter (τ=0.05) is correctly applied in the contrastive loss.
- **DBSCAN clustering for unsupervised learning**: The prototype memory relies on DBSCAN for generating pseudo-labels and cluster prototypes, necessitating understanding of density-based clustering parameters. Quick check: Monitor the number of clusters and outlier ratio produced by DBSCAN during training.
- **Multi-scale feature aggregation**: The method combines features at different scales (token, prototype, instance), requiring understanding of how to aggregate and normalize features across these levels. Quick check: Verify that feature normalization is consistent across all memory bank operations.

## Architecture Onboarding

**Component map**: Input images → ViT encoder → Token Constraint → Multi-scale Memory Bank (Prototype + Instance) → Contrastive Loss → Updated features

**Critical path**: The core pipeline processes input images through the ViT backbone, applies Token Constraint to filter patch noises, then feeds the cleaned features into the multi-scale memory bank for contrastive learning. The prototype memory provides stable cluster-level supervision while the instance memory captures individual sample variations.

**Design tradeoffs**: The method trades increased memory consumption (storing all instance features) for improved outlier exploration and feature consistency. The Token Constraint adds computational overhead but provides significant noise reduction benefits. The multi-scale approach requires careful balancing of loss weights and memory bank update strategies.

**Failure signatures**: 
- GPU OOM errors due to large batch size (512) and full instance memory bank storage
- Clustering collapse if DBSCAN parameters are inappropriate, leading to poor pseudo-labels
- Performance degradation if patch noise rate (α) is set too high or too low
- Training instability if loss weights are not properly balanced

**First experiments**:
1. Verify ViT backbone outputs correct token structure ([CLS] + 3 [PART] tokens, 768-dim each)
2. Test Token Constraint module with synthetic noisy data to validate noise filtering capability
3. Evaluate memory bank update frequency impact on training stability and final performance

## Open Questions the Paper Calls Out
- **Self-attention refinement**: How can the self-attention mechanism be further refined to intrinsically mitigate damage from patch and pseudo-label noises without relying on external loss constraints?
- **Patch noise rate transferability**: To what extent is the optimal patch noise rate (α=0.075) transferable to datasets with significantly different resolutions or occlusion patterns?
- **Scalability of instance memory**: Does the storage of all training samples in the instance-level memory bank create scalability bottlenecks when applied to video-based or web-scale re-identification datasets?

## Limitations
- **DBSCAN parameter specification**: The paper uses DBSCAN but does not specify critical parameters (eps, min_samples), making exact reproduction difficult
- **Memory scalability**: The instance memory bank stores all training samples, potentially creating scalability issues for larger datasets
- **Hyperparameter sensitivity**: Limited ablation studies on key hyperparameters like temperature, momentum, and patch noise rate reduce understanding of method robustness

## Confidence

| Claim | Confidence |
|-------|------------|
| Overall framework design and experimental methodology | High |
| Specific implementation details of Token Constraint and memory bank integration | Medium |
| Individual component performance contributions and hyperparameter sensitivity | Low |

## Next Checks

1. **Reproduce with Specified DBSCAN Parameters**: Test different DBSCAN parameter combinations (e.g., eps=0.5, min_samples=5) to determine their impact on clustering quality and final performance. Report the cluster/outlier ratios and final mAP/Rank-1 scores.

2. **Component Ablation Study**: Implement and evaluate each component separately (ViT only, ViT + Token Constraint, ViT + Prototype Memory, ViT + Instance Memory) to quantify individual contributions to the final performance.

3. **Scalability Analysis**: Evaluate the method's performance and memory usage on a larger dataset (e.g., PersonX) or with increased training epochs. Measure the memory consumption of the instance memory bank and assess whether the method scales linearly with dataset size.