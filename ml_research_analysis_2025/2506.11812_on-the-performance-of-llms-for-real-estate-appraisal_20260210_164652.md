---
ver: rpa2
title: On the Performance of LLMs for Real Estate Appraisal
arxiv_id: '2506.11812'
source_url: https://arxiv.org/abs/2506.11812
tags:
- llms
- price
- real
- estate
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper evaluates large language models (LLMs) for real estate\
  \ appraisal, focusing on their ability to predict house prices through in-context\
  \ learning. It systematically compares prompting strategies\u2014zero-shot, few-shot,\
  \ and hybrid approaches\u2014across diverse housing datasets in the US, Belgium,\
  \ Spain, and China."
---

# On the Performance of LLMs for Real Estate Appraisal

## Quick Facts
- arXiv ID: 2506.11812
- Source URL: https://arxiv.org/abs/2506.11812
- Reference count: 40
- Primary result: LLMs generate competitive house price estimates through in-context learning with geographically and hedonically similar examples, though they struggle with spatial reasoning and are overconfident in price intervals.

## Executive Summary
This paper evaluates large language models (LLMs) for real estate appraisal using in-context learning strategies. The study systematically compares zero-shot, few-shot, and hybrid prompting approaches across four diverse housing datasets in the US, Belgium, Spain, and China. Results show that GPT-4o-mini outperforms other models, with the "10 ex. mixed" strategy (combining geographic and hedonic examples) consistently delivering optimal performance. While LLMs approach traditional machine learning baselines in predictive accuracy, they demonstrate overconfidence in price intervals and undervalue location effects. The research highlights LLMs' potential to democratize real estate insights while identifying critical limitations requiring further investigation.

## Method Summary
The study evaluates LLMs for house price prediction through In-Context Learning without parameter updates. Four datasets (King County USA, Flanders Belgium, Barcelona Spain, Beijing China) are processed with 60:20:20 train-validation-test splits. Twelve prompting strategies are compared: zero-shot, few-shot with 3 or 10 examples, with/without market reports, and example selection via haversine/cosine/mixed distance. LLMs tested include Llama 3.2:3B, Llama 3.1:70B, and GPT-4o-mini with temperature=0. ML baselines include kNN (k=3,10) and LightGBM. Performance is measured via MAPE, percentage error std, prediction interval coverage/width, and feature importance alignment with SHAP values.

## Key Results
- GPT-4o-mini consistently outperforms larger models like Llama 3.1:70B in structured tabular tasks
- The "10 ex. mixed" strategy (5 geographic + 5 hedonic neighbors) provides optimal balance for example selection
- LLMs approach traditional ML baselines in predictive accuracy but demonstrate 20-35% higher MAPE on average
- LLM-generated prediction intervals cover only 25-65% of true prices (target: 90%), indicating severe overconfidence
- LLMs effectively leverage hedonic variables (size, rooms, amenities) but struggle with spatial and temporal reasoning

## Why This Works (Mechanism)

### Mechanism 1
In-Context Learning with similarity-based example retrieval approximates k-Nearest Neighbor interpolation with enhanced semantic understanding. The model retrieves K examples based on geographic proximity and hedonic similarity, then infers prices from observed neighbors in the prompt. This works because LLMs possess pre-trained world knowledge to understand property-value relationships without weight updates.

### Mechanism 2
LLMs prioritize hedonic features effectively because they align with semantic concepts in training data, but fail to weigh spatial coordinates correctly. Raw coordinates tokenize into meaningless numbers, and even reverse-geocoded addresses don't trigger strong location-value signals compared to Gradient Boosted Trees that explicitly model spatial interactions.

### Mechanism 3
Injecting external market reports acts as manual calibration for temporal trends, shifting the price baseline. Market reports provide explicit signals about price indices and trends, allowing LLMs to adjust internal valuation logic and compensate for inability to learn temporal trends from date strings alone.

## Foundational Learning

**In-Context Learning (ICL)**: LLMs perform regression via prompt examples rather than gradient descent. Quick check: How does the model adjust if you swap "geographically similar" examples for "hedonically similar" ones?

**Automated Valuation Models (AVMs) & Hedonic Regression**: The paper benchmarks against traditional ML and compares feature importance using SHAP. Quick check: If an LLM ignores spatial coordinates but weighs "square footage" heavily, does it align with a GBT model trained without location data?

**Uncertainty Quantification (Conformal Prediction)**: The paper identifies "overconfidence" as a key failure mode. Quick check: Why is a narrow prediction interval with low coverage more dangerous than a wide interval with high coverage in real estate?

## Architecture Onboarding

**Component map**: Data Serializer → Retriever → Context Injector → Inference Engine → Evaluator

**Critical path**: Data Serializer → Retriever link is critical. If reverse geocoding fails or the retriever selects outliers, LLM reasoning degrades.

**Design tradeoffs**: Accessibility vs. Accuracy (LLMs are out-of-the-box accessible but underperform SOTA GBT models by 20-35% MAPE). Interpretability vs. Reliability (LLMs provide natural language explanations aligned with SHAP values but have unreliable confidence intervals).

**Failure signatures**: The Beijing Anomaly (MAPE > 0.40 due to complex spatial/temporal dynamics). Interval Collapse (10-50% coverage vs. 90% target).

**First 3 experiments**: 1) Baseline Serialization: Run zero-shot vs. few-shot on small subset. 2) Retrieval Ablation: Compare "Geo-only" vs. "Hedonic-only" vs. "Mixed" strategies. 3) Interval Calibration: Force model to generate intervals and measure coverage.

## Open Questions the Paper Calls Out

**Open Question 1**: Can alternative geographic encoding strategies overcome LLMs' limited spatial reasoning and tokenization issues with coordinates? Evidence needed: Study comparing encoding methods showing increased alignment with spatial feature importance.

**Open Question 2**: To what extent do advanced prompting techniques like Chain-of-Thought or Retrieval-Augmented Generation improve accuracy and robustness? Evidence needed: Benchmarking CoT or RAG performance on same datasets to bridge accuracy gap with traditional ML.

**Open Question 3**: Can iterative prompting or external calibration methods resolve LLM overconfidence in price intervals? Evidence needed: Demonstrating user-friendly method achieving 90% coverage comparable to conformal prediction baselines.

## Limitations

- Proprietary Flanders dataset limits reproducibility and requires author contact or dataset substitution
- Performance gap of 20-35% higher MAPE compared to traditional ML models indicates LLMs are not ready to replace established methods
- Geographic overfitting risk where few-shot examples perform poorly when transferred to different markets

## Confidence

**High Confidence**: LLM performance on hedonic features aligns with traditional SHAP analysis; GPT-4o-mini outperforms larger models in tabular tasks.

**Medium Confidence**: "10 ex. mixed" strategy provides optimal balance; market reports improve zero-shot performance with precise temporal granularity.

**Low Confidence**: LLM intervals can be calibrated to achieve 90% coverage uniformly across all datasets and conditions.

## Next Checks

1. **Interval Coverage Validation**: Measure actual coverage percentage of LLM-generated intervals against 90% target to verify overconfidence (expected 25-65% coverage).

2. **Geographic Transfer Test**: Evaluate model trained with US examples on Barcelona dataset (and vice versa) to quantify geographic overfitting risk.

3. **Feature Importance Comparison**: Compute SHAP values for both LLM predictions and LightGBM baseline on same validation set to verify alignment on hedonic features while LLM underweights spatial coordinates.