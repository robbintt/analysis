---
ver: rpa2
title: 'BadViM: Backdoor Attack against Vision Mamba'
arxiv_id: '2507.00577'
source_url: https://arxiv.org/abs/2507.00577
tags:
- state
- backdoor
- vision
- attack
- badvim
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BadViM is the first backdoor attack framework designed specifically
  for Vision Mamba architectures. It exploits the centralized hidden state vulnerability
  through Resonant Frequency Triggers (RFT) and Hidden State Alignment.
---

# BadViM: Backdoor Attack against Vision Mamba

## Quick Facts
- **arXiv ID**: 2507.00577
- **Source URL**: https://arxiv.org/abs/2507.00577
- **Authors**: Yinghao Wu; Liyan Zhang
- **Reference count**: 21
- **Primary result**: First backdoor attack framework specifically targeting Vision Mamba architectures

## Executive Summary
BadViM introduces the first backdoor attack framework designed specifically for Vision Mamba (ViM) architectures. The attack exploits a fundamental architectural vulnerability in ViM's centralized hidden state representation through two novel mechanisms: Resonant Frequency Triggers (RFT) and Hidden State Alignment. By identifying model-specific resonant frequencies and aligning poisoned inputs' hidden states with target class centroids, BadViM achieves near-perfect attack success rates above 99.8% on CIFAR-10 and ImageNet-1K while maintaining minimal clean data accuracy degradation. The attack demonstrates exceptional robustness against common defenses including PatchDrop, PatchShuffle, and JPEG compression.

## Method Summary
BadViM exploits Vision Mamba's centralized hidden state vulnerability through a two-phase approach. First, it performs frequency-domain sensitivity analysis to identify model-specific resonant frequencies that evade the model's memory attenuation mechanisms. Second, it generates distributed frequency-domain triggers and employs a composite loss function that aligns poisoned inputs' final hidden states with target class manifolds. The method combines traditional cross-entropy loss on clean data with a hidden state alignment loss that forces the entire recurrent accumulation process to converge to specific points in feature space. This architectural attack achieves superior performance compared to traditional patch-based backdoor attacks by leveraging the centralized nature of ViM's hidden state representation.

## Key Results
- Achieves attack success rates above 99.8% on CIFAR-10 and ImageNet-1K
- Maintains minimal clean data accuracy degradation (CDA loss negligible)
- Demonstrates exceptional robustness against PatchDrop, PatchShuffle, and JPEG compression defenses
- Outperforms existing backdoor attacks on Vision Mamba models

## Why This Works (Mechanism)

### Mechanism 1: Persistent Signal Injection via Resonant Frequency Triggers
- Distributed frequency-domain triggers evade ViM's memory attenuation by continuously re-injecting malicious signals at every token position
- Core assumption: Forget gate mechanism cannot attenuate signals continuously present in every input token
- Break condition: If perturbations are localized or incorrect frequency bands are identified

### Mechanism 2: Direct Hidden State Manipulation
- Aligning poisoned inputs' final hidden states with target class centroids achieves higher attack success than output-label-only supervision
- Core assumption: Final hidden state h(N) is the single bottleneck controlling model predictions
- Break condition: If target class manifold is not well-clustered (high intra-class variance)

### Mechanism 3: Centralized Vulnerability Exploitation
- ViM's architectural shift from distributed attention to centralized hidden state creates a concentrated attack surface
- Core assumption: Centralized representations are inherently more fragile than distributed ones when vulnerabilities are identified
- Break condition: If model architecture includes multiple parallel hidden states or checkpoint-style state retention

## Foundational Learning

- **Concept: Selective State Space Models (S6)**
  - Why needed here: Understanding how h(i) = eA(i) ⊙ h(i-1) + B(i)(∆(i) ⊙ x(i)) differs from attention is essential to grasp why traditional patch attacks fail and frequency attacks succeed
  - Quick check question: Can you explain why a forget gate (eA(i)) attenuates isolated signals but not continuously-present distributed signals?

- **Concept: Frequency-Domain Sensitivity Analysis**
  - Why needed here: The RFT construction requires understanding how to measure S(u,v) via perturbation-based gradient estimation and why resonant frequencies differ from arbitrary high-frequency bands
  - Quick check question: Why would a model's resonant frequencies survive JPEG compression better than random frequency perturbations?

- **Concept: Backdoor Attack Taxonomy (Clean-label vs. Poison-control)**
  - Why needed here: BadViM assumes training-control capabilities; distinguishing this threat model from inference-time or clean-label attacks clarifies applicability boundaries
  - Quick check question: What capabilities does the attacker need for BadViM that they wouldn't need for a patch-based backdoor on ViT?

## Architecture Onboarding

- **Component map**: Input Image → [Frequency Sensitivity Analyzer] → S(u,v) heatmap → [Resonant Trigger Generator] → δ (spatial trigger) → Clean Image + δ → Poisoned Image → [ViM Backbone] → h(N) (final hidden state) → [Composite Loss] = L_CCE(clean) + λ · L_alignment(poisoned, ht)

- **Critical path**: Frequency sensitivity analysis must identify bands where model predictions meaningfully change. If sensitivity heatmap is flat (no resonant frequencies), trigger generation fails. Hidden state alignment requires stable target centroids; compute ht using running averages across training batches, not single-batch estimates.

- **Design tradeoffs**:
  - k% frequency selection (Eq. 3): Lower k → stealthier but weaker trigger; higher k → stronger but more detectable
  - λ weighting: Controls alignment vs. classification loss balance. Too high → clean accuracy degrades; too low → ASR drops
  - Poisoning rate: Paper uses 10%; lower rates require stronger triggers or more alignment iterations

- **Failure signatures**:
  - ASR <90% with CDA maintained: Likely insufficient trigger magnitude (ϵ too small) or wrong frequency bands
  - CDA drops >2%: λ too high or trigger too aggressive; reduce perturbation magnitude
  - PatchDrop defense succeeds: Trigger not sufficiently distributed; verify trigger is present across all patches

- **First 3 experiments**:
  1. Baseline frequency sensitivity validation: Compute S(u,v) heatmap on pretrained ViM-Tiny using ImageNet validation set (100 images)
  2. Single-component ablation: Run BadViM with RFT only (no alignment loss) and alignment only (random trigger)
  3. Defense robustness sanity check: Apply JPEG compression (quality=75) to poisoned samples before inference

## Open Questions the Paper Calls Out
None

## Limitations
- No ablation studies test whether resonant frequencies identified on ImageNet generalize to CIFAR-10 or different ViM model variants
- Defense robustness evaluation lacks depth; doesn't characterize failure modes or explain why distributed frequency triggers resist specific interventions
- All experiments use ViM-Tiny and ViM-Small architectures; scalability to larger models unaddressed
- No detailed analysis of whether CDA degradation is uniform across classes or concentrated in specific categories

## Confidence

**High Confidence (90-100%)**:
- BadViM successfully achieves >99.8% attack success rate on ViM architectures
- Distributed trigger mechanism outperforms traditional patch-based attacks on Vision Mamba
- BadViM demonstrates superior robustness to JPEG compression compared to existing backdoor attacks

**Medium Confidence (60-89%)**:
- Architectural vulnerability of centralized hidden states in Vision Mamba is accurately characterized
- Hidden State Alignment loss meaningfully contributes to attack effectiveness beyond trigger injection alone
- Resonant frequency triggers provide inherent defense resistance compared to spatial triggers

**Low Confidence (0-59%)**:
- Generalization of resonant frequency identification across different ViM model variants and datasets
- Scalability of BadViM to larger ViM architectures (ViM-Base/Large)
- Long-term stability of identified resonant frequencies across model retraining cycles

## Next Checks

**Check 1: Cross-Dataset Frequency Stability**
Compute S(u,v) sensitivity heatmaps for ViM-Tiny on both CIFAR-10 and ImageNet-1K validation sets (minimum 100 images each). Calculate correlation coefficient between frequency sensitivity distributions across datasets. If correlation <0.7, investigate whether frequency sensitivity is dataset-specific rather than model-specific.

**Check 2: Ablation of Hidden State Alignment Component**
Run controlled experiments with three variants: (1) RFT only, (2) Random trigger with alignment loss, (3) BadViM full pipeline. Compare ASR improvements between variants. If alignment-only variant achieves >95% ASR, the primary attack mechanism may be simpler than claimed.

**Check 3: Defense Mechanism Robustness Analysis**
Apply JPEG compression at multiple quality levels (25, 50, 75, 90) to poisoned inputs. Measure ASR degradation at each level and identify which frequency bands survive compression. Additionally, test whether adversarial training on compressed versions can reduce attack effectiveness by >20%. This validates whether resonant frequencies provide genuine robustness or simply exploit JPEG compression implementation details.