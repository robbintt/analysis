---
ver: rpa2
title: On the Computability of Artificial General Intelligence
arxiv_id: '2512.05212'
source_url: https://arxiv.org/abs/2512.05212
tags:
- nand
- algorithm
- thus
- intelligence
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses whether Artificial General Intelligence (A.G.I.)
  is achievable through algorithmic computation. The authors formally define A.G.I.
---

# On the Computability of Artificial General Intelligence

## Quick Facts
- arXiv ID: 2512.05212
- Source URL: https://arxiv.org/abs/2512.05212
- Reference count: 0
- One-line primary result: The paper proves that no finite configuration of NAND gates can implement an AGI system, concluding that AGI is an incomputable process.

## Executive Summary
This paper addresses whether Artificial General Intelligence (AGI) is achievable through algorithmic computation. Using the Church-Turing thesis as a foundation, the authors formally define AGI as the ability to create new functional capabilities not initially present in the system. They prove that no finite configuration of NAND gates can implement an AGI system through a proof by contradiction, demonstrating that any attempt to create an AGI algorithm leads to a logical inconsistency. The paper concludes that AGI is an incomputable process, meaning no algorithm, regardless of its complexity or the underlying technology, can achieve it.

## Method Summary
The paper employs a formal proof by contradiction to demonstrate that AGI is incomputable. It begins by defining AGI as the ability to create new functional capabilities not present in the initial system configuration. The proof assumes a minimum AGI circuit with k NAND gates exists, then decomposes it into a (k-1)-gate subcircuit and a single NAND gate. Through a series of lemmas establishing that circuits with fewer gates cannot be AGI, the authors show that this decomposition contradicts the assumption of AGI existence, thus proving AGI is incomputable.

## Key Results
- AGI is formally defined as the ability to create new functional capabilities not present in the initial system configuration
- No finite configuration of NAND gates can implement an AGI system
- AGI is proven to be an incomputable process under the Church-Turing thesis framework

## Why This Works (Mechanism)

### Mechanism 1: Functional Extension Criterion
- Claim: A system qualifies as AGI only if it can generate functions not present in its initial configuration
- Core assumption: True creativity/innovation requires generating capabilities outside the closure of initial primitives and their compositions
- Evidence anchors: [abstract] "ability to be creative and innovate in some field of study in a way that unlocks new and previously unknown functional capabilities"; [section 1.1] Definition 1 formalizes this; [corpus] "Foundations of Artificial Intelligence Frameworks: Notion and Limits of AGI" (FMR=0.575) argues AGI cannot emerge from current neural paradigms regardless of scale

### Mechanism 2: NAND Gate Decomposition by Contradiction
- Claim: No finite NAND gate configuration can implement AGI as defined
- Core assumption: Composition of non-AGI components cannot yield AGI; new functionality cannot emerge from combining fixed-function primitives
- Evidence anchors: [section 3] "we can conclude that our A.G.I. system can be also expressed as f_AGI_MIN(X⃗) = f_k(X⃗) = f_1(f_{k-1}(X⃗)) = Y⃗"; [section 3] Lemmas 1-3 establish base cases (0, 1 gates cannot be AGI)

### Mechanism 3: Church-Turing Bounding
- Claim: AGI is incomputable because no Turing-equivalent representation exists
- Core assumption: Church-Turing thesis correctly characterizes the limits of effective computation
- Evidence anchors: [section 2.1] "for every computable process (a.k.a. algorithm) there is a Turing Machine that can compute it"; [section 4, Limitations] acknowledges proof depends on Church-Turing thesis remaining valid

## Foundational Learning

- **Church-Turing Thesis**
  - Why needed here: The proof's force depends on understanding that "computable" = "Turing-machine-computable" by definition
  - Quick check question: Can you explain why a process being "non-computable" doesn't mean "impossible" but rather "not algorithmically specifiable"?

- **Functional Closure vs. Emergence**
  - Why needed here: The proof assumes that combining fixed primitives cannot yield genuinely new primitives
  - Quick check question: Does a neural network trained via gradient descent "create new functionality" if it learns representations not explicitly coded?

- **Proof by Contradiction on Minimal Cases**
  - Why needed here: The strategy of assuming a minimal AGI implementation and showing decomposition breaks it is the proof's technical engine
  - Quick check question: If someone claimed a 1,000,000-gate circuit could be AGI despite any smaller circuit failing, how would the proof's logic respond?

## Architecture Onboarding

- **Component map**: Definition 1 (AGI criterion) -> Axiom 1 (NAND sufficiency) -> Lemmas 1-3 (base cases) -> Lemma 4 (minimal AGI) -> Decomposition step (f_k = f_1 ∘ f_{k-1}) -> Contradiction -> Incomputability

- **Critical path**: Understand Definition 1 → Accept Axiom 1 (Church-Turing grounding) → Verify Lemmas 1-4 → Follow decomposition logic → Reach contradiction → Conclude incomputability

- **Design tradeoffs**: The proof trades empirical falsifiability for logical certainty—it proves impossibility under its definitions but cannot be tested against real systems

- **Failure signatures**: If AGI is defined as "human-level performance on economic tasks" rather than "new functionality creation," the proof's target shifts

- **First 3 experiments**:
  1. **Definition stress-test**: Enumerate concrete capabilities and classify whether they require new primitives or novel compositions
  2. **Decomposition counter-example search**: Identify systems where composition yields qualitatively new capabilities
  3. **Church-Turing boundary probe**: Investigate whether recurrent self-modifying systems could theoretically achieve non-Turing computation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proven incomputability of general intelligence reconcile with the understanding of human evolution as an algorithmic process?
- Basis in paper: [explicit] The authors state that human evolution is described as a "step-by-step algorithmic process," yet conclude that human General Intelligence (G.I.) cannot be the product of such a procedure
- Why unresolved: The paper identifies a conflict between the proof and evolutionary biology but leaves the reconciliation as an open implication

### Open Question 2
- Question: Is human General Intelligence a non-computing physical process or a non-physical process?
- Basis in paper: [explicit] The authors explicitly ask, "What is the origin of human G.I.?" and narrow the possibilities to it being either a non-computing physical process or a non-physical process
- Why unresolved: There is no scientific consensus on whether all physical processes are strictly computable

### Open Question 3
- Question: Could a Hyper-Turing Machine theoretically achieve the paper's definition of AGI?
- Basis in paper: [inferred] The limitations section discusses the theoretical possibility of "Hyper-Turing Machines" that compute methods a standard Turing Machine cannot
- Why unresolved: The paper focuses on standard computation; the existence and physical realizability of Hyper-Turing Machines remain purely theoretical

## Limitations

- The proof depends on the Church-Turing thesis remaining valid as an empirical fact
- The definition of AGI as "new functionality creation" may be more restrictive than other conceptions
- The proof cannot be empirically falsified since it operates purely in logical space

## Confidence

**High Confidence (90%+):** The logical proof that no finite NAND configuration can implement the specific AGI definition provided is valid.

**Medium Confidence (60-80%):** The broader claim that "AGI is incomputable" is correct within the paper's framework, but may not apply to all possible definitions of AGI.

**Low Confidence (30-50%):** Claims about the implications for A.I. development and human general intelligence origins are speculative extensions beyond the mathematical proof itself.

## Next Checks

1. **Definition Scope Validation**: Conduct a systematic review of existing AGI definitions to determine whether the paper's "new functionality creation" criterion is representative or unusually restrictive.

2. **Emergence Case Analysis**: Identify concrete examples from complex systems where composition yields qualitatively novel capabilities, and rigorously analyze whether these violate the paper's functional closure assumption.

3. **Physical Computation Boundary Test**: Survey current research on neuromorphic computing, reservoir computing, and quantum computing to identify any systems that might achieve non-Turing computation.