---
ver: rpa2
title: Partial Domain Adaptation via Importance Sampling-based Shift Correction
arxiv_id: '2507.20191'
source_url: https://arxiv.org/abs/2507.20191
tags:
- domain
- source
- sampling
- target
- distribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses partial domain adaptation (PDA), a scenario
  where the source domain has more classes than the target domain. Previous methods
  rely on reweighing source samples to correct label distribution shift, but this
  approach cannot sufficiently explore the latent structure and may lead to overfitting.
---

# Partial Domain Adaptation via Importance Sampling-based Shift Correction

## Quick Facts
- arXiv ID: 2507.20191
- Source URL: https://arxiv.org/abs/2507.20191
- Authors: Cheng-Jun Guo; Chuan-Xian Ren; You-Wei Luo; Xiao-Lin Xu; Hong Yan
- Reference count: 40
- Best baseline accuracy: 78.3% (Office-Home), 88.7% (VisDA-2017)

## Executive Summary
This paper addresses partial domain adaptation (PDA), where the source domain has more classes than the target domain. Previous methods rely on reweighing source samples to correct label distribution shift, but this approach cannot sufficiently explore the latent structure and may lead to overfitting. The authors propose a novel importance sampling-based shift correction (IS2C) method that builds a sampling domain whose label distribution matches the target, and samples new labeled data from this domain to train the model. This approach explicitly aligns class-conditional distributions between source and target domains.

## Method Summary
The proposed IS2C method addresses partial domain adaptation by constructing an auxiliary sampling domain whose label distribution matches the target domain. The method first estimates the target label distribution using pseudo-labels on target samples, then builds a sampling domain by importance weighting source samples based on this estimated distribution. New labeled data is sampled from this domain to train the model, effectively aligning class-conditional distributions between source and target domains. The approach provides theoretical guarantees for generalization error bounds and demonstrates superior performance on standard PDA benchmarks.

## Key Results
- Achieves 79.2% accuracy on Office-Home compared to 78.3% for best baseline
- Achieves 89.3% accuracy on VisDA-2017 compared to 88.7% for best baseline
- Effectively reduces class-conditional discrepancy between source and target domains
- Provides theoretical guarantees for generalization error bounds

## Why This Works (Mechanism)
The IS2C method works by explicitly aligning the label distributions between source and target domains through importance sampling. By constructing a sampling domain that matches the target's label distribution, the method ensures that the model learns features that are discriminative across all target classes while maintaining source supervision. This approach overcomes the limitations of simple reweighting methods by exploring the latent structure of the data and providing a more robust way to handle distribution shift.

## Foundational Learning
- Partial Domain Adaptation: A domain adaptation scenario where source has more classes than target. Why needed: To handle real-world scenarios where labeled source data contains more categories than target data. Quick check: Verify class count difference between domains.
- Importance Sampling: A technique for estimating properties of a particular distribution while only having samples generated from a different distribution. Why needed: To correct label distribution shift between domains. Quick check: Confirm sampling weights sum to 1.
- Domain Discrepancy: The difference between source and target domain distributions. Why needed: To measure adaptation effectiveness. Quick check: Compute MMD or other discrepancy metrics.
- Generalization Error: The difference between expected error on unseen data versus training data. Why needed: To evaluate model's ability to generalize. Quick check: Compare training vs validation performance.
- Pseudo-labeling: Assigning labels to unlabeled data based on model predictions. Why needed: To estimate target label distribution. Quick check: Verify pseudo-label confidence scores.

## Architecture Onboarding

Component Map: Source Domain -> Importance Weighting -> Sampling Domain -> Training Model -> Target Domain

Critical Path: The method constructs an auxiliary sampling domain through importance weighting, then samples new labeled data from this domain to train the model. This creates a feedback loop where the model learns from data that matches the target distribution while maintaining source supervision.

Design Tradeoffs: The approach trades computational complexity for improved alignment between domains. Building and sampling from the auxiliary domain adds overhead but provides more robust adaptation than simple reweighting. The method also requires careful tuning of the importance sampling weights to balance source and target distributions.

Failure Signatures: The method may fail when the source domain contains significant noise or outliers that don't align with target classes. Performance can degrade if the estimated target label distribution is inaccurate or if the class-conditional distributions are too dissimilar between domains.

First Experiments:
1. Test on synthetic PDA dataset with known class distribution shift to validate method's effectiveness
2. Compare IS2C performance with different pseudo-labeling confidence thresholds
3. Evaluate sensitivity to importance sampling weight parameters on validation set

## Open Questions the Paper Calls Out
None

## Limitations
- Assumes source domain contains all target classes and can capture distribution shift through sampling
- Computational overhead of building and sampling from auxiliary domain may be prohibitive for large-scale applications
- Theoretical guarantees assume ideal conditions that may not hold in practical scenarios
- Limited exploration of hyperparameter sensitivity and robustness to noisy labels

## Confidence

High confidence in the method's ability to reduce class-conditional discrepancy between domains
Medium confidence in the generalization of theoretical guarantees to real-world scenarios
Medium confidence in the scalability of the approach to larger datasets and more complex domain shifts

## Next Checks

1. Evaluate IS2C's performance on more challenging domain adaptation scenarios where source and target domains have significant structural differences beyond label distribution shift
2. Conduct ablation studies to determine the impact of each component in the IS2C framework and identify potential bottlenecks
3. Test the method's robustness to noisy labels and outliers in the source domain to assess its practical applicability in real-world settings