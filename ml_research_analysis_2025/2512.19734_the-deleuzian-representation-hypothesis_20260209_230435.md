---
ver: rpa2
title: The Deleuzian Representation Hypothesis
arxiv_id: '2512.19734'
source_url: https://arxiv.org/abs/2512.19734
tags:
- concepts
- concept
- activations
- sparse
- extracted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an unsupervised method for extracting interpretable
  concepts from neural network activations by modeling concepts as differences between
  activations. The approach clusters pairwise activation differences using feature-weighted
  KMeans, with weights inversely proportional to skewness to promote diversity.
---

# The Deleuzian Representation Hypothesis

## Quick Facts
- arXiv ID: 2512.19734
- Source URL: https://arxiv.org/abs/2512.19734
- Reference count: 40
- Method extracts interpretable concepts from neural networks by modeling them as differences between activations, outperforming SAE variants on 13 of 20 tasks

## Executive Summary
This paper introduces an unsupervised approach to concept extraction in neural networks that fundamentally reframes concepts as differences between activation patterns rather than universal categories. By clustering pairwise activation differences with feature-weighted KMeans, the method produces interpretable concepts that demonstrate causal influence on model behavior and achieve lossless steering. The approach requires only a single hyperparameter and scales linearly with dataset size, showing strong performance across vision, language, and audio modalities.

## Method Summary
The method extracts concepts by clustering pairwise differences between neural activation vectors using feature-weighted KMeans, where weights are inversely proportional to feature skewness to promote diversity. Concepts are defined as centroids of these clusters, representing interpretable directions in activation space. The approach leverages discriminant analysis principles to identify directions that maximize separation between examples, and enables lossless steering of model behavior through projection onto the concept basis. It operates unsupervised, requiring only the number of concepts as a hyperparameter, and scales linearly with dataset size.

## Key Results
- Outperforms prior unsupervised SAE variants on probe loss across 13 of 20 tasks
- Approaches supervised baseline performance while requiring no labels
- Demonstrates lossless steering capability, proving causal influence on downstream predictions
- Shows high consistency across runs (MPPC metric) and scales linearly with dataset size

## Why This Works (Mechanism)
The method works by reframing concepts as differences rather than universals, capturing the relational nature of meaning in neural representations. By clustering activation differences, it identifies directions in activation space that consistently separate examples, effectively discovering the dimensions along which the model distinguishes between concepts. The feature-weighting scheme using inverse skewness ensures diverse concept extraction by down-weighting features that vary little across examples, while the discriminant analysis foundation ensures extracted directions are maximally informative for separating classes.

## Foundational Learning
- **Discriminant Analysis**: Needed to identify directions that maximize class separation; quick check: verify that extracted concepts align with known class boundaries in supervised settings
- **Skewness-based Feature Weighting**: Needed to promote diversity by down-weighting features with little variation; quick check: compare concept diversity with and without this weighting
- **KMeans Clustering**: Needed to group similar activation differences into coherent concepts; quick check: test stability of clusters across multiple runs
- **Activation Difference Modeling**: Needed to capture relational aspects of concepts; quick check: verify that concepts capture semantic differences between examples

## Architecture Onboarding

Component Map: Dataset -> Activation Extraction -> Pairwise Difference Calculation -> Feature Weighting -> KMeans Clustering -> Concept Extraction

Critical Path: Activation extraction and pairwise difference calculation form the computational bottleneck, as they require O(nÂ²) comparisons for n examples. The feature weighting step is critical for ensuring concept diversity and interpretability.

Design Tradeoffs: The method trades computational efficiency (quadratic scaling with dataset size) for unsupervised operation and interpretability. The single hyperparameter design simplifies usage but may limit fine-tuning for specific tasks.

Failure Signatures: Poor performance on tasks where concepts are highly task-specific and cannot be captured by activation differences alone. Failure to extract diverse concepts when features exhibit low skewness across the dataset.

First Experiments:
1. Run concept extraction on a small, interpretable dataset (e.g., MNIST) to visually verify concept quality
2. Compare concept diversity with and without the skewness-based feature weighting
3. Test lossless steering capability on a simple classification task to verify causal influence

## Open Questions the Paper Calls Out
None

## Limitations
- Uncertainty about whether activation differences truly capture human-interpretable concepts versus mathematical artifacts
- Performance gap relative to supervised methods on certain tasks (7 of 20)
- Potential suppression of relevant concepts that naturally exhibit skewed distributions through the feature-weighting scheme

## Confidence
- **High confidence**: Lossless steering experiments demonstrating causal influence; linear scaling properties and computational efficiency
- **Medium confidence**: Comparative performance against SAE variants; qualitative interpretability of extracted concepts
- **Low confidence**: Philosophical alignment with Deleuze's framework providing genuine interpretive value

## Next Checks
1. Conduct ablation studies removing the skewness-based feature weighting to determine its actual contribution to performance versus diversity
2. Perform human evaluation studies where annotators assess whether extracted concepts align with their semantic expectations across different domains
3. Test the method on models with known failure modes (e.g., bias amplification) to verify whether concept extraction can identify problematic representations