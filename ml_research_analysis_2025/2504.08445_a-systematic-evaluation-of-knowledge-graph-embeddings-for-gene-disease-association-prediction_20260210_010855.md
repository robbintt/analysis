---
ver: rpa2
title: A Systematic Evaluation of Knowledge Graph Embeddings for Gene-Disease Association
  Prediction
arxiv_id: '2504.08445'
source_url: https://arxiv.org/abs/2504.08445
tags:
- prediction
- methods
- link
- node-pair
- diseases
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a systematic framework comparing link prediction
  and node-pair classification tasks for gene-disease association prediction using
  knowledge graph embeddings. The framework integrates biomedical ontologies, logical
  definitions, and ontology mappings to create enriched knowledge graphs.
---

# A Systematic Evaluation of Knowledge Graph Embeddings for Gene-Disease Association Prediction

## Quick Facts
- **arXiv ID:** 2504.08445
- **Source URL:** https://arxiv.org/abs/2504.08445
- **Reference count:** 40
- **Primary result:** Link prediction methods outperform node-pair classification for gene-disease association prediction, with semantic matching models excelling at predicting diseases from genes and translational models better for predicting genes from diseases.

## Executive Summary
This study systematically compares link prediction and node-pair classification tasks for gene-disease association prediction using knowledge graph embeddings. The framework integrates biomedical ontologies (Gene Ontology, Human Phenotype Ontology, Human Disease Ontology) with logical definitions and ontology mappings to create enriched knowledge graphs. Results demonstrate that link prediction methods outperform node-pair classification across all metrics, with semantic matching models (HolE/ComplEx) excelling at predicting diseases from genes, while translational distance models (TransE) are superior for predicting genes from diseases. The study also shows that additional links between ontologies significantly improve method performance compared to disease-specific ontologies alone.

## Method Summary
The framework uses 16,378 gene-disease pairs from DisGeNET with a 70/30 train-test split. Link prediction employs OpenKE with six embedding models (TransE/TransD/TransH/DistMult/HolE/ComplEx) at 200 dimensions for 100 epochs. Node-pair classification uses PyRDF2Vec for embeddings with Hadamard aggregation and XGBoost classifiers. Ten knowledge graph variants are constructed using RDFLib, integrating ontologies with annotations, logical definitions (350), and mappings (494). Performance is evaluated using Hits@1, Hits@3, and Hits@10 metrics for both prediction directions.

## Key Results
- Link prediction methods achieve significantly higher Hits@k scores than node-pair classification
- Semantic matching models (HolE/ComplEx) excel at predicting diseases from genes
- Translational distance models (TransE) are superior for predicting genes from diseases
- Knowledge graphs with additional links between ontologies show improved performance compared to disease-specific ontologies alone

## Why This Works (Mechanism)

### Mechanism 1
Link prediction outperforms node-pair classification because it directly leverages the graph's topology during embedding training, whereas NPC isolates association edges as classification labels. In LP, gene-disease associations are treated as edges within the KG, allowing the embedding model to traverse these connections to learn entity proximity. In NPC, these associations are removed from the graph structure and used only as labels, forcing the model to rely on synthetic negative samples which may introduce bias or noise.

### Mechanism 2
Connecting disparate ontologies via logical definitions and mappings significantly boosts predictive accuracy more than adding a domain-specific ontology alone. Logical definitions and mappings create explicit "semantic bridges" between Gene Ontology and Human Phenotype Ontology, reducing path length between biological entities and phenotypes, allowing embedding models to propagate relevance signals more effectively across previously siloed sub-graphs.

### Mechanism 3
Predictive efficacy is direction-dependent; semantic matching models excel at predicting diseases from genes, while translational distance models excel at predicting genes from diseases. This reflects the biological reality of the task difficulty—predicting a disease from a gene (1-to-many, polygenic) benefits from the complex correlation patterns captured by semantic matching, while predicting a gene from a disease (many-to-1) benefits from the translation-based properties of models like TransE.

## Foundational Learning

- **Concept:** Knowledge Graph Embeddings (Translational vs. Semantic)
  - **Why needed here:** You must understand that TransE models relations as vector translations (h + r ≈ t), whereas HolE/ComplEx use dot products or circular correlation. The paper hinges on how these different mathematical assumptions fit different biological questions.
  - **Quick check question:** Can you explain why a translational model might fail to model a symmetric relationship compared to a semantic matching model?

- **Concept:** Negative Sampling Bias
  - **Why needed here:** The paper identifies negative sampling as a key failure mode for Node-Pair Classification. You need to understand that randomly sampling non-associated pairs as "negatives" can accidentally label unknown true associations as false, confusing the model.
  - **Quick check question:** In a gene-disease graph with 10,000 genes and 1,000 diseases, why is "random sampling" for negative training examples risky?

- **Concept:** Ontological Interoperability (Mappings/LDs)
  - **Why needed here:** The performance boost comes from connecting GO and HP. You need to grasp that these are distinct "vocabularies" and that logical definitions (e.g., 'has_part') allow a machine to reason across them.
  - **Quick check question:** If you merge two ontologies without logical definitions or mappings, how does the random walk algorithm behave compared to a graph with explicit cross-ontology links?

## Architecture Onboarding

- **Component map:** DisGeNET -> RDFLib (merge ontologies + annotations + LDs/Mappings) -> OpenKE/PyRDF2Vec -> Scoring Functions/Scikit-Learn Classifiers -> Custom Rank-based Hits@k calculator

- **Critical path:** Data Splitting -> KG Construction (Crucial Step: inject Logical Definitions here) -> Training Embeddings (100 epochs) -> **Fork:** (A) Calculate Scores & Rank (LP) OR (B) Hadamard Product + Train XGBoost (NPC)

- **Design tradeoffs:**
  - **LP (Link Prediction):** Higher Hits@k and ranking accuracy; harder to interpret why a specific rank was assigned; requires negative sampling *during* training (in-batch).
  - **NPC (Node-Pair Classification):** Lower ranking power; guarantees ranking of *all* test entities (even low probability ones); requires explicit negative sampling *before* training; more complex pipeline (Embed -> Combine -> Classify).

- **Failure signatures:**
  - **Performance Plateau:** If Hits@1 is low (~0.3-0.4), check if Logical Definitions (LDs) were actually loaded into the RDFLib graph.
  - **Recall Collapse (NPC):** If NPC misses known positives, check the negative sampling strategy. Random sampling likely introduced false negatives.
  - **Directional Imbalance:** If Gene->Disease works but Disease->Gene fails (or vice versa), check if you are using the correct model type (HolE vs TransE) for the specific prediction direction.

- **First 3 experiments:**
  1. **Sanity Check (LP vs NPC):** Run the "G+H" (Gene Ontology + Human Phenotype) graph on both TransE (LP) and RDF2Vec+XGBoost (NPC). Verify that LP yields higher Hits@10 as per the paper's baseline.
  2. **Semantic Ablation:** Run the best LP model (HolE) on "G+H" vs "G+H+L+M" (with Logical Definitions and Mappings). Quantify the lift provided solely by the semantic links.
  3. **Directional Stress Test:** Train TransE and HolE. Measure Hits@1 for both (Gene->Disease) and (Disease->Gene). Confirm TransE wins on Genes and HolE wins on Diseases.

## Open Questions the Paper Calls Out

### Open Question 1
Does the inclusion of protein-protein interaction (PPI) networks significantly enhance the predictive accuracy of the knowledge graph framework? The study relied on ontological annotations (GO, HP, DO) but did not integrate PPI data, which the authors note provides functional context for molecular perturbations.

### Open Question 2
Can deep graph neural networks (GNNs) outperform the shallow knowledge graph embedding methods evaluated in this study? The authors focused on shallow methods for computational efficiency, leaving deep learning architectures untested within this systematic comparison.

### Open Question 3
Does the performance gap between node-pair classification and link prediction persist when using more sophisticated negative sampling strategies? The study attributes part of the inferior performance of node-pair classification to synthetic negative sampling; it remains unclear if better sampling would close the gap with link prediction.

## Limitations
- Performance comparisons constrained by fixed default negative sampling strategies in OpenKE and PyRDF2Vec
- Node-pair classification pipeline requires additional preprocessing (Hadamard aggregation) that inherently loses ranking information
- Evaluation assumes all true associations not in DisGeNET are truly negative, potentially introducing false negatives

## Confidence
- **High confidence**: Link prediction outperforming node-pair classification (supported by direct experimental comparison)
- **Medium confidence**: Directional superiority of semantic matching vs. translational models (mechanism partially supported, biological justification inferred)
- **Medium confidence**: Performance gains from logical definitions and mappings (ablation studies show improvement, but specific contribution of each component not isolated)

## Next Checks
1. **Negative sampling analysis**: Compare performance using different negative sampling strategies (in-batch vs. pre-generated) to quantify impact on node-pair classification results.
2. **Ablation of semantic bridges**: Systematically remove logical definitions and mappings to measure individual contribution to performance gains.
3. **Cross-validation robustness**: Test whether directional model preferences (HolE for disease→gene, TransE for gene→disease) hold across different train-test splits and embedding dimensions.