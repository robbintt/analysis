---
ver: rpa2
title: Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration
arxiv_id: '2510.05013'
source_url: https://arxiv.org/abs/2510.05013
tags:
- robot
- learning
- motor
- which
- curiosity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores how robots can learn actions associated with
  imperative sentences through self-exploration by integrating active inference with
  reinforcement learning. The study investigates five hypotheses about developmental
  learning: generalization improves with compositional scale, curiosity enhances learning,
  rote learning precedes generalization, simpler actions develop before complex ones,
  and exception-handling shows U-shaped performance.'
---

# Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration

## Quick Facts
- arXiv ID: 2510.05013
- Source URL: https://arxiv.org/abs/2510.05013
- Reference count: 0
- Primary result: Robots learn to generalize language-action mappings to 85% success on untrained compositions through curiosity-driven self-exploration

## Executive Summary
This paper demonstrates how robots can learn to associate imperative sentences with actions through self-exploration by integrating active inference with reinforcement learning. The study investigates five developmental hypotheses about learning progression in embodied language acquisition. Using a simulated mobile robot with vision, touch, and proprioception sensors, the experiments show that curiosity-driven exploration significantly improves generalization performance while revealing characteristic developmental trajectories in action complexity and exception handling.

## Method Summary
The approach combines VRNN-based forward models with SAC actor-critic architectures. The robot learns through intrinsic rewards derived from KL-divergence between posterior and prior distributions (curiosity) and motor entropy. Training uses 33% of possible sentence-action combinations while testing generalization on the remaining 67%. The system employs modality-specific encoders/decoders and separate latent variables for each sensory modality, enabling multi-modal handling of the learning task.

## Key Results
- Generalization success rate improves from 25% to 85% as compositional vocabulary scale increases
- Curiosity-driven exploration yields 85% success rate versus 25% without curiosity
- U-shaped developmental trajectories emerge in exception-handling conditions (7/10 robots)
- Simpler actions like "watch" develop before more complex actions like "push left/right"

## Why This Works (Mechanism)

### Mechanism 1
Curiosity-driven exploration accelerates language-action learning by maximizing information gain through adversarial tension between prediction and action. The actor minimizes expected free energy by maximizing KL-divergence between posterior and prior distributions (seeking unpredictable outcomes), while the forward model simultaneously trains to minimize that same divergence. This creates a "racing" dynamic where exploration drives the agent toward novel sensorimotor experiences that the model must then learn to predict.

### Mechanism 2
Compositional vocabulary scale directly determines generalization capacity under sparse training. With larger vocabularies (6 verbs × 6 adjectives × 5 nouns), the model learns compositional structure rather than rote pairings. The effective sample complexity becomes proportional to the sum of elements rather than their product, enabling 85% success on untrained combinations from only 33% training coverage.

### Mechanism 3
Exception-handling induces U-shaped developmental trajectories through representational redescription. The model first learns rote pairings, then overgeneralizes compositional rules (causing errors on exceptions), and finally reorganizes internal representations to encode exceptions separately. PCA analysis shows exception commands migrating between clusters during learning.

## Foundational Learning

- **Concept: Active Inference and Free Energy Principle**
  - Why needed here: The entire architecture builds on minimizing evidence free energy (perception) and expected free energy (action). Without this foundation, the curiosity mechanism is unintelligible.
  - Quick check question: Can you explain why minimizing expected free energy leads to information-seeking behavior?

- **Concept: Variational Recurrent Neural Networks (VRNN)**
  - Why needed here: The forward model uses VRNNs to handle temporal complexity and stochasticity. Separate latent variables per sensory modality are critical to the architecture.
  - Quick check question: How does a VRNN differ from a standard RNN in handling uncertainty?

- **Concept: Soft Actor-Critic (SAC) Reinforcement Learning**
  - Why needed here: The actor-critic pair is trained via SAC to minimize expected free energy. Understanding entropy-regularized RL is necessary to modify the reward structure.
  - Quick check question: Why does SAC use entropy regularization, and how does this relate to the motor entropy term in this architecture?

## Architecture Onboarding

- **Component map:**
  - Sensory input → modality-specific encoders → posterior latent variables → concatenated hidden state → actor generates motor command → environment executes → forward model predicts next state → critic evaluates → all components updated from replay buffer

- **Critical path:** Sensory input → modality-specific encoders → posterior latent variables → concatenated hidden state → actor generates motor command → environment executes → forward model predicts next state → critic evaluates → all components updated from replay buffer

- **Design tradeoffs:**
  - Separate vs. shared latent variables: Separate latents per modality enable multi-modal handling but increase parameters
  - Curiosity weighting (η): Higher curiosity accelerates exploration but may delay task mastery; paper uses η_vision=0.05, η_touch=2.0, η_feedback=0.3
  - Replay buffer size (256 episodes): Limits long-term memory but enables stable training

- **Failure signatures:**
  - No curiosity condition: ~25% success rate, entangled verb representations in PCA
  - Small vocabulary scale: ~25% generalization even with full training convergence
  - Exception handling: Only 49% average success; some individuals fail entirely (15% success)

- **First 3 experiments:**
  1. Replicate the "all curiosity" vs. "no curiosity" comparison on a reduced action set (2 verbs, 3 nouns) to verify curiosity effects without full compute burden.
  2. Ablate motor entropy (set α=0) while keeping curiosity to isolate the contribution of stochastic exploration vs. information gain.
  3. Visualize latent space evolution during training using PCA on command embeddings to confirm compositional clustering emerges before generalization improves.

## Open Questions the Paper Calls Out

### Open Question 1
Does incorporating interactive, bidirectional communication between robots and tutors accelerate language-action acquisition compared to one-directional instruction? The Discussion states that natural development involves bidirectional communication and "Future studies should extend the current framework to include interactive communication between tutors and robots." This remains unresolved as the current study limited communication to a one-directional pathway.

### Open Question 2
Can the active inference framework enable the evolution of dynamic action-related language (verbs) in multi-robot systems, moving beyond static object labeling? The Discussion proposes extending the model to "collective active inference" to study the "evolution of dynamic linguistic structures, including verbs," which remains largely unexplored. Previous research and the current study focus primarily on object labeling or individual learning.

### Open Question 3
Does the required training sample size scale linearly (proportional to the sum of elements) rather than multiplicatively as the compositional vocabulary increases? The Discussion notes a hypothesis that necessary training size scales with the summation of dimensions, stating "This hypothesis becomes more plausible... which should be confirmed in much more scaled experiments in the future." While current results with limited scales (48 to 180 compositions) support the trend, it remains unverified if this efficient scaling holds for significantly larger vocabularies.

## Limitations

- The scaling law claim is based on a single dataset with 6×6×5 vocabulary, limiting generalizability to other compositional domains.
- U-shaped learning evidence relies on only 7/10 individuals showing the pattern, with 3/10 showing no clear trajectory.
- The architectural claims about separate latents per modality versus shared representations remain underspecified in terms of trade-offs.

## Confidence

- **High confidence**: Curiosity-driven exploration accelerates learning (direct comparison shows 85% vs 25% success).
- **Medium confidence**: Compositional scaling improves generalization (strong effect size but single configuration tested).
- **Medium confidence**: Exception-handling induces U-shaped learning (majority show pattern but with individual variation).
- **Medium confidence**: Action development follows complexity ordering (timing differences observed but developmental sequencing not explicitly tested).

## Next Checks

1. **Vocabulary scaling validation**: Systematically vary vocabulary size (2×2×2, 3×3×3, 4×4×4, 6×6×5) and measure generalization as a function of vocabulary dimension product. This tests whether the scaling effect holds across the predicted range.

2. **Curiosity ablation study**: Train identical models with curiosity weights η = 0.0, 0.01, 0.05, 0.1, 0.2 for each modality independently. Plot learning curves to identify optimal curiosity magnitudes and modality-specific effects.

3. **Exception timing analysis**: For the exception-handling conditions, record the exact epoch when each exception command's success rate dips below its initial value, then rises again. Compare timing to non-exception commands to quantify the "overgeneralization" phase duration.