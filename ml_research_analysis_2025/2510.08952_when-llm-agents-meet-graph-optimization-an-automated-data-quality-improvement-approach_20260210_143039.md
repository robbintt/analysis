---
ver: rpa2
title: 'When LLM Agents Meet Graph Optimization: An Automated Data Quality Improvement
  Approach'
arxiv_id: '2510.08952'
source_url: https://arxiv.org/abs/2510.08952
tags:
- text
- label
- graph
- structure
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes LAGA, a large language and graph agent framework\
  \ that automates text-attributed graph quality optimization. It addresses common\
  \ defects\u2014text sparsity/noise/imbalance, structural sparsity/noise/imbalance,\
  \ and label sparsity/noise/imbalance\u2014through a closed-loop pipeline of four\
  \ specialized agents: Detection, Planning, Action, and Evaluation."
---

# When LLM Agents Meet Graph Optimization: An Automated Data Quality Improvement Approach

## Quick Facts
- **arXiv ID:** 2510.08952
- **Source URL:** https://arxiv.org/abs/2510.08952
- **Reference count:** 40
- **Primary result:** LAGA framework automates TAG quality optimization via four specialized agents, achieving state-of-the-art accuracy across 5 datasets and 9 degradation scenarios.

## Executive Summary
This paper introduces LAGA, a multi-agent framework that leverages large language models and graph optimization to automate the improvement of text-attributed graph (TAG) quality. LAGA addresses common defects—text sparsity/noise/imbalance, structural sparsity/noise/imbalance, and label sparsity/noise/imbalance—through a closed-loop pipeline of four specialized agents: Detection, Planning, Action, and Evaluation. The framework integrates semantic and structural learning with targeted repair operations, dynamically adjusting loss weights and repair strategies based on issue severity. Experiments demonstrate consistent performance gains over 16 baselines across diverse datasets and GNN backbones.

## Method Summary
LAGA operates on text-attributed graphs (TAGs) where nodes have text attributes and edges represent relationships. The framework employs a closed-loop pipeline with four specialized agents. The Detection Agent uses tools like TF-IDF, Louvain clustering, and k-means to identify defects across text, structure, and labels. The Planning Agent, powered by an LLM, interprets detection reports and dynamically assigns loss weights and repair priorities based on severity. The Action Agent executes graph learning using a dual-encoder design (semantic LLM and structural GCN) and performs targeted optimization operations such as text repair, node generation, and edge manipulation. The Evaluation Agent assesses quality via detection tool outputs, downstream task performance, and LLM judgment, deciding whether to continue optimization. The framework iterates until quality thresholds are met or iteration limits are reached.

## Key Results
- LAGA consistently outperforms 16 baselines across five datasets and nine degradation scenarios, achieving state-of-the-art accuracy.
- The framework demonstrates stable performance across hyperparameter settings and scales effectively to large graphs using subgraph partitioning.
- Dynamic planning and cross-modality joint learning contribute to robust optimization, with ablation studies showing the value of adaptive strategies.

## Why This Works (Mechanism)

### Mechanism 1: Multi-Agent Decomposition for Specialized Quality Control
- **Claim:** If TAG quality defects span multiple modalities and require different competencies, then decomposing the optimization pipeline into specialized agents may improve effectiveness compared to monolithic approaches.
- **Mechanism:** Four agents (Detection, Planning, Action, Evaluation) each focus on a distinct stage: anomaly localization, strategy formulation, execution, and validation. This modularity enables targeted expertise and allows iterative closed-loop refinement.
- **Core assumption:** Separate agents can effectively coordinate through structured reports (e.g., detection report R_det, planning report R_plan) without excessive overhead or misalignment.
- **Evidence anchors:**
  - [abstract] "integrating detection, planning, action, and evaluation agents into an automated loop"
  - [section 3.1] "LAGA includes four agents in a closed-loop pipeline: Detection, Planning, Action, and Evaluation"
  - [corpus] Related work on multi-agent LLM systems (e.g., SOCIA-Nabla) shows similar decomposition for complex tasks, though direct evidence for TAG quality is limited in this corpus.
- **Break condition:** If inter-agent communication overhead dominates or if defects are highly coupled such that decomposition prevents holistic understanding, the mechanism may degrade.

### Mechanism 2: LLM-Driven Adaptive Planning Over Static Rules
- **Claim:** If TAG defects are ambiguous and context-dependent, then LLM-based planning may outperform fixed rule-based strategies by dynamically prioritizing repairs and adjusting loss weights.
- **Mechanism:** The Planning Agent uses an LLM to interpret detection signals (severity levels from S_ser), generate optimization priorities (π), and assign reliability-aware loss weights (α, β, γ) based on defect severity. This allows context-sensitive strategies (e.g., reordering optimization steps when noise propagation risks exist).
- **Core assumption:** The LLM can accurately assess issue severity and generate coherent, executable plans from structured detection reports without hallucinating inappropriate strategies.
- **Evidence anchors:**
  - [abstract] "The Planning agent dynamically adjusts loss weights and repair strategies based on issue severity"
  - [section 3.3] "The Planning Agent transcends fixed rule-based heuristics by dynamically formulating optimization trajectories based on detection reports"
  - [corpus] Weak direct evidence for LLM planning in TAG quality; related work (e.g., Maestro) shows LLM-based optimization for agent graphs, but not specifically for data quality.
- **Break condition:** If LLM outputs are inconsistent or if detection reports are too noisy for reliable interpretation, planning may become unreliable.

### Mechanism 3: Cross-Modality Joint Learning via Dual-Encoder Design
- **Claim:** If defects in one modality can mask or amplify defects in another, then jointly learning semantic and structural embeddings with modality-specific objectives may improve TAG quality more effectively than isolated optimizations.
- **Mechanism:** The Action Agent uses a dual-encoder: a semantic encoder (LLM-enhanced text processing) and a structural encoder (GCN). These are trained with a combined loss (semantic loss L_sema, structural loss L_stu, label loss L_label) that aligns representations and prioritizes reliable modalities via severity-aware weights.
- **Core assumption:** Joint training with aligned objectives can resolve inter-modality conflicts (e.g., noisy text misleading structure learning) without requiring perfect modality independence.
- **Evidence anchors:**
  - [abstract] "integrates semantic and structural learning with targeted repair operations"
  - [section 3.4] "The Action Agent unifies Graph Learning, which builds robust embeddings, with Graph Optimization... It unifies a dual-encoder design (semantic + structure encoders)"
  - [corpus] Related work (e.g., UltraTAG-S) uses dual-channel encoders for TAG learning, supporting the plausibility of this approach.
- **Break condition:** If one modality is severely degraded such that its embeddings are misleading, joint learning may propagate errors unless properly down-weighted (which the planning agent attempts to handle).

## Foundational Learning

- **Text-Attributed Graphs (TAGs)**
  - **Why needed here:** LAGA operates on TAGs where nodes have text attributes and edges represent relationships. Understanding the interplay between text semantics and graph structure is essential.
  - **Quick check question:** Can you name the three modalities (text, structure, label) and the three defect types (sparsity, noise, imbalance) that define the 3x3 quality taxonomy?

- **Graph Neural Networks (GNNs)**
  - **Why needed here:** LAGA's Action Agent uses GNNs (e.g., GCN) for structure learning and as backbone models for evaluation. GNN basics (message passing, aggregation) are assumed.
  - **Quick check question:** How does a GCN update a node's representation based on its neighbors?

- **Multi-Agent LLM Systems**
  - **Why needed here:** LAGA is fundamentally a multi-agent system where LLMs drive planning, evaluation, and text repair. Familiarity with agent roles and communication is helpful.
  - **Quick check question:** What are the four agents in LAGA, and what is the primary output of each (e.g., report, plan, optimized graph)?

## Architecture Onboarding

- **Component map:** Detection Agent (R_det) -> Planning Agent (R_plan) -> Action Agent (R_ana) -> Evaluation Agent (R_eval) -> (continue or stop).

- **Critical path:** Start with Detection Agent on input TAG -> Planning Agent formulates strategy -> Action Agent executes learning and optimization -> Evaluation Agent assesses. If δ=True, loop back with updated graph.

- **Design tradeoffs:**
  - **Offline preprocessing:** LAGA is designed for one-time optimization; upfront cost is amortized over multiple downstream uses.
  - **LLM dependence:** Planning and Evaluation rely on LLM reasoning; smaller/cheaper models may reduce cost but risk plan quality.
  - **Generative text repair:** Fine-tuned LLM may hallucinate content; entropy loss (H(t_out)) encourages diversity but doesn't guarantee factual correctness.

- **Failure signatures:**
  - **Oscillating optimizations:** If Evaluation Agent thresholds (τ_imp) are too strict, the loop may not converge. Check iteration counts in Table 5 (typically 1-5 iterations).
  - **Error propagation:** If Planning Agent misassigns severity (e.g., down-weights a critical modality), subsequent actions may degrade quality. Review planning outputs in case studies (Appendix N).
  - **Memory issues on large graphs:** Subgraph partitioning (Appendix O) is required for graphs like ogbn-arxiv; without it, OOM errors occur.

- **First 3 experiments:**
  1. **Single-defect validation:** Run LAGA on Cora with text sparsity (ratio=0.4). Verify that Detection Agent flags the issue, Planning Agent prioritizes text optimization, and Action Agent improves classification accuracy (compare with baselines in Table 1).
  2. **Ablation on planning:** Disable dynamic planning (use fixed priority/weights) on a noisy scenario (e.g., structure noise on Citeseer). Compare accuracy with full LAGA to quantify the contribution of adaptive planning (Table 2).
  3. **Scalability test:** Apply LAGA with subgraph partitioning to ogbn-arxiv under text noise. Measure total runtime and final accuracy. Compare with baseline GCN performance (Table 3) to ensure gains justify preprocessing cost.

## Open Questions the Paper Calls Out
None

## Limitations

- **LLM Planning Reliability:** The Planning Agent's ability to consistently generate optimal strategies depends on the quality and robustness of its reasoning over detection reports, with limited analysis of performance under ambiguous or conflicting defect signals.
- **Text Repair Hallucination Risk:** The Action Agent uses a fine-tuned LLM to repair or generate text attributes; the entropy-based loss encourages diversity but does not guarantee factual correctness, potentially introducing hallucinated or inconsistent content.
- **Scalability to Very Large Graphs:** While subgraph partitioning is proposed for large graphs like ogbn-arxiv, the paper does not provide detailed runtime or memory analysis for graphs orders of magnitude larger, and the closed-loop iteration may become computationally prohibitive at scale.

## Confidence

- **Multi-Agent Effectiveness:** High — Modular decomposition is well-grounded in related work and supported by consistent experimental results.
- **LLM-Driven Adaptive Planning:** Medium — Plausible and shows performance gains, but direct evidence for TAG quality contexts is limited and LLM reasoning introduces variability.
- **Cross-Modality Joint Learning:** Medium — Supported by related TAG learning work, but assumption of robust handling of severe modality degradation is not fully validated under extreme conditions.

## Next Checks

1. **Ablation on Planning Strategy:** Disable the LLM-based dynamic planning and use a fixed, rule-based prioritization across all modalities and severities. Compare downstream task accuracy and iteration counts to quantify the contribution of adaptive planning under controlled defect patterns.

2. **Hallucination Audit on Text Repair:** After LAGA text optimization, manually or automatically assess the factual consistency and semantic coherence of repaired/augmented text attributes against original or external knowledge sources to quantify hallucination risk.

3. **Scalability Stress Test:** Apply LAGA to graphs significantly larger than ogbn-arxiv (e.g., social networks with millions of nodes) with and without subgraph partitioning. Measure memory usage, per-iteration runtime, and convergence behavior to identify bottlenecks and validate the practicality of the proposed partitioning strategy.