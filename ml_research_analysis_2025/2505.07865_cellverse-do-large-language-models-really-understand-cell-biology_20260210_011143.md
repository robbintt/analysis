---
ver: rpa2
title: 'CellVerse: Do Large Language Models Really Understand Cell Biology?'
arxiv_id: '2505.07865'
source_url: https://arxiv.org/abs/2505.07865
tags:
- cell
- data
- single-cell
- gene
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces CELLVERSE, a language-centric benchmark\
  \ designed to evaluate large language models (LLMs) on single-cell biology tasks.\
  \ The authors transform single-cell multi-omics data into natural language format\
  \ and formulate three hierarchical tasks\u2014cell type annotation, drug response\
  \ prediction, and perturbation analysis\u2014as question-answering problems."
---

# CellVerse: Do Large Language Models Really Understand Cell Biology?

## Quick Facts
- arXiv ID: 2505.07865
- Source URL: https://arxiv.org/abs/2505.07865
- Reference count: 40
- This paper introduces CELLVERSE, a language-centric benchmark designed to evaluate large language models (LLMs) on single-cell biology tasks.

## Executive Summary
This paper introduces CELLVERSE, a language-centric benchmark designed to evaluate large language models (LLMs) on single-cell biology tasks. The authors transform single-cell multi-omics data into natural language format and formulate three hierarchical tasks—cell type annotation, drug response prediction, and perturbation analysis—as question-answering problems. They evaluate 14 LLMs ranging from 160M to 671B parameters, including both open-source (C2S-Pythia, Qwen, Llama, DeepSeek) and closed-source (GPT-4 family) models. Results show that generalist LLMs outperform specialist models and demonstrate preliminary understanding of cell biology, but all models struggle significantly. For cell type annotation, top models achieve only 42-61% accuracy; for drug response prediction, no model performs significantly better than random guessing. The work establishes CELLVERSE as the first benchmark for assessing LLM capabilities in cell biology and highlights the substantial challenges remaining in this domain.

## Method Summary
CELLVERSE transforms single-cell multi-omics data into natural language through Cell2Sentence (C2S) encoding, which converts each cell's gene expression profile into a ranked list of gene names treated as a sentence. Gene Regulatory Networks are translated into natural language statements describing regulatory relationships. The benchmark includes four tasks formulated as multiple-choice QA problems: cell type annotation (CTA), drug response prediction (DRP), perturbation significance analysis (PSA), and perturbation direction analysis (PDA). The authors evaluate 14 LLMs under zero-shot and few-shot settings, measuring accuracy, precision, recall, and F1 scores across five sub-datasets spanning scRNA-seq, CITE-seq, ASAP-seq, and scATAC-seq modalities.

## Key Results
- Specialist models (C2S-Pythia) consistently underperform generalist models despite task-specific training
- GPT-4 family achieves 42-61% accuracy on cell type annotation, while no model exceeds random guessing on drug response prediction
- DeepSeek-R1 achieves 76.67% accuracy on perturbation significance but only 62.96% on direction prediction
- Few-shot learning often degrades performance due to noise in single-cell data
- GPT-4 models systematically refuse to answer drug response and perturbation questions

## Why This Works (Mechanism)

### Mechanism 1: Cell2Sentence (C2S) Encoding Preserves Ranked Gene Expression Information
Converting single-cell expression profiles into ranked gene name sequences enables LLMs to process high-dimensional biological data through their natural language interface. C2S treats gene names as vocabulary tokens and represents each cell as a sentence composed of the top n most highly expressed genes in descending order, preserving essential cellular characteristics in a compact, interpretable form with controllable context length.

### Mechanism 2: Gene Regulatory Network (GRN) Translation Enables Perturbation Reasoning
Encoding gene-gene regulatory relationships as natural language statements allows LLMs to reason about perturbation effects through textual inference. GRN edges are translated into conditional statements: if edge weight exceeds threshold τ, then "perturbing g_a leads to change in g_b"; otherwise, no significant relationship is asserted. This bridges graph-based biological knowledge and language-driven inference.

### Mechanism 3: Task-to-QA Reformulation Leverages Pre-trained Language Understanding
Reformulating single-cell analysis tasks as multiple-choice QA problems allows generalist LLMs to apply pre-trained reasoning capabilities without task-specific training. Each biological task is converted to a natural language question with candidate answers, enabling models to leverage their existing linguistic knowledge for biological reasoning.

## Foundational Learning

- **Concept: Single-cell multi-omics data modalities**
  - **Why needed here:** CellVerse integrates four distinct sequencing technologies (scRNA-seq, CITE-seq, ASAP-seq, scATAC-seq), each capturing different biological signals. Understanding what each measures is essential for interpreting task design and results.
  - **Quick check question:** Which modality captures chromatin accessibility rather than gene expression?

- **Concept: Gene expression ranking vs. absolute values**
  - **Why needed here:** The C2S mechanism discards quantitative expression values in favor of ranked gene names. This design choice affects what biological signal is preserved and lost.
  - **Quick check question:** If Gene A has expression 1000 and Gene B has expression 990, how does C2S represent them compared to Gene A=1000 and Gene B=100?

- **Concept: Zero-shot vs. few-shot evaluation in domain-specific tasks**
  - **Why needed here:** CellVerse evaluates models under both settings. Obs. 5 shows few-shot learning "yields limited gains and often even degrades performance," contradicting typical LLM behavior patterns.
  - **Quick check question:** Why might noisy single-cell data in few-shot examples hurt rather than help model performance?

## Architecture Onboarding

- **Component map:** Raw single-cell data (scRNA-seq/CITE-seq/ASAP-seq/scATAC-seq) → Data transformation layer [C2S encoder | GRN translator] → Natural language QA pairs [question + candidate answers] → LLM inference layer [14 evaluated models] → Multiple-choice prediction [cell type | drug response | perturbation significance/direction]

- **Critical path:** The data transformation layer determines what biological signal reaches the LLM. C2S quality (gene count, ranking fidelity) directly constrains downstream reasoning. The paper uses top-n genes in descending order with context length scaling experiments.

- **Design tradeoffs:**
  - Context length vs. noise: Longer gene lists provide more information but may introduce noise from low-expression genes
  - Specialist vs. generalist models: Specialist C2S-Pythia models fail completely while larger generalist models show emerging capabilities
  - Open-ended vs. multiple-choice format: All questions converted to multiple-choice because "all models struggle to make reasonable decisions under open-ended question settings"

- **Failure signatures:**
  - GPT-4 refusal pattern: Refuses to answer drug response and perturbation analysis questions, outputting 0% or near-0% accuracy
  - Qwen "No" bias: Tends to answer "No" to all perturbation significance questions, achieving high accuracy only because the "No" class dominates
  - C2S-Pythia hallucination: Specialist models generate predictions but with systematic errors across all tasks
  - Drug response at chance: All models achieve 43-55% accuracy on binary drug response prediction, with best model at only 55%

- **First 3 experiments:**
  1. Reproduce C2S encoding on a small single-cell dataset: Take a public scRNA-seq sample, normalize expression, rank genes, and format as a cell sentence. Verify that cell type marker genes appear in top positions for known cell types.
  2. Evaluate a single LLM on one CellVerse sub-task: Use GPT-4o-mini on the CITE-seq cell type annotation task. Compare accuracy against the reported 48.57% baseline to validate your evaluation pipeline.
  3. Test context length sensitivity: For the same task, vary the number of genes included in the cell sentence (e.g., 50, 100, 200, 500 genes) and plot accuracy vs. context length. Determine if your setup reproduces the observation that GPT-4 benefits from longer contexts while DeepSeek does not.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can quantitative difficulty levels be effectively assigned to single-cell QA tasks to enable more nuanced evaluation?
- **Basis in paper:** The authors explicitly state that CELLVERSE "does not yet provide a quantitative distinction in their levels of difficulty" and suggest future work should draw inspiration from mathematical benchmarks to assign difficulty levels.
- **Why unresolved:** Current aggregate accuracy scores mask whether models fail on inherently complex biological reasoning or simple noisy inputs.
- **What evidence would resolve it:** A validated methodology for grading problem complexity that reveals a performance gradient across different difficulty tiers.

### Open Question 2
- **Question:** Does extending the benchmark to multilingual settings preserve or degrade LLM performance in cell biology reasoning?
- **Basis in paper:** The limitations section notes that "all prompts and questions are currently formulated in English" and explicitly lists extending the benchmark to multilingual QA settings as a goal for global applicability.
- **Why unresolved:** It is unknown if the observed "preliminary understanding capabilities" are an artifact of English-centric training data or transferable linguistic reasoning.
- **What evidence would resolve it:** Evaluation of models on translated versions of the CELLVERSE benchmark showing comparable performance metrics.

### Open Question 3
- **Question:** Why does few-shot in-context learning often degrade performance in single-cell analysis, and how can sample quality be optimized?
- **Basis in paper:** Observation 5 notes that few-shot learning yields "limited gains and often even degrades performance," leading the authors to hypothesize that the "high level of noise inherent in single-cell data" interferes with generalization.
- **Why unresolved:** It is unclear if the failure is due to the noise magnitude or the models' inability to attend to relevant biological signals in the context.
- **What evidence would resolve it:** Ablation studies demonstrating that specific filtering for high-quality, low-noise few-shot examples significantly reverses the performance degradation.

## Limitations
- Specialist models trained specifically on single-cell data fail completely while generalist models show better performance
- GPT-4 models systematically refuse to answer drug response and perturbation questions due to safety protocols
- All prompts and questions are currently formulated in English, limiting global applicability
- Few-shot learning often degrades performance due to noise in single-cell data

## Confidence
- **High confidence:** The CellVerse benchmark construction methodology and evaluation framework are sound
- **Medium confidence:** The conclusion that LLMs demonstrate "preliminary understanding" of cell biology is supported by performance above random chance on some tasks
- **Low confidence:** The claim that LLMs could eventually replace domain-specific tools is highly speculative given current performance gaps

## Next Checks
1. Validate C2S encoding biological fidelity: Take a known marker gene and systematically test whether cell sentences from pure cell populations consistently rank the marker in top positions across different datasets.
2. Test open-ended vs. multiple-choice performance gap: Evaluate GPT-4o-mini on both formats with identical inputs and measure the performance difference.
3. Validate specialist model failure mode: Re-train C2S-Pythia on a subset of CellVerse data with controlled hyperparameters and evaluate on held-out test sets to determine whether the failure is due to architecture limitations or fundamental issues with the C2S representation.