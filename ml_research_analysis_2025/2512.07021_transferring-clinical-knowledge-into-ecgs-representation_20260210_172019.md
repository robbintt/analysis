---
ver: rpa2
title: Transferring Clinical Knowledge into ECGs Representation
arxiv_id: '2512.07021'
source_url: https://arxiv.org/abs/2512.07021
tags:
- data
- clinical
- learning
- multimodal
- encoder
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a three-stage training paradigm that transfers
  knowledge from multimodal clinical data (lab tests, vitals, biometrics) into a unimodal
  ECG encoder for diagnosis classification. The approach uses self-supervised, joint-embedding
  pre-training to align ECG signal and tabular clinical data representations, followed
  by fine-tuning for multi-label diagnosis classification and laboratory abnormality
  prediction from the ECG embedding alone.
---

# Transferring Clinical Knowledge into ECGs Representation

## Quick Facts
- arXiv ID: 2512.07021
- Source URL: https://arxiv.org/abs/2512.07021
- Reference count: 14
- Diagnoses classification AUROC: 0.795 (vs 0.768 baseline)

## Executive Summary
This paper proposes a three-stage training paradigm that transfers knowledge from multimodal clinical data (lab tests, vitals, biometrics) into a unimodal ECG encoder for diagnosis classification. The approach uses self-supervised, joint-embedding pre-training to align ECG signal and tabular clinical data representations, followed by fine-tuning for multi-label diagnosis classification and laboratory abnormality prediction from the ECG embedding alone. Evaluated on MIMIC-IV-ECG, the method outperforms a signal-only baseline in diagnosis classification (AUROC: 0.795 vs 0.768) while only requiring ECG at inference. It also predicts laboratory abnormalities (AUROC: 0.701) from the ECG embedding, providing clinically-grounded explanations for diagnostic decisions. The approach bridges much of the performance gap to fully multimodal models without requiring all data modalities at inference, offering a practical path toward more accurate and trustworthy ECG-based diagnostic AI systems.

## Method Summary
The method employs a three-stage training paradigm: (1) self-supervised joint-embedding pre-training using Barlow Twins loss to align ECG signal representations with tabular clinical data embeddings, (2) fine-tuning for multi-label diagnosis classification with partially frozen ECG encoder, and (3) fine-tuning for laboratory abnormality prediction from the same ECG embedding. The approach transfers contextual clinical knowledge into the ECG encoder during pre-training, enabling accurate diagnosis classification at inference time using only ECG signals. The predicted laboratory abnormalities serve as an indirect explanation mechanism, offering a reasoning trace for diagnostic predictions without requiring multimodal data at inference.

## Key Results
- Outperforms signal-only baseline in diagnosis classification (AUROC: 0.795 vs 0.768)
- Predicts laboratory abnormalities from ECG embedding alone (AUROC: 0.701)
- Bridges ~3% AUROC gap to fully multimodal models while requiring only ECG at inference
- Achieves clinically-grounded explanations through auxiliary lab abnormality prediction task

## Why This Works (Mechanism)

### Mechanism 1: Cross-Modal Knowledge Transfer via Joint-Embedding
- Claim: Self-supervised joint-embedding pre-training transfers contextual clinical knowledge into the ECG encoder, improving downstream diagnostic performance without requiring multimodal data at inference.
- Mechanism: Two encoders process ECG signals (Φx, S4-based) and tabular clinical data (Φm, MLP) separately. Projector networks (Θx, Θm) map both to a shared embedding space. Barlow Twins loss aligns embeddings by forcing the cross-correlation matrix toward identity—pulling same-patient embeddings together (invariance) while decorrelating embedding dimensions (redundancy reduction). The ECG encoder learns representations that are predictive of clinical context.
- Core assumption: ECG signals contain latent physiological information that systematically correlates with lab values, vitals, and biometrics; this relationship is learnable through statistical alignment.
- Evidence anchors:
  - [abstract]: "We employ a self-supervised, joint-embedding pre-training stage to create an ECG representation that is enriched with contextual clinical information, while only requiring the ECG signal at inference time."
  - [section 2.1]: "By minimizing this loss, the signal encoder Φx is trained to produce representations hx that are not only descriptive of the ECG signal itself but are also highly predictive of the rich, contextual information contained in the clinical data m. This process effectively transfers the clinical knowledge into the parameters of the waveform encoder."
  - [corpus]: CLEF (arXiv:2512.02180) supports clinically-guided contrastive learning for ECG foundation models; AnyECG-Lab (arXiv:2510.22301) demonstrates feasibility of lab value estimation from ECG signals. No direct replication of this specific joint-embedding method found.
- Break condition: If ECG signals lack physiologically meaningful correlation with the selected tabular clinical variables, the joint-embedding will transfer noise rather than knowledge, potentially degrading performance.

### Mechanism 2: Partial Freezing for Catastrophic Forgetting Mitigation
- Claim: Partially freezing the pre-trained encoder during fine-tuning preserves transferred clinical knowledge while adapting task-specific heads.
- Mechanism: After joint-embedding pre-training, early layers of Φx are frozen. New task-specific heads (Ψy for diagnosis, Ψm for lab reconstruction) are initialized and trained with BCE loss. Freezing prevents gradient updates from overwriting the aligned representations learned during pre-training.
- Core assumption: Early layers encode general, transferable physiological features; task-specific adaptations are primarily needed in downstream projection layers.
- Evidence anchors:
  - [section 2.2]: "The pre-trained encoder Φx is partially frozen to prevent catastrophic forgetting of the transferred clinical knowledge."
  - [section 4]: "A primary limitation of our work lies in the three-stage sequential training paradigm. This approach introduces the risk of catastrophic forgetting... To mitigate this, we partially froze the early layers of the signal encoder, preserving the foundational representations learned during pre-training."
  - [corpus]: No corpus papers directly validate partial freezing in this specific context; this is a standard transfer learning technique.
- Break condition: If downstream tasks require significant modification of early-layer representations (e.g., fundamentally different signal features), partial freezing will limit achievable performance.

### Mechanism 3: Secondary Task as Indirect Explanation Mechanism
- Claim: Predicting laboratory abnormalities from the ECG embedding provides clinically-grounded, post-hoc explanations for diagnostic predictions.
- Mechanism: A reconstruction head (Ψm) predicts binary lab abnormality labels (e.g., "Hemoglobin_high") from the same ECG embedding used for diagnosis. At inference, the model outputs both a diagnosis and predicted abnormalities, offering a reasoning trace: "The model predicts diagnosis Y, and it's doing so as it also is predicting associated lab abnormality M*."
- Core assumption: Predicted lab abnormalities have clinical relevance to diagnoses; the ECG embedding captures physiologically meaningful correlates of both.
- Evidence anchors:
  - [abstract]: "Furthermore, as an indirect way to explain the model's output we train it to also predict associated laboratory abnormalities directly from the ECG embedding."
  - [section 2.3]: "Our hypothesis is that the ability of the model to successfully perform this pseudo-reconstruction task, using only the ECG signal as input, serves to provide a mechanism for model explainability."
  - [section 4]: "Our evaluation of the model's interpretability is indirect... this assessment does not establish a causal relationship between the predicted abnormalities and the final diagnoses."
  - [corpus]: Weak corpus support for this specific explanation mechanism; related work on XAI in healthcare notes limitations of non-causal explanations.
- Break condition: If predicted abnormalities are spuriously correlated with diagnoses (or driven by confounders), the "explanations" may mislead clinicians rather than inform them. The paper explicitly acknowledges this limitation.

## Foundational Learning

- **Concept: Self-Supervised Joint-Embedding (Barlow Twins)**
  - Why needed here: The pre-training stage uses Barlow Twins to align ECG and tabular embeddings without negative samples. You must understand redundancy reduction objectives and collapse avoidance.
  - Quick check question: Why does Barlow Twins decorrelate embedding dimensions rather than using contrastive negative pairs?

- **Concept: Catastrophic Forgetting in Sequential Training**
  - Why needed here: The three-stage paradigm risks overwriting pre-trained knowledge during fine-tuning. Understanding this informs why partial freezing is necessary.
  - Quick check question: If you fully unfroze the encoder during fine-tuning, what failure mode would you expect and why?

- **Concept: Multi-Label Classification with BCE Loss**
  - Why needed here: Both diagnosis classification and lab abnormality prediction are multi-label tasks. You need to understand why BCE (not softmax cross-entropy) is appropriate here.
  - Quick check question: Why is macro-averaged AUROC the reported metric rather than micro-averaged or accuracy?

## Architecture Onboarding

- **Component map:**
  [ECG Signal X] → Φx (S4 encoder, partially frozen) → hx → Θx (projector, pre-training only)
  [Tabular Data M] → Φm (MLP) → hm → Θm (projector, pre-training only)

  Pre-training: L_je = BarlowTwins(Θx(hx), Θm(hm))

  Fine-tuning:
  hx → Ψy (classification head) → Ŷ (diagnoses) → L_c = BCE(Y, Ŷ)
  hx → Ψm (reconstruction head) → M̂* (lab abnormalities) → L_r = BCE(M*, M̂*)

- **Critical path:**
  1. **Pre-training (Stage 1):** Train Φx, Φm, Θx, Θm jointly with Barlow Twins loss on paired ECG-tabular data. Save Φx weights.
  2. **Classification Fine-tuning (Stage 2):** Load Φx, freeze early layers, initialize Ψy, train on labeled diagnoses.
  3. **Reconstruction Fine-tuning (Stage 3):** Using same Φx, initialize Ψm, train on lab abnormality labels. Inference uses both heads.

- **Design tradeoffs:**
  - Sequential vs. joint multi-task: Paper tried joint optimization but found it "highly challenging and unstable." Sequential training sacrifices some knowledge retention for training stability.
  - Partial vs. full freezing: Freezing too much limits adaptation; freezing too little risks forgetting. Paper chose early-layer freezing without specifying exact layer boundary.
  - Unimodal inference vs. multimodal: Sacrifices ~3% AUROC (0.795 vs 0.826) compared to full multimodal model, but gains practical deployability.

- **Failure signatures:**
  - **Representational collapse during pre-training:** Embeddings converge to constant vectors. Monitor embedding variance and cross-correlation matrix rank.
  - **Poor knowledge transfer:** Fine-tuned model underperforms signal-only baseline (0.795 < 0.768 would indicate negative transfer).
  - **Low lab prediction AUROC:** If reconstruction task fails (AUROC << 0.701), explanation mechanism provides uninformative or misleading outputs.
  - **Training instability:** Joint multi-task optimization diverges; stick to sequential stages with partial freezing.

- **First 3 experiments:**
  1. **Reproduce baseline:** Train supervised signal-only model per Strodthoff et al. [2024] protocol. Verify AUROC ≈ 0.768.
  2. **Pre-training validation:** Run joint-embedding pre-training. Visualize embedding alignment (t-SNE of zx vs. zm by patient) and verify Barlow Twins loss converges without collapse.
  3. **Ablation study:** Compare (a) full model, (b) without pre-training (random init), (c) without reconstruction task. Isolate contribution of each stage to diagnosis AUROC and lab prediction performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can advanced continual learning strategies, such as representation distillation or regularization-based methods, prevent catastrophic forgetting more effectively than the current partial freezing approach?
- Basis in paper: [Explicit] The authors identify the sequential training paradigm as a limitation and suggest "future work could explore more advanced continual learning strategies... [such as] regularization-based methods... or representation distillation."
- Why unresolved: The current three-stage approach risks losing transferred knowledge during fine-tuning, and simultaneous optimization of all losses was found to be unstable.
- What evidence would resolve it: Comparative experiments showing that distillation or regularization techniques result in higher retention of pre-trained features or improved diagnostic AUROC compared to partial freezing.

### Open Question 2
- Question: Is there a causal relationship between the laboratory abnormalities predicted from the ECG embedding and the final diagnostic classifications?
- Basis in paper: [Explicit] The authors state their "assessment does not establish a causal relationship between the predicted abnormalities and the final diagnoses" and suggest "causal inference methods" for future investigation.
- Why unresolved: While the model predicts abnormalities (correlation), it is unclear if these abnormalities are the actual physiological drivers behind the specific diagnosis predictions.
- What evidence would resolve it: A study utilizing causal inference techniques or clinician feedback to validate that the predicted lab abnormalities are clinically salient explanations for the specific diagnoses made.

### Open Question 3
- Question: Can the joint-embedding framework be effectively scaled to n > 2 modalities by integrating unstructured clinical text using an anchor-based approach?
- Basis in paper: [Explicit] The authors propose generalizing the framework to "align representations from all three modalities (ECG, tabular, text)" using the "ECG’s latent space as a central anchor."
- Why unresolved: The current study only validates alignment between ECG signals and tabular data; the efficacy of aligning text notes to this latent space remains unproven.
- What evidence would resolve it: Successful training and evaluation of a tri-modal model that incorporates clinical notes, demonstrating improved classification performance or more natural text-based explanations.

## Limitations

- The interpretability mechanism (lab abnormality prediction) does not establish causal relationships between predicted abnormalities and final diagnoses, limiting clinical utility of explanations.
- Partial freezing strategy may restrict the model's ability to fully adapt to downstream tasks if early-layer representations need significant modification.
- Sequential three-stage training introduces potential knowledge loss between stages and requires careful hyperparameter tuning to prevent forgetting.

## Confidence

- **High Confidence:** The core mechanism of cross-modal knowledge transfer via Barlow Twins pre-training is well-supported by the 0.795 AUROC outperforming the 0.768 baseline.
- **Medium Confidence:** The effectiveness of partial freezing for catastrophic forgetting mitigation is theoretically sound but lacks direct empirical validation in this specific context.
- **Low Confidence:** The clinical utility and reliability of lab abnormality prediction as an explanation mechanism, given the explicit acknowledgment of non-causal relationships.

## Next Checks

1. **Ablation study:** Compare full model against (a) without pre-training, (b) without reconstruction task, and (c) with different freezing strategies to isolate contributions and validate the necessity of each component.

2. **Explanation mechanism validation:** Analyze correlation patterns between predicted lab abnormalities and actual diagnoses across different disease categories to assess whether explanations are clinically meaningful or spuriously correlated.

3. **Generalization test:** Evaluate model performance on an external ECG dataset (if available) or using cross-hospital validation within MIMIC-IV-ECG to assess whether knowledge transfer generalizes beyond the training population.