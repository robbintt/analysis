---
ver: rpa2
title: 'COSMIC: Generalized Refusal Direction Identification in LLM Activations'
arxiv_id: '2506.00085'
source_url: https://arxiv.org/abs/2506.00085
tags:
- refusal
- cosmic
- direction
- steering
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: COSMIC introduces an automated framework for identifying refusal
  directions in LLM activation spaces using cosine similarity, eliminating reliance
  on output tokens or manual analysis. It selects steering directions and layers by
  comparing internal activations between harmful and harmless prompts, enabling robust
  refusal behavior control.
---

# COSMIC: Generalized Refusal Direction Identification in LLM Activations

## Quick Facts
- arXiv ID: 2506.00085
- Source URL: https://arxiv.org/abs/2506.00085
- Reference count: 40
- Primary result: Automated refusal direction identification via cosine similarity matching internal activations

## Executive Summary
COSMIC introduces an automated framework for identifying refusal directions in LLM activation spaces using cosine similarity, eliminating reliance on output tokens or manual analysis. It selects steering directions and layers by comparing internal activations between harmful and harmless prompts, enabling robust refusal behavior control. Tested across eight models, COSMIC matches or exceeds prior methods in jailbreak success and refusal induction, even under adversarial complete refusal or weak alignment. It successfully steers weakly aligned models toward safer behavior with minimal false refusals, demonstrating robustness across diverse alignment conditions.

## Method Summary
COSMIC identifies refusal directions by computing difference-in-means vectors between harmful and harmless prompt activations across layers, then selects directions using cosine similarity inversion scoring. The method evaluates internal activation similarity to identify candidate layers, applies linear or affine interventions (ablation for jailbreaking, addition for inducing refusal), and filters directions based on median peak filtering and KL divergence constraints. Unlike prior token-matching approaches, COSMIC operates purely on activation geometry, enabling application to adversarial and weakly aligned models where output tokens are unreliable.

## Key Results
- Matches or exceeds prior methods in jailbreak success rate across eight instruction-tuned models
- Induces refusal behavior in weakly aligned models with minimal false positives
- Functions under adversarial "complete refusal" conditions where models refuse all inputs
- Achieves steering with <0.1 KL divergence on harmless prompts, preserving model coherence

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Activation Isolation
- **Claim:** Vector difference between mean activations of harmful and harmless prompts isolates refusal behavior
- **Mechanism:** Computes $r_{i,l} = r^+_{i,l} - r^-_{i,l}$ using post-instruction tokens to subtract compliance baseline from refusal state
- **Core assumption:** Linear Representation Hypothesis - features are represented as directions in activation space
- **Break condition:** Non-linear encoding or feature superposition that simple subtraction cannot disentangle

### Mechanism 2: Inversion Scoring via Cosine Similarity
- **Claim:** High cosine similarity between inverted harmful activations and harmless activations indicates successful behavior steering
- **Mechanism:** Selects direction maximizing cosine similarity in 10% of layers with lowest base similarity, hypothesized to be where refusal is conceptualized
- **Core assumption:** Cosine similarity correlates with behavioral similarity independent of output tokens
- **Break condition:** Selected layers track unrelated features, causing activation changes without behavioral modification

### Mechanism 3: Affine vs. Linear Intervention
- **Claim:** Removal (ablation) suppresses refusal; addition induces refusal via linear or affine concept editing
- **Mechanism:** Uses either pure projection removal/addition (LCE) or baseline-preserving affine editing (ACE)
- **Core assumption:** Model's internal geometry aligns with intervention type (linear vs affine)
- **Break condition:** Non-monotonic steering responses where simple vector operations yield inconsistent results

## Foundational Learning

- **Concept:** Residual Stream & Layer Norm
  - **Why needed:** Interventions occur at layer inputs/outputs in residual stream; understanding information flow is critical for knowing where to intervene
  - **Quick check:** Does the intervention apply before or after the attention module in the target layer?

- **Concept:** Cosine Similarity
  - **Why needed:** Core metric for selecting directions without output text, measuring directional alignment rather than magnitude
  - **Quick check:** Why is cosine similarity preferred over Euclidean distance for comparing activation vectors?

- **Concept:** Difference-in-Means
  - **Why needed:** Technique for generating candidate directions by contrasting average activation states of two datasets
  - **Quick check:** What happens to the candidate direction if the "harmless" dataset contains prompts that trigger similar features to the "harmful" dataset?

## Architecture Onboarding

- **Component map:** Dataset Splitter -> Candidate Generator -> Layer Selector -> Scorer (COSMIC) -> Applier (LCE/ACE)
- **Critical path:** Selection of L_low layers (lowest 10% similarity) is the heuristic anchor; if irrelevant layers are selected, the scorer optimizes for noise
- **Design tradeoffs:** Generality vs precision - trades output-token matching precision for internal activation matching generality; heuristic dependency on lowest 10% similarity layers may miss refusal mechanisms
- **Failure signatures:** High KL divergence (>0.1) indicating destroyed model coherence; non-monotonic steering with oscillating behavior; false positives from last-token exploitation
- **First 3 experiments:** 1) Replicate baseline similarity plot to confirm L_low layers for target model 2) Apply COSMIC ablation to standard aligned model and measure ASR vs induced refusal rate 3) Force "complete refusal" and verify COSMIC can extract functional ablation direction

## Open Questions the Paper Calls Out

### Open Question 1
Do refusal behaviors follow linear, affine, or nonlinear representation structures, and does this vary by model architecture or training? Current experiments show inconsistent steering responses contradicting both linear and affine assumptions, but underlying geometry remains uncharacterized. Resolution requires systematic evaluation across diverse models with activation manifold analysis.

### Open Question 2
Can refusal directions from weakly aligned models be refined for reliable safety alignment without false refusals? Current COSMIC reduces ASR by 10-20% with minimal false refusals, but comprehensive safety comparable to trained alignment remains unproven. Resolution requires demonstrating consistent safety improvement across diverse adversarial benchmarks.

### Open Question 3
What is the optimal method for selecting evaluation layers, replacing the 10% lowest similarity heuristic? The heuristic lacks theoretical justification and may miss important layers. Resolution requires comparative analysis of alternative criteria showing improved steering performance.

### Open Question 4
Why do certain models exhibit asymmetric refusal steering (enabling induction but not ablation) and what determines model-specific steerability? Asymmetry suggests different encoding or incomplete extraction, but root cause is unidentified. Resolution requires layer-wise analysis of refusal circuitry in asymmetric models.

## Limitations
- Core assumptions may not generalize beyond instruction-tuned LLMs trained on standard refusal datasets
- Reliance on post-instruction tokens and L_low heuristic introduces potential brittleness if refusal occurs outside selected layers
- Performance on non-English languages, domain-specific models, or novel refusal strategies remains untested

## Confidence
- **High confidence:** Basic contrastive activation isolation mechanism is well-grounded and implementation details are clear
- **Medium confidence:** Inversion scoring mechanism works for tested models but generalizability to different architectures is uncertain
- **Low confidence:** Affine vs linear intervention distinction shows model-dependent results suggesting oversimplified geometric assumptions

## Next Checks
1. Test COSMIC on multilingual models using refusal prompts in languages other than English to verify activation-based approach generalizes beyond English training data

2. Apply COSMIC to transformer variants with different attention mechanisms (Mamba, RWKV) to determine whether method depends on specific architectural features

3. Design battery of jailbreak prompts targeting COSMIC-identified steering directions to measure exploitable blind spots or circumvention over time