---
ver: rpa2
title: 'Efficient Jailbreaking of Large Models by Freeze Training: Lower Layers Exhibit
  Greater Sensitivity to Harmful Content'
arxiv_id: '2502.20952'
source_url: https://arxiv.org/abs/2502.20952
tags:
- layers
- training
- harmful
- score
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study analyzes parameter distributions across layers of large
  language models to identify critical layers sensitive to harmful content generation.
  By conducting statistical analysis and computing a Comprehensive Sensitivity Score,
  it identifies lower layers as particularly sensitive to generating harmful content.
---

# Efficient Jailbreaking of Large Models by Freeze Training: Lower Layers Exhibit Greater Sensitivity to Harmful Content

## Quick Facts
- **arXiv ID:** 2502.20952
- **Source URL:** https://arxiv.org/abs/2502.20952
- **Reference count:** 35
- **Primary result:** Freeze training of lower layers reduces training duration and GPU memory consumption while maintaining high jailbreak success rates

## Executive Summary
This study presents a novel approach to efficiently jailbreak large language models by identifying and selectively fine-tuning sensitive layers rather than performing full-parameter training. Through statistical analysis of parameter distributions across layers, the research demonstrates that lower layers exhibit significantly greater sensitivity to harmful content generation. The proposed Freeze training strategy selectively updates only these sensitive lower layers while freezing higher layers, achieving comparable jailbreak success rates with dramatically reduced computational resources. The method was validated across multiple model architectures including Qwen2.5, GLM4, Llama3.1, Mistral, and Baichuan2.

## Method Summary
The research employs a two-phase approach: sensitivity analysis and selective fine-tuning. First, it calculates a Comprehensive Sensitivity Score for each layer by comparing parameter distributions between harmful and harmless content using t-tests and Cohen's d statistics. Lower layers with scores above 0.6 are identified as sensitive. The Freeze training strategy then performs supervised fine-tuning using only these sensitive layers (specifically the first 5 layers in the Front5 variant), freezing all other parameters. This is implemented using the LLaMA-Factory framework on a curated dataset of 50,000 harmful Q&A pairs, evaluating success through Attack Success Rate and Harm Score metrics.

## Key Results
- Lower layers consistently show higher sensitivity to harmful content generation across multiple model architectures
- Freeze-Front5-SFT achieves comparable jailbreak success rates while reducing training duration and GPU memory consumption by significant margins
- The approach outperforms full-parameter fine-tuning methods in efficiency metrics without sacrificing effectiveness
- The method demonstrates generalizability across diverse architectures including dense models from different providers

## Why This Works (Mechanism)
The approach works because lower layers in transformer architectures encode more general, task-agnostic features that are highly sensitive to content type shifts. When these layers are exposed to harmful prompts, their parameters adjust more dramatically than higher layers, which encode more task-specific and refined representations. By selectively fine-tuning only these sensitive layers, the model can adopt harmful generation capabilities while maintaining the computational efficiency of frozen higher layers that preserve general instruction-following capabilities.

## Foundational Learning
- **Comprehensive Sensitivity Score calculation**: Statistical measure combining t-test differences and Cohen's d to quantify layer sensitivity to harmful content
  - Why needed: Identifies which layers are most responsive to harmful prompt adaptation
  - Quick check: Verify score calculation matches the formula $S_{score} = \alpha \times Diff_{harmful} - \beta \times Diff_{harmless}$

- **Layer-wise parameter distribution analysis**: Comparing statistical properties of parameters across layers for different content types
  - Why needed: Reveals which layers change most significantly when adapting to harmful content
  - Quick check: Confirm lower layers show larger distributional shifts for harmful vs harmless content

- **Freeze training methodology**: Selective parameter updates where only specified layers are trainable while others remain frozen
  - Why needed: Enables computational efficiency by avoiding full-parameter optimization
  - Quick check: Verify gradient flow is blocked for frozen layers during training

- **Attack Success Rate (ASR) measurement**: Percentage of successful jailbreaks on harmful prompts
  - Why needed: Primary metric for evaluating jailbreak effectiveness
  - Quick check: Define clear criteria for what constitutes a successful jailbreak

- **Harm Score evaluation**: 1-5 scale measuring severity of harmful content generation
  - Why needed: Quantifies not just success but the degree of harmful output
  - Quick check: Ensure grading rubric is consistently applied across evaluations

- **Supervised Fine-Tuning (SFT) on curated datasets**: Training on labeled instruction-output pairs
  - Why needed: Standard approach for adapting models to specific behaviors
  - Quick check: Verify dataset formatting matches LLaMA-Factory requirements

## Architecture Onboarding

**Component Map:** Data Preparation -> Sensitivity Analysis -> Freeze Training -> Evaluation -> Comparison

**Critical Path:** The most time-sensitive components are Sensitivity Analysis (must be completed before training begins) and Freeze Training (the main computational bottleneck that benefits from the efficiency gains).

**Design Tradeoffs:** The approach trades potential performance gains from full fine-tuning against dramatic efficiency improvements. The key insight is that lower layers capture the most sensitive features for content adaptation, making full fine-tuning unnecessary for achieving jailbreak objectives.

**Failure Signatures:** Low ASR indicates insufficient training duration or incorrect layer freezing configuration. Catastrophic forgetting manifests as gibberish output or loss of instruction-following. OOM errors suggest inadequate GPU resources for even the reduced parameter set.

**First Experiments:**
1. Run sensitivity analysis on Qwen2.5-7B-Instruct to verify lower layers show $S_{score} > 0.6$
2. Implement Freeze-Front5-SFT with minimal dataset to test training pipeline functionality
3. Compare resource usage between Freeze training and full fine-tuning on small subset

## Open Questions the Paper Calls Out

The paper explicitly identifies three key open questions for future research: whether the sensitivity of lower layers generalizes to mixture-of-experts architectures, whether jailbreaks persist over extended interaction sequences due to potential self-correction mechanisms in higher layers, and how upstream and downstream dependencies between layers influence sensitivity scores when analyzed in isolation. These questions highlight limitations in the current study's scope and suggest directions for extending the analysis to more complex architectures and temporal dynamics.

## Limitations
- The study focuses on dense transformer architectures and does not examine mixture-of-experts models
- Experiments measure immediate jailbreak success without assessing long-term behavior or conversation depth
- The statistical methodology treats layers as independent units without accounting for cross-layer interactions
- Key hyperparameters (learning rate, batch size, epochs) are not fully specified, limiting reproducibility

## Confidence

| Claim | Confidence |
|-------|------------|
| Lower layers exhibit greater sensitivity to harmful content generation | High |
| Freeze training reduces training duration and GPU memory consumption | High |
| The approach outperforms full-layer fine-tuning methods | Medium |
| Method generalizes across multiple architectures | Medium |

## Next Checks
1. Replicate the Comprehensive Sensitivity Score analysis on the Qwen2.5-7B-Instruct model to verify that lower layers consistently show $S_{score} > 0.6$ for harmful content generation
2. Implement the Freeze-Front5-SFT training with varying learning rates (1e-5, 5e-5, 1e-4) to determine the optimal configuration that achieves both high ASR and computational efficiency
3. Compare the Freeze training approach against LoRA-based fine-tuning using identical datasets, training durations, and evaluation protocols to validate the claimed superiority