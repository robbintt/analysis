---
ver: rpa2
title: On Linear Representations and Pretraining Data Frequency in Language Models
arxiv_id: '2504.12459'
source_url: https://arxiv.org/abs/2504.12459
tags:
- country
- linear
- person
- pretraining
- causality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the relationship between pretraining data
  frequency and the emergence of linear representations in language models. The authors
  study how often subject-object pairs in factual relations co-occur in training data
  and find that linear representations form when these co-occurrences exceed specific
  frequency thresholds (e.g., 1k for subjects and 2k for objects).
---

# On Linear Representations and Pretraining Data Frequency in Language Models

## Quick Facts
- **arXiv ID:** 2504.12459
- **Source URL:** https://arxiv.org/abs/2504.12459
- **Reference count:** 40
- **Primary result:** Linear representations form in language models when subject-object pairs co-occur frequently in pretraining data, with specific frequency thresholds required for different model sizes.

## Executive Summary
This paper investigates the relationship between pretraining data frequency and the emergence of linear representations in language models. The authors study how often subject-object pairs in factual relations co-occur in training data and find that linear representations form when these co-occurrences exceed specific frequency thresholds (e.g., 1k for subjects and 2k for objects). They also show that this effect is independent of training stage and correlates strongly with in-context learning accuracy. Additionally, they demonstrate that measuring linear representation quality enables predicting term frequencies in pretraining data, even for unseen relations, using features like causality and faithfulness. The results suggest that manipulating training data frequency could control model behavior, and their tool for counting token co-occurrences supports further research in this area.

## Method Summary
The authors develop a method to measure whether language models encode factual relations as linear representations by extracting hidden states and computing Jacobian matrices that approximate the non-linear transformation. They introduce "causality" and "faithfulness" metrics to evaluate these linear representations, then correlate their quality with pretraining term frequencies measured through a custom Batch Search tool that counts subject-object co-occurrences. The study uses multiple model scales (OLMo-1B, OLMo-7B, GPT-J) and tests on various factual relations to establish frequency thresholds and develop a regression model that predicts pretraining frequencies from LRE quality features.

## Key Results
- Linear representations form when subject-object pairs co-occur above specific frequency thresholds (1-2k for 7B models, 4-5k for 1B models)
- Causality scores for LREs correlate strongly with pretraining co-occurrence frequency (r=0.82)
- LRE quality features can predict pretraining term frequencies with ~70% accuracy, even for unseen relations
- The frequency threshold for linear representation formation scales inversely with model size

## Why This Works (Mechanism)

### Mechanism 1: Frequency-Induced Linearization
- **Claim:** If subject-object pairs co-occur frequently in pretraining, the model is likely to encode their relationship as a linear direction in activation space.
- **Mechanism:** High co-occurrence frequency acts as a strong statistical signal, encouraging the optimizer to compress the relational mapping (subject $\to$ object) into a linear representation (LRE) to efficiently minimize loss.
- **Core assumption:** Repeated exposure forces the model to settle on a linear solution rather than a complex non-linear one for relational recall.
- **Evidence anchors:**
  - [abstract]: "formation of linear representations is strongly connected to pretraining term frequencies."
  - [section 4.2]: "Co-occurrence frequencies highly correlate with causality (r = 0.82)."
  - [corpus]: "Provable Low-Frequency Bias of In-Context Learning" supports that low-frequency concepts struggle to form stable representations.
- **Break condition:** If co-occurrence counts drop below the model-size-dependent threshold (e.g., <1k for 7B models), linear representations consistently fail to form.

### Mechanism 2: LRE Metrics as Frequency Proxies
- **Claim:** If a linear representation exists, its specific geometric properties (causality and faithfulness) can be decoded to estimate the original pretraining term frequency.
- **Mechanism:** The "steepness" or consistency of the linear map (measured by "Hard Causality") scales with the number of times the model has seen the data, allowing a regression model to map LRE quality back to corpus counts.
- **Core assumption:** The model does not saturate its representation quality early; it continues to refine the linear structure as frequency increases.
- **Evidence anchors:**
  - [section 5.2]: "LRE features encode a strong signal allowing for accurate predictions about 70% of the time."
  - [table 1]: Regression generalizes across models (OLMo $\to$ GPT-J) using LRE features but not log-probs alone.
  - [corpus]: Evidence is weak in immediate neighbors; this specific predictive direction appears novel to this paper.
- **Break condition:** If the relation is low-frequency (e.g., "star constellation"), the signal is too noisy for accurate regression prediction (Section 5.4).

### Mechanism 3: Scaling-Dependent Frequency Thresholds
- **Claim:** The specific co-occurrence count required to trigger a linear representation decreases as model size increases.
- **Mechanism:** Larger models have higher capacity, allowing them to form robust linear representations from fewer examples compared to smaller models which require more repetition to "memorize" the structure.
- **Core assumption:** The "linear representation hypothesis" holds better for larger models with more dimensions.
- **Evidence anchors:**
  - [section 4.2]: OLMo-1B requires ~4.4k co-occurrences, while OLMo-7B and GPT-J (6B) require only ~1k-2k.
  - [abstract]: Mentions "regardless of when these occurrences happen," implying a total count threshold is key.
- **Break condition:** If the model is under-parameterized for the task complexity, no amount of frequency may induce a clean linear representation (though this specific break condition is less explored in the text).

## Foundational Learning

- **Concept: Linear Relational Embeddings (LREs)**
  - **Why needed here:** This is the core metric used to determine if a model has learned a fact "linearly." You must understand that an LRE attempts to approximate the model's non-linear forward pass for a relation (e.g., "plays instrument") using a single affine transformation ($Ws + b$).
  - **Quick check question:** Can you calculate the Jacobian matrix for a small model layer to understand how $W$ is derived?

- **Concept: Causality vs. Faithfulness**
  - **Why needed here:** The paper distinguishes between "faithfulness" (does the LRE predict the right token?) and "causality" (can we intervene with the LRE to *change* the prediction?). High correlation with frequency is primarily driven by **causality**.
  - **Quick check question:** If an LRE has high faithfulness but low causality, what does that imply about the model's internal computation?

- **Concept: Co-occurrence vs. Memorization**
  - **Why needed here:** The paper argues that co-occurrence is a proxy for the "mention" of a fact, distinct from exact text memorization.
  - **Quick check question:** Why is counting subject-object pairs in a sequence (Batch Search) preferred over exact phrase matching for this analysis?

## Architecture Onboarding

- **Component map:**
  1. Batch Search Tool: Custom Cython tool to count token co-occurrences in pretraining batches (Input: Dolma/Pile; Output: Counts).
  2. LRE Fitting Module: Extracts hidden states and computes the Jacobian ($W, b$) using 8 examples (Input: Relations dataset; Output: LRE $W$).
  3. Evaluation Suite: Computes Faithfulness/Causality scores for LREs.
  4. Frequency Predictor: Random Forest regression mapping LRE metrics $\to$ Log frequency.

- **Critical path:**
  1. Select a relation (e.g., "country-capital") and run **Batch Search** to get ground-truth counts.
  2. Fit an **LRE** on 8 examples from that relation using the model's hidden states.
  3. Measure **Causality** (intervention success) and correlate with the counts from step 1.

- **Design tradeoffs:**
  - **LRE Fitting Data:** The paper shows you can fit LREs on examples the model gets *incorrect* without significant performance drop (Appendix B). This allows analyzing early checkpoints where the model is incompetent.
  - **Layer Selection:** You must sweep layers to find the "linear" sweet spot; early layers are too raw, late layers too non-linear.

- **Failure signatures:**
  - **High Accuracy / Low Causality:** The model predicts correctly via non-linear memorization or heuristics (common in low-frequency or "star constellation" relations).
  - **Regression Failure:** If the regression predicts uniform frequencies, the LRE features likely lack variance (check if hard causality is near 0).

- **First 3 experiments:**
  1. Reproduce the Threshold Plot: Run the LRE analysis on OLMo-1B vs. 7B checkpoints to visualize the 4k vs. 2k co-occurrence threshold (Figure 2).
  2. Cross-Model Frequency Prediction: Train the regression on OLMo LRE features and test on GPT-J to verify generalization (Table 1).
  3. Ablate Example Choice: Fit LREs using only "correct" vs. "incorrect" examples for a specific relation and compare causality scores to verify the "incorrect example" robustness claim.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What computational mechanisms do language models use to solve factual recall tasks for relations that achieve high accuracy but fail to form consistent linear representations?
- Basis in paper: [explicit] The authors note in Section 4.3 that "it is still an open question how LMs are able to recall these tasks," specifically citing relations like "star constellation name" which exhibit high few-shot accuracy but low LRE causality.
- Why unresolved: Current interpretability tools focus on linear approximations; identifying complex, non-linear circuits for specific low-frequency relations is difficult and was outside the scope of this frequency analysis.
- What evidence would resolve it: Mechanistic circuit analysis targeting relations with high accuracy/low linearity to identify non-linear sub-networks or "lookup table" behaviors.

### Open Question 2
- Question: To what extent does the specific linguistic context or template used to present a fact influence the formation and quality of its linear representation?
- Basis in paper: [explicit] The authors state in the Limitations section: "We also do not discuss the role of the presentation of facts on the formation of LRE features," though they speculate the impact is minimal based on correlation strength.
- Why unresolved: The study relies on subject-object co-occurrence counts as a proxy for relation frequency without controlling for the syntactic diversity or specific templates in which these pairs appear.
- What evidence would resolve it: A controlled study varying the frequency of specific relational templates (e.g., "X is the capital of Y" vs. "X, the capital of Y,") while keeping subject-object co-occurrence constant to measure the impact on LRE formation.

### Open Question 3
- Question: Does the specific timing or distribution of term exposure during pretraining causally determine the formation of linear representations, independent of total frequency?
- Basis in paper: [explicit] The authors state in the Limitations: "We can not draw causal claims about how exposure affects individual representations, due to the cost of counterfactual pretraining."
- Why unresolved: Observational analysis of standard pretraining checkpoints cannot isolate frequency as a causal variable from other simultaneous optimization dynamics or data distribution shifts.
- What evidence would resolve it: Intervention studies involving counterfactual pretraining runs where specific subject-object pairs are injected at varying intervals or frequencies to isolate their causal effect on representation geometry.

## Limitations

- The paper relies on co-occurrence frequency as a proxy for factual knowledge exposure, but doesn't fully resolve whether sequence-level or document-level counting methods better capture the signal driving linear representation formation.
- The generalizability of the LRE quality â†’ frequency regression is limited to tested relation types and doesn't extend to non-factual knowledge domains.
- The claim that linear representations form "regardless of when these occurrences happen" during pretraining is not empirically validated through timing-controlled experiments.

## Confidence

**High Confidence:**
- The existence of a minimum frequency threshold for linear representation formation (1-2k co-occurrences for 7B models)
- The strong correlation (r=0.82) between causality and co-occurrence frequency within the tested relation types

**Medium Confidence:**
- The claim that frequency thresholds scale inversely with model size
- The ability to predict term frequencies using LRE features

**Low Confidence:**
- The assertion that linear representations form "regardless of when these occurrences happen" during pretraining
- The broader implication that manipulating pretraining data frequency could "control model behavior"

## Next Checks

1. **Sequence vs. Document Frequency Validation:** Replicate the causality-frequency correlation analysis using both Batch Search (sequence-level) and WIMBD (document-level) counting methods on the same relations. Quantify the systematic difference and test whether the correlation remains significant with document-level counts after appropriate normalization.

2. **Out-of-Distribution Relation Testing:** Apply the frequency prediction regression model to relations outside the standard factual knowledge set (e.g., "emotional reaction-cause" or "procedural step sequences"). Measure whether LRE features still predict frequencies above chance and whether the causality-frequency correlation holds for these relation types.

3. **Early vs. Late Co-occurrence Timing:** Design an experiment that controls when subject-object pairs appear during pretraining (e.g., all co-occurrences in first 10% vs. last 10% of training data). Test whether the same frequency threshold applies regardless of timing, or whether early exposure is more effective at inducing linear representations.