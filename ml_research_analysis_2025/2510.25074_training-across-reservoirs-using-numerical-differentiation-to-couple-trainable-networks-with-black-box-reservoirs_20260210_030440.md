---
ver: rpa2
title: 'Training Across Reservoirs: Using Numerical Differentiation To Couple Trainable
  Networks With Black-Box Reservoirs'
arxiv_id: '2510.25074'
source_url: https://arxiv.org/abs/2510.25074
tags:
- bond
- black-box
- which
- reservoir
- gradient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: BOND enables end-to-end training of hybrid architectures combining
  neural networks with black-box functions by leveraging local computational graphs
  and adaptively bounded perturbations. Unlike existing zeroth-order methods that
  scale with parameter space, BOND scales only with black-box input dimensionality,
  achieving convergence comparable to automatic differentiation.
---

# Training Across Reservoirs: Using Numerical Differentiation To Couple Trainable Networks With Black-Box Reservoirs

## Quick Facts
- arXiv ID: 2510.25074
- Source URL: https://arxiv.org/abs/2510.25074
- Reference count: 40
- One-line primary result: BOND enables end-to-end training of hybrid architectures combining neural networks with black-box functions by leveraging local computational graphs and adaptively bounded perturbations.

## Executive Summary
BOND introduces a novel method for training hybrid neural network architectures that incorporate black-box functions, such as untrained reservoirs or pre-trained models with unknown gradients. The approach uses numerical differentiation with adaptive perturbation bounds to estimate gradients for the black-box components while maintaining end-to-end trainability of the network. This enables researchers to experiment with unconventional reservoir architectures without requiring full differentiability or retraining of the black-box components.

The method achieves convergence comparable to automatic differentiation while scaling only with the input dimensionality of the black-box function rather than the entire network parameter space. Experimental results on California House Price, FashionMNIST, CIFAR10, and CIFAR100 datasets demonstrate that embedding black-box functions can improve performance without increasing the number of trainable parameters, with accuracy gains of up to 0.51% on CIFAR100 and 1.11% on California House Price data.

## Method Summary
BOND leverages local computational graphs to isolate the black-box function from the trainable network, then uses numerical differentiation with adaptive perturbation bounds to estimate gradients for the black-box component. The key insight is that instead of requiring gradients for all network parameters (O(dθ)), the method only needs to estimate gradients for the black-box input space (O(dR)), where dR is typically much smaller than dθ. This is achieved by perturbing inputs to the black-box function and observing output changes, then using these finite difference approximations to update both the black-box and network parameters through backpropagation. The adaptive perturbation bounds help maintain numerical stability while ensuring accurate gradient estimation.

## Key Results
- BOND scales gradient estimation complexity from O(dθ) to O(dR), where dR ≪ dθ
- Accuracy improvements of up to 0.51% on CIFAR100 and 1.11% on California House Price data
- Computational overhead of 40x more forward passes compared to conventional backpropagation
- Maintains convergence comparable to automatic differentiation despite using numerical methods

## Why This Works (Mechanism)
BOND works by creating a computational graph that treats the black-box function as a differentiable node through numerical gradient estimation. The method uses finite difference approximations with carefully chosen perturbation sizes to estimate how changes in the black-box inputs affect outputs. By bounding these perturbations adaptively, the approach maintains numerical stability while ensuring that the gradient estimates remain accurate enough for effective optimization. The key mechanism is that backpropagation can flow through the numerical differentiation step, allowing both the network and black-box components to be updated jointly during training.

## Foundational Learning

**Finite Difference Approximation**: Estimates gradients by evaluating function outputs at slightly perturbed inputs. Why needed: Provides a way to approximate derivatives when analytical gradients are unavailable. Quick check: Verify that the approximation error decreases as perturbation size approaches zero.

**Computational Graph Construction**: Creates local subgraphs that isolate black-box components while maintaining differentiability. Why needed: Enables backpropagation through hybrid architectures containing non-differentiable elements. Quick check: Confirm that the graph correctly captures all dependencies between network and black-box components.

**Adaptive Perturbation Bounds**: Dynamically adjusts perturbation sizes based on local function behavior. Why needed: Prevents numerical instability while maintaining gradient accuracy. Quick check: Monitor that perturbation sizes remain within stable ranges throughout training.

**Gradient Flow Through Numerical Operations**: Allows backpropagation to pass through finite difference computations. Why needed: Enables joint optimization of both network and black-box components. Quick check: Verify that gradients propagate correctly through the numerical differentiation layer.

**Complexity Reduction Analysis**: Demonstrates that gradient estimation scales with black-box input dimension rather than total network parameters. Why needed: Shows computational efficiency gains over naive approaches. Quick check: Compare actual computation counts against theoretical complexity bounds.

## Architecture Onboarding

**Component Map**: Input Data -> Neural Network -> Black-Box Function -> Output Layer -> Loss Function

**Critical Path**: The critical computation path flows through the neural network to produce inputs for the black-box function, then through the black-box function to produce outputs that feed into the final layers and loss calculation. The numerical differentiation occurs at the boundary between the network and black-box function.

**Design Tradeoffs**: The method trades computational efficiency (40x more forward passes) for the ability to incorporate non-differentiable components. This allows greater architectural flexibility but at significant computational cost. The adaptive perturbation bounds provide a balance between numerical stability and gradient accuracy.

**Failure Signatures**: Poor convergence may indicate that perturbation sizes are too large or small, causing inaccurate gradient estimates. High computational overhead without performance gains suggests the black-box function isn't providing useful regularization or feature transformation. Vanishing gradients through the numerical differentiation layer could indicate numerical instability.

**First Experiments**:
1. Test BOND with a simple sine wave black-box function to verify gradient flow and convergence
2. Compare BOND against standard backpropagation on a fully differentiable network to establish baseline performance
3. Evaluate BOND with different perturbation strategies (fixed vs adaptive) to assess impact on convergence

## Open Questions the Paper Calls Out
None

## Limitations
- Significant computational overhead requiring 40x more forward passes than conventional backpropagation
- Limited experimental validation on small-scale problems; scalability to larger architectures untested
- Small performance gains (0.51% on CIFAR100) may not justify computational costs in all scenarios

## Confidence

High confidence: Theoretical foundation leveraging local computational graphs and adaptive perturbation bounds is mathematically sound, with well-established finite difference approximation framework reducing complexity from O(dθ) to O(dR).

Medium confidence: Empirical results showing performance improvements are based on limited experimental validation and may be sensitive to hyperparameter choices or dataset characteristics, with relatively small accuracy gains that might not justify computational overhead.

Low confidence: Claims about unique positioning among existing methods lack comparative analysis with alternative hybrid architecture approaches, and don't adequately address whether similar results could be achieved through different means.

## Next Checks

1. Conduct large-scale experiments on industrial-sized datasets and architectures to verify whether computational overhead remains manageable and whether performance improvements scale with problem complexity.

2. Perform ablation studies to quantify individual contributions of each component in the BOND framework, particularly the impact of adaptive perturbation bounds versus fixed-step approaches.

3. Compare BOND's performance against alternative hybrid architecture methods that don't require extensive perturbation-based gradient estimation, including both zeroth-order optimization techniques and approaches leveraging partial differentiability of black-box components.