---
ver: rpa2
title: A Study on Inference Latency for Vision Transformers on Mobile Devices
arxiv_id: '2510.25166'
source_url: https://arxiv.org/abs/2510.25166
tags:
- latency
- vits
- mobile
- memory
- inference
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive analysis of vision transformer
  (ViT) inference latency on mobile devices, comparing 190 real-world ViTs with 102
  CNNs across six mobile platforms and two ML frameworks. The study reveals that ViTs
  generally exhibit higher latency than CNNs with similar FLOPs due to self-attention
  mechanisms and GELU activation functions.
---

# A Study on Inference Latency for Vision Transformers on Mobile Devices

## Quick Facts
- arXiv ID: 2510.25166
- Source URL: https://arxiv.org/abs/2510.25166
- Reference count: 36
- This paper presents a comprehensive analysis of vision transformer (ViT) inference latency on mobile devices, comparing 190 real-world ViTs with 102 CNNs across six mobile platforms and two ML frameworks.

## Executive Summary
This study comprehensively analyzes vision transformer inference latency on mobile devices by profiling 190 real-world ViTs against 102 CNNs across six platforms and two ML frameworks. The research reveals that ViTs consistently exhibit higher latency than CNNs with similar FLOPs due to self-attention mechanisms and GELU activation functions. Memory consumption and arithmetic intensity emerge as key bottlenecks for ViTs on mobile hardware. Based on these insights, the authors construct a dataset of 1000 synthetic ViTs with representative building blocks and state-of-the-art architectures, demonstrating that simple ML predictors can estimate ViT inference latency with errors of 4.4-8.2% for synthetic models and 6.1-8.2% for real-world models.

## Method Summary
The study profiles 190 real-world ViTs and 102 CNNs on six mobile platforms using PyTorch Mobile and TFLite, extracting operation-level features (FLOPs, memory formats, shapes) to train per-operation latency predictors. The authors generate 1000 synthetic ViTs from a defined search space covering embedding lengths, token mixers, and input sizes, using 900 for training and 100 for validation. Per-operation latency is predicted using GBDT and Random Forest models, with end-to-end latency computed as the sum of individual operation predictions. The synthetic dataset aims to represent the real-world ViT distribution for neural architecture search applications.

## Key Results
- ViTs exhibit higher latency than CNNs with similar FLOPs on mobile devices due to self-attention and GELU operations
- Memory consumption and arithmetic intensity are identified as primary bottlenecks for ViTs on mobile hardware
- ML predictors trained on synthetic ViTs achieve 4.4-8.2% MAPE on synthetic test sets and 6.1-8.2% MAPE on real-world ViTs

## Why This Works (Mechanism)
The study's approach works because it decomposes the complex latency prediction problem into per-operation predictions, leveraging the fact that mobile inference latency is dominated by specific operations (Conv, Linear, Attention) rather than global architectural choices. By profiling real models to identify bottlenecks and generating synthetic data that captures the design space, the method creates a representative training distribution. The use of simple ML models like GBDT and Random Forest is effective because latency prediction benefits from capturing non-linear relationships between operation configurations and execution time on specific hardware.

## Foundational Learning

**Vision Transformer Architecture**: Understanding ViT components (patch embedding, self-attention, MLP blocks) is needed to identify latency bottlenecks. Quick check: Can you trace data flow through a ViT layer?

**Mobile ML Frameworks**: Knowledge of PyTorch Mobile and TFLite optimization pipelines is crucial since latency depends on framework-specific implementations. Quick check: What backend (XNNPACK, QNNPACK) does your framework use?

**Arithmetic Intensity**: The ratio of FLOPs to memory access determines computational efficiency on mobile hardware. Quick check: Calculate arithmetic intensity for Conv vs Attention operations.

**GELU Activation**: Input-dependent latency requires special handling in predictors. Quick check: How does GELU latency scale with input tensor size?

## Architecture Onboarding

**Component Map**: Model Graph -> Operation Extraction -> Feature Engineering -> Per-Operation Predictors -> End-to-End Latency

**Critical Path**: The latency prediction pipeline follows: parse model → extract operation features → predict per-operation latency → sum for total latency. The most critical components are accurate feature extraction and proper handling of framework-specific optimizations.

**Design Tradeoffs**: Synthetic data generation balances coverage of design space against representativeness of real-world architectures. The paper chose 1000 synthetic models to cover embedding lengths (16-1024), token mixers (SepConv/Attention), and input sizes (224/256), accepting potential distribution mismatch for broader search space coverage.

**Failure Signatures**: High prediction errors on GELU operations indicate insufficient input-dependent features. Large generalization gaps between synthetic and real-world test errors suggest the search space doesn't capture real-world architectural patterns. Framework version mismatches can cause systematic latency prediction biases.

**Three First Experiments**:
1. Profile a small set of real ViTs and CNNs to verify the reported latency trends and identify operation-level bottlenecks.
2. Generate a minimal synthetic dataset (50 models) and train predictors to test the feature engineering pipeline.
3. Compare predictions from different ML frameworks (PyTorch Mobile vs TFLite) on the same models to quantify framework impact.

## Open Questions the Paper Calls Out
None

## Limitations
- Synthetic ViTs may not fully represent real-world architectural patterns, leading to generalization gaps in latency prediction
- Exact feature engineering details and hyperparameters for ML predictors are not specified, limiting reproducibility
- Framework and library versions significantly impact latency measurements but are not precisely documented

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| ViTs exhibit higher latency than CNNs with similar FLOPs | High |
| Memory consumption and arithmetic intensity are key bottlenecks | High |
| Synthetic dataset enables accurate latency prediction | Medium |
| Simple ML predictors achieve "highly accurate" estimation | Low |

## Next Checks

1. **Feature Engineering Validation**: Reconstruct the exact feature set and preprocessing pipeline by comparing synthetic test set error with and without ViT-specific features (self-attention dimensions, GELU input shapes).

2. **Synthetic-to-Real Transfer Analysis**: Evaluate synthetic dataset coverage by clustering operations from synthetic and real-world ViTs, measuring the proportion of real-world operation configurations outside the synthetic training distribution.

3. **Framework Version Impact Study**: Reproduce latency measurements using different versions of PyTorch Mobile and TFLite (e.g., v1.12 vs v2.0) on the same hardware to quantify framework optimization impact on reported latency ratios.