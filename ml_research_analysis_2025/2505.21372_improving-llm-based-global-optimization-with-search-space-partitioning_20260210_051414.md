---
ver: rpa2
title: Improving LLM-based Global Optimization with Search Space Partitioning
arxiv_id: '2505.21372'
source_url: https://arxiv.org/abs/2505.21372
tags:
- hollm
- optimization
- function
- number
- global
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HOLLM, a novel hierarchical global optimization
  algorithm that leverages Large Language Models (LLMs) for blackbox function optimization.
  HOLLM addresses the challenge of LLM-based sampling in high-dimensional spaces by
  partitioning the search space into promising subregions using a KD-tree, where each
  subregion acts as a "meta-arm" selected via a bandit-inspired scoring mechanism.
---

# Improving LLM-based Global Optimization with Search Space Partitioning

## Quick Facts
- **arXiv ID:** 2505.21372
- **Source URL:** https://arxiv.org/abs/2505.21372
- **Reference count:** 40
- **Primary result:** HOLLM matches or surpasses leading global optimization methods by partitioning search space into promising subregions selected via bandit-inspired scoring.

## Executive Summary
This paper introduces HOLLM, a hierarchical global optimization algorithm that leverages Large Language Models (LLMs) for blackbox function optimization. The key innovation addresses LLM sampling bias in high-dimensional spaces by partitioning the search space into promising subregions using a KD-tree, where each subregion acts as a "meta-arm" selected via a bandit-inspired scoring mechanism. Within each selected subregion, an LLM proposes high-quality candidate points without requiring domain-specific priors. Empirical evaluations demonstrate that HOLLM consistently matches or surpasses leading global optimization methods while substantially outperforming global LLM-based sampling strategies.

## Method Summary
HOLLM operates through a five-step iterative loop: (1) Partition the search space into K leaves using a KD-tree with maximum leaf size m₀=⌈d/2⌉, splitting on highest-variance dimension at median; (2) Score each partition using a composite function combining maximum observed value, geometric volume, and UCB-V variance terms; (3) Select M=5 regions via stochastic sampling based on scores; (4) Generate k=5 candidates per region using LLM with partition bounds and in-context examples; (5) Evaluate top b=4 candidates by LLM-predicted scores and add to history. The method uses cosine annealing for exploration weight α_t and partitions rebuild each iteration.

## Key Results
- HOLLM consistently matches or surpasses leading global optimization methods on synthetic functions, hyperparameter optimization, and real-world tasks.
- Substantially outperforms global LLM-based sampling strategies, particularly in multimodal functions and complex landscapes.
- Effectively balances exploration and exploitation through UCB-V inspired scoring mechanism.

## Why This Works (Mechanism)

### Mechanism 1
LLM sampling quality degrades as search space volume increases relative to samples; partitioning into smaller subregions improves proposal diversity and relevance. By constraining the LLM to propose points within smaller hyperrectangles, the model operates in reduced ranges per dimension, making relative differences between candidate values more salient and reducing clustering behavior observed in global LLM sampling.

### Mechanism 2
The UCB-V inspired scoring function B_ℓ,t = μ̄_ℓ,t + α_t(β₁V̄_ℓ,t + β₂E_ℓ,t) provides principled exploration-exploitation balance by combining empirical best values (max, not mean), geometric volume (d-th root favors large under-explored regions), and variance-aware uncertainty (favors high-uncertainty regions relative to sample count). The α_t cosine annealing schedule gradually shifts from exploration-heavy to exploitation-heavy.

### Mechanism 3
LLMs encode a "meta-prior" about optimization landscapes from pre-training on optimization literature and scientific data, enabling effective candidate generation when provided with localized context and historical examples. The LLM receives partition boundaries and historical (x, f(x)) pairs as in-context examples, leveraging pattern recognition from pre-training rather than explicit probabilistic modeling.

## Foundational Learning

- **Multi-Armed Bandits & UCB**
  - Why needed here: HOLLM treats each partition as a "meta-arm" and uses UCB-V style scoring; understanding exploration-exploitation tradeoffs is essential for tuning α_t, β₁, β₂.
  - Quick check question: Given three arms with mean rewards [0.8, 0.6, 0.4] and sample counts [100, 10, 5], which would a UCB1 policy select? What if variance estimates were [0.01, 0.2, 0.5]?

- **KD-Tree Data Structure**
  - Why needed here: HOLLM rebuilds the KD-tree each iteration to partition search space; understanding split criteria and leaf capacity constraints is necessary for debugging partition behavior.
  - Quick check question: In a 3D space with points clustered along the x-axis, how would a variance-based KD-tree split differ from a median-based split after 20 iterations?

- **In-Context Learning in LLMs**
  - Why needed here: HOLLM relies on LLMs generating candidates from in-context examples; understanding how example ordering, quantity, and format affect output quality helps debug poor proposals.
  - Quick check question: If an LLM receives 5 in-context examples with f(x) values [10, 9, 8, 7, 6] and is asked to propose new points, what implicit assumption might it make about the objective function landscape?

## Architecture Onboarding

- **Component map:**
  Initial Data → LOOP: PARTITION (KD-tree → K leaves) → SCORE (μ̄, V̄, E → B_ℓ) → SELECT (sample M leaves) → SAMPLE (LLM_GENERATE → k proposals) → EVALUATE (rank by predicted, evaluate top b) → Return best

- **Critical path:**
  1. Verify KD-tree partitions cover full space and respect bounds (empty cells get high exploration scores by default)
  2. Confirm score normalization preserves relative weights when K_t changes between iterations
  3. Validate LLM prompt construction includes global history + local bounds
  4. Check candidate filtering: exactly b points evaluated per iteration, selected from k×M proposals by predicted value

- **Design tradeoffs:**
  - Leaf capacity m₀: Lower values create finer partitions for precise exploitation but risk sparse leaves with unreliable variance estimates; higher values coarsen partitions and may group dissimilar regions. Default d/2.
  - Candidates per region k: Low k=1 under-exploits promising regions; high k=10 wastes budget on suboptimal regions early. Default k=5 with M=5 (25 total proposals/iteration).
  - Exploration weight α_max: Higher values (1.0) favor diverse exploration for multimodal landscapes; lower values (0.2) accelerate exploitation on smoother functions. Task-dependent tuning required.

- **Failure signatures:**
  - Stagnation at local optimum: α_min too high or annealing too slow; check if α_t reaches ~0.01 by final iterations
  - Excessive variance between runs: Partition selection too stochastic; reduce M or increase k to stabilize proposals per iteration
  - LLM generates out-of-bounds candidates: Prompt validation failing; verify bounding box formatting
  - Partitions don't refine around optima: m_t growing too fast; check λ parameter (default 0) and ensure tree rebuilds each iteration

- **First 3 experiments:**
  1. **Sanity check on 2D quadratic:** Run HOLLM on f(x₁,x₂) = -x₁² - x₂² with 20 iterations, visualize partitions. Expected: partitions should concentrate near origin (0,0).
  2. **Ablation on leaf capacity:** On 10D Levy, compare m₀ ∈ {d/4, d/2, d, 2d} with all other defaults fixed. Expected: d/4 or d/2 should outperform coarser settings.
  3. **Baseline comparison on real task:** Run HOLLM vs. Global-LLM vs. GP-EI on Vehicle Safety (5D) for 50 iterations, 5 seeds. Expected: HOLLM > Global-LLM > GP-EI.

## Open Questions the Paper Calls Out

- **Question:** Can formal regret bounds be derived for HOLLM, particularly given the dynamic nature of its KD-tree partitioning which is refitted at every round?
  - **Basis in paper:** "Finally, our approach currently lacks formal theoretical guarantees, especially regarding regret bounds, which we leave for the future."
  - **Why unresolved:** Standard hierarchical bandit algorithms typically rely on fixed tree structures; HOLLM re-fits the KD-tree at each iteration, changing the partitions (arms) dynamically based on the data history, which complicates theoretical analysis.
  - **What evidence would resolve it:** A theoretical derivation showing simple or cumulative regret bounds for the algorithm, specifically accounting for the time-varying number of leaves K_t and the specific UCB-V scoring mechanism used.

- **Question:** Does the axis-aligned KD-tree partitioning strategy generalize effectively to purely discrete or categorical search spaces compared to continuous domains?
  - **Basis in paper:** The authors note that in the FCNet hyperparameter optimization task (discrete space), "the benefit of using space partitioning in this task is less pronounced... probably due to the discrete nature of the search space."
  - **Why unresolved:** While HOLLM excels on continuous benchmarks, the empirical results suggest the gains are smaller on discrete tasks, potentially due to the mismatch between continuous KD-tree splits and the actual structure of the categorical search space.
  - **What evidence would resolve it:** A dedicated ablation study comparing HOLLM's performance on high-dimensional discrete tasks against continuous tasks of similar complexity, or an analysis comparing KD-tree splits against discrete-specific partitioning methods.

- **Question:** How does the algorithm's performance scale with dimensionality and LLM inference costs in very high-dimensional settings (e.g., > 50 dimensions)?
  - **Basis in paper:** "Limitations" section mentions that "inference and monetary cost of LLMs... can limit scalability in high-dimensional settings," and the empirical evaluation is limited to dimensions ≤ 20.
  - **Why unresolved:** While the paper demonstrates success on synthetic functions up to 20D and real-world tasks up to 9D, it is unclear if the method remains sample-efficient or cost-effective compared to methods like TuRBO in significantly higher dimensions where LLM biases might re-emerge.
  - **What evidence would resolve it:** Empirical results on standard high-dimensional benchmarks (e.g., 50D+ or 100D+ synthetic functions) including a cost analysis comparing LLM API calls/inference time against the performance of traditional surrogate-based methods.

## Limitations

- The paper's claim that LLM meta-priors significantly outperform explicit surrogate models like GP-EI remains largely theoretical, with the mechanism of LLM "pattern recognition" from pre-training lacking rigorous validation.
- Partitioning strategy assumes objective functions have reasonably local structure; for highly non-local or deceptive functions, the KD-tree may create misleading subregions that fragment the search space.
- The UCB-V scoring weights (β₁, β₂) are not systematically tuned across tasks, leaving open questions about whether reported performance generalizes or depends on fortuitous hyperparameter choices.

## Confidence

- **High confidence:** KD-tree partitioning improves LLM sampling coverage compared to global prompting (supported by Hausdorff distance experiments and ablation studies).
- **Medium confidence:** The composite scoring function balances exploration-exploitation better than pure exploitation or exploration variants (ablated in Figure 8b, but component weights β₁, β₂ not independently validated).
- **Low confidence:** LLM meta-priors provide unique value beyond partitioning alone (claimed based on HOLLM outperforming KDTree+GP, but LLM "meta-prior" mechanism remains largely asserted rather than empirically established).

## Next Checks

1. **Validate partitioning-LLM interaction:** Compare HOLLM against a variant where LLM receives the same local context but uses random sampling within partitions (eliminating "meta-prior" claim) on Hartmann 6D and Rastrigin 10D.

2. **Stress-test UCB-V components:** Run ablation with β₁=0.2, 0.5, 0.8 on Levy 10D to verify exploration-exploitation balance is robust across different function modalities.

3. **Test against adversarial landscapes:** Evaluate HOLLM on a synthetic function with deceptive local optima and non-local structure to assess partitioning assumptions under failure conditions.