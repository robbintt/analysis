---
ver: rpa2
title: Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation
  Projection
arxiv_id: '2508.15449'
source_url: https://arxiv.org/abs/2508.15449
tags:
- unlearning
- score
- projection
- performance
- retain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces Metamorphosis Representation Projection
  (MRP), a novel approach to machine unlearning in large language models. The method
  addresses two key limitations of existing unlearning techniques: inability to handle
  continuous unlearning requests and vulnerability to relearning attacks.'
---

# Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection

## Quick Facts
- arXiv ID: 2508.15449
- Source URL: https://arxiv.org/abs/2508.15449
- Reference count: 40
- Unlearning performance score of 0.905 after four unlearn tasks (baseline best 0.785)

## Executive Summary
This paper introduces Metamorphosis Representation Projection (MRP), a novel approach to machine unlearning in large language models that addresses critical limitations of existing methods. MRP tackles two fundamental challenges: handling continuous unlearning requests and resisting relearning attacks. The method achieves these goals by projecting model representations onto orthogonal complement spaces of unlearn data, requiring training of only 0.1M parameters while maintaining high unlearning effectiveness.

The approach demonstrates significant improvements over baseline methods, achieving superior stability with average standard deviation of 0.028 compared to baselines' 0.050+. MRP maintains QA accuracy of 0.383 on unlearn tasks after five relearning epochs, substantially better than baseline methods' 0.506. The method uses PCA and QR decomposition to initialize projection matrices, enabling efficient orthogonal projection of representations to forget specified harmful information.

## Method Summary
Metamorphosis Representation Projection (MRP) addresses machine unlearning limitations by projecting model representations onto orthogonal complement spaces of unlearn data. The method initializes projection matrices using PCA to identify principal components of unlearn data representations, then applies QR decomposition to obtain orthogonal bases. During inference, input representations are projected onto these orthogonal spaces, effectively removing information patterns associated with harmful content. The approach requires training only 0.1M parameters, making it highly parameter-efficient while maintaining effectiveness across multiple unlearning tasks.

## Key Results
- Unlearning performance score of 0.905 after four unlearn tasks (baseline best: 0.785)
- QA accuracy maintenance of 0.383 on unlearn tasks after five relearning epochs (baseline: 0.506)
- Superior stability with average standard deviation of 0.028 compared to baselines' 0.050+

## Why This Works (Mechanism)
MRP works by leveraging orthogonal projection to remove harmful information patterns from model representations. By projecting representations onto spaces orthogonal to unlearn data, the method effectively erases specific knowledge while preserving overall model functionality. The use of PCA and QR decomposition ensures that projection matrices are both effective at capturing unlearn patterns and numerically stable. This orthogonal projection approach creates a mathematical barrier against relearning, as information removed through orthogonal complement projection cannot be easily recovered through standard training processes.

## Foundational Learning

**Orthogonal Projection**
- Why needed: Enables selective removal of information patterns without affecting other model capabilities
- Quick check: Verify projection matrices satisfy P^2 = P and P^T = P properties

**Principal Component Analysis (PCA)**
- Why needed: Identifies dominant patterns in unlearn data representations for effective projection matrix initialization
- Quick check: Confirm explained variance ratio captures sufficient information from unlearn data

**QR Decomposition**
- Why needed: Converts PCA components into orthogonal basis for stable projection operations
- Quick check: Validate resulting matrices satisfy Q^T Q = I orthogonality condition

**Representation Space Manipulation**
- Why needed: Provides mathematical framework for controlled information removal from LLMs
- Quick check: Measure representation similarity before and after projection to verify effectiveness

## Architecture Onboarding

**Component Map**
Input -> Encoder -> Projection Matrix Application -> Output Decoder

**Critical Path**
The critical path involves computing input representations, applying orthogonal projection matrices, and generating outputs. This path must maintain real-time performance while executing projection operations efficiently.

**Design Tradeoffs**
MRP trades computational overhead during inference for improved unlearning effectiveness and stability. The method requires storing projection matrices for each unlearn task, increasing memory requirements but enabling precise control over information removal. The parameter-efficient training approach (0.1M parameters) minimizes computational cost during updates while maintaining effectiveness.

**Failure Signatures**
Common failure modes include: (1) projection matrices that are not truly orthogonal, leading to incomplete unlearning; (2) over-projection that removes useful information beyond target harmful content; (3) projection matrices that fail to capture sufficient variance from unlearn data, resulting in ineffective unlearning.

**3 First Experiments**
1. Verify orthogonal projection matrices satisfy mathematical properties using random test data
2. Measure representation similarity changes before and after projection on synthetic unlearn tasks
3. Benchmark inference latency impact of projection operations compared to baseline inference

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focuses on synthetic unlearn tasks rather than real harmful content, limiting practical validation
- Computational overhead and memory requirements for maintaining projection matrices at scale are not thoroughly analyzed
- Long-term stability assessment limited to five relearning epochs, leaving questions about extended use performance

## Confidence

**High Confidence**: Orthogonal projection mechanism is mathematically sound; parameter efficiency claims are verifiable through described PCA/QR approach.

**Medium Confidence**: Unlearning performance scores are promising but rely on synthetic rather than real harmful content evaluation.

**Low Confidence**: Long-term stability claims and production deployment readiness remain uncertain due to limited evaluation scope and duration.

## Next Checks

1. **Real-World Harmful Content Testing**: Evaluate MRP on actual harmful content datasets (toxic language, copyrighted material, personal information) to validate practical effectiveness and identify edge cases.

2. **Scalability and Overhead Analysis**: Measure inference latency, memory consumption, and computational overhead when scaling to 100+ unlearn tasks to assess production feasibility.

3. **Long-Term Stability Assessment**: Conduct extended evaluation over 50+ relearning epochs to monitor performance degradation patterns and test robustness against adversarial unlearn requests.