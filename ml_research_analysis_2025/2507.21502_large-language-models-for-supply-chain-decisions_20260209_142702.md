---
ver: rpa2
title: Large Language Models for Supply Chain Decisions
arxiv_id: '2507.21502'
source_url: https://arxiv.org/abs/2507.21502
tags:
- supply
- data
- chain
- technology
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper demonstrates how Large Language Models (LLMs) can significantly\
  \ enhance supply chain decision-making by enabling planners to understand tools'\
  \ recommendations, analyze scenarios, and update models without relying on technical\
  \ experts. By translating natural language queries into optimization code, LLMs\
  \ allow planners to perform complex analyses\u2014like \"what-if\" scenarios\u2014\
  in minutes instead of days."
---

# Large Language Models for Supply Chain Decisions

## Quick Facts
- arXiv ID: 2507.21502
- Source URL: https://arxiv.org/abs/2507.21502
- Reference count: 0
- Primary result: LLMs enable planners to perform supply chain "what-if" analyses in minutes instead of days with ~90% accuracy

## Executive Summary
This paper demonstrates how Large Language Models can democratize access to sophisticated supply chain planning tools by translating natural language queries into executable optimization code. The system allows supply chain planners to perform complex analyses like scenario planning and model modifications without relying on data scientists, achieving significant productivity gains. In a production deployment at Microsoft's cloud supply chain, the approach reduced planners' time spent on demand drift analysis from one week to minutes and achieved a 23% reduction in fulfillment investigation time.

The core innovation lies in using in-context learning with domain-specific examples rather than model fine-tuning, preserving privacy by keeping proprietary data separate from the LLM service. The system translates natural language questions into mathematical programming code that modifies optimization models, executes them against company data repositories, and returns results in natural language. This approach addresses the critical challenge of enabling non-technical users to leverage complex optimization tools while maintaining data security and achieving production-viable accuracy.

## Method Summary
The system employs in-context learning where domain-specific question-code pairs are appended to user queries before sending to GPT-4. The LLM generates mathematical programming code representing modifications to the optimization model, which executes against the supply chain tool's data repository. Results flow back through an interpreter for natural language response. The architecture maintains data privacy by keeping proprietary data separate from the LLM service, with the LLM operating only on queries and examples while code execution happens locally against internal data.

## Key Results
- Achieved approximately 90% accuracy using GPT-4 for query-to-code translation
- Reduced planners' time on demand drift analysis from one week to minutes
- Achieved 23% reduction in fulfillment investigation time in production deployment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can translate natural language queries into executable optimization code for supply chain analysis
- Mechanism: The LLM receives a user query, retrieves relevant example question-code pairs from a pre-built repository (in-context learning), generates mathematical code representing modifications to the optimization model, which is then executed by the supply chain tool. Results flow back through an interpreter for natural language response
- Core assumption: The optimization tools have well-defined interfaces (APIs) that can be programmatically invoked, and the query-to-code translation achieves sufficient accuracy for production use
- Evidence anchors:
  - [abstract] "By translating natural language queries into optimization code, LLMs allow planners to perform complex analyses—like 'what-if' scenarios—in minutes instead of days."
  - [section 4] "The LLM is responsible for translating the human query into a 'mathematical code'... This small change in the mathematical model is then fed to the supply chain tool to produce a modified plan."
- Break condition: If optimization tools lack programmatic APIs, or if query ambiguity exceeds the LLM's disambiguation capability without extensive clarification loops

### Mechanism 2
- Claim: In-context learning with domain-specific examples achieves production-viable accuracy without model fine-tuning
- Mechanism: Rather than modifying LLM parameters, the system appends relevant (question, code) pairs from a curated repository to the user query. The LLM infers patterns from these examples to generate appropriate code for new queries
- Core assumption: A sufficiently large and representative repository of question-code pairs exists for the target domain, and similar query patterns recur frequently enough for examples to transfer
- Evidence anchors:
  - [abstract] "The system also achieved approximately 90% accuracy using GPT-4."
  - [section 2] "In-context learning is an alternative approach, which involves incorporating a few training examples into the prompt (or query) without changing the LLM."
  - [section 4] "The basic idea is to generate a large repository of questions and code answers. Some of these question-answer pairs are then appended to the user query."
- Break condition: If the query distribution shifts significantly from the example repository, or if repository maintenance becomes unsustainable

### Mechanism 3
- Claim: Separating proprietary data from the LLM service preserves privacy while enabling analysis
- Mechanism: The LLM operates as a cloud service receiving only the query and examples. Mathematical code generated by the LLM is executed locally against the company's data repository; only results (not raw data) are processed for response generation
- Core assumption: The generated code can execute against internal data without requiring that data to be embedded in the prompt itself
- Evidence anchors:
  - [section 3] "The LLM can be utilized as a cloud service, whereas the propriety data does not need to be transferred to the LLM."
  - [section 4, Figure 1] "Note that the application data need not be passed to the LLM."
- Break condition: If complex queries require data context embedded in prompts (e.g., RAG patterns for document-heavy queries), weakening the privacy boundary

## Foundational Learning

- Concept: **Mathematical Programming / Optimization Formulation**
  - Why needed here: The system translates natural language into optimization constraints and objectives. Users must understand that "force retailer R to use factory F" maps to a constraint, not a suggestion
  - Quick check question: Can you explain why adding "retailer R must use factory F" is a constraint modification rather than an objective function change?

- Concept: **In-Context Learning vs. Fine-Tuning**
  - Why needed here: The paper explicitly uses in-context learning (appending examples) rather than fine-tuning. Understanding this distinction is critical for system design and cost estimation
  - Quick check question: If you need the LLM to handle a completely new query type not represented in your example repository, which approach would be more appropriate and why?

- Concept: **LLM Accuracy Limitations and Verification**
  - Why needed here: The paper reports ~90% accuracy, meaning ~10% of outputs require correction. Systems must include verification and fallback mechanisms
  - Quick check question: What verification step would you design to catch an LLM-generated constraint that is syntactically valid but semantically wrong for the business problem?

## Architecture Onboarding

- Component map:
  - Question Handler -> LLM Service -> Supply Chain Tool -> Data Repository -> Interpreter -> User

- Critical path: User Query → Question Handler (append examples) → LLM (generate code) → Supply Chain Tool (execute on data) → Interpreter (natural language response) → User

- Design tradeoffs:
  - **GPT-4 vs. smaller models**: GPT-4 achieves ~90% accuracy; smaller models (Llama-2, Phi-2) may reduce cost but require fine-tuning evaluation
  - **In-context learning vs. fine-tuning**: In-context avoids training costs but increases per-query token costs; fine-tuning has upfront cost but lower per-query cost
  - **Data locality vs. context richness**: Keeping data separate preserves privacy but may limit LLM effectiveness for complex queries

- Failure signatures:
  - Ambiguous queries returning plausible but incorrect code (e.g., "better" interpreted as cost reduction vs. throughput increase)
  - Generated code that is syntactically valid but produces infeasible optimization problems
  - Missing or stale examples in the repository causing degraded accuracy on edge cases
  - Cost escalation from long prompts (many appended examples) at high query volumes

- First 3 experiments:
  1. **Data Discovery Baseline**: Implement the simplest pattern—natural language to SQL queries against a single data table. Measure translation accuracy on 50 test questions of varying complexity
  2. **What-If Query with Mock Optimizer**: Build a minimal optimization model (e.g., 3 suppliers, 2 factories, 2 retailers). Create 30 question-code pairs. Test whether in-context learning correctly generates constraint modifications for novel but similar queries
  3. **Verification Loop Prototype**: Design and test a verification step that compares LLM-generated code against expected code structure (e.g., constraint count, variable references) before execution. Measure false positive and false negative rates

## Open Questions the Paper Calls Out

- How can systems automatically verify the correctness and computational tractability of mathematical models generated from scratch by LLMs? (Section 8 explicitly asks this)
- Can Small Language Models (SLMs) match the performance of large models (e.g., GPT-4) in complex, interactive supply chain planning tasks? (Section 8 notes this as an interesting area)
- What validation tools are required to enable LLMs to reliably model complex, industrial-scale supply chain structures end-to-end? (Section 5 states current tools are insufficient)

## Limitations

- Accuracy claims rely on single case study without independent validation
- Approach assumes optimization tools have stable, well-documented APIs not universally available
- Does not address how question-code repository scales with model complexity or maintenance requirements

## Confidence

- **High Confidence**: The core architectural pattern (LLM-to-code translation with in-context learning) is technically sound and the privacy-preserving data separation approach is well-justified
- **Medium Confidence**: The 23% reduction in fulfillment investigation time is plausible given the time compression claims, but lacks comparative baseline data from controlled experiments
- **Low Confidence**: The generalizability of ~90% accuracy across different supply chain domains and the long-term sustainability of the example repository maintenance model

## Next Checks

1. **Cross-Domain Accuracy Validation**: Test the system with 100+ diverse queries across three distinct supply chain domains (manufacturing, retail, logistics) to verify the claimed 90% accuracy holds beyond the Microsoft case study

2. **Repository Maintenance Cost Analysis**: Track the time and expertise required to maintain the question-code repository over a 6-month period as business rules and model structures evolve

3. **Failure Mode Characterization**: Systematically catalog and categorize the ~10% of queries where the system fails, distinguishing between ambiguity, incorrect code generation, and data-related issues to inform verification mechanisms