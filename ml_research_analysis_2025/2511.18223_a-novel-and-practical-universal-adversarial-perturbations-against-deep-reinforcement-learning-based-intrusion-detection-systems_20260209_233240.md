---
ver: rpa2
title: A Novel and Practical Universal Adversarial Perturbations against Deep Reinforcement
  Learning based Intrusion Detection Systems
arxiv_id: '2511.18223'
source_url: https://arxiv.org/abs/2511.18223
tags:
- adversarial
- attack
- proposed
- attacks
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces a novel Universal Adversarial Perturbation
  (UAP) attack tailored for Deep Reinforcement Learning (DRL)-based Intrusion Detection
  Systems (IDS). The attack leverages domain-specific constraints derived from network
  data rules and mathematical relationships among features to ensure practical applicability.
---

# A Novel and Practical Universal Adversarial Perturbations against Deep Reinforcement Learning based Intrusion Detection Systems

## Quick Facts
- arXiv ID: 2511.18223
- Source URL: https://arxiv.org/abs/2511.18223
- Reference count: 40
- Primary result: Proposed Customized UAP achieves 90% FNR and 65% accuracy against DRL-IDS

## Executive Summary
This work introduces a novel Universal Adversarial Perturbation (UAP) attack specifically designed for Deep Reinforcement Learning (DRL)-based Intrusion Detection Systems (IDS). The attack leverages domain-specific constraints derived from network data rules and mathematical relationships among features to ensure practical applicability. A Customized UAP is further developed by incorporating the Pearson Correlation Coefficient (PCC) to optimize perturbation effectiveness, enhancing attack performance by maximizing the perturbation's influence on model predictions.

The experimental results demonstrate that the proposed Customized UAP outperforms four established UAP baselines, as well as two input-dependent attacks (FGSM and BIM), achieving a False Negative Rate (FNR) of up to 90% and accuracy as low as 65% under high perturbation levels. This work highlights the vulnerability of DRL-based IDS to adversarial attacks and underscores the importance of robust defenses in real-world network security scenarios.

## Method Summary
The methodology targets DQN-based IDS using the CICIDS2018 dataset with 76 features after preprocessing. The approach employs a two-stage attack: first generating a standard UAP using Algorithm 1 with domain constraints that maintain feature relationships, then optimizing with a Customized UAP using PCC-based loss at layer 4. The DQN architecture consists of four fully-connected layers (64 nodes each) with ReLU activation. Domain constraints partition features into three groups: Main Features (MF) that can be directly perturbed, Related Features (RF) that must be recalculated based on MF changes using specific formulas, and Other Features (UF) that remain unchanged. The PCC optimization maximizes the correlation between model activations before and after perturbation to enhance attack effectiveness.

## Key Results
- Customized UAP outperforms four baseline UAPs (C-UAP, F-UAP, V-UAP, FFF-UAP)
- Achieves FNR up to 90% and accuracy as low as 65% under high perturbation levels
- PCC-based optimization provides significant performance improvement over standard UAP methods
- Successfully demonstrates practical applicability through domain-specific constraints

## Why This Works (Mechanism)
The attack exploits the vulnerability of DRL-based IDS to universal perturbations that can be crafted to remain effective across multiple samples. By leveraging domain knowledge about feature relationships and valid ranges, the perturbations can be optimized while maintaining realistic network traffic characteristics. The PCC-based optimization specifically targets the model's decision boundary by maximizing the perturbation's influence on intermediate layer activations, making the attack more effective than traditional perturbation methods that focus solely on final output changes.

## Foundational Learning
- **Universal Adversarial Perturbations**: Small perturbations that generalize across multiple inputs - needed to create efficient attacks that don't require per-sample optimization; quick check: verify perturbation size stays within L∞ bounds
- **Pearson Correlation Coefficient (PCC)**: Statistical measure of linear correlation between variables - used to optimize perturbation effectiveness by maximizing correlation between activations; quick check: ensure PCC values increase during optimization
- **Domain Constraints in Network Traffic**: Feature relationships and valid ranges specific to network data - ensures generated perturbations remain realistic and applicable; quick check: verify perturbed samples satisfy MF/RF/UF constraints
- **Deep Q-Network (DQN)**: Reinforcement learning algorithm using Q-value approximation - serves as the target IDS model; quick check: confirm DQN achieves reasonable baseline accuracy before attack
- **Feature Recalculation Formulas**: Mathematical relationships between dependent features - maintains data validity during perturbation; quick check: verify RF features are correctly recalculated from MF changes

## Architecture Onboarding

**Component map:**
DQN-IDS -> CICIDS2018 data -> UAP generation -> Attack evaluation

**Critical path:**
Data preprocessing → DQN training → UAP generation (with constraints) → Attack evaluation → Performance measurement

**Design tradeoffs:**
- Domain constraints vs. perturbation flexibility: Strict constraints limit attack strength but ensure practical applicability
- PCC optimization vs. computational cost: More effective but requires additional computation per iteration
- Feature grouping accuracy: Incorrect grouping could lead to invalid perturbations or reduced effectiveness

**Failure signatures:**
- FNR significantly below 90%: Likely indicates incorrect domain constraint implementation or missing feature recalculation
- UAP generation divergence: May indicate improper L∞ projection or seed selection issues
- Poor attack transferability: Could suggest over-reliance on specific DQN architecture characteristics

**Exactly 3 first experiments:**
1. Verify DQN baseline accuracy on clean CICIDS2018 test set before any attacks
2. Test basic UAP generation with domain constraints on small subset of data
3. Validate feature recalculation formulas by perturbing MF features and checking RF consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can DRL-based IDS be effectively defended against the proposed PCC-based UAP attacks without significantly degrading detection performance?
- Basis in paper: [inferred] The conclusion explicitly "underscores the importance of robust defenses in real-world network security scenarios," yet the experimental scope is limited to attack generation and execution without evaluating mitigation strategies.
- Why unresolved: The work focuses on exploiting vulnerabilities using a novel loss function (PCC), but it does not investigate whether standard defenses like adversarial training or defensive distillation can resist this specific PCC-driven perturbation.
- What evidence would resolve it: Experimental results comparing the performance of the proposed UAP against hardened DRL models that have undergone various defense mechanisms.

### Open Question 2
- Question: Does the Customized UAP maintain its high evasion success rate in black-box or gray-box threat scenarios where the attacker lacks full model knowledge?
- Basis in paper: [inferred] The methodology section explicitly defines the threat setting as "white-box," assuming the adversary has full access to the target model's parameters and gradients.
- Why unresolved: Real-world attackers rarely possess full white-box access to commercial IDS; the transferability of the PCC-based perturbation to unknown or obfuscated models remains unverified.
- What evidence would resolve it: Evaluation of the generated UAP's fooling rate when applied to surrogate models with different architectures or parameters than the source model.

### Open Question 3
- Question: Can the proposed feature grouping and mathematical recalculation constraints generalize to other network traffic datasets with different feature schemas?
- Basis in paper: [inferred] The domain constraints and "Recalculate" formulations (Table II) are derived specifically for the CICIDS2018 dataset, and no other datasets are used for evaluation.
- Why unresolved: Network datasets (e.g., UNSW-NB15) have different feature sets and inter-feature dependencies; the specific mathematical relationships leveraged here may not exist or may differ in other contexts.
- What evidence would resolve it: Replicating the experiment on a secondary dataset to observe if the UAP generation remains feasible and effective under different domain rules.

## Limitations
- The CICIDS2018 dataset represents a specific network traffic scenario that may not capture full diversity of real-world IDS deployments
- Domain constraints are specific to this dataset's characteristics and may not transfer to other intrusion detection contexts
- Evaluation focuses exclusively on black-box transferability from a single DQN architecture

## Confidence

**High confidence:** The Customized UAP algorithm's superiority over baseline UAPs (C-UAP, F-UAP, V-UAP, FFF-UAP) is well-supported by the ablation study results and the PCC-based optimization provides a clear methodological contribution

**Medium confidence:** The practical applicability claims are reasonable given the domain constraints but would benefit from validation across multiple IDS architectures and datasets

**Medium confidence:** The 90% FNR and 65% accuracy results are credible within the experimental setup but may not represent worst-case scenarios for all DRL-IDS implementations

## Next Checks

1. Validate the domain constraint implementation by testing whether perturbed samples remain within valid feature ranges and satisfy the MF/RF/UF relationships defined in Table II, comparing against the reported results
2. Reproduce the ablation study showing Customized UAP's performance advantage over the four baseline UAPs under identical conditions (seed_set size, max_iter, delta thresholds)
3. Test attack transferability by applying the UAP generated from DQN to other DRL algorithms (PPO, A3C) and traditional ML models (Random Forest, SVM) to verify cross-model effectiveness claims