---
ver: rpa2
title: An explainable transformer circuit for compositional generalization
arxiv_id: '2502.15801'
source_url: https://arxiv.org/abs/2502.15801
tags:
- head
- output
- token
- figure
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work identifies and mechanistically interprets the circuit
  responsible for compositional generalization in a compact transformer. Through causal
  ablations and path-patching analyses, the authors discovered a minimal circuit involving
  five key attention heads that implement a structured algorithm for function composition.
---

# An explainable transformer circuit for compositional generalization

## Quick Facts
- arXiv ID: 2502.15801
- Source URL: https://arxiv.org/abs/2502.15801
- Authors: Cheng Tang; Brenden Lake; Mehrdad Jazayeri
- Reference count: 8
- Key outcome: Identified minimal circuit of 5 attention heads enabling compositional generalization

## Executive Summary
This work identifies and mechanistically interprets the circuit responsible for compositional generalization in a compact transformer. Through causal ablations and path-patching analyses, the authors discovered a minimal circuit involving five key attention heads that implement a structured algorithm for function composition. The circuit encodes index information from both the question and function arguments, enabling the model to correctly predict composed outputs. The authors validate their interpretation by precisely steering model behavior through targeted activation edits, demonstrating that swapping positional embeddings in the circuit leads to predictable shifts in attention patterns.

## Method Summary
The authors employed causal intervention techniques including ablations, path-patching, and activation editing to identify and validate a minimal circuit for compositional generalization. They systematically tested head combinations to find the critical 5-head circuit, then verified its role through targeted modifications that predictably altered model behavior. The analysis revealed that these heads work together to encode positional information from both input functions and questions, implementing a structured composition algorithm.

## Key Results
- Model achieves 98% accuracy on held-out compositional tasks
- Identified minimal circuit of 5 key attention heads responsible for compositionality
- Targeted activation edits successfully steer model behavior in predictable ways
- Swapping positional embeddings in circuit leads to predictable attention pattern shifts

## Why This Works (Mechanism)
The circuit works by encoding positional information from both the question and function arguments through a coordinated sequence of attention operations. The five key heads form a computational pipeline that first extracts index information, then