---
ver: rpa2
title: 'Model Merging is Secretly Certifiable: Non-Vacuous Generalisation Bounds for
  Low-Shot Learning'
arxiv_id: '2505.15798'
source_url: https://arxiv.org/abs/2505.15798
tags:
- bound
- error
- learning
- pac-bayes
- generalisation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper demonstrates that model merging methods can achieve
  non-vacuous generalization bounds for low-shot learning with large models, providing
  a first-time certification for models like ViT-B and Mistral-7B with only 100 training
  examples. The key insight is that model merging learns a small number of merging
  parameters regardless of the base model size, making the certified generalization
  gap tiny and independent of network size.
---

# Model Merging is Secretly Certifiable: Non-Vacuous Generalisation Bounds for Low-Shot Learning

## Quick Facts
- **arXiv ID:** 2505.15798
- **Source URL:** https://arxiv.org/abs/2505.15798
- **Reference count:** 40
- **Primary result:** Demonstrates non-vacuous PAC-Bayes generalization bounds for model merging methods (Task Arithmetic, AdaMerging) on large models (ViT-B, Mistral-7B) using only 100 training examples.

## Executive Summary
This paper shows that model merging methods can achieve non-vacuous generalization bounds for low-shot learning, even with large models. By re-interpreting existing merging algorithms through a PAC-Bayes framework, the authors prove these methods provide meaningful performance guarantees "off-the-shelf" without modification. The key insight is that model merging learns a small number of parameters regardless of base model size, making certified generalization gaps tiny and independent of network size. The paper further proposes optimizing the PAC-Bayes bound directly as the learning objective, which improves certificates from vacuous to non-vacuous in challenging cases.

## Method Summary
The method applies PAC-Bayes theory to model merging by treating merging weights as learnable parameters in a distribution over hypotheses. Four merging algorithms are analyzed: Task Arithmetic (1 parameter), Ties-Merging (M parameters), Task-wise AdaMerging (M parameters), and Layer-wise AdaMerging (M×L parameters). A Gaussian prior/posterior is used with variance 0.05, and bounds are computed using either the Seeger bound (inverted via Newton's method) or a closed-form upper bound. Bound optimization is performed via CMA-ES (gradient-free), and data-dependent priors are created by splitting training data and using first half to initialize the prior mean. Experiments span vision (CLIP-ViT-B/32 on 8 datasets with 100 shots each) and language (Mistral-7B on BBH benchmark).

## Key Results
- Task Arithmetic and Task-wise AdaMerging achieve non-vacuous bounds (PB Bound < 1) off-the-shelf on vision tasks
- Layer-wise AdaMerging requires bound optimization to convert vacuous bounds to non-vacuous (PB Bound improves from 1.000 to 0.744-0.819)
- Data-dependent prior further tightens bounds, achieving PB Bound of 0.483 on EuroSAT vs 1.000 without
- 7B-scale LLMs achieve substantial gains over zero-shot baselines while maintaining non-vacuous bounds
- Test errors within 5% of training error can be certified across vision and language tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Model merging achieves non-vacuous generalization bounds because the number of learnable parameters depends on the number of source models, not their size.
- **Mechanism:** Standard fine-tuning optimizes millions of parameters, causing PAC-Bayes KL terms to explode. Model merging re-parameterizes learning as weight combination coefficients (1-196 parameters in experiments), so KL(Q∥P) remains small regardless of whether base models are 88M or 7B parameters.
- **Core assumption:** The merging weights parameterize a sufficiently expressive hypothesis class to solve the target task.
- **Evidence anchors:**
  - [abstract] "the number of learnable parameters is dependent on the number of source models, and potentially independent of their size"
  - [section 2] "In these cases the learnable parameters for the downstream tasks are handful of weighting factors compared to billions of parameters in the source models themselves"
  - [corpus] Neighbor work on intrinsic dimensionality (arXiv:2501.19067) supports low-dimensional subspace learning enabling generalization guarantees.
- **Break condition:** When merging requires many parameters (e.g., layer-wise AdaMerging with 196 weights), bounds become vacuous without additional techniques.

### Mechanism 2
- **Claim:** Directly optimizing the PAC-Bayes bound converts vacuous certificates to non-vacuous ones.
- **Mechanism:** Standard merging minimizes only training error Ĺ(Q). The proposed objective (Eq. 10) minimizes Ĺ(Q) + √[(KL(Q∥P) + log(n/δ))/(2(n-1))], explicitly trading off fit against complexity. This prevents the posterior from drifting too far from the prior.
- **Core assumption:** Gradient-free optimization (CMA-ES) can find good solutions in the small parameter space.
- **Evidence anchors:**
  - [section 4.2] "optimising this objective in parameter space can make the posterior 'fit' the PAC-Bayes bound more tightly"
  - [table 1] Layer-wise AdaMerging improves from vacuous (PB Bound = 1.000) to non-vacuous (0.744-0.819) with bound optimization
  - [corpus] Related work on prompt optimization (arXiv:2510.08413) similarly uses PAC-Bayes with informative priors for low-data settings.
- **Break condition:** Excessive regularization from bound optimization can cause underfitting (test error increases in some LW-Ada cases).

### Mechanism 3
- **Claim:** Data-dependent priors tighten bounds by initializing near good posteriors.
- **Mechanism:** Split training data: use first half to run standard merging, treat resulting weights as prior mean μ_P. Then optimize PAC-Bayes objective on second half. Since prior now encodes task-relevant information, KL(Q∥P) stays small even when Q is well-performing.
- **Core assumption:** Splitting already-small datasets (100 → 50/50) still leaves sufficient data for both stages.
- **Evidence anchors:**
  - [section 4.2] "This two-stage process can substantially improve the tightness of the final bound, as the prior is now more likely to be near a good posterior"
  - [table 2] LW-Ada + DDP achieves PB Bound of 0.483 on EuroSAT vs. 1.000 without
  - [corpus] Prior work Perez-Ortiz et al. [32] used data-dependent priors for neural network certification.
- **Break condition:** If the first-stage merging fails to find a good region, the informed prior provides no benefit.

## Foundational Learning

- **Concept: PAC-Bayes Bounds**
  - Why needed here: The entire certification framework rests on interpreting merging as producing distributions over parameters (not single points) bounded by Theorems 1 and 2.
  - Quick check question: Can you explain why PAC-Bayes requires sampling a new θ for each prediction, and how this differs from standard ensembling?

- **Concept: KL Divergence Between Gaussians**
  - Why needed here: Computing certificates requires evaluating KL(Q∥P) analytically (Eq. 11); this term directly determines bound tightness.
  - Quick check question: Given two Gaussians N(μ_Q, σ²I) and N(μ_P, σ²I) with d dimensions, how does KL scale with d and ||μ_Q - μ_P||²?

- **Concept: Model Merging Methods (Task Arithmetic, AdaMerging)**
  - Why needed here: These are the base learners being certified; understanding their parameterization determines how many dimensions contribute to the KL term.
  - Quick check question: Task Arithmetic learns one scalar; Task-wise AdaMerging learns M scalars; Layer-wise AdaMerging learns M×L scalars. Which would you expect to have tightest bounds and why?

## Architecture Onboarding

- **Component map:**
  Source Models (M pretrained networks) -> Merging Parameter Space (d = 1 to M×L parameters) -> Prior P: N(μ_P, λ⁻¹I) <- μ_P = uniform OR data-dependent -> Posterior Q: N(μ_Q, λ⁻¹I) <- Found by optimization -> Certificate: Solve kl(Ĺ(Q)∥C) = KL(Q∥P) + log(n/δ)/(n-1)

- **Critical path:**
  1. Select merging method → determines parameter count d
  2. Set prior variance λ (default 0.05) and mean (uniform or DDP)
  3. Optimize Eq. 10 using CMA-ES (gradient-free)
  4. Compute PB Bound via Newton's method on Eq. 9
  5. If vacuous: try bound optimization or DDP

- **Design tradeoffs:**
  - More merging parameters (layer-wise) → better empirical performance but harder to certify
  - Smaller prior variance → tighter potential bounds but harder optimization
  - DDP uses all data but requires successful first-stage learning

- **Failure signatures:**
  - Vacuous bounds (PB > 1): Too many parameters, prior too far from good posterior
  - High test error with non-vacuous bound: Over-regularization from bound optimization
  - Large gap between train and PB bound: Model capacity exceeds what's needed for task

- **First 3 experiments:**
  1. Replicate Task Arithmetic on CLIP-ViT-B/32 with 100 samples on EuroSAT; verify off-the-shelf non-vacuous bound without code changes.
  2. Compare Layer-wise AdaMerging with vs. without bound optimization on SVHN; quantify bound tightening.
  3. Implement DDP for Layer-wise AdaMerging; measure whether test error recovers while maintaining improved bounds.

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but based on the content, the following unresolved issues are apparent:

### Open Question 1
- Question: Can the certifiable model merging framework extend to larger-scale LLMs (e.g., 70B+ parameters) while maintaining non-vacuous bounds?
- Basis in paper: [explicit] The authors demonstrate certification for Mistral-7B as a "proof of concept" and note this is the first demonstration for large models in low-shot regimes, implying scaling further remains unexplored.
- Why unresolved: Only 7B-scale models were tested, and the computational and theoretical challenges of larger models were not addressed.
- What evidence would resolve it: Successful non-vacuous bounds achieved on 70B+ parameter models with similar 100-example regimes.

### Open Question 2
- Question: What is the minimum number of source models required to achieve non-vacuous certification, and how does this interact with source model diversity?
- Basis in paper: [inferred] The bound tightness depends on KL divergence between prior and posterior, but the relationship between source model pool characteristics (quantity, quality, diversity) and certificate quality was not systematically studied.
- Why unresolved: Experiments used fixed pools (7 vision models, 4 LLM variants) without ablation on source model requirements.
- What evidence would resolve it: Ablation studies varying source model count and diversity, measuring resulting bound tightness.

### Open Question 3
- Question: Can alternative distribution families beyond diagonal Gaussians and categorical distributions yield tighter bounds for model merging?
- Basis in paper: [explicit] Appendix B discusses only "popular" Gaussian and categorical families, noting computational tractability but not optimality.
- Why unresolved: Other families (e.g., structured covariances, mixture distributions) might better capture posterior geometry but were not explored.
- What evidence would resolve it: Comparative experiments with richer distribution families showing improved bounds without excessive computational cost.

## Limitations
- **Vacuous bounds with layer-wise AdaMerging:** When merging requires many parameters (e.g., 196 for M×L), bounds become vacuous without additional techniques like data-dependent priors.
- **Data-dependent prior reduces training data:** Splitting small datasets (100 → 50/50) may compromise learning quality for the actual task.
- **Scalability to larger models:** While 7B-scale models are certified, the framework's behavior on 70B+ parameter models remains untested.

## Confidence

**High confidence:** The core mechanism that model merging reduces learnable parameters is well-supported by both theory and experiments. The claim that PAC-Bayes bounds are non-vacuous for Task Arithmetic and Task-wise AdaMerging with 1-8 parameters is strongly evidenced.

**Medium confidence:** The bound optimization technique reliably converts vacuous to non-vacuous bounds, though the paper notes it can cause underfitting in some cases. The improvement from data-dependent priors is substantial but requires successful first-stage merging.

**Low confidence:** The scalability claims for 7B-scale LLMs are based on limited experiments (5 BBH tasks). The assertion that non-vacuous bounds are maintained "without any modification" is technically true but requires careful prior initialization and optimization.

## Next Checks

1. Systematically test the parameter-count threshold where bounds become vacuous by varying M and L in AdaMerging, then measure KL divergence and bound tightness.

2. Compare CMA-ES bound optimization against alternative gradient-based methods on the same small parameter spaces to verify that gradient-free optimization is necessary.

3. Evaluate whether the data-dependent prior approach degrades when the first-stage merging fails (e.g., on BBH tasks where merging underperforms zero-shot).