---
ver: rpa2
title: 'PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval'
arxiv_id: '2504.20624'
source_url: https://arxiv.org/abs/2504.20624
tags:
- retrieval
- user
- sigir
- generation
- part
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PaRT, a framework that enhances social chatbots
  with personalized real-time retrieval to enable proactive dialogues. The approach
  addresses the limitations of passive chatbots by integrating user profiles and dialogue
  context into large language models to refine user queries and identify underlying
  intents.
---

# PaRT: Enhancing Proactive Social Chatbots with Personalized Real-Time Retrieval

## Quick Facts
- **arXiv ID:** 2504.20624
- **Source URL:** https://arxiv.org/abs/2504.20624
- **Reference count:** 40
- **Primary result:** Achieves 21.77% improvement in average dialogue duration via personalized real-time retrieval for proactive social chatbots

## Executive Summary
This paper introduces PaRT, a framework designed to enhance social chatbots by enabling proactive dialogue through personalized real-time retrieval. Unlike passive chatbots that wait for user input, PaRT initiates and transitions conversations by integrating user profiles and dialogue context into large language models. The system refines user queries, identifies underlying intents, retrieves relevant real-world information from platforms like RedNote, and generates engaging, knowledge-grounded responses. Deployed in a real-world production environment for over 30 days, PaRT demonstrates a significant 21.77% improvement in dialogue duration, validating its effectiveness in sustaining user engagement through proactive topic initiation.

## Method Summary
PaRT is built on a retrieval-augmented generation (RAG) architecture that combines user profiling, intent-guided query refinement, and real-time knowledge injection. The system first summarizes user information and dialogue history into a dynamic profile. An LLM-based intent-guided query refiner analyzes this context to categorize user intent (natural transition, explicit retrieval, or implicit retrieval) and rewrites queries for optimal retrieval. These refined queries are used to search an external platform (RedNote) for current, relevant content. The retrieved passages are summarized and injected into the final response generation, which is optimized for both informativeness and engagement. The model uses Qwen2-7B-Instruct for most components and Qwen2-72B-Instruct for final generation, trained on 11,455 SFT samples with a focus on balancing latency and quality.

## Key Results
- **21.77% improvement** in average dialogue duration achieved in real-world deployment
- **31.71% improvement** in overall retrieval performance when using LLM-refined queries versus raw user queries
- **Personalized generation** provides more satisfying responses compared to direct generation, confirming the value of user profiles

## Why This Works (Mechanism)

### Mechanism 1: Intent-Guided Query Refinement
The system uses an LLM to analyze dialogue context and user profiles, categorizing user intent into three types: natural transition, explicit retrieval, or implicit retrieval. Based on this intent and known user preferences, the LLM rewrites the query into a targeted search phrase. This approach leads to a 31.71% improvement in retrieval performance compared to using raw user utterances. The core assumption is that the LLM can accurately infer unstated user goals and that a rewritten, entity-focused query will better align with user needs.

### Mechanism 2: Dynamic User Profiling for Personalization
A dedicated module summarizes critical user information (interests, past activities) into a profile, which is used to bias topic generation toward user interests and tailor response tone and content. Personalized generation provides more satisfying responses, confirming the significant value of user profiles. The core assumption is that user engagement is positively correlated with the chatbot's ability to recall and build upon specific, long-term user interests.

### Mechanism 3: Real-Time Knowledge Injection for Proactivity
The system proactively injects up-to-date, real-world information via retrieval, allowing the chatbot to initiate and sustain conversations with novel topics. This overcomes the "knowledge boundary" of static models by accessing a live, high-quality external knowledge base. The core assumption is that a primary driver of user disengagement is the exhaustion of topics or lack of new information, which can be solved by accessing current external knowledge.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - **Why needed here:** This is the foundational architecture of PaRT. The system is not just an LLM; it's an LLM integrated with a search engine.
  - **Quick check question:** In a standard RAG pipeline, what is the flow of information from the user's query to the final generated response?

- **Concept: Proactive vs. Reactive Dialogue**
  - **Why needed here:** The paper defines its value proposition against "passive" or reactive chatbots. Grasping this distinction is critical for understanding the design goals.
  - **Quick check question:** How does a proactive chatbot's behavior differ from a standard one when a user's response indicates waning interest in the current topic?

- **Concept: Query Rewriting**
  - **Why needed here:** A core technical contribution is *how* the system retrieves information. It rewrites queries based on intent, a key information retrieval technique.
  - **Quick check question:** Why is a user's raw utterance in a multi-turn chat often a poor direct input for a search engine? What is the goal of rewriting it?

## Architecture Onboarding

- **Component map:** User Profiler -> Intent-guided Query Refiner -> Retriever (RedNote) -> Summarizer & Generator -> Final Response
- **Critical path:** Dialogue Context + User Profile -> **Query Refiner** -> Refined Query -> **Retriever (RedNote)** -> Retrieved Notes -> **Summarizer & Generator** -> Final Response. The Query Refiner is the critical new component to inspect first.
- **Design tradeoffs:**
    - **Latency vs. Quality:** The system uses a multi-step pipeline (intent, retrieval, summarization, generation). Each step adds latency. They use a smaller model (Qwen2-7B) for most tasks and a larger one (Qwen2-72B) for generation to manage this.
    - **Retrieval Quantity (k):** Retrieving too many documents (k > 5) introduces noise and degrades performance. The paper identifies k=5 as the optimal balance.
- **Failure signatures:**
    - **Generic/Irrelevant Response:** Often traces back to a failure in the Query Refiner, which produced a poor search query.
    - **Hallucination/Stale Info:** May indicate a failure in the Retrieval step (not finding relevant real-time info) or the LLM ignoring the retrieved context.
    - **Repetitive/Off-topic Proactivity:** Suggests the User Profile is either empty or not being correctly incorporated into the Query Refiner.
- **First 3 experiments:**
  1. **Intent Classification Accuracy:** Evaluate the Query Refiner's ability to correctly label intents (natural transition, explicit/implicit retrieval) on a held-out dataset.
  2. **Retrieval Relevance (P@k):** Compare the precision of retrieved documents using raw user queries vs. LLM-refined queries to validate the 31.71% improvement claim.
  3. **Ablation on User Profile:** Run the system with the User Profiler disabled to measure the drop in personalization and engagement metrics, isolating the profile's contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the computational overhead of the multi-stage pipeline (intent refinement, retrieval, summarization, and generation) introduce latency that degrades the real-time user experience?
- **Basis in paper:** [inferred] The authors mention utilizing Qwen2-7B-Instruct for components other than generation to "balance the latency-cost tradeoff," but they do not report specific latency metrics or the end-to-end response time in the online deployment.
- **Why unresolved:** The paper focuses on retrieval precision and dialogue duration but does not quantify the time cost of the sequential LLM calls required for every turn.
- **What evidence would resolve it:** Reporting of average response latency (ms) per turn and user retention metrics specifically correlated with wait times in the A/B test.

### Open Question 2
- **Question:** How does the system distinguish between engaging proactivity and intrusive annoyance when initiating topics or transitioning away from the user's current subject?
- **Basis in paper:** [inferred] While the paper reports a 21.77% increase in dialogue duration, it relies on a single engagement metric. It does not measure user frustration or "interruption" perception when the "intent-guided query refiner" triggers an "implicit retrieval" (topic switch).
- **Why unresolved:** Increased duration could result from either genuine enjoyment or confusion/forced interaction, and the paper lacks qualitative feedback or satisfaction scores regarding the proactive interruptions.
- **What evidence would resolve it:** Inclusion of user satisfaction surveys (e.g., Net Promoter Score) or qualitative analysis of user reactions immediately following a proactive topic transition.

### Open Question 3
- **Question:** To what extent does the reliance on a single retrieval source (RedNote) constrain the chatbot's ability to support non-lifestyle domains?
- **Basis in paper:** [inferred] The retrieval-augmented generation module relies exclusively on RedNote, which the authors describe as a "lifestyle-sharing platform," to provide "real-time insights."
- **Why unresolved:** While effective for the described scenarios (travel, movies), the paper does not address how the system handles user interests that fall outside the lifestyle domain (e.g., academic, technical, or niche hobbies), potentially leading to hallucinations or generic responses in those areas.
- **What evidence would resolve it:** Analysis of retrieval failure rates or generation quality scores specifically for out-of-domain queries compared to in-domain lifestyle queries.

## Limitations

- **Data Dependency and Bias:** The system's effectiveness hinges on the quality and coverage of its training data (11,455 SFT samples) and the external knowledge source (RedNote), which may introduce topical or cultural biases.
- **Scalability of User Profiling:** The current user profiling mechanism may not scale well to long-term interactions or capture nuanced, evolving user preferences, and the paper does not address how the system handles profile drift.
- **Evaluation Gaps:** The paper lacks a direct comparison to a strong baseline that uses retrieval without the full PaRT pipeline, and offline evaluation metrics are assessed via LLM judges, which may not fully capture human-perceived engagement or satisfaction.

## Confidence

- **High Confidence:** The core retrieval-augmented generation architecture is sound and aligns with established RAG principles. The reported improvements in retrieval relevance (31.71% gain) and dialogue duration are specific and measurable.
- **Medium Confidence:** The intent-guided query refinement mechanism is plausible and supported by related work, but the exact implementation details (prompt templates, intent categories) are not fully specified, making independent validation challenging.
- **Low Confidence:** The claim that the system achieves "proactive" dialogue is difficult to verify without observing the system in action. The paper does not provide concrete examples of how the system initiates novel topics or transitions smoothly without user prompts, beyond stating that it does so.

## Next Checks

1. **Ablation Study on Retrieval Quality:** Conduct a controlled experiment comparing PaRT's performance against a baseline that uses the same LLM for query rewriting but without the retrieval component. This would isolate the contribution of real-time knowledge injection to engagement metrics.

2. **User Diversity Testing:** Deploy the system with a diverse set of test users representing different demographics, interests, and conversational styles. Measure performance variance to identify potential biases or limitations in the user profiling and query refinement components.

3. **Longitudinal Profile Stability:** Implement a logging mechanism to track user profile evolution over time. Analyze whether the system's responses remain relevant and personalized as user preferences shift, or if profile staleness leads to decreased engagement.