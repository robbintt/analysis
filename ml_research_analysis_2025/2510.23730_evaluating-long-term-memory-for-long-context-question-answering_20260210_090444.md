---
ver: rpa2
title: Evaluating Long-Term Memory for Long-Context Question Answering
arxiv_id: '2510.23730'
source_url: https://arxiv.org/abs/2510.23730
tags:
- memory
- answer
- context
- question
- prompt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates memory-augmented approaches for long-context
  conversational question answering, comparing full-context prompting, retrieval-augmented
  generation, agentic memory, episodic learning with reflections, and prompt optimization.
  Experiments on LoCoMo and QMSum datasets show that memory-augmented methods reduce
  token usage by over 90% while maintaining competitive accuracy, with F1 scores ranging
  from 70-95% across different models and reasoning categories.
---

# Evaluating Long-Term Memory for Long-Context Question Answering

## Quick Facts
- arXiv ID: 2510.23730
- Source URL: https://arxiv.org/abs/2510.23730
- Authors: Alessandra Terranova; Björn Ross; Alexandra Birch
- Reference count: 35
- Primary result: Memory-augmented approaches reduce token usage by over 90% while maintaining competitive accuracy (F1 scores 70-95%) across LoCoMo and QMSum datasets.

## Executive Summary
This study evaluates memory-augmented approaches for long-context conversational question answering, comparing full-context prompting, retrieval-augmented generation, agentic memory, episodic learning with reflections, and prompt optimization. Experiments on LoCoMo and QMSum datasets show that memory-augmented methods reduce token usage by over 90% while maintaining competitive accuracy, with F1 scores ranging from 70-95% across different models and reasoning categories. Retrieval-based methods excel at multi-hop reasoning, while episodic memory improves temporal and adversarial question handling. Instruction-tuned models benefit most from complex memory architectures, while foundation models perform better with simpler RAG approaches.

## Method Summary
The study compares six memory-augmented approaches (Full Context, RAG, A-Mem, RAG+PromptOpt, RAG+EpMem, RAG+PromptOpt+EpMem) on LoCoMo and QMSum datasets. For episodic memory, the first 10% of LoCoMo conversations generate answers, compute F1 scores, and produce natural language reflections identifying error types, which are stored and retrieved at inference. Models tested include Llama 3.2-3B, Qwen2.5-7B (base & instruct), and GPT-4o mini. Embeddings use bge-m3 for RAG and all-minilm-l6-v2 for A-Mem. Evaluation measures F1 per reasoning category (Multi-Hop, Subgraph, Temporal, Single-Hop, Adversarial) and average tokens per query. Five runs with different seeds on 24GB GPU.

## Key Results
- Memory-augmented approaches reduce token usage by over 90% compared to full-context prompting (23k-26k tokens vs. 600-1500 tokens per query)
- RAG outperforms other approaches at Multi-Hop reasoning (F1 20-40 range), while episodic memory improves adversarial question handling
- Instruction-tuned models benefit most from complex memory architectures, while foundation models perform better with simpler RAG approaches
- Temporal reasoning remains a persistent weakness across all approaches (F1 4-12 range vs. 20-40 for other categories)

## Why This Works (Mechanism)

### Mechanism 1: Retrieval-based Semantic Memory (RAG)
- **Claim**: RAG provides efficient knowledge access while reducing token consumption by over 90% compared to full-context prompting.
- **Mechanism**: Top-k retrieval pipeline indexes conversation utterances using bge-m3 embeddings; at inference, cosine similarity retrieves the k=10 most relevant snippets with timestamps, which are appended to the prompt before generation.
- **Core assumption**: Semantic similarity between query embeddings and utterance embeddings correlates with relevance for answering questions.
- **Evidence anchors**: [abstract] "memory-augmented approaches reduce token usage by over 90% while maintaining competitive accuracy"; [Section 4.1] "RAG outperforms other approaches at Multi-Hop reasoning"; [Section 4.6] "Full Context approaches consistently require between 23000 and 26000 tokens per query, RAG approaches... use between 600 and 1500 tokens".
- **Break condition**: When adversarial questions reference content with high surface-level semantic similarity, retrieval surfaces confounding information rather than supporting "no information available" detection.

### Mechanism 2: Episodic Memory through Reflection-based Learning
- **Claim**: Episodic memory improves adversarial and temporal reasoning by enabling models to learn from failure patterns.
- **Mechanism**: The model answers sample questions, receives F1 scores and labels, then generates natural language reflections identifying error types (omission, temporal misinterpretation, assumption errors). These reflection-augmented examples are stored and retrieved as in-context demonstrations for similar future queries.
- **Core assumption**: Models can generalize from specific failure reflections to improve reasoning on similar question categories without weight updates.
- **Evidence anchors**: [abstract] "episodic memory can help LLMs recognise the limits of their own knowledge"; [Section 4.4] "Rag+EpMem outperforms RAG on GPT-4o mini and Llama3.2 3B Instruct"; [Section 4.4] Error analysis: 47% omission errors, 27% temporal misinterpretation, 11% assumption/overgeneralization errors identified in 199 episodic memories.
- **Break condition**: Foundation models with weaker instruction-following capabilities do not reliably generate useful reflections; benefits observed primarily in instruction-tuned models.

### Mechanism 3: Memory Architecture Complexity Scaling with Model Capability
- **Claim**: Optimal memory architecture complexity scales with model capability—foundation models benefit most from simple RAG, while instruction-tuned models gain from episodic learning and agentic memory.
- **Mechanism**: Model capability determines effective use of memory complexity. Foundation models struggle with A-Mem's structured output requirements but perform well with simple retrieval. Instruction-tuned models leverage richer semantic structures and episodic reflections.
- **Core assumption**: Instruction-following and reasoning capabilities limit the complexity of memory architectures a model can effectively utilize.
- **Evidence anchors**: [abstract] "Memory architecture complexity should scale with model capability, with foundation models benefitting most from RAG, and stronger instruction-tuned models gaining from episodic learning"; [Section 4.3] "RAG shows substantially better performance across all foundation models. This gap narrows for instruction-tuned models, which are able to take advantage of the full potential of A-Mem"; [Table 4] Base vs. instruction-tuned rankings show inverted patterns.
- **Break condition**: A-Mem requires two LLM calls per utterance for metadata generation; models unable to produce consistent structured output will fail at memory construction.

## Foundational Learning

- **Concept: Retrieval-Augmented Generation (RAG)**
  - Why needed here: RAG serves as the baseline semantic memory implementation; understanding chunking, embedding, and retrieval is essential for interpreting results.
  - Quick check question: Can you explain why embedding-based retrieval might surface semantically similar but factually irrelevant content for adversarial questions?

- **Concept: In-Context Learning (ICL)**
  - Why needed here: Episodic memory operates via ICL—storing question-answer-reflection triples as examples retrieved at inference time without gradient updates.
  - Quick check question: How does storing reflections alongside examples differ from standard few-shot prompting?

- **Concept: Memory Taxonomy (Semantic/Episodic/Procedural)**
  - Why needed here: The paper systematically compares three memory types; understanding their functional distinctions is necessary for architecture selection.
  - Quick check question: For a customer support chatbot that needs to remember past interactions and improve its response style, which memory types would be most relevant?

## Architecture Onboarding

- **Component map:**
  Input Query → Embedding (bge-m3) → Semantic Memory Retrieval (RAG top-k OR A-Mem structured notes) → Episodic Memory Retrieval (top-3 similar reflection examples, optional) → Procedural Memory (optimized prompts, optional) → LLM Generation → Answer

- **Critical path:**
  1. Start with RAG (k=10 for conversational QA, k=20 for summarization) as semantic memory baseline
  2. If using instruction-tuned model ≥7B or GPT-4o-mini, add episodic memory layer
  3. Evaluate adversarial question handling; if performance lags, increase episodic memory buffer
  4. Skip procedural memory for QA tasks (Section 4.5 shows negative results); consider only for transfer learning scenarios

- **Design tradeoffs:**
  - RAG vs. A-Mem: RAG is 4-5x more token-efficient at inference and requires no memory construction overhead; A-Mem provides richer context but needs 2 LLM calls per utterance for metadata
  - Full Context vs. Memory-Augmented: Full Context provides upper-bound accuracy (rank 1.00 for Llama-Instruct) at 23k+ tokens/query; memory approaches use <1.5k tokens with competitive performance
  - Episodic memory buffer size: Paper uses 3 retrieved examples; larger buffers untested

- **Failure signatures:**
  - Temporal reasoning degradation across all approaches (F1 4-12 range vs. 20-40 for other categories)—indicates fundamental limitation, not architecture issue
  - Adversarial over-correction: RAG+EpMem may over-generate "no information available" (Qwen: 95.59 adversarial F1 but 6.48 multi-hop F1)
  - Procedural memory overfitting: Optimized prompts focus on specific examples rather than abstracting patterns (Section 4.5, Appendix B.6.5)
  - Foundation model + A-Mem failure: Inconsistent structured output generation breaks memory construction

- **First 3 experiments:**
  1. Establish baseline: Compare Full Context vs. RAG (k=10) on your target model using 50-100 questions across reasoning categories to measure efficiency-performance tradeoff
  2. Episodic memory pilot: Generate reflections on 20 failed questions, store as episodic buffer, evaluate improvement on similar category questions
  3. Adversarial stress test: Evaluate whether episodic memory reduces false positives (answering unanswerable questions) without degrading legitimate question accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do agentic approaches to selecting experience examples compare to fixed update schedules for episodic and procedural memory?
- Basis in paper: Authors state "Future works should investigate agentic approaches to selecting experience examples, removing the need for fixed update schedules."
- Why unresolved: Current implementation uses only the first 10% of data to generate memories, limiting understanding of how continuous memory accumulation affects performance.
- What evidence would resolve it: Experiments comparing fixed-schedule memory updates with adaptive, agent-driven selection across full conversation trajectories.

### Open Question 2
- Question: How does the selection of positive versus negative examples for episodic and procedural memory affect overall QA performance?
- Basis in paper: Authors ask "how the selection of positive or negative examples for episodic and procedural memory affects overall results."
- Why unresolved: Current study retrieves top-3 most similar experiences regardless of outcome valence; optimal balance remains unknown.
- What evidence would resolve it: Ablation studies varying positive/negative example ratios in episodic memory, measuring F1 score changes across reasoning categories.

### Open Question 3
- Question: What mechanisms for forgetting, updating, and consolidating memories can handle contradictions in long-term conversational memory?
- Basis in paper: Authors acknowledge "Our study did not address long-term memory management issues such as mechanisms for forgetting, updating, or consolidating memories and handling contradictions."
- Why unresolved: Current approaches append or retrieve without mechanisms to resolve conflicting information or remove outdated memories.
- What evidence would resolve it: Evaluation of memory consolidation strategies on dialogues containing contradictions or updated information over time.

### Open Question 4
- Question: Can memory-based adaptation methods match or exceed reinforcement learning approaches for experiential learning in LLMs?
- Basis in paper: Authors propose "Comparing such non-parametric, memory-based adaptation with reinforcement learning methods may further illuminate how LLMs can learn not just from data, but from their own experiences."
- Why unresolved: No direct comparison exists between episodic memory approaches and RL-based agent learning.
- What evidence would resolve it: Benchmark comparison of F1 scores and sample efficiency between memory-augmented and RL-trained agents on LoCoMo-style tasks.

## Limitations
- Synthetic adversarial question generation without human verification of ground truth difficulty
- Temporal reasoning remains a persistent weakness across all approaches with F1 scores below 12%
- Evaluation focuses exclusively on two datasets (LoCoMo and QMSum), limiting generalizability

## Confidence

- **High Confidence**: Retrieval-based methods reduce token usage by >90% while maintaining competitive accuracy (Section 4.6 token measurements verified with multiple models)
- **Medium Confidence**: Episodic memory improves adversarial question handling and helps models recognize knowledge limits
- **Medium Confidence**: Memory architecture complexity should scale with model capability

## Next Checks
1. **Human evaluation of reflection quality**: Annotate 50 randomly selected reflections from episodic memory buffer to assess whether they correctly identify error types and provide actionable insights, then measure correlation between reflection quality and performance improvement.
2. **Temporal reasoning stress test**: Create a new benchmark specifically targeting temporal reasoning with human-verified ground truth, testing whether adding explicit temporal context to RAG retrieval improves performance beyond current ~10% F1 scores.
3. **Generalization cross-dataset validation**: Apply the best-performing memory architecture (RAG+EpMem) to at least two additional long-context datasets from different domains (e.g., legal documents, medical records) to test robustness beyond conversational QA and summarization.