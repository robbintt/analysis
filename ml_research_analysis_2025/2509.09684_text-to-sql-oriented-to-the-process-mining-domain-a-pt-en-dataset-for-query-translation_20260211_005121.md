---
ver: rpa2
title: 'Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query
  Translation'
arxiv_id: '2509.09684'
source_url: https://arxiv.org/abs/2509.09684
tags:
- process
- event
- qualifier
- dataset
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces text2SQL4PM, a bilingual Portuguese-English
  dataset for text-to-SQL tasks in the process mining domain. The dataset contains
  1,655 natural language utterances (including paraphrases), 205 SQL statements, and
  ten qualifiers for task complexity analysis.
---

# Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation

## Quick Facts
- arXiv ID: 2509.09684
- Source URL: https://arxiv.org/abs/2509.09684
- Reference count: 39
- Introduces text2SQL4PM, a bilingual Portuguese-English dataset for text-to-SQL tasks in process mining domain

## Executive Summary
This paper introduces text2SQL4PM, a bilingual Portuguese-English dataset for text-to-SQL tasks in the process mining domain. The dataset contains 1,655 natural language utterances (including paraphrases), 205 SQL statements, and ten qualifiers for task complexity analysis. Built through expert curation, manual translation, and careful annotation, it addresses the unique challenges of process mining, such as specialized vocabularies and single-table relational structures derived from event logs. A baseline evaluation using GPT-3.5 Turbo achieved 31.8% exact structure match and 44.5% execution accuracy for Portuguese, with slightly higher results for English, demonstrating the dataset's feasibility and utility for evaluating text-to-SQL implementations in this domain.

## Method Summary
The authors constructed the text2SQL4PM dataset through a multi-phase process. First, they created a corpus of 205 SQL queries based on the academic travel reimbursement domain, extracting data from SAP ERP using the ProM log importer. They then generated 820 Portuguese utterances from these SQL statements through expert curation. These utterances were manually translated to English, and additional paraphrases were generated for both languages, resulting in 1,655 total utterances. The dataset includes ten qualifiers (generic, domain, function, aggregate, condition, order, value, arithmetic, case level, having) to characterize task complexity. The dataset is split into training (131 SQL), validation (33 SQL), and test (41 SQL) sets, with SQL queries and associated utterances distributed accordingly.

## Key Results
- Baseline evaluation using GPT-3.5 Turbo achieved 31.8% exact structure match and 44.5% execution accuracy for Portuguese queries
- English queries performed slightly better with 36.6% exact structure match and 56.1% execution accuracy
- Dataset demonstrates significant challenges with temporal ordering and domain-specific vocabulary, with case-level queries showing particularly low accuracy (25-40%)

## Why This Works (Mechanism)
The dataset works by providing a specialized resource that captures the unique characteristics of process mining queries, including temporal ordering constraints, domain-specific vocabulary, and the single-table event log structure typical in process mining. The manual translation and paraphrasing ensure high-quality bilingual coverage, while the complexity qualifiers enable detailed analysis of model performance across different query types.

## Foundational Learning
- **Event Log Structure**: Understanding how process mining data is typically stored in single-table event logs is crucial for designing appropriate queries
  - Why needed: Process mining relies on event logs where each row represents an event with case ID, activity, timestamp, and resource
  - Quick check: Verify that SQL queries use self-joins rather than multiple tables for temporal queries

- **Process Query Languages (PQL)**: Alternative to SQL for process mining that can express complex process patterns
  - Why needed: SQL is limited for advanced process mining tasks like discovery and conformance checking
  - Quick check: Compare the expressiveness of SQL queries in the dataset with PQL constructs

- **Task Complexity Qualifiers**: Framework for categorizing query difficulty based on required SQL features
  - Why needed: Enables systematic evaluation of model performance across different query types
  - Quick check: Ensure all ten qualifiers (generic, domain, function, aggregate, condition, order, value, arithmetic, case level, having) are represented in the dataset

## Architecture Onboarding
- **Component Map**: Natural Language Utterances -> Text-to-SQL Model -> SQL Query -> Database -> Results
- **Critical Path**: Query translation requires accurate parsing of temporal constraints, domain vocabulary, and SQL syntax
- **Design Tradeoffs**: Single-table structure simplifies data modeling but requires complex self-joins for temporal queries
- **Failure Signatures**: Models struggle with temporal ordering (case-level queries), domain-specific terminology, and complex aggregate conditions
- **First Experiments**:
  1. Evaluate zero-shot performance on generic queries (without domain-specific terms)
  2. Test temporal query accuracy by focusing on case-level utterances
  3. Assess cross-lingual transfer by training on one language and testing on the other

## Open Questions the Paper Calls Out
### Open Question 1
- **Question**: Can semantic parsing in process mining be extended to Process Query Languages (PQL) to support tasks beyond exploratory information retrieval?
- **Basis in paper**: The Conclusion states that SQL is limited to exploratory retrieval and suggests "focus on creating datasets using a process query language" as an alternative for future research
- **Why unresolved**: The current dataset and baseline are restricted to SQL, which cannot inherently support advanced process mining tasks like discovery or monitoring without complex, often unfeasible, query constructions
- **What evidence would resolve it**: A new dataset mapping natural language to PQL operators, along with models capable of executing discovery algorithms via natural language

### Open Question 2
- **Question**: How can text-to-SQL models be improved to accurately resolve temporal ordering constraints (e.g., "activity A follows activity B") in non-normalized event logs?
- **Basis in paper**: The "General challenges" section (Section 4.2) highlights that GPT-3.5 Turbo failed to capture temporal order in case-level queries (Table 20), often ignoring sequence or reversing timestamps
- **Why unresolved**: Standard text-to-SQL models struggle with the self-joins and recursive logic required to process sequences within a single-table event log structure
- **What evidence would resolve it**: A model architecture or prompt strategy that consistently generates correct self-joins for sequential event queries, improving the "case level" accuracy (currently low at ~25-40%)

### Open Question 3
- **Question**: To what extent does fine-tuning on the text2SQL4PM dataset improve performance on "domain-specific" vocabulary compared to zero-shot baselines?
- **Basis in paper**: The results (Table 12) show the zero-shot baseline struggled significantly with "domain" qualifiers (0-16.7% accuracy) compared to "generic" or "value" qualifiers
- **Why unresolved**: The paper establishes a zero-shot baseline but does not evaluate whether the dataset is sufficient to teach models the specific jargon of the academic travel reimbursement domain
- **What evidence would resolve it**: A comparative evaluation showing significant accuracy gains in the "domain" qualifier category after fine-tuning LLMs on the training split of text2SQL4PM

## Limitations
- Dataset size remains relatively modest at 1,655 utterances and 205 SQL statements, which may limit generalizability
- Evaluation relies primarily on GPT-3.5 Turbo as a baseline, potentially not representing full potential of text-to-SQL systems
- Focus on single-table relational structure limits applicability to more complex multi-table scenarios

## Confidence
- High confidence in dataset construction methodology and relevance of process mining domain focus
- Medium confidence in baseline evaluation results due to single LLM and limited hyperparameter tuning
- Medium confidence in task complexity annotations, as they rely on expert judgment which may vary between practitioners

## Next Checks
1. Evaluate additional state-of-the-art text-to-SQL models beyond GPT-3.5 Turbo to establish more comprehensive baseline performance metrics
2. Conduct inter-rater reliability analysis for the task complexity annotations across multiple process mining experts
3. Test the dataset's effectiveness for cross-lingual transfer learning by training models on one language and evaluating on the other