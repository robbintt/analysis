---
ver: rpa2
title: 'Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention
  in Japanese Versus Analytical Focus in English'
arxiv_id: '2507.00700'
source_url: https://arxiv.org/abs/2507.00700
tags:
- japanese
- shot
- holistic
- first
- analytic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates whether Vision-Language Models (VLMs) trained
  on Japanese and English exhibit culturally grounded attentional patterns. Using
  a framework of image selection, caption generation, and in-context learning-based
  classification, the authors analyze the tendency of VLMs to produce holistic (context-focused)
  versus analytic (object-focused) descriptions.
---

# Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention in Japanese Versus Analytical Focus in English

## Quick Facts
- arXiv ID: 2507.00700
- Source URL: https://arxiv.org/abs/2507.00700
- Authors: Ahmed Sabir; Azinovič Gasper; Mengsay Loem; Rajesh Sharma
- Reference count: 15
- Primary result: Japanese-trained VLMs produce more holistic (context-focused) captions than English-trained VLMs, with dataset cultural alignment amplifying the effect

## Executive Summary
This study investigates whether Vision-Language Models trained on Japanese and English exhibit culturally-grounded attentional patterns. Using image selection, caption generation, and in-context learning-based classification, the authors analyze holistic (context-focused) versus analytic (object-focused) descriptions. Results show Japanese models like GPT-4o-JP and larger models like Gemma-27B-JP generate more holistic captions, with up to 73% holistic output on Japanese-centric datasets. Dataset cultural alignment and model size significantly influence these patterns, suggesting VLMs internalize not just linguistic structure but culturally-influenced cognitive styles.

## Method Summary
The study employs a three-stage pipeline: (1) image selection using similarity voting across four object detectors to filter COCO images, (2) caption generation using language-specific VLMs (GPT-4o for English, GPT-4o-JP for Japanese), and (3) classification of captions as holistic or analytic using GPT-4o as judge with 5-shot or 6-shot in-context learning prompts. The classification threshold and prompt design significantly affect holistic ratio measurements, with balanced prompts reducing but not eliminating bias.

## Key Results
- GPT-4o-JP produces 26.10-28.64% holistic captions on COCO vs. GPT-4o-EN at 12.34-14.08%
- Japanese-centric datasets increase holistic output to 73.37% for GPT-4o-JP
- Larger models (GPT-4o-JP, Gemma-27B-JP) show stronger holistic tendencies than smaller models (VILA-JP-14B)
- Dataset cultural alignment amplifies holistic/analytic tendencies beyond language alone

## Why This Works (Mechanism)

### Mechanism 1: Training Data Internalization
VLMs learn statistical regularities in word order, attribute density, and scene framing from culturally-distinct training corpora. Japanese captions more frequently establish background context before identifying objects, creating holistic patterns that models reproduce during generation.

### Mechanism 2: Cultural Activation Through Images
Culturally-familiar images (Japanese landmarks, anime, food) activate latent patterns learned during training, producing stronger alignment with expected cognitive styles. Image content matters beyond language alone.

### Mechanism 3: Model Scale Enables Cultural Nuance
Larger models develop richer representations of cultural-contextual relationships through greater training data diversity, allowing more nuanced activation of culture-specific descriptive schemas when prompted in different languages.

## Foundational Learning

- **Holistic vs. Analytic Attention**: The paper operationalizes this dichotomy; holistic attention foregrounds context/relationships while analytic attention isolates objects. Quick check: Would a holistic description of a beach sunset begin with "the beach" or "the child"?

- **In-Context Learning (ICL) Classification**: The paper uses GPT-4o with 5-shot and 6-shot prompts to classify captions. Quick check: Why might a "balanced" 6-shot prompt produce different classifications than a random 5-shot prompt?

- **Cross-Cultural Psychology of Perception**: The paper grounds its hypothesis in Masuda & Nisbett's research showing East Asian participants attend more to context than Western participants. Quick check: What intellectual traditions does the paper cite as historical roots of holistic vs. analytic thinking?

## Architecture Onboarding

- **Component map**: Image Selection Pipeline (4 detectors → cosine similarity voting → filtered images) → Caption Generation Module (VLMs → language-specific captions) → Classification Module (GPT-4o ICL → binary output)

- **Critical path**: 1) Filter images with high-confidence object detection, 2) Generate captions in target language using appropriate VLM, 3) Classify via GPT-4o ICL with prompt design significantly affecting results

- **Design tradeoffs**: Prompting strategy affects holistic ratios by 2-7 points; culturally-specialized models don't always outperform general large models; dataset choice (COCO vs. Japanese-centric) produces 40+ point differences

- **Failure signatures**: Low classifier agreement indicates noisy image selection; small models + mismatched language prompts wash out cultural signal; evaluating only on culturally-unaligned datasets underestimates model's cultural capacity

- **First 3 experiments**: 1) Reproduce Table 1 on held-out COCO subset to verify GPT-4o-JP produces higher holistic ratios, 2) Ablate dataset alignment by generating captions for same images from COCO and 1K-JP datasets, 3) Test language-only switching by forcing GPT-4o to generate Japanese captions using English prompts

## Open Questions the Paper Calls Out
- Do the observed cognitive style divergences persist across a broader range of languages including Korean, Chinese, and Romance languages?
- To what extent are cognitive styles driven by linguistic structure versus cultural context embedded in training data?
- Is the ability to replicate cultural cognitive styles strictly a function of model parameter count or does it require specific architectural inductive biases?

## Limitations
- Limited evidence that training corpora actually contain the hypothesized holistic-analytic differences in descriptive patterns
- Classification relies entirely on GPT-4o's judgment, which could introduce its own cultural biases
- Language-switching experiments not performed to isolate linguistic vs. cultural effects

## Confidence
- **High Confidence**: Dataset cultural alignment significantly affects holistic/analytic ratios
- **Medium Confidence**: Model size correlates with cultural expression replication
- **Medium Confidence**: Japanese VLMs produce more holistic descriptions than English counterparts
- **Low Confidence**: Effect persists when controlling for all confounding factors

## Next Checks
1. Perform ablation studies varying training corpus composition while holding model architecture constant to isolate data effects
2. Implement language-only switching experiment (English prompts with Japanese output generation) to separate linguistic structure from cultural prompt effects
3. Measure inter-rater reliability of the GPT-4o classifier across different annotator populations to validate classification consistency