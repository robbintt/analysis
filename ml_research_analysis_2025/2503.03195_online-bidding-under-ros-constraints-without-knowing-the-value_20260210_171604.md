---
ver: rpa2
title: Online Bidding under RoS Constraints without Knowing the Value
arxiv_id: '2503.03195'
source_url: https://arxiv.org/abs/2503.03195
tags:
- regret
- value
- constraint
- algorithm
- constraints
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies online bidding in advertising with Return-on-Spend
  (RoS) and budget constraints, where the advertiser does not know the value of each
  impression in advance. The authors propose a novel UCB-style algorithm that simultaneously
  learns impression values and optimizes bids to maximize value while satisfying constraints.
---

# Online Bidding under RoS Constraints without Knowing the Value

## Quick Facts
- arXiv ID: 2503.03195
- Source URL: https://arxiv.org/abs/2503.03195
- Reference count: 40
- One-line primary result: Novel UCB-style algorithm achieves O(√(T log(|B|T)/V)) regret and constraint violation for online bidding with unknown values under RoS constraints.

## Executive Summary
This paper studies online bidding in advertising with Return-on-Spend (RoS) and budget constraints, where the advertiser does not know the value of each impression in advance. The authors propose a novel UCB-style algorithm that simultaneously learns impression values and optimizes bids to maximize value while satisfying constraints. The algorithm maintains confidence sets for allocation, pricing, and value estimates, then selects bids to maximize reward within these sets. Theoretical analysis shows the algorithm achieves O(√(T log(|B|T)/V)) regret and constraint violation, where T is the number of rounds and V is the maximum per-round value from an oracle. This improves upon prior work by avoiding restrictive assumptions like Slater points and achieving logarithmic dependence on the bid set size rather than √|B|.

## Method Summary
The algorithm maintains confidence sets for allocation (x), pricing (q), and value (v) estimates based on historical data. In each round, it solves an optimization problem that selects a bid distribution to maximize expected reward while satisfying constraints under optimistic parameter estimates. The key innovation is using upper confidence bounds for allocation and value (optimistic for reward) while using lower confidence bounds for pricing (pessimistic for cost). This ensures the algorithm explores bids that might yield high value while maintaining feasibility. The method explicitly avoids Slater conditions by basing its analysis on the oracle value V rather than constraint slack.

## Key Results
- Achieves O(√(T log(|B|T)/V)) regret and constraint violation bounds
- Improves upon prior primal-dual methods by avoiding Slater point assumptions
- Demonstrates logarithmic dependence on bid set size |B| rather than √|B|
- Shows strong empirical performance on synthetic data compared to existing approaches

## Why This Works (Mechanism)

### Mechanism 1: Optimistic Constrained Optimization via Confidence Sets
The algorithm achieves sub-linear regret by simultaneously maximizing an optimistic estimate of value while satisfying constraints under optimistic estimates of cost. It maintains confidence sets for allocation, pricing, and value, selecting upper confidence bounds for value and allocation but lower confidence bounds for pricing. This optimistic view allows exploration of high-value bids while assuming minimal costs.

### Mechanism 2: Replacing Slater Slack with Oracle Value Dependence
The algorithm avoids the performance collapse of primal-dual methods in tight feasible regions by basing its regret bound on the Oracle value (V) rather than the Slater slack (κ). This ensures that as long as the optimal strategy has non-zero value, the learner gathers enough samples to estimate values accurately, bounding regret independently of constraint slack.

### Mechanism 3: Efficient Non-Convex Reduction via Monotonicity
The seemingly intractable non-convex optimization of selecting the best optimistic model parameters is solved efficiently by exploiting auction monotonicity. Because allocation and payment functions in standard auctions are monotonic (higher bids → higher win prob/cost), the optimal choice always lies at the boundary of the confidence intervals.

## Foundational Learning

- **Concept: Upper Confidence Bound (UCB)**
  - Why needed here: This is the core heuristic ("Optimism in the Face of Uncertainty"). You must understand that the algorithm picks the best plausible scenario consistent with observed data to drive exploration.
  - Quick check question: If the algorithm has won 0 out of 100 auctions with bid b=0.5, would the UCB for the allocation function x̂(0.5) be high or low? (Answer: High, because uncertainty is high, and UCB is optimistic).

- **Concept: Slater's Condition & Duality**
  - Why needed here: To appreciate the paper's contribution, you need to know why existing constrained bandit algorithms fail. They act like a "math lawyer" arguing about constraints; if there is no wiggle room (Slater slack), the "argument" (dual variables) spirals out of control.
  - Quick check question: Why does a "Slater point" guarantee bounded dual variables in standard convex optimization?

- **Concept: Regret vs. Constraint Violation**
  - Why needed here: This paper optimizes the trade-off between doing well (Value) and following rules (RoS/Budget). You need to distinguish between "losing money" (regret) and "overspending" (constraint violation).
  - Quick check question: Does an algorithm with O(√T) regret guarantee zero constraint violation? (No, the paper proves O(√T) violation).

## Architecture Onboarding

- **Component map:** History Buffer -> Estimator -> Confidence Set Builder -> LP Solver -> Bid Sampler
- **Critical path:** The optimization step (Problem 3.3) is the bottleneck. While simplified by Lemma 3.2, it runs in O(|B|³) due to the LP. The size of the bid set B is the primary driver of computation time.
- **Design tradeoffs:**
  - Bid Set Granularity (|B|): Increasing the number of possible bids improves potential optimality but increases computation cost cubically (O(|B|³)) while only affecting regret logarithmically (log|B|). A coarse grid is computationally cheaper with minimal regret loss.
  - Conservativeness: The confidence interval width √(log(2|B|T)/(2t)) controls exploration. Wider intervals increase exploration (and constraint violation) but may slow convergence to the optimal bid.
- **Failure signatures:**
  - Value Collapse: If V is small, the term √T/V in the regret bound explodes. The algorithm will appear to "thrash" and fail to converge.
  - Distribution Shift: If the environment is non-stationary, the i.i.d. assumption fails. The confidence intervals will be invalid, leading to "Optimistic collapse" (assuming high value where none exists).
- **First 3 experiments:**
  1. Slater Stress Test: Replicate the scenario in Appendix F where κ ≈ 0 but V > 0. Compare UCB-RoS against a primal-dual baseline. Expectation: Primal-dual incurs linear regret; UCB-RoS remains stable.
  2. Scaling with |B|: Run the algorithm with varying bid set sizes. Plot Regret vs. log|B| and Runtime vs. |B|³ to verify theoretical dependencies.
  3. Constraint Drift: Visualize "cumulative spend" vs. "cumulative value" over time. Check if RoS constraint violation stays within the O(√T) bound or drifts linearly.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Can near-optimal regret and constraint violation bounds be achieved for online bidding with unknown values under adversarial (non-stochastic) competing bids and impression values?
- **Basis in paper:** [explicit] The conclusion states: "Another promising direction is to consider adversarial environments where the competing bids or impression values are chosen adversarially."
- **Why unresolved:** The UCB-style algorithm and its analysis fundamentally rely on stochastic (i.i.d.) assumptions for concentration inequalities and confidence set construction. The optimism-in-the-face-of-uncertainty principle does not naturally extend to adversarial settings without modification.
- **What evidence would resolve it:** An algorithm with provable sublinear regret and constraint violation bounds in an adversarial setting, or a formal lower bound proving impossibility of such guarantees.

### Open Question 2
- **Question:** Can the algorithm be extended to incorporate contextual information while maintaining theoretical guarantees?
- **Basis in paper:** [explicit] The conclusion states: "Finally, it would be valuable to develop variants of our algorithm that can incorporate contextual information into the decision-making process."
- **Why unresolved:** Contextual information introduces high-dimensional state spaces that require fundamentally different confidence set constructions, and the current LP-based optimization may not scale.
- **What evidence would resolve it:** A contextual variant with regret bounds scaling polynomially in context dimension rather than exponentially, validated empirically on realistic advertising datasets.

### Open Question 3
- **Question:** Is the 1/V dependence in the regret bound truly unavoidable for online bidding with unknown values and RoS constraints?
- **Basis in paper:** [inferred] The authors state: "we believe that a dependence on V is unavoidable. This conjecture is supported by the lower bound established in [1] for online bidding with unknown value (albeit without RoS constraints)." No formal lower bound exists for this specific setting.
- **Why unresolved:** The cited lower bound applies to unconstrained utility maximization; whether it extends to RoS-constrained value maximization remains unproven.
- **What evidence would resolve it:** A formal lower bound proof showing Ω(√T/V) regret is necessary, or an improved algorithm achieving better dependence on V.

### Open Question 4
- **Question:** Can the approach be extended to multi-advertiser settings with strategic interactions while preserving efficiency guarantees?
- **Basis in paper:** [explicit] The conclusion states: "One direction is to extend our approach to more complex settings, such as those with multiple advertisers."
- **Why unresolved:** Multiple advertisers introduce game-theoretic dynamics where each agent's bidding strategy affects others' outcomes. The single-agent analysis does not address equilibrium concepts or welfare at equilibrium.
- **What evidence would resolve it:** Equilibrium analysis (e.g., price of anarchy bounds) for multi-agent deployment, or convergence guarantees to approximately efficient equilibria under decentralized learning.

## Limitations

- **Stochastic Assumption Dependency**: The algorithm's theoretical guarantees rely heavily on the i.i.d. assumption for the underlying stochastic environment. In non-stationary or adversarial settings, the confidence intervals may fail to cover true parameters, leading to persistent constraint violations and poor regret performance.
- **Oracle Value Dependence**: The regret bound's inverse dependence on V creates sensitivity to the scale of rewards. When V is very small, the algorithm's performance degrades significantly, as reflected in the √T/V term in the bound.
- **Computational Complexity**: While the monotonicity reduction makes the problem tractable, solving the optimization Problem 3.3 still requires O(|B|³) computation per round due to the LP solver. This limits practical scalability to large bid sets.

## Confidence

- **High Confidence**: The algorithm's mechanism for using optimistic parameter estimates within confidence sets is sound and well-established in the bandit literature. The theoretical analysis correctly identifies how avoiding Slater conditions improves upon primal-dual approaches.
- **Medium Confidence**: The empirical results showing improved performance over baselines are promising, but the lack of competing algorithm hyperparameters and limited experimental diversity (synthetic data only) reduces confidence in generalizability to real-world advertising scenarios.
- **Low Confidence**: The paper's treatment of the relationship between bid set granularity and practical performance lacks depth. While the theory shows logarithmic dependence on |B|, the computational trade-offs and their real-world implications are not fully explored.

## Next Checks

1. **Slater Stress Test**: Replicate Appendix F's scenario where κ ≈ 0 but V > 0. Compare UCB-RoS against a primal-dual baseline (like [18]) to empirically verify that UCB-RoS remains stable while primal-dual incurs linear regret.

2. **Scaling Experiment**: Run the algorithm with varying bid set sizes (e.g., |B|=10, 100, 1000). Plot both Regret vs. log|B| and Runtime vs. |B|³ to verify the theoretical dependencies and assess the practical impact of bid granularity.

3. **Real-World Validation**: Implement the algorithm on real advertising auction data (e.g., from a DSP platform) to test whether the i.i.d. assumption holds and whether the algorithm's performance translates beyond synthetic environments.