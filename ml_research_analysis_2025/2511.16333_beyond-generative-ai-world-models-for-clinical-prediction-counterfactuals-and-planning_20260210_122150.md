---
ver: rpa2
title: 'Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals,
  and Planning'
arxiv_id: '2511.16333'
source_url: https://arxiv.org/abs/2511.16333
tags:
- generative
- world
- planning
- imaging
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This review shows that most world models in healthcare achieve\
  \ L1\u2013L2 capabilities (temporal and action-conditioned prediction), with fewer\
  \ instances of L3 (counterfactual rollouts) and rare L4 (planning/control). The\
  \ work highlights a shift from pure generative modeling toward prediction-first\
  \ dynamics learning using learned transitions p(st+1|st,at) and future-latent predictive\
  \ objectives (e.g., JEPA)."
---

# Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning

## Quick Facts
- arXiv ID: 2511.16333
- Source URL: https://arxiv.org/abs/2511.16333
- Reference count: 37
- Most world models in healthcare achieve L1–L2 capabilities (temporal and action-conditioned prediction), with fewer instances of L3 (counterfactual rollouts) and rare L4 (planning/control)

## Executive Summary
This review examines the current state of world models in healthcare, revealing a progression from basic generative modeling toward more sophisticated prediction-first dynamics learning. The analysis shows that while most systems achieve L1–L2 capabilities (temporal and action-conditioned prediction), fewer demonstrate L3 counterfactual reasoning and rare instances reach L4 planning and control. The work identifies critical gaps in action space formalization, interventional validation, multimodal state construction, and trajectory-level uncertainty calibration that must be addressed to advance clinically reliable higher-level world model systems.

## Method Summary
The review systematically analyzed published literature on world models in healthcare, categorizing systems based on their capabilities across four levels (L1–L4). The classification relied on qualitative assessment of methodological descriptions, focusing on temporal prediction, action-conditioned forecasting, counterfactual reasoning, and planning/control capabilities. The analysis examined cross-cutting themes including action space definitions, validation approaches, multimodal integration, and uncertainty handling. Papers were evaluated for their implementation of learned transition models p(st+1|st,at) and future-latent predictive objectives.

## Key Results
- Most healthcare world models achieve L1–L2 capabilities (temporal and action-conditioned prediction)
- Limited L3 capabilities (counterfactual rollouts) and rare L4 implementations (planning/control) exist
- Critical gaps include underspecified action spaces, weak interventional validation, incomplete multimodal state construction, and limited trajectory-level uncertainty calibration

## Why This Works (Mechanism)
World models in healthcare work by learning predictive dynamics from sequential clinical data, enabling systems to forecast patient states under various conditions. The shift from pure generative modeling to prediction-first dynamics learning allows these systems to learn transition functions p(st+1|st,at) that can be conditioned on actions. Future-latent predictive objectives like JEPA enable systems to plan without full reconstruction, improving efficiency. The framework's effectiveness stems from its ability to model temporal dependencies, incorporate interventions, and reason about counterfactual scenarios, though current implementations remain limited to lower capability levels.

## Foundational Learning
- **Temporal prediction**: Forecasting future patient states from historical data - needed to establish baseline predictive capabilities and validate model performance over time - quick check: can the model accurately predict vital signs 24 hours ahead?
- **Action-conditioned prediction**: Modeling how interventions affect future states - needed to enable interventional planning and treatment optimization - quick check: does the model correctly predict outcomes under different medication regimens?
- **Counterfactual reasoning**: Simulating alternative scenarios that didn't occur - needed for treatment comparison and decision support - quick check: can the model accurately predict what would have happened with different interventions?
- **Planning and control**: Optimizing sequences of actions to achieve desired outcomes - needed for automated treatment planning and closed-loop systems - quick check: can the model find optimal intervention sequences within clinical constraints?
- **Multimodal state construction**: Integrating diverse data types (vitals, labs, imaging, notes) - needed to capture complete patient representations - quick check: does the model maintain performance when combining multiple data modalities?
- **Uncertainty calibration**: Quantifying prediction reliability across trajectories - needed for safe clinical deployment and risk assessment - quick check: does the model's confidence align with actual prediction accuracy?

## Architecture Onboarding
- **Component map**: Data preprocessing -> State representation learning -> Transition model (p(st+1|st,at)) -> Prediction module -> Planning module (L4) -> Validation framework
- **Critical path**: State representation learning -> Transition model -> Prediction module -> Clinical validation
- **Design tradeoffs**: Generative vs. predictive objectives (full reconstruction vs. efficient planning), explicit vs. implicit action spaces, deterministic vs. probabilistic forecasting, model complexity vs. interpretability
- **Failure signatures**: Poor counterfactual accuracy indicates insufficient causal grounding, multimodal integration failures suggest state representation issues, planning failures indicate transition model inadequacy
- **First 3 experiments**: 1) Benchmark temporal prediction accuracy on MIMIC-IV vs. baselines, 2) Validate counterfactual rollouts against known clinical outcomes, 3) Test planning module on simulated treatment optimization tasks

## Open Questions the Paper Calls Out
None provided in the source material.

## Limitations
- The review's scope is limited to published literature, potentially underrepresenting emerging work on higher-level world model capabilities
- Classification into L1–L4 categories relies on qualitative assessment, which may vary across reviewers
- Many papers lack explicit action space definitions, making consistent categorization difficult
- The review does not account for unpublished or proprietary systems that may have advanced further in clinical deployment

## Confidence
- **High Confidence**: Most healthcare world models achieve L1–L2 capabilities, well-supported by corpus evidence and methodological descriptions
- **Medium Confidence**: Limited L3 and rare L4 capabilities based on current literature, but may not capture cutting-edge unpublished work
- **Medium Confidence**: Identified gaps in action space formalization, interventional validation, and multimodal state construction inferred from literature analysis

## Next Checks
1. Conduct systematic annotation of 50+ additional papers to validate the L1–L4 classification framework and assess inter-rater reliability
2. Implement and benchmark a minimal clinical world model on a standard dataset (e.g., MIMIC-IV) to empirically test the feasibility of L3 counterfactual rollouts
3. Survey domain experts to assess the clinical utility and feasibility of different action space formalizations for various intervention types