---
ver: rpa2
title: 'Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation'
arxiv_id: '2503.07826'
source_url: https://arxiv.org/abs/2503.07826
tags:
- function
- multi-turn
- data
- functions
- trajectories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for synthesizing high-quality training
  data for multi-turn function calling in large language models. The key idea is to
  model function interactions as a graph and use node operations to construct reliable
  function signature paths, then generate queries and function calls through iterative
  back-and-forth translation.
---

# Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation

## Quick Facts
- arXiv ID: 2503.07826
- Source URL: https://arxiv.org/abs/2503.07826
- Reference count: 29
- Primary result: 68.01 on BFCL-v3, 73.30 on ToolQuery, surpassing Gemini-1.5-pro-002

## Executive Summary
This paper proposes Magnet, a method for synthesizing high-quality training data for multi-turn function calling in large language models. The key innovation is modeling function interactions as a dependency graph and using node operations to construct reliable function signature paths. The method generates queries and function calls through iterative back-and-forth translation, using context distillation to guide generation of positive and negative trajectories with a teacher model. Experiments show that training on the synthesized data significantly improves performance on two benchmarks, achieving state-of-the-art results.

## Method Summary
Magnet synthesizes multi-turn function-calling training data through a three-phase process: First, it builds a local dependency graph from 5,011 APIs, sampling function signature paths via random walks of length 7. Second, it applies node operations (Insert, Merge, Split) to create realistic multi-turn scenarios and uses back-and-forth translation to convert signatures to queries and executable function calls. Third, it employs hint-based context distillation with Gemini-1.5-pro-002 to generate positive trajectories (with reference FCs as hints) and negative trajectories (with incorrect FCs from SFT model mistakes), then trains using SFT followed by mDPO.

## Key Results
- Magnet-14B-mDPO achieves 68.01 on BFCL-v3 and 73.30 on ToolQuery, surpassing the teacher model Gemini-1.5-pro-002
- Positive hints in context distillation improve multi-turn performance by 14.5% compared to direct teacher distillation
- Optimal irrelevance data ratio of 15-17% balances multi-turn success with hallucination detection

## Why This Works (Mechanism)

### Mechanism 1: Graph-Structured Dependency Sampling Creates Realistic Multi-Turn Chains
Structuring functions as a dependency graph and sampling via random walk produces more coherent multi-turn trajectories than random API sampling. Nodes represent functions; directed edges connect source outputs to target inputs. Random walks of length 7 sample paths where information naturally flows between turns. Three node operations—Insert (nested/implicit calls), Merge (parallel calls), Split (missing info)—systematically cover multi-turn failure modes.

### Mechanism 2: Hint-Based Context Distillation Improves Teacher Output Quality
Injecting ground-truth function calls as hints during trajectory generation reduces teacher model errors and enables contrastive preference learning. For positive trajectories, reference FCs are added as [Hint] sections after queries, guiding the teacher without explicit mention in final output. For negative trajectories, incorrect FCs collected from SFT model mistakes are injected as misleading hints.

### Mechanism 3: Back-and-Forth Translation Ensures Query-Execution Consistency
Alternating between query synthesis (back-translation) and executable FC generation (forth-translation) creates self-consistent training data. Given a function signature path Φ, back-translation M_b converts f_h → q_h (query). Forth-translation M_f converts (q_h, f_h, t_{h-1}) → fc_h (executable call with filled parameters), using previous outputs t_{h-1}.

## Foundational Learning

- **Direct Preference Optimization (DPO) and multi-turn DPO (mDPO)**: The paper uses mDPO loss to train against negative trajectories; understanding how preference pairs shape policy is essential. Quick check: Can you explain why mDPO sums log-probabilities across all turns in a trajectory rather than optimizing per-turn?

- **Context Distillation vs. Standard Knowledge Distillation**: Hint-based context distillation is the core data generation technique; differs from output-based distillation. Quick check: How does providing hints in context differ from fine-tuning on teacher outputs directly?

- **Function Calling as Structured Prediction**: FC requires generating valid function names and parameter values in specific formats; errors compound across turns. Quick check: What makes multi-turn FC harder than single-turn (nested dependencies, state tracking, irrelevance detection)?

## Architecture Onboarding

- **Component map:** Function Pool (5,011 APIs) → Local Dependency Graph Builder (30 neighbors per node) → FSP Generator (random walk + Insert/Merge/Split) → Back-and-Forth Translator (query synthesis ↔ executable FC generation) → Trajectory Distiller (hint-based positive/negative trajectory creation) → Training Pipeline (SFT → mDPO)

- **Critical path:** Graph construction → FSP sampling → Node operations → Translation → Hint injection → Teacher generation → SFT → mDPO. The graph quality and node operations directly determine challenge coverage; translation quality determines executable validity.

- **Design tradeoffs:** Random walk length (7 steps) balances complexity vs. coherence; longer paths increase error propagation. Irrelevance data ratio (15-17% optimal) trades off multi-turn success vs. hallucination detection. Hint-based distillation improves quality but requires ground-truth FCs, creating dependency on translation accuracy.

- **Failure signatures:** Low multi-turn scores with high single-turn scores → likely graph edge quality issue or insufficient node operation coverage. High hallucination rates → irrelevance data ratio too low. Negative trajectory mDPO provides no gain → hints may not be sufficiently contrastive.

- **First 3 experiments:**
  1. Ablate each node operation (Insert, Merge, Split) independently on a held-out multi-turn validation set; expect Insert to affect nested/long-dependency scores, Split to affect missing-function/param detection.
  2. Compare hint-based distillation vs. direct teacher output distillation on the same FSPs; measure multi-turn accuracy gap (paper reports 14.5% difference).
  3. Vary irrelevance data ratio (10%, 15%, 20%, 25%) and plot multi-turn success vs. irrelevance detection tradeoff curve to find task-specific optimal.

## Open Questions the Paper Calls Out

### Open Question 1
How can the Magnet synthesis pipeline be extended to generate "reflection" trajectories that train agents to autonomously recover from erroneous actions? The authors state in the Limitations section: "An ideal agent would be able to reflect on their wrong actions and restart the exploration, which is currently limited in our model, due to lack of such data in our training set."

### Open Question 2
What specific mechanisms are required to resolve conflicts where retrieved tool knowledge contradicts the model's internal parametric knowledge? The authors identify a failure mode where "the model might still output some fixed date... This reflects some limitations in resolving knowledge conflicts within context and internal knowledge."

### Open Question 3
Does the graph-based node operation approach (Insert, Merge, Split) generalize effectively to multi-lingual and multi-modal tool-use scenarios? The paper explicitly states: "The function signatures we studied... mainly consist of English and pure texts. It is possible some conclusions... might not generalize well to other languages and modalities."

### Open Question 4
Is the optimal ratio of irrelevance data (15-17%) universal, or does it vary significantly based on the base model's pre-training data composition? The paper notes a trade-off between multi-turn success and irrelevance detection, identifying an "optimal ratio" but stating the "exact ratio is subject to changes based on different tasks and models."

## Limitations

- The exact prompts for back-translation are abbreviated, making precise reproduction difficult
- The paper does not provide detailed validation of the dependency graph construction, which is critical for generating coherent multi-turn trajectories
- While ablation studies show node operations contribute to performance, the specific impact of each operation on different multi-turn failure modes is not quantified

## Confidence

- **High Confidence**: The overall framework of graph-based function signature paths and back-and-forth translation is sound and supported by the paper's results. The use of mDPO with preference pairs is a standard and effective approach.
- **Medium Confidence**: The specific implementation details, particularly the prompts and LLM interactions, are critical for success but not fully specified. The 14.5% improvement from hint-based distillation is impressive but needs independent replication.
- **Low Confidence**: The paper does not provide sufficient evidence that the synthesized data generalizes beyond the specific benchmarks (BFCL-v3, ToolQuery) used for evaluation.

## Next Checks

1. **Graph Quality Validation**: Manually sample and evaluate 30 random FSPs from the dependency graph to assess semantic coherence between consecutive functions.

2. **Ablation of Node Operations**: Independently measure the impact of each node operation (Insert, Merge, Split) on a held-out multi-turn validation set, focusing on nested dependencies, long chains, and irrelevance detection.

3. **Hint-Based Distillation Replication**: Replicate the hint-based distillation experiment, comparing it to direct teacher output distillation on the same FSPs, to verify the 14.5% improvement claim.