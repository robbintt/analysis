---
ver: rpa2
title: 'Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration'
arxiv_id: '2412.15701'
source_url: https://arxiv.org/abs/2412.15701
tags:
- task
- agent
- agents
- action
- co-gym
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Collaborative Gym (Co-Gym) introduces a framework for developing
  and evaluating human-agent collaboration with dual control over task environments
  and non-turn-taking interaction. The framework enables bidirectional communication
  between humans and agents through collaboration acts and a notification protocol,
  while providing an evaluation suite that assesses both collaboration outcomes and
  processes.
---

# Collaborative Gym: A Framework for Enabling and Evaluating Human-Agent Collaboration

## Quick Facts
- **arXiv ID**: 2412.15701
- **Source URL**: https://arxiv.org/abs/2412.15701
- **Reference count**: 40
- **Primary result**: Framework for human-agent collaboration with dual control and non-turn-taking interaction; benchmark experiments show collaborative agents outperform fully autonomous agents across three tasks.

## Executive Summary
Collaborative Gym (Co-Gym) introduces a framework for developing and evaluating collaborative agents that engage in bidirectional communication with humans while interacting with task environments. The framework supports asynchronous, non-turn-taking interaction through collaboration acts and a notification protocol, enabling both humans and agents to act on shared workspaces. Across three representative tasks—travel planning, related work writing, and tabular analysis—benchmark experiments demonstrate that collaborative agents consistently outperform fully autonomous agents, achieving win rates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related Work when evaluated by real users.

## Method Summary
Co-Gym models each task as a partially observable Markov decision process with shared and private observations. The framework implements a notification protocol using Redis to manage asynchronous communication through four event types: shared observation changes, private observation changes, messages, and inactivity. Three agent types are evaluated: Fully Autonomous, Collaborative, and Collaborative with Situational Planning. All agents use ReAct-style prompting with scratchpad memory for in-session context. The situational planning module adds a two-stage decision process: first classifying whether to take a task action, communicate, or wait, then executing. Evaluation occurs in both simulated mode (using a user simulator with hidden information) and real mode (with human participants), measuring delivery rate, task performance, initiative entropy, overall satisfaction, and win rate against autonomous baselines.

## Key Results
- Collaborative agents with situational planning achieved win rates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related Work when evaluated by real users.
- Non-turn-taking interaction achieved higher task performance (0.84 vs 0.81), satisfaction (3.95 vs 3.55), and 70% win rate compared to turn-taking baseline in ablation study.
- Communication failures were prevalent in 65% of real cases and 80% of simulated cases, while situational awareness failures occurred in 40% of real cases and 47% of simulated cases.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Non-turn-taking interaction with dual control improves human-agent collaboration outcomes compared to fully autonomous agents.
- Mechanism: The Co-Gym framework supports asynchronous collaboration through collaboration acts (SendTeammateMessage, WaitTeammateContinue) and a notification protocol. This allows both humans and agents to act on a shared workspace without enforced turn-taking, enabling opportunistic human intervention and parallel progress. The notification protocol broadcasts changes in shared observations, private changes, and messages, reducing coordination overhead.
- Core assumption: The assumption is that human-agent teams benefit from flexible, asynchronous interaction and that users value direct control over shared artifacts. This may not hold for purely conversational tasks or when users prefer passive roles.
- Evidence anchors:
  - [abstract] "Co-Gym introduces a framework for developing and evaluating collaborative agents that engage in bidirectional communication with humans while interacting with task environments... through a flexible, non-turn-taking interaction paradigm."
  - [section] Ablation study (Section 5.3, Table 6) shows Co-Gym's non-turn-taking interaction achieves higher task performance (0.84 vs 0.81), satisfaction (3.95 vs 3.55), and 70% win rate against a turn-taking baseline.
  - [corpus] CowPilot (arXiv:2501.16609) explores dual-control, turn-taking web navigation, providing a related but distinct approach. FMR indicates corpus evidence is moderate.
- Break condition: This mechanism may not generalize to tasks where strict turn-taking is preferred, or where the shared workspace model is not applicable (e.g., real-time physical collaboration).

### Mechanism 2
- Claim: Human-agent collaboration leads to higher task performance when agents leverage human expertise and latent preferences through iterative interaction.
- Mechanism: Collaborative agents (especially with situational planning) use a two-stage decision process: first classifying whether to take a task action, communicate, or wait, then executing. This enables proactive information seeking (e.g., asking for preferences before acting) and iterative refinement (e.g., incorporating feedback on drafts). The shared workspace and bidirectional communication allow humans to guide agents based on domain knowledge.
- Core assumption: The effectiveness assumes agents can effectively recognize when to ask for help and that humans have relevant expertise or preferences to contribute. It also assumes the iterative process does not introduce excessive overhead.
- Evidence anchors:
  - [abstract] "The best-performing collaborative agents consistently outperform their fully autonomous counterparts... achieving win rates of 86% in Travel Planning, 74% in Tabular Analysis, and 66% in Related Work."
  - [section] Section 5.1.1: "Among completed tasks, collaborative agents leads to better task performance. Collaborative Agent with Situational Planning achieves the best Task Performance across all three tasks."
  - [corpus] LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey (arXiv:2505.00753) notes reliability challenges with fully autonomous agents, supporting the need for collaboration. FMR indicates corpus evidence is weak.
- Break condition: Performance gains may diminish if agents cannot effectively integrate human feedback or if humans lack relevant expertise, leading to increased coordination costs without benefits.

### Mechanism 3
- Claim: Situational planning improves collaboration process metrics (e.g., initiative balance) and reduces communication failures compared to baseline collaborative agents.
- Mechanism: The situational planning module uses a 3-way classification prompt (task action, communicate, wait) before action generation. This explicit consideration step encourages proactive communication (e.g., asking clarifying questions), balanced initiative-taking, and waiting for responses when needed. The scratchpad memory helps maintain context over long sessions.
- Core assumption: The assumption is that this structured planning step helps the LM make more context-aware decisions about when to act, communicate, or wait, and that the benefits outweigh the additional inference step. It assumes the LM can follow the classification prompt effectively.
- Evidence anchors:
  - [section] Table 3 (Co-Gym Simulated): Collaborative Agent with Situational Planning shows higher Initiative Entropy (e.g., 0.90 vs 0.42 for GPT-4o in Travel Planning) and significant Task Performance improvements over baseline Collaborative Agents.
  - [section] Error analysis (Section 5.2, Table 5): Communication failures are prevalent (65% real, 80% simulated), suggesting room for improvement even with situational planning.
  - [corpus] Corpus evidence for this specific mechanism is weak; related work focuses on frameworks rather than internal agent planning modules.
- Break condition: If the underlying LM fails to follow the classification prompt accurately, or if the task requires rapid sequential actions, the additional planning step could introduce latency without benefits.

## Foundational Learning

- Concept: **Partially Observable Markov Decision Process (POMDP)**
  - Why needed here: Co-Gym models each task as a POMDP (Section 3.1) with shared and private observations. Understanding POMDPs is essential to grasp how agents operate with incomplete information and how observations drive decisions.
  - Quick check question: How does the private flag in Co-Gym's step function affect the notification protocol?

- Concept: **Asynchronous Event-Driven Architecture**
  - Why needed here: The notification protocol (Section 3.2, Listing 1) uses an event loop with channels (e.g., `{role}/obs`, `step`) managed by Redis. This enables non-turn-taking interaction.
  - Quick check question: Which event types trigger notifications to all team members versus only the associated party?

- Concept: **ReAct-style Prompting with Memory**
  - Why needed here: All agent types use ReAct prompting with a scratchpad for in-session memory (Section 5.1, Appendix E). This is the core agentic pattern used in Co-Gym.
  - Quick check question: What is the role of the scratchpad update prompt in the Collaborative Agent's workflow?

## Architecture Onboarding

- Component map:
  1. **EnvNode**: Manages task environment state, processes actions via `step(role, action)`, and emits notifications based on the private flag.
  2. **AgentNode**: Wraps the LM agent, subscribes to `{role}/obs` notifications, and sends actions to the `step` channel.
  3. **Notification Protocol (Redis)**: Implements channels for observation broadcasts (`{role}/obs`) and action steps (`step`), with event handling for four event types (shared obs, private obs, messages, inactivity).
  4. **Task Environments (CoEnv subclasses)**: Define task-specific action spaces, observation spaces, and scoring functions (e.g., TravelPlanning, RelatedWork, TabularAnalysis).
  5. **Collaborative Agent with Situational Planning**: Uses a scratchpad update prompt, a 3-way situational planning prompt, and an action generation prompt.

- Critical path:
  1. Human or agent takes an action.
  2. AgentNode sends action to `step` channel.
  3. EnvNode processes action, updates environment, and emits notifications based on action type and private flag.
  4. AgentNode and human UI receive notifications.
  5. AgentNode triggers LM inference: scratchpad update → situational planning (3-way classification) → action generation (if needed).
  6. If action is generated, it is sent back to the `step` channel. If "wait," AgentNode remains idle.

- Design tradeoffs:
  1. **Non-turn-taking vs. Turn-taking**: Non-turn-taking offers flexibility but risks concurrent edits or communication overload. Co-Gym ablation (Table 6) shows non-turn-taking preferred, but requires UI to handle concurrent updates.
  2. **Dual Control**: Allows human intervention but requires conflict resolution. Co-Gym does not specify merge strategies for concurrent edits.
  3. **Simulated vs. Real Conditions**: Simulated enables scalable testing but may not capture all human behaviors. Real is more realistic but resource-intensive.

- Failure signatures:
  1. **Communication Failures (C.1-C.7)**: Agent processes tasks without informing user (23-24%), doesn't confirm actions before execution (29-46%), provides inadequate summaries (14%). Fix: Improve situational planning prompts to enforce status updates.
  2. **Situational Awareness Failures (SA.1-SA.6)**: Repetitive queries (13-26%), failure to process multiple messages cohesively (11-9%). Fix: Enhance scratchpad memory to track past queries and responses.
  3. **Environment Awareness Failures (EA.1-EA.4)**: Proposing actions unavailable in the environment (2% real). Fix: Validate action feasibility before generation.

- First 3 experiments:
  1. **Baseline Replication**: Run a Fully Autonomous Agent and a Collaborative Agent with Situational Planning on the Travel Planning task in simulated mode. Compare Task Performance and Initiative Entropy to Table 3 values to validate your setup.
  2. **Ablation of Notification Protocol**: Remove the notification protocol and enforce turn-taking (as in Section 5.3) on a small sample (N=20). Compare task performance and user satisfaction to confirm the ablation result.
  3. **Error Analysis on New Task**: Add a simple new task environment (e.g., email drafting). Run a Collaborative Agent and manually annotate failures using the taxonomy in Table 10. Identify top failure modes and iterate on agent prompts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the dual-control, non-turn-taking interaction paradigm improve outcomes in creative design or real-time decision-making tasks?
- Basis in paper: [explicit] Appendix A states the current tasks are representative but limited, and "Including a wider variety of tasks, such as creative design or real-time decision-making, could provide more comprehensive evaluation."
- Why unresolved: The current benchmark only covers travel planning, tabular analysis, and related work writing, which may not share the same interaction dynamics as creative or time-sensitive domains.
- What evidence would resolve it: Benchmarking agent performance and human satisfaction on new Co-Gym environments designed for creative or real-time tasks.

### Open Question 2
- Question: Can the simulated condition be leveraged to effectively train or fine-tune collaborative agents?
- Basis in paper: [explicit] Appendix A notes that "exploring how to leverage simulated conditions to improve collaborative agents remains a meaningful direction for future work."
- Why unresolved: The paper currently utilizes the simulated condition primarily for reproducible evaluation rather than for agent optimization or learning.
- What evidence would resolve it: Demonstrating that agents trained or iteratively refined within Co-Gym (Simulated) show statistically significant performance gains when deployed in Co-Gym (Real).

### Open Question 3
- Question: How does the framework perform across diverse user populations with varying levels of domain expertise?
- Basis in paper: [explicit] Appendix A identifies "Deploying Co-Gym (Real) more broadly to include diverse user populations across varying expertise levels" as a critical next step.
- Why unresolved: The current real-world experiments involved a "relatively limited number of human participants" with specific recruitment criteria (e.g., professional travel planners).
- What evidence would resolve it: A large-scale user study analyzing task performance and satisfaction scores across a stratified sample of users with different expertise backgrounds.

### Open Question 4
- Question: What specific architectural modifications are required to mitigate the high rate of situational awareness and communication failures?
- Basis in paper: [inferred] The error analysis reveals situational awareness failures in 40% of real cases and communication failures in 65% (Table 5), highlighting persistent limitations in current agent scaffolding.
- Why unresolved: While the paper attributes these errors to underlying LMs and scaffolding, it does not propose specific structural solutions to these identified failure modes.
- What evidence would resolve it: An ablation study testing specific improvements to agent memory or planning modules that specifically target the SA and C error categories.

## Limitations

- The framework's effectiveness depends heavily on task suitability for the shared workspace model and users' willingness to engage in collaborative control.
- The evaluation reveals persistent failure modes, with communication failures in 65% of real interactions and situational awareness failures in 40%, suggesting current models struggle with fundamental collaboration requirements.
- The simulated evaluation, while enabling large-scale testing, may not fully capture human behavioral patterns, and the real evaluation sample sizes (50 trajectories per task) may limit generalizability.

## Confidence

**High Confidence**: The core framework design (dual control, non-turn-taking interaction, notification protocol) is well-specified and validated through ablation studies. The Task Performance metrics and win rates against autonomous agents are empirically measured.

**Medium Confidence**: The error taxonomy and identified failure modes are based on systematic annotation but may not capture all failure patterns. The simulated evaluation's fidelity to real human behavior remains uncertain.

**Low Confidence**: The framework's generalization to tasks beyond the three studied domains (travel planning, related work writing, tabular analysis) is not established, particularly for tasks requiring real-time physical collaboration or strict turn-taking preferences.

## Next Checks

1. **Cross-Domain Generalization Test**: Implement the framework for a new task domain (e.g., collaborative document editing or email management) and evaluate whether the same performance gains and failure patterns emerge.

2. **User Preference Validation**: Conduct a controlled study comparing user satisfaction and task outcomes between non-turn-taking and enforced turn-taking interaction modes across different user demographics and task types.

3. **Failure Mode Mitigation Experiment**: Design and implement targeted prompt engineering or architectural modifications to address the top two failure modes (communication failures and situational awareness failures), then re-evaluate performance to measure improvement.