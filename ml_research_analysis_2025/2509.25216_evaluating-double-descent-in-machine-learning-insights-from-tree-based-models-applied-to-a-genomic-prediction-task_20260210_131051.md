---
ver: rpa2
title: 'Evaluating Double Descent in Machine Learning: Insights from Tree-Based Models
  Applied to a Genomic Prediction Task'
arxiv_id: '2509.25216'
source_url: https://arxiv.org/abs/2509.25216
tags:
- descent
- double
- complexity
- learning
- leaf
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigated whether the double descent phenomenon\u2014\
  where test error first decreases, then increases, and decreases again as model complexity\
  \ grows\u2014is a true generalisation principle or an artefact of how complexity\
  \ is measured. Using decision trees and gradient boosting regressors on both genomic\
  \ and synthetic datasets, complexity was varied along two orthogonal axes: learner\
  \ capacity (e.g., number of leaves or boosting steps) and ensemble size."
---

# Evaluating Double Descent in Machine Learning: Insights from Tree-Based Models Applied to a Genomic Prediction Task

## Quick Facts
- arXiv ID: 2509.25216
- Source URL: https://arxiv.org/abs/2509.25216
- Authors: Guillermo Comesaña Cimadevila
- Reference count: 39
- One-line result: Double descent only emerges when learner capacity and ensemble size are scaled jointly, supporting the unfolding hypothesis that double descent is a projection artifact rather than a fundamental learning principle.

## Executive Summary
This study investigates whether double descent—a phenomenon where test error first decreases, then increases, and decreases again as model complexity grows—represents a true generalization principle or an artifact of how complexity is measured. Using decision trees and gradient boosting regressors on both genomic and synthetic datasets, the research varies complexity along two orthogonal axes: learner capacity (e.g., number of leaves or boosting steps) and ensemble size. The findings reveal that double descent consistently emerges only when complexity is scaled jointly across these axes, while independent variation produces classical U- or L-shaped generalization curves. This supports the unfolding hypothesis, suggesting double descent results from projecting distinct learning regimes onto a single complexity axis rather than reflecting fundamental generalization dynamics.

## Method Summary
The study examines double descent behavior using decision trees and gradient boosting regressors on genomic data (M. tuberculosis isoniazid resistance) and synthetic Friedman #1 benchmark. Complexity is varied along two orthogonal axes: learner capacity (P_leaf or P_boost) and ensemble size (P_ens). Three regimes are tested: varying P_leaf at fixed P_ens, varying P_ens at fixed P_leaf, and composite scaling (capacity first, then ensemble). The analysis uses 70:30 train-test splits with fixed random seed, squared-loss regression formulation, and test-set Mean Squared Error as the primary metric. The genomic dataset contains 765,413 SNPs from 500 samples, while the synthetic dataset uses n=500, p=50 with controlled noise.

## Key Results
- Double descent only appears when learner capacity and ensemble size are scaled jointly, not when varied independently
- When axes are decoupled, generalization follows classical U-shaped curves for capacity and L-shaped curves for ensemble size
- P_ens consistently acts as an implicit regularizer, reducing variance through ensemble averaging without changing individual learner bias
- The interpolation threshold (peak error) occurs at the point where training error approaches zero

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Double descent emerges only when learner capacity (P_leaf, P_boost) and ensemble size (P_ens) are scaled jointly, not independently.
- **Mechanism:** The composite scaling trajectory passes through three regimes: underfitting (low capacity), interpolation threshold (peak variance), and variance-controlled overparameterization (ensemble averaging). When projected onto a single complexity axis, these transitions produce the characteristic double descent curve.
- **Core assumption:** Learner capacity and ensemble size represent orthogonal complexity dimensions with distinct generalization dynamics.
- **Evidence anchors:**
  - [abstract] "double descent consistently emerges only when complexity is scaled jointly across these axes"
  - [Results] "When model complexity was increased in a composite manner... a clear double descent pattern emerged"
  - [corpus] Weak direct support; corpus focuses on double descent in neural networks and kernel methods without multi-axis analysis

### Mechanism 2
- **Claim:** The "unfolding hypothesis" explains double descent as a projection artifact rather than a fundamental learning principle.
- **Mechanism:** Distinct generalization behaviors—classical bias–variance trade-off along the capacity axis and monotonic improvement along the ensemble axis—appear merged when complexity is measured unidimensionally. Disentangling reveals the underlying separable dynamics.
- **Core assumption:** Generalization behavior is axis-specific; P_leaf governs bias–variance trade-off while P_ens provides variance reduction through averaging.
- **Evidence anchors:**
  - [abstract] "support[s] the unfolding hypothesis, which attributes double descent to the projection of distinct generalisation regimes onto a single complexity axis"
  - [Results] "when capacity and ensemble size are disentangled, the apparent double descent resolves into more interpretable U- and L-shaped curves"
  - [corpus] No direct validation; Curth et al. (2023) is cited but not present in corpus neighbors

### Mechanism 3
- **Claim:** Ensemble size (P_ens) functions as an implicit regularizer by reducing variance without capacity changes.
- **Mechanism:** Increasing P_ens adds independent learners whose errors average out, reducing ensemble variance while leaving individual learner bias unchanged. This produces monotonically improving L-shaped curves.
- **Core assumption:** Learners in the ensemble have sufficiently uncorrelated errors for averaging to reduce variance.
- **Evidence anchors:**
  - [Results] "holding P_leaf constant and increasing P_ens reduced MSE smoothly and monotonically, producing an L-shaped curve"
  - [Results] "P_ens consistently acted as a stabilising factor, revealing its role as an implicit regulariser"
  - [corpus] Indirect support from ensemble learning literature; no corpus papers test this specific mechanism

## Foundational Learning

- **Concept:** Bias–Variance Trade-off
  - **Why needed here:** The paper frames double descent against classical U-shaped generalization; understanding how bias decreases and variance increases with complexity is essential to interpret the results.
  - **Quick check question:** Can you sketch why test error is minimized at intermediate complexity in classical theory?

- **Concept:** Interpolation Threshold
  - **Why needed here:** The peak in double descent occurs near the point where models achieve zero training error; this threshold structures the transition between regimes.
  - **Quick check question:** What happens to training error as model parameters approach the number of training samples?

- **Concept:** Ensemble Variance Reduction
  - **Why needed here:** Explains why P_ens produces L-shaped curves while P_leaf produces U-shaped curves; averaging reduces variance without changing capacity.
  - **Quick check question:** Why does averaging predictions from multiple high-variance learners improve generalization?

## Architecture Onboarding

- **Component map:**
  - Learner capacity axis (P_leaf/P_boost) -> controls model expressivity and interpolation ability
  - Ensemble size axis (P_ens) -> controls variance through averaging
  - Composite trajectory -> sequential scaling (capacity first, then ensemble) traversing interpolation threshold

- **Critical path:** To reproduce double descent, first scale P_leaf/P_boost toward interpolation (training MSE → 0), then scale P_ens past the threshold. To avoid double descent, tune axes independently.

- **Design tradeoffs:**
  - High P_leaf with low P_ens: fast interpolation, high variance, risk of overfitting spike
  - Low P_leaf with high P_ens: stable but may underfit
  - Joint tuning: may obscure which axis drives performance changes

- **Failure signatures:**
  - Sharp test error peak near interpolation threshold when scaling capacity alone
  - Monotonic improvement when scaling only P_ens
  - Irreproducible double descent if axes are confounded in hyperparameter search

- **First 3 experiments:**
  1. Fix P_ens = 1, sweep P_leaf ∈ {2, ..., 500} on your dataset; expect U-shaped curve.
  2. Fix P_leaf = 100, sweep P_ens ∈ {1, ..., 50}; expect L-shaped monotonic decrease.
  3. Composite sweep: grow P_leaf to interpolation, then increase P_ens; expect double descent with peak at threshold.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Does the unfolding hypothesis provide a valid framework for understanding double descent in deep neural networks?
- **Basis in paper:** [explicit] The authors state, "Whether the unfolding hypothesis... offers a valid or useful framework for understanding double descent in deep neural networks remains an open question."
- **Why unresolved:** The study restricted its scope to classical (non-deep) learners, specifically tree-based models, leaving the applicability of the unfolding hypothesis to deep learning architectures unverified.
- **What evidence would resolve it:** Applying the multidimensional complexity scaling framework to deep neural networks to observe if double descent disappears when complexity axes (e.g., width vs. depth) are varied independently rather than jointly.

### Open Question 2
- **Question:** Does the multidimensional complexity framework explain generalisation dynamics in support vector machines (SVMs)?
- **Basis in paper:** [explicit] The authors note that results may not generalise to "other algorithmic families, such as support vector machines, where the dynamics of double descent have not yet been critically examined," and suggest extending the framework to them.
- **Why unresolved:** The current experiments utilized decision trees and gradient boosting, excluding kernel-based methods like SVMs.
- **What evidence would resolve it:** Replicating the orthogonal scaling experiments on SVMs to determine if independent axis scaling similarly reverts error curves to classical U- or L-shapes.

### Open Question 3
- **Question:** How do feature redundancy and label noise in high-dimensional biological data shift the interpolation threshold and error peaks?
- **Basis in paper:** [explicit] The authors highlight that retaining irrelevant features (redundancy) and inherent noise may have amplified variance, and suggest future work should "explore how factors such as dimensionality reduction, feature redundancy, and label noise shape generalisation dynamics."
- **Why unresolved:** The study intentionally avoided dimensionality reduction to align with specific double descent literature, leaving the interaction between data cleanliness and the unfolding hypothesis untested.
- **What evidence would resolve it:** Experiments systematically varying levels of feature redundancy and label noise while measuring the impact on the height and location of the test error peak near the interpolation threshold.

## Limitations

- The study lacks a formal mathematical model linking orthogonal complexity axes to double descent emergence, relying instead on empirical observations
- The genomic dataset (M. tuberculosis isoniazid resistance) represents a narrow application domain, limiting generalizability to other structured prediction tasks
- The unfolding hypothesis interpretation remains conceptual without rigorous theoretical grounding

## Confidence

- **High:** Double descent only appears under joint scaling of capacity and ensemble size
- **Medium:** Unfolding hypothesis as explanation for double descent artifact
- **Medium:** Ensemble size functions as implicit variance regularizer

## Next Checks

1. Replicate experiments with neural networks varying width and depth jointly vs independently to test if unfolding hypothesis extends beyond tree-based models
2. Implement theoretical analysis deriving double descent from variance decomposition along orthogonal complexity axes
3. Test robustness across multiple genomic datasets and classification tasks to validate domain-specific findings