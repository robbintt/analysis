---
ver: rpa2
title: 'FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup
  Segmentation in Fundus Images'
arxiv_id: '2502.06220'
source_url: https://arxiv.org/abs/2502.06220
tags:
- segmentation
- image
- fundus
- medical
- fundusam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces FunduSAM, a deep learning model that adapts
  the Segment Anything Model (SAM) for optic disc and cup segmentation in fundus images.
  The authors address the challenge of applying SAM to medical images by introducing
  three key modifications: Adapters for parameter-efficient fine-tuning, a Convolutional
  Block Attention Module (CBAM) for enhanced feature extraction, and polar transformation
  for preprocessing.'
---

# FunduSAM: A Specialized Deep Learning Model for Enhanced Optic Disc and Cup Segmentation in Fundus Images
## Quick Facts
- arXiv ID: 2502.06220
- Source URL: https://arxiv.org/abs/2502.06220
- Reference count: 30
- Achieves Dice scores of 0.961 for optic disc and 0.867 for optic cup segmentation on REFUGE dataset

## Executive Summary
This paper presents FunduSAM, a deep learning model that adapts the Segment Anything Model (SAM) for optic disc and cup segmentation in fundus images. The authors address the challenge of applying SAM to medical images by introducing three key modifications: Adapters for parameter-efficient fine-tuning, a Convolutional Block Attention Module (CBAM) for enhanced feature extraction, and polar transformation for preprocessing. The model is evaluated on the REFUGE dataset with 1,200 fundus images, achieving state-of-the-art performance with Dice scores of 0.961 for optic disc and 0.867 for optic cup, representing improvements of 3.44% and 8.24% over the next best method respectively.

## Method Summary
FunduSAM adapts the Segment Anything Model (SAM) for medical image segmentation through three key modifications. First, Adapters are added to the transformer layers to enable parameter-efficient fine-tuning while maintaining the generality of SAM. Second, a Convolutional Block Attention Module (CBAM) is incorporated into the CNN backbone to enhance feature extraction by applying both channel and spatial attention mechanisms. Third, polar transformation preprocessing is applied to the input images to better capture the circular anatomy of the optic disc and cup. The model is trained on the REFUGE dataset with 1,200 fundus images, using a combination of automatic point prompts generated from ground truth labels and the proposed architectural modifications.

## Key Results
- Achieved Dice scores of 0.961 for optic disc and 0.867 for optic cup segmentation on REFUGE dataset
- Improved performance by 3.44% and 8.24% over next best methods for optic disc and cup respectively
- Ablation study confirmed effectiveness of each component, with Adapters showing greatest impact

## Why This Works (Mechanism)
The model works by adapting SAM's transformer-based architecture to handle the specific challenges of medical image segmentation. The Adapter modules allow efficient fine-tuning of SAM's parameters for the medical domain while preserving its generalization capabilities. The CBAM attention mechanism helps the model focus on relevant anatomical features in fundus images. The polar transformation preprocessing better aligns with the circular geometry of optic structures, improving the model's ability to accurately delineate boundaries. These modifications together enable FunduSAM to overcome the domain gap between natural images (SAM's original training domain) and medical fundus images.

## Foundational Learning
- **Segment Anything Model (SAM)**: A foundation model for image segmentation that requires prompt-based interaction
  - Why needed: Provides a strong starting point with pre-trained weights on diverse natural images
  - Quick check: Verify SAM can perform basic segmentation on fundus images before modifications
  
- **Adapters in transformers**: Parameter-efficient fine-tuning modules added to transformer layers
  - Why needed: Enables domain adaptation without extensive retraining of entire SAM model
  - Quick check: Compare performance with and without adapters on a validation subset
  
- **Convolutional Block Attention Module (CBAM)**: Attention mechanism combining channel and spatial attention
  - Why needed: Enhances feature extraction for medical images with complex anatomical structures
  - Quick check: Measure attention maps' focus on relevant anatomical regions
  
- **Polar transformation**: Coordinate system conversion that maps Cartesian coordinates to polar coordinates
  - Why needed: Better represents circular anatomy of optic disc and cup structures
  - Quick check: Compare segmentation quality on polar vs. Cartesian transformed images
  
- **Optic disc localization**: Preliminary identification of optic disc center for cropping and transformation
  - Why needed: Required for accurate polar transformation preprocessing step
  - Quick check: Evaluate localization accuracy before and after transformation
  
- **Prompt engineering for medical segmentation**: Design of interaction mechanisms for medical image annotation
  - Why needed: SAM requires user prompts which must be adapted for clinical workflows
  - Quick check: Test different prompt types (points, boxes) on segmentation accuracy

## Architecture Onboarding
- Component map: Input Image -> OD Localization -> Polar Transformation -> FunduSAM (SAM + Adapters + CBAM) -> Segmentation Output
- Critical path: The preprocessing pipeline (localization + polar transformation) -> CBAM-enhanced feature extraction -> Adapter-based fine-tuning -> Segmentation head
- Design tradeoffs: Polar transformation improves circular structure segmentation but requires accurate OD localization; Adapters preserve SAM's generality but add complexity; CBAM improves feature extraction but increases computational cost
- Failure signatures: Poor OD localization leads to misaligned polar transformation; inadequate adapter training causes domain gap issues; missing CBAM reduces feature discrimination for small cup structures
- Three first experiments: 1) Evaluate FunduSAM without polar transformation to assess preprocessing impact; 2) Test different adapter configurations to find optimal fine-tuning strategy; 3) Compare CBAM with other attention mechanisms for feature enhancement

## Open Questions the Paper Calls Out
### Open Question 1
- Question: Does FunduSAM generalize to fundus images from diverse clinical settings and imaging devices beyond the REFUGE dataset?
- Basis in paper: The paper notes "due to the different shooting cameras, there are large differences in the color, texture and contrast" between REFUGE training and test sets, and acknowledges "domain adaptation problem." Evaluation is limited to a single dataset from one challenge.
- Why unresolved: No external validation or cross-dataset experiments were conducted. Real-world deployment would face variations in patient populations, disease stages, and imaging hardware not captured in REFUGE.
- What evidence would resolve it: Evaluation on independent public datasets (e.g., RIM-ONE, DRISHTI-GS, IDRiD) and multi-center clinical data with different camera systems.

### Open Question 2
- Question: How does FunduSAM's segmentation accuracy translate to clinically meaningful Cup-to-Disc Ratio (CDR) measurements for glaucoma screening?
- Basis in paper: The introduction emphasizes that "CDR is commonly used to assess the condition" and "early screening and accurate diagnosis are crucial," yet the paper only reports Dice and IoU segmentation metrics, not CDR estimation error or glaucoma classification performance.
- Why unresolved: High segmentation Dice does not guarantee accurate CDR calculation, particularly for small structures like the optic cup where boundary errors proportionally affect vertical diameter measurements more significantly.
- What evidence would resolve it: Direct evaluation of CDR estimation error against clinical ground truth, correlation with ophthalmologist assessments, and receiver operating characteristic analysis for glaucoma detection.

### Open Question 3
- Question: What is the impact of prompt type and quality on FunduSAM's segmentation performance in real clinical workflows?
- Basis in paper: The implementation states: "To simplify the experimental process, we randomly sample a point in the foreground region of the label to simulate the prompt process." This simulates idealized prompts rather than realistic clinical annotations.
- Why unresolved: SAM's interactivity is highlighted as "especially critical in the medical field," but the evaluation uses automatically generated point prompts from ground truth labels. Real clinical prompts may be imprecise, sparse, or use different modalities (bounding boxes, scribbles).
- What evidence would resolve it: Systematic evaluation across prompt types (points, boxes, scribbles), prompt quantities, and prompt noise levels; user studies with clinicians providing real prompts.

### Open Question 4
- Question: How dependent is FunduSAM's performance on the accuracy of the preliminary optic disc localization required for polar transformation?
- Basis in paper: The method section states "we used the method from Wang et al. [18] to crop the OD, and the cropped image is converted from a Cartesian coordinate system image to a polar coordinate system image."
- Why unresolved: The polar transformation preprocessing step requires accurate OD center/ROI localization before transformation. Pipeline errors from the cropping stage could propagate and degrade segmentation, but this dependency is not analyzed in the ablation study or error analysis.
- What evidence would resolve it: Sensitivity analysis varying the center point offset; evaluation of end-to-end pipeline including automatic OD localization; comparison with and without polar transformation when localization is imperfect.

## Limitations
- Relatively modest improvement in optic cup segmentation (8.24% gain) despite significant architectural modifications, suggesting potential fundamental constraints
- Reliance on polar transformation preprocessing may limit applicability to images with significant pathologies or non-standard acquisition angles
- Evaluation on a single dataset (REFUGE) with 1,200 images raises questions about generalizability to diverse clinical settings and populations

## Confidence
- High confidence in technical implementation and architectural modifications
- Medium confidence in claimed performance improvements due to single dataset evaluation
- Medium confidence in the ablation study results, though potential confounding effects between components exist

## Next Checks
1. Evaluate FunduSAM on multiple independent fundus image datasets with varying acquisition protocols and patient demographics
2. Test the model's robustness to severe pathological cases, including advanced glaucoma, diabetic retinopathy, and macular degeneration
3. Conduct a direct comparison with recent medical foundation models (like RETFound) using identical evaluation protocols and datasets