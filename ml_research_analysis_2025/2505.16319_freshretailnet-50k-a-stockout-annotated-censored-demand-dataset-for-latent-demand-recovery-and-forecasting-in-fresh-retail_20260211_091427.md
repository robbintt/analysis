---
ver: rpa2
title: 'FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent
  Demand Recovery and Forecasting in Fresh Retail'
arxiv_id: '2505.16319'
source_url: https://arxiv.org/abs/2505.16319
tags:
- demand
- forecasting
- data
- retail
- sales
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of censored demand estimation
  in perishable retail, where stockouts lead to unobserved demand and systematic forecasting
  bias. The authors introduce FreshRetailNet-50K, a large-scale benchmark dataset
  with 50,000 store-product time series, hourly sales data, and verified stockout
  annotations across 898 stores and 863 perishable SKUs.
---

# FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail

## Quick Facts
- arXiv ID: 2505.16319
- Source URL: https://arxiv.org/abs/2505.16319
- Reference count: 40
- Introduces a 50K time series dataset with verified stockout annotations for latent demand recovery in perishable retail

## Executive Summary
This paper addresses the challenge of censored demand estimation in perishable retail, where stockouts lead to unobserved demand and systematic forecasting bias. The authors introduce FreshRetailNet-50K, a large-scale benchmark dataset with 50,000 store-product time series, hourly sales data, and verified stockout annotations across 898 stores and 863 perishable SKUs. The dataset uniquely captures demand dynamics with hourly resolution and rich contextual covariates, enabling the study of latent demand recovery during stockouts. A two-stage modeling approach is proposed: first, reconstruct latent demand using precise stockout annotations, then train demand forecasting models on the recovered demand. Experimental results show a 2.73% improvement in prediction accuracy and a reduction in systematic demand underestimation from 7.37% to near-zero bias. The dataset and code are publicly released to support further research in demand imputation and perishable inventory optimization.

## Method Summary
The authors propose a two-stage approach to address censored demand in perishable retail. First, they reconstruct latent demand during stockout periods using a recovery model (TimesNet, iTransformer, or GPVAE) that leverages hourly sales, stockout masks, and contextual covariates including promotions, weather, and calendar features. Second, they train forecasting models (TFT) on the recovered demand rather than the censored sales data. This pipeline breaks the self-reinforcing cycle where models learn to mistake inventory scarcity for low demand, explicitly decoupling demand from supply constraints.

## Key Results
- 2.73% improvement in prediction accuracy when training on recovered demand versus raw sales
- Reduction in systematic demand underestimation from 7.37% to near-zero bias (0.57%-2.58% WPE)
- Hourly resolution captures demand suppression during stockouts that daily aggregation obscures
- Contextual covariates (promotions, weather) improve latent demand recovery accuracy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** A two-stage "recover-then-forecast" pipeline appears to reduce systematic demand underestimation (bias) more effectively than training directly on censored sales data.
- **Mechanism:** By explicitly reconstructing latent demand during stockout periods (Stage 1) before training the final forecasting model (Stage 2), the system breaks the self-reinforcing cycle where models learn to mistake inventory scarcity for low demand. This decouples the inventory constraint from the demand signal.
- **Core assumption:** The latent demand recovery model (e.g., TimesNet) can accurately generalize patterns from observed periods to unobserved stockout periods using available covariates.
- **Evidence anchors:**
  - [abstract] Reports reducing systematic demand underestimation from 7.37% to near-zero bias.
  - [section 5.3] Table 3 shows that TFT trained on Raw Sales has a WPE of -7.37%, which improves to 0.57%-2.58% when trained on recovered demand.
  - [corpus] Paper 79620 ("Dynamic Pricing with Adversarially-Censored Demands") reinforces the theoretical need to handle censored demand separately from inventory constraints to avoid policy bias.
- **Break condition:** If the recovery model introduces high variance or overestimation during imputation, the subsequent forecasting model may overstock, leading to increased spoilage.

### Mechanism 2
- **Claim:** Hourly temporal resolution is likely necessary to accurately distinguish true zero demand from stockout-induced zero demand in perishable retail.
- **Mechanism:** Daily or weekly aggregations average out stockout signals (e.g., a 2-hour stockout becomes a minor dip in daily sales). Hourly data captures the sharp "zero sales" signal specific to the stockout window, allowing the model to flag and impute only the specific censored hours rather than smoothing over the whole day.
- **Core assumption:** Inventory status and sales are recorded synchronously at the hourly level; data alignment errors (lag) do not misclassify the cause of zero sales.
- **Evidence anchors:**
  - [section 2.1] States that daily/weekly aggregation "obscures stockouts due to temporal averaging effects," whereas hourly data "reveals far more pronounced demand suppression."
  - [abstract] Highlights "hourly sales data" as a unique capability enabling the study of latent demand.
  - [corpus] Paper 88991 (VN2 Winner Report) supports the importance of granular feature engineering for stockout-aware forecasting, though focuses on weekly cycles.
- **Break condition:** If demand is extremely sparse (e.g., low-sale items with 0-1 units/hour), hourly resolution may result in excessive zero-inflation, destabilizing the imputation model.

### Mechanism 3
- **Claim:** Treating stockouts as Missing Not At Random (MNAR) events driven by covariates (promotions, weather) improves recovery accuracy over standard imputation.
- **Mechanism:** Stockouts are not random; they correlate with high demand (promotions) or external factors (weather). By feeding these covariates into the recovery model, the mechanism explicitly accounts for the cause of the stockout, allowing it to predict the "missing" demand based on the context (e.g., if it rained and a promo ran, the latent demand was likely high).
- **Core assumption:** The covariates (precipitation, discounts) have a stable, learnable relationship with demand uplift across different stores and SKUs.
- **Evidence anchors:**
  - [section 3.3] "Stockout events... exhibit structured missingness patterns... Promotional depth... increases stockouts... by amplifying demand."
  - [section 4.1] Equation 3 defines the recovery function $\hat{d}$ as explicitly dependent on promotional ($p$), weather ($w$), and calendar ($c$) features.
  - [corpus] Paper 13021 ("Diffusion-aware Censored Gaussian Processes") aligns with this approach, modeling censored observations with covariate-aware uncertainty.
- **Break condition:** If covariate data is missing or delayed (e.g., weather forecast errors), the recovery model may fail to predict the demand surge, reverting to mean imputation.

## Foundational Learning

- **Concept: Censored Demand vs. Sales**
  - **Why needed here:** This paper is built on the premise that sales â‰  demand. A practitioner must understand that training on sales data inherently teaches the model to repeat inventory failures (stockouts).
  - **Quick check question:** If a product sells 0 units today, does that mean customers didn't want it, or that the shelf was empty?

- **Concept: Missing Not At Random (MNAR)**
  - **Why needed here:** Standard imputation (mean, forward-fill) fails here because the "missing" data (stockouts) is systematically correlated with high demand (e.g., during promotions). The missingness itself is a signal.
  - **Quick check question:** Why would filling missing stockout hours with the average of non-stockout hours lead to underestimation?

- **Concept: Intra-day Temporal Dynamics (Bimodality)**
  - **Why needed here:** Fresh retail exhibits specific peaks (9 AM, 4 PM). Models must capture these cycles to accurately recover demand for a stockout occurring at 11 AM versus 11 PM.
  - **Quick check question:** How would a daily aggregation model fail to capture the urgency of replenishing stock before the 4 PM pre-dinner rush?

## Architecture Onboarding

- **Component map:** Hourly Sales ($y$) + Stockout Mask ($s$) + Covariates (Promos $p$, Weather $w$, Calendar $c$) -> Recovery Engine -> Aggregator -> Forecaster
- **Critical path:** The accuracy of the final forecast depends almost entirely on the **Recovery Engine's** ability to decouple demand from supply constraints. If Stage 1 imputes garbage, Stage 2 forecasts garbage.
- **Design tradeoffs:**
  - TimesNet vs. Transformers: The paper notes TimesNet excels at multi-periodicity (daily/weekly cycles) but Transformers (iTransformer) may better handle covariate fusion.
  - Bias vs. Accuracy: Some methods (GPVAE) might smooth data (lower accuracy) but reduce bias.
  - Complexity: A two-stage pipeline is harder to maintain than an end-to-end model, but the paper argues the bias reduction is worth the cost.
- **Failure signatures:**
  - **Overestimation:** If the recovery model is too aggressive, it may hallucinate demand during stockouts, leading to overstocking and spoilage (high WPE positive).
  - **High Variance in Low-Sale Items:** The paper warns that sparse, long-tail SKUs are prone to instability; generic models may fail here.
  - **Metric Confusion:** Optimizing solely for WAPE (magnitude) might hide systematic bias (WPE). You must monitor both.
- **First 3 experiments:**
  1. **Baseline Establishment:** Train a TFT model directly on raw sales (no recovery). Measure WPE to confirm the negative bias (underestimation).
  2. **Ablation on Granularity:** Compare recovering demand using hourly data vs. daily data to verify that daily aggregation obscures the stockout signal.
  3. **Covariate Sensitivity:** Run the recovery model with and without weather/promo covariates during known stockout periods to quantify the "MNAR" effect (how much info is lost by ignoring context).

## Open Questions the Paper Calls Out
- The paper does not explicitly call out open questions in the provided content.

## Limitations
- Dataset is limited to a single fresh-retail chain in China, raising questions about generalizability across different markets, product categories, and inventory policies.
- Recovery performance on extremely sparse items (very low daily sales) is not thoroughly validated; the paper notes these as "long-tail" cases prone to instability.
- Two-stage pipeline adds operational complexity and may be sensitive to errors in the first stage propagating to the second.

## Confidence

**Key Limitations**
- Dataset is limited to a single fresh-retail chain in China, raising questions about generalizability across different markets, product categories, and inventory policies.
- Recovery performance on extremely sparse items (very low daily sales) is not thoroughly validated; the paper notes these as "long-tail" cases prone to instability.
- Two-stage pipeline adds operational complexity and may be sensitive to errors in the first stage propagating to the second.

**Confidence Labels**
- High: The existence of systematic underestimation when training on censored sales (supported by WPE of -7.37% in Table 3).
- Medium: The claim that hourly resolution is strictly necessary (daily aggregation experiments are not shown).
- Low: Generalization of recovery performance to markets with different demand patterns or promotion structures.

## Next Checks
1. Test the recovery model on a dataset from a different geographic market to assess cross-dataset generalization.
2. Conduct an ablation study comparing hourly vs. daily aggregation recovery to quantify the cost of temporal smoothing.
3. Evaluate model performance on the bottom 10% of sparse SKUs to measure stability on long-tail items.