---
ver: rpa2
title: Effects of Distributional Biases on Gradient-Based Causal Discovery in the
  Bivariate Categorical Case
arxiv_id: '2509.01621'
source_url: https://arxiv.org/abs/2509.01621
tags:
- causal
- distribution
- learning
- case
- interventions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how distributional biases affect gradient-based
  causal discovery in the bivariate categorical case. The authors identify two key
  biases: Marginal Distribution Asymmetry (differences in entropy between marginal
  distributions) and Marginal Distribution Shift Asymmetry (unequal distribution shifts
  during interventions).'
---

# Effects of Distributional Biases on Gradient-Based Causal Discovery in the Bivariate Categorical Case

## Quick Facts
- **arXiv ID:** 2509.01621
- **Source URL:** https://arxiv.org/abs/2509.01621
- **Reference count:** 33
- **Key outcome:** This paper investigates how distributional biases affect gradient-based causal discovery in the bivariate categorical case, showing that entropy differences and intervention asymmetries can mislead causal inference.

## Executive Summary
This paper identifies two key distributional biases that affect gradient-based causal discovery in bivariate categorical systems. The first bias, Marginal Distribution Asymmetry, arises when marginal distributions have different entropies, causing models to favor predicting the lower-entropy variable regardless of true causal direction. The second bias, Marginal Distribution Shift Asymmetry, occurs when interventions are applied asymmetrically, leading models to perceive the variable with faster-changing distributions as the independent cause. Through experiments with simple marginal and conditional models, the authors demonstrate these biases can significantly impact convergence and even reverse inferred causal directions. Notably, the ENCO model is shown to be robust to both biases by avoiding direct competition between causal factorizations.

## Method Summary
The study uses synthetic bivariate categorical data where variables have K=5 categories. Distributional biases are controlled through Dirichlet prior parameters (ε) and intervention rates (λ). The Marginal Distribution Asymmetry is created by setting α1=1K and α2=1/(εK)1K, while Marginal Distribution Shift Asymmetry is controlled by the proportion λ of interventions applied to X2 versus X1. Two simple models (Marginal Model with vector i and Conditional Model with matrix W) are trained using Gumbel-Softmax to represent discrete structural parameters as continuous weights. The models are optimized using Adam with learning rate 0.1 for 300 epochs with batch size 128. Success is measured by the convergence of structural parameter c1, where values near 1 indicate correct factorization X1→X2 and values near 0 indicate the reverse direction.

## Key Results
- Both Marginal Distribution Asymmetry and Marginal Distribution Shift Asymmetry can significantly bias gradient-based causal discovery models
- Bias 2 (intervention asymmetry) can fully reverse the direction of causal inference when distribution shifts are unbalanced
- The ENCO model demonstrates robustness to both biases by analyzing causal dependencies separately for each variable
- Gradient-based methods are particularly susceptible to these biases when competing between different causal factorizations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Gradient-based models may converge to incorrect causal factorizations if marginal entropies differ (Bias 1).
- **Mechanism:** If P(X1) has lower entropy (is "spikier") than P(X2), the optimization landscape favors factorizations that rely on predicting the lower-entropy variable. The model effectively exploits the "easier" distribution regardless of true causal direction.
- **Core assumption:** The optimizer gravitates toward minima that minimize prediction error for the most constrained (low-entropy) variables first.
- **Evidence anchors:**
  - [abstract]: Identifies "Marginal Distribution Asymmetry, where differences in entropy skew causal learning."
  - [section]: Section 5.1 shows "both models favor predicting the variable with the lower entropy."
  - [corpus]: Weak/no direct corpus support for this specific bias; neighboring papers focus on density ratios or velocity models.
- **Break condition:** Setting ε=1 (BDe prior) equalizes entropy, eliminating the bias.

### Mechanism 2
- **Claim:** Models can be misled by the rate of distribution shift during interventions (Bias 2).
- **Mechanism:** Interventions on a variable change its distribution (measured by KL divergence). If interventions are applied asymmetrically (parameter λ), the variable with the faster-changing distribution generates a stronger learning signal, potentially causing the model to infer it as the independent cause.
- **Core assumption:** Structural parameter updates correlate with the magnitude of distribution shifts observed across intervention steps.
- **Evidence anchors:**
  - [abstract]: Identifies "Marginal Distribution Shift Asymmetry, where repeated interventions cause faster shifts."
  - [section]: Section 5.2 notes models "perceive the variable with the faster-changing marginal distribution... as the independent variable."
  - [corpus]: Weak corpus alignment; related works do not explicitly model intervention frequency asymmetry.
- **Break condition:** Calibrating λ such that distribution shifts are balanced (ΔS1,2 ≈ 0).

### Mechanism 3
- **Claim:** Architectures that decouple edge existence from direction (e.g., ENCO) are robust to these biases.
- **Mechanism:** Instead of comparing competing factorizations (X→Y vs. Y→X) directly via likelihood, ENCO compares the likelihood of Y given X vs. Y independent of X. This isolates the gain of adding a specific edge without conflating it with the marginal learnability of the target variable.
- **Core assumption:** A true causal dependency improves the likelihood of the effect variable more than a spurious one, even under distributional asymmetry.
- **Evidence anchors:**
  - [abstract]: Notes that "eliminating competition between possible causal factorizations can make models robust."
  - [section]: Section 5.3 Equation 12 shows ENCO gradients compare L(X→Y) vs L(¬X→Y), neutralizing marginal bias.
  - [corpus]: "Incorporating structural uncertainty" (corpus) discusses model averaging, which aligns with avoiding hard competitive commitments, though not the exact mechanism.
- **Break condition:** If the loss function forces a direct likelihood competition between opposing arrows (X→Y vs. Y→X), robustness is lost.

## Foundational Learning

- **Concept:** **Entropy and KL Divergence**
  - **Why needed here:** Essential to quantify the two biases: Bias 1 is defined by entropy differences (H(X)), and Bias 2 by distribution shift differences (DKL).
  - **Quick check question:** If P(X) changes to P'(X), does DKL(P'||P) measure the "distance" or the "information gain"?

- **Concept:** **Interventional vs. Observational Data**
  - **Why needed here:** Bias 2 specifically arises from the frequency (λ) and type of interventions (Cases 1-4), which temporarily break causal dependencies.
  - **Quick check question:** In an interventional setting on X, does P(Y|X) remain invariant, or does P(Y|do(X))?

- **Concept:** **Gumbel-Softmax Relaxation**
  - **Why needed here:** The models use Gumbel-Softmax to represent discrete structural parameters (c1, c2) as continuous weights, allowing gradient flow.
  - **Quick check question:** How does the temperature parameter τ affect the "discreteness" of the structural decision?

## Architecture Onboarding

- **Component map:** Data Generator -> Models (MM/CM) -> Optimization (Adam)
- **Critical path:**
  1. Generate bivariate samples with controlled ε and intervention frequency λ
  2. Pass samples through MM or CM to get predictions x̂
  3. Calculate Cross-Entropy loss
  4. Backpropagate to update structural logits (z) and functional weights
- **Design tradeoffs:** Increasing ε allows testing robustness to entropy imbalance but reduces synthetic data realism; lowering Gumbel temperature speeds convergence but risks premature locking to wrong directions
- **Failure signatures:**
  - **Bias 1 Failure:** Model converges to X2→X1 when X1 has high entropy, even if ground truth is X1→X2
  - **Bias 2 Failure:** Model direction flips when λ crosses the balance point (ΔS ≈ 0)
- **First 3 experiments:**
  1. **Observational Baseline:** Set λ=0 (no interventions). Sweep ε from 0.1 to 10. Verify if model convergence tracks the low-entropy variable (Section 5.1)
  2. **Interventional Stress Test:** Set ε=1 (symmetric). Sweep λ from 0 to 1. Verify if convergence flips from c1 ≈ 1 to c1 ≈ 0 as λ increases (Section 5.2)
  3. **Robustness Verification:** Run ENCO on the setting from Experiment 2. Confirm that structural parameters (θ12) remain stable (near 1.0) across all λ values (Section 5.3)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do Marginal Distribution Asymmetry and Marginal Distribution Shift Asymmetry affect gradient-based causal discovery in multivariate settings with more than two variables?
- Basis in paper: Inferred. The paper explicitly restricts its theoretical and empirical analysis to the "bivariate categorical case," leaving the behavior of more complex DAGs unexplored.
- Why unresolved: The interaction between these biases and larger causal structures (e.g., v-structures or longer causal chains) could dampen or amplify the observed convergence failures.
- What evidence would resolve it: Empirical evaluation of susceptible methods on synthetic multivariate datasets while controlling for ε and λ.

### Open Question 2
- Question: Can the "competition between possible causal factorizations" be effectively removed from susceptible architectures to improve robustness without compromising other performance metrics?
- Basis in paper: Explicit. The authors suggest in the conclusion that "eliminating competition between possible causal factorizations can make models robust," implying this as a design goal for future work.
- Why unresolved: While ENCO avoids competition, it is unclear if standard competition-based objectives (like those in Bengio et al.) can be modified to gain robustness without losing their specific learning dynamics.
- What evidence would resolve it: Ablation studies modifying the loss functions of susceptible models to isolate factorization learning.

### Open Question 3
- Question: Do the identified distributional biases persist or manifest differently in continuous data distributions compared to the categorical case?
- Basis in paper: Inferred. The paper relies on entropy definitions for categorical variables and Dirichlet priors; it does not confirm if the mechanisms apply to continuous variables used in many real-world applications.
- Why unresolved: The relationship between entropy differences and "spikiness" may differ in continuous spaces, potentially altering the effect of Bias 1.
- What evidence would resolve it: Theoretical derivation of Bias 1 using differential entropy and experiments on continuous synthetic data (e.g., Gaussian processes).

## Limitations
- The study is limited to bivariate categorical systems, leaving scalability to higher-dimensional or mixed-type data unexplored
- The simulation-based approach may not fully capture the complexity of real-world causal discovery scenarios where multiple biases could interact simultaneously
- The work focuses exclusively on synthetic data, without validation on real observational or interventional datasets

## Confidence
- Claims about Bias 1 (entropy asymmetry) affecting convergence: **Medium** - well-supported by controlled experiments but limited to synthetic data
- Claims about Bias 2 (intervention asymmetry) reversing causal direction: **Medium** - demonstrated in specific parameter ranges but mechanism requires further validation
- Claims about ENCO's robustness: **High** - clearly demonstrated through direct comparison, though based on limited experimental scope

## Next Checks
1. **Multi-variable Extension:** Test whether the identified biases persist when extending from bivariate to trivariate or higher-dimensional categorical causal graphs, where the interaction between multiple variables may amplify or mitigate these effects.

2. **Real-world Data Validation:** Apply the gradient-based causal discovery methods to real observational and interventional datasets (e.g., medical or economic data) to verify whether the distributional biases identified in synthetic settings manifest similarly in practice.

3. **Bias Interaction Analysis:** Systematically vary both ε and λ simultaneously to study how the two biases interact - whether they compound, cancel, or create new failure modes when both entropy asymmetry and intervention asymmetry are present together.