---
ver: rpa2
title: License Plate Images Generation with Diffusion Models
arxiv_id: '2501.03374'
source_url: https://arxiv.org/abs/2501.03374
tags:
- images
- dataset
- synthetic
- data
- license
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of limited publicly available
  license plate datasets due to privacy regulations like GDPR. The authors propose
  using diffusion models to synthesize realistic license plate images as a solution.
---

# License Plate Images Generation with Diffusion Models

## Quick Facts
- arXiv ID: 2501.03374
- Source URL: https://arxiv.org/abs/2501.03374
- Authors: Mariia Shpir; Nadiya Shvai; Amir Nakib
- Reference count: 34
- Primary result: Diffusion model generates realistic Ukrainian license plates, improving LPR accuracy by 3% when expanded with pseudolabeled synthetic data

## Executive Summary
This paper addresses the challenge of limited publicly available license plate datasets due to privacy regulations like GDPR by proposing diffusion models for synthetic generation. The authors train a Denoising Diffusion Probabilistic Model (DDPM) on 78k Ukrainian license plate images and generate 1000 synthetic images for analysis. The generated images achieve an 86.4% success rate when manually classified for structural validity. The synthetic data is used to train a license plate recognition model, showing a 3% improvement in accuracy compared to a baseline model trained on real data when the synthetic dataset is expanded with pseudolabeled images. The authors release a synthetic dataset of 10,000 Ukrainian license plate images.

## Method Summary
The method involves training a DDPM on 78,855 real Ukrainian license plate images resized to 64x64 pixels. The diffusion model uses 5 resolution levels with self-attention at 16x16 and 8x8, trained for 100 epochs with AdamW optimizer (LR 1e-4 with cosine scheduler). Generated images are manually validated for "AA0000AA" format compliance. A YOLOv9-c model is trained on 864 manually labeled synthetic images, then used to pseudolabel an expanded dataset of 15,864 images with a confidence threshold of 0.8. The final LPR model is trained on this expanded dataset.

## Key Results
- Generated images achieve 86.4% success rate for structural validity (AA0000AA format)
- Synthetic data expanded with pseudolabeling improves LPR accuracy by 3% (94.1% → 97.5%)
- Fréchet Inception Distance (FID) score of 22.47 indicates reasonable distributional similarity
- Released synthetic dataset contains 10,000 Ukrainian license plate images

## Why This Works (Mechanism)

### Mechanism 1: Iterative Denoising for Structured Text Generation
Denoising Diffusion Probabilistic Models (DDPMs) can synthesize license plate images with valid textual structures and background textures where GANs often struggle with stability. The model learns to reverse a gradual noising process, iteratively refining the image tensor over many steps (e.g., 100 epochs). This progressive refinement allows the model to settle into stable local minima representing valid plate formats ("AA0000AA") and character geometries. The training dataset (78k images) must be sufficiently large and diverse to cover the manifold of valid license plate appearances without mode collapse.

### Mechanism 2: Volume-Based Compensation via Pseudolabeling
Scaling synthetic data volume with pseudolabeling improves downstream recognition accuracy (LPR) beyond what is achievable with a limited set of real data. A small set of manually labeled synthetic images (864) bootstraps a detector (YOLOv9-c), which is used to pseudolabel a much larger set of synthetic images (expanding to 15,864). The downstream model generalizes better from this larger, slightly noisy synthetic distribution than from a tiny, overfitting real distribution. Pseudolabels generated with high confidence (threshold 0.8) are accurate enough to act as ground truth for training.

### Mechanism 3: Distributional Fidelity in Generation
The diffusion model implicitly learns the statistical frequency of characters and regional codes, generating a synthetic dataset that mirrors the "difficulty spectrum" of real data. By training on real images, the model captures the prior probability of specific prefixes (e.g., region codes) and character shapes. The real training data must be representative of the target deployment distribution for this mechanism to work effectively.

## Foundational Learning

- **Concept: Denoising Diffusion Probabilistic Models (DDPM)**
  - **Why needed here:** This is the core generative engine. Unlike GANs which map noise to image in one step, DDPMs use a Markov chain to slowly denoise data.
  - **Quick check question:** Can you explain why a "cosine scheduler" for the learning rate might help a diffusion model converge on high-frequency details like text strokes compared to a constant rate?

- **Concept: Pseudolabeling (Semi-Supervised Learning)**
  - **Why needed here:** The paper bridges the gap between synthetic utility and real performance using this technique. It converts unlabeled synthetic data into labeled training data using a model trained on a small labeled subset.
  - **Quick check question:** What is the risk of setting the confidence threshold too low (e.g., 0.3) when generating pseudolabels for the 15k dataset expansion?

- **Concept: Fréchet Inception Distance (FID)**
  - **Why needed here:** Used as a quantitative metric for generation quality. It compares the distribution of generated features (from a pre-trained Inception network) to real features.
  - **Quick check question:** Why is a lower FID score (22.47 reported here) generally preferred, and what does it imply about the generated images compared to the training set?

## Architecture Onboarding

- **Component map:** Noise → DDPM Generator → 64x64 image → Upscaler → 193x72 image → Filter → Annotated images → YOLOv9-c detector → Pseudolabels → Final YOLOv9-c recognizer

- **Critical path:**
  1. Train DDPM on 78k real images (approx 30 hours on Tesla T4)
  2. Generate ~15k images
  3. Manually label 864 valid images to train preliminary detector
  4. Use preliminary detector to label remaining ~15k images (Pseudolabeling)
  5. Train final detector on full 15k+ dataset

- **Design tradeoffs:**
  - **Resolution vs. Detail:** The model trains at 64x64 pixels to fit in memory and reduce computation, requiring a later upscale. This likely contributes to character confusion (e.g., '8' vs 'B').
  - **Manual vs. Automated Filtering:** The paper relies on manual classification for initial analysis. Automated filtering based on regex/OCR validity is needed for scaling to 10k+ images.

- **Failure signatures:**
  - **"Structure-free" Noise:** Images failing to form plate structures, often due to insufficient training steps or high learning rates
  - **Character Hallucination:** Valid plate backgrounds with gibberish or invalid characters (13.6% failure rate)
  - **Pseudolabel Overfitting:** Models may ignore failed parts of letters during pseudolabeling, propagating bad labels

- **First 3 experiments:**
  1. **Baseline Sanity Check:** Train YOLOv9 model on 864 real images and test on 1000-image test set to establish 94.1% baseline
  2. **Synthetic vs. Real A/B Test:** Train second YOLOv9 model on 864 synthetic images. Expect slight performance drop (~90.9%) to verify "realness gap"
  3. **Scaling Test:** Generate 15,000 images, pseudolabel them using model from Experiment 2, and retrain. Check if accuracy exceeds baseline (target >95%)

## Open Questions the Paper Calls Out

- **Question:** Does incorporating conditional controls (e.g., weather, lighting, camera angle) into the diffusion architecture improve the robustness of the generated dataset compared to the unconditional approach used?
- **Question:** Can a license plate recognition (LPR) model trained exclusively on this synthetic data generalize effectively to real-world scenarios without requiring fine-tuning on real images?
- **Question:** Does increasing the native training resolution beyond 64x64 pixels reduce the character generation failure rate (currently 13.6%) and improve the legibility of complex characters?

## Limitations
- Data dependency: The 78k private training set defines all distributional priors; without access, replication fidelity is uncertain
- Manual filtering: Success rate (86.4%) relies on manual validation; scaling to 10k+ images requires automated structural checks
- Pseudolabel confidence: No ablation study provided for threshold selection (0.8); risk of confirmation bias not quantified

## Confidence
- **High confidence:** DDPM architecture can generate plausible license plates (mechanistically sound)
- **Medium confidence:** 3% LPR improvement is valid (controlled comparison, but dependent on private data)
- **Low confidence:** Distributional fidelity claims (Section 3.3) - no external validation or cross-dataset comparison

## Next Checks
1. **Automated validity filter:** Implement regex-based "AA0000AA" validation and compare success rates to manual classification
2. **Pseudolabel threshold ablation:** Test confidence thresholds (0.5, 0.7, 0.8, 0.9) to quantify accuracy/quality tradeoff
3. **Cross-dataset transferability:** Train diffusion model on CCPD or synthetic data, then evaluate LPR performance on Ukrainian test set to test distributional robustness