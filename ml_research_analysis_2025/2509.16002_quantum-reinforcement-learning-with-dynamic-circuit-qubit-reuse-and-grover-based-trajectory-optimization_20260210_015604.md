---
ver: rpa2
title: Quantum Reinforcement Learning with Dynamic-Circuit Qubit Reuse and Grover-Based
  Trajectory Optimization
arxiv_id: '2509.16002'
source_url: https://arxiv.org/abs/2509.16002
tags:
- quantum
- uni00000014
- state
- qubit
- uni00000037
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a fully quantum reinforcement learning framework\
  \ that integrates a quantum Markov decision process, dynamic circuit-based qubit\
  \ reuse, and Grover\u2019s algorithm for trajectory optimization. The framework\
  \ encodes states, actions, rewards, and transitions entirely within the quantum\
  \ domain, enabling parallel exploration of state-action sequences through superposition\
  \ and eliminating classical subroutines."
---

# Quantum Reinforcement Learning with Dynamic-Circuit Qubit Reuse and Grover-Based Trajectory Optimization

## Quick Facts
- **arXiv ID:** 2509.16002
- **Source URL:** https://arxiv.org/abs/2509.16002
- **Reference count:** 0
- **Primary result:** Proposes a fully quantum RL framework using dynamic circuits and Grover's algorithm to optimize trajectories while reducing qubit usage from 7*T to 7 for T time steps.

## Executive Summary
This paper introduces a fully quantum reinforcement learning framework that integrates a quantum Markov decision process, dynamic circuit-based qubit reuse, and Grover's algorithm for trajectory optimization. The framework encodes states, actions, rewards, and transitions entirely within the quantum domain, enabling parallel exploration of state-action sequences through superposition and eliminating classical subroutines. Dynamic circuit operations, including mid-circuit measurement and reset, allow reuse of the same physical qubits across multiple agent-environment interactions, reducing qubit requirements while preserving logical continuity. Quantum arithmetic computes trajectory returns, and Grover's search is applied to the superposition of these evaluated trajectories to amplify the probability of measuring those with the highest return, thereby accelerating the identification of the optimal policy.

## Method Summary
The framework implements a quantum Markov decision process where states, actions, transitions, and rewards are encoded as quantum registers. Multi-controlled Ry rotations encode transition probabilities, while CNOT gates handle reward encoding. The key innovation is dynamic circuit qubit reuse: after each timestep, mid-circuit measurement collapses the state, a 2000ns delay is applied, qubits are reset, and CNOT gates propagate the next state into the current state register for the next iteration. This reduces qubit requirements from 7*T to 7 while maintaining trajectory fidelity. Quantum arithmetic computes trajectory returns, and Grover's algorithm amplifies the probability of measuring trajectories with maximum return.

## Key Results
- Dynamic-circuit implementation preserves trajectory fidelity while reducing qubit usage by 66% relative to static design
- Framework operates within constraints of current quantum processors, validated on IBM Heron-class hardware
- Grover amplification successfully identifies optimal trajectories (T-151, T-143) with higher probability than random baseline
- Simulation demonstrates exact logical equivalence between dynamic and static implementations for trajectory probabilities

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Enables multi-step quantum RL interactions without linear qubit growth by recycling physical registers.
- **Mechanism:** Mid-circuit measurements collapse specific time-step registers into classical bits; mid-circuit resets clear the physical qubits; and CNOT gates propagate the subsequent state (|s'_t⟩) into the current state register (|s_{t+1}⟩) for the next iteration.
- **Core assumption:** Assumption: The cumulative error from repeated reset and measurement cycles remains lower than the decoherence error that would result from holding idle qubits in a larger static circuit.
- **Evidence anchors:**
  - [abstract] "Dynamic circuit operations... allow reuse of the same physical qubits... reducing qubit requirements from 7*T to 7."
  - [Section IV.B] Describes the sequence of "mid-circuit measurement... mid-circuit reset... propagation" using CNOTs to ensure |s'_t⟩ becomes |s_{t+1}⟩.
  - [corpus] "Optimization Framework for Reducing Mid-circuit Measurements and Resets" (Paper 27760) supports the feasibility of optimizing these operations to manage overhead.
- **Break condition:** If reset operations introduce significant latency that exceeds the system's coherence time, or if readout errors accumulate faster than gate errors in a static implementation.

### Mechanism 2
- **Claim:** Encodes stochastic environment dynamics directly into quantum amplitudes for parallel exploration.
- **Mechanism:** Multi-controlled R_y(θ) rotations encode classical transition probabilities P(s'|s,a) into quantum state amplitudes, allowing the agent to evolve through all possible trajectories simultaneously via superposition.
- **Core assumption:** The environment is a Markov Decision Process (MDP) where transitions depend only on the current state and action.
- **Evidence anchors:**
  - [abstract] "QMDP encodes states, actions, transitions, and rewards in superposition."
  - [Section IV.A] Defines the rotation angle as θ = 2arcsin(√P(s'|s,a)) to reproduce transition probabilities.
  - [corpus] "QuantGraph" (Paper 4074) similarly casts graph optimization as quantum searches over discrete trajectory spaces.
- **Break condition:** If the "multi-controlled" gate depth required to encode complex transitions becomes too deep for NISQ coherence limits.

### Mechanism 3
- **Claim:** Accelerates optimal policy discovery by treating return maximization as an amplitude amplification task.
- **Mechanism:** Quantum arithmetic computes the return |g⟩ for all trajectories in superposition; Grover's oracle flips the phase of trajectories with maximum return, and the diffusion operator amplifies their probability of being measured.
- **Core assumption:** There is a known or calculable threshold for the "maximum return" to construct the oracle.
- **Evidence anchors:**
  - [abstract] "Grover's search is applied... to amplify the probability of measuring those with the highest return."
  - [Section IV.C.2] Defines the oracle U_w that inverts the phase of desired trajectories (Eq. 12).
  - [corpus] Corpus evidence for specific Grover-based RL speedup on hardware is limited/weak relative to simulation claims in this specific context.
- **Break condition:** If noise drowns out the amplitude amplification effect, preventing the optimal trajectory from reaching a measurable probability threshold.

## Foundational Learning

- **Concept: Dynamic Circuits (Mid-circuit Measurement & Reset)**
  - **Why needed here:** This is the specific architectural feature that allows the 7-qubit constraint. Without understanding how a qubit is measured and reset *during* execution (not just at the end), the scalability claim cannot be understood.
  - **Quick check question:** Can you explain the difference between a "static" circuit execution and one that utilizes real-time feedback for resetting qubits?

- **Concept: Quantum Markov Decision Process (QMDP)**
  - **Why needed here:** The paper maps classical RL states/actions not to data, but to quantum registers. You need to understand how a probability (transition) becomes a rotation angle (θ).
  - **Quick check question:** How would you encode a 75% probability of moving from State A to State B using a single-qubit rotation gate?

- **Concept: Grover's Algorithm (Amplitude Amplification)**
  - **Why needed here:** This replaces the classical "argmax" loop. The paper assumes you know that Grover's algorithm finds a marked item in O(√N) time.
  - **Quick check question:** In this framework, what defines the "marked item" that the Oracle looks for? (Answer: The trajectory with the maximum return).

## Architecture Onboarding

- **Component map:** 2-qubit State (|s⟩) -> 1-qubit Action (|a⟩) -> 2-qubit Next State (|s'⟩) -> 2-qubit Reward (|r⟩) -> Return register (|g⟩)
- **Critical path:**
  1. Initialize: Apply Hadamards to create superposition of all states/actions.
  2. Interact: Apply multi-controlled Ry (transitions) and CNOTs (rewards).
  3. Measure & Reset: Measure outcome -> Store Classically -> Reset Qubits.
  4. Propagate: CNOT |s'⟩ → |s⟩.
  5. Repeat: Repeat interaction loop for T steps.
  6. Optimize: Apply Grover iteration (Oracle + Diffusion) to final state history.
- **Design tradeoffs:**
  - Static vs. Dynamic: Static circuits have lower latency sensitivity but scale qubits linearly (7T). Dynamic circuits scale constantly (7 qubits) but introduce latency from readout/reset delays and are sensitive to timing errors.
  - Fidelity: Dynamic circuits avoid storing long-lived entanglement (reducing decoherence risk) but suffer from accumulation of reset/readout errors over multiple steps.
- **Failure signatures:**
  - Timing Conflicts: Hardware errors if delay between measurement and reset is insufficient (Paper notes 2000ns delay was required on IBM Heron).
  - Barren Noise: In Grover optimization, noise may flatten the amplitude distribution, making the "optimal" trajectory indistinguishable from random noise.
  - State Corruption: Incorrect CNOT propagation if |s'⟩ is not properly reset or measured before reuse.
- **First 3 experiments:**
  1. Qubit Reuse Validation (Simulation): Run a 1-step vs 3-step dynamic circuit on a noise-free simulator (Qiskit Aer) to verify that trajectory probabilities match exactly (confirming logical equivalence).
  2. Hardware Timing Calibration: Deploy the 3-step interaction circuit on real hardware (e.g., IBM Heron) specifically varying the "delay" parameter between reset and reuse to identify the stability threshold (e.g., 2000ns) where errors minimize.
  3. Grover Amplification Fidelity: Execute the full pipeline including the Grover search on hardware; measure the frequency of the optimal trajectory (T-151) with and without the Grover iterations to quantify the "amplification" vs. noise floor.

## Open Questions the Paper Calls Out
None

## Limitations
- Hardware validation limited to single trajectory (T-151) and small problem sizes (7 qubits, 3 timesteps)
- Exact reward values and Grover oracle construction underspecified, making full reproduction difficult
- Scaling behavior beyond toy MDPs and impact of accumulated reset/readout errors in longer trajectories remain uncertain

## Confidence
- **High Confidence:** The dynamic-circuit qubit reuse mechanism and its theoretical qubit savings (7*T → 7) are well-defined and internally consistent
- **Medium Confidence:** The QMDP encoding of transitions via multi-controlled Ry rotations is correct in principle, but its effectiveness in preserving trajectory probabilities under hardware noise is less certain
- **Low Confidence:** The Grover-based trajectory optimization's ability to reliably identify the optimal policy on real hardware is the most speculative claim, given the lack of broader experimental validation

## Next Checks
1. **Scalability Simulation:** Implement and simulate the framework on larger MDPs (e.g., 5 states, 3 actions, 5 timesteps) to identify when reset/readout error accumulation overwhelms the qubit savings
2. **Noise Sensitivity Analysis:** Perform a detailed simulation comparing the fidelity of the dynamic-circuit approach against a static circuit for the same MDP, systematically varying readout error rates and reset latencies
3. **Grover Amplification Robustness:** On hardware, test the Grover amplification across a diverse set of MDPs with varying reward structures to quantify how often the optimal trajectory is successfully identified versus when noise causes a false positive