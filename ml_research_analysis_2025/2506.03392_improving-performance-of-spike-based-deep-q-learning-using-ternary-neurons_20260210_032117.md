---
ver: rpa2
title: Improving Performance of Spike-based Deep Q-Learning using Ternary Neurons
arxiv_id: '2506.03392'
source_url: https://arxiv.org/abs/2506.03392
tags:
- spiking
- neurons
- ternary
- neuron
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the use of ternary spiking neurons to improve
  the representation capacity of spiking neural networks in deep Q-learning tasks.
  The authors mathematically analyze the performance degradation observed with existing
  ternary neuron models and hypothesize that gradient estimation bias during training
  is the underlying cause.
---

# Improving Performance of Spike-based Deep Q-Learning using Ternary Neurons

## Quick Facts
- **arXiv ID**: 2506.03392
- **Source URL**: https://arxiv.org/abs/2506.03392
- **Reference count**: 40
- **Primary result**: Asymmetric ternary spiking neurons improve DSQN performance by 130% on average across 7 Atari games compared to binary baselines.

## Executive Summary
This paper addresses the performance degradation observed when using ternary spiking neurons in deep Q-learning. The authors identify gradient estimation bias as the root cause, where symmetric positive/negative thresholds in standard ternary neurons lead to zero expected gradients. They propose an asymmetric ternary spiking neuron model with different thresholds for positive and negative spikes, which mitigates this bias. The model achieves an average 130% performance improvement over binary spiking neuron baselines while maintaining training stability and avoiding gradient vanishing/exploding problems across seven Atari games.

## Method Summary
The method introduces Asymmetric Ternary LIF neurons into a Deep Spiking Q-Network (DATSQN) architecture. The neuron emits spikes from {-1, 0, 1} based on membrane potential relative to asymmetric thresholds (fixed positive threshold v_th^p=1, learnable negative threshold v_th^n initialized to 2). The network uses 3 convolutional layers followed by 2 fully connected layers, with inputs converted to spike trains via rate-based Bernoulli encoding. Training uses surrogate gradient learning with a Straight-Through Estimator and ε-greedy exploration over 1M steps with learning rate 5×10^-5.

## Key Results
- Achieves average 130% improvement over binary spiking neuron baseline on 7 Atari games
- Maintains training stability without gradient vanishing/exploding problems
- Demonstrates superior performance compared to symmetric ternary and binary baselines

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Standard ternary spiking neurons with symmetric thresholds may degrade reinforcement learning performance due to gradient estimation bias, whereas asymmetric thresholds mitigate this.
- **Mechanism**: Symmetric thresholds cause equal firing probabilities for positive and negative spikes when membrane potential is Gaussian, canceling expected gradients. Asymmetric thresholds break this symmetry, ensuring non-zero expected gradients.
- **Core assumption**: Membrane potential approximates zero-mean Gaussian distribution in subthreshold regime.
- **Evidence anchors**:
  - [abstract]: "...hypothesize that gradient estimation bias during the training process is the underlying potential cause..."
  - [section 4.1]: "...for ternary neurons with symmetric thresholds... the expected gradient becomes zero."
- **Break condition**: If membrane potential distributions are heavily skewed or non-Gaussian, gradient cancellation may not occur as predicted.

### Mechanism 2
- **Claim**: Introducing a ternary spike space {-1, 0, 1} increases the representation capacity (information entropy) of the network relative to binary spikes {0, 1}.
- **Mechanism**: Ternary spikes add an inhibitory channel, allowing explicit representation of negative membrane potentials. This increases maximum information entropy of spike distribution, enabling higher fidelity value function approximation.
- **Core assumption**: Training process can successfully utilize expanded spike alphabet without prohibitive optimization costs.
- **Evidence anchors**:
  - [abstract]: "...improve the representation capacity of binary spiking neurons..."
  - [section 4.1]: "...ternary LIF increases the representation capacity... by at most r bits."
- **Break condition**: If expanded representation is not matched by improved trainability (e.g., vanishing gradients), performance will not improve.

### Mechanism 3
- **Claim**: The proposed asymmetric ternary neuron maintains training stability comparable to ReLU-based networks by satisfying block dynamical isometry.
- **Mechanism**: Theoretical analysis shows variance of input-output Jacobian relates to firing rate r. Maintaining specific firing rate profile avoids exploding/vanishing gradient problem, ensuring stable gradient flow during backpropagation through time.
- **Core assumption**: Firing rate r remains within stable range (0.1 to 0.5) during training.
- **Evidence anchors**:
  - [abstract]: "...maintaining training stability and avoiding gradient vanishing/exploding problems."
  - [section 4.3]: Theorem 4.7 proves asymmetric model achieves at least dynamical isometry of ReLU activations.
- **Break condition**: If firing rates become extremely high or low, isometry conditions degrade, potentially destabilizing training.

## Foundational Learning
- **Concept**: Surrogate Gradient Learning
  - **Why needed here**: Spiking neuron firing is non-differentiable step function. Smooth surrogate functions (e.g., ATan, Sigmoid) approximate gradient of spike threshold for backpropagation.
  - **Quick check question**: Why can't we calculate the derivative of a binary spike event directly?
- **Concept**: Leaky Integrate-and-Fire (LIF) Dynamics
  - **Why needed here**: Paper modifies standard LIF membrane potential update and reset mechanism. Understanding decay (β), threshold (v_th), and reset potential is required for asymmetric thresholds.
  - **Quick check question**: What happens to the membrane potential after a spike is emitted?
- **Concept**: Deep Q-Learning (DQN)
  - **Why needed here**: Paper embeds spiking neurons into DQN architecture to play Atari games. Must grasp concept of approximating Q-function and role of replay buffer.
  - **Quick check question**: In DQN, what does the network approximate—the policy directly or the value of state-action pairs?

## Architecture Onboarding
- **Component map**: Input encoder -> Conv layers -> FC layers -> Output layer
- **Critical path**:
  1. Encode observation I into spikes X via rate-based Bernoulli sampling
  2. Iterate for t=1 to T (Simulation Window):
     - Update membrane potential m_k(t)
     - Check asymmetric thresholds (v_th^p, v_th^n) to emit {-1, 0, 1}
     - Reset potential if spiked
  3. Sum output spikes to get Q-values
  4. Select action via ε-greedy policy
- **Design tradeoffs**:
  - **Latency vs. Accuracy**: Shorter simulation window (T=20) reduces latency and energy but increases task difficulty (less temporal information)
  - **Capacity vs. Bias**: Ternary neurons increase capacity but introduce gradient bias if symmetric; asymmetric design fixes bias but adds learnable parameter overhead
- **Failure signatures**:
  - **Symmetric Ternary DQN**: Performance degrades compared to binary (gradient cancellation)
  - **Vanishing Gradients**: Monitored via average gradient norm; if norms approach zero, check threshold symmetry or learning rate
- **First 3 experiments**:
  1. **Baseline Comparison**: Train Binary DSQN vs. Symmetric Ternary DQN on Breakout to confirm performance drop in symmetric models
  2. **Ablation on Thresholds**: Implement DATSQN with fixed asymmetric thresholds vs. learnable negative threshold (v_th^n) to verify benefit of learning bias
  3. **Gradient Analysis**: Plot average gradient norm over training steps for Binary, Symmetric Ternary, and Asymmetric Ternary models to visually confirm gradient stability vs. cancellation

## Open Questions the Paper Calls Out
None

## Limitations
- Performance gains demonstrated primarily on Atari games, generalization to other RL tasks uncertain
- Asymmetric design introduces additional learnable parameter (v_th^n) whose initialization and impact across environments not fully characterized
- Reliance on specific membrane potential distribution assumption (Gaussian) for gradient bias hypothesis

## Confidence
- **Mechanism 1 (Gradient Bias)**: Medium confidence. Theoretical analysis sound but Gaussian distribution assumption critical and not empirically verified across training
- **Mechanism 2 (Representation Capacity)**: High confidence. Information-theoretic argument clear and performance improvement demonstrates practical benefit
- **Mechanism 3 (Training Stability)**: High confidence. Isometry theorem provides strong theoretical grounding, absence of gradient vanishing/exploding is direct observation

## Next Checks
1. **Distribution Validation**: Empirically verify membrane potential distribution assumption by plotting histograms during training. Check if zero-mean Gaussian assumption holds and correlates with gradient norms
2. **Architecture Generalization**: Test DATSQN model on non-Atari RL task (e.g., LunarLander-v2) to assess if 130% improvement generalizes beyond tested games
3. **Parameter Sensitivity**: Conduct ablation study on negative threshold initialization (v_th^n) and learning rate to determine if improvement is robust to hyperparameter choices