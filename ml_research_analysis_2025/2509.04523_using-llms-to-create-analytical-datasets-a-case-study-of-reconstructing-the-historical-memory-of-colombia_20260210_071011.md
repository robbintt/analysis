---
ver: rpa2
title: 'Using LLMs to create analytical datasets: A case study of reconstructing the
  historical memory of Colombia'
arxiv_id: '2509.04523'
source_url: https://arxiv.org/abs/2509.04523
tags:
- events
- data
- violence
- articles
- article
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates how large language models (LLMs) can be
  used to reconstruct Colombia's historical memory of violence by processing over
  200,000 Spanish-language newspaper articles. Using GPT-4o-mini, the researchers
  extracted 78,685 violent events from 1992-2022, creating a detailed transactional
  dataset that goes beyond official records by providing granular details about victims,
  perpetrators, and context.
---

# Using LLMs to create analytical datasets: A case study of reconstructing the historical memory of Colombia

## Quick Facts
- arXiv ID: 2509.04523
- Source URL: https://arxiv.org/abs/2509.04523
- Reference count: 40
- Primary result: LLMs extracted 78,685 violent events from 200,000+ Spanish newspaper articles (1992-2022), creating granular dataset for Colombia's historical memory

## Executive Summary
This study demonstrates how large language models can reconstruct historical violence patterns by processing unstructured text from Colombian newspapers. Using GPT-4o-mini, researchers extracted 78,685 violent events from over 200,000 articles spanning 1992-2022, creating a detailed transactional dataset that captures victim information, perpetrator details, and contextual factors beyond official records. The methodology enables analysis of violence trends and policy impacts at granular geographic levels.

The LLM pipeline successfully generated a dataset that revealed distinct patterns in violence against civilians, combatants, and infrastructure across different regions and time periods. While the study found no significant relationship between coca eradication efforts and violence levels, it illustrates LLMs' potential to transform humanities research and policy analysis by extracting structured data from vast text corpora. The approach offers a replicable framework for analyzing conflict archives in other contexts where text contains embedded analytical information.

## Method Summary
The researchers employed GPT-4o-mini to process 202,804 Spanish-language newspaper articles from El Tiempo between 1992-2022. They designed a two-phase LLM pipeline: first extracting individual violent events with detailed attributes (victim demographics, perpetrator information, location, date, violence type), then grouping events into coherent narratives. The extracted events underwent deduplication and quality filtering, resulting in 78,685 high-quality violent events. The final dataset enabled both descriptive analysis of violence patterns and regression analysis examining relationships between coca eradication and violence levels across 1,097 municipalities.

## Key Results
- Extracted 78,685 violent events from 202,804 newspaper articles spanning 1992-2022
- Generated granular dataset capturing victim demographics, perpetrator details, and violence context
- Found no statistically significant relationship between coca eradication efforts and violence levels

## Why This Works (Mechanism)
The LLM approach works by leveraging transformer-based models' ability to understand context and extract structured information from unstructured text. GPT-4o-mini's training on diverse Spanish-language content enabled accurate identification of violent events and their attributes within news articles. The two-phase extraction process first captures individual event details, then contextualizes them within broader narratives, ensuring both granularity and coherence in the resulting dataset.

## Foundational Learning
**Named Entity Recognition (NER)**: Essential for identifying victims, perpetrators, locations, and dates within text. Quick check: Test model on sample sentences to verify accurate entity extraction.

**Event Coreference Resolution**: Needed to link related mentions of the same violent event across multiple articles. Quick check: Verify that related event mentions are correctly grouped into single events.

**Temporal Reasoning**: Required to accurately extract and normalize dates from various textual formats. Quick check: Validate date extraction accuracy on articles with different date representations.

**Violence Type Classification**: Critical for categorizing events by type (combatant vs civilian targeting, etc.). Quick check: Test classification accuracy on known event types.

**Multilingual Processing**: Important for handling Spanish-language content with regional variations. Quick check: Assess model performance across different Colombian Spanish dialects.

## Architecture Onboarding

**Component Map**: Article Collection -> LLM Event Extraction -> Event Grouping -> Deduplication -> Quality Filtering -> Analytical Dataset

**Critical Path**: Newspaper articles → GPT-4o-mini extraction → Event grouping → Deduplication → Final dataset → Policy analysis

**Design Tradeoffs**: The study used GPT-4o-mini for cost-effectiveness versus larger models' potential accuracy gains. They prioritized extraction breadth over depth, accepting some noise for comprehensive coverage. The two-phase approach balanced granular detail with contextual coherence.

**Failure Signatures**: High false positive rates would manifest as inflated event counts with questionable validity. Incomplete extraction would show systematic gaps in certain violence types or regions. Poor deduplication would result in duplicate events inflating counts.

**First Experiments**:
1. Test LLM extraction on 100 sample articles to assess precision and recall
2. Run deduplication algorithm on known duplicate pairs to evaluate performance
3. Compare extracted events against ground truth samples to validate accuracy

## Open Questions the Paper Calls Out

**Open Question 1**: To what extent does newspaper source selection bias affect the completeness and representativeness of LLM-extracted conflict event datasets? The authors acknowledge that violent crimes are less likely to be reported on by the press and note only 5.9%-10.2% overlap with official records, but do not systematically quantify underrepresentation across violence types, regions, or periods.

**Open Question 2**: Can LLM-based extraction pipelines be effectively transferred to other conflict settings with different linguistic, journalistic, and political contexts? While the authors state their pipeline can serve as a template for other contexts, no empirical validation is provided beyond Colombia.

**Open Question 3**: What is the true relationship between coca eradication efforts and violence levels in Colombia, given conflicting findings across studies using different data sources? The authors describe this as an open question and note their finding of no significant relationship contradicts some prior studies, with differences potentially attributable to varying violence measures, time periods, and data sources.

## Limitations
- Uses single newspaper source (El Tiempo), potentially introducing selection bias
- GPT-4o-mini may sacrifice accuracy for cost-effectiveness compared to larger models
- No systematic evaluation of false positives and false negatives in event extraction
- Limited validation against ground truth samples to assess dataset reliability

## Confidence
- LLM methodology feasibility: High
- Descriptive findings reliability: Medium
- Policy analysis conclusions: Medium
- Dataset precision and recall: Low

## Next Checks
1. Conduct systematic evaluation of extracted events against ground truth samples to quantify precision, recall, and false discovery rates
2. Replicate the analysis using multiple newspaper sources to assess consistency and identify source-specific biases
3. Apply the same LLM pipeline to other conflict-affected regions to test generalizability and identify context-dependent performance variations