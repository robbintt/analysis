---
ver: rpa2
title: 'FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering'
arxiv_id: '2510.25621'
source_url: https://arxiv.org/abs/2510.25621
tags:
- answer
- evidence
- question
- query
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FARSIQA, a novel retrieval-augmented generation
  (RAG) system designed for high-stakes Persian Islamic question answering. It addresses
  the challenges of hallucination and unfaithfulness in LLMs when applied to sensitive
  domains.
---

# FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering

## Quick Facts
- arXiv ID: 2510.25621
- Source URL: https://arxiv.org/abs/2510.25621
- Reference count: 29
- Introduces FAIR-RAG architecture achieving 97.0% Negative Rejection and 74.3% Answer Correctness on Islamic question answering

## Executive Summary
FARSIQA is a novel retrieval-augmented generation (RAG) system designed for high-stakes Persian Islamic question answering. It addresses the challenges of hallucination and unfaithfulness in LLMs when applied to sensitive domains. The core innovation is the FAIR-RAG architecture, an iterative, adaptive framework that decomposes complex queries, assesses evidence sufficiency, and refines retrieval until a comprehensive context is built. FARSIQA operates on a knowledge base of over one million authoritative Islamic documents. Rigorous evaluation on the IslamicPCQA benchmark demonstrates state-of-the-art performance, validating that iterative, adaptive RAG architectures are crucial for building faithful and reliable AI systems in sensitive domains.

## Method Summary
FARSIQA implements the FAIR-RAG architecture with an iterative refinement loop (max 3 iterations). It uses hybrid retrieval combining BM25 sparse search with a fine-tuned dense retriever on 24,000 Islamic Q&A pairs, fused via Reciprocal Rank Fusion. The system dynamically routes queries through different LLMs: Llama-3-8B for decomposition and SEA, Llama-3.1-70B for filtering and generation, and DeepSeek-R1 for complex reasoning. The pipeline includes query decomposition, structured evidence assessment to identify gaps, iterative refinement through targeted sub-queries, and final synthesis with strict grounding requirements.

## Key Results
- Achieves 97.0% Negative Rejection rate, representing a 40-point improvement over baselines
- Demonstrates 74.3% Answer Correctness on the IslamicPCQA benchmark
- Shows 80.1% improvement rate when increasing iterations from 1 to 3
- Achieves 16.2% increase in Recall@3 after domain-specific fine-tuning

## Why This Works (Mechanism)

### Mechanism 1: Iterative Gap Filling via Structured Evidence Assessment (SEA)
The system implements a self-correcting loop where an LLM explicitly audits retrieved evidence against a checklist of required facts. The SEA agent deconstructs queries into required findings, compares retrieved documents against this list, and generates targeted sub-queries to fill specific gaps. This iterative process loops up to 3 times, significantly improving multi-hop reasoning capabilities compared to single-pass retrieval. The loop terminates when evidence is deemed sufficient or maximum iterations are reached.

### Mechanism 2: Domain-Specific Hybrid Retrieval Fusion
FARSIQA combines dense semantic search with sparse keyword matching (BM25), enhanced by domain-specific fine-tuning on Islamic texts. This addresses vocabulary mismatch problems inherent in specialized religious texts, allowing the system to capture semantic intent while ensuring strict keyword matching for specific theological terms and proper names. The system uses Reciprocal Rank Fusion to merge top-3 documents from each retriever (total 6, re-ranked to 3), balancing semantic understanding with keyword precision.

### Mechanism 3: Adaptive Query Decomposition for Parallel Reasoning
Complex comparative queries are broken down into parallel investigative tracks, allowing the system to solve multi-hop problems that would otherwise overload a single semantic vector. For example, "Compare X and Y" becomes independent sub-queries for each entity, processed in parallel. This prevents the lexical chasm where a single query vector averages two distinct concepts into a meaningless middle ground, ensuring evidence is gathered for all entities before synthesis.

## Foundational Learning

- **Concept: Dense vs. Sparse Retrieval (Hybrid Search)**
  - Why needed: Religious texts require both semantic matching ("Prayer") and exact keyword matching ("Salat"). Understanding RRF fusion is critical for debugging retrieval failures.
  - Quick check: If a user asks about a specific Arabic term transliterated into Persian, which retriever (Dense or Sparse) is more likely to fail if not fine-tuned, and how does RRF save it?

- **Concept: Agentic Design Patterns (Reflection/Refinement)**
  - Why needed: This system is not a pipeline; it is a loop. The LLM critiques its own findings (SEA) before generating an answer, with the Refiner acting on the critique.
  - Quick check: In the FAIR-RAG loop, what specific output from the Structured Evidence Assessment triggers the Query Refinement agent to act?

- **Concept: Faithfulness vs. Correctness**
  - Why needed: The paper optimizes for faithfulness (adherence to retrieved context), not just correctness (truth). An answer can be "faithful" to a wrong document but "unfaithful" if it hallucinates a correct fact not in the text.
  - Quick check: According to Section 6.7, what is the primary cause of failure when the system retrieves the correct evidence but outputs a wrong answer?

## Architecture Onboarding

- **Component map:** Orchestrator -> Query Agent (Llama-3-8B) -> Hybrid Retrieval (Dense + BM25) -> RRF Fusion -> Filter Agent (Llama-3.1-70B) -> SEA Agent (Llama-3-8B) -> Refinement/Generator (Llama-3.1-70B/DeepSeek-R1)
- **Critical path:** The Structured Evidence Assessment (SEA) prompt. If miscalibrated (too lenient, exits early; too strict, loops endlessly), it becomes the primary bottleneck for quality and latency.
- **Design tradeoffs:** Latency vs. Depth: Authors chose 3 iterations empirically (4th iteration increased latency by 7.4% with negligible gain). Cost vs. Reasoning: Dynamic model selection (DeepSeek-R1 is 11.8x more expensive but used only for complex logic).
- **Failure signatures:**
  - "Correct Evidence, Wrong Answer" (54.9% of failures): Check Generator prompts for logical inference issues
  - "Hallucinated Ruling" (Safety Failure): Check Validator for high-risk classification failures
  - "Incomplete Answer": Check SEA Recall (62.6%) for premature loop termination
- **First 3 experiments:**
  1. Retrieval Ablation: Disable Sparse (BM25) retriever on 50 multi-hop queries to verify proper noun retrieval drops
  2. Iteration Threshold Test: Force max_iter=1 on 100 "Noisy Context" questions to verify distractor filtering fails without refinement
  3. Safety Stress Test: Submit 20 out-of-scope "trap" questions to verify Query Validation and Negative Rejection mechanisms

## Open Questions the Paper Calls Out

- **Open Question 1:** How can the system mitigate the high rate of generation failures where the LLM fails to reason over correct evidence? The paper reports 54.9% of errors occur during final synthesis even with correct context, suggesting current prompting strategies for "Strict Grounding" are insufficient for complex synthesis.

- **Open Question 2:** Does the predominance of Shi'a sources in the knowledge base systematically bias the model's theological or jurisprudential outputs? The collection predominantly features Shi'a texts, and answers may inherently reflect these perspectives, but the paper does not quantify how source diversity impacts validity on controversial topics.

- **Open Question 3:** How can the recall of the Structured Evidence Assessment (SEA) module be improved to prevent premature loop termination? The SEA module has only 62.6% recall, indicating a tendency to judge evidence as sufficient prematurely, which leads to incomplete answers.

- **Open Question 4:** Can the system support multi-turn reasoning without increasing latency or error propagation? The paper identifies "Lack of Conversational Context" as a key limitation, noting the system is stateless and cannot understand follow-up questions.

## Limitations
- The SEA module has only 62.6% recall for identifying missing evidence, leaving significant gaps in the iterative refinement process
- High performance was achieved on a curated IslamicPCQA benchmark, which may not generalize to more diverse or adversarial question distributions
- DeepSeek-R1 is 11.8x more expensive than baseline models but is only selectively used, creating potential inconsistencies in reasoning quality across query types

## Confidence
- **High confidence**: Iterative refinement demonstrably improves retrieval quality (80.1% improvement from 1 to 3 iterations), and hybrid retrieval addresses vocabulary mismatch (16.2% recall improvement)
- **Medium confidence**: Domain-specific fine-tuning is sound for specialized vocabulary, but exact quality of 24,000 training triplets and their impact is uncertain
- **Low confidence**: Generator performance on logical inference remains weak (54.9% of failures), suggesting fundamental limitations that iterative retrieval cannot fully address

## Next Checks
1. **SEA recall stress test**: Run system on 100 complex multi-hop queries with known answer structures, then manually audit SEA agent's gap identification accuracy to verify 62.6% recall holds under adversarial conditions
2. **Out-of-domain generalization**: Evaluate FARSIQA on non-Islamic specialized domains (medical or legal QA) using identical architecture and prompts to measure whether benefits transfer beyond curated knowledge base
3. **Safety boundary analysis**: Systematically test Query Validation and Negative Rejection mechanisms with adversarial inputs that exploit religious language to verify consistent rejection of harmful content