---
ver: rpa2
title: Malware Classification from Memory Dumps Using Machine Learning, Transformers,
  and Large Language Models
arxiv_id: '2503.02144'
source_url: https://arxiv.org/abs/2503.02144
tags:
- malware
- learning
- features
- classification
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The study evaluates six traditional machine learning models (Logistic
  Regression, KNN, SVM, Decision Tree, Random Forest, XGBoost) and two deep learning
  models (RNN, Transformers) for malware classification using memory dump data, alongside
  two Gemini-based few-shot learning approaches. Four feature sets were tested: All
  Features, Literature Review Features, Top 45 Features from Random Forest, and Down-Sampled
  with Top 45 Features.'
---

# Malware Classification from Memory Dumps Using Machine Learning, Transformers, and Large Language Models

## Quick Facts
- arXiv ID: 2503.02144
- Source URL: https://arxiv.org/abs/2503.02144
- Reference count: 31
- Primary result: XGBoost achieved 87.42% accuracy on memory dump malware classification using top 45 features selected by Random Forest importance

## Executive Summary
This study evaluates six traditional machine learning models, two deep learning models, and two Gemini-based few-shot learning approaches for classifying malware from memory dumps. The researchers tested four feature sets: all 58 features, literature review features, top 45 features selected by Random Forest importance, and down-sampled top 45 features. XGBoost achieved the highest accuracy of 87.42% using the top 45 features, closely followed by Random Forest at 87.23%. Deep learning models underperformed significantly (RNN: 66.71%, Transformers: 71.59%), and down-sampling reduced performance across all models by approximately 6%. The study demonstrates that traditional machine learning models outperform deep learning and LLM approaches for structured memory dump classification tasks.

## Method Summary
The study classified memory dump data from the MalMem2022 dataset (58 features, 58,596 samples) into four malware categories using six traditional ML models (Logistic Regression, KNN, SVM, Decision Tree, Random Forest, XGBoost), two deep learning models (RNN, Transformer), and two Gemini-based few-shot learning approaches. Feature selection was performed using Random Forest importance ranking to identify the top 45 features. Four feature sets were evaluated: all features, literature review features, top 45 features, and down-sampled top 45 features. Models were trained and evaluated using accuracy, F1-score, precision, and recall metrics. The best performance was achieved with XGBoost on the top 45 features configuration.

## Key Results
- XGBoost achieved highest accuracy of 87.42% using top 45 features selected by Random Forest importance
- Random Forest closely followed with 87.23% accuracy on the same feature set
- Deep learning models underperformed significantly (RNN: 66.71%, Transformers: 71.59%)
- Down-sampling reduced performance across all models by approximately 6%
- Gemini zero-shot and few-shot approaches showed the lowest accuracy (40.65% and 48.65%, respectively)

## Why This Works (Mechanism)

### Mechanism 1: Feature Selection via Importance Ranking Reduces Noise
Random Forest calculates feature importance based on impurity reduction across splits, filtering to top features removes low-signal dimensions that introduce noise without contributing discriminative information. The most predictive signal for malware family classification is concentrated in a subset of features rather than distributed evenly across all 58.

### Mechanism 2: Tree-Based Ensembles Capture Non-Linear Interactions in Structured Forensic Features
XGBoost sequentially fits residual errors with shallow trees, capturing feature interactions directly; Random Forest averages multiple decorrelated trees, reducing overfitting. Both handle mixed feature scales and missing patterns common in forensic artifacts.

### Mechanism 3: Data Volume Loss from Down-Sampling Outweighs Class Balance Benefits
Memory dump patterns contain subtle family-specific variations; aggressive down-sampling removes informative samples, reducing the effective training distribution coverage. The informational cost of sample removal exceeded the benefit of balance.

## Foundational Learning

- **Concept: Memory Forensics Artifacts** - Understanding what information dumps contain (processes, loaded modules, network connections) is essential for feature interpretation.
  - Quick check: Can you name three types of artifacts extractable from a memory dump that might indicate malware presence?

- **Concept: Feature Importance via Random Forest** - Understanding this mechanism prevents data leakage when reusing ranking and training data.
  - Quick check: Why is it problematic to compute feature importance and train your final model on the same dataset without proper cross-validation?

- **Concept: Gradient Boosting vs. Bagging** - Understanding their different ensemble strategies helps diagnose which works better for specific data characteristics.
  - Quick check: How does XGBoost's sequential residual fitting differ from Random Forest's parallel tree averaging, and what does this imply for overfitting risk?

## Architecture Onboarding

- **Component map:** Data ingestion (MalMem2022 dataset, 58 features, 58,596 samples) -> Feature engineering (Four configurations: All Features, Literature Review, Top 45 RF, Down-Sampled Top 45) -> Model layer (Traditional ML, Deep Learning, LLM) -> Evaluation (Accuracy, F1, Precision, Recall across feature sets)

- **Critical path:** 1) Load and validate dataset integrity (check for missing values, feature distributions) 2) Compute feature importance using Random Forest on training split only 3) Select top 45 features; train XGBoost with cross-validation 4) Compare against full-feature baseline to quantify selection benefit 5) Evaluate on held-out test set; report all four metrics

- **Design tradeoffs:** Feature selection vs. full features reduces noise and compute but risks discarding weak-signal features; paper shows 0.09% accuracy gain for XGBoost. Down-sampling for balance vs. full data shows ~6% accuracy drop; prefer full data with class weighting if imbalance is moderate. Deep learning vs. traditional ML: Transformers/RNN underperformed by 15-20%; deep learning adds complexity without accuracy gains on this structured dataset.

- **Failure signatures:** XGBoost accuracy drops >5% from reported: Check for data leakage (feature selection on full dataset), improper train/test split, or missing feature preprocessing. Deep learning models diverge or overfit quickly: Reduce epochs, increase batch size, or add regularization; paper used only 3-6 epochs. LLM classifications near random: Gemini achieved 40-48%; this is expected behavior for zero/few-shot on structured forensic data without fine-tuning.

- **First 3 experiments:** 1) Replicate the top 45 feature selection using RF importance on a held-out fold; train XGBoost and verify accuracy approaches 87% range 2) Ablation test: Compare top 10, 20, 30, 45, 58 features to identify the optimal feature count for this dataset 3) Baseline comparison: Train XGBoost on full features with class weighting vs. down-sampling to quantify the tradeoff between balance and data volume

## Open Questions the Paper Calls Out

### Open Question 1
Can hybrid architectures integrating traditional models (like XGBoost) with deep learning methods outperform standalone models in memory dump malware classification? The conclusion states that future work should focus on "exploring hybrid models that integrate deep learning and traditional algorithms to leverage the strengths of both approaches." Performance metrics (Accuracy, F1-score) of a hybrid model exceeding the current best baseline of 87.42% accuracy would resolve this.

### Open Question 2
To what extent does advanced fine-tuning improve the performance of Large Language Models (specifically Gemini) on structured memory dump data? The authors note that while few-shot learning performed poorly, future work could focus on "enhancing Gemini's capabilities through advanced fine-tuning." A fine-tuned LLM achieving significantly higher accuracy than the 48.65% few-shot baseline would resolve this.

### Open Question 3
Does the superiority of traditional machine learning models over deep learning persist when applied to larger and more diverse memory dump datasets? The conclusion suggests that future research should involve "testing these methods on larger and more diverse datasets" to validate the findings. A replication showing whether the accuracy gap between XGBoost and Transformers/RNNs widens or narrows would resolve this.

## Limitations
- Dataset specifics (MalMem2022 details, exact feature definitions, preprocessing steps) are not fully specified, creating potential reproducibility gaps
- Deep learning implementation lacks complete technical details (TabTransformer architecture, RNN input formatting for tabular memory features)
- LLM methodology shows poor performance but lacks explanation of prompt engineering or evaluation methodology

## Confidence
- **High confidence**: XGBoost and Random Forest performance claims (87.42% and 87.23% accuracy) are well-supported by standard evaluation metrics and feature selection methodology
- **Medium confidence**: Deep learning underperformance interpretation (RNN: 66.71%, Transformers: 71.59%) - while data supports the claim, architectural choices may have limited model potential
- **Low confidence**: Gemini LLM results (40.65% zero-shot, 48.65% few-shot) - these approaches appear fundamentally mismatched to the structured forensic classification task

## Next Checks
1. **Feature selection validation**: Implement cross-validated feature importance ranking to verify that top 45 features consistently capture the majority of discriminative signal without data leakage
2. **Deep learning architecture review**: Test alternative TabTransformer configurations (more layers, attention heads) and proper sequential RNN formatting to determine if poor performance stems from model design or inherent limitations
3. **LLM applicability assessment**: Compare Gemini results against simple majority-class baseline to quantify whether LLM approaches add any value beyond random guessing for structured memory dump classification