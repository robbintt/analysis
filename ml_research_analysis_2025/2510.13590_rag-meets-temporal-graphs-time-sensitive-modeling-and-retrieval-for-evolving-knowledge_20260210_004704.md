---
ver: rpa2
title: 'RAG Meets Temporal Graphs: Time-Sensitive Modeling and Retrieval for Evolving
  Knowledge'
arxiv_id: '2510.13590'
source_url: https://arxiv.org/abs/2510.13590
tags:
- temporal
- time
- retrieval
- answer
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper
---

# RAG Meets Temporal Graphs: Time-Sensitive Modeling and Retrieval for Evolving Knowledge

## Quick Facts
- arXiv ID: 2510.13590
- Source URL: https://arxiv.org/abs/2510.13590
- Reference count: 40
- Primary result: Achieves 0.599 Correct score on time-sensitive QA, outperforming GraphRAG by 0.18.

## Executive Summary
This paper introduces Temporal Graph RAG (TG-RAG), a framework that extends RAG with explicit temporal modeling for time-sensitive question answering over evolving knowledge bases. By constructing a bi-level temporal graph with timestamped edges and a hierarchical time graph, TG-RAG enables precise retrieval of facts at specific times while supporting efficient incremental updates. The system outperforms state-of-the-art RAG methods on earnings call transcript data, demonstrating superior handling of temporal queries through localized retrieval and dynamic subgraph filtering.

## Method Summary
TG-RAG constructs a bi-level temporal graph consisting of a temporal knowledge graph with timestamped relations and a hierarchical time graph. Documents are chunked and processed by an LLM to extract temporal quadruples (entity1, entity2, relation, timestamp), which populate the graph as parallel edges for facts occurring at different times. A time hierarchy organizes timestamps from year to day granularity. For retrieval, temporal expressions are extracted from queries to define a time scope, which filters semantically retrieved edges before applying Personalized PageRank to rank relevant entities and chunks. The system supports incremental updates by generating reports only for new leaf time nodes and their ancestors, avoiding full recomputation.

## Key Results
- Correct score of 0.599 vs GraphRAG's 0.419 on ECT-QA dataset (18% absolute improvement)
- Refusal rate of 0.382 vs GraphRAG's 0.462, indicating better confidence in answers
- Update cost reduced from 30.0M/7.8M tokens to 1.6M/2.0M tokens (95% reduction)

## Why This Works (Mechanism)

### Mechanism 1: Bi-Level Temporal Graph with Timestamped Edges
Explicit temporal edges distinguish facts that differ only in time, resolving embedding ambiguity. Lower layer stores temporal quadruples (v1, v2, relation, τ) as parallel edges; upper layer organizes timestamps hierarchically (year→quarter→month). Cross-layer edges bind facts to temporal scope, enabling time-scoped retrieval. Assumes LLM-based quadruple extraction reliably identifies timestamps and normalizes them; temporal expressions in queries map cleanly to hierarchy nodes.

### Mechanism 2: Query-Centric Time Identification and Temporal Subgraph Retrieval
Filtering edges by query-identified temporal scope improves retrieval precision for time-sensitive queries. (1) LLM extracts temporal expressions from query → set Tq; (2) Retrieve top-K edges by semantic similarity → subgraph GqK; (3) Filter edges by τ∈Tq; (4) Run Personalized PageRank from temporally-filtered seeds to score entities and chunks. Assumes queries contain extractable temporal constraints; top-K semantic retrieval captures relevant edges before temporal filtering.

### Mechanism 3: Incremental Update via Selective Summary Regeneration
Propagating updates only through new leaf nodes and ancestors reduces update cost vs. full re-indexing. New documents → extract quadruples → merge into existing graph → generate reports only for new time nodes → incrementally update ancestor reports upward. Unaffected nodes untouched. Assumes new knowledge predominantly creates new temporal nodes rather than modifying existing ones; summary propagation is loss-tolerant.

## Foundational Learning

- **Concept: Temporal Knowledge Graphs (TKGs)**
  - Why needed here: TG-RAG extends static KGs with timestamped relations; understanding TKGs clarifies why standard triples (subject, relation, object) fail for time-sensitive facts.
  - Quick check question: Given triples (CompanyX, revenue, $5B) and (CompanyX, revenue, $6B), can you determine which year each applies to? (No—temporal KG adds timestamps to resolve.)

- **Concept: Personalized PageRank (PPR)**
  - Why needed here: Local retrieval uses PPR to propagate relevance from seed entities to connected nodes, ranking evidence beyond direct semantic matches.
  - Quick check question: If PPR starts from seed entity "Western Digital," which connected entities receive higher scores—direct neighbors or 3-hop neighbors? (Direct neighbors, with decay over distance.)

- **Concept: Incremental Indexing in RAG**
  - Why needed here: Real-world corpora evolve; understanding re-indexing costs explains why naive RAG struggles with continuous updates.
  - Quick check question: If you add 10% new documents to a vector database, what fraction of embeddings must be recomputed in naive RAG vs. TG-RAG? (Naive: all new chunks; TG-RAG: only new temporal nodes and ancestors.)

## Architecture Onboarding

- **Component map:**
  Chunker → LLM Quadruple Extractor → Temporal KG Builder → Time Hierarchy Builder → Report Generator (bottom-up) → Query Time Identifier → Semantic Edge Retriever (top-K) → Temporal Filter → PPR Scorer → Chunk Ranker → LLM Generator

- **Critical path:**
  1. Quadruple extraction quality determines graph fidelity—prompt engineering is high-leverage.
  2. Time node alignment (query Tq → hierarchy) gates retrieval; failure here cascades.
  3. Report generation token budget controls indexing cost; too small → summaries lose detail.

- **Design tradeoffs:**
  - Graph compactness vs. expressiveness: TG-RAG uses ~17K entities vs. GraphRAG's ~45K (Table VIII), but parallel temporal edges increase edge count.
  - Local vs. global retrieval: Local for precise facts (token budget 12K, 10% chunks), global for trends (24K, 90% reports).
  - Update frequency vs. staleness: Frequent small updates efficient; batch updates underutilize incremental design.

- **Failure signatures:**
  - Empty Tq: Query lacks temporal expression → temporal filter returns nothing → check for fallback to semantic-only mode.
  - Temporal ambiguity: "before 2024" vs. "2023 Q4" mismatch in granularity → normalize all timestamps to finest granularity during indexing.
  - Edge explosion: High-frequency entities (e.g., daily updates) create many parallel edges → consider edge aggregation for coarse-grained queries.

- **First 3 experiments:**
  1. **Temporal extraction validation:** Manually inspect 50 extracted quadruples; measure timestamp accuracy, relation correctness, entity normalization. Target: >90% timestamp precision.
  2. **Retrieval ablation:** Run w/o temporal filter, w/o PPR, w/o both on held-out queries; compare Correct/Refusal/Incorrect scores to isolate mechanism contributions.
  3. **Update cost benchmark:** Index 2020–2023 corpus, then incrementally add 2024; measure token consumption and query performance drift on base vs. new queries. Verify <10% cost vs. full re-index.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text. However, several implicit questions arise from the methodology and evaluation approach.

## Limitations
- PPR hyperparameter configuration remains unspecified, which could significantly impact retrieval quality across different graph densities.
- The incremental update mechanism assumes new facts primarily create new temporal nodes rather than modifying existing ones—a valid assumption for earnings data but potentially problematic for domains requiring frequent fact corrections.
- The temporal extraction pipeline's reliance on LLM-based quadruple extraction introduces potential brittleness when handling complex temporal expressions or documents with poor timestamp normalization.

## Confidence
- **High Confidence (8-10/10):** The bi-level temporal graph architecture effectively resolves time-sensitive retrieval problems by distinguishing identical facts at different times through parallel temporal edges. The empirical results showing TG-RAG's superiority over GraphRAG on Correct/Refusal metrics are robust and well-supported.
- **Medium Confidence (6-7/10):** The incremental update mechanism's claimed efficiency gains (reducing token cost from 30M to 1.6M) are domain-specific and may not generalize to knowledge bases with frequent fact modifications requiring ancestor re-summaries. The time hierarchy's effectiveness depends heavily on query temporal expression quality.
- **Low Confidence (3-5/10):** The paper's performance claims for abstract question answering (Comprehensiveness, Diversity, Temporal Coverage) are based on pairwise LLM comparisons that may introduce circular evaluation bias. The token budget allocations (12K vs 24K) and their impact on retrieval quality are not systematically validated.

## Next Checks
1. **Temporal Extraction Robustness Test:** Manually evaluate 100 extracted quadruples from diverse document types (not just earnings calls) to measure timestamp accuracy and relation correctness across domains with varying temporal expression patterns.

2. **Cross-Domain Generalization Benchmark:** Replicate the TG-RAG pipeline on a non-financial temporal knowledge base (e.g., news articles or scientific publications) to verify whether the 0.18 Correct score improvement over GraphRAG holds outside the earnings call domain.

3. **Update Mechanism Stress Test:** Design test cases where existing facts require modification (not just addition) and measure whether the incremental update mechanism maintains retrieval accuracy without requiring full re-indexing.