---
ver: rpa2
title: Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems
arxiv_id: '2512.23809'
source_url: https://arxiv.org/abs/2512.23809
tags:
- shap
- learning
- attacks
- zta-fl
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Zero-Trust Agentic Federated Learning (ZTA-FL) addresses security
  gaps in Industrial IoT (IIoT) deployments by combining TPM-based cryptographic attestation,
  SHAP-weighted aggregation for Byzantine detection, and on-device adversarial training.
  The hierarchical edge-fog-cloud architecture achieves 97.8% detection accuracy,
  93.2% under 30% Byzantine attacks (3.1% improvement over FLAME), and 89.3% adversarial
  robustness while reducing communication overhead by 34%.
---

# Zero-Trust Agentic Federated Learning for Secure IIoT Defense Systems

## Quick Facts
- arXiv ID: 2512.23809
- Source URL: https://arxiv.org/abs/2512.23809
- Reference count: 40
- Achieves 97.8% detection accuracy with 93.2% Byzantine resilience and 89.3% adversarial robustness

## Executive Summary
This paper presents Zero-Trust Agentic Federated Learning (ZTA-FL), a framework addressing security gaps in Industrial IoT deployments through hardware-rooted authentication, explainable Byzantine detection, and on-device adversarial training. The hierarchical edge-fog-cloud architecture achieves superior security metrics while reducing communication overhead by 34% compared to baseline federated learning approaches.

## Method Summary
ZTA-FL combines TPM-based cryptographic attestation for zero-trust agent verification, SHAP-weighted aggregation for Byzantine detection, and on-device adversarial training to harden models against evasion attacks. The framework uses an 8-bit quantized CNN-LSTM architecture trained on non-IID IIoT datasets with hierarchical aggregation across edge, fog, and cloud layers. The method achieves 97.8% detection accuracy with theoretical guarantees for Byzantine resilience under 30% attack rates and maintains 89.3% adversarial robustness against FGSM and PGD attacks.

## Key Results
- 97.8% baseline detection accuracy on Edge-IIoTset
- 93.2% accuracy under 30% Byzantine attacks (3.1% improvement over FLAME)
- 89.3% adversarial robustness against FGSM/PGD attacks
- 34% reduction in communication overhead through 8-bit quantization

## Why This Works (Mechanism)

### Mechanism 1: TPM-based Cryptographic Attestation
Hardware-rooted identity verification prevents impersonation and Sybil attacks through TPM-generated attestation tokens containing {ID_i, timestamp, PCR measurement, nonce} signed with TPM private keys. Fog nodes verify signatures, freshness, and PCR values before accepting updates, achieving FAR < 10^-7.

### Mechanism 2: SHAP-weighted Byzantine Detection
Feature importance stability provides explainable detection of poisoned model updates through SHAP stability scores (s_i = 1 - ||φ_i - φ_ref||_2 / ||φ_ref||_2). This identifies Byzantine agents beyond μ_s - 2σ_s threshold with theoretical detection probability ≥ 0.75 when attack magnitude exceeds 2σ_s / (ρL_φ).

### Mechanism 3: On-device Adversarial Training
Local adversarial example generation hardens models against evasion attacks through FGSM/PGD generation on-device. Each agent trains on 70% clean + 30% adversarial examples, achieving 87.6% adversarial accuracy (+16.4% over baseline) while preserving data privacy.

## Foundational Learning

- **Federated Learning (FedAvg algorithm)**: Core paradigm for distributed training without data centralization; understand local gradient computation, model aggregation, communication rounds, and non-IID challenges. Quick check: Can you explain why FedAvg degrades under non-IID data distributions?

- **Byzantine fault tolerance in distributed ML**: Context for understanding poisoning attack vectors (label flipping, gradient manipulation, backdoors) and why distance-based methods like Krum fail with heterogeneous IIoT data. Quick check: Why do distance-based methods like Krum fail with heterogeneous IIoT data?

- **SHAP (SHapley Additive exPlanations)**: Core detection mechanism for feature attribution stability; understand how SHAP values represent feature contributions to predictions and how stability scores identify Byzantine behavior. Quick check: What does a SHAP value represent for a given feature in a model prediction?

## Architecture Onboarding

- **Component map**: Perception module → Local IDS (8-bit CNN-LSTM) → Adversarial training → TPM attestation → TLS 1.3 upload → Fog attestation verification → SHAP computation → Robust aggregation → Cloud global update

- **Critical path**: Attestation (4.2ms) → Local training + adversarial (~20s) → SHAP filtering (3.1s) → Aggregation → Convergence check

- **Design tradeoffs**: +97% computational overhead (28.2s vs 14.3s per round) vs +34% communication reduction; Byzantine tolerance (β < 0.5) vs 8.2% FPR under extreme non-IID; hierarchical fog structure handles 1000+ agents in 127s/round

- **Failure signatures**: Extreme non-IID causes 8.2% false positives; slow poisoning (α < 0.1/round) undetected after 50+ rounds; β > 0.4 collusion reduces accuracy to 78.4%; clean-label backdoors achieve 18.4% ASR

- **First 3 experiments**: 1) Clean baseline replication on Edge-IIoTset (97.8% accuracy, 42-round convergence); 2) Byzantine stress test with 30% label-flipping attacks (93.2% accuracy); 3) Ablation validation comparing baseline → +attestation → +SHAP → +adversarial → full configurations

## Open Questions the Paper Calls Out

- Can cumulative SHAP drift tracking effectively detect slow poisoning attacks (α < 0.1 per round over 50+ rounds) without excessive false positives? Current per-round detection fails for attacks lasting 50+ rounds with α < 0.1.

- Does computing SHAP values on common validation datasets leak statistically significant information about participating agents' local data distributions? Formal privacy evaluation remains future work.

- What detection and mitigation mechanisms can maintain robustness when Byzantine agents collude to shift SHAP distributions (β > 0.3)? Collusion-based attacks degrade accuracy to 78.4% versus 93.2% at β = 0.3.

- How do hardware TPM implementations (Infineon SLB 9670, ARM TrustZone) compare to software emulator in attestation latency and false rejection rates under real IIoT deployment conditions? Hardware validation planned as immediate follow-on research.

## Limitations

- Architecture specification gaps exist with only high-level CNN-LSTM descriptions provided, requiring hyperparameter tuning for exact replication
- SHAP reference computation ambiguity affects detection performance and theoretical guarantees
- 97% computational overhead increase may be prohibitive for battery-powered edge devices
- Framework assumes TPM keys cannot be extracted via side-channel attacks or forged signatures

## Confidence

**High Confidence**: TPM-based attestation achieves FAR < 10^-7; hierarchical architecture reduces communication overhead by 34%; 97.8% baseline detection accuracy; component-wise ablation contributions verified

**Medium Confidence**: 93.2% accuracy under 30% Byzantine attacks; 89.3% adversarial robustness; theoretical Byzantine detection guarantees

**Low Confidence**: Scalability to 1000+ agents (simulation-based); extreme non-IID failure modes; slow poisoning detection effectiveness

## Next Checks

- Replicate architecture specification ambiguity by implementing multiple CNN-LSTM configurations within 487K parameter constraint to validate approach robustness to architectural details

- Conduct comprehensive security analysis of TPM attestation mechanism by modeling physical attack scenarios (side-channel analysis, early firmware compromise) and quantifying security guarantees under realistic threat models

- Evaluate framework performance against clean-label backdoor attacks (18.4% vulnerability) by testing whether combining SHAP detection with backdoor-specific defenses maintains 93.2% Byzantine accuracy while reducing ASR