---
ver: rpa2
title: Learning Reconfigurable Representations for Multimodal Federated Learning with
  Missing Data
arxiv_id: '2510.22880'
source_url: https://arxiv.org/abs/2510.22880
tags:
- missing
- modality
- learning
- data
- pepsy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a new framework, PEPSY, for multimodal federated\
  \ learning with missing data. The framework introduces locally adaptive representations\
  \ based on learnable client-side embedding controls that encode each client\u2019\
  s data-missing patterns."
---

# Learning Reconfigurable Representations for Multimodal Federated Learning with Missing Data

## Quick Facts
- arXiv ID: 2510.22880
- Source URL: https://arxiv.org/abs/2510.22880
- Reference count: 40
- Primary result: Up to 36.45% performance improvement under severe data incompleteness

## Executive Summary
This paper proposes PEPSY, a framework for multimodal federated learning that addresses the challenge of heterogeneous missing data across clients. The key innovation is the introduction of locally adaptive representations through learnable client-side embedding controls that encode each client's data-missing patterns. These embeddings serve as reconfiguration signals that align globally aggregated representations with each client's local context, enabling more effective use of shared information despite missing modalities. The framework demonstrates significant performance improvements on medical datasets (PTBXL and SleepEDF) compared to existing federated learning baselines, particularly under severe missingness conditions.

## Method Summary
PEPSY operates by extracting modality-specific, data-specific, and missing-pattern features at each client, then selecting relevant embedding controls via cosine similarity to adapt the global model to local missingness patterns. The framework employs contrastive reconfiguration losses (L_ds and L_rc) to align representations across different data-missing contexts, while the server aggregates models using FedAvg and clusters data-missing profiles using PFPT-based clustering. The approach handles both IID and Non-IID data distributions across clients and demonstrates robustness across various missing patterns and degrees of missingness.

## Key Results
- Achieves up to 36.45% performance improvement under severe data incompleteness compared to baselines
- Shows robust performance across various missing patterns in both IID and Non-IID settings
- Demonstrates consistent improvements across PTBXL (12-lead ECG) and SleepEDF (5 modalities) datasets

## Why This Works (Mechanism)
PEPSY works by creating a dynamic reconfiguration mechanism where each client learns to adapt the global model to its specific data-missing patterns through learnable embedding controls. These controls act as adaptive signals that transform the globally aggregated representation into one that better matches the client's local context. The contrastive reconfiguration losses ensure that similar data instances across different clients maintain semantic similarity despite different missing patterns, while the PFPT clustering aggregates data-missing profiles to improve the global model's ability to handle heterogeneity.

## Foundational Learning
- **FedAvg aggregation**: Why needed - to combine client models while preserving global knowledge; Quick check - verify aggregation produces reasonable global model
- **Contrastive learning**: Why needed - to maintain semantic consistency across different missing patterns; Quick check - monitor contrastive loss convergence
- **PFPT clustering**: Why needed - to aggregate data-missing profiles and capture client heterogeneity; Quick check - visualize cluster centroids and profile alignment
- **Inception Network encoders**: Why needed - to extract modality-specific features from heterogeneous data sources; Quick check - validate feature extraction quality per modality
- **Cosine similarity for control selection**: Why needed - to match embedding controls to client-specific missing patterns; Quick check - monitor control selection diversity across clients
- **Multi-loss optimization**: Why needed - to balance representation learning with missingness adaptation; Quick check - track individual loss components during training

## Architecture Onboarding
**Component Map**: Data → Modality Encoders → Feature Extraction → Embedding Control Selection → Reconfiguration Losses → Local Model Update → Server Aggregation → PFPT Clustering → Global Model Update

**Critical Path**: Client feature extraction → embedding control selection → contrastive reconfiguration → model update → server aggregation → profile clustering

**Design Tradeoffs**: The framework trades computational complexity at clients (multiple encoders, control selection) for improved robustness to missing data. The use of κ≪|Ψ| controls balances expressiveness with efficiency. The PFPT clustering adds server-side computation but enables better handling of heterogeneous missing patterns.

**Failure Signatures**: 
- Embedding controls collapse (all clients select same controls)
- PFPT clustering fails to align profiles across clients
- Performance drops significantly with pm≥0.8
- Contrastive losses dominate or vanish during training

**First Experiments**:
1. Implement baseline with standard Inception-v1 architecture and validate on PTBXL dataset
2. Test embedding control diversity by monitoring selection patterns across clients during training
3. Validate PFPT clustering effectiveness by visualizing t-SNE of global embeddings

## Open Questions the Paper Calls Out
None

## Limitations
- Specific Inception Network architecture variant is not fully specified, which could affect reproducibility
- PFPT clustering implementation details are missing, including hyperparameters and cluster selection logic
- Embedding control pool initialization strategy is unclear, including size and initialization values

## Confidence
- High confidence in framework's conceptual soundness and empirical improvements
- Medium confidence in exact reproducibility due to architectural and implementation details
- Low confidence in performance consistency across different hardware configurations

## Next Checks
1. Implement a baseline version using standard Inception-v1 architecture and validate on PTBXL dataset
2. Test embedding control diversity by monitoring selection patterns across clients during training
3. Validate PFPT clustering effectiveness by visualizing t-SNE of global embeddings and checking centroid convergence patterns