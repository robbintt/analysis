---
ver: rpa2
title: Zero-shot Shark Tracking and Biometrics from Aerial Imagery
arxiv_id: '2501.05717'
source_url: https://arxiv.org/abs/2501.05717
tags:
- shark
- flair
- video
- videos
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces FLAIR, a zero-shot approach for tracking
  sharks and extracting biometrics from aerial drone imagery using Segment Anything
  Model 2 and Contrastive Language-Image Pretraining. FLAIR processes drone videos
  to segment shark species of interest and extract measurements like length and tailbeat
  frequency without requiring labeled training data.
---

# Zero-shot Shark Tracking and Biometrics from Aerial Imagery

## Quick Facts
- arXiv ID: 2501.05717
- Source URL: https://arxiv.org/abs/2501.05717
- Reference count: 21
- Zero-shot shark segmentation and tracking from aerial drone videos, achieving Dice score of 0.81 on Pacific nurse sharks without labeled training data

## Executive Summary
This study introduces FLAIR, a zero-shot approach for tracking sharks and extracting biometrics from aerial drone imagery using Segment Anything Model 2 and Contrastive Language-Image Pretraining. FLAIR processes drone videos to segment shark species of interest and extract measurements like length and tailbeat frequency without requiring labeled training data. The method achieved a Dice score of 0.81 on Pacific nurse shark segmentation and generalized well to other shark species. It outperformed state-of-the-art object detection models and matched human-in-the-loop approaches while requiring no human annotation effort, significantly reducing the workload for marine ecology studies.

## Method Summary
FLAIR is a zero-shot pipeline that combines SAM 2 for instance segmentation with CLIP for candidate filtering, enabling shark tracking and biometric extraction from aerial drone footage. The method samples frames at 30-frame intervals, generates segmentation masks using SAM 2 Automatic Mask Generator, filters candidates through CLIP with species-specific prompts, and tracks sharks across videos. Biometrics like body length and tailbeat frequency are extracted through mask analysis and signal processing, with length conversion using camera parameters. The approach requires no training data and works across different shark species, demonstrating strong generalization potential.

## Key Results
- Achieved Dice score of 0.81 for Pacific nurse shark segmentation in zero-shot setting
- Extracted body lengths within 5% accuracy compared to manual measurements
- Computed tailbeat frequency with mean error of only 2.07% compared to human analysis
- Outperformed state-of-the-art object detection models while requiring no human annotation

## Why This Works (Mechanism)
FLAIR leverages the zero-shot capabilities of large foundation models (SAM 2 and CLIP) to overcome the data scarcity problem in marine ecology. SAM 2 provides robust segmentation masks without requiring species-specific training, while CLIP's text-image alignment enables species-specific filtering using natural language prompts. The 30-frame sampling interval balances computational efficiency with tracking continuity, and the IOU-based track merging ensures coherent animal trajectories. This combination allows the system to work across different shark species and environmental conditions without retraining.

## Foundational Learning
- Zero-shot learning: Training models on general data to perform tasks on new classes without specific examples - needed because marine species data is scarce and expensive to annotate; quick check: verify model can process novel animal types
- Instance segmentation vs object detection: Segmenting precise object boundaries rather than bounding boxes - needed for accurate biometric measurements; quick check: compare mask boundaries to object edges
- CLIP text-image alignment: Using natural language to guide computer vision models - needed to filter shark candidates without labeled data; quick check: test different prompts for target species
- SAM 2 video prediction: Maintaining segmentation consistency across video frames - needed for continuous tracking; quick check: verify mask stability during shark movement
- Skeletonization for length measurement: Converting 2D masks to 1D centerlines - needed to extract body length from top-down views; quick check: confirm centerline follows body axis
- Tailbeat frequency extraction: Analyzing periodic motion patterns in time series - needed for swimming behavior analysis; quick check: verify frequency peaks in FFT

## Architecture Onboarding

**Component Map:** Drone Video -> SAM 2 Auto Mask Generator -> CLIP Scoring -> Candidate Filtering -> SAM 2 Video Prediction -> Track Merging -> Biometrics Extraction

**Critical Path:** Video frames → SAM 2 segmentation → CLIP filtering → Track propagation → Biometric computation

**Design Tradeoffs:** 30-frame sampling interval balances speed vs tracking continuity; 0.95 CLIP threshold trades precision for recall; IOU 0.7 merging threshold balances track fragmentation vs false merges

**Failure Signatures:** Low Dice scores indicate poor segmentation; spurious detections suggest CLIP threshold too low; track fragmentation suggests sampling interval too large

**3 First Experiments:**
1. Test FLAIR on a new shark species with different body proportions to assess generalization
2. Run ablation studies varying CLIP prompts to quantify sensitivity to prompt wording
3. Evaluate performance on videos with varying water clarity to identify environmental failure modes

## Open Questions the Paper Calls Out
- Does FLAIR generalize effectively to non-shark marine taxa (e.g., cetaceans, rays) or terrestrial megafauna without requiring modifications to the CLIP prompts?
- Can segmentation heuristics be developed to consistently exclude shark shadows in shallow water and retain fine morphological features (e.g., pectoral fins) in turbid conditions?
- Can the pipeline be augmented to accurately estimate absolute biometrics from aerial videos that lack standard drone telemetry metadata?

## Limitations
- Performance degrades in turbid water where fine morphological features are obscured
- Current implementation cannot consistently separate shark shadows from the animal body
- Accurate biometric extraction requires drone metadata (altitude, focal length) that may not be available in archival footage

## Confidence
- Zero-shot segmentation performance: High confidence (Dice = 0.81 on tested species)
- Biometric extraction accuracy: Medium confidence (matches manual measurements within 5%)
- Generalization across species: Medium confidence (tested on few species, promising results)
- CLIP prompt sensitivity: Low confidence (prompts not specified in paper)

## Next Checks
1. Test FLAIR on a new shark species with different body proportions and habitats to assess cross-species generalization
2. Run ablation studies varying CLIP prompts and probability thresholds to quantify sensitivity to these design choices
3. Evaluate performance on videos with varying water clarity, depth, and lighting conditions to identify environmental failure modes