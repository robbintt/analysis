---
ver: rpa2
title: Efficient Graph Understanding with LLMs via Structured Context Injection
arxiv_id: '2509.00740'
source_url: https://arxiv.org/abs/2509.00740
tags:
- graph
- context
- llms
- structured
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a structured context injection framework to\
  \ improve LLM performance on graph reasoning tasks without requiring fine-tuning\
  \ or multi-step querying. The method injects task-specific and narrative-grounded\
  \ information\u2014such as character relationships from Game of Thrones\u2014into\
  \ LLM inputs, enhancing interpretability and reasoning over graph structures."
---

# Efficient Graph Understanding with LLMs via Structured Context Injection

## Quick Facts
- arXiv ID: 2509.00740
- Source URL: https://arxiv.org/abs/2509.00740
- Reference count: 25
- Key outcome: Structured context injection framework improves LLM graph reasoning accuracy without fine-tuning, achieving up to 95.74% accuracy on connectivity tasks

## Executive Summary
This paper proposes a structured context injection framework to improve LLM performance on graph reasoning tasks without requiring fine-tuning or multi-step querying. The method injects task-specific and narrative-grounded information—such as character relationships from Game of Thrones—into LLM inputs, enhancing interpretability and reasoning over graph structures. Two approaches, GOT Random and GOT Subgraph, were evaluated across four graph tasks using both LLaMA 3 8B and Gemini 1.5 Flash models. Results show consistent accuracy gains, with GOT Subgraph achieving up to 95.74% accuracy on connectivity with Gemini 1.5 Flash, outperforming baselines. The approach offers a practical, cost-efficient alternative to complex graph reasoning methods.

## Method Summary
The framework introduces a novel approach to graph reasoning by injecting structured, narrative-grounded context into LLM prompts. The method leverages a Game of Thrones-inspired format (GOT) that includes character descriptions, relationships, and storylines to provide richer semantic context for graph tasks. Two variants are proposed: GOT Random, which randomly selects nodes and relationships for injection, and GOT Subgraph, which strategically selects subgraphs based on task relevance. The framework processes graph inputs through an injection layer that adds GOT-formatted context before passing to the LLM, enabling improved reasoning without requiring model fine-tuning or complex multi-step querying.

## Key Results
- GOT Subgraph approach achieved 95.74% accuracy on connectivity tasks with Gemini 1.5 Flash, outperforming baseline methods
- Consistent accuracy improvements across four graph reasoning tasks when using structured context injection
- LLaMA 3 8B showed more modest but still measurable gains compared to Gemini 1.5 Flash, indicating model-dependent effectiveness
- Structured context injection provided cost-efficient performance gains without requiring expensive fine-tuning procedures

## Why This Works (Mechanism)
The method works by providing LLMs with richer semantic context that bridges the gap between abstract graph structures and human-readable narratives. By injecting GOT-formatted information including character descriptions, relationship narratives, and storylines, the LLM gains additional contextual understanding that enhances its ability to reason about graph relationships. This structured injection approach effectively simulates domain knowledge that would otherwise require expensive fine-tuning, while maintaining the efficiency of single-step prompting. The narrative grounding appears to help LLMs better interpret relationship types and entity attributes within graph structures.

## Foundational Learning
- Graph representation fundamentals: Understanding nodes, edges, and graph properties is essential for interpreting how LLMs process graph-structured data
- Why needed: Provides baseline knowledge for evaluating how structured context injection improves graph reasoning capabilities
- Quick check: Can you explain the difference between adjacency matrices and edge lists for representing graph data?

- Prompt engineering techniques: Knowledge of how prompt structure affects LLM output is crucial for understanding context injection effectiveness
- Why needed: Helps assess why narrative-grounded prompts perform better than standard graph representations
- Quick check: What prompt engineering strategies have you used to improve LLM performance on structured data tasks?

- Context window optimization: Understanding how LLMs handle large input contexts is important for evaluating injection overhead
- Why needed: Determines practical limits of context injection and its scalability
- Quick check: How do different LLMs handle context length limitations, and what strategies mitigate these constraints?

## Architecture Onboarding

Component map: Input Graph -> Graph Parser -> GOT Injection Layer -> LLM (LLaMA 3 8B / Gemini 1.5 Flash) -> Output Reasoning

Critical path: Graph input is parsed into structured format, passes through GOT injection layer where narrative context is added, then processed by LLM to produce reasoning output. The injection layer is the key differentiator that enables performance improvements.

Design tradeoffs: The framework trades increased input size and computational overhead for improved reasoning accuracy without fine-tuning costs. The choice between GOT Random and GOT Subgraph represents a balance between simplicity and strategic context selection. Using narrative-grounded context improves interpretability but may introduce domain-specific bias.

Failure signatures: Performance degradation may occur with highly complex or cyclic graph structures not well-represented in the GOT narrative format. Models with smaller context windows may struggle with large graph injections. The framework may show limited effectiveness on graph types that don't map well to narrative relationships (e.g., weighted graphs, temporal graphs).

First experiments:
1. Test GOT Subgraph on synthetic graphs with varying densities to measure scalability
2. Compare GOT Random vs GOT Subgraph performance on graphs with different relationship types
3. Evaluate injection overhead by measuring latency increases across different graph sizes

## Open Questions the Paper Calls Out
None specified in the provided information.

## Limitations
- Evaluation relies entirely on synthetic graphs and Game of Thrones character networks, potentially limiting generalizability to real-world graph structures
- Performance gains are primarily shown with Gemini 1.5 Flash, while LLaMA 3 8B shows more modest improvements, suggesting model-specific effectiveness
- Manual creation of GOT narratives introduces potential bias and questions about scalability to other domains
- Paper doesn't address computational overhead from context injection or analyze how performance scales with graph size beyond tested range

## Confidence
- High: The GOT Subgraph approach consistently outperforms baselines across multiple tasks and models when evaluated on the reported metrics
- Medium: Claims about cost-efficiency and practicality relative to fine-tuning approaches, as computational costs weren't directly measured or compared
- Medium: Generalizability to other graph types and domains beyond the synthetic and GOT datasets tested

## Next Checks
1. Test the framework on real-world graph datasets (e.g., social networks, citation networks, or knowledge graphs) with varying structural properties to assess robustness
2. Conduct controlled experiments measuring actual computational overhead and latency introduced by context injection versus baseline prompting
3. Perform ablation studies systematically removing individual components (entity descriptions, relationship narratives, GOT format) to quantify their independent contributions to performance gains