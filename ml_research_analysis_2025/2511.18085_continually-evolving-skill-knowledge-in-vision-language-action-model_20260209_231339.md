---
ver: rpa2
title: Continually Evolving Skill Knowledge in Vision Language Action Model
arxiv_id: '2511.18085'
source_url: https://arxiv.org/abs/2511.18085
tags:
- knowledge
- task
- learning
- arxiv
- skill
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem of continual skill learning in
  vision-language-action (VLA) models, which struggle to retain and adapt knowledge
  across diverse manipulation tasks. To overcome this, the authors propose Stellar
  VLA, a knowledge-driven continual learning framework with two variants: T-Stellar,
  which models task-centric knowledge spaces, and TS-Stellar, which additionally captures
  hierarchical task-skill structures.'
---

# Continually Evolving Skill Knowledge in Vision Language Action Model

## Quick Facts
- arXiv ID: 2511.18085
- Source URL: https://arxiv.org/abs/2511.18085
- Reference count: 40
- Key result: Stellar VLA achieves over 50% average improvement in final success rates compared to baselines on LIBERO benchmark

## Executive Summary
This paper addresses the challenge of continual skill learning in vision-language-action (VLA) models, which typically suffer from catastrophic forgetting when learning new manipulation tasks. The authors propose Stellar VLA, a knowledge-driven continual learning framework that dynamically discovers and preserves task knowledge through a Dirichlet Process-based knowledge space. The approach enables self-supervised knowledge evolution without requiring additional annotations or predefined architecture expansion, allowing the model to adapt to new tasks while retaining previous capabilities.

## Method Summary
Stellar VLA employs a knowledge-driven continual learning framework with two variants: T-Stellar models task-centric knowledge spaces using Dirichlet Process Mixture Models, while TS-Stellar additionally captures hierarchical task-skill structures through Hierarchical Dirichlet Processes. The method uses joint learning of task latent representations and knowledge space to enable self-supervised knowledge evolution. Knowledge-guided expert routing in a Mixture-of-Experts architecture provides task specialization without extra network parameters, balancing parameter sharing and isolation. The framework operates with minimal experience replay buffers (1-5% of data) while maintaining strong performance on manipulation tasks.

## Key Results
- Stellar VLA achieves over 50% average improvement in final success rates compared to baselines on LIBERO benchmark
- TS-Stellar excels in complex action inference by capturing hierarchical task-skill structures
- The method demonstrates effective knowledge retention and discovery without requiring additional annotations
- Real-world experiments validate the approach beyond simulation environments

## Why This Works (Mechanism)

### Mechanism 1: Self-Supervised Knowledge Space Evolution
The model uses a Dirichlet Process Mixture Model (DPMM) running alongside a VAE encoder to dynamically discover and organize new task clusters. As the VAE produces task latents from vision-language data, the DPMM probabilistically assigns them to existing Gaussian clusters or instantiates new clusters based on the concentration parameter Î±. This allows the knowledge space to expand self-supervised as new tasks arrive, preventing catastrophic forgetting through constrained latent representations.

### Mechanism 2: Knowledge-Guided Expert Routing
Instead of routing based on diffusion noise levels, Stellar computes a knowledge embedding consisting of a "Relation Embedding" (distance to cluster centers) and a "Top-K Semantic Embedding." This vector guides the MoE router to select specific experts for the current task latent, achieving better task-specific specialization than noise-level routing. This isolates parameters for distinct tasks while sharing experts for similar clusters, lowering training overhead.

### Mechanism 3: Hierarchical Task-Skill Modeling (TS-Stellar)
TS-Stellar models tasks as distributions over shared skills using Hierarchical Dirichlet Processes. It employs a hierarchical VAE with task latents (from language) and skill latents (from visual observation), forcing the model to learn reusable skill primitives shared across the global measure. This allows new tasks to be constructed from existing skill clusters, excelling in long-horizon or complex manipulation tasks.

## Foundational Learning

- **Dirichlet Process & Non-parametric Bayes**: The DP allows infinite mixture clustering, enabling new clusters to emerge as needed when task complexity grows. Quick check: Can you explain why a finite GMM fails when the number of future tasks is unknown?

- **Variational Autoencoders & Latent Constraints**: The VAE compresses vision-language data into task latents, but with a modified KL divergence loss that constrains these latents relative to the DP knowledge space rather than a standard unit Gaussian. Quick check: How does modifying the VAE's prior from N(0,1) to a DP mixture prevent catastrophic forgetting?

- **Mixture of Experts Routing**: The action prediction head uses MoE with knowledge-guided routing instead of standard noise-based routing. Quick check: What specific input tensor is fed into the MoE Router in Stellar VLA, and how does it differ from MoDE?

## Architecture Onboarding

- **Component map**: CLIP (Text) + ResNet (Vision) -> Hierarchical VAE Encoder (z_task, z_skill) -> Knowledge Space (DPMM/HDP) -> Knowledge Embedding Generator (f_R, f_S) -> Softmax Gate -> Diffusion Transformer with MoE Blocks -> Action Output

- **Critical path**: The co-evolution loop requires implementing the variational inference update (memoVB) for the Knowledge Space simultaneously with the VAE training step. If the Knowledge Space is static while the VAE drifts, the KL constraint becomes misleading and routing fails.

- **Design tradeoffs**: T-Stellar (flat clustering) is simpler and lighter; TS-Stellar (hierarchical) is computationally heavier but necessary for long-horizon tasks. The tiny replay buffer (1-5%) reduces memory overhead but places immense pressure on the Knowledge Space to act as a proxy for past data.

- **Failure signatures**: Rigid behavior (performing previous task actions on new tasks) indicates DP failed to open new cluster; gripper desynchronization in dual-arm tasks indicates missing hierarchical skill prior or oscillating routing.

- **First 3 experiments**: 1) Ablate Knowledge Space (train with Gaussian prior and noise routing) to verify performance drop (~20-30%). 2) Latent visualization (t-SNE) to confirm distinct clusters for T-Stellar vs overlapping regions for TS-Stellar. 3) Forgetting test (NBT) comparing Stellar vs baseline after training Task A, then Task B, then evaluating Task A.

## Open Questions the Paper Calls Out

The paper explicitly identifies scaling to larger VLA models and more complex skill spaces as future work. While the current experiments validate the approach on standard benchmarks, the stability and tractability of the Dirichlet Process-based knowledge space on models with billions of parameters across benchmarks with significantly higher task diversity (>100 skills) remain unexplored.

## Limitations

- Performance gains heavily depend on proper integration of DP clustering with MoE routing, with underspecified architectural details making exact reproduction challenging
- Reliance on tiny experience replay buffers (1-5%) places immense pressure on knowledge space to prevent forgetting, with robustness across diverse unseen task distributions yet to be fully validated
- Strong claims about knowledge space generalization to truly novel tasks without catastrophic forgetting require more extensive long-term validation beyond current benchmarks

## Confidence

- **High Confidence**: The core concept of using non-parametric DP/HDP for dynamic task knowledge organization is well-founded and logically addresses continual learning
- **Medium Confidence**: Significant performance improvements reported, but exact component contributions (DPMM vs HDP vs routing vs ER) are difficult to isolate from ablation studies
- **Low Confidence**: Claims about self-evolving knowledge space and long-term generalization require more direct empirical validation

## Next Checks

1. **Ablation of Knowledge Space**: Train baseline with standard Gaussian prior and noise-based routing to directly quantify DP/HDP impact on Final Success Rate and NBT metrics

2. **Latent Space Visualization**: Generate and visualize task latents (z) for 5-7 distinct tasks using t-SNE/UMAP to confirm T-Stellar shows separate clusters while TS-Stellar shows hierarchical structure

3. **Long-Tail Forgetting Test**: After full training sequence, perform long-interval recall test evaluating first 3 tasks after 10+ task gaps to track success rate decay and test long-term retention claims