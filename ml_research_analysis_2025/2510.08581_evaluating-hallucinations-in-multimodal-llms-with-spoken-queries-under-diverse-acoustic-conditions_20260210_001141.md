---
ver: rpa2
title: Evaluating Hallucinations in Multimodal LLMs with Spoken Queries under Diverse
  Acoustic Conditions
arxiv_id: '2510.08581'
source_url: https://arxiv.org/abs/2510.08581
tags:
- spoken
- queries
- hallucinations
- noise
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates how spoken queries affect hallucinations
  in multimodal large language models (MLLMs) by introducing RePOPE-Spk, an audio-augmented
  extension of the RePOPE benchmark where queries are provided as speech under diverse
  acoustic conditions. Experiments with Gemini and Gemma models show that spoken queries
  consistently degrade performance: accuracy drops by 3% under clean speech and up
  to 20% with environmental noise.'
---

# Evaluating Hallucinations in Multimodal LLMs with Spoken Queries under Diverse Acoustic Conditions

## Quick Facts
- **arXiv ID**: 2510.08581
- **Source URL**: https://arxiv.org/abs/2510.08581
- **Reference count**: 0
- **Primary result**: Spoken queries degrade multimodal LLM performance by 3% under clean speech and up to 20% with environmental noise, revealing inherent challenges for voice-based multimodal interaction.

## Executive Summary
This paper introduces RePOPE-Spk, an audio-augmented extension of the RePOPE benchmark, to evaluate how spoken queries affect hallucinations in multimodal large language models (MLLMs). By converting text queries to speech under clean and noisy acoustic conditions, the study reveals consistent performance degradation across both proprietary (Gemini) and open-source (Gemma) models. The findings show that environmental noise amplifies false positives, while extending query duration offers partial mitigation. Strategies like many-shot prompting and chain-of-thought reasoning provide limited improvements, suggesting that current mitigation techniques are insufficient for robust voice-based multimodal reasoning.

## Method Summary
The study evaluates object hallucination in MLLMs using RePOPE-Spk, where text queries from the RePOPE benchmark are converted to speech via TTS at 16 kHz. Environmental noise from ESC-50 is mixed at 5 dB and 0 dB SNR to simulate real-world acoustic conditions. Two MLLMs—Gemini-1.5-Flash and Gemma-3n—are tested on binary object existence questions using accuracy, recall, precision, and F1 metrics. The evaluation examines modality effects (text vs. clean vs. noisy speech), input ordering (image→speech vs. speech→image), query length padding, many-shot prompting, and chain-of-thought strategies.

## Key Results
- Accuracy drops by 3% under clean speech and up to 20% with environmental noise
- Noise amplifies false positives, with Gemini precision falling from 95.9% (text) to 64.6% (0 dB)
- Input order matters: Gemma degrades severely with speech-first inputs (F1: 83.5 → 70.1)
- Longer noisy queries partially restore performance: Gemini F1 improves from 74.3 to 82.9 when extended to 10 seconds
- Many-shot prompting plateaus at 5 examples for speech inputs, unlike text-based LLMs

## Why This Works (Mechanism)

### Mechanism 1: Cross-Modal Signal Degradation Cascade
Converting text queries to spoken form introduces accuracy loss even under clean acoustic conditions due to speech encoding adding a processing layer that may lose or distort semantic precision before the query reaches the language model.

### Mechanism 2: Noise-Induced False Positive Amplification
Environmental noise causes models to generate more false positives, suggesting overconfident yes responses under acoustic uncertainty as noisy speech inputs produce weaker or more ambiguous token representations.

### Mechanism 3: Temporal Context Buffering Effect
Extending noisy spoken query duration partially restores performance as longer audio provides more acoustic context tokens, potentially allowing the model to average out noise artifacts or strengthen signal representations through redundancy.

## Foundational Learning

- **Object Hallucination in VLMs**: Models assert objects not present in images. Why needed: RePOPE-Spk builds directly on POPE/RePOPE object hallucination methodology. Quick check: Can you explain why precision (not just accuracy) is critical for hallucination detection?

- **Signal-to-Noise Ratio (SNR)**: Ratio of signal power to noise power, measured in dB. Why needed: Paper uses 5 dB and 0 dB SNR conditions as primary noise stress tests. Quick check: Would lower SNR (e.g., -5 dB) likely improve or worsen hallucination rates?

- **Multimodal Input Ordering**: Sequence of presenting modalities (e.g., image before speech). Why needed: Table 2 shows Gemma degrades severely with S→I ordering (F1: 83.5 → 70.1). Quick check: Why might a model trained primarily on text-first data struggle with speech-first inputs?

## Architecture Onboarding

- **Component map**: Image encoder -> Speech encoder -> Multimodal fusion -> LLM backbone -> Response classification
- **Critical path**: Image encoding → Speech encoding → Multimodal fusion → Token generation → Response classification. Noise injection occurs at speech input; degradation propagates through fusion.
- **Design tradeoffs**: Unified multimodal interface vs. cascaded ASR+LLM (paper uses unified); many-shot prompting gains plateau at 5 shots; CoT strategies show limited improvements.
- **Failure signatures**: High recall, low precision under noise (models say yes too often); S→I ordering causes severe drops in some models; CoT on stronger model underperforms weaker model on noisy speech.
- **First 3 experiments**: 1) Replicate Table 1 baseline: Compare text vs. clean audio vs. noisy audio on target MLLM. 2) Ablate input order: Test I→S vs. S→I. 3) Test temporal padding: Extend noisy queries to 5s and 10s.

## Open Questions the Paper Calls Out

### Open Question 1
What mechanisms enable longer spoken query duration to partially mitigate noise-induced hallucinations, and can this effect be exploited systematically? The paper documents the phenomenon but does not investigate the underlying cause.

### Open Question 2
Why does many-shot prompting plateau at 5 examples for speech inputs, unlike text-based LLMs where performance continues improving with more examples? The paper observes the plateau but does not determine the underlying cause.

### Open Question 3
How do results generalize to natural human speech with varied accents, prosody, and speaking rates, beyond the controlled TTS synthesis used in RePOPE-Spk? The authors acknowledge using TTS with consistent speaker profile, establishing internal validity but leaving external validity unexplored.

### Open Question 4
What architectural or training modifications could make MLLMs inherently robust to spoken queries rather than requiring post-hoc mitigation strategies? The paper demonstrates the problem's pervasiveness but does not propose fundamental solutions beyond prompting techniques.

## Limitations
- TTS synthesis method and speaker profile are unspecified, making it unclear whether degradation stems from modality effects or synthesis artifacts
- Response parsing method for binary yes/no outputs is not detailed, raising concerns about consistency
- Environmental noise categories from ESC-50 are used but mixing SNR levels are not verified against real-world speech degradation patterns

## Confidence
- **High**: Core finding that spoken queries degrade multimodal model accuracy
- **Medium**: Noise-induced false positive amplification
- **Medium**: Temporal context buffering effect
- **Low**: TTS synthesis quality as independent variable

## Next Checks
1. **Ablate TTS Quality**: Reproduce experiments using two different TTS systems to isolate whether degradation is inherent to speech modality or dependent on synthesis quality.

2. **Parse Response Boundaries**: Implement and validate a consistent binary parsing method for model outputs to ensure observed performance differences aren't artifacts of response interpretation.

3. **Extend SNR Range**: Test at -5 dB and -10 dB SNR levels to determine if performance curves plateau or if degradation accelerates.