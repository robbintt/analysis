---
ver: rpa2
title: Reading with Intent -- Neutralizing Intent
arxiv_id: '2501.03475'
source_url: https://arxiv.org/abs/2501.03475
tags:
- text
- dataset
- passages
- emotions
- emotion-translator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper expands on the Reading with Intent task by creating
  a synthetic dataset of text passages translated into 11 distinct emotions. Using
  five LLMs, context passages were transformed into different emotional tones and
  combined into a dataset.
---

# Reading with Intent -- Neutralizing Intent

## Quick Facts
- arXiv ID: 2501.03475
- Source URL: https://arxiv.org/abs/2501.03475
- Authors: Benjamin Reichman; Adar Avsian; Larry Heck
- Reference count: 7
- Key outcome: Emotion-translator improves Reading with Intent task performance by ~3% on factually accurate sarcastic passages

## Executive Summary
This paper addresses the challenge of emotional and sarcastic text in Retrieval-Augmented Generation (RAG) systems by creating a synthetic dataset of 3.6M passages transformed into 11 distinct emotional tones using five different LLMs. The authors train an emotion translation model to convert between emotional states, demonstrating that neutralizing sarcastic passages improves downstream LLM comprehension by about 3% on factually accurate text. Human evaluations confirm the model better reconstructs both emotional and factual content compared to zero-shot approaches. The work highlights both the potential of synthetic emotion data and the limitations of current approaches when dealing with mixed sarcasm and factual distortions.

## Method Summary
The method involves retrieving passages from Natural Questions using GPL, then transforming each passage into 11 emotions using five different LLMs (Llama 3, Qwen 2.5, Phi-3, Gemma, Mistral-7B) to create a diverse synthetic corpus. An emotion translator is fine-tuned using LoRA (rank 8) on Llama-3.1-8B-Instruct with 90% cross-emotion mapping and 10% self-mapping regularization. The model learns to translate between emotions using prompt prefixes specifying source and target emotions. For deployment, retrieved passages are classified for emotion and translated to neutral tone before being processed by downstream LLMs.

## Key Results
- Emotion-translator achieves BLEU score 4.87× higher than unfine-tuned model on human-annotated test set
- Neutralizing factually accurate sarcastic passages improves Reading with Intent task performance by ~2.8% on average
- Human evaluations show emotion-translator outperforms zero-shot LLM in emotional and factual reconstruction

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Synthetic data generation using multiple LLMs produces a more diverse and representative emotional corpus than single-model generation.
- **Mechanism:** Each passage is randomly assigned to one of five LLMs per emotion. Combining outputs reduces model-specific biases in emotional expression. The KL-Divergence of the combined dataset (unigram: 0.3, bigram: 4, trigram: 11) is lower than any individual model's output, indicating closer distributional alignment with original text.
- **Core assumption:** Diversity across model architectures and training corpora translates to broader emotional coverage.
- **Evidence anchors:** [abstract], [section 3], [section 4]

### Mechanism 2
- **Claim:** Fine-tuning with LoRA on a parallel emotion corpus enables controllable emotion-to-emotion translation while preserving factual content.
- **Mechanism:** Training examples are prefixed with prompts specifying source and target emotions. The model learns conditional next-token prediction via cross-entropy loss. 10% of examples use self-mapping (same source and target emotion) for regularization, enabling the model to preserve tone when emotion is unknown.
- **Core assumption:** Emotion can be treated as a discrete, transferable attribute separable from semantic content.
- **Evidence anchors:** [abstract], [section 5], [section 6.2]

### Mechanism 3
- **Claim:** Neutralizing sarcastic context passages improves downstream LLM comprehension for factually accurate but emotionally complex text.
- **Mechanism:** Sarcasm introduces processing overhead for LLMs trained primarily on neutral text. Translating sarcastic passages to neutral tone reduces this overhead without altering factual content, restoring performance to baseline levels on standard benchmarks.
- **Core assumption:** Sarcasm processing difficulty stems primarily from tone, not from factual ambiguity.
- **Evidence anchors:** [abstract], [section 6.1]

## Foundational Learning

- **Concept:** Retrieval-Augmented Generation (RAG) architecture
  - **Why needed here:** The entire problem framing assumes context passages are retrieved from corpora and fed to an LLM. Understanding the query-context separation is essential.
  - **Quick check question:** Can you explain why Wikipedia-like text is easier for RAG systems than internet-sourced text?

- **Concept:** Parameter-efficient fine-tuning (LoRA)
  - **Why needed here:** The emotion-translator uses LoRA with rank 8 to adapt Llama-3.1-8B-Instruct without modifying base weights.
  - **Quick check question:** What is the tradeoff between LoRA rank and adaptation capacity?

- **Concept:** Style transfer vs. emotion translation
  - **Why needed here:** Prior work treated emotion as binary (positive/negative); this paper treats it as multi-class with 11 discrete emotions.
  - **Quick check question:** Why might back-translation evaluation be necessary when human emotional datasets lack parallel bitext?

## Architecture Onboarding

- **Component map:** NQ queries → GPL retrieval → 5-LLM emotion transformation → combined corpus → LoRA fine-tuning → emotion-translator → downstream LLM
- **Critical path:** Synthetic data quality determines translator performance; translator quality determines downstream task improvement. Human evaluation validates both.
- **Design tradeoffs:** Treating emotions as categorical "directions" without magnitude limits fine-grained control. Self-mapping regularization improves stability but may dilute translation sharpness. Neutralization helps factually accurate sarcastic text but not factually distorted sarcastic text.
- **Failure signatures:** NQ-PSM/NQ-PSA datasets show ~0% improvement: neutralization does not help when sarcasm co-occurs with factual distortion. BLEU scores remain low (~5.82) even for fine-tuned model: emotion translation has many valid outputs, so exact string matching is misleading.
- **First 3 experiments:**
  1. Replicate synthetic data generation on a small corpus (100 passages × 3 emotions × 2 LLMs) and compute KL-Divergence against original.
  2. Train emotion-translator on subset (1,000 examples, 3 emotions) and evaluate round-trip translation on held-out human text.
  3. Deploy translator in RAG pipeline on NQ-FS subset; measure accuracy change vs. baseline without neutralization.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can models be designed to handle heterogeneous mixtures of sarcastic and non-sarcastic passages where the sarcastic passages are factually distorted?
- **Basis in paper:** [explicit] The conclusion states that future work should prioritize developing methods for handling such heterogeneous mixtures (as represented by the NQ-PSM and NQ-PSA datasets), as current neutralization approaches are insufficient for this complexity.
- **Why unresolved:** The current emotion-translator improves performance on factually accurate sarcasm but fails to improve or degrade performance on factually distorted sarcasm, leaving the challenge of processing potentially deceptive content unaddressed.
- **What evidence would resolve it:** A method that yields statistically significant improvements on the NQ-PSA and NQ-PSM benchmarks compared to the baseline.

### Open Question 2
- **Question:** Can the emotion-translation framework be extended to model and control emotional magnitude (intensity) rather than treating emotions solely as categorical directions?
- **Basis in paper:** [explicit] The Limitations section notes that the current synthetic data generation method treats emotions as categorical "directions" without accounting for variations in magnitude.
- **Why unresolved:** The current model conflates shifts between emotions with shifts in emotional intensity, making it difficult to preserve intensity while changing the emotion type or to steer the model toward specific magnitudes.
- **What evidence would resolve it:** A dataset labeled for emotional intensity and a translation model capable of decoupling emotion type from intensity in its output.

### Open Question 3
- **Question:** How can emotion neutralization be achieved without removing linguistic signals, such as sarcasm, that LLMs might use to detect deception?
- **Basis in paper:** [inferred] The results section notes that neutralizing factually distorted sarcastic passages removes a "signal" for deception, resulting in no performance gain; this suggests a tension between neutralizing tone and preserving veracity cues.
- **Why unresolved:** The paper demonstrates that while neutralization aids readability, it flattens nuanced indicators of untrustworthiness, and the authors provide no solution for retaining these signals during translation.
- **What evidence would resolve it:** A neutralization technique that maintains or enhances the model's ability to reject factually distorted passages while still normalizing the text.

## Limitations

- The assumption that emotional tone can be treated as a discrete, separable attribute from factual content is not fully validated, particularly for factually distorted sarcastic passages.
- The 11-emotion taxonomy lacks magnitude or intensity dimensions, preventing nuanced control over emotional expression strength.
- BLEU metric's low scores (~5.82) indicate it is an inappropriate evaluation measure for this subjective task, yet it remains the primary quantitative metric.

## Confidence

- **High Confidence:** The synthetic dataset generation methodology (multi-LLM aggregation reducing KL-Divergence) and its impact on downstream task performance (~3% improvement on factually accurate sarcastic passages) are well-supported by empirical results and human evaluations.
- **Medium Confidence:** The mechanism of emotion-to-emotion translation using LoRA fine-tuning is sound, but the evaluation methodology (BLEU scores, human evaluations) may not fully capture translation quality given the subjective nature of emotional expression.
- **Low Confidence:** The assumption that sarcasm processing difficulty stems primarily from tone rather than factual ambiguity is challenged by the lack of improvement on factually distorted sarcastic passages, suggesting the mechanism may be incomplete.

## Next Checks

1. Conduct ablation studies testing emotion-translator performance on factually distorted sarcastic passages with and without factual preservation constraints to isolate whether the limitation is fundamental or implementation-specific.
2. Implement a controlled human evaluation study comparing synthetic emotion transformations against human-annotated emotional text to quantify generation accuracy and identify systematic biases in the multi-LLM approach.
3. Test the emotion translation model on embarrassment, nervousness, and relief emotions (not in the original 11) to evaluate generalization capability and determine if the model learns transferable emotion transformation principles or merely memorizes the training set.