---
ver: rpa2
title: 'TetriServe: Efficient DiT Serving for Heterogeneous Image Generation'
arxiv_id: '2510.01565'
source_url: https://arxiv.org/abs/2510.01565
tags:
- tetriserve
- requests
- parallelism
- serving
- request
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents TetriServe, a novel system for efficiently serving
  Diffusion Transformer (DiT) models under strict Service Level Objectives (SLOs).
  The core challenge addressed is that existing serving systems using fixed-degree
  sequence parallelism are inefficient for heterogeneous workloads with mixed resolutions
  and deadlines, leading to poor GPU utilization and low SLO attainment.
---

# TetriServe: Efficient DiT Serving for Heterogeneous Image Generation

## Quick Facts
- arXiv ID: 2510.01565
- Source URL: https://arxiv.org/abs/2510.01565
- Authors: Runyu Lu; Shiqi He; Wenxuan Tan; Shenggui Li; Ruofan Wu; Jeff J. Ma; Ang Chen; Mosharaf Chowdhury
- Reference count: 40
- One-line primary result: TetriServe achieves up to 32% higher SLO attainment than existing solutions through step-level sequence parallelism

## Executive Summary
TetriServe addresses the challenge of efficiently serving Diffusion Transformer (DiT) models under strict Service Level Objectives (SLOs) for heterogeneous image generation workloads. The system introduces step-level sequence parallelism, dynamically adjusting parallelism for individual requests based on their deadlines, overcoming the inefficiencies of fixed-degree sequence parallelism used in existing systems. By employing a round-based scheduling mechanism that discretizes time into fixed rounds, TetriServe makes deadline-aware scheduling tractable while minimizing GPU hour consumption and late completions.

The paper presents comprehensive experimental results demonstrating TetriServe's effectiveness across various models (FLUX.1-dev, SD3), hardware platforms (8×H100, 4×A40), and workload types (uniform, skewed). The system achieves significant improvements in SLO attainment compared to existing solutions, particularly xDiT with fixed parallelism, while maintaining high performance across different arrival rates, resolution types, and SLO scales. The approach preserves image quality while optimizing resource utilization through intelligent scheduling and parallelism management.

## Method Summary
TetriServe introduces a novel approach to serving DiT models by implementing step-level sequence parallelism that dynamically adjusts the degree of parallelism for individual requests based on their deadlines. Unlike existing systems that use fixed-degree sequence parallelism, TetriServe's approach allows for more efficient resource utilization by tailoring parallelism to each request's specific requirements. The system employs a round-based scheduling mechanism that discretizes time into fixed rounds, enabling tractable deadline-aware scheduling while minimizing GPU hour consumption and late completions.

The core innovation lies in the ability to balance the trade-off between resource efficiency and SLO attainment by dynamically adjusting parallelism at the step level rather than maintaining fixed parallelism throughout the serving process. This approach is particularly effective for heterogeneous workloads with mixed resolutions and deadlines, where traditional fixed approaches struggle to maintain optimal performance. The system's design ensures that image quality is preserved while achieving significant improvements in SLO attainment compared to baseline methods.

## Key Results
- Achieves up to 32% higher SLO attainment compared to xDiT with fixed parallelism
- Demonstrates effectiveness across multiple hardware platforms (8×H100, 4×A40) and models (FLUX.1-dev, SD3)
- Maintains high performance across various workload types including uniform and skewed distributions
- Preserves image quality while optimizing resource utilization through intelligent scheduling

## Why This Works (Mechanism)
TetriServe's effectiveness stems from its dynamic approach to parallelism management, which addresses the fundamental inefficiency of fixed-degree sequence parallelism in heterogeneous serving environments. By adjusting parallelism at the step level based on individual request deadlines, the system can allocate resources more intelligently, ensuring that urgent requests receive appropriate computational resources while less time-sensitive requests can utilize more efficient parallelism configurations. The round-based scheduling mechanism provides a practical framework for implementing this dynamic approach while maintaining tractable scheduling complexity.

The system's ability to balance resource utilization with SLO attainment is achieved through careful consideration of the trade-offs between parallelism degree and completion time. By discretizing time into rounds, TetriServe can make scheduling decisions that optimize both GPU hour consumption and the number of late completions, leading to overall improved system performance. This approach is particularly effective in environments with mixed resolution requests and varying deadlines, where traditional fixed approaches would struggle to maintain optimal performance across all request types.

## Foundational Learning

**Sequence Parallelism**
- Why needed: Enables efficient distribution of DiT computation across multiple GPUs by partitioning sequence dimensions
- Quick check: Verify that sequence parallelism correctly partitions attention and feed-forward computations across devices

**Step-Level Adaptation**
- Why needed: Allows dynamic adjustment of parallelism based on individual request requirements and deadlines
- Quick check: Confirm that parallelism adjustments are made at each step without introducing synchronization overhead

**Round-Based Scheduling**
- Why needed: Discretizes time to make deadline-aware scheduling tractable while minimizing computational overhead
- Quick check: Validate that round duration is appropriately chosen to balance scheduling granularity and overhead

**SLO Attainment Metrics**
- Why needed: Provides quantitative measure of system performance in meeting service level objectives
- Quick check: Ensure metrics accurately capture both completion time and quality requirements

## Architecture Onboarding

**Component Map**
Scheduler -> Round Manager -> Resource Allocator -> DiT Execution Engine -> GPU Pool

**Critical Path**
Request arrival → Deadline-aware scheduling → Resource allocation → DiT execution → Result delivery

**Design Tradeoffs**
- Fixed vs. dynamic parallelism: TetriServe chooses dynamic for better resource utilization
- Round duration: Longer rounds reduce scheduling overhead but may impact SLO attainment
- Quality vs. speed: System maintains quality while optimizing for completion time

**Failure Signatures**
- High late completion rates indicate insufficient parallelism allocation
- GPU underutilization suggests over-provisioning or inefficient scheduling
- Quality degradation may result from excessive parallelism reducing computation time

**First Experiments**
1. Baseline comparison with fixed parallelism systems under uniform workload
2. Stress test with mixed resolution requests to evaluate dynamic adaptation
3. Scalability test across different GPU cluster sizes and hardware configurations

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation focused on specific DiT models (FLUX.1-dev and SD3) and GPU configurations (H100 and A40), limiting generalizability
- Round-based scheduling may introduce granularity issues for deadlines falling between round boundaries
- Assumes perfect knowledge of request deadlines and arrival times, which may not hold in real-world scenarios

## Confidence

**High confidence**: The core technical contribution of step-level sequence parallelism and its efficiency benefits are well-supported by experimental results across multiple hardware configurations and workload types.

**Medium confidence**: The comparison with xDiT baseline is comprehensive, but additional comparisons with other state-of-the-art serving systems would strengthen superiority claims.

**Medium confidence**: Quality preservation claims are supported by FID scores, but additional perceptual studies could strengthen these assertions.

## Next Checks

1. Evaluate TetriServe's performance with additional DiT models beyond FLUX.1-dev and SD3 to assess generalizability across different model architectures.

2. Test the system under dynamic workload conditions where arrival rates and request deadlines vary unpredictably to validate robustness in production scenarios.

3. Implement and evaluate the impact of different round durations on SLO attainment to optimize the trade-off between scheduling granularity and computational overhead.