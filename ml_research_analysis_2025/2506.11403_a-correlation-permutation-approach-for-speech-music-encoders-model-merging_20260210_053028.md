---
ver: rpa2
title: A correlation-permutation approach for speech-music encoders model merging
arxiv_id: '2506.11403'
source_url: https://arxiv.org/abs/2506.11403
tags:
- speech
- merging
- hubert
- mert
- permutation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a correlation-permutation approach to merge
  independently trained speech and music encoders without requiring shared initialization.
  The method computes layer-wise permutation matrices that maximize feature-wise cross-correlations
  between models, enabling effective alignment of otherwise disjoint weight spaces.
---

# A correlation-permutation approach for speech-music encoders model merging

## Quick Facts
- arXiv ID: 2506.11403
- Source URL: https://arxiv.org/abs/2506.11403
- Reference count: 40
- Primary result: Correlation-permutation method improves merged speech-music encoder performance by 14.83 points over linear interpolation

## Executive Summary
This paper addresses the challenge of merging independently trained speech and music encoders without shared initialization. The authors propose a correlation-permutation approach that computes layer-wise permutation matrices to maximize feature-wise cross-correlations between models, effectively aligning their internal representations. Applied to HuBERT and MERT encoders, this method enables successful model merging while preserving capabilities in both domains. The approach demonstrates substantial performance gains on SUPERB and MARBLE benchmarks compared to naive averaging, with ablation studies revealing which components require permutation for optimal results.

## Method Summary
The correlation-permutation approach merges independently trained HuBERT (speech) and MERT (music) encoders by aligning their internal feature channels through optimal permutations. The method computes cross-correlation matrices between activations of corresponding layers from both models on calibration data, then solves for optimal assignment using the LinearSumAssignment algorithm to find permutation matrices. These permutations are applied to MERT weights before merging via linear interpolation (λ=0.9 for HuBERT, λ=0.1 for MERT). The correlation computation reshapes activations from R^(B×C×T) to R^(C×B·T) for layer-wise processing, and permutations are applied after CNN layers and specific transformer components including attention heads and FFN W2 outputs.

## Key Results
- The correlation-permutation approach achieves a 14.83-point improvement in average score compared to linear interpolation
- Merged model shows 15.24-point improvement over HuBERT and 14.37-point improvement over MERT on MARBLE tasks
- Ablation studies demonstrate that permuting CNN layers and specific transformer components is essential, with deeper layers requiring more reordering than shallow ones

## Why This Works (Mechanism)
The correlation-permutation approach works by aligning the internal feature representations of independently trained models through optimal channel permutations. Since speech and music encoders learn different feature spaces without shared initialization, their corresponding layers may have mismatched channel orderings. By maximizing cross-correlations between activations, the method finds the optimal mapping between channels, effectively realigning the models' feature spaces before merging. This allows the merged model to leverage complementary information from both domains while maintaining individual task performance.

## Foundational Learning
- **Cross-correlation maximization**: Needed to quantify similarity between feature channels across models. Quick check: Verify correlation matrices show clear patterns indicating meaningful relationships between channels.
- **LinearSumAssignment algorithm**: Required to solve the optimal assignment problem for permutation matrices. Quick check: Confirm permutations maximize total correlation score and are reproducible.
- **Layer-wise activation extraction**: Essential for computing correlations at appropriate points in the model. Quick check: Validate activation shapes match expected dimensions for correlation computation.

## Architecture Onboarding
**Component map**: Input audio -> CNN backbone (HuBERT/MERT) -> Transformer blocks (HuBERT/MERT) -> Pooler -> Task-specific heads

**Critical path**: CNN layers → Transformer attention heads → FFN W2 → Pooler → Classification layers

**Design tradeoffs**: The method trades computational overhead during merging (correlation computation and permutation solving) for improved post-merge performance. Fixed interpolation weights simplify implementation but may not be optimal for all tasks.

**Failure signatures**: Performance collapse similar to naive averaging (Avg Score ~476) indicates incorrect permutation application or correlation computation errors. Speech degradation suggests CNN permutation issues.

**First experiments**: 1) Compute and visualize correlation matrices between models to verify meaningful relationships exist. 2) Apply permutations to validation data and check alignment improvement. 3) Test merged model on a single task to verify basic functionality before full evaluation.

## Open Questions the Paper Calls Out
None

## Limitations
- The method requires calibration data from both domains, adding preprocessing overhead
- Fixed interpolation weights (λ=0.9/0.1) may not be optimal across all tasks and were selected based on validation
- Evaluation is limited to HuBERT and MERT architectures, raising questions about generalizability to other models

## Confidence
High: The correlation-permutation methodology is well-defined, the performance improvements are significant and consistent across multiple benchmarks, and the ablation studies provide clear evidence for which components require permutation.

Medium: The generalizability claims are limited by evaluation on only two specific architectures (HuBERT and MERT), and the optimal interpolation weight may vary with different model pairs.

## Next Checks
1. Verify the exact activation points within attention heads by comparing correlation matrices when using attention scores versus value-weighted outputs
2. Test permutation stability across multiple calibration dataset samples to assess variance
3. Experiment with different interpolation weights (λ) to establish sensitivity and potentially find better combinations