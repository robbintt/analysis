---
ver: rpa2
title: Estimating Semantic Alphabet Size for LLM Uncertainty Quantification
arxiv_id: '2509.14478'
source_url: https://arxiv.org/abs/2509.14478
tags:
- semantic
- entropy
- size
- uncertainty
- estimators
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of estimating semantic entropy
  for large language models (LLMs) in the black-box setting, where repeated sampling
  for uncertainty quantification is computationally expensive. The authors find that
  canonical discrete semantic entropy (DSE) underestimates the true semantic entropy
  for typical sample sizes, as expected from theory.
---

# Estimating Semantic Alphabet Size for LLM Uncertainty Quantification

## Quick Facts
- **arXiv ID**: 2509.14478
- **Source URL**: https://arxiv.org/abs/2509.14478
- **Reference count**: 40
- **Primary result**: Hybrid DSE estimator consistently achieves lowest MSE among explicit discrete semantic entropy estimators across five models and four datasets

## Executive Summary
This paper addresses the problem of semantic entropy estimation for large language models in black-box settings where repeated sampling for uncertainty quantification is computationally expensive. The authors identify that canonical discrete semantic entropy (DSE) systematically underestimates true semantic entropy for typical sample sizes due to unobserved semantic categories. To address this, they propose a modified semantic alphabet size estimator that accounts for these unobserved categories, resulting in more accurate semantic entropy estimation. Their hybrid approach outperforms existing methods in incorrectness detection while maintaining interpretability.

## Method Summary
The authors propose a coverage-adjusted approach to semantic entropy estimation that modifies the canonical DSE formula by incorporating a semantic alphabet size estimator. They develop a hybrid estimator that combines observed semantic categories with a theoretical bound on unobserved categories, derived from Good-Turing frequency estimation. This hybrid estimator is then used to adjust DSE for sample coverage, resulting in more accurate semantic entropy estimates. The method operates in the black-box setting, requiring only input-output pairs without access to model internals.

## Key Results
- Canonical DSE underestimates true semantic entropy for typical sample sizes, as expected from theory
- The hybrid DSE estimator consistently achieves the lowest mean squared error among explicit discrete semantic entropy estimators across five models and four datasets
- Two semantic alphabet size estimators, including the proposed hybrid one, achieve higher latent strength estimates than most other UQ methods in incorrectness detection experiments
- The proposed approach outperforms many top-performing alternatives in LLM incorrectness detection while remaining highly interpretable

## Why This Works (Mechanism)
The mechanism works by addressing the fundamental bias in semantic entropy estimation: when sampling is limited, many semantic categories remain unobserved, leading to systematic underestimation. The hybrid estimator corrects for this by incorporating a theoretical bound on the number of unobserved categories based on Good-Turing frequency estimation. This coverage-adjusted approach provides a more accurate estimate of the true semantic alphabet size, which when used to adjust DSE, yields better-calibrated uncertainty estimates.

## Foundational Learning

**Semantic Entropy**: Measures the uncertainty in the semantic distribution of LLM outputs. Why needed: Forms the basis for quantifying model uncertainty and calibration. Quick check: Compare entropy values across different prompts or model temperatures.

**Good-Turing Frequency Estimation**: A statistical method for estimating the probability of unobserved events based on observed frequencies. Why needed: Provides the theoretical foundation for estimating unobserved semantic categories. Quick check: Verify that the estimated probability mass for unseen events decreases as sample size increases.

**Rao-Blackwellized Monte Carlo Integration (RBMCI)**: A variance reduction technique used in white-box semantic entropy estimation. Why needed: Improves efficiency of white-box SE but not modified to account for unseen categories. Quick check: Compare variance of RBMCI estimates with and without variance reduction.

## Architecture Onboarding

**Component Map**: Input prompts -> LLM black-box sampling -> Output collection -> Semantic clustering -> Alphabet size estimation -> Coverage adjustment -> DSE calculation

**Critical Path**: The core innovation lies in the semantic alphabet size estimation and coverage adjustment steps, which directly impact the accuracy of the final DSE estimate.

**Design Tradeoffs**: The approach trades computational overhead for improved accuracy. While more computationally intensive than canonical DSE, the hybrid estimator provides better-calibrated uncertainty estimates crucial for safety-critical applications.

**Failure Signatures**: Poor clustering quality or extreme class imbalance in semantic categories could lead to biased alphabet size estimates. The method may also struggle with highly diverse or open-ended prompts where semantic clustering becomes ambiguous.

**Three First Experiments**:
1. Compare MSE of canonical DSE vs. hybrid DSE across different sample sizes on a fixed model-dataset pair
2. Ablation study of alphabet size estimators (pure Good-Turing vs. hybrid) on the same tasks
3. Test sensitivity to clustering method by running experiments with different NLI models

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Can the coverage-adjusted approach be extended to the white-box Semantic Entropy (SE) setting to directly adjust for unobserved semantic categories using sequence log-probabilities?
- **Basis in paper**: [explicit] The authors state, "Future work may extend the approach described herein to the white-box setting by directly adjusting SE for unobserved semantic categories."
- **Why unresolved**: The study focuses on black-box DSE. While the authors note that white-box SE also exhibits underestimation bias (similar to plugin DSE), they did not modify the RBMCI used in white-box SE to account for unseen semantic classes.
- **What evidence would resolve it**: Deriving a modified RBMCI formula that incorporates the hybrid alphabet size estimator and demonstrating reduced MSE compared to standard white-box SE.

### Open Question 2
- **Question**: To what extent does the performance of the hybrid DSE estimator depend on the specific semantic clustering strategy employed (e.g., NLI vs. LLM-based)?
- **Basis in paper**: [inferred] The authors acknowledge a limitation in Section 6.2: "We take semantic cluster labels as fixed, without ablating across alternative clustering strategies."
- **Why unresolved**: The accuracy of the alphabet size estimator relies on observed semantic categories. The authors note that high false negative rates in clustering could positively bias estimates, but the interaction between the proposed bias-correction mechanism and clustering errors remains unquantified.
- **What evidence would resolve it**: An ablation study comparing the hybrid DSE performance when using different clustering backbones (e.g., DeBERTa-v3 vs. GPT-4o-mini) on the same model-dataset pairs.

### Open Question 3
- **Question**: Can the hybrid semantic alphabet size estimator effectively quantify the extent of an LLM's unexpressed factual knowledge, distinct from its role in uncertainty quantification?
- **Basis in paper**: [explicit] The authors suggest, "semantic alphabet size estimation... may have broader application... for instance... to estimate the extent of LLMs' unexpressed factual knowledge."
- **Why unresolved**: The paper validates the estimator only for entropy calibration and incorrectness detection. The utility of $\hat{|S|}_{Hybrid}$ as a metric for the volume of unexpressed knowledge (e.g., facts the model knows but does not output) is proposed but not tested.
- **What evidence would resolve it**: Experiments correlating the estimated alphabet size on open-ended prompts with independent benchmarks of LLM factual knowledge bounds.

## Limitations

The proposed semantic alphabet size estimators may have limited generalizability across different LLM architectures and domains, as experiments focus on five specific models and four datasets. The paper does not address potential computational overhead introduced by the modified estimators, particularly for real-time applications where sampling efficiency is critical.

## Confidence

*High Confidence Claims:*
- The theoretical result that canonical DSE underestimates true semantic entropy is well-established
- The hybrid estimator consistently achieves lowest MSE among discrete semantic entropy estimators
- The proposed estimators outperform alternatives in incorrectness detection tasks

*Medium Confidence Claims:*
- The practical significance of improved semantic entropy estimation for real-world applications
- The robustness of results across diverse model architectures and domains
- The computational efficiency of the proposed approach in production settings

## Next Checks

1. Test the proposed semantic alphabet size estimators across a broader range of LLM architectures (including smaller models, different training paradigms, and multimodal systems) to assess generalizability.

2. Conduct ablation studies measuring the computational overhead of the modified estimators compared to canonical DSE, particularly in real-time or resource-constrained scenarios.

3. Evaluate the impact of improved semantic entropy estimation on downstream uncertainty-sensitive tasks beyond incorrectness detection, such as active learning, decision-making under uncertainty, or safety-critical applications.