---
ver: rpa2
title: Feature Extraction and Analysis for GPT-Generated Text
arxiv_id: '2503.13687'
source_url: https://arxiv.org/abs/2503.13687
tags:
- text
- abstracts
- human
- introductions
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a comprehensive analysis of feature extraction
  and classification for distinguishing between human-written and GPT-generated academic
  text. The authors collected English theses and abstracts from Turkish graduate students
  written before 2021, then generated corresponding text using GPT-3.5 for comparison.
---

# Feature Extraction and Analysis for GPT-Generated Text

## Quick Facts
- arXiv ID: 2503.13687
- Source URL: https://arxiv.org/abs/2503.13687
- Authors: A. Selvioğlu; V. Adanova; M. Atagoziev
- Reference count: 28
- Key outcome: Binary classification distinguishing human-written vs GPT-generated academic text using extracted features and ML classifiers

## Executive Summary
This paper presents a comprehensive analysis of feature extraction and classification for distinguishing between human-written and GPT-generated academic text. The authors collected English theses and abstracts from Turkish graduate students written before 2021, then generated corresponding text using GPT-3.5 for comparison. They extracted 11 features including statistical measurements, morphological features, and semantic similarity measures. Classification models achieved high accuracy (98-100%) on separate abstract and introduction datasets, with paragraph size emerging as the most important distinguishing feature.

## Method Summary
The study collected 90 English theses (84 doctoral, 6 master's) from Turkish graduate students across 7 disciplines, with GPT-3.5 generating matching abstracts and introductions from thesis titles. The authors extracted 11 features: paragraph size, sentence length, word size, %words>5 chars, punctuation count, entropy, prefixes, relative clauses, MTLD, paragraph-title similarity, and paragraph-paragraph similarity. Classification used Random Forest with SHAP interpretability and BERT fine-tuning for paragraph-level classification, achieving 98-100% accuracy on separate datasets and 93% on combined data.

## Key Results
- Classification models achieved 98-100% accuracy on separate abstract and introduction datasets
- Paragraph size was identified as the most important distinguishing feature across all models
- GPT-generated text shows longer sentences but shorter paragraphs compared to human authors
- Entropy successfully differentiated human from GPT text despite similar lexical diversity scores

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-generated text exhibits consistent structural patterns distinguishable from human writing through paragraph brevity and sentence elongation.
- Mechanism: The model's autoregressive generation produces normalized output distributions (narrow sentence length curves around 2-3 sentences per paragraph), while human writing shows higher variance in structural choices.
- Core assumption: Structural patterns reflect fundamental differences in generation processes rather than domain-specific conventions.
- Evidence anchors:
  - [abstract]: "GPT producing longer sentences but shorter paragraphs compared to human authors"
  - [section IV.C]: "GPT curves are narrow for both abstracts and introductions, centered around 2-3 sentences per paragraph"
  - [corpus]: Neighbor papers confirm structural features as detection signals, though generalization across domains remains unverified.
- Break condition: Domain-specific writing conventions may override patterns (e.g., sociology texts showed longer human sentences than GPT).

### Mechanism 2
- Claim: Entropy differentiates human from GPT text despite similar lexical diversity scores.
- Mechanism: Humans produce less predictable word distributions (higher entropy) even when vocabulary richness (MTLD) is comparable, suggesting GPT has repetitive structural patterns beneath surface-level diversity.
- Core assumption: Entropy captures distributional properties not reflected in type-token ratios.
- Evidence anchors:
  - [section IV.B]: "Human-written introductions have on average significantly higher entropy... human text is less predictable, with less repetitions"
  - [section IV.B]: "While the lexical diversity of GPT-generated text is similar to human-written text, it has more repetitive or predictable structure"
  - [corpus]: Weak corpus support; neighbor papers focus on embedding-based rather than entropy-based detection.
- Break condition: Text length strongly affects entropy; short texts may not exhibit stable differences.

### Mechanism 3
- Claim: Semantic similarity to prompts (titles) and internal paragraph coherence provide detection signals.
- Mechanism: GPT-generated content stays close to prompt semantics and maintains high inter-paragraph similarity because generation is conditioned on limited context; human writing exhibits more semantic diversification.
- Core assumption: The prompt was the only input to GPT; humans had broader source material.
- Evidence anchors:
  - [section III.C]: "Naturally, we expect the GPT-generated text to be semantically very close to the title"
  - [section IV.F]: "Average paragraph similarity for GPT-generated introductions are fairly high, indicating that the paragraphs contain contextually close contents"
  - [corpus]: No direct corpus confirmation; this mechanism may be prompt-setup specific.
- Break condition: If GPT is given extensive context documents, similarity patterns may converge toward human baselines.

## Foundational Learning

- Concept: **SHAP (SHapley Additive exPlanations)**
  - Why needed here: Required to interpret feature importance in the Random Forest classifier and understand which extracted features drive predictions.
  - Quick check question: Can you explain why paragraph size received the highest SHAP value across all three model configurations?

- Concept: **Measure of Textual Lexical Diversity (MTLD)**
  - Why needed here: Used as one of the 11 features; understanding its resistance to text length effects versus simple Type-Token Ratio is essential.
  - Quick check question: Why might MTLD show similar values for human and GPT text while entropy differs?

- Concept: **Sentence-BERT (SBERT) embeddings**
  - Why needed here: Used to compute semantic similarity features (paragraph-to-title, paragraph-to-paragraph); understanding its optimization for sentence-level tasks versus token-level BERT is necessary.
  - Quick check question: Why was SBERT chosen over standard BERT for computing semantic similarity features?

## Architecture Onboarding

- Component map: Thesis abstracts/introductions → preprocessing (citation removal, paragraph truncation) → feature extraction layer: 11 features computed per document → classification layer: Random Forest with SHAP interpretability / BERT fine-tuning for paragraph-level classification → evaluation layer: t-SNE visualization, accuracy metrics, feature importance analysis

- Critical path:
  1. Text preprocessing (preserve punctuation/structure for style signals)
  2. Feature computation (all 11 features must be extracted before classification)
  3. Model training (Random Forest for feature importance; BERT for end-to-end)
  4. SHAP analysis for interpretability

- Design tradeoffs:
  - Feature-based vs. end-to-end: Feature extraction enables interpretability but may miss latent patterns BERT captures.
  - Combined vs. separate datasets: Abstracts and introductions achieved 98-100% separately but only 93% combined, suggesting domain-specific calibration matters.
  - Text cleaning: Authors deliberately preserved punctuation and stopwords as they encode stylistic information.

- Failure signatures:
  - Short human paragraphs misclassified as GPT-generated (BERT failures)
  - Field-specific conventions overriding general patterns (sociology sentence lengths)
  - Combined dataset accuracy degradation (93% vs. 98-100%)

- First 3 experiments:
  1. Replicate paragraph size analysis on your target domain to verify this feature's discriminative power before building full pipeline.
  2. Test entropy vs. MTLD separately to confirm whether distributional unpredictability is more informative than vocabulary diversity.
  3. Fine-tune BERT on domain-specific paragraphs with explicit length stratification to characterize failure modes for short human texts.

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses on Turkish graduate students' academic writing, limiting generalizability to other domains and cultural contexts
- The counterintuitive finding of longer GPT sentences but shorter paragraphs lacks mechanistic explanation
- Feature extraction methodology relies on morphological analysis techniques with unspecified implementation details

## Confidence

**High Confidence**: Classification accuracy results (98-100% on separate datasets) and paragraph size as most important feature are well-supported by experimental design and SHAP analysis.

**Medium Confidence**: Semantic similarity findings are plausible given generation mechanism but may be specific to prompt-only setup; domain-specific calibration requirement is well-documented but needs field-specific validation.

**Low Confidence**: The longer GPT sentences but shorter paragraphs pattern needs mechanistic explanation; generalizability across different academic disciplines remains unverified; morphological feature extraction methods lack implementation details.

## Next Checks
1. Replicate the entire feature extraction and classification pipeline on academic texts from a different cultural/cognitive context (e.g., North American universities) to verify generalizability of the paragraph size and entropy patterns.

2. Generate GPT text using both title-only prompts and extensive context documents, then compare whether the semantic similarity patterns persist or converge toward human baselines.

3. Systematically analyze the short human paragraphs that BERT misclassifies as GPT-generated to determine whether this represents a fundamental limitation or can be mitigated through length-stratified training.