---
ver: rpa2
title: Instruction-based Time Series Editing
arxiv_id: '2508.01504'
source_url: https://arxiv.org/abs/2508.01504
tags:
- time
- series
- editing
- arxiv
- conditions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Instruction-based Time Series Editing, a
  novel task that enables fine-grained modification of time series using natural language
  instructions. The authors propose InstructTime, the first instruction-based editor,
  which leverages contrastive learning to align time series and text embeddings in
  a shared hyperspherical space, and decodes interpolated embeddings to generate edits
  at varying strengths.
---

# Instruction-based Time Series Editing

## Quick Facts
- **arXiv ID:** 2508.01504
- **Source URL:** https://arxiv.org/abs/2508.01504
- **Reference count:** 40
- **Primary result:** Introduces InstructTime, the first instruction-based time series editor that achieves higher editability and preservability than state-of-the-art methods on synthetic and real-world datasets.

## Executive Summary
This paper introduces Instruction-based Time Series Editing, a novel task that enables fine-grained modification of time series using natural language instructions. The authors propose InstructTime, the first instruction-based editor, which leverages contrastive learning to align time series and text embeddings in a shared hyperspherical space, and decodes interpolated embeddings to generate edits at varying strengths. Experiments on synthetic and real-world datasets show that InstructTime outperforms state-of-the-art methods in both instruction-based and attribute-based settings, achieving higher editability and preservability with controllable editing strength. It also generalizes to unseen instructions through few-shot tuning.

## Method Summary
InstructTime uses a two-stage training process with multi-resolution convolutional encoders and a transformer decoder. The method aligns time series and instruction embeddings in a shared hyperspherical space using contrastive learning, then performs interpolation between embeddings to control editing strength. The architecture consists of parallel 1D-CNNs for time series encoding, frozen SentenceTransformer with MLPs for instruction encoding, and a transformer decoder that generates edited time series from interpolated embeddings. Training alternates between contrastive alignment and reconstruction objectives.

## Key Results
- InstructTime achieves 6-16% higher editability (RaTS) than TEdit on synthetic, Air Quality, and NICU datasets while maintaining better preservability
- Interpolation experiments show smooth monotonic transitions in editability and preservability as editing strength increases from 0.0 to 1.0
- Few-shot tuning with as few as 2 examples enables generalization to unseen instructions, with only 1-2% performance drop compared to full training

## Why This Works (