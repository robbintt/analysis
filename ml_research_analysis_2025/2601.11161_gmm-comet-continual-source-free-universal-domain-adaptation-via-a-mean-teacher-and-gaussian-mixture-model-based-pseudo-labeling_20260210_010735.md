---
ver: rpa2
title: 'GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher
  and Gaussian Mixture Model-Based Pseudo-Labeling'
arxiv_id: '2601.11161'
source_url: https://arxiv.org/abs/2601.11161
tags:
- domain
- adaptation
- source
- target
- teacher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces the first study on continual source-free universal
  domain adaptation (SF-UniDA), where a model must adapt sequentially to multiple
  unlabeled target domains with both domain and category shifts. The proposed method,
  GMM-COMET, combines Gaussian mixture model-based pseudo-labeling with a mean teacher
  framework to improve stability over long adaptation sequences.
---

# GMM-COMET: Continual Source-Free Universal Domain Adaptation via a Mean Teacher and Gaussian Mixture Model-Based Pseudo-Labeling

## Quick Facts
- arXiv ID: 2601.11161
- Source URL: https://arxiv.org/abs/2601.11161
- Reference count: 11
- This work introduces the first study on continual source-free universal domain adaptation (SF-UniDA), where a model must adapt sequentially to multiple unlabeled target domains with both domain and category shifts.

## Executive Summary
This work introduces the first study on continual source-free universal domain adaptation (SF-UniDA), where a model must adapt sequentially to multiple unlabeled target domains with both domain and category shifts. The proposed method, GMM-COMET, combines Gaussian mixture model-based pseudo-labeling with a mean teacher framework to improve stability over long adaptation sequences. It introduces consistency losses to prevent excessive drift from the source model and enhance robustness. Experiments on DomainNet, CIFAR-10-C, and CIFAR-100-C show that GMM-COMET is the only method consistently improving upon the source-only baseline across all category shift scenarios (partial, open, and open-partial set), achieving the best overall performance. It sets a strong baseline for future research in continual SF-UniDA.

## Method Summary
The method builds on a pre-trained ResNet-50 source model and employs a mean teacher framework where a student model is trained with gradient updates while a teacher model is updated via exponential moving average (EMA). For pseudo-labeling, features are projected to 64 dimensions and modeled with a per-class Gaussian Mixture Model (GMM) that tracks means and covariances. OOD detection uses Mahalanobis distance or entropy scores with adaptive thresholds. The student is trained with four losses: contrastive loss (pulling same-class features together), entropy loss (regularizing predictions), source consistency loss (constraining deviation from source model), and teacher consistency loss (constraining deviation from teacher model). Adaptation occurs sequentially across target domains without source data access.

## Key Results
- GMM-COMET is the only method consistently improving upon the source-only baseline across all category shift scenarios (partial, open, and open-partial set)
- Achieves the best overall performance on DomainNet, CIFAR-10-C, and CIFAR-100-C datasets
- Mean teacher stabilization is crucial, with ablation showing significant performance drops when removed
- Consistency losses prevent catastrophic forgetting and model collapse during long adaptation sequences

## Why This Works (Mechanism)

### Mechanism 1
Mean Teacher stabilization mitigates error accumulation during sequential domain shifts. An Exponential Moving Average (EMA) of student weights updates the teacher, smoothing noisy gradient updates. This provides a stable reference for pseudo-labeling, preventing the feedback loop where a student reinforces its own incorrect predictions. Core assumption: The distribution shift occurs at a rate where the EMA (αMT=0.999 or 0.99) is slow enough to retain past knowledge but fast enough to track the domain. Evidence: Ablation shows removing the teacher causes significant performance drop on CIFAR-100-C. Break condition: Highly dynamic shifts where the teacher lags too far behind the student, preventing adaptation.

### Mechanism 2
GMM-based feature modeling enables robust separation of "known" vs. "unknown" classes without source data. The method models the feature space as a Gaussian Mixture Model (GMM), updating class means and covariances online using soft teacher predictions. It uses the Mahalanobis distance or likelihood entropy to detect out-of-distribution (OOD) samples, assigning them a separate "unknown" pseudo-label. Core assumption: Feature clusters for different classes are roughly Gaussian and separable in the reduced 64-dim projection space. Evidence: Claims this method accumulates knowledge over time and supports OOD detection better than direct prediction. Break condition: Severe class imbalance or non-Gaussian feature distributions where the GMM estimate becomes unstable.

### Mechanism 3
Consistency losses act as a regularizer to prevent catastrophic forgetting and model collapse. Two L2 losses constrain the model: one enforces similarity between student and teacher features (Lcon,mt), and another anchors the student to the original source model (Lcon,src). This limits the "drift" allowed during adaptation. Core assumption: The source model's feature extractor remains a valid initialization even after multiple domain shifts. Evidence: Ablation shows these losses are especially beneficial in highly dynamic continual shift scenarios. Break condition: When the domain shift is so large that the source features are no longer relevant, strict consistency would hinder necessary adaptation.

## Foundational Learning

- **Concept: Mean Teacher Framework**
  - **Why needed here:** It is the core architectural scaffold used to generate stable pseudo-labels from unlabeled target data.
  - **Quick check question:** Does the teacher model receive gradient updates directly via backprop? (Answer: No, only via EMA of student weights).

- **Concept: Gaussian Mixture Models (GMM)**
  - **Why needed here:** Used to probabilistically model the feature distribution for OOD detection and pseudo-label assignment.
  - **Quick check question:** In this paper, is the GMM retrained from scratch every batch? (Answer: No, it is updated recursively/online).

- **Concept: Contrastive Learning**
  - **Why needed here:** Used to pull samples of the same pseudo-class together and push others apart, improving the feature clusters for the GMM.
  - **Quick check question:** How are positive pairs formed for the contrastive loss? (Answer: Samples sharing the same pseudo-label OR samples paired with their class's GMM mean).

## Architecture Onboarding

- **Component map:** Source Model (g_s, h_s) -> Student (g, h) -> Teacher (g̃, h̃) -> Projection Head (r(·)) -> GMM Module -> Pseudo-labeling -> Losses (Lc, Le, Lcon,src, Lcon,mt) -> SGD Update -> EMA Update

- **Critical path:**
  1. Inference: Target Batch → Teacher → Projection → GMM scoring → OOD Detection → Pseudo-labels
  2. Update: Calculate Losses (Lc + Le + Lcon) → Update Student via SGD
  3. Sync: Update Teacher weights via EMA

- **Design tradeoffs:**
  - Momentum (αMT): High values (0.999) ensure stability but slow adaptation; low values adapt faster but risk instability
  - Projection Dimension (FDr): 64 dims selected as trade-off between memory efficiency and retaining cluster information
  - OOD Thresholds (τ): Adaptive initialization (first 50 batches) vs. fixed values

- **Failure signatures:**
  - Model Collapse: Accuracy drops to random chance; caused by student drifting too far from teacher (fix: increase λ2, λ3)
  - Stagnation: No improvement over source-only; caused by over-regularization or high rejection ratio (preject) filtering all samples
  - Unknown Class Confusion: "Unknown" samples leak into known classes; likely GMM initialization failure or wrong OOD metric (Mahalanobis vs. Entropy)

- **First 3 experiments:**
  1. Sanity Check (Source-Only vs. GMM-COMET): Run on CIFAR-10-C without adaptation vs. full method to confirm the implementation improves upon the baseline.
  2. Consistency Ablation: Disable Lcon,src and Lcon,mt to reproduce the performance drop shown in Figure 1/2; verifies the loss weights are tuned correctly.
  3. OOD Metric Sensitivity: Swap Mahalanobis distance for Normalized Entropy on CIFAR-10 to verify the paper's claim that Mahalanobis works better for fewer classes.

## Open Questions the Paper Calls Out

### Open Question 1
Can continual SF-UniDA be extended to handle changing category shifts across target domains, where the label space Y_t differs between consecutive domains in the stream? Basis: "We assume that all consecutive target domains share the same label space... We leave the analysis of changing category shifts in addition to (or instead of) the continual domain shifts open for future work." Why unresolved: Current experiments fix the category shift type across all target domains; GMM-based pseudo-labeling assumes static known/unknown class structure. What evidence would resolve it: A method that dynamically detects and adapts to label space changes across domains while maintaining performance on known classes.

### Open Question 2
Can unknown class samples be clustered or classified rather than simply rejected, enabling discovery of semantic structure in target-private classes? Basis: "Another promising direction is to move beyond rejection and enable the classification or clustering of samples from unknown classes, thereby further advancing the scope of SF-UniDA." Why unresolved: Current approach only assigns "unknown" label; no mechanism to discover structure within unknown samples during online adaptation. What evidence would resolve it: Extension of GMM-COMET that outputs cluster assignments for unknown samples with quantitative evaluation of discovered clusters.

### Open Question 3
When should the mean teacher stabilization mechanism be applied versus removed, given its scenario-dependent effectiveness? Basis: Ablation shows mean teacher significantly improves CIFAR-100-C (dynamic shifts) but degrades performance on DomainNet PDA, indicating the EMA can slow adaptation in simpler settings. Why unresolved: No principled criterion exists to determine whether stabilization helps or hinders for a given adaptation scenario. What evidence would resolve it: An adaptive mechanism that monitors shift dynamics and enables/disables mean teacher accordingly, with performance matching or exceeding fixed configurations across all scenarios.

### Open Question 4
How should OOD detection thresholds adapt when domain characteristics change significantly during continual adaptation? Basis: Thresholds τ_l and τ_u are computed from first N_init=50 batches and remain fixed; this may become suboptimal as the model encounters domains with different class distributions or corruption types. Why unresolved: Static thresholds assume representative initialization data, which may not hold across diverse continual shifts. What evidence would resolve it: A dynamic threshold update strategy that outperforms fixed thresholds on long sequences with heterogeneous domain shifts.

## Limitations
- The effectiveness of GMM-based OOD detection relies on Gaussian and separable feature clusters, which may break down under severe class imbalance or non-linear domain shifts
- Method's sensitivity to hyperparameter tuning (λ2, λ3, τ thresholds) across diverse datasets is not extensively explored
- Computational overhead of maintaining GMM statistics across long adaptation sequences is not quantified
- Lack of source training details (epochs, augmentation) limits exact reproducibility

## Confidence
- **High:** The core contribution of being the first to study continual source-free universal domain adaptation is clearly stated and supported. The empirical superiority of GMM-COMET over baselines in multiple category shift scenarios is well-documented with quantitative results.
- **Medium:** The ablation studies supporting the necessity of the mean teacher and consistency losses are convincing, but the robustness of the GMM-based OOD detection across varying data distributions is less thoroughly validated.
- **Low:** The claims about the method's ability to handle highly dynamic shifts (e.g., severity 5 in CIFAR-C) are based on a single experimental setup without extensive stress-testing.

## Next Checks
1. **GMM Robustness Test:** Systematically evaluate the GMM-based OOD detection performance under varying levels of class imbalance and non-Gaussian feature distributions to identify failure conditions.
2. **Hyperparameter Sensitivity Analysis:** Conduct a grid search over the consistency loss weights (λ2, λ3) and OOD thresholds (τ) across multiple datasets to determine the method's robustness to hyperparameter choices.
3. **Computational Overhead Benchmarking:** Measure the runtime and memory consumption of GMM-COMET during long adaptation sequences (e.g., 10+ domains) and compare it to simpler baseline methods to quantify the trade-off between performance and efficiency.