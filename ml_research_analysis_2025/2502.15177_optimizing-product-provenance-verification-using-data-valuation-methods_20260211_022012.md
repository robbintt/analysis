---
ver: rpa2
title: Optimizing Product Provenance Verification using Data Valuation Methods
arxiv_id: '2502.15177'
source_url: https://arxiv.org/abs/2502.15177
tags:
- data
- shapley
- values
- valuation
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of determining and verifying
  product provenance in global supply chains, particularly for commodities like timber
  and agricultural products, where misrepresentation can lead to illegal trade. The
  authors propose a novel deployed data valuation framework using Shapley values to
  enhance the selection and utilization of training data for machine learning models
  applied to Stable Isotope Ratio Analysis (SIRA).
---

# Optimizing Product Provenance Verification using Data Valuation Methods

## Quick Facts
- **arXiv ID:** 2502.15177
- **Source URL:** https://arxiv.org/abs/2502.15177
- **Reference count:** 15
- **Primary result:** Novel data valuation framework using Shapley values improves geographic origin verification accuracy for commodities like timber via strategic training data selection

## Executive Summary
This paper presents a deployed data valuation framework that leverages Shapley values to optimize training data selection for machine learning models in product provenance verification. The system enhances Stable Isotope Ratio Analysis (SIRA) by quantifying the marginal utility of individual training samples, guiding strategic sampling campaigns for more robust and cost-effective monitoring. The framework has been implemented and validated in live enforcement systems, demonstrating tangible improvements in detecting fraudulent trade practices in global supply chains.

## Method Summary
The framework combines Gaussian Process Regression (GPR) with Truncated Monte Carlo Shapley (TMC-Shapley) data valuation to optimize training data selection for geographic origin prediction. The method calculates Shapley values for each training sample, identifying those that contribute positively or negatively to model performance. An iterative data selection process removes low-value samples, improving prediction accuracy (measured by RMSE) while reducing computational costs. The approach supports both forward prediction (location to isotopes) and backward inference (isotopes to location) through Bayesian inversion of the GPR model.

## Key Results
- TMC-Shapley-based removal of low-value samples achieves ~0.80 RMSE reduction compared to ~0.19 for random removal
- Data valuation rankings show high agreement across different model architectures (GPR vs. Random Forest)
- Framework successfully deployed in live provenance verification systems used by enforcement agencies

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Iteratively removing training samples with low or negative Shapley values appears to improve the predictive accuracy (reduce RMSE) of geographic origin models more effectively than random removal.
- **Mechanism**: The system calculates the Truncated Monte Carlo (TMC) Shapley value for each data point, approximating its marginal contribution to model performance. By ranking and removing low-value points, the framework filters redundant or detrimental samples (e.g., outliers or data inconsistent with spatial patterns), leaving a higher-signal training set.
- **Core assumption**: The importance of a data point, as calculated on the full dataset, provides a reliable heuristic for its impact on smaller subsets, and the removal of low-value points does not destroy critical boundary conditions for rare classes.
- **Evidence anchors**:
  - [Abstract]: "By quantifying the marginal utility of individual samples... our method guides strategic, cost-effective, and robust sampling campaigns."
  - [Section 4.3/Table 1]: Shows TMC-Shapley based removal achieves an RMSE reduction of ~0.80 compared to ~0.19 for random removal.
  - [Corpus]: Weak direct support; neighboring papers focus on supply chain resilience and ontologies rather than Shapley-based data valuation.
- **Break condition**: Performance degrades if data points are highly interdependent (e.g., clusters where the value of one point relies on the presence of another), causing static valuations to become stale after sequential removals.

### Mechanism 2
- **Claim**: Gaussian Process Regression (GPR) allows for the inversion of isotope prediction (Forward: Location $\to$ Isotopes) to support probabilistic origin verification (Backward: Isotopes $\to$ Location).
- **Mechanism**: The "Forward" model builds spatial correlation maps (isoscapes) using GPR kernels to predict isotope ratios at unobserved locations. The "Backward" model applies Bayes' rule to this generative model, calculating the posterior probability of a claimed origin given the observed sample chemistry.
- **Core assumption**: Isotope ratios vary smoothly across geography in a way captured by the kernel function, and measurement noise is adequately modeled by the GPR variance term.
- **Evidence anchors**:
  - [Section 3.1]: "For the backward model... we leverage Bayesian inference to reverse the prediction... [providing] a posterior probability map over X."
  - [Corpus]: No direct mechanism in neighbors; focus is on network resilience and product ontologies.
- **Break condition**: The mechanism fails if environmental isotope gradients are non-stationary or discontinuous (e.g., abrupt changes in soil geology) across small distances not captured by the global kernel.

### Mechanism 3
- **Claim**: Data valuation rankings appear robust across different model architectures, suggesting that value is a property of the data distribution rather than the specific learning algorithm.
- **Mechanism**: Experiments compare data value ranks derived from Random Forests versus GPR. Despite different inductive biases, both architectures tend to agree on which points are high-value (informative) vs. low-value (detrimental), suggesting the method identifies noisy or representative samples independent of the model.
- **Core assumption**: The ranking stability implies that a faster, approximate model (like Random Forest) can be used to calculate values for a more complex model (like GPR) without significant loss in selection quality.
- **Evidence anchors**:
  - [Section 4.2]: "Figures 2(d-f)... demonstrate a high degree of agreement between the two models [GPR and Random Forest]."
  - [Corpus]: Neighbors (e.g., "Optimizing Multi-Tier Supply Chain") discuss hybrid models but do not address cross-architectural data valuation.
- **Break condition**: Rankings may diverge significantly if the architectures have fundamentally different capabilities regarding feature interactions (e.g., linear vs. non-linear).

## Foundational Learning

- **Concept**: **Shapley Values (Game Theory)**
  - **Why needed here**: This is the mathematical engine used to assign a "price" or utility to specific data points. Understanding that it averages marginal contributions across all possible subsets is critical to interpreting why a point might have a negative value (harmful to the coalition).
  - **Quick check question**: If a data point adds noise that confuses the model, should its Shapley value be positive or negative?

- **Concept**: **Gaussian Process Regression (GPR)**
  - **Why needed here**: The base predictive engine for "isoscapes." Unlike simple regression, GPR provides uncertainty estimates, which are explicitly used in the Bayesian inversion for provenance checks.
  - **Quick check question**: How does the kernel function in a GPR define the "smoothness" of the predicted isoscape?

- **Concept**: **Isoscapes (Stable Isotope Ratio Analysis)**
  - **Why needed here**: The domain application. You must understand that isotopes (e.g., $\delta^{13}\text{C}$, $\delta^{2}\text{H}$) vary predictably by geography/climate to see why a regression model can trace origin.
  - **Quick check question**: Why would timber from a coastal region have a different isotopic signature than timber from an inland, high-altitude region?

## Architecture Onboarding

- **Component map**: Raw reference sample data (Geolocation + Stable Isotope Ratios) -> Pre-processing (Median Imputation/Listwise Deletion) -> TMC-Shapley Valuation Engine -> Model Core (GPR Forward/Bayesian Backward) -> Iterative Data Selection Decision Logic
- **Critical path**: The TMC-Shapley calculation is the bottleneck. It requires retraining the GPR model for numerous random permutations of the dataset. Optimizing this loop (e.g., via parallelization or efficient sampling) is key to system latency.
- **Design tradeoffs**:
  - Scalability vs. Uncertainty: The authors note Random Forests are more scalable than GPR but lack principled uncertainty quantification.
  - Granularity vs. Robustness: Section 4.6 suggests removing *clusters* of low-value points improves performance more than one-by-one removal, trading fine-grained control for faster convergence.
- **Failure signatures**:
  - Runaway Compute: If the convergence tolerance for TMC-Shapley is set too tight, the valuation step may never complete due to the high cost of GPR retraining.
  - Domain Shift: A model trained on data valued for one geography (e.g., USA) may fail if applied blindly to a new geography (e.g., Europe) without recalculating values, as "value" is context-dependent.
- **First 3 experiments**:
  1. Baseline Validation: Train a GPR isoscape model on the raw dataset and record the baseline RMSE for the Backward (origin prediction) task.
  2. Valuation Impact: Calculate Shapley values, remove the bottom 10% of low-value samples, retrain the GPR, and observe the delta in RMSE.
  3. Architecture Sensitivity: Compute Shapley values using a Random Forest (fast) and use those ranks to select data for a GPR (accurate). Compare performance to using GPR-derived values directly to test the "surrogate valuation" hypothesis.

## Open Questions the Paper Calls Out
- **Open Question 1**: Can the data valuation framework be generalized to other natural resource supply chains beyond timber? The current study validates the framework primarily using timber datasets; it is uncertain if the method performs similarly across commodities with different chemical properties or data scarcity levels.
- **Open Question 2**: How can the framework incorporate cross-modal data to enhance provenance verification? The current implementation relies heavily on SIRA; combining SIRA with distinct data types introduces complexity in calculating unified data valuations.
- **Open Question 3**: What advancements are needed to improve the scalability and robustness of the valuation models? The paper identifies a "pronounced trade-off" between computational feasibility and valuation precision due to the high complexity of Gaussian Process regression and Monte Carlo sampling.

## Limitations
- High computational cost of Shapley value estimation for large datasets
- Sensitivity of rankings to the choice of utility function
- Assumption that single-point valuations remain valid after sequential removals

## Confidence
- **High**: TMC-Shapley-based removal outperforms random removal (RMSE drop ~0.80 vs. ~0.19)
- **Medium**: Shapley rankings are architecture-independent (based on single cross-model comparison)
- **Low**: Scalability to production deployments (computational cost not profiled at large scales)

## Next Checks
1. Profile TMC-Shapley runtime and memory usage on progressively larger datasets (N=500 → 5000 → 50,000) to quantify scalability.
2. Perform k-fold cross-validation of data valuations to test stability of rankings across data subsets.
3. Evaluate degradation of backward (origin) predictions when low-value points are removed, not just RMSE, to ensure enforcement-relevant accuracy is maintained.