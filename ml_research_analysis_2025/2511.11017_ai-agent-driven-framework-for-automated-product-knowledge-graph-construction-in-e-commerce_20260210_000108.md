---
ver: rpa2
title: AI Agent-Driven Framework for Automated Product Knowledge Graph Construction
  in E-Commerce
arxiv_id: '2511.11017'
source_url: https://arxiv.org/abs/2511.11017
tags:
- knowledge
- product
- graph
- ontology
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces an AI agent-driven framework for automating
  product knowledge graph construction in e-commerce, addressing the challenge of
  extracting structured data from unstructured product descriptions. The framework
  uses three LLM-powered agents to iteratively create, refine, and populate a product
  ontology and knowledge graph, eliminating manual schema design and extraction rules.
---

# AI Agent-Driven Framework for Automated Product Knowledge Graph Construction in E-Commerce

## Quick Facts
- **arXiv ID**: 2511.11017
- **Source URL**: https://arxiv.org/abs/2511.11017
- **Reference count**: 21
- **Primary result**: Over 97% property coverage and minimal redundancy in product KG construction from 291 air conditioner descriptions using three LLM-powered agents.

## Executive Summary
This paper introduces an AI agent-driven framework that automates product knowledge graph construction from unstructured e-commerce descriptions. The system eliminates manual schema design by using three LLM-powered agents to iteratively create, refine, and populate a product ontology and knowledge graph. Evaluated on real-world air conditioner descriptions, the framework achieved over 97% property coverage and generated 7,459 RDF triples from 282 products, demonstrating strong scalability and accuracy for structured knowledge extraction in retail environments.

## Method Summary
The framework employs a three-stage pipeline using ChatGPT 4.1 Mini: (1) iterative ontology extraction from ~30 product samples until plateau, (2) zero-shot refinement for generality and consistency, and (3) RDF triple generation per product description. The system produces RDF/Turtle output with domain/range/comment metadata. The approach addresses the challenge of extracting structured data from unstructured product descriptions by leveraging LLM capabilities to automatically construct and populate product ontologies without manual intervention.

## Key Results
- Achieved >97% property coverage across 282 products in the air conditioner dataset
- Generated 7,459 RDF triples from 282 products with minimal redundancy
- Produced a fine-grained ontology with 42 classes and 69 properties
- Demonstrated strong scalability with only 3% RDF parsing failures

## Why This Works (Mechanism)
The framework succeeds by breaking down complex knowledge graph construction into manageable stages handled by specialized agents. The iterative ontology creation captures domain-specific entities and relationships from sample products, while the refinement stage ensures consistency and removes redundancy. The final population stage leverages the refined ontology to systematically extract structured information from individual product descriptions. This staged approach allows LLMs to focus on specific tasks while maintaining coherence across the entire knowledge graph construction process.

## Foundational Learning
- **Ontology Construction**: Understanding how to represent domain knowledge as classes, properties, and relationships is fundamental to knowledge graph systems. This is needed because product descriptions lack inherent structure. Quick check: Can you identify the main entities and their relationships in a sample product description?
- **Iterative Sampling**: Using representative samples to bootstrap knowledge extraction prevents the system from being overwhelmed by full dataset complexity. This is needed because processing all products at once would be inefficient and potentially inconsistent. Quick check: Can you determine when your sample set has captured sufficient domain knowledge?
- **RDF/Turtle Format**: Standardized semantic web format ensures interoperability and enables semantic reasoning. This is needed because raw extracted data must be structured for querying and integration. Quick check: Can you parse and validate RDF triples using an RDF library?
- **Zero-shot Refinement**: Prompting the LLM to improve an existing ontology without examples tests the model's understanding of consistency and generality. This is needed because manual ontology refinement is time-consuming and error-prone. Quick check: Can you formulate prompts that improve ontology structure while maintaining coverage?
- **Property Coverage Metrics**: Measuring how many products contain each property indicates ontology completeness and extraction effectiveness. This is needed because coverage directly impacts the utility of the knowledge graph. Quick check: Can you calculate coverage percentages for each property across your dataset?
- **Redundancy Detection**: Identifying and eliminating duplicate or overlapping concepts improves ontology quality and query efficiency. This is needed because LLM-generated ontologies often contain inconsistencies. Quick check: Can you spot redundant classes or properties in a given ontology?

## Architecture Onboarding

**Component Map**
Ontology Creation Agent -> Ontology Refinement Agent -> KG Population Agent -> RDF Storage

**Critical Path**
The critical path is: Product Sample Selection → Ontology Extraction → Refinement → Triple Generation → Validation. Each stage must complete successfully before the next begins, with RDF parsing failures representing the primary bottleneck.

**Design Tradeoffs**
The framework trades comprehensive manual ontology design for automated generation, accepting potential LLM limitations in exchange for scalability. Using a single LLM model simplifies the system but may miss domain-specific nuances that specialized models or hybrid approaches could capture. The zero-shot refinement approach prioritizes generality over task-specific optimization.

**Failure Signatures**
- Invalid RDF output (3% observed rate) manifests as parsing errors when loading triples
- Ontology explosion occurs when iterative extraction continues beyond plateau detection
- Property coverage gaps indicate incomplete ontology or extraction failures
- Redundancy in the ontology suggests insufficient refinement or inconsistent extraction prompts

**First Experiments**
1. Run ontology extraction on 30-50 sample products and track new elements per iteration to identify the plateau point
2. Validate RDF output parsing success rate across a batch of product descriptions to establish baseline quality
3. Compare ontology coverage metrics before and after refinement to quantify improvement

## Open Questions the Paper Calls Out
None

## Limitations
- Results are based on a single product category (air conditioners) with 291 examples, limiting generalizability
- The 3% RDF parsing failure rate is acknowledged but not fully analyzed for impact
- Manual validation process for ontology quality lacks detailed criteria and inter-rater reliability assessment
- Single LLM model dependency without comparison to alternatives or hybrid approaches

## Confidence
- **High Confidence**: Three-stage agent architecture is clearly defined and RDF output format with metadata is verifiable
- **Medium Confidence**: Coverage metrics and scalability claims are based on single dataset and category
- **Low Confidence**: Generalizability to other categories, optimal prompt formulations, and robustness to varied description formats remain uncertain

## Next Checks
1. Test the framework on at least two additional product categories (e.g., electronics and home goods) with comparable dataset sizes to evaluate cross-domain performance
2. Conduct a comparative evaluation using different LLM models (GPT-4, Claude, open-source alternatives) to determine model dependency
3. Implement systematic error analysis of the 3% RDF parsing failures, categorizing error types and measuring their impact on downstream applications