---
ver: rpa2
title: Time Series Foundation Models for Process Model Forecasting
arxiv_id: '2512.07624'
source_url: https://arxiv.org/abs/2512.07624
tags:
- time
- series
- process
- forecasting
- tsfms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates the application of Time Series Foundation\
  \ Models (TSFMs) to Process Model Forecasting (PMF), a task of predicting the evolution\
  \ of process control-flow structures over time. The authors evaluate zero-shot use\
  \ of three TSFM families\u2014Chronos, MOIRAI, and TimesFM\u2014on directly-follows\
  \ time series derived from real-life event logs, comparing them against traditional\
  \ and specialized forecasting models."
---

# Time Series Foundation Models for Process Model Forecasting

## Quick Facts
- **arXiv ID:** 2512.07624
- **Source URL:** https://arxiv.org/abs/2512.07624
- **Reference count:** 40
- **Primary result:** Zero-shot Time Series Foundation Models (TSFMs) achieve lower forecasting errors than traditional models trained from scratch on process mining data.

## Executive Summary
This paper investigates the application of Time Series Foundation Models (TSFMs) to Process Model Forecasting (PMF), a task of predicting the evolution of process control-flow structures over time. The authors evaluate zero-shot use of three TSFM families—Chronos, MOIRAI, and TimesFM—on directly-follows time series derived from real-life event logs, comparing them against traditional and specialized forecasting models. TSFMs generally achieve lower forecasting errors (MAE and RMSE) than models trained from scratch, indicating effective transfer of temporal knowledge from non-process domains. Fine-tuning via LoRA or full adaptation provides only modest and dataset-dependent gains, so zero-shot use remains a strong default. The study highlights the generalization capability and data efficiency of TSFMs for PMF and offers insights into their adaptation and evaluation in process mining contexts.

## Method Summary
The study evaluates Time Series Foundation Models for Process Model Forecasting by converting event logs into Directly-Follows (DF) time series through daily aggregation and DFG extraction. Four public event logs (BPI2017, BPI2019_1, Sepsis, Hospital Billing) are partitioned into sub-logs, from which DF frequencies are extracted per edge to form univariate time series. TSFMs (Chronos, MOIRAI, TimesFM) are applied in zero-shot, LoRA-based PEFT, and full fine-tuning modes, with 7-day forecast horizons. Models are compared against Naive Seasonal and XGBoost baselines using MAE/RMSE (primary) and Entropic Relevance for process-level conformance. LoRA is configured with rank r=2 and α=4, applied to attention projections; full fine-tuning is also tested but often underperforms due to overfitting.

## Key Results
- Zero-shot TSFMs outperform traditional and specialized models trained from scratch on DF time series, achieving 15-25% MAE reduction on moderate stationarity logs.
- LoRA-based fine-tuning provides only modest, dataset-dependent gains; full fine-tuning often degrades performance due to overfitting on small/complex PMF datasets.
- Process-level evaluation (Entropic Relevance) reveals that acceptable MAE/RMSE can coexist with poor process conformance, indicating point-wise accuracy doesn't guarantee meaningful process model forecasting.

## Why This Works (Mechanism)

### Mechanism 1: Zero-Shot Temporal Transfer from Heterogeneous Pre-Training
TSFMs pre-trained on generic time series corpora can forecast process dynamics (DF relations) without task-specific training, outperforming models trained from scratch. Foundation models trained on 100B+ observations across diverse domains learn generalizable temporal pattern recognition—seasonality, trend, drift, transitions—that transfers to out-of-domain modalities. DF time series, despite sparsity and non-Gaussianity, share structural temporal properties with pre-training data.

### Mechanism 2: Multi-Pattern Recognition Within Heterogeneous Corpora
TSFMs handle diverse time series characteristics within a single event log better than traditional models requiring explicit configuration. Exposure to heterogeneous pre-training data builds internal pattern-matching capabilities. The model implicitly classifies each DF series by its characteristics (seasonality, trend, shifting) and applies appropriate forecasting strategies without manual tuning.

### Mechanism 3: Constrained Adaptation via Low-Rank Reparameterization
LoRA-based fine-tuning provides modest, dataset-dependent gains while full fine-tuning risks catastrophic overfitting on small PMF datasets. LoRA adds trainable low-rank matrices to self-attention projections while freezing pre-trained weights. With r=2≪min(d,k), updates are constrained to a low-dimensional subspace, limiting capacity for overfitting.

## Foundational Learning

- **Concept: Directly-Follows (DF) Relations and Time-Indexed DFGs**
  - Why needed here: The entire PMF formulation represents process evolution as multivariate time series where each DF edge is a variable with frequency evolving over time windows.
  - Quick check question: Given an event log partitioned into daily windows, how many time series variables would a DFG with 50 unique edges produce?

- **Concept: Foundation Model Zero-Shot Transfer**
  - Why needed here: The paper's central contribution is demonstrating zero-shot TSFM effectiveness for PMF. Understanding why pre-training on non-process data transfers requires grasping the foundation model paradigm.
  - Quick check question: What types of temporal patterns might a model learn from Wikipedia page view data that would transfer to process activity frequency forecasting?

- **Concept: Parameter-Efficient Fine-Tuning (LoRA)**
  - Why needed here: The paper evaluates LoRA as the primary adaptation strategy. Understanding the reparameterization W = W₀ + (α/r)BA—and why low rank prevents overfitting—is necessary to interpret results.
  - Quick check question: With r=2 and scaling factor α=4, how many trainable parameters does LoRA add to a 768×768 attention weight matrix?

## Architecture Onboarding

- **Component map:**
  - Event log -> Time partitioning (ΔT=1 day) -> Sequence of sub-logs
  - Sub-logs -> Time-indexed DFGs -> DF frequency time series per edge
  - DF series (univariate) -> Pre-trained Transformer (Chronos/MOIRAI/TimesFM) with patch-based encoding
  - Forecasted DF frequencies -> DFG reassembly -> Forecasted process model
  - Evaluation: MAE/RMSE + Entropic Relevance (process-level conformance)

- **Critical path:**
  1. Preprocess event log: aggregate events by daily windows, extract DF relations
  2. Convert each DF edge to univariate time series
  3. Configure TSFM: expanding window context (all prior data) for inference; 48-day sliding window for training
  4. Generate forecasts: 7-step ahead, sample quantiles (0.1, 0.5, 0.9), take median as point prediction
  5. Reassemble forecasted frequencies into DFG for process-level evaluation

- **Design tradeoffs:**
  - Zero-shot vs. fine-tuning: Zero-shot is default; fine-tuning gains are modest and unreliable on small/complex logs
  - Univariate vs. multivariate inference: Paper uses univariate throughout; prior benchmarks show multivariate doesn't help for PMF
  - Model size vs. inference cost: Larger models perform better but newer small models achieve competitive results through architectural improvements
  - LoRA rank selection: r=2 with α=4 balances adaptation capacity and overfitting risk

- **Failure signatures:**
  - Catastrophic overfitting: Full fine-tuning causing MAE to nearly double
  - Process-level mismatch: Low fitting ratios (<20%) with high Entropic Relevance (>25) despite acceptable MAE
  - Weak temporal signal: Stationarity <0.05 combined with non-Gaussianity >0.5 suggests time series lacks learnable structure
  - Small model failure: Chronos-Bolt-tiny and MOIRAI-1.1-small sometimes underperform Naive Seasonal baseline

- **First 3 experiments:**
  1. Establish zero-shot baseline: Run Chronos-2, MOIRAI-2.0, and TimesFM-2.5 zero-shot on DF time series with 7-day horizon. Compare MAE/RMSE against Naive Seasonal and XGBoost.
  2. Model iteration ablation: Compare older vs. newer model variants holding parameter size roughly constant. Verify architectural improvements matter more than raw parameter count.
  3. LoRA adaptation test: Apply LoRA (r=2, α=4) to Chronos-Bolt-small on largest log. Train 3 epochs with 60/20/20 split. Compare against zero-shot and full fine-tuning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can alternative parameter-efficient fine-tuning (PEFT) methods provide more consistent performance gains than LoRA for PMF?
- Basis in paper: The Discussion states that "Evaluating additional TSFMs and alternative PEFT approaches could reveal better adaptation strategies," noting that LoRA gains were often marginal.
- Why unresolved: The study was limited by resource constraints and only tested LoRA, which frequently failed to improve upon zero-shot baselines due to overfitting risks.
- What evidence would resolve it: A comparative study benchmarking other PEFT techniques against LoRA on the same DF time series.

### Open Question 2
- Question: How do specific architectural choices and pretraining corpora influence TSFM performance on process-specific tasks?
- Basis in paper: The Discussion identifies the need for "deeper investigation into how architectural choices and pretraining corpora affect performance on process-specific tasks."
- Why unresolved: While the study compares families (Chronos, MOIRAI, TimesFM), it does not isolate whether performance stems from model size, architecture, or the nature of the pretraining data.
- What evidence would resolve it: Ablation studies or controlled experiments varying pretraining datasets while keeping architecture constant.

### Open Question 3
- Question: Do TSFMs maintain their zero-shot advantage when applied to a larger, more diverse collection of high-quality event logs?
- Basis in paper: The Discussion notes that the study is limited to four logs and that "expanding this to a larger, more diverse collection of high-quality logs would strengthen and generalize our findings."
- Why unresolved: The heterogeneity of DF time series characteristics varies significantly; it is unclear if the results hold for processes with different structural complexities.
- What evidence would resolve it: Evaluation of the proposed TSFM pipeline on a standardized benchmark containing dozens of diverse real-world event logs.

### Open Question 4
- Question: Can richer structural representations improve forecasting accuracy beyond univariate Directly-Follows (DF) time series?
- Basis in paper: The Conclusion suggests that future work "should explore richer structural representations," while the Methodology section notes DF series suffer from sparsity and fail to capture interdependencies.
- Why unresolved: The current approach converts complex graph structures into univariate series, potentially losing relational context that multivariate models or graph-based approaches could utilize.
- What evidence would resolve it: Developing a framework that encodes process topology or concurrency directly into the TSFM input and comparing results against the DF baseline.

## Limitations

- TSFM zero-shot transfer effectiveness depends heavily on temporal pattern similarity between pre-training corpora and process mining data. Degraded performance occurs on highly non-stationary, non-Gaussian DF time series.
- Model adaptation via LoRA provides only modest, dataset-dependent gains. Full fine-tuning risks catastrophic overfitting on small/complex PMF datasets.
- Process-level evaluation reveals that acceptable MAE/RMSE can coexist with poor process conformance, indicating point-wise accuracy doesn't guarantee meaningful process model forecasting.

## Confidence

- **High confidence**: TSFMs outperform traditional models trained from scratch on DF time series (MAE/RMSE reductions of 15-25% on moderate stationarity logs).
- **Medium confidence**: LoRA-based adaptation provides modest gains but is dataset-dependent; full fine-tuning often degrades performance due to overfitting.
- **Low confidence**: Zero-shot TSFMs will consistently transfer temporal knowledge to all process mining contexts, especially highly non-stationary or non-Gaussian DF time series.

## Next Checks

1. **Stationarity sensitivity test**: Systematically evaluate TSFM performance across DF time series with varying stationarity (0.001-0.3) and non-Gaussianity (0.2-0.6) to quantify transfer limits and identify failure thresholds.
2. **LoRA rank ablation study**: Compare LoRA adaptation with r=1, 2, 4, 8 on multiple PMF datasets to determine optimal rank selection and identify overfitting patterns.
3. **Multivariate inference validation**: Implement and benchmark multivariate TSFM forecasting on PMF datasets to verify whether univariate-only approach is suboptimal for logs with correlated DF series.