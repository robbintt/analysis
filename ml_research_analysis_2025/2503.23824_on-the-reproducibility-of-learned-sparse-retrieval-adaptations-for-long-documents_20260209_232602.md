---
ver: rpa2
title: On the Reproducibility of Learned Sparse Retrieval Adaptations for Long Documents
arxiv_id: '2503.23824'
source_url: https://arxiv.org/abs/2503.23824
tags:
- document
- terms
- retrieval
- segment
- segments
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines Learned Sparse Retrieval (LSR) for long document
  retrieval by reproducing ExactSDM and SoftSDM methods. The experiments confirm that
  the first segment dominates retrieval performance and that Score-Max remains robust
  across varying document lengths.
---

# On the Reproducibility of Learned Sparse Retrieval Adaptations for Long Documents

## Quick Facts
- **arXiv ID**: 2503.23824
- **Source URL**: https://arxiv.org/abs/2503.23824
- **Reference count**: 23
- **Primary result**: ExactSDM and SoftSDM improve LSR performance for long documents, with Score-Max aggregation remaining robust across varying document lengths.

## Executive Summary
This study reproduces and analyzes ExactSDM and SoftSDM methods for Learned Sparse Retrieval (LSR) of long documents. The experiments validate that Score-Max aggregation maintains retrieval effectiveness as document segment count increases, while representation aggregation degrades. Both ExactSDM and SoftSDM improve LSR performance through proximity-based matching, with ExactSDM emerging as the most effective method for long documents. The analysis reveals that unique and global terms in segments significantly impact scoring, while intersection terms are less influential. The findings support the robustness of Score-Max and SDM methods across datasets and document variations, validating their effectiveness for scalable long-document retrieval.

## Method Summary
The paper adapts ExactSDM and SoftSDM for long document retrieval using Learned Sparse Retrieval with a frozen DistilBERT encoder. Documents are split into 512-token segments, and segment scores are aggregated using Score-Max or SDM variants. ExactSDM constrains document terms to self-translation without expansion, while SoftSDM allows expansion. Hyperparameters (n-gram size n, proximity window prx) are fine-tuned on the MSDoc training set. The evaluation uses MSMARCO Document Ranking (MSDoc) and TREC Robust04 datasets, measuring MRR@10 and nDCG@10 respectively.

## Key Results
- Score-Max aggregation consistently outperforms representation aggregation (Rep-max, Rep-sum, Rep-mean) across varying document lengths.
- ExactSDM shows stronger results for long documents (3+ segments) compared to SoftSDM, though hyperparameter tuning is critical.
- The first segment dominates document relevance, with unique terms contributing ~30% and global terms ~40% of the score.
- Both ExactSDM and SoftSDM improve LSR performance through proximity-based matching, with improvements of 1-2% on Robust04.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Score-Max aggregation maintains retrieval effectiveness as document segment count increases, while representation aggregation degrades.
- **Mechanism**: Score-Max evaluates each segment independently and takes the maximum score across segments, avoiding noise accumulation from aggregating sparse representations. Representation aggregation combines high-dimensional sparse vectors, where adding segments introduces conflicting term weights and dilutes discriminative signals.
- **Core assumption**: The most relevant segment exists and can be scored independently; query-relevant signals are localized rather than uniformly distributed across a long document.
- **Evidence anchors**: [abstract] "Score-Max consistently outperforms other methods, maintaining robustness as segment count increases"; [section 4.1] "Unlike Rep-max, which prioritizes global term importance, Score-max evaluates each segment independently, thereby reducing noise accumulation and enhancing robustness"
- **Break condition**: If query relevance requires synthesizing information across multiple non-adjacent segments (e.g., multi-hop reasoning), Score-Max will fail since it ignores cross-segment dependencies.

### Mechanism 2
- **Claim**: ExactSDM and SoftSDM improve LSR performance by incorporating proximity-based matching (n-grams and term proximity) beyond individual term matching.
- **Mechanism**: Standard LSR scores via dot product of sparse query and document vectors, treating terms independently. SDM variants extend this with three potential functions: (1) individual term matching (ψT), (2) exact n-gram/phrase matching (ψO), and (3) proximity matching within a window (ψU).
- **Core assumption**: Query terms exhibit sequential dependencies; phrases and proximate term co-occurrences signal relevance more strongly than isolated term matches.
- **Evidence anchors**: [abstract] "ExactSDM and SoftSDM improve LSR performance through proximity-based matching, with ExactSDM showing stronger results for long documents"; [section 4.1] "both SDM variants achieve higher MRR@10, with improvements of approximately 1% on MSDoc Document"
- **Break condition**: If hyperparameters (n-gram size n, proximity window prx) are poorly tuned for the target dataset, SDM methods may underperform baseline Score-Max.

### Mechanism 3
- **Claim**: The first segment of a long document disproportionately determines relevance scoring, driven by unique and global terms rather than intersection terms.
- **Mechanism**: Analysis reveals three term categories in the first segment: (1) Unique terms (exclusive to segment 1), (2) Intersection terms (shared with one other segment), and (3) Global terms (present across multiple segments). Unique terms contribute ~30% and global terms ~40% of the first segment's score, while intersection terms are less impactful.
- **Core assumption**: Document authors place salient information early; unique terms in segment 1 are discriminative rather than noise.
- **Evidence anchors**: [abstract] "The first segment dominates document relevance, with unique and global terms playing critical roles in scoring"; [section 4.3] Figure 2d shows "unique terms in the first segment significantly influence the document-query score, accounting for approximately 30%"
- **Break condition**: If relevant information is concentrated in later segments (e.g., conclusion, appendix, or inverted-pyramid violations), first-segment-focused retrieval will miss it.

## Foundational Learning

- **Concept**: Learned Sparse Retrieval (LSR) / Splade architecture
  - **Why needed here**: This paper adapts LSR for long documents; understanding how Splade generates sparse representations via MLM head and log-projection is prerequisite.
  - **Quick check question**: Can you explain why LSR produces vocabulary-aligned sparse vectors (|V| ≈ 30k dimensions) and how this enables inverted indexing?

- **Concept**: Sequential Dependence Model (SDM) from traditional IR
  - **Why needed here**: ExactSDM and SoftSDM adapt SDM's three-term-dependency functions (individual, ordered, unordered) to neural sparse representations.
  - **Quick check question**: What are the three potential functions in SDM, and how do they differ from bag-of-words matching?

- **Concept**: Segment aggregation strategies (score vs. representation)
  - **Why needed here**: The paper's central comparison is between score aggregation (Score-Max) and representation aggregation (Rep-max, Rep-sum, Rep-mean) for handling documents exceeding 512 tokens.
  - **Quick check question**: Why does summing sparse segment representations risk favoring longer documents regardless of relevance density?

## Architecture Onboarding

- **Component map**: DistilBERT encoder -> MLM head -> sparse projection -> segmentation (512 tokens) -> aggregation (Score-Max/SDM) -> inverted index -> top-200 re-ranking
- **Critical path**: Pre-encode all document segments to sparse vectors -> retrieve top-10K segments via inverted index -> aggregate segment scores to document scores (Score-Max or SDM variant) -> re-rank top-200 documents with SDM fine-tuned parameters
- **Design tradeoffs**: Score-Max is simple and robust but ignores cross-segment signals; ExactSDM is best for long documents but requires hyperparameter tuning; SoftSDM is better for short/medium documents but introduces noise for longer documents
- **Failure signatures**: Score-Max plateaus after 4-5 segments on MSDoc; SoftSDM underperforms on Robust04 by ~2% vs. ExactSDM; representation aggregation catastrophically fails as segments increase
- **First 3 experiments**:
  1. Reproduce baseline Score-Max on MSDoc Dev: Encode segments, aggregate via max-score, measure MRR@10. Expect ~36.6-36.8 across segment counts.
  2. Hyperparameter sweep for ExactSDM: Test n ∈ {2, 5} and prx ∈ {8, 10} on Robust04. Verify Table 4 trends: SoftSDM benefits from larger windows, ExactSDM is more stable.
  3. Ablation on document length: Split queries by relevant document segment count (short ≤2, long ≥3). Confirm ExactSDM outperforms SoftSDM on long documents (Table 6: 41.62 vs. 41.35 at 5 segments).

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What specific hyperparameter tuning strategies are required to improve ExactSDM performance on out-of-domain datasets like Robust04?
- **Basis in paper**: [explicit] Section 4.1 states that while SoftSDM gained from tuning (n-grams/proximity), the authors "could not replicate similar gains for ExactSDM, highlighting the need for further research in this area."
- **Why unresolved**: The paper demonstrates that unlike SoftSDM, ExactSDM does not respond intuitively to increased window sizes on unseen data, and the authors did not identify a configuration that bridges this performance gap.
- **What evidence would resolve it**: A systematic ablation study showing a specific configuration of n-grams and proximity windows that yields statistically significant improvements for ExactSDM on the Robust04 dataset.

### Open Question 2
- **Question**: Can the retrieval effectiveness be further improved by explicitly modeling the distinct roles of "unique" versus "global" terms within the first segment?
- **Basis in paper**: [explicit] Section 5 concludes by highlighting "the importance of unique and global terms, suggesting the exploration of their full potential."
- **Why unresolved**: The analysis (Section 4.3) identifies that unique (30%) and global (40%) terms drive the scoring, but the current SDM adaptations treat these term types uniformly rather than leveraging their specific statistical contributions.
- **What evidence would resolve it**: A modified scoring function that applies differential weights to unique and global terms in the first segment, resulting in higher MRR@10 or nDCG@10 compared to the current uniform approach.

### Open Question 3
- **Question**: What causes the consistent performance degradation of SoftSDM on the Robust04 dataset compared to the original reported results?
- **Basis in paper**: [inferred] Section 4.1 notes "minor discrepancies of around 2% in the SoftSDM results on the Robust04 experiments" which, despite validating overall trends, suggest an unstated instability or sensitivity in the model when applied to this specific zero-shot scenario.
- **Why unresolved**: While the authors verified the code and hyperparameters, the reproducibility gap persisted specifically for SoftSDM on Robust04, implying an unknown variable—such as random seed sensitivity or minor environment differences—affects this specific configuration.
- **What evidence would resolve it**: A variance analysis across multiple runs with different seeds on Robust04 to determine if the 2% drop is statistically significant or merely an artifact of initialization.

## Limitations

- **Implementation fragility**: The study relies on a frozen repository and HuggingFace checkpoint with documented runtime errors and unclear hyperparameter settings, creating potential reproducibility gaps.
- **Scope of generalization**: Results are validated on only two datasets (MSDoc and Robust04) with a single LSR architecture, limiting claims about broader applicability.
- **Hyperparameter sensitivity**: The advantage of ExactSDM over SoftSDM depends critically on hyperparameter tuning, making the superiority claim configuration-dependent rather than architectural.

## Confidence

- **High confidence**: Score-Max aggregation maintains robustness across varying segment counts, and first-segment dominance is empirically observed.
- **Medium confidence**: ExactSDM shows stronger results for long documents than SoftSDM, though this advantage is hyperparameter-dependent.
- **Low confidence**: The mechanism explaining why unique and global terms dominate first-segment scoring is speculative correlation without causal evidence.

## Next Checks

1. **Hyperparameter robustness test**: Systematically vary n ∈ {2, 3, 5} and prx ∈ {6, 8, 10} on both MSDoc and Robust04 to determine if ExactSDM's advantage persists across the full parameter space.

2. **Cross-domain generalization**: Apply the same methodology to another long-document dataset (e.g., TREC-COVID or GOV2) to verify whether first-segment dominance and Score-Max robustness generalize beyond the original two datasets.

3. **Alternative segmentation strategy**: Implement hierarchical segmentation (e.g., paragraph-level within 512-token chunks) and compare Score-Max performance against flat segmentation to test whether observed patterns hold with better document structure preservation.