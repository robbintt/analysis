---
ver: rpa2
title: LLM Driven Processes to Foster Explainable AI
arxiv_id: '2511.07086'
source_url: https://arxiv.org/abs/2511.07086
tags:
- reasoning
- system
- vester
- sensitivity
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper presents a modular, explainable LLM-agent pipeline\
  \ that externalizes reasoning into auditable artifacts for decision support. The\
  \ system implements three structured frameworks\u2014Vester\u2019s Sensitivity Analysis,\
  \ normal-form games, and sequential games\u2014with swappable LLM components paired\
  \ with deterministic analyzers."
---

# LLM Driven Processes to Foster Explainable AI

## Quick Facts
- arXiv ID: 2511.07086
- Source URL: https://arxiv.org/abs/2511.07086
- Authors: Marcel Pehlke; Marc Jansen
- Reference count: 24
- Primary result: Modular LLM-agent pipeline externalizes reasoning into auditable artifacts, achieving 55.5% factor alignment and 57% role agreement in logistics case, with 92.97/100 quality score via LLM judge

## Executive Summary
This paper presents a modular, explainable LLM-agent pipeline that externalizes reasoning into auditable artifacts for decision support. The system implements three structured frameworks—Vester's Sensitivity Analysis, normal-form games, and sequential games—with swappable LLM components paired with deterministic analyzers. In a real-world logistics case (100 runs), the pipeline achieved 55.5% factor alignment with human baselines overall (62.9% on core factors) and 57% role agreement. An LLM judge scored pipeline runs at 92.97/100, matching human baseline quality.

The pipeline reliably reproduced structured decision-making processes, providing traceable reasoning rather than opaque outputs, and demonstrated policy-relevant insights when applied to Canada's housing crisis without prior knowledge of specific measures.

## Method Summary
The authors developed a modular LLM-agent pipeline architecture where reasoning processes are externalized into auditable artifacts. The system implements three structured frameworks: Vester's Sensitivity Analysis for factor importance identification, normal-form games for simultaneous strategic interaction, and sequential games for turn-based decision processes. Each framework consists of swappable LLM components (prompting, planning, execution) paired with deterministic analyzers that validate outputs. The pipeline processes structured inputs through multiple reasoning stages, generating intermediate artifacts that can be inspected for explainability. In the logistics case study, 100 pipeline runs were compared against human-generated baselines using both automated LLM judging and factor alignment metrics.

## Key Results
- Vester pipeline achieved 55.5% factor alignment with human baselines overall, rising to 62.9% on core factors
- Role agreement reached 57% in the logistics case study
- LLM judge scored pipeline runs at 92.97/100, matching human baseline quality
- Successfully applied to Canada's housing crisis policy analysis without prior domain knowledge

## Why This Works (Mechanism)
The pipeline's effectiveness stems from externalizing reasoning through structured frameworks that break down complex decision-making into verifiable stages. By implementing established decision analysis methods (Vester, game theory) as deterministic pipelines with LLM components, the system constrains outputs to follow logical patterns while maintaining flexibility in problem-solving approaches. The modular design allows swapping components without breaking the overall process, and the deterministic analyzers provide quality control by validating intermediate outputs against logical constraints. This architecture transforms LLM reasoning from a black box into a traceable process where each decision point can be audited.

## Foundational Learning
**Vester Sensitivity Analysis**: A systematic method for identifying critical factors in complex systems; needed for understanding how the pipeline identifies key decision variables, quick check by verifying factor importance rankings match established methods.

**Normal-form games**: Strategic interaction models where players choose actions simultaneously; needed for understanding simultaneous decision frameworks, quick check by confirming payoff matrix construction follows game theory principles.

**Sequential games**: Turn-based decision processes with perfect or imperfect information; needed for understanding multi-stage reasoning pipelines, quick check by verifying backward induction or forward-looking reasoning.

**LLM judge methodology**: Using LLMs to evaluate output quality against baselines; needed for understanding automated quality assessment, quick check by comparing judge scores across different evaluation criteria.

**Modular pipeline architecture**: Design pattern allowing component swapping without system failure; needed for understanding flexibility and maintenance, quick check by successfully replacing one LLM component with another model.

**Deterministic analyzers**: Rule-based validation systems that verify LLM outputs; needed for understanding quality control mechanisms, quick check by confirming analyzers catch logical inconsistencies in intermediate outputs.

## Architecture Onboarding

**Component Map**: Input -> LLM Prompt Generator -> LLM Planner -> LLM Executor -> Deterministic Analyzer -> Output Artifact -> LLM Judge

**Critical Path**: The LLM Prompt Generator → LLM Executor → Deterministic Analyzer sequence is critical, as failures in execution or validation halt the pipeline. The LLM Judge provides final quality assessment but doesn't affect the core reasoning process.

**Design Tradeoffs**: The system trades raw LLM performance for explainability by constraining outputs through structured frameworks and validation steps. This reduces the risk of hallucination but may miss creative solutions that fall outside predefined logical structures. The modular design enables flexibility but introduces complexity in component coordination.

**Failure Signatures**: Common failures include prompt misalignment (LLM generates off-topic content), logical inconsistencies (deterministic analyzers flag contradictions), and quality drops (LLM judge scores below threshold). Early detection occurs when deterministic analyzers reject intermediate outputs, allowing rapid iteration on problematic components.

**First 3 Experiments**:
1. Replace the LLM Executor in the Vester pipeline with a different model family (e.g., Claude instead of GPT) while keeping all other components constant
2. Remove the deterministic analyzer from one pipeline run to observe quality degradation and identify which validation steps are most critical
3. Apply the sequential game framework to a new domain (e.g., healthcare treatment planning) to test generalizability beyond logistics

## Open Questions the Paper Calls Out
None

## Limitations
- Single-case validation in logistics constrains generalizability to other domains
- LLM judge-based quality assessment lacks direct human validation, raising questions about score reliability
- 55.5% factor alignment and 57% role agreement leave substantial unexplained variance
- Modular architecture flexibility demonstrated but not rigorously tested across different model families or sizes

## Confidence
- High: The pipeline successfully implements structured decision-making frameworks with traceable reasoning artifacts
- Medium: The quality assessment via LLM judge is internally consistent but not externally validated
- Medium: The logistics case study demonstrates feasibility but limited domain coverage

## Next Checks
1. Direct human evaluation of pipeline outputs across multiple domains to validate the LLM judge's scoring
2. Cross-model testing with different LLM architectures to assess performance stability when swapping components
3. Expanded case studies in diverse domains (healthcare, finance, policy) to evaluate generalizability beyond logistics