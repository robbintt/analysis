---
ver: rpa2
title: 'From Personal to Collective: On the Role of Local and Global Memory in LLM
  Personalization'
arxiv_id: '2509.23767'
source_url: https://arxiv.org/abs/2509.23767
tags:
- memory
- global
- logo
- user
- users
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "LoGo addresses two personalization challenges\u2014cold-start\
  \ and biasing\u2014by combining user-specific local memory with evolving global\
  \ memory that captures collective user trends. A mediator module reconciles conflicts\
  \ between local and global signals."
---

# From Personal to Collective: On the Role of Local and Global Memory in LLM Personalization

## Quick Facts
- arXiv ID: 2509.23767
- Source URL: https://arxiv.org/abs/2509.23767
- Reference count: 15
- LoGo improves cold-start prediction accuracy by up to 18.05% and enhances output diversity for active users

## Executive Summary
LoGo addresses two key challenges in LLM personalization: cold-start scenarios where limited user data exists, and biasing where outputs are overly tailored to specific users. The framework combines user-specific local memory with evolving global memory that captures collective user trends, mediated by a reconciliation module. Through experiments on five benchmarks, LoGo demonstrates significant improvements in cold-start performance while maintaining or enhancing output diversity for established users.

## Method Summary
LoGo implements a dual-memory architecture where user interactions are stored in both local and global memory components. The local memory maintains user-specific preferences and patterns, while the global memory aggregates collective knowledge across all users. A mediator module dynamically balances these two memory sources, resolving conflicts between individual and collective preferences. During inference, the system retrieves relevant information from both memory types and synthesizes them to generate personalized outputs that avoid overfitting to individual patterns while benefiting from collective insights.

## Key Results
- Cold-start user prediction accuracy improved by up to 18.05% compared to baseline methods
- Enhanced output diversity for active users, preventing excessive personalization bias
- Demonstrated effectiveness across five different benchmark datasets

## Why This Works (Mechanism)
LoGo works by addressing the fundamental tension between individual personalization and collective knowledge in LLM systems. The local memory provides the specificity needed for accurate personalization, while the global memory offers robustness through statistical patterns learned from many users. The mediator module serves as a dynamic arbitrator, determining when to prioritize individual preferences versus collective wisdom based on factors like data availability and confidence levels. This dual-memory approach prevents the system from becoming either too generic (by ignoring individual signals) or too narrow (by overfitting to limited user data).

## Foundational Learning
- **Cold-start personalization**: Why needed - Users have limited interaction history initially; Quick check - Compare performance on users with <10 interactions vs >100 interactions
- **Memory-based personalization**: Why needed - Traditional fine-tuning is computationally expensive for individual users; Quick check - Measure inference time and memory overhead per user
- **Collective knowledge aggregation**: Why needed - Individual data points are noisy and sparse; Quick check - Analyze diversity metrics across user cohorts
- **Mediator design**: Why needed - Direct combination of local and global signals can create conflicts; Quick check - Test with synthetic conflict scenarios
- **Dual-memory reconciliation**: Why needed - Balancing specificity vs. generalizability is critical for practical deployment; Quick check - Perform ablation studies removing each memory component

## Architecture Onboarding

**Component Map**: User Input -> Local Memory Retrieval -> Global Memory Retrieval -> Mediator -> LLM Output

**Critical Path**: The inference pipeline flows from user input through both memory retrievals, then to the mediator for conflict resolution, before final generation by the LLM. The mediator represents the critical decision point where performance can be significantly impacted.

**Design Tradeoffs**: The system trades increased memory overhead for improved personalization quality and faster adaptation. While maintaining separate memory stores adds complexity, it enables more nuanced personalization than monolithic approaches. The mediator introduces additional computational overhead but provides crucial balance between personalization and generalization.

**Failure Signatures**: Over-reliance on global memory manifests as generic outputs that ignore user preferences. Excessive local memory usage produces outputs that lack broader context and may be brittle to user behavior changes. Mediator failures typically result in oscillating or inconsistent personalization as it swings between local and global signals.

**First 3 Experiments**: 
1. Baseline comparison with local-only and global-only memory configurations
2. Mediator sensitivity analysis varying the weighting parameters between memory sources
3. Cold-start performance evaluation across different user activity levels

## Open Questions the Paper Calls Out
None

## Limitations
- Evaluation relies on five benchmarks that may not reflect real-world complexity
- Cold-start improvement claims may be sensitive to benchmark selection and parameter tuning
- Limited quantitative metrics for output diversity improvements
- Computational overhead and memory requirements at scale are not discussed

## Confidence
- Cold-start performance improvement (18.05%): Medium confidence
- Output diversity enhancement for active users: Low-Medium confidence
- Effectiveness of modeling collective knowledge: Medium confidence

## Next Checks
1. Conduct ablation studies to isolate contributions of local memory, global memory, and mediator components
2. Perform cross-dataset validation to verify cold-start improvements are not benchmark-specific
3. Implement time-based evaluation to assess adaptation to evolving user preferences and global memory scalability