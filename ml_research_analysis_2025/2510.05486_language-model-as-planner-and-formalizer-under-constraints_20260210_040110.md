---
ver: rpa2
title: Language Model as Planner and Formalizer under Constraints
arxiv_id: '2510.05486'
source_url: https://arxiv.org/abs/2510.05486
tags:
- constraints
- pddl
- planning
- on-table
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CoPE introduces constraints to planning benchmarks, showing that
  they consistently halve LLM performance and expose scaling and robustness issues.
  Four LLMs, three formal languages, and five methods were evaluated on four datasets,
  with results demonstrating significant drops in correctness when constraints are
  added.
---

# Language Model as Planner and Formalizer under Constraints

## Quick Facts
- arXiv ID: 2510.05486
- Source URL: https://arxiv.org/abs/2510.05486
- Reference count: 40
- Key outcome: LLM performance consistently halves with constraints, exposing scaling and robustness issues across planning benchmarks

## Executive Summary
This paper introduces CoPE, a benchmark that evaluates Large Language Models (LLMs) as planners and formalizers under realistic constraints. Across four datasets, three formal languages, and five methods, the authors demonstrate that adding constraints systematically degrades LLM performance by 30-50%. The study reveals that PDDL outperforms SMT in most cases, and that LLM-as-formalizer, while more interpretable, loses its robustness to problem complexity when constraints are introduced. The benchmark highlights the need for future evaluations that better reflect real-world planning complexity.

## Method Summary
The authors evaluate LLM-as-planner (end-to-end action sequence generation) and LLM-as-formalizer (translation to PDDL/SMT/LTL) on constrained planning tasks. They use one-shot prompting across three formalization techniques: generate, edit, and revision (up to 3 error-based retries). Four datasets are used—BlocksWorld-100, CoinCollector-100, BlocksWorld-XL-100 (50 blocks), and MysteryBlocksWorld-100 (lexically obfuscated)—each with 100 manually annotated natural language constraints categorized as Initial, Goal, Action, or State constraints. Plan correctness is validated using VAL against ground-truth PDDL, with solvers (dual-bfws-ffparser for PDDL, Z3 for SMT, Spot for LTL) invoked as needed.

## Key Results
- Constraints consistently halve planning performance across all methods and domains
- PDDL outperforms SMT in most configurations, with SMT showing more syntax and semantic errors
- LLM-as-formalizer loses its robustness to problem complexity and lexical shift when constraints are introduced
- State constraints prove most challenging for editing methods, requiring new predicates and temporal tracking

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adding linguistically rich, formally categorized constraints systematically degrades LLM planning performance by approximately 50% across methods and domains.
- Mechanism: Constraints require integrating additional boolean conditions into the action space, state space, or goal conditions. This increases the search space complexity and introduces new predicates that must be correctly instantiated and composed with existing domain logic, which LLMs struggle to do reliably.
- Core assumption: The constraint categories (Initial, Goal, Action, State) as defined in the paper provide a relatively complete coverage of typical constraint types in planning problems.
- Evidence anchors:
  - [abstract]: "Over 4 LLMs, 3 formal languages, 5 methods, and 4 datasets, CoPE shows that constraints consistently halve planning performance, with correctness dropping by 30-50% across domains."
  - [section 6 Results]: "It is evident that constraints make planning and formalizing much more difficult... introducing constraints consistently degrades (often halves) the planning performances over all cases."
  - [corpus]: Related work "Are LLMs Better Formalizers than Solvers on Complex Problems?" confirms performance gains of formalization methods but does not specifically evaluate constraint-heavy scenarios, suggesting this degradation finding is novel.
- Break condition: If constraints can be expressed as simple conjunctions to existing predicates without requiring new predicate definitions or action modifications, degradation may be reduced.

### Mechanism 2
- Claim: LLM-as-formalizer demonstrates robustness to problem complexity and lexical perturbation without constraints, but this robustness disappears when constraints are introduced.
- Mechanism: Formalizers translate problems into structured representations that external solvers execute, insulating against lexical variation and scaling issues. However, constraints require modifying the formal representation itself (adding predicates, modifying preconditions), and LLMs make systematic errors in this modification step that solvers cannot recover from.
- Core assumption: The external solver correctly executes valid PDDL/SMT/LTL representations, so performance differences reflect formalization quality rather than solver limitations.
- Evidence anchors:
  - [section 6 Results]: "As we corroborate past work by showing the robustness of LLM-as-formalizer over LLM-as-planner to problem complexity and lexical shift, we clearly demonstrate that the introduction of constraints substantially negates such robustness."
  - [section 6 Results - Mystery BlocksWorld]: "LLM-as-formalizer remains robust to lexical perturbation, without constraints. However, such robustness disappears with the constraints, as the performance for all 4 LLMs and 2 formalizing methods decreases by two thirds or more."
  - [corpus]: "Vision Language Models Cannot Plan, but Can They Formalize?" explores formalization for VLMs but does not evaluate constraint scenarios; corpus evidence on this specific mechanism is limited.
- Break condition: If constraint integration can be handled via a separate constraint formalization module that appends to the base problem specification without modifying existing predicates, robustness may partially recover.

### Mechanism 3
- Claim: Initial and goal constraints are easier to address via editing than state constraints, because they require modifying boundary conditions rather than introducing new predicates that track intermediate states.
- Mechanism: Initial and goal constraints can be expressed by editing the `:init` or `:goal` sections of PDDL problem files directly. State constraints require adding new predicates to track intermediate states across action sequences and modifying action preconditions/effects to maintain these predicates—substantially more complex edits.
- Core assumption: The editing approach (generating base PDDL then applying targeted modifications) correctly isolates constraint-specific changes from base domain specification.
- Evidence anchors:
  - [section 3 - Definition 3-6]: Formal definitions show Initial and Goal constraints modify `s_0` or `ψ_goal` directly, while State constraints require `τ' ⊊ τ` where entire state sequences must be constrained.
  - [section 6 Results]: "Recalling the definitions in Section 3, local edits may allow LLMs as PDDL formalizers to satisfy initial and goal constraints more easily compared to state constraints, since they do not require introducing and applying new predicates."
  - [corpus]: No direct corpus evidence on constraint category difficulty; this appears to be a novel contribution of the benchmark.
- Break condition: State constraints that can be compiled into action preconditions (e.g., "no action may cause stack height > 3") may be easier than state constraints requiring temporal tracking across arbitrary state sequences.

## Foundational Learning

- Concept: STRIPS Planning Formalism (States, Actions, Preconditions, Effects)
  - Why needed here: The entire benchmark assumes familiarity with PDDL, which implements STRIPS-style planning. Understanding how actions modify state via preconditions and effects is essential for interpreting why constraint integration is difficult.
  - Quick check question: Given an action `pick_up(block_A)` with precondition `clear(block_A) ∧ on_table(block_A) ∧ arm_empty` and effect `holding(block_A) ∧ ¬clear(block_A) ∧ ¬on_table(block_A)`, what state must hold before execution and what state holds after?

- Concept: Constraint Categories in Planning (Initial, Goal, Action, State)
  - Why needed here: The benchmark categorizes constraints to enable systematic analysis. Each category requires different modifications to the planning problem representation.
  - Quick check question: Is the constraint "You may only pick up a block if you put down the previous block first" an action constraint or a state constraint? Why might it be ambiguous?

- Concept: Solver-Based vs. End-to-End Planning
  - Why needed here: The paper compares LLM-as-planner (end-to-end plan generation) against LLM-as-formalizer (generating PDDL for external solvers). Understanding this distinction is critical for interpreting why formalizers show different robustness profiles.
  - Quick check question: If an LLM generates syntactically valid PDDL that semantically misrepresents the constraint, will the solver catch this error? Why or why not?

## Architecture Onboarding

- Component map:
  - Input layer: `(D_d, D_p, DF'_G, C)` — domain description, problem description, PDDL action headers, constraint text
  - Planner path: LLM → Action sequence → VAL validator → Correctness score
  - Formalizer path: LLM → PDDL/SMT/LTL code → External solver → Plan → VAL validator → Correctness score
  - Formalizer variants: Generate (single-pass), Edit (generate base → identify constraint edits → regenerate), Revision (generate → receive solver errors → regenerate up to 3 times)
  - Constraint categories: Initial (modifies `:init`), Goal (modifies `:goal`), Action (modifies action preconditions/effects), State (requires new predicates and temporal tracking)

- Critical path:
  1. Parse input `(D_d, D_p, DF'_G, C)` into structured prompt
  2. Route to planner or formalizer based on evaluation configuration
  3. For formalizers: generate PDDL/SMT/LTL → invoke solver (dual-bfws-ffparser for PDDL, Z3 for SMT, Spot for LTL)
  4. Validate resulting plan against ground-truth PDDL using VAL
  5. Compute correctness percentage over evaluation set

- Design tradeoffs:
  - PDDL vs. SMT: PDDL more naturally expresses planning domains; SMT provides richer constraint modeling but generates more syntax/semantic errors (Table 4 shows PDDL outperforms SMT in most configurations)
  - Generate vs. Edit: Editing localizes constraint changes but assumes base PDDL is correct; generation handles constraint and domain simultaneously but increases error surface
  - Revision: Improves correctness by leveraging solver feedback but adds latency and may not recover from fundamental semantic errors

- Failure signatures:
  - Planner failures: Hallucinated actions, violated preconditions, unsatisfied constraints, incorrect goal achievement
  - Formalizer failures: PDDL/Python syntax errors, undeclared predicates/functions, logically incorrect preconditions, false constraint encoding
  - Scaling failures: Near-zero performance on BlocksWorld-XL (50 blocks) even without constraints, suggesting fundamental scaling limits
  - Memorization artifacts: Sharp performance drop on MysteryBlocksWorld for planners (obfuscated names break pattern matching)

- First 3 experiments:
  1. Replicate baseline: Run LLM-as-planner and LLM-as-formalizer (PDDL, generate) on BlocksWorld-100 without constraints to establish baseline correctness. Expected: Planner ~70-90%, Formalizer ~40-70% depending on model.
  2. Constraint sensitivity analysis: Add Initial, Goal, Action, and State constraints separately to measure per-category degradation. Expected: Initial/Goal ~20-30% drop, State ~40-60% drop.
  3. Scaling test: Evaluate best-performing configuration on BlocksWorld-XL (50 blocks) with and without constraints. Expected: Sharp degradation even without constraints; constraints reduce performance to near-zero for some configurations.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do LLMs perform when planning with complex constraints involving conjunction, negation, or ambiguity?
- Basis in paper: [explicit] The Limitations section states that "interesting phenomena such as the conjunction, negation, or ambiguity of the constraints are left for future work."
- Why unresolved: The current CoPE benchmark focuses on single, categorized constraints and does not model these compound or ambiguous logical structures.
- What evidence would resolve it: An extension of the CoPE benchmark including compound constraints, along with an evaluation of model performance on these specific linguistic and logical complexities.

### Open Question 2
- Question: Which specific constraint categories (Initial, Goal, Action, State) consistently pose the greatest difficulty for LLMs across diverse formal languages?
- Basis in paper: [inferred] In the results section ("What category of constraints is hard?"), the authors note that while there are hypotheses (e.g., state constraints being harder for PDDL), the empirical results are "non-decisive" and vary significantly by model and formalism.
- Why unresolved: The paper finds that while PDDL and SMT respond differently to constraint types, no clear, universal pattern of difficulty emerges across the tested models and domains.
- What evidence would resolve it: A larger-scale ablation study across more domains and formal languages that isolates constraint categories to identify statistically significant difficulty hierarchies.

### Open Question 3
- Question: How can the faithfulness of LLM-generated formalizations be evaluated to prevent false positives where a plan is valid but the code is semantically incorrect?
- Basis in paper: [explicit] The Limitations section highlights that the "plan correctness" metric may induce false positives because the generated code might not "actually correctly describe the environment," leading to concerns in interpretability.
- Why unresolved: The authors note there is currently "no feasible way to overcome this issue" automatically, as techniques like graph isomorphism work for problem files but not for domain files.
- What evidence would resolve it: The development of a new evaluation metric or validation tool capable of verifying the semantic alignment of generated domain files with the ground truth, independent of the plan output.

## Limitations
- Constraint integration mechanism remains incompletely specified—unclear whether constraints compile into existing PDDL or require structural modifications
- Evaluation relies on one-shot prompting without few-shot demonstrations or chain-of-thought prompting
- Correctness metric may overestimate true performance since VAL validation can pass semantically incorrect plans

## Confidence

- High confidence: Constraint degradation effect is consistently observed across all configurations (abstract: "constraints consistently halve planning performance")
- Medium confidence: PDDL outperforms SMT/LTL claims, though Table 4 shows methodological inconsistencies in solver invocation
- Low confidence: Claims about LLM-as-formalizer robustness to lexical perturbation, as the MysteryBlocksWorld evaluation shows this advantage disappears with constraints but the underlying mechanism remains unclear

## Next Checks

1. Replicate the constraint degradation effect on BlocksWorld-100 using different prompt engineering (few-shot vs. one-shot) to isolate whether degradation stems from constraint complexity or prompt format
2. Implement a constraint compilation baseline that automatically translates constraints into PDDL preconditions without LLM involvement, then compare against LLM-as-formalizer to measure the true LLM contribution
3. Conduct ablation on constraint categories by providing models with only the base PDDL problem and a separate constraint file, testing whether structural separation improves performance compared to integrated constraint encoding