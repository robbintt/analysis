---
ver: rpa2
title: Online time series prediction using feature adjustment
arxiv_id: '2509.03810'
source_url: https://arxiv.org/abs/2509.03810
tags:
- online
- time
- prediction
- learning
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ADAPT-Z, a method for online time series
  forecasting that addresses distribution shifts by updating feature representations
  of latent factors rather than model parameters. The approach uses an adapter module
  that combines current feature representations with historical gradient information
  to handle delayed feedback in multi-step forecasting.
---

# Online time series prediction using feature adjustment

## Quick Facts
- arXiv ID: 2509.03810
- Source URL: https://arxiv.org/abs/2509.03810
- Reference count: 40
- Primary result: ADAPT-Z achieves up to 25.99% error reduction compared to baseline models across 13 datasets

## Executive Summary
ADAPT-Z introduces a novel approach to online time series forecasting that addresses distribution shifts by updating feature representations of latent factors rather than model parameters. The method uses an adapter module that combines current feature representations with historical gradient information to handle delayed feedback in multi-step forecasting. Extensive experiments demonstrate consistent performance improvements over standard base models and state-of-the-art online learning approaches, particularly in adapting to non-stationary environments while maintaining stable performance across different prediction horizons.

## Method Summary
ADAPT-Z decomposes prediction models into encoder f and prediction head g, learning a correction term δ_t such that g(z_t + δ_t) approximates y_t. The adapter module processes both current features z_t and historical gradients using a dual-path MLP structure. During deployment, ADAPT-Z operates in k-step delayed fashion, caching historical data and updating the adapter when true values become available. The method requires fine-tuning the adapter on validation data before online deployment, then updating only the adapter and final layer using online gradient descent with learning rates 0.0003 (adapter) and 0.00003 (final layer).

## Key Results
- Achieves up to 25.99% error reduction compared to baseline models across 13 datasets
- Consistently outperforms state-of-the-art online learning approaches in handling distribution shifts
- Demonstrates particular effectiveness in multi-step forecasting scenarios with delayed feedback
- Shows robust performance across different prediction horizons (12, 24, 48 steps)

## Why This Works (Mechanism)

### Mechanism 1: Feature-Space Correction via Latent Factor Alignment
Updating feature representations of latent factors addresses distribution shift more effectively than updating model weights because distribution shifts originate from changes in underlying latent factors. ADAPT-Z learns a correction term δ_t such that g(z_t + δ_t) approximates y_t, bypassing the need to update high-dimensional model parameters. This approach assumes observed distribution shifts stem from changes in latent factors (e.g., economic conditions affecting traffic patterns), and encoder outputs capture these factors.

### Mechanism 2: Historical Gradient Fusion for Delayed Feedback Mitigation
Combining current features with batch-averaged historical gradients enables robust adaptation despite multi-step prediction delays. At time t, for k-step prediction, true values aren't available until t+k. ADAPT-Z computes historical gradients using a batch from timestamps t-k-b to t-k, averaging to reduce variance. These gradients are fed alongside current features z_t into the adapter via a dual-path structure to handle magnitude disparity.

### Mechanism 3: Lightweight Adapter with Frozen Base Model
Freezing the base model and updating only a small adapter module + final layer provides stable adaptation while preserving learned representations. The adapter is a 5-layer MLP with dual-path input processing. Only adapter parameters (and optionally the final prediction layer) are updated via online gradient descent, maintaining the pretrained encoder's useful representations while adjusting the mapping from features to outputs.

## Foundational Learning

- **Encoder-Decoder Decomposition**: Understanding that z_t = f(x_t) and ŷ_t = g(z_t) is essential for identifying where to inject the correction δ_t. Quick check: Given a transformer-based forecaster, which layer's output represents the latent feature representation z_t?

- **Online Gradient Descent with Non-Stationary Regret**: The method uses k-step delayed OGD. Understanding dynamic regret bounds helps interpret why batch averaging helps (reduces gradient variance term λ in the bound). Quick check: Why does single-sample gradient estimation perform poorly in online time series settings?

- **Covariate Shift vs. Concept Drift**: The paper distinguishes normalization methods (address covariate shift) from feature-space correction (addresses concept drift where x→y mapping changes). Quick check: If input distribution changes but x→y relationship stays constant, would RevIN alone suffice?

## Architecture Onboarding

- **Component map:**
Input x_t → Encoder f → Feature z_t ──┐
                                      ├→ Adapter A → δ_t → (+) → Prediction Head g → ŷ_t
Historical Gradient hisgrad_{t-k} ────┘

- **Critical path:**
1. Feature extraction location matters: Table 4 shows performance varies by extraction point. Default: second-to-last block output.
2. Adapter initialization: Train on validation set for 3 epochs (or training set for better results).
3. Online update loop: Cache (z, ŷ, his_grad) for each timestep; when y_{t-k} arrives, compute loss and update adapter + final layer.

- **Design tradeoffs:**
- Feature location: Earlier layers (Block 1) vs. later (Projection layer) — dataset-dependent (Table 4).
- Batch size for gradient computation: Default 24; Figure 5 shows high variance in optimal values across datasets/horizons.
- Online learning rate: Figure 6 shows optimal range 0.00005–0.0003; values >0.005 cause instability.

- **Failure signatures:**
- Performance degrades when base model is weak (TimesNet cases in Table 7).
- Direct input adjustment performs worse than baseline (Table 4, "Input" row).
- High learning rate (>0.005) causes MSE spikes.

- **First 3 experiments:**
1. Baseline comparison: Run ADAPT-Z vs. fOGD (feature-only OGD) on a single dataset using iTransformer. Expected: ADAPT-Z should outperform fOGD by 2–5% MSE reduction.
2. Feature location ablation: Extract features from Input, Emb, Block1, Block2, Projection layers on electricity dataset. Expected: Block-level features outperform raw input; optimal layer varies by dataset.
3. Delayed feedback stress test: Vary prediction horizon k∈{1, 24, 48} and measure MSE gap between ADAPT-Z and fOGD. Expected: Gap widens at larger k due to ADAPT-Z's gradient fusion handling delay better.

## Open Questions the Paper Calls Out

### Open Question 1
Can advanced sample selection strategies, such as experience replay or hard sample mining, improve the stability of gradient estimation in ADAPT-Z compared to the current fixed-batch approach? The current method uses a fixed window of recent samples to compute historical gradients, which may not be the most efficient way to reduce gradient variance or select informative data points for adaptation.

### Open Question 2
Does incorporating temporal sample ordering during the pre-training phase of time series models improve their subsequent online adaptation performance? Standard training treats samples as independent to optimize parameters for a static distribution, but this ignores the sequential dependencies available during online deployment that could be leveraged to learn "how to learn" or adapt.

### Open Question 3
Can enhanced adapter architectures (e.g., attention-based or recurrent modules) outperform the current dual-path MLP design in capturing complex correction dependencies? The current adapter uses a simple dual-path MLP to fuse features and gradients, primarily to handle magnitude differences. It is unclear if more sophisticated temporal modeling within the adapter could better capture the dynamics of the correction term δ_t.

### Open Question 4
Is there an automated or theoretically grounded method to determine the optimal layer within a base model for applying feature adjustment? The current method relies on manual selection or heuristics (e.g., "second last block"), which may be suboptimal for different architectures or data distributions, and lacks a mechanism to dynamically select the best layer during deployment.

## Limitations
- No theoretical guarantees or formal regret bounds provided for the method
- Significant hyperparameter sensitivity requiring dataset-dependent tuning
- Performance degrades when base model features are fundamentally misaligned with task
- Computational overhead during deployment despite being lighter than full model updates

## Confidence

- **Empirical performance claims**: High (13 datasets, multiple baselines, consistent improvements)
- **Theoretical mechanism claims**: Medium (plausible but not formally proven)
- **Hyperparameter robustness**: Low-Medium (significant dataset-dependent tuning required)

## Next Checks

1. **Theoretical analysis**: Derive regret bounds for the k-step delayed OGD with historical gradient averaging to understand convergence guarantees and identify conditions under which the method fails.

2. **Extreme distribution shift test**: Create synthetic dataset with abrupt covariate shift (e.g., sensor failure changing data distribution) to stress-test whether feature-space correction outperforms normalization methods like RevIN.

3. **Real-time performance evaluation**: Measure inference latency and memory usage during online deployment on resource-constrained devices to quantify practical deployment overhead.