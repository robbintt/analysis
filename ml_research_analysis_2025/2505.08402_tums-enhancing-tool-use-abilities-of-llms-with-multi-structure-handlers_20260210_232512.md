---
ver: rpa2
title: 'TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers'
arxiv_id: '2505.08402'
source_url: https://arxiv.org/abs/2505.08402
tags:
- tool
- arxiv
- tums
- tools
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes TUMS, a framework that enhances the tool-use
  capabilities of LLMs by transforming tool-level processing into parameter-level
  processing. The core idea is to use multi-structure handlers to generate accurate
  parameters for tool calls, considering the different difficulties of various tools.
---

# TUMS: Enhancing Tool-use Abilities of LLMs with Multi-structure Handlers

## Quick Facts
- **arXiv ID:** 2505.08402
- **Source URL:** https://arxiv.org/abs/2505.08402
- **Authors:** Aiyao He; Sijia Cui; Shuai Xu; Yanna Wang; Bo Xu
- **Reference count:** 40
- **Primary result:** 19.6% average improvement on easy ToolQA questions, 50.6% on hard questions

## Executive Summary
This paper introduces TUMS, a framework that enhances large language models' (LLMs) tool-use capabilities by transforming tool-level processing into parameter-level processing. The core innovation lies in using multi-structure handlers to generate accurate parameters for tool calls, recognizing that different tools require different reasoning strategies. TUMS consists of four key components: an intent recognizer, a task decomposer, a subtask processor with multi-structure handlers (Direct, Parallel, Serial), and an executor. The framework achieves significant performance gains on the ToolQA benchmark, demonstrating both effectiveness and efficiency improvements over existing methods.

## Method Summary
TUMS addresses the limitation of LLMs in generating accurate parameters for tool calls by introducing a parameter-level processing approach. The framework employs four modules working in sequence: (1) an Intent Recognizer that classifies the dataset to provide context hints, (2) a Task Decomposer that breaks down questions into subtasks and selects appropriate tools, (3) a Subtask Processor with three multi-structure handlers (Direct, Parallel, Serial) that generate tool parameters based on tool complexity, and (4) an Executor that runs the tool and returns results. The multi-structure handlers represent a novel approach where tool calls are decomposed into multiple reasoning steps when necessary, particularly for complex tools like SQL interpreters. The system uses Qwen1.5-72B-Chat as the base LLM with temperature=0 and max_tokens=256.

## Key Results
- **Performance gains:** TUMS achieves 19.6% average improvement on easy ToolQA questions and 50.6% improvement on hard questions compared to baseline methods
- **Efficiency:** The framework demonstrates improved efficiency with lower average LLM calls per correct answer while maintaining high accuracy
- **Ablation results:** Removing the multi-structure handlers (TUMS-OS) or intent recognizer (TUMS-NIR) significantly degrades performance, confirming their importance

## Why This Works (Mechanism)

### Mechanism 1: Parameter-level Processing via Multi-structure Handlers
- **Claim:** Shifting from tool-level to parameter-level processing reduces non-executable actions by tailoring generation strategies to tool complexity
- **Mechanism:** Instead of treating all tool invocations identically, TUMS routes requests to specific handlers (Direct, Parallel, or Serial) based on the tool's difficulty and parameter count, enabling fine-grained reasoning
- **Core assumption:** LLMs fail at parameter generation due to undifferentiated prompting strategies, not lack of knowledge
- **Evidence anchors:** Abstract states "transforming tool-level processing into parameter-level processing"; Section 3.3 describes "fine-grained approach" with multi-structured parameter generation
- **Break condition:** Tools requiring recursive logic or patterns outside Direct/Parallel/Serial may fail

### Mechanism 2: Context Narrowing via Intent Recognition
- **Claim:** Intent recognition minimizes planning errors by constraining the decomposer's search space
- **Mechanism:** Initial module extracts keywords to identify likely dataset (e.g., "Coffee" vs. "Flight"), appending hints to restrict tool selection and prevent irrelevant tool calls
- **Core assumption:** LLM planning degrades as toolset size increases; constraining options improves selection accuracy
- **Evidence anchors:** Section 3.1 describes appending hints to prompts; Section 4.2 shows improved efficiency with lowest average cost
- **Break condition:** Misclassification of dataset intent propagates incorrect constraints, causing cascading failures

### Mechanism 3: Serial Generation for Complex Tools
- **Claim:** Serial generation structures mitigate syntax and logic errors in complex tool invocations
- **Mechanism:** For intricate tools like SQL, enforces sequential chain: extract framework skeleton → map concepts to database columns → synthesize final code
- **Core assumption:** Complex code generation is compositional; separating structural logic from value mapping reduces cognitive load
- **Evidence anchors:** Section 3.3 describes breaking down SQL generation into manageable sequential steps
- **Break condition:** If database schema is too large or unclear for mapping step, serial handler cannot ground values correctly

## Foundational Learning

- **Concept: Tool-Augmented LLMs (ReAct Pattern)**
  - **Why needed here:** TUMS evolves the ReAct paradigm; understanding "Thought -> Action -> Observation" loops is prerequisite to understanding how TUMS inserts "Multi-structure Handlers" between Thought and Action
  - **Quick check question:** Can you explain the difference between a standard LLM response and a ReAct-style trajectory?

- **Concept: Parameter Generation vs. Tool Selection**
  - **Why needed here:** The paper critiques prior work for focusing on selection while ignoring parameter accuracy; distinguishing these steps is vital for understanding TUMS's Subtask Processor
  - **Quick check question:** If an LLM calls `calculate("two plus two")` and fails, is that a selection error or a parameter error?

- **Concept: Divide-and-Conquer Prompting**
  - **Why needed here:** Parallel and Serial handlers rely on splitting complex prompts into sub-operations; understanding prompt chaining is required to implement these handlers
  - **Quick check question:** How would you split "Filter flights from NY to London after 5pm" into distinct variables for a tool input?

## Architecture Onboarding

- **Component map:** User Question -> Intent Recognizer (Classifies dataset -> Generates Hint) -> Task Decomposer (Receives Hint + History -> Selects Tool + Subtask) -> Subtask Processor (Receives Tool + Subtask -> Selects Handler -> Generates API Parameters) -> Executor (Runs API -> Returns Result) -> Loop (Result feeds back to Decomposer until `[Finish]`)

- **Critical path:** The interface between Task Decomposer and Subtask Processor; ambiguous subtask descriptions prevent handlers from generating parameters regardless of sophistication

- **Design tradeoffs:**
  - **Latency vs. Accuracy:** TUMS trades single-step speed for multi-step accuracy; Serial/Parallel handlers require multiple inference calls per tool use, increasing latency and token cost
  - **Specificity vs. Generality:** Handlers (especially SQL Serial) seem tailored to ToolQA benchmark structure; adapting to new domains may require rewriting handler prompts

- **Failure signatures:**
  - **Infinite Loop:** Decomposer repeatedly tries same failed tool sequence without using `[Finish]`
  - **Mapping Hallucination:** Serial handler invents non-existent database column name due to truncated schema context
  - **Hint Bias:** Intent Recognizer forces wrong dataset (e.g., generic math as "Coffee" query), restricting Decomposer from solving problem

- **First 3 experiments:**
  1. **Pipeline Validation:** Run TUMS on single ToolQA dataset (e.g., Coffee) and verify Intent Recognizer correctly identifies dataset >90% of time
  2. **Ablation (One-Structure):** Disable Multi-structure handlers and force all tools to use "Direct Generation" (TUMS-OS); confirm performance drop of approximately 20% from Figure 3
  3. **Stress Test:** Feed query with ambiguous intent to verify if Task Decomposer can self-correct when Intent Recognizer provides weak or empty hint

## Open Questions the Paper Calls Out

- **Open Question 1:** How can TUMS framework be extended to autonomously design or select more sophisticated handler structures beyond Direct, Parallel, and Serial paradigms?
  - **Basis:** Section 3.3 states processor "is capable of expansion to more sophisticated structures"
  - **Unresolved:** Current implementation uses three manually defined structures; paper doesn't explore dynamic generation of novel patterns for unforeseen tool complexities
  - **Resolution evidence:** Demonstration of meta-handler or learning algorithm creating and applying novel structure (e.g., recursive) to previously failing tools

- **Open Question 2:** How can Task Decomposer be improved to autonomously determine optimal tool paths for extremely challenging tasks without preference-based hints?
  - **Basis:** Appendix 6.2 notes "bottleneck to generating accurate plan" for hard questions and manual implementation of preference-based hints
  - **Unresolved:** Reliance on manual hints suggests decomposer lacks mechanism to evaluate path efficiency in complex scenarios
  - **Resolution evidence:** Updated decomposer achieving comparable performance on hard benchmarks without preference-based hints

- **Open Question 3:** Can parameter-level processing strategy be effectively integrated with improved retrieval mechanisms to address failures from limited context window retrieval?
  - **Basis:** Section 4.2 attributes poor SciREX performance to retrieval tool returning only first three most related contents
  - **Unresolved:** Paper focuses on parameter accuracy but doesn't address insufficient data retrieval scenarios
  - **Resolution evidence:** Experiments showing TUMS combined with sliding window or hierarchical retrieval improves dense text datasets like SciREX

## Limitations

- **Handler routing logic:** The paper does not specify how to select Direct/Parallel/Serial per tool, requiring assumptions about rule-based mapping
- **Complete prompt exemplars:** Exact few-shot examples for intent recognition and handler prompts are not provided, affecting reproducibility
- **Unknown parameters:** MAX-STEPS parameter for decomposition loop is not defined, potentially impacting convergence behavior

## Confidence

- **High confidence** in overall framework architecture and reported performance improvements (19.6% easy, 50.6% hard)
- **Medium confidence** in mechanism explanations for why parameter-level processing improves accuracy over tool-level approaches
- **Medium confidence** in efficiency claims given multi-step nature potentially increasing token costs

## Next Checks

1. **Handler routing validation:** Test whether assumed rule-based mapping of tools to handlers matches authors' implementation and produces similar performance
2. **Intent recognition accuracy:** Verify dataset classification achieves >90% accuracy on held-out validation set, critical for efficiency gains
3. **Ablation robustness:** Implement TUMS-OS and TUMS-NIR variants to confirm reported performance drops and efficiency differences match Figure 3 results