---
ver: rpa2
title: Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications
arxiv_id: '2507.02291'
source_url: https://arxiv.org/abs/2507.02291
tags:
- semantic
- knowledge
- communication
- unseen
- kgzs-sc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces KGZS-SC, a knowledge graph-enhanced zero-shot
  semantic communication framework that integrates structured semantic information
  to improve generalization, interpretability, and robustness for unseen data. The
  proposed approach leverages a knowledge graph-based semantic knowledge base (KG-SKB)
  to align visual features with semantic embeddings in a shared embedding space, reducing
  communication overhead by transmitting compact semantic representations.
---

# Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications

## Quick Facts
- arXiv ID: 2507.02291
- Source URL: https://arxiv.org/abs/2507.02291
- Authors: Zhaoyu Zhang; Lingyi Wang; Wei Wu; Fuhui Zhou; Qihui Wu
- Reference count: 17
- Key outcome: KGZS-SC achieves 57.43% seen and 41.64% unseen classification accuracy at SNR=-10dB, with 72.9%, 49.1%, 59.1%, and 15.7% improvements over ZSL-SC.

## Executive Summary
This paper introduces KGZS-SC, a knowledge graph-enhanced zero-shot semantic communication framework that integrates structured semantic information to improve generalization, interpretability, and robustness for unseen data. The proposed approach leverages a knowledge graph-based semantic knowledge base (KG-SKB) to align visual features with semantic embeddings in a shared embedding space, reducing communication overhead by transmitting compact semantic representations. A two-stage training process employs a ResNet-based semantic encoder and a graph convolutional network (GCN) to capture local and global semantic dependencies, while zero-shot learning enables direct classification of unseen categories without retraining.

## Method Summary
KGZS-SC builds a KG-SKB from ConceptNet two-hop subgraphs around seen categories, initializes nodes with GloVe embeddings, and computes edge weights via Laplace-smoothed random walk statistics. A two-layer GCN propagates semantic information through this graph to generate category embeddings. The framework uses a two-stage training process: Stage 1 trains ResNet semantic encoder and GCN jointly to align visual features with category embeddings; Stage 2 fine-tunes channel encoder/decoder while freezing semantic components, using combined reconstruction and alignment losses. At inference, decoded semantic symbols are classified via similarity matching against precomputed category embeddings.

## Key Results
- KGZS-SC achieves 57.43% classification accuracy for seen categories and 41.64% for unseen categories at SNR=-10dB
- The framework demonstrates 72.9%, 49.1%, 59.1%, and 15.7% improvements over ZSL-SC across different SNR levels
- Robust generalization is maintained across varying SNR levels, with strong performance even in noisy environments
- Harmonic mean of 48.28% indicates balanced performance on both seen and unseen categories

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Structured knowledge graph alignment creates a unified semantic embedding space that enables knowledge transfer from seen to unseen categories.
- **Mechanism**: The KG-SKB constructs a global graph by extracting two-hop subgraphs around seen categories from ConceptNet, initializing nodes with GloVe embeddings, and computing edge weights via Laplace-smoothed random walk statistics. This explicit graph structure maps semantic relationships (entity-relation-entity triples) into a continuous embedding space where visually and semantically similar concepts cluster together.
- **Core assumption**: The relational structure in external knowledge graphs correlates with visual similarity and task-relevant semantic features; unseen categories can be grounded through their graph connections to seen categories.
- **Evidence anchors**:
  - [abstract]: "KG-SKB aligns the semantic features in a shared category semantics embedding space and enhances the generalization ability of the transmitter through aligned semantic features"
  - [Section III.A, Eq. 1-3]: Global graph construction via node/edge set union, GloVe initialization, and Laplace-smoothed edge weighting
  - [corpus]: "Knowledge Abstraction for Knowledge-based Semantic Communication" (arXiv:2507.17784) similarly leverages knowledge structures for semantic communication generalization
- **Break condition**: If unseen categories are semantically isolated (few/no edges to seen categories in the knowledge graph), alignment provides no transfer benefit—the paper acknowledges this limitation with categories like "statue" and "donkey" in Figure 2.

### Mechanism 2
- **Claim**: Graph convolutional propagation over KG-SKB captures multi-hop semantic dependencies, producing generalized category embeddings robust to channel noise.
- **Mechanism**: A two-layer GCN aggregates neighbor features with symmetric normalization (√deg(v)deg(u)), followed by residual connections with layer normalization to prevent over-smoothing. Each node's representation is refined by incorporating information from its local neighborhood (one-hop) while the second layer extends reach to global dependencies, yielding final embeddings φ(y) for all categories.
- **Core assumption**: Semantic relationships in the graph are transitive and compositional—two-hop neighbors share meaningful attributes with the target category.
- **Evidence anchors**:
  - [abstract]: "graph convolutional network (GCN) to capture local and global semantic dependencies"
  - [Section III.B, Eq. 4-7]: GCN aggregation with normalization, residual + LayerNorm, and ReLU activation
  - [corpus]: No direct corpus evidence on GCN-based semantic communication; weak external validation
- **Break condition**: Over-smoothing occurs if layer count increases without normalization; disconnected graph components receive no propagated signal.

### Mechanism 3
- **Claim**: Zero-shot classification operates via similarity matching in the learned embedding space, eliminating retraining for novel categories.
- **Mechanism**: At inference, decoded semantic symbols ŝ are compared against pre-computed category embeddings φ(y) for all Y = Ys ∪ Yu using Euclidean distance. The argmax selection (Eq. 10) yields classification without gradient updates—unseen category embeddings are generated offline by applying the trained GCN to their KG-SKB subgraphs.
- **Core assumption**: The embedding space geometry learned from seen categories generalizes such that unseen categories fall near semantically similar seen neighbors (e.g., "zebra" near "cow").
- **Evidence anchors**:
  - [abstract]: "zero-shot learning (ZSL) is leveraged to enable direct classification for unseen cases without the demand for retraining or additional computational overhead"
  - [Section III.C, Eq. 10]: Classification by argmax similarity between decoded semantics and category embeddings
  - [corpus]: "Zero-shot learning with common sense knowledge graphs" (cited as [10]) provides foundational ZSL+KG methodology
- **Break condition**: Hubness problem—frequent embedding vectors become spurious nearest neighbors; the paper claims KG-SKB alignment mitigates this but provides no ablation isolating the effect.

### Mechanism 4
- **Claim**: Two-stage training decouples semantic representation learning from channel robustness, improving convergence and generalization.
- **Mechanism**: Stage 1 trains ResNet semantic encoder and GCN jointly using cross-entropy-style loss (Eq. 8) to align visual features with correct category embeddings. Stage 2 freezes semantic components and fine-tunes channel encoder/decoder using combined recovery loss (reconstruction fidelity) and alignment loss (semantic consistency with GCN embeddings), weighted by λ=0.9.
- **Core assumption**: Semantic features learned in Stage 1 are sufficiently general to survive channel corruption after Stage 2 fine-tuning.
- **Evidence anchors**:
  - [abstract]: "two-stage training process employs a ResNet-based semantic encoder and a graph convolutional network (GCN)"
  - [Section III.C, Eq. 8-9]: Explicit loss formulations for both training stages with alignment loss providing "reverse guidance"
  - [corpus]: No direct corpus comparison for staged training in semantic communication
- **Break condition**: If Stage 1 overfits to seen categories, Stage 2 alignment loss cannot recover generalization—manifests as high seen accuracy but low unseen accuracy.

## Foundational Learning

- **Knowledge Graphs and Triple Representations**:
  - Why needed here: KG-SKB is constructed from ConceptNet triples ⟨entity, relation, entity⟩; understanding how explicit relational structure differs from latent embeddings is essential.
  - Quick check question: Explain how a two-hop subgraph around "car" might connect to "boat" through shared attributes.

- **Zero-Shot Learning (ZSL) and the Seen/Unseen Split**:
  - Why needed here: The entire framework hinges on classifying Yu without training examples; understanding the inductive ZSL setting (semantic embeddings available at train time) vs. transductive is critical.
  - Quick check question: Why must Ys ∩ Yu = ∅ in standard ZSL, and what happens if this constraint is violated?

- **Graph Convolutional Networks (GCNs)**:
  - Why needed here: The GCN transforms KG-SKB structure into continuous embeddings; understanding neighbor aggregation, normalization, and over-smoothing is necessary for debugging representation quality.
  - Quick check question: What does symmetric normalization by √deg(v)deg(u) accomplish compared to unnormalized aggregation?

## Architecture Onboarding

- **Component map**:
  [Image Input] → [ResNet-50 Semantic Encoder] → [Channel Encoder]
                                                         ↓
  [KG-SKB: ConceptNet + GloVe + Edge Weights]            [AWGN Channel: h·z + n]
         ↓                                                ↓
  [Two-Layer GCN] → [Category Embeddings φ(y)]    [Channel Decoder]
         ↓                                                ↓
  [Shared Embedding Space (2049-dim)] ←---------- [Semantic Decoder → ŝ]
                                                            ↓
                                                    [Similarity Scoring]
                                                            ↓
                                                    [argmax over Y → ŷ]

- **Critical path**:
  1. Offline: Build KG-SKB from ConceptNet two-hop subgraphs; initialize with GloVe
  2. Offline: Train GCN + ResNet (Stage 1) on seen category images
  3. Offline: Compute φ(y) for all Y = Ys ∪ Yu via trained GCN
  4. Online: Transmit image → ResNet → Channel Encoder → AWGN → Channel Decoder
  5. Online: Decode ŝ, compute similarity to all φ(y), return argmax

- **Design tradeoffs**:
  - **Embedding dimension**: D=300 (node) → 2049 (semantic); higher dims improve separation but increase bandwidth
  - **GCN depth**: Two layers balance local/global dependencies; deeper risks over-smoothing
  - **λ = 0.9**: Favors semantic alignment over reconstruction; lower values improve noise robustness but may lose semantic precision
  - **Two-hop subgraph**: Captures indirect relationships; deeper extraction increases O(|Ys|(V+E)) complexity

- **Failure signatures**:
  - **Semantic isolation**: Low confidence on categories with sparse KG connectivity (see "statue" in Fig. 2)
  - **Channel collapse at low SNR**: Accuracy degrades sharply below SNR = -5 dB if alignment loss underweighted
  - **Seen-unseen gap**: Harmonic mean << seen accuracy indicates overfitting to Ys
  - **Hubness**: Repeated misclassification to a few frequent categories suggests embedding space imbalance

- **First 3 experiments**:
  1. **Ablate KG-SKB**: Replace GCN embeddings with raw GloVe vectors; measure harmonic mean drop to isolate graph propagation contribution
  2. **Vary λ in [0.5, 0.99]**: Plot seen/unseen accuracy tradeoff; identify optimal balance for target SNR regime
  3. **Cross-dataset transfer**: Train on APY, test on a held-out subset of ImageNet categories with ConceptNet coverage; assess out-of-domain generalization

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the framework be enhanced to bridge the semantic gap for unseen categories that are structurally isolated from seen classes (e.g., "statue" or "donkey" in the APY dataset)?
- **Basis in paper:** [explicit] Section IV states that isolated unseen categories in the PCA visualization "indicate that the learned feature space lacks sufficient semantic grounding," limiting generalization despite the use of KG-SKB.
- **Why unresolved:** The current graph-based embeddings rely on structural connectivity (neighborhoods) to transfer knowledge, failing for disjoint distributions where unseen entities lack strong relational paths to seen classes.
- **What evidence would resolve it:** Demonstration of improved harmonic mean accuracy specifically on datasets containing structurally disjoint categories, or the integration of a mechanism that infers relationships for disconnected nodes.

### Open Question 2
- **Question:** How does the KGZS-SC framework perform under realistic channel impairments, such as multipath fading, compared to the simulated AWGN environment?
- **Basis in paper:** [inferred] The system model in Section II explicitly defines the physical channel using only a gain factor and Additive White Gaussian Noise (AWGN), omitting fading or interference models common in wireless networks.
- **Why unresolved:** Semantic symbols may exhibit different sensitivities to the amplitude fluctuations and phase distortions caused by fading channels compared to the Gaussian noise tested in the paper.
- **What evidence would resolve it:** Simulation results showing classification accuracy and semantic recovery loss over Rayleigh or Rician fading channels.

### Open Question 3
- **Question:** Can the static knowledge graph-based semantic knowledge base (KG-SKB) be updated dynamically in real-time to accommodate emerging entities without requiring full model retraining?
- **Basis in paper:** [inferred] The paper notes in the Introduction that dynamic scenarios involve "unseen entities" and "semantic patterns," yet the methodology relies on static pre-trained GloVe embeddings and fixed graph topologies.
- **Why unresolved:** The described two-stage training process is offline; the paper does not propose a mechanism for online graph topology updates or embedding refinement as new knowledge becomes available.
- **What evidence would resolve it:** Implementation of an incremental learning update rule for the GCN and semantic encoder that maintains accuracy on new classes without catastrophic forgetting of old ones.

## Limitations

- **Knowledge graph coverage**: Performance degrades for unseen categories with sparse connections to seen categories in ConceptNet, limiting generalization from truly isolated concepts
- **GCN architecture vulnerability**: While mitigated by normalization and residual connections, deeper GCN layers risk over-smoothing and may not scale well
- **Computational complexity**: O(|Ys|(V+E)) complexity for two-hop subgraph extraction and reliance on GloVe initialization may not scale to larger, more diverse category sets

## Confidence

- **High confidence**: Knowledge graph alignment + GCN propagation + similarity-based zero-shot classification shows consistent empirical improvements across SNR levels
- **Medium confidence**: Strong results on APY dataset, but no cross-dataset validation to confirm robustness to distribution shift
- **Low confidence**: The framework's scalability assertions are not supported by experiments with larger category sets or different knowledge graph structures

## Next Checks

1. **Cross-dataset transfer test**: Train KGZS-SC on APY, evaluate on a held-out ImageNet subset with ConceptNet coverage to assess generalization beyond the training distribution
2. **Hubness analysis**: Measure nearest-neighbor concentration (e.g., using k-occurrence statistics) in the learned embedding space to quantify and mitigate the hubness problem
3. **Knowledge graph depth ablation**: Compare two-hop vs. three-hop subgraph extraction on a subset of categories to evaluate the tradeoff between computational cost and semantic relationship capture