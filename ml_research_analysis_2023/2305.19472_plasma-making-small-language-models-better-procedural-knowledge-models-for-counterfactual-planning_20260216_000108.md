---
ver: rpa2
title: 'PlaSma: Making Small Language Models Better Procedural Knowledge Models for
  (Counterfactual) Planning'
arxiv_id: '2305.19472'
source_url: https://arxiv.org/abs/2305.19472
tags:
- step
- goal
- plan
- planning
- counterfactual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents PlaSma, a framework for endowing small language
  models with procedural knowledge and planning capabilities. The key idea is to use
  symbolic procedural knowledge distillation to transfer knowledge from a large language
  model (LLM) to a smaller model, along with an inference-time decoding algorithm
  to improve reasoning.
---

# PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning

## Quick Facts
- arXiv ID: 2305.19472
- Source URL: https://arxiv.org/abs/2305.19472
- Reference count: 40
- Small language models (770M-11B parameters) outperform their larger teacher models (175B parameters) on procedural planning tasks when enhanced with PlaSma

## Executive Summary
PlaSma is a framework that enhances small language models with procedural knowledge and planning capabilities through symbolic knowledge distillation. The approach transfers knowledge from large language models (like GPT-3) to smaller models via a curated dataset called COPLAN, which contains procedural plans, conditions, and counterfactual variations. By combining knowledge distillation with a novel verifier-guided decoding algorithm, PlaSma enables small models to generate high-quality procedural plans that are temporally and causally coherent, achieving performance competitive with much larger models.

## Method Summary
The PlaSma framework works through three main stages: (1) generating procedural knowledge from a large teacher model using few-shot prompting, then filtering this data with critic models to create the COPLAN dataset; (2) training smaller student models (T5 variants) on this knowledge using both task-specific and multi-task distillation objectives; and (3) applying a verifier-guided step-wise beam search decoding algorithm during inference to ensure generated plans are semantically coherent and temporally accurate. The multi-task objective trains on planning, counterfactual planning, and plan revision tasks simultaneously to improve generalization.

## Key Results
- The best student model outperforms its larger teacher model (175B parameters) on planning tasks
- Small models achieve performance competitive with much larger models (175B parameters) on both standard and counterfactual planning
- Verifier-guided decoding significantly improves plan quality compared to standard decoding methods
- Multi-task distillation provides consistent improvements across all three planning-related tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Symbolic procedural knowledge distillation transfers high-level procedural reasoning from large LLMs to smaller models via curated datasets
- Mechanism: Large teacher models generate procedural knowledge (goals, plans, conditions) which is then filtered by a critic model to ensure quality, creating a high-quality dataset (COPLAN) that smaller models can learn from
- Core assumption: The knowledge generated by large LLMs, when properly filtered, is sufficiently accurate and complete to be useful for training smaller models
- Evidence anchors: [abstract] "We develop symbolic procedural knowledge distillation to enhance the commonsense knowledge in small language models" / [section] "Our knowledge verbalization process results in a large (counterfactual) procedural planning dataset, COPLAN, which is then used to train smaller models"
- Break condition: If the critic model fails to adequately filter low-quality data, the smaller models will learn incorrect or incomplete procedural knowledge

### Mechanism 2
- Claim: Verifier-guided step-wise beam search improves the temporal and causal coherence of generated plans by incorporating validation at each step
- Mechanism: During decoding, the model generates multiple candidate next steps and selects among them using a combination of the model's own probability and a verifier's validity score, ensuring each step logically follows from the previous ones
- Core assumption: A trained verifier can accurately assess the validity of individual steps in the context of the overall plan
- Evidence anchors: [abstract] "we develop... an inference-time algorithm to facilitate more structured and accurate reasoning" / [section] "To address this challenge, we develop a verifier-guided step-wise beam search to better leverage the multi-step structure of plans"
- Break condition: If the verifier model is poorly trained or the weight between the model and verifier is incorrectly set, the decoding process may not improve plan quality

### Mechanism 3
- Claim: Multi-task distillation (training on planning, counterfactual planning, and plan revision) improves generalization by leveraging the relationships between these tasks
- Mechanism: The model is trained on three related tasks simultaneously, using a joint loss function that combines objectives from all tasks, allowing it to learn shared representations and improve performance across all tasks
- Core assumption: The three tasks (planning, counterfactual planning, and plan revision) share enough underlying structure that training on all of them improves performance on each individual task
- Evidence anchors: [abstract] "we develop... a multi-task distillation objective to train a smaller model on this knowledge" / [section] "We thus minimize the joint loss" followed by the multi-task objective equation
- Break condition: If the tasks are too dissimilar or the model capacity is insufficient, multi-task training may lead to negative transfer and worse performance on all tasks

## Foundational Learning

- Concept: Procedural planning as conditional text generation
  - Why needed here: The paper frames procedural planning as decomposing a high-level goal into a sequence of steps, which is essentially a conditional generation problem where the condition is the goal
  - Quick check question: How does the model generate plans given a goal input?

- Concept: Knowledge distillation
  - Why needed here: The approach transfers knowledge from a large teacher model to smaller student models, which is the core technique being used to enable smaller models to perform complex planning tasks
  - Quick check question: What is the difference between task-specific and multi-task distillation in this context?

- Concept: Beam search and decoding algorithms
  - Why needed here: The paper introduces a novel verifier-guided step-wise beam search, which is an enhancement to standard decoding algorithms to improve plan quality
  - Quick check question: How does the verifier-guided step-wise beam search differ from standard beam search?

## Architecture Onboarding

- Component map: Large teacher model (GPT-3) -> Critic models for filtering -> Student models (T5 variants) -> Verifier model for step validation -> COPLAN dataset for training data

- Critical path:
  1. Large model generates procedural knowledge
  2. Critic models filter the generated data
  3. Student models are trained on the filtered data
  4. During inference, verifier-guided decoding is applied

- Design tradeoffs:
  - Larger teacher models generate better knowledge but are more expensive
  - More stringent filtering improves data quality but reduces dataset size
  - Complex decoding algorithms improve output quality but increase inference time

- Failure signatures:
  - Poor plan quality despite training: likely issues with data filtering or model capacity
  - Inconsistent performance across tasks: may indicate multi-task training issues
  - Slow inference: likely due to complex decoding algorithm

- First 3 experiments:
  1. Test the knowledge generation pipeline end-to-end with a small dataset
  2. Train a student model on a filtered subset of generated data
  3. Implement and test the verifier-guided decoding algorithm on a simple planning task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of using different LLM teachers on the quality and diversity of the distilled procedural knowledge?
- Basis in paper: Explicit
- Why unresolved: The paper only uses GPT-3 as the teacher model for knowledge verbalization. It would be valuable to explore how different LLM teachers, such as PaLM or LaMDA, might affect the resulting knowledge and its applicability to various planning tasks
- What evidence would resolve it: Conduct experiments using different LLM teachers for knowledge verbalization and compare the quality and diversity of the resulting COPLAN datasets and the performance of distilled models on various planning tasks

### Open Question 2
- Question: How does the verifier-guided step-wise beam search decoding algorithm perform compared to other decoding strategies, such as nucleus sampling or top-k sampling?
- Basis in paper: Inferred
- Why unresolved: The paper introduces a novel verifier-guided step-wise beam search decoding algorithm but does not compare its performance to other decoding strategies. It would be interesting to see how it fares against other popular decoding methods in terms of plan quality and coherence
- What evidence would resolve it: Conduct experiments comparing the verifier-guided step-wise beam search decoding algorithm to other decoding strategies, such as nucleus sampling or top-k sampling, in terms of plan quality, coherence, and efficiency

### Open Question 3
- Question: Can the symbolic procedural knowledge distillation approach be extended to other domains beyond procedural planning, such as question answering or text summarization?
- Basis in paper: Inferred
- Why unresolved: The paper focuses on applying symbolic procedural knowledge distillation to the domain of procedural planning. It would be valuable to explore whether this approach can be generalized to other domains that require reasoning and knowledge integration
- What evidence would resolve it: Conduct experiments applying the symbolic procedural knowledge distillation approach to other domains, such as question answering or text summarization, and evaluate the performance of the distilled models compared to baselines

### Open Question 4
- Question: How does the performance of the distilled models scale with the size of the teacher model and the student model?
- Basis in paper: Explicit
- Why unresolved: The paper explores the impact of scale on distillation performance but does not provide a comprehensive analysis of how the performance scales with the size of both the teacher and student models. It would be valuable to understand the relationship between model sizes and distillation effectiveness
- What evidence would resolve it: Conduct experiments varying the sizes of both the teacher and student models and analyze the performance of the distilled models in terms of plan quality, efficiency, and scalability

### Open Question 5
- Question: Can the verifier-guided step-wise beam search decoding algorithm be further improved by incorporating additional semantic or contextual information?
- Basis in paper: Inferred
- Why unresolved: The paper introduces a verifier-guided step-wise beam search decoding algorithm that relies on a step-wise verifier for validity checks. It would be interesting to explore whether incorporating additional semantic or contextual information, such as the overall plan coherence or the specific constraints of the planning task, could further enhance the decoding process
- What evidence would resolve it: Conduct experiments incorporating additional semantic or contextual information into the verifier-guided step-wise beam search decoding algorithm and evaluate its impact on plan quality, coherence, and task-specific performance

## Limitations

- The effectiveness of the approach heavily depends on the quality of the COPLAN dataset, which is generated from a single large language model (GPT-3) and may have inherent biases
- The paper does not explore how well the approach generalizes to domains outside procedural planning, limiting understanding of its broader applicability
- The relative contribution of each component (knowledge distillation, verifier-guided decoding, multi-task training) to overall performance is not clearly isolated through ablation studies

## Confidence

**High confidence** in the overall effectiveness of the PlaSma framework for improving small model planning capabilities, based on consistent improvements across multiple evaluation metrics and tasks.

**Medium confidence** in the specific mechanisms (knowledge distillation, verifier-guided decoding, multi-task training) as the primary drivers of improvement, due to limited ablation studies and lack of comparison to simpler alternatives.

**Low confidence** in the scalability of the approach to domains outside procedural planning, as the paper focuses exclusively on planning tasks without exploring generalization to other knowledge-intensive domains.

## Next Checks

1. **Ablation study on critic filtering**: Quantify the impact of data filtering quality on student model performance by comparing models trained on filtered vs. unfiltered COPLAN data.

2. **Decoding algorithm comparison**: Isolate the contribution of verifier-guided decoding by comparing plan quality with and without the verifier across multiple decoding methods (beam search, nucleus sampling).

3. **Alternative distillation approaches**: Test whether sequential training on individual tasks achieves similar performance to multi-task training, to validate the claimed benefits of joint optimization.