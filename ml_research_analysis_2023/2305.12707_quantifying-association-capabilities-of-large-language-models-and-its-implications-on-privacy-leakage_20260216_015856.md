---
ver: rpa2
title: Quantifying Association Capabilities of Large Language Models and Its Implications
  on Privacy Leakage
arxiv_id: '2305.12707'
source_url: https://arxiv.org/abs/2305.12707
tags:
- language
- association
- email
- data
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the association capabilities of large language
  models (LLMs) and their implications for privacy leakage, particularly regarding
  personally identifiable information (PII). Using models like GPT-Neo, GPT-J, and
  GPT-NeoX across sizes ranging from 125M to 20B parameters, the research examines
  how well LLMs can associate related entities in both commonsense and PII domains.
---

# Quantifying Association Capabilities of Large Language Models and Its Implications on Privacy Leakage

## Quick Facts
- arXiv ID: 2305.12707
- Source URL: https://arxiv.org/abs/2305.12707
- Reference count: 11
- One-line primary result: Larger language models show stronger association capabilities, with 3% of email addresses and 1% of phone numbers correctly predicted from name prompts, raising privacy concerns.

## Executive Summary
This study investigates how large language models (LLMs) can associate related entities, particularly focusing on privacy implications for personally identifiable information (PII). Using models ranging from 125M to 20B parameters, the research examines association capabilities in both commonsense knowledge and PII domains. The findings reveal that larger models exhibit stronger association capabilities, with prediction accuracy improving when target pairs have shorter co-occurrence distances and higher co-occurrence frequencies. While the proportion of PII that can be associated remains relatively low (approximately 3% for email addresses and 1% for phone numbers with a 20B model), the study underscores the potential risk to PII confidentiality as LLMs continue to scale.

## Method Summary
The study evaluates association capabilities using three model families (GPT-Neo, GPT-J, and GPT-NeoX) across five sizes trained on the Pile dataset. The LAMA dataset (31,161 pairs) provides commonsense knowledge associations, while the Enron Email dataset offers PII associations (3,294 email and 3,113 phone number pairs). Zero-shot prompting with carefully designed templates is used to query associations, and evaluation measures prediction accuracy alongside an Association Easiness Score based on co-occurrence frequency and distance. The methodology examines how factors like model size, co-occurrence distance, and frequency impact association accuracy for both commonsense and PII associations.

## Key Results
- Larger models consistently show stronger association capabilities, with accuracy improving as model size increases
- Shorter co-occurrence distances and higher co-occurrence frequencies lead to better association accuracy, though with diminishing returns beyond certain thresholds
- There is a notable performance gap between associating commonsense knowledge (31,161 pairs) versus PII (3,294 emails, 3,113 phone numbers), with the latter showing lower accuracy
- With a 20B parameter model, approximately 3% of email addresses and 1% of phone numbers are correctly predicted when given appropriate prompts containing owner names

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Larger language models exhibit stronger association capabilities, improving their ability to connect related entities.
- Mechanism: As model size increases, the model's capacity to learn complex patterns and associations from training data improves, leading to better performance in associating related entities.
- Core assumption: Model parameters and training data scale proportionally, allowing larger models to capture more nuanced associations.
- Evidence anchors:
  - [abstract] "as models scale up, their capacity to associate entities/information intensifies"
  - [section 7.1] "Larger Model, Stronger Association. The results consistently show that a larger model yields higher accuracy."
  - [corpus] Weak evidence; only general terms found, no specific citations.

### Mechanism 2
- Claim: Shorter co-occurrence distances between entities in training data lead to better association accuracy.
- Mechanism: When entities appear closer together in text, the model learns stronger associations between them, improving prediction accuracy.
- Core assumption: Proximity in text reflects meaningful relationships that the model can learn to associate.
- Evidence anchors:
  - [abstract] "target pairs demonstrate shorter co-occurrence distances"
  - [section 7.1] "Shorter Distance, Better Association. As depicted in Figure 2, a discernible trend emerges within the LAMA dataset, indicating a positive correlation between accuracy and shorter co-occurrence distance ranges."
  - [corpus] Weak evidence; no specific corpus citations found.

### Mechanism 3
- Claim: Higher co-occurrence frequencies between entities improve association accuracy, but with diminishing returns beyond a threshold.
- Mechanism: Frequent co-occurrence strengthens the learned associations, but excessive frequency may lead to memorization rather than generalization.
- Core assumption: Frequency reflects the strength of the relationship between entities in the training data.
- Evidence anchors:
  - [abstract] "higher co-occurrence frequencies"
  - [section 7.1] "Higher Frequency, Better Association. Figures 4a and 4b both substantiate that an increased co-occurrence frequency in the training data leads to an improvement in prediction accuracy"
  - [corpus] Weak evidence; no specific corpus citations found.

## Foundational Learning

- Concept: Co-occurrence distance and frequency
  - Why needed here: Understanding how entity proximity and repetition in training data affect model associations is crucial for interpreting the results and designing mitigation strategies.
  - Quick check question: If two entities appear 10 characters apart 100 times in training data versus 100 characters apart 100 times, which scenario would likely yield better association accuracy?

- Concept: Differential privacy
  - Why needed here: Differential privacy techniques are mentioned as potential mitigation strategies for PII leakage, so understanding how they work is important for evaluating their effectiveness.
  - Quick check question: How does adding calibrated noise during training help protect privacy while maintaining model utility?

- Concept: Memorization vs. association
  - Why needed here: The paper distinguishes between memorization (verbatim retention) and association (connecting related information), which is key to understanding the privacy risks.
  - Quick check question: What's the difference between a model memorizing an email address verbatim versus associating a name with an email address?

## Architecture Onboarding

- Component map: Data preprocessing -> Model loading -> Prompt engineering -> Prediction generation -> Evaluation calculation -> Analysis
- Critical path: Data → Model → Prompt → Prediction → Evaluation → Analysis
- Design tradeoffs:
  - Model size vs. computational cost: Larger models show better associations but require more resources
  - Prompt specificity vs. generality: More specific prompts may improve accuracy but reduce generalizability
  - Privacy protection vs. utility: Stricter privacy measures may reduce model performance
- Failure signatures:
  - Low association accuracy despite high co-occurrence frequency may indicate data quality issues
  - High accuracy on test data but poor generalization suggests overfitting
  - Inconsistent results across model sizes may point to implementation bugs
- First 3 experiments:
  1. Verify association accuracy scales with model size using LAMA dataset
  2. Test the effect of co-occurrence distance on association accuracy
  3. Evaluate privacy risks by measuring PII prediction accuracy on Enron dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact threshold of co-occurrence frequency and distance beyond which language models' association capabilities no longer improve?
- Basis in paper: [explicit] The paper states that there exists a threshold beyond which it becomes difficult to enhance the accuracy further, and that exponential increases in co-occurrence frequency are required for linear improvements in association capability.
- Why unresolved: The paper mentions that a threshold exists but does not specify the exact numerical values or provide a clear boundary where this plateau effect occurs.
- What evidence would resolve it: Systematic experiments varying co-occurrence frequency and distance parameters across different model sizes to identify the precise point where accuracy gains diminish.

### Open Question 2
- Question: How does the quality and structure of training data (formal vs. informal, structured vs. unstructured) impact the association capabilities of language models?
- Basis in paper: [explicit] The paper highlights a significant performance gap between LAMA (high-quality knowledge sources like Wikipedia) and Enron Email datasets (informal, unstructured conversations), attributing this to training data quality differences.
- Why unresolved: While the paper identifies that training data quality affects association capabilities, it does not quantify how different types of data quality (formal vs. informal, structured vs. unstructured) specifically influence these capabilities or provide concrete metrics for comparison.
- What evidence would resolve it: Comparative studies using multiple datasets with varying degrees of formality and structure, measuring association accuracy and identifying which data characteristics most strongly influence model performance.

### Open Question 3
- Question: What is the relationship between model size and privacy risk in terms of PII association capabilities, and at what point does increasing model size become counterproductive from a privacy standpoint?
- Basis in paper: [explicit] The paper indicates that larger models exhibit stronger association capabilities, which presents increased privacy risks, but notes that exponential increases in model parameters may be required for linear improvements in accuracy.
- Why unresolved: The paper suggests that privacy risks increase with model size but does not establish a clear threshold or tipping point where the privacy costs outweigh the benefits of larger models, nor does it quantify the marginal privacy risk per unit increase in model parameters.
- What evidence would resolve it: Empirical analysis correlating model size with PII association accuracy while measuring the corresponding increase in privacy risk, identifying the point of diminishing returns where additional parameters provide minimal accuracy gains but significantly increase privacy vulnerabilities.

## Limitations
- The study focuses on a narrow slice of PII (email addresses and phone numbers) from a single dataset, limiting generalizability to other PII types
- The distinction between memorization and genuine association remains unclear, as the methodology primarily measures prompt-based predictions
- Results may not generalize across different model architectures beyond the GPT-Neo/J/NoX family trained on the Pile dataset

## Confidence
- Model Size Correlation: High - consistent trend across multiple model sizes with statistical significance
- Co-occurrence Factors Impact: High - clearly demonstrated through experimental data and visual evidence
- PII Association Gap: Medium-High - real gap exists but small sample size of PII pairs introduces uncertainty

## Next Checks
1. Replicate experiments using alternative PII datasets from different domains (medical records, social media) to assess generalizability across varied contexts
2. Evaluate association capabilities using models with different architectures (BERT, T5) and training datasets to determine architecture-agnostic patterns
3. Conduct temporal stability analysis measuring how association capabilities change over time with continued training and data exposure