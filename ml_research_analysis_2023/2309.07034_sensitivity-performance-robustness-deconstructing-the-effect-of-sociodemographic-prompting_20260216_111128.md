---
ver: rpa2
title: 'Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic
  Prompting'
arxiv_id: '2309.07034'
source_url: https://arxiv.org/abs/2309.07034
tags:
- prompting
- sociodemographic
- flan-t5
- tk-instruct
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We study sociodemographic prompting, a technique that aims to guide
  the output of language models by incorporating sociodemographic profiles of annotators.
  Through a comprehensive evaluation across seven datasets and six instruction-tuned
  model families, we demonstrate that sociodemographic prompting can improve zero-shot
  performance for subjective NLP tasks, but is not robust to prompt formulation changes
  and should not be used as a direct proxy for human annotation.
---

# Sensitivity, Performance, Robustness: Deconstructing the Effect of Sociodemographic Prompting

## Quick Facts
- arXiv ID: 2309.07034
- Source URL: https://arxiv.org/abs/2309.07034
- Reference count: 40
- Primary result: Sociodemographic prompting improves zero-shot performance for subjective NLP tasks but is not robust to prompt formulation changes.

## Executive Summary
This paper investigates sociodemographic prompting, a technique that guides language model outputs by incorporating sociodemographic profiles of annotators. Through comprehensive evaluation across seven datasets and six instruction-tuned model families, the authors demonstrate that while this approach can improve performance on subjective NLP tasks, it suffers from significant limitations. The technique shows inconsistent results across different models and datasets, and is particularly sensitive to how prompts are formulated. The study reveals that sociodemographic prompting should not be used as a direct proxy for human annotation but can effectively identify ambiguous instances likely to cause annotator disagreement.

## Method Summary
The study evaluates sociodemographic prompting across seven datasets spanning four subjective NLP tasks: toxicity detection, stance detection, hatespeech detection, and sentiment classification. Six instruction-tuned model families (GPT-3, T5 variants, OPT, and Pythia) are used in zero-shot prompting scenarios with and without sociodemographic information. The researchers implement three prompt formulations (standard, paraphrased, minimal) to assess robustness. Performance is evaluated using accuracy, F1, cross-entropy, and Jensen-Shannon divergence metrics. Statistical analysis employs generalized linear mixed models to account for fixed and random effects across datasets and model types. The approach involves data preprocessing, prompt generation with sociodemographic profiles, model inference, prediction aggregation, and evaluation against ground truth or original annotations.

## Key Results
- Sociodemographic prompting improves zero-shot performance for subjective NLP tasks, with prediction changes ranging from 5% to 20% across model families
- Prompt formulation significantly affects outcomes, with prediction differences up to 35% even for semantically equivalent formats
- The technique effectively identifies ambiguous instances likely to cause annotator disagreement, though best-performing zero-shot models are not necessarily the best at modeling disagreement
- Results show large variance across different model types, sizes, and datasets

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Sociodemographic prompting changes model predictions by aligning them with the expected views of a specified demographic group.
- **Mechanism**: The prompt includes sociodemographic attributes (e.g., gender, age, race, education, political affiliation) that guide the LLM to simulate the perspective of an individual with those characteristics. This changes the internal reasoning path the model uses to arrive at a label.
- **Core assumption**: LLMs have learned associations between sociodemographic attributes and subjective viewpoints during pretraining, allowing them to simulate demographic-specific perspectives when prompted.
- **Evidence anchors**: [abstract] "sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give." [section] "Our results show that sociodemographic prompting improves zero-shot performance for subjective NLP tasks..." [corpus] "Average neighbor FMR=0.407" - indicates moderate relatedness to existing work on demographic prompting
- **Break condition**: If the LLM has not been exposed to sufficient demographic-attribute-to-opinion mappings during pretraining, or if the sociodemographic attributes are not relevant to the task at hand, the prompting will have minimal or no effect.

### Mechanism 2
- **Claim**: The effect of sociodemographic prompting is not robust to prompt formulation changes.
- **Mechanism**: Even semantically equivalent prompt formulations can lead to drastically different model outputs. This brittleness arises because LLMs interpret surface-level linguistic patterns differently than humans understand semantic meaning.
- **Core assumption**: The model's understanding of a prompt differs from its semantic meaning, as previously demonstrated in literature.
- **Evidence anchors**: [abstract] "its outcomes largely vary for different model types, sizes, and datasets, and are subject to large variance with regards to prompt formulations." [section] "Table 5 presents the percentage of prediction differences between the different formats across datasets and models. Even for semantically equivalent formats (0,1) prediction differences can rise up to 35%." [corpus] "One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization" - directly related to prompt formulation effects
- **Break condition**: If prompt formulation effects are properly controlled or if the model is specifically fine-tuned to be robust to surface-level variations in sociodemographic prompts.

### Mechanism 3
- **Claim**: Sociodemographic prompting can identify ambiguous instances that are likely to cause disagreement among human annotators.
- **Mechanism**: When sociodemographic prompting produces varying outputs across different demographic profiles for the same instance, it indicates that the instance is ambiguous and likely to generate disagreement in human annotation. This allows for targeted annotation efforts.
- **Core assumption**: Disagreement in human annotations correlates with the variation in model outputs when prompted with different sociodemographic profiles.
- **Evidence anchors**: [abstract] "our results show that sociodemographic prompting is effective at identifying instances which annotators disagree upon, thereby showcasing this technique as a viable tool during annotation projects." [section] "True positives are instances which received disagreement in both setups... Figure 4. Surprisingly, the best-performing zero-shot models... are not the best at modeling the disagreement." [corpus] "Stop! In the Name of Flaws: Disentangling Personal Names and Sociodemographic Attributes in NLP" - related to sociodemographic attributes in NLP
- **Break condition**: If the relationship between model disagreement patterns and human annotation disagreement is not stable across tasks or datasets, or if sociodemographic attributes are not predictive of human disagreement patterns.

## Foundational Learning

- **Concept**: Subjective NLP tasks and inter-annotator agreement
  - Why needed here: The paper focuses on subjective tasks (toxicity detection, sentiment analysis, etc.) where annotator backgrounds significantly influence decisions. Understanding that these tasks have inherent disagreement is crucial for interpreting the results.
  - Quick check question: What is inter-annotator agreement and why is it particularly relevant for subjective NLP tasks like toxicity detection?

- **Concept**: Prompt engineering and few-shot learning with LLMs
  - Why needed here: The study uses prompting techniques to guide LLM outputs. Understanding how prompt formulation affects model behavior is essential for interpreting the robustness findings.
  - Quick check question: How does prompt formulation affect the outputs of large language models in zero-shot learning scenarios?

- **Concept**: Generalized linear mixed models (GLMMs) for statistical analysis
  - Why needed here: The paper uses GLMMs to account for various fixed and random effects while analyzing the sensitivity and performance of different models. Understanding this statistical approach is important for interpreting the significance of the findings.
  - Quick check question: What is the purpose of using generalized linear mixed models in analyzing the effects of sociodemographic prompting across different datasets and model types?

## Architecture Onboarding

- **Component map**: Datasets (DP, Jigsaw, GHC, H-Twitter, SE2016, GWSD, Diaz) -> Preprocessing (filtering, sampling 1,000 instances) -> Prompt generation (with sociodemographic profiles) -> Model inference (GPT-3, T5, OPT, Pythia variants) -> Prediction aggregation (majority voting, likelihood scoring) -> Evaluation (accuracy, F1, cross-entropy, JS divergence) -> Statistical analysis (GLMMs)

- **Critical path**: Data preprocessing → Prompt generation with sociodemographic profiles → Model inference using zero-shot prompting → Aggregation of predictions → Evaluation against ground truth or original annotations → Statistical analysis using GLMMs

- **Design tradeoffs**: Using sociodemographic prompting trades off potential performance gains in subjective tasks against lack of robustness to prompt formulation and inability to reliably proxy human annotation. The approach requires careful dataset selection and attribute alignment across different annotation schemas.

- **Failure signatures**: Poor performance on tasks with high inter-annotator agreement, large prediction changes when prompt formulation is slightly modified, inconsistent effects across model families and sizes, inability to accurately predict individual annotator responses even when sociodemographic information is provided.

- **First 3 experiments**:
  1. Test prediction changes when prompting with sociodemographic profiles vs. standard prompting on a small subset of DP dataset across multiple model families
  2. Compare zero-shot performance using sociodemographic prompting vs. standard prompting on Jigsaw dataset, measuring both hard and soft evaluation metrics
  3. Evaluate robustness by comparing predictions across three different prompt formulations (standard, paraphrased, minimal) for the same sociodemographic profile on H-Twitter dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the sensitivity of LLMs to sociodemographic prompting change when using more complex or nuanced sociodemographic attributes (e.g., intersectional identities, lived experiences)?
- Basis in paper: [inferred] The paper shows that using individual sociodemographic attributes leads to varying degrees of prediction changes, but does not explore more complex or nuanced attributes.
- Why unresolved: The study focused on a limited set of sociodemographic attributes due to data availability and complexity concerns.
- What evidence would resolve it: Experiments comparing prediction changes using simple versus complex sociodemographic attributes, and measuring the impact on model performance.

### Open Question 2
- Question: Is there a correlation between the size of the dataset used for instruction-tuning and the model's sensitivity to sociodemographic prompting?
- Basis in paper: [inferred] The paper shows that larger models are more sensitive to sociodemographic prompting, but does not explore the relationship with the size of the instruction-tuning dataset.
- Why unresolved: The study did not investigate the impact of the instruction-tuning dataset size on model sensitivity.
- What evidence would resolve it: Experiments comparing the sensitivity of models trained on datasets of different sizes to sociodemographic prompting.

### Open Question 3
- Question: How does the performance of sociodemographic prompting compare to other methods for modeling annotator disagreement, such as multi-task learning or conditional modeling?
- Basis in paper: [explicit] The paper shows that sociodemographic prompting can improve zero-shot performance for subjective NLP tasks, but does not compare it to other methods for modeling annotator disagreement.
- Why unresolved: The study focused on evaluating sociodemographic prompting in isolation and did not benchmark it against other approaches.
- What evidence would resolve it: Experiments comparing the performance of sociodemographic prompting to other methods for modeling annotator disagreement on the same tasks and datasets.

## Limitations

- The study only tests three specific prompt formulations, limiting generalizability of robustness findings to other prompt variations
- Adopted sociodemographic profiles for datasets without original annotator data may introduce systematic biases affecting cross-dataset comparisons
- Relatively small sample size (1,000 instances per dataset after filtering) may limit statistical power for detecting subtle effects

## Confidence

**High Confidence**: The finding that sociodemographic prompting improves zero-shot performance for subjective NLP tasks is well-supported by the empirical results across seven datasets and six model families. The statistical analysis using GLMMs provides robust evidence for this core claim.

**Medium Confidence**: The observation that sociodemographic prompting is not robust to prompt formulation changes is demonstrated convincingly within the tested formulations, but the extent to which this brittleness generalizes to other prompt variations remains uncertain. Similarly, the effectiveness of sociodemographic prompting for identifying ambiguous instances shows promise but requires further validation across more diverse task types.

**Low Confidence**: The comparative analysis of different model families' sensitivity to sociodemographic prompting has limitations due to the relatively small sample sizes and the fact that adopted sociodemographic profiles may not accurately reflect the true distribution of annotator characteristics across datasets.

## Next Checks

1. **Prompt Formulation Robustness Expansion**: Test the sensitivity to prompt formulation using a broader range of variations including paraphrased prompts, prompts with different syntactic structures, and prompts with varying levels of sociodemographic detail to determine whether the observed brittleness is specific to the tested formulations or represents a more general phenomenon.

2. **Cross-Dataset Sociodemographic Alignment**: Conduct a validation study to assess the accuracy of adopted sociodemographic profiles by comparing model predictions using adopted profiles versus predictions using original annotator data where available, to quantify the potential bias introduced by profile adoption.

3. **Sample Size Sensitivity Analysis**: Replicate the core analyses using progressively larger sample sizes (2,000, 5,000, and full dataset sizes where feasible) to determine whether the observed effects and relationships stabilize with increased statistical power, particularly for the model family comparisons and disagreement prediction analyses.