---
ver: rpa2
title: Enhancing Actuarial Non-Life Pricing Models via Transformers
arxiv_id: '2311.07597'
source_url: https://arxiv.org/abs/2311.07597
tags:
- transformer
- here
- uthrich
- actuarial
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores how transformer models can enhance traditional
  actuarial pricing models for non-life insurance. It introduces three novel approaches
  that combine generalized linear models (GLMs) with transformer architectures: the
  Combined Actuarial Feature Tokenizer Transformer (CAFTT), LocalGLM-Feature-Tokenizer-Transformer
  (LocalGLMftt), and their ensemble variants.'
---

# Enhancing Actuarial Non-Life Pricing Models via Transformers

## Quick Facts
- arXiv ID: 2311.07597
- Source URL: https://arxiv.org/abs/2311.07597
- Reference count: 10
- Key outcome: Transformer-based actuarial models outperform traditional GLMs while maintaining interpretability

## Executive Summary
This paper introduces transformer-based approaches to enhance traditional actuarial pricing models for non-life insurance. The authors propose three novel architectures that combine generalized linear models (GLMs) with transformer components: CAFTT, LocalGLMftt, and their ensemble variants. These methods leverage the interpretability and data preprocessing advantages of GLMs while incorporating the predictive power of transformers for handling complex feature interactions. The models are evaluated on a French motor insurance dataset and demonstrate superior performance compared to traditional GLMs and neural network baselines, with ensembles achieving the best results. The study shows that transformers can effectively enhance actuarial pricing models while maintaining compatibility with existing industry workflows and interpretability requirements.

## Method Summary
The paper introduces three transformer-based actuarial pricing approaches: CAFTT (Combined Actuarial Feature Tokenizer Transformer) extends GLMs by adding transformer output as an additional term to the linear predictor; LocalGLMftt uses transformer-based β(x) for feature-specific adjustments; and ensemble variants combine multiple models trained with different random seeds. The Feature Tokenizer converts both categorical and numerical features into embeddings suitable for transformer processing, eliminating the need for one-hot encoding. Models are trained using AdamW optimizer with early stopping on Poisson deviance loss, and evaluated against GLMs, FNNs, CANNs, LocalGLMnet, and pure FTT baselines.

## Key Results
- Transformer-based actuarial models (CAFTT and LocalGLMftt) outperform traditional GLMs and neural network baselines on Poisson deviance loss
- Ensembles of 5 transformer models achieve performance comparable to single models with tuned hyperparameters, reducing computational cost
- The models maintain GLM interpretability while adding nonlinear feature representation through transformer components
- Feature Tokenizer enables handling of both categorical and numerical features through learned embeddings without one-hot encoding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CAFTT and LocalGLMftt improve predictive power by combining the linear interpretability of GLMs with the nonlinear feature representation of transformers.
- Mechanism: The model takes the GLM's linear predictor as a starting point and adds a transformer's output as an additional term. The transformer learns complex interactions and nonlinearities while the GLM component preserves interpretability and industry-standard preprocessing.
- Core assumption: The GLM component captures the majority of explainable variance, and the transformer adds meaningful residual improvements without overfitting.
- Evidence anchors:
  - [abstract] states that the methods "achieve better results than the benchmark models while preserving certain generalized linear model advantages"
  - [section 3.6] describes CAFTT as an extension of GLM where the transformer "enhances the GLM prediction further by the nonlinear features representation"
  - [section 3.7] explains LocalGLMftt similarly but uses transformer-based β(x) for feature-specific adjustments
- Break condition: If the GLM component is poorly specified or the transformer overfits, the combined model may underperform both individual components.

### Mechanism 2
- Claim: The transformer component can handle both categorical and numerical features through learned embeddings, eliminating the need for one-hot encoding.
- Mechanism: Feature Tokenizer Transformer (FTT) converts each feature into embeddings of fixed length. Categorical features use lookup tables, while numerical features use learned mappings. This preserves the original feature structure while enabling transformer processing.
- Core assumption: Learned embeddings capture more meaningful relationships than traditional encoding methods, especially for numerical features where binning or scaling may lose information.
- Evidence anchors:
  - [section 3.5] describes how FTT embeds "both categorical and numerical features" and notes that "it is very popular in insurance to use bins for numerical features and add numerical features this way as categorical ones"
  - [section 4.2] states that transformer models use "the same numerical feature preprocessing as in the LocalGLMnet case but since we are applying a categorical embedding, we don't need a one hot encoding"
- Break condition: If embeddings are poorly initialized or the embedding dimension is too small, the transformer may fail to capture important feature relationships.

### Mechanism 3
- Claim: Ensemble averaging of multiple transformer models with default hyperparameters achieves performance comparable to single models with tuned hyperparameters, reducing computational cost.
- Mechanism: Multiple models trained with different random seeds and validation splits create diverse predictions. Averaging these predictions reduces variance while maintaining the benefits of transformer architecture.
- Core assumption: Model diversity from different training runs captures different aspects of the data distribution, and averaging provides robust predictions without extensive hyperparameter search.
- Evidence anchors:
  - [section 4.2] states that "an ensemble of 5 FTTdef models delivers very similar results as a single hyperparameter-tuned model" and cites Gorishniy et al (2021) showing this relationship
  - [section 4.3] demonstrates that ensembles of transformer models achieve better performance than single models
- Break condition: If models are too similar (e.g., same random seed) or if overfitting is severe across models, ensemble averaging may not provide benefits.

## Foundational Learning

- Concept: Generalized Linear Models (GLMs) and their extensions
  - Why needed here: The entire architecture builds upon GLM foundations, using GLM coefficients as starting points and maintaining interpretability
  - Quick check question: What is the canonical link function for Poisson regression and why is it commonly used?

- Concept: Transformer architectures and attention mechanisms
  - Why needed here: The transformer component processes tabular features through self-attention, requiring understanding of multi-head attention and positional encoding
  - Quick check question: How does the Feature Tokenizer convert categorical and numerical features into embeddings suitable for transformer processing?

- Concept: Poisson regression and deviance loss
  - Why needed here: The models predict claim frequency using Poisson regression, and performance is evaluated using Poisson deviance loss
  - Quick check question: What property makes Poisson deviance loss appropriate for evaluating insurance claim frequency models?

## Architecture Onboarding

- Component map: Raw features -> Feature Tokenizer -> Transformer blocks -> Linear predictor combination -> Output activation
- Critical path: Feature preprocessing → Embedding generation → Transformer processing → Linear predictor combination → Output activation
- Design tradeoffs:
  - Embedding dimension vs. model complexity: Larger embeddings capture more information but increase parameters and training time
  - Number of transformer blocks vs. performance: More blocks may improve performance but risk overfitting and increase computation
  - Ensemble size vs. resource usage: Larger ensembles improve robustness but require more memory and training time
- Failure signatures:
  - Poor performance despite long training: Likely overfitting or improper initialization
  - Large gap between train and test loss: Overfitting, especially with transformer components
  - Mean predictions far from true values: Need for rebalancing or calibration
- First 3 experiments:
  1. Train a simple GLM with basic feature engineering to establish baseline performance
  2. Implement CAFTT with default hyperparameters and compare to GLM performance
  3. Create a 5-model ensemble of CAFTT and evaluate improvement over single model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do transformer-based actuarial models perform on other types of insurance pricing problems beyond motor third-party liability claims frequency, such as claim severity prediction or demand modeling?
- Basis in paper: [explicit] The paper focuses specifically on claims frequency prediction and mentions that there are typically three types of problems in non-life insurance pricing but only addresses one of them
- Why unresolved: The study only evaluated transformer models on a claims frequency dataset, leaving performance on other pricing problems unexplored
- What evidence would resolve it: Empirical comparisons of transformer models on claim severity and demand modeling datasets, with performance metrics compared to traditional GLMs

### Open Question 2
- Question: What are the optimal embedding strategies for numerical features in transformer models for actuarial applications, particularly when dealing with features that have different distributions or require domain-specific transformations?
- Basis in paper: [explicit] The paper notes that numerical feature embedding can significantly impact model performance and mentions several embedding strategies but does not explore which are optimal for insurance data
- Why unresolved: The study used default embedding settings rather than exploring different numerical embedding techniques or their impact on model performance
- What evidence would resolve it: Systematic comparison of different numerical embedding methods (quantiles, target-aware bins, periodic activations) on insurance datasets with varying feature characteristics

### Open Question 3
- Question: How can transformer-based actuarial models be adapted to maintain time consistency and handle temporal effects that are crucial in insurance modeling?
- Basis in paper: [explicit] The discussion section explicitly mentions that time consistency is a critical concern for actuaries and that machine learning models need to address this limitation
- Why unresolved: The paper does not propose or test any methods for incorporating temporal stability into transformer architectures or handling year-specific effects
- What evidence would resolve it: Development and evaluation of transformer architectures with built-in temporal regularization or time-aware attention mechanisms on multi-year insurance datasets

## Limitations

- Evaluation limited to a single dataset (French motor insurance) which may not generalize to other insurance domains or regions
- Minimal hyperparameter tuning with default settings used for many components, potentially leaving performance gains unrealized
- Interpretability benefits of maintaining GLM components are asserted but not rigorously quantified or demonstrated

## Confidence

- **High confidence**: The core mechanism of combining GLMs with transformers through additive enhancement is well-supported by the mathematical framework and empirical results
- **Medium confidence**: The assertion that ensembles achieve comparable performance to hyperparameter-tuned models relies on external literature and may not hold across all problem domains
- **Low confidence**: The generalization of results to other insurance domains, severity modeling, or different geographic regions is not established

## Next Checks

1. **Cross-domain validation**: Evaluate the proposed transformer-based models on additional insurance datasets (e.g., property insurance, health insurance, or data from different countries) to assess generalizability beyond the French motor insurance domain.

2. **Hyperparameter optimization study**: Conduct a systematic hyperparameter search for the transformer components (embedding dimensions, number of attention heads, transformer layers) to determine if the default settings are optimal or if performance can be significantly improved.

3. **Interpretability analysis**: Quantify the interpretability benefits by comparing feature importance analysis, partial dependence plots, or other interpretable methods between pure transformer models and the hybrid GLM-transformer approaches to validate the claimed advantages of maintaining GLM components.