---
ver: rpa2
title: 'FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things'
arxiv_id: '2310.00109'
source_url: https://arxiv.org/abs/2310.00109
tags:
- data
- dataset
- training
- learning
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FedAIoT, the first federated learning (FL)
  benchmark specifically designed for Artificial Intelligence of Things (AIoT). FedAIoT
  includes eight datasets collected from diverse IoT devices covering modalities like
  wireless signals, drone images, and smart home sensor data.
---

# FedAIoT: A Federated Learning Benchmark for Artificial Intelligence of Things

## Quick Facts
- arXiv ID: 2310.00109
- Source URL: https://arxiv.org/abs/2310.00109
- Reference count: 28
- Primary result: First federated learning benchmark specifically for IoT applications with eight diverse datasets and unified end-to-end framework

## Executive Summary
FedAIoT introduces the first federated learning benchmark tailored for Artificial Intelligence of Things (AIoT) applications. The benchmark includes eight diverse IoT datasets collected from authentic devices like smartwatches, drones, and smart home sensors, covering modalities such as wireless signals, drone images, and sensor data. FedAIoT provides a unified end-to-end framework that addresses IoT-specific challenges including non-IID data partitioning, resource-efficient model selection, and quantization techniques. The evaluation reveals that data heterogeneity significantly impacts certain IoT modalities, noisy labels severely degrade accuracy on some datasets, and FP16 quantization reduces memory usage by 57-63% with minimal accuracy loss.

## Method Summary
FedAIoT provides an end-to-end federated learning framework for AIoT applications. The method involves IoT-specific preprocessing for each dataset (normalization, spectrogram extraction, sliding windows), non-IID data partitioning using Dirichlet allocation, and resource-efficient model selection (LSTM, ResNet18, YOLOv8n, BiLSTM, MLP). The framework supports various FL configurations including different client sampling ratios, noisy label simulation using probabilistic confusion matrices, and quantization (FP16). Experiments evaluate overall accuracy, data heterogeneity impacts, label noise effects, and quantization performance across all eight datasets.

## Key Results
- Data heterogeneity significantly impacts model performance, particularly for UT-HAR, AEP, and EPIC-SOUNDS datasets
- Noisy labels severely degrade federated learning accuracy on certain datasets
- FP16 quantization reduces memory usage by 57-63% with minimal accuracy loss, critical for resource-constrained IoT devices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data heterogeneity level strongly impacts model performance in federated learning for IoT.
- Mechanism: Non-IID data distribution across clients causes model drift; models trained on heterogeneous data partitions cannot generalize as well across the full data distribution.
- Core assumption: Clients in IoT settings have naturally heterogeneous data due to different usage patterns, environments, and sensor conditions.
- Evidence anchors:
  - [abstract] "Results show that data heterogeneity significantly impacts some IoT modalities"
  - [section] "Data heterogeneity level and FL optimizer have different impacts on different datasets...UT-HAR, AEP, and EPIC-SOUNDS is very sensitive to the data heterogeneity level"
  - [corpus] Weak evidence; corpus neighbors do not discuss data heterogeneity impacts specifically.
- Break condition: If IoT devices generate identically distributed data or if local adaptation mechanisms compensate for heterogeneity.

### Mechanism 2
- Claim: Noisy labels severely degrade federated learning accuracy in IoT applications.
- Mechanism: Label noise propagates through federated averaging, corrupting the global model updates and preventing convergence to a good solution.
- Core assumption: IoT sensor data collection often involves manual labeling with errors, and federated learning amplifies these errors across clients.
- Evidence anchors:
  - [abstract] "noisy labels severely degrade accuracy on certain datasets"
  - [section] "we examine the impact of noisy labels...noisy labels severely degrade federated learning accuracy on certain datasets"
  - [corpus] Weak evidence; corpus neighbors do not address label noise in federated learning.
- Break condition: If noise-resilient training techniques (e.g., robust loss functions, label correction) are applied.

### Mechanism 3
- Claim: Quantized training reduces memory usage significantly with minimal accuracy loss, enabling FL on resource-constrained IoT devices.
- Mechanism: FP16 precision reduces model parameter size by half and speeds up computation, allowing larger models or more frequent updates on devices with limited memory.
- Core assumption: IoT devices have strict memory constraints that prevent full-precision training, but modern hardware supports efficient FP16 operations.
- Evidence anchors:
  - [abstract] "Quantized training (FP16) reduces memory usage by 57-63% with minimal accuracy loss"
  - [section] "Table 7 highlights the need for quantized training given the limited RAM resources on representative IoT devices"
  - [corpus] Weak evidence; corpus neighbors do not discuss quantization effects in federated learning.
- Break condition: If FP16 introduces numerical instability or if device hardware does not support efficient FP16 operations.

## Foundational Learning

- Concept: Federated learning basics
  - Why needed here: Understanding how local model training and global aggregation work is essential to grasp why data heterogeneity and quantization matter.
  - Quick check question: What happens to the global model if one client's data distribution is very different from others?

- Concept: Non-IID data partitioning
  - Why needed here: FedAIoT's benchmark relies on creating realistic non-IID partitions; understanding Dirichlet allocation and quantile binning is key to interpreting results.
  - Quick check question: How does the α parameter in Dirichlet allocation affect the similarity of data distributions across clients?

- Concept: Model quantization and precision
  - Why needed here: Quantized training is a core technique in FedAIoT for enabling FL on IoT devices; knowing how FP16 works helps explain memory savings and accuracy trade-offs.
  - Quick check question: Why might batch normalization layers be problematic when using FP16 precision?

## Architecture Onboarding

- Component map: Datasets -> Preprocessing pipeline -> Non-IID partitioning -> Model training -> FL aggregation -> Evaluation
- Critical path:
  1. Load dataset → apply preprocessing → partition non-IID → train local model → aggregate globally → evaluate
- Design tradeoffs:
  - Model complexity vs. device memory: Simpler models fit constrained devices but may underfit
  - Communication cost vs. accuracy: More frequent aggregation improves accuracy but increases bandwidth
  - Label noise simulation vs. realism: Probabilistic confusion matrix vs. uniform noise
- Failure signatures:
  - High variance across clients: Indicates severe data heterogeneity or poor aggregation
  - Accuracy collapse with label noise: Suggests lack of noise resilience in model or training
  - Memory errors during FP16 training: Points to unsupported operations or numerical instability
- First 3 experiments:
  1. Run centralized training on a single dataset to establish baseline accuracy.
  2. Apply non-IID partitioning with varying α and observe accuracy degradation.
  3. Enable FP16 quantization and measure memory usage and accuracy impact.

## Open Questions the Paper Calls Out
- How does the proposed noisy label scheme compare to uniform label error distributions in terms of FL convergence and final accuracy across different IoT modalities?
- What is the optimal client sampling ratio that balances model performance with resource consumption across different IoT modalities?
- How do different quantization levels (beyond FP16) affect FL performance and memory usage on various IoT devices?

## Limitations
- Benchmark focuses on supervised FL scenarios and does not address unsupervised or semi-supervised approaches for IoT applications.
- Label noise simulation uses a probabilistic confusion matrix rather than real-world noisy label distributions.
- Quantization evaluation is limited to FP16 precision; impact of other quantization strategies remains unexplored.

## Confidence
- **High Confidence**: The core contribution of providing the first federated learning benchmark specifically for IoT applications with eight diverse datasets.
- **Medium Confidence**: The empirical findings regarding data heterogeneity impacts and quantization benefits, given the controlled experimental conditions.
- **Low Confidence**: The generalizability of results to all IoT scenarios, as the benchmark covers a specific set of device types and use cases.

## Next Checks
1. Evaluate FedAIoT performance on additional IoT datasets beyond the eight provided to assess generalizability across different sensor modalities and applications.
2. Implement and compare alternative label noise models (e.g., real-world crowdsourced labeling errors) against the current probabilistic confusion matrix approach.
3. Extend quantization experiments to include INT8 and mixed precision training to determine if similar memory savings and accuracy trade-offs exist.