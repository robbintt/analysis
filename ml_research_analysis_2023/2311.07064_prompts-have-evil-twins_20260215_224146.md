---
ver: rpa2
title: Prompts have evil twins
arxiv_id: '2311.07064'
source_url: https://arxiv.org/abs/2311.07064
tags:
- warm
- propane
- gpt-4
- start
- prune
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces PROPANE, a method for automatically optimizing
  natural language prompts to induce desired behaviors in large language models (LLMs).
  The core idea is to treat prompt design as an inverse problem: given example documents
  generated by an unknown ground-truth prompt, PROPANE seeks to reconstruct a prompt
  that leads to statistically similar outputs by minimizing the KL divergence between
  the prompt-induced distributions.'
---

# Prompts have evil twins

## Quick Facts
- arXiv ID: 2311.07064
- Source URL: https://arxiv.org/abs/2311.07064
- Reference count: 40
- Primary result: PROPANE automatically optimizes natural language prompts to induce desired behaviors in LLMs, discovering obfuscated prompts that are unintelligible to humans but functionally equivalent to ground truth prompts

## Executive Summary
This paper introduces PROPANE, a method for automatically optimizing natural language prompts to induce desired behaviors in large language models (LLMs). The core idea is to treat prompt design as an inverse problem: given example documents generated by an unknown ground-truth prompt, PROPANE seeks to reconstruct a prompt that leads to statistically similar outputs by minimizing the KL divergence between the prompt-induced distributions. The authors formalize this as a maximum-likelihood optimization problem and solve it using discrete optimization techniques adapted from adversarial attack literature.

The primary findings are that PROPANE can both improve existing prompts (outperforming GPT-4-suggested prompts) and discover obfuscated prompts that are unintelligible to humans but functionally equivalent to the ground truth. Remarkably, these obfuscated prompts transfer between models of different sizes in the Pythia suite and appear more resilient to token reordering than natural prompts, suggesting they may contain task-specific "special tokens."

## Method Summary
PROPANE treats prompt design as an inverse problem, reconstructing prompts that induce statistically similar outputs to unknown ground-truth prompts. The method minimizes KL divergence between output distributions using the Greedy Coordinate Gradient (GCG) algorithm for discrete optimization over token sequences. Given example documents from a ground-truth prompt, PROPANE either initializes randomly or uses GPT-4 suggestions, then iteratively edits tokens to minimize the divergence. The approach frames prompt reconstruction as maximum likelihood estimation, where the goal is to find the prompt under which the observed documents are most likely to have been generated.

## Key Results
- PROPANE can outperform prompts suggested by GPT-4 in terms of inducing the ground truth distribution
- PROPANE discovers obfuscated prompts that are unintelligible to humans but functionally equivalent to ground truth prompts
- These obfuscated prompts transfer between models of different sizes and appear more resilient to token reordering than natural prompts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PROPANE reconstructs prompts by minimizing the KL divergence between the ground-truth prompt distribution and the reconstructed prompt distribution, which corresponds to a maximum likelihood estimation problem.
- Mechanism: The KL divergence measures how much the distribution of outputs from the reconstructed prompt diverges from the distribution of outputs from the unknown ground-truth prompt. By minimizing this divergence, PROPANE finds a prompt that induces statistically similar outputs to the ground truth. The authors formalize this as a maximum-likelihood optimization problem: find the prompt under which the example documents are most likely to have been drawn.
- Core assumption: The statistical similarity measured by KL divergence captures the functional equivalence between prompts. If two prompts induce similar output distributions, they are functionally equivalent in guiding the LLM.
- Evidence anchors:
  - [abstract] "We wish to reconstruct a prompt which leads to statistically-similar behavior in the LLM as the ground-truth prompt... we seek a prompt p that minimizes the Kullback-Leibler (KL) divergence between the reconstructed and ground-truth prompts."
  - [section] "We wish to reconstruct a prompt which leads to statistically-similar behavior in the LLM as the ground-truth prompt... we seek a prompt p that minimizes the Kullback-Leibler (KL) divergence between the reconstructed and ground-truth prompts."
- Break condition: If the ground-truth prompt distribution is multimodal or has complex structure that cannot be captured by a single prompt, minimizing KL divergence might converge to a suboptimal solution that averages behaviors rather than capturing distinct modes.

### Mechanism 2
- Claim: PROPANE can find obfuscated prompts that transfer between models of different sizes, suggesting these prompts contain task-specific "special tokens" whose mere co-occurrence drives model output.
- Mechanism: The optimization process discovers prompts that, while unintelligible to humans, contain specific token combinations that are highly effective at inducing desired behaviors in the LLM. These token combinations appear to be less sensitive to token order and more transferable across model sizes than natural prompts. The authors conjecture that PROPANE prompts may contain a small number of "special tokens" whose mere co-occurrence drives the model output.
- Core assumption: The LLM's internal representation and processing of tokens is fundamentally different from human interpretation. Tokens that appear random or irrelevant to humans can have specific semantic meaning or trigger specific behaviors in the model.
- Evidence anchors:
  - [abstract] "We further demonstrate that PROPANE can be used to (a) improve existing prompts, and (b) discover semantically obfuscated prompts that transfer between models."
  - [section] "We find that PROPANE can return non-interpretable prompts that are functionally similar to the ground truth... these 'obfuscated' prompts transfer between models... PROPANE prompts appear to be less impacted by the order of tokens than ground-truth prompts."
- Break condition: If the model's tokenization or embedding space changes significantly between versions, the special tokens discovered by PROPANE for one model may not transfer effectively to another model, breaking the transferability property.

### Mechanism 3
- Claim: PROPANE improves upon prompts suggested by GPT-4 by finding prompts that induce more similar output distributions to the ground truth.
- Mechanism: While GPT-4 can suggest prompts that seem reasonable to humans, PROPANE optimizes the prompt based on the actual output distribution it induces in the target LLM. This data-driven optimization can find prompts that are more effective than those suggested by another LLM, even one as capable as GPT-4. The authors find that PROPANE can outperform prompts suggested by GPT-4 in terms of inducing the ground truth distribution.
- Core assumption: The effectiveness of a prompt is determined by the distribution of outputs it induces in the target LLM, not by how reasonable it appears to humans or other LLMs. An LLM can be optimized to find prompts that are more effective for a specific task and model than prompts suggested by general-purpose LLMs.
- Evidence anchors:
  - [abstract] "Given a set of documents for an unknown ground truth prompt, we query GPT-4... We find that PROPANE can outperform prompts suggested by GPT-4 in terms of inducing the ground truth distribution."
  - [section] "We benchmark against the reconstruction ability of commercial LLMs. We provide GPT-4 with our training corpus... and ask it to provide an example prompt that could have generated the corpus. We then compute the KL divergence with respect to our original prompt. This method performs roughly on par with GCG from a cold start... We combine both methods, by warm-starting GCG with the suggested prompt from GPT-4. This provides a strong improvement over both the standard cold-start GCG and the GPT-4 prompt suggestion."
- Break condition: If the target LLM's output distribution is highly sensitive to small changes in prompt wording, the optimization process might become unstable or converge to local minima that don't generalize well.

## Foundational Learning

- Concept: Kullback-Leibler (KL) divergence as a measure of statistical distance between probability distributions
  - Why needed here: The core optimization objective in PROPANE is to minimize the KL divergence between the ground-truth prompt distribution and the reconstructed prompt distribution. Understanding KL divergence is essential to grasp why this optimization problem corresponds to maximum likelihood estimation.
  - Quick check question: If two prompts induce identical output distributions in an LLM, what is the KL divergence between them?

- Concept: Maximum likelihood estimation (MLE) in statistics
  - Why needed here: The authors frame prompt reconstruction as a maximum likelihood problem, where the goal is to find the prompt under which the observed example documents are most likely to have been generated. This statistical framing justifies the use of KL divergence as the optimization objective.
  - Quick check question: In the context of PROPANE, what is the relationship between minimizing KL divergence and maximizing the likelihood of the example documents under the reconstructed prompt?

- Concept: Discrete optimization techniques for prompt engineering
  - Why needed here: Prompts are strings of tokens, making the optimization problem discrete rather than continuous. PROPANE adapts techniques from adversarial attack literature, specifically the Greedy Coordinate Gradient (GCG) algorithm, to optimize over the discrete space of possible prompts.
  - Quick check question: Why can't standard gradient descent methods be directly applied to optimize prompts, and how does GCG address this challenge?

## Architecture Onboarding

- Component map:
  - Input: Example documents generated by an unknown ground-truth prompt
  - Core: PROPANE optimization framework (KL divergence minimization via GCG)
  - Output: Reconstructed prompt that induces statistically similar outputs
  - Evaluation: KL divergence between reconstructed and ground-truth prompts, transferability tests

- Critical path:
  1. Generate example documents from ground-truth prompt
  2. Initialize reconstruction (random or GPT-4 warm start)
  3. Run GCG optimization to minimize KL divergence
  4. Evaluate reconstructed prompt against ground truth
  5. Test transferability across model sizes

- Design tradeoffs:
  - Optimization stability vs. reconstruction quality: GCG can be unstable, requiring careful hyperparameter tuning
  - Interpretability vs. effectiveness: Obfuscated prompts may be more effective but less interpretable
  - Computational cost vs. accuracy: More documents and optimization epochs improve accuracy but increase cost

- Failure signatures:
  - KL divergence plateaus at high values: Optimization stuck in local minima
  - Reconstructed prompts contain mostly special characters: Optimization exploring unlikely token space
  - Poor transferability between models: Special tokens not universal across model architectures

- First 3 experiments:
  1. Reconstruct a simple prompt (e.g., "Suggest an interesting book to read") using 50 documents and compare KL divergence with GPT-4-suggested prompts
  2. Test transferability of reconstructed prompts across Pythia model sizes (70M to 12B parameters)
  3. Evaluate token-order-sensitivity of PROPANE prompts vs. natural prompts using the shuffling test described in the paper

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can PROPANE be used for textual style transfer by optimizing prompts for specific styles?
- Basis in paper: [explicit] The paper suggests this as a future direction: "an interesting extension is to explore how our framework could be adapted for textual style transfer: optimizing prompts for a certain style and using them as a plug-in for user queries"
- Why unresolved: The authors only mention this as a potential application without providing any experimental results or demonstrations.
- What evidence would resolve it: Experimental results showing PROPANE can optimize prompts for different writing styles (e.g., formal vs informal, creative vs technical) and that these optimized prompts can be successfully applied to transform user queries into the desired style.

### Open Question 2
- Question: Can PROPANE improve compression performance when used as a pre-processing step for arithmetic encoding?
- Basis in paper: [explicit] The authors propose: "Another direction is to apply PROPANE to help compress corpora of documents. Given documents d1,...,dn drawn from a distribution, one would find a PROPANE prompt that would configure the model to be better at predicting documents from that distribution. This could yield improved performance when the model is used as a compression algorithm via arithmetic encoding"
- Why unresolved: The authors only propose this application without testing it or providing theoretical analysis of potential gains.
- What evidence would resolve it: Experimental comparison showing whether using PROPANE-optimized prompts before arithmetic encoding achieves better compression ratios than standard approaches on various document corpora.

### Open Question 3
- Question: What optimization techniques beyond single-token edits could improve PROPANE's performance?
- Basis in paper: [explicit] The authors state: "there is still much room for improvement of optimization techniques over prompts. Currently, Greedy Coordinate Gradient (GCG) edits a single token at a time in a localized fashion, and is rather unstable. Some extensions may include multi-token insertions and deletions, as well as varying the number of tokens during the optimization"
- Why unresolved: The authors only suggest potential improvements without implementing or testing them.
- What evidence would resolve it: Experimental results comparing PROPANE with single-token GCG against variants that use multi-token operations or adaptive token counts, measuring both reconstruction accuracy and prompt fluency.

## Limitations

- Evaluation scope primarily limited to text generation tasks using Pythia suite models, with unclear generalizability to other task types or model architectures
- Statistical equivalence (low KL divergence) doesn't necessarily guarantee functional equivalence in all contexts or capture important qualitative differences
- GCG optimization can be unstable, but the paper lacks comprehensive analysis of failure modes and conditions for optimization failure

## Confidence

- **High**: The basic premise that prompt reconstruction can be framed as a maximum likelihood problem using KL divergence
- **Medium**: The claim that PROPANE can improve upon GPT-4-suggested prompts based on KL divergence metrics
- **Low**: The assertion that obfuscated prompts contain "special tokens" that transfer between models, and that these tokens are less sensitive to order than natural prompts

## Next Checks

1. **Cross-task transferability test**: Apply PROPANE to reconstruct prompts for different task types (e.g., classification, reasoning, code generation) and evaluate whether the same optimization framework performs consistently across tasks. This would test the generality of the approach beyond text generation.

2. **Ablation study on optimization parameters**: Systematically vary key GCG hyperparameters (top-k candidates, learning rate, epoch count) and document their impact on reconstruction quality and optimization stability. This would help identify optimal settings and failure conditions.

3. **Human evaluation of obfuscated prompts**: Conduct blinded human evaluations comparing obfuscated PROPANE prompts to natural prompts for the same tasks. Measure whether humans can identify functional differences that aren't captured by KL divergence metrics, and whether the obfuscated prompts have any discernible patterns or structures despite being "unintelligible."