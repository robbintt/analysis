---
ver: rpa2
title: Revisiting N-CNN for Clinical Practice
arxiv_id: '2308.05877'
source_url: https://arxiv.org/abs/2308.05877
tags:
- pain
- n-cnn
- tuned
- class
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper revisits the Neonatal Convolutional Neural Network (N-CNN)
  by optimizing its hyperparameters to improve classification metrics, explainability,
  and reliability for neonatal pain assessment. The authors propose a novel approach
  using soft labels derived from the Neonatal Facial Coding System (NFCS) during training.
---

# Revisiting N-CNN for Clinical Practice

## Quick Facts
- arXiv ID: 2308.05877
- Source URL: https://arxiv.org/abs/2308.05877
- Reference count: 14
- Key outcome: Hyperparameter tuning of N-CNN improves F1 score (+5.64%), precision (+2.46%), and sensitivity (+6.47%) but significantly degrades calibration (ECE increases from 0.035 to 0.091)

## Executive Summary
This study revisits the Neonatal Convolutional Neural Network (N-CNN) for pain assessment by optimizing hyperparameters and introducing NFCS-based soft labels. The authors demonstrate that tuning learning rate, regularization, and training epochs, combined with soft labels derived from the Neonatal Facial Coding System, improves classification metrics significantly. However, these improvements come at the cost of calibration performance, with the tuned model showing an Expected Calibration Error three times higher than the original. The findings highlight the critical tradeoff between accuracy and calibration in medical AI models, particularly for neonatal pain assessment applications.

## Method Summary
The researchers optimized the N-CNN architecture by tuning hyperparameters including learning rate, regularization, epochs, and label smoothing without modifying the original shallow CNN structure. They implemented NFCS-based soft labels using a sigmoid function to convert hard labels to probabilistic values. The model was trained on two datasets (iCOPE and UNIFESP) using 10-fold leave-sample-subjects-out cross-validation with extensive data augmentation. Performance was evaluated using classification metrics (F1 score, precision, recall, accuracy) and calibration error (ECE), with explainability assessed through Grad-CAM and Integrated Gradients.

## Key Results
- Tuned N-CNN achieved F1 score improvement of +5.64% (from 0.7406 to 0.7825)
- Precision increased by +2.46% and sensitivity by +6.47% compared to original N-CNN
- Calibration degraded significantly: ECE increased from 0.035 to 0.091 (3× higher)
- Soft labels from NFCS improved classification metrics without changing architecture
- Grad-CAM and IG attribution maps focused appropriately on facial regions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Soft labels derived from NFCS improve model classification metrics without changing the N-CNN architecture.
- Mechanism: NFCS-based soft labels provide probabilistic class membership instead of binary hard labels, which regularizes training and prevents overfitting.
- Core assumption: The NFCS scoring system accurately reflects pain-related facial action units in neonatal images.
- Evidence anchors:
  - [abstract] "We also applied soft labels derived from the Neonatal Facial Coding System (NFCS) during training."
  - [section] "Using the NFCS as a soft label, we encourage the output neuron of the 'Pain' class to be more confident in images with more FAUs of pain."

### Mechanism 2
- Claim: Hyperparameter tuning (learning rate, regularization, epochs) improves F1 score, precision, and sensitivity without modifying the architecture.
- Mechanism: Adjusting hyperparameters optimizes the training dynamics and regularization strength, leading to better convergence and generalization.
- Core assumption: The original N-CNN hyperparameters were not already optimal for the given datasets.
- Evidence anchors:
  - [abstract] "Hyperparameter tuning led to improvements in F1 score (+5.64%), precision (+2.46%), and sensitivity (+6.47%) compared to the original N-CNN."
  - [section] "We selected hyperparameters according to Table 1 that do not modify the original N-CNN architecture, primarily affecting learning rate and training regularization."

### Mechanism 3
- Claim: Calibration performance degrades when using label smoothing and NFCS soft labels, despite improved classification metrics.
- Mechanism: Label smoothing reduces overconfidence but also flattens probability distributions, making the model less calibrated to actual event frequencies.
- Core assumption: Calibration is a distinct property from classification accuracy and requires separate optimization.
- Evidence anchors:
  - [abstract] "However, these improvements did not translate to better calibration performance. The Tuned N-CNN exhibited an Expected Calibration Error (ECE) of 0.091, approximately three times higher than the original N-CNN's ECE of 0.035."
  - [section] "Despite achieving higher classification metrics, the Tuned N-CNN did not exhibit the same level of calibration as the Original N-CNN."

## Foundational Learning

- Concept: Neonatal Facial Coding System (NFCS)
  - Why needed here: NFCS provides the soft labels used to train the model and is central to the proposed method.
  - Quick check question: What does an NFCS score ≥ 3 indicate in the context of neonatal pain assessment?

- Concept: Label Smoothing Regularization (LSR)
  - Why needed here: LSR is one of the hyperparameters tuned and is used to create soft labels from hard labels.
  - Quick check question: How does LSR modify the target labels during training, and what is its effect on model confidence?

- Concept: Expected Calibration Error (ECE)
  - Why needed here: ECE quantifies how well predicted confidences align with actual event frequencies, which is critical for clinical reliability.
  - Quick check question: If a model has an ECE of 0.091, what does that say about its calibration compared to a model with ECE of 0.035?

## Architecture Onboarding

- Component map:
  Input layer (120×120 grayscale) -> Shallow CNN layers -> Output layer (2 neurons, softmax) -> Adam optimizer with cosine annealing

- Critical path:
  1. Load and preprocess images (resize to 120×120)
  2. Apply data augmentation (shifts, rotation, shear, brightness, zoom, flip)
  3. Train with NFCS-based soft labels and tuned hyperparameters
  4. Evaluate classification metrics and calibration
  5. Generate explainability maps (Grad-CAM, Integrated Gradients)

- Design tradeoffs:
  - Shallow architecture limits explainability but reduces computational load
  - Soft labels improve metrics but hurt calibration
  - Leave-sample-subjects-out cross-validation ensures subject independence but reduces training data

- Failure signatures:
  - High ECE indicates poor calibration despite good accuracy
  - Attribution maps focusing on non-facial regions suggest model overfitting or poor feature learning
  - Low confidence predictions in high-confidence regions indicate miscalibration

- First 3 experiments:
  1. Train with original N-CNN hyperparameters and hard labels to establish baseline
  2. Apply label smoothing (ε = 0.3) and evaluate impact on F1 and ECE
  3. Replace hard labels with NFCS-derived soft labels and compare performance metrics

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- Significant degradation in calibration performance despite improved classification metrics
- Small dataset sizes (60+63 and 164+196 images) limiting generalizability
- Incomplete specification of NFCS-based soft label implementation details

## Confidence

**High Confidence Claims:**
- Tuned N-CNN achieves statistically significant improvements in F1 score (+5.64%), precision (+2.46%), and sensitivity (+6.47%)
- ECE calculation methodology is sound and calibration degradation is reliably measured
- Soft label approach using NFCS scores is technically feasible

**Medium Confidence Claims:**
- Clinical significance of calibration-accuracy tradeoff for neonatal pain assessment
- Optimal balance between classification performance and calibration for medical AI applications
- Generalizability of findings to larger neonatal populations

**Low Confidence Claims:**
- Absolute impact of each individual hyperparameter on performance improvements
- Effectiveness of NFCS-based soft labels versus alternative soft labeling strategies
- Robustness of findings across different neonatal pain assessment contexts

## Next Checks
1. **Calibration Benchmarking**: Evaluate the Tuned N-CNN against other calibration methods (temperature scaling, isotonic regression) to determine if calibration can be improved without sacrificing classification metrics.

2. **Cross-Dataset Validation**: Test the model on an independent neonatal pain dataset not used in training or validation to assess generalizability and robustness of the calibration-accuracy tradeoff.

3. **Ablation Study**: Systematically remove each hyperparameter modification (learning rate, regularization, epochs, LSR) to quantify their individual contributions to performance improvements and calibration degradation.