---
ver: rpa2
title: The effect of data augmentation and 3D-CNN depth on Alzheimer's Disease detection
arxiv_id: '2309.07192'
source_url: https://arxiv.org/abs/2309.07192
tags:
- data
- adni
- accuracy
- fold
- augmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the impact of data augmentation strategies
  and 3D-CNN depth on Alzheimer's Disease detection using MRI data. The authors trained
  15 models combining three augmentation strategies (simultaneous vs.
---

# The effect of data augmentation and 3D-CNN depth on Alzheimer's Disease detection

## Quick Facts
- arXiv ID: 2309.07192
- Source URL: https://arxiv.org/abs/2309.07192
- Reference count: 0
- Up to 10% variation in accuracy based on augmentation and depth choices

## Executive Summary
This study investigates how data augmentation strategies and 3D-CNN architecture depth affect Alzheimer's Disease detection using MRI data. The authors systematically test 15 models combining three augmentation strategies with five CNN architectures of varying depth. Results show that separate application of affine transformations yields better performance than combined application, and that optimal model depth follows a concave curve with intermediate values performing best. The best model achieved 87.21% validation accuracy and 81.95% testing accuracy.

## Method Summary
The study uses the ADNI1 dataset (550 MRI scans: 307 CN, 243 AD) preprocessed to 96×96×73 resolution. Three data augmentation strategies are tested: combined transformations (N samples), separate transformations (3N samples), and repeated combined transformations (3N samples). Five CNN architectures with 4, 6, 8, 10, and 12 convolutional layers are evaluated using 7-fold cross-validation with 10 training trials per fold. Models are trained with Adam optimizer (lr=0.001), ℓ2 penalty (0.01), batch size 50, and early stopping (patience=20).

## Key Results
- Up to 10% variation in accuracy based on augmentation strategy and model depth choices
- Best performance achieved with 8-layer CNN using separate transformations: 87.21% validation accuracy, 81.95% testing accuracy
- Separate application of affine transformations outperforms combined application across all architectures
- Model accuracy follows a concave curve with depth, peaking at intermediate values (8 layers optimal)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Separate application of affine transformations yields better accuracy than combined application.
- Mechanism: Separate transformations create more diverse training samples (3N vs N) without introducing unrealistic synthetic data, improving generalization.
- Core assumption: Diversity from separate transformations outweighs combined transformations, and transformations represent real-world variation.
- Evidence anchors:
  - [abstract] "When affine transformation are applied separately, the model is more accurate, independently from the adopted architecture."
  - [section] "strategies (B) (in green) and (C) (in fuchsia) generate the same amount of data, (B) outperforms (C) in all models, suggesting that applying the transformation separately significantly improves the CNN model."

### Mechanism 2
- Claim: Model accuracy follows a concave curve with respect to convolutional layer depth, peaking at intermediate values.
- Mechanism: Shallow models underfit due to limited capacity, while very deep models overfit due to increased parameters and limited data.
- Core assumption: Dataset size is insufficient to support very deep models, and architectural constraints prevent overfitting.
- Evidence anchors:
  - [abstract] "For all strategies, the model accuracy followed a concave behavior at increasing number of convolutional layers, peaking at an intermediate value of layers."
  - [section] "the accuracy curves for all augmentation methods show a similar pattern: the best results are obtained for intermediate amounts of layers, while accuracy decreases for higher numbers of convolutional layers."

### Mechanism 3
- Claim: Cross-validation and multiple training trials improve stability and reliability of results.
- Mechanism: 7-fold cross-validation and 10 training trials account for data partitioning variance and weight initialization variance, providing robust performance estimates.
- Core assumption: Dataset is sufficiently large and diverse to support meaningful cross-validation splits.
- Evidence anchors:
  - [section] "we set up a stratified-K-fold cross-validation loop. We set K= 7... Each model has been run 10 times at fixed parameters."
  - [section] "This makes unclear which data has been selected for the experiments... All experiments are run only once, without assessing the weight robustness."

## Foundational Learning

- Concept: Data augmentation through affine transformations
  - Why needed here: Limited dataset size (550 MRI scans) requires augmentation to prevent overfitting and improve generalization.
  - Quick check question: What are the three affine transformations applied in this study, and how does their separate application differ from combined application in terms of generated sample count?

- Concept: Convolutional Neural Network depth optimization
  - Why needed here: Study investigates how varying convolutional layer count affects performance, finding intermediate depth optimal.
  - Quick check question: According to the study, what is the optimal number of convolutional layers for the best-performing model, and why does accuracy decrease for both shallower and deeper architectures?

- Concept: Cross-validation and model stability assessment
  - Why needed here: 7-fold cross-validation and 10 trials provide robust performance estimates and assess model stability.
  - Quick check question: How does the study ensure that its performance estimates are not due to random chance in data splitting or weight initialization?

## Architecture Onboarding

- Component map: Load MRI data -> Preprocess (resize, normalize) -> Apply augmentation strategy -> Train 3D-CNN with early stopping -> Evaluate with cross-validation and multiple trials

- Critical path: 1. Load and preprocess MRI data (resize, normalize) 2. Apply augmentation strategy to training data 3. Train model with early stopping and cross-validation 4. Evaluate performance metrics across folds and trials 5. Compare different architectures and augmentation strategies

- Design tradeoffs:
  - Model depth vs. overfitting: Deeper models have more parameters but require more data to avoid overfitting
  - Augmentation strategy vs. computational cost: Strategy B generates 3× more samples than A, increasing training time but improving accuracy
  - Image resolution vs. memory requirements: Lower resolution reduces memory usage but may lose important features

- Failure signatures:
  - Training accuracy much higher than validation accuracy: overfitting
  - Very low accuracy across all folds: underfitting or data quality issues
  - High variance between trials: model instability or insufficient training

- First 3 experiments:
  1. Train 4-layer model with strategy A augmentation on fold 0, trial 1 to verify basic pipeline functionality
  2. Train 8-layer model with strategy B augmentation on fold 0, trial 1 to compare depth effects
  3. Train 4-layer model with strategy B augmentation on all 7 folds, trial 1 to test cross-validation setup

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal depth of convolutional layers for 3D-CNN models in Alzheimer's Disease detection, and how does this vary with different data augmentation strategies?
- Basis in paper: [explicit] The paper states that "the model accuracy followed a concave behavior at increasing number of convolutional layers, peaking at an intermediate value of layers" and that "the best model (8 CL, (B))" was identified.
- Why unresolved: While the study identified an optimal depth for the specific dataset and augmentation strategy used, it remains unclear if this optimal depth would hold for different datasets, image resolutions, or augmentation strategies.
- What evidence would resolve it: Further experiments varying the dataset characteristics, image resolutions, and augmentation strategies to determine if the optimal depth changes.

### Open Question 2
- Question: How does the application of affine transformations separately versus concurrently affect the performance of 3D-CNN models in Alzheimer's Disease detection?
- Basis in paper: [explicit] The paper found that "When affine transformation are applied separately, the model is more accurate, independently from the adopted architecture."
- Why unresolved: The study only tested specific affine transformations (zoom, shift, rotation) and did not explore other types of transformations or their combinations, leaving uncertainty about the generalizability of the finding.
- What evidence would resolve it: Experiments testing a wider variety of affine transformations and their combinations to determine the robustness of the finding.

### Open Question 3
- Question: What is the impact of data augmentation on the generalizability of 3D-CNN models for Alzheimer's Disease detection across different domains (e.g., different MRI resolutions)?
- Basis in paper: [explicit] The paper tested the best model on an external dataset with different MRI resolution, obtaining an accuracy of 71% and an AUC curve of 0.76.
- Why unresolved: While the study provides initial evidence of the model's generalizability, it remains unclear how different data augmentation strategies might affect the model's performance on datasets with varying characteristics.
- What evidence would resolve it: Further experiments testing the model's performance on multiple external datasets with varying characteristics, comparing the impact of different data augmentation strategies.

## Limitations
- Limited to single dataset (ADNI1), raising questions about generalization to other cohorts or acquisition protocols
- Clinical relevance threshold for diagnostic systems remains undefined despite 10% performance variation
- Optimal augmentation strategy (separate transformations) may not generalize to other medical imaging modalities

## Confidence
- High Confidence: The core finding that separate affine transformations outperform combined ones is well-supported by systematic experiments across multiple architectures.
- Medium Confidence: The concave relationship between model depth and accuracy is observed but may be dataset-dependent and could shift with larger training sets.
- Low Confidence: The specific optimal depth (8 layers) is likely overfit to this particular dataset size and architecture choices.

## Next Checks
1. Test the augmentation strategies on an independent Alzheimer's dataset to verify generalization of the separate-transformations advantage.
2. Vary the dataset size (subsampling) to determine how the optimal model depth shifts with available training data.
3. Evaluate whether the findings extend to other medical imaging tasks beyond Alzheimer's detection, such as tumor classification or brain lesion detection.