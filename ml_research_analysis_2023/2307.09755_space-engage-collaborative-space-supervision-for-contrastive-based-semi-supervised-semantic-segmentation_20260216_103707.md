---
ver: rpa2
title: 'Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised
  Semantic Segmentation'
arxiv_id: '2307.09755'
source_url: https://arxiv.org/abs/2307.09755
tags:
- space
- learning
- representation
- logit
- spaces
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses semi-supervised semantic segmentation (S4),
  which aims to train a segmentation model with limited labeled images and a large
  number of unlabeled images. The authors propose Collaborative Space Supervision
  (CSS), a method that utilizes supervision from both the logit space and the representation
  space to enhance the knowledge exchange between the two spaces.
---

# Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation

## Quick Facts
- arXiv ID: 2307.09755
- Source URL: https://arxiv.org/abs/2307.09755
- Reference count: 40
- Key outcome: Proposes Collaborative Space Supervision (CSS) for semi-supervised semantic segmentation that combines logit space and representation space supervision to achieve competitive performance on PASCAL VOC 2012 and Cityscapes benchmarks.

## Executive Summary
This paper addresses semi-supervised semantic segmentation by introducing Collaborative Space Supervision (CSS), a method that leverages supervision from both logit space and representation space to enhance knowledge exchange and robustness. The approach uses dual-space pseudo-label generation with a mix strategy that only considers mutually agreeable labels, reducing noise from either space. Additionally, it introduces similarity-based indicators between representations and prototypes for more accurate sampling in contrastive learning. The method is evaluated on two public benchmarks and demonstrates competitive performance compared to state-of-the-art approaches.

## Method Summary
The method employs a DeepLabv3+ architecture with ResNet-101 backbone, featuring both segmentation and representation heads. It implements a teacher-student framework with EMA updates, combining self-training with pixel-wise contrastive learning. The key innovation is dual-space supervision where pseudo-labels are generated from both logit space (segmentation head) and representation space (representation head), then combined using a mix pseudo-labeling strategy that takes the intersection of both sources. The representation space uses similarity between representations and class prototypes as indicators for sampling, replacing traditional confidence-based approaches. The overall training objective combines supervised loss, unsupervised loss, and contrastive loss with prototype-based learning.

## Key Results
- Demonstrates competitive performance on PASCAL VOC 2012 and Cityscapes with limited labeled data
- Achieves improved pseudo-label accuracy by combining logit and representation space supervision
- Shows that similarity-based indicators in representation space outperform confidence-based sampling
- Effectively reduces noise in pseudo-labels through the mix pseudo-labeling strategy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dual-space supervision improves robustness by correcting noisy pseudo-labels using representation space semantic information.
- Mechanism: Generates pseudo-labels from both logit space and representation space, then combines them via mix pseudo-labeling to leverage the strengths of both spaces.
- Core assumption: Representation space semantic information can correct noise in logit space pseudo-labels, with the two spaces complementing each other.
- Evidence anchors: [abstract] supervision reduces risk of overfitting to incorrect semantic information; [section 3.3] pseudo-labels produced by collaboration of two spaces; [corpus] weak evidence without direct citation.
- Break condition: If representation space contains insufficient semantic information or the two spaces have highly correlated errors.

### Mechanism 2
- Claim: Similarity between representations and prototypes is more accurate than confidence for selecting samples in representation space.
- Mechanism: Calculates similarity using cosine similarity and softmax normalization to measure confusion levels between representations and class prototypes.
- Core assumption: Similarity better reflects confusion levels than confidence from logit space predictions.
- Evidence anchors: [abstract] similarity used as new indicator to tilt training under-performing representations; [section 3.2] softmax similarity helps discover confusion between representations and prototypes; [section 5.2] confidence not able to represent confusion level.
- Break condition: If prototypes are poorly initialized or classes have highly overlapping feature distributions.

### Mechanism 3
- Claim: Mix pseudo-labeling strategy reduces noise by only considering mutually agreeable pseudo-labels between the two spaces.
- Mechanism: Defines final pseudo-labels as the intersection of pseudo-labels from both spaces, ensuring only labels agreed upon by both are used.
- Core assumption: Mutually agreeable pseudo-labels between two independent sources have higher reliability.
- Evidence anchors: [section 3.3] mix pseudo-labeling mitigates negative effects of noise; [section 5.1] representation space pseudo-labels enhance accuracy of final pseudo-labels; [corpus] weak evidence without direct citation.
- Break condition: If the two spaces frequently disagree even on correct labels, or if one space consistently underperforms.

## Foundational Learning

- Concept: Contrastive learning in pixel-wise semantic segmentation
  - Why needed here: Builds upon pixel-wise contrastive learning approaches that aggregate representations to their class prototypes while separating them from different classes
  - Quick check question: What is the difference between instance-wise contrastive learning and pixel-wise contrastive learning in semantic segmentation?

- Concept: Prototype-based classification and learning
  - Why needed here: Uses class prototypes to generate pseudo-labels from representation space and as targets for contrastive learning
  - Quick check question: How are class prototypes calculated and updated in this method?

- Concept: Semi-supervised learning via self-training and consistency regularization
  - Why needed here: Employs teacher-student framework with EMA updates and combines self-training with contrastive learning
  - Quick check question: What is the role of the teacher model in the self-training framework?

## Architecture Onboarding

- Component map: Encoder → Segmentation Head (logit space) + Representation Head (representation space) → Pseudo-label generation from both spaces → Mix pseudo-labeling → Contrastive loss with similarity-based sampling
- Critical path: Representation extraction → Prototype calculation → Pseudo-label generation → Sampling with indicators → Loss computation
- Design tradeoffs: Similarity-based indicators provide more accurate sampling but require maintaining prototypes; dual-space supervision improves robustness but increases computational complexity
- Failure signatures: Poor prototype initialization leading to incorrect pseudo-labels, high disagreement between spaces indicating model confusion, or similarity indicators failing to identify under-performing representations
- First 3 experiments:
  1. Validate that pseudo-labels from representation space have different characteristics than those from logit space by visualizing and comparing IoU scores
  2. Test whether using similarity as an indicator improves sample selection quality compared to confidence-based selection
  3. Compare performance of mix pseudo-labeling versus using pseudo-labels from either space alone

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of pseudo-labels from representation space compare to those from logit space in terms of their impact on model performance across different classes?
- Basis in paper: [explicit] The paper discusses the quality of pseudo-labels obtained from logit space and representation space, showing that representation space pseudo-labels can enhance accuracy, particularly for under-performing classes.
- Why unresolved: While the paper provides evidence of the superiority of representation space pseudo-labels, it does not fully explore how this quality varies across different classes or image regions.
- What evidence would resolve it: Detailed analysis of pseudo-label quality across various classes and image regions, possibly through visualization or quantitative metrics, could provide deeper insights into the strengths and weaknesses of each approach.

### Open Question 2
- Question: What are the specific mechanisms by which the similarity indicator in representation space improves the learning process compared to confidence-based indicators?
- Basis in paper: [explicit] The paper introduces a new indicator based on similarity between representations and prototypes, arguing it directly reflects confusion levels and leads to more efficient learning.
- Why unresolved: The paper suggests the superiority of similarity-based indicators but does not provide a comprehensive explanation of the underlying mechanisms that make them more effective than confidence-based ones.
- What evidence would resolve it: Empirical studies comparing the effects of similarity-based and confidence-based indicators on learning efficiency and model performance could clarify the advantages of each approach.

### Open Question 3
- Question: How does the proposed method perform in scenarios with different levels of class imbalance in the dataset?
- Basis in paper: [inferred] The paper focuses on semi-supervised semantic segmentation but does not explicitly address the impact of class imbalance on its performance.
- Why unresolved: Class imbalance is a common issue in real-world datasets, and its effects on the proposed method's performance are not explored.
- What evidence would resolve it: Experiments evaluating the method's performance on datasets with varying levels of class imbalance could reveal its robustness and adaptability to such challenges.

## Limitations

- Major uncertainties remain around the empirical validation of the dual-space supervision mechanism, with no ablation studies directly isolating the contribution of the correction mechanism
- Evidence supporting the superiority of similarity-based indicators over confidence is limited to qualitative comparisons and single dataset experiments
- The effectiveness of mix pseudo-labeling is demonstrated through class-wise IoU improvements but lacks statistical significance testing and analysis of failure cases

## Confidence

- Dual-space supervision effectiveness: Medium
- Similarity-based indicator superiority: Low-Medium
- Mix pseudo-labeling noise reduction: Medium

## Next Checks

1. Conduct ablation studies isolating the correction effect of representation space on logit space pseudo-labels by comparing single-space vs dual-space supervision
2. Perform statistical significance testing on similarity indicator improvements across multiple datasets and model backbones
3. Analyze failure cases where the two spaces produce mutually exclusive but incorrect pseudo-labels to understand the limitations of the intersection strategy