---
ver: rpa2
title: 'Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model Splitting'
arxiv_id: '2312.09148'
source_url: https://arxiv.org/abs/2312.09148
tags:
- subtask
- training
- split-ensemble
- each
- submodels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Split-Ensemble, a novel approach for efficient
  out-of-distribution (OOD) detection in deep learning models without additional data
  or computational cost. The core idea is to split a multiclass classification task
  into complementary subtasks, where each submodel is trained with OOD-aware objectives
  on its specific subtask.
---

# Split-Ensemble: Efficient OOD-aware Ensemble via Task and Model Splitting

## Quick Facts
- arXiv ID: 2312.09148
- Source URL: https://arxiv.org/abs/2312.09148
- Reference count: 40
- Key outcome: Split-Ensemble improves accuracy by 0.8-25.5% and OOD detection by 2.2-29.6% over single model baseline

## Executive Summary
Split-Ensemble is a novel approach for efficient out-of-distribution (OOD) detection in deep learning models without requiring external OOD data or computational overhead. The method splits a multiclass classification task into complementary subtasks, training each submodel with OOD-aware objectives on its specific subtask. By leveraging a tree-like architecture that shares early layers and prunes redundant computation, Split-Ensemble achieves significant improvements in both accuracy and OOD detection performance across CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets.

## Method Summary
The method works by first dividing the original multiclass task into semantically meaningful subtasks, where each submodel treats data from other groups as pseudo-OOD for outlier exposure training. A tree-like architecture is then constructed through iterative splitting and pruning of a shared backbone, where early layers are shared across subtasks while high-level features diverge. OOD-aware label conversion and class-balanced weighting prevent over-confidence and class imbalance bias. The final output is obtained by concatenating logits from all branches, enabling efficient ensemble performance without additional computational cost.

## Key Results
- Accuracy improvements of 0.8%, 1.8%, and 25.5% over single model baseline on CIFAR-10, CIFAR-100, and Tiny-ImageNet respectively
- OOD detection performance surpasses baseline by 2.2%, 8.1%, and 29.6% mean AUROC across the three datasets
- Computational efficiency maintained through layer sharing and global pruning across branches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Split-Ensemble improves OOD detection without external OOD data by splitting a single multiclass task into complementary subtasks, each trained with its own OOD-aware objective.
- Mechanism: By grouping semantically similar classes into subtasks, each submodel treats data from other groups as pseudo-OOD, enabling outlier exposure training within the same dataset.
- Core assumption: Semantic similarity grouping ensures that each submodel can effectively learn the boundary between its ID classes and pseudo-OOD classes.
- Evidence anchors: [abstract] "Specifically, we propose a novel subtask-splitting ensemble training objective, where a common multiclass classification task is split into several complementary subtasks."
- Break condition: If semantic grouping fails to separate classes into meaningful subsets, subtasks will overlap and pseudo-OOD will leak into ID, degrading OOD detection.

### Mechanism 2
- Claim: Tree-like architecture sharing early layers and splitting later layers enables efficient ensemble performance without extra compute cost.
- Mechanism: Iterative splitting and pruning based on layer-wise sensitivity and correlation removes redundant computation while preserving diverse high-level features per subtask.
- Core assumption: Low-level features are shared across subtasks while high-level features diverge, so splitting at appropriate layers preserves performance while reducing cost.
- Evidence anchors: [section 4.1] "Most subtasks processing, as part of the original task, can utilize similar low-level features. Hence, it is possible to share early layers across submodels."
- Break condition: If pruning removes too much capacity or splits too early, each submodel will lack the capacity to handle its full input space, hurting accuracy.

### Mechanism 3
- Claim: OOD-aware label conversion and class-balanced weighting improve submodel confidence calibration and robustness.
- Mechanism: Assigning uniform label targets to pseudo-OOD classes and reweighting loss prevents over-confidence and class imbalance bias.
- Core assumption: Submodels can learn to output low confidence on unseen classes if trained with uniform targets on pseudo-OOD.
- Evidence anchors: [section 3.2] "We substitute the OOD class target...into the loss formulation...to get LCB (X, ˆY), which we use to train each submodel."
- Break condition: If uniform OOD targets are too weak or reweighting is imbalanced, submodels may still overfit to their ID classes and fail on true OOD.

## Foundational Learning

- Concept: Cross-entropy loss and its limitations for OOD detection.
  - Why needed here: Understanding why softmax outputs are uncalibrated and how cross-entropy alone doesn't detect OOD.
  - Quick check question: What happens to softmax probabilities when a model encounters an unseen class during inference?

- Concept: Ensemble methods and their computational trade-offs.
  - Why needed here: Knowing why naive ensembles improve uncertainty but are expensive, motivating the need for efficient alternatives.
  - Quick check question: How does parameter sharing in efficient ensembles affect submodel diversity and OOD detection?

- Concept: Sensitivity-based pruning and layer-wise correlation analysis.
  - Why needed here: Understanding how to identify which layers to split and which filters to prune based on task sensitivity.
  - Quick check question: How does the intersection-over-union (IoU) score between sensitivity masks determine optimal split points?

## Architecture Onboarding

- Component map:
  Backbone -> Split Layer(s) -> Branch(es) -> Prune -> Concat Output

- Critical path:
  Backbone → Split Layer(s) → Branch(es) → Prune → Concat Output

- Design tradeoffs:
  - Early split: More diversity, higher pruning cost, risk of undercapacity
  - Late split: Less diversity, lower pruning cost, risk of redundancy
  - Pruning aggressiveness: More pruning = efficiency but possible accuracy loss

- Failure signatures:
  - Accuracy drop after split: Too aggressive split or pruning
  - Poor OOD detection: Semantic grouping not meaningful, or OOD-aware target too weak
  - High compute cost: Insufficient pruning, too many splits

- First 3 experiments:
  1. Train single model baseline on CIFAR-100, measure accuracy and OOD AUROC
  2. Implement Split-Ensemble with 2 subtasks (simple grouping), compare performance to baseline
  3. Vary MCT threshold (0.1, 0.4, 0.7) and measure accuracy/OOD trade-off

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of splits for balancing performance and computational efficiency?
- Basis in paper: [inferred] The paper discusses varying the number of splits (2, 4, 5, 8, 10) and their impact on accuracy and OOD detection, but doesn't definitively state an optimal number.
- Why unresolved: The optimal number likely depends on the specific dataset and task complexity, requiring further empirical study across diverse scenarios.
- What evidence would resolve it: Systematic experiments comparing performance and efficiency across different datasets and tasks with varying split numbers.

### Open Question 2
- Question: How does the semantic grouping strategy for subtasks compare to other potential grouping methods?
- Basis in paper: [explicit] The paper shows semantic grouping outperforms random grouping, but doesn't explore other grouping strategies.
- Why unresolved: There may be more effective grouping methods based on different criteria (e.g., feature similarity, class hierarchy) that could further improve performance.
- What evidence would resolve it: Comparative studies evaluating different grouping strategies (semantic, random, feature-based, hierarchical) across multiple datasets.

### Open Question 3
- Question: What are the theoretical guarantees for the MCT threshold selection in automated splitting?
- Basis in paper: [inferred] The paper proposes using MCT thresholds for splitting but doesn't provide theoretical analysis of its optimality or convergence properties.
- Why unresolved: Understanding the theoretical properties would provide insights into the method's reliability and guide threshold selection in practice.
- What evidence would resolve it: Theoretical analysis proving convergence properties and establishing relationships between MCT thresholds, model complexity, and performance.

## Limitations
- The effectiveness of OOD detection depends heavily on the quality of semantic groupings, which are not specified in detail
- Optimal split points and pruning levels require extensive hyperparameter tuning that may not generalize across datasets
- The method's computational efficiency claims need validation across different network architectures beyond ResNet

## Confidence

**High Confidence**: The general framework of task splitting and efficient ensemble architecture is well-specified and reproducible. The mathematical formulations for OOD-aware training objectives are clear and implementable.

**Medium Confidence**: The empirical results showing accuracy and OOD detection improvements are well-documented, but the dependency on specific semantic groupings introduces uncertainty about generalizability.

**Low Confidence**: The architectural details for optimal splitting and pruning are underspecified, making it difficult to assess whether the reported efficiency gains are achievable in practice without extensive hyperparameter tuning.

## Next Checks

1. **Reproduce with Controlled Groupings**: Implement the Split-Ensemble method using a fixed, reproducible semantic grouping strategy (e.g., grouping classes by super-category in CIFAR-100) to assess whether the OOD detection improvements are consistent across different grouping schemes.

2. **Architecture Sensitivity Analysis**: Systematically vary the MCT threshold and split layer locations to measure how sensitive accuracy and OOD detection performance are to these architectural choices. This would help determine if the reported results are robust or highly tuned.

3. **Cross-Dataset Generalization**: Apply the method to a held-out dataset (e.g., SVHN or STL-10) with different semantic groupings to test whether the OOD detection improvements generalize beyond the three datasets used in the paper.