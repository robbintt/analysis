---
ver: rpa2
title: 'DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence
  Understanding'
arxiv_id: '2310.18359'
source_url: https://arxiv.org/abs/2310.18359
tags:
- social-iq
- answer
- dataset
- performance
- t5-small
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper identifies significant biases in the Social-IQ dataset
  for social intelligence understanding and proposes a debiased benchmark called DeSIQ.
  The authors analyze the original dataset and find that even small language models
  can exploit spurious correlations to achieve near-perfect performance without proper
  understanding.
---

# DeSIQ: Towards an Unbiased, Challenging Benchmark for Social Intelligence Understanding

## Quick Facts
- arXiv ID: 2310.18359
- Source URL: https://arxiv.org/abs/2310.18359
- Reference count: 20
- Key outcome: DeSIQ reduces biases in Social-IQ, remaining challenging for models while incorporating commonsense knowledge improves performance

## Executive Summary
This paper addresses significant biases in the Social-IQ dataset for social intelligence understanding by creating DeSIQ, a debiased benchmark. The authors demonstrate that even small language models can exploit spurious correlations in the original dataset to achieve near-perfect performance without understanding social contexts. Through systematic analysis and perturbation of answer options, they construct DeSIQ to effectively remove these biases. The paper also proposes a new multi-modal architecture that incorporates commonsense knowledge, achieving strong performance on the challenging DeSIQ benchmark.

## Method Summary
The authors first analyze biases in Social-IQ using six methods including NCAQ, MPM, RIWI, RIW A, RA WI, and RA W A. They construct DeSIQ by replacing incorrect answer options with correct ones from other questions using the RIW A perturbation. The study trains baseline models (LSTM, T5-small) and a proposed model (T5-smallDelphi with commonsense knowledge pretraining) on both original and debiased datasets. Performance is evaluated on development sets using binary and 4-way accuracy metrics across A2 and A4 configurations.

## Key Results
- T5-small achieves perfect 100% accuracy on Social-IQ without context or question, exploiting spurious correlations
- DeSIQ effectively reduces bias, dropping model performance close to random guessing
- T5-smallDelphi with commonsense knowledge pretraining achieves strong performance on DeSIQ

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Social-IQ contains substantial biases allowing models to achieve near-perfect performance without understanding social intelligence
- Mechanism: Spurious correlations exist between answer options themselves, independent of questions or context. T5-small learns these correlations and exploits them to classify answers correctly
- Core assumption: The model can separate correct and incorrect answers based solely on their linguistic patterns without needing the question or context
- Evidence anchors:
  - [abstract] "Our analysis reveals that Social-IQ contains substantial biases, which can be exploited by a moderately strong language model to learn spurious correlations to achieve perfect performance without being given the context or even the question"
  - [section 2.3] "T5-small achieves a perfect 100% accuracy score on v1 and 63.35% on v2 without being given the context nor the question"

### Mechanism 2
- Claim: DeSIQ debiasing approach effectively removes biases by replacing incorrect answer options with correct ones from other questions
- Mechanism: By substituting incorrect answers with correct answers from different questions, the linguistic patterns that distinguish correct from incorrect answers are destroyed, forcing the model to rely on actual understanding
- Core assumption: The linguistic patterns that make answer options separable are destroyed when correct answers from other questions are substituted
- Evidence anchors:
  - [abstract] "We introduce DeSIQ, a new challenging dataset, constructed by applying simple perturbations to Social-IQ"
  - [section 3.2] "DeSIQd largely reduces the bias in Social-IQ, effectively reducing the performance of both LSTM and T5-small close to random guess"

### Mechanism 3
- Claim: Incorporating commonsense knowledge into language models improves performance on social intelligence tasks
- Mechanism: Pretraining on commonsense datasets like Social Chemistry 101, ETHICS, and Moral Stories provides the model with relevant knowledge that helps it understand social contexts better
- Core assumption: Social intelligence understanding requires background knowledge that can be captured through pretraining on commonsense corpora
- Evidence anchors:
  - [abstract] "We propose a new model architecture that incorporates commonsense knowledge and achieves strong performance on DeSIQ"
  - [section 4] "Inspired by Jiang et al. (2021), we distill commonsense social knowledge from the following datasets into T5-small"

## Foundational Learning

- Concept: Dataset bias and spurious correlations
  - Why needed here: Understanding why models can achieve high accuracy without real understanding is crucial for evaluating benchmarks
  - Quick check question: What would happen to model performance if you shuffled the answer options randomly?

- Concept: Multi-modal learning
  - Why needed here: The task involves integrating information from text, video, and audio, requiring understanding of how different modalities contribute to understanding
  - Quick check question: How does adding video features affect model performance compared to just using text?

- Concept: Commonsense knowledge integration
  - Why needed here: Social intelligence tasks often require background knowledge that isn't explicitly stated in the input
  - Quick check question: Why might pretraining on social norms datasets help with social intelligence understanding?

## Architecture Onboarding

- Component map: Input processing (separate encoders for question, correct answer, incorrect answer, transcript, video, audio) → Feature projection (three MLPs to map different modalities to same dimensional space) → Backbone model (main transformer-based model that processes concatenated features) → Output layer (classification layer for correct/incorrect answer prediction)
- Critical path: Question → Answer encoding → Commonsense knowledge integration → Multi-modal fusion → Prediction
- Design tradeoffs: Using separate encoders for each modality allows specialized processing but requires careful alignment, while concatenation simplifies architecture but may lose modality-specific information
- Failure signatures: Performance drops to random guessing on DeSIQ indicate successful debiasing, while high performance suggests remaining biases
- First 3 experiments:
  1. Test baseline performance on Social-IQ with "a" input only to verify the bias exists
  2. Apply RIW A perturbation and measure performance drop to confirm bias mechanism
  3. Train on DeSIQd with "q+a+t" input to verify debiasing effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do biases in the Social-IQ dataset affect the development of AI models for social intelligence understanding?
- Basis in paper: [explicit] The paper identifies substantial biases in the Social-IQ dataset and shows that these biases can be exploited by moderately strong language models to achieve near-perfect performance without proper understanding
- Why unresolved: While the paper proposes DeSIQ as a debiased benchmark, it does not fully explore the long-term implications of biases in Social-IQ on the development of AI models for social intelligence
- What evidence would resolve it: Comparative studies of AI models trained on Social-IQ vs. DeSIQ in real-world social intelligence tasks, and longitudinal analysis of model performance as biases are addressed

### Open Question 2
- Question: What is the impact of incorporating socio-cultural and commonsense knowledge into large language models for social intelligence tasks?
- Basis in paper: [explicit] The paper suggests that injecting commonsense knowledge into the backbone language model in their architecture would improve the model's performance on social intelligence tasks
- Why unresolved: The paper does not provide a comprehensive analysis of the effectiveness of incorporating socio-cultural and commonsense knowledge into large language models for social intelligence tasks
- What evidence would resolve it: Systematic evaluation of large language models with and without socio-cultural and commonsense knowledge on social intelligence benchmarks, and analysis of their performance in real-world social scenarios

### Open Question 3
- Question: How can multi-modal language models be effectively utilized to exploit video and audio input for social intelligence understanding?
- Basis in paper: [explicit] The paper proposes a new model architecture to better handle multi-modal inputs, but acknowledges that further research is needed to best utilize multi-modal inputs in DeSIQ-2.0
- Why unresolved: The paper does not provide a definitive solution for effectively utilizing multi-modal language models to exploit video and audio input for social intelligence understanding
- What evidence would resolve it: Development and evaluation of multi-modal language models that effectively integrate video and audio input for social intelligence tasks, and comparison of their performance with uni-modal models

## Limitations

- The debiasing approach relies on simple perturbation by swapping answer options, which may not address all forms of bias or create new artifacts
- The commonsense knowledge pretraining shows improvement but lacks ablation studies on individual knowledge sources
- The analysis focuses on textual biases and doesn't fully address potential biases in the video and audio modalities

## Confidence

- Dataset bias discovery: High - clear empirical evidence with controlled experiments
- DeSIQ construction effectiveness: Medium - demonstrated on the proposed bias types but may not cover all bias forms
- Commonsense knowledge integration: Medium - shows improvement but lacks ablation studies on individual knowledge sources

## Next Checks

1. Test model performance on DeSIQ with randomized answer order to verify that biases are truly eliminated rather than just shifted
2. Conduct ablation studies on the commonsense knowledge pretraining to isolate which knowledge sources contribute most to performance gains
3. Evaluate the approach on additional social intelligence benchmarks to assess generalizability beyond the Social-IQ dataset family