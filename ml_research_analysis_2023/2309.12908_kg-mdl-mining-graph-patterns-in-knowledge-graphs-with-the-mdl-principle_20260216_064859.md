---
ver: rpa2
title: 'KG-MDL: Mining Graph Patterns in Knowledge Graphs with the MDL Principle'
arxiv_id: '2309.12908'
source_url: https://arxiv.org/abs/2309.12908
tags:
- patterns
- graph
- data
- pattern
- mining
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KG-MDL is a graph pattern mining approach based on the Minimum
  Description Length principle, specifically designed for knowledge graphs. It addresses
  the challenges of pattern explosion and the unique characteristics of knowledge
  graphs, such as being multigraphs with power-law degree distributions.
---

# KG-MDL: Mining Graph Patterns in Knowledge Graphs with the MDL Principle

## Quick Facts
- arXiv ID: 2309.12908
- Source URL: https://arxiv.org/abs/2309.12908
- Reference count: 34
- KG-MDL is a graph pattern mining approach based on the Minimum Description Length principle, specifically designed for knowledge graphs.

## Executive Summary
KG-MDL is a parameter-less, anytime graph pattern mining algorithm that adapts the GRAPH MDL+ approach for knowledge graphs. It addresses the challenges of pattern explosion and the unique characteristics of knowledge graphs, such as being multigraphs with power-law degree distributions. The approach generates human-sized sets of descriptive patterns without restrictions on their shape, effectively extracting small sets of patterns that cover most of the data and minimize the MDL description length.

## Method Summary
KG-MDL mines graph patterns from knowledge graphs using the Minimum Description Length (MDL) principle. It converts RDF triples into a labeled multigraph representation, then applies an iterative search algorithm that starts with singleton patterns and merges neighboring embeddings based on MDL score improvements. The approach introduces a new graph representation for knowledge graphs and modifies the MDL encoding to handle multigraphs, enabling the extraction of descriptive patterns that provide insights into both the schema and factual content of the knowledge graphs.

## Key Results
- KG-MDL generates human-sized and descriptive sets of graph patterns
- The approach minimizes MDL description length while covering most of the data
- Extracted patterns provide insights into both schema and factual content of knowledge graphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The MDL principle compresses knowledge graph structure by encoding patterns rather than raw facts
- Mechanism: KG-MDL maps RDF triples into a labeled multigraph, then selects a small set of graph patterns that minimize the total description length of the model (code table) plus the data encoded with it (rewritten graph)
- Core assumption: The set of selected patterns can represent most of the data's structural regularities, so fewer bits are needed than encoding all triples individually
- Evidence anchors:
  - [abstract] "generates a human-sized and descriptive set of graph patterns" and "minimize the MDL description length"
  - [section 4.2.3] "description length that KG-MDL uses to compare different sets of patterns" with explicit L(M) + L(D|M) formula
  - [corpus] Weak — no direct citation; only mentions MDL principle generally
- Break condition: If graph patterns do not cover enough vertex/edge labels, compression ratio degrades toward 100%

### Mechanism 2
- Claim: Port-based encoding avoids loss of structural information when merging patterns
- Mechanism: Each pattern has ports (vertices) that overlap with other pattern occurrences; edges between embeddings and ports preserve connectivity without duplicating edges
- Core assumption: Graph patterns can be composed by sharing ports without ambiguity, and port labeling is sufficient to reconstruct the original graph
- Evidence anchors:
  - [section 4.2.1] "ports of a pattern are the vertices that the pattern's occurrences share" and example in Fig. 4-5
  - [section 4.2.2] "rewritten graph ... composed of two disjoint sets of vertices: each embedding vertex ... represents an occurrence"
  - [corpus] Weak — only mentions MDL and graph mining separately
- Break condition: If port overlap is ambiguous (multiple embeddings map to same port but incompatible structure), reconstruction fails

### Mechanism 3
- Claim: Parameter-free anytime search finds good patterns quickly by iterative merging
- Mechanism: Start from singleton patterns, iteratively merge neighboring embeddings in rewritten graph, accept merge if description length decreases, stop when no improvement
- Core assumption: Local improvements (merging best pair) lead toward global optimum of MDL, and timeout prevents overfitting to rare complex patterns
- Evidence anchors:
  - [section 4.3] "algorithm starts with an initial code table CT0 composed of singleton patterns only" and "tries to add them to the current code table"
  - [section 4.4] "add the possibility to specify a maximum time to spend on each code table row" and experimental timeout results
  - [corpus] Weak — no direct citation of anytime or parameter-free aspects
- Break condition: If timeout too low, useful patterns missed; if too high, search slows and may overfit to noise

## Foundational Learning

- Concept: Minimum Description Length (MDL) principle
  - Why needed here: Core metric for selecting minimal yet descriptive pattern set
  - Quick check question: What two parts compose the MDL description length in KG-MDL?

- Concept: Graph pattern embedding and isomorphism
  - Why needed here: Determines how patterns match data and how occurrences are counted
  - Quick check question: How does KG-MDL define an occurrence of pattern GP in graph GD?

- Concept: Prequential plug-in codes
  - Why needed here: Efficiently encode sequences of vertex/edge labels without knowing full distribution
  - Quick check question: In a prequential code, does the order of elements in the sequence affect the description length?

## Architecture Onboarding

- Component map:
  KG Preprocessor -> Multigraph Converter -> Pattern Miner (KG-MDL) -> Code Table Generator -> Rewritten Graph Builder -> MDL Evaluator -> Search Controller
  External: RDF input, SPARQL query output, visualization web interface

- Critical path:
  1. Load RDF triples -> Convert to KG-MDL graph format
  2. Build initial singleton code table
  3. For each iteration:
     - Compute rewritten graph with timeout
     - Generate candidate merges from neighboring embeddings
     - Evaluate MDL score for each candidate
     - If improvement, accept and loop; else terminate

- Design tradeoffs:
  - Pattern generality vs. interpretability: larger patterns cover more but harder to understand
  - Timeout tuning: balances runtime vs. pattern coverage quality
  - Multigraph support: increases expressiveness but adds encoding complexity

- Failure signatures:
  - Memory blowup: indicates patterns with exponentially many occurrences (power-law degree effect)
  - Stalled search: timeout too low, preventing discovery of useful merges
  - Low compression ratio: patterns not capturing enough structural regularities

- First 3 experiments:
  1. Run KG-MDL on small synthetic graph (e.g., 100 vertices, 200 edges) with no timeout to observe pattern count and compression ratio
  2. Vary row cover timeout (e.g., 50ms, 200ms, 500ms) on medium dataset and compare final MDL scores
  3. Convert extracted patterns to SPARQL queries and execute on original KG to verify correctness of embeddings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can KG-MDL be adapted to handle large-scale knowledge graphs with millions of triples?
- Basis in paper: [inferred] The paper discusses the need for scaling to larger graphs and mentions sampling approaches as a potential solution, but acknowledges that this is not trivial
- Why unresolved: The paper does not provide a concrete solution for scaling KG-MDL to large-scale graphs
- What evidence would resolve it: A detailed study on the performance of KG-MDL with different sampling strategies and their impact on the quality of extracted patterns

### Open Question 2
- Question: Can KG-MDL be extended to support less specific matches for literal values, such as substring matching or range inclusion?
- Basis in paper: [inferred] The paper mentions the possibility of extending KG-MDL to handle less specific matches for literal values in the conclusion section
- Why unresolved: The paper does not explore this extension or provide any experimental results on its effectiveness
- What evidence would resolve it: An implementation of KG-MDL with support for less specific literal matches and an evaluation of its performance on various knowledge graph datasets

### Open Question 3
- Question: How does the choice of the row cover timeout parameter affect the quality of the extracted patterns in KG-MDL?
- Basis in paper: [explicit] The paper discusses the impact of the row cover timeout parameter on the performance of KG-MDL in Section 4.4
- Why unresolved: The paper provides some insights into the effect of the row cover timeout, but a comprehensive study on its impact across different knowledge graph datasets is missing
- What evidence would resolve it: A systematic evaluation of KG-MDL with varying row cover timeout values on multiple knowledge graph datasets, analyzing the trade-off between runtime and pattern quality

## Limitations
- The paper lacks detailed implementation specifics for MDL encoding primitives and the exact heuristic for candidate pattern ranking
- Experimental validation is limited to medium-sized KGs, leaving uncertainty about scalability to larger knowledge graphs
- The paper does not provide statistical significance testing for the claimed improvements in pattern quality and compression ratios

## Confidence

- High confidence in the core MDL-based compression mechanism (Mechanism 1)
- Medium confidence in the port-based encoding approach (Mechanism 2) due to limited implementation details
- Medium confidence in the anytime search algorithm (Mechanism 3) without specific timeout parameter recommendations

## Next Checks

1. Implement and test the prequential plug-in encoding on synthetic data to verify the claimed compression efficiency
2. Conduct runtime and memory usage experiments on progressively larger knowledge graphs to establish scalability boundaries
3. Compare pattern coverage and interpretability against alternative graph mining approaches (e.g., gSpan, CloseGraph) on benchmark KG datasets