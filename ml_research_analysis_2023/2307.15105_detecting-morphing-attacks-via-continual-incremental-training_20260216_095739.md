---
ver: rpa2
title: Detecting Morphing Attacks via Continual Incremental Training
arxiv_id: '2307.15105'
source_url: https://arxiv.org/abs/2307.15105
tags:
- learning
- training
- data
- which
- different
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates continual learning (CL) methods for incrementally
  training morphing attack detection (MAD) systems in privacy-constrained environments.
  It addresses the challenge of updating models as new data chunks become available
  without storing or transferring sensitive data.
---

# Detecting Morphing Attacks via Continual Incremental Training

## Quick Facts
- arXiv ID: 2307.15105
- Source URL: https://arxiv.org/abs/2307.15105
- Reference count: 40
- Primary result: LwF outperforms other CL methods in MAD, with λ tuning critical for performance

## Executive Summary
This paper addresses the challenge of updating morphing attack detection (MAD) systems in privacy-constrained environments where data cannot be stored or transferred. The authors investigate continual learning methods for incrementally training MAD models as new data chunks become available. They find that Learning without Forgetting (LwF) is the most effective approach, particularly when the λ parameter is properly tuned to the experience size. The study introduces the Borda Ranking over Time (BRoT) metric to assess model performance across the entire incremental training process.

## Method Summary
The method involves incremental training of MAD systems using continual learning techniques when new data chunks become available. ArcFace is used as a fixed feature extractor to extract facial features, which are then fed into an MLP classifier. The study compares multiple CL methods including LwF, EWC, SI, and SLDA. Models are updated incrementally as new data chunks arrive, with performance evaluated using metrics like BPCER, APCER, EER, AUC, and the novel BRoT metric. The key innovation is the application of LwF with proper λ tuning to balance preserving prior knowledge and adapting to new data.

## Key Results
- LwF consistently outperforms other CL methods (EWC, SI, SLDA) in MAD incremental training scenarios
- Proper λ tuning is critical for LwF performance, with larger λ values needed for smaller experience sizes
- BRoT metric effectively captures model robustness across the entire incremental training process
- Results generalize beyond MAD to object classification tasks, validating the effectiveness of LwF

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: LwF effectively preserves prior knowledge while adapting to new data chunks in MAD
- **Mechanism**: LwF uses a two-model setup—frozen old model and current model—where the current model is trained with a combined loss that includes both new task accuracy and distillation loss from the old model
- **Core assumption**: The frozen old model accurately represents previously learned features, and distillation loss meaningfully constrains the current model from overwriting them
- **Evidence anchors**: Abstract states LwF "can effectively bridge the gap between traditional batch training and incremental learning"; LwF is identified as "one of the best-performing algorithms"

### Mechanism 2
- **Claim**: Variable experience size necessitates careful λ tuning in LwF to maintain model performance
- **Mechanism**: Larger λ values emphasize preservation of prior knowledge, which is more critical when experience size is small (less new data to learn from)
- **Core assumption**: The relationship between experience size and optimal λ is monotonic and consistent across datasets
- **Evidence anchors**: Paper notes "different λ strongly impact the performance of the LwF, especially in relation to different training experience sizes" and "with small experience sizes it is better to have larger λ values, and vice versa"

### Mechanism 3
- **Claim**: BRoT metric captures model robustness across the entire incremental training process better than single-point metrics
- **Mechanism**: BRoT accumulates Borda scores at each testing experience, rewarding algorithms that consistently rank high, not just peak performance
- **Core assumption**: Rank stability across experiences correlates with real-world deployment reliability
- **Evidence anchors**: BRoT "enables the understanding of which algorithm has the greatest probability of having high accuracy across the whole learning process" and "confirms the tendency noted in the previous cases, revealing that the proper choice of λ is needed to enhance the probability to achieve the best performance"

## Foundational Learning

- **Concept**: Continual Learning (CL) and catastrophic forgetting
  - **Why needed here**: Incremental training without full dataset access risks forgetting prior knowledge, critical in MAD privacy constraints
  - **Quick check question**: What is the difference between CL and standard online learning?

- **Concept**: Distillation loss in LwF
  - **Why needed here**: Balances old knowledge preservation and new learning, key for tuning λ in variable experience sizes
  - **Quick check question**: How does distillation loss prevent catastrophic forgetting?

- **Concept**: Morphing attack detection (MAD) fundamentals
  - **Why needed here**: Understanding MAD task specifics (e.g., differential MAD, BPCER/APCER metrics) is required to interpret results and design experiments
  - **Quick check question**: What is the difference between S-MAD and D-MAD?

## Architecture Onboarding

- **Component map**: Data ingestion → ArcFace feature extractor → MLP classifier → CL module (LwF) → evaluation metrics (BPCER, APCER, AUC, BRoT)
- **Critical path**: Load new data chunk → extract features with ArcFace → update MLP via LwF → evaluate on fixed test set → record metrics
- **Design tradeoffs**:
  - Using ArcFace (fixed) vs. training a feature extractor jointly: fixed reduces privacy risk but may limit task adaptation
  - Replay memory vs. LwF: replay improves performance but conflicts with privacy constraints; LwF is privacy-compliant but less robust
  - Fixed λ vs. adaptive λ: fixed simpler but may require extensive tuning; adaptive more robust but adds complexity
- **Failure signatures**:
  - Rising BPCER over experiences → catastrophic forgetting
  - Inconsistent BRoT rankings → unstable model
  - Large variance across dataset permutations → overfitting or poor generalization
- **First 3 experiments**:
  1. Test LwF with λ=0 (plain fine-tuning) on small experience sizes to confirm catastrophic forgetting baseline
  2. Sweep λ over [50,500] for experience size=100 to identify optimal range
  3. Compare LwF vs. EWC on fixed experience size=200 with λ=200 to validate best-performing CL method

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the performance of LwF-based incremental training compare to other CL methods like EWC and SI when dealing with very small data chunks (e.g., fewer than 50 samples)?
- **Basis in paper**: The paper mentions that LwF performs best among CL methods tested, but does not explore extremely small data chunk sizes in detail
- **Why unresolved**: The paper only tests data chunk sizes starting from 50 samples, leaving the performance on smaller chunks unexplored
- **What evidence would resolve it**: Conducting experiments with data chunks smaller than 50 samples and comparing the performance of LwF with other CL methods like EWC and SI

### Open Question 2
- **Question**: Can the effectiveness of LwF be further improved by dynamically adjusting the λ parameter during training rather than keeping it fixed?
- **Basis in paper**: The paper notes that the choice of λ is challenging and varies with experience size, suggesting that an adaptive choice of λ may be beneficial
- **Why unresolved**: The paper uses a fixed λ value throughout training, without exploring the potential benefits of dynamic adjustment
- **What evidence would resolve it**: Implementing a method to dynamically adjust λ during training and comparing its performance with the fixed λ approach

### Open Question 3
- **Question**: How does the use of embedding-based replay memory compare to traditional sample-based replay memory in terms of privacy and performance in the incremental training scenario?
- **Basis in paper**: The paper mentions that embedding-based replay memory could be a workaround for privacy constraints but notes that further investigations are needed
- **Why unresolved**: The paper does not implement or test embedding-based replay memory, leaving its potential benefits and drawbacks unexplored
- **What evidence would resolve it**: Implementing and testing embedding-based replay memory in the incremental training scenario and comparing its performance and privacy implications with traditional sample-based replay memory

## Limitations

- Study relies on ArcFace as fixed feature extractor, which may not adapt optimally to MAD task
- λ tuning rule is heuristic and may not generalize to other datasets or tasks
- BRoT metric lacks external validation and its correlation with real-world reliability is unproven
- Results may not generalize to other MAD paradigms beyond differential MAD

## Confidence

- **High**: LwF outperforms other CL methods (EWC, SI, SLDA) in MAD incremental training; λ tuning is critical for performance; BRoT captures stability across incremental steps
- **Medium**: λ-tuning rule based on experience size is effective but heuristic; BRoT correlates with model robustness but lacks external validation
- **Low**: Fixed ArcFace feature extractor limits adaptation; results may not generalize to other MAD paradigms; privacy constraint assumptions may not fully represent all deployment scenarios

## Next Checks

1. **External BRoT Validation**: Apply BRoT to other incremental learning tasks (e.g., object classification) to confirm its correlation with real-world reliability
2. **Feature Extractor Ablation**: Compare LwF performance using fixed ArcFace vs. jointly trained feature extractor to quantify the adaptation gap
3. **Generalization Test**: Evaluate LwF with the proposed λ-tuning rule on a non-MAD dataset (e.g., CIFAR-100 incremental) to verify its broader applicability