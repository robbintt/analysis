---
ver: rpa2
title: Enhancing Text Generation with Cooperative Training
arxiv_id: '2303.09075'
source_url: https://arxiv.org/abs/2303.09075
tags:
- training
- discriminator
- generator
- round
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a self-consistent learning framework that
  cooperatively trains a generator and discriminator in a closed loop, enabling both
  models to improve together without the instability issues of adversarial methods.
  The approach uses dynamic thresholding to select and filter generated samples, which
  enhances the generator's domain specificity and improves the discriminator's performance
  over multiple training rounds.
---

# Enhancing Text Generation with Cooperative Training

## Quick Facts
- arXiv ID: 2303.09075
- Source URL: https://arxiv.org/abs/2303.09075
- Reference count: 38
- Key outcome: Cooperative training framework achieves 10+ absolute F1 improvements in zero-shot settings and new state-of-the-art performance in full-data settings for sentence semantic matching tasks

## Executive Summary
This paper introduces a self-consistent learning framework that cooperatively trains a generator and discriminator in a closed loop, enabling both models to improve together without the instability issues of adversarial methods. The approach uses dynamic thresholding to select and filter generated samples, which enhances the generator's domain specificity and improves the discriminator's performance over multiple training rounds. Experiments on sentence semantic matching tasks show significant gains: the discriminator achieves 10+ absolute percentage point improvements in zero-shot settings across multiple datasets, and the overall system reaches new state-of-the-art performance in full-data settings, demonstrating the effectiveness of cooperative training over adversarial alternatives.

## Method Summary
The framework implements cooperative training between a generator (Transformer-XL/OPT) and discriminator (BERT-like) in alternating rounds. The generator creates sentence pairs conditioned on input prompts, which the discriminator scores for semantic similarity. A dynamic thresholding mechanism filters samples based on confidence scores, with thresholds increasing each round to drive convergence. Only high-confidence samples are used to train both models, creating a self-consistent loop where the generator learns to produce domain-specific, semantically similar sentences while the discriminator improves its scoring ability. The system uses pre-training data for initial model warm-up, followed by self-consistent training on domain-related corpora with evaluation on sentence semantic matching benchmarks.

## Key Results
- Discriminator achieves 10+ absolute F1 improvements in zero-shot settings across multiple datasets
- New state-of-the-art performance in full-data settings for sentence semantic matching tasks
- Framework demonstrates stability without mode collapse or non-convergence issues common in adversarial training

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Cooperative training in a closed loop enables the generator and discriminator to mutually improve until reaching a scoring consensus.
- **Mechanism**: The generator creates samples that are scored by the discriminator, and only samples passing a dynamic threshold are used to train both models in alternating rounds. This feedback loop ensures the generator produces domain-specific data while the discriminator becomes better at distinguishing relevant samples.
- **Core assumption**: The generator can produce meaningful samples that the discriminator can score meaningfully, and both models can improve from the other's output.
- **Evidence anchors**:
  - [abstract] "This framework proves to be easy to train and free from instabilities such as mode collapse and non-convergence."
  - [section] "We propose a self-consistent learning framework, in which a discriminator and a generator are cooperatively trained in a closed-loop form."
  - [corpus] Weak: No direct citations about cooperative loops, but the neighbor paper "BetterV: Controlled Verilog Generation with Discriminative Guidance" suggests related discriminative guidance methods.
- **Break condition**: If the generator produces low-quality or irrelevant samples, the discriminator cannot provide useful feedback, breaking the loop. Mode collapse could occur if the generator overfits to a narrow set of samples that always pass the threshold.

### Mechanism 2
- **Claim**: Dynamic thresholding with increasing thresholds drives convergence toward a scoring consensus between generator and discriminator.
- **Mechanism**: Thresholds ϵ_t,k increase each round according to a linear function, ensuring only high-confidence samples are used. This prevents the generator from exploiting weak discriminators and forces both models to improve.
- **Core assumption**: Increasing thresholds will converge to a point where the generator and discriminator reach mutual agreement on sample quality.
- **Evidence anchors**:
  - [abstract] "Experiments on sentence semantic matching tasks show significant gains...demonstrating the effectiveness of cooperative training over adversarial alternatives."
  - [section] "We propose a selection mechanism that uses dynamic thresholds to filter samples. This mechanism is empirically shown to play a critical role in closing the gap between the generator and the discriminator."
  - [corpus] Weak: No direct citations, but the concept aligns with self-consistent learning principles in neighbor paper "UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings."
- **Break condition**: If thresholds increase too rapidly, no samples may pass, halting training. If thresholds increase too slowly, the system may not converge efficiently.

### Mechanism 3
- **Claim**: The generator improves domain specificity and language fluency by learning from filtered samples selected by the discriminator.
- **Mechanism**: After the discriminator scores generated samples, only those with high confidence (passing the threshold) are used to train the generator. This ensures the generator learns to produce samples that are both semantically similar and domain-relevant.
- **Core assumption**: The discriminator can accurately identify high-quality, domain-relevant samples, and the generator can learn from these filtered samples.
- **Evidence anchors**:
  - [abstract] "the discriminator achieves 10+ AP of improvement on the zero-shot setting and new state-of-the-art performance on the full-data setting."
  - [section] "the generated samples can easily deviate from the real data distribution without exploiting any of the signals passed back from the discrimination task."
  - [corpus] Weak: No direct citations, but the neighbor paper "Debiasing Vision-Language Models via Biased Prompts" suggests related discriminative guidance methods.
- **Break condition**: If the discriminator's threshold is too strict, the generator may not receive enough training data. If the discriminator is biased, the generator may learn to produce biased samples.

## Foundational Learning

- **Concept**: Self-consistent learning and closed-loop training.
  - **Why needed here**: This framework relies on the generator and discriminator improving each other through alternating training rounds. Understanding self-consistent learning is crucial to grasp how the models reach a scoring consensus.
  - **Quick check question**: What is the key difference between cooperative and adversarial training in this framework?
- **Concept**: Dynamic thresholding and selection mechanisms.
  - **Why needed here**: The dynamic thresholds ensure only high-quality samples are used for training, driving convergence and preventing mode collapse. Understanding how thresholds are adjusted is critical for implementation.
  - **Quick check question**: How does the threshold function affect the convergence of the cooperative training loop?
- **Concept**: Conditional generation and domain specificity.
  - **Why needed here**: The generator must produce domain-specific samples based on input sentences. Understanding conditional generation is essential for implementing the generator's training process.
  - **Quick check question**: Why is conditional generation used instead of unconditional generation in this framework?

## Architecture Onboarding

- **Component map**: Pre-training data → Generator (Transformer-XL/OPT) → Discriminator (BERT-like) → Dynamic threshold module → Data filtering pipeline → Generator/Discriminator training → Repeat
- **Critical path**: Generate samples → Score with discriminator → Filter by threshold → Train discriminator → Re-score samples → Filter by threshold → Train generator → Repeat
- **Design tradeoffs**:
  - Threshold increase rate: Too fast may halt training; too slow may not converge.
  - Batch size: Larger batches may improve stability but require more memory.
  - Generator architecture: Transformer-XL provides better context handling but is more complex than standard transformers.
- **Failure signatures**:
  - Generator collapse: If all generated samples are rejected by the discriminator, check threshold values and generator training data.
  - Discriminator overfitting: If discriminator performance plateaus, consider adding regularization or adjusting learning rate.
  - Training instability: If F1 scores fluctuate, verify data filtering and threshold adjustment logic.
- **First 3 experiments**:
  1. Verify threshold adjustment logic by logging threshold values each round and ensuring they increase monotonically.
  2. Test data filtering by checking the percentage of samples passing each threshold and ensuring it decreases over rounds.
  3. Validate convergence by plotting KL divergence between generator and discriminator score distributions and ensuring it decreases.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions.

## Limitations

- Limited technical specifications for dynamic thresholding mechanism and mathematical formulations
- No ablation studies to isolate the impact of cooperative training versus thresholding mechanism
- Selection of sentence pairs for pre-training and self-consistent training is not clearly specified
- No analysis of potential bias amplification through the cooperative loop

## Confidence

- **High confidence**: Overall framework design and superiority over adversarial training for sentence semantic matching tasks
- **Medium confidence**: Specific implementation details and hyperparameter choices
- **Low confidence**: Generalizability to other text generation tasks beyond semantic matching

## Next Checks

1. Implement the cooperative training loop with varying threshold increase rates to empirically determine the optimal convergence behavior
2. Compare cooperative training against both adversarial training and supervised training baselines on additional semantic similarity datasets
3. Analyze the diversity of generated samples across training rounds to verify that the generator maintains semantic variety while improving quality