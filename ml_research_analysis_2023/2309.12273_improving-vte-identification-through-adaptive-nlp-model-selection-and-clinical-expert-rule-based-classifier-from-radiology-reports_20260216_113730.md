---
ver: rpa2
title: Improving VTE Identification through Adaptive NLP Model Selection and Clinical
  Expert Rule-based Classifier from Radiology Reports
arxiv_id: '2309.12273'
source_url: https://arxiv.org/abs/2309.12273
tags:
- data
- reports
- dataset
- class
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study develops a VTE classification model using DL and NLP\
  \ techniques. We employed a pre-trained ClinicalBERT for word embedding, a Bi-LSTM\
  \ network for classification tasks, and a rule-based classifier to enhance the DL\
  \ model\u2019s performance."
---

# Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports

## Quick Facts
- arXiv ID: 2309.12273
- Source URL: https://arxiv.org/abs/2309.12273
- Reference count: 24
- This study develops a VTE classification model using DL and NLP techniques with ClinicalBERT + Bi-LSTM architecture, achieving 97% accuracy for DVT and 98.3% accuracy for PE.

## Executive Summary
This study develops a deep learning and natural language processing model to classify Venous Thromboembolism (VTE) events from free-text radiology reports. The approach combines ClinicalBERT word embeddings with a Bi-LSTM network, enhanced by data augmentation techniques and a rule-based classifier developed by medical experts. The model demonstrates high accuracy in detecting both Deep Vein Thrombosis (DVT) and Pulmonary Embolism (PE) from radiology reports, with particular success in improving detection of the rare PE class through the integration of rule-based methods with deep learning.

## Method Summary
The study employs a multi-component approach to VTE classification from radiology reports. ClinicalBERT provides domain-specific word embeddings trained on medical text, which are processed by a Bi-LSTM network for classification. For the PE dataset, data augmentation techniques including synonym replacement and random swapping address class imbalance. A rule-based classifier, developed by medical experts, is integrated with the deep learning model to enhance performance, particularly for the rare PE class. The Adaptive Pre-trained Model Selection (APMS) algorithm dynamically selects the most suitable pre-trained model for the task.

## Key Results
- Achieved 97% accuracy and 97% F1 score for DVT classification
- Achieved 98.3% accuracy and 98.4% F1 score for PE classification
- Rule-based classifier integration significantly improved PE detection in imbalanced dataset

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ClinicalBERT + Bi-LSTM architecture improves VTE classification accuracy compared to simpler models.
- Mechanism: ClinicalBERT provides domain-specific word embeddings trained on medical text, capturing clinical semantics better than general BERT. The Bi-LSTM layer then processes these embeddings bidirectionally, capturing both past and future context for each token, leading to better classification.
- Core assumption: The VTE dataset contains medical terminology and context that ClinicalBERT was specifically trained to understand.
- Evidence anchors:
  - [abstract] states "achieving an impressive 97% accuracy and 97% F1 score in predicting DVT, and an outstanding 98.3% accuracy and 98.4% F1 score in predicting PE."
  - [section] "We select ClinicalBERT because of its superior performance [9] and its relevance to the domain of medical texts."
  - [corpus] weak evidence - no direct citations about ClinicalBERT's performance on VTE data.

### Mechanism 2
- Claim: Data augmentation techniques (synonym replacement and random swapping) improve model performance on the PE dataset.
- Mechanism: Limited and imbalanced datasets often lead to overfitting. Data augmentation creates synthetic training examples by replacing words with synonyms or swapping word positions, increasing dataset size and diversity without changing semantic meaning.
- Core assumption: The synonym replacement maintains semantic equivalence and doesn't introduce noise that would confuse the model.
- Evidence anchors:
  - [section] "The resulting augmented dataset D′ contains the original images along with their augmented versions, ready for training a robust VTE classification model."
  - [section] "Both techniques exhibit better results than not employing any augmentation."
  - [corpus] weak evidence - no direct citations about data augmentation effectiveness for VTE classification.

### Mechanism 3
- Claim: Rule-based classifier integration significantly improves DL model predictions on the PE dataset.
- Mechanism: Deep learning models often underperform on imbalanced datasets, especially for minority classes. The rule-based classifier, developed by medical experts, captures explicit patterns in CT scan reports. By combining DL predictions with rule-based outputs (prioritizing rules when they disagree with DL), the system achieves better overall accuracy, especially for PE detection.
- Core assumption: The rule-based classifier captures clinically relevant patterns that the DL model misses due to data imbalance or limited training examples.
- Evidence anchors:
  - [section] "The integration of rule-based methods with deep learning enhances the model's ability to capture complex patterns and achieve more effective and accurate VTE classification."
  - [section] "The incorporation of rule-based systems plays a crucial role in enhancing the DL model's predictive capacity, especially for the rare class."
  - [corpus] weak evidence - no direct citations about rule-based classifier effectiveness for VTE.

## Foundational Learning

- Concept: Transfer Learning
  - Why needed here: VTE datasets are small and expensive to label. Transfer learning allows leveraging knowledge from large pre-trained models (ClinicalBERT) to improve performance on limited VTE data.
  - Quick check question: Why is fine-tuning ClinicalBERT on VTE data more effective than training a model from scratch on the same data?

- Concept: Natural Language Processing (NLP) for medical text
  - Why needed here: Radiology reports are unstructured text containing critical VTE information. NLP techniques extract meaningful features from this text for machine learning.
  - Quick check question: How does tokenization of medical reports differ from standard text tokenization, and why is it important for VTE classification?

- Concept: Data Imbalance and Augmentation
  - Why needed here: PE cases are much rarer than non-PE cases in the dataset. This imbalance can cause models to bias toward the majority class. Data augmentation helps address this by creating synthetic minority class examples.
  - Quick check question: What are the risks of over-augmenting minority class examples in an imbalanced dataset?

## Architecture Onboarding

- Component map: Input → Tokenizer → ClinicalBERT Embedding → [CLS] Feature Extraction → Bi-LSTM → Linear Layer → Output. Additional path: Input → Rule-based Classifier → Output. Final prediction combines DL and rule outputs.
- Critical path: Tokenization → ClinicalBERT embedding → [CLS] feature extraction → Bi-LSTM processing → Linear classification. This sequence transforms raw text to numerical features for VTE classification.
- Design tradeoffs: ClinicalBERT vs BioBERT vs base BERT - ClinicalBERT offers better domain relevance but may overfit on very small datasets. Bi-LSTM vs LSTM vs Linear - Bi-LSTM captures context better but requires more training data and computational resources.
- Failure signatures: Poor performance on minority class indicates data imbalance issues. High variance between training and validation suggests overfitting. Rule-based classifier dominating DL predictions suggests DL model inadequacy.
- First 3 experiments:
  1. Test ClinicalBERT + Bi-LSTM on DVT dataset without any data augmentation to establish baseline performance.
  2. Apply synonym replacement data augmentation on PE dataset and measure improvement in minority class detection.
  3. Integrate rule-based classifier with DL predictions on PE dataset and measure specificity improvement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed method compare to other state-of-the-art NLP models for VTE classification in terms of accuracy, sensitivity, and specificity?
- Basis in paper: [explicit] The paper mentions comparing the proposed method with baseline contextual embedding techniques and classification methods, including ClinicalBERT, BioBERT, and base BERT, combined with LSTM or linear classifiers.
- Why unresolved: The paper does not provide a comprehensive comparison with other state-of-the-art NLP models for VTE classification, such as those using attention mechanisms or transformers.
- What evidence would resolve it: A detailed comparison of the proposed method with other state-of-the-art NLP models for VTE classification, using the same datasets and evaluation metrics.

### Open Question 2
- Question: How does the proposed method perform on datasets with different sizes and class distributions, and how does it generalize to other medical conditions or domains?
- Basis in paper: [inferred] The paper mentions using two datasets with different sizes and class distributions, but it does not explore how the proposed method performs on datasets with varying characteristics or in other medical domains.
- Why unresolved: The paper does not provide evidence of the proposed method's performance on diverse datasets or its ability to generalize to other medical conditions or domains.
- What evidence would resolve it: Testing the proposed method on multiple datasets with varying sizes, class distributions, and medical conditions, and evaluating its performance and generalization capabilities.

### Open Question 3
- Question: How does the proposed method handle rare or unseen medical terms or concepts in the input text, and how does it incorporate domain-specific knowledge or ontologies?
- Basis in paper: [inferred] The paper mentions using ClinicalBERT, which is pre-trained on clinical notes, but it does not discuss how the proposed method handles rare or unseen medical terms or concepts, or how it incorporates domain-specific knowledge or ontologies.
- Why unresolved: The paper does not provide information on the proposed method's ability to handle rare or unseen medical terms or concepts, or its incorporation of domain-specific knowledge or ontologies.
- What evidence would resolve it: Testing the proposed method on datasets containing rare or unseen medical terms or concepts, and evaluating its ability to handle them and incorporate domain-specific knowledge or ontologies.

## Limitations

- Data source limitation: The study uses datasets from a single medical center, raising concerns about generalizability to other institutions with different reporting styles.
- Implementation transparency: The Adaptive Pre-trained Model Selection algorithm lacks detailed implementation information, making it difficult to assess its contribution to performance.
- Rule-based classifier opacity: Minimal details about the specific rules implemented in the PE classifier make it challenging to evaluate clinical validity and sustainability.

## Confidence

**High Confidence**: ClinicalBERT + Bi-LSTM architecture can achieve high accuracy on VTE classification tasks when properly trained on medical text data; data augmentation techniques can improve model performance on imbalanced datasets.

**Medium Confidence**: The integration of rule-based classifiers with deep learning models can enhance minority class detection; the specific combination of ClinicalBERT, Bi-LSTM, data augmentation, and rule-based integration achieves the reported performance metrics.

**Low Confidence**: The Adaptive Pre-trained Model Selection algorithm reliably identifies the optimal pre-trained model for VTE classification; the model's performance would generalize to different healthcare settings without significant degradation.

## Next Checks

1. **External Validation Study**: Test the complete model pipeline (ClinicalBERT + Bi-LSTM + rule-based integration) on radiology reports from at least two different healthcare institutions to assess generalizability. Compare performance metrics across institutions and identify any systematic variations in accuracy or false positive rates.

2. **Ablation Study on Model Components**: Systematically remove each major component (ClinicalBERT, Bi-LSTM, data augmentation, rule-based classifier) and measure the impact on performance. This will quantify the individual contribution of each component and identify whether simpler architectures could achieve similar results with less complexity.

3. **Temporal Validation**: Apply the model to radiology reports from different time periods (e.g., reports from 2018-2019 vs. 2023) to assess whether the model maintains performance over time as reporting styles and clinical practices evolve. This will reveal whether the rule-based components remain valid and whether the DL model adapts to temporal changes in language use.