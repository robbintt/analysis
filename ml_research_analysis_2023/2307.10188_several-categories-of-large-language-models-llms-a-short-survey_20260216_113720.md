---
ver: rpa2
title: 'Several categories of Large Language Models (LLMs): A Short Survey'
arxiv_id: '2307.10188'
source_url: https://arxiv.org/abs/2307.10188
tags:
- language
- arxiv
- large
- preprint
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey paper provides a comprehensive overview of various
  categories of large language models (LLMs), including task-based financial LLMs,
  multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs,
  and code language models. The paper discusses the methods, attributes, datasets,
  transformer models, and comparison metrics applied in each category of LLMs.
---

# Several categories of Large Language Models (LLMs): A Short Survey

## Quick Facts
- arXiv ID: 2307.10188
- Source URL: https://arxiv.org/abs/2307.10188
- Reference count: 0
- Primary result: This survey provides a comprehensive overview of five major LLM categories with taxonomy tables mapping models to datasets and applications.

## Executive Summary
This survey paper systematically categorizes large language models (LLMs) into five major domains: task-based financial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models. For each category, the paper provides taxonomy tables that detail model configurations, benchmark datasets, implementation details, and applications. The survey identifies unresolved problems in LLM development, particularly around chatbots and virtual assistants, including challenges in boosting NLP capabilities, enhancing chatbot intelligence, and resolving moral and legal dilemmas.

## Method Summary
The paper employs a survey methodology that synthesizes existing research across different LLM categories. It creates structured taxonomy tables that map various models to their benchmark datasets, implementation details, and applications. The survey examines recent developments in each LLM subcategory and identifies open issues and future research directions. The approach focuses on providing a comprehensive overview rather than deep technical analysis of individual models.

## Key Results
- Categorizes LLMs into five major domains with detailed taxonomy tables
- Identifies unresolved problems in chatbot and virtual assistant development
- Provides cross-domain insights by examining multiple LLM subcategories
- Highlights the need for balancing LLM benefits with privacy and ethical concerns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The survey works by categorizing LLMs into five major domains, each with specific applications and datasets.
- Mechanism: It provides structured taxonomy tables that map models to their benchmark datasets, implementation details, and applications.
- Core assumption: Clear categorization helps developers and researchers understand LLM landscape and make informed choices.
- Evidence anchors:
  - [abstract]: "The survey gives a general summary of the methods, attributes, datasets, transformer models, and comparison metrics applied in each category of LLMs."
  - [section]: "This survey attempts to cover the most recent research on LLMs and provides academics and engineers with a helpful resource."
  - [corpus]: Weak evidence - corpus neighbors focus on broader LLM surveys rather than this specific categorization approach.
- Break condition: If categorization becomes too granular or overlaps significantly between domains, the taxonomy loses clarity and utility.

### Mechanism 2
- Claim: The survey works by highlighting unresolved problems in LLM development, particularly in chatbots and virtual assistants.
- Mechanism: It identifies key challenges like boosting NLP, enhancing chatbot intelligence, and resolving moral/legal dilemmas, providing future research directions.
- Core assumption: Identifying problems and challenges helps focus research efforts and guide development priorities.
- Evidence anchors:
  - [abstract]: "Furthermore, it highlights unresolved problems in the field of developing chatbots and virtual assistants, such as boosting natural language processing, enhancing chatbot intelligence, and resolving moral and legal dilemmas."
  - [section]: "Due to the size of large language models, their deployment requires a high level of technical expertise, including a firm understanding of deep learning, transformer models, distributed software, and hardware as well as ethical and legal issues arising from the liability and harm potential of such systems."
  - [corpus]: Weak evidence - corpus neighbors discuss broader LLM challenges but not the specific focus on chatbots and virtual assistants.
- Break condition: If the identified problems are not representative of the broader LLM development community's concerns, the survey loses relevance.

### Mechanism 3
- Claim: The survey works by providing a comprehensive overview of different LLM subcategories, enabling cross-domain learning and application.
- Mechanism: It covers task-based financial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models, allowing insights to transfer between domains.
- Core assumption: Cross-domain understanding accelerates innovation by revealing common patterns and transferable techniques.
- Evidence anchors:
  - [abstract]: "The survey emphasizes recent developments and efforts made for various LLM kinds, including task-based financial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models."
  - [section]: "Recent studies have focused on various LLM types, such as multilingual LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models."
  - [corpus]: Weak evidence - corpus neighbors discuss individual LLM categories but not the comprehensive cross-domain approach.
- Break condition: If the coverage of different LLM subcategories is superficial or unbalanced, the cross-domain insights become unreliable.

## Foundational Learning

- Concept: Transformer architecture
  - Why needed here: LLMs are fundamentally transformer-based models, understanding their architecture is crucial for comprehending model capabilities and limitations.
  - Quick check question: What are the key components of a transformer architecture and how do they contribute to language understanding?

- Concept: Pre-training and fine-tuning
  - Why needed here: LLMs undergo pre-training on large datasets and fine-tuning for specific tasks, understanding this process is essential for grasping model capabilities.
  - Quick check question: What is the difference between pre-training and fine-tuning in the context of LLMs, and why are both necessary?

- Concept: Benchmark datasets and evaluation metrics
  - Why needed here: Evaluating LLM performance requires understanding benchmark datasets and metrics used across different domains.
  - Quick check question: What are some common benchmark datasets used to evaluate LLMs in different domains, and what metrics are typically used?

## Architecture Onboarding

- Component map: Introduction -> Related Work (LLM subcategories) -> Taxonomy Tables (detailed model configurations) -> Open Issues -> Conclusion
- Critical path: Understanding the survey structure → Identifying relevant LLM subcategories → Examining taxonomy tables for specific models → Recognizing unresolved problems and future directions
- Design tradeoffs: Comprehensive coverage vs. depth of analysis for each LLM subcategory; broad taxonomy vs. detailed technical specifications
- Failure signatures: Incomplete or inaccurate taxonomy tables; failure to identify key unresolved problems; lack of cross-domain insights
- First 3 experiments:
  1. Examine taxonomy tables for a specific LLM subcategory (e.g., biomedical and clinical) to understand model configurations and applications.
  2. Compare implementation details across different LLM subcategories to identify common patterns and transferable techniques.
  3. Analyze the unresolved problems section to understand key challenges and potential research directions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal approach to ensure patient privacy while leveraging large clinical language models for analyzing unstructured electronic health records (EHRs)?
- Basis in paper: [explicit] "It is not clear how large clinical language models with billions of parameters can help medical AI systems utilize unstructured electronic health records (EHRs) within the current legal and ethical framework while ensuring privacy of patient information and accuracy of the information provided."
- Why unresolved: The paper highlights the challenge of balancing the potential benefits of using LLMs for analyzing EHRs with the need to protect patient privacy and ensure data accuracy. This requires developing new methods for anonymization, encryption, and access control that can be applied at scale.
- What evidence would resolve it: Demonstrations of LLM systems that can analyze EHRs with high accuracy while maintaining strict privacy controls and obtaining patient consent. Evaluation of the effectiveness of different privacy-preserving techniques in the context of LLMs.

### Open Question 2
- Question: How can the training of large language models be made more environmentally sustainable and cost-effective?
- Basis in paper: [inferred] The paper mentions that "Scaling and maintaining large language models can be difficult and expensive" and that "Building a foundational large language model often requires months of training time and millions of dollars."
- Why unresolved: Training LLMs requires significant computational resources, leading to high energy consumption and costs. This limits the accessibility and scalability of LLM technology.
- What evidence would resolve it: Development and evaluation of more efficient training algorithms, hardware optimizations, and techniques for reducing the size of LLMs without sacrificing performance.

### Open Question 3
- Question: What are the ethical and legal implications of using large language models for decision-making in sensitive domains like healthcare and finance?
- Basis in paper: [explicit] The paper mentions "unresolved problems in the field of developing chatbots and virtual assistants, such as boosting natural language processing, enhancing chatbot intelligence, and resolving moral and legal dilemmas."
- Why unresolved: LLMs are increasingly being used for decision-making in critical domains, but their decision-making processes are often opaque and can perpetuate biases present in the training data. This raises concerns about accountability, fairness, and transparency.
- What evidence would resolve it: Frameworks for auditing and explaining LLM decision-making, guidelines for responsible use of LLMs in sensitive domains, and studies on the potential biases and risks associated with LLM applications.

## Limitations

- The survey lacks technical depth in model architectures and training procedures, focusing instead on surface-level categorizations
- Taxonomy tables do not include quantitative performance comparisons between models within each category
- Coverage of only five LLM categories may miss emerging domains or niche applications
- Analysis of unresolved problems and future directions is general and could benefit from more specific technical insights

## Confidence

- **High**: The categorization of LLM types into five major domains is well-supported and clearly presented
- **Medium**: The taxonomy tables and model references are comprehensive but lack quantitative performance data
- **Low**: The analysis of unresolved problems and future directions is general and could benefit from more specific technical insights

## Next Checks

1. Verify the completeness of taxonomy tables by cross-referencing with recent LLM literature to ensure no significant models or datasets are missing
2. Conduct a quantitative analysis comparing performance metrics across different LLM categories using common benchmark datasets
3. Investigate the technical feasibility of proposed research directions by consulting with domain experts in each LLM category