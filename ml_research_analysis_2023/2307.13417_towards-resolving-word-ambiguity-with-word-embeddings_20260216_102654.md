---
ver: rpa2
title: Towards Resolving Word Ambiguity with Word Embeddings
arxiv_id: '2307.13417'
source_url: https://arxiv.org/abs/2307.13417
tags:
- word
- cluster
- words
- context
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of identifying and evaluating
  word ambiguity in unsupervised manner, using word embeddings and DBSCAN clustering.
  The authors propose an automatic DBSCAN parameter selection method based on silhouette
  score and noise ratio, which leads to high-quality clusters that are semantically
  coherent and correspond well to the perceived meanings of a given word.
---

# Towards Resolving Word Ambiguity with Word Embeddings

## Quick Facts
- arXiv ID: 2307.13417
- Source URL: https://arxiv.org/abs/2307.13417
- Authors: 
- Reference count: 40
- Primary result: Proposes automatic DBSCAN parameter selection for clustering word context vectors to identify ambiguous words and evaluate their level of ambiguity

## Executive Summary
This paper addresses the challenge of identifying and evaluating word ambiguity in an unsupervised manner using word embeddings and DBSCAN clustering. The authors propose an automatic DBSCAN parameter selection method based on silhouette score and noise ratio, which produces high-quality clusters that are semantically coherent and correspond well to the perceived meanings of a given word. The method is evaluated on a German Wikipedia corpus, demonstrating its effectiveness in identifying ambiguous words and assessing their level of ambiguity.

## Method Summary
The paper presents a method for resolving word ambiguity by clustering context vectors of target words using DBSCAN. CBOW word embeddings are trained on a German Wikipedia corpus, and context vectors are generated by summing the embeddings of surrounding words within a fixed window. An automatic DBSCAN parameter selection method is proposed based on a heuristic score that balances silhouette score, cluster count, epsilon value, and noise ratio. Cluster labels are generated using words most similar to cluster centroids in the IN and OUT embedding spaces.

## Key Results
- The proposed automatic DBSCAN parameter selection method produces high-quality clusters that are semantically coherent and correspond to word meanings
- The method effectively identifies ambiguous words and evaluates their level of ambiguity on a German Wikipedia corpus
- The dual embedding spaces (IN and OUT) provide complementary views for generating interpretable cluster labels

## Why This Works (Mechanism)

### Mechanism 1
Word embedding context vectors capture semantic variation that corresponds to different meanings of an ambiguous word. For each occurrence of a target word, a context vector is created by summing the embeddings of surrounding words within a fixed window. These context vectors aggregate all contexts where the word appears, implicitly grouping them by meaning. Clustering these context vectors groups together contexts that share semantic similarity, thereby revealing different meanings.

### Mechanism 2
The dual embedding spaces (IN and OUT) of Word2Vec provide complementary views of word similarity that help interpret clusters. The IN space captures words that typically occur in the context of the target word (thematic similarity), while the OUT space captures words the network predicts as likely center words (functional similarity). By examining both, one can generate descriptive labels for clusters from different angles, improving interpretability.

### Mechanism 3
An automated DBSCAN parameter selection based on silhouette score, cluster count, and noise ratio produces high-quality, interpretable clusters that correspond to word meanings. The parameter score formula balances the number of clusters, average silhouette score (cluster cohesion), epsilon value (cluster tightness), and noise ratio. This heuristic selects parameters that maximize cluster quality while avoiding degenerate results like single clusters or excessive noise.

## Foundational Learning

- Concept: Word embeddings and CBOW architecture
  - Why needed here: The paper relies on CBOW word embeddings to generate context vectors. Understanding how CBOW works (predicting center word from context) and how embeddings are trained is essential to grasp why context vectors can capture semantic variation.
  - Quick check question: In CBOW, what is the relationship between the IN and OUT embedding spaces, and how does this relate to predicting context vs. center words?

- Concept: DBSCAN clustering algorithm
  - Why needed here: The paper uses DBSCAN to cluster context vectors. Understanding DBSCAN's parameters (epsilon, min_samples), how it defines clusters (core, border, noise points), and its sensitivity to density is crucial for interpreting the clustering results and the parameter selection heuristic.
  - Quick check question: How does DBSCAN decide whether a point is a core point, border point, or noise, and how do epsilon and min_samples influence this decision?

- Concept: Silhouette score for cluster evaluation
  - Why needed here: The paper uses silhouette score to evaluate cluster quality. Understanding how silhouette score is calculated (intra-cluster vs. inter-cluster distances) and what values indicate good vs. poor clustering is important for interpreting the parameter selection results.
  - Quick check question: What does a silhouette score close to 1, 0, or -1 indicate about the separation and cohesion of clusters?

## Architecture Onboarding

- Component map: Tokenization -> Word Embedding Training -> Context Vector Generation -> Clustering -> Cluster Labeling -> Evaluation
- Critical path: Tokenization → Word Embedding Training → Context Vector Generation → Clustering → Cluster Labeling → Evaluation
- Design tradeoffs:
  - Using simple CBOW embeddings vs. contextual embeddings (like ELMo or BERT): CBOW is faster and uses less resources but may not capture as fine-grained context dependence.
  - Fixed context window size (5) vs. dynamic or larger windows: Fixed size is simple but may miss long-range dependencies; larger windows may introduce noise.
  - DBSCAN vs. other clustering methods (like K-means): DBSCAN can find clusters of varying shapes and sizes and handle noise, but requires careful parameter tuning; K-means is simpler but assumes spherical clusters and requires specifying K.
- Failure signatures:
  - If context vectors do not separate meaningfully (e.g., all silhouette scores are low), the embeddings may not capture semantic distinctions well.
  - If the automated parameter selection consistently chooses parameters that yield too few or too many clusters, the heuristic may not match the corpus characteristics.
  - If cluster labels are not interpretable (e.g., too generic or unrelated to the target word), the labeling method may not be effective for the domain or language.
- First 3 experiments:
  1. Run the pipeline on a small, controlled dataset with known ambiguous words and their meanings (e.g., a few Wikipedia pages with clear disambiguation pages) to verify that the method can recover the known meanings.
  2. Compare clustering results using only IN space vs. only OUT space vs. both for labeling to assess the contribution of each space to interpretability.
  3. Vary the context window size (e.g., 3, 5, 7) and observe the impact on the number and quality of clusters to find an optimal window size for the corpus.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does IDF-weighting impact the clustering quality and the parameter selection score when computing cluster vectors?
- Basis in paper: The paper mentions that using IDF-weighting could decrease the impact of unspecific words, suggesting potential improvement.
- Why unresolved: The authors did not experiment with IDF-weighting, leaving its effect on clustering quality and parameter selection unexplored.
- What evidence would resolve it: Experiments comparing clustering results and parameter scores with and without IDF-weighting applied to context vectors.

### Open Question 2
- Question: What is the optimal window size for context vector generation to balance between capturing specific meanings and avoiding overly broad domain-level clusters?
- Basis in paper: The paper references work indicating that a bigger window size could produce domain-level, less specific meanings, but the impact on clustering quality is not tested.
- Why unresolved: The authors only tested a fixed window size of 5 and did not explore how varying the window size affects the granularity of cluster meanings.
- What evidence would resolve it: Systematic experiments with different window sizes and analysis of resulting cluster specificity and coherence.

### Open Question 3
- Question: How would using a more advanced tokenizer that better identifies named entities and noun phrases impact the quality of cluster labels and overall disambiguation accuracy?
- Basis in paper: The authors propose switching to a more elaborate tokenizer for better named entity and noun phrase recognition, suggesting potential improvements in cluster labeling.
- Why unresolved: The paper does not implement or test a more advanced tokenizer, leaving the impact on cluster labels and disambiguation accuracy unknown.
- What evidence would resolve it: Comparison of cluster labels and disambiguation accuracy using the current tokenizer versus a more advanced one.

## Limitations
- The generalizability of the results to other languages, domains, or corpora remains uncertain as the paper only evaluates the approach on a German Wikipedia corpus.
- The paper does not provide a quantitative evaluation of the cluster quality or a comparison to alternative methods, limiting the ability to assess the relative performance of the proposed approach.
- The reliance on a fixed context window size and the choice of specific DBSCAN parameters may not be optimal for all types of ambiguous words or all types of semantic distinctions.

## Confidence
- High confidence in the core mechanism that context vectors can capture semantic variation corresponding to different meanings of an ambiguous word, as this is a well-established principle in distributional semantics.
- Medium confidence in the effectiveness of the automated DBSCAN parameter selection method, as the paper provides some evidence of its performance but lacks a rigorous quantitative evaluation.
- Low confidence in the generalizability of the results to other languages, domains, or corpora, as the paper only evaluates the approach on a German Wikipedia corpus.

## Next Checks
1. Conduct a quantitative evaluation of the cluster quality using metrics such as normalized mutual information or adjusted rand index, comparing the results to a gold standard dataset of disambiguated word senses.
2. Test the approach on a diverse set of languages, domains, and corpora to assess its robustness and generalizability beyond the German Wikipedia corpus used in the paper.
3. Compare the performance of the proposed method to alternative approaches for word sense induction or disambiguation, such as supervised methods or other unsupervised clustering techniques, to establish its relative effectiveness.