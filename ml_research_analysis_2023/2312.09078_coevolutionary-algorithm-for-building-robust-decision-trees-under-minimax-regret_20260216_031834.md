---
ver: rpa2
title: Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret
arxiv_id: '2312.09078'
source_url: https://arxiv.org/abs/2312.09078
tags:
- coevordt
- tree
- mixed
- fprdt
- trees
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CoEvoRDT, a novel coevolutionary algorithm
  for constructing robust decision trees (DTs) that can withstand adversarial attacks
  on high-dimensional data. The algorithm employs adaptive coevolution, where populations
  of DTs and perturbed features evolve in competition, allowing the DTs to learn and
  adapt from interactions with perturbed data.
---

# Coevolutionary Algorithm for Building Robust Decision Trees under Minimax Regret

## Quick Facts
- arXiv ID: 2312.09078
- Source URL: https://arxiv.org/abs/2312.09078
- Reference count: 40
- Key outcome: Novel coevolutionary algorithm outperforms 4 state-of-the-art methods on robustness metrics across 20 datasets

## Executive Summary
This paper introduces CoEvoRDT, a coevolutionary algorithm for constructing robust decision trees that can withstand adversarial attacks on high-dimensional data. The method employs adaptive coevolution where populations of decision trees and perturbed features evolve in competition, allowing the DTs to learn and adapt from interactions with perturbed data. The algorithm optimizes various target metrics including minimax regret, which provides a more realistic measure of robustness compared to adversarial accuracy. Tested on 20 popular datasets, CoEvoRDT shows superior performance compared to four state-of-the-art algorithms, outperforming all competitors on 13 datasets with adversarial accuracy metrics and all 20 datasets with minimax regret.

## Method Summary
CoEvoRDT uses a coevolutionary approach where two populations evolve alternately: decision trees and adversarial perturbations. Each DT is evaluated against all perturbations, and each perturbation is evaluated against the top-performing DTs. The algorithm uses mixed Nash equilibrium strategies to enhance convergence and store robust solutions in a Hall of Fame. By fostering competition between populations, the method guides the search toward optimal robust solutions. The alternating optimization progressively tightens bounds on the robust objective, converging when both populations reach local optima against each other. The method can optimize various target metrics and integrates results from other methods.

## Key Results
- Outperforms all 4 state-of-the-art competitors on 13 datasets with adversarial accuracy metrics
- Achieves superior performance on all 20 tested datasets with minimax regret metric
- Shows significant robustness improvements over traditional decision tree methods
- Demonstrates flexibility in accommodating various target metrics beyond just robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coevolutionary competition between decision trees and adversarial perturbations drives robustness by forcing DTs to generalize across a wide range of perturbed inputs.
- Mechanism: The algorithm maintains two evolving populations—one of decision trees and one of input perturbations. Each DT is evaluated against all perturbations, and each perturbation is evaluated against the top-performing DTs. This adversarial dynamic forces the DT population to adapt to worst-case scenarios while the perturbation population seeks weaknesses in current DTs.
- Core assumption: Robustness can be learned through competitive coevolution rather than direct optimization of robustness metrics.
- Evidence anchors:
  - [abstract] "we leverage adaptive coevolution to allow DTs to evolve and learn from interactions with perturbed input data"
  - [section] "By fostering competition between populations, coevolutionary algorithms can guide the search towards the optimal solutions"
- Break condition: If the perturbation population fails to maintain diversity or converges to trivial perturbations that don't challenge the DTs.

### Mechanism 2
- Claim: Mixed Nash equilibrium strategies in the Hall of Fame promote diversity and robustness by preserving solutions that perform well across diverse perturbations.
- Mechanism: Instead of storing only the single best-performing DT, the algorithm computes mixed Nash equilibrium strategies between DT and perturbation populations. These mixed strategies represent probability distributions over multiple DTs/perturbations that collectively form a robust solution. The Hall of Fame stores these mixed strategies, forcing subsequent evolution to consider a broader solution space.
- Core assumption: Mixed strategies from game theory provide better robustness guarantees than pure strategies in adversarial contexts.
- Evidence anchors:
  - [abstract] "Inspired by the game theory, CoEvoRDT utilizes mixed Nash equilibrium to enhance convergence"
  - [section] "Instead of adding the highest-fitness individual to the HoF, in CoEvoRDT, we use a game-theoretic approach"
- Break condition: If the Nash equilibrium computation becomes computationally intractable or if the mixed strategies fail to improve over pure strategies.

### Mechanism 3
- Claim: The alternating optimization between DT and perturbation populations progressively tightens bounds on the robust objective, converging to optimal solutions.
- Mechanism: The algorithm alternates between evolving DTs for multiple generations, then evolving perturbations for multiple generations, repeating this cycle. This creates a tightening effect where perturbations become increasingly challenging while DTs become increasingly robust, with convergence occurring when both populations reach local optima against each other.
- Core assumption: Alternating optimization can achieve the same convergence as simultaneous optimization in adversarial settings.
- Evidence anchors:
  - [section] "The alternating optimization can be understood as improving candidate DTs while progressively tightening a bound on the robust objective"
  - [section] "Theorem 1. If both the decision tree and the perturbation population contain an individual that maximizes their fitness against the opposing population, the decision tree in the current population with the highest fitness optimizes the robust objective"
- Break condition: If the alternating pattern causes oscillation rather than convergence, or if one population consistently dominates the other.

## Foundational Learning

- Concept: Minimax regret as a robustness metric
  - Why needed here: Unlike adversarial accuracy which focuses on worst-case performance, minimax regret considers the difference between the robust DT's performance and the optimal DT's performance across all perturbations, providing a more realistic measure of robustness.
  - Quick check question: How does minimax regret differ from adversarial accuracy in evaluating model robustness?

- Concept: Coevolutionary algorithms and population dynamics
  - Why needed here: The algorithm relies on simultaneous evolution of competing populations (DTs and perturbations) where fitness is evaluated through interactions between populations, requiring understanding of coevolutionary dynamics.
  - Quick check question: What is the key difference between standard evolutionary algorithms and coevolutionary algorithms?

- Concept: Mixed Nash equilibrium in adversarial optimization
  - Why needed here: The Hall of Fame uses mixed Nash equilibrium to store robust strategies that perform well against diverse perturbations, requiring understanding of game-theoretic concepts in optimization contexts.
  - Quick check question: Why might a mixed strategy be more robust than a pure strategy in adversarial machine learning?

## Architecture Onboarding

- Component map:
  DT Population -> Evaluation Engine -> Selection -> Perturbation Population -> Evaluation Engine -> Selection -> Nash Equilibrium Solver -> Hall of Fame -> Repeat

- Critical path: DT Population → Evaluation → Selection → Perturbation Population → Evaluation → Selection → Nash Equilibrium → Hall of Fame → Repeat until stop condition

- Design tradeoffs:
  - Population sizes: Larger populations improve diversity but increase computation time
  - Ntop parameter: Larger values improve perturbation evaluation but may reduce focus on strongest DTs
  - HoF size: Larger HoFs preserve more diversity but increase memory and computation
  - lc parameter: Longer evolution periods per population improve convergence but may cause oscillations

- Failure signatures:
  - Population stagnation: Fitness improvements plateau early
  - Loss of diversity: Population converges to similar solutions
  - Oscillation: Performance alternates between populations without convergence
  - Computational explosion: Runtime grows exponentially with dataset size

- First 3 experiments:
  1. Run CoEvoRDT on a simple 2D dataset with ε=0.1 to verify basic functionality and convergence behavior
  2. Compare results with varying Ntop values (1, 10, 50) on a medium-sized dataset to understand evaluation impact
  3. Test HoF construction strategies (Nash mixed tree vs. top K vs. single best) on a benchmark dataset to measure robustness impact

## Open Questions the Paper Calls Out

- Question: How does CoEvoRDT perform when optimizing fairness criteria in combination with robustness?
  - Basis in paper: [explicit] The paper mentions that CoEvoRDT can integrate other objective criteria such as fairness (Aghaei, Azizi, and Vayanos 2019; Jo et al. 2022).
  - Why unresolved: The experiments only evaluated CoEvoRDT's performance on robustness metrics (adversarial accuracy and minimax regret) without considering fairness objectives.
  - What evidence would resolve it: Experiments comparing CoEvoRDT's performance on fairness-robustness trade-offs against other methods that optimize both objectives.

- Question: What is the impact of using different population sizes (NT and NP) on CoEvoRDT's convergence speed and final performance?
  - Basis in paper: [inferred] The paper mentions that NT=200 and NP=500 were chosen as good compromises between results quality and computation time, but does not explore other population size combinations.
  - Why unresolved: The paper does not provide a systematic study of how population sizes affect CoEvoRDT's performance and convergence.
  - What evidence would resolve it: Experiments varying NT and NP independently and together, measuring convergence speed and final performance on robustness metrics.

- Question: How does CoEvoRDT's performance scale with increasing dataset dimensionality and size?
  - Basis in paper: [explicit] The paper tested CoEvoRDT on 20 datasets with varying numbers of instances, features, and perturbation coefficients, but does not provide a systematic analysis of scaling behavior.
  - Why unresolved: The experiments did not explicitly investigate how CoEvoRDT's performance changes as dataset dimensionality and size increase.
  - What evidence would resolve it: Experiments evaluating CoEvoRDT on datasets with systematically increasing dimensionality and size, measuring performance on robustness metrics and computation time.

## Limitations
- Computational complexity scales with population sizes and perturbation sample sizes, limiting applicability to very large datasets
- Evaluation framework relies on random perturbation sampling, which may not capture all possible adversarial attacks
- Exclusive focus on decision trees limits generalizability to other model families

## Confidence
- High confidence in the core mechanism: Coevolutionary competition between DTs and perturbations provides a principled approach to robustness learning, supported by the alternating optimization framework and theoretical convergence guarantees.
- Medium confidence in the Nash equilibrium implementation: While the game-theoretic foundation is sound, the practical impact of mixed strategies versus pure strategies on real-world robustness requires further validation across diverse threat models.
- Medium confidence in the comparative results: The claimed superiority over four state-of-the-art methods appears well-supported by the experimental setup, though the exclusive focus on decision trees limits generalizability to other model families.

## Next Checks
1. **Perturbation diversity validation**: Test CoEvoRDT's robustness against structured adversarial attacks (e.g., gradient-based methods) rather than random perturbations to verify generalization beyond the training perturbation distribution.

2. **Population size sensitivity**: Systematically vary NT, NP, and NHoF parameters across a wider range to identify optimal configurations and establish scalability boundaries for different dataset characteristics.

3. **Transfer learning capability**: Evaluate whether DTs trained on one dataset using CoEvoRDT can maintain robustness when applied to related datasets with different feature distributions, testing the algorithm's ability to learn generalizable robustness patterns.