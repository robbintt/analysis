---
ver: rpa2
title: Invariance assumptions for class distribution estimation
arxiv_id: '2311.17225'
source_url: https://arxiv.org/abs/2311.17225
tags:
- shift
- distribution
- class
- target
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies class distribution estimation under dataset
  shift. The problem is to estimate class prior probabilities in a test dataset where
  only features are observed, given a training dataset with both features and labels.
---

# Invariance assumptions for class distribution estimation

## Quick Facts
- arXiv ID: 2311.17225
- Source URL: https://arxiv.org/abs/2311.17225
- Authors: 
- Reference count: 12
- Primary result: Sparse joint shift generalizes prior probability shift and enables class distribution estimation when other assumptions fail

## Executive Summary
This paper addresses the problem of estimating class prior probabilities in a test dataset where only features are observed, given training data with both features and labels. The author examines three types of invariance assumptions - covariate shift, factorizable joint shift, and sparse joint shift - to determine their suitability for class distribution estimation under dataset shift. The key finding is that sparse joint shift is particularly appealing as it generalizes prior probability shift while maintaining identifiability, making it suitable for designing class distribution estimators.

## Method Summary
The paper presents methods for class distribution estimation under three invariance assumptions. For covariate shift, it introduces probabilistic classify and count, and importance weighting approaches that leverage unchanged posterior probabilities. For sparse joint shift, it develops a conditional confusion matrix approach that estimates posterior probabilities within strata defined by feature transformations. The methods are validated theoretically through identifiability analysis and consistency proofs, with the sparse joint shift approach showing particular promise as it generalizes prior probability shift while maintaining theoretical guarantees.

## Key Results
- Sparse joint shift (SJS) generalizes prior probability shift while maintaining identifiability
- Covariate shift enables estimation through probabilistic classify and count and importance weighting methods
- Factorizable joint shift lacks identifiability without additional constraints
- The conditional confusion matrix approach effectively estimates class priors under SJS
- Covariate shift, sparse covariate shift, and sparse joint shift are related when conditional distribution invariance holds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sparse joint shift (SJS) enables class distribution estimation even when covariate shift and prior probability shift assumptions fail.
- Mechanism: SJS assumes that the joint distribution of labels and a transformation of features is invariant between training and test sets. By stratifying on this transformation, the problem reduces to a series of manageable estimation tasks, each satisfying prior probability shift assumptions.
- Core assumption: There exists a feature transformation T such that conditional distributions of features given both the class and T are invariant between training and test sets.
- Evidence anchors:
  - [abstract] "The key finding is that sparse joint shift is particularly appealing as it generalizes prior probability shift while maintaining identifiability."
  - [section] "SJS is shown to be a generalization of prior probability shift and found to be a suitable assumption for designing class distribution estimators."
  - [corpus] Weak evidence; the corpus does not contain explicit mentions of SJS or sparse joint shift.
- Break condition: If no such transformation T exists that creates sufficient strata for estimation, or if the conditional independence assumptions required by SJS are violated.

### Mechanism 2
- Claim: Covariate shift enables class distribution estimation by assuming posterior class probabilities remain unchanged between distributions.
- Mechanism: Under covariate shift, the relationship P[Y=y|X=x] = Q[Y=y|X=x] holds. This allows estimation of test class priors by averaging estimated posterior probabilities over the test feature distribution.
- Core assumption: The posterior class probabilities (the "concept") are invariant between training and test distributions.
- Evidence anchors:
  - [abstract] "For covariate shift, the paper presents two new estimation approaches: probabilistic classify and count, and importance weighting."
  - [section] "Definition 2 (Covariate Shift)... P [Y = y | X = x] = ηy(x) = Q[Y = y | X = x], almost surely for all x under PX and under QX."
  - [corpus] No explicit mention of covariate shift in the corpus, but the concept is fundamental to domain adaptation literature.
- Break condition: If the posterior probabilities change between distributions, or if the feature distributions have disjoint supports.

### Mechanism 3
- Claim: Importance weighting under covariate shift provides a consistent estimator for class prior probabilities.
- Mechanism: By weighting training samples by the ratio of test to training feature densities, one can create a weighted sample that approximates the test distribution. Class priors are then estimated by counting weighted labels.
- Core assumption: The feature importance weight function wX(x) = qX(x)/pX(x) can be accurately estimated from samples.
- Evidence anchors:
  - [section] "With the feature importance weight function wX defined by (2b), under covariate shift it holds true that Q[Y = y] = EP [wX(X) 1{y}(Y )]"
  - [section] "The class prior probabilities Q[Y = y] can be estimated by means of the estimator ¯Qm[Y = y] = 1/m ∑ wX(xi) 1{y}(yi)"
  - [corpus] No direct evidence in corpus about importance weighting, but the concept is well-established in domain adaptation.
- Break condition: If the density ratio is impossible to estimate accurately, or if the training and test feature distributions have little overlap.

## Foundational Learning

- Concept: Dataset shift (distribution shift)
  - Why needed here: The entire paper addresses estimation problems under distributional changes between training and test data.
  - Quick check question: What is the difference between covariate shift and prior probability shift?

- Concept: Importance weighting
  - Why needed here: It's a key technique for handling covariate shift and is used in one of the proposed estimation methods.
  - Quick check question: How does importance weighting correct for differences in feature distributions?

- Concept: Sufficient statistics and transformations
  - Why needed here: The sparse joint shift approach relies on finding transformations that make certain conditional distributions invariant.
  - Quick check question: What makes a transformation T "sufficient" for estimating posterior probabilities under covariate shift?

## Architecture Onboarding

- Component map: Feature extraction -> Posterior probability estimation -> Feature importance weight estimation -> Class prior calculation -> Cross-method validation
- Critical path: 1. Estimate posterior probabilities from training data 2. Identify appropriate feature transformation (if using SJS) 3. Estimate feature importance weights (if using covariate shift) 4. Calculate class prior probabilities using chosen method 5. Validate results using alternative estimation approach
- Design tradeoffs:
  - SJS requires identifying appropriate transformations but can handle more complex shifts
  - Covariate shift is simpler but requires the concept to remain unchanged
  - Importance weighting is theoretically sound but can have high variance when density ratios are extreme
- Failure signatures: Large discrepancies between different estimation methods, high variance in importance weighted estimates, poor classifier performance on either training or test data
- First 3 experiments:
  1. Implement and compare probabilistic classify and count vs. importance weighting under simulated covariate shift
  2. Test sparse joint shift estimation with a known transformation (e.g., age groups in medical data)
  3. Validate identifiability conditions for factorizable joint shift on synthetic data with known parameters

## Open Questions the Paper Calls Out

- Open Question 1: How can we identify feature transformations that entail SJS when theoretical considerations cannot identify them?
  - Basis in paper: [explicit] The paper mentions that an open research problem is how to identify feature transformations that entail SJS if they cannot be identified by theoretical considerations. Chen et al. (2022) suggested brute-force approaches, but these have issues that might make their application questionable.
  - Why unresolved: Theoretical methods may not always be sufficient to identify the correct transformations, and brute-force approaches have limitations and issues that make them unreliable.
  - What evidence would resolve it: Development of new methods or approaches that can reliably identify feature transformations leading to SJS without relying solely on theoretical considerations or brute-force methods.

- Open Question 2: What are the practical implications of using the conditional confusion matrix approach for class distribution estimation under SJS?
  - Basis in paper: [explicit] The paper describes the conditional confusion matrix approach as a method to estimate target posterior probabilities and class prior probabilities under SJS. It mentions that this approach generalizes the confusion matrix approach and could be deployed to check assumptions of prior probability shift.
  - Why unresolved: While the approach is described, the paper does not provide detailed empirical results or case studies demonstrating its effectiveness in real-world scenarios.
  - What evidence would resolve it: Empirical studies or case studies applying the conditional confusion matrix approach to real-world datasets, comparing its performance with other methods, and demonstrating its practical utility.

- Open Question 3: How does the identifiability of factorizable joint shift (FJS) under additional constraints compare to its lack of identifiability in the unsupervised setting?
  - Basis in paper: [explicit] The paper notes that FJS is not fully identifiable in the unsupervised setting of this paper, i.e., if no labels are observed in the target dataset. However, it does not discuss how additional constraints might make FJS identifiable.
  - Why unresolved: The paper highlights the lack of identifiability under FJS but does not explore or provide examples of additional constraints that could resolve this issue.
  - What evidence would resolve it: Research that identifies specific additional constraints or conditions under which FJS becomes identifiable, along with empirical or theoretical evidence supporting these constraints.

## Limitations

- Sparse joint shift requires identifying appropriate feature transformations, which may be challenging in practice
- The conditional confusion matrix approach needs accurate posterior probability estimation within each stratum
- Factorizable joint shift lacks identifiability without additional constraints, limiting its practical utility
- Limited empirical validation on real-world datasets to demonstrate practical effectiveness

## Confidence

**High confidence**: The theoretical framework for covariate shift and its relationship to importance weighting is well-established and clearly presented. The distinction between different types of shift assumptions and their identifiability conditions is rigorously analyzed.

**Medium confidence**: The practical effectiveness of the sparse joint shift approach depends heavily on the ability to find appropriate transformations. While the generalization from prior probability shift is mathematically sound, real-world applicability may be limited by the difficulty of identifying suitable T.

**Low confidence**: The paper does not provide sufficient empirical validation of the proposed methods on real-world datasets. The theoretical advantages of sparse joint shift over other approaches need to be demonstrated through comprehensive experiments across diverse domains.

## Next Checks

1. **Cross-method validation**: Implement all three estimation approaches (probabilistic classify and count, importance weighting, and conditional confusion matrix) on the same dataset with known shift characteristics, and compare their consistency and accuracy.

2. **Transformation sensitivity analysis**: Systematically evaluate how different choices of feature transformation T affect the performance of sparse joint shift estimation, using synthetic data with controlled shift patterns.

3. **Break-case identification**: Design adversarial scenarios where each shift assumption fails (e.g., posterior probability change for covariate shift, non-identifiable parameters for factorizable joint shift) to quantify the robustness of each method.