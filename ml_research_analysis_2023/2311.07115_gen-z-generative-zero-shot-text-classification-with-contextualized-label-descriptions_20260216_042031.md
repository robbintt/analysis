---
ver: rpa2
title: 'Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label
  Descriptions'
arxiv_id: '2311.07115'
source_url: https://arxiv.org/abs/2311.07115
tags:
- label
- classification
- text
- descriptions
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Gen-Z, a zero-shot text classification framework
  that uses a generative approach with contextualized label descriptions to achieve
  better performance and robustness compared to discriminative baselines. The key
  idea is to explicitly incorporate contextual information via label descriptions,
  instead of relying on implicit concept learning as in few-shot in-context learning.
---

# Gen-Z: Generative Zero-Shot Text Classification with Contextualized Label Descriptions

## Quick Facts
- arXiv ID: 2311.07115
- Source URL: https://arxiv.org/abs/2311.07115
- Reference count: 36
- Key outcome: Gen-Z achieves better zero-shot performance than discriminative baselines by using contextualized label descriptions in a generative framework

## Executive Summary
This paper introduces Gen-Z, a generative zero-shot text classification framework that explicitly incorporates contextual information through expressive label descriptions. Unlike traditional few-shot in-context learning that relies on implicit concept acquisition, Gen-Z directly models p(x|y) by estimating the likelihood of generating input text given label descriptions. The approach aggregates probabilities across multiple paraphrases of each label description, improving robustness to prompt variations while enabling seamless integration of additional context like domain, author, or reader information.

## Method Summary
Gen-Z generates label descriptions for each class, creates multiple paraphrases of these descriptions, and computes the likelihood of generating each input text given each paraphrased description. Probabilities are aggregated across paraphrases per label, and the label with highest aggregated probability is selected. The framework uses contextual information (domain, source, author, addressee, reader demographics) within label descriptions to prime the model. Evaluation involves computing macro-F1 scores across 19 text classification datasets using six model families ranging from 125M to 13B parameters, with results averaged over 10 trials using different subsets of label descriptions.

## Key Results
- Gen-Z consistently outperforms zero-shot discriminative baselines across all 19 datasets and six model families
- The approach achieves competitive performance with few-shot in-context learning while being more robust to prompt variations
- Incorporating contextual information through label descriptions significantly improves performance on personalized classification tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Generative classification with label descriptions improves calibration by measuring p(x|y) instead of p(y|x)
- Mechanism: Generative models estimate the likelihood of generating the input text given a label description, avoiding surface form competition where multiple descriptions compete for probability mass
- Core assumption: The generative formulation p(x|y) provides better worst-case performance than discriminative p(y|x) for text classification
- Evidence anchors: [abstract] "instead of relying on implicit concept learning as in few-shot in-context learning", [section] "Prior work has shown evidence that generative classifiers can be more robust than the discriminative ones which may look for shortcuts to predict the label"
- Break condition: If the generative model's pretraining distribution is too far from the target domain, the likelihood estimates become unreliable

### Mechanism 2
- Claim: Aggregating over multiple paraphrased label descriptions reduces variance from prompt variations
- Mechanism: By computing p(x|zi) for multiple paraphrases zi of each label description and summing them, the approach smooths out individual prompt sensitivity
- Core assumption: Different paraphrases of the same semantic content will produce similar probabilities, and averaging them reduces noise
- Evidence anchors: [abstract] "we propose to compute and aggregate the results across multiple paraphrases of the label descriptions", [section] "unlike common prompting scenarios, the label descriptions, zi, are unique for each label yi being considered"
- Break condition: If paraphrases introduce semantic drift or if the model overfits to specific phrasings, aggregation may not help

### Mechanism 3
- Claim: Incorporating contextual information through label descriptions acts as explicit concept priming
- Mechanism: Label descriptions include domain, author, reader, or subject information that primes the model with relevant context, replacing implicit concept learning from demonstrations
- Core assumption: The language model can effectively use the additional contextual information in label descriptions to improve classification
- Evidence anchors: [abstract] "GEN-Z is multivariate, as label descriptions allow us to seamlessly integrate additional contextual information", [section] "To prime the models to solve the task, we propose to explicitly incorporate contextual information via expressive label descriptions"
- Break condition: If the contextual information is noisy or irrelevant, it may degrade performance rather than improve it

## Foundational Learning

- Concept: Probabilistic classification frameworks (generative vs discriminative)
  - Why needed here: Understanding the difference between p(x|y) and p(y|x) is crucial for grasping why the generative approach works
  - Quick check question: What is the key mathematical difference between how generative and discriminative classifiers estimate probabilities?

- Concept: Language model prompting and in-context learning
  - Why needed here: The paper builds on in-context learning mechanisms but replaces them with zero-shot approaches
  - Quick check question: How does in-context learning differ from the proposed zero-shot approach in terms of concept acquisition?

- Concept: Bayesian inference and concept learning
  - Why needed here: The paper draws connections between in-context learning and Bayesian inference over latent concepts
  - Quick check question: In the Bayesian interpretation of in-context learning, what role does the context variable Î¸ play?

## Architecture Onboarding

- Component map: Label description generator -> Language model -> Probability aggregation module -> Classification decision layer -> Context integration module
- Critical path: 1. Generate label descriptions for each class, 2. Create paraphrases of each description, 3. For each input, compute p(x|zi) for all label-description pairs, 4. Aggregate probabilities by summing over paraphrases per label, 5. Select label with highest aggregated probability
- Design tradeoffs: Multiple paraphrases vs computational cost (tradeoff between robustness and efficiency), Generative vs discriminative formulation (tradeoff between calibration and simplicity), Context integration depth vs model capacity (tradeoff between personalization and generalization)
- Failure signatures: High variance across different paraphrase sets (indicates sensitivity to specific phrasings), Performance degradation when adding contextual information (indicates context is noisy or irrelevant), Poor performance on datasets with semantically overlapping classes (indicates need for more specific descriptions)
- First 3 experiments: 1. Compare single paraphrase vs multiple paraphrase aggregation on a sentiment dataset, 2. Test generative vs discriminative formulations on the same dataset, 3. Evaluate impact of adding domain context to label descriptions on classification accuracy

## Open Questions the Paper Calls Out

- How do the findings of Gen-Z transfer to languages other than English, given that all datasets used in the study are exclusively in English?
- How does the performance of Gen-Z compare to other methods when the dataset includes more diverse gender identities beyond binary male/female?
- What is the impact of using different aggregation strategies (arithmetic mean, geometric mean, harmonic mean) on the performance of Gen-Z in the generative classification setup?

## Limitations
- Heavy dependence on high-quality, contextually rich label descriptions with no systematic guidance for creating effective descriptions
- Limited evaluation scope focusing on simple classification tasks with semantically distinct classes
- Computational cost of generating and evaluating multiple paraphrases per label makes the approach impractical for real-time applications or large label spaces

## Confidence
- **High Confidence (9/10):** Empirical results showing Gen-Z outperforms zero-shot discriminative baselines
- **Medium Confidence (6/10):** Claims of achieving competitive results compared to few-shot in-context learning
- **Low Confidence (3/10):** Theoretical claims about inherent robustness advantages of generative over discriminative classification

## Next Checks
1. Ablation study on label description quality: Systematically vary description quality and informativeness to quantify dependence on description quality versus generative formulation
2. Stress test with adversarial paraphrases: Generate intentionally misleading paraphrases to measure performance degradation compared to standard prompting approaches
3. Scalability evaluation on large label spaces: Test Gen-Z on datasets with 50+ labels to validate computational feasibility claims and measure performance scaling