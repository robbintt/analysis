---
ver: rpa2
title: Towards a Prediction of Machine Learning Training Time to Support Continuous
  Learning Systems Development
arxiv_id: '2309.11226'
source_url: https://arxiv.org/abs/2309.11226
tags:
- uni00000013
- uni00000014
- time
- training
- uni00000048
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper evaluates the Full Parameter Time Complexity (FPTC)
  method for predicting machine learning training times. It investigates two research
  questions: whether the slope parameter is execution environment-dependent and whether
  FPTC can predict training times.'
---

# Towards a Prediction of Machine Learning Training Time to Support Continuous Learning Systems Development

## Quick Facts
- arXiv ID: 2309.11226
- Source URL: https://arxiv.org/abs/2309.11226
- Reference count: 26
- The slope parameter in FPTC is not only environment-dependent but also varies with dataset features, especially for Random Forest, limiting generalizability of the method.

## Executive Summary
This paper evaluates the Full Parameter Time Complexity (FPTC) method for predicting machine learning training times, specifically for Logistic Regression and Random Forest classifiers. The study investigates whether the slope parameter in FPTC is execution environment-dependent and whether FPTC can accurately predict training times. Experiments on 7 heterogeneous datasets reveal that the slope parameter varies significantly with dataset characteristics, particularly the number of features for Random Forest. While FPTC successfully predicts training times for some datasets, it fails for others with no clear correlation to dataset properties, and tends to systematically underestimate actual training times.

## Method Summary
The study uses the Full Parameter Time Complexity (FPTC) approach to predict training times for Logistic Regression and Random Forest classifiers. The method involves computing a slope parameter through linear regression between actual training times and FPTC predictions across subsets of the dataset. This slope is then used to scale FPTC predictions to actual training times. The evaluation uses 7 heterogeneous datasets with varying dimensions (30940-373 instances, 59-10000 features, 2 classes) and specific hyperparameters for each model type. Prediction accuracy is measured using Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE).

## Key Results
- The slope parameter in FPTC varies not only with execution environment but also with dataset features, especially for Random Forest classifiers.
- FPTC successfully predicts training times for some datasets but fails for others, with no clear correlation between dataset characteristics and prediction accuracy.
- The FPTC method tends to systematically underestimate actual training times, particularly for larger or more complex datasets.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The slope parameter in FPTC is not solely dependent on execution environment but also varies with dataset characteristics.
- Mechanism: The slope is computed via linear regression between actual training times and FPTC predictions across subsets of the dataset. Variations in the number of features alter this relationship, causing slope instability.
- Core assumption: Linear regression slope adequately captures the relationship between FPTC and actual training time under varying feature counts.
- Evidence anchors:
  - [section] "Concerning the Random Forest classifier, it can be seen from figure 1b how the slopes present a higher variability among them, starting from a value around 8.5 ∗ 10−10 using 501 features to a value of 2 ∗ 10−10 using 9519 features."
  - [corpus] "Average neighbor FMR=0.438" (weak evidence for related literature, no direct mechanism support).
- Break condition: If the relationship between FPTC and training time is non-linear or if feature count effects are confounded with other dataset attributes.

### Mechanism 2
- Claim: FPTC can predict training times for some datasets but fails for others, with no clear correlation to dataset characteristics.
- Mechanism: The prediction accuracy depends on how well the FPTC formula aligns with the actual computational complexity of the model on the given dataset. This alignment varies across datasets.
- Core assumption: FPTC formula captures the essential computational components of training time.
- Evidence anchors:
  - [abstract] "FPTC successfully predicts training times for some datasets but fails for others, with no clear correlation between dataset characteristics and prediction accuracy."
  - [section] "From this analysis, we can conclude how the FPTC method is able to predict the training time of a Logistic Regression and Random Forest classifier under certain circumstances (i.e., datasets) while it is not working in others."
- Break condition: If FPTC formula omits critical computational steps or if dataset characteristics interact in ways not modeled by FPTC.

### Mechanism 3
- Claim: FPTC tends to underestimate actual training times, especially for larger or more complex datasets.
- Mechanism: The FPTC formula may not fully account for overheads such as data loading, preprocessing, or parallelization effects, leading to systematic underestimation.
- Core assumption: The constants and exponents in the FPTC formula are calibrated to capture all major time components.
- Evidence anchors:
  - [section] "From this table, it can be seen how the FPTC method tends to underestimate the real training time, especially in Adult (with a delta of almost 2 seconds between the actual training time and the predicted one), and APS (with a delta of almost 50 seconds between the actual training time and the predicted one)."
- Break condition: If additional computational steps are introduced or if hardware/software optimizations alter time distribution.

## Foundational Learning

- Concept: Linear regression for parameter estimation
  - Why needed here: Used to compute the slope parameter that relates FPTC to actual training times.
  - Quick check question: What happens to the slope if training times grow faster than FPTC predictions with increasing dataset size?

- Concept: Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE)
  - Why needed here: Metrics used to quantify the accuracy of FPTC predictions against actual training times.
  - Quick check question: Why might MAPE be misleading when actual training times are very small?

- Concept: Time complexity analysis of ML algorithms
  - Why needed here: Understanding how algorithmic steps scale with dataset size and features is essential for interpreting FPTC behavior.
  - Quick check question: How does the number of iterations in Logistic Regression affect its training time complexity?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training -> FPTC calculation -> Slope computation -> Error evaluation -> Result interpretation

- Critical path: Slope computation → FPTC prediction → Error evaluation → Result interpretation

- Design tradeoffs:
  - Using synthetic vs. real datasets for slope computation: synthetic allows control but may lack realism.
  - Number of feature subsets: more subsets improve slope stability but increase computation.
  - Choice of error metrics: RMSE is sensitive to outliers; MAPE can explode for small true values.

- Failure signatures:
  - High variability in slopes across feature subsets → unreliable predictions.
  - Systematic underestimation of training times → missing computational components in FPTC.
  - Inconsistent prediction accuracy across datasets → FPTC not generalizable.

- First 3 experiments:
  1. Replicate slope computation with a different synthetic dataset to test robustness.
  2. Vary the number of trees in Random Forest to see how it affects slope stability.
  3. Add a preprocessing step (e.g., feature selection) and observe changes in prediction accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific dataset characteristics beyond feature count affect the slope parameter in FPTC?
- Basis in paper: [inferred] The paper shows slope varies with feature count for Random Forest and states "the slope is also related to the number of features of the dataset used to compute them." This suggests other dataset characteristics may also influence slope.
- Why unresolved: The experiments only varied feature count while keeping other dataset properties constant. Other characteristics like sample size, class balance, or feature correlations were not systematically studied.
- What evidence would resolve it: Controlled experiments varying one dataset characteristic at a time (sample size, feature dimensionality, class distribution, feature correlations) while computing slopes for both Logistic Regression and Random Forest.

### Open Question 2
- Question: Can the FPTC method be adapted to predict training times for deep learning models?
- Basis in paper: [explicit] The paper only evaluated FPTC on Logistic Regression and Random Forest classifiers, leaving "the analysis of other methods to future works" and explicitly mentioning deep learning as a future direction.
- Why unresolved: The current FPTC formulations are specific to traditional ML algorithms with explicit mathematical formulations. Deep learning models have different training dynamics and architectures that may require fundamentally different complexity formulations.
- What evidence would resolve it: Application of FPTC principles to deep learning architectures, developing new complexity formulations for neural networks, and empirical validation on various deep learning models.

### Open Question 3
- Question: Is there a systematic way to select the optimal slope value for a given dataset and model combination?
- Basis in paper: [inferred] The paper shows that prediction accuracy strongly depends on the slope value, which varies between datasets, but provides no method for selecting the appropriate slope.
- Why unresolved: The authors simply tried multiple slopes computed from synthetic datasets and selected the one yielding best predictions, but this approach doesn't scale and provides no guidance for new datasets.
- What evidence would resolve it: Development of a principled method (e.g., based on dataset characteristics, model complexity, or a small calibration set) that reliably predicts the optimal slope without exhaustive search.

## Limitations
- The slope parameter varies significantly with dataset features, limiting the generalizability of FPTC predictions.
- The method systematically underestimates actual training times, suggesting missing computational components in the FPTC formula.
- No clear correlation exists between dataset characteristics and prediction accuracy, making it difficult to identify suitable datasets for FPTC.

## Confidence
- High confidence in the observation that slope parameters vary with dataset features, supported by direct experimental evidence.
- Medium confidence in the conclusion that FPTC is not generalizable, as the sample size of datasets is limited.
- Medium confidence in the underestimation trend, though the specific causes (e.g., missing computational steps) require further investigation.

## Next Checks
1. Replicate the slope computation experiments with a larger and more diverse set of datasets to confirm the variability pattern.
2. Analyze the FPTC formula to identify potential missing computational components that could explain the systematic underestimation.
3. Test the impact of different hyperparameter settings (e.g., number of trees in Random Forest) on slope stability and prediction accuracy.