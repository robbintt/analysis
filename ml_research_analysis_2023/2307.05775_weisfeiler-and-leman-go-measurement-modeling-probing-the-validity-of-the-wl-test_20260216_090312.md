---
ver: rpa2
title: 'Weisfeiler and Leman Go Measurement Modeling: Probing the Validity of the
  WL Test'
arxiv_id: '2307.05775'
source_url: https://arxiv.org/abs/2307.05775
tags:
- graph
- expressive
- power
- k-wl
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper critically examines the use of the k-dimensional Weisfeiler-Leman
  (k-WL) test as a measure of graph neural network (GNN) expressive power. Through
  a survey of 18 graph ML practitioners and theoretical analysis, the authors find
  that k-WL does not guarantee isometry, can be irrelevant to real-world graph tasks,
  and may not promote generalization or trustworthiness.
---

# Weisfeiler and Leman Go Measurement Modeling: Probing the Validity of the WL Test

## Quick Facts
- arXiv ID: 2307.05775
- Source URL: https://arxiv.org/abs/2307.05775
- Reference count: 40
- Key outcome: The paper critically examines the use of the k-dimensional Weisfeiler-Leman (k-WL) test as a measure of graph neural network (GNN) expressive power. Through a survey of 18 graph ML practitioners and theoretical analysis, the authors find that k-WL does not guarantee isometry, can be irrelevant to real-world graph tasks, and may not promote generalization or trustworthiness. Their experiments on popular benchmarks show that 1-WL often distinguishes all non-isomorphic graphs or nodes, suggesting that more expressive GNNs may not be necessary for these tasks. They also find that GNNs may learn representations more optimal for specific tasks than WL-aligned ones. The authors argue for extensional definitions and measurement of expressive power based on benchmarks, and provide guiding questions for constructing such benchmarks. This work highlights the need for more rigorous evaluation of GNN expressive power and its practical implications.

## Executive Summary
This paper critically examines the use of the k-dimensional Weisfeiler-Leman (k-WL) test as a theoretical upper bound on graph neural network (GNN) expressive power. Through a survey of 18 graph ML practitioners and empirical analysis on popular benchmarks, the authors find that k-WL often does not constrain practical GNN performance, may lack isometry, and can be irrelevant to real-world graph tasks. They argue for extensional definitions of expressive power based on task-specific benchmarks rather than intensional definitions based on theoretical properties like k-WL alignment. The authors provide guiding questions for constructing benchmarks that better measure GNN expressive power in practice.

## Method Summary
The paper employs a mixed-methods approach to evaluate the validity of k-WL as a measure of GNN expressive power. The authors conduct a survey of 18 graph ML practitioners to understand their conceptualizations of expressive power and perceptions of k-WL. They then perform theoretical analysis of k-WL's reliability and validity as a measurement tool. Finally, they audit popular graph ML benchmarks to assess k-WL's relevance and alignment with GNN representations. The study combines qualitative insights from practitioners with quantitative analysis of benchmark performance to argue for a shift towards extensional definitions of expressive power.

## Key Results
- 1-WL often distinguishes all non-isomorphic graphs or nodes in common benchmarks, suggesting that more expressive GNNs may not be necessary for these tasks.
- k-WL does not guarantee isometry, which can harm generalization when GNNs align their representations with k-WL colorings.
- GNNs may learn representations more optimal for specific tasks than WL-aligned ones, as evidenced by GIN representations being more aligned with task labels than 1-WL colorings.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The k-WL test is used as a theoretical upper bound on GNN expressive power, but the paper shows this bound often does not constrain practical GNN performance.
- Mechanism: Practitioners measure expressive power by comparing how many non-isomorphic graph/node pairs a GNN can distinguish to those distinguishable by k-WL. If k-WL can distinguish all non-isomorphic graphs in a benchmark, then in theory any GNN with expressive power ≤ k-WL should also distinguish them, implying perfect performance. However, the paper shows that 1-WL often distinguishes all non-isomorphic graphs/nodes in common benchmarks, meaning more expressive GNNs are not needed in practice.
- Core assumption: k-WL serves as a sufficient condition for achieving high accuracy on graph tasks, so if k-WL distinguishes all non-isomorphic instances, GNNs should also.
- Evidence anchors:
  - [abstract]: "1-WL often distinguishes all non-isomorphic graphs or nodes, suggesting that more expressive GNNs may not be necessary for these tasks."
  - [section]: "Our findings suggest that, in theory, a GNN that is as expressive as 1-WL would be able to perform close to perfectly on these benchmarks."
- Break condition: If a benchmark contains graph pairs that are non-isomorphic but have the same 1-WL coloring, or if the task labels are not aligned with graph isomorphism, then 1-WL expressive power will not guarantee good performance.

### Mechanism 2
- Claim: The k-WL test does not guarantee isometry, meaning it may map similar graphs to very different representations, which can harm generalization.
- Mechanism: Isometry means similar inputs map to similar outputs. The paper shows that k-WL can produce very different colorings for graphs with small edit distances, violating isometry. This means a GNN constrained to align with k-WL may need a complex decoder to map these dissimilar k-WL representations to similar labels, harming generalization.
- Core assumption: Generalization benefits from isometry, so lack of isometry in k-WL is problematic.
- Evidence anchors:
  - [abstract]: "k-WL does not guarantee isometry"
  - [section]: "G1 and G2, which have an edit distance of 1, may have more distinct representations than G1 and G4, which have a larger edit distance. This is unintuitive (with respect to metric space axioms) and demonstrates that k-WL is misaligned with how expressive power may be conceptualized for edit distance prediction."
- Break condition: If the task does not require isometry (e.g., substructure counting), or if the decoder is powerful enough to handle non-isometric representations, the lack of isometry may not harm performance.

### Mechanism 3
- Claim: The paper argues for extensional definitions of expressive power based on benchmarks rather than intensional definitions based on theoretical properties like k-WL.
- Mechanism: An intensional definition defines a concept by its necessary and sufficient conditions (e.g., "a GNN is expressive if it can distinguish as many non-isomorphic graphs as k-WL"). An extensional definition defines a concept by listing its instances (e.g., "a GNN is expressive on task T if it performs well on benchmark B for T"). The paper argues that extensional definitions are more practical, task-driven, and trustworthy.
- Core assumption: Practical success on benchmarks is a better measure of expressive power than theoretical alignment with k-WL.
- Evidence anchors:
  - [abstract]: "We argue for extensional definitions and measurement of expressive power based on benchmarks"
  - [section]: "Extensional definitions reduce the contestedness of expressive power, as expressive power will be defined in the context of a specific task, thus drawing from domain knowledge."
- Break condition: If theoretical properties like k-WL alignment are important for reasons beyond practical task performance (e.g., for understanding fundamental limits of GNNs), then intensional definitions may still be valuable.

## Foundational Learning

- Concept: Isomorphism and automorphism
  - Why needed here: The paper discusses how k-WL is used to test graph and node isomorphism, so understanding these concepts is crucial.
  - Quick check question: What is the difference between graph isomorphism and node automorphism?

- Concept: Weisfeiler-Leman (WL) test
  - Why needed here: The WL test is the core theoretical tool used to measure GNN expressive power, so understanding its mechanics is essential.
  - Quick check question: How does the 1-WL test iteratively refine node colors to test for isomorphism?

- Concept: Graph neural networks (GNNs)
  - Why needed here: The paper is about the expressive power of GNNs, so understanding what GNNs are and how they work is fundamental.
  - Quick check question: What is the general architecture of a GNN, and how does it map graphs to representations?

## Architecture Onboarding

- Component map: Survey -> Theoretical analysis -> Benchmark auditing -> Guiding questions
- Critical path: Survey → Theoretical analysis → Benchmark auditing → Guiding questions
- Design tradeoffs: Balancing theoretical rigor with practical relevance; balancing survey breadth with depth
- Failure signatures: Survey responses are inconsistent or unclear; theoretical analysis reveals fundamental flaws in k-WL; benchmark auditing shows k-WL is often irrelevant to real tasks
- First 3 experiments:
  1. Run 1-WL on a benchmark and count how many non-isomorphic graphs/nodes it can distinguish
  2. Train a GIN on the same benchmark and compare its representations to 1-WL colorings
  3. Evaluate a majority-vote classifier on 1-WL equivalence classes to see if they predict labels well

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design benchmarks that accurately measure expressive power while also promoting fairness, robustness, and privacy in graph machine learning?
- Basis in paper: [explicit] The authors argue for extensional definitions and measurement of expressive power based on benchmarks, and contribute guiding questions for constructing such benchmarks.
- Why unresolved: The authors acknowledge that current benchmarks may not adequately measure expressive power or promote ethical aspects of graph ML, but do not provide a concrete solution.
- What evidence would resolve it: Development and validation of new benchmarks that measure expressive power while also promoting fairness, robustness, and privacy.

### Open Question 2
- Question: To what extent do graph neural networks learn representations that align with Weisfeiler-Leman (WL) colorings in practice?
- Basis in paper: [explicit] The authors conduct experiments on popular benchmarks and find that graph isomorphism networks (GIN) learn representations that are more optimal with respect to task labels than WL-aligned ones.
- Why unresolved: The authors only examine the alignment of GIN representations with 1-WL colorings, and do not explore the alignment of other GNN architectures with k-WL colorings.
- What evidence would resolve it: Empirical studies comparing the alignment of different GNN architectures with k-WL colorings on a variety of tasks and datasets.

### Open Question 3
- Question: How can we develop task-specific measurements of expressive power that are aligned with the goals of the task and promote generalization?
- Basis in paper: [explicit] The authors argue that k-WL may not be aligned with specific tasks and suggest developing other measurements of expressive power.
- Why unresolved: The authors do not provide concrete guidance on how to develop task-specific measurements of expressive power.
- What evidence would resolve it: Development and validation of task-specific measurements of expressive power that promote generalization and are aligned with the goals of the task.

## Limitations
- The survey sample size of 18 practitioners may not fully represent the diversity of perspectives in the graph ML community.
- The benchmark auditing focused on popular graph datasets, potentially missing edge cases where k-WL alignment becomes more critical.
- The complex relationship between theoretical expressiveness and practical performance remains incompletely understood.

## Confidence
- High confidence: Our findings regarding the prevalence of 1-WL distinguishing all non-isomorphic graphs in common benchmarks.
- Medium confidence: Our practitioner survey results and theoretical analysis of k-WL's limitations.
- Low confidence: The generalizability of our findings to all possible graph tasks and datasets.

## Next Checks
1. Conduct a larger-scale survey with practitioners across different application domains to validate our findings about conceptualizations of expressive power.
2. Perform systematic experiments on synthetic benchmarks specifically designed to test cases where k-WL alignment might be necessary for good performance.
3. Investigate the relationship between k-WL alignment and generalization by testing GNNs on out-of-distribution data where isomorphism-based distinctions may differ from task-relevant distinctions.