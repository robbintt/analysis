---
ver: rpa2
title: Unleashing the Power of Shared Label Structures for Human Activity Recognition
arxiv_id: '2301.03462'
source_url: https://arxiv.org/abs/2301.03462
tags:
- label
- open
- activity
- names
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a new human activity recognition (HAR) framework
  that explicitly models label name semantics to improve activity recognition performance.
  The core idea is that activity names often share sub-structures, such as common
  actions or objects, which can be leveraged to transfer knowledge across different
  activities.
---

# Unleashing the Power of Shared Label Structures for Human Activity Recognition

## Quick Facts
- arXiv ID: 2301.03462
- Source URL: https://arxiv.org/abs/2301.03462
- Reference count: 40
- Primary result: SemanticHAR reduces error rate by approximately 19-31% on six HAR datasets compared to best performing baselines

## Executive Summary
This paper introduces SemanticHAR, a novel framework for human activity recognition that explicitly models the semantic structure of activity labels. The core insight is that activity names often share sub-structures (e.g., "open" in "open microwave" and "open drawer"), and these shared tokens can be leveraged to transfer knowledge across different activities. By using a sequence-to-sequence architecture with label augmentation techniques, SemanticHAR achieves state-of-the-art performance on seven benchmark HAR datasets, particularly excelling in few-shot learning and label imbalance settings.

## Method Summary
SemanticHAR uses a sequence-to-sequence architecture consisting of a 1D CNN encoder for feature extraction from sensory time series and an LSTM decoder for generating label name sequences. The framework introduces label augmentation techniques that randomly replace original label sequences with meaningful tokens during training, helping the model capture semantic structures across activities. During inference, constraint decoding ensures all generated labels are valid sequences from the label set. This approach preserves relationships among activities better than traditional integer classification methods.

## Key Results
- SemanticHAR achieves 19-31% error rate reduction compared to best performing baselines on six HAR datasets
- Outperforms state-of-the-art HAR models especially in few-shot learning and label imbalance settings
- Demonstrates consistent improvement across seven different benchmark datasets

## Why This Works (Mechanism)

### Mechanism 1
Modeling label name semantics improves activity recognition by transferring knowledge of shared tokens across activities. The framework decomposes activity labels into shared tokens (e.g., "open", "walk") and learns these separately, enabling knowledge transfer between activities that share common actions or objects. Core assumption: Activities with similar label names (sharing sub-structures) have similar patterns in the input sensory data.

### Mechanism 2
Label augmentation helps the model capture semantics of shared tokens across different activities. During training, the method randomly replaces original label sequences with their meaningful tokens (e.g., all instances of "open X" become "open"), forcing the model to learn the semantics of each token. Core assumption: Randomly augmenting labels with single meaningful tokens improves the model's understanding of shared semantic structures.

### Mechanism 3
Sequence-to-sequence architecture with constraint decoding ensures all generated labels are valid while capturing label semantics. Instead of classifying to integer IDs, the model generates label name sequences and uses constraint decoding to only consider valid label sequences from the label set during inference. Core assumption: Generating label names as sequences preserves relationships among activities better than integer classification.

## Foundational Learning

- **Sequence-to-sequence modeling**: Why needed here - Traditional HAR models classify activities as integer IDs, losing the semantic relationships between activities. Sequence-to-sequence modeling allows the framework to generate label names as sequences, preserving these relationships.
- **Label augmentation**: Why needed here - The method needs to help the model better capture the semantics of shared tokens across different activities, especially when some activities have limited samples.
- **Constraint decoding**: Why needed here - During inference, the method needs to ensure that all generated labels are valid sequences from the label set, not arbitrary sequences.

## Architecture Onboarding

- **Component map**: Input sensory time series -> 2-layer CNN encoder with batch normalization and ReLU -> Linear layer -> Feature vector -> Initialize LSTM hidden and cell states -> LSTM decoder with teacher forcing -> Generate label name sequence -> Constraint decoding ensures only valid sequences

- **Critical path**: 1. Input sensory time series → Encoder → Feature vector; 2. Feature vector → Initialize LSTM hidden and cell states; 3. LSTM decoder generates label name sequence token by token; 4. Constraint decoding ensures only valid sequences are considered

- **Design tradeoffs**: Using sequence-to-sequence vs classification - Better semantic preservation but higher computational cost; Label augmentation probability - Too high may lose activity context, too low may not learn token semantics well; LSTM hidden dimension - Larger dimensions capture more context but increase computation

- **Failure signatures**: Poor performance on activities with shared tokens - Indicates encoder-decoder misalignment; Degraded performance without label augmentation - Suggests model fails to learn token semantics; Invalid label sequences during inference - Indicates constraint decoding issues

- **First 3 experiments**: 1. Compare SemanticHAR vs VanillaHAR (same encoder, direct classification) on a dataset with shared label names; 2. Test impact of label augmentation by running with and without it on the same dataset; 3. Evaluate performance on a dataset without shared label names before and after using ChatGPT to generate shared tokens

## Open Questions the Paper Calls Out

1. **How does the performance of SemanticHAR compare when using pre-trained language models like BERT for embedding the label names instead of randomly initialized embeddings?**
   - Basis: The paper mentions trying pre-trained Glove embeddings but not modern pre-trained language models
   - Why unresolved: The paper only briefly mentions trying pre-trained Glove embeddings and does not explore more advanced pre-trained language models
   - What evidence would resolve it: Experiments comparing SemanticHAR's performance with different types of pre-trained language model embeddings (e.g., BERT, RoBERTa) versus randomly initialized embeddings

2. **Can the label augmentation technique be further improved by incorporating semantic similarity between words beyond just randomly selecting tokens from the same label?**
   - Basis: The current augmentation method is quite simple and may not fully exploit semantic relationships between words
   - Why unresolved: The current augmentation method is quite simple and may not fully exploit the semantic relationships between words in different label names
   - What evidence would resolve it: Experiments comparing different label augmentation strategies, such as using word embeddings to find semantically similar words for augmentation

3. **How does SemanticHAR's performance change when applied to image-based activity recognition tasks where the label names have shared structures?**
   - Basis: The paper mentions plans to adapt the proposed model to other data modalities like images and videos
   - Why unresolved: While the paper demonstrates strong performance on sensor-based HAR, it does not validate whether the same approach would be effective for image-based activity recognition
   - What evidence would resolve it: Experiments applying SemanticHAR to image-based activity recognition datasets (e.g., UCF101, HMDB51) with appropriate modifications

## Limitations
- The effectiveness of label augmentation depends heavily on identifying truly "meaningful tokens" versus noise, which isn't clearly defined
- The sequence-to-sequence approach adds computational overhead compared to direct classification
- The paper doesn't explore scenarios where shared label tokens don't correspond to similar sensory patterns

## Confidence
- **High Confidence**: The experimental results showing improved performance on seven benchmark datasets, with 19-31% error reduction compared to baselines
- **Medium Confidence**: The claim that modeling label semantics transfers knowledge across activities
- **Medium Confidence**: The effectiveness of label augmentation

## Next Checks
1. Run an ablation study on label augmentation: Compare SemanticHAR with and without label augmentation on a dataset with clear shared tokens to quantify the specific contribution of this component
2. Test cross-dataset generalization: Train SemanticHAR on one dataset and evaluate on another to verify if semantic knowledge transfers across different activity vocabularies
3. Analyze sensory patterns: For activities with shared tokens, analyze whether their sensory patterns are indeed more similar than activities without shared tokens, validating the core assumption