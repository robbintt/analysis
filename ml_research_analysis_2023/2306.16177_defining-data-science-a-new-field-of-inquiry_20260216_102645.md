---
ver: rpa2
title: 'Defining data science: a new field of inquiry'
arxiv_id: '2306.16177'
source_url: https://arxiv.org/abs/2306.16177
tags:
- science
- data
- paradigm
- research
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Data science is not a science but a distinct research paradigm.
  The paper proposes defining data science using classical research paradigms (philosophy,
  problem-solving, and reference framework) to address its multiple inconsistent definitions.
---

# Defining data science: a new field of inquiry

## Quick Facts
- arXiv ID: 2306.16177
- Source URL: https://arxiv.org/abs/2306.16177
- Reference count: 37
- Primary result: Data science is a distinct research paradigm, not a science, defined through a six-component reference framework that unifies over 40 disciplines' definitions

## Executive Summary
This paper addresses the challenge of multiple inconsistent definitions of data science by proposing a classical research paradigm approach. Using a six-component reference framework (axiology, ontology, epistemology, methodology, methods, technology), the work aligns definitions across 106 publications and over 40 disciplines to create a unified, coherent definition. The research establishes data science as fundamentally independent from science, with different epistemological foundations and methodological approaches. The paper provides candidate definitions for essential data science artifacts and outlines a process for developing unified definitions to guide the field's evolution and address communication challenges across disciplines.

## Method Summary
The paper uses a paradigm approach that applies a data science reference framework to align multiple inconsistent definitions. The method involves collecting relevant data science definitions, using the research paradigm framework to align their respective artifacts, deriving unified understanding from aligned definitions, and expressing unified definitions using a specification language. The approach systematically addresses the incommensurability thesis by creating translation mechanisms between different disciplinary perspectives on data science.

## Key Results
- Data science and science are fundamentally independent research paradigms with different epistemological foundations
- A six-component reference framework (axiology, ontology, epistemology, methodology, methods, technology) can unify multiple inconsistent data science definitions
- Data science results are probabilistic and inscrutable, while scientific results are definitive and causal
- The paper provides candidate definitions for essential data science artifacts and a process for their evolution

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The paper uses classical research paradigms to define data science as a new, independent field of inquiry.
- Mechanism: It aligns multiple inconsistent definitions across 106 publications and over 40 disciplines using a six-component reference framework (axiology, ontology, epistemology, methodology, methods, technology) to create a unified, coherent definition.
- Core assumption: A classical research paradigm framework can be adapted to a new, data-driven field like data science.
- Evidence anchors:
  - [abstract] "Data science is not a science. It is a research paradigm... due to its infancy, many definitions are independent, application specific, mutually incomplete, redundant, or inconsistent"
  - [section] "The research addresses this data science multiple definitions challenge by proposing the development of coherent, unified definition based on a data science reference framework"
  - [corpus] Found 25 related papers with average FMR=0.439, showing moderate relevance but no direct citations yet
- Break condition: If the six-component framework cannot accommodate emerging data science methods or if the community rejects the unified definition.

### Mechanism 2
- Claim: Data science and science are fundamentally independent fields of inquiry with different epistemological foundations.
- Mechanism: The paper contrasts science's objective, quantitative reasoning with data science's learning from data approach, showing that data science results are probabilistic, correlational, and inscrutable, while scientific results are definitive, causal, and robust.
- Evidence anchors:
  - [abstract] "data science and science are fundamentally independent fields of inquiry, with data science seeking uncertain insights through inscrutable AI-based methods, while science seeks definitive knowledge through objective quantitative methods"
  - [section] "Data science results violate the principles of scientific results, and vice versa... science and data science are fundamentally independent research paradigms"
  - [corpus] Weak evidence - corpus neighbors focus on definitional challenges but don't directly address the science/data science distinction
- Break condition: If emerging data science methods become transparent and produce definitive causal knowledge comparable to scientific methods.

### Mechanism 3
- Claim: The proposed data science reference framework provides a unifying structure for developing and evolving data science definitions across disciplines.
- Mechanism: The framework approach uses the unified understanding of data science research paradigm categories to guide and structure a single, unified, coherent definition of emerging data science research paradigm with generic artifacts consistent with those in each data science research paradigm.
- Evidence anchors:
  - [abstract] "The work provides candidate definitions for essential data science artifacts and outlines a process for developing unified, coherent definitions to guide the field's evolution"
  - [section] "The paradigm approach (steps 1-3) applies the data science research paradigm, defined in terms of generic data science artifacts and definitions of its categories defined by artifact instances"
  - [corpus] Moderate evidence - corpus includes papers on definitional challenges in related fields but lacks direct evidence of framework success
- Break condition: If the framework cannot adapt to new data science methods or if practitioners find it too abstract for practical application.

## Foundational Learning

- Concept: Research Paradigms
  - Why needed here: Understanding research paradigms is essential to grasp how data science differs from science and how to define it properly
  - Quick check question: What are the three classical research paradigms mentioned, and how does data science differ from each?

- Concept: Reference Framework Components
  - Why needed here: The six-component framework (axiology, ontology, epistemology, methodology, methods, technology) is the core structure for defining data science
  - Quick check question: Which component of the reference framework would define the purpose and value of data science, and which would define the computational methods used?

- Concept: Incommensurability Thesis
  - Why needed here: Understanding Kuhn's thesis helps explain why multiple definitions exist and how to address them
  - Quick check question: How might incommensurability affect the unification of data science definitions across different disciplines?

## Architecture Onboarding

- Component map: axiology -> ontology -> epistemology -> methodology -> methods -> technology
- Critical path: 1) Collect all relevant data science definitions, 2) Use the research paradigm definition to align their respective artifacts, 3) Derive unified understanding from aligned artifact definitions, 4) Use unified understanding to derive unified definitions, 5) Express definitions using specification language, 6) Examine and resolve challenges from changing source definitions.
- Design tradeoffs: The framework prioritizes comprehensiveness and coherence over simplicity, which may make it harder to adopt initially but provides better long-term structure for the field's evolution.
- Failure signatures: Inconsistencies between source definitions and unified definitions, inability to accommodate new data science methods, or rejection by the data science community.
- First 3 experiments:
  1. Map the six components to existing data science publications and identify where definitions diverge
  2. Test the framework's ability to accommodate a new data science method (e.g., foundation models) by attempting to integrate it into the existing structure
  3. Conduct a small-scale unification of definitions from two different data science disciplines to identify challenges and refine the process

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific criteria or metrics should be used to determine when a unified definition of data science is sufficiently mature and comprehensive for practical application?
- Basis in paper: [inferred] The paper discusses the need for a unified definition but does not specify concrete criteria for determining when such a definition is complete.
- Why unresolved: The paper emphasizes the evolving nature of data science and the complexity of defining it, suggesting that determining completeness is inherently challenging.
- What evidence would resolve it: A detailed framework specifying measurable criteria (e.g., consensus metrics, application breadth, interdisciplinary acceptance) that can be used to evaluate the maturity of a data science definition.

### Open Question 2
- Question: How can the incommensurability thesis be practically addressed when attempting to unify multiple definitions of data science across different disciplines?
- Basis in paper: [explicit] The paper explicitly mentions Kuhn's incommensurability thesis as a complicating factor in unifying definitions.
- Why unresolved: The paper acknowledges the challenge but does not provide concrete methods for resolving incommensurability between different data science definitions.
- What evidence would resolve it: Development and validation of translation mechanisms or interoperability frameworks that can reconcile conflicting definitions while preserving their core meanings.

### Open Question 3
- Question: What are the most effective methods for quantifying and managing the risks associated with inscrutable AI-based data science methods in practical applications?
- Basis in paper: [explicit] The paper extensively discusses the inscrutable nature of AI-based methods and the associated risks.
- Why unresolved: While the paper identifies the problem and mentions some techniques (e.g., demonstrable solutions), it does not provide a comprehensive framework for risk quantification and management.
- What evidence would resolve it: Empirical studies comparing different risk management approaches and their effectiveness in real-world applications, along with standardized metrics for assessing inscrutability-related risks.

## Limitations
- The framework's ability to accommodate rapidly evolving data science methods, particularly foundation models and large language models, remains untested
- The proposed unified definitions may be too abstract for practical application by data science practitioners
- The fundamental independence claim between data science and science may be challenged as interpretability methods improve

## Confidence

| Claim | Confidence Level |
|-------|------------------|
| Multiple inconsistent definitions of data science is a well-established problem | High |
| The six-component framework provides a systematic approach to unification | Medium |
| Data science and science are fundamentally independent paradigms | Medium |
| Candidate definitions for essential data science artifacts are complete | Low |

## Next Checks

1. **Framework Adaptability Test**: Apply the six-component framework to a recent, emerging data science method (e.g., transformer-based models) to verify it can accommodate new approaches without structural modifications

2. **Community Acceptance Survey**: Conduct a small-scale survey of data science practitioners across different disciplines to assess whether the unified definitions align with their understanding and practical needs

3. **Cross-Paradigm Comparison**: Systematically compare the framework's treatment of data science with how other research paradigms (qualitative, quantitative, design science) handle methodological evolution and definition unification