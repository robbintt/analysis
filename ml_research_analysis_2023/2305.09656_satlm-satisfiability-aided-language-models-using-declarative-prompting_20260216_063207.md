---
ver: rpa2
title: 'SatLM: Satisfiability-Aided Language Models Using Declarative Prompting'
arxiv_id: '2305.09656'
source_url: https://arxiv.org/abs/2305.09656
tags:
- reasoning
- language
- proglm
- satlm
- prescribed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SATLM, a novel approach to improve the reasoning
  capabilities of large language models (LLMs) by using declarative prompting and
  a SAT solver. The key idea is to parse a natural language reasoning problem into
  a declarative task specification using an LLM, and then leverage an automated theorem
  prover (SAT solver) to derive the final answer.
---

# SatLM: Satisfiability-Aided Language Models Using Declarative Prompting

## Quick Facts
- **arXiv ID**: 2305.09656
- **Source URL**: https://arxiv.org/abs/2305.09656
- **Reference count**: 31
- **Primary result**: SATLM achieves new state-of-the-art results on LSAT and BoardgameQA by parsing natural language problems into declarative logical specifications and using a SAT solver to derive answers.

## Executive Summary
This paper introduces SATLM, a novel approach that improves reasoning capabilities of large language models (LLMs) by using declarative prompting combined with a SAT solver. Instead of having LLMs generate reasoning steps in natural language, SATLM parses problems into declarative logical specifications that directly capture problem constraints. The SAT solver then guarantees correctness by deriving answers from these specifications. This approach outperforms imperative program-aided LMs by significant margins across multiple reasoning tasks.

## Method Summary
SATLM uses declarative prompting to parse natural language reasoning problems into logical formulas. The LLM generates these formulas based on the problem description, then a SAT solver processes them to derive the final answer. This differs from imperative approaches like PROGLM that generate executable reasoning steps. The declarative specifications are closer to the problem description, allowing more accurate parsing, while the SAT solver guarantees correctness and enables selective prediction through feedback signals like UNSAT (unsatisfiable) and AMBIG (ambiguous) conditions.

## Key Results
- SATLM consistently outperforms PROGLM on 8 different datasets spanning 4 reasoning tasks
- Achieves new state-of-the-art results on LSAT and BoardgameQA
- Outperforms PROGLM by 23% on a challenging subset of the GSM arithmetic reasoning dataset
- Higher selective prediction accuracy by abstaining from uncertain predictions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Declarative prompting allows LLMs to more accurately parse natural language reasoning problems by aligning the specification closer to the problem description.
- **Mechanism**: The LLM generates logical formulas that directly represent the constraints and relationships stated in the problem, avoiding the need to infer an imperative plan from the natural language.
- **Core assumption**: The LLM can accurately parse the natural language into logical formulas when prompted with a declarative specification.
- **Evidence anchors**: SATLM consistently outperforms program-aided LMs in the imperative paradigm (PROGLM) by a large margin, achieving new state-of-the-art results on LSAT and BoardgameQA.
- **Break condition**: The natural language problem description is highly procedural or the LLM struggles with formal logic syntax.

### Mechanism 2
- **Claim**: Offloading reasoning to a SAT solver guarantees correctness of the answer and avoids planning errors.
- **Mechanism**: The SAT solver systematically derives the solution from the declarative specification, ensuring that the answer satisfies all stated constraints.
- **Core assumption**: The SAT solver can efficiently solve the logical formulas generated by the LLM and produce a correct answer.
- **Evidence anchors**: By only using the LLMs to generate declarative specifications and relying on a solver to handle the reasoning, SATLM generates the correct answer.
- **Break condition**: The logical formulas are too complex for the SAT solver to handle efficiently or the solver cannot find a solution within a reasonable time limit.

### Mechanism 3
- **Claim**: SATLM can abstain from making uncertain predictions by leveraging feedback signals from the SAT solver.
- **Mechanism**: The SAT solver provides feedback on whether the formulas are unsatisfiable, ambiguous, or have execution errors, allowing SATLM to avoid making incorrect predictions.
- **Core assumption**: The SAT solver can accurately identify unsatisfiable, ambiguous, or erroneous formulas and provide meaningful feedback.
- **Evidence anchors**: SATLM can abstain from making uncertain predictions if it parses a problem into an unsatisfiable or ambiguous specification, giving it even higher accuracy in the selective prediction setting.
- **Break condition**: The SAT solver cannot distinguish between unsatisfiable, ambiguous, or erroneous formulas, or the feedback is not meaningful for the task at hand.

## Foundational Learning

- **Concept**: SAT (Boolean Satisfiability Problem)
  - **Why needed here**: SAT is the core computational problem that the SAT solver solves to derive the final answer from the declarative specification.
  - **Quick check question**: What is the difference between a SAT problem and a constraint satisfaction problem (CSP)?

- **Concept**: First-Order Logic
  - **Why needed here**: The declarative specification uses first-order logic formulas to represent the constraints and relationships in the problem.
  - **Quick check question**: What is the difference between first-order logic and propositional logic?

- **Concept**: Theorem Proving
  - **Why needed here**: The SAT solver is essentially a theorem prover that proves the validity of the logical formulas in the declarative specification.
  - **Quick check question**: What is the difference between a sound and a complete theorem prover?

## Architecture Onboarding

- **Component map**: LLM (declarative prompting) -> SAT solver -> Answer extraction
- **Critical path**: 
  1. LLM generates logical formulas from natural language
  2. SAT solver solves the logical formulas and provides feedback
  3. Answer extraction extracts the final answer from the SAT solver's output
- **Design tradeoffs**: 
  - Declarative vs. imperative prompting: Declarative prompting allows for more accurate parsing but may require more complex logical formulas
  - SAT solver vs. other solvers: SAT solver guarantees correctness but may be less efficient for certain types of problems
  - Answer extraction vs. direct output: Answer extraction allows for more control over the final answer but may introduce additional complexity
- **Failure signatures**: 
  - LLM generates incorrect logical formulas: The SAT solver may not be able to solve the problem or may provide incorrect feedback
  - SAT solver cannot solve the problem: The logical formulas may be too complex or the solver may not be efficient enough
  - Answer extraction fails: The SAT solver's output may not be in the expected format or the extraction process may introduce errors
- **First 3 experiments**: 
  1. Test the LLM's ability to generate logical formulas from natural language using a small set of examples
  2. Test the SAT solver's ability to solve the logical formulas generated by the LLM using a small set of examples
  3. Test the answer extraction process using the SAT solver's output and a small set of examples

## Open Questions the Paper Calls Out
- How can we best integrate declarative and imperative prompting styles for more flexible reasoning?
- How can we improve the performance of SATLM on problems that lead to ambiguous or unsatisfiable formulas?
- How does the performance of SATLM scale with the complexity of the reasoning problems and the size of the language models?

## Limitations
- Evaluation focuses primarily on logical and arithmetic reasoning tasks where formal specifications are naturally applicable
- Computational efficiency concerns - SAT solvers may introduce significant latency compared to direct LLM reasoning
- Approach's effectiveness on non-logical reasoning tasks (commonsense, creative problem-solving) remains untested

## Confidence
- SATLM outperforms imperative approaches by large margins (High confidence)
- Declarative specifications are more accurately parsed than imperative reasoning steps (Medium confidence)
- SAT solver guarantees correctness and enables selective prediction (Medium confidence)

## Next Checks
1. Test on non-logical reasoning tasks: Apply SATLM to datasets involving commonsense reasoning or qualitative reasoning to assess whether the declarative approach generalizes beyond tasks with natural formal specifications.
2. Evaluate computational overhead: Measure end-to-end latency of SATLM compared to baseline approaches, including LLM inference time, SAT solving time, and answer extraction, to understand practical deployment implications.
3. Analyze failure modes systematically: Conduct detailed error analysis on cases where SATLM fails or abstains, examining whether failures stem from LLM parsing errors, SAT solver limitations, or answer extraction issues.