---
ver: rpa2
title: Modelling Human Visual Motion Processing with Trainable Motion Energy Sensing
  and a Self-attention Network
arxiv_id: '2305.09156'
source_url: https://arxiv.org/abs/2305.09156
tags:
- motion
- human
- visual
- vision
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a two-stage computational model for human
  motion perception that bridges the gap between biological and computer vision approaches.
  The model combines trainable motion energy sensing (mimicking V1) with a recurrent
  self-attention network (mimicking MT) to extract informative motion flow from complex
  natural scenes.
---

# Modelling Human Visual Motion Processing with Trainable Motion Energy Sensing and a Self-attention Network

## Quick Facts
- arXiv ID: 2305.09156
- Source URL: https://arxiv.org/abs/2305.09156
- Reference count: 40
- Key outcome: A two-stage model combining trainable motion energy sensing with attention-based recurrent integration that better predicts human motion perception than standard optical flow models on the Sintel benchmark

## Executive Summary
This paper introduces a computational model for human motion perception that bridges biological and computer vision approaches. The model consists of two stages: first, trainable multi-scale Gabor filters extract local motion energy similar to V1 processing; second, a recurrent self-attention network performs global motion integration mimicking MT function. The model successfully replicates human responses to various psychophysical stimuli including drifting Gabors, plaid patterns, and barber-pole illusions. Notably, when tested on the Sintel benchmark, the model predicts human responses better than ground truth optical flow, whereas state-of-the-art computer vision models show the opposite behavior.

## Method Summary
The model uses a two-stage approach to human motion perception. Stage I employs multi-scale spatiotemporal Gabor filters (8 pyramid levels with 256 complex cells each) to extract local motion energy from input image sequences. Stage II constructs a graph from these motion energy features and applies attention-based recurrent integration using Conv-GRU blocks to solve the aperture problem and perform global motion integration. The model is trained on a combination of the Sintel benchmark, pseudo-labeled DA VIS dataset, and self-created datasets with simple motion stimuli, using supervised learning to predict optical flow.

## Key Results
- The model successfully replicates human responses to drifting Gabor stimuli, plaid patterns, and barber-pole illusions
- On the Sintel benchmark, the model predicts human responses better than ground truth optical flow
- Partial correlation analysis shows the model outperforms several computer vision models in explaining human responses that deviate from ground truth

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The two-stage architecture successfully mimics the hierarchical processing of V1→MT motion pathways by combining trainable motion energy extraction with attention-based recurrent integration.
- Mechanism: Stage I uses multi-scale Gabor filters to extract local motion energy at different spatial scales, while Stage II constructs a graph from these features and applies attention-based recurrent processing to integrate local motions into global flow interpretations.
- Core assumption: Motion integration in the brain follows a similar hierarchical pattern where V1 extracts local motion energy and MT integrates these signals into global interpretations.
- Evidence anchors:
  - [abstract] "combines trainable motion energy sensing with a recurrent self-attention network for adaptive motion integration and segregation"
  - [section] "mimicked the function of V1... employed attention-based recurrent integration to model the function of MT"
  - [corpus] Weak evidence - no direct citations about V1→MT modeling found
- Break condition: The model would fail if the attention-based recurrent mechanism cannot effectively resolve the aperture problem or if the multi-scale Gabor filters cannot capture sufficient motion energy variation.

### Mechanism 2
- Claim: The attention-based recurrent network can explain both physiological findings (change in component vs pattern cells) and psychophysical phenomena (global motion pooling, barber-pole illusion).
- Mechanism: The graph construction with cosine similarity-based adjacency matrices allows flexible connectivity between spatial locations, while the Conv-GRU blocks perform iterative motion integration that converges to stable global interpretations.
- Core assumption: The attention mechanism can approximate the complex connectivity patterns found in biological motion processing systems.
- Evidence anchors:
  - [section] "constructed an undirected fully connected graph from the map of local motion energy, and used the attention mechanism for adaptive global motion integration and segregation"
  - [section] "the proposed recurrent motion integration architecture can generate more human-like deviations from GT"
  - [corpus] Weak evidence - no direct citations about attention mechanisms in biological motion processing found
- Break condition: The model would fail if the iterative process doesn't converge or if the attention mechanism cannot capture the necessary long-range dependencies for global motion integration.

### Mechanism 3
- Claim: The model outperforms computer vision models in explaining human responses that deviate from ground truth by capturing human-like motion perception characteristics.
- Mechanism: Through partial correlation analysis, the model shows better performance in explaining human responses that deviate from ground truth compared to standard optical flow models, suggesting it captures human-like biases and perceptual phenomena.
- Core assumption: Human motion perception systematically deviates from ground truth in ways that can be captured by computational models.
- Evidence anchors:
  - [abstract] "the model predicts human responses better than the ground truth, whereas the state-of-the-art CV models show the opposite"
  - [section] "partial correlation analysis demonstrates that the model outperforms several CV models in explaining human responses that deviate from ground truth"
  - [section] "our model prediction is more similar to human-perceived flow than the GT flow"
- Break condition: The model would fail if the partial correlation advantage disappears on different datasets or if the model becomes too specialized to the Sintel benchmark.

## Foundational Learning

- Spatiotemporal Gabor filters:
  - Why needed here: They provide optimal resolution in both spatial and temporal domains for motion energy extraction, mimicking V1 direction-selective neurons
  - Quick check question: What are the three key parameters that control the shape and tuning of Gabor filters in this model?

- Graph neural networks and attention mechanisms:
  - Why needed here: They enable flexible connectivity patterns for motion integration that go beyond the local receptive fields of standard convolutions
  - Quick check question: How does the cosine similarity-based adjacency matrix differ from standard attention mechanisms?

- Recurrent neural networks (specifically Conv-GRU):
  - Why needed here: They simulate the iterative, feedback-based processing that likely occurs in MT for motion integration and solving the aperture problem
  - Quick check question: What is the key difference between the spatial integration performed by Conv-GRU versus standard convolutional layers?

## Architecture Onboarding

- Component map:
  Input frames → Multi-scale Gabor filtering → Energy normalization → Graph construction → Attention-based integration (Conv-GRU) → Flow decoding

- Critical path:
  Input frames → Multi-scale Gabor filtering → Energy normalization → Graph construction → Attention-based integration (Conv-GRU) → Flow decoding

- Design tradeoffs:
  - Multi-scale vs single-scale processing: Multi-scale provides better coverage of different motion speeds but increases computational complexity
  - Graph construction vs direct convolution: Graph approach allows long-range interactions but requires careful normalization to avoid instability
  - Recurrent vs feedforward: Recurrent allows iterative refinement but increases inference time

- Failure signatures:
  - Poor performance on non-textured stimuli suggests Stage I Gabor filters are not well-tuned
  - Unstable or oscillating outputs suggest issues with graph normalization or Conv-GRU training
  - Performance similar to standard optical flow models suggests the attention mechanism isn't capturing human-like deviations

- First 3 experiments:
  1. Test on synthetic drifting Gabor stimuli to verify Stage I captures correct local motion energy
  2. Test on plaid patterns to verify Stage II correctly performs motion integration and resolves aperture problem
  3. Test on barber-pole illusion to verify boundary integration and contextual effects are captured

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How exactly are attention mechanisms implemented in the human brain for motion integration?
- Basis in paper: [explicit] The paper notes that while attention-based recurrent networks show promise for modeling human visual motion grouping and segmentation, how this is actually implemented in the human brain remains an open question.
- Why unresolved: The attention mechanism in the proposed model is a computational approximation, but the actual neural implementation in biological systems is unknown and requires further investigation.
- What evidence would resolve it: Neurophysiological recordings from MT and MST areas during motion integration tasks, combined with computational modeling that can bridge the gap between artificial attention mechanisms and biological neural circuits.

### Open Question 2
- Question: How does the model handle non-Fourier (second-order) motion detection?
- Basis in paper: [explicit] The discussion section explicitly states that the current model does not process several important abilities of human motion perception, including non-Fourier motion detection.
- Why unresolved: The model relies on first-stage motion energy computation which is based on Fourier analysis, while human vision can detect motion of patterns that contain no first-order luminance changes.
- What evidence would resolve it: Testing the model on second-order motion stimuli like contrast-defined gratings or motion-defined textures, and comparing its responses to human perception and ground truth.

### Open Question 3
- Question: What are the specific neural mechanisms that allow adaptive motion pooling sensitive to surface segmentation?
- Basis in paper: [explicit] The discussion mentions that the model does not process motion integration sensitive to surface segmentation, which is an important aspect of human motion perception.
- Why unresolved: While the attention mechanism shows potential for combining motion integration and object segmentation, the specific neural mechanisms that enable humans to integrate motion signals while being sensitive to surface boundaries and segmentation cues are not yet understood.
- What evidence would resolve it: Detailed neurophysiological studies examining how MT neurons respond to motion signals when surface segmentation cues are present or manipulated, combined with computational models that can replicate these adaptive integration behaviors.

## Limitations
- The model's ability to generalize beyond the Sintel benchmark to naturalistic video sequences remains unclear
- The self-attention mechanism lacks direct biological validation linking its operation to MT neural circuits
- The claim that the model "predicts human responses better than ground truth" captures systematic perceptual biases rather than necessarily superior motion estimation

## Confidence
- High confidence: The two-stage architecture successfully implements the proposed mechanism combining Gabor filtering with attention-based recurrent integration
- Medium confidence: The model captures human-like deviations from ground truth in the Sintel benchmark
- Low confidence: The biological plausibility of the attention mechanism as a model of MT function

## Next Checks
1. Test model performance on naturalistic video datasets (e.g., KITTI, DAVIS) to assess generalization beyond synthetic benchmarks
2. Compare model predictions with additional psychophysical datasets that include a wider variety of motion illusions and integration phenomena
3. Analyze the learned attention patterns to determine if they reflect known principles of biological motion processing, such as center-surround organization or motion opponency