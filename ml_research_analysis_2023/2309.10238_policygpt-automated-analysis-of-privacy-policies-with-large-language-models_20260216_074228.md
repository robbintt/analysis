---
ver: rpa2
title: 'PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models'
arxiv_id: '2309.10238'
source_url: https://arxiv.org/abs/2309.10238
tags:
- privacy
- data
- policies
- policy
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study investigates a privacy policy text analysis framework
  PolicyGPT based on large language models. The framework was tested using two datasets:
  one comprising privacy policies from 115 websites annotated by legal experts, and
  another consisting of privacy policies from 304 mobile applications manually annotated
  at the sentence level.'
---

# PolicyGPT: Automated Analysis of Privacy Policies with Large Language Models

## Quick Facts
- arXiv ID: 2309.10238
- Source URL: https://arxiv.org/abs/2309.10238
- Reference count: 40
- Key outcome: PolicyGPT achieves 97% accuracy on website privacy policies and 87% on mobile app policies using zero-shot learning with LLMs

## Executive Summary
This study presents PolicyGPT, a framework for automated privacy policy analysis using large language models (LLMs). The framework employs prefix prompt engineering to classify privacy policies into 10 predefined categories. Tested on two datasets - 115 website privacy policies annotated by legal experts and 304 mobile app privacy policies manually annotated at the sentence level - PolicyGPT demonstrated high accuracy rates of 97% and 87% respectively under zero-shot learning conditions. The results significantly outperform baseline machine learning and neural network models, showcasing the potential of LLMs for privacy policy categorization tasks.

## Method Summary
The study uses prefix prompt engineering with LLMs (ChatGPT, GPT-4, and Claude2) to classify privacy policies into 10 categories. The framework processes two datasets: OPP-115 (115 website privacy policies with legal expert annotations) and PPGDPR (304 mobile app privacy policies with sentence-level manual annotations). The prefix prompts define task content and category definitions in three segments: background definition, information instruction, and task description. Zero-shot learning is employed without requiring task-specific training data. Results are evaluated by comparing LLM outputs against human annotations using accuracy and F1 scores.

## Key Results
- PolicyGPT achieved 97% accuracy on the OPP-115 dataset of website privacy policies
- PolicyGPT achieved 87% accuracy on the PPGDPR dataset of mobile app privacy policies
- Both results surpass baseline machine learning and neural network models under zero-shot learning conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prefix prompts effectively prime the LLM to understand and apply privacy policy categories.
- Mechanism: The prefix prompt structure explicitly defines the annotation scheme, explains each category, and then requests a classification for the target text. This design allows the LLM to absorb the semantic information of both the categories and the target text, boosting its proficiency in classification tasks.
- Core assumption: The LLM can correctly interpret the prompt instructions and apply them to the target text.
- Evidence anchors:
  - [abstract] The study investigates a privacy policy text analysis framework PolicyGPT based on the LLM, using prefix prompts to establish task content and category definitions.
  - [section] The prompt is structured into three distinct segments: background definition, information instruction, and task description, which empowers the model to learn the nuanced meanings embedded in each privacy category.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.427, average citations=0.0. Top related titles include "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale" and "Unveiling Privacy Policy Complexity: An Exploratory Study Using Graph Mining, Machine Learning, and Natural Language Processing."
- Break condition: If the prompt instructions are ambiguous or the target text is too complex for the LLM to parse, the classification accuracy will decrease.

### Mechanism 2
- Claim: Large language models, particularly GPT-4, outperform traditional machine learning models in privacy policy classification tasks.
- Mechanism: The transformer-based architecture of GPT-4 allows for better understanding and generation of natural language, handling long-range dependencies in text and learning semantic patterns across large datasets. This is particularly beneficial in tasks like privacy policy classification where understanding context and semantics is crucial.
- Core assumption: The LLM has been trained on a sufficiently large and diverse dataset to capture the nuances of privacy policy language.
- Evidence anchors:
  - [abstract] Under zero-shot learning conditions, PolicyGPT achieved an accuracy rate of 97% on the first dataset and 87% on the second, surpassing baseline machine learning and neural network models.
  - [section] GPT-4's superior performance can be attributed to its transformer-based architecture, which allows for a better understanding and generation of natural language. It can handle long-range dependencies in text and learn semantic patterns across large datasets.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.427, average citations=0.0. Top related titles include "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale" and "Unveiling Privacy Policy Complexity: An Exploratory Study Using Graph Mining, Machine Learning, and Natural Language Processing."
- Break condition: If the LLM is not sufficiently large or diverse, or if the privacy policy language is too specialized, the performance may not surpass traditional models.

### Mechanism 3
- Claim: Zero-shot learning is effective for privacy policy classification with large language models.
- Mechanism: The LLM's training on vast amounts of data allows it to learn a wide array of patterns and nuances in human language, enabling it to generalize and predict in unseen situations without explicit training on the specific task.
- Core assumption: The LLM's pre-training covers a broad enough range of language patterns to be applicable to privacy policy text.
- Evidence anchors:
  - [abstract] Under zero-shot learning conditions, PolicyGPT demonstrated robust performance, achieving high accuracy rates on both datasets.
  - [section] The results from A/B tests showed that the use of few-shot prompts did not provide a significant improvement in the accuracy of the model's classifications. Considering the huge amount of data behind the LLM, zero-shot can also achieve good results.
  - [corpus] Found 25 related papers (using 8). Average neighbor FMR=0.427, average citations=0.0. Top related titles include "Let's Measure the Elephant in the Room: Facilitating Personalized Automated Analysis of Privacy Policies at Scale" and "Unveiling Privacy Policy Complexity: An Exploratory Study Using Graph Mining, Machine Learning, and Natural Language Processing."
- Break condition: If the LLM's pre-training data does not adequately cover the language patterns in privacy policies, zero-shot learning may not be effective.

## Foundational Learning

- Concept: Privacy policy structure and language
  - Why needed here: Understanding the structure and language of privacy policies is crucial for effectively applying the LLM to classification tasks.
  - Quick check question: What are the key components typically found in a privacy policy, and how are they usually expressed?

- Concept: Large language model capabilities and limitations
  - Why needed here: Knowing the strengths and weaknesses of LLMs, particularly in terms of their ability to understand and generate natural language, is essential for leveraging them effectively in privacy policy analysis.
  - Quick check question: What are the key differences between transformer-based models like GPT-4 and traditional machine learning models in terms of language processing?

- Concept: Prompt engineering techniques
  - Why needed here: Crafting effective prompts is critical for guiding the LLM to produce accurate and relevant outputs for privacy policy classification tasks.
  - Quick check question: What are the key elements of a well-designed prompt for privacy policy classification, and how do they influence the LLM's performance?

## Architecture Onboarding

- Component map: Prefix prompt generator -> LLM (ChatGPT/GPT-4) -> Result evaluator
- Critical path: Prefix prompt generation -> LLM processing of input text -> Result evaluation
- Design tradeoffs: Using zero-shot learning trades off the need for task-specific training data for leveraging the LLM's pre-existing knowledge
- Failure signatures: Unclear prompts lead to inaccurate classifications; insufficient LLM diversity or specialized language causes subpar performance
- First 3 experiments:
  1. Test effectiveness of different prefix prompt structures on a small subset of privacy policies
  2. Compare ChatGPT vs GPT-4 performance on larger privacy policy dataset
  3. Evaluate impact of few-shot vs zero-shot prompts on classification accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do large language models (LLMs) like GPT-4 perform on privacy policy analysis tasks in languages other than English?
- Basis in paper: [explicit] The paper focuses on English privacy policies and does not explore the performance of LLMs on non-English text.
- Why unresolved: The paper does not provide any experiments or data on multilingual privacy policy analysis, leaving the generalizability of LLMs to other languages unexplored.
- What evidence would resolve it: Conducting experiments with privacy policies in various languages and comparing the performance of LLMs to baseline models in each language.

### Open Question 2
- Question: Can the accuracy of privacy policy classification by LLMs be further improved by incorporating additional context, such as the website or app category?
- Basis in paper: [inferred] The paper mentions that some datasets provide context about the website or app category, but it does not investigate whether this additional information enhances LLM performance.
- Why unresolved: The paper does not explore the potential benefits of incorporating contextual information beyond the privacy policy text itself.
- What evidence would resolve it: Training and evaluating LLMs with and without additional contextual information, such as website or app category, and comparing the classification accuracy.

### Open Question 3
- Question: How do the performance and resource requirements of LLMs for privacy policy analysis scale with the length and complexity of the policies?
- Basis in paper: [explicit] The paper demonstrates the effectiveness of LLMs on privacy policies of varying lengths but does not analyze the scaling behavior or resource consumption.
- Why unresolved: The paper does not provide insights into how the performance and computational demands of LLMs change as the size and complexity of privacy policies increase.
- What evidence would resolve it: Conducting experiments with privacy policies of different lengths and complexities, measuring the accuracy, inference time, and computational resources required by LLMs.

## Limitations

- The study relies on relatively small datasets (115 website policies and 304 mobile app policies) that may not capture full diversity of privacy policy language
- Evaluation methodology excludes or discards "Other" category annotations, potentially biasing results toward the 10 defined categories
- The paper does not address temporal stability - privacy policies frequently change and performance over time is not evaluated

## Confidence

- **High confidence**: The empirical findings that PolicyGPT achieves 97% accuracy on OPP-115 and 87% on PPGDPR datasets using zero-shot learning, and that these results surpass baseline machine learning and neural network models
- **Medium confidence**: The claim that zero-shot learning is sufficient and that few-shot prompts provide no significant improvement (lacks detailed statistical analysis)
- **Low confidence**: The generalizability of these results to real-world deployment scenarios, as the study does not address cost considerations, API limitations, or performance on privacy policies in different languages or jurisdictions

## Next Checks

1. **Temporal validation**: Re-run PolicyGPT on the same datasets after introducing synthetic changes to privacy policies (e.g., updated language, new regulations) to assess robustness over time
2. **Cross-jurisdictional testing**: Evaluate PolicyGPT on privacy policies from different regulatory frameworks (GDPR, CCPA, PIPL) to determine if performance generalizes across legal contexts
3. **Cost-benefit analysis**: Compare the computational cost and latency of PolicyGPT against traditional ML models for production deployment, including token usage calculations for both prompt and completion phases