---
ver: rpa2
title: Fixing Overconfidence in Dynamic Neural Networks
arxiv_id: '2302.06359'
source_url: https://arxiv.org/abs/2302.06359
tags:
- msdnet
- uncertainty
- laplace
- vanilla
- classi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the problem of overconfident and miscalibrated
  predictions in dynamic neural networks, which hinders their ability to distinguish
  easy from hard samples and thus limits computational efficiency. The authors propose
  a probabilistic approach based on last-layer Laplace approximations combined with
  model-internal ensembling across the multiple exits of an MSDNet.
---

# Fixing Overconfidence in Dynamic Neural Networks

## Quick Facts
- arXiv ID: 2302.06359
- Source URL: https://arxiv.org/abs/2302.06359
- Reference count: 40
- Key outcome: Laplace approximation + model-internal ensembling improves calibration and reduces overconfidence in MSDNets

## Executive Summary
This paper addresses overconfidence and miscalibration in dynamic neural networks (specifically MSDNets), which hampers their ability to distinguish easy from hard samples and limits computational efficiency. The authors propose a probabilistic approach using last-layer Laplace approximations combined with model-internal ensembling across multiple exits. This provides well-calibrated uncertainty estimates that reduce overconfidence and improve decision-making at each exit. Experiments on CIFAR-100 and ImageNet demonstrate consistent gains in accuracy, better uncertainty capture (lower NLPD), and improved calibration (lower ECE), especially for larger models.

## Method Summary
The method involves training a vanilla MSDNet with standard cross-entropy loss, then applying a post-hoc last-layer Laplace approximation to each intermediate classifier. Temperature scaling and prior variance parameters are optimized via grid search on validation data. Model-internal ensembling aggregates predictions across all exits up to the current one using weights proportional to computational complexity. Decision thresholds are calculated on validation data to enforce computational budgets. The approach adds minimal computational overhead while significantly improving both accuracy and calibration.

## Key Results
- Consistent improvements in Top-1/Top-5 accuracy across CIFAR-100 and ImageNet
- Better uncertainty capture with lower negative log-predictive density (NLPD) scores
- Improved calibration with reduced expected calibration error (ECE)
- Computational overhead remains minimal (~0.1-0.4% on CIFAR-100, ~0.05-0.16% on ImageNet)

## Why This Works (Mechanism)

### Mechanism 1: Laplace Approximation for Epistemic Uncertainty
The Laplace approximation reduces overconfidence by providing calibrated uncertainty estimates for the last layer parameters through second-order Taylor expansion of the log-posterior around the MAP estimate. This yields a Gaussian posterior that captures epistemic uncertainty, critical for distinguishing hard samples from easy ones.

### Mechanism 2: Model-Internal Ensembling (MIE)
MIE improves predictive robustness by aggregating predictions across intermediate classifiers. By taking a weighted average of predictions from all previous exits up to the current classifier, MIE incorporates uncertainty information from earlier stages and smooths out overconfident predictions.

### Mechanism 3: Temperature Scaling
Temperature scaling optimizes the calibration of Laplace-approximated predictions by scaling pre-softmax logits. This softens or sharpens predicted probabilities, allowing fine-tuning of calibration without retraining the model.

## Foundational Learning

- **Concept: Bayesian inference and posterior approximation**
  - Why needed here: Understanding how the Laplace approximation works to approximate the posterior distribution of last layer parameters
  - Quick check question: What is the key difference between a point estimate (like MAP) and a posterior distribution in Bayesian inference?

- **Concept: Aleatoric vs. epistemic uncertainty**
  - Why needed here: The paper explicitly addresses both types of uncertainty, with Laplace approximation primarily targeting epistemic uncertainty about model parameters
  - Quick check question: In the context of image classification, what kind of uncertainty would be associated with ambiguous or mislabeled images?

- **Concept: Calibration metrics (ECE, NLPD)**
  - Why needed here: The paper evaluates improvements in calibration using these metrics, which measure how well predicted confidences match empirical accuracy
  - Quick check question: If a model has high expected calibration error (ECE), what does that say about the relationship between its confidence scores and actual accuracy?

## Architecture Onboarding

- **Component map:**
  - MSDNet backbone (multi-scale, dense connectivity)
  - Intermediate classifiers at each block exit
  - Laplace approximation module (applied to last linear layer of each classifier)
  - Model-internal ensembling (weighted average of predictions up to current classifier)
  - Temperature scaling (per-exit parameter optimization)
  - Decision threshold calculation (based on validation set)

- **Critical path:**
  1. Train vanilla MSDNet with standard cross-entropy loss
  2. Apply last-layer Laplace approximation to each intermediate classifier
  3. Optimize temperature and prior variance parameters via grid search
  4. Implement model-internal ensembling
  5. Calculate decision thresholds on validation set
  6. Deploy with calibrated uncertainty estimates for early exiting

- **Design tradeoffs:**
  - Laplace approximation vs. full Bayesian inference: Computational efficiency vs. approximation accuracy
  - MIE vs. deep ensembles: No additional training vs. potentially better uncertainty estimates
  - Per-exit vs. global temperature scaling: Fine-grained calibration vs. simplicity
  - Fixed vs. learned decision thresholds: Deterministic behavior vs. potential overfitting to validation set

- **Failure signatures:**
  - Overconfidence persists: Check if Laplace approximation is properly implemented and if temperature scaling is optimized
  - Calibration degrades with budget: Verify that decision thresholds are appropriately set and that uncertainty estimates are stable across exits
  - Computational overhead too high: Review efficient Laplace sampling implementation and ensure MIE weights are pre-computed

- **First 3 experiments:**
  1. Implement vanilla MSDNet on CIFAR-100, verify baseline accuracy and calibration metrics
  2. Add Laplace approximation to last layer of each classifier, check improvement in NLPD and ECE
  3. Implement MIE and compare Top-1 accuracy and calibration metrics against vanilla and Laplace-only versions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of Laplace prior variance affect the trade-off between calibration and accuracy in MSDNets?
- Basis in paper: [explicit] The paper discusses optimizing temperature scaling and Laplace prior variance via grid search, suggesting its importance
- Why unresolved: The paper only mentions grid search optimization but doesn't provide a detailed analysis of how different prior variances impact the balance between calibration and accuracy
- What evidence would resolve it: A systematic ablation study showing the impact of various Laplace prior variances on calibration metrics (ECE, NLPD) and accuracy across different model sizes and datasets

### Open Question 2
- Question: Can the computational efficiency of the Laplace approximation be further improved for even larger models or datasets?
- Basis in paper: [inferred] The paper presents an efficient implementation but acknowledges that Laplace approximation adds computational overhead, especially for large models like ImageNet
- Why unresolved: The paper focuses on demonstrating the effectiveness of the current efficient implementation but doesn't explore potential further optimizations
- What evidence would resolve it: A comparative study evaluating alternative approximation methods or algorithmic optimizations against the current efficient Laplace implementation on larger models and datasets

### Open Question 3
- Question: How does the model-internal ensembling (MIE) approach compare to traditional deep ensembles in terms of both accuracy and uncertainty quantification?
- Basis in paper: [explicit] The paper proposes MIE as a computationally efficient alternative to deep ensembles but doesn't directly compare the two approaches
- Why unresolved: The paper focuses on the benefits of MIE but lacks a direct comparison to deep ensembles to quantify the trade-offs
- What evidence would resolve it: A controlled experiment comparing MIE and deep ensembles on the same datasets and model architectures, evaluating both accuracy and uncertainty metrics

## Limitations
- The assumption that the last-layer posterior can be well-approximated by a Gaussian may break down for very deep networks or those with complex loss landscapes
- Computational overhead claims are based on specific efficient implementation details that may vary across frameworks
- Limited empirical validation of Laplace approximation specific to dynamic networks in the existing literature

## Confidence
- High confidence: Temperature scaling optimization and its impact on calibration
- Medium confidence: Laplace approximation's effectiveness in reducing overconfidence
- Medium confidence: Model-internal ensembling's contribution to predictive robustness

## Next Checks
1. Test the proposed method on MSDNet variants with different numbers of intermediate classifiers to verify calibration improvements generalize
2. Implement and compare against deep ensembles and Monte Carlo dropout baselines on the same dynamic network architecture
3. Evaluate the method on datasets with long-tail class distributions to assess whether calibration improvements hold for rare classes