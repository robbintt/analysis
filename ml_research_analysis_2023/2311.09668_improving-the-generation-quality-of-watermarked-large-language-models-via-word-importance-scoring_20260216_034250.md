---
ver: rpa2
title: Improving the Generation Quality of Watermarked Large Language Models via Word
  Importance Scoring
arxiv_id: '2311.09668'
source_url: https://arxiv.org/abs/2311.09668
tags:
- uni00000013
- uni00000011
- importance
- uni00000048
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of degraded text quality in large
  language model (LLM) watermarking. Token-level watermarking modifies generation
  logits to embed detectable patterns, but this can harm output quality when important
  tokens are altered.
---

# Improving the Generation Quality of Watermarked Large Language Models via Word Importance Scoring

## Quick Facts
- arXiv ID: 2311.09668
- Source URL: https://arxiv.org/abs/2311.09668
- Reference count: 4
- This paper proposes Watermarking with Importance Scoring (WIS) to improve text quality in LLM watermarking by protecting high-importance tokens from modification.

## Executive Summary
This paper addresses the challenge of degraded text quality in large language model watermarking. Token-level watermarking algorithms modify generation logits to embed detectable patterns, but this can harm output quality when important tokens are altered. The authors propose WIS, a framework that estimates token importance and protects high-importance tokens from being modified by the watermarking algorithm. WIS introduces three importance scoring methods: perturbation-based (using BERTScore), regression-based (fine-tuned BERT on paraphrase frequency), and classification-based (binary prediction). Evaluated on FIB and ELI5 datasets, WIS improves ROUGE-1 scores while maintaining comparable watermark detection rates, with perturbation-based scoring showing consistent gains across settings.

## Method Summary
The WIS framework integrates with token-level watermarking by estimating token importance at each generation step and preventing modification of high-importance tokens. Three importance scoring methods are proposed: perturbation-based scoring computes BERTScore cosine similarity between the original and perturbed token sequences; regression-based scoring uses a fine-tuned BERT model to predict paraphrase frequency; and classification-based scoring uses a BERT binary classifier. The framework applies these scores to identify and protect tokens critical for semantic correctness during watermarking. Experiments use LLaMA-2-13B with FIB and ELI5 datasets, evaluating the trade-off between ROUGE-1 scores and watermark detection rates across varying watermarking strengths.

## Key Results
- WIS improves ROUGE-1 scores while maintaining comparable detection rates compared to baseline watermarking
- Perturbation-based scoring (WIS-Perturbation) shows consistent quality improvements across all watermarking strengths
- Model-based methods (WIS-Regression and WIS-Classification) excel at higher watermarking strengths (γ ≥ 0.35)
- WIS achieves better trade-off curves between text quality and detection rate than baseline watermarking

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Token-level watermarking degrades text quality when important tokens are modified
- Mechanism: Watermarking algorithm alters logits to promote greenlist tokens, but if these tokens are semantically critical, their forced selection degrades semantic correctness
- Core assumption: The original LLM outputs contain important tokens that should be preserved for semantic correctness
- Evidence anchors:
  - [abstract]: "this watermarking algorithm alters the logits during generation, which can lead to a downgraded text quality if it chooses to promote tokens that are less relevant given the input"
  - [section 1]: "Due to the well-known hallucinations in LLMs, the entropy of logits may not correctly reflect the factual importance of tokens in the generated output"
  - [corpus]: Weak - no direct evidence found
- Break condition: If token importance scoring function fails to correctly identify semantically important tokens

### Mechanism 2
- Claim: Importance scoring protects semantically critical tokens from watermark modification
- Mechanism: WIS framework estimates token importance and prevents modification of high-importance tokens by the watermarking algorithm, preserving semantic quality
- Core assumption: Tokens identified as important by scoring function are indeed critical for semantic correctness
- Evidence anchors:
  - [section 4.1]: "At each generation step, we estimate the importance of the token to generate, and prevent it from being impacted by watermarking if it is important for the semantic correctness of the output"
  - [section 4.2]: "if st in s = [ s1, ..., st] contains important information, the semantic representation of s would be changed significantly if we add a perturbation to st"
  - [corpus]: Weak - no direct evidence found
- Break condition: If importance scoring function has high false positive rate for non-critical tokens

### Mechanism 3
- Claim: Different importance scoring methods have complementary strengths
- Mechanism: Perturbation-based method works consistently across settings, while model-based methods excel at higher watermarking strengths by better capturing semantic importance
- Core assumption: Different scoring methods capture different aspects of token importance, leading to complementary performance
- Evidence anchors:
  - [section 5.3]: "WIS-Perturbation outstrips the baseline in achieving higher ROUGE-1 scores at comparable detection rates, showcasing its efficacy notably at γ = 0.25"
  - [section 5.3]: "With an elevation in γ, WIS-Regression and WIS-Classification begin to dominate"
  - [corpus]: Weak - no direct evidence found
- Break condition: If scoring method selection is not matched to watermarking strength

## Foundational Learning

- Concept: Token-level watermarking algorithm (Kirchenbauer et al. 2023)
  - Why needed here: Understanding the baseline mechanism is essential to grasp what WIS improves
  - Quick check question: How does the watermarking algorithm partition the vocabulary and modify logits?

- Concept: Importance scoring function definition and implementation
  - Why needed here: The core of WIS is the importance scoring function that identifies which tokens to protect
  - Quick check question: What are the three proposed methods for implementing the importance scoring function?

- Concept: Trade-off between text quality and detection rate
  - Why needed here: WIS aims to improve this trade-off, so understanding it is crucial
  - Quick check question: What happens to ROUGE-1 scores as detection rate increases with watermarking strength?

## Architecture Onboarding

- Component map: Input text -> Importance scoring -> Watermarking with protection of high-importance tokens -> Output text
- Critical path: Input text → Importance scoring → Watermarking with protection of high-importance tokens → Output text
- Design tradeoffs:
  - Accuracy vs. efficiency of importance scoring function
  - Protection of important tokens vs. watermark detection rate
  - Different scoring methods for different watermarking strengths
- Failure signatures:
  - High false positive rate in importance scoring leads to unnecessary token protection
  - Low false negative rate in importance scoring fails to protect critical tokens
  - Scoring function adds significant inference time overhead
- First 3 experiments:
  1. Implement baseline watermarking without importance scoring on FIB dataset
  2. Add perturbation-based importance scoring and compare ROUGE-1 vs detection rate
  3. Compare different importance scoring methods (perturbation, regression, classification) at various watermarking strengths

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the importance scoring function generalize across different LLM architectures and domains beyond text generation?
- Basis in paper: [explicit] The paper evaluates WIS on LLaMA-2-13B and two specific datasets (FIB and ELI5), but doesn't test generalization to other architectures or domains.
- Why unresolved: The current experiments only demonstrate performance on a single LLM model and two specific text generation tasks. The importance scoring methods may not transfer well to different model architectures or domains with different linguistic patterns.
- What evidence would resolve it: Experiments testing WIS across multiple LLM architectures (different sizes, training objectives) and diverse domains (code generation, dialogue systems, scientific writing) would establish generalizability.

### Open Question 2
- Question: What is the optimal balance between computational efficiency and importance scoring accuracy in real-time applications?
- Basis in paper: [inferred] The paper mentions efficiency concerns but doesn't systematically explore the trade-off between scoring accuracy and computational overhead.
- Why unresolved: The three scoring methods have different computational costs (perturbation-based vs model-based), but the paper doesn't analyze how much accuracy is sacrificed for efficiency gains or vice versa.
- What evidence would resolve it: Systematic ablation studies varying window sizes, model complexity, and scoring frequency while measuring both accuracy improvements and computational overhead would quantify this trade-off.

### Open Question 3
- Question: How do adversarial attacks specifically targeting the importance scoring module affect WIS performance?
- Basis in paper: [explicit] The paper discusses security considerations but doesn't evaluate specific attacks against the importance scoring component.
- Why unresolved: While the paper mentions potential vulnerabilities to attackers inferring greenlist tokens, it doesn't test targeted attacks designed to fool the importance scoring function itself.
- What evidence would resolve it: Red-teaming experiments where attackers craft inputs specifically designed to manipulate the importance scoring module, combined with robustness evaluations of different scoring methods, would reveal vulnerability patterns.

## Limitations
- Small dataset sizes (500 examples each) may not provide sufficient statistical power for robust conclusions
- Importance scoring functions may not perfectly capture true semantic importance versus spurious correlations
- Hyperparameter choices (r0 thresholds, window sizes) appear arbitrary and may not generalize across tasks

## Confidence
**High Confidence**: The core observation that token-level watermarking can degrade text quality when important tokens are modified.
**Medium Confidence**: The WIS framework's ability to improve the quality-detection trade-off through importance scoring.
**Low Confidence**: The specific implementation details of the importance scoring functions and their generalizability.

## Next Checks
1. **Statistical significance testing**: Perform paired t-tests or bootstrap confidence intervals on ROUGE-1 scores across multiple runs to establish whether observed improvements are statistically significant rather than random variation.
2. **Ablation study on importance scoring**: Compare WIS performance against a random token protection baseline to determine whether the importance scoring function provides meaningful improvement over simply protecting a random subset of tokens.
3. **Cross-task generalization**: Evaluate WIS on additional datasets beyond FIB and ELI5 (e.g., summarization, dialogue) to assess whether the observed improvements transfer to different generation tasks and whether the same hyperparameters remain effective.