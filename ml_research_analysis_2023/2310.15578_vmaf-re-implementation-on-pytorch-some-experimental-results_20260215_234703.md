---
ver: rpa2
title: 'VMAF Re-implementation on PyTorch: Some Experimental Results'
arxiv_id: '2310.15578'
source_url: https://arxiv.org/abs/2310.15578
tags:
- vmaf
- image
- implementation
- version
- video
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The authors re-implemented the VMAF video quality metric in PyTorch\
  \ and showed it matches the standard C implementation to within 0.01 VMAF units\
  \ (\u224810\u207B\xB2 relative error). They demonstrated that VMAF gradients can\
  \ be computed reliably for optimization tasks, contrary to claims of non-differentiability."
---

# VMAF Re-implementation on PyTorch: Some Experimental Results

## Quick Facts
- arXiv ID: 2310.15578
- Source URL: https://arxiv.org/abs/2310.15578
- Reference count: 14
- Primary result: PyTorch re-implementation of VMAF matches C implementation within 0.01 VMAF units and enables reliable gradient-based optimization for video compression preprocessing

## Executive Summary
This paper presents a PyTorch re-implementation of the VMAF video quality metric, demonstrating that it can achieve numerical agreement with the standard C implementation while enabling reliable gradient computation for optimization tasks. The authors address claims about VMAF's non-differentiability by showing that when implemented with floating-point precision, all constituent operations (VIF, ADM, motion feature, and SVM regression) are mathematically differentiable. They validate this through gradient checking using finite differences and demonstrate practical utility by training a preprocessing filter for video compression that outperforms traditional unsharp masking methods.

## Method Summary
The authors re-implement VMAF in PyTorch by closely following the Netflix C implementation's algorithmic structure while replacing discrete integer operations with floating-point equivalents. The implementation includes all VMAF components: VIF (Visual Information Fidelity) using four-scale downsampling and mutual information calculation, ADM (Artifact Detection Model) using wavelet decomposition, motion features for temporal information, and SVM regression for final score aggregation. Numerical accuracy is verified by comparing scores against the reference C implementation on 79 video streams from the Netflix dataset, while gradient reliability is confirmed through finite difference approximation comparisons.

## Key Results
- PyTorch implementation achieves numerical agreement with C implementation within 0.01 VMAF units (≈10⁻² relative error)
- Gradient checking confirms computed gradients match numerical approximations within acceptable error margins
- Trained preprocessing filter using VMAF gradients outperforms unsharp masking in video compression tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VMAF implemented in PyTorch can be differentiated reliably for gradient-based optimization
- Mechanism: The PyTorch re-implementation replaces discrete integer operations with floating-point equivalents, enabling backpropagation through all constituent operations (VIF, ADM, motion feature, and SVM regression). Gradient checking using finite differences confirms that computed gradients match numerical approximations within acceptable error margins.
- Core assumption: All VMAF components (VIF, ADM, motion feature) are mathematically differentiable when implemented with floating-point precision rather than integer quantization
- Evidence anchors:
  - [abstract] "We investigate gradients computation when using VMAF as an objective function and demonstrate that training using this function does not result in ill-behaving gradients."
  - [section] "VIF, ADM and motion features along with the final score regression are mostly composed of simple tensor manipulations, convolution operations... which are differentiable."
  - [corpus] Weak/no direct evidence; neighboring papers focus on video encoding control and neural embeddings rather than VMAF differentiability
- Break condition: Integer quantization is reintroduced, or non-differentiable operations (like hard clipping) are used without smooth approximations

### Mechanism 2
- Claim: The PyTorch implementation achieves numerical agreement with the standard C implementation to within 10^-2 VMAF units
- Mechanism: The re-implementation follows the C implementation's algorithmic structure closely, using equivalent floating-point operations. Small discrepancies arise from differences in image padding and the use of floating-point vs quantized integer values, but these are negligible for practical applications.
- Core assumption: Algorithmic equivalence between PyTorch and C implementations is sufficient for numerical convergence, despite implementation-level differences
- Evidence anchors:
  - [abstract] "For this implementation comparisons with the standard (libvmaf) show the discrepancy ≲ 10−2 in VMAF units."
  - [section] "The difference in scores measured over 79 video streams... is ≤ 0.01±0.01 VMAF units... The small differences observed for sub-metrics probably occur because of discrepancies in image padding which are different in PyTorch and the official implementation in libvmaf"
  - [corpus] No relevant evidence; neighboring papers focus on different quality assessment or gradient computation methods
- Break condition: Significant algorithmic deviations are introduced, or numerical precision requirements exceed 10^-2 tolerance

### Mechanism 3
- Claim: Gradient-based training with VMAF as objective function improves video compression preprocessing filter performance compared to unsharp masking
- Mechanism: Using the differentiable PyTorch implementation, VMAF gradients can be computed with respect to preprocessing filter parameters. Gradient descent optimization then directly maximizes VMAF score through filter adaptation, finding superior parameter configurations compared to hand-tuned methods like unsharp masking.
- Core assumption: Maximizing VMAF score through preprocessing correlates with perceptual video quality improvement in compression scenarios
- Evidence anchors:
  - [abstract] "Using this implementation, we trained a preprocessing filter for video compression that outperformed unsharp masking, with easy-to-implement results confirmed by numerical experiments."
  - [section] "Our implementation enabled us to employ VMAF as a cost function for various optimization tasks related to compression"
  - [corpus] No direct evidence; neighboring papers focus on quality prediction and gradient preconditioning rather than VMAF-based filter training
- Break condition: The relationship between VMAF optimization and perceptual quality breaks down for specific content types or compression scenarios

## Foundational Learning

- Concept: VMAF metric composition (VIF, ADM, motion feature, SVM regression)
  - Why needed here: Understanding how VMAF is constructed is essential for knowing which components are differentiable and how gradients flow through the system
  - Quick check question: What are the three elementary features that VMAF computes for each frame before applying SVM regression?

- Concept: Gradient checking methodology
  - Why needed here: Verifying that computed gradients are correct is critical before using VMAF for optimization; understanding the finite difference approximation and its limitations is essential
  - Quick check question: What is the formula for central difference approximation of a derivative, and what are the key considerations when choosing epsilon?

- Concept: Image quality assessment metrics and their differentiability properties
  - Why needed here: VMAF builds on VIF and ADM, which have specific mathematical properties (mutual information, wavelet decomposition) that affect differentiability
  - Quick check question: Why might mutual information, as used in VIF, be considered non-differentiable in the strict mathematical sense?

## Architecture Onboarding

- Component map: Input video frames → Color space conversion → VIF computation (four-scale downsampling + mutual information) → ADM computation (wavelet decomposition) → Motion feature extraction → Feature normalization → SVM regression (RBF kernel) → Aggregated VMAF score
- Critical path: Frame processing → Feature extraction (VIF, ADM, motion) → Feature normalization → SVM regression → Score aggregation
- Design tradeoffs:
  - Floating-point vs integer precision: Enables differentiability but may introduce small numerical discrepancies
  - Single-frame vs multi-frame processing: Current implementation processes frames independently for VIF/ADM, motion feature adds temporal information
  - Exact vs approximate gradient computation: Finite difference checking provides verification but is computationally expensive
- Failure signatures:
  - NaN or infinite gradients: Likely indicates numerical instability in logarithmic or division operations
  - Zero gradients across entire parameter space: May indicate improper gradient flow or non-differentiable operations
  - Large discrepancies (>10^-2) from reference implementation: Suggests algorithmic deviation or implementation error
- First 3 experiments:
  1. Verify numerical agreement: Run both PyTorch and reference C implementations on the same 50-frame video sample and compare VMAF scores frame-by-frame
  2. Gradient checking validation: Implement a simple convolution filter, compute gradients via backpropagation, and compare with finite difference approximations using the reference C implementation
  3. End-to-end optimization test: Train a simple 3x3 convolution filter to maximize VMAF score on a sample video and verify that performance exceeds unsharp masking baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific limitations and potential numerical instability issues when computing VMAF gradients for optimization tasks, particularly in edge cases or with certain types of video content?
- Basis in paper: [inferred] The paper mentions investigating gradients computation and demonstrates that training using VMAF as an objective function does not result in ill-behaving gradients, but does not provide detailed analysis of potential edge cases or specific numerical issues.
- Why unresolved: The paper provides a general statement about gradient behavior but lacks detailed analysis of edge cases, specific numerical issues, or limitations of the gradient computation method.
- What evidence would resolve it: A comprehensive study analyzing gradient behavior across various types of video content, edge cases, and potential numerical instability issues. This could include systematic testing of different video scenarios and reporting on any observed gradient anomalies or computational challenges.

### Open Question 2
- Question: How does the performance of VMAF-based optimization compare to other video quality metrics (e.g., PSNR, SSIM) in practical video compression tasks, and under what conditions does VMAF provide a significant advantage?
- Basis in paper: [explicit] The paper mentions that VMAF has become one of the main tools for image/video quality assessment in compression tasks, but does not directly compare its optimization performance to other metrics.
- Why unresolved: While the paper demonstrates successful use of VMAF for optimization, it does not provide a comparative analysis with other quality metrics in terms of compression performance or practical advantages.
- What evidence would resolve it: Empirical studies comparing the effectiveness of VMAF-based optimization to other metrics in various video compression scenarios, including quantitative results on compression ratios, subjective quality, and computational efficiency.

### Open Question 3
- Question: What are the implications of using a differentiable VMAF implementation for end-to-end learning in video compression systems, and how does it impact the overall system performance compared to traditional two-step approaches?
- Basis in paper: [explicit] The paper discusses the potential use of the PyTorch implementation for training neural networks in tasks such as compression and image enhancement, but does not provide specific results or analysis of end-to-end learning scenarios.
- Why unresolved: The paper introduces the concept of using differentiable VMAF for optimization but does not explore the specific implications or performance benefits of end-to-end learning in video compression systems.
- What evidence would resolve it: Experimental results comparing end-to-end learning systems using differentiable VMAF with traditional two-step approaches in terms of compression efficiency, quality metrics, and computational resources. This could include case studies of real-world video compression scenarios and their performance metrics.

## Limitations

- The numerical agreement with the reference implementation, while within the stated 10^-2 tolerance, shows sub-metric discrepancies that could indicate implementation differences beyond just image padding
- The gradient verification relies on finite difference approximations which, while standard, introduce their own numerical uncertainties
- The single application (preprocessing filter training) provides limited evidence for broader optimization scenarios

## Confidence

- **High confidence**: VMAF can be implemented in PyTorch with numerical agreement to within 10^-2 VMAF units compared to the C reference implementation
- **Medium confidence**: The gradients computed through backpropagation are reliable and can be used for optimization tasks
- **Medium confidence**: Gradient-based training with VMAF as objective function improves preprocessing filter performance compared to unsharp masking

## Next Checks

1. **Cross-validation on diverse content**: Test the PyTorch implementation across a broader range of video content types (animation, sports, low-light scenes) to verify that the 10^-2 accuracy threshold holds consistently across different visual characteristics.

2. **Gradient stability analysis**: Perform extensive gradient checking across multiple optimization scenarios with varying learning rates and filter sizes to identify potential instability regions or pathological cases where gradients become unreliable.

3. **End-to-end perceptual validation**: Conduct subjective quality assessment studies comparing videos processed with the optimized filter against both unsharp masking and the reference C implementation to verify that VMAF optimization correlates with perceived quality improvements.