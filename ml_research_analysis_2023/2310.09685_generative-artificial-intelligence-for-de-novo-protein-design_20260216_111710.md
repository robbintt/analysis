---
ver: rpa2
title: Generative artificial intelligence for de novo protein design
arxiv_id: '2310.09685'
source_url: https://arxiv.org/abs/2310.09685
tags:
- protein
- design
- proteins
- diffusion
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This review highlights how generative artificial intelligence has
  enabled dramatic progress in de novo protein design. The authors outline how sequence-based
  approaches using large language models and structure-based methods using diffusion
  models allow sampling from plausible protein space beyond what is found in nature.
---

# Generative artificial intelligence for de novo protein design

## Quick Facts
- arXiv ID: 2310.09685
- Source URL: https://arxiv.org/abs/2310.09685
- Reference count: 0
- One-line primary result: Generative AI enables de novo protein design with experimental success rates reaching 20%

## Executive Summary
This review explores how generative artificial intelligence has revolutionized de novo protein design. Two main approaches are discussed: sequence-based methods using large language models and structure-based methods using diffusion models. These approaches enable sampling from protein space beyond what evolution has explored, allowing the design of proteins with novel folds and functions. The review highlights key advances including 20% experimental success rates, the ability to condition designs on desired properties, and the importance of incorporating biochemical knowledge.

## Method Summary
The review synthesizes approaches for de novo protein design using generative AI, focusing on two main paradigms: sequence-based generation using large language models trained on protein sequences, and structure-based generation using diffusion models trained on protein structures. The process involves training generative models on natural protein datasets, conditioning them on desired properties, generating novel protein designs, and experimentally validating the designs. Key methodological components include proper data preprocessing, incorporating biochemical knowledge, and using classifier models for property conditioning.

## Key Results
- Experimental success rates of designed proteins reaching 20%
- Diffusion models can generate diverse protein structures including novel folds
- Models can be conditioned on desired properties or natural language queries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Diffusion models can sample from plausible protein space beyond what evolution explored
- Mechanism: Diffusion models are trained by iteratively adding Gaussian noise to protein structures, then learning to denoise. This enables them to model a probability distribution over protein structures, allowing sampling from regions of high fitness.
- Core assumption: The noising process does not destroy the underlying biophysical constraints that define plausible proteins
- Evidence anchors:
  - [abstract] "Diffusion models that can generate diverse protein structures including novel folds"
  - [section] "Diffusion models have learned to generalize beyond the parts of protein space inhabited by natural proteins"
  - [corpus] Weak - no direct evidence in corpus about diffusion models specifically

### Mechanism 2
- Claim: Conditioning diffusion models on desired properties enables targeted protein design
- Mechanism: By incorporating classifier models trained on noised structures, the diffusion trajectory can be guided towards desired outcomes like specific shapes, symmetries, or functions
- Core assumption: The classifier models can accurately predict the desired properties from intermediate noisy states
- Evidence anchors:
  - [abstract] "Models that can be conditioned on desired properties or natural language queries"
  - [section] "The conditioning process results in quicker, more effective outcomes and enabling more semantic conditioning"
  - [corpus] Weak - no specific corpus evidence about conditioning mechanisms

### Mechanism 3
- Claim: Incorporating biochemical knowledge improves generative model performance
- Mechanism: Pre-processing data to remove problematic regions (like signal peptides), using codon-based embeddings, and leveraging structural alphabets all improve model accuracy by providing more relevant training signals
- Core assumption: The biochemical knowledge incorporated is actually relevant to the protein design task
- Evidence anchors:
  - [abstract] "The power of incorporating biochemical knowledge to improve performance and interpretability"
  - [section] "Several studies have shown that incorporating biochemical insights in the training data, data processing and protein representation leads to significantly improved outcomes"
  - [corpus] Weak - no specific corpus evidence about biochemical knowledge incorporation

## Foundational Learning

- Concept: Probability distributions and sampling
  - Why needed here: Generative models learn to model probability distributions over protein space and sample from them
  - Quick check question: What is the difference between a generative model and a discriminative model?

- Concept: Diffusion processes
  - Why needed here: Diffusion models use a specific type of generative process involving iterative noising and denoising
  - Quick check question: How does the diffusion process in generative models differ from traditional denoising autoencoders?

- Concept: SE(3) equivariance
  - Why needed here: Protein structures should be invariant to rigid transformations like rotation and translation
  - Quick check question: Why is it important for protein structure models to be SE(3) equivariant?

## Architecture Onboarding

- Component map: Generative model (diffusion or LLM) -> Structure-to-sequence module (if structure-based) -> Classifier models (for conditioning) -> Experimental validation pipeline
- Critical path: Training data -> Model architecture -> Training process -> Sampling/inference -> Experimental validation
- Design tradeoffs: More parameters vs. computational cost, incorporating structure vs. sequence-only, conditioning vs. unconstrained generation
- Failure signatures: Low experimental success rates, inability to generate diverse structures, poor conditioning performance
- First 3 experiments:
  1. Train a basic diffusion model on a small protein dataset and verify it can generate plausible structures
  2. Implement conditioning on secondary structure and test generation performance
  3. Compare experimental success rates of unconditioned vs. conditioned designs

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the best in silico metrics for prioritizing protein designs for experimental testing?
- Basis in paper: [explicit] The paper states "determining the best in silico metrics to prioritise designs for experimental testing" as a field-wide challenge.
- Why unresolved: Current metrics like pLDDT have been shown to be poor predictors of experimental functionality, while other metrics like ProteinMPNN and ESM-1v log-likelihood scores perform better but still have limitations.
- What evidence would resolve it: Comparative studies evaluating different combinations of in silico metrics against large experimental datasets of designed proteins, determining which combinations best predict experimental success across different protein types and design tasks.

### Open Question 2
- Question: How can generative models be improved to design proteins that undergo large conformational changes?
- Basis in paper: [explicit] The paper highlights the challenge of "designing proteins that can undergo large conformational changes" as a key limitation.
- Why unresolved: Current models struggle to capture protein conformational landscapes and predict multiple conformers efficiently without extensive molecular dynamics simulations.
- What evidence would resolve it: Development and validation of generative models that can simultaneously generate multiple conformational states from sequence or structure alone, with experimental verification of designed proteins that undergo specific conformational changes upon stimuli.

### Open Question 3
- Question: How can biochemical knowledge be effectively incorporated into generative protein design models?
- Basis in paper: [explicit] The paper emphasizes "the power of incorporating biochemical knowledge to improve performance and interpretability" throughout.
- Why unresolved: While some studies have shown benefits of incorporating biochemical insights (e.g., data preprocessing, structural alphabets), there is no systematic framework for determining which biochemical features to include and how to integrate them effectively.
- What evidence would resolve it: Comparative studies testing different approaches to incorporating biochemical knowledge (e.g., structural features, codon information, PTM data) and their impact on model performance across various design tasks, leading to best practices for biochemical knowledge integration.

## Limitations
- Claims are primarily based on theoretical arguments rather than extensive empirical evidence
- Limited peer-reviewed validation available for the specific approaches discussed
- Unclear reproducibility of claimed 20% experimental success rates

## Confidence
- Medium confidence: Claims about diffusion models generating novel protein structures and achieving 20% experimental success rates
- Medium confidence: Assertions about conditioning models on desired properties
- Low confidence: Specific performance comparisons between different generative approaches and claims about incorporating biochemical knowledge improving interpretability

## Next Checks
1. Replicate the claimed 20% success rate by generating and testing proteins using publicly available diffusion models with standardized experimental protocols
2. Systematically evaluate how well diffusion models can be conditioned on different property types by generating proteins for each condition and measuring success rates
3. Compare performance of models with and without specific biochemical preprocessing on the same design tasks to quantify the actual benefit