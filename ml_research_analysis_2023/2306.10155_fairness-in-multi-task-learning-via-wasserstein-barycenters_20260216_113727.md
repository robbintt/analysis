---
ver: rpa2
title: Fairness in Multi-Task Learning via Wasserstein Barycenters
arxiv_id: '2306.10155'
source_url: https://arxiv.org/abs/2306.10155
tags:
- fairness
- learning
- fair
- multi-task
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method to enforce fairness constraints
  in multi-task learning (MTL) by extending the strong demographic parity definition
  to the multi-task setting using multi-marginal Wasserstein barycenters. The authors
  develop a closed-form solution for the optimal fair multi-task predictor and construct
  a data-driven plug-in estimator that achieves fairness while maintaining the advantages
  of MTL.
---

# Fairness in Multi-Task Learning via Wasserstein Barycenters

## Quick Facts
- **arXiv ID**: 2306.10155
- **Source URL**: https://arxiv.org/abs/2306.10155
- **Reference count**: 40
- **Primary result**: A post-processing method using Wasserstein barycenters that enforces Demographic Parity fairness in multi-task learning while preserving predictive performance

## Executive Summary
This paper introduces a method to enforce fairness constraints in multi-task learning by extending Demographic Parity to the multi-task setting using multi-marginal Wasserstein barycenters. The approach provides a closed-form solution for the optimal fair multi-task predictor and constructs a data-driven plug-in estimator that achieves fairness while maintaining MTL advantages. The method is evaluated on synthetic and real datasets, demonstrating effective reduction in unfairness while preserving predictive performance, especially when labels are scarce in one task.

## Method Summary
The method transforms the multi-task learning problem under Demographic Parity fairness into a Wasserstein barycenter construction. It trains an unconstrained multi-task model on labeled data, then applies post-processing using Wasserstein-2 distances to adjust predictions. The approach estimates cumulative distribution functions from unlabeled data and transforms predictions via optimal transport mappings to enforce fairness. The post-processing nature allows application to any pre-trained MTL model, making it flexible and broadly applicable.

## Key Results
- The method effectively reduces unfairness (measured by Kolmogorov-Smirnov test) while preserving predictive performance
- Performance is especially strong when labels are scarce in one task
- The post-processing approach maintains the advantages of multi-task learning
- Achieves fair predictions across both regression and binary classification tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Demographic Parity fairness can be enforced by transforming the multi-task problem into a Wasserstein barycenter problem
- Core assumption: Marginal distributions of predictions conditioned on sensitive attributes have densities
- Evidence: Abstract states closed-form solution exists; section 3 shows transformation to multi-marginal Wasserstein-2 barycenters
- Break condition: If marginal distributions don't have densities, the Wasserstein barycenter formulation may not be valid

### Mechanism 2
- Claim: The optimal fair predictor preserves group-wise rank statistics
- Core assumption: Optimal transport mapping is monotonic within sensitive groups
- Evidence: Theorem 1 shows post-processing preserves rank statistics conditional on sensitive feature
- Break condition: If transformation is not monotonic within groups (e.g., due to approximation errors), rank preservation may fail

### Mechanism 3
- Claim: Fairness can be achieved without retraining via post-processing approach
- Core assumption: Original MTL model provides useful predictions that can be adjusted
- Evidence: Abstract mentions post-processing nature; section 2.2 positions work in post-processing methods
- Break condition: If original model's predictions are highly biased or poor quality, post-processing may fail

## Foundational Learning

- Concept: Wasserstein distance and Wasserstein barycenters
  - Why needed here: Measures discrepancy between distributions of predictions conditioned on sensitive attributes; optimal fair predictor formulated as Wasserstein barycenter
  - Quick check question: What is the definition of Wasserstein-2 distance between two univariate probability measures ν and ν'?
    Answer: W₂²(ν,ν') = inf γ∈Γν,ν' {∫|y−y'|²dγ(y,y')}, where Γν,ν' is set of distributions on R×R having ν and ν' as marginals

- Concept: Demographic Parity (DP) fairness
  - Why needed here: Paper aims to enforce DP fairness requiring independence between sensitive attribute and predictions
  - Quick check question: What is the formal definition of DP fairness for predictor gt?
    Answer: A predictor gt is DP-fair if for all s,s'∈S, sup u∈Yt |P(gt(X,S)≤u|S=s)−P(gt(X,S)≤u|S=s')| = 0

- Concept: Multi-task learning (MTL) with parameter sharing
  - Why needed here: Considers setting where tasks share common representation to leverage similarities and improve performance when labels are scarce
  - Quick check question: How are task-specific predictors expressed in terms of shared representation?
    Answer: gt(·) = ft∘hθ(·), where hθ is shared representation function and ft is task-related function

## Architecture Onboarding

- Component map: Multi-task model -> Post-processing module -> Evaluation module
- Critical path: 1) Train unconstrained MTL model on labeled data, 2) Estimate CDFs/quantiles from unlabeled data, 3) Apply post-processing transformation, 4) Evaluate performance and fairness
- Design tradeoffs: Post-processing allows application to any pre-trained model but may not achieve same fairness level as in-processing methods; requires unlabeled data for CDF estimation; trade-off weights λ balance performance and fairness
- Failure signatures: High unfairness after post-processing (method ineffective for biased data); significant performance drop (post-processing too aggressive); unstable CDF/quantile estimates from insufficient unlabeled data
- First 3 experiments: 1) Train unconstrained MTL model and evaluate fairness using KS test, 2) Apply post-processing method and evaluate fairness/performance, 3) Vary trade-off weights λ and observe effect on performance-fairness balance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the post-processing approach perform when applied to more complex MTL architectures in computer vision or natural language processing?
- Basis: Authors note extending approach to these domains would be natural next step but provide no empirical results
- Why unresolved: Current evaluation limited to tabular data; performance on other data types unknown
- What evidence would resolve it: Experiments applying method to MTL models in computer vision/NLP, comparing performance and fairness to baselines

### Open Question 2
- Question: What are theoretical implications of considering general multivariate setting where fairness enforced simultaneously across all tasks?
- Basis: Authors note theoretical discussion on this extension would be interesting but left for future work
- Why unresolved: Current approach relies on quantile estimation which may not be feasible in general multivariate setting
- What evidence would resolve it: Development of theoretical framework for simultaneous fairness enforcement in multivariate settings with empirical validation

### Open Question 3
- Question: How does choice of trade-off weights λ affect balance between fairness and predictive performance in different MTL scenarios?
- Basis: Paper discusses using YOTO approach to handle trade-off weights but doesn't explore impact of different λ choices
- Why unresolved: Optimal λ choice may vary depending on specific tasks and data distribution; impact not fully characterized
- What evidence would resolve it: Systematic experiments varying λ across different MTL scenarios, analyzing resulting fairness-performance trade-offs

## Limitations

- Relies heavily on Assumption 1 (existence of densities for marginal distributions) which may not hold in real-world scenarios
- Method's performance under small group sizes or severe class imbalance is not extensively explored
- Computational complexity of post-processing step for large-scale applications remains unclear

## Confidence

- **High Confidence**: Mathematical formulation of Wasserstein barycenter problem and connection to DP fairness is well-established and rigorously proven
- **Medium Confidence**: Empirical evaluation demonstrates method's effectiveness on synthetic and real datasets, but results may not generalize to all MTL scenarios
- **Low Confidence**: Scalability and robustness to violations of core assumptions (e.g., non-density marginal distributions) are not thoroughly investigated

## Next Checks

1. **Robustness to Assumption Violations**: Test method on datasets where marginal distributions don't have densities (e.g., discrete features) and evaluate performance and fairness
2. **Scalability Analysis**: Assess computational complexity of post-processing step and its impact on large-scale MTL problems
3. **Sensitivity to Group Sizes**: Investigate method's performance when sensitive groups have highly imbalanced sizes, a common real-world scenario