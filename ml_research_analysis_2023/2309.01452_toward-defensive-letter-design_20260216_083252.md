---
ver: rpa2
title: Toward Defensive Letter Design
arxiv_id: '2309.01452'
source_url: https://arxiv.org/abs/2309.01452
tags:
- letter
- images
- defensibility
- attacks
- adversarial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the defensibility of letter images against
  adversarial attacks, focusing on the letters themselves rather than image classifiers.
  Three key questions are addressed: how defensive are individual letter images, can
  we estimate defensibility before attacks, and can we generate more defensive letter
  images.'
---

# Toward Defensive Letter Design

## Quick Facts
- arXiv ID: 2309.01452
- Source URL: https://arxiv.org/abs/2309.01452
- Reference count: 12
- Primary result: Generated letter images can be made more defensive against adversarial attacks, increasing average robustness from 17.8 to 21.7 attacks needed for misclassification

## Executive Summary
This paper explores the defensibility of letter images against adversarial attacks, focusing on the letters themselves rather than image classifiers. The study addresses three key questions: how defensive are individual letter images, can we estimate defensibility before attacks, and can we generate more defensive letter images. Using Iterative Fast Gradient Sign Method (I-FGSM) to measure defensibility by the number of attacks needed to misrecognize a letter, the research demonstrates that simpler, standard fonts have higher defensibility. A deep regression model is built to estimate defensibility without actual attacks, and a GAN-based method is proposed to generate more defensive letter images by optimizing for classifier recognition. Results show the proposed GAN model successfully generates more defensive letters, increasing average defensibility from 17.8 to 21.7 attacks needed for misrecognition.

## Method Summary
The paper employs a multi-step methodology to investigate letter defensibility. First, I-FGSM attacks are used to measure the defensibility of 26Ã—3,124 letter images from Google Fonts by counting the number of attacks needed to misrecognize each letter. A CNN classifier with two convolutional layers and two fully-connected layers is trained to classify letters. A deep regression model is then trained to estimate defensibility from letter images without performing attacks. Finally, a two-step GAN-based method is proposed: first training a standard GAN to generate realistic letter images, then further training the generator using the classifier's loss function to produce images that minimize classification loss, thereby increasing defensibility.

## Key Results
- Simpler, standard fonts have higher defensibility against adversarial attacks than decorative fonts
- A deep regression model can estimate defensibility from letter images with strong correlation to ground-truth values
- GAN-based generation of letter images increases average defensibility from 17.8 to 21.7 attacks needed for misclassification
- Decorative fonts are more vulnerable because they often appear as outliers in their class distribution

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Simpler and more standard fonts have higher defensibility against adversarial attacks
- Mechanism: Decorative fonts often appear as outliers in the distribution of letter classes, making them closer to neighboring classes and thus more vulnerable to adversarial perturbations. Standard fonts are located near the center of their class distribution, requiring more attacks to push them into misclassification.
- Core assumption: The robustness of a letter image to adversarial attacks is related to its position within the intra-class distribution
- Evidence anchors:
  - [abstract] Results show that simpler, standard fonts have higher defensibility
  - [section 3.2] Letter images by decorative fonts tend to have smaller defensibility since they are often outliers or located far from the center of the distribution of each letter class
  - [corpus] No direct evidence, but related work on adversarial attacks on images supports the general principle
- Break condition: If the classifier's decision boundary changes significantly, the relationship between font style and defensibility may no longer hold

### Mechanism 2
- Claim: There is a correlation between letter shape and defensibility that can be estimated by a deep regression model
- Mechanism: A deep CNN regression model trained on letter images and their measured defensibility values can learn to predict defensibility from letter shapes alone, without performing actual attacks
- Core assumption: The visual features of letter images that contribute to their defensibility can be learned by a regression model
- Evidence anchors:
  - [abstract] A deep regression model is built to estimate defensibility without actual attacks
  - [section 4.1] A deep regression model is trained to estimate the defensibility of each letter image
  - [section 4.2] Clear positive correlation between ground-truth and estimation proves strong correlations between letter shapes and defensibility
- Break condition: If the regression model fails to generalize to new letter styles or fonts not seen during training

### Mechanism 3
- Claim: A GAN-based model can generate letter images with higher defensibility by optimizing for classifier recognition
- Mechanism: A two-step GAN training process first generates realistic letter images, then further trains the generator using a classifier's loss function to produce images that minimize classification loss (opposite of attacking), resulting in higher defensibility
- Core assumption: Minimizing classification loss for a given classifier will result in images that are more resistant to that classifier's adversarial attacks
- Evidence anchors:
  - [abstract] A GAN-based method is proposed to generate more defensive letter images by optimizing for classifier recognition
  - [section 5.1] The generator is trained with a new loss function to increase the defensibility of generated letter images
  - [section 5.2] Quantitative evaluation shows generated images have higher defensibility (average 21.7 vs 17.8 attacks needed)
- Break condition: If the generated images become too stylized or lose readability, they may not be useful in practice

## Foundational Learning

- Concept: Adversarial attacks and defenses
  - Why needed here: Understanding the context of why letter images need to be defensive and how attacks work is crucial for grasping the paper's contributions
  - Quick check question: What is the main difference between traditional adversarial defense approaches and the approach taken in this paper?

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: The paper proposes a GAN-based method for generating defensive letter images, so understanding GAN architecture and training is essential
  - Quick check question: How does the two-step training process in the proposed GAN model differ from standard GAN training?

- Concept: Deep learning for image classification
  - Why needed here: The paper uses CNNs for both attacking letter images and estimating their defensibility, so familiarity with CNN architectures is necessary
- Quick check question: Why might a simple CNN with two convolutional layers be sufficient for this letter classification task?

## Architecture Onboarding

- Component map:
  - I-FGSM attacker -> CNN classifier -> Regression model for defensibility estimation -> GAN generator -> GAN discriminator -> Classifier-based loss for GAN training

- Critical path:
  1. Measure defensibility of original letter images using I-FGSM
  2. Train regression model to estimate defensibility from images
  3. Train GAN to generate realistic letter images
  4. Further train GAN using classifier loss to increase defensibility
  5. Evaluate generated images for improved defensibility

- Design tradeoffs:
  - Using a simple CNN vs. a more complex architecture for classification and regression
  - Choosing I-FGSM as the attack method vs. other attack algorithms
  - Balancing defensibility with readability in generated images
  - Training the regression model jointly with the GAN vs. separately

- Failure signatures:
  - Regression model consistently overestimates defensibility for fragile letters
  - Generated images have low actual defensibility despite high estimated defensibility
  - Defensibility improvements plateau after a certain number of GAN training iterations
  - Generated images become unreadable or too stylized

- First 3 experiments:
  1. Measure defensibility of a small set of letter images using I-FGSM to verify the basic methodology
  2. Train a simple regression model to estimate defensibility and evaluate its performance on a held-out test set
  3. Implement the two-step GAN training process and generate a small set of letter images to visually inspect for defensibility improvements

## Open Questions the Paper Calls Out
The paper identifies several open questions, including the challenge of defining reasonable attack constraints without introducing bias toward specific font styles, the transferability of letter image defensibility measured against CNNs to other classifier architectures like transformers or capsule networks, and the relationship between human-perceived letter readability under natural distortions and computer-measured defensibility against adversarial attacks. These questions remain unresolved and require further investigation to advance the field of defensive letter design.

## Limitations
- The study only uses a single CNN architecture, limiting generalizability to other classifier types
- The relationship between human-perceived readability and computer-measured defensibility remains unexplored
- The defensive gains shown may not transfer to other attack types beyond I-FGSM

## Confidence
- High confidence: Basic methodology for measuring defensibility via I-FGSM attacks is sound and reproducible
- Medium confidence: Regression model can estimate defensibility from letter shapes alone, though correlation strength may vary
- Medium confidence: GAN-based generation of more defensive letters works as demonstrated, but may face practical constraints

## Next Checks
1. Test the defensive properties of generated letters against multiple attack methods beyond I-FGSM to verify robustness across attack types
2. Evaluate human readability of generated defensive letters to ensure practical usability isn't compromised
3. Test the regression model's generalization to letter styles and fonts not present in the original Google Fonts dataset