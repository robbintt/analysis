---
ver: rpa2
title: Bidirectional Looking with A Novel Double Exponential Moving Average to Adaptive
  and Non-adaptive Momentum Optimizers
arxiv_id: '2307.00631'
source_url: https://arxiv.org/abs/2307.00631
tags: []
core_contribution: This paper proposes a novel bidirectional-looking optimizer framework
  that leverages both historical and future information for model training. The method
  combines a double exponential moving average (DEMA) variant for backward-looking,
  motivated by stock market indicators, and a dynamic asymptotic lookahead strategy
  for forward-looking.
---

# Bidirectional Looking with A Novel Double Exponential Moving Average to Adaptive and Non-adaptive Momentum Optimizers

## Quick Facts
- arXiv ID: 2307.00631
- Source URL: https://arxiv.org/abs/2307.00631
- Reference count: 40
- Primary result: ADMETA optimizer outperforms Adam, RAdam, and Ranger on diverse tasks through bidirectional optimization

## Executive Summary
This paper introduces ADMETA, a bidirectional-looking optimizer that combines backward-looking DEMA and forward-looking dynamic lookahead strategies. The method aims to improve optimization by leveraging both historical and future information during training. Experimental results across image classification, NLP, and audio tasks demonstrate superior convergence and generalization compared to existing optimizers. The bidirectional approach addresses limitations of unidirectional methods by smoothing gradients while maintaining early-stage speed and late-stage convergence.

## Method Summary
ADMETA implements a bidirectional optimization framework with two variants: ADMETA S (based on SGDM) and ADMETA R (based on RAdam). The backward-looking component uses a DEMA variant to smooth gradients while reducing lag compared to standard EMA. The forward-looking component implements dynamic lookahead with an asymptotic interpolation weight η_t that transitions from fast to slow weights during training. The optimizer can wrap any base optimizer and introduces additional hyperparameters λ (DEMA smoothing) and k (lookahead synchronization period).

## Key Results
- ADMETA R and ADMETA S outperform Adam, RAdam, and Ranger on CIFAR-10/100, GLUE, SQuAD, NER, and audio classification benchmarks
- DEMA variant provides faster convergence and better generalization than standard EMA on optimization tasks
- Dynamic lookahead with adaptive η_t maintains early-stage training speed while improving late-stage convergence
- Bidirectional looking demonstrates consistent improvements across diverse model architectures and tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DEMA variant reduces lag and overshoot compared to EMA by blending current gradient with moving average in a non-linear way.
- Mechanism: DEMA applies a second EMA layer over the linear combination of current gradient and first EMA, effectively creating a faster response to trend changes while smoothing short-term noise.
- Core assumption: Mini-batch training introduces random noise; blending current gradient helps maintain trend without overreacting to noise.
- Evidence anchors:
  - [abstract]: "Inspired by stock market indicators, DEMA... can effectively maintain the trend while reducing the impact caused by short-term bias."
  - [section 2.2]: "DEMA (Mulloy, 1994) is a faster moving average strategy... we developed a DEMA variant for the model optimization."
  - [corpus]: Weak - no direct comparison studies found; inference based on stock market usage.
- Break condition: If gradient noise is low or batch size is very large, DEMA advantage diminishes; may even add unnecessary computation.

### Mechanism 2
- Claim: Dynamic asymptotic lookahead improves early-stage training speed and late-stage convergence by adjusting the interpolation weight between fast and slow weights.
- Mechanism: η_t starts at 1 and asymptotically approaches a target (0.5 or 0.8) using a predefined function, giving more weight to fast weights early and slow weights later.
- Core assumption: Fixed η in original Lookahead causes early-stage slowness and late-stage oscillations; adaptive η balances these phases.
- Evidence anchors:
  - [abstract]: "dynamic lookahead strategy which asymptotically approaches a set value, maintaining its speed at early stage and high convergence performance at final stage."
  - [section 2.3]: "We argue that using fixed stepsizes in each synchronization is not an optimal strategy... we turn the constant η into a ηt that changes over step monotonously and asymptotically."
  - [corpus]: Weak - no ablation with constant η found; inference based on theoretical argument.
- Break condition: If synchronization period k is too short, η_t changes too fast and may destabilize training; if k is too long, benefit of early fast phase is lost.

### Mechanism 3
- Claim: Bidirectional looking combines backward (historical) and forward (future) information to improve optimization robustness.
- Mechanism: Backward part uses DEMA to smooth gradients; forward part uses dynamic lookahead to average fast and slow weights adaptively.
- Core assumption: Single-direction information (only past or only future) is insufficient for complex loss surfaces; combining both directions yields better local optima.
- Evidence anchors:
  - [abstract]: "we innovatively combine the backward-looking and forward-looking aspects of the optimizer algorithm and propose a novel ADMETA optimizer framework."
  - [section 2.1]: "we introduce a bidirectional view, backward-looking and forward-looking."
  - [section 3.4]: "bidirectional looking is beneficial for optimization."
  - [corpus]: Weak - no direct comparison with unidirectional baselines found; inference based on ablation studies.
- Break condition: If one direction dominates the other in a given task, combining both may add unnecessary complexity without benefit.

## Foundational Learning

- Concept: Exponential Moving Average (EMA) and its bias correction.
  - Why needed here: Both SGDM and Adam use EMA for momentum; understanding EMA is essential to grasp why DEMA is an improvement.
  - Quick check question: What is the effective window size of EMA with β=0.9? (Answer: ~10 steps)

- Concept: Adaptive learning rate and second-moment estimation.
  - Why needed here: RAdam and Adam rely on adaptive learning rates based on squared gradients; knowing this helps understand how DEMA modifies the first moment.
  - Quick check question: In Adam, what does v_t represent and how is it used? (Answer: second moment of gradients, used to scale learning rate per parameter)

- Concept: Lookahead optimizer mechanism.
  - Why needed here: Dynamic lookahead is built on Lookahead; understanding the original mechanism is necessary to see the improvement.
  - Quick check question: How often does Lookahead synchronize fast and slow weights? (Answer: every k steps, default k=10)

## Architecture Onboarding

- Component map:
  Base optimizer -> DEMA layer -> Dynamic lookahead layer -> Parameter update

- Critical path:
  1. Compute gradient g_t
  2. Apply DEMA to get momentum m_t
  3. Update θ_t using base optimizer with m_t
  4. Every k steps, update slow weights ϕ_t using η_t
  5. Set θ_t = ϕ_t after synchronization

- Design tradeoffs:
  - DEMA vs EMA: DEMA reduces lag but adds computation and storage
  - Dynamic η vs fixed η: Better performance but requires function design and tuning
  - Additional hyperparameters (λ, β, η_t function) increase tuning complexity

- Failure signatures:
  - Training loss plateaus early: Likely λ too large, causing DEMA to oversmooth
  - Validation accuracy drops after initial rise: η_t function may be too aggressive; slow weights not contributing enough
  - Training becomes unstable: k too small or η_t too large early on

- First 3 experiments:
  1. Replace EMA with DEMA in SGDM (ADMETA S without lookahead) and compare convergence on CIFAR-10
  2. Add fixed η=0.5 lookahead to SGDM and compare with dynamic η
  3. Combine DEMA + dynamic lookahead in ADMETA S and compare against base SGDM and RAdam on GLUE tasks

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- DEMA and dynamic lookahead mechanisms lack direct empirical comparisons with unidirectional alternatives
- Implementation details for DEMA variant and dynamic lookahead parameterization are underspecified
- Computational overhead compared to other optimizers on large-scale models is not analyzed
- Limited exploration of alternative functional forms for η_t function

## Confidence
- High confidence: Bidirectional framework architecture is correctly described and implementable
- Medium confidence: DEMA provides smoother gradients than EMA based on mathematical derivation but limited empirical validation
- Low confidence: Dynamic lookahead consistently improves both early-stage speed and late-stage convergence across all tasks

## Next Checks
1. Direct unidirectional comparison: Implement and compare ADMETA S against three variants - standard SGDM, SGDM with DEMA only, and SGDM with lookahead only - on CIFAR-10 to isolate the contribution of each mechanism.

2. Hyperparameter sensitivity analysis: Systematically vary λ (0.5, 0.7, 0.9) and k (5, 10, 20) across all benchmark tasks to determine robustness and identify failure modes where the bidirectional approach degrades performance.

3. Gradient noise sensitivity test: Train the same model architecture with varying batch sizes (32, 128, 512) to quantify whether DEMA's advantage scales with gradient noise level as claimed, or if it provides diminishing returns at larger batch sizes.