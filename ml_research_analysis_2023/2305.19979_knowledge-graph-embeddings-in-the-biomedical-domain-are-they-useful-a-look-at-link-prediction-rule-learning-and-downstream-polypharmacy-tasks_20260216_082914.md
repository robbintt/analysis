---
ver: rpa2
title: 'Knowledge Graph Embeddings in the Biomedical Domain: Are They Useful? A Look
  at Link Prediction, Rule Learning, and Downstream Polypharmacy Tasks'
arxiv_id: '2305.19979'
source_url: https://arxiv.org/abs/2305.19979
tags:
- knowledge
- biokg
- complex
- embedding
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the performance of knowledge graph embedding
  models on BioKG, a comprehensive biomedical knowledge graph. The authors find that
  using recent training best practices, they can achieve a three-fold improvement
  in link prediction performance compared to previous work on the same graph.
---

# Knowledge Graph Embeddings in the Biomedical Domain: Are They Useful? A Look at Link Prediction, Rule Learning, and Downstream Polypharmacy Tasks

## Quick Facts
- arXiv ID: 2305.19979
- Source URL: https://arxiv.org/abs/2305.19979
- Reference count: 40
- Knowledge graph embedding models achieve 3x improvement in link prediction on BioKG with optimal training configurations

## Executive Summary
This paper evaluates knowledge graph embedding (KGE) models on BioKG, a comprehensive biomedical knowledge graph containing 2,067,998 entries across 17 relations. The authors demonstrate that using recent best practices - specifically 1vsAll negative sampling with cross-entropy loss - achieves a three-fold improvement in link prediction performance compared to previous work on the same graph. The study also shows that these embeddings can be successfully transferred to downstream polypharmacy tasks, including drug-drug interactions and drug-target interactions, with performance improvements when using pretrained embeddings.

## Method Summary
The authors evaluate six KGE models (TransE, TransH, RotatE, DistMult, ComplEx, ConvE) on BioKG using 30 quasi-random hyperparameter optimization trials. They compare different negative sampling strategies (1vsAll vs random sampling) and loss functions (cross-entropy vs margin ranking loss). The best-performing model (ComplEx) is then used to initialize entity embeddings for downstream polypharmacy tasks including DDI-Efficacy, DDI-Minerals, DPI-FDA, and DEP-FDA-EXP. They also evaluate AnyBURL, a rule-based model, for relation classification tasks on BioKG.

## Key Results
- KGE models achieve 3x improvement in link prediction performance (MRR from 0.17 to 0.46) using 1vsAll negative sampling with cross-entropy loss
- Factorisation models (ComplEx, DistMult) and neural network models (ConvE) outperform translational models on BioKG
- Pretrained link prediction embeddings improve downstream polypharmacy task performance, with ComplEx-P requiring fewer epochs to reach similar or better results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using 1vsAll negative sampling and CE loss significantly improves link prediction performance compared to random negative sampling with margin ranking loss.
- Mechanism: 1vsAll negative sampling generates all possible corrupted triples for each positive triple, ensuring that the model learns to distinguish true from false triples more effectively. CE loss directly optimizes the probability of predicting the correct triple, which is better suited for ranking tasks than margin ranking loss.
- Core assumption: The KG contains enough true triples to make 1vsAll sampling computationally feasible and that CE loss is better suited for ranking tasks than margin ranking loss.
- Evidence anchors:
  - [abstract] "By taking into account recent studies outlining the best practices for KGE algorithms [17], previously determined limitations can be overcome."
  - [section] "Based on the evaluations on KGs with statistics similar to those of BioKG in another work [17], 1vsAll (where feasible, negative sampling otherwise, see Section 3.2.1) and CE loss seemed like better choices. The presented results confirm that this is the case, which underlines the importance of optimal training setup."
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.257, average citations=0.0."

### Mechanism 2
- Claim: Factorisation models like ComplEx and DistMult outperform other classes of models on BioKG.
- Mechanism: Factorisation models use similarity-based scoring functions, which are better suited for biomedical KGs where entities and relations are often similar in nature. ComplEx and DistMult can capture complex relationships in the KG by embedding entities and relations in complex space.
- Core assumption: Similarity-based scoring functions are better suited for biomedical KGs than translational models.
- Evidence anchors:
  - [abstract] "Generally, the results suggest that factorisation models such as ComplEx and DistMult outperform other classes of models. Translational models perform worst. This indicates that similarity-based scoring functions might be a good fit for biomedical KGs such as BioKG."
  - [section] "Factorisation models such as ComplEx and DistMult, and neural network models such as ConvE generally perform better than the other classes of models."
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.257, average citations=0.0."

### Mechanism 3
- Claim: Pretrained link prediction embeddings can be transferred to downstream polypharmacy tasks with good results.
- Mechanism: The best-performing link prediction model (ComplEx) on BioKG can be used to initialize the entity embeddings for downstream polypharmacy tasks. This allows the model to leverage the knowledge learned from the large BioKG and adapt it to the specific polypharmacy tasks.
- Core assumption: The knowledge learned from BioKG is transferable to downstream polypharmacy tasks.
- Evidence anchors:
  - [abstract] "We demonstrate that knowledge graph embedding models are applicable in practice by evaluating the best-performing model on four tasks that represent real-life polypharmacy situations. Results suggest that knowledge learnt from large biomedical knowledge graphs can be transferred to such downstream use cases."
  - [section] "When comparing ComplEx to ComplEx-P, two observations can be made. Firstly, ComplEx-P's best-found configuration requires significantly fewer epochs to reach similar or better performance for all four benchmarks. Secondly, for DPI-FDA and DEP-FDA-EXP, the best configuration for ComplEx-P produces more accurate results in comparison with the best configuration for ComplEx."
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.257, average citations=0.0."

## Foundational Learning

- Concept: Knowledge Graph Embeddings (KGEs)
  - Why needed here: KGEs are used to represent entities and relations in a low-dimensional space, allowing for efficient link prediction and downstream tasks.
  - Quick check question: What are the main differences between translational, factorisation, and neural network KGE models?

- Concept: Link Prediction (LP)
  - Why needed here: LP is the task of identifying missing triples in a knowledge graph, which is essential for understanding the relationships between entities.
  - Quick check question: How is the performance of LP models evaluated using rank-based metrics?

- Concept: Transfer Learning
  - Why needed here: Transfer learning allows the knowledge learned from a large KG to be applied to downstream tasks, improving performance and reducing training time.
  - Quick check question: What are the benefits and challenges of using pretrained embeddings for downstream tasks?

## Architecture Onboarding

- Component map:
  BioKG -> KGE models (TransE, TransH, RotatE, DistMult, ComplEx, ConvE) -> Link prediction evaluation -> Best model (ComplEx) -> Downstream polypharmacy tasks (DDI-Efficacy, DDI-Minerals, DPI-FDA, DEP-FDA-EXP)

- Critical path:
  1. Train KGE models on BioKG using optimal hyperparameters (1vsAll negative sampling, CE loss)
  2. Evaluate the best-performing KGE model on BioKG using rank-based metrics
  3. Initialize the entity embeddings of downstream polypharmacy tasks with the best-performing KGE model's entity embeddings
  4. Train the downstream polypharmacy tasks using the initialized entity embeddings

- Design tradeoffs:
  - Using 1vsAll negative sampling vs. random negative sampling: 1vsAll sampling is more computationally expensive but provides better performance
  - Using CE loss vs. margin ranking loss: CE loss directly optimizes the probability of predicting the correct triple, which is better suited for ranking tasks
  - Using factorisation models vs. translational models: Factorisation models use similarity-based scoring functions, which are better suited for biomedical KGs

- Failure signatures:
  - Poor performance on BioKG: Indicates that the KGE models are not learning effectively from the KG
  - Poor performance on downstream polypharmacy tasks: Indicates that the knowledge learned from BioKG is not transferable to the downstream tasks
  - High computational cost: Indicates that the 1vsAll negative sampling is too expensive for the size of the KG

- First 3 experiments:
  1. Train KGE models on BioKG using different combinations of negative sampling and loss functions to find the optimal configuration
  2. Evaluate the best-performing KGE model on BioKG using different rank-based metrics to ensure robust performance
  3. Initialize the entity embeddings of downstream polypharmacy tasks with the best-performing KGE model's entity embeddings and evaluate the performance improvement compared to training from scratch

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of KGE models on BioKG compare to their performance on other biomedical knowledge graphs?
- Basis in paper: [inferred] The paper evaluates KGE models on BioKG, but does not compare their performance to other biomedical KGs.
- Why unresolved: The authors focus on BioKG specifically and do not provide a comparative analysis with other biomedical KGs.
- What evidence would resolve it: A study comparing KGE performance across multiple biomedical KGs, including BioKG, would provide insights into the relative strengths and weaknesses of KGE models in this domain.

### Open Question 2
- Question: What are the specific limitations of rule-based models like AnyBURL when applied to large biomedical knowledge graphs?
- Basis in paper: [explicit] The paper mentions that rule-based models struggle with exponentially increasing search space and computational overhead for large KGs.
- Why unresolved: The authors do not provide a detailed analysis of the specific limitations or propose solutions to overcome these challenges.
- What evidence would resolve it: A study investigating the scalability of rule-based models on large biomedical KGs and proposing techniques to improve their efficiency would address this question.

### Open Question 3
- Question: How can the interpretability of KGE models be improved for biomedical applications?
- Basis in paper: [inferred] The paper highlights the importance of interpretability in the biomedical domain and mentions that AnyBURL provides interpretable rules, but does not explore methods to improve KGE interpretability.
- Why unresolved: The authors do not discuss techniques to make KGE predictions more interpretable or explainable.
- What evidence would resolve it: A study proposing methods to extract interpretable rules or explanations from KGE predictions would contribute to improving their interpretability in biomedical applications.

## Limitations

- The computational cost of 1vsAll negative sampling scales poorly with KG size, limiting applicability to very large biomedical knowledge graphs
- Polypharmacy downstream tasks use relatively small datasets (50-76 test triples), raising concerns about statistical significance and generalizability
- Results are based on a single biomedical KG (BioKG), limiting generalizability to other biomedical knowledge graphs with different characteristics

## Confidence

- Link prediction improvements with optimal training setup: High confidence
- Factorisation models outperform other classes: Medium confidence
- Transfer learning to polypharmacy tasks: Low confidence

## Next Checks

1. Replicate the link prediction experiments using both 1vsAll and random negative sampling on BioKG to quantify the performance gap and computational tradeoffs
2. Test the transfer learning approach on additional biomedical KGs and downstream tasks with larger datasets to assess generalizability
3. Perform ablation studies removing the transfer learning initialization to measure the actual contribution of pretrained embeddings vs. task-specific training