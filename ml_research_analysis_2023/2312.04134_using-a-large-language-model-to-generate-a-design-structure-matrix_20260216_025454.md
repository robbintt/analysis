---
ver: rpa2
title: Using a Large Language Model to generate a Design Structure Matrix
arxiv_id: '2312.04134'
source_url: https://arxiv.org/abs/2312.04134
tags:
- design
- entries
- auto-dsm
- data
- chatgpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Auto-DSM, a workflow that uses a Large Language
  Model (LLM) to automate the generation of Design Structure Matrices (DSMs). The
  method improves productivity by querying organization-specific proprietary data
  to identify system elements and their relationships, reducing the time and cost
  associated with traditional manual DSM generation.
---

# Using a Large Language Model to generate a Design Structure Matrix

## Quick Facts
- arXiv ID: 2312.04134
- Source URL: https://arxiv.org/abs/2312.04134
- Reference count: 6
- 77.3% DSM entry reproduction rate compared to human experts

## Executive Summary
This paper presents Auto-DSM, a workflow that uses a Large Language Model (LLM) to automate the generation of Design Structure Matrices (DSMs). The method improves productivity by querying organization-specific proprietary data to identify system elements and their relationships, reducing the time and cost associated with traditional manual DSM generation. A no-code prototype was tested on a diesel engine DSM, successfully reproducing 77.3% of DSM entries generated by human experts. The results demonstrate that Auto-DSM can serve as an effective tool for supporting DSM generation, particularly when manual methods are not feasible.

## Method Summary
Auto-DSM uses a LangChain-based workflow that processes organization-specific proprietary documents to generate DSMs. The method involves splitting documents into text embeddings, storing them in a vector database, and using two carefully designed prompts to identify system elements and their relationships. The LLM queries are executed with temperature=0 to ensure consistent outputs. The workflow was tested on a diesel engine system using various input data combinations including technical handbooks and YouTube comments.

## Key Results
- Auto-DSM reproduced 77.3% of DSM entries compared to human experts
- Correctness varied from 82.6% (with high-quality handbooks) to 40.0% (with YouTube comments)
- Combining multiple datasets created a pooling effect that balanced out extreme values

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Auto-DSM achieves 77.3% DSM entry reproduction by leveraging organization-specific proprietary data through an off-the-shelf LLM.
- Mechanism: The workflow splits proprietary documents into embeddings, retrieves relevant splits using two carefully designed prompts, and queries an LLM to identify system elements and relationships, ensuring contextual relevance.
- Core assumption: The proprietary data contains sufficient detail to accurately identify both DSM headings and dependencies.
- Evidence anchors:
  - [abstract] "A no-code prototype was tested on a diesel engine DSM, successfully reproducing 77.3% of DSM entries generated by human experts."
  - [section 3] "The entire workflow is illustrated in Figure 2... identifies DSM headings and populates DSM entries by querying organisation-specific proprietary data with an LLM."
- Break condition: Proprietary data is too sparse or ambiguous, leading to incorrect or missing DSM entries.

### Mechanism 2
- Claim: Using a high-quality dataset consistently produces higher Correctness and Completeness than using lower-quality or unstructured data.
- Mechanism: High-quality handbooks provide structured, complete information about system components and their mechanical links, enabling the LLM to produce accurate DSM entries.
- Core assumption: Structured, expert-authored documentation is more reliable than unstructured user comments or incomplete sources.
- Evidence anchors:
  - [section 4.2] "Auto-DSM with handbook [2] produced a Correctness of 82.6% while Auto-DSM with YouTube comments [3] produced a Correctness of 40.0%."
  - [section 4.1] "This suggests that the results generated are sensitive to the quality of the input data used in Auto-DSM."
- Break condition: Dataset quality varies unpredictably within the same source, making generalization unreliable.

### Mechanism 3
- Claim: Combining multiple input datasets creates a pooling effect that avoids extreme Correctness or Completeness values.
- Mechanism: Merging datasets balances out weaknesses in individual sources, improving overall DSM accuracy.
- Core assumption: Complementary datasets can cover each other's gaps without introducing conflicting information.
- Evidence anchors:
  - [section 4.2] "Combining input data in this work resulted in a pooling effect... the exact number of identical DSM entries found when [1, 2] and [1, 2, 3] were used was within the highest and lowest number of identical DSM entries achieved by their constituent input data."
- Break condition: Combined datasets introduce contradictory or redundant information, reducing overall accuracy.

## Foundational Learning

- Concept: Design Structure Matrix (DSM) and dependency modeling
  - Why needed here: DSMs are the target artifact; understanding their structure and purpose is essential for designing the workflow.
  - Quick check question: What distinguishes a symmetrical from an asymmetrical DSM entry?

- Concept: Text embedding and vector retrieval
  - Why needed here: Embeddings enable efficient semantic search across large document corpora for relevant DSM information.
  - Quick check question: How does the `similarity` metric influence which text splits are retrieved for a query?

- Concept: Large Language Model prompting and response parsing
  - Why needed here: Prompts must elicit precise DSM headings and entries, and responses must be parsed into a consistent matrix format.
  - Quick check question: Why does the workflow enforce `temperature=0` in the LLM configuration?

## Architecture Onboarding

- Component map: Document → Split → Embed → Store → Retrieve → Query → Format → DSM
- Critical path: Text splitter (LangChain) → Text embedder (OpenAI LLM) → Vector store (LangChain) → Retriever (similarity-based) → LLM query handler (ChatOpenAI) → DSM formatter (CSV output)
- Design tradeoffs:
  - Speed vs. accuracy: Smaller splits are faster but may miss context; larger splits are slower but more accurate.
  - Dataset size vs. noise: Larger datasets may include irrelevant information but improve coverage.
  - Fixed prompts vs. flexibility: Predefined prompts ensure consistency but may miss domain-specific nuances.
- Failure signatures:
  - Low Correctness: Poor-quality or insufficient input data.
  - Low Completeness: Prompts fail to elicit "Yes"/"No" answers, yielding many "I don't know" responses.
  - Inconsistent DSM entries: Dataset contradictions or ambiguous embeddings.
- First 3 experiments:
  1. Test Auto-DSM on a simple system (e.g., bicycle) with a single high-quality document to verify basic functionality.
  2. Vary the text split size (e.g., 500, 1000, 1500 chars) to observe effects on Correctness and Completeness.
  3. Combine two datasets of differing quality to confirm the pooling effect and measure accuracy improvement.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Auto-DSM's performance vary across different types of engineering systems beyond diesel engines?
- Basis in paper: [explicit] The paper demonstrates Auto-DSM on a diesel engine example and suggests future research should explore other product systems, but doesn't report results on different systems
- Why unresolved: The study only tested one type of engineering system (diesel engine), so generalizability to other domains remains unknown
- What evidence would resolve it: Testing Auto-DSM on diverse engineering systems (aerospace, automotive, electronics, etc.) with varying complexity and comparing performance metrics (Correctness, Completeness) across domains

### Open Question 2
- Question: What is the optimal size and composition of input data for maximizing Auto-DSM's accuracy?
- Basis in paper: [explicit] The paper shows varying results with different input data combinations but doesn't identify optimal data characteristics or minimum requirements
- Why unresolved: The study tested only 5 settings with fixed data sizes and didn't systematically vary input data characteristics (volume, quality, diversity) to find optimal conditions
- What evidence would resolve it: Controlled experiments varying input data size, quality, and diversity while measuring impact on Correctness and Completeness metrics

### Open Question 3
- Question: How does Auto-DSM's accuracy compare to human experts when domain expertise is limited or unavailable?
- Basis in paper: [inferred] The paper compares Auto-DSM to expert-generated DSMs but doesn't examine scenarios where expert input is scarce or costly
- Why unresolved: The comparison assumes availability of expert DSMs as ground truth, but the primary motivation is to address situations where manual DSM generation is impractical
- What evidence would resolve it: Comparative studies between Auto-DSM outputs and DSMs generated by teams with varying levels of domain expertise, including novice teams and non-experts

## Limitations

- The 77.3% reproduction rate is based on a single diesel engine system and may not generalize to other domains
- Performance is highly sensitive to input data quality, with significant drops when using lower-quality sources
- The no-code prototype implementation details are not fully specified, though code is reportedly available online

## Confidence

**High Confidence**: The core mechanism of using LLM embeddings and retrieval for DSM generation is technically sound and the workflow architecture is clearly described. The observation that input data quality directly affects output accuracy is well-supported by the comparative results.

**Medium Confidence**: The 77.3% reproduction rate is meaningful within the context of the specific diesel engine system and proprietary documents used, but may not generalize to other engineering domains without further validation. The pooling effect observed with combined datasets needs more systematic testing.

**Low Confidence**: The generalizability of the approach to very large or complex systems is uncertain, as the evaluation was limited to a single diesel engine case study. The paper does not address potential LLM hallucinations or how the system handles ambiguous or contradictory information in the input data.

## Next Checks

1. **Dataset Quality Impact Test**: Systematically vary the quality and completeness of input documents (e.g., using partial handbooks, technical manuals, and user comments) to quantify the relationship between input data quality and DSM accuracy across multiple test systems.

2. **Cross-Domain Generalization Test**: Apply Auto-DSM to a different engineering system (e.g., aerospace or manufacturing) with well-documented dependencies to assess whether the 77.3% accuracy rate holds across domains or requires domain-specific prompt engineering.

3. **Error Analysis on Reference DSM**: Conduct a detailed comparison between the LLM-generated DSM and the expert reference DSM to identify systematic patterns in the 22.7% of missing entries (e.g., are they consistently certain types of relationships or components).