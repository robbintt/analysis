---
ver: rpa2
title: Fast Optimal Transport through Sliced Wasserstein Generalized Geodesics
arxiv_id: '2307.01770'
source_url: https://arxiv.org/abs/2307.01770
tags:
- min-swgg
- wasserstein
- transport
- optimal
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces min-SWGG, a fast approximation of the Wasserstein
  distance that provides an associated transport plan. min-SWGG leverages 1D projections
  and optimal permutations to compute a transport cost that serves as an upper bound
  of the true Wasserstein distance.
---

# Fast Optimal Transport through Sliced Wasserstein Generalized Geodesics

## Quick Facts
- arXiv ID: 2307.01770
- Source URL: https://arxiv.org/abs/2307.01770
- Reference count: 40
- Key outcome: Introduces min-SWGG, a fast approximation of Wasserstein distance using 1D projections and permutations, with complexity on par with sliced Wasserstein distance.

## Executive Summary
This paper presents min-SWGG, a computationally efficient approximation of the Wasserstein distance that provides both a distance upper bound and an associated transport plan. The method leverages optimal 1D projections and permutations induced by sorting projected samples to construct a transport plan that is always feasible and computable in O(dn + n log n). Unlike exact optimal transport which scales cubically, min-SWGG achieves similar complexity to sliced Wasserstein distance while guaranteeing to be an upper bound of the true Wasserstein distance. The approach is shown to be a proper metric that metrizes weak convergence and is amenable to gradient-based optimization through a generalized geodesic reformulation.

## Method Summary
min-SWGG approximates the Wasserstein distance by restricting transport plans to permutations induced by sorting along optimal 1D projections. For a given projection direction θ, samples from both distributions are projected and sorted, creating permutations σθ and τθ. The transport cost is computed by matching samples according to these permutations, yielding a cost that upper bounds the true Wasserstein distance. To find optimal projections, the method offers two algorithms: random search over directions (complexity O(dLn + Ln log n)) and gradient descent with smoothing (complexity O(sdn + sn log sn) per iteration). The smoothing procedure enables gradient-based optimization by blurring the sorted projections, making the objective differentiable.

## Key Results
- min-SWGG is proven to be a proper metric and an upper bound of the Wasserstein distance
- The method achieves O(dn + n log n) complexity, comparable to sliced Wasserstein distance
- min-SWGG successfully scales to high dimensions where exact OT becomes intractable
- Provides a closed-form expression for Wasserstein distance when one distribution is supported on a line
- Demonstrates effectiveness in applications including gradient flows, colorization, and point cloud registration

## Why This Works (Mechanism)

### Mechanism 1
- Claim: min-SWGG is an upper bound of the true Wasserstein distance while remaining computationally cheap.
- Mechanism: The method restricts the transport plan to permutations induced by sorting along optimal 1D projections, which is always feasible and computable in O(dn + n log n).
- Core assumption: The set of such permutations is a subset of all possible permutations, hence the cost is always at least as large as the optimal OT cost.
- Evidence anchors: [abstract]: "min-SWGG is an upper bound of WD"; [section]: "From the sub-optimality of the permutations σθ, τθ... we necessarily have W2 ≤ min-SWGG2"
- Break condition: If the dimension is large enough relative to n (d ≥ 2n), all permutations become feasible and min-SWGG equals W2, so the upper-bound property no longer distinguishes it.

### Mechanism 2
- Claim: The generalized geodesic reformulation makes min-SWGG amenable to gradient-based optimization.
- Mechanism: By expressing SWGG as a ν-based Wasserstein distance where ν is supported on a line, the discontinuities of permutations are smoothed via Gaussian blurring, enabling gradient descent on the projection direction.
- Core assumption: Blurring the sorted projections yields a differentiable surrogate that approximates the original SWGG closely enough for optimization.
- Evidence anchors: [section]: "We build upon the blurred Wasserstein distance... to define ]µ1→2g,θ"; [abstract]: "is amenable to gradient descent optimization"
- Break condition: If blurring parameter ϵ is too large, the landscape becomes too flat and optimization loses signal; if too small, discontinuities remain.

### Mechanism 3
- Claim: min-SWGG metrizes weak convergence of probability measures.
- Mechanism: The distance is a proper metric (triangle inequality, symmetry, identity) and upper bounds W2, which is known to metrize weak convergence. The limit behavior ensures convergence of measures implies convergence of min-SWGG to zero.
- Core assumption: Weak convergence of empirical measures to a continuous one preserves the ordering of projections sufficiently well.
- Evidence anchors: [section]: "min-SWGG metricizes the weak convergence in P2n(Rd)"; [abstract]: "we show that min-SWGG is an upper bound of WD and that it has a complexity similar to as Sliced-Wasserstein"
- Break condition: For discrete measures with very small n, the empirical projections may not reflect the underlying continuous ordering, breaking the equivalence.

## Foundational Learning

- Concept: Wasserstein distance and optimal transport plans
  - Why needed here: min-SWGG is defined as an upper bound and approximation to W2, so understanding the exact OT formulation is essential to see why permutations yield an upper bound.
  - Quick check question: What is the difference between a transport map and a transport plan, and when is each unique?

- Concept: Sliced-Wasserstein distance (SWD)
  - Why needed here: min-SWGG builds on the idea of projecting distributions onto lines and computing 1D OT, so familiarity with SWD helps grasp why min-SWGG can inherit its complexity.
  - Quick check question: How is the 1D Wasserstein distance computed between two empirical samples, and what is its computational complexity?

- Concept: Wasserstein generalized geodesics
  - Why needed here: The reformulation of min-SWGG via generalized geodesics is the key to making it optimizable; understanding the pivot measure construction is necessary.
  - Quick check question: In a generalized geodesic, how is the pivot measure chosen and what role does it play in the transport cost?

## Architecture Onboarding

- Component map: Data ingestion (µ1, µ2) -> Projection Pθ -> Sorting -> Permutations (σθ, τθ) -> Transport map construction -> Cost evaluation -> Optimization (optional) -> Output (min-SWGG value and transport plan)

- Critical path:
  1. Project distributions onto direction θ
  2. Sort projected samples to obtain permutations
  3. Build transport map via permutation inversion
  4. Compute cost as upper bound to W2
  5. If optimizing, smooth permutations and apply gradient descent

- Design tradeoffs:
  - Random search is O(Ldn + Ln log n) and easy but may need many projections in high dimension
  - Gradient descent with smoothing is faster in high dimension but requires tuning of s and ε hyperparameters
  - Exact W2 is O(n3 log n) and intractable for large n, so min-SWGG trades exactness for scalability

- Failure signatures:
  - min-SWGG value much larger than W2 consistently → projections not capturing geometry well
  - Gradient descent diverging or stuck → ε too small (discontinuities) or too large (flat landscape)
  - Transport map visually poor in applications → suboptimal θ not representative of true geometry

- First 3 experiments:
  1. Verify that min-SWGG ≥ W2 for small synthetic Gaussians in low dimension
  2. Compare runtime of random search vs gradient descent for increasing dimension
  3. Apply min-SWGG to color transfer and check visual quality vs exact OT on subsampled data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical upper bound for min-SWGG in terms of the Wasserstein distance?
- Basis in paper: [inferred] The paper mentions that min-SWGG is an upper bound of the Wasserstein distance and conjectures that there may exist an upper bound of the form min-SWGG^2 ≤ ψ(d, n, d')W^2, where d' is the maximum of the dimensions of the distributions.
- Why unresolved: The authors conjecture about the existence of an upper bound but do not provide a theoretical proof or the exact form of the function ψ.
- What evidence would resolve it: A rigorous mathematical proof establishing the upper bound of min-SWGG in terms of the Wasserstein distance, including the exact form of the function ψ and its dependence on the dimensions d, n, and d'.

### Open Question 2
- Question: How does min-SWGG behave when n grows for continuous distributions?
- Basis in paper: [inferred] The paper discusses the behavior of min-SWGG with the number of points n and conjectures that there may be an upper bound, but it does not explicitly address the behavior for continuous distributions as n grows.
- Why unresolved: The paper focuses on empirical distributions and does not provide a theoretical analysis of the behavior of min-SWGG for continuous distributions as the sample size n increases.
- What evidence would resolve it: A theoretical analysis of the convergence of min-SWGG to the Wasserstein distance for continuous distributions as the sample size n increases, potentially including a proof of consistency or rates of convergence.

### Open Question 3
- Question: What is the relationship between the set of permutations covered by min-SWGG and the Birkhoff polytope?
- Basis in paper: [explicit] The paper mentions that the set of permutations covered by min-SWGG is a subset of the Birkhoff polytope and discusses the fact that min-SWGG and WD coincide when d > 2n, implying that all permutations are covered.
- Why unresolved: The paper does not provide a detailed characterization of how the set of permutations covered by min-SWGG relates to the entire Birkhoff polytope, especially for dimensions d < 2n.
- What evidence would resolve it: A mathematical characterization of the set of permutations covered by min-SWGG, including a proof of how this set relates to the Birkhoff polytope and an analysis of the fraction of permutations covered as a function of the dimension d and the number of points n.

### Open Question 4
- Question: How does min-SWGG perform in high-dimensional spaces where the distributions are supported on low-dimensional manifolds?
- Basis in paper: [inferred] The paper mentions that min-SWGG might be useful in high-dimensional spaces but does not provide experimental results or theoretical analysis for distributions supported on low-dimensional manifolds.
- Why unresolved: The paper focuses on general high-dimensional spaces but does not specifically address the case where distributions lie on low-dimensional manifolds, which is a common scenario in many applications.
- What evidence would resolve it: Experimental results comparing min-SWGG with other OT approximations on datasets where the distributions are known to lie on low-dimensional manifolds, as well as a theoretical analysis of the performance of min-SWGG in such scenarios.

## Limitations

- The method is an approximation that may overestimate the true Wasserstein distance, potentially leading to suboptimal decisions in applications where the exact distance matters
- Performance heavily depends on finding good projection directions, which becomes challenging in very high dimensions without sufficient samples
- The smoothing procedure required for gradient optimization introduces hyperparameters that need careful tuning and may affect the quality of the solution

## Confidence

- **High confidence**: min-SWGG is a proper metric and upper bounds the Wasserstein distance (proven in theory)
- **Medium confidence**: min-SWGG metrizes weak convergence (proven for discrete measures with n samples, but continuous case not fully explored)
- **Medium confidence**: Gradient descent optimization with smoothing is effective (demonstrated empirically, but hyperparameter sensitivity not fully characterized)

## Next Checks

1. **Theoretical boundary testing**: Verify the claim that min-SWGG = W2 when d ≥ 2n by constructing explicit examples and checking the equivalence.
2. **Hyperparameter sensitivity analysis**: Systematically vary the smoothing parameter ε in gradient descent optimization and measure the impact on convergence speed and final min-SWGG value.
3. **High-dimensional scaling study**: Test min-SWGG on synthetic data with d >> n (e.g., d = 100, n = 50) and compare the effectiveness of random search vs gradient descent in finding optimal projections.