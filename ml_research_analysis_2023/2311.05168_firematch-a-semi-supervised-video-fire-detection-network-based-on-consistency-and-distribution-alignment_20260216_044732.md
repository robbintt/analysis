---
ver: rpa2
title: 'FireMatch: A Semi-Supervised Video Fire Detection Network Based on Consistency
  and Distribution Alignment'
arxiv_id: '2311.05168'
source_url: https://arxiv.org/abs/2311.05168
tags:
- fire
- data
- video
- classification
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FireMatch is a semi-supervised video fire detection method that
  combines consistency regularization with pseudo-labeling and adversarial distribution
  alignment. It generates pseudo-labels for unlabeled video data using self-adaptive
  thresholds and applies strong augmentations to learn robust features.
---

# FireMatch: A Semi-Supervised Video Fire Detection Network Based on Consistency and Distribution Alignment

## Quick Facts
- **arXiv ID**: 2311.05168
- **Source URL**: https://arxiv.org/abs/2311.05168
- **Reference count**: 11
- **Primary result**: FireMatch achieves 76.92% and 91.81% accuracy on two real-world fire datasets, outperforming state-of-the-art semi-supervised classification methods.

## Executive Summary
FireMatch is a semi-supervised video fire detection method that addresses the challenge of limited labeled data in fire detection scenarios. The approach combines consistency regularization with pseudo-labeling and adversarial distribution alignment to leverage both labeled and unlabeled video data. By introducing self-adaptive thresholds for pseudo-label generation and video cross-set sample augmentation, FireMatch improves classification accuracy while reducing the impact of dataset imbalance. The method demonstrates significant performance gains over fully supervised baselines and existing semi-supervised techniques.

## Method Summary
FireMatch employs a 3D-ResNet backbone with multiple loss components to learn from both labeled and unlabeled video data. The core innovation lies in combining consistency regularization with self-adaptive pseudo-labeling, where the model predicts weakly augmented samples and retains pseudo-labels above a dynamically adjusted threshold. Strong augmentations are then applied to these samples during training to enforce consistency. Additionally, the method introduces video cross-set sample augmentation (VCSA) to expand training data and reduce the distribution gap between labeled and unlabeled samples. A fairness loss component encourages diverse predictions to address overconfidence in non-fire classes caused by dataset imbalance.

## Key Results
- Achieves 76.92% accuracy on the Firesense dataset
- Achieves 91.81% accuracy on the Custom-Compiled Fire Dataset
- Outperforms state-of-the-art semi-supervised classification methods
- Demonstrates effectiveness with limited labeled data (as few as 10% of training samples)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Consistency regularization with self-adaptive pseudo-label improves classification accuracy by leveraging unlabeled data while reducing noise from incorrect pseudo-labels.
- Mechanism: The method generates pseudo-labels for weakly augmented unlabeled samples and uses these to train the model on strongly augmented versions, enforcing consistency. The self-adaptive threshold adjusts over training iterations to include more samples early (speeding convergence) and filter out errors later.
- Core assumption: Early training benefits from higher recall of potentially correct pseudo-labels, while later training benefits from higher precision.
- Evidence anchors:
  - [abstract]: "we first combine consistency regularization with pseudo-label... the proposed model predicts weakly augmented samples and retains pseudo-label above a threshold, while training on strongly augmented samples"
  - [section]: "we introduce the self-adaptive threshold (SAT) in the part of consistency regularization combined with pseudo-labels... allows more potentially correct samples to be included in training and speeds up convergence. As the model becomes more confident... the thresholds are raised to filter out incorrect samples"
- Break condition: If the self-adaptive threshold fails to adjust correctly, early convergence gains could be lost or later precision could degrade due to retained noise.

### Mechanism 2
- Claim: Adversarial distribution alignment via video cross-set sample augmentation reduces the empirical distribution gap between labeled and unlabeled data, improving generalization.
- Mechanism: VCSA interpolates labeled and unlabeled video samples in feature space, creating new training samples that blend temporal dynamics from both sets. A discriminator then minimizes the feature distribution distance, encouraging aligned latent representations.
- Core assumption: Interpolated samples preserve meaningful temporal structure and are closer to the true data distribution than either original set alone.
- Evidence anchors:
  - [abstract]: "we generate video cross-set augmented samples by adversarial distribution alignment to expand the training data and alleviate the decline in classification performance caused by insufficient labeled data"
  - [section]: "we generate video cross-set augmentation samples... bridging the gap between the empirical distributions of labeled and unlabeled data"
- Break condition: If interpolation breaks temporal coherence (e.g., via inappropriate spatial augmentations), generated samples may be uninformative or misleading.

### Mechanism 3
- Claim: Fairness loss encourages diverse predictions and mitigates overconfidence bias toward non-fire classes caused by dataset imbalance.
- Mechanism: The loss measures the divergence between predicted class distributions and the histogram of retained pseudo-labels, penalizing models that consistently predict the same class regardless of input variation.
- Core assumption: Encouraging diversity in predictions forces the model to attend to subtle features distinguishing fire from non-fire, reducing systematic bias.
- Evidence anchors:
  - [abstract]: "we introduce a fairness loss to help the model produce diverse predictions for input samples, thereby addressing the issue of high confidence with the non-fire class in fire classification scenarios"
  - [section]: "we introduce a fair class objective to encourage the model to make different predictions... mitigating biases towards specific classes"
- Break condition: If the fairness term dominates training, the model may sacrifice discriminative power for diversity, harming overall accuracy.

## Foundational Learning

- Concept: Consistency regularization
  - Why needed here: Semi-supervised learning requires leveraging unlabeled data; consistency regularization enforces that perturbations of the same sample yield similar predictions, enabling learning from unlabeled videos.
  - Quick check question: What happens if consistency regularization is applied with overly strong augmentations on video data?

- Concept: Adversarial distribution alignment
  - Why needed here: Labeled and unlabeled video data often have mismatched distributions; adversarial alignment reduces this gap, improving generalization.
  - Quick check question: How does the VCSA method differ from standard MixUp when applied to video?

- Concept: Self-adaptive thresholding
  - Why needed here: Fixed thresholds for pseudo-labeling either admit too much noise or discard useful data; adaptive thresholds balance precision and recall across training.
  - Quick check question: What is the role of the EMA momentum decay in updating the global threshold?

## Architecture Onboarding

- Component map: 3D CNN backbone -> Classifier head -> supervised loss; Unlabeled data -> weak/strong augment -> 3D CNN -> Prediction head -> consistency loss; VCSA samples -> 3D CNN -> Classifier + Discriminator -> alignment loss
- Critical path: Labeled data -> 3D CNN -> Classifier -> supervised loss; Unlabeled data -> weak/strong augment -> 3D CNN -> Prediction head -> consistency loss; VCSA samples -> 3D CNN -> Classifier + Discriminator -> alignment loss
- Design tradeoffs:
  - Weak augmentation limited to flipping preserves temporal coherence but may under-regularize
  - Strong augmentation via RandAugment increases robustness but risks temporal disruption
  - VCSA expands data but requires careful interpolation to maintain video semantics
- Failure signatures:
  - High unlabeled loss with low overall loss -> inconsistency regularization failing
  - Labeled accuracy high but unlabeled accuracy low -> distribution misalignment
  - Convergence stalls after initial fast progress -> adaptive threshold miscalibration
- First 3 experiments:
  1. Validate that weak augmentation (flipping only) preserves temporal structure better than random crop/flip.
  2. Test VCSA interpolation with different Î²-distribution shapes to find optimal augmentation diversity.
  3. Measure fairness loss impact by comparing prediction entropy before and after its inclusion.

## Open Questions the Paper Calls Out

- How does the performance of FireMatch scale with the size and diversity of the training dataset for fire detection?
- Can the adversarial distribution alignment and video cross-set sample augmentation techniques proposed in FireMatch be effectively applied to other domains of video classification beyond fire detection?
- How does the performance of FireMatch compare to fully supervised models when a large amount of labeled data is available?

## Limitations

- The self-adaptive threshold mechanism lacks detailed mathematical formulation, creating uncertainty about its precise implementation and effectiveness across varying class distributions
- The fairness loss formulation is only conceptually described, making it difficult to assess its exact contribution to the overall performance gains
- Limited ablation studies prevent definitive attribution of improvements to individual components versus synergistic effects

## Confidence

- **High confidence**: The overall framework combining consistency regularization with semi-supervised learning principles is sound and well-established in the literature
- **Medium confidence**: The specific application to video fire detection and the use of 3D-CNNs for temporal feature extraction are reasonable but require domain-specific validation
- **Low confidence**: Claims about the fairness loss's effectiveness and the specific benefits of video cross-set sample augmentation lack sufficient empirical support

## Next Checks

1. Conduct comprehensive ablation studies isolating each component (consistency regularization, fairness loss, VCSA) to quantify individual contributions
2. Test the self-adaptive threshold mechanism on synthetic data with known class distributions to verify its dynamic adjustment behavior
3. Evaluate model performance under different degrees of dataset imbalance to assess the fairness loss's impact on mitigating class bias