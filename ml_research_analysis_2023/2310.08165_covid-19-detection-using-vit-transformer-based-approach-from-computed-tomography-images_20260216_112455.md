---
ver: rpa2
title: COVID-19 detection using ViT transformer-based approach from Computed Tomography
  Images
arxiv_id: '2310.08165'
source_url: https://arxiv.org/abs/2310.08165
tags:
- covid-19
- images
- diagnosis
- patient
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a Swin Transformer-based approach for COVID-19
  detection using CT images. The method resizes CT images to 384x384 pixels and applies
  the swinbasepatch4window12384 model to classify individual slices, then uses majority
  voting for patient-level diagnosis.
---

# COVID-19 detection using ViT transformer-based approach from Computed Tomography Images

## Quick Facts
- arXiv ID: 2310.08165
- Source URL: https://arxiv.org/abs/2310.08165
- Reference count: 17
- Primary result: Swin Transformer-based approach achieves macro F1 score of 0.95 on COV19-CT-DB dataset for COVID-19 detection from CT images

## Executive Summary
This study introduces a Swin Transformer-based approach for COVID-19 detection using CT images. The method resizes CT images to 384x384 pixels and applies the swin_base_patch4_window12_384 model to classify individual slices, then uses majority voting for patient-level diagnosis. Trained on the COV19-CT-DB dataset with 1,650 COVID and 6,100 Non-COVID cases, the model achieved a macro F1 score of 0.95 on the validation set, outperforming baseline and competing methods. The approach demonstrates robust performance in binary classification, with high precision and recall across both COVID and Non-COVID categories, highlighting its effectiveness for large-scale medical imaging diagnosis.

## Method Summary
The proposed method employs a Swin Transformer architecture (swin_base_patch4_window12_384) to classify individual CT slices as COVID-19 or Non-COVID, then aggregates slice-level predictions using majority voting to produce patient-level diagnoses. The model was trained on the COV19-CT-DB dataset using cross-entropy loss with Adam optimizer, learning rate of 0.001, 20 epochs, and batch size of 32. CT images were resized from 512x512 to 384x384 pixels to match the model's requirements. The majority voting approach tallies predictions across all slices for each patient, with the most frequent class determining the final diagnosis.

## Key Results
- Achieved macro F1 score of 0.95 on validation set for binary COVID-19 classification
- Outperformed baseline and competing methods on the COV19-CT-DB dataset
- Demonstrated high precision and recall across both COVID and Non-COVID categories

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Swin Transformer architecture captures long-range spatial dependencies effectively for COVID-19 diagnosis.
- Mechanism: Swin Transformer uses shifted window-based self-attention, allowing efficient modeling of global image features while preserving local details across non-overlapping patches.
- Core assumption: CT slices can be effectively represented as sequences of patches where spatial relationships encode pathological patterns.
- Evidence anchors:
  - [abstract] "Leveraging state-of-the-art Transformer models in computer vision"
  - [section] "The Swin Transformer, specifically the swin_base_patch4_window12_384 variant, represents a cutting-edge architecture for handling vision tasks"
  - [corpus] No direct corpus evidence; assumes Swin Transformer efficacy is transferable from general CV to medical imaging.
- Break condition: If CT image pathologies require more complex 3D modeling than patch-wise attention provides.

### Mechanism 2
- Claim: Patient-level majority voting aggregates slice-level predictions to improve diagnostic robustness.
- Mechanism: Each CT scan contains multiple slices; predictions for each slice are tallied, and the most frequent class determines the patient's diagnosis, reducing noise from ambiguous slices.
- Core assumption: COVID-19 pathology is spatially distributed across slices, so the majority vote reflects the true patient condition.
- Evidence anchors:
  - [section] "To determine the overall diagnosis for each patient, a majority voting approach...was employed"
  - [abstract] "To determine the overall diagnosis for each patient, a majority voting approach as well as other thresholding approaches were employed"
  - [corpus] No direct corpus evidence; assumption based on standard voting aggregation methods.
- Break condition: If slice-level predictions are highly inconsistent or noisy, majority voting may amplify errors.

### Mechanism 3
- Claim: Input image resizing to 384x384 preserves essential diagnostic features while matching Swin Transformer requirements.
- Mechanism: Resizing from original CT scan size to 384x384 allows compatibility with Swin Transformer patch embedding, enabling effective feature extraction without excessive loss of resolution.
- Core assumption: Downsampling to 384x384 retains sufficient detail for distinguishing COVID-19 from non-COVID patterns.
- Evidence anchors:
  - [section] "input images were resized from the standard CT scan size of 512x512 to match the model's expectations"
  - [abstract] "input images were resized from the standard CT scan size of 512x512 to match the model's expectations"
  - [corpus] No direct corpus evidence; relies on standard image preprocessing assumptions.
- Break condition: If critical diagnostic features are lost during resizing, model performance may degrade.

## Foundational Learning

- Concept: Vision Transformer architecture and patch embedding
  - Why needed here: Understanding how ViTs process images as sequences of patches is crucial to grasp why Swin Transformer is effective for CT image analysis.
  - Quick check question: How does patch embedding in ViTs differ from traditional convolutional approaches in capturing spatial information?

- Concept: Attention mechanisms and shifted window-based self-attention
  - Why needed here: Swin Transformer's efficiency and ability to capture long-range dependencies rely on its unique attention mechanism.
  - Quick check question: What advantage does shifted window-based self-attention provide over standard self-attention in ViTs?

- Concept: Medical image classification and patient-level aggregation
  - Why needed here: Translating slice-level predictions into patient-level diagnoses requires understanding aggregation strategies like majority voting.
  - Quick check question: Why might majority voting be preferred over simple averaging in patient-level COVID-19 diagnosis from CT slices?

## Architecture Onboarding

- Component map: Input preprocessing (CT slice resizing to 384x384) -> Patch embedding (4x4 patches) -> Positional embeddings (added to patches) -> Transformer blocks (multiple with attention and feed-forward layers) -> Classification head (binary output) -> Patient aggregation (majority voting)

- Critical path: 1. Load and resize CT slices to 384x384 2. Pass through Swin Transformer for slice-level prediction 3. Aggregate slice predictions via majority voting 4. Output patient-level COVID-19 diagnosis

- Design tradeoffs:
  - Resizing from 512x512 to 384x384 may lose fine-grained details but improves computational efficiency and model compatibility.
  - Majority voting reduces noise but may mask ambiguous cases where slices are split evenly.
  - Swin Transformer's shifted window attention balances global context and local detail but may still miss very fine 3D structures.

- Failure signatures:
  - Low recall despite high precision may indicate the model misses subtle COVID-19 patterns.
  - Inconsistent slice-level predictions across patients suggest poor generalization or noisy preprocessing.
  - Macro F1 close to weighted F1 indicates class imbalance or biased model predictions.

- First 3 experiments:
  1. Vary image resizing dimensions (e.g., 512x512, 384x384, 256x256) and measure impact on macro F1 score.
  2. Compare majority voting with weighted voting or threshold-based aggregation to assess robustness.
  3. Test alternative attention mechanisms (e.g., full self-attention vs shifted window) to quantify efficiency vs accuracy trade-offs.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided text.

## Limitations
- Limited transparency in preprocessing pipeline beyond basic resizing
- Missing implementation details for majority voting algorithm
- No external validation on independent datasets or clinical deployment scenarios

## Confidence
- **High confidence**: The Swin Transformer architecture's effectiveness for image classification is well-established in computer vision literature.
- **Medium confidence**: The binary classification performance metrics (macro F1 = 0.95) are internally validated but not independently verified.
- **Low confidence**: Claims about clinical applicability and robustness in diverse real-world settings due to limited external validation.

## Next Checks
1. Conduct external validation on independent CT datasets to verify model generalization across different scanning protocols and patient populations.
2. Perform ablation studies comparing Swin Transformer with alternative architectures (e.g., EfficientNet, ResNet) to isolate the contribution of the transformer approach.
3. Evaluate model performance on challenging cases with ambiguous or subtle COVID-19 patterns to assess clinical utility in edge cases.