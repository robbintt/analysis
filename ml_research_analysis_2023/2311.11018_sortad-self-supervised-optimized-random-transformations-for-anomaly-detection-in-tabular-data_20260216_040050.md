---
ver: rpa2
title: 'SORTAD: Self-Supervised Optimized Random Transformations for Anomaly Detection
  in Tabular Data'
arxiv_id: '2311.11018'
source_url: https://arxiv.org/abs/2311.11018
tags:
- samples
- data
- transformations
- anomaly
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SORTAD addresses challenges in self-supervised anomaly detection
  for tabular data, where data lacks inherent correlations and anomalies can be easily
  detected. The method optimally selects transformations from randomly generated candidates
  to improve classification and reduce computational overhead.
---

# SORTAD: Self-Supervised Optimized Random Transformations for Anomaly Detection in Tabular Data

## Quick Facts
- **arXiv ID**: 2311.11018
- **Source URL**: https://arxiv.org/abs/2311.11018
- **Reference count**: 40
- **Primary result**: Outperforms state-of-the-art methods on 10 tabular datasets with VS Random score of 17.74±7.64 at 3% threshold

## Executive Summary
SORTAD addresses challenges in self-supervised anomaly detection for tabular data where data lacks inherent correlations and anomalies can be easily detected. The method optimally selects transformations from randomly generated candidates to improve classification and reduce computational overhead. It uses a novel scoring function based on distance metrics to guide transformation selection, and employs a modified Dirichlet probability scoring method to handle easy detection scenarios. SORTAD demonstrates superior performance and stability across various tabular anomaly detection tasks.

## Method Summary
SORTAD generates reversible polynomial transformations using Chebyshev and Legendre bases, then optimally selects the most effective transformations through a scoring function that balances inter-transformation separation and intra-transformation cohesion. The selected transformations are used to train a classifier that predicts which transformation was applied to each sample. Finally, a modified Dirichlet probability scoring method generates anomaly scores, addressing the "Easy Detection" problem common in tabular data where anomalies can be too easily separated from normal samples.

## Key Results
- VS Random score of 17.74±7.64 at 3% threshold, outperforming next best method (RecTrans) at 14.43±10.96
- Superior performance across 10 benchmark datasets including SMTP, Thyroid, Credit Card, and others
- Demonstrates stability with consistent performance across varying anomaly ratios (0.17%-14.60%)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Optimal transformation selection improves classification by increasing inter-transformation separation while maintaining low intra-transformation variance.
- **Core assumption**: Normal samples behave similarly under transformations while anomalous samples display irregular behavior, allowing separation through variance metrics.
- **Evidence**: Scoring function balances outer variance (distance between transformation outputs) and inner variance (cohesion within transformation outputs).
- **Break condition**: If normal samples exhibit heterogeneous behavior under transformations, or if anomalous samples happen to align with normal sample patterns.

### Mechanism 2
- **Claim**: Modified Dirichlet scoring addresses Easy Detection by incorporating distance from mean probability distribution.
- **Core assumption**: In Easy Detection scenarios, anomalous samples receive abnormally high transformation prediction scores, which should be penalized rather than rewarded.
- **Evidence**: Modified scoring function uses distance from mean score when concentration parameter indicates Easy Detection.
- **Break condition**: If mean score on training data doesn't represent expected behavior, or if Easy Detection doesn't manifest as described.

### Mechanism 3
- **Claim**: Reversible polynomial transformations with numerical stability improvements enable effective feature space manipulation.
- **Core assumption**: Polynomial transformations can effectively separate normal and anomalous samples when properly constrained to avoid numerical issues.
- **Evidence**: Divide factor and non-constant basis elements prevent underflow/overflow while maintaining reversibility.
- **Break condition**: If divide factor is insufficient for extreme values, or if non-constant constraint limits transformation diversity.

## Foundational Learning

- **Concept**: Understanding of tabular data characteristics (uncorrelated features, sparse distributions)
  - *Why needed*: SORTAD specifically addresses challenges unique to tabular data
  - *Quick check*: Why can't we use rotation-based transformations like GEOM for tabular data?

- **Concept**: Self-supervised learning principles and pretext tasks
  - *Why needed*: SORTAD builds on self-supervised anomaly detection frameworks
  - *Quick check*: What makes a good pretext task for anomaly detection in tabular data?

- **Concept**: Statistical variance concepts and distance metrics
  - *Why needed*: Core mechanism relies on variance-based scoring functions
  - *Quick check*: How does balancing inner and outer variance improve transformation selection?

## Architecture Onboarding

- **Component map**: Transformation generator -> Scoring module -> Selection layer -> Classifier -> Scoring engine -> Anomaly detection
- **Critical path**: Transformation generation → Scoring → Selection → Classification → Scoring → Anomaly detection
- **Design tradeoffs**: More temporary transformations (k) → better selection but higher computational cost; Higher polynomial degree → more expressive transformations but increased risk of numerical issues
- **Failure signatures**: High variance in VS Random scores across runs → transformation selection not working effectively; Performance drops to zero on some datasets → Easy Detection not properly handled; Numerical overflow/underflow errors → divide factor or non-constant constraints insufficient
- **First 3 experiments**:
  1. Test transformation selection with varying k values (5, 10, 20, 50) on SMTP dataset to find optimal balance
  2. Compare standard Dirichlet vs modified scoring on Thyroid dataset to verify Easy Detection handling
  3. Validate numerical stability by testing with different divide factors on Credit Card dataset with extreme values

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does performance scale with number of temporary transformations, and is there a point of diminishing returns?
- **Basis**: Paper states performance improves with more transformations but doesn't analyze rate of improvement or identify upper limit
- **Resolution**: Detailed analysis showing VS Random score as function of temporary transformations, identifying trends or plateaus

### Open Question 2
- **Question**: How does SORTAD perform on high-dimensional tabular data or image data?
- **Basis**: Paper focuses on low-dimensional tabular datasets, leaving generalizability to other data types unexplored
- **Resolution**: Benchmarking SORTAD against other methods on high-dimensional tabular datasets and image datasets

### Open Question 3
- **Question**: How does choice of scoring function (Dirichlet vs summation) affect performance in different anomaly detection scenarios?
- **Basis**: Paper introduces modified Dirichlet scoring but doesn't provide comprehensive analysis across scenarios
- **Resolution**: Systematic comparison of SORTAD's performance using different scoring functions across wide range of anomaly detection scenarios

## Limitations
- Performance claims rely heavily on specific experimental setup with 10 datasets, limiting generalizability
- Easy Detection handling mechanism assumes training data mean scores accurately represent normal behavior, which may not hold for all datasets
- Modified Dirichlet scoring introduces additional hyperparameters that may require dataset-specific tuning

## Confidence

| Claim | Confidence |
|-------|------------|
| Superior performance metrics (VS Random, Recall, ROC-AUC) | High |
| Theoretical framework for transformation selection | Medium |
| Easy Detection handling and modified Dirichlet scoring | Low |

## Next Checks
1. Conduct sensitivity analysis on Easy Detection threshold R=3 across different datasets to determine if parameter needs dataset-specific tuning
2. Test SORTAD's performance on additional tabular datasets with varying anomaly ratios (both very rare and relatively common anomalies) to validate robustness claims
3. Implement ablation studies removing Divide Factor and Non-Constant constraints to quantify their actual impact on numerical stability and performance