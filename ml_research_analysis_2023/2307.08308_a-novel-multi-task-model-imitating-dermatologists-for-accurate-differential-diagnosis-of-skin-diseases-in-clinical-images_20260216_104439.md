---
ver: rpa2
title: A Novel Multi-Task Model Imitating Dermatologists for Accurate Differential
  Diagnosis of Skin Diseases in Clinical Images
arxiv_id: '2307.08308'
source_url: https://arxiv.org/abs/2307.08308
tags:
- skin
- diseases
- disease
- lesion
- body
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work proposes DermImitFormer, a multi-task model that imitates
  dermatologists'' diagnostic procedures for accurate skin disease diagnosis from
  clinical images. The model leverages three key strategies: multi-task learning for
  simultaneous disease, body part, and lesion attribute prediction; a lesion selection
  module to focus on informative lesion regions; and a cross-interaction module to
  model the complex reasoning between these factors.'
---

# A Novel Multi-Task Model Imitating Dermatologists for Accurate Differential Diagnosis of Skin Diseases in Clinical Images

## Quick Facts
- arXiv ID: 2307.08308
- Source URL: https://arxiv.org/abs/2307.08308
- Reference count: 26
- Primary result: Multi-task model achieves state-of-the-art 78.8% F1-score and 82.6% accuracy on Derm-49 dataset

## Executive Summary
This paper introduces DermImitFormer, a novel multi-task model designed to mimic dermatologists' diagnostic reasoning for accurate skin disease classification from clinical images. The model employs three key strategies: simultaneous prediction of disease, body part, and lesion attributes through multi-task learning; a lesion selection module to focus on informative lesion regions; and a cross-interaction module to model complex reasoning between these factors. A new large-scale clinical image dataset (Derm-49) with 57,246 images was established to evaluate the approach. Experiments on three datasets demonstrate state-of-the-art performance, with the multi-task approach improving interpretability and diagnostic accuracy while showing particular effectiveness in localizing lesions and modeling diagnostic relationships.

## Method Summary
DermImitFormer is a multi-task vision transformer that simultaneously predicts skin disease type, body part location, and lesion attributes from clinical images. The architecture uses a ViT-B/16 backbone with task-specific heads for each prediction target. A lesion selection module mimics dermatologists' zoom-in behavior by computing attention scores between class tokens and patch tokens, selecting the top K tokens most relevant to lesions. A cross-interaction module models the complex diagnostic reasoning between body parts, lesion attributes, and diseases through cross-attention-based feature fusion. The model is trained using SGD with CutMix augmentation on Derm-49, a new dataset containing 57,246 images across 49 diseases, 15 body parts, and 27 lesion attributes.

## Key Results
- DermImitFormer achieves 78.8% F1-score and 82.6% accuracy on Derm-49, outperforming single-task baselines by 1.3% and 1.4% respectively
- State-of-the-art performance on SD-198 (73.6% F1-score) and PAD-UFES-20 (74.5% F1-score) datasets
- Ablation studies demonstrate the effectiveness of multi-task learning, lesion selection module, and cross-interaction module
- Qualitative attention maps show improved lesion localization compared to baseline ViT without lesion selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-task learning improves diagnostic accuracy and interpretability by simultaneously predicting disease, body part, and lesion attributes.
- Mechanism: Joint optimization of multiple related tasks forces the model to learn shared representations that capture cross-task correlations, improving feature alignment and reducing gradient conflicts.
- Core assumption: Disease classification benefits from auxiliary tasks that provide clinically relevant context (e.g., body part localization, lesion attribute recognition).
- Evidence anchors:
  - [abstract]: "Through multi-task learning, the model simultaneously predicts body parts and lesion attributes in addition to the disease itself, enhancing diagnosis accuracy and improving diagnosis interpretability."
  - [section]: "Quantitative results demonstrate that multi-task learning (D+B+A) increases the F1-score from 77.8 to 79.1."
  - [corpus]: Weak evidence - corpus contains related works but no direct evidence of this specific multi-task strategy's effectiveness.
- Break condition: If the auxiliary tasks are not clinically relevant or their labels are noisy, the shared representations may degrade disease classification performance.

### Mechanism 2
- Claim: The lesion selection module improves lesion localization by mimicking dermatologists' zoom-in action.
- Mechanism: The module computes mutual attention scores between class tokens and patch tokens, selecting the top K tokens most relevant to lesions to focus learning on informative regions.
- Core assumption: Vision transformers' global attention can be refined to prioritize lesion-specific patches over background noise.
- Evidence anchors:
  - [abstract]: "The designed lesion selection module mimics dermatologists' zoom-in action, effectively highlighting the local lesion features from noisy backgrounds."
  - [section]: "Qualitative results are shown in Fig. 4(a), which depicts the attention maps obtained from the last transformer layer. Without LSM, vision transformers would struggle of localizing lesions and produce noisy attention maps. With LSM, the attention maps are more discriminative and lesions are localized precisely."
  - [corpus]: No direct evidence found in corpus for this specific lesion selection approach.
- Break condition: If lesions are too small or poorly defined in clinical images, the attention mechanism may fail to identify informative patches.

### Mechanism 3
- Claim: The cross-interaction module models complex diagnostic reasoning between body parts, lesion attributes, and diseases through feature fusion.
- Mechanism: Cross-attention blocks integrate global and local representations from different tasks, creating mutually enhanced features that better capture the diagnostic relationships.
- Core assumption: The diagnostic process involves non-linear interactions between clinical factors that can be learned through attention-based fusion.
- Evidence anchors:
  - [abstract]: "the presented cross-interaction module explicitly models the complicated diagnostic reasoning between body parts, lesion attributes, and diseases"
  - [section]: "These mutually enhanced features from CIM are concatenated together to generate more accurate predictions of diseases, body parts, and attributes."
  - [corpus]: No direct evidence found in corpus for this specific cross-interaction approach.
- Break condition: If the cross-attention mechanism introduces excessive complexity without meaningful feature alignment, it may harm generalization.

## Foundational Learning

- Concept: Vision Transformers
  - Why needed here: DermImitFormer uses ViT as the backbone to capture global contextual features from clinical images.
  - Quick check question: What is the role of positional embeddings in ViT?

- Concept: Multi-task Learning
  - Why needed here: The model simultaneously predicts disease, body part, and lesion attributes to leverage shared representations and improve interpretability.
  - Quick check question: How does joint optimization affect gradient conflicts between tasks?

- Concept: Attention Mechanisms
  - Why needed here: Both lesion selection and cross-interaction modules rely on attention to identify relevant features and model relationships.
  - Quick check question: What is the difference between self-attention and cross-attention?

## Architecture Onboarding

- Component map: Input image → Patch embedding → Shared ViT backbone → Task-specific heads (disease, body part, attribute) → Lesion Selection Module → Cross-Interaction Module → Output predictions
- Critical path: The lesion selection module and cross-interaction module are critical for performance gains; failure here directly impacts accuracy.
- Design tradeoffs: Multi-task learning improves accuracy but increases complexity and training time; lesion selection adds computational overhead but improves localization.
- Failure signatures: Poor lesion localization (noisy attention maps), gradient conflicts between tasks (unstable training), or overfitting to specific body parts/attributes.
- First 3 experiments:
  1. Baseline ViT performance without any additional modules.
  2. Ablation study removing the lesion selection module to measure its impact on localization.
  3. Single-task version of the model to quantify the benefit of multi-task learning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the DermImitFormer model's performance generalize to clinical images from diverse populations with different skin tones and ethnic backgrounds?
- Basis in paper: [inferred] The paper establishes a new large-scale clinical image dataset (Derm-49) with 57,246 images, but does not explicitly address the diversity of skin tones and ethnic backgrounds in the dataset.
- Why unresolved: The paper does not provide information on the diversity of the dataset in terms of skin tones and ethnic backgrounds, which is crucial for assessing the model's generalization to diverse populations.
- What evidence would resolve it: An analysis of the dataset's diversity in terms of skin tones and ethnic backgrounds, along with performance metrics of the model on images from diverse populations, would help address this question.

### Open Question 2
- Question: How does the DermImitFormer model handle rare skin diseases with limited training data?
- Basis in paper: [inferred] The paper mentions the use of a large-scale dataset (Derm-49) with 49 most common skin diseases, but does not explicitly discuss the model's performance on rare diseases with limited training data.
- Why unresolved: The paper does not provide information on the model's performance on rare skin diseases, which is important for understanding its applicability in real-world clinical settings where rare diseases may be encountered.
- What evidence would resolve it: Experiments evaluating the model's performance on rare skin diseases with limited training data, along with strategies for handling such cases, would help address this question.

### Open Question 3
- Question: How does the DermImitFormer model handle the temporal aspect of skin diseases, such as changes in appearance over time?
- Basis in paper: [inferred] The paper focuses on the static analysis of clinical images for skin disease diagnosis, but does not explicitly address the temporal aspect of skin diseases.
- Why unresolved: The paper does not provide information on how the model handles the temporal evolution of skin diseases, which is crucial for accurate diagnosis and monitoring of disease progression.
- What evidence would resolve it: Experiments evaluating the model's performance on longitudinal data, along with techniques for incorporating temporal information, would help address this question.

## Limitations
- The lesion selection module's effectiveness may degrade when lesions are small or poorly defined in clinical images.
- The cross-interaction module introduces significant architectural complexity without clear ablation evidence isolating its specific contribution.
- Evaluation only considers top-1 accuracy without examining failure cases or clinical utility in diagnostic workflows.

## Confidence
- **High confidence**: The multi-task learning framework (Disease+Body Part+Attributes) and its demonstrated performance improvements across three datasets are well-supported by ablation studies and quantitative results.
- **Medium confidence**: The lesion selection module's effectiveness in improving localization is supported by qualitative attention maps but lacks quantitative localization metrics or comparisons to established segmentation approaches.
- **Medium confidence**: The cross-interaction module's contribution to modeling diagnostic reasoning is conceptually sound but lacks ablation evidence isolating its impact from other architectural components.

## Next Checks
1. **Ablation study isolation**: Conduct a controlled ablation study where the lesion selection module is replaced with a standard segmentation backbone (e.g., Mask R-CNN) to quantify the specific contribution of the attention-based approach versus established methods.

2. **Clinical workflow validation**: Implement a user study where dermatologists interact with the model's attention visualizations and multi-task outputs to assess whether the increased interpretability translates to practical diagnostic improvements in real clinical scenarios.

3. **Failure case analysis**: Perform a detailed analysis of top-1 errors on Derm-49, particularly focusing on cases where the model's multi-task predictions (body part/attributes) differ from ground truth, to understand whether the model is learning spurious correlations versus genuine diagnostic patterns.