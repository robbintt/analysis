---
ver: rpa2
title: 'Hinge-Wasserstein: Estimating Multimodal Aleatoric Uncertainty in Regression
  Tasks'
arxiv_id: '2306.00560'
source_url: https://arxiv.org/abs/2306.00560
tags:
- uncertainty
- loss
- line
- entropy
- horizon
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of overconfident uncertainty estimates
  in regression-by-classification models. The authors propose hinge-Wasserstein, a
  loss function that improves uncertainty estimation by introducing a threshold parameter
  that disregards low-probability bins during training.
---

# Hinge-Wasserstein: Estimating Multimodal Aleatoric Uncertainty in Regression Tasks

## Quick Facts
- arXiv ID: 2306.00560
- Source URL: https://arxiv.org/abs/2306.00560
- Reference count: 32
- Primary result: Hinge-Wasserstein loss reduces AUSE by 30.47% (slope) and 65.00% (offset) on HLW dataset while maintaining competitive AUC scores

## Executive Summary
This paper addresses the problem of overconfident uncertainty estimates in regression-by-classification models by introducing hinge-Wasserstein, a novel loss function that improves uncertainty estimation by disregarding low-probability bins below a threshold during training. The method is evaluated on both synthetic datasets with controlled uncertainty and the real-world Horizon Lines in the Wild benchmark, demonstrating superior separation between in-distribution and out-of-distribution samples through entropy analysis.

## Method Summary
Hinge-Wasserstein is a modified Wasserstein distance loss that improves uncertainty estimation by removing the penalty for bins with probability below a threshold γW. During training, bins with probability below γW are zeroed out, the remaining probabilities are re-normalized, and then the Wasserstein distance is computed. This makes the loss more permissive with uncertain predictions and allows the model to better represent complex distributions with multiple modes, particularly useful when the true distribution is multi-modal or when full ground truth distributions are unavailable.

## Key Results
- Reduces AUSE for slope parameter by 30.47% and offset parameter by 65.00% compared to standard NLL loss on HLW dataset
- Shows better separation between in-distribution and out-of-distribution samples based on entropy distribution
- Captures multimodality in synthetic datasets with two conflicting lines while maintaining competitive AUC scores for horizon detection

## Why This Works (Mechanism)

### Mechanism 1
The hinge-Wasserstein loss improves uncertainty estimation by removing the penalty for low-probability bins below a threshold, which allows the model to better represent aleatoric uncertainty. During loss computation, bins with probability below γW are zeroed out, the remaining probabilities are re-normalized, and then the Wasserstein distance is computed. This makes the loss "more permissive" with uncertain predictions and reduces overconfidence. Core assumption: In ambiguous scenarios, the true distribution may have multiple modes, but standard losses force the model to concentrate probability mass into a single dominant mode.

### Mechanism 2
Hinge-Wasserstein better separates in-distribution from out-of-distribution samples based on entropy of the output distribution. By being more permissive of low-probability bins, the model learns to assign higher entropy to uncertain (OOD) cases, while confident (ID) cases have lower entropy, leading to better separation in entropy space. Core assumption: The true uncertainty in OOD cases should be reflected in higher entropy of the predicted distribution.

### Mechanism 3
Hinge-Wasserstein improves aleatoric uncertainty estimation by allowing secondary modes when the input contains conflicting cues. In the synthetic dataset with two lines, hinge-Wasserstein enables the model to predict multi-modal distributions, capturing the uncertainty from conflicting geometric cues. Core assumption: Aleatoric uncertainty arises when the input data contains genuine ambiguity (e.g., two plausible horizon lines), and the model should reflect this in its output distribution.

## Foundational Learning

- **Regression-by-classification**: Why needed here: It allows the model to predict full probability distributions over continuous outputs, which is necessary for capturing multimodal aleatoric uncertainty. Quick check: How does regression-by-classification differ from direct regression in terms of representing uncertainty?

- **Wasserstein distance**: Why needed here: It accounts for the order of bins and penalizes errors based on the distance between bins, making it more suitable for regression tasks than standard cross-entropy. Quick check: Why is Wasserstein distance preferred over cross-entropy for regression-by-classification?

- **Aleatoric vs. epistemic uncertainty**: Why needed here: The paper explicitly studies and distinguishes between these two types of uncertainty, and the hinge-Wasserstein loss is shown to improve estimation of both. Quick check: What is the difference between aleatoric and epistemic uncertainty, and how can each be detected from the model's output?

## Architecture Onboarding

- **Component map**: Resnet18 backbone → linear layer → softplus → normalization → K-bin output → decoding (argmax) → uncertainty measure (entropy or std)
- **Critical path**: Input image → feature extraction → probability distribution over bins → decoding to continuous value → uncertainty quantification
- **Design tradeoffs**: Softplus + normalization vs. softmax for output activation; hinge-Wasserstein vs. entropy-Wasserstein for loss; entropy vs. std for uncertainty measure
- **Failure signatures**: Overconfidence (low entropy even for OOD samples); underconfidence (uniform distribution even for ID samples); poor separation of ID/OOD in entropy space
- **First 3 experiments**:
  1. Train on synthetic dataset with one line per image; evaluate entropy distribution for ID vs. OOD test sets
  2. Train on synthetic dataset with two lines per image; visualize predicted distributions for one-line vs. two-line test sets
  3. Train on HLW dataset; compare AUSE and AUC for NLL, plain Wasserstein, entropy-Wasserstein, and hinge-Wasserstein losses

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of hinge-Wasserstein compare to other loss functions on tasks beyond horizon line detection and stereo disparity estimation? Basis in paper: The paper only evaluates hinge-Wasserstein on two specific tasks, suggesting potential for broader application. Why unresolved: The paper does not explore the generalizability of hinge-Wasserstein to other regression-by-classification tasks. What evidence would resolve it: Comparative experiments applying hinge-Wasserstein to diverse regression tasks and benchmarking against other loss functions.

### Open Question 2
What is the optimal threshold parameter γW for hinge-Wasserstein in different applications? Basis in paper: The paper uses γW = 0.02 for horizon line detection but does not explore how to determine this parameter for other tasks. Why unresolved: The paper does not provide a systematic method for selecting the threshold parameter. What evidence would resolve it: A study investigating the impact of γW on performance across various tasks and developing guidelines for parameter selection.

### Open Question 3
How does the use of more sophisticated mode decoding techniques affect the performance of hinge-Wasserstein? Basis in paper: The paper mentions that using a more advanced peak decoding could reduce the quantization error but leaves this for future work. Why unresolved: The paper does not explore the potential benefits of advanced decoding techniques with hinge-Wasserstein. What evidence would resolve it: Experiments comparing hinge-Wasserstein with different decoding methods to quantify performance improvements.

### Open Question 4
Can hinge-Wasserstein be effectively combined with ensemble methods to further improve uncertainty estimation? Basis in paper: The paper discusses ensemble methods as a separate approach to uncertainty estimation, suggesting potential for combination. Why unresolved: The paper does not investigate the integration of hinge-Wasserstein with ensemble techniques. What evidence would resolve it: Experiments demonstrating the performance of hinge-Wasserstein when used in conjunction with ensemble methods compared to each approach individually.

## Limitations

- Limited evaluation to horizon line detection and stereo disparity estimation tasks
- Threshold parameter γW appears somewhat arbitrary without systematic sensitivity analysis
- Reliance on entropy-based separation may not distinguish ambiguous in-distribution cases from true OOD samples

## Confidence

**Confidence: Medium** - Improvements demonstrated on synthetic and real-world benchmarks, but primarily measured on a single task (horizon line detection). Generalization to other regression tasks remains untested.

**Confidence: Low** - Mechanism for separating ID/OOD samples relies heavily on entropy analysis without thorough investigation of potential false positives from ambiguous in-distribution cases.

**Confidence: High** - Core technical contribution of modifying Wasserstein loss is clearly specified and implemented with sound mathematical formulation.

## Next Checks

1. **Cross-domain generalization test**: Apply hinge-Wasserstein to a different regression task (e.g., depth estimation or object detection bounding box regression) to verify if improvements in uncertainty estimation generalize beyond horizon line detection.

2. **Parameter sensitivity analysis**: Systematically vary the threshold parameter γW across multiple orders of magnitude and analyze its impact on both performance metrics (AUSE, AUC) and uncertainty quality to establish guidelines for parameter selection.

3. **Alternative uncertainty metrics**: Evaluate the model using additional uncertainty quantification metrics such as Expected Calibration Error (ECE) or negative log-likelihood on OOD detection tasks to provide complementary evidence of improved uncertainty estimation beyond the sparsification error metric used in the paper.