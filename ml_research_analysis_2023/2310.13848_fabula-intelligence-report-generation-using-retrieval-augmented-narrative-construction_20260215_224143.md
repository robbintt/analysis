---
ver: rpa2
title: 'FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative
  Construction'
arxiv_id: '2310.13848'
source_url: https://arxiv.org/abs/2310.13848
tags:
- plot
- intelligence
- event
- narrative
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: FABULA addresses the challenge of manual intelligence report generation
  by introducing a Retrieval-Augmented Generation (RAG) approach that uses structured
  event information from knowledge graphs to guide Large Language Models. The system
  extracts and organizes event plot points based on the Inverted Plot Pyramid narrative
  structure, stores them in an Event Plot Graph, and uses these as prompts to generate
  intelligence reports.
---

# FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction

## Quick Facts
- arXiv ID: 2310.13848
- Source URL: https://arxiv.org/abs/2310.13848
- Reference count: 33
- One-line primary result: FABULA achieves high semantic relevance (Rouge-1: 61.27, Rouge-2: 24.51) and strong linguistic fluency (4.2/5) in intelligence report generation using structured event information from knowledge graphs.

## Executive Summary
FABULA introduces a Retrieval-Augmented Generation approach that automates intelligence report generation by extracting structured event information from news articles and storing it in a knowledge graph. The system uses the Inverted Plot Pyramid narrative structure to organize event details and retrieve them as keyword prompts for a fine-tuned GPT-Neo model. Evaluation shows FABULA significantly reduces hallucinations compared to traditional LLM generation while maintaining high semantic relevance and linguistic fluency.

## Method Summary
FABULA extracts event plot points from news articles using Named Entity Recognition and Part of Speech Tagging, organizes them according to the Inverted Plot Pyramid structure, and stores them in an Event Plot Graph using an Event Narrative Ontology. SPARQL queries retrieve relevant plot points for analyst queries, which are then converted to linearized keyword prompts. These prompts are fed to a fine-tuned GPT-Neo model using prefix-tuning to generate fluent intelligence reports. The system was trained on a corpus combining news articles from major sources with official intelligence reports.

## Key Results
- High semantic relevance with Rouge-1 score of 61.27 and Rouge-2 score of 24.51
- Strong linguistic fluency rated 4.2/5 by human evaluators
- Generated reports closely match analyst expectations with minimal hallucinations or redundancy

## Why This Works (Mechanism)

### Mechanism 1
FABULA reduces hallucination by using structured narrative plot points from a knowledge graph as controlled prompts for LLM generation. Instead of relying on the LLM to invent details, the system retrieves pre-classified event elements stored in an Event Plot Graph and feeds them as keyword prompts to GPT-Neo, constraining generation to known facts.

### Mechanism 2
Fine-tuning GPT-Neo on a combined news and intelligence report corpus aligns its vocabulary and output style with the target domain. Training on both raw news articles and structured intelligence reports allows the model to learn both general vocabulary and specific formatting expected in intelligence reports.

### Mechanism 3
Prefix-tuning with narrative prompt sets allows GPT-Neo to generate from a structured set of keywords rather than a single sentence prompt. By optimizing continuous task-specific virtual vectors attached to the frozen GPT-Neo, the system can take a linearized set of event plot keywords and produce fluent, coherent text.

## Foundational Learning

- Concept: Narrative plot structures (e.g., Inverted Plot Pyramid)
  - Why needed here: FABULA relies on the IPP to organize event details into coherent, journalist-style intelligence reports.
  - Quick check question: What are the three main sections of the Inverted Plot Pyramid and what type of information belongs in each?

- Concept: Knowledge graphs and RDF triples
  - Why needed here: The Event Plot Graph stores extracted plot points as RDF triples, enabling efficient querying and retrieval of structured event information.
  - Quick check question: How are plot points represented as RDF triples in the Event Plot Graph?

- Concept: SPARQL query language
  - Why needed here: FABULA uses SPARQL templates to extract relevant plot points from the Event Plot Graph based on analyst queries.
  - Quick check question: What is the purpose of the SPARQL query shown in Listing 1, and what plot points does it retrieve?

## Architecture Onboarding

- Component map: News Intelligence Corpus (D + IR) -> Narrative Plot Concept Extractor (NPCE) -> Event Plot Graph (EPG) -> SPARQL Templates -> Prefix-tuner -> Fine-tuned GPT-Neo -> Report Generator

- Critical path: Query → SPARQL extraction from EPG → linearized keyword prompt → Prefix-tuner → GPT-Neo → Intelligence report

- Design tradeoffs: Using a knowledge graph adds structure but increases complexity and upfront data extraction effort; fine-tuning GPT-Neo aligns style but requires domain data and training resources; prefix-tuning allows structured prompting but may reduce flexibility compared to full finetuning.

- Failure signatures: Incomplete or hallucinated reports → Likely missing or incorrect plot points in EPG; Stylistically off reports → Possible domain mismatch in fine-tuning corpus; Nonsensical or incoherent text → Likely keyword prompt is too sparse or disordered for prefix-tuning.

- First 3 experiments: Verify SPARQL extraction returns correct plot points for a known event query; Test prefix-tuning with a simple linearized prompt set to ensure GPT-Neo generates coherent text; Evaluate generated report quality using Rouge scores against a Wikipedia event summary.

## Open Questions the Paper Calls Out

### Open Question 1
How can FABULA be adapted to work with different narrative plot structures beyond the Inverted Plot Pyramid? The paper acknowledges other narrative theories exist but focuses only on IPP without exploring implementation or effectiveness of alternatives.

### Open Question 2
What is the optimal balance between automated narrative extraction and human analyst oversight to minimize information gaps and hallucinations? The paper discusses FABULA's ability to reduce hallucinations but doesn't explore how human analysts can best interact with the system.

### Open Question 3
How does FABULA's performance scale when processing real-time streaming data from hundreds of concurrent events? The paper uses a static corpus but acknowledges the system is designed for RSS feed triggers from multiple sources.

## Limitations

- The system's performance heavily depends on the accuracy and completeness of the Event Plot Graph, with errors propagating directly to generated reports.
- Claims about minimal hallucination and redundancy are inferred from semantic relevance scores rather than directly measured.
- The system's effectiveness on novel event types not represented in the training corpus remains unverified.

## Confidence

**High Confidence**: The general RAG approach of using structured knowledge graphs to guide LLM generation is well-established in the literature and the basic evaluation metrics (Rouge scores, human fluency ratings) are appropriately applied.

**Medium Confidence**: The specific combination of fine-tuning with prefix-tuning on keyword prompts is less conventional and would benefit from ablation studies comparing it to standard fine-tuning approaches.

**Low Confidence**: Claims about minimal hallucination and redundancy are not directly measured - these are inferred from semantic relevance scores rather than explicitly tested.

## Next Checks

1. **Hallucination Audit**: Run generated reports through a fact-checking pipeline against source documents to measure actual hallucination rates, including both automated factuality scoring and expert human review.

2. **Edge Case Testing**: Systematically test the model on events with incomplete or ambiguous plot points to determine how well the prefix-tuning mechanism handles sparse information and whether it compensates by hallucinating.

3. **Knowledge Graph Quality Assessment**: Evaluate the completeness and accuracy of the Event Plot Graph by measuring recall of relevant plot points for a diverse set of events, and analyze how missing plot points affect generation quality.