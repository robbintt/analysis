---
ver: rpa2
title: 'Spatial Knowledge-Infused Hierarchical Learning: An Application in Flood Mapping
  on Earth Imagery'
arxiv_id: '2312.07767'
source_url: https://arxiv.org/abs/2312.07767
tags:
- spatial
- learning
- labels
- deep
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of training deep learning models
  for Earth imagery tasks (like flood mapping) when only limited labeled data is available.
  The authors propose a novel Spatial Knowledge-Infused Hierarchical Learning (SKI-HL)
  framework that integrates spatial domain knowledge with deep learning to overcome
  this limitation.
---

# Spatial Knowledge-Infused Hierarchical Learning: An Application in Flood Mapping on Earth Imagery

## Quick Facts
- arXiv ID: 2312.07767
- Source URL: https://arxiv.org/abs/2312.07767
- Authors: 
- Reference count: 39
- One-line primary result: SKI-HL achieves ~0.95 accuracy on flood mapping with as few as 4 labeled samples using spatial knowledge infusion and hierarchical learning.

## Executive Summary
This paper addresses the challenge of training deep learning models for Earth imagery tasks when limited labeled data is available. The authors propose a novel Spatial Knowledge-Infused Hierarchical Learning (SKI-HL) framework that integrates spatial domain knowledge with deep learning to overcome data scarcity. By inferring full labels from sparse and noisy input labels using spatial knowledge base rules while training a neural network model iteratively, the method achieves high accuracy even with minimal labeled samples.

## Method Summary
SKI-HL employs a multi-resolution hierarchy that refines labels from coarse to fine resolution, focusing computational resources on uncertain areas. The framework integrates uncertainty quantification throughout the inference and learning process, using probabilistic soft logic for spatial knowledge representation and uncertainty-aware multi-instance learning for deep learning. The method works by grounding spatial knowledge rules hierarchically, calculating uncertainty for each cell using entropy, and selectively refining only high-uncertainty cells to the next finer resolution level.

## Key Results
- Achieves accuracy rates around 0.95 even with as few as 4 initial labeled samples on real-world flood mapping datasets
- Outperforms several baseline methods including Pretrain, Self-training, DeepProbLog, and ABL
- Demonstrates particular effectiveness in handling spatial uncertainty and reducing computational costs through its hierarchical label inference strategy

## Why This Works (Mechanism)

### Mechanism 1
Hierarchical multi-resolution grounding enables scalable spatial logic inference by reducing ground atoms exponentially. The framework partitions the spatial raster into hierarchical grids where each cell at level k represents a group of cells at level k-1, creating a tree structure where only leaf nodes are grounded with logic rules. Core assumption: Spatial relationships exhibit hierarchical characteristics where coarse-level inference can provide useful information for fine-level refinement.

### Mechanism 2
Uncertainty-guided selective refinement focuses computational resources on areas most likely to benefit from higher resolution. The framework calculates uncertainty for each cell using entropy of inferred labels, then selectively refines only high-uncertainty cells to the next finer resolution level. Core assumption: Areas with higher label uncertainty are more likely to contain important boundaries or complex spatial relationships that benefit from finer resolution.

### Mechanism 3
Uncertainty-aware deep learning bridges the gap between symbolic logic inference and feature-based learning. The deep learning module uses inferred uncertain labels as training targets with modified loss functions that handle soft labels (probabilities between 0-1) rather than binary labels, and employs multi-instance learning to aggregate predictions from finer resolution to match coarse label resolution. Core assumption: The uncertainty information from logical inference contains valuable signal that can improve deep learning performance beyond simple binary labels.

## Foundational Learning

- Concept: Multi-instance learning
  - Why needed here: The hierarchical label inference operates at different resolutions, requiring the deep learning model to aggregate predictions from multiple finer-resolution pixels to match the coarser-resolution inferred labels
  - Quick check question: If a coarse cell contains 100 pixels, how should the model aggregate their predictions to compare with the single inferred label for that cell?

- Concept: Probabilistic soft logic and t-norms
  - Why needed here: The framework needs to handle uncertainty in spatial knowledge rules that cannot always be perfectly satisfied, requiring soft truth values between 0 and 1 rather than binary logic
  - Quick check question: How does the framework compute the truth value of a rule like "if A is flooded and B is adjacent to A, then B is flooded" when the spatial knowledge is uncertain?

- Concept: Hierarchical data structures and tree traversal
  - Why needed here: The multi-resolution approach creates a tree-like structure where cells at different levels must be efficiently navigated and refined based on uncertainty
  - Quick check question: In a hierarchy with 3 levels and grid size constant η=2, how many total cells exist across all levels for an original 8×8 pixel image?

## Architecture Onboarding

- Component map: Hierarchical label inference module -> Uncertainty calculation -> Selective refinement -> Deep learning module with uncertainty-aware loss -> Iterative training loop
- Critical path: The main computational bottleneck is the label inference at finer resolutions, particularly when many cells are selected for refinement. The deep learning training is relatively stable across iterations.
- Design tradeoffs: Coarser resolutions provide computational efficiency but lose spatial detail; finer resolutions provide accuracy but increase computation exponentially. The uncertainty-guided approach attempts to optimize this tradeoff.
- Failure signatures: Poor performance may indicate either (1) inadequate spatial knowledge rules, (2) uncertainty metrics not capturing true inference needs, or (3) deep learning unable to learn effectively from soft labels.
- First 3 experiments:
  1. Test the hierarchical inference on a small synthetic dataset with known ground truth to verify that uncertainty-guided refinement improves accuracy
  2. Compare deep learning performance using binary vs. soft labels on a validation set to measure the benefit of uncertainty-aware training
  3. Profile computational time at each resolution level to identify the most expensive operations and potential optimization opportunities

## Open Questions the Paper Calls Out

- How does SKI-HL perform when applied to other geospatial applications beyond flood mapping? The authors mention that future work includes expanding to other geospatial applications to validate generalizability, but current evaluation is limited to flood mapping datasets.
- How can temporal dynamics be incorporated into SKI-HL for analyzing changes in Earth imagery over time? The authors suggest incorporating temporal dynamics features as future work, particularly for applications like deforestation tracking, but the current framework focuses on static spatial data.
- What is the optimal balance between computational efficiency and spatial granularity in the hierarchical label inference process? The authors discuss the trade-off between computational efficiency and inference granularity but do not provide a definitive solution for optimizing this balance.

## Limitations

- The methodology relies heavily on the quality of spatial knowledge base rules, which are not fully specified in the paper, making exact replication challenging.
- Computational efficiency gains from uncertainty-guided refinement, while theoretically sound, may vary significantly depending on the specific characteristics of the input data and spatial relationships being modeled.
- The reported 0.95 accuracy may depend critically on having an extensive, well-crafted knowledge base that is not fully described.

## Confidence

- High confidence: The hierarchical multi-resolution approach for reducing computational complexity
- Medium confidence: The effectiveness of uncertainty-guided selective refinement in improving accuracy
- Low confidence: The specific spatial knowledge base rules and their impact on performance

## Next Checks

1. **Knowledge Base Sensitivity Analysis**: Test the framework's performance using different sets of spatial knowledge rules (minimal vs. comprehensive) to quantify how rule quality affects the final accuracy, particularly focusing on whether the reported 0.95 accuracy depends critically on having an extensive, well-crafted knowledge base.

2. **Uncertainty Metric Validation**: Compare the framework's uncertainty quantification (AvU metric) against ground truth uncertainty in controlled synthetic datasets where true uncertainty is known, to verify that the entropy-based uncertainty measures accurately reflect actual inference reliability.

3. **Generalization Across Domains**: Apply the SKI-HL framework to a different Earth imagery task (e.g., land cover classification or building detection) with limited labels to assess whether the hierarchical knowledge-infused approach generalizes beyond flood mapping or is task-specific.