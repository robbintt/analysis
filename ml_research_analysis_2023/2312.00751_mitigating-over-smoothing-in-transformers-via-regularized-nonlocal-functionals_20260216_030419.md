---
ver: rpa2
title: Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals
arxiv_id: '2312.00751'
source_url: https://arxiv.org/abs/2312.00751
tags:
- neutreno
- deit
- over-smoothing
- transformer
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the over-smoothing problem in deep transformers,
  where token representations become identical as the model's depth increases. It
  shows that self-attention layers implicitly minimize a nonlocal functional promoting
  smoothness, causing token uniformity.
---

# Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals

## Quick Facts
- arXiv ID: 2312.00751
- Source URL: https://arxiv.org/abs/2312.00751
- Reference count: 40
- Key outcome: NeuTRENO significantly outperforms baseline transformers and state-of-the-art methods in reducing over-smoothing across image classification, segmentation, and language modeling tasks.

## Executive Summary
This paper addresses the over-smoothing problem in deep transformers, where token representations become increasingly similar as model depth increases. The authors show that self-attention layers implicitly minimize a nonlocal functional that promotes smoothness, causing token uniformity. They propose NeuTRENO, which adds a convex fidelity term to this functional to preserve token fidelity. This leads to a new attention formula that includes a term penalizing the difference between output and input tokens. The method achieves state-of-the-art results across multiple tasks while maintaining computational efficiency.

## Method Summary
The method builds on the observation that self-attention layers implicitly minimize a nonlocal functional that promotes smoothness. NeuTRENO adds a convex fidelity term to this functional, which penalizes the difference between output and input tokens. The resulting attention formula is derived from discretizing the gradient flow of the regularized functional. The key innovation is the modified attention computation that balances smoothing with fidelity preservation, implemented as an additional term in the attention output.

## Key Results
- Top-1 accuracy: 73.01% vs. 72.17% (baseline) on ImageNet classification
- SS MIoU: 37.24% vs. 35.72% (baseline) on ADE20K image segmentation
- Test perplexity: 33.70 vs. 34.29 (baseline) on WikiText-103 language modeling

## Why This Works (Mechanism)

### Mechanism 1
Self-attention layers implicitly minimize a nonlocal functional that promotes smoothness, causing token uniformity (over-smoothing). The self-attention operation corresponds to a gradient descent step toward minimizing a nonlocal functional $J(u) = \frac{1}{2} \iint_{\Omega\times\Omega} \|u(x) - u(y)\|^2 k(x,y) dx dy$. This functional penalizes high-frequency noise and encourages smoothness in token representations. Core assumption: The affinity kernel $k(x,y)$ is symmetric and positive, and the functional $J(u)$ is well-defined over the token space.

### Mechanism 2
Adding a convex fidelity term to the nonlocal functional preserves token fidelity and mitigates over-smoothing. The regularized functional $E(u,f) = J(u) + G(u,f)$ includes a fidelity term $G(u,f) = \frac{\lambda}{2} \int_\Omega \|u(x) - f(x)\|^2 dx$ that penalizes deviation from input tokens, counteracting the smoothing effect of $J(u)$. Core assumption: The fidelity term is convex and well-defined, and the parameter $\lambda$ is appropriately chosen.

### Mechanism 3
NeuTRENO attention is an Euler discretization of the gradient flow of the regularized functional, providing a principled way to mitigate over-smoothing. The NeuTRENO attention formula $u(i) = \sum_{j=1}^N \text{softmax}(q(i)^T k(j)/\sqrt{D_{qk}}) v(j) + \tilde{\lambda}(v_0(i) - v(i))$ is derived by discretizing the gradient flow of $E(u,f)$ with an adaptive step size, incorporating both the smoothing term and the fidelity term. Core assumption: The discretization is accurate and stable, and the adaptive step size is appropriately chosen.

## Foundational Learning

- **Concept**: Variational denoising and functional analysis
  - **Why needed here**: Understanding the mathematical framework of variational denoising and functional analysis is crucial for deriving and analyzing the nonlocal functional and its regularization.
  - **Quick check question**: What is the role of the fidelity term in the regularized functional, and how does it affect the denoising process?

- **Concept**: Gradient descent and discretization methods
  - **Why needed here**: Understanding gradient descent and discretization methods is essential for deriving the NeuTRENO attention formula from the gradient flow of the regularized functional.
  - **Quick check question**: How does the Euler method discretization relate to the NeuTRENO attention formula, and what are the implications of using an adaptive step size?

- **Concept**: Random walk and graph theory
  - **Why needed here**: Understanding random walk and graph theory is important for analyzing the over-smoothing phenomenon and its relation to the diffusion process in self-attention.
  - **Quick check question**: How does the random walk perspective explain the convergence of token representations to a constant vector, and what are the implications for the over-smoothing issue?

## Architecture Onboarding

- **Component map**: Input tokens $X$ -> Query, key, value matrices $Q,K,V$ -> Attention matrix $A = \text{softmax}(QK^\top / \sqrt{D_{qk}})$ -> Output tokens $U = AV + \tilde{\lambda}(V_0 - V)$

- **Critical path**:
  1. Compute query, key, and value matrices from input tokens
  2. Compute attention matrix using softmax function
  3. Apply NeuTRENO modification by adding the fidelity term
  4. Compute output tokens using the modified attention matrix and value matrix

- **Design tradeoffs**:
  - Choosing the parameter $\tilde{\lambda}$ to balance between smoothing and fidelity
  - Selecting the linear transformations for query, key, and value matrices to capture relevant relationships
  - Deciding whether to use symmetric or asymmetric self-attention

- **Failure signatures**:
  - Over-smoothing: Cosine similarity between token representations increases with depth
  - Underfitting: Cosine similarity between token representations is too low, indicating lack of smoothness
  - Numerical instability: Large gradients or exploding/vanishing values during training

- **First 3 experiments**:
  1. Compare the cosine similarity between token representations of NeuTRENO and baseline models across layers on a small dataset (e.g., CIFAR-10)
  2. Analyze the impact of different values of $\tilde{\lambda}$ on the performance of NeuTRENO on a validation set
  3. Evaluate the robustness of NeuTRENO to adversarial examples and out-of-distribution data compared to the baseline model

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the optimal value of the hyperparameter λ in NeuTRENO for different tasks and datasets?
  - Basis in paper: The paper mentions an ablation study on the choice of λ in Table 13, showing that different values of λ lead to varying performance. However, it does not provide a definitive answer on the optimal value for all tasks and datasets.
  - Why unresolved: The optimal value of λ may depend on the specific task, dataset, and model architecture. Finding the optimal value requires extensive experimentation and may not be generalizable across all settings.
  - What evidence would resolve it: A comprehensive study that systematically varies λ across different tasks, datasets, and model architectures to identify patterns and guidelines for choosing the optimal value.

- **Open Question 2**: How does NeuTRENO compare to other state-of-the-art methods for mitigating over-smoothing in transformers?
  - Basis in paper: The paper compares NeuTRENO to the DeiT baseline and FeatScale on various tasks, showing superior performance. However, it does not provide a comprehensive comparison to other methods in the literature.
  - Why unresolved: There are numerous methods proposed in the literature for addressing over-smoothing in transformers. A thorough comparison of NeuTRENO to these methods is needed to establish its relative effectiveness and efficiency.
  - What evidence would resolve it: A comprehensive empirical study that compares NeuTRENO to other state-of-the-art methods on a wide range of tasks and datasets, using consistent evaluation metrics and model architectures.

## Limitations

- The theoretical framework assumes certain properties of the affinity kernel that may not hold in all practical scenarios.
- The experimental validation is limited to three specific tasks (image classification, segmentation, and language modeling) without exploring other transformer applications.
- The sensitivity to the fidelity parameter $\tilde{\lambda}$ is not extensively studied across different model architectures and tasks.

## Confidence

**High confidence**: The theoretical foundation connecting self-attention to nonlocal functionals and the core mathematical derivation of the NeuTRENO attention mechanism are well-established and rigorous.

**Medium confidence**: The empirical improvements demonstrated on benchmark tasks are significant, but the experimental setup could benefit from more extensive ablation studies and comparisons with a broader range of baselines.

**Low confidence**: The long-term generalization capabilities of NeuTRENO across diverse domains and the sensitivity to hyperparameter choices (particularly $\tilde{\lambda}$) remain uncertain without more extensive experimentation.

## Next Checks

1. **Cross-domain robustness test**: Evaluate NeuTRENO on a diverse set of tasks beyond the three benchmark datasets, including text generation (e.g., summarization, translation), multimodal tasks (image-text alignment), and scientific computing applications to assess generalizability.

2. **Ablation study on $\tilde{\lambda}$**: Conduct a comprehensive sensitivity analysis varying $\tilde{\lambda}$ across multiple orders of magnitude to identify optimal ranges and failure modes, including testing on small datasets where effects are more observable.

3. **Theoretical verification of kernel properties**: Systematically test the assumptions about the affinity kernel symmetry and positive definiteness across different attention mechanisms and input distributions to identify conditions where the theoretical guarantees may break down.