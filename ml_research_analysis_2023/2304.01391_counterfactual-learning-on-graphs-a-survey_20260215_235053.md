---
ver: rpa2
title: 'Counterfactual Learning on Graphs: A Survey'
arxiv_id: '2304.01391'
source_url: https://arxiv.org/abs/2304.01391
tags:
- counterfactual
- graph
- learning
- prediction
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides the first comprehensive review of counterfactual
  learning on graphs, categorizing methods into counterfactual fairness, counterfactual
  explanation, counterfactual link prediction and recommendation, and real-world applications.
  It introduces a unified framework that models counterfactual augmentation and regularization
  to address bias, interpretability, and causal reasoning limitations in graph neural
  networks.
---

# Counterfactual Learning on Graphs: A Survey

## Quick Facts
- arXiv ID: 2304.01391
- Source URL: https://arxiv.org/abs/2304.01391
- Reference count: 40
- Key outcome: First comprehensive survey of counterfactual learning on graphs, introducing unified frameworks and categorizing methods across fairness, explanation, link prediction, and real-world applications.

## Executive Summary
This survey provides the first comprehensive review of counterfactual learning on graphs, addressing critical limitations in graph neural networks including bias, interpretability, and causal reasoning. The authors systematically categorize existing methods into four main areas: counterfactual fairness, counterfactual explanation, counterfactual link prediction and recommendation, and real-world applications. The survey introduces unified frameworks that model counterfactual augmentation and regularization to improve model generalization, fairness, and interpretability in graph-based machine learning systems.

## Method Summary
The survey conducts a systematic literature review of counterfactual learning methods on graph-structured data, organizing existing research into a coherent taxonomy. It provides unified mathematical frameworks for counterfactual augmentation and regularization across different application domains, and identifies key evaluation metrics and datasets for each category. The paper synthesizes methodological approaches and highlights promising future directions including scalability, dynamic graphs, and unsupervised counterfactual learning.

## Key Results
- Introduces first systematic taxonomy of counterfactual learning on graphs across four main categories
- Proposes unified frameworks for counterfactual augmentation and regularization in graph neural networks
- Identifies key evaluation metrics and datasets for assessing counterfactual graph learning methods
- Highlights critical future directions including scalability, dynamic graphs, and unsupervised approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual learning enables models to generalize beyond distribution shifts by learning causal relationships instead of spurious correlations.
- Mechanism: By modeling what would have happened under different conditions (counterfactuals), the model learns invariant features that remain stable across different environments.
- Core assumption: The observed data contains sufficient information to infer the underlying causal structure, even without explicit interventions.
- Evidence anchors:
  - [abstract] "The ability to learn with counterfactuals and generalize to unseen environments is considered a significant component of general AI."
  - [section 2.3] "Compared with traditional statistical models, casual models have better generalization ability in modeling real-world systems"
- Break condition: If the causal structure is too complex or unobservable, counterfactual learning may fail to extract meaningful patterns from the data alone.

### Mechanism 2
- Claim: Graph counterfactual learning improves fairness by ensuring predictions remain consistent when sensitive attributes are changed.
- Mechanism: The model learns representations that are invariant to sensitive attributes by minimizing the discrepancy between factual and counterfactual outcomes.
- Core assumption: Sensitive attributes have identifiable causal effects that can be isolated and neutralized through representation learning.
- Evidence anchors:
  - [abstract] "counterfactual learning has shown promising results in alleviating these drawbacks" (fairness mentioned as one drawback)
  - [section 3.1.2] "Counterfactual fairness makes the outputs of a machine learning model for an individual in actual world remain the same when we flip the sensitive attribute of the same individual to the counterfactual world"
- Break condition: If sensitive attributes are entangled with other features in ways that cannot be disentangled, fairness guarantees may not hold.

### Mechanism 3
- Claim: Counterfactual explanations provide actionable insights by identifying minimal changes needed to achieve different predictions.
- Mechanism: Instead of just identifying correlated features, the model finds perturbations that would actually change the outcome, providing clear guidance on what to modify.
- Core assumption: The decision boundary of the model can be meaningfully perturbed through small changes to the input graph structure or features.
- Evidence anchors:
  - [abstract] "counterfactual explanation on graphs aims to identify the necessary changes to the input graph that can alter the prediction outcome"
  - [section 4.1] "graph counterfactual explanation aims to explain the prediction by finding a minimal change of the input features and graph structure that would cause the target model to classify the modified input to a desired different class"
- Break condition: If the model's decision boundary is too complex or non-differentiable, finding minimal changes may be computationally intractable.

## Foundational Learning

- Concept: Causal inference and potential outcomes framework
  - Why needed here: The survey builds on foundational causal inference concepts to frame counterfactual learning on graphs
  - Quick check question: What is the difference between factual and counterfactual outcomes in the potential outcomes framework?

- Concept: Graph neural networks and message passing
  - Why needed here: GNNs form the basis for representation learning on graphs that counterfactual methods build upon
  - Quick check question: How does the message passing mechanism in GNNs aggregate information from neighboring nodes?

- Concept: Fairness metrics and bias mitigation
  - Why needed here: Many counterfactual graph learning methods aim to address fairness issues in graph-based predictions
  - Quick check question: What is the difference between statistical parity and counterfactual fairness?

## Architecture Onboarding

- Component map: Preliminaries -> Unified Frameworks -> Fairness Methods -> Explanation Methods -> Link Prediction/Recommendation Methods -> Applications -> Future Directions
- Critical path: Understanding the unified frameworks is critical - they provide the mathematical foundation that connects all the methods in each category. The frameworks show how counterfactual augmentation and regularization work together.
- Design tradeoffs: The survey balances breadth (covering many categories) with depth (detailed method descriptions). This means some categories get less detailed treatment than others, but provides a comprehensive overview.
- Failure signatures: If a reader struggles with the mathematical notation in the frameworks, they likely need to review the preliminaries section first. If they can't connect the taxonomy to the methods, they may need to revisit the framework sections.
- First 3 experiments:
  1. Implement a simple counterfactual fairness method using the unified framework (Section 3.2.1) on a small synthetic graph dataset
  2. Create counterfactual explanations for a GNN on a known graph (like BA-Shapes) to verify the perturbation approach works
  3. Apply counterfactual link prediction augmentation to a recommendation dataset to see if it improves performance on distribution shifts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can graph counterfactual learning be made scalable for large-scale real-world graphs?
- Basis in paper: [explicit] Section 7 mentions that existing graph counterfactual learning approaches are time-consuming and often struggle with scalability, making them unsuitable for large-scale graphs.
- Why unresolved: The paper acknowledges the importance of scalability but does not provide specific solutions or approaches to address this challenge.
- What evidence would resolve it: Research demonstrating effective techniques for scaling graph counterfactual learning to large graphs, such as distributed algorithms, approximate methods, or novel architectures.

### Open Question 2
- Question: How can graph counterfactual learning be extended to handle dynamic graphs effectively?
- Basis in paper: [explicit] Section 7 highlights that many real-world graphs are inherently dynamic, but existing graph counterfactual learning approaches mainly focus on static graphs. The paper emphasizes the need to address the complexity of modeling graph structure over time and the lack of high-quality dynamic graph datasets.
- Why unresolved: The paper recognizes the importance of dynamic graphs but does not provide specific solutions or approaches to handle their dynamic nature.
- What evidence would resolve it: Research proposing novel techniques for incorporating temporal information into graph counterfactual learning, such as dynamic graph neural networks, temporal causal inference, or dynamic counterfactual data augmentation.

### Open Question 3
- Question: How can unsupervised graph counterfactual learning be developed and evaluated?
- Basis in paper: [explicit] Section 7 mentions that there are very few explorations for unsupervised/self-supervised graph counterfactual learning. The paper highlights the challenges of investigating causal structure without labeled data and generating counterfactual outcomes without ground truth labels.
- Why unresolved: The paper acknowledges the gap in unsupervised graph counterfactual learning but does not provide specific approaches or evaluation metrics.
- What evidence would resolve it: Research proposing novel unsupervised/self-supervised graph counterfactual learning techniques, along with evaluation metrics tailored for this setting, such as unsupervised counterfactual fairness metrics or unsupervised counterfactual explanation evaluation.

## Limitations
- Limited empirical validation across diverse graph datasets and real-world scenarios
- Many methods assume idealized conditions that rarely hold in practice
- Rapid field evolution means some recently published work may not be included
- Scalability challenges for large-scale graph counterfactual learning remain unresolved

## Confidence
- Confidence in unified frameworks: Medium - mathematical foundations appear sound but lack extensive experimental validation
- Confidence in fairness claims: Medium-Low - complex interplay between graph structure and sensitive attributes may not be fully captured
- Confidence in taxonomy and categorization: High - systematically organizes existing literature with clear distinctions

## Next Checks
1. Test the unified framework implementation on a temporal graph dataset to verify generalizability claims
2. Compare counterfactual explanation methods on the BA-Shapes benchmark with established GNN baselines
3. Evaluate fairness metrics from Section 3.2 on a real-world social network dataset with known sensitive attributes