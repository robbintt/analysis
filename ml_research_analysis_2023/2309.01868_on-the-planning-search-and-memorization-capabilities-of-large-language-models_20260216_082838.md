---
ver: rpa2
title: On the Planning, Search, and Memorization Capabilities of Large Language Models
arxiv_id: '2309.01868'
source_url: https://arxiv.org/abs/2309.01868
tags:
- planning
- language
- search
- gpt-4
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the planning capabilities of large language
  models (LLMs), specifically GPT-4, across various planning subfields. The research
  examines GPT-4's performance in planning domain extraction, graph search path planning,
  and adversarial planning.
---

# On the Planning, Search, and Memorization Capabilities of Large Language Models

## Quick Facts
- arXiv ID: 2309.01868
- Source URL: https://arxiv.org/abs/2309.01868
- Reference count: 38
- Primary result: GPT-4 shows effective PDDL generation and simple graph search but struggles with complex graphs and adversarial planning due to state memorization limitations

## Executive Summary
This study investigates GPT-4's capabilities across three planning domains: planning domain extraction, graph search path planning, and adversarial planning. The research demonstrates that GPT-4 can effectively extract PDDL representations from textual descriptions for simple tasks and perform graph search algorithms on small graphs (5-15 nodes). However, the model shows significant limitations with complex graphs and cannot execute adversarial search algorithms due to its inability to maintain game state across turns. The study proposes fine-tuning approaches to improve Chain of Thought capabilities, but results show only minor improvements, highlighting the fundamental limitations of current LLMs in logical reasoning tasks.

## Method Summary
The study evaluates GPT-4's planning capabilities through three main experiments: (1) generating PDDL domain specifications from 100 textual task descriptions across various complexity levels, (2) testing graph search algorithm implementation on weighted graphs ranging from 5 to 95 nodes using BFS, DFS, and Dijkstra's algorithms, and (3) designing heuristics for adversarial planning in Tic-Tac-Toe while evaluating the model's ability to maintain game state. The researchers also attempt to improve performance through fine-tuning a domain-specific LLM by freezing original weights and modifying the final layer, though this yields only minor improvements.

## Key Results
- GPT-4 successfully generates valid PDDL for simple daily tasks with correct predicates and actions
- Model accurately executes BFS, DFS, and Dijkstra's algorithms on graphs with 5-15 nodes
- GPT-4 creates reasonable Tic-Tac-Toe heuristics but fails to play the game due to state memorization issues
- Fine-tuning approach shows only minor improvements in Chain of Thought capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can extract key components of planning domains from textual descriptions
- Mechanism: The model leverages its vast training data to recognize patterns in task descriptions and map them to PDDL constructs (objects, predicates, actions, initial/goal states)
- Core assumption: The textual description contains sufficient detail about the domain structure for the model to infer correct PDDL representations
- Evidence anchors:
  - [abstract]: "GPT-4 can effectively extract key components of planning domains from textual descriptions and generate structured representations suitable for automated planning systems"
  - [section 4]: The cross-the-road example shows GPT-4 generating valid PDDL with correct predicates and actions from a simple text prompt
  - [corpus]: Weak evidence - no corpus papers directly address PDDL generation, though planning-related papers exist
- Break condition: When task complexity exceeds the model's implicit knowledge boundaries, leading to incorrect domain specifications

### Mechanism 2
- Claim: GPT-4 can understand and apply graph search algorithms to find paths in simple graphs
- Mechanism: The model processes algorithm descriptions and graph structures to generate step-by-step traversals that follow the specified algorithm
- Core assumption: The graph size and structure are within the model's working memory capacity for tracking visited nodes and reconstructing paths
- Evidence anchors:
  - [section 5]: GPT-4 successfully applies BFS, DFS, and Dijkstra's algorithm on small graphs (5-15 nodes) with high accuracy
  - [corpus]: Weak evidence - while search-related papers exist, none specifically examine LLMs' algorithmic reasoning capabilities
- Break condition: As graph complexity increases beyond ~15 nodes, the model's accuracy drops significantly due to tracking limitations

### Mechanism 3
- Claim: GPT-4 can generate reasonable heuristics for adversarial planning but cannot execute adversarial search algorithms
- Mechanism: The model uses its knowledge of game evaluation to propose heuristic functions, but lacks the ability to maintain game state and explore the full game tree
- Core assumption: The heuristic generation task is more pattern-matching from examples rather than requiring state tracking
- Evidence anchors:
  - [section 6]: GPT-4 successfully creates a Tic-Tac-Toe heuristic but fails to play the game correctly due to state memorization issues
  - [abstract]: "GPT-4's limitations in adversarial planning due to its inability to memorize previous states and perform adversarial search algorithms"
  - [corpus]: Weak evidence - no corpus papers directly address LLM limitations in adversarial search
- Break condition: When the task requires maintaining and updating game state across multiple turns

## Foundational Learning

- Concept: PDDL syntax and semantics
  - Why needed here: To understand how planning domains are formally represented and what constitutes valid PDDL output
  - Quick check question: What are the mandatory sections in a PDDL domain file?

- Concept: Graph search algorithms (BFS, DFS, Dijkstra)
  - Why needed here: To understand the algorithms GPT-4 claims to execute and how they should produce correct outputs
  - Quick check question: What is the key difference in path optimality guarantees between BFS and DFS?

- Concept: Adversarial planning concepts (Minimax, Monte Carlo Tree Search)
  - Why needed here: To understand why GPT-4 can generate heuristics but not execute adversarial search
  - Quick check question: What fundamental capability does Minimax require that GPT-4 lacks?

## Architecture Onboarding

- Component map: GPT-4 (language model) -> Text prompt (task description) -> Generated PDDL/graph path/heuristic -> Evaluation against ground truth
- Critical path: Prompt formulation -> Model inference -> Output parsing -> Result validation
- Design tradeoffs: Model capability vs. task complexity, zero-shot performance vs. fine-tuning requirements
- Failure signatures: Inconsistent PDDL predicates, incorrect path reconstruction in larger graphs, inability to maintain game state
- First 3 experiments:
  1. Test GPT-4 on PDDL generation for increasingly complex tasks (daily tasks -> board games -> domain-specific)
  2. Evaluate graph search accuracy on graphs of increasing size (5→15→25→35 nodes)
  3. Assess heuristic generation quality for different game types (Tic-Tac-Toe -> Connect Four -> Chess)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can fine-tuning strategies effectively improve large language models' performance on adversarial planning tasks, and what specific fine-tuning approaches would be most effective?
- Basis in paper: [explicit] The paper mentions fine-tuning a domain-specific LLM to improve Chain of Thought capabilities, but the fine-tuned model only showed minor improvements.
- Why unresolved: The paper only attempts one fine-tuning approach (freezing original weights and modifying final layer) with limited success, leaving the question of whether alternative fine-tuning strategies could yield better results.
- What evidence would resolve it: Empirical results comparing multiple fine-tuning approaches (different architectures, training strategies, dataset compositions) on adversarial planning benchmarks.

### Open Question 2
- Question: What is the fundamental limitation preventing large language models from performing adversarial search algorithms like Mini-max or Monte Carlo Tree Search?
- Basis in paper: [explicit] The paper states that "Due to the fact that GPTs are a series of language models for next-word prediction, they can neither understand the state of the game nor search over all the possibilities" and they "cannot memorize the sequence of previous states correctly."
- Why unresolved: While the paper identifies these limitations, it does not investigate whether these are inherent constraints of the language model architecture or could be overcome through architectural modifications or alternative approaches.
- What evidence would resolve it: Experimental results testing whether architectural modifications (memory mechanisms, different pretraining objectives) or alternative formulations could enable effective adversarial search.

### Open Question 3
- Question: How can complex planning and search problems be decomposed into subproblems that large language models can handle effectively?
- Basis in paper: [inferred] The paper notes that "GPT-4 is only capable of simple graph search" but "provides the possibility of decomposing a complex graph into simple graphs and performing graph search."
- Why unresolved: The paper identifies this potential decomposition strategy but does not explore how to systematically decompose complex problems or whether this approach scales to real-world applications.
- What evidence would resolve it: Demonstrations of decomposition algorithms for various planning and search problems, along with empirical validation of their effectiveness on progressively more complex tasks.

## Limitations
- Study relies on GPT-4's zero-shot performance without extensive prompt engineering optimization
- Limited validation on complex, real-world planning problems beyond simple daily tasks
- Graph search experiments do not explore potential mitigation strategies for larger graphs
- Fine-tuning approach shows only minor improvements, suggesting either insufficient training data or architectural limitations

## Confidence

- **High Confidence**: GPT-4's ability to extract planning domains from textual descriptions for simple, daily tasks
- **Medium Confidence**: GPT-4's graph search capabilities on small graphs (5-15 nodes) with simple algorithms
- **Low Confidence**: Claims about GPT-4's fundamental limitations in adversarial planning and the effectiveness of proposed fine-tuning approaches

## Next Checks

1. **Prompt Engineering Study**: Conduct a systematic ablation study testing different prompt formulations, few-shot examples, and instruction tuning approaches to optimize GPT-4's performance on planning tasks.

2. **Graph Decomposition Experiments**: Evaluate whether breaking larger graphs into smaller subgraphs and combining results can extend GPT-4's graph search capabilities beyond the current 15-node limitation.

3. **Architectural Modification Testing**: Test whether integrating external memory mechanisms or tree search algorithms with GPT-4 can overcome its state-tracking limitations in adversarial planning scenarios.