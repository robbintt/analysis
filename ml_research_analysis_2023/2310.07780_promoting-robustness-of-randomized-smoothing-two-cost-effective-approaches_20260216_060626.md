---
ver: rpa2
title: 'Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches'
arxiv_id: '2310.07780'
source_url: https://arxiv.org/abs/2310.07780
tags:
- ensemble
- advmacer
- smoothadv
- macer
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes two cost-effective approaches to improve robustness
  of randomized smoothing classifiers. The first approach, AdvMacer, combines adversarial
  training and robustness certification maximization to achieve up to 124% improvement
  in average certified radius over MACER baseline while being 3x faster to train.
---

# Promoting Robustness of Randomized Smoothing: Two Cost-Effective Approaches

## Quick Facts
- arXiv ID: 2310.07780
- Source URL: https://arxiv.org/abs/2310.07780
- Reference count: 40
- Key outcome: AdvMacer improves certified radius by up to 124% over MACER while training 3x faster; EsbRs ensemble adds 8-15% additional improvement

## Executive Summary
This paper addresses the challenge of improving certified robustness in randomized smoothing classifiers through two novel approaches. The first, AdvMacer, combines adversarial training with robustness certification maximization, achieving significantly better performance than state-of-the-art baselines while reducing training time. The second approach, EsbRs, introduces a post-processing ensemble method that leverages theoretical analysis of variance reduction to further improve certified radii. Both methods are validated across multiple datasets (CIFAR-10, ImageNet, SVHN) and demonstrate substantial improvements in average certified radius while maintaining competitive clean accuracy.

## Method Summary
The paper proposes two complementary approaches to enhance randomized smoothing classifiers. AdvMacer integrates adversarial training with certified radius maximization by optimizing the certified radius on adversarial examples during training, using a combined loss function that balances clean accuracy and certified robustness. EsbRs is a post-processing ensemble method that constructs mixed-model ensembles from different training approaches (e.g., combining AdvMacer and SmoothAdv models) and computes optimal ensemble weights through analytical optimization based on variance-covariance analysis. The certification evaluation uses the standard CERTIFY algorithm with 100,000 samples for accurate radius estimation.

## Key Results
- AdvMacer achieves up to 124% improvement in average certified radius over MACER baseline while training 3x faster
- EsbRs ensemble provides additional 8% improvement over SmoothAdv and 15% over MACER
- Methods demonstrate consistent performance across CIFAR-10, ImageNet, and SVHN datasets with noise levels σ = 0.25, 0.50, 1.00
- Optimal weighted ensembles outperform naive averaging in all tested scenarios

## Why This Works (Mechanism)

### Mechanism 1: AdvMacer combines adversarial training with certification maximization
AdvMacer optimizes certified radius on adversarial examples rather than clean data, forcing the classifier to have large margins at perturbed points while still classifying them correctly. This bridges the gap between robust training and adversarial training by ensuring that adversarial examples generated by PGD are classified correctly, which is necessary for meaningful certified radius improvement.

### Mechanism 2: Mixed-model ensembles reduce variance between different training methods
EsbRs demonstrates that mixed-model ensembles can outperform intra-model ensembles by reducing variance between different training methods. By combining models trained with different approaches (e.g., AdvMacer and SmoothAdv), the ensemble reduces the variance in classification logits between models from different categories more than within the same category, leading to larger certified radii.

### Mechanism 3: Optimal weighted ensembles through analytical optimization
The paper derives an optimization problem that finds optimal weights for ensemble components based on their variance and covariance structure, maximizing the lower bound on top class probability. This analytical approach to weight computation outperforms naive averaging by leveraging the specific variance-covariance structure of model outputs.

## Foundational Learning

- **Concept: Randomized smoothing and certified robustness** - Why needed: This is the foundational technique being improved; understanding how Gaussian noise provides provable robustness guarantees is essential. Quick check: How does Theorem 2.1 from [4] relate the difference in class probabilities to the certified radius?

- **Concept: Adversarial training and PGD-based attacks** - Why needed: Both AdvMacer and SmoothAdv use adversarial training, so understanding how PGD generates adversarial examples and how these examples are used in training is crucial. Quick check: What is the difference between the adversarial examples generated in SmoothAdv versus those used in AdvMacer?

- **Concept: Ensemble methods and variance reduction** - Why needed: EsbRs is fundamentally an ensemble method, so understanding how ensembles reduce variance and improve generalization is key to understanding its effectiveness. Quick check: Why does reducing variance in classification logits lead to larger certified radii in randomized smoothing?

## Architecture Onboarding

- **Component map**: Base classifier training pipeline (with options for SmoothAdv, MACER, or AdvMacer) -> Ensemble construction module (EsbRs with optimal weight computation) -> Certification evaluation system (CERTIFY algorithm) -> Hyperparameter management system

- **Critical path**: 1. Train base models using AdvMacer (or other methods) 2. Estimate variance/covariance structure of model outputs 3. Compute optimal ensemble weights using Algorithm 2 4. Construct ensemble and evaluate certified radius 5. Iterate on hyperparameters if needed

- **Design tradeoffs**: Training time vs. certified radius (AdvMacer achieves better ACR with less training time than MACER); Ensemble diversity vs. complexity (mixed-model ensembles may work better but require careful weight optimization); Computational cost of certification (larger N in CERTIFY gives more accurate estimates but increases computation time)

- **Failure signatures**: Decreased ACR after ensemble (likely variance assumption violated: αi < βi); No improvement over baselines (hyperparameters may be poorly chosen: λ, γ, T, m); Slow convergence (learning rate or batch size may need adjustment)

- **First 3 experiments**: 1. Implement AdvMacer with default hyperparameters (λ=12.0, γ=8.0, T=2, m=8) on CIFAR-10 with σ=0.5 and compare ACR to SmoothAdv baseline; 2. Create a simple equal-weight ensemble of two AdvMacer models and verify ACR improvement over single model; 3. Implement optimal weight computation for a 2-model ensemble (one AdvMacer, one SmoothAdv) and verify mixed-model ensemble outperforms intra-model ensemble

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of AdvMacer and EsbRs scale with larger datasets or more complex architectures beyond ResNet-110? The paper demonstrates effectiveness on CIFAR-10, ImageNet, and SVHN with ResNet-110, but does not explore scaling to larger models or datasets.

### Open Question 2
What is the theoretical limit of certified radius improvement achievable through model ensemble techniques like EsbRs? The paper introduces EsbRs and provides theoretical analysis, but does not explore the upper bounds of improvement.

### Open Question 3
How sensitive are the results of AdvMacer and EsbRs to the choice of hyperparameters, and is there a systematic way to optimize them? The paper mentions specific hyperparameter choices but does not provide a systematic method for optimization or discuss sensitivity.

## Limitations
- The core assumption that adversarial examples must be correctly classified for AdvMacer to improve certified radius lacks theoretical guarantees in all scenarios
- Variance reduction mechanism in EsbRs relies on untested assumptions about model output distributions across different architectures
- Optimal weight computation becomes computationally challenging for larger ensembles due to variance-covariance matrix estimation requirements

## Confidence
- **High confidence**: AdvMacer achieves faster training with improved certified radius compared to MACER baseline (supported by ablation studies and quantitative metrics)
- **Medium confidence**: Mixed-model ensembles consistently outperform intra-model ensembles across datasets (supported by experimental results but limited theoretical guarantees)
- **Low confidence**: The optimal weight computation algorithm always produces weights that maximize certified radius (theoretical derivation exists but practical limitations acknowledged)

## Next Checks
1. Test AdvMacer on adversarial examples that lie exactly at the boundary of certified radii to verify the assumption that correct classification at perturbed points is necessary for radius improvement
2. Systematically compare variance within model types versus covariance between types across different training methods and architectures to validate the fundamental assumption behind EsbRs effectiveness
3. Implement the optimal weight computation for ensembles with k=3,4,5 models to test whether the algorithm remains tractable and whether performance gains continue to scale with ensemble size