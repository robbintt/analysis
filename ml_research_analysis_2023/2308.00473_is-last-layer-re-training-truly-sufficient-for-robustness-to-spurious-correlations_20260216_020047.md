---
ver: rpa2
title: Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?
arxiv_id: '2308.00473'
source_url: https://arxiv.org/abs/2308.00473
tags:
- spurious
- group
- layer
- accuracy
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether last-layer retraining is truly
  sufficient for robustness to spurious correlations. The authors examine Deep Feature
  Reweighting (DFR), a method that retrains only the final layer of a classification
  model using a small group-balanced dataset.
---

# Is Last Layer Re-Training Truly Sufficient for Robustness to Spurious Correlations?

## Quick Facts
- arXiv ID: 2308.00473
- Source URL: https://arxiv.org/abs/2308.00473
- Reference count: 7
- Primary result: Last-layer retraining (DFR) significantly improves worst-group accuracy but does not completely eliminate spurious correlations

## Executive Summary
This paper investigates whether last-layer retraining is truly sufficient for robustness to spurious correlations by examining Deep Feature Reweighting (DFR), a method that retrains only the final layer of a classification model using a small group-balanced dataset. While DFR significantly improves worst-group accuracy on both benchmark (Waterbirds) and real-world medical (ISIC Skin) datasets, qualitative analysis reveals that it does not completely eliminate spurious correlations. Activation maps show that DFR still focuses on spurious features to some extent, and certain neurons respond to both core and spurious features simultaneously.

## Method Summary
The Deep Feature Reweighting (DFR) method involves two stages: first, training an ERM base model with a pre-trained ResNet50 backbone, then retraining only the final layer using logistic regression on a small group-balanced subset. The method assumes that ERM models learn core features sufficiently well, so correcting spurious correlations only requires reweighting the last layer's features rather than full model retraining. The approach prunes irrelevant connections in the final layer, creating a sparse weight matrix that reduces the impact of spurious features while maintaining classification performance.

## Key Results
- DFR achieves worst-group accuracy of 94.5% on Waterbirds dataset compared to 68.5% for ERM baseline
- On ISIC Skin dataset, DFR improves worst-group accuracy from 71.4% (ERM) to 88.8%
- CAM visualizations reveal DFR still exhibits spurious feature activation, with neurons responding to both core and spurious features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DFR improves worst-group accuracy by reweighting last-layer features using a small group-balanced dataset
- Mechanism: ERM learns core features sufficiently well, so retraining only the final layer with balanced data corrects spurious correlations without full model retraining
- Core assumption: The feature representation learned by ERM is already robust to spurious features and only needs correction at the classification stage
- Evidence anchors:
  - [abstract] "DFR only needs to retrain the last layer of the classification model with a small group-balanced data set."
  - [section] "Based on the main argument that ERM models can learn core features sufficiently well, DFR only needs to retrain the last layer of the classification model with a small group-balanced data set."
  - [corpus] Found related work confirming DFR's effectiveness on benchmark datasets but no direct mechanism validation
- Break condition: If ERM fails to learn robust core features, last-layer retraining cannot correct the problem

### Mechanism 2
- Claim: DFR prunes irrelevant connections in the last layer to reduce spurious feature impact
- Mechanism: During retraining, logistic regression identifies and downweights neurons responding to spurious features, creating a sparse weight matrix
- Core assumption: Spurious features activate distinct neurons that can be identified and eliminated through group-balanced retraining
- Evidence anchors:
  - [section] "We observe an unexpectedly high percentage of connections with zero weight in DFR (96% for ISIC Skin and 65% for Waterbirds, on average across five runs for each dataset)."
  - [section] "DFR effectively removes the major impact of spurious correlations as expected."
  - [corpus] Related work on pruning techniques shows similar parameter reduction without accuracy loss
- Break condition: If spurious features are distributed across many neurons or mixed with core features, pruning becomes ineffective

### Mechanism 3
- Claim: DFR maintains some spurious correlation sensitivity because certain neurons respond to both core and spurious features
- Mechanism: The method cannot distinguish neurons that activate on both lesion and patch features, so these mixed-response neurons retain spurious correlation influence
- Core assumption: Neurons in the feature representation layer can encode both core and spurious features simultaneously
- Evidence anchors:
  - [section] "There are neurons with complex responses, which DFR is incapable of distinguishing. It appears that DFR partially selects this type of neurons which can respond to both, lesion and color patches."
  - [section] "This finding suggests that even though DFR improves the worst-group accuracy by a large margin, its reasoning may still be flawed."
  - [corpus] No corpus evidence found for this mixed-response mechanism
- Break condition: If all neurons could be cleanly separated into core-only or spurious-only categories, this mechanism would not apply

## Foundational Learning

- Concept: Group robustness and spurious correlations
  - Why needed here: The entire paper addresses how to handle model failures due to spurious correlations affecting different groups
  - Quick check question: What is the difference between core features and spurious features in classification tasks?

- Concept: Last-layer retraining and feature reweighting
  - Why needed here: DFR specifically targets only the final classification layer rather than full model retraining
  - Quick check question: Why might retraining only the last layer be more efficient than full model retraining?

- Concept: Class activation maps (CAM) for interpretability
  - Why needed here: The paper uses CAM to visualize whether models focus on correct vs spurious features
  - Quick check question: How do activation maps help identify which image regions a model uses for classification?

## Architecture Onboarding

- Component map: Pre-trained ResNet50 → Feature representation layer (d neurons) → Final classification layer (sigmoid neuron) → Logistic regression for retraining
- Critical path: ERM training → Feature extraction → Group-balanced dataset creation → Logistic regression retraining → Evaluation
- Design tradeoffs: Speed and efficiency of last-layer retraining vs incomplete spurious correlation removal; simplicity vs need for group-balanced validation data
- Failure signatures: High worst-group accuracy improvement but persistent spurious feature activation in CAM visualizations; significant last-layer weight pruning but incomplete spurious feature elimination
- First 3 experiments:
  1. Reproduce DFR on Waterbirds dataset to verify worst-group accuracy improvements
  2. Generate and compare CAM visualizations between ERM and DFR models on ISIC Skin dataset
  3. Analyze neuron-level activation patterns to identify core-only vs spurious-only vs mixed-response neurons

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the effectiveness of DFR vary significantly across different types of spurious correlations (e.g., background vs. object presence vs. medical imaging artifacts)?
- Basis in paper: [explicit] The paper demonstrates DFR's effectiveness on two datasets with different spurious correlation types (Waterbirds with background, ISIC Skin with colored patches) but notes varying results between them
- Why unresolved: The paper only examines two specific types of spurious correlations in different domains, limiting generalizability to other correlation types or domains
- What evidence would resolve it: Systematic testing of DFR across multiple datasets with diverse spurious correlation types (background, object presence, medical artifacts, lighting conditions, etc.) and comparison of effectiveness metrics

### Open Question 2
- Question: What is the minimum group-balanced dataset size required for DFR to effectively mitigate spurious correlations?
- Basis in paper: [inferred] The paper mentions DFR requires "a small group-balanced data set" but doesn't explore how the size of this dataset affects performance
- Why unresolved: The paper doesn't investigate the relationship between group-balanced dataset size and DFR effectiveness, leaving uncertainty about scalability and practical deployment requirements
- What evidence would resolve it: Experiments varying the size of group-balanced datasets while measuring worst-group accuracy and comparing to baseline performance

### Open Question 3
- Question: Can DFR's effectiveness be improved by incorporating domain-specific knowledge into the neuron selection process?
- Basis in paper: [explicit] The paper suggests that "future research incorporate professional medical knowledge for deeper comprehension of reasoning" in the ISIC Skin domain
- Why unresolved: The paper only suggests this possibility without testing it, leaving open whether domain expertise would improve DFR's ability to identify core vs. spurious features
- What evidence would resolve it: Comparative experiments applying DFR with and without domain-specific feature selection criteria, measuring improvements in worst-group accuracy and spurious correlation elimination

### Open Question 4
- Question: Are there alternative pruning methods that could better identify and eliminate spurious features than DFR's logistic regression approach?
- Basis in paper: [inferred] The paper notes that DFR "fails to eliminate all spurious correlations" and suggests "more advanced methods" may be needed
- Why unresolved: The paper doesn't explore whether different pruning or feature selection methods could outperform DFR's current approach of retraining only the last layer
- What evidence would resolve it: Comparative studies testing DFR against alternative pruning methods (structured pruning, magnitude-based pruning, etc.) on multiple datasets, measuring worst-group accuracy and spurious feature elimination

## Limitations
- DFR improves worst-group accuracy but does not completely eliminate spurious correlations, as evidenced by CAM visualizations showing continued focus on spurious features
- The study only examines two datasets (Waterbirds and ISIC Skin), limiting generalizability across different domains and spurious correlation types
- The analysis of mixed-response neurons is based on qualitative visual inspection rather than quantitative metrics for measuring spurious correlation strength

## Confidence
- Evidence quality: Medium - The qualitative CAM analysis and neuron activation patterns provide compelling evidence, but mixed-response findings lack quantitative validation
- Method validity: Medium - DFR's effectiveness on worst-group accuracy is well-established, but the claim of "truly sufficient" robustness appears overstated
- Generalizability: Low - Limited to two datasets with specific types of spurious correlations, making broader claims uncertain

## Next Checks
1. Replicate DFR experiments on additional datasets with different spurious correlation types to assess generalizability
2. Develop quantitative metrics for measuring remaining spurious correlation strength beyond accuracy scores
3. Investigate the relationship between group-balanced dataset size and DFR effectiveness through systematic size variation experiments