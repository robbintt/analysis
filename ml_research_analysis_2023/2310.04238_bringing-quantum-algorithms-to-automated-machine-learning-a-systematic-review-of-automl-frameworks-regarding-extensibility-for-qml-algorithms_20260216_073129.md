---
ver: rpa2
title: 'Bringing Quantum Algorithms to Automated Machine Learning: A Systematic Review
  of AutoML Frameworks Regarding Extensibility for QML Algorithms'
arxiv_id: '2310.04238'
source_url: https://arxiv.org/abs/2310.04238
tags:
- frameworks
- uni00000048
- automl
- framework
- uni0000004c
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study systematically evaluates AutoML frameworks for their
  extensibility to Quantum Machine Learning (QML) algorithms. A four-phase selection
  approach assesses frameworks against hard and soft criteria, including community
  activity, ML support, and quantum-specific requirements.
---

# Bringing Quantum Algorithms to Automated Machine Learning: A Systematic Review of AutoML Frameworks Regarding Extensibility for QML Algorithms

## Quick Facts
- arXiv ID: 2310.04238
- Source URL: https://arxiv.org/abs/2310.04238
- Reference count: 17
- Primary result: Ray and AutoGluon selected as optimal low- and high-level AutoML frameworks for QML extensibility

## Executive Summary
This study systematically evaluates AutoML frameworks for their extensibility to Quantum Machine Learning (QML) algorithms through a four-phase multi-criteria selection approach. The research identifies Ray and AutoGluon as the most suitable frameworks for integrating quantum algorithms, balancing technical requirements with practical usability. The methodology combines objective hard criteria with subjective soft criteria, validated through industrial use-case studies across classification, regression, and forecasting tasks.

## Method Summary
The paper employs a systematic four-phase selection methodology to identify AutoML frameworks suitable for QML integration. Phase 1 establishes a market overview of open-source frameworks, Phase 2 applies hard criteria (active development, open-source status, Python interface) to filter candidates, Phase 3 ranks remaining frameworks using soft criteria (ML backend support, search space size, optimizer variety), and Phase 4 validates selections through use-case studies with industry partners. The approach culminates in selecting Ray for low-level optimization needs and AutoGluon for high-level pipeline synthesis, with QML integration planned via wrapper libraries.

## Key Results
- Ray and AutoGluon identified as optimal frameworks through systematic multi-criteria evaluation
- Four-phase selection approach successfully narrows from broad market overview to final selection
- QML integration feasible via wrapper libraries without requiring native framework modification
- Use-case studies across classification, regression, and forecasting validate framework performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The four-phase multi-criteria selection approach systematically filters AutoML frameworks by aligning them with both hard and soft criteria, enabling structured choice balancing technical fitness and real-world applicability.
- Mechanism: Begins with broad market overview, applies hard criteria (active development, open-source, Python interface) to exclude unsuitable candidates, then ranks remaining frameworks using soft criteria (ML backend support, search space size, optimizer variety) validated via use-case studies. This phased narrowing reduces noise and focuses selection on frameworks meeting both baseline and nuanced needs.
- Core assumption: Framework attributes can be meaningfully decomposed into objective and subjective dimensions independently rankable.
- Evidence anchors: [abstract] "systematic selection on a multi-phase, multi-criteria approach" and "hard and soft criteria regarding their software and ML attributes"
- Break condition: If hard criteria are mis-specified or soft criteria lack differentiation, framework ranking could misalign with actual use-case needs.

### Mechanism 2
- Claim: Ray and AutoGluon selected because they satisfy both high-level and low-level AutoML abstraction needs while being extensible for QML via wrapper libraries.
- Mechanism: Ray offers flexible, performant optimization (CASH formulation) and broad backend support, suitable for low-level automation where user provides structure. AutoGluon offers high-level pipeline synthesis and ensemble construction, abstracting preprocessing and algorithm selection. Both are open-source, well-documented, with active communities allowing quantum algorithm integration without modifying core frameworks.
- Core assumption: QML integration can be achieved via wrapper libraries without native support, provided framework is modular and supports custom pipelines.
- Evidence anchors: [abstract] "we select Ray and AutoGluon as the suitable low- and high-level frameworks respectively"
- Break condition: If quantum-specific requirements (hardware constraints, backend queuing) cannot be mapped onto wrapper-based integration, selection may fail.

### Mechanism 3
- Claim: Use-case studies with industry partners validate framework performance and guide final selection by exposing practical constraints like resource consumption, ease of use, and model quality.
- Mechanism: Four industrial use-cases (classification, regression, forecasting, image tasks) implemented using candidate frameworks. Developers evaluate each framework on predictive quality, training/inference times, resource usage, and configurability. Expert interviews provide qualitative feedback on usability and alignment with domain needs, informing final choice.
- Core assumption: Real-world use-cases reveal practical strengths and weaknesses not evident from feature checklists alone.
- Evidence anchors: [abstract] "use-case studies across classification, regression, and forecasting tasks" and "evaluation feedback during the use-case study"
- Break condition: If use-cases are not representative of target QML scenarios, validation may not generalize to quantum-specific workflows.

## Foundational Learning

- Concept: AutoML problem formulation hierarchy (HPO → AS → CASH → PSO)
  - Why needed here: Framework selection depends on understanding which level of automation each framework supports; low-level tools focus on HPO/CASH while high-level tools address full PSO.
  - Quick check question: What is the difference between HPO and CASH in AutoML, and why does this distinction matter for framework selection?

- Concept: Quantum Computing (QC) constraints in NISQ era
  - Why needed here: Selection process must consider quantum-specific requirements like noise handling, limited qubits, decoherence, and backend queuing, which influence how frameworks can be extended.
  - Quick check question: What are the main hardware and algorithmic challenges when integrating QML into AutoML pipelines?

- Concept: Multi-criteria decision analysis (MCDA)
  - Why needed here: Selection approach is essentially an MCDA problem; understanding how to weigh hard vs. soft criteria and aggregate scores is essential for interpreting framework ranking.
  - Quick check question: How do hard and soft criteria differ in their impact on software selection, and how should they be combined?

## Architecture Onboarding

- Component map: Market overview -> Hard criteria filtering -> Soft criteria ranking -> Use-case validation -> Final framework selection
- Critical path:
  1. Collect market overview and hard criteria scores
  2. Apply hard criteria filters → long list
  3. Apply soft criteria ranking → short list
  4. Run use-case implementations with short list
  5. Conduct expert interviews → final selection
  6. Design QML wrapper integration for selected frameworks
- Design tradeoffs:
  - Using wrappers vs. native QML support: wrappers avoid modifying core frameworks but may limit deep integration; native support would be more seamless but requires framework modification.
  - Low-level vs. high-level: low-level gives fine-grained control but requires more ML expertise; high-level abstracts complexity but may be less flexible for QML.
  - Single vs. dual framework approach: using both Ray and AutoGluon covers abstraction spectrum but increases integration complexity.
- Failure signatures:
  - Framework fails hard criteria (e.g., inactive development, wrong license) → excluded early
  - Soft criteria ranking ambiguous → ties in short list
  - Use-case performance inconsistent across tasks → question framework generality
  - QML wrapper integration breaks due to incompatible pipeline stages → redesign needed
- First 3 experiments:
  1. Implement a simple HPO task (e.g., SVM hyperparameter tuning) using Ray to validate low-level optimization integration.
  2. Build a complete classification pipeline using AutoGluon on tabular data to test high-level automation and preprocessing.
  3. Create a QML wrapper for a quantum kernel method (e.g., QSVM) and integrate it into AutoGluon's pipeline to assess quantum extensibility.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the integration of QML algorithms into AutoML frameworks affect the computational efficiency and accuracy of ML pipelines compared to classical algorithms?
- Basis in paper: [inferred] The paper discusses the potential of QML algorithms to expedite hyperparameter optimization and improve pipeline performance, but does not provide empirical data on the actual impact.
- Why unresolved: The study focuses on framework selection and theoretical integration possibilities rather than conducting experiments to measure performance differences between classical and quantum-enhanced pipelines.
- What evidence would resolve it: Empirical studies comparing the computational efficiency and accuracy of ML pipelines using QML algorithms versus classical algorithms within AutoML frameworks.

### Open Question 2
- Question: What are the specific challenges and limitations of implementing QML algorithms in existing AutoML frameworks, and how can they be addressed?
- Basis in paper: [explicit] The paper mentions challenges such as noise, limited qubits, short circuit depths, and the need for feature reduction and error mitigation in the NISQ era.
- Why unresolved: While the paper identifies these challenges, it does not provide detailed solutions or strategies for overcoming them in the context of AutoML.
- What evidence would resolve it: Detailed case studies or technical reports demonstrating successful integration of QML algorithms into AutoML frameworks, addressing the identified challenges.

### Open Question 3
- Question: How do different quantum computing backends (e.g., IBM Qiskit, Xanadu’s PennyLane) impact the performance and feasibility of QML algorithms in AutoML frameworks?
- Basis in paper: [inferred] The paper mentions the need to support various quantum computing backends but does not explore the impact of different backends on QML algorithm performance.
- Why unresolved: The study does not compare or analyze the performance of QML algorithms across different quantum computing backends.
- What evidence would resolve it: Comparative studies evaluating the performance of QML algorithms using different quantum computing backends within AutoML frameworks.

### Open Question 4
- Question: What are the implications of quantum-specific preprocessing steps, such as feature reduction and error mitigation, on the overall workflow of AutoML frameworks?
- Basis in paper: [inferred] The paper suggests that quantum-specific preprocessing steps are necessary but does not delve into their implications on the AutoML workflow.
- Why unresolved: The study identifies the need for these preprocessing steps but does not explore how they integrate into or affect the existing AutoML pipeline.
- What evidence would resolve it: Detailed workflow analyses or simulations showing how quantum-specific preprocessing steps are incorporated into AutoML frameworks and their impact on pipeline efficiency and accuracy.

## Limitations

- Framework selection methodology relies heavily on subjective scoring for soft criteria and qualitative use-case feedback, introducing potential bias
- Feasibility of wrapper-based QML integration is assumed but not demonstrated through empirical validation
- Paper does not address potential quantum-specific limitations that may prevent seamless integration into classical AutoML pipelines

## Confidence

- **High confidence**: The four-phase selection approach is logically structured and follows established multi-criteria decision analysis principles. The hard criteria filtering is objective and verifiable.
- **Medium confidence**: The soft criteria ranking and use-case study methodology are reasonable but depend on subjective judgment and limited sample size. The selection of Ray and AutoGluon appears justified by the described criteria.
- **Low confidence**: The feasibility of wrapper-based QML integration is assumed but not demonstrated. The paper does not address potential quantum-specific limitations that may prevent seamless integration into classical AutoML pipelines.

## Next Checks

1. Implement a proof-of-concept QML algorithm (e.g., quantum kernel SVM) as a wrapper in both Ray and AutoGluon, measuring integration complexity and runtime overhead.
2. Conduct a sensitivity analysis of the framework scoring by varying soft criteria weights to test robustness of the selection outcome.
3. Validate the framework selection by applying it to a quantum-specific use-case (e.g., quantum chemistry property prediction) and measuring performance against classical AutoML baselines.