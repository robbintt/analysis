---
ver: rpa2
title: 'TOP-Training: Target-Oriented Pretraining for Medical Extractive Question
  Answering'
arxiv_id: '2310.16995'
source_url: https://arxiv.org/abs/2310.16995
tags:
- corpus
- covid-qa
- bert
- language
- roberta
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of domain adaptation for extractive
  question answering in specialized domains like biomedicine. The authors propose
  TOP-Training, a target-oriented pretraining approach that generates synthetic domain-specific
  corpora using large language models (LLMs) like Galactica, based on entities extracted
  from target QA datasets.
---

# TOP-Training: Target-Oriented Pretraining for Medical Extractive Question Answering

## Quick Facts
- arXiv ID: 2310.16995
- Source URL: https://arxiv.org/abs/2310.16995
- Reference count: 17
- This paper proposes a method to pretrain models for extractive QA in specialized domains using synthetic corpora generated by LLMs.

## Executive Summary
This paper introduces TOP-Training, a novel approach for domain adaptation in medical extractive question answering. The method uses large language models like Galactica to generate synthetic domain-specific corpora based on entities extracted from target QA datasets. This synthetic data is then used to pretrain bidirectional transformer models before fine-tuning on the target dataset. Experiments on COVID-QA and RadQA datasets demonstrate that TOP-Training achieves state-of-the-art performance on COVID-QA and improves results on RadQA compared to existing domain-specific models, even when trained on much smaller corpora.

## Method Summary
TOP-Training involves extracting named entities from target medical QA datasets using NER tools like scispaCy. These entities are used to generate synthetic texts via LLMs (Galactica) with prompts tailored to each domain (e.g., "Title: [entity]" for COVID-QA). The resulting synthetic corpus is used to pretrain BERT/RoBERTa models, which are then fine-tuned on the target QA datasets. This approach does not require large unlabeled datasets from the target domain and leverages bidirectional transformers over autoregressive models for better extractive QA performance.

## Key Results
- TOP-Training achieves state-of-the-art performance on COVID-QA with RoBERTa.
- Improves results on RadQA compared to existing domain-specific models.
- Demonstrates effectiveness with a 67.4 MB synthetic corpus versus the 3.5B word corpus used by LUKE.
- Highlights limitations of autoregressive LLMs for extractive QA tasks.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic corpora generated by LLMs can teach bidirectional transformers domain-specific writing styles even when the LLMs have never seen such data.
- Mechanism: Galactica is prompted with entities from the target dataset to generate synthetic text that mimics the writing style of the target domain.
- Core assumption: The generated text sufficiently matches the style and topical content of the target domain to improve model performance.
- Evidence anchors:
  - [abstract]: "Specifically, for a target Medical-EQA dataset, we extract its entities and leverage large language models (LLMs) to generate synthetic texts containing those entities"
  - [section]: "we create prompts for the identified entities to generate contexts mimicking the respective datasets"
  - [corpus]: Weak evidence - the paper demonstrates performance improvements but doesn't provide quantitative analysis of style similarity between generated and target texts.
- Break condition: Generated text fails to capture essential domain characteristics (terminology, structure, tone) making it ineffective for pretraining.

### Mechanism 2
- Claim: Bidirectional transformers (BERT/RoBERTa) outperform autoregressive models for extractive question answering in specialized domains.
- Mechanism: Bidirectional models can extract spans from text based on contextual information from both directions, while autoregressive models generate text which may hallucinate answers.
- Core assumption: The task of extractive QA benefits more from bidirectional context than from the generative capabilities of autoregressive models.
- Evidence anchors:
  - [abstract]: "Overall, our contributions are threefold: (i) TOP-Training, a new pretraining technique to effectively adapt LLMs to better solve a target problem, (ii) TOP-Training has a wide application scope because it does not require the target problem to have a large set of unlabeled data, and (iii) our experiments highlight the limitations of autoregressive LLMs, emphasizing TOP-Training as a means to unlock the true potential of bidirectional LLMs."
  - [section]: "Additionally, their autoregressive architecture is not well-suited for extractive QA as they are designed to synthesize new text rather than extract spans from given text"
  - [corpus]: Weak evidence - the paper shows decoder models perform poorly but doesn't systematically compare different architectures on the same pretraining approach.
- Break condition: The extractive QA task fundamentally requires generation rather than extraction, making autoregressive models superior.

### Mechanism 3
- Claim: Synthetic corpora can be more effective than real domain data for pretraining when the target domain has limited unlabeled data.
- Mechanism: Galactica generates a synthetic corpus specifically tailored to the target dataset, avoiding noise from irrelevant domain content that would be present in a general domain corpus.
- Core assumption: A smaller, highly targeted synthetic corpus is more beneficial than a larger general domain corpus for the specific downstream task.
- Evidence anchors:
  - [abstract]: "This synthetic data is then used to pretrain bidirectional transformer models (BERT/RoBERTa) before fine-tuning on the target dataset."
  - [section]: "our approach confines training to the required concepts"
  - [corpus]: Moderate evidence - the paper shows RoBERTa achieves SOTA on COVID-QA with a 67.4 MB synthetic corpus versus the 3.5B word corpus used by LUKE.
- Break condition: The synthetic corpus contains factual errors or hallucinated content that degrades model performance.

## Foundational Learning

- Concept: Domain adaptation
  - Why needed here: The paper addresses the challenge of adapting models trained on general data to specialized medical domains where terminology and writing styles differ significantly.
  - Quick check question: What is the difference between domain adaptation and task adaptation in NLP?

- Concept: Knowledge distillation
  - Why needed here: The approach uses a large LLM (Galactica) to generate synthetic data that "distills" domain knowledge into smaller bidirectional models.
  - Quick check question: How does knowledge distillation differ from traditional pretraining in terms of data flow?

- Concept: Named Entity Recognition (NER)
  - Why needed here: NER is used to extract entities from the target dataset to generate synthetic corpora.
  - Quick check question: What are the potential issues with using NER to identify entities for synthetic data generation?

## Architecture Onboarding

- Component map: Synthetic corpus generation (Galactica + entity extraction) → Targeted pretraining (BERT/RoBERTa + synthetic corpus) → Fine-tuning (SQuAD → target dataset)
- Critical path: Entity extraction → Prompt engineering → Corpus generation → Model pretraining → Fine-tuning
- Design tradeoffs: Smaller targeted corpus vs. larger general domain corpus; bidirectional vs. autoregressive models; synthetic vs. real domain data
- Failure signatures: Poor performance despite synthetic data generation suggests issues with prompt engineering or corpus quality; model instability during pretraining may indicate learning rate or batch size issues
- First 3 experiments:
  1. Generate synthetic corpus using basic prompt ("Title: [entity]") and verify output quality
  2. Pretrain BERT on synthetic corpus and evaluate on SQuAD to check if pretraining was effective
  3. Fine-tune pretrained model on target dataset and compare to baseline model performance

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but based on the limitations section, potential open questions include:
- How to effectively integrate fact-checking mechanisms to eliminate inaccurate information in synthetic corpora
- Whether the approach generalizes to non-biomedical domains
- The optimal size and composition of synthetic corpora for different domain adaptation tasks

## Limitations
- The paper acknowledges that corpus generation requires significant computational resources (8 GPUs) which may be a barrier for some users
- The approach has only been demonstrated for biomedical domains; applicability to other specialized domains like finance or law is not established
- The synthetic data generation process relies on the LLM not hallucinating or generating incorrect information, which is difficult to verify at scale
- The paper doesn't provide quantitative analysis of how closely the synthetic corpus matches the target domain's writing style

## Confidence

- **High confidence**: The experimental results showing performance improvements on COVID-QA and RadQA datasets are directly measured and reproducible.
- **Medium confidence**: The claim that bidirectional models outperform autoregressive models for extractive QA is supported by results but lacks systematic ablation studies across different architectures and pretraining approaches.
- **Low confidence**: The assertion that synthetic corpora are more effective than real domain data is based on comparisons with limited baselines and doesn't account for potential hallucination in generated text.

## Next Checks
1. **Corpus Quality Analysis**: Conduct a quantitative comparison between synthetic and real domain texts using metrics like perplexity, semantic similarity, and terminology overlap to validate that generated texts match target domain characteristics.
2. **Cross-Domain Generalization**: Test TOP-Training on non-biomedical domains (e.g., legal or financial QA datasets) to assess whether the approach generalizes beyond the demonstrated use cases.
3. **Synthetic Data Validation**: Implement a fact-checking mechanism for synthetic texts by cross-referencing generated content with reliable sources to measure hallucination rates and their impact on downstream performance.