---
ver: rpa2
title: 'Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly
  Supervised Semantic Segmentation'
arxiv_id: '2308.11052'
source_url: https://arxiv.org/abs/2308.11052
tags:
- saliency
- saliencies
- maps
- image
- cams
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts a comprehensive study comparing saliency maps
  and class activation maps (CAMs) for weakly supervised semantic segmentation (WS3).
  While CAMs are effective at highlighting discriminative regions, they tend to miss
  non-discriminative regions crucial for segmentation.
---

# Beyond Discriminative Regions: Saliency Maps as Alternatives to CAMs for Weakly Supervised Semantic Segmentation

## Quick Facts
- arXiv ID: 2308.11052
- Source URL: https://arxiv.org/abs/2308.11052
- Reference count: 27
- Primary result: Saliency maps outperform CAMs in recovering non-discriminative regions for weakly supervised semantic segmentation

## Executive Summary
This paper compares saliency maps and class activation maps (CAMs) for weakly supervised semantic segmentation (WS3). While CAMs effectively highlight discriminative regions, they often miss non-discriminative regions critical for complete segmentation. Saliency maps, which measure pixel-level contributions to classification, show promise in recovering these missing regions. The authors introduce novel evaluation metrics and demonstrate through extensive experiments that saliency maps with random cropping aggregation significantly outperform CAMs in recovering non-discriminative regions across benchmark datasets.

## Method Summary
The study fine-tunes ResNet50 models on MNIST, PASCAL VOC, and MS COCO datasets, generating both CAMs and saliency maps for weakly supervised segmentation. CAMs are produced using weighted activation maps, while saliency maps are computed via gradient attribution. The method applies various post-processing techniques (smoothing, superpixel assignment) and stochastic aggregation methods (SmoothGrad, BinaryMask, random cropping) to improve saliency map quality. Evaluation uses mIoU and novel metrics (NDR-Recall, DR-Recall, Foreground Precision) to assess segmentation performance and discriminative/non-discriminative region recovery.

## Key Results
- Saliency maps consistently outperform CAMs in recovering non-discriminative regions across all datasets
- Random cropping aggregation significantly improves saliency performance without requiring model fine-tuning
- Larger contribution windows (via increased kernel size) enable better non-discriminative region recovery
- Post-processing techniques like superpixel-based smoothing enhance segmentation quality

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Saliency maps inherently recover non-discriminative regions (NDRs) that CAMs miss.
- **Mechanism**: Saliency maps compute pixel-level gradients of the classification score with respect to input pixels, capturing contributions from all regions that affect the prediction, not just discriminative features.
- **Core assumption**: Gradients propagate through the entire network and can highlight regions outside the discriminative set if they still contribute to classification.
- **Evidence anchors**:
  - [abstract] "attribution methods such as saliency maps provide an alternative approach for assigning a score to every pixel based on its contribution to the classification prediction"
  - [section 3] "the important distinction is that for CAMs, the DR/NDR depends on the values of the activation map A(i,j), while for SMs, the HSR/LSR depends on the gradient ∂GAP(A)/∂I |(i,j)"
- **Break condition**: If the network has zero gradients for non-discriminative regions due to architectural constraints (e.g., small contribution windows), saliency maps will fail to recover them.

### Mechanism 2
- **Claim**: Random cropping improves saliency map quality by disrupting spatial structure and aggregating diverse local views.
- **Mechanism**: Random cropping acts as a spatial perturbation that forces the classifier to focus on different sub-regions, and aggregating these saliency maps weighted by classification confidence produces a more stable, noise-reduced output.
- **Core assumption**: The classifier's attention is distributed across different crops, and the aggregation preserves the most salient regions while reducing noise.
- **Evidence anchors**:
  - [section 7.1] "random cropping can also be viewed as a perturbation technique where the individual crops disintegrate the spatial structure of the input image"
  - [section 7] "random cropping-based aggregated saliencies employ the 'Model-org' classifier to compute the saliencies, showing that random cropping does not require the classifier to be finetuned on additional perturbations to perform well"
- **Break condition**: If crops are too small or too large relative to object size, or if the classifier is invariant to spatial perturbations, aggregation gains diminish.

### Mechanism 3
- **Claim**: The contribution window size determines the extent of NDR recovery in saliency maps.
- **Mechanism**: Larger convolutional kernels increase the spatial extent of gradient influence from input pixels to final activations, allowing non-activated pixels to still receive gradient signals if they fall within the contribution window of activated pixels.
- **Core assumption**: Gradients from activated pixels can propagate back to non-activated regions if their contribution windows overlap.
- **Evidence anchors**:
  - [section 3.2] "we can show that if the contribution window of a non-activated pixel is smaller than its distance from an activated pixel, it will have 0 gradients. However, this is practically not likely as the contribution window size generally grows linearly with the depth of ConvNets"
  - [section 5.1] "as the contribution window expands (achieved by increasing the F×F kernel size), saliencies can progressively encompass more NDRs"
- **Break condition**: If kernels are 1x1 or contribution windows are artificially constrained, NDR recovery will be minimal.

## Foundational Learning

- **Concept**: Difference between activation maps and attribution maps
  - **Why needed here**: Understanding why CAMs and saliency maps behave differently is central to the paper's contribution.
  - **Quick check question**: What is the key distinction between how CAMs and saliency maps assign scores to pixels?

- **Concept**: Contribution window in convolutional networks
  - **Why needed here**: Explains how gradients propagate back to input space and why larger kernels help recover NDRs.
  - **Quick check question**: How does the size of the convolutional kernel affect the contribution window and NDR recovery?

- **Concept**: Stochastic aggregation techniques
  - **Why needed here**: Random cropping and noise injection are used to improve saliency map stability and quality.
  - **Quick check question**: Why does aggregating multiple perturbed saliency maps produce better results than a single map?

## Architecture Onboarding

- **Component map**:
  Classifier backbone -> Feature extractor -> GAP layer -> Saliency computation -> Aggregation module -> Post-processing -> Pseudo-ground truth generation

- **Critical path**:
  1. Input image → classifier → classification score
  2. Compute saliency map (gradient of score w.r.t. input)
  3. Apply spatial perturbation (random cropping)
  4. Aggregate saliency maps weighted by crop scores
  5. Post-process (smoothing or superpixel assignment)
  6. Generate pseudo-ground truth for segmentation

- **Design tradeoffs**:
  - **CAMs vs Saliencies**: CAMs are faster and focus on discriminative regions but miss NDRs; saliencies recover NDRs but are noisier.
  - **Aggregation method**: Noise injection requires fine-tuning but smooths saliencies; random cropping doesn't require fine-tuning but needs careful crop sizing.
  - **Post-processing**: Kernel smoothing reduces noise but may blur boundaries; superpixel-based smoothing preserves boundaries but depends on superpixel quality.

- **Failure signatures**:
  - Poor NDR recovery: Saliency maps are too sparse or focused only on discriminative regions (small contribution window).
  - Excessive noise: Saliency maps are scattered and unstable (insufficient aggregation or poor post-processing).
  - Inconsistent results: Aggregation method or crop size is poorly chosen relative to object scale.

- **First 3 experiments**:
  1. **Contribution window analysis**: Train 5-layer ConvNet with varying kernel sizes on MNIST, compare CAM vs saliency NDR-Recall.
  2. **Random cropping sensitivity**: Apply random cropping aggregation with different crop numbers and scales on VOC, measure mIoU and NDR-Recall.
  3. **Noise vs cropping comparison**: Compare SmoothGrad/BinaryMask (noise-based) vs random cropping on VOC, evaluate stability and segmentation quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of saliency maps compare to CAMs when applied to more complex datasets like COCO?
- Basis in paper: [inferred] The paper shows that saliency maps outperform CAMs in recovering non-discriminative regions on the PASCAL VOC dataset, but the performance on the COCO dataset is not directly compared.
- Why unresolved: The paper provides results for both datasets, but the comparison between saliency maps and CAMs is more detailed for the PASCAL VOC dataset. The COCO dataset results are presented but not as comprehensively analyzed in terms of the specific metrics discussed for PASCAL VOC.
- What evidence would resolve it: A detailed comparison of saliency maps and CAMs on the COCO dataset using the same evaluation metrics (mIoU, NDR-Recall, DR-Recall, FG-Precision) as used for the PASCAL VOC dataset would provide a clearer understanding of their relative performance on more complex datasets.

### Open Question 2
- Question: What is the impact of different noise levels and types on the performance of saliency maps in weakly supervised semantic segmentation?
- Basis in paper: [explicit] The paper discusses the use of SmoothGrad and BinaryMask for stochastic aggregation of saliencies and analyzes the sensitivity of performance towards noise levels and types.
- Why unresolved: While the paper provides some insights into the sensitivity of performance towards noise levels and types, it does not explore the full range of possible noise configurations or their impact on different datasets and models.
- What evidence would resolve it: A comprehensive study that tests various noise levels and types across different datasets and models, measuring their impact on the performance of saliency maps, would provide a deeper understanding of the optimal noise configurations for weakly supervised semantic segmentation.

### Open Question 3
- Question: How do different post-processing techniques affect the quality of saliency maps for weakly supervised semantic segmentation?
- Basis in paper: [explicit] The paper discusses the use of kernel smoothing and superpixel-based background resolve as post-processing techniques to improve the quality of saliency maps.
- Why unresolved: The paper provides some results on the effectiveness of these techniques, but it does not explore other potential post-processing methods or their combinations.
- What evidence would resolve it: An extensive evaluation of various post-processing techniques, including but not limited to kernel smoothing and superpixel-based methods, and their combinations, on the quality of saliency maps for weakly supervised semantic segmentation, would help identify the most effective approaches.

## Limitations

- The theoretical analysis of contribution windows assumes linear growth with network depth, but this relationship may vary across architectures
- The comparative advantage of saliency maps depends heavily on specific post-processing choices, making direct comparisons architecture-sensitive
- The random cropping aggregation shows strong empirical results but lacks theoretical grounding for why it outperforms noise-based methods

## Confidence

- **High**: Saliency maps can recover non-discriminative regions that CAMs miss; larger contribution windows improve NDR recovery
- **Medium**: Random cropping significantly improves saliency map quality; saliency maps are viable alternatives to CAMs for WS3
- **Low**: The proposed evaluation metrics fully capture segmentation quality; noise-based aggregation is uniformly inferior to cropping-based aggregation

## Next Checks

1. **Contribution window sensitivity**: Systematically vary kernel sizes in a controlled architecture and measure the trade-off between discriminative and non-discriminative region recovery.
2. **Aggregation method comparison**: Compare random cropping against multiple noise-based methods (SmoothGrad variants) on identical network architectures to isolate the effect of perturbation type.
3. **Post-processing ablation**: Evaluate the impact of different post-processing techniques (kernel smoothing vs. superpixel assignment) on segmentation quality across multiple datasets.