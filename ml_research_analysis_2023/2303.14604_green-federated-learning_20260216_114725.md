---
ver: rpa2
title: Green Federated Learning
arxiv_id: '2303.14604'
source_url: https://arxiv.org/abs/2303.14604
tags:
- carbon
- emissions
- learning
- concurrency
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a large-scale empirical study of the carbon
  emissions of a production federated learning (FL) system running on millions of
  user devices. By instrumenting and profiling all major components, the authors quantify
  the emissions from client devices, servers, and communication channels.
---

# Green Federated Learning

## Quick Facts
- arXiv ID: 2303.14604
- Source URL: https://arxiv.org/abs/2303.14604
- Reference count: 40
- Primary result: Client compute and communication account for 97% of federated learning carbon emissions

## Executive Summary
This paper presents a large-scale empirical study measuring carbon emissions from a production federated learning system operating on millions of user devices. By instrumenting and profiling all major components, the authors quantify emissions from client devices, servers, and communication channels. They find that client compute and communication dominate the carbon footprint (97%), with server compute contributing only 1-2%. The authors establish that carbon emissions correlate strongly with the product of rounds to reach target accuracy and number of concurrent clients. They demonstrate that synchronous FL has lower carbon emissions than asynchronous FL despite slower convergence, and propose guidelines to reduce FL's carbon footprint by up to 200x while maintaining model performance.

## Method Summary
The authors instrumented a production federated learning system called Papaya to measure carbon emissions across all components. They collected detailed power consumption data from 210 representative Android devices, logged device vitals including country, model specifications, and timing metrics during training. The system ran language modeling tasks using Reddit dataset with both synchronous and asynchronous FL configurations. Power profiles were used to estimate device energy consumption, while server utilization was monitored during aggregation. Carbon intensity was calculated based on geographic location of devices. The study systematically varied hyperparameters including concurrency, learning rates, and local epochs to measure their impact on both model accuracy and carbon emissions.

## Key Results
- Client compute and communication contribute 97% of federated learning carbon emissions
- Server compute accounts for only 1-2% of total carbon footprint
- Carbon emissions are highly correlated with the product of rounds to target accuracy and number of concurrent clients
- Synchronous FL has lower carbon emissions than asynchronous FL despite longer training times
- Carbon footprint can be reduced by up to 200x through optimized hyperparameter selection while maintaining model performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Carbon emissions of FL tasks are primarily driven by the product of concurrency and the time/rounds to reach target accuracy.
- Mechanism: Each client device in an FL task consumes a roughly constant amount of energy per unit of compute time and per unit of data transmitted. As concurrency increases, more devices train in parallel, so the total energy per time unit scales linearly with concurrency. The total training time decreases with higher concurrency, but only sublinearly, so the overall carbon footprint is proportional to the product of concurrency and training time.
- Core assumption: Device power consumption and communication costs per unit of training are independent of concurrency.
- Evidence anchors:
  - [abstract] "the carbon footprint of an FL task is highly correlated with the product of its running time and the number of users active in training (i.e., concurrency)."
  - [section 5.3] "Figures 8 and 9... confirm the product of rounds and concurrency is a good proxy to predict the carbon footprint of synchronous FL."
- Break condition: If device power consumption scales superlinearly with concurrency due to contention or heat, or if the model architecture changes to have significantly different per-device energy use.

### Mechanism 2
- Claim: Synchronous FL has lower carbon emissions than asynchronous FL for the same target accuracy, despite taking longer.
- Mechanism: Asynchronous FL requires more frequent model updates, which increases the number of communication rounds and thus the total data transmitted. Each round incurs both client compute and network energy costs. Synchronous FL batches updates and thus amortizes these costs, leading to lower per-accuracy carbon emissions even though it may take longer.
- Core assumption: The energy per round is constant and independent of model staleness.
- Evidence anchors:
  - [abstract] "Asynchronous FL is faster than synchronous FL... but it comes at the cost of higher carbon emissions."
  - [section 5.1] "We can also see that the majority of the carbon footprint is contributed by the client compute — consistent with FL's pushing the AI processing to the edge of the network."
- Break condition: If asynchronous FL achieves a disproportionate reduction in training time, or if communication costs dominate in a different way.

### Mechanism 3
- Claim: Server compute contributes negligibly to FL carbon emissions (< 2%) compared to client compute and communication.
- Mechanism: The server side performs aggregation and optimization over a single model, while clients perform heavy local training on individual data. Even with millions of clients, the server's computational load per client is tiny compared to the distributed local training work.
- Core assumption: The server workload is proportional to the number of clients but the per-client workload is minimal.
- Evidence anchors:
  - [section 5.1] "The carbon footprint attributable to the server-side computation is small (∼1–2%)... client computation contributes to almost half of the overall carbon footprint."
  - [section 4.2] "We observe that utilization of the Aggregator for the language modeling FL task is less than 1%."
- Break condition: If server-side cryptographic operations (e.g., secure aggregation) become much more expensive, or if the server architecture changes.

## Foundational Learning

- Concept: Federated Learning (FL)
  - Why needed here: Understanding how FL distributes training across many devices is critical to analyzing where energy is spent.
  - Quick check question: In FL, where does the model training primarily happen—on the server or on the clients?

- Concept: Carbon Intensity
  - Why needed here: FL devices run on diverse energy mixes, so carbon emissions depend on both energy use and local carbon intensity.
  - Quick check question: Why is it important to account for the geographic location of FL devices when estimating carbon emissions?

- Concept: Hyperparameter Tuning in FL
  - Why needed here: The study shows that hyperparameters like concurrency, learning rate, and local epochs directly affect both convergence time and carbon emissions.
  - Quick check question: Which FL hyperparameter has the largest direct impact on carbon emissions, and why?

## Architecture Onboarding

- Component map:
  Client Runtime -> Logger -> Server Components (Coordinator, Selector, Aggregator) -> Measurement System

- Critical path:
  1. Client device selected and runs FL training
  2. Logger records timing and device info
  3. Power profiles used to estimate device energy use
  4. Server metrics collected for compute and networking
  5. All data aggregated to compute total carbon emissions

- Design tradeoffs:
  - High concurrency reduces training time but increases total energy use
  - Synchronous FL is slower but more energy-efficient per round than asynchronous FL
  - Detailed power profiling is accurate but only possible for a subset of devices

- Failure signatures:
  - Large variance in reported carbon emissions may indicate missing or incorrect power profiles
  - Anomalously high server energy use may indicate bugs in aggregation logic
  - Discrepancies between model accuracy and training time could suggest suboptimal hyperparameters

- First 3 experiments:
  1. Measure carbon emissions for synchronous vs. asynchronous FL at fixed concurrency and target accuracy
  2. Vary concurrency and measure the effect on carbon emissions and training time
  3. Test the linear relationship between (rounds x concurrency) and carbon emissions for synchronous FL

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal trade-off between concurrency and carbon emissions for achieving a target accuracy in federated learning?
- Basis in paper: [explicit] The authors find that carbon emissions are highly correlated with the product of the number of rounds to reach target accuracy and the number of clients active in training (concurrency).
- Why unresolved: While the authors identify the correlation, the optimal balance between these factors is not explicitly determined.
- What evidence would resolve it: Empirical studies that systematically vary concurrency and measure the resulting carbon emissions and accuracy to identify the optimal point.

### Open Question 2
- Question: How do compression and quantization techniques impact the carbon footprint of federated learning?
- Basis in paper: [explicit] The authors suggest that compression and quantization could reduce carbon emissions of the communication stack.
- Why unresolved: The potential benefits and trade-offs of these techniques are not explored in the study.
- What evidence would resolve it: Experimental comparisons of carbon emissions and model performance with and without compression/quantization techniques.

### Open Question 3
- Question: How does the inclusion of differential privacy as an additional criterion affect the carbon footprint of federated learning?
- Basis in paper: [explicit] The authors encourage considering the carbon footprint alongside accuracy, convergence speed, and other metrics, and mention differential privacy as a potential additional criterion.
- Why unresolved: The impact of differential privacy on carbon emissions is not investigated.
- What evidence would resolve it: Empirical studies that measure the carbon footprint of federated learning with and without differential privacy guarantees.

## Limitations
- Analysis relies on a production FL system with limited disclosure of specific implementation details
- Power profiling data is limited to 210 Android devices, potentially not fully representative of global user base
- Geographic distribution of users is not specified, affecting carbon intensity calculations
- Linear relationship between (rounds x concurrency) and carbon emissions may not hold for all FL tasks

## Confidence
- High confidence in the overall finding that client compute and communication dominate FL carbon emissions (>97%)
- Medium confidence in the specific numerical estimates for server-side contributions (1-2%)
- Medium confidence in the linear correlation model between (rounds x concurrency) and carbon footprint for synchronous FL
- Medium confidence in the comparison between synchronous and asynchronous FL carbon efficiency

## Next Checks
1. Validate the linear relationship between (rounds x concurrency) and carbon emissions across different FL tasks (computer vision, speech recognition) beyond the language modeling task studied
2. Conduct controlled experiments varying geographic distribution of FL clients to quantify the impact of carbon intensity differences on total emissions
3. Test the carbon efficiency findings with different model architectures (CNNs, transformers) and federated optimization algorithms (FedAvg, FedProx) to assess generalizability