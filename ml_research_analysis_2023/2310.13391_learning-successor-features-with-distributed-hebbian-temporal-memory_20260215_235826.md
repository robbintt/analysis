---
ver: rpa2
title: Learning Successor Features with Distributed Hebbian Temporal Memory
arxiv_id: '2310.13391'
source_url: https://arxiv.org/abs/2310.13391
tags:
- learning
- state
- algorithm
- memory
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DHTM, a novel algorithm for online sequence
  learning in non-stationary, partially observable environments. DHTM is based on
  factor graph formalism and a multi-component neuron model, inspired by neurophysiological
  models of the neocortex.
---

# Learning Successor Features with Distributed Hebbian Temporal Memory

## Quick Facts
- arXiv ID: 2310.13391
- Source URL: https://arxiv.org/abs/2310.13391
- Reference count: 40
- Key outcome: DHTM outperforms LSTM and RWKV on non-stationary datasets and performs comparably to CSCG on SR accuracy and agent adaptability

## Executive Summary
This paper presents DHTM, a novel algorithm for online sequence learning in non-stationary, partially observable environments. DHTM uses factor graph formalism and a multi-component neuron model inspired by neurophysiological models of the neocortex. It employs distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning of traditional temporal memory algorithms. DHTM aims to capture sequential data relationships and form Successor Representations (SRs) for decision making under uncertainty. Experiments show that DHTM outperforms LSTM and RWKV on non-stationary datasets and performs comparably to a biologically inspired HMM-like algorithm, CSCG.

## Method Summary
DHTM is an online sequence learning algorithm that uses factor graph formalism and a multi-component neuron model. It employs distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning of traditional temporal memory algorithms like RNN and HMM. DHTM captures sequential data relationships and forms Successor Representations (SRs) for decision making under uncertainty. The algorithm consists of an encoder (Spatial Pooler), DHTM core (factor graph with segments, messages, context and emission factors), decoder (linear layer), SR module, and agent policy. DHTM learns fully online using local Hebbian-like rules and performs inference via segment-based belief propagation.

## Key Results
- DHTM outperforms LSTM and RWKV on non-stationary datasets in terms of SR accuracy (surprise metric)
- DHTM performs comparably to a biologically inspired HMM-like algorithm (CSCG) on SR accuracy and agent adaptability in changing environments
- DHTM learns fully online using only local Hebbian-like rules, circumventing gradient drawbacks and making the learning process much faster

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DHTM's local Hebbian-like learning rules avoid the instability of gradient-based methods in online settings.
- Mechanism: By using only local updates to factor values and synaptic weights based on coincident activity (Hebbian rule), DHTM sidesteps the need for backpropagation through time, which is prone to exploding/vanishing gradients and requires full sequence access.
- Core assumption: Local Hebbian updates can capture sufficient statistical dependencies in the data for effective sequence modeling.
- Evidence anchors:
  - [abstract]: "overcome the instability and slow learning of traditional temporal memory algorithms like RNN and HMM... employs only local Hebbian-like learning rules... circumventing gradient drawbacks and making the learning process much faster"
  - [section 3.1]: "DHTM learns fl and wul weights by Monte-Carlo Hebbian-like updates... This is similar to Baum-Welch's update rule... but, in our case, the previous state (context) is represented by a group of RVs."
  - [corpus]: Weak - related works focus on Hebbian plasticity and online adaptation but do not directly validate DHTM's specific rule efficacy.
- Break condition: If the local statistics are insufficient to capture long-range dependencies or if the environment has highly non-stationary dynamics that require more global optimization.

### Mechanism 2
- Claim: Sparse transition matrices stored in dendritic segments reduce trainable parameters and speed up learning.
- Mechanism: Each segment corresponds to a non-zero entry in a transition matrix, and only active segments are updated. This sparsity is enforced by the columnar emission structure and Hebbian growth of segments, drastically reducing the number of parameters compared to dense matrices.
- Core assumption: The underlying state transition structure is sparse enough that most entries can be zero, and sparse representation is sufficient for accurate modeling.
- Evidence anchors:
  - [abstract]: "utilizes distributed representations, sparse transition matrices... The DHTM learns fully online employing only local Hebbian-like rules."
  - [section 3.1]: "we don't explicitly store large transition matrices, only their non-zero parts... factor entries are zero, meaning cells have no segments. As learning proceeds, new segments are grown."
  - [corpus]: Weak - related work on sparse representations exists but does not validate DHTM's specific sparse segment storage.
- Break condition: If the true transition dynamics are dense or if the sparsity assumption leads to underfitting critical dependencies.

### Mechanism 3
- Claim: The segment-based belief propagation approximates log-sum-exp with max, enabling efficient and biologically plausible inference.
- Mechanism: Instead of computing full log-sum-exp over all possible state combinations (computationally expensive), DHTM uses a max operation over segment-induced excitations, inspired by neurophysiological models of dendritic integration.
- Core assumption: The max approximation preserves sufficient discriminative information for accurate state inference, and the neurophysiological inspiration is valid.
- Evidence anchors:
  - [section 3.1]: "we also approximate logarithmic sum with max operation inspired by the neurophysiological model of segment aggregation by cell [40]."
  - [corpus]: Weak - related spiking and dendritic computation models exist but do not validate DHTM's specific approximation.
- Break condition: If the max approximation loses critical probability mass or fails in highly multimodal posterior distributions.

## Foundational Learning

- Concept: Factor graphs and sum-product belief propagation
  - Why needed here: DHTM's inference engine is built on factor graph formalism to decompose complex joint distributions into tractable local factors.
  - Quick check question: Can you write the joint distribution factorization for a Hidden Markov Model using factor graphs?

- Concept: Successor Representations (SR)
  - Why needed here: DHTM is designed to form SRs by predicting cumulative future observations, which are then used to speed up TD learning in RL.
  - Quick check question: How does the SR formula M_ij = sum over l of gamma^l * P(o_{t+l}=j | h_t=i) relate to the model's prediction of future observations?

- Concept: Hebbian learning and synaptic plasticity
  - Why needed here: DHTM's learning rules are based on local Hebbian updates that strengthen connections when pre- and post-synaptic activity coincide.
  - Quick check question: What is the difference between a simple Hebbian update and the more sophisticated segment-based update used in DHTM?

## Architecture Onboarding

- Component map:
  Encoder (SP) -> DHTM core (factor graph with segments, messages, context and emission factors) -> Decoder (linear layer) -> SR module -> Agent policy (softmax over predicted state values)

- Critical path:
  1. Observe -> preprocess -> encode to SDR
  2. DHTM inference: compute posterior over hidden states given SDR
  3. DHTM learning: update segments and messages via Hebbian rules
  4. SR update: accumulate predictions for TD learning
  5. Policy: choose action based on predicted values

- Design tradeoffs:
  - Sparse vs dense transition matrices: sparsity reduces parameters but may underfit
  - Local vs global learning: local Hebbian rules are stable but may converge slower
  - Max vs log-sum-exp: max is efficient but may lose probability mass in multimodal cases

- Failure signatures:
  - Poor reconstruction quality: SP encoder/decoder not learning useful features
  - Slow or unstable SR learning: segments not capturing transitions well
  - Agent not adapting: policy not updating due to poor value predictions

- First 3 experiments:
  1. Test SP encoder/decoder on synthetic sequences to ensure it learns meaningful SDRs
  2. Run DHTM on a simple HMM-generated sequence to verify it recovers the true transition matrix
  3. Integrate DHTM into a basic grid-world RL task and compare learning curves to an LSTM baseline

## Open Questions the Paper Calls Out
No open questions are explicitly called out in the provided paper content.

## Limitations
- The paper does not provide a thorough comparison with other state-of-the-art sequence learning methods, such as Transformers or other biologically inspired models.
- The experimental setup and hyperparameter choices are not clearly defined, making it difficult to assess the robustness of the results.
- The paper does not provide a comprehensive ablation study or sensitivity analysis to identify the critical factors contributing to DHTM's success.

## Confidence
- High: The core concept of using factor graphs and Hebbian-like learning rules for online sequence learning is well-established in the literature and theoretically sound.
- Medium: The experimental results demonstrate the potential of DHTM in non-stationary environments, but the lack of detailed implementation and hyperparameter information limits the confidence in the reported performance.
- Low: The paper does not provide a comprehensive ablation study or sensitivity analysis to identify the critical factors contributing to DHTM's success, making it difficult to assess the robustness of the algorithm.

## Next Checks
1. Conduct a detailed ablation study to identify the impact of key components (e.g., factor graph structure, Hebbian learning rules, sparse transition matrices) on DHTM's performance and compare with ablations of competing methods.
2. Perform a thorough hyperparameter sensitivity analysis to determine the robustness of DHTM's performance across different configurations and provide guidelines for hyperparameter selection.
3. Compare DHTM with a broader range of state-of-the-art sequence learning methods, including Transformers and other biologically inspired models, on a variety of non-stationary datasets and environments to establish its relative strengths and weaknesses.