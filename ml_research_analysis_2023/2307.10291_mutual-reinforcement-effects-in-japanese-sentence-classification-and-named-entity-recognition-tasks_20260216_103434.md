---
ver: rpa2
title: Mutual Reinforcement Effects in Japanese Sentence Classification and Named
  Entity Recognition Tasks
arxiv_id: '2307.10291'
source_url: https://arxiv.org/abs/2307.10291
tags:
- framework
- accuracy
- scnm
- format
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores mutual reinforcement effects between sentence
  classification and named entity recognition in Japanese by integrating the two tasks
  into a single multi-task learning framework. The authors construct a novel dataset
  combining sentence classification labels with named entity annotations from Wikipedia,
  and propose a Sentence-to-Label Generation (SLG) framework to handle both tasks
  using a format converter and constraint mechanism.
---

# Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks

## Quick Facts
- arXiv ID: 2307.10291
- Source URL: https://arxiv.org/abs/2307.10291
- Reference count: 7
- Key outcome: Joint training of SC and NER improves both tasks by ~1 point; SLG framework shows strong few-shot learning

## Executive Summary
This paper explores mutual reinforcement effects between Japanese sentence classification and named entity recognition by integrating both tasks into a single multi-task learning framework. The authors construct a novel dataset combining SC labels with NER annotations from Wikipedia and propose a Sentence-to-Label Generation (SLG) framework using format conversion and constraint mechanisms. Experiments demonstrate that joint training improves SC accuracy by 1.13 points and NER by 1.06 points compared to standalone tasks, while also showing strong few-shot learning capabilities.

## Method Summary
The Sentence-to-Label Generation (SLG) framework unifies SC and NER tasks through format conversion, converting diverse input formats into a unified sequence-to-sequence format with prompt words and mark tokens. The framework employs incremental learning on a large NER corpus (Shinra NER) before fine-tuning on the combined dataset, and uses a Constraint Mechanism to ensure correct output formatting. The approach uses T5 and BART generative models with format converters that transform raw text into structured outputs containing both SC labels and NER annotations.

## Key Results
- Joint training improves SC accuracy by 1.13 points and NER by 1.06 points compared to standalone tasks
- SLG framework demonstrates strong few-shot learning capabilities, outperforming standard fine-tuning in low-data scenarios
- The Constraint Mechanism raises format accuracy from 63.61 to 100, significantly improving overall performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint training of SC and NER tasks creates mutual reinforcement effects.
- Mechanism: Shared knowledge between tasks allows each to benefit from contextual information provided by the other - entity identification improves sentence understanding and vice versa.
- Core assumption: Sufficient semantic overlap exists between sentence-level and word-level information in the dataset.
- Evidence anchors: SC and NER tasks exhibit correlations in extracted labels; joint training shows 1.13 and 1.06 point improvements respectively.

### Mechanism 2
- Claim: The Sentence-to-Label Generation (SLG) framework effectively unifies different IE tasks through format conversion.
- Mechanism: Converting diverse input formats into unified sequence-to-sequence format with appropriate prompts and mark tokens enables consistent generation of both SC labels and entity spans.
- Core assumption: A unified format with proper prompts can guide the generative model to produce both SC labels and NER labels/spans.
- Evidence anchors: Format converter enables SLG to handle SCNM task and separate SC/NER tasks; accuracy increases from 0.37 to 0.56 with sufficient prompt words.

### Mechanism 3
- Claim: The Constraint Mechanism (CM) significantly improves format generation accuracy.
- Mechanism: Forcing the first generated token to be a specific mark token guides subsequent token predictions toward accurate format generation.
- Core assumption: Controlling initial token generation can influence the entire sequence generation process.
- Evidence anchors: CM raises format accuracy from 63.61 to 100; corroborates model's capacity to generate accurate formats.

## Foundational Learning

- Concept: Sequence-to-sequence generation models
  - Why needed here: SLG framework relies on generative models (T5, BART) to convert input sentences into labeled outputs rather than traditional sequence tagging.
  - Quick check question: What is the key difference between sequence-to-sequence generation and sequence tagging in NER tasks?

- Concept: Incremental learning (IL)
  - Why needed here: IL pre-trains the model on a large NER corpus before fine-tuning on the combined dataset, allowing acquisition of foundational entity recognition capabilities.
  - Quick check question: How does incremental learning differ from standard fine-tuning in terms of knowledge transfer?

- Concept: Format conversion and prompt engineering
  - Why needed here: The format converter transforms raw text into a unified format with appropriate prompts and mark tokens that guide the generative model's output.
  - Quick check question: Why is it important to use different mark tokens for SC labels versus NER labels in the input format?

## Architecture Onboarding

- Component map: Input → Format Converter → Incremental Learning (optional) → Constraint Mechanism → Generative Model (T5/BART) → Output format validation → SC label + NER labels/spans
- Critical path: The model must successfully convert input format, generate constrained initial tokens, and produce outputs in the correct format to achieve high accuracy
- Design tradeoffs: T5 vs BART selection (T5 has larger pre-training corpus but BART may overfit less); strict format evaluation ensures quality but may be too stringent; unified format enables multi-task learning but requires careful prompt design
- Failure signatures: Format accuracy drops below threshold (indicates CM or format converter issues); task-specific accuracy decreases when tasks are combined (indicates negative interference); model generates nonsensical text (indicates format conversion problems)
- First 3 experiments:
  1. Test different format converter designs on a small subset to find optimal prompt structure
  2. Compare T5 vs BART base/large models on full SCNM dataset with identical settings
  3. Run ablation study removing IL and/or CM to measure individual contributions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the SLG framework's performance scale when applied to other language pairs beyond Japanese, particularly in languages with different morphological complexity?
- Basis in paper: The paper focuses exclusively on Japanese language tasks but discusses the generalizability of the SLG framework through its format converter component
- Why unresolved: Experiments were limited to Japanese language data, leaving uncertainty about cross-linguistic applicability
- What evidence would resolve it: Systematic experiments applying SLG to multiple languages with varying morphological complexity (e.g., Chinese, German, Arabic) and comparing performance metrics

### Open Question 2
- Question: What is the optimal balance between the three components of the SLG framework (Format Converter, Incremental Learning, and Constraint Mechanism) for different types of information extraction tasks?
- Basis in paper: Ablation experiments showed varying impacts of IL and CM across T5 and BART models, suggesting component effectiveness may be task-dependent
- Why unresolved: The paper tested limited combinations and didn't systematically explore optimal weighting or configuration of components for different task types
- What evidence would resolve it: Comprehensive ablation studies across diverse IE tasks (relation extraction, event extraction, etc.) with systematic component weighting experiments

### Open Question 3
- Question: How does the mutual reinforcement effect between SC and NER tasks vary with domain specificity of the data?
- Basis in paper: The paper mentions that SCNM dataset categories are generic rather than domain-specific, and notes the need for domain-specific datasets in future work
- Why unresolved: Experiments used general Wikipedia data without exploring how domain specificity affects the mutual reinforcement phenomenon
- What evidence would resolve it: Experiments comparing SC-NER mutual reinforcement effects across multiple domains (medical, legal, technical) using domain-specific datasets

### Open Question 4
- Question: What are the theoretical limits of the few-shot learning capabilities demonstrated by the SLG framework?
- Basis in paper: The paper shows SLG outperforms fine-tuning in 5-shot and 10-shot scenarios but doesn't explore lower sample sizes or identify minimum effective sample size
- Why unresolved: Experiments only tested 5-shot and 10-shot scenarios, leaving uncertainty about framework's effectiveness at extreme few-shot settings
- What evidence would resolve it: Experiments testing SLG framework with 1-shot, 2-shot, and 3-shot scenarios, along with mathematical analysis of sample complexity requirements

## Limitations

- The generalizability of mutual reinforcement effects across languages and domains remains uncertain, as the study focuses exclusively on Japanese Wikipedia data
- The SCNM dataset construction method is not fully detailed, raising questions about reproducibility and the semantic overlap between SC and NER tasks
- The format accuracy metric is very strict, potentially overestimating real-world performance where partial correctness might be acceptable

## Confidence

**High Confidence**: Format conversion through prompt engineering and mark tokens is well-established in sequence-to-sequence models; incremental learning approach for pre-training on NER before fine-tuning is a standard technique with predictable effects.

**Medium Confidence**: The mutual reinforcement hypothesis is supported by empirical results but lacks deeper analysis of why specific correlations between SC labels and NER entities exist; Constraint Mechanism effectiveness is demonstrated but underlying reasons for success are not fully explored.

**Low Confidence**: Claims about few-shot learning capabilities are mentioned but not rigorously evaluated; comparison between T5 and BART performance lacks sufficient detail to draw strong conclusions about which architecture is superior for this task.

## Next Checks

1. **Cross-linguistic validation**: Replicate the experiment using English or other language datasets to verify whether mutual reinforcement effects persist across different linguistic structures and domain distributions.

2. **Error analysis and ablation**: Conduct detailed error analysis to identify which SC categories and NER entity types show the strongest mutual reinforcement, and perform ablation studies to quantify individual contributions of format conversion, incremental learning, and constraint mechanisms.

3. **Practical deployment testing**: Evaluate the SLG framework on real-world Japanese text outside Wikipedia (e.g., news articles, social media) to assess whether format conversion and constraint mechanisms remain effective with more diverse linguistic patterns and noise.