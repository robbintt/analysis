---
ver: rpa2
title: 'BanditPAM++: Faster $k$-medoids Clustering'
arxiv_id: '2310.18844'
source_url: https://arxiv.org/abs/2310.18844
tags:
- banditpam
- algorithm
- each
- clustering
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'BanditPAM++ accelerates the BanditPAM k-medoids algorithm through
  two techniques: Virtual Arms (VA), which reduces the per-iteration complexity by
  a factor of k, and Permutation-Invariant Caching (PIC), which enables reuse of distance
  computations across algorithm phases. The method reformulates the clustering problem
  as a sequential multi-armed bandit, allowing for adaptive sampling of pairwise distances.'
---

# BanditPAM++: Faster $k$-medoids Clustering

## Quick Facts
- arXiv ID: 2310.18844
- Source URL: https://arxiv.org/abs/2310.18844
- Reference count: 40
- Primary result: BanditPAM++ achieves up to 10x speedup over BanditPAM while maintaining identical clustering quality

## Executive Summary
BanditPAM++ accelerates the BanditPAM k-medoids clustering algorithm through two key techniques: Virtual Arms (VA) and Permutation-Invariant Caching (PIC). VA reduces per-iteration complexity by a factor of k by exploiting the structure that only the closest medoid matters for each data point's loss computation. PIC enables reuse of distance computations across BUILD and SWAP phases by casting the algorithm as a Sequential Permutation-Invariant Multi-Armed Bandit. The method reformulates k-medoids as a sequential multi-armed bandit problem, allowing adaptive sampling of pairwise distances instead of exhaustive computation.

## Method Summary
BanditPAM++ implements two optimization techniques to accelerate the BanditPAM k-medoids algorithm. Virtual Arms (VA) exploits the structure of k-medoids loss functions to reuse distance computations, reducing per-swap complexity from O(k) to O(1) for all but one medoid. Permutation-Invariant Caching (PIC) leverages the fact that the algorithm can be formulated as a Sequential Permutation-Invariant Multi-Armed Bandit, enabling reuse of distance computations across different phases of the algorithm. The approach maintains the same clustering quality as BanditPAM while significantly reducing wall-clock runtime through adaptive sampling of pairwise distances.

## Key Results
- Achieves identical clustering quality to BanditPAM with loss ratio = 1.00
- Demonstrates up to 10x speedup on CIFAR10 dataset in wall-clock runtime
- Shows scalability improvements as the number of clusters k increases
- Validated across multiple datasets (CIFAR10, MNIST, 20 Newsgroups) with different distance metrics

## Why This Works (Mechanism)

### Mechanism 1: Virtual Arms (VA) Reuse
When computing the loss change for swapping medoid m with non-medoid x_i, the effect on data point x_s depends on m only when m is the closest medoid to x_s. For all other medoids, the effect is identical, allowing reuse of the same distance computation. This reduces per-swap complexity from O(k) distance calculations to O(1) for all but one medoid. The core assumption is that the distance function and current medoid assignments create this special structure where only the closest medoid matters for each data point.

### Mechanism 2: Permutation-Invariant Caching (PIC)
Because BanditPAM++ can be formulated as a Sequential Permutation-Invariant Multi-Armed Bandit, distance computations can be reused across both BUILD and SWAP phases. By choosing a fixed permutation of reference points and evaluating them in order, we can cache distance computations and reuse them across different iterations and phases. The core assumption is that the SPIMAB formulation holds with the same set of reference points (the data itself) across all iterations.

### Mechanism 3: Sequential Multi-Armed Bandit Formulation
Each step of the k-medoids algorithm is reformulated as a best-arm identification problem in a sequential multi-armed bandit, allowing adaptive sampling of pairwise distances. Instead of computing all O(n²) pairwise distances, the algorithm samples distances adaptively based on confidence bounds, focusing computation on promising swaps. The core assumption is that the reward function for each "arm" (potential swap) can be estimated from a subset of distance computations, and these estimates concentrate around true values.

## Foundational Learning

- Multi-armed bandit theory and best-arm identification: Needed because BanditPAM++ uses bandit algorithms to adaptively sample distance computations instead of computing all pairwise distances. Quick check: What is the key difference between regret minimization and best-arm identification in bandit problems?

- Sub-Gaussian concentration inequalities: Needed because the algorithm relies on confidence bounds that assume rewards are sub-Gaussian to guarantee correct arm selection. Quick check: What does it mean for a random variable to be σ-sub-Gaussian?

- Permutation-invariant statistics: Needed because PIC relies on the fact that the order of sampling reference points doesn't affect the distribution of sample means. Quick check: Why does averaging over a random permutation of reference points give the same result as averaging over a fixed order?

## Architecture Onboarding

- Component map: Distance cache -> Virtual arms manager -> Bandit solver -> Permutation-invariant cache -> Swap executor
- Critical path: BUILD phase (select k initial medoids using bandit sampling and caching) -> SWAP phase (iteratively find and perform optimal swaps using VA and PIC) -> Termination (stop after T swaps or convergence)
- Design tradeoffs: Memory vs computation (PIC requires storing up to 1000 distances per point), Adaptivity vs accuracy (bandit sampling trades off exploration and exploitation), Complexity vs simplicity (VA reduces complexity but requires careful bookkeeping)
- Failure signatures: If VA fails (similar runtime to original BanditPAM, k times slower), If PIC fails (no reuse across phases, only within-phase reuse via VA), If bandit solver fails (may return suboptimal swaps, degrading clustering quality)
- First 3 experiments: 1) Verify VA structure on small dataset by checking if ∆lm,xi(xs) values are equal for m ≠ mc(s), 2) Test PIC by running BUILD and SWAP with same permutation and measuring cache hit rate, 3) Validate bandit convergence by comparing selected swaps with full exhaustive search on small dataset

## Open Questions the Paper Calls Out

### Open Question 1
What is the theoretical upper bound on the speedup factor that BanditPAM++ can achieve over BanditPAM, given the relationship between k and n in practical datasets? The paper shows up to 10× speedup on CIFAR10 but doesn't provide a theoretical upper bound. This would require theoretical analysis showing maximum possible speedup factor as a function of k and n, validated with additional experiments on diverse datasets.

### Open Question 2
How does the performance of BanditPAM++ compare to other state-of-the-art k-medoids algorithms on datasets with non-Euclidean distance metrics, such as Jaccard or Hamming distance? The paper only uses L2, L1, and cosine distances in experiments. This would require experiments comparing BanditPAM++ to other algorithms on datasets with non-Euclidean metrics.

### Open Question 3
What is the impact of the permutation-invariant cache (PIC) size on the performance of BanditPAM++, and is there an optimal cache size for different dataset sizes and characteristics? The paper uses up to 1,000 distance computations per point but doesn't explore different cache sizes. This would require experiments varying PIC size across different dataset sizes to determine optimal cache size and impact on performance.

## Limitations
- Only tested on L1, L2, and cosine distance metrics without exploring other distance functions
- Memory overhead from caching up to 1000 distances per point is not quantified
- Speedup depends on dataset characteristics and varies significantly across different datasets

## Confidence
- VA mechanism: High - correctness follows directly from Theorem 1 and k-medoids loss structure
- PIC mechanism: Medium - effectiveness depends on specific permutation choices and cache management
- Bandit formulation: Medium - convergence guarantees rely on sub-Gaussian assumptions that may not hold for all distance functions

## Next Checks
1. Verify the VA structure empirically by computing ∆lm,xi(xs) values across multiple data points and confirming equality for m ≠ mc(s)
2. Test PIC with different reference point permutations to identify optimal ordering strategies and measure cache hit rates
3. Benchmark on additional distance functions (e.g., Mahalanobis, edit distance) to test the generality of bandit formulation assumptions