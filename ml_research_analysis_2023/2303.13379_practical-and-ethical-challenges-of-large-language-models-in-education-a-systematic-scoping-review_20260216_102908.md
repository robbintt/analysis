---
ver: rpa2
title: 'Practical and Ethical Challenges of Large Language Models in Education: A
  Systematic Scoping Review'
arxiv_id: '2303.13379'
source_url: https://arxiv.org/abs/2303.13379
tags:
- educational
- innovations
- llms
- studies
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This systematic review of 118 peer-reviewed studies from 2017-2022
  identified 53 use cases for large language models (LLMs) in automating educational
  tasks across nine categories: profiling/labelling, detection, grading, teaching
  support, prediction, knowledge representation, feedback, content generation, and
  recommendation. The review found that while LLMs-based innovations show high performance
  in simple classification and generation tasks, most remain in early development
  stages (TRL-2-4) with poor replicability and limited transparency beyond AI experts.'
---

# Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review

## Quick Facts
- arXiv ID: 2303.13379
- Source URL: https://arxiv.org/abs/2303.13379
- Reference count: 40
- Only 11 of 118 reviewed studies were publicly available for replication

## Executive Summary
This systematic scoping review analyzed 118 peer-reviewed studies from 2017-2022 to identify practical and ethical challenges of large language models (LLMs) in education. The review found 53 distinct use cases across nine educational task categories, with LLMs showing high performance in simple classification and generation tasks but struggling with more complex educational applications. Most innovations remain in early development stages with poor replicability and limited transparency. The study recommends updating existing innovations with state-of-the-art models, improving open-sourcing practices, and adopting human-centered approaches throughout development to enhance both practicality and ethicality.

## Method Summary
The study conducted a systematic scoping review using PRISMA protocol across four databases (Scopus, ACM Digital Library, IEEE Xplore, Web of Science) with specific search terms for LLMs and education. After screening 4,980 records, 118 studies were included and analyzed using inductive thematic analysis to categorize educational tasks, stakeholders, and machine learning approaches. The review assessed practicality through technological readiness levels (TRL) and performance metrics, and ethicality through transparency, privacy, equality, and beneficence dimensions. Data extraction was performed by two independent reviewers with inter-rater reliability scores (kappa = 0.75 for title/abstract, 0.73 for full-text).

## Key Results
- Identified 53 use cases for LLMs across nine educational task categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation
- Found most LLM-based innovations remain at TRL-2 to TRL-4 stages with only 11 studies publicly available for replication
- Only 11% of studies explicitly addressed privacy concerns and 6% addressed equality issues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can automate high-complexity NLP tasks in education with minimal manual effort due to zero- and few-shot learning.
- Mechanism: LLMs like GPT-3 are pretrained on diverse datasets, enabling them to generalize to new tasks without task-specific fine-tuning, reducing the development workload.
- Core assumption: The tasks are sufficiently similar to those in the pretraining corpus for effective transfer learning.
- Evidence anchors:
  - [abstract] "As several LLMs... have been pretrained on massive amounts of data across multiple disciplines, they are capable of completing natural language processing tasks with little (few-shot learning) or no additional training (zero-shot learning)"
  - [section] "The state-of-the-art LLMs could potentially achieve similar performance with a zero-shot approach [4]"
- Break condition: If the task domain is highly specialized or requires domain-specific knowledge not represented in the pretraining data.

### Mechanism 2
- Claim: LLM-based innovations automate educational tasks effectively when the task complexity is low, but struggle with higher complexity tasks.
- Mechanism: Simple classification and generation tasks align well with LLM capabilities, while complex tasks require deeper domain understanding that current LLMs lack.
- Core assumption: Task complexity correlates with the need for contextual understanding and nuanced decision-making.
- Evidence anchors:
  - [abstract] "LLMs-based innovations show high performance in simple classification and generation tasks"
  - [section] "For classification tasks, LLMs-based innovations have shown high performance for simple educational tasks... However, the classification performance of LLMs-based innovations decreases for other educational tasks"
- Break condition: If the task requires deep domain expertise or multi-step reasoning that exceeds current LLM capabilities.

### Mechanism 3
- Claim: LLMs amplify existing societal biases when trained on unfiltered internet data, necessitating careful mitigation strategies.
- Mechanism: LLMs learn patterns from training data, including biased representations, which they reproduce in outputs unless explicitly addressed.
- Core assumption: The pretraining corpus contains biased representations that influence LLM outputs.
- Evidence anchors:
  - [abstract] "LLMs-based innovations (e.g., ChatGPT) could contain human-like biases based on the existing ethical and moral norms of society, such as inheriting biased and toxic knowledge (e.g., gender and racial biases) when trained on unfiltered internet text data"
  - [section] "potential bias and discrimination issues may occur if adopting a model that is accurate but unfair"
- Break condition: If comprehensive bias detection and mitigation strategies are not implemented during development.

## Foundational Learning

- Concept: Technological Readiness Levels (TRL)
  - Why needed here: Provides a standardized framework to assess the maturity and practical applicability of LLM-based innovations
  - Quick check question: What TRL level indicates that a system has been successfully operated in its intended environment?

- Concept: Transparency Index for AI Systems
  - Why needed here: Evaluates how interpretable and explainable LLM-based innovations are to different stakeholder groups
  - Quick check question: Which tier of transparency would an LLM system reach if it was interpretable to AI researchers but not to educators?

- Concept: Human-Centered AI Development
  - Why needed here: Ensures LLM-based innovations align with stakeholder needs and address practical and ethical concerns throughout development
  - Quick check question: What is the primary benefit of involving stakeholders throughout the development process of LLM-based educational innovations?

## Architecture Onboarding

- Component map: LLM core model → Task-specific adapter/fine-tuning layer → Educational domain knowledge integration → Output filtering and bias mitigation → Stakeholder feedback loop
- Critical path: Data collection and preprocessing → Model selection and adaptation → Performance evaluation → Ethical assessment → Stakeholder validation
- Design tradeoffs: Balance between model capability and computational/resource costs, between automation and human oversight, between model performance and interpretability
- Failure signatures: Poor performance on complex tasks, biased or inappropriate outputs, lack of stakeholder adoption, privacy breaches
- First 3 experiments:
  1. Benchmark LLM performance on a simple classification task (e.g., sentiment analysis of student feedback) using zero-shot learning
  2. Fine-tune an LLM on a specific educational dataset and compare performance with zero-shot approach
  3. Implement a bias detection mechanism and evaluate its effectiveness on a diverse dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively measure the technology readiness of LLMs-based innovations in authentic educational settings?
- Basis in paper: [explicit] The paper discusses the low technology readiness of LLMs-based innovations, with most being in the early stages of development and testing.
- Why unresolved: The paper highlights the need for in-the-wild studies but does not provide a concrete framework for measuring technology readiness in real educational contexts.
- What evidence would resolve it: Developing and validating a comprehensive assessment framework that includes stakeholder feedback, integration challenges, and real-world performance metrics.

### Open Question 2
- Question: What are the long-term impacts of using LLMs-based innovations on student learning outcomes and teacher workloads?
- Basis in paper: [inferred] The paper suggests that LLMs could reduce teacher workloads and benefit students, but lacks empirical evidence on long-term impacts.
- Why unresolved: Most studies focus on short-term performance metrics rather than longitudinal studies that track educational outcomes over time.
- What evidence would resolve it: Conducting multi-year studies that evaluate changes in student performance, engagement, and teacher satisfaction.

### Open Question 3
- Question: How can we ensure the ethical use of LLMs in education while maintaining their effectiveness?
- Basis in paper: [explicit] The paper identifies ethical challenges such as privacy, equality, and beneficence, but offers limited solutions for balancing ethics with performance.
- Why unresolved: The tension between maximizing model performance and adhering to ethical guidelines remains unresolved, particularly with commercial LLMs.
- What evidence would resolve it: Developing and testing ethical frameworks that integrate stakeholder input and demonstrate minimal impact on model performance.

## Limitations

- The review's findings are constrained by the limited number of publicly available studies (only 11 out of 118 could be accessed for replication), raising concerns about the generalizability of reported performance metrics
- The focus on English-language publications may overlook non-English educational contexts and innovations
- The rapid evolution of LLM technology means that findings from 2017-2022 may already be outdated, particularly regarding newer models like GPT-4 and ChatGPT

## Confidence

- **High Confidence:** The systematic methodology (PRISMA protocol, dual-reviewer screening) and clear categorization of use cases across nine educational task types
- **Medium Confidence:** The assessment of technological readiness levels (TRL) and performance metrics, limited by the fact that most innovations remain at early development stages (TRL-2-4)
- **Low Confidence:** Claims about bias mitigation effectiveness and privacy protection, given that only 11% of studies explicitly addressed these issues

## Next Checks

1. Attempt to replicate classification performance on simple educational tasks (sentiment analysis, intent detection) using zero-shot prompting with current state-of-the-art models
2. Test bias detection mechanisms on a diverse educational dataset to verify claims about societal bias amplification
3. Assess transparency levels of LLM-based educational tools with both AI experts and educators to validate the proposed transparency index tiers