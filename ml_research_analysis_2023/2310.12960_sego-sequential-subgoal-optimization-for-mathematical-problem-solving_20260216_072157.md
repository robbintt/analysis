---
ver: rpa2
title: 'SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving'
arxiv_id: '2310.12960'
source_url: https://arxiv.org/abs/2310.12960
tags:
- subgoal
- sego
- math
- arxiv
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SEGO (Sequential Subgoal Optimization), a
  novel framework that enhances large language models' ability to solve mathematical
  problems. SEGO establishes a theoretical connection between the subgoal breakdown
  process and the probability of solving problems, then uses sequential subgoal optimization
  to identify better subgoals.
---

# SEGO: Sequential Subgoal Optimization for Mathematical Problem-Solving

## Quick Facts
- arXiv ID: 2310.12960
- Source URL: https://arxiv.org/abs/2310.12960
- Reference count: 27
- Primary result: 72.5% accuracy on GSM8K and 40.0% on MATH benchmarks using a 13B model

## Executive Summary
SEGO (Sequential Subgoal Optimization) is a novel framework that enhances large language models' ability to solve mathematical problems by optimizing intermediate subgoals. The framework establishes a theoretical connection between subgoal breakdown processes and problem-solving probability, then uses sequential optimization to identify better subgoals. By incorporating these optimized subgoals into policy model training, SEGO significantly improves mathematical problem-solving performance on standard benchmarks.

## Method Summary
SEGO implements a five-module framework: Subgoal Generator creates initial subgoal drafts, Subgoal Optimizer refines them through sequential optimization using annealed importance sampling, Reward Model evaluates subgoal quality, Policy Model solves problems using the optimized subgoals, and Likelihood Estimator approximates the probability of reaching goals. The system is trained using instruction finetuning on data collected from gpt-3.5-turbo-0613 across GSM8K, MATH, and AQuA datasets. Sequential subgoal optimization is performed through a transition operator that balances exploration and exploitation in the vast search space of possible subgoals.

## Key Results
- Achieves 72.5% accuracy on GSM8K benchmark with 13B model
- Reaches 40.0% accuracy on MATH benchmark with 13B model
- Outperforms existing methods with comparable model sizes
- Demonstrates consistent improvement over no-optimization baseline (-Sequential variant)

## Why This Works (Mechanism)

### Mechanism 1
Sequential subgoal optimization improves mathematical problem-solving by finding better intermediate subgoals that increase the probability of reaching the final goal. SEGO uses annealed importance sampling to navigate the vast search space of possible subgoals, accepting improved subgoals through a transition operator that balances exploration and exploitation. Core assumption: The optimal subgoal distribution can be approximated through sequential sampling with carefully designed transition criteria.

### Mechanism 2
The evidence lower bound (ELBO) provides a theoretical foundation for quantifying the effectiveness of subgoal selection. SEGO constructs an ELBO that lower bounds the probability of solving the complete problem, allowing optimization of subgoal selection through the EM algorithm. Core assumption: The ELBO can be accurately estimated and optimized even in complex mathematical problem spaces.

### Mechanism 3
Instruction finetuning of auxiliary modules enables effective subgoal generation and optimization. The subgoal generator and optimizer modules are trained through instruction finetuning on data collected from gpt-3.5-turbo-0613, allowing them to produce contextually appropriate subgoals. Core assumption: The instruction finetuning approach can effectively teach the modules to generate useful subgoals for mathematical problems.

## Foundational Learning

- **Concept**: Annealed Importance Sampling (AIS)
  - Why needed here: AIS provides the theoretical foundation for navigating the vast search space of possible subgoals efficiently
  - Quick check question: What is the key advantage of AIS over standard importance sampling in high-dimensional spaces?

- **Concept**: Evidence Lower Bound (ELBO) in variational inference
  - Why needed here: The ELBO provides a theoretically grounded metric for quantifying the effectiveness of subgoal selection
  - Quick check question: How does the ELBO relate to the true log-likelihood in variational inference?

- **Concept**: Instruction finetuning for code generation
  - Why needed here: Instruction finetuning enables the auxiliary modules to understand and generate contextually appropriate mathematical subgoals
  - Quick check question: What are the key differences between instruction finetuning and standard supervised finetuning?

## Architecture Onboarding

- **Component map**: Problem → Subgoal Generator → Sequential Optimization (Subgoal Optimizer) → Policy Model → Solution
- **Critical path**: Problem → Subgoal Generator → Sequential Optimization (Subgoal Optimizer) → Policy Model → Solution
- **Design tradeoffs**: 
  - Model size vs. performance: 13B model achieves 72.5% on GSM8K vs. 68.7% for 7B
  - Sequential optimization steps (N and η) vs. computational cost
  - Quality of instruction finetuning data vs. effectiveness of subgoal generation
- **Failure signatures**:
  - Poor subgoal generation: Reward model consistently rejects subgoals
  - Ineffective optimization: Subgoal quality plateaus quickly during training
  - Likelihood estimator drift: Estimates become uncorrelated with actual success probability
- **First 3 experiments**:
  1. Verify sequential optimization improves over no optimization by training -Sequential variant
  2. Test different values of N and η to find optimal balance between performance and computation
  3. Evaluate the impact of instruction finetuning quality on subgoal generator effectiveness

## Open Questions the Paper Calls Out
- What is the theoretical upper bound on the improvement in problem-solving accuracy that can be achieved through sequential subgoal optimization, and how does this bound scale with problem complexity?
- How does the performance of SEGO compare when using different base language models (e.g., GPT-4 vs. CodeLLaMA) for the policy model and auxiliary modules?
- What is the impact of subgoal validity on long-term learning and generalization beyond the training distribution?

## Limitations
- Theoretical foundation relies on assumptions about subgoal distributions that aren't empirically validated across diverse mathematical domains
- Performance is evaluated only on GSM8K and MATH benchmarks, leaving effectiveness for complex mathematical domains untested
- Heavy reliance on synthetic data from gpt-3.5-turbo-0613 without thorough analysis of data quality impact

## Confidence

**High Confidence**: Sequential subgoal optimization improves performance over baseline methods; larger models consistently outperform smaller models; framework architecture is clearly defined and implementable

**Medium Confidence**: Theoretical guarantees provided by ELBO and AIS in this specific context; scalability to more complex mathematical domains; sensitivity of performance to hyperparameters across different problem types

**Low Confidence**: Robustness to variations in instruction finetuning data quality; effectiveness of reward model and likelihood estimator across diverse problem distributions; computational efficiency compared to alternatives

## Next Checks
1. Conduct ablation study on training data quality by systematically varying the quality and diversity of instruction finetuning data
2. Evaluate SEGO on mathematical domains not represented in GSM8K or MATH to assess generalizability
3. Compare wall-clock time and computational resources required by SEGO against alternative subgoal optimization methods across different model sizes and problem complexities