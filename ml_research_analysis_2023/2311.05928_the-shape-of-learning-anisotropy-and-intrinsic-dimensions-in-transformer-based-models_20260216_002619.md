---
ver: rpa2
title: 'The Shape of Learning: Anisotropy and Intrinsic Dimensions in Transformer-Based
  Models'
arxiv_id: '2311.05928'
source_url: https://arxiv.org/abs/2311.05928
tags:
- anisotropy
- embeddings
- intrinsic
- training
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the anisotropy dynamics and intrinsic dimension
  of embeddings in transformer architectures, comparing encoders and decoders. The
  key findings reveal that decoder embeddings exhibit a distinct bell-shaped anisotropy
  profile with highest concentrations in middle layers, contrasting with the uniformly
  distributed anisotropy in encoders.
---

# The Shape of Learning: Anisotropy and Intrinsic Dimensions in Transformer-Based Models

## Quick Facts
- **arXiv ID**: 2311.05928
- **Source URL**: https://arxiv.org/abs/2311.05928
- **Reference count**: 11
- **Key outcome**: Decoder embeddings exhibit bell-shaped anisotropy with highest concentrations in middle layers, while intrinsic dimension shows initial expansion followed by compression during training

## Executive Summary
This study investigates the geometric properties of embeddings in transformer architectures, comparing encoders and decoders through the lens of anisotropy and intrinsic dimension. The research reveals that decoder embeddings display a distinctive bell-shaped anisotropy profile with peak concentrations in middle layers, contrasting with the uniform distribution observed in encoders. Additionally, the intrinsic dimension of decoder embeddings follows a two-phase training pattern: initial expansion into higher-dimensional space followed by compression toward more compact representations. These findings provide new insights into the contrasting behavior of encoder and decoder transformer architectures and their geometric properties during training.

## Method Summary
The study analyzes transformer embeddings using singular value decomposition (SVD) to compute anisotropy scores and the Facco et al. method to estimate intrinsic dimension. Embeddings are extracted from various transformer models and grouped into batches of at least 4096 elements, which are then shuffled for intrinsic dimension calculation. The preprocessing pipeline involves cleaning the enwik8 dataset by removing code, media, and HTML tags while maintaining a 205-character vocabulary. Anisotropy is calculated as the ratio of the top singular value to the sum of all singular values, while intrinsic dimension is estimated through linear regression on the log-transformed ratio of nearest-neighbor distances.

## Key Results
- Decoder embeddings show a bell-shaped anisotropy profile with highest concentrations in middle layers, contrasting with uniformly distributed anisotropy in encoders
- Intrinsic dimension of decoder embeddings follows a two-phase training pattern: initial expansion followed by compression toward compact representations
- Local isotropy within global anisotropy characterizes transformer embeddings, enhancing model expressiveness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decoder embeddings exhibit a distinct bell-shaped anisotropy profile with highest concentrations in middle layers
- Mechanism: The decoder architecture's causal self-attention mechanism creates a progression where early layers handle sequential dependencies while middle layers achieve optimal balance between context expansion and representation refinement, resulting in concentrated anisotropy
- Core assumption: The self-attention mechanism in decoders inherently creates different geometric properties compared to encoders due to the causal masking and autoregressive nature
- Evidence anchors: [abstract] "Our findings reveal that the anisotropy profile in transformer decoders exhibits a distinct bell-shaped curve, with the highest anisotropy concentrations in the middle layers." [section] "In contrast to the encoders, decoders showcase a unique bell-shaped structure, indicating that the middle layers tend to have a higher anisotropy concentration among all examined models."

### Mechanism 2
- Claim: Intrinsic dimension of decoder embeddings follows a two-phase training pattern: initial expansion followed by compression
- Mechanism: During early training, the model explores higher-dimensional representations to capture diverse linguistic patterns, then refines these into more compact representations as training progresses and the model converges on optimal feature representations
- Core assumption: The training dynamics naturally progress from exploration to exploitation, with the model initially needing to discover diverse representations before refining them
- Evidence anchors: [abstract] "the intrinsic dimension of embeddings increases in the initial phases of training, indicating an expansion into higher-dimensional space. Which is then followed by a compression phase towards the end of training with dimensionality decrease, suggesting a refinement into more compact representations." [section] "The initial stages exhibit a sharp rise, indicating the model's attempt to map the information to higher dimensional spaces. However, as training progresses, there is a notable decline, suggesting a subsequent phase where the model compresses this information, refining more compact concepts."

### Mechanism 3
- Claim: Local isotropy within global anisotropy characterizes transformer embeddings
- Mechanism: While embeddings show global directional bias (anisotropy), within local neighborhoods they maintain isotropy, which enhances model expressiveness by allowing diverse local representations while maintaining global coherence
- Core assumption: The balance between global and local geometric properties is essential for effective representation learning in transformers
- Evidence anchors: [section] "Recent research reveals that global anisotropy is a common trait among all transformer-based architectures... However, within local subspaces, isotropy prevails, enhancing model expressiveness and contributing to high performance in downstream tasks."

## Foundational Learning

- Concept: Singular Value Decomposition (SVD) for anisotropy calculation
  - Why needed here: SVD is used to decompose the embedding matrix and compute anisotropy scores by analyzing the distribution of singular values
  - Quick check question: If you have a matrix with singular values [10, 2, 1], what would the anisotropy score be using the formula provided in the paper?

- Concept: Intrinsic dimension estimation via neighborhood distances
  - Why needed here: The method estimates intrinsic dimension by analyzing how the volume of neighborhoods scales with dimension, using the ratio of distances to nearest neighbors
  - Quick check question: If the cumulative distribution function F(μ) = (1 - μ^(-d)) and you observe that log(1 - F(μ))/log(μ) ≈ 3, what is the estimated intrinsic dimension?

- Concept: Causal vs. non-causal attention mechanisms
  - Why needed here: Understanding the difference between decoder (causal) and encoder (non-causal) attention is crucial for interpreting why they show different anisotropy profiles
  - Quick check question: How does causal masking in decoder attention affect the ability of tokens to attend to future context compared to encoder attention?

## Architecture Onboarding

- Component map: Data pipeline: enwik8 dataset preprocessing (removing code, media, HTML tags) → batching (min 4096 elements) → embedding extraction → Analysis pipeline: SVD computation for anisotropy → nearest neighbor distance analysis for intrinsic dimension → layer-wise averaging with standard deviation → Model coverage: BERT, RoBERTa, ALBERT (encoders) vs OPT, Llama-2, GPT2, GPT-J, Falcon (decoders)

- Critical path: Embedding extraction → batch processing → metric computation (anisotropy/intrinsic dimension) → layer-wise aggregation → cross-model comparison

- Design tradeoffs: The choice of batch size (4096 minimum) balances statistical reliability against computational efficiency. Larger batches provide more stable estimates but require more memory and computation time.

- Failure signatures: Uniform anisotropy across all layers might indicate insufficient model diversity or training issues. Missing the bell-shaped profile in decoders could suggest architectural modifications or training anomalies.

- First 3 experiments:
  1. Verify the bell-shaped anisotropy profile by computing layer-wise anisotropy scores for a pretrained decoder model like GPT-2, plotting the results to confirm the middle-layer concentration
  2. Test the two-phase intrinsic dimension pattern by training a decoder from scratch on enwik8, periodically measuring intrinsic dimension across training steps to observe the expansion-compression dynamic
  3. Compare encoder vs decoder anisotropy by training identical architectures with and without causal masking, measuring how the attention mechanism affects the geometric properties of embeddings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do anisotropy dynamics and intrinsic dimensionality patterns vary across different architectures, datasets, and training configurations beyond the models examined in this study?
- Basis in paper: [explicit] The paper acknowledges limitations in model diversity and notes that findings are based on specific transformer models, with generalization to all architectures not guaranteed
- Why unresolved: The study focused on a limited set of transformer models and datasets, leaving open the question of how these patterns generalize to other architectures, training approaches, and data domains
- What evidence would resolve it: Comprehensive studies across diverse transformer architectures (different sizes, pretraining objectives), various datasets (different domains, sizes), and multiple training configurations (different hyperparameters, objectives) would help establish the generality of these patterns

### Open Question 2
- Question: What is the relationship between anisotropy patterns and downstream task performance in transformer models?
- Basis in paper: [inferred] While the paper identifies distinct anisotropy patterns in encoders and decoders, it notes that the direct implications of these patterns on downstream tasks remain to be fully explored
- Why unresolved: The study focuses on characterizing anisotropy and intrinsic dimensionality patterns but does not establish a clear connection to practical performance implications in downstream tasks
- What evidence would resolve it: Systematic experiments correlating anisotropy patterns with performance across various downstream tasks would clarify whether these patterns have practical significance for model effectiveness

### Open Question 3
- Question: What are the underlying mechanisms driving the two-phase training behavior observed in intrinsic dimensionality, and how can this knowledge be leveraged to improve training efficiency?
- Basis in paper: [explicit] The paper observes a two-phase dynamic in intrinsic dimension but doesn't fully explain the mechanisms behind this behavior or its implications for training optimization
- Why unresolved: While the paper identifies the pattern of initial expansion followed by compression in intrinsic dimensionality, it doesn't provide a theoretical explanation for why this occurs or how to leverage this understanding for practical benefits
- What evidence would resolve it: Detailed analysis of the training dynamics, including monitoring of internal representations and attention patterns during both phases, combined with experiments testing different training strategies based on these insights, would help explain and utilize this phenomenon

## Limitations

- The study relies on a character-level language modeling task (enwik8) rather than typical token-level benchmarks, which may limit generalizability to standard NLP applications
- The batch size requirement (≥4096) for intrinsic dimension estimation creates computational constraints that may affect the robustness of the findings
- The analysis focuses on static embeddings rather than contextualized representations during inference, potentially missing dynamic geometric properties

## Confidence

- **High confidence**: The decoder bell-shaped anisotropy profile (Claim supported by direct visualization and consistent across multiple decoder models)
- **Medium confidence**: The two-phase intrinsic dimension pattern (Observed in training dynamics but requires further validation across different architectures and tasks)
- **Medium confidence**: The global-local anisotropy distinction (Theoretical grounding is strong, but empirical verification across diverse model families needs expansion)

## Next Checks

1. **Cross-task validation**: Test the anisotropy and intrinsic dimension patterns on standard NLP benchmarks (GLUE, SuperGLUE) to verify if the character-level findings generalize to token-level tasks
2. **Architectural ablation study**: Systematically remove or modify self-attention mechanisms in decoders to determine if the bell-shaped anisotropy profile depends specifically on causal masking or other architectural features
3. **Temporal dynamics analysis**: Track how anisotropy and intrinsic dimension evolve during individual training epochs rather than just across training checkpoints to better understand the mechanistic drivers of the two-phase pattern