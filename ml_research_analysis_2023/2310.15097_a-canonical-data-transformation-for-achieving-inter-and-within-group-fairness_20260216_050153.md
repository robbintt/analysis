---
ver: rpa2
title: A Canonical Data Transformation for Achieving Inter- and Within-group Fairness
arxiv_id: '2310.15097'
source_url: https://arxiv.org/abs/2310.15097
tags:
- fairness
- group
- feature
- framework
- within-group
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of ensuring fairness in machine
  learning by introducing a framework that satisfies both inter-group and within-group
  fairness. The core method idea involves mapping feature vectors of individuals from
  different demographic groups to an inter-group-fair canonical domain, preserving
  the relative relationships within groups to guarantee within-group fairness.
---

# A Canonical Data Transformation for Achieving Inter- and Within-group Fairness

## Quick Facts
- arXiv ID: 2310.15097
- Source URL: https://arxiv.org/abs/2310.15097
- Authors: 
- Reference count: 38
- Key outcome: Pre-processing framework achieves inter- and within-group fairness with minimal accuracy loss compared to regularization-based methods on COMPAS and Law School datasets.

## Executive Summary
This paper introduces a pre-processing framework that addresses the challenge of achieving both inter-group and within-group fairness in machine learning. The core idea is to map feature vectors from different demographic groups to an inter-group-fair canonical domain while preserving relative relationships within groups. This is accomplished through a transformation based on k-d trees that maintains within-group fairness by keeping score relationships intact. The framework demonstrates superior performance compared to regularization-based approaches, achieving significant fairness improvements with minimal accuracy degradation across multiple datasets and model types.

## Method Summary
The framework works by first splitting the dataset by sensitive attributes, then using histogram specification to map group score distributions to match the population distribution. Feature correspondences are established between group and population feature vectors, and new feature vectors are mapped using a weighted combination of their k-nearest neighbors in the group domain via k-d trees. This pre-processing transformation allows baseline models (Logistic Regression, MLP, SVM) to achieve both inter-group fairness (threshold-invariant demographic parity) and within-group fairness with minimal accuracy loss. For comparison, regularization-based methods incorporating Earth Mover's distance and Kullback-Leibler divergence regularizers are also implemented during training.

## Key Results
- The pre-processing framework achieves both inter-group and within-group fairness on COMPAS and Law School datasets
- Framework demonstrates superior performance with minimal accuracy loss compared to regularization-based methods
- Significant reduction in unfairness metrics while maintaining high accuracy and AUC across multiple baseline models
- Pre-processing approach avoids the accuracy-fairness tradeoff typically seen in regularization methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The pre-processing framework preserves within-group fairness by mapping feature vectors to a canonical domain while maintaining relative score relationships within each group.
- Mechanism: The framework uses histogram specification to transform group score distributions to match the population distribution, then constructs feature correspondences between group and population feature vectors. New feature vectors are mapped using a weighted combination of their k-nearest neighbors in the group domain, preserving the relative ordering of scores within each group.
- Core assumption: The distance between scores is correlated with the distance between feature vectors in the input space, ensuring that close scores correspond to close feature vectors.
- Evidence anchors:
  - [abstract] "The mapping is constructed to preserve the relative relationship between the scores obtained from the unprocessed feature vectors of individuals from the same demographic group, guaranteeing within-group fairness."
  - [section] "Because the scores in ˆs(i)tr and str are approximately equally distributed, each score in ˆs(i)tr should be close in distance to some score in str."
  - [corpus] Weak evidence - corpus does not provide specific details about the mechanism of preserving within-group fairness.
- Break condition: If the correlation between score distance and feature vector distance breaks down, the mapping may not preserve relative score relationships within groups.

### Mechanism 2
- Claim: The pre-processing framework achieves inter-group fairness by transforming group feature distributions to match the population distribution.
- Mechanism: Histogram specification is used to map the score distributions of each group to the population score distribution. This creates a correspondence between feature vectors in each group and the population, allowing the framework to transform group feature vectors to the canonical population domain.
- Core assumption: Equalizing score distributions across groups leads to equal treatment of individuals from different groups, satisfying inter-group fairness criteria.
- Evidence anchors:
  - [abstract] "The framework maps the feature vectors of members from different groups to an inter-group-fair canonical domain before feeding them into a scoring function."
  - [section] "We then perform histogram specification [14] to map the distribution of scores associated with each group to the population score distribution."
  - [corpus] Weak evidence - corpus does not provide specific details about how equalizing score distributions achieves inter-group fairness.
- Break condition: If equalizing score distributions does not lead to equal treatment of individuals from different groups, inter-group fairness may not be achieved.

### Mechanism 3
- Claim: The pre-processing framework outperforms regularization-based methods by avoiding the accuracy-fairness tradeoff.
- Mechanism: Regularization methods must balance accuracy and fairness during training, often leading to a decrease in accuracy to achieve fairness. The pre-processing framework transforms features before training, allowing the baseline model to maintain high accuracy while achieving fairness.
- Core assumption: Transforming features before training does not significantly impact the model's ability to learn accurate decision boundaries.
- Evidence anchors:
  - [abstract] "This is achieved through a pre-processing transformation based on k-d trees... demonstrating superior performance in achieving fairness with minimal accuracy loss compared to regularization-based methods."
  - [section] "Experimental results demonstrate that our pre-processing framework can achieve both inter-group and within-group fairness with little penalty on accuracy."
  - [corpus] Weak evidence - corpus does not provide specific details about the accuracy-fairness tradeoff in regularization methods.
- Break condition: If feature transformation significantly impacts the model's ability to learn accurate decision boundaries, the pre-processing framework may not outperform regularization methods.

## Foundational Learning

- Concept: K-d trees and nearest neighbor search
  - Why needed here: K-d trees are used to efficiently find the nearest neighbors of new feature vectors in the group domain, allowing for their mapping to the population domain.
  - Quick check question: How does the time complexity of constructing a k-d tree compare to that of a Delaunay triangulation for high-dimensional data?

- Concept: Histogram specification
  - Why needed here: Histogram specification is used to transform group score distributions to match the population distribution, creating feature correspondences between groups and the population.
  - Quick check question: Why is histogram specification a monotonically increasing transform, and how does this property ensure the preservation of within-group fairness?

- Concept: Threshold-invariant fairness
  - Why needed here: The framework aims to achieve threshold-invariant demographic parity, which requires equal score distributions across groups regardless of the decision threshold.
  - Quick check question: How does the framework ensure that equalizing score distributions leads to threshold-invariant fairness, and what are the potential limitations of this approach?

## Architecture Onboarding

- Component map: Baseline model training -> Histogram specification and feature correspondence establishment -> K-d tree construction and feature mapping -> Score calculation and decision making

- Critical path: The critical path involves constructing the k-d trees and using them to map new feature vectors from the group domain to the population domain. This process must be efficient to allow for real-time decision making.

- Design tradeoffs: The choice between using k-d trees and Delaunay triangulation for manifold representation involves a tradeoff between computational efficiency and the quality of the feature mapping. K-d trees are more efficient but may not capture the manifold structure as well as Delaunay triangulation.

- Failure signatures: If the framework fails to achieve fairness, potential causes include a breakdown in the correlation between score distance and feature vector distance, or an inability to construct accurate feature correspondences between groups and the population.

- First 3 experiments:
  1. Verify that histogram specification correctly transforms group score distributions to match the population distribution.
  2. Test the accuracy of the k-d tree nearest neighbor search for mapping new feature vectors.
  3. Evaluate the framework's ability to achieve both inter-group and within-group fairness on a small, well-understood dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the framework perform on datasets with multiple sensitive attributes?
- Basis in paper: [inferred] The paper focuses on scenarios where a single binary sensitive attribute creates inter-group unfairness. However, it mentions that the framework has the potential to be generalized to other forms of data, such as image data, and to datasets with multiple sensitive attributes.
- Why unresolved: The paper only provides experimental results for datasets with a single sensitive attribute. It does not explore the performance of the framework on datasets with multiple sensitive attributes, which could be a common scenario in real-world applications.
- What evidence would resolve it: Experimental results on datasets with multiple sensitive attributes, comparing the framework's performance to methods designed for multi-attribute fairness, would provide evidence to resolve this question.

### Open Question 2
- Question: How does the choice of k (number of nearest neighbors) in the k-d tree affect the framework's performance?
- Basis in paper: [explicit] The paper mentions that the number of nearest neighbors (k) is set to 10 for all experiments, but it does not explore how different values of k affect the framework's performance.
- Why unresolved: The paper does not provide any analysis or discussion on the sensitivity of the framework to the choice of k. Different values of k could potentially lead to different mappings and affect the framework's ability to achieve inter- and within-group fairness.
- What evidence would resolve it: Conducting experiments with different values of k and analyzing the impact on the framework's performance would provide evidence to resolve this question.

### Open Question 3
- Question: How does the framework handle continuous sensitive attributes?
- Basis in paper: [inferred] The paper focuses on scenarios where the sensitive attribute is binary (e.g., race). However, in real-world applications, sensitive attributes are often continuous (e.g., age, income). The paper does not discuss how the framework would handle such continuous sensitive attributes.
- Why unresolved: The paper does not provide any theoretical analysis or experimental results on how the framework would perform when dealing with continuous sensitive attributes. This is a limitation as many real-world applications involve continuous sensitive attributes.
- What evidence would resolve it: Extending the framework to handle continuous sensitive attributes and conducting experiments on datasets with continuous sensitive attributes would provide evidence to resolve this question.

## Limitations

- The framework's performance on datasets with multiple sensitive attributes has not been evaluated
- The impact of different k values in k-d trees on framework performance remains unexplored
- Handling of continuous sensitive attributes is not addressed in the current framework

## Confidence

- High: The mechanism for preserving within-group fairness through maintaining relative score relationships is well-supported by the theoretical framework and experimental results.
- Medium: Uncertainties exist regarding the framework's robustness when the correlation between score distance and feature vector distance breaks down.
- Medium: While the paper demonstrates that equalizing score distributions leads to inter-group fairness, the general applicability to other fairness definitions and domains is less certain.
- Medium: The framework's performance compared to regularization-based methods is well-established for tested datasets and models, but effectiveness for more complex models or different data types remains to be seen.

## Next Checks

1. Test the framework's robustness to varying correlations between score distance and feature vector distance by introducing controlled noise in the input space and measuring the impact on within-group fairness.

2. Evaluate the framework's ability to achieve other fairness definitions, such as equalized odds or predictive parity, on datasets with different sensitive attributes and outcome variables.

3. Compare the framework's performance and fairness metrics against regularization-based methods on a wider range of datasets, including high-dimensional data and non-binary classification tasks.