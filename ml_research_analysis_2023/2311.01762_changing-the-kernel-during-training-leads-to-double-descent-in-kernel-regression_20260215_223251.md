---
ver: rpa2
title: Changing the Kernel During Training Leads to Double Descent in Kernel Regression
arxiv_id: '2311.01762'
source_url: https://arxiv.org/abs/2311.01762
tags:
- bandwidth
- training
- constant
- data
- decreasing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the effects of changing the bandwidth of
  translational-invariant kernels during training when solving kernel regression with
  gradient descent. It presents a theoretical bound on the out-of-sample generalization
  error that advocates for decreasing the bandwidth during training, thus increasing
  model complexity.
---

# Changing the Kernel During Training Leads to Double Descent in Kernel Regression

## Quick Facts
- arXiv ID: 2311.01762
- Source URL: https://arxiv.org/abs/2311.01762
- Authors: 
- Reference count: 40
- The paper presents a theoretical bound showing that decreasing bandwidth during training leads to double descent behavior in kernel regression, with improved generalization compared to constant bandwidth approaches.

## Executive Summary
This paper investigates kernel regression with time-varying bandwidth during gradient descent training. The authors present a theoretical bound on generalization error that advocates for decreasing bandwidth during training, increasing model complexity gradually. This approach leads to double descent behavior when model complexity is measured by minimum bandwidth, with benign overfitting occurring at very small minimum bandwidths. The method is demonstrated to outperform constant-bandwidth approaches selected by cross-validation or marginal likelihood maximization on both synthetic and real data, and is extended to neural networks through neural tangent kernel modification.

## Method Summary
The method implements kernel gradient descent (KGD) with a bandwidth schedule that decreases σ during training based on the speed of R² improvement. The bandwidth update follows a rule where σ is reduced when the R² speed falls below a threshold vR², while ensuring σ never drops below a minimum value σm. The theoretical foundation comes from a generalization bound showing that decreasing bandwidth helps avoid both small k*_2 (weighted average of kernel norms) early in training and small smin (minimum eigenvalue) later in training. The algorithm is compared against constant-bandwidth kernel ridge regression with bandwidths selected by generalized cross-validation (GCV) and marginal likelihood maximization (MML).

## Key Results
- Decreasing bandwidth during training leads to double descent behavior as a function of minimum bandwidth σm
- Kernel regression with decreasing bandwidth outperforms constant-bandwidth approaches selected by GCV or MML
- Decreasing bandwidth all the way to zero results in benign overfitting, circumventing model selection
- The approach extends to neural networks via neural tangent kernel modification, reducing overfitting and iteration count

## Why This Works (Mechanism)

### Mechanism 1
Decreasing the bandwidth during training allows the model to start simple and increase complexity gradually, avoiding early overfitting while enabling later fine-tuning to zero training error. Kernel gradient descent with a bandwidth schedule mimics forward stagewise additive modeling. Early large bandwidths yield low-complexity models that capture broad patterns; as bandwidth shrinks, model complexity increases, fitting residuals left by simpler models. This progression prevents both underfitting and extreme predictions. The core assumption is that model complexity is inversely related to bandwidth; generalization improves when complexity grows during training.

### Mechanism 2
The bound on out-of-sample error supports bandwidth reduction by showing the error term scales with k*_2 / smin, both of which improve when bandwidth is large early and small later. Proposition 1 bounds |fμ(x*)| ≤ k*_2 · min(t, 1/smin) · ||yμ||2. Here k*_2 is weighted average of k* norms, which is small if bandwidth is large early; smin is time-average smallest eigenvalue, which is small if bandwidth is large for long. The bound indicates generalization is good when neither term is too small. The core assumption is that the generalization error bound directly governs practical performance and can be used to justify the bandwidth schedule.

### Mechanism 3
Double descent arises because for very small minimum bandwidth σm, both k*_2 and 1/smin shrink, making the error term k*_2 / smin moderate and yielding good generalization despite zero training error. Table 1 and section 4 show that for large σm, errors are high; as σm decreases, training error drops and test error rises (classical overfitting); for very small σm with decreasing bandwidth, test error drops again due to benign overfitting. This is because k*_2/smin becomes small, preventing extreme predictions. The core assumption is that the interplay between training time, minimum bandwidth, and bound terms creates a non-monotonic test error curve.

## Foundational Learning

- Concept: Kernel ridge regression (KRR) and its gradient flow solution
  - Why needed here: The paper builds on KRR as the baseline and extends it via gradient descent; understanding the closed-form solution and its equivalence to gradient flow is essential for grasping the non-constant kernel extension.
  - Quick check question: What is the relationship between the regularization parameter λ in KRR and the training time t in kernel gradient flow?

- Concept: Bandwidth (σ) in translational-invariant kernels and its effect on model complexity
  - Why needed here: Bandwidth controls the smoothness of the kernel; small σ yields complex, localized models, large σ yields smooth, global models. The paper's core claim is that varying σ during training controls complexity progression.
  - Quick check question: How does the model's derivative norm scale with σ according to Proposition 3?

- Concept: Double descent phenomenon and overfitting
  - Why needed here: The paper's key empirical result is double descent as a function of minimum bandwidth; understanding how overfitting can be benign at very high complexity is central.
  - Quick check question: Why does zero training error sometimes coincide with good generalization in highly overparameterized regimes?

## Architecture Onboarding

- Component map: Data → Kernel matrix K(σ) → Gradient descent updates → Bandwidth schedule → Predictions
- Critical path: 1. Initialize with large σ0 → 2. Compute KGD updates → 3. Monitor R² speed → 4. Decrease σ when speed < vR2 → 5. Repeat until convergence or σm reached
- Design tradeoffs: Bandwidth decrease speed (too fast → underfitting; too slow → overfitting), choice of kernel (Matérn ν, Cauchy) affects smoothness and double descent shape, regularization λ vs training time t (λ=1/t links closed-form and gradient flow solutions)
- Failure signatures: Poor training R² despite decreasing σ (bandwidth schedule too aggressive), high test error after convergence (overfitting due to insufficient regularization or too small σm), singular kernel matrices (σ too small relative to data scale)
- First 3 experiments: 1. Synthetic linear + sinusoidal data: compare KGD with decreasing σ vs KRR with constant σ selected by GCV/MML; verify improved R² and absence of hump in error curve. 2. U.K. temperature data: run 366 daily folds; test if decreasing σ yields lower test error and more stable p-values across days. 3. Double descent curve: fix λ=0.001, vary minimum σm over 100 values; plot training vs test error for both constant and decreasing σ to confirm second descent.

## Open Questions the Paper Calls Out

### Open Question 1
How does the bandwidth update scheme proposed in the paper generalize to non-translational invariant kernels? The paper focuses on translational-invariant kernels and proposes a bandwidth-decreasing scheme based on R2 on training data. It does not discuss how this scheme might be adapted for other types of kernels. Empirical studies comparing the performance of the proposed bandwidth update scheme on different types of kernels (e.g., polynomial, sigmoid, etc.) would provide evidence for or against the generalizability of the scheme.

### Open Question 2
How sensitive is the proposed bandwidth update scheme to the choice of the minimum R2 speed parameter (vR2)? The paper mentions that the minimum R2 speed, vR2, controls the decrease of the bandwidth and that the choice of vR2 = 0.05 leads to good performance. However, it does not provide a systematic study of the sensitivity of the scheme to different values of vR2. Empirical studies varying the value of vR2 and measuring the resulting performance of the bandwidth update scheme would provide evidence for the sensitivity of the scheme to this parameter.

### Open Question 3
Can the proposed bandwidth update scheme be extended to other iterative optimization methods beyond kernel gradient descent? The paper discusses the relationship between kernel gradient descent and forward stagewise additive modeling, suggesting that the proposed bandwidth update scheme could be viewed as a way to increase model complexity during training. This raises the question of whether similar schemes could be applied to other iterative optimization methods. Empirical studies applying the proposed bandwidth update scheme to other iterative optimization methods (e.g., gradient boosting, neural networks) would provide evidence for or against the generalizability of the scheme.

## Limitations
- The theoretical bound relies on kernel smoothness assumptions that may not hold for all kernel types, particularly the Laplace kernel with discontinuous derivatives.
- The empirical validation is limited to specific synthetic and real-world datasets, leaving generalizability to other domains unclear.
- The connection between benign overfitting and the specific bandwidth schedule is theoretically motivated but not rigorously proven beyond the presented bound.

## Confidence
- High confidence: The empirical demonstration of double descent behavior when varying minimum bandwidth is well-supported by experiments on both synthetic and real data.
- Medium confidence: The theoretical bound provides reasonable justification for the bandwidth schedule, though its practical applicability depends on kernel properties and data characteristics.
- Medium confidence: The extension to neural networks via neural tangent kernel modification shows promise but requires further validation across diverse network architectures.

## Next Checks
1. Test the decreasing bandwidth approach on diverse datasets including high-dimensional image data and text embeddings to assess generalization beyond the current domains.
2. Conduct ablation studies varying the rate of bandwidth decrease and R² speed threshold to determine optimal scheduling parameters across different problem types.
3. Extend the neural tangent kernel experiments to multiple network architectures (CNNs, transformers) and tasks to verify the robustness of the overfitting mitigation claim.