---
ver: rpa2
title: Counterfactual Explanations for Time Series Forecasting
arxiv_id: '2310.08137'
source_url: https://arxiv.org/abs/2310.08137
tags:
- forecasting
- time
- series
- counterfactual
- forecastcf
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the novel problem of generating counterfactual
  explanations for time series forecasting, a task previously unexplored in the literature.
  The authors propose ForecastCF, a gradient-based algorithm that perturbs input time
  series to generate counterfactuals satisfying user-defined lower and upper bound
  constraints on forecasted values over a time horizon.
---

# Counterfactual Explanations for Time Series Forecasting

## Quick Facts
- arXiv ID: 2310.08137
- Source URL: https://arxiv.org/abs/2310.08137
- Reference count: 40
- Primary result: Introduces ForecastCF, a gradient-based algorithm for generating counterfactual explanations in time series forecasting, outperforming baselines in validity and data manifold closeness

## Executive Summary
This paper addresses the novel problem of generating counterfactual explanations for time series forecasting. The authors propose ForecastCF, a gradient-based algorithm that perturbs input time series to generate counterfactuals satisfying user-defined lower and upper bound constraints on forecasted values. Evaluated across six real-world datasets and four deep learning architectures, ForecastCF demonstrates significantly higher validity ratios and stepwise validity AUC compared to baseline methods while maintaining strong data manifold closeness.

## Method Summary
ForecastCF employs gradient-based perturbation to modify input time series such that forecasted values fall within specified bounds. The algorithm uses a loss function combining deviation from constraint bounds with a masking vector to focus updates on violating timesteps. Two instantiations for desired trajectory bounds are formulated using polynomial trends, allowing customization through hyperparameters. The method is evaluated using validity ratio, stepwise validity AUC, proximity, and compactness metrics across GRU, Seq2seq, WaveNet, and N-Beats architectures trained on CIF2016, NN5, Tourism, M4 Finance, SP500, and MIMIC datasets.

## Key Results
- ForecastCF achieves validity ratios of 0.699-0.867 versus 0.216-0.576 for baselines
- Stepwise validity AUC scores reach 0.567-0.686 compared to 0.008-0.367 for baselines
- Proximity scores range from 0.12 to 0.51 and compactness remains above 0.59 for most datasets
- Performance improves with smaller desired change percentages and wider constraint bounds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ForecastCF generates counterfactuals by perturbing the input time series using gradient descent to minimize a loss function that enforces desired forecast constraints.
- Mechanism: The algorithm applies gradient-based perturbations to the input time series x to obtain a counterfactual x′ such that the forecasted values f(x′) fall within specified lower and upper bound constraints. The loss function L combines the deviation from these bounds with a masking vector to focus updates only on timesteps violating the constraints.
- Core assumption: The forecasting model f is differentiable, allowing gradients to be computed with respect to the input time series.
- Evidence anchors:
  - [abstract] "ForecastCF, a gradient-based algorithm that perturbs input time series to generate counterfactuals satisfying user-defined lower and upper bound constraints on forecasted values over a time horizon."
  - [section] "We propose ForecastCF, an example-based approach to explaining the forecasted values of a black-box forecasting model. Our approach employs gradient-based perturbation for generating the counterfactuals..."
  - [corpus] Weak evidence: The corpus contains papers on counterfactual explanations for time series but lacks direct discussion of gradient-based perturbation mechanisms for forecasting.
- Break condition: The forecasting model is non-differentiable, or the perturbation leads to counterfactuals that fall outside the data manifold.

### Mechanism 2
- Claim: ForecastCF uses instantiations of desired trajectory bounds to define the lower and upper bound constraints for the forecasted values.
- Mechanism: The algorithm provides two instantiations for defining the desired trajectory bounds: polynomial trend and polynomial trend with limitations. These instantiations allow customization of the counterfactual generation process by specifying hyperparameters like center function, shift, fraction of standard deviation, desired change percent, and polynomial order.
- Core assumption: The desired trajectory bounds can be accurately represented using polynomial functions or polynomial functions with additional constraints.
- Evidence anchors:
  - [section] "In this section, we formulate two instantiations for desired trajectory bounds in our proposed algorithm. We show that the desired trajectory can be customized by a range of hyperparameters to provide the upper bound vector α and the lower bound vector β."
  - [section] "Polynomial trend. In the polynomial trend instantiation, we define five hyperparameters to choose the desired prediction outcome: center function c(·), shift s, fraction of standard deviation f r, the desired change percent cp, and the polynomial order poly order."
  - [corpus] Weak evidence: The corpus mentions counterfactual explanations for time series but does not provide specific details on instantiations of desired trajectory bounds.
- Break condition: The desired trajectory bounds cannot be accurately represented using the proposed instantiations, or the hyperparameters cannot be effectively tuned for a given dataset.

### Mechanism 3
- Claim: ForecastCF achieves high validity and data manifold closeness by generating counterfactuals that satisfy the desired forecast constraints while remaining close to the original time series.
- Mechanism: The algorithm uses the validity ratio and stepwise validity AUC metrics to measure the proportion of counterfactual forecasts that satisfy the desired constraints. It also employs proximity and compactness metrics to ensure that the generated counterfactuals are close to the original time series and maintain similarity to the original timesteps.
- Core assumption: The proposed metrics accurately capture the validity and data manifold closeness of the generated counterfactuals.
- Evidence anchors:
  - [abstract] "Our results show that ForecastCF outperforms the baseline in terms of counterfactual validity and data manifold closeness."
  - [section] "We adopt evaluation metrics from recent counterfactual studies to the forecasting setup. We consider two groups of metrics: (a) validity and (b) data manifold closeness."
  - [corpus] Weak evidence: The corpus contains papers on counterfactual explanations for time series but lacks specific discussion on the validity and data manifold closeness metrics used in ForecastCF.
- Break condition: The metrics do not accurately capture the validity and data manifold closeness of the generated counterfactuals, or the algorithm fails to generate counterfactuals that satisfy the desired constraints while remaining close to the original time series.

## Foundational Learning

- Concept: Gradient-based optimization
  - Why needed here: ForecastCF relies on gradient descent to perturb the input time series and generate counterfactuals that satisfy the desired forecast constraints.
  - Quick check question: What is the purpose of using gradient-based optimization in ForecastCF, and how does it differ from other optimization techniques?

- Concept: Counterfactual explanations
  - Why needed here: ForecastCF generates counterfactual explanations for time series forecasting, which provide actionable insights into how the input time series can be modified to achieve desired forecast outcomes.
  - Quick check question: How do counterfactual explanations differ from other interpretability techniques, and what are their key advantages in the context of time series forecasting?

- Concept: Polynomial functions
  - Why needed here: ForecastCF uses polynomial functions to define the desired trajectory bounds for the forecasted values, allowing customization of the counterfactual generation process.
  - Quick check question: What are the advantages of using polynomial functions to represent the desired trajectory bounds, and how do they compare to other function types?

## Architecture Onboarding

- Component map:
  Input time series x -> Forecasting model f(·) -> Lower and upper bound constraints α and β -> Gradient-based perturbation algorithm -> Validity and data manifold closeness metrics -> Instantiations for desired trajectory bounds

- Critical path:
  1. Receive input time series x and define desired trajectory bounds α and β
  2. Apply gradient-based perturbations to x to generate counterfactual x′
  3. Evaluate the validity and data manifold closeness of the generated counterfactual
  4. Iterate until a valid counterfactual is found or maximum iterations are reached

- Design tradeoffs:
  - Tradeoff between validity and data manifold closeness: Higher validity may require more significant modifications to the original time series, potentially reducing data manifold closeness.
  - Choice of instantiation for desired trajectory bounds: Different instantiations may be more suitable for different datasets or forecasting tasks.
  - Hyperparameter tuning: The performance of ForecastCF depends on the careful selection of hyperparameters, such as learning rate and desired change percent.

- Failure signatures:
  - Low validity ratio and stepwise validity AUC: The generated counterfactuals fail to satisfy the desired forecast constraints.
  - High proximity and low compactness: The counterfactuals are too far from the original time series or lack similarity to the original timesteps.
  - Non-convergence: The algorithm fails to find a valid counterfactual within the maximum number of iterations.

- First 3 experiments:
  1. Evaluate the validity and data manifold closeness of ForecastCF on a simple univariate time series dataset with known ground truth counterfactuals.
  2. Compare the performance of ForecastCF with different instantiations for desired trajectory bounds on a real-world time series dataset.
  3. Investigate the impact of hyperparameter tuning on the performance of ForecastCF using an ablation study.

## Open Questions the Paper Calls Out
- Question: How do counterfactual explanations perform when applied to multivariate time series forecasting tasks?
- Basis in paper: [explicit] The paper mentions extending the solution to multivariate forecasting and integrating exogenous variables as future work.
- Why unresolved: The current work only focuses on univariate time series forecasting, leaving the multivariate case unexplored.
- What evidence would resolve it: Experimental results comparing ForecastCF's performance on multivariate datasets against baseline methods and existing approaches for multivariate forecasting.

- Question: What is the impact of different constraint functions (beyond polynomial trends) on the quality and validity of counterfactual explanations?
- Basis in paper: [explicit] The paper mentions that constraint bounds can be defined using other forms of functions, such as exponential or trigonometric functions, but only demonstrates polynomial trend instantiations.
- Why unresolved: Only polynomial trend and polynomial trend with limitations instantiations are evaluated, limiting understanding of how different constraint shapes affect counterfactual generation.
- What evidence would resolve it: Comparative experiments applying ForecastCF with various constraint functions (exponential, trigonometric, etc.) across multiple datasets to assess validity, proximity, and compactness metrics.

- Question: How does the performance of counterfactual explanations vary across different deep learning architectures beyond the four tested (GRU, Seq2seq, WaveNet, N-Beats)?
- Basis in paper: [explicit] The paper evaluates ForecastCF on four specific DL architectures but suggests future work could extend to other forecasting models.
- Why unresolved: The study is limited to four architectures, and the performance on other state-of-the-art or emerging architectures remains unknown.
- What evidence would resolve it: Empirical results showing ForecastCF's effectiveness across a broader range of DL architectures, including transformers, attention-based models, and statistical models without DL.

## Limitations
- The gradient-based perturbation mechanism assumes differentiable forecasting models, limiting applicability to non-differentiable or black-box models where gradients cannot be computed.
- The polynomial trend instantiation for desired trajectory bounds may not capture complex real-world patterns, and the empirical determination of hyperparameters lacks theoretical guarantees.
- The evaluation focuses primarily on validity and proximity metrics, with limited discussion of computational efficiency or scalability to longer time series.

## Confidence
- High confidence: The gradient-based perturbation mechanism and overall framework design are well-founded and clearly explained.
- Medium confidence: The choice of evaluation metrics and comparison with baselines is appropriate, though the baselines may not represent state-of-the-art counterfactual methods.
- Low confidence: The empirical determination of hyperparameters and their sensitivity to different datasets is not thoroughly explored.

## Next Checks
1. **Robustness to model architecture**: Test ForecastCF across a broader range of forecasting models, including non-differentiable and ensemble methods, to assess generalizability.
2. **Hyperparameter sensitivity analysis**: Conduct systematic ablation studies varying learning rates, max iterations, and fraction values across all datasets to understand stability and optimal configurations.
3. **Real-world deployment test**: Apply ForecastCF to a practical forecasting scenario with domain experts to validate the actionability and interpretability of generated counterfactuals beyond quantitative metrics.