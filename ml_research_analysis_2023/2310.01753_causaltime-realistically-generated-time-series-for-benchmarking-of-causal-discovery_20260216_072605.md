---
ver: rpa2
title: 'CausalTime: Realistically Generated Time-series for Benchmarking of Causal
  Discovery'
arxiv_id: '2310.01753'
source_url: https://arxiv.org/abs/2310.01753
tags:
- causal
- time-series
- discovery
- datasets
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CausalTime introduces a pipeline to generate realistic time-series
  data with ground-truth causal graphs for benchmarking time-series causal discovery
  (TSCD) algorithms. The method fits real-world time-series using a causally disentangled
  neural network (CDNN) combined with normalizing flows to capture dynamics and noise.
---

# CausalTime: Realistically Generated Time-series for Benchmarking of Causal Discovery

## Quick Facts
- arXiv ID: 2310.01753
- Source URL: https://arxiv.org/abs/2310.01753
- Reference count: 40
- One-line primary result: Introduces pipeline to generate realistic time-series data with ground-truth causal graphs for benchmarking time-series causal discovery algorithms.

## Executive Summary
CausalTime introduces a pipeline to generate realistic time-series data with ground-truth causal graphs for benchmarking time-series causal discovery (TSCD) algorithms. The method fits real-world time-series using a causally disentangled neural network (CDNN) combined with normalizing flows to capture dynamics and noise. Hypothetical causal graphs are extracted via DeepSHAP or prior knowledge, then refined into actual causal graphs by splitting the model into causal, residual, and noise terms. Generated data closely mimics real observations across diverse domains (e.g., air quality, traffic, healthcare), validated via PCA/t-SNE visualization, discriminative scores, and MMD metrics. Benchmarking on CausalTime shows existing TSCD algorithms achieve lower AUROC/AUPRC compared to synthetic benchmarks, highlighting the dataset's realism and the need for improved algorithms.

## Method Summary
The CausalTime pipeline generates realistic time-series data with ground-truth causal graphs for benchmarking TSCD algorithms. It first fits real-world time-series using a causally disentangled neural network (CDNN) with normalizing flows to capture dynamics and noise. Then, it extracts hypothesized causal graphs via DeepSHAP importance analysis or prior knowledge (e.g., geographic distance thresholds). The hypothesized graphs are refined into actual causal graphs by splitting the NAR model into causal, residual, and noise terms. Finally, the pipeline generates time-series data using autoregressive sampling with the derived causal graph, closely resembling the original observations. The generated datasets are validated through visualization, discriminative scores, and MMD metrics, and used to benchmark TSCD algorithms.

## Key Results
- CausalTime-generated datasets closely mimic real-world time-series across diverse domains (air quality, traffic, healthcare).
- Existing TSCD algorithms achieve lower AUROC/AUPRC on CausalTime versus synthetic benchmarks, highlighting the realism and difficulty of the generated data.
- The pipeline generalizes across fields and provides a rigorous evaluation framework for TSCD algorithms.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Deep neural networks with normalizing flows can accurately capture realistic time-series dynamics.
- Mechanism: The causally disentangled neural network (CDNN) architecture separates causal effects into distinct MLP/LSTM paths for each output variable, preventing interference between variables. Normalizing flows model the residual noise distributions with high fidelity.
- Core assumption: The time-series dynamics are stationary and can be approximated by a NAR model with additive noise.
- Evidence anchors:
  - [abstract]: "harness deep neural networks along with normalizing flow to accurately capture realistic dynamics"
  - [section]: "we fit the dynamic process of multivariate time-series with a deep neural network and normalizing flow"
- Break condition: If the time-series exhibits non-stationary behavior or the NAR assumption is violated, the fitting accuracy will degrade.

### Mechanism 2
- Claim: DeepSHAP importance analysis can extract contributing causal parents from the fitted neural network.
- Mechanism: By computing Shapley values for each input variable's contribution to each output prediction, the method identifies which variables are most influential in the NAR model.
- Core assumption: The fitted neural network faithfully represents the underlying data-generating process, so feature importance correlates with causal relevance.
- Evidence anchors:
  - [abstract]: "we extract hypothesized causal graphs by performing importance analysis on the neural network"
  - [section]: "we now proceed to extract a hypothetical causal graph (HCG) H by identifying the most contributing variables"
- Break condition: If the NAR model fitting is poor or the neural network is uninterpretable, the importance analysis may not reflect true causal structure.

### Mechanism 3
- Claim: Splitting the NAR model into causal, residual, and noise terms preserves data fidelity while generating with an actual causal graph.
- Mechanism: The method keeps the causal term (using only parents from the HCG), adds back the residual term (capturing non-causal dependencies), and adds the noise term, maintaining the original dynamics.
- Core assumption: The residual term captures the instantaneous effects and other dependencies not represented in the causal graph.
- Evidence anchors:
  - [abstract]: "we derive the ground truth causal graphs by splitting the causal model into causal term, residual term, and noise term"
  - [section]: "we propose to split the NAR model taking the form of a fully connected graph into causal term, residual term, and noise term"
- Break condition: If the residual term is incorrectly estimated or the noise model is misspecified, the generated data may not match the original distribution.

## Foundational Learning

- Concept: Vector autoregression (VAR) models
  - Why needed here: The NAR model is a generalization of VAR that allows nonlinear functions instead of linear combinations
  - Quick check question: What is the key difference between VAR and NAR models in terms of functional form?

- Concept: Shapley values and feature importance
  - Why needed here: DeepSHAP uses Shapley values to quantify each input variable's contribution to each output prediction, enabling causal parent identification
  - Quick check question: How do Shapley values assign importance in a way that satisfies efficiency, symmetry, and additivity properties?

- Concept: Normalizing flows for density estimation
  - Why needed here: Normalizing flows learn invertible transformations to model complex noise distributions, improving upon simple Gaussian assumptions
  - Quick check question: What is the key mathematical property that allows normalizing flows to perform density estimation?

## Architecture Onboarding

- Component map: Data preprocessing -> NAR fitting (CDNN + Normalizing flow) -> HCG extraction (DeepSHAP or prior graph) -> Generation with ACG -> Evaluation
- Critical path: Data → NAR fitting → HCG extraction → Generation with ACG → Evaluation
- Design tradeoffs:
  - CDNN vs component-wise networks: More parameters vs weight sharing and efficiency
  - DeepSHAP sparsity level: Higher sparsity (fewer edges) vs lower sparsity (more edges)
  - Scheduled sampling probability: Reduces error accumulation vs slower convergence
- Failure signatures:
  - Poor NAR fitting: High MSE on held-out data, time-series distributions don't match
  - Incorrect HCG: Generated time-series have different dependencies than original
  - Bad noise modeling: Generated data has incorrect autocorrelation or marginal distributions
- First 3 experiments:
  1. Fit CDNN to synthetic VAR data with known structure, verify MSE and recovered graph accuracy
  2. Apply pipeline to simple real dataset (e.g., air quality), check visualization similarity and discriminative score
  3. Generate with different HCG sparsity levels, measure impact on TSCD algorithm performance

## Open Questions the Paper Calls Out
- Question: How does the CausalTime pipeline perform when extended to multi-scale causal effects that exist widely in realistic time-series?
- Basis in paper: [inferred] The paper mentions this as a future work direction, noting that most causal discovery algorithms do not consider long-term or multi-scale associations.
- Why unresolved: The current implementation uses a restricted NAR model with a maximum time lag τmax, which does not account for multi-scale associations.
- What evidence would resolve it: Testing the CausalTime pipeline on datasets with known multi-scale causal effects and comparing the performance to the current single-scale implementation.

## Limitations
- The pipeline's performance heavily depends on the accuracy of NAR model fitting and the interpretability of DeepSHAP importance scores.
- Normalizing flow noise modeling assumes invertible residual distributions, which may not hold for all real-world time-series.
- Benchmark results comparing TSCD algorithms on CausalTime versus synthetic datasets depend on the realism of the generated data matching real causal discovery tasks.

## Confidence
- High confidence: The CDNN architecture can fit time-series data with reasonable accuracy, and the autoregressive generation process is well-defined.
- Medium confidence: DeepSHAP can extract meaningful causal parent relationships from the fitted NAR model, though this depends on the model's faithfulness.
- Low confidence: The normalizing flow noise modeling perfectly captures the residual distributions, and the generated time-series fully represent real-world causal discovery challenges.

## Next Checks
1. Apply the pipeline to synthetic VAR data with known ground truth and quantify the accuracy of recovered causal graphs using AUROC/AUPRC metrics.
2. Compare TSCD algorithm performance on CausalTime-generated data versus real-world datasets with known causal structures to validate benchmark realism.
3. Perform ablation studies on the NAR model components (causal, residual, noise terms) to measure their individual contributions to data fidelity and causal graph accuracy.