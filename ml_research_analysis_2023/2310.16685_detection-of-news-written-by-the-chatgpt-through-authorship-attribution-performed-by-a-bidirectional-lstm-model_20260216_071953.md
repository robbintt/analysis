---
ver: rpa2
title: Detection of news written by the ChatGPT through authorship attribution performed
  by a Bidirectional LSTM model
arxiv_id: '2310.16685'
source_url: https://arxiv.org/abs/2310.16685
tags:
- news
- chatgpt
- number
- used
- authorship
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of distinguishing ChatGPT-generated
  news articles from human-written ones, aiming to combat misinformation and restore
  trust in news sources. The authors built a dataset of 1,000 news articles, equally
  split between human-written and ChatGPT-generated content.
---

# Detection of news written by the ChatGPT through authorship attribution performed by a Bidirectional LSTM model

## Quick Facts
- arXiv ID: 2310.16685
- Source URL: https://arxiv.org/abs/2310.16685
- Reference count: 27
- Primary result: Bidirectional LSTM model achieves 91.57% accuracy in detecting ChatGPT-generated news articles

## Executive Summary
This paper presents a method for distinguishing ChatGPT-generated news articles from human-written ones using authorship attribution. The authors developed a dataset of 1,000 news articles (500 human, 500 AI-generated) and compared three classification approaches: XGBoost, Artificial Neural Network, and Bidirectional LSTM. The Bidirectional LSTM model significantly outperformed the others with 91.57% accuracy, while human evaluators achieved only 57.78% accuracy. The study demonstrates that machine learning models can effectively detect AI-generated content, offering a potential tool for combating misinformation in news media.

## Method Summary
The authors built a dataset of 1,000 news articles equally split between human-written and ChatGPT-generated content from BBC News, TechCrunch, and The Verge. Articles were processed through POS tagging to extract 13 stylometric features for traditional models (XGBoost and ANN) and 200-integer POS sequences for the Bidirectional LSTM. The LSTM model used 64 units in its bidirectional layer, 32 units in dense layers, and dropout of 0.2. The Bidirectional LSTM achieved 91.57% accuracy, significantly outperforming the ANN (83.15%) and XGBoost (81.05%) models.

## Key Results
- Bidirectional LSTM achieved 91.57% accuracy in detecting ChatGPT-generated news articles
- Human evaluators achieved only 57.78% accuracy in the same task
- XGBoost model achieved 81.05% accuracy using 13 stylometric features
- ANN model achieved 83.15% accuracy using the same 13-feature vector

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The bidirectional LSTM outperforms other models by capturing both forward and backward dependencies in POS tag sequences, encoding syntactic patterns that differ between human and AI-generated news.
- Mechanism: POS tags are converted to integer sequences of fixed length (200), embedded into 150-dimensional vectors, and processed by a bidirectional LSTM with 64 units. The backward pass conditions each tag prediction on future context, improving discrimination of subtle style differences.
- Core assumption: POS sequences of equal length preserve sufficient discriminative information for authorship attribution.
- Evidence anchors: Abstract states LSTM achieved 91.57% accuracy; section explains bidirectional LSTM allows previous and next terms to influence analysis.

### Mechanism 2
- Claim: XGBoost and ANN models perform worse because they rely on static stylometric features that miss deeper sequential patterns present in the text.
- Mechanism: XGBoost uses gradient boosting on 13 numeric features (e.g., punctuation ratio, POS tag frequencies), while ANN uses dense layers on the same flat feature vectors. Neither can model sequential dependencies beyond the static feature space.
- Core assumption: Stylometric features capture most discriminative signal, and sequential context doesn't significantly improve performance.
- Evidence anchors: Section reports XGBoost achieved 81.05% accuracy and ANN achieved 83.15% accuracy on the testing set.

### Mechanism 3
- Claim: Human evaluators perform poorly because they rely on subjective cues and lack the consistency of algorithmic feature extraction and classification.
- Mechanism: Human judgment is influenced by limited attention span and cognitive bias, whereas the LSTM applies uniform feature extraction and pattern matching across the entire sequence.
- Core assumption: Human evaluators can detect AI-generated text with sufficient training, but in practice lack systematic processing capacity.
- Evidence anchors: 63 people completed the study with average accuracy of 57.78%; abstract states human evaluators achieved only 57.78% accuracy.

## Foundational Learning

- Concept: Part-of-Speech (POS) tagging
  - Why needed here: Converts raw text into grammatical categories that capture syntactic patterns used for authorship attribution
  - Quick check question: What NLTK POS tagger was used to produce 226 possible categories for feature extraction?

- Concept: Stylometric feature extraction
  - Why needed here: Transforms linguistic properties into numeric features that classifiers can process
  - Quick check question: How many stylometric features were extracted in treatment number 1, and what categories do they cover?

- Concept: Bidirectional LSTM architecture
  - Why needed here: Enables modeling of both past and future context for each token, improving detection of sequential stylistic patterns
  - Quick check question: What are the dimensions of the embedding layer and the number of units in the bidirectional LSTM layer used in the best-performing model?

## Architecture Onboarding

- Component map: Text → Tokenization → POS tagging → Integer sequence conversion → Padding/truncation (200) → Embedding (150-dim) → Bidirectional LSTM (64 units) → Dense layers (32 units, ReLU) → Output layer (1 unit, sigmoid)
- Critical path: POS sequence generation → embedding → bidirectional LSTM → dense layers → binary classification
- Design tradeoffs: Fixed-length POS sequences simplify batching but may truncate informative context; embedding size (150) balances expressiveness and overfitting risk; bidirectional processing doubles context but increases computation
- Failure signatures: Low validation accuracy suggests overfitting or insufficient training data; very low training accuracy indicates underfitting or poor feature extraction; consistent bias toward one class suggests imbalanced dataset or weak discriminative features
- First 3 experiments:
  1. Train the bidirectional LSTM on the training set, validate on the validation set, and record accuracy
  2. Vary the embedding dimension (e.g., 100, 150, 200) to assess impact on performance
  3. Compare performance when using only forward LSTM vs. bidirectional LSTM to quantify the benefit of backward context

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the Bidirectional LSTM model generalize to news articles from sources other than BBC News, TechCrunch, and The Verge?
- Basis in paper: The authors explicitly state that their model was not tested on news from sources other than the three used in the dataset
- Why unresolved: The study only used news articles from three specific sources, limiting the model's generalizability
- What evidence would resolve it: Testing the model on a dataset containing news articles from a diverse range of sources and comparing its performance to the results obtained in the current study

### Open Question 2
- Question: What is the impact of the news article's length on the performance of the Bidirectional LSTM model?
- Basis in paper: The authors mention that article size was limited to prevent bias, but do not investigate the impact of length on model performance
- Why unresolved: The study does not explore how article length affects the model's ability to accurately classify them
- What evidence would resolve it: Conducting experiments with news articles of varying lengths and analyzing the model's performance for each length category

### Open Question 3
- Question: How does the performance of the Bidirectional LSTM model compare to other state-of-the-art models for authorship attribution on news articles?
- Basis in paper: The authors compare their model's performance to human evaluators but do not compare it to other models in the literature
- Why unresolved: The study does not provide a benchmark against other models for authorship attribution on news articles
- What evidence would resolve it: Implementing and testing other state-of-the-art models on the same dataset and comparing their performance to the Bidirectional LSTM model

## Limitations

- Dataset construction method may not reflect real-world ChatGPT usage patterns, as articles were generated by first summarizing human articles
- Dataset size of 1,000 articles is relatively small for authorship attribution tasks, potentially limiting generalization to diverse writing styles
- Fixed 200-token sequence length may truncate or pad informative context, affecting the model's ability to capture full stylistic patterns

## Confidence

- High Confidence: Experimental methodology and performance metrics are clearly reported; LSTM architecture specification and comparative performance are well-documented
- Medium Confidence: Human evaluator results support the claim that algorithmic detection outperforms human judgment, but small sample size (63 evaluators) limits interpretation
- Low Confidence: Transferability of results to real-world scenarios where ChatGPT might be used differently than the controlled generation process employed in this study

## Next Checks

1. **Dataset Diversity Validation:** Test the trained LSTM model on an independently collected dataset where ChatGPT-generated articles are produced using varied prompting strategies (direct rewrites, creative modifications, different temperature settings) to assess robustness to different generation approaches.

2. **Cross-Domain Generalization:** Evaluate model performance on news articles from domains not represented in the original dataset (e.g., scientific journals, opinion pieces, or social media content) to determine if the POS-based features generalize beyond the specific news sources used.

3. **Human-in-the-Loop Optimization:** Conduct controlled experiments training human evaluators on the specific POS and stylometric features that the LSTM uses, then compare their performance to the baseline 57.78% to determine if algorithmic advantages stem from superior pattern recognition or simply from consistent application of learned cues.