---
ver: rpa2
title: 'WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against
  Deep Neural Networks'
arxiv_id: '2310.11595'
source_url: https://arxiv.org/abs/2310.11595
tags:
- waveattack
- backdoor
- samples
- attack
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: WaveAttack is a novel frequency-based backdoor attack method that
  uses Discrete Wavelet Transform (DWT) to extract high-frequency features for trigger
  generation. The method introduces asymmetric frequency obfuscation by adding adaptive
  residuals in both training and inference stages to enhance attack effectiveness
  while maintaining high stealthiness.
---

# WaveAttack: Asymmetric Frequency Obfuscation-based Backdoor Attacks Against Deep Neural Networks

## Quick Facts
- arXiv ID: 2310.11595
- Source URL: https://arxiv.org/abs/2310.11595
- Reference count: 20
- Key outcome: WaveAttack achieves up to 28.27% improvement in PSNR, 1.61% improvement in SSIM, and 70.59% reduction in IS while maintaining high attack success rates

## Executive Summary
WaveAttack introduces a novel frequency-based backdoor attack method that leverages Discrete Wavelet Transform (DWT) to extract high-frequency features for trigger generation. The method uses asymmetric frequency obfuscation by applying different trigger strengths during training (α=1.0) and inference (α=100.0) to enhance stealthiness while maintaining attack effectiveness. Experimental results demonstrate that WaveAttack outperforms state-of-the-art backdoor attack methods across multiple datasets while remaining robust against existing defense mechanisms.

## Method Summary
WaveAttack decomposes images using DWT to extract the high-frequency HH component, where a U-Net-like generator creates imperceptible residuals that serve as backdoor triggers. During training, these triggers are added with a small coefficient (α=1.0) to minimize detection, while inference uses a larger coefficient (α=100.0) to ensure trigger activation. The method optimizes both the generator (using Adam) and the classifier (using SGD) simultaneously, with L∞ norm constraints on residuals and cross-entropy loss for classification. The approach maintains high image quality through high-frequency embedding while achieving effective backdoor attacks.

## Key Results
- Achieves up to 28.27% improvement in PSNR compared to state-of-the-art methods
- Demonstrates 1.61% improvement in SSIM while maintaining attack effectiveness
- Reduces Inception Score (IS) by 70.59% indicating better image fidelity
- Maintains high attack success rates across CIFAR-10, CIFAR-100, GTSRB, and ImageNet datasets
- Shows robustness against multiple existing backdoor defense mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: WaveAttack uses high-frequency components to embed triggers that are imperceptible to humans but still effective for DNNs
- Mechanism: The method extracts high-frequency features from images using Discrete Wavelet Transform (DWT), specifically the HH component, and adds subtle residuals to this component to create backdoor triggers
- Core assumption: DNNs are more sensitive to high-frequency features than humans, allowing triggers to remain invisible while maintaining attack effectiveness
- Evidence anchors:
  - [abstract] "wavelet transform has been widely investigated in various image-processing tasks" and "DWT to extract the high-frequency component for backdoor trigger generation"
  - [section] "Unlike humans that are not sensitive to high-frequency features, DNNs can effectively learn high-frequency features of images" and "it is much more difficult to figure out the difference between the original image and the poisoned counterpart on HH"
  - [corpus] Weak - corpus neighbors discuss backdoor detection methods but don't directly address frequency-based triggers

### Mechanism 2
- Claim: Asymmetric frequency obfuscation enhances attack effectiveness while maintaining stealthiness
- Mechanism: During training, triggers are added with a small coefficient (α=1.0) to minimize detection, but during inference, a larger coefficient (α=100.0) is used to ensure trigger activation
- Core assumption: The difference in trigger strength between training and inference stages can bypass detection methods while maintaining attack success
- Evidence anchors:
  - [abstract] "we introduce an asymmetric frequency obfuscation method, which can add an adaptive residual in the training and inference stage"
  - [section] "we employ a coefficient α with a small value (i.e., α=1.0) to improve the stealthy of triggers during the training process, while a larger value (i.e., α=100.0) is used to enhance the impact of triggers"
  - [corpus] Missing - no direct corpus evidence about asymmetric frequency obfuscation

### Mechanism 3
- Claim: WaveAttack maintains high image quality while achieving effective backdoor attacks
- Mechanism: By adding triggers only to the high-frequency component and using a U-Net-like generator to create imperceptible residuals, the method preserves image quality metrics (PSNR, SSIM) while achieving high attack success rates
- Core assumption: Adding triggers to high-frequency components has minimal impact on perceptual quality while maintaining attack effectiveness
- Evidence anchors:
  - [abstract] "WaveAttack not only achieves higher stealthiness and effectiveness, but also outperforms state-of-the-art (SOTA) backdoor attack methods in the fidelity of images by up to 28.27% improvement in PSNR"
  - [section] "it is much more difficult to figure out the difference between the original image and the poisoned counterpart on HH" and "the residual generated by WaveAttack is the smallest and leaves only a few subtle artifacts"
  - [corpus] Weak - corpus neighbors discuss backdoor attacks but don't specifically address frequency-based methods for maintaining image quality

## Foundational Learning

- Concept: Discrete Wavelet Transform (DWT) and its inverse (IDWT)
  - Why needed here: DWT is used to decompose images into frequency components, specifically to extract the high-frequency HH component where triggers are embedded
  - Quick check question: What are the four frequency components obtained from Haar wavelet decomposition using DWT?

- Concept: Asymmetric optimization techniques
  - Why needed here: The method uses different trigger strengths during training (α=1.0) versus inference (α=100.0) to balance stealthiness and effectiveness
  - Quick check question: Why does using different coefficients for training and inference help evade detection while maintaining attack success?

- Concept: Generator networks for creating imperceptible perturbations
  - Why needed here: A U-Net-like generator creates the residuals added to the high-frequency component, ensuring they remain imperceptible
  - Quick check question: What architectural feature of U-Net helps preserve input features while generating residuals?

## Architecture Onboarding

- Component map: Input images → DWT decomposition → HH component modification → IDWT reconstruction → classifier training → inference with asymmetric coefficients
- Critical path: DWT extraction of HH component → generator creation of residuals → asymmetric coefficient application → IDWT reconstruction → classifier training with modified samples
- Design tradeoffs: High-frequency trigger embedding provides better stealthiness but requires more computational resources than pixel-space attacks; asymmetric coefficients improve effectiveness but add complexity
- Failure signatures: Low attack success rate despite high PSNR/SSIM values indicates the high-frequency triggers aren't effectively activating the backdoor; detection by backdoor defense methods indicates the asymmetric approach isn't sufficient
- First 3 experiments:
  1. Implement basic DWT decomposition and IDWT reconstruction on sample images to verify frequency component extraction works correctly
  2. Create a simple generator that adds residuals to the HH component and measure PSNR/SSIM impact on sample images
  3. Train a small classifier with modified samples using asymmetric coefficients and test attack success rate on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does WaveAttack perform against adaptive defenses that specifically target frequency-based backdoor triggers?
- Basis in paper: [inferred] The paper demonstrates WaveAttack's robustness against several existing defenses but does not evaluate against defenses specifically designed to detect frequency-based attacks or analyze frequency domain characteristics.
- Why unresolved: Current defense evaluation focuses on general backdoor detection methods rather than specialized frequency-based detection techniques that could potentially identify the high-frequency trigger characteristics.
- What evidence would resolve it: Empirical results comparing WaveAttack against specialized frequency-based detection methods and defenses that analyze wavelet transform coefficients or frequency domain features.

### Open Question 2
- Question: What is the minimum poisoning rate required for WaveAttack to maintain effectiveness while preserving stealthiness?
- Basis in paper: [inferred] The paper uses a fixed 10% poisoning rate for experiments but does not systematically investigate the relationship between poisoning rate, attack success rate, and stealthiness metrics across different datasets.
- Why unresolved: Understanding the minimum effective poisoning rate is crucial for practical deployment and would help determine the attack's efficiency in resource-constrained scenarios.
- What evidence would resolve it: Comprehensive experiments varying the poisoning rate (e.g., 1%, 3%, 5%, 10%, 15%) while measuring ASR, PSNR, SSIM, and IS to identify the threshold where effectiveness drops below acceptable levels.

### Open Question 3
- Question: How does WaveAttack's performance generalize to real-world scenarios where the adversary has limited control over training data and processes?
- Basis in paper: [explicit] The paper acknowledges in the Broader Impact section that WaveAttack requires more computing resources and runtime overhead than existing methods, and notes limitations when the adversary can only control the training dataset rather than the full training process.
- Why unresolved: The current evaluation assumes full control over training, which may not reflect practical constraints where adversaries have limited access to training infrastructure or datasets.
- What evidence would resolve it: Experiments evaluating WaveAttack under constrained threat models with limited training data access, varying degrees of training process control, and different dataset distributions that better reflect real-world conditions.

## Limitations

- The method requires more computational resources and runtime overhead compared to existing backdoor attack methods
- Effectiveness may be limited when the adversary can only control the training dataset rather than the full training process
- Asymmetric frequency obfuscation, while effective, adds complexity that might be detected by sophisticated analysis of training-inference discrepancies

## Confidence

- **High confidence**: The core mechanism of using DWT to extract HH components for trigger embedding is technically sound and well-supported by the frequency sensitivity differences between humans and DNNs
- **Medium confidence**: The asymmetric coefficient approach (α=1.0 for training, α=100.0 for inference) appears effective but needs more rigorous testing against state-of-the-art detection methods
- **Medium confidence**: The image quality preservation claims (PSNR, SSIM improvements) are supported by experiments but could be affected by different dataset characteristics or model architectures

## Next Checks

1. Test WaveAttack's effectiveness against adaptive defense mechanisms that specifically look for training-inference discrepancies, particularly those analyzing feature space activations
2. Evaluate the method's performance across a broader range of DNN architectures beyond the ones tested (ResNet18, VGG16, SENet18, ResNeXt29, DenseNet121) to verify consistent effectiveness
3. Conduct ablation studies to quantify the individual contributions of the asymmetric coefficients and high-frequency embedding to overall attack success, separating their effects systematically