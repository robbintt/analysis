---
ver: rpa2
title: 'Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study
  on Wikidata'
arxiv_id: '2309.08491'
source_url: https://arxiv.org/abs/2309.08491
tags:
- knowledge
- llms
- wikidata
- context
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the task of knowledge base completion using
  large language models (LLMs) by predicting object entities given subject and relation
  pairs from Wikidata. The core method involves a two-step pipeline: knowledge probing
  using pre-trained LLMs with prompt engineering and few-shot learning, followed by
  entity mapping to Wikidata QIDs using the MediaWiki API and disambiguation techniques.'
---

# Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata

## Quick Facts
- arXiv ID: 2309.08491
- Source URL: https://arxiv.org/abs/2309.08491
- Reference count: 40
- Key result: Achieved macro-averaged F1-score of 0.701 across 21 Wikidata properties using GPT-3.5-turbo and GPT-4

## Executive Summary
This paper explores knowledge base completion using large language models (LLMs) by predicting object entities given subject and relation pairs from Wikidata. The authors develop a two-step pipeline: knowledge probing using pre-trained LLMs with prompt engineering and few-shot learning, followed by entity mapping to Wikidata QIDs using the MediaWiki API and disambiguation techniques. Experiments demonstrate that LLMs can effectively complete knowledge bases when appropriately applied, achieving a macro-averaged F1-score of 0.701 across 21 Wikidata properties, though performance varies significantly across domains and requires careful consideration of disambiguation methods.

## Method Summary
The paper presents a knowledge base completion approach using LLMs that operates through two main phases. First, knowledge probing uses pre-trained LLMs with carefully engineered prompt templates and few-shot learning to generate object entity predictions in string format. Second, entity mapping employs the MediaWiki Action API to search for candidate Wikidata entities matching the predicted strings, followed by domain-specific disambiguation methods (case-based, keyword-based, or LM-based) to select the correct QIDs. The system handles 21 Wikidata properties across 7 domains including music, television, sports, geography, chemistry, business, and public figure information.

## Key Results
- Achieved macro-averaged F1-score of 0.701 across 21 Wikidata properties
- F1-scores ranged from 0.328 to 1.00 across different properties
- GPT-4 outperformed GPT-3.5-turbo in most cases, though context effectiveness varied by model
- Retrieval-augmented context helped some relations but hurt others, depending on knowledge alignment
- Disambiguation methods reduced errors in 13 relations with observed disambiguation mistakes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large Language Models can act as knowledge repositories for structured data completion when guided with appropriate prompts and context.
- Mechanism: The pipeline uses few-shot learning with prompt engineering to elicit object predictions from LLMs, then maps those predictions to Wikidata QIDs via API lookup and disambiguation. This bridges natural language generation with structured KG representation.
- Core assumption: LLM predictions, when properly prompted and contextualized, will align with actual Wikidata facts and be mappable via labels and aliases.
- Evidence anchors:
  - [abstract] "utilize pre-trained LLMs to produce the relevant objects in string format and link them to their respective Wikidata QIDs"
  - [section 3.2.1] "we engineered prompt templates for probing knowledge from LLMs" and "perform few-shot learning"
  - [corpus] weak - corpus doesn't contain detailed evidence about LLM accuracy on structured knowledge; only cites related schema-generation work

### Mechanism 2
- Claim: Retrieval-augmented prompts improve LLM predictions by providing relevant Wikipedia context, but only for certain relations and models.
- Mechanism: For relations where Wikidata and Wikipedia knowledge diverge, adding Wikipedia intro/Infobox context can either help or hurt performance depending on alignment and LLM model capabilities.
- Core assumption: Wikipedia context will be relevant and consistent with Wikidata facts for the given subject-relation pairs.
- Evidence anchors:
  - [section 4.3] "providing relevant corpus as context to LLMs is an established method" and "we experimented with various sources and forms of context"
  - [section 4.3] "gpt-3.5-turbo benefits from the context more compared with GPT-4"
  - [corpus] weak - corpus neighbors focus on schema generation and data work, not context effectiveness

### Mechanism 3
- Claim: Domain-specific disambiguation methods (case-based, keyword-based, LM-based) effectively resolve entity mapping ambiguities where baseline methods fail.
- Mechanism: For relations with limited answer spaces, hard-coded rules map objects to correct QIDs; for larger spaces with common keywords, keyword filtering selects candidates; for open-ended relations, LLM-based selection chooses among candidates using descriptions.
- Core assumption: The disambiguation method chosen matches the structure of the answer space and can correctly resolve ambiguities.
- Evidence anchors:
  - [section 3.2.2] "treated different relations with three improved methods: case-based, keyword-based, and LM-based"
  - [section 4.4] "we observed disambiguation mistakes in 13 relations" and "implemented improved disambiguation methods"
  - [corpus] weak - no direct evidence in corpus about disambiguation effectiveness

## Foundational Learning

- Concept: Prompt Engineering and Few-Shot Learning
  - Why needed here: LLMs need structured prompts and examples to generate accurate predictions for knowledge base completion tasks
  - Quick check question: How would you design a prompt template for predicting "CountryHasOfficialLanguage" given a subject entity?

- Concept: Entity Linking and Disambiguation
  - Why needed here: LLM outputs are strings that must be mapped to specific Wikidata entities using labels, aliases, and descriptions
  - Quick check question: What are the limitations of using only the first candidate from MediaWiki API for entity mapping?

- Concept: Knowledge Graph Quality and Gaps
  - Why needed here: Wikidata incompleteness and knowledge gaps between Wikipedia and Wikidata affect LLM performance and highlight areas for improvement
  - Quick check question: How could LLM predictions help identify missing or outdated triples in Wikidata?

## Architecture Onboarding

- Component map:
  Input -> Prompt Engineering -> LLM Prediction -> MediaWiki API Search -> Disambiguation -> Wikidata QIDs

- Critical path:
  1. Receive subject-relation pair
  2. Select appropriate prompt template and disambiguation method
  3. Generate predictions via LLM
  4. Search candidates via MediaWiki API
  5. Apply disambiguation to select correct QIDs
  6. Return results

- Design tradeoffs:
  - Using GPT-4 vs gpt-3.5-turbo: Better accuracy but higher cost
  - Retrieval-augmented context: Can help or hurt depending on alignment
  - Disambiguation methods: Trade-off between coverage, accuracy, and computational cost

- Failure signatures:
  - Low F1 scores on specific relations (e.g., PersonHasEmployer) indicate LLM knowledge gaps
  - High disambiguation errors suggest label/alias mismatches in Wikidata
  - Performance drop with context suggests knowledge gap between Wikipedia and Wikidata

- First 3 experiments:
  1. Run baseline pipeline on test set with question prompts and baseline disambiguation
  2. Test retrieval-augmented context for relations with known Wikipedia-Wikidata alignment
  3. Apply improved disambiguation methods to relations with observed errors in baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the knowledge gap between Wikidata and Wikipedia be effectively bridged to improve LLM performance in knowledge base completion tasks?
- Basis in paper: [explicit] The paper discusses discrepancies between information in Wikidata and Wikipedia, citing examples like Ferrari S.p.A.'s parent company information.
- Why unresolved: The paper identifies the knowledge gap as an open issue but doesn't propose specific solutions for bridging it.
- What evidence would resolve it: Experiments demonstrating improved LLM performance when using techniques to align or reconcile conflicting information between Wikidata and Wikipedia sources.

### Open Question 2
- Question: What is the optimal strategy for combining multiple LLMs with complementary strengths to maximize knowledge base completion performance?
- Basis in paper: [explicit] The paper notes that different LLMs contain different knowledge and that an ensemble approach could lead to improved performance.
- Why unresolved: While the paper suggests this approach could be beneficial, it doesn't provide specific methods for combining or weighting different LLMs.
- What evidence would resolve it: Empirical results comparing various ensemble strategies (e.g., voting, weighted averaging, cascade approaches) across different types of knowledge base completion tasks.

### Open Question 3
- Question: How can LLMs be effectively integrated into collaborative knowledge engineering workflows to improve both efficiency and accuracy of knowledge base updates?
- Basis in paper: [explicit] The paper suggests LLMs could play a pivotal role in collaborative knowledge engineering but doesn't specify implementation details.
- Why unresolved: The paper identifies this as a promising direction but doesn't explore practical integration methods or human-AI interaction models.
- What evidence would resolve it: Case studies or user studies demonstrating successful integration of LLMs into existing knowledge engineering workflows, measuring both productivity gains and quality improvements.

## Limitations
- Performance variability across relations (F1-scores from 0.328 to 1.00) indicates approach isn't universally applicable
- String-based entity mapping through MediaWiki API search creates vulnerabilities when labels/aliases don't match LLM predictions
- Disambiguation methods still struggle with certain relations where answer spaces are large or knowledge gaps exist

## Confidence

- **High Confidence**: The overall pipeline architecture and methodology are well-established, with clear two-step process from LLM prediction to entity mapping. The reported F1-score of 0.701 macro average across 21 properties provides reliable baseline performance data.
- **Medium Confidence**: The effectiveness of retrieval-augmented context shows mixed results (helpful for some relations/models, detrimental for others), requiring careful evaluation before deployment. The domain-specific disambiguation methods show promise but their general applicability needs further validation.
- **Low Confidence**: The paper's claims about LLM knowledge coverage and the relationship between Wikipedia and Wikidata knowledge gaps are primarily observational without systematic analysis of underlying causes.

## Next Checks

1. **Ablation Study on Disambiguation Methods**: Test each disambiguation technique (case-based, keyword-based, LM-based) independently across all 21 relations to quantify their individual contributions and identify optimal selection criteria for different relation types.

2. **Knowledge Gap Analysis**: Systematically compare LLM predictions against Wikidata coverage for each relation domain to identify specific areas where knowledge is missing or outdated, and measure how frequently LLM predictions reveal actual knowledge gaps versus prediction errors.

3. **Context Effectiveness Validation**: Conduct controlled experiments varying Wikipedia context quality and relevance for relations where retrieval-augmented context showed mixed results, measuring the threshold at which context transitions from helpful to harmful.