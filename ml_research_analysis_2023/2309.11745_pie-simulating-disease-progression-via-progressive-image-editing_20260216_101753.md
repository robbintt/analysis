---
ver: rpa2
title: 'PIE: Simulating Disease Progression via Progressive Image Editing'
arxiv_id: '2309.11745'
source_url: https://arxiv.org/abs/2309.11745
tags:
- disease
- progression
- image
- diffusion
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes PIE, a novel framework for simulating disease
  progression in medical imaging using text-to-image generative models. PIE enables
  controlled manipulation of disease-related image features, allowing for precise
  and realistic disease progression simulation.
---

# PIE: Simulating Disease Progression via Progressive Image Editing

## Quick Facts
- arXiv ID: 2309.11745
- Source URL: https://arxiv.org/abs/2309.11745
- Reference count: 40
- Key outcome: PIE framework simulates disease progression in medical imaging using text-to-image generative models, outperforming baselines in realism and clinical alignment

## Executive Summary
PIE introduces a novel framework for simulating disease progression in medical imaging by leveraging text-to-image generative models. The method enables controlled manipulation of disease-related image features through iterative refinement, allowing for precise and realistic disease progression simulation. By theoretically analyzing the process as gradient descent with an exponentially decaying learning rate, PIE achieves superior performance in terms of CLIP score (realism) and disease classification confidence (alignment) compared to baseline methods. A user study with 35 veteran physicians found 76.2% agreement with the fidelity of the generated progressions, indicating clinical relevance.

## Method Summary
PIE fine-tunes Stable Diffusion on target medical datasets and uses iterative DDIM inversion with text conditioning to progressively edit disease-related features. The framework takes medical images, clinical reports, and ROI masks as inputs, then applies denoising diffusion with exponentially decaying step sizes to simulate disease progression. The method is evaluated on three medical imaging datasets (chest X-ray, retinopathy, skin lesion) using CLIP-I score for realism and disease classification confidence for alignment, with physician validation confirming clinical fidelity.

## Key Results
- Outperforms Stable Diffusion Walk and Style-Based Manifold Extrapolation baselines in CLIP score and disease classification confidence
- 76.2% physician agreement with fidelity of generated progressions in user study
- Achieves controlled disease progression simulation while maintaining image realism through ROI-constrained editing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PIE's iterative refinement process is equivalent to gradient descent with an exponentially decaying learning rate.
- Mechanism: Each PIE step performs DDIM inversion and denoising guided by clinical text, which translates mathematically into moving the latent representation along the negative log-likelihood gradient with a step size that shrinks geometrically.
- Core assumption: The optimal noise predictor in DDIM corresponds to the score function ∇x log p(x|y).
- Evidence anchors:
  - [abstract] "We theoretically analyze the iterative refining process in our framework as a gradient descent with an exponentially decayed learning rate."
  - [section] "From above, we can conclude that as n grows bigger the changes between steps would grow smaller."
  - [corpus] Weak - no direct external comparison found.
- Break condition: If the noise predictor deviates from the true score (e.g., due to training data bias or insufficient text alignment), the equivalence breaks down.

### Mechanism 2
- Claim: ROI masks constrain edits to disease-related regions while preserving unrelated image features.
- Mechanism: The mask MROI in Algorithm 1 blends edited and original pixels, ensuring progressive changes stay localized and do not corrupt non-disease anatomy.
- Core assumption: The mask accurately delineates disease extent in the image.
- Evidence anchors:
  - [abstract] "PIE allows for more precise and controllable manipulation of disease-related image features."
  - [section] "ROI mask for medical imaging can be extracted from real or synthetic clinical reports... It helps keep unrelated regions consistent through the progressive changes using PIE."
  - [corpus] Weak - no external validation of mask accuracy.
- Break condition: If the mask mislabels healthy tissue as disease, edits will corrupt non-disease areas.

### Mechanism 3
- Claim: Text conditioning via CLIP embeddings guides edits toward realistic disease manifestations.
- Mechanism: Clinical report y is embedded and used as conditioning in the denoising network, steering latent updates toward semantically consistent disease progression.
- Core assumption: The text embedding space aligns with visual disease features in the image domain.
- Evidence anchors:
  - [abstract] "leverage recent advancements in text-to-image generative models to simulate disease progression accurately and personalize it for each patient."
  - [section] "text conditioning [Rombach et al., 2022], which could either be real or simulated, providing the potential trajectory of the patient’s disease progression."
  - [corpus] Weak - no quantitative analysis of text-image alignment quality.
- Break condition: If the text and image modalities are poorly aligned, edits may produce unrealistic or clinically meaningless results.

## Foundational Learning

- Concept: Diffusion probabilistic models (DDPM)
  - Why needed here: PIE builds directly on DDIM's denoising framework; understanding the forward/reverse process is essential.
  - Quick check question: In DDIM, how is the latent at step t related to the previous step and noise?
- Concept: Text-to-image generative models (Stable Diffusion)
  - Why needed here: PIE fine-tunes Stable Diffusion for domain-specific medical imagery and uses its latent space for editing.
  - Quick check question: What is the role of the U-Net in Stable Diffusion during denoising?
- Concept: Gradient-based optimization in high-dimensional latent spaces
  - Why needed here: PIE's equivalence to gradient descent means understanding how gradients propagate in image latent spaces is critical.
  - Quick check question: Why does an exponentially decaying learning rate help in iterative image editing?

## Architecture Onboarding

- Component map: Input medical image → DDIM inversion → Denoising U-Net (text-guided) → ROI-constrained blending → Next step iteration
- Critical path: 1) Fine-tune Stable Diffusion on medical dataset, 2) Generate ROI masks, 3) Run PIE for N steps with text conditioning, 4) Evaluate with classification confidence and CLIP-I
- Design tradeoffs:
  - Higher γ → faster progression but risk of artifacts
  - Larger N → smoother changes but longer runtime
  - Strict ROI mask → better preservation but less context adaptation
- Failure signatures:
  - Sudden unrealistic appearance changes → γ too high
  - No disease progression visible → γ too low or mask too restrictive
  - Mode collapse or repetitive patterns → insufficient fine-tuning data
- First 3 experiments:
  1. Run PIE on a held-out healthy image with a known disease text prompt; verify CLIP-I stays high while confidence rises.
  2. Vary γ from 0.1 to 0.8; plot confidence vs CLIP-I to identify stable operating region.
  3. Compare outputs with and without ROI mask on a validation set; quantify preservation of non-disease anatomy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between maintaining the realism of the original image and the progressive addition of disease features, particularly for complex diseases with overlapping symptoms?
- Basis in paper: [inferred] The paper discusses the importance of maintaining realism and controlling the modification of disease features. However, it doesn't explicitly explore the trade-offs for complex diseases with overlapping symptoms.
- Why unresolved: The paper focuses on single-disease progression and doesn't delve into the complexities of simulating multiple co-occurring diseases with overlapping symptoms. The theoretical analysis and ablation studies focus on individual parameters but don't specifically address the challenge of balancing realism and disease progression in complex cases.
- What evidence would resolve it: Experiments comparing the performance of PIE on single diseases versus co-occurring diseases with overlapping symptoms, with metrics that specifically evaluate the realism of the original image features alongside the accuracy of disease progression.

### Open Question 2
- Question: How does the performance of PIE vary across different medical imaging modalities (e.g., MRI, CT scans) and disease types, and what are the specific challenges and adaptations needed for each?
- Basis in paper: [explicit] The paper demonstrates PIE's effectiveness on three medical imaging datasets (chest X-ray, retinopathy, skin lesion) but doesn't explore its performance on other modalities like MRI or CT scans.
- Why unresolved: The paper focuses on a limited set of medical imaging modalities and disease types. The theoretical analysis and ablation studies are not specific to different imaging modalities or disease types, leaving questions about PIE's generalizability and the specific challenges and adaptations needed for other scenarios.
- What evidence would resolve it: Experiments applying PIE to a wider range of medical imaging modalities and disease types, with detailed analysis of the performance differences and the specific challenges and adaptations required for each.

### Open Question 3
- Question: What are the ethical implications of using AI-generated disease progression images in clinical decision-making, and how can we ensure responsible and unbiased use of this technology?
- Basis in paper: [explicit] The paper acknowledges the potential negative social impacts of using AI-generated images in clinical settings, including privacy concerns, accuracy issues, and potential discrimination.
- Why unresolved: The paper raises important ethical considerations but doesn't provide concrete solutions or guidelines for ensuring responsible and unbiased use of the technology. The user study focuses on physician agreement with the fidelity of the generated progressions but doesn't address the broader ethical implications of using these images in clinical decision-making.
- What evidence would resolve it: Development and implementation of ethical guidelines and regulations for using AI-generated disease progression images in clinical settings, along with studies evaluating the impact of these guidelines on clinical decision-making and patient outcomes.

## Limitations

- Mask Generation and Accuracy: The paper relies on ROI masks extracted from clinical reports but does not provide validation of mask accuracy against ground truth annotations, leaving a critical dependency unverified.
- Generalization Across Disease Types: The framework is tested on three distinct medical imaging modalities but does not establish whether the same hyperparameters generalize across different disease progression patterns.
- Text-Image Alignment Quality: The framework assumes clinical text embeddings align with visual disease features, but no quantitative analysis is provided to verify this alignment.

## Confidence

**High Confidence**: The theoretical analysis of PIE as gradient descent with exponentially decaying learning rate is well-supported by the mathematical derivation. The proof follows standard diffusion model theory and the connection to DDIM is clear.

**Medium Confidence**: The superiority claims over baselines are supported by quantitative metrics and physician agreement, but the user study sample size (35 physicians) is relatively small for medical validation.

**Low Confidence**: The mask generation process and its impact on simulation quality is not adequately validated. The paper states masks can be "extracted from real or synthetic clinical reports" but provides no details on the extraction methodology or accuracy assessment.

## Next Checks

1. **Mask Accuracy Validation**: Implement ground truth comparison between generated ROI masks and expert-annotated disease regions on a held-out validation set. Calculate IoU scores to quantify mask precision and assess impact on simulation quality.

2. **Cross-Disease Hyperparameter Transferability**: Test the framework on a fourth medical imaging dataset with different disease progression patterns. Systematically vary γ and N parameters to determine if the same optimal settings generalize or require disease-specific tuning.

3. **Cross-Modal Alignment Analysis**: Conduct quantitative evaluation of text-to-image alignment by computing CLIP similarity between clinical reports and their corresponding disease stages. Compare against random text pairs to establish baseline alignment quality and identify potential failure modes in text-guided editing.