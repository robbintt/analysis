---
ver: rpa2
title: 'Simple diffusion: End-to-end diffusion for high resolution images'
arxiv_id: '2301.11093'
source_url: https://arxiv.org/abs/2301.11093
tags:
- diffusion
- resolution
- zero
- alt1
- simple
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces \"simple diffusion,\" a technique for training\
  \ high-resolution diffusion models without the complexity of cascades or latent\
  \ spaces. The key findings include: 1) adjusting the noise schedule to add more\
  \ noise at higher resolutions, 2) scaling the U-Net architecture at the 16\xD7 16\
  \ resolution, 3) adding dropout only at lower resolutions, and 4) using downsampling\
  \ to avoid high-resolution feature maps."
---

# Simple diffusion: End-to-end diffusion for high resolution images

## Quick Facts
- arXiv ID: 2301.11093
- Source URL: https://arxiv.org/abs/2301.11093
- Reference count: 21
- Primary result: Achieves state-of-the-art FID scores among diffusion models without sampling modifiers for high-resolution image generation

## Executive Summary
This paper introduces "simple diffusion," a technique for training high-resolution diffusion models without the complexity of cascades or latent spaces. By adjusting the noise schedule to add more noise at higher resolutions, scaling the U-Net architecture at the 16×16 resolution, adding dropout only at lower resolutions, and using downsampling to avoid high-resolution feature maps, the authors enable training a single diffusion model directly in pixel space up to 512×512 resolution. The method achieves state-of-the-art FID scores among diffusion models without sampling modifiers across multiple resolutions.

## Method Summary
Simple diffusion modifies standard diffusion training by shifting the noise schedule to add more noise at higher resolutions, scaling the U-Net architecture at 16×16 resolution, applying dropout only at lower resolutions, and using downsampling strategies to avoid high-resolution feature maps. The approach uses a shifted cosine noise schedule with signal-to-noise ratio scaling, U-Net/U-ViT architectures with architectural modifications, and multiscale training loss. Training is performed end-to-end in pixel space without cascades or latent spaces, using Adam optimizer with learning rate 5e-5, batch size 512, and EMA with decay 0.9999 for 1.5M steps.

## Key Results
- Achieves state-of-the-art FID scores among diffusion models without sampling modifiers: 2.26/2.88 FID train/eval at 128×128, 3.76/3.71 at 256×256, and 4.30/4.28 at 512×512 on ImageNet
- Outperforms existing methods in text-to-image generation while maintaining end-to-end training simplicity
- Demonstrates that high-resolution diffusion models can be trained directly in pixel space without cascades or latent spaces

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Shifting the noise schedule based on resolution improves sample quality because the original cosine schedule does not add enough noise for high-resolution images.
- Mechanism: The α-cosine schedule's signal-to-noise ratio (SNR) is insufficient at high resolutions, causing global structure to be defined too early. Shifting the log SNR curve by `2·log(64/d)` compensates for the reduced noise per pixel when downsampling, ensuring adequate noise exposure at all resolutions.
- Core assumption: High-resolution images require proportionally more noise in the diffusion process to maintain quality during downsampling to lower resolutions.
- Evidence anchors:
  - [abstract]: "adjusting the noise schedule to add more noise at higher resolutions"
  - [section]: "We argue that for higher resolutions, this schedule can be changed in a predictable way to retain good visual sample quality."
  - [corpus]: "On the Importance of Noise Scheduling for Diffusion Models" (supports the general claim that noise scheduling is crucial for performance)
- Break condition: If the relationship between SNR and resolution does not scale as hypothesized, or if the downsampling assumption fails.

### Mechanism 2
- Claim: Scaling only the 16×16 resolution layer is sufficient for improving performance without excessive memory use.
- Mechanism: Lower resolution feature maps have manageable memory footprints, allowing for more channels without exceeding memory limits. Scaling at 16×16 balances computational intensity and memory usage, enabling deeper networks without OOM issues.
- Core assumption: Computational intensity (FLOPs/features) and memory requirements scale favorably at lower resolutions, making them ideal for architectural scaling.
- Evidence anchors:
  - [abstract]: "scaling the U-Net architecture at the 16× 16 resolution"
  - [section]: "We hypothesize that mainly scaling on a particular resolution, namely the 16× 16 resolution is sufficient to improve performance within a range of network sizes we consider."
  - [corpus]: "LSSGen: Leveraging Latent Space Scaling in Flow and Diffusion for Efficient Text to Image Generation" (related to efficient scaling strategies)
- Break condition: If the 16×16 resolution is not the optimal point for scaling, or if memory constraints shift to other layers.

### Mechanism 3
- Claim: Adding dropout only at lower resolutions improves regularization without degrading high-resolution feature maps.
- Mechanism: Dropout at lower resolutions provides regularization where it is most effective, avoiding the memory cost and potential degradation of high-resolution layers. This targeted approach balances overfitting prevention with performance.
- Core assumption: Dropout is necessary for regularization, but high-resolution layers are too memory-intensive and sensitive to be regularized effectively.
- Evidence anchors:
  - [abstract]: "adding dropout only at lower resolutions"
  - [section]: "We hypothesize that it should be sufficient to only add dropout at the lower resolutions. This avoids regularizing the high resolution layers which are memory-wise expensive, while still using the dropout regularization that has been successful for models trained on lower resolution images."
  - [corpus]: Weak evidence; no direct corpus support found for this specific mechanism.
- Break condition: If dropout at lower resolutions is insufficient for regularization, or if high-resolution layers require regularization despite the cost.

## Foundational Learning

- Concept: Diffusion models and the denoising process
  - Why needed here: Understanding the basics of how diffusion models work is crucial for grasping the modifications proposed in this paper.
  - Quick check question: What is the main idea behind denoising diffusion models, and how do they generate data?

- Concept: Noise schedules and their impact on sample quality
  - Why needed here: The paper heavily focuses on adjusting the noise schedule for high-resolution images, so understanding how noise schedules affect sample quality is essential.
  - Quick check question: How does the α-cosine noise schedule work, and why might it be insufficient for high-resolution images?

- Concept: Architectural scaling and memory constraints
  - Why needed here: The paper proposes scaling the architecture at a specific resolution to balance performance and memory usage, so understanding the relationship between architectural scaling and memory constraints is important.
  - Quick check question: Why is scaling at the 16×16 resolution beneficial, and how does it help avoid memory issues?

## Architecture Onboarding

- Component map: Input image -> DWT/convolutional downsampling -> Residual blocks at various resolutions -> Self-attention layers at 8×8 and 16×16 -> Upsampling -> Output image generation
- Critical path: The critical path for image generation involves: 1) Input image processing and downsampling 2) Progressive denoising through residual blocks and self-attention layers 3) Upsampling to the original resolution 4) Output image generation
- Design tradeoffs: The main tradeoffs involve: balancing performance and memory usage by scaling at the 16×16 resolution, using dropout for regularization while avoiding high-resolution layers, choosing between DWT and convolutional layers for downsampling
- Failure signatures: Common failure modes include: insufficient noise in the diffusion process, leading to poor sample quality; memory issues when scaling the architecture beyond the 16×16 resolution; overfitting due to inadequate regularization
- First 3 experiments:
  1. Test the effect of different noise schedules on sample quality by training models with the original cosine schedule and the shifted schedule for various resolutions.
  2. Evaluate the impact of scaling the architecture at different resolutions by training models with varying numbers of residual blocks at 16×16, 32×32, and 64×64.
  3. Assess the effectiveness of dropout regularization by training models with dropout at different resolutions (e.g., 8×8, 16×16, 32×32) and comparing sample quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal noise schedule shift factor for very high resolutions beyond 512×512, and how does this scale with resolution?
- Basis in paper: [explicit] The paper discusses shifting the noise schedule by factors of 2 (from 32 to 64 to 128) and finds that shift 64 works well for 512×512 resolution, with minimal difference between shifts of 64 and 32.
- Why unresolved: The paper only tests up to 512×512 resolution. The scaling behavior for even higher resolutions is unknown.
- What evidence would resolve it: Systematic experiments testing noise schedule shifts at resolutions like 1024×1024 and 2048×2048 to determine if the optimal shift continues to scale linearly or follows a different pattern.

### Open Question 2
- Question: How does the multiscale loss perform for resolutions smaller than 256×256, and at what resolution does it become detrimental?
- Basis in paper: [explicit] The paper shows that the multiscale loss improves FID at 512×512 resolution but slightly degrades performance at 256×256 resolution.
- Why unresolved: The paper only tests two resolution points. The crossover point where multiscale loss transitions from beneficial to detrimental is unknown.
- What evidence would resolve it: Experiments testing the multiscale loss at resolutions like 128×128, 64×64, and 32×32 to identify the exact resolution threshold.

### Open Question 3
- Question: What is the optimal dropout strategy for different architectural scales and how does it interact with model size?
- Basis in paper: [explicit] The paper finds that dropout should only be applied at lower resolutions (below 16×16, 32×32, or 64×64), but doesn't explore how this interacts with different model sizes or architectural configurations.
- Why unresolved: The paper only tests one dropout strategy across different model sizes. The relationship between dropout placement, model scale, and regularization effectiveness is unexplored.
- What evidence would resolve it: Experiments varying dropout placement and intensity across different model sizes (small, medium, large) and architectural configurations to identify optimal dropout strategies for each scale.

## Limitations

- The paper's claims about noise schedule scaling rely on empirical observations rather than theoretical guarantees, lacking rigorous validation across diverse image distributions
- Architectural scaling at 16×16 resolution is presented as optimal but may be dataset-dependent rather than a general principle
- The dropout-only-at-lower-resolutions strategy has limited theoretical justification and no direct empirical comparison to alternative regularization schemes

## Confidence

- **High confidence**: The general approach of end-to-end diffusion without cascades or latent spaces is well-established and reproducible. The architectural modifications (U-ViT variant, downsampling strategies) are clearly specified and follow standard practices.
- **Medium confidence**: The noise schedule modifications and their impact on sample quality are supported by experimental results, but the underlying mechanism could vary with different datasets or image types. The 16×16 scaling sweet spot appears empirically validated but may not generalize.
- **Low confidence**: The dropout-only-at-lower-resolutions claim has the weakest empirical support, with no direct comparison to full-network dropout or alternative regularization methods.

## Next Checks

1. Test noise schedule sensitivity: Train identical models with the shifted schedule versus the original cosine schedule across multiple datasets (CIFAR-10, FFHQ, LSUN) to verify the universality of the SNR scaling claim.
2. Evaluate architectural scaling points: Systematically compare model performance when scaling occurs at 8×8, 16×16, 32×32, and 64×64 resolutions to determine if 16×16 is truly optimal or dataset-dependent.
3. Benchmark regularization strategies: Compare the dropout-only-at-lower-resolutions approach against full-network dropout and other regularization methods (weight decay, spectral normalization) to validate the claimed efficiency gains.