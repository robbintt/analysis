---
ver: rpa2
title: A Survey of Text Watermarking in the Era of Large Language Models
arxiv_id: '2312.07913'
source_url: https://arxiv.org/abs/2312.07913
tags:
- text
- watermark
- watermarking
- language
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides the first comprehensive survey of text watermarking
  techniques in the era of large language models (LLMs). It systematically categorizes
  and analyzes current watermarking methods into four main types: format-based, lexical-based,
  syntactic-based, and generation-based watermarking.'
---

# A Survey of Text Watermarking in the Era of Large Language Models

## Quick Facts
- arXiv ID: 2312.07913
- Source URL: https://arxiv.org/abs/2312.07913
- Reference count: 40
- Primary result: First comprehensive survey of text watermarking techniques for large language models, categorizing methods into four main types and analyzing evaluation metrics, applications, and challenges.

## Executive Summary
This paper provides the first comprehensive survey of text watermarking techniques in the era of large language models (LLMs). The survey systematically categorizes current watermarking methods into four main types: format-based, lexical-based, syntactic-based, and generation-based watermarking. It also covers watermarking specifically designed for LLMs, including training time watermarking, watermarking during logits generation, and watermarking during token sampling. The paper discusses evaluation metrics from multiple perspectives and identifies key application scenarios such as copyright protection, fake news detection, and academic integrity. Current challenges are highlighted, including balancing watermark payload with text quality, improving robustness against watermark removal attacks, and enhancing unforgeability.

## Method Summary
The paper conducts a systematic literature review of 40 reference papers on text watermarking methods. It categorizes watermarking techniques into four main types based on their implementation approach: format-based, lexical-based, syntactic-based, and generation-based watermarking. For each category, the paper extracts key implementation details, evaluation metrics, and strengths/weaknesses from the surveyed papers. The findings are synthesized into a comprehensive framework that compares methods across multiple evaluation dimensions including success rate, text quality, robustness, and unforgeability.

## Key Results
- Text watermarking techniques can be systematically categorized into four main types: format-based, lexical-based, syntactic-based, and generation-based
- Watermarking for LLMs introduces new approaches including training time watermarking and watermarking during token generation
- Key challenges include balancing watermark payload with text quality, improving robustness against attacks, and enhancing unforgeability
- Evaluation metrics must consider success rate, text quality impact, robustness against various attacks, and unforgeability
- Application scenarios include copyright protection, fake news detection, and academic integrity verification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Format-based watermarking techniques are effective because they modify invisible Unicode characters that do not alter the visible text content.
- Mechanism: By substituting standard whitespace characters with alternative Unicode codepoints (e.g., U+0020 with U+2004), watermarks are embedded in a way that remains undetectable to human readers but can be programmatically detected through analysis of character codepoints.
- Core assumption: The watermark detector has access to the text in its raw character form and can analyze Unicode codepoints, and the watermark will survive common text processing steps like copy-paste operations.
- Evidence anchors:
  - [section] "Por et al. [57] proposed a watermarking scheme named UniSpach, which inserts Unicode space characters into inter-sentence, inter-word, end-of-line and inter-paragraph spacings."
  - [section] "WHITEMARK replaces a whitespace (U+0020) with another codepoint of a whitespace (e.g. U+2004)."
- Break condition: If text undergoes canonicalization or normalization processes that convert all whitespace characters to a standard form, or if the text is converted to an image format where character-level analysis is not possible.

### Mechanism 2
- Claim: Lexical-based watermarking works by embedding information through controlled synonym substitutions that maintain semantic meaning while introducing detectable patterns.
- Mechanism: The watermark generator selects specific words in the text and replaces them with synonyms according to a predetermined encoding scheme. The detector reverses this process by identifying potential watermark words and applying the inverse substitution rules to extract the embedded message.
- Core assumption: There exists a sufficiently large set of semantically equivalent words that can be substituted without significantly degrading text quality, and the substitution patterns are not easily disrupted by natural language variations.
- Evidence anchors:
  - [section] "Topkara et al. [76] presented a synonym substitution text watermarking approach, using the linguistic database WordNet[15] as its synonym dictionary."
  - [section] "Yang et al. [85] proposed a novel BERT-based infill model to generate lexical substitution candidates, taking the overall sentence's meaning into account."
- Break condition: When the text undergoes extensive synonym replacement or paraphrasing that disrupts the specific substitution patterns used for watermark embedding, or when the synonym database used for watermarking differs from that used for detection.

### Mechanism 3
- Claim: Watermarking during logits generation in LLMs works by biasing the probability distribution of token generation to favor certain tokens over others in a detectable pattern.
- Mechanism: The watermark generator modifies the logits output by the LLM by adding a small bias Î´ to the logits of tokens in a "green list" while leaving "red list" tokens unchanged. This creates a statistical preference for green tokens in the generated text that can be detected by analyzing token frequencies.
- Core assumption: The LLM's token sampling process is sufficiently sensitive to small changes in logits probabilities to produce a detectable bias in token selection, and the bias is small enough to not significantly degrade text quality.
- Evidence anchors:
  - [section] "When ð‘€ð‘¤ generates the ð‘–ð‘¡â„Ž token, a small bias ð›¿ is added to the logits of the tokens in the green list."
  - [section] "The watermark detector assesses whether a text is watermarked by first utilizing the hash function to categorize each token as red or green sequentially."
- Break condition: When the text undergoes significant paraphrasing or rewriting that changes token sequences while preserving meaning, or when attackers develop methods to detect and neutralize the bias in logits.

## Foundational Learning

- Concept: Large Language Model (LLM) text generation pipeline
  - Why needed here: Understanding how LLMs generate text is crucial for comprehending how watermarking techniques can be integrated at different stages of the generation process.
  - Quick check question: What are the three main steps in the LLM text generation process that can be targeted for watermark embedding?

- Concept: Text quality evaluation metrics
  - Why needed here: Assessing the impact of watermarking on text quality is essential for balancing watermark robustness with text usability.
  - Quick check question: Which three evaluation metrics are commonly used to assess text quality in the context of watermarking?

- Concept: Watermark detection scenarios
  - Why needed here: Different detection scenarios (private vs. public) have different security requirements and constraints for watermark implementation.
  - Quick check question: What is the key difference between private detection and public detection scenarios in terms of watermark unforgeability?

## Architecture Onboarding

- Component map: Watermark generator -> Text/LLM output -> Watermark detector -> Extraction result. The generator embeds information through format changes, lexical substitutions, syntactic modifications, or logits biasing. The detector identifies and extracts watermark information using complementary decoding schemes.

- Critical path: For LLM watermarking during logits generation, the critical path is: LLM generates logits â†’ watermark generator modifies logits with bias â†’ token sampling produces watermarked text â†’ detector analyzes token distribution to identify watermark. Each step must maintain timing and probability constraints to ensure both effectiveness and undetectability.

- Design tradeoffs: There is a fundamental tradeoff between watermark robustness and text quality. Stronger watermarks (more detectable) typically require more significant modifications to text or logits, which can degrade quality. Additionally, increasing watermark payload (information capacity) often reduces robustness to attacks.

- Failure signatures: Watermark detection failure can manifest as false positives (detecting watermarks in human-generated text), false negatives (missing watermarks in LLM-generated text), or incorrect extraction of watermark information. Text quality degradation may appear as increased perplexity, reduced semantic similarity, or decreased task-specific performance.

- First 3 experiments:
  1. Implement a basic format-based watermark detector that analyzes Unicode codepoints in sample text and measures detection accuracy on watermarked vs. non-watermarked samples.
  2. Create a lexical substitution watermark generator and detector using a simple synonym database, then evaluate the impact on text perplexity and semantic similarity.
  3. Implement a logits modification watermark for an LLM by adding bias to token probabilities, then measure the green token proportion in generated text and test robustness against simple paraphrasing attacks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can text watermarking algorithms effectively balance watermark payload with text quality and robustness in real-world applications?
- Basis in paper: [explicit] The paper identifies this as a key challenge in section 1, noting that enhancing one aspect of watermarking might impact performance in another.
- Why unresolved: Current algorithms struggle to simultaneously maintain high payload, preserve text quality, and resist various attacks. This trade-off is fundamental to watermarking design.
- What evidence would resolve it: A watermarking algorithm that demonstrates high payload (multi-bit), minimal impact on text quality (measured by PPL and semantic similarity), and strong robustness against multiple attack types (character-level, word-level, document-level) in comprehensive real-world testing.

### Open Question 2
- Question: What are the most effective methods for detecting and preventing AI-generated fake news at scale while maintaining user privacy?
- Basis in paper: [inferred] The paper discusses the potential of text watermarking for fake news detection in section 6.3, but notes this area remains underexplored.
- Why unresolved: Current fake news detection methods lack scalability and may infringe on user privacy. Watermarking could help, but implementation challenges remain.
- What evidence would resolve it: A scalable system that can reliably detect AI-generated content across various platforms, with minimal false positives, while preserving user privacy through techniques like differential privacy or federated learning.

### Open Question 3
- Question: How can text watermarking technology be adapted to protect academic integrity in an era where AI-generated content is increasingly indistinguishable from human writing?
- Basis in paper: [explicit] The paper identifies this as an important application area in section 6.2, noting current detection methods lack interpretability and may not be robust to out-of-domain text.
- Why unresolved: Existing detection tools are easily circumvented and may not work well across different domains or languages. The paper suggests watermarking could help but doesn't provide concrete solutions.
- What evidence would resolve it: A comprehensive academic integrity system that integrates watermarking technology with existing detection methods, demonstrating high accuracy across multiple domains (essays, research papers, exams) while being difficult to circumvent through paraphrasing or translation.

## Limitations

- The survey's comprehensiveness depends on the completeness of the literature search - while 40 papers are cited, it's unclear if this captures the full landscape of text watermarking research
- Many evaluation results are presented qualitatively rather than with specific quantitative benchmarks, making it difficult to compare the relative effectiveness of different approaches
- The survey focuses on describing existing methods but provides limited empirical validation of the claimed trade-offs between watermark robustness and text quality

## Confidence

- High confidence: The categorization framework (format-based, lexical-based, syntactic-based, generation-based) is well-established and logically structured
- Medium confidence: The identified application scenarios (copyright protection, fake news detection, academic integrity) are reasonable but may not represent all potential use cases
- Medium confidence: The challenges identified (payload-quality balance, attack robustness, unforgeability) are theoretically sound but lack comprehensive empirical validation

## Next Checks

1. Verify the completeness of the literature coverage by conducting an independent search using alternative keyword combinations and checking for missing major watermarking approaches
2. Implement a representative sample of methods from each category and conduct head-to-head comparisons measuring success rate, text quality impact, and robustness against common attacks
3. Test the unforgeability claims by attempting to generate synthetic watermarked text that could fool detectors, particularly for public detection scenarios where this is most critical