---
ver: rpa2
title: Personalization of CTC-based End-to-End Speech Recognition Using Pronunciation-Driven
  Subword Tokenization
arxiv_id: '2310.09988'
source_url: https://arxiv.org/abs/2310.09988
tags:
- wordpiece
- speech
- recognition
- named
- p2wp
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of recognizing personal named
  entities in end-to-end speech recognition systems, particularly those based on Connectionist
  Temporal Classification (CTC). The authors present a novel method for generating
  additional subword tokenizations for personal entities from their pronunciations,
  which is combined with contextual biasing and wordpiece prior normalization techniques.
---

# Personalization of CTC-based End-to-End Speech Recognition Using Pronunciation-Driven Subword Tokenization

## Quick Facts
- arXiv ID: 2310.09988
- Source URL: https://arxiv.org/abs/2310.09988
- Reference count: 0
- Achieves personal named entity accuracy on par with competitive hybrid systems

## Executive Summary
This paper addresses the challenge of recognizing personal named entities in end-to-end CTC-based speech recognition systems. The authors propose a novel pronunciation-driven subword tokenization approach that generates additional representations for personal entities from their pronunciations, combined with contextual biasing and wordpiece prior normalization. Experiments across American English, Chinese Mandarin, and German demonstrate significant improvements in contact entity error rates and overall word error rates, achieving performance comparable to hybrid systems.

## Method Summary
The method combines three key techniques: (1) pronunciation-driven wordpiece tokenization (P2WP) that maps phone sequences to wordpiece sequences likely to be assigned high probabilities by the CTC model, (2) contextual biasing using class placeholders in an external word-based language model, and (3) wordpiece prior normalization that estimates and subtracts the CTC model's internal language model score to better combine with the external LM. The P2WP model is trained on lexicon-derived phone/wordpiece pairs weighted by word frequency, providing additional subword representations for rare personal entities.

## Key Results
- Achieves personal named entity accuracy on par with competitive hybrid systems
- Up to 40.8% relative reduction in contact entity error rate
- 27.9% relative reduction in WER on contact name-rich subsets
- P2WP model is more efficient than LG FST approach (0.53M vs 5.44M arcs)

## Why This Works (Mechanism)

### Mechanism 1
Pronunciation-driven wordpiece tokenization generates additional subword representations that align better with acoustic realizations of rare personal entities. The P2WP model learns to map phone sequences to wordpiece sequences that the CTC model is likely to assign high probabilities to given the corresponding acoustics, trained on lexicon-derived phone/wordpiece pairs weighted by word frequency.

### Mechanism 2
Combining pronunciation-driven tokenization with contextual biasing and wordpiece prior normalization achieves accuracy on par with hybrid systems. Contextual biasing uses class placeholders in the external LM to adapt to personal named entities, while wordpiece prior normalization estimates and subtracts the CTC model's internal LM score to allow better combination with the external LM.

### Mechanism 3
The P2WP model is more efficient and effective than previous methods like the LG FST approach. The P2WP model directly maps phone sequences to wordpieces, avoiding the intermediate step of mapping to full word sequences, resulting in smaller model size and better accuracy.

## Foundational Learning

- **Connectionist Temporal Classification (CTC)**: The core architecture used in the end-to-end speech recognition system being personalized. Why needed: CTC enables streaming speech recognition without explicit alignment. Quick check: What is the main advantage of CTC over attention-based encoder-decoder architectures for streaming applications?

- **Finite State Transducers (FSTs)**: Used for decoding, combining the CTC model output with language models and contextual biasing. Why needed: FSTs provide a mathematically rigorous framework for composing multiple models during decoding. Quick check: How does the composition of multiple FSTs (T, L, Guni, G-1 uni, G) enable the final decoding process?

- **Subword Tokenization**: WordPiece tokenization is used as the output representation for the CTC model, allowing handling of rare words. Why needed: Subword tokenization balances vocabulary size with the ability to represent rare words. Quick check: Why is subword tokenization preferred over character-level or word-level tokenization for speech recognition?

## Architecture Onboarding

- **Component map**: Audio input → CTC Model → WordPiece sequence → External LM scores (with prior normalization) → P2WP-generated alternatives → Contextual biasing FSTs → Final word sequence

- **Critical path**: 1) Audio input → CTC Model → WordPiece sequence 2) WordPiece sequence → External LM scores (with prior normalization) 3) WordPiece sequence → P2WP-generated alternatives 4) All alternatives → Contextual biasing FSTs → Final word sequence

- **Design tradeoffs**: Model size vs. accuracy (P2WP is smaller but may have different coverage), latency vs. accuracy (more P2WP N-best outputs improve accuracy but increase latency), language-specific effectiveness (wordpiece prior normalization works well for en/de but not for zh)

- **Failure signatures**: High CEER but low WER (personalization techniques ineffective for rare entities), degraded performance on non-contact subsets (over-biasing or over-normalization), large model size (inefficient implementation of FSTs or P2WP model)

- **First 3 experiments**: 1) Baseline CTC model performance on contact-rich vs. contact-free subsets 2) P2WP model accuracy and efficiency compared to LG FST approach 3) Effect of wordpiece prior normalization on overall and entity-specific accuracy across languages

## Open Questions the Paper Calls Out

### Open Question 1
How does the effectiveness of the pronunciation-driven subword tokenization approach vary across different language families and writing systems? The paper only tests three languages with different characteristics without systematic analysis of how language family or writing system type affects effectiveness.

### Open Question 2
What is the optimal number of P2WP model outputs (N-best list) to balance recognition accuracy against computational cost? The paper only provides results for two specific values without analyzing the full trade-off curve.

### Open Question 3
How does the P2WP model's performance change when trained on different types of pronunciation lexicons (human-curated vs. grapheme-to-phoneme generated)? The paper uses a mixed approach without isolating the effect of lexicon quality.

### Open Question 4
Can the P2WP model be effectively integrated with neural contextual biasing approaches? The paper mentions neural contextual biasing as related work but focuses on FST-based methods without exploring integration possibilities.

### Open Question 5
How does the effectiveness of wordpiece prior normalization vary with different tokenization strategies (e.g., character vs. wordpiece)? The paper notes language-dependent effectiveness but doesn't explore different tokenization strategies systematically.

## Limitations

- Language-specific effectiveness of wordpiece prior normalization varies significantly across languages (effective for English/German but not Chinese Mandarin)
- Performance evaluation limited to voice assistant tasks and contact name recognition, unclear how well it generalizes to other domains
- Heavy dependence on external language model quality, with no detailed analysis of minimum requirements or diminishing returns

## Confidence

**High Confidence**:
- Pronunciation-driven wordpiece tokenization can generate additional subword representations for personal entities
- Contextual biasing through class placeholders in external LM is effective
- P2WP model is more efficient than LG FST approach

**Medium Confidence**:
- Combination of techniques achieves accuracy on par with hybrid systems
- Approach reduces contact entity error rate by up to 40.8% relative
- Method is effective across English, Chinese, and German

**Low Confidence**:
- Specific reasons for language-dependent effectiveness of wordpiece prior normalization
- Optimal number of P2WP N-best outputs for balancing accuracy and latency
- Performance on domains outside voice assistant contact recognition

## Next Checks

1. **Cross-linguistic ablation study**: Conduct a controlled experiment removing wordpiece prior normalization from the Chinese Mandarin setup to isolate its contribution and understand why it's ineffective in this language.

2. **Domain generalization test**: Apply the personalization pipeline to a different domain (e.g., medical terminology recognition) to assess whether the reported improvements generalize beyond contact names.

3. **External LM sensitivity analysis**: Systematically vary the size and quality of the external language model to determine the minimum requirements for effective personalization and identify the point of diminishing returns.