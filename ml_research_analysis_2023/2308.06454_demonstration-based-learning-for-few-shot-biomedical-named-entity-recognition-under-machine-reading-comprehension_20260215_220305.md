---
ver: rpa2
title: Demonstration-based learning for few-shot biomedical named entity recognition
  under machine reading comprehension
arxiv_id: '2308.06454'
source_url: https://arxiv.org/abs/2308.06454
tags:
- learning
- linguistics
- few-shot
- computational
- shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a demonstration-based learning method for few-shot
  biomedical named entity recognition (BioNER) by reformulating the task as a machine
  reading comprehension (MRC) problem. The proposed method constructs task demonstrations
  using a density-based approach and leverages pre-trained language models for improved
  performance in low-resource scenarios.
---

# Demonstration-based learning for few-shot biomedical named entity recognition under machine reading comprehension

## Quick Facts
- arXiv ID: 2308.06454
- Source URL: https://arxiv.org/abs/2308.06454
- Reference count: 40
- Key outcome: Density-based demonstration learning improves few-shot BioNER performance, achieving F1 scores of 61.7-73.1% across six datasets in 25-50 shot settings.

## Executive Summary
This study presents a demonstration-based learning method for few-shot biomedical named entity recognition by reformulating the task as a machine reading comprehension problem. The approach leverages density-based demonstration construction to provide high-information examples when training data is limited. By utilizing pre-trained language models and a dual classifier for start/end position prediction, the method achieves competitive performance compared to fully supervised approaches while requiring significantly fewer annotated examples.

## Method Summary
The proposed method reformulates BioNER as an MRC problem where entities are identified through start and end position prediction rather than token classification. Task demonstrations are constructed using a density-based approach that selects sentences with the highest entity density. These demonstrations are concatenated with input sentences and encoded using a pre-trained biomedical language model (PubmedBERT). The model employs separate binary classifiers for predicting start and end positions, with end position prediction conditioned on the predicted start position. Entity spans are extracted using a unidirectional nearest match principle. The method is evaluated on six benchmark BioNER datasets under 25-shot and 50-shot learning scenarios.

## Key Results
- Achieves average F1 scores of 61.7%, 84.1%, 69.1%, 70.1%, 50.6%, and 59.9% on BC4CHEMD, BC5CDR-Chemical, BC5CDR-Disease, NCBI-Disease, BC2GM, and JNLPBA datasets respectively in 25-shot learning
- Improves to average F1 scores of 73.1%, 86.8%, 76.1%, 75.6%, 61.7%, and 65.4% in 50-shot learning
- Demonstrates competitive performance against fully supervised learning methods with limited training data
- Shows the MRC framework is more suitable for few-shot BioNER compared to traditional CRF approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reformulating BioNER as an MRC problem allows the model to leverage pre-trained language model strengths in span prediction.
- Mechanism: Instead of token-level classification, the model predicts start and end positions of entities, which aligns with the architecture's natural strengths.
- Core assumption: The MRC framework can effectively handle entity recognition when provided with appropriate context and query construction.
- Evidence anchors:
  - [abstract] "By redefining biomedical named entity recognition (BioNER) as a machine reading comprehension (MRC) problem, we propose a demonstration-based learning method"
  - [section] "Inspired by the key ideas in MRC, our proposed method breaks down the BioNER task into two classification problems: predicting the start and end position of the answer span within the context"
  - [corpus] Weak evidence - only 1/8 related papers mention MRC framework for BioNER
- Break condition: When entity spans overlap or when context is insufficient for accurate span prediction.

### Mechanism 2
- Claim: Density-based demonstration construction improves model performance by providing high-information examples.
- Mechanism: The "grape" demonstration selects sentences with the highest entity density, providing rich context for few-shot learning.
- Core assumption: Higher entity density in demonstrations leads to better model learning in low-resource scenarios.
- Evidence anchors:
  - [abstract] "we propose a demonstration-based learning method to address few-shot BioNER, which involves constructing appropriate task demonstrations"
  - [section] "We formulate a new demonstration type called the 'grape' demonstration in order to improve the model's capacity for performing BioNER under the MRC framework"
  - [corpus] Weak evidence - only 1/8 related papers discuss demonstration-based approaches
- Break condition: When high-density demonstrations contain ambiguous or noisy entity contexts.

### Mechanism 3
- Claim: Demonstration-based learning reduces the gap between few-shot and fully supervised performance.
- Mechanism: By incorporating task demonstrations, the model gains additional context and examples that help bridge the annotation gap.
- Core assumption: Demonstrations can partially substitute for the lack of extensive training data in few-shot scenarios.
- Evidence anchors:
  - [abstract] "MRC-based language models can achieve highly competitive performance levels, even when compared to fully supervised learning methods"
  - [section] "The experimental results indicate that the MRC framework is more suitable for BioNER in few-shot learning compared to the CRF framework"
  - [corpus] No direct evidence - related papers focus on different approaches (LLMs, multi-task learning)
- Break condition: When demonstrations introduce bias or when the demonstration selection process fails to capture relevant patterns.

## Foundational Learning

- Concept: Machine Reading Comprehension (MRC) framework
  - Why needed here: MRC provides the span prediction capability essential for BioNER task reformulation
  - Quick check question: How does MRC differ from traditional token classification in handling entity recognition?

- Concept: Demonstration-based learning
  - Why needed here: Demonstrations provide additional context and examples when training data is limited
  - Quick check question: What are the key differences between demonstration-based learning and traditional few-shot learning approaches?

- Concept: Density-based demonstration selection
  - Why needed here: Ensures demonstrations contain maximum information content for efficient learning
  - Quick check question: Why would selecting high-density entity sentences be more beneficial than random examples?

## Architecture Onboarding

- Component map: Input sentence + demonstration sentence -> PubmedBERT encoder -> Start position classifier + End position classifier -> Predicted entity spans

- Critical path:
  1. Demonstration selection and concatenation
  2. BERT encoding of combined sequence
  3. Start position prediction
  4. End position prediction (conditioned on start)
  5. Span alignment using nearest match principle

- Design tradeoffs:
  - Demonstration length vs. maximum sequence length
  - Single vs. multiple entity predictions per sentence
  - Fixed vs. dynamic demonstration selection

- Failure signatures:
  - Poor performance on low-density entity sentences
  - Inconsistent predictions across similar contexts
  - Degradation when demonstration quality varies

- First 3 experiments:
  1. Compare performance with and without demonstrations on BC4CHEMD dataset
  2. Test different demonstration selection strategies (density-based vs. random)
  3. Evaluate impact of demonstration length on model performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of demonstration-based learning scale with larger few-shot settings (e.g., 100-shot or 200-shot) compared to fully supervised learning?
- Basis in paper: [inferred] The paper shows performance improvements in 25-shot and 50-shot settings but does not explore larger few-shot scenarios. The authors mention that fully supervised learning requires significantly more annotated data.
- Why unresolved: The study focuses on very low-resource settings (25 and 50 shots) and does not investigate the performance ceiling of the proposed method in moderately low-resource scenarios.
- What evidence would resolve it: Experimental results comparing the proposed method against fully supervised learning in 100-shot, 200-shot, and 500-shot settings would provide insights into scalability.

### Open Question 2
- Question: What is the impact of demonstration selection strategies beyond density-based approaches on model performance?
- Basis in paper: [explicit] The authors propose a density-based demonstration selection method but acknowledge that other strategies might exist. They compare only density-based vs. popular-type demonstrations.
- Why unresolved: The study focuses on two specific demonstration selection strategies without exploring alternative approaches that might be more effective for different entity types or datasets.
- What evidence would resolve it: Comparative experiments using different demonstration selection strategies (e.g., semantic similarity, diversity-based, or entropy-based methods) across various BioNER datasets would clarify the optimal approach.

### Open Question 3
- Question: How does the proposed method perform on cross-domain few-shot BioNER tasks, where the target domain has limited data but source domains have abundant data?
- Basis in paper: [inferred] The study evaluates the method within individual datasets but does not address cross-domain scenarios, which are common in real-world applications where biomedical subdomains may have varying levels of annotation.
- Why unresolved: The experimental setup uses single-domain evaluation without considering domain adaptation or transfer learning aspects.
- What evidence would resolve it: Experiments testing the model's performance when training on one biomedical domain (e.g., chemicals) and evaluating on another (e.g., diseases) with limited target-domain data would demonstrate cross-domain effectiveness.

## Limitations

- Demonstration Quality Dependency: Performance heavily depends on the quality of demonstration selection, which may struggle with ambiguous or overlapping entities
- Dataset Bias Concerns: Evaluation limited to six specific BioNER datasets, raising questions about generalizability to other biomedical domains
- Computational Constraints: Sequence length limitations may force exclusion of potentially useful demonstrations

## Confidence

**High Confidence Claims**:
- The MRC reformulation approach effectively leverages pre-trained language models' span prediction capabilities
- Demonstration-based learning provides measurable performance improvements in few-shot scenarios
- The method achieves competitive results compared to fully supervised approaches with limited training data

**Medium Confidence Claims**:
- Density-based demonstration selection consistently outperforms random demonstration selection
- The gap between few-shot and fully supervised performance can be meaningfully reduced through demonstrations
- The method generalizes well across different BioNER datasets and entity types

**Low Confidence Claims**:
- The proposed method will scale effectively to clinical or other biomedical text domains
- Performance improvements are solely attributable to the demonstration mechanism rather than other factors
- The unidirectional nearest match principle is optimal for entity span alignment

## Next Checks

1. **Cross-Dataset Generalization Test**: Evaluate the method on additional BioNER datasets not included in the original study (e.g., NCBI Disease variants, clinical text datasets) to assess generalizability beyond the six benchmark datasets.

2. **Ablation Study on Demonstration Selection**: Systematically compare density-based demonstration selection against alternative strategies (random, frequency-based, or model-selected demonstrations) to isolate the specific contribution of the density-based approach.

3. **Long Sequence Performance Analysis**: Test the method's performance with varying demonstration lengths approaching the maximum sequence limit to understand the impact of demonstration truncation and identify optimal demonstration-to-input ratios.