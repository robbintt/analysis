---
ver: rpa2
title: 'Salesforce CausalAI Library: A Fast and Scalable Framework for Causal Analysis
  of Time Series and Tabular Data'
arxiv_id: '2301.10859'
source_url: https://arxiv.org/abs/2301.10859
tags:
- causal
- data
- variables
- time
- library
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The Salesforce CausalAI Library is an open-source Python library
  for causal analysis of time series and tabular data, supporting both continuous
  and discrete variable types. It includes algorithms for causal discovery (PC, Granger
  causality, VARLINGAM) and causal inference (estimating average and conditional treatment
  effects), with support for handling missing values, incorporating domain knowledge,
  and multi-processing for speed.
---

# Salesforce CausalAI Library: A Fast and Scalable Framework for Causal Analysis of Time Series and Tabular Data

## Quick Facts
- arXiv ID: 2301.10859
- Source URL: https://arxiv.org/abs/2301.10859
- Reference count: 1
- Primary result: Open-source Python library for causal analysis of time series and tabular data with significant speedups over existing libraries

## Executive Summary
The Salesforce CausalAI Library provides a comprehensive Python framework for causal discovery and inference on both time series and tabular data. The library implements multiple algorithms including PC, Granger causality, and VARLINGAM, supporting both continuous and discrete variables with handling for missing values and domain knowledge incorporation. Key innovations include multi-processing support via Ray for accelerated computation and a user-friendly UI for non-coders. Experimental results demonstrate significant improvements in both accuracy (F1 scores of 0.86 vs 0.62-0.74) and speed (3.3x-4.7x faster) compared to existing libraries on synthetic data benchmarks.

## Method Summary
The library implements three main causal discovery algorithms: PC algorithm for general causal discovery using conditional independence tests, Granger causality for time series analysis assuming linear relationships, and VARLINGAM for time series with contemporaneous causal connections. The PC algorithm supports linear tests (Fisher's z-test), partial correlation tests, and kernel-based tests (KCI) for non-linear relationships. Causal inference is performed by learning conditional models from observational data and using these to estimate average and conditional treatment effects. The framework includes data generators for synthetic experiments, data transformation utilities, and support for incorporating prior knowledge through a PriorKnowledge class. Multi-processing via Ray enables parallelization of independent conditional independence tests, while a web-based UI provides graphical access to core functionality.

## Key Results
- PC algorithm achieves F1 score of 0.86 on synthetic data compared to 0.62-0.74 for causal-learn and tigramite
- Speed improvements of 3.3x-4.7x faster training times versus existing libraries
- Multi-processing reduces computation time significantly for large datasets, though overhead may slow small dataset processing
- User-friendly UI enables non-coders to perform causal discovery and inference without Python programming

## Why This Works (Mechanism)

### Mechanism 1
Multi-processing with Ray library reduces computation time for causal discovery on large datasets by parallelizing conditional independence tests and independent regression tasks across multiple CPU cores. This works because independence between CI tests allows safe parallelization without affecting results. The mechanism breaks when datasets are too small for parallelization overhead to be worthwhile, or when dependency between CI tests violates independence assumptions.

### Mechanism 2
Targeted causal discovery reduces computational overhead when only specific variable relationships are needed by limiting search space to causal parents of specified target variable rather than full graph. This works when user's interest in specific variable relationships is well-defined and computational savings justify potential loss of broader causal understanding. The mechanism fails when user later needs relationships beyond the initially targeted variable, requiring complete rediscovery.

### Mechanism 3
Full CI test using all N-2 variables speeds up PC algorithm in worst-case scenarios by replacing exponential search through condition sets with single comprehensive test. This works because time-lagged causal discovery assumption prevents colliders, making full CI test valid. The mechanism breaks when contemporaneous relationships exist, or independence test loses power with large condition sets.

## Foundational Learning

- Concept: Causal Markov condition and faithfulness assumptions
  - Why needed here: PC algorithm relies on these to infer causal structure from conditional independence tests
  - Quick check question: If two variables are d-separated in the causal graph, what should be true about their probabilistic independence?

- Concept: Vector autoregression (VAR) for time series causal discovery
  - Why needed here: VARLINGAM algorithm uses VAR to estimate time-lagged causal effects before applying LiNGAM
  - Quick check question: What is the key assumption about the relationship between variables that VAR requires?

- Concept: Average Treatment Effect (ATE) and Conditional ATE (CATE) definitions
  - Why needed here: Causal inference module computes these effects to estimate intervention outcomes
  - Quick check question: How does CATE differ from ATE in terms of conditioning on variables?

## Architecture Onboarding

- Component map: DataGenerator -> DataTransform -> TimeSeriesData/TabularData -> PriorKnowledge -> PC/Granger/VARLINGAM -> CausalInference -> Visualization/UI
- Critical path: Data preparation and transformation must complete before discovery, discovery results feed into inference engine, UI provides non-coding access to this pipeline
- Design tradeoffs: Speed vs accuracy controlled by max_condition_set_size parameter, general vs specialized algorithms (PC handles nonlinear relationships while Granger/VARLINGAM are faster but assume linearity), code-free vs flexible (UI trades customization for accessibility)
- Failure signatures: Empty causal graph may indicate overly conservative p-value threshold or missing important variables, slow performance may be due to large dataset without multiprocessing enabled or very large condition sets, inconsistent results with different random seeds indicate potential faithfulness violations
- First 3 experiments:
  1. Generate synthetic data with known SEM using DataGenerator, run PC algorithm with default settings, verify discovered graph matches ground truth
  2. Create small time series dataset, compare PC algorithm speed with and without multiprocessing enabled
  3. Use PriorKnowledge to specify known edge, verify algorithm respects this constraint during discovery

## Open Questions the Paper Calls Out

### Open Question 1
What is the impact of different kernels in the KCI test on the accuracy of causal discovery for nonlinear relationships? The paper mentions PCSingle and PCAPI support KCI test for nonlinear causal relationships but doesn't provide experiments or analysis on kernel impact. This remains unresolved due to lack of empirical evidence on how kernel choice affects KCI test performance. Experiments comparing KCI test performance with different kernels on various synthetic datasets with known ground truth causal graphs would resolve this question.

### Open Question 2
How does the performance of VARLINGAM algorithm compare to other causal discovery algorithms for time series data with contemporaneous causal connections? While VARLINGAM is introduced for this specific case, the paper lacks experimental comparison with other algorithms. This remains unresolved without empirical evidence or theoretical analysis on VARLINGAM's performance versus alternatives. Experiments comparing VARLINGAM with PC and Granger causality on synthetic datasets containing contemporaneous causal connections would resolve this.

### Open Question 3
What is the impact of multi-processing on the performance of causal inference algorithms for large datasets? Although multi-processing can speed up causal inference algorithms, the paper doesn't provide experiments analyzing this impact. This remains unresolved without evidence on how multi-processing affects accuracy and speed of causal inference algorithms. Experiments comparing causal inference performance with and without multi-processing on various large datasets would resolve this question.

## Limitations
- Performance comparisons rely on synthetic data experiments, which may not reflect real-world data violations of algorithm assumptions
- Speed benefits from multi-processing depend heavily on dataset size, with overhead potentially negating gains for smaller datasets
- PC algorithm assumes Causal Markov condition and faithfulness, which may not hold in practice

## Confidence
- High confidence: Core functionality claims (algorithm implementations, UI features, data generation capabilities)
- Medium confidence: Performance claims (speedup factors, F1 score improvements) based on synthetic benchmarks
- Low confidence: Real-world applicability claims without field testing data

## Next Checks
1. Replicate synthetic data experiments on different machine to verify reported speedup factors and F1 score improvements
2. Test library on real-world datasets with known causal structures to assess performance beyond synthetic benchmarks
3. Evaluate impact of different kernel choices in KCI tests on non-linear relationship detection accuracy