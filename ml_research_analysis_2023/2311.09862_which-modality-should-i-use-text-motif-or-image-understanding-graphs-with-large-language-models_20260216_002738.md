---
ver: rpa2
title: 'Which Modality should I use -- Text, Motif, or Image? : Understanding Graphs
  with Large Language Models'
arxiv_id: '2311.09862'
source_url: https://arxiv.org/abs/2311.09862
tags:
- node
- graph
- label
- modality
- motif
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how to effectively encode graph data for
  Large Language Models (LLMs), addressing their context size limitations. It proposes
  encoding graphs using text, motif, and image modalities, with prompts designed to
  approximate global connectivity.
---

# Which Modality should I use -- Text, Motif, or Image? : Understanding Graphs with Large Language Models

## Quick Facts
- arXiv ID: 2311.09862
- Source URL: https://arxiv.org/abs/2311.09862
- Reference count: 13
- This study investigates how to effectively encode graph data for Large Language Models (LLMs), addressing their context size limitations.

## Executive Summary
This study investigates how to effectively encode graph data for Large Language Models (LLMs), addressing their context size limitations. It proposes encoding graphs using text, motif, and image modalities, with prompts designed to approximate global connectivity. A new benchmark, GRAPH TMI, is introduced to evaluate LLMs on graph structure analysis, focusing on homophily, motif presence, and graph difficulty. Key findings show that image modality, particularly with vision-language models like GPT-4V, outperforms text in managing token limits while retaining critical information, and surpasses prior graph neural network (GNN) encoders. The study also examines factors affecting each modality's performance and highlights current limitations and future directions for LLMs in graph understanding and reasoning tasks.

## Method Summary
The study encodes graphs using three modalities (text, motif, image) and prompts LLMs (GPT-4, GPT-4V) to perform node classification. A new benchmark called GRAPH TMI is introduced, which evaluates LLMs on graph structure analysis tasks. The methodology includes designing encoding functions for each modality, creating prompts that approximate global connectivity, and categorizing graphs by difficulty based on homophily and motif presence. The evaluation metrics include Accuracy Rate (A), Mismatch Rate (M), Denial Rate (D), and Token Limit Fraction (T).

## Key Results
- Image modality with GPT-4V outperforms text modality in balancing token limits while preserving essential information for node classification
- Graph difficulty based on homophily and motif counts influences the choice of encoding modality, with easy graphs favoring image and difficult graphs favoring text
- Motif attachment information has a more significant impact on node classification than motif count information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Image modality encoding outperforms text modality in balancing token limits while retaining critical information for node classification tasks.
- Mechanism: Images provide a global view of graph structure with fewer tokens than verbose text descriptions, allowing efficient use of LLM context windows.
- Core assumption: Vision-language models like GPT-4V can effectively interpret visual graph representations and extract relevant structural information for classification.
- Evidence anchors:
  - [abstract]: "image modality, especially with vision-language models like GPT-4V, is superior to text in balancing token limits and preserving essential information"
  - [section 4.1]: Figure 5 shows image modality has lower token limit fraction while maintaining comparable accuracy to text modality
  - [corpus]: No direct corpus evidence for this specific mechanism
- Break condition: If vision-language models cannot effectively interpret graph images or if the visual representation becomes too complex to convey meaningful information.

### Mechanism 2
- Claim: Graph task difficulty based on homophily and motif counts influences the choice of encoding modality for classification.
- Mechanism: Easy graphs (high homophily, few motifs) work well with image modality, while difficult graphs (low homophily, many motifs) benefit from text modality's detailed local information.
- Core assumption: The presence of similar labels and simple structures in easy graphs can be effectively captured visually, while complex structures require detailed textual descriptions.
- Evidence anchors:
  - [section 4.1]: Figure 7 shows easy problems have higher accuracy with image modality, while medium/hard problems perform better with text modality
  - [section 3.7]: GRAPH TMI benchmark categorizes graphs by difficulty based on homophily and motif criteria
  - [corpus]: No direct corpus evidence for this specific mechanism
- Break condition: If the heuristic for determining graph difficulty is inaccurate or if the relationship between difficulty and modality performance is not consistent across different datasets.

### Mechanism 3
- Claim: Motif attachment information has a more significant impact on node classification than motif count information.
- Mechanism: Providing the specific motifs attached to the unlabeled node gives local and global context, while count information alone is less informative.
- Core assumption: The actual nodes connected through motifs provide more relevant context for classification than just knowing how many motifs exist.
- Evidence anchors:
  - [section 4.2.2]: Figure 10 shows "triangle and star attached to ? node" motif information performs best with highest accuracy and lowest mismatch/denial rates
  - [section 3.5]: Discussion of motif encoding providing local and global context
  - [corpus]: No direct corpus evidence for this specific mechanism
- Break condition: If the motif attachment information becomes too verbose or if the LLM cannot effectively process the additional structural information.

## Foundational Learning

- Concept: Graph theory fundamentals (nodes, edges, connectivity, motifs)
  - Why needed here: Understanding graph structure is essential for interpreting how different encoding modalities represent and process graph information
  - Quick check question: What is the difference between a triangle motif and a star motif in graph theory?

- Concept: Large language model architecture and context windows
  - Why needed here: Understanding LLM limitations and capabilities is crucial for designing effective encoding modalities and prompts
  - Quick check question: What is the maximum token limit for GPT-4V and how does it affect graph encoding choices?

- Concept: Network analysis metrics (homophily, clustering coefficient, density)
  - Why needed here: These metrics help categorize graph difficulty and understand why certain encoding modalities perform better on specific graph types
  - Quick check question: How does a high clustering coefficient affect the choice between text and image encoding modalities?

## Architecture Onboarding

- Component map: Graph data -> Modality encoders (Text, Motif, Image) -> LLM (GPT-4, GPT-4V) -> Node classification results -> Evaluation metrics

- Critical path: Graph → Modality encoding → LLM prompt → Classification → Evaluation metrics

- Design tradeoffs:
  - Text modality: Detailed but verbose, high token usage
  - Motif modality: Balanced local/global view, computational complexity for motif detection
  - Image modality: Efficient token usage, dependent on VLM interpretation capabilities

- Failure signatures:
  - High denial rate: LLM cannot process the information or is confused by the input
  - Low accuracy: Encoding modality fails to capture relevant graph structure
  - High token limit fraction: Encoding is too verbose for the available context window

- First 3 experiments:
  1. Compare all three encoding modalities on a simple graph with clear homophily to establish baseline performance
  2. Test different edge encoding functions (edgelist, adjacency list, GML) to find most efficient representation
  3. Evaluate the impact of graph sampling strategies (ego vs forest fire) on node classification accuracy across different datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the image modality change when applied to directed graphs as opposed to the undirected graphs used in this study?
- Basis in paper: [inferred] The paper discusses the potential for applying their methodologies to directed graphs but does not explore this due to its unique characteristics and challenges.
- Why unresolved: The study focuses on undirected graphs and does not provide empirical data or analysis on the performance of the image modality in directed graphs.
- What evidence would resolve it: Conducting experiments using the image modality on a dataset of directed graphs and comparing the results with those obtained from undirected graphs.

### Open Question 2
- Question: How would incorporating hop distance into the homophily heuristic affect the accuracy of node classification across different modalities?
- Basis in paper: [inferred] The study acknowledges that its approach to estimating homophily is simplistic and does not account for hop distance, which could provide a more accurate representation of network homophily.
- Why unresolved: The paper does not explore the impact of hop distance on the homophily heuristic and its subsequent effect on node classification accuracy.
- What evidence would resolve it: Implementing the homophily heuristic with hop distance as a factor and evaluating the node classification accuracy across the text, motif, and image modalities.

### Open Question 3
- Question: What is the impact of using more computationally intensive algorithms for detecting network motifs on the scalability and efficiency of the motif modality encoding?
- Basis in paper: [explicit] The paper identifies the computational demands of detecting network motifs as a significant challenge and mentions that this process requires advanced algorithms and extensive computational power.
- Why unresolved: The study does not explore the trade-offs between computational intensity and the accuracy or efficiency of the motif modality encoding.
- What evidence would resolve it: Performing a comparative analysis of the motif modality encoding using different algorithms for motif detection, ranging from less to more computationally intensive, and assessing their impact on scalability and efficiency.

## Limitations
- The study focuses on citation networks (CORA, CITESEER, PUBMED), which are relatively small and have specific structural properties
- The mechanisms proposed for why image modality outperforms text on easy graphs and why motif attachment information is more valuable than count information need validation on diverse graph datasets
- The assumption that vision-language models can effectively interpret visual graph representations is critical but untested beyond the GPT-4V experiments presented

## Confidence

High confidence: The claim that image modality can reduce token usage while maintaining classification accuracy, based on direct empirical comparison in Figure 5

Medium confidence: The mechanism linking graph difficulty (homophily/motif counts) to optimal encoding modality, supported by Figure 7 but requiring broader dataset validation

Low confidence: The superiority of motif attachment information over count information, as this requires more extensive ablation studies across different graph types

## Next Checks

1. Test the three encoding modalities on large-scale graphs (e.g., social networks with millions of nodes) to verify if image modality maintains its efficiency advantage and if LLM context windows become a bottleneck

2. Conduct cross-dataset experiments using graphs from diverse domains (biological, transportation, social) to validate if the homophily-difficulty heuristic generalizes beyond citation networks

3. Perform ablation studies on motif encoding by comparing attachment information vs. count information across graphs with varying motif complexity to isolate the true source of performance differences