---
ver: rpa2
title: 'Don''t Overlook the Grammatical Gender: Bias Evaluation for Hindi-English
  Machine Translation'
arxiv_id: '2312.03710'
source_url: https://arxiv.org/abs/2312.03710
tags:
- gender
- bias
- evaluation
- translation
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses gender bias in Hindi-English machine translation
  by highlighting the limitations of existing gender bias evaluation methods for non-English
  source languages. The authors propose evaluating bias using sentences containing
  grammatical gender cues from the source language rather than gender-neutral sentences.
---

# Don't Overlook the Grammatical Gender: Bias Evaluation for Hindi-English Machine Translation

## Quick Facts
- **arXiv ID**: 2312.03710
- **Source URL**: https://arxiv.org/abs/2312.03710
- **Reference count**: 6
- **Primary result**: Existing gender-neutral bias evaluation methods fail to expose gender bias in Hindi-English NMT; grammatically gendered evaluation reveals significant bias against females

## Executive Summary
This paper addresses a critical gap in gender bias evaluation for Hindi-English machine translation systems. While existing methods using gender-neutral sentences fail to expose bias, the authors demonstrate that evaluation using sentences with grammatical gender cues from Hindi (gender-inflected pronouns, adjectives, and verbs) effectively reveals significant gender bias. They create two new Hindi-language bias evaluation benchmarks - OTSC-Hindi and WinoMT-Hindi - and test four NMT systems (IndicTrans, Google Translate, Microsoft Translator, and AWS Translate), finding substantial bias against female translations despite clear feminine grammatical markers in the source.

## Method Summary
The authors propose evaluating NMT models for gender bias using source sentences containing grammatical gender cues rather than gender-neutral sentences. They manually create two Hindi-language test sets: OTSC-Hindi (Occupation Testset with Simple Context) and WinoMT-Hindi (704 WinoBias-like sentences with gender cues). These test sets incorporate Hindi's gender-inflected elements (pronouns, adjectives, and verbs) to provide unambiguous gender information. The evaluation is performed on four Hindi-English NMT systems using both traditional TGBI scores and WinoMT metrics (Acc, ∆G, ∆S) to quantify gender bias.

## Key Results
- Existing TGBI evaluation fails to expose gender bias in Hindi-English NMT systems
- Evaluation using grammatically gendered sentences reveals significant bias against females in all four tested NMT systems
- OTSC-Hindi and WinoMT-Hindi benchmarks successfully expose gender bias that gender-neutral evaluations miss
- The bias stems from NMT models relying on biased statistical associations rather than grammatical gender cues

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Existing gender bias evaluation methods using gender-neutral sentences fail to expose bias in NMT systems for languages with grammatical gender.
- Mechanism: When source sentences contain grammatical gender cues, the NMT model must use contextual information to determine gender rather than relying on biased statistical associations. If the model consistently defaults to masculine translations despite clear feminine grammatical markers, this reveals underlying gender bias.
- Core assumption: NMT models have learned biased associations between occupations and genders during training, which they rely on when gender information is ambiguous.
- Evidence anchors: [abstract] "they depend on biased correlations"; [section] "evaluation based on TGBI (results not shown here) gives almost similar performance on all NMT systems which shows that it is not good at exposing gender bias"

### Mechanism 2
- Claim: Hindi grammatical gender markers provide unambiguous gender information that should be preserved in English translation.
- Mechanism: Hindi uses gender-inflected elements (pronouns, adjectives, verbs) that explicitly mark gender. When these markers indicate feminine gender but the translation defaults to masculine, it demonstrates the model's failure to correctly interpret grammatical gender cues and instead relies on stereotypical associations.
- Core assumption: The grammatical gender system in Hindi provides sufficient contextual information for gender disambiguation that should override statistical biases.
- Evidence anchors: [section] "In Hindi, elements like pronouns, adjectives, and verbs are inflected with gender"; [section] "we propose to evaluate NMT models for bias using sentences with grammatical gender cues of the source language"

### Mechanism 3
- Claim: Evaluating bias using grammatically gendered sentences reveals more nuanced forms of bias than gender-neutral sentence evaluation.
- Mechanism: Gender-neutral evaluation only tests whether models introduce bias when gender is ambiguous. Grammatically gendered evaluation tests whether models can correctly interpret and preserve gender information when it's explicitly provided, revealing biases in gender interpretation rather than just gender assignment.
- Core assumption: Correct gender interpretation is a distinct capability from bias-free gender assignment, and both need to be evaluated separately.
- Evidence anchors: [abstract] "evaluate for bias using such source sentences to determine if NMT models can discern gender from the grammatical gender cues rather than relying on biased associations"; [section] "evaluation using grammatical gender cues exposes bias more effectively than existing methods like TGBI"

## Foundational Learning

- Concept: Grammatical gender systems in languages
  - Why needed here: Understanding how Hindi marks gender through inflection is essential to create appropriate evaluation benchmarks and interpret results
  - Quick check question: What grammatical elements in Hindi carry gender information that could be used for bias evaluation?

- Concept: Coreference resolution in NMT
  - Why needed here: The paper discusses how NMT models have poor coreference resolution ability, leading them to rely on biased associations rather than actual gender information
  - Quick check question: How does poor coreference resolution contribute to gender bias in machine translation?

- Concept: Gender bias metrics in NLP
  - Why needed here: The paper uses specific metrics (Acc, ∆G, ∆S) from WinoMT evaluation, which require understanding how gender bias is quantified in translation tasks
  - Quick check question: What do the Acc, ∆G, and ∆S metrics measure in the context of gender bias evaluation?

## Architecture Onboarding

- Component map: Data generation module -> NMT evaluation pipeline -> Bias measurement system -> Result analysis module
- Critical path: Data generation → NMT system testing → Bias metric calculation → Result analysis → Interpretation of whether bias stems from grammatical gender interpretation failure
- Design tradeoffs: Manual creation of Hindi WinoMT sentences vs. automatic generation; focusing on grammatical gender vs. semantic gender context; evaluating multiple NMT systems vs. deep analysis of single system
- Failure signatures: High percentage of masculine translations despite feminine grammatical markers; similar performance across different NMT systems; TGBI evaluation failing to expose bias
- First 3 experiments:
  1. Create OTSC-Hindi test set with simple occupation context and grammatical gender markers, evaluate on 4 NMT systems
  2. Develop WinoMT-Hindi with diverse grammatical gender cues and evaluate using Acc, ∆G, ∆S metrics
  3. Compare results with TGBI evaluation on gender-neutral sentences to demonstrate superior bias exposure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of bias evaluation benchmarks like OTSC-Hindi and WinoMT-Hindi vary across different language families beyond Indo-Aryan languages like Hindi?
- Basis in paper: [explicit] The paper emphasizes the importance of tailoring bias evaluation to the linguistic features of source languages, particularly those with grammatical gender. It uses Hindi as a case study but suggests extending this approach to other languages.
- Why unresolved: The paper only evaluates Hindi-English NMT systems. There is no analysis of how these benchmarks would perform for other language pairs, especially those with different grammatical gender systems or no grammatical gender at all.
- What evidence would resolve it: Creating and testing OTSC and WinoMT-like benchmarks for other language pairs (e.g., Romance languages, Slavic languages, or languages without grammatical gender) and comparing their effectiveness in exposing gender bias.

### Open Question 2
- Question: Can the effectiveness of grammatical gender cues in exposing bias be quantified and compared to other linguistic features (e.g., honorifics, verb aspects) in non-English source languages?
- Basis in paper: [inferred] The paper highlights the significance of grammatical gender markers but does not explore other linguistic features that could be used for bias evaluation in source languages.
- Why unresolved: The paper focuses solely on grammatical gender cues (pronouns, adjectives, verbs) without investigating whether other linguistic features might be equally or more effective in exposing bias.
- What evidence would resolve it: Systematic studies comparing the bias-exposing effectiveness of various linguistic features (e.g., honorifics, verb aspects, noun classifiers) across multiple non-English source languages.

### Open Question 3
- Question: How do different NMT architectures (e.g., Transformer, RNN, CNN) perform in handling grammatical gender cues in source languages, and does this impact bias exposure?
- Basis in paper: [inferred] The paper evaluates four Hindi-English NMT systems but does not analyze how different architectural choices might affect their ability to handle grammatical gender cues and expose bias.
- Why unresolved: The evaluation focuses on model outputs but does not delve into the architectural differences that might explain variations in bias handling.
- What evidence would resolve it: Comparative studies of NMT architectures' performance on grammatical gender cues, potentially through ablation studies or architectural modifications, to determine which designs are most effective at handling gender information.

## Limitations

- The study focuses on only four commercial and one research NMT system, which may not represent the full landscape of available translation models
- Manual creation of evaluation benchmarks, while ensuring quality, limits scalability and may introduce subjective biases in sentence construction
- The paper doesn't investigate whether the observed bias stems from training data imbalances, model architecture limitations, or evaluation artifacts

## Confidence

- **High confidence**: The core finding that existing gender-neutral evaluation methods (like TGBI) fail to expose gender bias in Hindi-English translation, and that grammatically gendered evaluation reveals significant bias against females
- **Medium confidence**: The claim that grammatical gender cues in Hindi should unambiguously determine gender in English translations
- **Medium confidence**: The assertion that this methodology should be extended to other languages with grammatical gender

## Next Checks

1. **Cross-linguistic validation**: Apply the grammatically gendered evaluation methodology to other languages with grammatical gender (e.g., Spanish, German, Russian) to test generalizability beyond Hindi-English
2. **Bias source attribution**: Conduct ablation studies to determine whether observed bias primarily stems from training data imbalances, model architecture limitations, or evaluation methodology issues
3. **Longitudinal analysis**: Track gender bias trends across multiple versions of the same NMT systems over time to assess whether identified biases are persistent or improving with model updates