---
ver: rpa2
title: Open Domain Knowledge Extraction for Knowledge Graphs
arxiv_id: '2312.09424'
source_url: https://arxiv.org/abs/2312.09424
tags:
- facts
- odke
- extraction
- knowledge
- wikipedia
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ODKE is an automated, scalable framework for extracting high-quality
  entities and facts from open web sources to grow industry-scale knowledge graphs.
  It addresses the challenge of maintaining completeness and freshness of KGs at scale
  by combining pattern-based, traditional ML-based, and LLM-based extractors with
  both streaming and batch processing modes.
---

# Open Domain Knowledge Extraction for Knowledge Graphs

## Quick Facts
- arXiv ID: 2312.09424
- Source URL: https://arxiv.org/abs/2312.09424
- Authors: 
- Reference count: 25
- One-line primary result: ODKE achieves up to 99.2% extraction precision and 100K facts per minute throughput for growing open-domain knowledge graphs

## Executive Summary
ODKE is an automated, scalable framework for extracting high-quality entities and facts from open web sources to grow industry-scale knowledge graphs. It addresses the challenge of maintaining completeness and freshness of KGs at scale by combining pattern-based, traditional ML-based, and LLM-based extractors with both streaming and batch processing modes. The system supports multiple languages and includes link inference to add missing facts without actual extraction. ODKE bridges freshness gaps between Wikipedia and Wikidata, discovers new trendy entities, and adds missing facts via link inference, achieving up to 99.2% extraction precision and 100K facts per minute throughput.

## Method Summary
ODKE combines pattern-based extractors for semi-structured data (like Wikipedia infoboxes), traditional ML-based extractors (MRC models) for plain text, and LLM-based extractors for ambiguous or complex extraction tasks. The system operates in two modes - batch mode processes all missing/stale facts weekly, while streaming mode handles the most critical facts (top 1%) with hourly updates. It supports multilingual extraction through language-specific patterns and includes a link inference component that can infer missing relationships based on existing facts. The pipeline consists of extraction initiation, evidence retrieval, knowledge extraction, corroboration, data export, and KG ingestion stages.

## Key Results
- Achieves up to 99.2% extraction precision across different extractor types
- Processes up to 100K facts per minute throughput in production deployment
- Bridges freshness gaps between Wikipedia and Wikidata, discovering new trendy entities
- Adds missing facts via link inference without requiring new extraction
- Supports both streaming (hourly updates for critical facts) and batch (weekly comprehensive updates) modes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ODKE's hybrid extractor architecture enables high precision and scalability by combining multiple extraction strategies.
- Mechanism: The system employs pattern-based extractors for semi-structured data (like Wikipedia infoboxes), traditional ML-based extractors (MRC models) for plain text, and LLM-based extractors for ambiguous or complex extraction tasks. This multi-pronged approach allows ODKE to handle diverse web data formats while maintaining high precision.
- Core assumption: Different extraction strategies are complementary and can be orchestrated effectively to handle the variety of web data formats.
- Evidence anchors:
  - [abstract] "ODKE utilizes a wide range of extraction models"
  - [section] "ODKE employs a variety of extractors, roughly subdivided into pattern-based... and model-based"
  - [corpus] "ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs" - shows LLM integration is an active area of development
- Break condition: The hybrid approach fails if the orchestration logic cannot effectively route extraction tasks to the appropriate extractor type, or if the extractors produce conflicting results that cannot be reconciled.

### Mechanism 2
- Claim: ODKE's dual-mode operation (batch and streaming) enables both comprehensive updates and near real-time freshness.
- Mechanism: The system operates in two modes - batch mode processes all missing/stale facts weekly, while streaming mode handles the most critical facts (top 1%) with hourly updates. This allows ODKE to balance between comprehensive knowledge graph updates and time-sensitive fact extraction.
- Core assumption: Not all facts require the same update frequency, and a tiered approach can optimize resource allocation while meeting application needs.
- Evidence anchors:
  - [abstract] "supports both streaming and batch processing at different latency"
  - [section] "ODKE is deployed in two modes, batch and streaming, each providing different SLAs"
  - [corpus] "Benchmark datasets for biomedical knowledge graphs" - shows domain-specific freshness requirements vary
- Break condition: The dual-mode approach breaks if the criteria for classifying facts as "critical" become misaligned with actual user needs, or if the streaming pipeline cannot maintain the promised SLA under load.

### Mechanism 3
- Claim: Link inference extends knowledge graph completeness without requiring new extraction.
- Mechanism: ODKE includes a link inference component that can infer missing relationships based on existing facts. For example, if A has spouse B, it can infer B has spouse A (symmetric relationship). This approach adds completeness without the computational cost of new extractions.
- Core assumption: Logical relationships between entities can be inferred with high confidence based on existing graph structure.
- Evidence anchors:
  - [abstract] "includes link inference to add missing facts without actual extraction"
  - [section] "Link inference is orthogonal to the extraction pipeline, which can improve the completeness and correctness of KG by inferring additional edges"
  - [corpus] "Deep Outdated Fact Detection in Knowledge Graphs" - shows link inference is complementary to fact freshness
- Break condition: Link inference fails if the inference rules are too permissive (creating incorrect facts) or too restrictive (missing valid inferences), or if the KG contains inconsistencies that propagate through inference.

## Foundational Learning

- Concept: Knowledge graph architecture and ontology
  - Why needed here: Understanding how facts are represented as (subject, predicate, object) triples and how different ontologies (like Wikidata's) structure relationships is essential for designing effective extractors and understanding the system's output.
  - Quick check question: What is the difference between a property and a relation in a knowledge graph ontology?

- Concept: Information extraction techniques
  - Why needed here: ODKE employs multiple extraction paradigms (pattern-based, ML-based, LLM-based). Understanding the strengths and limitations of each approach is crucial for extending the system or troubleshooting extraction issues.
  - Quick check question: When would you choose a pattern-based extractor over an LLM-based extractor for a specific extraction task?

- Concept: Stream processing and batch processing tradeoffs
  - Why needed here: ODKE's dual-mode operation requires understanding when to use streaming vs. batch processing, the associated latency requirements, and how to handle state management across these modes.
  - Quick check question: What factors would determine whether a fact should be processed in streaming mode versus batch mode?

## Architecture Onboarding

- Component map: Extraction Initiator → Evidence Retriever → Knowledge Extractor → Corroborator → Data Export & KG Ingestion

- Critical path: Extraction Initiator → Evidence Retriever → Knowledge Extractor → Corroborator → Data Export & KG Ingestion

- Design tradeoffs:
  - Pattern-based vs. model-based extractors: Pattern-based offers higher precision but less flexibility; model-based offers broader coverage but may be less precise
  - Streaming vs. batch processing: Streaming provides freshness but higher resource usage; batch is efficient but less timely
  - Multilingual support: Requires language-specific patterns but enables broader coverage

- Failure signatures:
  - Low precision: Indicates issues with extractor quality or corroborator scoring
  - Low recall: Suggests missing extraction patterns or inadequate evidence retrieval
  - High latency: Points to bottlenecks in processing pipeline or evidence retrieval
  - Data inconsistencies: May indicate issues with normalization or link inference

- First 3 experiments:
  1. Run a single Wikipedia page through the pattern-based extractor and verify the extracted facts against the source
  2. Test the search-based retrieval with a known entity and verify the retrieved documents contain relevant evidence
  3. Run the link inference on a small, controlled subgraph and verify the inferred relationships are correct

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can ODKE's link inference component be extended to handle more complex relationship types beyond symmetrical and asymmetrical relationships?
- Basis in paper: [explicit] The paper mentions that link inference currently supports symmetrical and asymmetrical relationships, but does not explore more complex relationship types.
- Why unresolved: The paper does not provide details on how to handle more complex relationships like transitive relationships or hierarchical relationships.
- What evidence would resolve it: Experimental results showing the effectiveness of ODKE's link inference component on more complex relationship types.

### Open Question 2
- Question: How can ODKE's throughput be further improved while maintaining high extraction precision?
- Basis in paper: [inferred] The paper mentions that ODKE can extract up to 100K facts per minute, but does not explore ways to further improve throughput while maintaining high precision.
- Why unresolved: The paper does not provide details on how to optimize ODKE's architecture or algorithms for higher throughput.
- What evidence would resolve it: Experimental results showing the throughput and precision of ODKE with different optimizations or architectures.

### Open Question 3
- Question: How can ODKE's LLM-based extractors be made more efficient for large-scale extraction tasks?
- Basis in paper: [explicit] The paper mentions that LLM-based extractors are computationally expensive and only used for ambiguous and challenging extraction tasks.
- Why unresolved: The paper does not provide details on how to make LLM-based extractors more efficient for large-scale extraction tasks.
- What evidence would resolve it: Experimental results showing the efficiency and effectiveness of LLM-based extractors on large-scale extraction tasks with different optimizations or architectures.

## Limitations
- The specific implementation details of the link inference patterns remain unclear, particularly how these patterns are configured for different relationship types and domains
- The exact orchestration logic that routes extraction tasks to appropriate extractors (pattern-based, ML-based, or LLM-based) is not fully specified
- The evaluation methodology for measuring precision and throughput claims is not detailed, lacking information about test datasets and measurement conditions

## Confidence
- High Confidence: The dual-mode operation (streaming and batch) design and its rationale for balancing freshness and resource efficiency
- Medium Confidence: The hybrid extractor architecture combining pattern-based, ML-based, and LLM-based approaches, though implementation details are sparse
- Low Confidence: The specific link inference patterns and their configuration for different use cases

## Next Checks
1. **Precision Validation**: Run ODKE on a controlled test dataset with known ground truth facts and measure precision across different extractor types (pattern-based, ML-based, LLM-based) to verify the 99.2% claim.
2. **Throughput Benchmark**: Deploy the system with realistic workloads and measure actual throughput under both streaming and batch modes to validate the 100K facts per minute capability.
3. **Link Inference Accuracy**: Create a small, controlled knowledge graph subgraph with known relationships and test the link inference component to verify it correctly infers symmetric relationships and doesn't introduce false positives.