---
ver: rpa2
title: 'Use Your INSTINCT: INSTruction optimization for LLMs usIng Neural bandits
  Coupled with Transformers'
arxiv_id: '2310.02905'
source_url: https://arxiv.org/abs/2310.02905
tags:
- instruction
- instinct
- input
- output
- soft
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We propose a novel algorithm INSTINCT for instruction optimization
  of black-box LLMs. INSTINCT uses a neural bandit algorithm with a neural network
  surrogate coupled with hidden representations from a pre-trained transformer.
---

# Use Your INSTINCT: INSTruction optimization for LLMs usIng Neural bandits Coupled with Transformers

## Quick Facts
- arXiv ID: 2310.02905
- Source URL: https://arxiv.org/abs/2310.02905
- Reference count: 29
- Primary result: Proposes INSTINCT algorithm that consistently outperforms baselines on instruction optimization tasks

## Executive Summary
This paper introduces INSTINCT, a novel algorithm for optimizing instructions for black-box large language models (LLMs) like ChatGPT. INSTINCT combines neural bandit algorithms with hidden representations from pre-trained transformers to efficiently search for optimal instructions. The method addresses the challenge of high-dimensional instruction spaces while maintaining principled exploration-exploitation tradeoffs. Experiments demonstrate that INSTINCT outperforms existing approaches on tasks including instruction induction and zero-shot chain-of-thought reasoning.

## Method Summary
INSTINCT uses a neural bandit framework with a neural network surrogate model coupled with hidden representations from a pre-trained transformer (Vicuna-13B). The algorithm pre-computes hidden representations for a discrete set of soft prompts to reduce computational cost, then iteratively selects prompts using a NeuralUCB acquisition function that balances exploration and exploitation. The selected soft prompts are converted to instructions by the white-box LLM, evaluated by the black-box LLM, and the results are used to update the surrogate model. This approach replaces traditional Gaussian Process surrogates in Bayesian Optimization with neural networks while preserving principled optimization properties.

## Key Results
- INSTINCT consistently outperforms baselines like APE and InstructZero on instruction induction tasks
- The algorithm improves zero-shot chain-of-thought reasoning performance for black-box LLMs
- Pre-computation of hidden representations significantly reduces computational cost during optimization
- The method achieves better score prediction accuracy through coupling with transformer hidden representations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural bandit algorithm replaces GP surrogate with NN surrogate while preserving principled exploration-exploitation tradeoff
- Mechanism: The NeuralUCB acquisition function uses predicted score plus uncertainty term to select next soft prompt, where uncertainty is calculated from NN gradient
- Core assumption: NN can model complex function mapping soft prompts to LLM performance scores
- Evidence anchors: [abstract] "neural bandit algorithm which replaces the GP in BO by an NN surrogate to optimize instructions", [section 2.2] "Neural bandit algorithms, such as NeuralUCB... replace the GP surrogate in BO with an NN surrogate while preserving the principled ability of BO to trade-off exploration vs. exploitation"

### Mechanism 2
- Claim: Coupling NN surrogate with pre-trained transformer hidden representations improves score prediction
- Mechanism: NN trained on hidden representations of soft prompts (extracted from pre-trained transformer) rather than raw soft prompt vectors
- Core assumption: Hidden representations contain task-relevant features that improve prediction accuracy
- Evidence anchors: [section 3.1] "we can stack an NN (i.e.,MLP) on top of the hidden representation z′ = g(z) to achieve accurate score predictions", [section 3.4] "connecting the hidden representation (of the last token in the final layer) of a pre-trained transformer with an MLP to perform prediction tasks has been commonly adopted"

### Mechanism 3
- Claim: Pre-computation of hidden representations reduces computational cost
- Mechanism: Discrete domain of soft prompts pre-computed and hidden representations cached before algorithm runs
- Core assumption: Good coverage of continuous domain can be achieved with discrete pre-computed set
- Evidence anchors: [section 3.2] "we can adopt a natural technique to significantly reduce its computational cost. That is, before running our INSTINCT, we generate a discrete domain eZ of soft prompts... Then, we pre-compute the hidden representation z′ = g(z) for every soft prompt z in this discrete domain", [section 3.2] "Given all pre-computed hidden representations... when selecting the next soft prompt zt during our algorithm... we can instead maximize over the fixed discrete domain eZ"

## Foundational Learning

- Concept: Bayesian Optimization and Gaussian Processes
  - Why needed here: Understanding BO framework provides context for why GP surrogate is replaced
  - Quick check question: What is the main limitation of using GP as surrogate for high-dimensional optimization problems?

- Concept: Neural Tangent Kernel and Neural Bandit Theory
  - Why needed here: Explains theoretical foundation for uncertainty estimation in NeuralUCB
  - Quick check question: How does the neural tangent kernel relate to the uncertainty measure in NeuralUCB?

- Concept: Random Projection for Dimensionality Reduction
  - Why needed here: Technique used to generate discrete domain and control soft prompt magnitudes
  - Quick check question: What is the relationship between intrinsic dimension and average L2 norm of projected vectors?

## Architecture Onboarding

- Component map: White-box LLM (Vicuna) -> Instruction generator -> Black-box LLM (ChatGPT) -> Evaluator -> NN surrogate (MLP) -> NeuralUCB acquisition -> Soft prompt selector -> Pre-computation module -> Random projection module

- Critical path:
  1. Pre-compute hidden representations for discrete domain
  2. Initialize observation history with random soft prompts
  3. Train NN on current observations
  4. Calculate NeuralUCB acquisition function
  5. Select next soft prompt
  6. Generate instruction using white-box LLM
  7. Evaluate instruction using black-box LLM
  8. Add observation to history
  9. Repeat from step 3

- Design tradeoffs:
  - NN complexity vs. training speed and over-fitting risk
  - Discrete domain size vs. search space coverage
  - Intrinsic dimension vs. soft prompt magnitude control
  - Exploration weight (νt) vs. exploitation tendency

- Failure signatures:
  - NN predictions consistently inaccurate → check training data quality and network architecture
  - Algorithm gets stuck in local optima → increase exploration weight or re-initialize
  - Pre-computation takes too long → reduce discrete domain size or use more efficient sampling
  - Soft prompts generate nonsensical instructions → check random projection matrix and intrinsic dimension

- First 3 experiments:
  1. Run INSTINCT with default parameters on a simple instruction induction task and verify it outperforms random search
  2. Test impact of intrinsic dimension on soft prompt magnitudes by varying d′ and measuring average L2 norms
  3. Compare performance with and without hidden representation coupling on a medium-difficulty task

## Open Questions the Paper Calls Out

- Question: How does the performance of INSTINCT scale with the size of the validation dataset DV?
- Question: How does INSTINCT's performance compare to other neural bandit algorithms, such as NeuralTS, in the context of instruction optimization for black-box LLMs?
- Question: How does the choice of the white-box LLM w affect INSTINCT's performance in instruction optimization?
- Question: How does INSTINCT's performance vary with different task domains or instruction types?
- Question: How does INSTINCT's performance scale with the dimensionality of the soft prompts?

## Limitations

- The use of black-box LLM evaluation introduces variability that cannot be fully controlled or replicated
- No statistical significance testing across multiple runs to verify consistency of improvements
- Limited theoretical justification for the performance gains from hidden representation coupling
- Computational efficiency gains from pre-computation are asserted but not quantified relative to baseline BO

## Confidence

**High Confidence Claims:**
- The INSTINCT algorithm framework is clearly defined and reproducible in structure
- The use of neural bandit algorithms with NN surrogates is a valid alternative to GP-based Bayesian Optimization
- Pre-computation of hidden representations can reduce computational cost in principle

**Medium Confidence Claims:**
- INSTINCT consistently outperforms baseline methods across all tested tasks
- The coupling of NN surrogate with transformer hidden representations provides meaningful performance improvements
- The algorithm successfully generates high-quality instructions for zero-shot chain-of-thought reasoning

**Low Confidence Claims:**
- The exact magnitude of performance improvements relative to baselines
- The consistency of improvements across different black-box LLM instances
- The robustness of the algorithm to hyperparameter variations

## Next Checks

1. **Statistical Significance Testing**: Run INSTINCT with 10+ random seeds on each task and perform paired t-tests to verify that improvements over baselines are statistically significant, reporting both effect sizes and p-values.

2. **Ablation Study on Hidden Representation Coupling**: Implement a version of INSTINCT that uses raw soft prompt vectors instead of hidden representations, keeping all other components identical, and measure the performance difference across all tasks to quantify the contribution of this architectural choice.

3. **Black-Box Model Variability Analysis**: Evaluate the same set of instructions using multiple instances or versions of the black-box LLM (e.g., different ChatGPT versions or temperature settings) to assess the stability of the optimization process and determine whether performance improvements are consistent across model variations.