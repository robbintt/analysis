---
ver: rpa2
title: 'OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models'
arxiv_id: '2310.16517'
source_url: https://arxiv.org/abs/2310.16517
tags:
- topic
- data
- occullama
- occuquest
- occupational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces OccuQuest, a dataset designed to mitigate
  occupational bias in large language models by covering over 1,000 occupations across
  26 categories. The dataset includes 110,000+ prompt-completion pairs and 30,000+
  dialogues, collected using ChatGPT to ensure comprehensive coverage of occupational
  topics.
---

# OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models

## Quick Facts
- arXiv ID: 2310.16517
- Source URL: https://arxiv.org/abs/2310.16517
- Reference count: 40
- Primary result: Fine-tuning LLaMA on OccuQuest yields OccuLLaMA with 86.4% win rate against WizardLM on professional queries

## Executive Summary
This paper introduces OccuQuest, a dataset designed to mitigate occupational bias in large language models by covering over 1,000 occupations across 26 categories. The dataset includes 110,000+ prompt-completion pairs and 30,000+ dialogues, collected using ChatGPT to ensure comprehensive coverage of occupational topics. Evaluation shows OccuQuest has a more balanced occupation distribution than existing datasets like Dolly, ShareGPT, and WizardLM. Fine-tuning LLaMA on OccuQuest yields OccuLLaMA, which outperforms state-of-the-art models on professional queries, achieving an 86.4% win rate against WizardLM on real-world questions. The approach demonstrates effective mitigation of occupational bias while maintaining strong general performance.

## Method Summary
The paper constructs OccuQuest by systematically requesting ChatGPT to generate queries and responses following a hierarchical structure (Occupation → Responsibility → Topic → Question) to ensure comprehensive occupational coverage. The dataset covers over 1,000 occupations across 26 categories with 110,000+ prompt-completion pairs. The authors fine-tune LLaMA-7B on this dataset to obtain OccuLLaMA, and combine with Tulu dataset to obtain ProLLaMa. Evaluation uses GPT-4 and human evaluations to compare performance against baselines (Vicuna, Tulu, WizardLM) on both general benchmarks and occupation-specific tasks.

## Key Results
- OccuQuest demonstrates more balanced occupational distribution compared to Dolly, ShareGPT, and WizardLM datasets
- OccuLLaMa achieves 86.4% win rate against WizardLM on occu-quora professional queries
- The model maintains strong performance on general benchmarks (MMLU, GSM8K, BBH, HumanEval) while improving on occupational tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical prompting ensures comprehensive occupational coverage
- Mechanism: The data construction process uses a four-level hierarchy (Occupation → Responsibility → Topic → Question) to systematically generate queries across all occupations, preventing bias toward common or well-represented jobs
- Core assumption: Structured hierarchical prompting will yield diverse and representative occupational data
- Evidence anchors: [abstract] "We systematically request ChatGPT, organizing queries hierarchically based on Occupation, Responsibility, Topic, and Question, to ensure a comprehensive coverage of occupational specialty inquiries."

### Mechanism 2
- Claim: Balanced dataset distribution improves model performance on specialized queries
- Mechanism: By including over 1,000 occupations across 26 categories with proportional representation, the model learns to respond accurately to queries from underrepresented professions
- Core assumption: Training data distribution directly influences model response quality across different occupational domains
- Evidence anchors: [abstract] "By comparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we observe that OccuQuest exhibits a more balanced distribution across occupations."

### Mechanism 3
- Claim: Synthetic data generation via ChatGPT provides cost-effective, scalable occupational data
- Mechanism: Using ChatGPT to generate both prompts and responses creates large-scale instruction-tuning data without manual authoring, covering diverse occupational scenarios
- Core assumption: ChatGPT-generated data maintains quality and diversity comparable to human-authored or real user interaction data
- Evidence anchors: [abstract] "We utilize ChatGPT to identify key topics of concern for practitioners in each occupation and generate relevant questions and answers accordingly."

## Foundational Learning

- Concept: Dataset construction methodology for mitigating bias
  - Why needed here: Understanding how structured data collection prevents occupational bias is crucial for replicating or extending this work
  - Quick check question: How does hierarchical prompting differ from random sampling in ensuring occupational coverage?

- Concept: Instruction tuning and its role in LLM alignment
  - Why needed here: The paper relies on instruction tuning to align LLaMA models with occupational expertise, making this fundamental
  - Quick check question: What distinguishes instruction tuning from standard supervised learning in LLMs?

- Concept: Evaluation methodologies for LLM bias and performance
  - Why needed here: GPT-4 and human evaluations are central to validating the effectiveness of occupational bias mitigation
  - Quick check question: How does pairwise comparison with position swapping reduce bias in LLM-as-a-judge evaluations?

## Architecture Onboarding

- Component map: Data collection → Dataset construction → Model fine-tuning → Evaluation → Combined dataset enhancement
- Critical path: Dataset construction (OccuQuest) → LLaMA fine-tuning (OccuLLaMa) → Performance evaluation on occupational test sets
- Design tradeoffs: ChatGPT-generated data offers scalability but may contain errors vs. human-authored data being more accurate but less scalable
- Failure signatures: Poor performance on specialized occupational queries, imbalanced dataset distribution, model hallucinations in professional contexts
- First 3 experiments:
  1. Generate synthetic occupational data using ChatGPT with hierarchical prompting for 5 occupations across different categories
  2. Fine-tune LLaMA-7B on the synthetic data and evaluate on a small occupational test set
  3. Compare performance against baseline models (Vicuna, WizardLM) on occupation-specific queries using GPT-4 evaluation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does OccuQuest's occupational distribution balance compare to human-created datasets when controlling for occupational category size?
- Basis in paper: [inferred] The paper compares OccuQuest against Dolly, ShareGPT, and WizardLM but doesn't control for category size differences in the comparison
- Why unresolved: The analysis shows balanced distribution but doesn't account for whether smaller categories (like Real Estate with 6 occupations) might inherently have fewer topics/questions
- What evidence would resolve it: A statistical analysis normalizing topic/question counts per occupation across categories to determine if balance is maintained after accounting for category size

### Open Question 2
- Question: What is the optimal mix ratio of OccuQuest to other instruction-tuning datasets (like Tulu) for maximizing both occupational coverage and general reasoning abilities?
- Basis in paper: [explicit] The paper shows ProLLaMa combining OccuQuest with Tulu performs well but doesn't explore optimal mixing ratios
- Why unresolved: The paper uses a 1:1 mix but doesn't systematically test different ratios or compare against other potential mixtures
- What evidence would resolve it: Ablation studies testing various ratios of OccuQuest to other datasets while measuring both occupational task performance and general benchmark performance

### Open Question 3
- Question: How do models trained on OccuQuest perform on real-world occupational queries from practitioners outside the AI field?
- Basis in paper: [explicit] The paper tests on Quora questions and mentions practitioners with weak AI connections but doesn't specifically test on practitioners
- Why unresolved: The occu-quora set uses publicly available questions that may not represent actual practitioner queries or domain-specific terminology
- What evidence would resolve it: Direct evaluation with occupational practitioners across different fields using their own questions and rating the model responses for practical utility

## Limitations

- The dataset construction relies entirely on synthetic data generation through ChatGPT, with no independent validation of accuracy or representation
- The evaluation framework focuses primarily on occupational bias mitigation but doesn't extensively explore potential emergence of other biases
- No direct comparison with human-authored occupational data to assess quality differences between synthetic and real-world data sources

## Confidence

**High Confidence**: The claim that OccuQuest achieves a more balanced occupational distribution compared to existing datasets (Dolly, ShareGPT, WizardLM) is well-supported by the comparative analysis provided.

**Medium Confidence**: The mechanism by which hierarchical prompting ensures comprehensive occupational coverage is plausible based on the methodology description, but lacks direct validation that the resulting data is truly representative across all 1,000+ occupations.

**Low Confidence**: The claim that ChatGPT-generated data maintains quality comparable to human-authored or real user interaction data is particularly uncertain, as no independent quality assessment or comparison with alternative data sources is provided.

## Next Checks

1. **Data Quality Validation**: Conduct blind evaluation comparing ChatGPT-generated occupational queries and responses against real occupational expert queries to assess accuracy, relevance, and potential hallucinations in the synthetic data.

2. **Bias Transfer Analysis**: Test whether the occupational bias mitigation in OccuLLaMa introduces or amplifies other types of biases (gender, racial, cultural) that weren't explicitly addressed in the dataset construction process.

3. **Generalization Assessment**: Evaluate model performance on tasks outside the occupational domain to quantify any degradation in general capabilities that might result from fine-tuning on specialized occupational data.