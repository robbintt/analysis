---
ver: rpa2
title: 'Vocabulary for Universal Approximation: A Linguistic Perspective of Mapping
  Compositions'
arxiv_id: '2305.12205'
source_url: https://arxiv.org/abs/2305.12205
tags:
- such
- proof
- maps
- theorem
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper establishes that a finite set of mapping functions\u2014\
  referred to as a vocabulary\u2014suffices to approximate any continuous mapping\
  \ on a compact domain via composition. The vocabulary consists of flow maps of simple\
  \ dynamical systems, with cardinality \\(O(d^2)\\) for dimension \\(d\\)."
---

# Vocabulary for Universal Approximation: A Linguistic Perspective of Mapping Compositions

## Quick Facts
- arXiv ID: 2305.12205
- Source URL: https://arxiv.org/abs/2305.12205
- Reference count: 40
- One-line primary result: A finite set of mapping functions (vocabulary) of cardinality O(d²) suffices to approximate any continuous function on a compact domain through composition.

## Executive Summary
This paper establishes that universal approximation can be achieved using a finite vocabulary of flow maps from dynamical systems, providing a linguistic perspective on function composition analogous to how finite vocabularies generate infinite expressions in natural language. The vocabulary consists of flow maps from simple dynamical systems with cardinality O(d²) for dimension d. The universal approximation property is proved constructively by first approximating orientation-preserving diffeomorphisms with deep compositions of affine and leaky-ReLU flow maps, then approximating each flow map using the Lie product formula and Kronecker's theorem.

## Method Summary
The paper constructs a finite vocabulary V of flow maps from dynamical systems and proves that compositions of these maps can approximate any continuous function on a compact domain. The approach involves two main steps: first, approximating orientation-preserving diffeomorphisms using deep compositions of affine and leaky-ReLU flow maps; second, approximating each individual flow map in the vocabulary using the Lie product formula and Kronecker's theorem. The vocabulary V is explicitly constructed to contain flow maps of specific dynamical systems, with cardinality O(d²).

## Key Results
- A finite vocabulary V of flow maps with cardinality O(d²) suffices for universal approximation
- The approach provides a linguistic perspective on function composition analogous to natural language
- Constructive proof establishes that any continuous function can be approximated by composing flow maps from V

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Universal approximation can be achieved by composing a finite set of flow maps from dynamical systems.
- Mechanism: The paper proves that any continuous mapping on a compact domain can be approximated by composing flow maps from a finite vocabulary V of size O(d²). This is done constructively by first approximating orientation-preserving diffeomorphisms with deep compositions of affine and leaky-ReLU flow maps, then approximating each flow map using the Lie product formula and Kronecker's theorem.
- Core assumption: The vocabulary V contains flow maps of simple dynamical systems that can approximate any continuous function through composition.
- Evidence anchors:
  - [abstract] "The universal approximation property is proved constructively: first, orientation-preserving diffeomorphisms are approximated using deep compositions of simple affine and leaky-ReLU flow maps; then, each such flow map is approximated by a sequence from the finite vocabulary using the Lie product formula and Kronecker's theorem."
  - [section] "We proved that it is possible to achieve the universal approximation property by composing a sequence of mappings in a finite set V."
- Break condition: If the core assumption fails, i.e., if the vocabulary V does not contain sufficient flow maps to approximate all continuous functions, the universal approximation property would not hold.

### Mechanism 2
- Claim: The Lie product formula and Kronecker's theorem are key tools for approximating flow maps.
- Mechanism: The Lie product formula allows approximating the exponential of a sum of matrices by products of matrix exponentials. Kronecker's theorem is used to approximate real numbers by rational combinations, which is then used to approximate flow maps with parameters that are irrational multiples.
- Core assumption: The Lie product formula and Kronecker's theorem can be applied to the specific flow maps in the vocabulary V to achieve the desired approximation.
- Evidence anchors:
  - [section] "For Part 2, the validation involves three techniques in math: the Lie product formula [18], the splitting method [21] and the Kronecker's theorem [2]."
  - [section] "Employing the Kronecker's Theorem 3.5 with γ = −√2, approximating t by p − q√2 such that |p − q√2 − t|< ε/C, then we have ∥φtv(x) − φp−q√2v(x)∥ < ε, ∀x ∈ Ω."
- Break condition: If the Lie product formula or Kronecker's theorem cannot be applied to the specific flow maps in V, or if the approximations are not accurate enough, the universal approximation property would fail.

### Mechanism 3
- Claim: The vocabulary V is constructed to contain a finite set of flow maps that can approximate any continuous function.
- Mechanism: The vocabulary V is explicitly constructed to contain flow maps of specific dynamical systems, including affine transformations and generalized leaky-ReLU functions. The cardinality of V is O(d²), where d is the dimension of the input space.
- Core assumption: The specific flow maps included in V are sufficient to approximate any continuous function through composition.
- Evidence anchors:
  - [abstract] "The vocabulary consists of flow maps of simple dynamical systems, with cardinality O(d²) for dimension d."
  - [section] "We will show that the following set V meets our requirement for universal approximations, V = {φτ±ei, φτ±Eijx, φτ±Σei,0(x), φτ±Σ0,ei(x) |i, j ∈ {1, 2, ..., d}, τ ∈ {1, √2}}."
- Break condition: If the specific flow maps in V are not sufficient to approximate all continuous functions, or if the cardinality O(d²) is not enough, the universal approximation property would not hold.

## Foundational Learning

- Concept: Dynamical systems and flow maps
  - Why needed here: The paper uses flow maps of dynamical systems as the building blocks for the vocabulary V. Understanding dynamical systems and flow maps is crucial for understanding how the approximation works.
  - Quick check question: Can you explain what a flow map is in the context of dynamical systems?

- Concept: Lie product formula and Kronecker's theorem
  - Why needed here: These mathematical tools are used to approximate flow maps in the vocabulary V. Understanding these theorems is essential for grasping the approximation mechanism.
  - Quick check question: Can you state the Lie product formula and explain its significance in this context?

- Concept: Universal approximation property
  - Why needed here: The paper aims to prove a universal approximation property for the vocabulary V. Understanding what universal approximation means and its implications is crucial for evaluating the results.
  - Quick check question: What is the universal approximation property, and why is it important in the context of this paper?

## Architecture Onboarding

- Component map:
  - Vocabulary V -> Flow maps -> Compositions -> Approximation of continuous functions

- Critical path:
  1. Construct the vocabulary V with flow maps of dynamical systems
  2. Use the Lie product formula and Kronecker's theorem to approximate each flow map in V
  3. Compose the approximated flow maps to approximate any continuous function on a compact domain

- Design tradeoffs:
  - The cardinality of V is O(d²), which may be large for high-dimensional input spaces
  - The approximation accuracy depends on the number of flow maps used in the composition, which may lead to long sequences for high accuracy

- Failure signatures:
  - If the approximation error is too large, it may indicate that the vocabulary V is not sufficient or that the number of flow maps used in the composition is not enough
  - If the approximation is computationally expensive, it may indicate that the number of flow maps used in the composition is too large

- First 3 experiments:
  1. Verify the approximation accuracy of the vocabulary V on simple functions, such as linear and polynomial functions
  2. Test the scalability of the approach by increasing the dimension of the input space and measuring the approximation error and computational cost
  3. Compare the approximation accuracy and computational cost of the proposed approach with other universal approximation methods, such as neural networks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal cardinality of the vocabulary V for universal approximation in dimension d?
- Basis in paper: [explicit] The paper constructs a vocabulary V with cardinality O(d^2) but notes it is not optimal, stating "the constructed V in Eq. (8) is not optimal" and that "the required sequence length may be extremely large" for practical applications.
- Why unresolved: The paper focuses on proving existence rather than finding the minimum cardinality. The construction method prioritizes theoretical proof over efficiency.
- What evidence would resolve it: A proof establishing the minimum cardinality needed for universal approximation, or empirical evidence showing how approximation error scales with vocabulary size for various function classes.

### Open Question 2
- Question: How does the sequence length required for approximation scale with the desired accuracy ε?
- Basis in paper: [inferred] The paper proves that for any ε > 0, there exists a sequence of mappings that approximates the target function within ε, but doesn't analyze the relationship between sequence length and ε.
- Why unresolved: The construction method is theoretical and doesn't provide concrete bounds on how sequence length grows with ε.
- What evidence would resolve it: Analytical bounds or empirical measurements showing how many compositions are needed to achieve ε accuracy for various function classes.

### Open Question 3
- Question: Can the vocabulary construction be adapted for functions with different input and output dimensions?
- Basis in paper: [explicit] The paper states "Our results can be directly extended to the case of different input and output dimensions" and provides a lifting construction for f ∈ C(R^dx, R^dy).
- Why unresolved: While the paper claims extension is possible, it doesn't provide the construction or analyze how the vocabulary cardinality changes when dx ≠ dy.
- What evidence would resolve it: A concrete construction of the vocabulary for the asymmetric case, along with analysis of how the O(d^2) cardinality scales when input and output dimensions differ.

## Limitations

- Proof Construction Gap: While the paper provides a constructive proof outline, several critical implementation details remain unspecified, including exact sequence length and computational complexity.
- Vocabulary Construction Specificity: The paper doesn't rigorously prove that the specific flow maps chosen are necessary or optimal, and the choice of parameters appears arbitrary.
- Dimensional Scaling Concerns: The paper doesn't analyze how approximation quality degrades with increasing dimension or provide empirical validation across varying dimensionalities.

## Confidence

**High Confidence**: The theoretical framework connecting dynamical systems flow maps to universal approximation is mathematically sound.

**Medium Confidence**: The constructive proof approach is valid in principle, but practical implementation details and numerical stability remain uncertain.

**Low Confidence**: Claims about computational efficiency and practical applicability lack supporting evidence.

## Next Checks

1. **Numerical Implementation Validation**: Implement the constructive proof algorithm for approximating simple functions (e.g., identity, rotation, scaling) and measure the actual approximation error versus theoretical bounds. Document the sequence length required to achieve ε accuracy.

2. **Dimensionality Scaling Study**: Systematically vary the input dimension d and measure how the vocabulary size O(d²) and approximation quality scale. Compare with theoretical predictions and identify at what dimensionality the approach becomes impractical.

3. **Computational Complexity Analysis**: Implement the composition of flow maps for high-dimensional functions and measure actual computational costs (time, memory). Compare these empirical costs with theoretical expectations and with standard neural network approaches for the same approximation tasks.