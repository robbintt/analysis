---
ver: rpa2
title: Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source
  Supervision
arxiv_id: '2312.08056'
source_url: https://arxiv.org/abs/2312.08056
tags:
- artifact
- image
- text
- arxiv
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of generating accurate visual
  images of lost historical artifacts from textual descriptions. The authors propose
  a novel knowledge-aware approach that uses a pre-trained diffusion model and incorporates
  three key techniques: LLM-enhanced prompting with explicit archaeological knowledge,
  contrastive learning for textual alignment, and multi-source supervision using edge
  and perceptual losses.'
---

# Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source Supervision

## Quick Facts
- **arXiv ID**: 2312.08056
- **Source URL**: https://arxiv.org/abs/2312.08056
- **Reference count**: 40
- **Primary result**: Novel knowledge-aware approach using LLM-enhanced prompting and multi-source supervision significantly outperforms existing methods for generating accurate historical artifact images from textual descriptions.

## Executive Summary
This paper addresses the challenging problem of generating accurate visual images of lost historical artifacts from textual descriptions. The authors propose a knowledge-aware approach that combines LLM-enhanced prompting with explicit archaeological knowledge, contrastive learning for textual alignment, and multi-source supervision using edge and perceptual losses. By leveraging these techniques with a pre-trained diffusion model, the method significantly improves the quality and accuracy of generated artifact images compared to existing approaches, as demonstrated by superior performance in automatic metrics and human evaluation.

## Method Summary
The proposed method builds upon a pre-trained Chinese Stable Diffusion model and introduces three key innovations. First, it uses GPT-3.5-TURBO to enhance textual prompts by extracting core information from raw artifact descriptions and supplementing them with explicit archaeological knowledge about material, shape, pattern, and type definition. Second, it employs contrastive learning to align text representations with domain expertise by minimizing distances between description-name pairs and maximizing distances between mismatched pairs from different time periods. Third, it introduces multi-source supervision through edge loss and perceptual loss to enforce stricter visual-semantic constraints, ensuring accurate shapes, colors, and textures in the generated images.

## Key Results
- Achieves significant improvements in CLIP Visual Similarity, SSIM, and LPIPS scores compared to baseline methods
- Outperforms existing approaches in both automatic metrics and human evaluation
- Successfully generates higher-quality artifact images that better align with implicit details and historical knowledge in written documents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-enhanced prompting infuses domain-specific archaeological knowledge into text prompts, improving image generation quality.
- Mechanism: The LLM extracts core information from raw artifact descriptions and retrieves relevant archaeological knowledge to construct structured prompts with explicit attributes like material, shape, pattern, and type definition.
- Core assumption: LLMs can effectively extract and supplement missing archaeological attributes from raw descriptions using in-context learning and their world knowledge.
- Evidence anchors:
  - [abstract]: "we construct prompts with explicit archaeological knowledge elicited from large language models (LLMs)"
  - [section 4.1]: "we use LLMs to extract the core and meaningful information in the given text prompt and reorganize them in a more structured way to explicitly present the current knowledge information"
  - [corpus]: Weak evidence - the corpus contains papers about artifact detection and correction, but none specifically address LLM-enhanced prompting for artifact image synthesis.
- Break condition: The LLM fails to extract meaningful information from the raw description or retrieves irrelevant archaeological knowledge, leading to noisy or misleading prompts.

### Mechanism 2
- Claim: Contrastive learning aligns text representations with domain expertise, improving the model's understanding of artifact descriptions.
- Mechanism: The model minimizes the distance between positive pairs (description-name pairs) and maximizes the distance between negative pairs (descriptions with names from different time periods) in the text encoder's embedding space.
- Core assumption: Artifact names are accurate and concise summaries of their descriptions, and aligning them through contrastive learning reflects domain knowledge.
- Evidence anchors:
  - [abstract]: "we incorporate additional textual guidance to correlated historical expertise in a contrastive manner"
  - [section 4.2]: "we propose the use of contrastive learning, which aims to minimize the distance between positive pairs... and to maximize the distance between negative ones with mismatching names"
  - [corpus]: No direct evidence - the corpus doesn't contain papers about contrastive learning for text-image alignment in artifact synthesis.
- Break condition: The contrastive learning fails to effectively differentiate between similar artifact descriptions or incorrectly aligns descriptions with unrelated names.

### Mechanism 3
- Claim: Multi-source supervision (edge loss and perceptual loss) enforces stricter visual-semantic constraints, improving the accuracy of generated artifact images.
- Mechanism: Edge loss minimizes the difference in contours between the generated and ground-truth images, while perceptual loss minimizes the difference in high-level features like color and texture.
- Core assumption: The vanilla Stable Diffusion model generates images with blurry edges and incorrect colors/patterns, and stricter visual constraints are necessary to address these issues.
- Evidence anchors:
  - [abstract]: "we introduce further visual-semantic constraints on edge and perceptual features that enable our model to learn more intricate visual details of the artifacts"
  - [section 4.3]: "we propose to use edge loss [28] and perceptual loss [12] that apply additional visual-semantic supervision on images generated by our Stable Diffusion model"
  - [corpus]: No direct evidence - the corpus doesn't contain papers about using edge and perceptual loss for artifact image synthesis.
- Break condition: The additional visual-semantic constraints overfit to the training data or introduce artifacts that degrade the overall image quality.

## Foundational Learning

- Concept: Diffusion models
  - Why needed here: The proposed method builds upon a pre-trained diffusion model (Stable Diffusion) as the backbone for artifact image synthesis.
  - Quick check question: What are the two main processes in diffusion models, and how do they contribute to image generation?

- Concept: Contrastive learning
  - Why needed here: Contrastive learning is used to align the text representations of artifact descriptions with their names, reflecting domain expertise.
  - Quick check question: How does contrastive learning help in learning better text representations for artifact descriptions?

- Concept: Perceptual loss
  - Why needed here: Perceptual loss is used to enforce stricter visual-semantic constraints on the generated artifact images, ensuring they have accurate colors and textures.
  - Quick check question: What is the purpose of perceptual loss in image generation tasks, and how does it differ from traditional pixel-wise loss functions?

## Architecture Onboarding

- Component map: LLM (GPT-3.5-TURBO) → Text encoder (CLIP) → U-Net (Stable Diffusion) → VAE → Generated image
- Critical path: LLM-enhanced prompt → Text encoder → U-Net → VAE → Generated image
- Design tradeoffs:
  - Using a pre-trained diffusion model as backbone vs. training from scratch
  - Incorporating additional supervision (contrastive learning, edge loss, perceptual loss) vs. relying solely on the diffusion model's training objective
  - Using a powerful LLM for prompt enhancement vs. simpler prompt engineering techniques
- Failure signatures:
  - Poor image quality despite high CLIP Visual Similarity (overfitting to textual content)
  - Inaccurate artifact shapes or patterns (insufficient edge loss supervision)
  - Incorrect colors or textures (insufficient perceptual loss supervision)
  - Noisy or misleading prompts (LLM fails to extract relevant archaeological knowledge)
- First 3 experiments:
  1. Compare the performance of the finetuned baseline model using raw descriptions vs. LLM-enhanced prompts.
  2. Evaluate the impact of contrastive learning on the model's ability to align text representations with domain expertise.
  3. Assess the effectiveness of edge loss and perceptual loss in improving the accuracy of generated artifact images.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform on artifacts from different time periods and regions, and does it show any bias towards certain types of artifacts or historical periods?
- Basis in paper: [inferred] The paper mentions that the dataset consists of artifacts from the National Palace Museum, which primarily focuses on Chinese artifacts. However, the paper does not explicitly discuss the model's performance on artifacts from different time periods and regions.
- Why unresolved: The paper does not provide a detailed analysis of the model's performance on artifacts from different time periods and regions, which could reveal potential biases or limitations in the model's ability to generalize to diverse historical contexts.
- What evidence would resolve it: Conducting experiments on a more diverse dataset that includes artifacts from various time periods and regions, and analyzing the model's performance across different categories, would provide insights into its generalizability and potential biases.

### Open Question 2
- Question: How sensitive is the model to the quality and completeness of the textual descriptions provided as input, and how does it handle cases where the descriptions are noisy, incomplete, or contain inaccuracies?
- Basis in paper: [explicit] The paper mentions that the raw descriptions of artifacts are often incomplete and filled with noisy messages, which the proposed method aims to address by using LLMs to enhance the prompt construction. However, the paper does not explicitly discuss the model's sensitivity to the quality and completeness of the input descriptions.
- Why unresolved: The paper does not provide a thorough analysis of the model's robustness to varying qualities of input descriptions, which is crucial for real-world applications where the descriptions may not always be perfect.
- What evidence would resolve it: Conducting experiments with different levels of noise and incompleteness in the input descriptions,