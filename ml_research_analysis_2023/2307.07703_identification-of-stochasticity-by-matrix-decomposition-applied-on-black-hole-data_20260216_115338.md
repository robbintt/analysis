---
ver: rpa2
title: 'Identification of Stochasticity by Matrix-decomposition: Applied on Black
  Hole Data'
arxiv_id: '2307.07703'
source_url: https://arxiv.org/abs/2307.07703
tags:
- timeseries
- stochastic
- data
- non-stochastic
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a two-legged matrix decomposition-based algorithm
  to classify time series as stochastic or non-stochastic. The first leg uses SVD
  decomposition followed by topological analysis (Betti numbers) on the top two right
  singular vectors, while the second leg uses PCA-derived features followed by SVM
  classification.
---

# Identification of Stochasticity by Matrix-decomposition: Applied on Black Hole Data

## Quick Facts
- arXiv ID: 2307.07703
- Source URL: https://arxiv.org/abs/2307.07705
- Reference count: 36
- Primary result: Two-legged matrix decomposition algorithm classifies time series as stochastic or non-stochastic with 11/12 agreement on black hole data

## Executive Summary
This paper presents a novel matrix decomposition-based algorithm for classifying time series as stochastic or non-stochastic. The method combines two complementary approaches: topological analysis of SVD-derived singular vectors and PCA-based feature extraction followed by SVM classification. The algorithm is applied to both synthetic data and astronomical observations of the black hole GRS 1915+105, showing promising results compared to traditional and deep learning approaches.

## Method Summary
The method employs two parallel analysis legs. The first leg uses SVD decomposition on phase-space reconstructed data, followed by topological analysis (Betti numbers) of the top two right singular vectors to distinguish structured from unstructured dynamics. The second leg uses PCA-derived eigenvalue ratio features extracted through hierarchical splitting, which are then classified using an SVM. The final classification is determined by concurrence between the two legs, with disagreements labeled as "Uncertain."

## Key Results
- Two legs concur on 11 out of 12 temporal classes of GRS 1915+105 black hole data
- The δ class is labeled as "Uncertain" due to conflicting SVD and PCA classifications
- Method shows O(N) + O(NlogN) computational complexity, comparable to deep learning approaches
- Outperforms traditional methods in binary classification accuracy on RXTE data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SVD decomposition reveals temporal structure through topology of top two right singular vectors
- Mechanism: Phase-space reconstruction captures temporal dependencies; SVD separates them into orthogonal modes. The E1-E2 topology (connected components and voids) encodes structured vs. unstructured dynamics
- Core assumption: Non-stochastic series produce structured attractors with multiple components/voids; stochastic series produce single blobs
- Evidence: Abstract mentions topological analysis leading to SVD-label; section describes expected topology patterns
- Break condition: Poor phase-space reconstruction parameters (M, τ) may not reflect true dynamics

### Mechanism 2
- Claim: PCA-derived eigenvalue ratios capture directional structure in time series segments
- Mechanism: Recursive splitting with eigenvalue ratio computation measures persistent orientation vs. isotropy across scales
- Core assumption: Non-stochastic series show high variance and average ratio; stochastic series show low variance and ratio ≈ 1
- Evidence: Abstract notes linear separability of PCA-derived features; section explains eigenvalue ratio interpretation
- Break condition: Poor splitting threshold leads to inappropriate segment sizes

### Mechanism 3
- Claim: Combining temporal-ordering-specific (SVD) and ordering-agnostic (PCA) analyses improves reliability
- Mechanism: Independent leg classifications with concurrence requirement reduces false positives
- Core assumption: Two methods are complementary with uncorrelated errors
- Evidence: Abstract describes concurrence logic; section mentions complementary nature
- Break condition: Shared blind spots cause correlated failures

## Foundational Learning

- Concept: Phase-space reconstruction using embedding dimension and time lag
  - Why needed: Required for SVD data matrix construction and temporal dependency capture
  - Quick check: What happens when embedding dimension is too small?

- Concept: Topological data analysis (Betti numbers)
  - Why needed: Quantifies topology of E1-E2 plot to distinguish structured vs. unstructured dynamics
  - Quick check: What do B0 and B1 represent in a 2D Betti descriptor?

- Concept: PCA and eigenvalue ratio analysis
  - Why needed: Detects directional structure without temporal ordering
  - Quick check: How does eigenvalue ratio change between dominant orientation and isotropic data?

## Architecture Onboarding

- Component map: Data → Phase-space reconstruction → SVD → Betti analysis → PCA features → SVM → Concurrence check → Final label
- Critical path: Data preprocessing → SVD leg processing → PCA leg processing → Fusion logic → Final classification
- Design tradeoffs: SVD sensitivity to parameters vs. PCA parameter-free nature; combined robustness vs. computational overhead
- Failure signatures: SVD false negatives (structured shows single blob), PCA false negatives (low ratio variance), fusion uncertainty from discordance
- First 3 experiments: 1) Validate Betti classification on synthetic data with ground truth, 2) Test PCA features on same synthetic data for linear separability, 3) Run full pipeline on RXTE subset comparing with published results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does the δ class exhibit conflicting labels between SVD and PCA legs, resulting in "Uncertain" classification?
- Basis: Paper explicitly states δ class is only one with non-concurring labels
- Why unresolved: Paper acknowledges ambiguity without definitive explanation
- Resolution needed: Additional δ class analysis or comparison with other classification methods

### Open Question 2
- Question: Can method extend to multi-class classification beyond binary stochastic/non-stochastic?
- Basis: Current method designed for binary classification; paper applies to 12 classes but still binary framework
- Why unresolved: Paper focuses exclusively on binary classification
- Resolution needed: Testing on datasets with multiple distinct behavior types

### Open Question 3
- Question: How does computational efficiency compare to deep learning on larger datasets?
- Basis: Paper claims O(N) + O(NlogN) complexity and compares to deep learning, but only for specific RXTE dataset
- Why unresolved: Theoretical analysis without empirical runtime comparisons across dataset sizes
- Resolution needed: Benchmarking experiments across varying dataset sizes

## Limitations
- Method relies on critical phase-space reconstruction parameters (M, τ) without specifying values used
- Recursive PCA splitting depends on unspecified eigenvalue ratio threshold
- Handling of "Uncertain" labels lacks clear downstream implications
- Real-world validation lacks comprehensive error analysis and uncertainty quantification

## Confidence
- High Confidence: Theoretical framework connecting topology to stochasticity is sound
- Medium Confidence: Synthetic data proof-of-concept; real-world validation incomplete
- Low Confidence: "Uncertain" label handling and implications not well-defined

## Next Checks
1. Perform parameter sensitivity analysis by varying M, τ (SVD leg) and splitting threshold (PCA leg) across different time series types
2. Conduct detailed error analysis on RXTE temporal classes where SVD and PCA labels disagree
3. Benchmark against established nonlinear time series analysis techniques on standardized datasets with known labels