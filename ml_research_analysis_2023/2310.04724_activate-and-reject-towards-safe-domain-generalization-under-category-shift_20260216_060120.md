---
ver: rpa2
title: 'Activate and Reject: Towards Safe Domain Generalization under Category Shift'
arxiv_id: '2310.04724'
source_url: https://arxiv.org/abs/2310.04724
tags:
- domain
- unknown
- classes
- pages
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles Domain Generalization under Category Shift (DGCS),
  where a model trained on source domain data must simultaneously classify known classes
  and detect unknown classes in target domains without access to target data during
  training. The key challenge is learning the concept of "unknown" without unknown-class
  training samples and adapting to unseen environments at test time.
---

# Activate and Reject: Towards Safe Domain Generalization under Category Shift

## Quick Facts
- arXiv ID: 2310.04724
- Source URL: https://arxiv.org/abs/2310.04724
- Reference count: 40
- Key outcome: ART framework achieves state-of-the-art H-scores, improving by 6.1% on average across vision tasks including image classification, object detection, and semantic segmentation

## Executive Summary
This paper addresses Domain Generalization under Category Shift (DGCS), where models must classify known classes and detect unknown classes in target domains without access to target data during training. The proposed Activate and Reject (ART) framework tackles this challenge through two components: Unknown-aware Gradient Diffusion (UGD) during training and Test-time Unknown Rejection (TUR) at test time. UGD forces the model to maintain non-zero responses for unknown classes while mitigating overconfidence in known classes, and TUR uses cross-domain nearest neighbor search to refine predictions without updating model parameters. ART demonstrates consistent improvements across multiple vision benchmarks.

## Method Summary
ART consists of two main components working together to address DGCS. During training, Unknown-aware Gradient Diffusion (UGD) combines an Unknown Activation Loss (LUA) that forces the unknown logit to respond to all inputs with a Logit Smoothing Cross-Entropy loss (LSCE) that uses temperature scaling and L2 penalties to reduce overconfidence. At test time, Test-time Unknown Rejection (TUR) uses cross-domain nearest neighbor search on stored source embeddings to determine if test samples belong to known classes, then updates target prototypes dynamically without backpropagation. The framework requires training a (|Cs|+1)-way classifier where Cs is the set of known classes, then applying TUR at inference time to refine predictions based on nearest neighbor consistency across domains.

## Key Results
- Improves H-score by 6.1% on average across PACS, Office-Home, Office-31, and Digits benchmarks
- Establishes new state-of-the-art results for object detection and semantic segmentation under DGCS
- Demonstrates consistent performance gains across different tasks, showing robust generalization capability
- Shows ART works especially well when the number of known classes is small

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unknown activation loss LUA forces the model to produce a non-zero logit for the unknown class during training
- Mechanism: By minimizing the negative log-likelihood of the unknown logit while ignoring the ground truth class, LUA ensures that the unknown logit responds to all input samples regardless of their true class label
- Core assumption: The model can learn to distinguish known from unknown classes without seeing unknown-class data during training
- Evidence anchors: [abstract] "During training, we promote the response to the unknown by optimizing the unknown probability"; [section 3.3] "we forceully increase the unknown probability by minimizing the negative log-likelihood"; [corpus] Weak evidence - no direct citations found supporting this specific activation mechanism

### Mechanism 2
- Claim: Temperature-scaled cross-entropy with L2 penalty (LSCE) mitigates overconfidence in known classes
- Mechanism: The temperature scaling (τ > 1) spreads probability mass more evenly across classes, while the L2 penalty on logits prevents excessive logit norm growth that would otherwise suppress the unknown logit
- Core assumption: Overconfident predictions on known classes are the primary reason unknown classes receive low probability
- Evidence anchors: [abstract] "smoothing the overall output to mitigate the overconfidence issue"; [section 3.2] "we introduce a smoothed cross-entropy loss to promote the response to the unknown by adding the penalty on the L2 norm of the logits"; [corpus] No direct citations found supporting this specific smoothing approach

### Mechanism 3
- Claim: Test-time unknown rejection (TUR) refines decision boundaries using cross-domain nearest neighbor search
- Mechanism: TUR uses prototype information and cyclic consistency constraints to identify whether test samples belong to known classes, then updates target prototypes dynamically without backpropagation
- Core assumption: The embedding space structure learned during training contains sufficient information to distinguish known from unknown classes at test time
- Evidence anchors: [abstract] "TUR uses cross-domain nearest neighbor search and prototype information to refine predictions without updating model parameters"; [section 3.3] "TUR first determines if the input belongs to known classes or not via a cross-domain nearest neighbor search"; [corpus] No direct citations found supporting this specific nearest-neighbor adaptation approach

## Foundational Learning

- Concept: Domain Generalization under Category Shift (DGCS)
  - Why needed here: This is the specific problem setting where models must classify known classes and detect unknown classes across domain shifts without target data during training
  - Quick check question: What are the two types of distribution shifts considered in DGCS?

- Concept: Overconfidence in deep neural networks
  - Why needed here: Standard softmax cross-entropy training leads to overconfident predictions that suppress unknown class detection
  - Quick check question: Why does overconfidence hurt unknown class detection in DGCS?

- Concept: Test-time adaptation without backpropagation
  - Why needed here: TUR needs to refine predictions using unlabeled test data without updating model parameters
  - Quick check question: How does TUR update target prototypes without gradient computation?

## Architecture Onboarding

- Component map: UGD (LUA + LSCE) → TUR (nearest neighbor search + prototype update) → final prediction
- Critical path: Training: standard features + classifier → UGD loss → source-trained model; Testing: feature extraction → nearest neighbor search → prototype comparison → TUR prediction
- Design tradeoffs: TUR is training-free but requires storing source embeddings; UGD adds complexity but improves unknown detection
- Failure signatures: High unknown class accuracy but very low known class accuracy suggests overconfidence mitigation gone too far
- First 3 experiments:
  1. Verify LUA alone increases unknown logit response on synthetic data with known/unknown separation
  2. Test LSCE temperature and λ sensitivity on a simple benchmark
  3. Validate TUR nearest neighbor search correctly identifies out-of-distribution samples on held-out data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ART perform when the number of known classes is very small relative to the total number of classes across source and target domains?
- Basis in paper: [explicit] The paper states "ART consistently outperforms the previous best method in terms of hs especially when the size is small" and shows experiments varying the number of known classes
- Why unresolved: While the paper demonstrates ART works better with fewer known classes, it doesn't establish the absolute minimum number of known classes needed for ART to be effective, nor does it explore the theoretical limits of this approach
- What evidence would resolve it: Systematic experiments testing ART with progressively fewer known classes (e.g., 1-2 classes) and theoretical analysis of the relationship between known class count and detection performance

### Open Question 2
- Question: What is the theoretical foundation for why smoothing the output logits (LSCE) improves unknown class detection performance?
- Basis in paper: [explicit] The paper introduces LSCE as a component of UGD but states "we aim to enhance the response to unknown classes by increasing the smoothness of the network's output" without providing theoretical justification
- Why unresolved: The paper provides empirical evidence that LSCE helps but doesn't explain the mechanism or prove why smoothing logits would improve discrimination between known and unknown classes
- What evidence would resolve it: Theoretical analysis connecting logit smoothness to decision boundary properties, or ablation studies isolating the effects of different smoothing components (temperature scaling vs. L2 penalty)

### Open Question 3
- Question: How does TUR's cross-domain nearest neighbor approach scale with very large source datasets where computing KNN for every test sample becomes computationally expensive?
- Basis in paper: [inferred] TUR uses KNN search on source embeddings for test-time adaptation, which is computationally intensive for large datasets
- Why unresolved: The paper demonstrates TUR's effectiveness but doesn't address computational complexity or propose optimizations for large-scale scenarios
- What evidence would resolve it: Performance and runtime analysis of TUR on datasets of varying sizes, or experiments comparing TUR with approximate nearest neighbor methods or learned prototypes

## Limitations

- UGD assumes the unknown logit can be meaningfully trained without seeing unknown-class samples, which may fail under severe domain shifts
- TUR's effectiveness depends on the learned embedding space remaining discriminative across domains, which can break under extreme domain shifts
- The framework requires storing source domain embeddings for TUR, creating memory constraints for large-scale applications

## Confidence

**High confidence**: The general problem formulation of DGCS and the motivation for addressing overconfidence in known classes are well-established. The paper demonstrates consistent performance improvements across multiple benchmarks and tasks, suggesting the overall approach is sound.

**Medium confidence**: The specific mechanisms of LUA and LSCE are logically coherent but lack direct empirical validation in isolation. The paper presents these as a combined UGD loss without separating their individual contributions.

**Low confidence**: TUR's effectiveness heavily depends on the quality of the learned embedding space and the assumption that cross-domain nearest neighbor search remains meaningful. The paper provides limited analysis of TUR's performance breakdown or sensitivity to hyperparameters like KNN K value.

## Next Checks

1. **Component isolation**: Run controlled experiments to measure the individual contribution of LUA vs LSCE in UGD by testing each loss component separately on a simple benchmark.

2. **TUR sensitivity analysis**: Systematically vary the KNN K parameter and prototype update rate ϕ in TUR to determine their impact on known vs unknown class accuracy, and test TUR's performance degradation as domain shift increases.

3. **Embedding space quality**: Visualize and quantitatively measure the embedding space separation between known and unknown classes across source and target domains to validate the assumption that nearest neighbor search remains meaningful under domain shift.