---
ver: rpa2
title: 'Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical
  Tasks'
arxiv_id: '2311.11608'
source_url: https://arxiv.org/abs/2311.11608
tags:
- biomedical
- tasks
- task
- taiyi
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors developed Taiyi, a bilingual (English and Chinese)
  large language model fine-tuned on diverse biomedical tasks. They curated 140 datasets
  across 15 biomedical NLP task types, created standardized instruction data, and
  employed a two-stage supervised fine-tuning strategy.
---

# Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse Biomedical Tasks

## Quick Facts
- arXiv ID: 2311.11608
- Source URL: https://arxiv.org/abs/2311.11608
- Reference count: 0
- Primary result: Taiyi achieves average F1-scores of 64.8% and accuracy of 64.8% on diverse biomedical NLP tasks

## Executive Summary
This paper presents Taiyi, a bilingual (English and Chinese) large language model fine-tuned on diverse biomedical tasks. The authors curated 140 datasets across 15 biomedical NLP task types and employed a two-stage supervised fine-tuning strategy to address task interference challenges. Taiyi demonstrates superior performance compared to general LLMs on named entity recognition, relation extraction, text classification, and question answering tasks, with average F1-scores of 64.8% and accuracy of 64.8%. The model shows promising bilingual multi-tasking capability in the biomedical domain while still underperforming specialized models on certain tasks.

## Method Summary
The authors developed Taiyi by fine-tuning Qwen-7B on 140 biomedical datasets across 15 task types using a two-stage supervised fine-tuning strategy. Stage 1 trained on 102 English datasets (~340K instances) for 5 epochs, followed by Stage 2 which continued training on combined English and 38 Chinese datasets for 3 epochs. The training used QLoRA with 8 A40 GPUs, batch size 12/GPU, and learning rate 0.0002. Datasets were converted to standardized instruction format and filtered for quality to avoid duplication and overlap.

## Key Results
- Achieved average F1-scores of 64.8% and accuracy of 64.8% across 13 biomedical test sets
- Two-stage fine-tuning strategy improved performance by approximately 10% compared to single-stage approaches
- Demonstrated zero-shot generalization capability on unseen biomedical entity types (species and cell lines)
- Showed superior performance compared to general LLMs on diverse biomedical tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage supervised fine-tuning improves performance by first specializing on generation-agnostic tasks before generalizing across all tasks.
- Mechanism: The first stage trains on tasks that are not naturally generative (NER, RE, TC, MT), allowing the model to learn task-specific patterns without interference. The second stage introduces generative tasks (QA, dialogue) using the specialized model as a starting point, reducing catastrophic forgetting.
- Core assumption: Task interference is minimized when similar task types are grouped and trained sequentially rather than mixed from the start.
- Evidence anchors:
  - [section] "When we simply combined all task datasets as a one-stage strategy to fine-tune the LLM, the results show poor performances on all tasks. The main reason may be the challenges of converging different tasks with varying levels of difficulty and dataset sizes."
  - [section] "The results show that our two-stage strategy can achieve significant improvement (~ average 10% in metrics) than the one-stage strategy on all English and Chinese tasks."
  - [corpus] No direct evidence; inference based on model behavior described in the paper.
- Break condition: If task interference is not the primary bottleneck, or if the two-stage split does not align with task difficulty gradients, the improvement may not materialize.

### Mechanism 2
- Claim: Curated high-quality bilingual datasets improve zero-shot generalization on unseen biomedical entity types.
- Mechanism: By training on diverse datasets that cover many entity types, the model learns generalizable patterns for entity recognition. This allows it to perform reasonably on unseen entity types (e.g., species, cell lines) through transfer of learned recognition cues.
- Core assumption: Entity recognition skills are transferable across semantically related biomedical entities even when specific entity types were not present in training data.
- Evidence anchors:
  - [section] "Among these entity types, Taiyi can achieve better performance to chemical, disease, gene, and variant entities, since these entities are seen in other related datasets (e.g., BC5CDR, GnormPlus, and tmVar) during the fine-tuning stage."
  - [section] "Moreover, it is noteworthy that even for the unseen entity types (i.e., species and cell lines) in the fine-tuning stage, Taiyi can still understand the entity recognition instruction and extract some species and cell line entities."
  - [corpus] No direct citations; claim is based on experimental results described in the paper.
- Break condition: If entity recognition is highly type-specific and cannot transfer across unseen categories, zero-shot performance would drop significantly.

### Mechanism 3
- Claim: Domain-specific instruction tuning produces more accurate biomedical outputs than general-domain instruction tuning.
- Mechanism: Instruction templates tailored to biomedical tasks encode domain-specific linguistic patterns and task expectations, enabling the model to generate more precise and contextually appropriate responses compared to models fine-tuned on general instructions.
- Core assumption: Instruction format and phrasing influence the model's ability to understand and execute task-specific requirements in specialized domains.
- Evidence anchors:
  - [section] "From the results, Taiyi generates more detailed and accurate responses to biomedical questions compared to the general domain model Qwen-Chat."
  - [section] "In the final case of relation extraction, Taiyi properly extracts complex biomedical relations between proteins, diseases, and chemicals, which Qwen-Chat is unable to capture."
  - [corpus] No direct evidence; based on qualitative comparison in the paper.
- Break condition: If the model's language understanding is not sensitive to instruction phrasing, or if domain knowledge is primarily encoded in pretraining rather than fine-tuning, the advantage of domain-specific instructions may be minimal.

## Foundational Learning

- Concept: Supervised fine-tuning (SFT)
  - Why needed here: To adapt a general-purpose LLM to specialized biomedical tasks by learning from manually annotated data.
  - Quick check question: What is the difference between SFT and continued pretraining in terms of data requirements and training objectives?

- Concept: Instruction tuning
  - Why needed here: To enable the model to follow natural language instructions for diverse biomedical NLP tasks rather than just pattern matching.
  - Quick check question: How does instruction tuning differ from standard supervised learning when the training data includes explicit task descriptions?

- Concept: Task interference in multi-task learning
  - Why needed here: To understand why simply mixing all biomedical tasks in one training stage leads to poor performance.
  - Quick check question: What factors contribute to task interference when fine-tuning a single model on multiple heterogeneous NLP tasks?

## Architecture Onboarding

- Component map: Qwen-7B -> Two-stage SFT pipeline -> Evaluation on 13 test sets -> Case studies on additional tasks
- Critical path: Data curation -> Task schema harmonization -> Instruction template creation -> Two-stage SFT -> Evaluation and analysis
- Design tradeoffs: Model size vs. training efficiency (Qwen-7B chosen over larger models), single-stage vs. two-stage training (two-stage chosen for better convergence), general vs. domain-specific instructions (domain-specific chosen for accuracy)
- Failure signatures: Poor performance on tasks not seen in fine-tuning (e.g., certain entity types), inability to generalize across languages, hallucinations in biomedical responses
- First 3 experiments:
  1. Compare one-stage vs. two-stage SFT on a subset of tasks to verify performance improvement
  2. Test zero-shot generalization on unseen entity types using BioRED dataset
  3. Qualitative comparison of outputs between domain-specific and general-domain instruction tuning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the two-stage fine-tuning strategy be further optimized to improve performance on generation tasks that are not generation tasks in nature?
- Basis in paper: [explicit] The paper mentions that the two-stage strategy significantly improves performance on tasks that are not generation tasks in nature, but the model still underperforms specialized models on tasks like information extraction.
- Why unresolved: The paper does not explore alternative fine-tuning strategies or hyperparameters to further enhance performance on these challenging tasks.
- What evidence would resolve it: Experiments comparing different fine-tuning strategies, such as multi-task learning or curriculum learning, on tasks that are not generation tasks in nature, along with an analysis of their impact on model performance.

### Open Question 2
- Question: How can the model's interpretability be improved for biomedical applications, particularly in explaining its reasoning and decision-making process?
- Basis in paper: [inferred] The paper mentions the need to improve the interpretability of the model's output, but does not provide specific methods or techniques to achieve this.
- Why unresolved: The paper does not discuss techniques like attention visualization, feature importance analysis, or model-agnostic interpretability methods that could enhance the model's explainability.
- What evidence would resolve it: Experiments demonstrating the effectiveness of interpretability techniques on Taiyi's outputs, along with user studies evaluating the clarity and usefulness of the explanations provided.

### Open Question 3
- Question: How can the model's safety and security be ensured in biomedical applications, particularly in handling sensitive patient data and preventing potential misuse?
- Basis in paper: [explicit] The paper mentions the need to study how to align human intentions using reinforcement learning methods to ensure safety in the medical field, but does not provide specific approaches or solutions.
- Why unresolved: The paper does not discuss techniques like adversarial training, privacy-preserving methods, or ethical guidelines for the responsible deployment of the model in biomedical settings.
- What evidence would resolve it: Experiments evaluating the model's robustness to adversarial attacks, privacy-preserving techniques to protect sensitive patient data, and case studies demonstrating the model's adherence to ethical guidelines in real-world biomedical applications.

## Limitations

- Limited evaluation scope with only a small subset of Chinese test cases, restricting validation of bilingual capabilities
- Qualitative comparisons with general-domain models lack systematic quantitative metrics for fine-grained analysis
- Claims about task interference mechanisms are not fully explored through ablation studies or alternative fine-tuning strategies

## Confidence

- **High confidence**: Claims about overall performance improvements over general LLMs on the 13 evaluated test sets (average F1 64.8%, accuracy 64.8%)
- **Medium confidence**: Claims about two-stage fine-tuning strategy superiority over one-stage approaches (~10% improvement), as the evidence is based on internal comparisons without ablation studies
- **Medium confidence**: Claims about zero-shot generalization to unseen entity types (species, cell lines), supported by limited experimental evidence

## Next Checks

1. Conduct a systematic ablation study comparing one-stage vs. two-stage fine-tuning across all 15 task types to quantify the contribution of each stage to overall performance improvements.

2. Test Taiyi on additional unseen biomedical entity types beyond species and cell lines to assess the true extent of zero-shot transfer capabilities.

3. Expand Chinese evaluation beyond the current limited test sets to provide robust validation of bilingual performance claims, including direct comparisons with Chinese-specific biomedical LLMs.