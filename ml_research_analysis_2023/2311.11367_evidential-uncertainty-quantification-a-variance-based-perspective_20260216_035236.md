---
ver: rpa2
title: 'Evidential Uncertainty Quantification: A Variance-Based Perspective'
arxiv_id: '2311.11367'
source_url: https://arxiv.org/abs/2311.11367
tags:
- uncertainty
- learning
- domain
- active
- evidential
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper adapts variance-based uncertainty quantification from
  regression to classification within the evidential deep learning framework. The
  method extends variance decomposition to covariance decomposition, allowing uncertainties
  to be quantified at both the sample level and class level, while also enabling the
  calculation of between-class correlations.
---

# Evidential Uncertainty Quantification: A Variance-Based Perspective

## Quick Facts
- arXiv ID: 2311.11367
- Source URL: https://arxiv.org/abs/2311.11367
- Reference count: 40
- Key outcome: Variance-based approach achieves similar or slightly better accuracy than entropy-based methods in active domain adaptation, with added benefits of class-level uncertainty quantification and between-class correlation analysis

## Executive Summary
This paper introduces a variance-based uncertainty quantification framework for classification within evidential deep learning. The method extends traditional variance decomposition from regression to classification by employing covariance decomposition, enabling uncertainty quantification at both sample and class levels. The approach is particularly effective in active domain adaptation scenarios, where it demonstrates similar or slightly improved performance compared to entropy-based methods while providing additional insights through class-wise uncertainty and correlation analysis. The framework also introduces certainty sampling as a complement to uncertainty sampling in active learning, showing improved performance especially under large domain shifts.

## Method Summary
The method adapts variance-based uncertainty quantification from regression to classification by extending variance decomposition to covariance decomposition using the law of total covariance. The approach treats classification targets as Dirichlet-distributed random vectors, decomposing the total covariance matrix into aleatoric and epistemic components. Class-wise uncertainties are extracted from diagonal elements of covariance matrices, while off-diagonal elements enable correlation analysis between classes. The framework is integrated with evidential neural networks using exponential output activation and is evaluated in active domain adaptation tasks combining active learning and domain adaptation.

## Key Results
- Variance-based approach achieves 79.5% AUROC on VisDA-2017 compared to 78.9% for entropy-based methods
- Class-wise uncertainty quantification successfully identifies difficult class pairs through correlation analysis
- Certainty sampling improves active learning performance, particularly under large domain shifts
- The method demonstrates improved stability across domain transitions compared to entropy-based approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Variance decomposition in classification can be extended from regression by replacing variance with covariance
- Mechanism: Total covariance matrix of classification targets is decomposed into aleatoric and epistemic components using the law of total covariance
- Core assumption: Classification targets can be treated as multidimensional random vectors following Dirichlet distribution
- Evidence anchors:
  - [abstract] "The variance decomposition technique in regression is extended to class covariance decomposition in classification based on the law of total covariance"
  - [section] "We define the aleatoric and epistemic components of the covariance matrix Cov[y] as aleatoric covariance matrix Cov[y]alea and epistemic covariance matrix Cov[y]epis"
  - [corpus] Weak - no direct corpus evidence supporting this specific covariance extension mechanism
- Break condition: If classification targets cannot be adequately modeled as Dirichlet-distributed random vectors, the covariance decomposition approach would fail

### Mechanism 2
- Claim: Class-wise uncertainties and between-class correlations can be directly derived from covariance matrices
- Mechanism: Diagonal elements provide class-wise uncertainties while off-diagonal elements enable correlation analysis
- Core assumption: Covariance structure of Dirichlet-distributed class probabilities contains meaningful information about uncertainty and inter-class relationships
- Evidence anchors:
  - [abstract] "Experiments on cross-domain datasets are conducted to illustrate that the variance-based approach not only results in similar accuracy as the entropy-based one in active domain adaptation but also brings information about class-wise uncertainties as well as between-class correlations"
  - [section] "The class correlation matrix can be directly obtained from the covariance matrix by definition"
  - [corpus] Weak - limited corpus evidence on using covariance for class correlation analysis in classification
- Break condition: If covariance structure does not capture meaningful uncertainty or correlation information, class-level analysis would be uninformative

### Mechanism 3
- Claim: Certainty sampling improves active learning performance by exploiting confidently correct predictions
- Mechanism: Samples with low epistemic uncertainty are assumed to have correct predictions and are added to labeled pool with pseudo-labels
- Core assumption: Low epistemic uncertainty is a strong indicator of prediction correctness
- Evidence anchors:
  - [abstract] "Additionally, the paper introduces certainty sampling as a complement to uncertainty sampling in active learning, improving overall performance, particularly under large domain shifts"
  - [section] "We propose simultaneous certainty and uncertainty sampling in active learning to exploit the value of confident samples"
  - [corpus] Weak - limited corpus evidence on certainty sampling in active learning
- Break condition: If low epistemic uncertainty does not correlate with prediction correctness, certainty sampling would introduce many incorrect pseudo-labels

## Foundational Learning

- Concept: Dirichlet Distribution
  - Why needed here: Forms theoretical foundation for evidential classification, enabling uncertainty quantification through distribution parameters
  - Quick check question: How does the Dirichlet distribution model the class probability vector in evidential deep learning?

- Concept: Law of Total Covariance
  - Why needed here: Provides mathematical framework for decomposing total uncertainty into aleatoric and epistemic components at class level
  - Quick check question: What is the relationship between total covariance, aleatoric covariance, and epistemic covariance in classification?

- Concept: Evidential Deep Learning Framework
  - Why needed here: Enables direct estimation of both aleatoric and epistemic uncertainties from single forward pass
  - Quick check question: How does evidential deep learning differ from traditional softmax-based classification in terms of uncertainty quantification?

## Architecture Onboarding

- Component map: Evidential Neural Network (ENN) with exponential output activation → Dirichlet parameter prediction → Uncertainty decomposition (covariance-based) → Active learning selection (certainty + uncertainty sampling)
- Critical path: Model training → Covariance calculation → Class-wise uncertainty extraction → Correlation analysis → Active sampling strategy
- Design tradeoffs: Covariance-based approach provides class-level insights but requires more complex matrix operations compared to entropy-based methods
- Failure signatures: High variance in class-wise uncertainties without clear correlation patterns; poor performance improvement with certainty sampling
- First 3 experiments:
  1. Compare variance-based vs entropy-based uncertainty quantification on simple classification dataset
  2. Test class-wise uncertainty extraction on multi-class problem with known difficult class pairs
  3. Implement certainty sampling and measure its impact on active learning performance with different domain shift levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the variance-based approach perform in regression problems compared to entropy-based approaches, especially when output variable is multidimensional?
- Basis in paper: [explicit] Paper discusses extension of variance-based uncertainty quantification from regression to classification but provides no experimental results for regression problems
- Why unresolved: Paper focuses on classification problems without providing experimental results for regression problems
- What evidence would resolve it: Experimental results comparing variance-based approach to entropy-based approaches in regression problems with multidimensional output variables

### Open Question 2
- Question: How does the variance-based approach handle class imbalance in dataset?
- Basis in paper: [inferred] Paper introduces class-balanced certainty sampling but does not explicitly discuss how variance-based approach handles class imbalance
- Why unresolved: No explicit discussion or experimental results on how variance-based approach handles class imbalance
- What evidence would resolve it: Experimental results comparing variance-based approach to entropy-based approaches in datasets with imbalanced class distributions

### Open Question 3
- Question: How does the variance-based approach perform in active learning tasks with noisy labels?
- Basis in paper: [inferred] Paper proposes certainty sampling but does not explicitly discuss performance with noisy labels
- Why unresolved: No explicit discussion or experimental results on performance with noisy labels
- What evidence would resolve it: Experimental results comparing variance-based approach to entropy-based approaches in active learning tasks with noisy labels

## Limitations
- Covariance decomposition requires careful numerical implementation as covariance matrices can be ill-conditioned with limited data
- Assumption that Dirichlet distributions adequately capture class probability structures may not hold for highly imbalanced or multi-modal class distributions
- Certainty sampling assumes low epistemic uncertainty correlates strongly with prediction correctness, which may not always be valid

## Confidence

- High Confidence: Mathematical framework for extending variance decomposition to classification through covariance decomposition is well-established and theoretically sound
- Medium Confidence: Empirical results showing similar or slightly better accuracy compared to entropy-based methods are convincing though performance gains are modest
- Medium Confidence: Class-level uncertainty quantification and correlation analysis are methodologically valid but practical utility requires further validation across diverse domains

## Next Checks

1. **Robustness Testing**: Evaluate approach on datasets with known class correlations (e.g., fine-grained datasets like CUB-200) to verify covariance-based method correctly identifies related classes

2. **Failure Mode Analysis**: Systematically test scenarios where low epistemic uncertainty does not imply correct predictions (e.g., biased datasets or adversarial examples) to validate certainty sampling assumption

3. **Computational Efficiency**: Compare computational overhead of covariance matrix operations versus entropy calculations, particularly for large-scale multi-class problems