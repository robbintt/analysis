---
ver: rpa2
title: 'Complementary Advantages of ChatGPTs and Human Readers in Reasoning: Evidence
  from English Text Reading Comprehension'
arxiv_id: '2311.10344'
source_url: https://arxiv.org/abs/2311.10344
tags:
- chatgpt
- inferences
- students
- plus
- reading
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study compared ChatGPT (both original and Plus versions)
  with Chinese high school students in three types of reading inferences: commonsense,
  emotional, and causal. The students showed superiority in local-culture-related
  commonsense inferences and causal inferences, while ChatGPT Plus excelled in daily-life
  commonsense inferences and emotional inferences.'
---

# Complementary Advantages of ChatGPTs and Human Readers in Reasoning: Evidence from English Text Reading Comprehension

## Quick Facts
- arXiv ID: 2311.10344
- Source URL: https://arxiv.org/abs/2311.10344
- Reference count: 14
- Key outcome: ChatGPT Plus excels in daily-life commonsense and emotional inferences while human students outperform in local-culture commonsense and causal inference

## Executive Summary
This study compares ChatGPT (both original and Plus versions) with Chinese high school students in three types of reading inferences: commonsense, emotional, and causal. The research reveals complementary strengths between human readers and AI models, with humans demonstrating superiority in context-specific and logical inferences while ChatGPTs perform better in general knowledge and frequency of correct responses. Notably, ChatGPT Plus showed the ability to improve its causal inference performance with updated commands, while the original ChatGPT did not.

## Method Summary
The study involved 114 Chinese senior-2 ESL students and two ChatGPT models (GPT-3.5 and GPT-4/Plus). Students completed three tests under controlled conditions: a 28-question commonsense inference test (13 local culture, 15 daily life), a 24-story emotional inference test adapted from Gernsbacher et al. (1992), and a causal inference test using "The Death Car" story with 5 questions. ChatGPT models were prompted to generate answers matching the number of student responses, with updated commands applied to ChatGPT Plus for the causal inference task.

## Key Results
- Students showed superiority in local-culture-related commonsense inferences and causal inferences
- ChatGPT Plus excelled in daily-life commonsense inferences and emotional inferences
- ChatGPT Plus improved its causal inference performance with updated commands, while original ChatGPT did not

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPTs excel at daily-life commonsense inference but falter on local-culture-specific knowledge
- Mechanism: ChatGPTs rely on pre-trained text datasets that include common, global knowledge but lack depth in regional or culture-specific content
- Core assumption: ChatGPT's training data prioritizes general knowledge over niche cultural specifics
- Evidence anchors:
  - [abstract]: "ChatGPT Plus excelled in daily-life commonsense inferences and emotional inferences"
  - [section]: "ChatGPT was weak at making inferences requiring specific world knowledge"
  - [corpus]: "Found 25 related papers... Top related titles: ChatGPT is Good but Bing Chat is Better for Vietnamese Students"

### Mechanism 2
- Claim: Human readers outperform ChatGPTs in causal inference by integrating text-wide logical relationships
- Mechanism: Human readers build coherent mental models by linking events, characters, and outcomes across the full narrative
- Core assumption: Human comprehension uses holistic narrative reasoning while ChatGPTs use token-by-token inference
- Evidence anchors:
  - [abstract]: "students demonstrated better logical analysis, outdoing both chatbots"
  - [section]: "students centered their focus on the couple and murderer by connecting events from the whole text"

### Mechanism 3
- Claim: ChatGPT Plus improves causal inference under refined commands, whereas ChatGPT does not
- Mechanism: GPT-4 has larger training datasets and better instruction-following capabilities
- Core assumption: GPT-4's architecture allows for better iterative reasoning under explicit multi-step instructions
- Evidence anchors:
  - [abstract]: "ChatGPT Plus displayed good causal reasoning ability while ChatGPT kept unchanged"
  - [section]: "ChatGPT Plus corrected its logical mistakes... while ChatGPT still focused on literal responses"

## Foundational Learning

- Concept: Inference types (referential, causal antecedent, causal consequence, etc.)
  - Why needed here: The study categorizes and compares three inference types to map model capabilities
  - Quick check question: What distinguishes causal antecedent from causal consequence inferences?

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: CoT enables LLMs to break reasoning into steps, improving accuracy on complex tasks
  - Quick check question: How does CoT differ from standard prompting in LLM reasoning?

- Concept: Sentiment and emotion detection
  - Why needed here: Emotional inference is evaluated using structured stories
  - Quick check question: What distinguishes sentiment analysis from emotion detection in NLP?

## Architecture Onboarding

- Component map: Narrative texts -> Pre-processing (translation, simplification) -> Model input -> ChatGPT (GPT-3.5) and ChatGPT Plus (GPT-4) -> Evaluation metrics
- Critical path: 1. Load and preprocess narrative texts 2. Generate inferences using baseline commands 3. Evaluate accuracy 4. Apply updated commands (for ChatGPT Plus only) 5. Re-evaluate and compare
- Design tradeoffs:
  - Simplicity vs. accuracy: Simple prompts may suffice for daily-life inference but not causal inference
  - Data scope vs. cultural specificity: Broad training data covers daily life but misses local cultures
  - Model size vs. efficiency: GPT-4 is more capable but computationally heavier
- Failure signatures:
  - Fabricated facts: ChatGPT invents details when lacking knowledge
  - Overgeneralization: Both models apply broad patterns to specific cultural contexts
  - Lack of logical integration: ChatGPT fails to connect narrative elements globally
- First 3 experiments:
  1. Run baseline commonsense inference with ChatGPT and ChatGPT Plus on daily-life vs. local-culture questions
  2. Test causal inference without updated commands; record logical error patterns
  3. Apply multi-step updated commands to ChatGPT Plus; compare causal inference accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do specific linguistic features of narrative texts influence performance differences between human readers and ChatGPT models?
- Basis in paper: [inferred] The study compares human and AI performance across three inference types but does not analyze how specific linguistic features might differentially impact these performances
- Why unresolved: The study uses pre-existing materials without systematically manipulating linguistic features
- What evidence would resolve it: Controlled experiments varying specific linguistic features while measuring inference accuracy for both human readers and different AI models

### Open Question 2
- Question: What are the long-term effects of AI assistance on human reading comprehension and inference skills?
- Basis in paper: [explicit] The study concludes that ChatGPT and human readers have complementary strengths, suggesting potential for combined use in educational settings
- Why unresolved: The research is cross-sectional and does not examine how repeated use of AI might affect human skills over time
- What evidence would resolve it: Longitudinal studies tracking human readers' inference abilities over time with varying degrees of AI assistance

### Open Question 3
- Question: How does the cultural background of both the text and the reader influence the performance gap between human readers and AI models?
- Basis in paper: [explicit] The study shows students outperform ChatGPT on local-culture-related commonsense inferences
- Why unresolved: The research only examines one cultural context (Chinese students reading English texts)
- What evidence would resolve it: Comparative studies testing readers from multiple cultural backgrounds on texts from different cultures

## Limitations
- Unknown exact wording of prompts used for ChatGPT models, particularly for Test 3 where commands were "updated elaborately"
- Local culture commonsense inference questions about Fuzhou customs may not be reproducible without cultural knowledge
- Results based on Chinese senior-2 ESL students, limiting generalizability to other populations

## Confidence

- **High confidence**: ChatGPT Plus outperforms ChatGPT in daily-life commonsense and emotional inferences
- **Medium confidence**: Human students excel in local-culture commonsense and causal inference
- **Low confidence**: The specific mechanism by which ChatGPT Plus improves with updated commands

## Next Checks

1. Test the same causal inference task with ChatGPT Plus using both baseline and explicitly structured chain-of-thought prompts to verify if improved reasoning stems from command complexity

2. Replace Fuzhou-specific questions with culturally equivalent questions from other regions to test whether human advantage in local culture inference is due to knowledge gaps or fundamental reasoning differences

3. Systematically vary command complexity for both ChatGPT and ChatGPT Plus on causal inference tasks, measuring accuracy changes to determine if GPT-4's improvement is due to instruction-following capability or underlying architectural advantages