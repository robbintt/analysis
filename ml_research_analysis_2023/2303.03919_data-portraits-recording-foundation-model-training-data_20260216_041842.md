---
ver: rpa2
title: 'Data Portraits: Recording Foundation Model Training Data'
arxiv_id: '2303.03919'
source_url: https://arxiv.org/abs/2303.03919
tags:
- data
- dataset
- datasets
- string
- corpus
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes "Data Portraits" as a documentation artifact
  for large language model training data, enabling efficient membership inference
  - answering whether a given example was seen during training. The authors implement
  a solution using strided Bloom filters that allows fast and space-efficient querying
  (only 3% dataset size overhead) while avoiding redistribution of sensitive data.
---

# Data Portraits: Recording Foundation Model Training Data

## Quick Facts
- arXiv ID: 2303.03919
- Source URL: https://arxiv.org/abs/2303.03919
- Authors: 
- Reference count: 14
- Key outcome: Data Portraits enable efficient membership inference for LLM training data using strided Bloom filters, with 3% dataset size overhead and millisecond query latency

## Executive Summary
This paper introduces "Data Portraits" as a documentation artifact for large language model training data, enabling efficient membership inference to determine if specific examples were seen during training. The authors implement a practical solution using strided Bloom filters that allows fast and space-efficient querying while avoiding redistribution of sensitive training data. They apply their tool to document The Pile corpus and demonstrate use cases including detecting test set leakage (finding leaked WMT 2020 English-Inuktitut test data), code plagiarism detection, and quantifying dataset overlap with various test sets.

## Method Summary
The authors implement a strided Bloom filter data sketching approach that hashes and stores only non-overlapping n-grams from training data, reducing storage requirements while maintaining membership inference capabilities. The system processes corpus text, generates strided n-grams, and populates a Bloom filter data structure stored in Redis. Query strings are broken into n-grams, checked against the Bloom filter, and consecutive matches are chained to infer longer overlapping sequences. The approach trades some accuracy for significant space efficiency, using only ~3% of the original dataset size while providing millisecond query latency.

## Key Results
- Data Portraits achieve 3% storage overhead compared to original dataset size
- System demonstrates millisecond query latency for membership testing
- Successfully identified leaked WMT 2020 English-Inuktitut test data in training corpus
- Enables code plagiarism detection and dataset overlap quantification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Strided Bloom filters enable fast membership testing while reducing storage overhead
- Mechanism: By storing only strided n-grams instead of all possible n-grams, the filter size is reduced by a factor equal to the stride length
- Core assumption: Query strings of sufficient length (at least 2n-1) will contain at least one strided n-gram
- Evidence anchors:
  - [abstract] "Our artifact uses data sketching (compressed or approximate views of data, Broder, 1997) to enable millisecond latency and minimal compute requirements, using only ~3% of the original dataset size."
  - [section] "Rather than storing all n-grams we store only tiled or strided n-grams. When building our Bloom filter data sketch, we hash n-grams with stride n (i.e. non overlapping, see Figure 2 row 2)."

### Mechanism 2
- Claim: Chaining consecutive matching n-grams enables approximate longest overlapping subsequence detection
- Mechanism: When multiple consecutive strided n-grams match (occurring n indices apart), they can be joined to form an inferred longer sequence
- Core assumption: Consecutive matching n-grams in the Bloom filter indicate they occurred in that order in the original text
- Evidence anchors:
  - [section] "We can further chain a set of matching query n-grams into longer sequences. If matches occur n indices apart, they can be joined as a single inferred string (final row, Figure 2)."
  - [section] "Recording the max length of a found chain gives us a measure of approximate longest overlapping subsequence."

### Mechanism 3
- Claim: Hash-based matching in Bloom filters avoids redistribution of sensitive data while maintaining privacy
- Mechanism: Bloom filters store only hash values of data elements rather than the data itself
- Core assumption: The one-way nature of cryptographic hashing makes it computationally infeasible to reverse-engineer original content
- Evidence anchors:
  - [section] "Since Bloom filters distribute only hashes, they provide some obfuscation. Bianchi et al. (2012) term this 'Better Than Nothing' privacy and discuss information hiding bounds on Bloom filters with various parameters."
  - [section] "Storing strided n-grams provides additional information hiding without changing the size of the universe."

## Foundational Learning

- Concept: Bloom filter false positive rate and its relationship to storage size
  - Why needed here: Understanding how to tune the Bloom filter parameters (number of hash functions, bit array size) is crucial for balancing storage efficiency against query accuracy
  - Quick check question: If you double the size of the Bloom filter bit array while keeping the number of elements constant, what happens to the false positive rate?

- Concept: String matching and n-gram tokenization
  - Why needed here: The system relies on breaking text into n-grams for both indexing and querying, requiring understanding of how different n-gram sizes affect matching accuracy and storage requirements
  - Quick check question: For a query string of length N and n-gram size n, how many n-grams will be generated?

- Concept: Probabilistic data structures and their error bounds
  - Why needed here: The system makes probabilistic guarantees about membership testing, requiring understanding of how to interpret and communicate uncertainty in results
  - Quick check question: If a Bloom filter has a false positive rate of 0.1% and you perform 1000 queries, how many false positives would you expect on average?

## Architecture Onboarding

- Component map: Data ingestion pipeline -> Bloom filter construction -> Redis backend -> Query interface -> Frontend web interface

- Critical path: 
  1. User submits query text
  2. System generates n-grams with stride 1 from query
  3. Each n-gram is hashed and checked against Bloom filter
  4. Matching n-grams are chained if occurring at expected intervals
  5. Results are returned to user with longest chain highlighted

- Design tradeoffs:
  - Storage vs. accuracy: Smaller Bloom filters save space but increase false positive rate
  - N-gram size vs. boundary sensitivity: Larger n-grams reduce false positives but increase risk of missing matches due to boundary alignment
  - Stride length vs. compression: Longer strides reduce storage but increase risk of missing matches

- Failure signatures:
  - High false positive rate: Observed when Bloom filter is too small for the dataset size
  - Missing expected matches: Occurs when query strings are too short or boundary alignment prevents detection
  - Slow query performance: Indicates Bloom filter implementation or Redis backend issues

- First 3 experiments:
  1. Measure false positive rate by querying random strings not in the corpus and comparing to theoretical expectations
  2. Test boundary alignment sensitivity by querying strings of different lengths and observing detection rates
  3. Benchmark query latency with varying Bloom filter sizes to establish the storage-performance tradeoff curve

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the false positive rate of strided Bloom filters scale with increasing n-gram length and different dataset characteristics?
- Basis in paper: [explicit] The paper mentions a false positive rate of 1Ã—10^-3 for their Pile implementation and discusses the probabilistic nature of Bloom filters
- Why unresolved: The paper only provides results for one specific configuration (50-gram width on the Pile) without exploring how false positive rates change with different n-gram lengths or dataset properties
- What evidence would resolve it: Systematic experiments varying n-gram length, dataset types, and measuring resulting false positive rates across multiple configurations

### Open Question 2
- Question: What is the minimum query string length required to ensure reliable membership inference across different datasets and use cases?
- Basis in paper: [explicit] The paper mentions that strings need to be at least 2n-1 characters long to guarantee matches, but doesn't systematically study the minimum reliable length
- Why unresolved: The paper only briefly mentions the theoretical minimum but doesn't provide empirical data on practical minimum lengths for reliable results
- What evidence would resolve it: Empirical studies testing query reliability across different minimum string lengths and datasets

### Open Question 3
- Question: How vulnerable are strided Bloom filter implementations to adversarial attacks that could create false positives?
- Basis in paper: [explicit] The paper discusses permutation attacks in Appendix C but doesn't quantify their practical feasibility
- Why unresolved: The paper acknowledges the theoretical possibility of attacks but doesn't provide concrete analysis of attack success rates or mitigation strategies
- What evidence would resolve it: Empirical testing of attack success rates under various configurations and development of defense mechanisms

## Limitations
- Missing implementation parameters for Bloom filter configuration (width, stride, false positive rate targets) makes exact reproduction challenging
- Limited discussion of how performance scales to significantly larger datasets or more frequent query loads
- "Better Than Nothing" privacy characterization provides only weak privacy guarantees with unclear information reconstruction risks

## Confidence
- High Confidence: The core mechanism of using strided Bloom filters for approximate membership testing is technically sound and well-established
- Medium Confidence: The chaining mechanism for inferring longer sequences from consecutive matches is plausible but depends heavily on the false positive rate of the underlying Bloom filter
- Low Confidence: The practical utility for detecting test set leakage and code plagiarism relies on assumptions about overlapping n-grams that haven't been rigorously validated

## Next Checks
1. Systematically measure the actual false positive rate across different Bloom filter configurations on the same dataset used in the paper, comparing empirical results against theoretical expectations
2. Create controlled experiments testing detection rates for strings of varying lengths and content patterns to quantify boundary alignment sensitivity
3. Apply the tool to multiple pairs of datasets with known overlap characteristics to validate the accuracy of the longest overlapping subsequence metric as a measure of dataset similarity