---
ver: rpa2
title: Knowledge-Augmented Large Language Models for Personalized Contextual Query
  Suggestion
arxiv_id: '2311.06318'
source_url: https://arxiv.org/abs/2311.06318
tags:
- query
- search
- suggestion
- knowledge
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces K-LaMP, a novel framework that augments Large
  Language Models (LLMs) with personalized context from users' search histories to
  improve contextual query suggestion. The core idea is to construct an entity-centric
  knowledge store for each user based on their search and browsing activities, which
  is then leveraged to provide contextually relevant LLM prompt augmentations.
---

# Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion

## Quick Facts
- arXiv ID: 2311.06318
- Source URL: https://arxiv.org/abs/2311.06318
- Reference count: 40
- Key outcome: K-LaMP significantly outperforms LLM baselines in generating contextually relevant, personalized, and useful query suggestions using entity-centric knowledge stores

## Executive Summary
This paper introduces K-LaMP, a novel framework that augments Large Language Models (LLMs) with personalized context from users' search histories to improve contextual query suggestion. The core idea is to construct an entity-centric knowledge store for each user based on their search and browsing activities, which is then leveraged to provide contextually relevant LLM prompt augmentations. This approach is lightweight and scalable, mitigating privacy and compliance concerns associated with deep user profiling. Experiments on real-world search logs show that K-LaMP significantly outperforms several LLM-powered baselines in generating query suggestions that are more contextually relevant, personalized, and useful.

## Method Summary
K-LaMP builds an entity-centric personal knowledge store from users' search and browsing histories, extracting entities via the NEMO entity linker and aggregating them with frequency and recency information. When a user views a web page, relevant entities are extracted from the page and matched to the user's knowledge store using three strategies: familiar (high-frequency entities), unfamiliar (low-frequency entities), and lapsed (time-decayed entities). These matched entities are then used to augment GPT-4 prompts for generating contextual query suggestions. The method requires no training, relying instead on prompt engineering and context augmentation.

## Key Results
- K-LaMP significantly outperforms LLM baselines on human evaluation metrics for contextual query suggestion
- Entity-centric knowledge stores (K_e) improve personalization compared to linear search history approaches (K_s)
- Familiar entity retrieval strategy produces more personalized suggestions than unfamiliar entity strategy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Entity-centric knowledge stores improve personalization over linear query histories
- Mechanism: By representing user knowledge as aggregated entities with frequency counts and timestamps, the system can match current context entities to personalized knowledge using exact matching rather than similarity-based retrieval
- Core assumption: Entities are atomic units that capture user interests and knowledge more effectively than raw text sequences
- Evidence anchors:
  - [abstract]: "This knowledge store is light-weight, since it only produces user-specific aggregate projections of interests and knowledge onto public knowledge graphs"
  - [section]: "entities are atomic units with associated counts and time-stamps, the matching and retrieval process can be operationalized in flexible ways"
  - [corpus]: Weak - the related papers focus on query suggestion but don't directly compare entity-centric vs linear approaches
- Break condition: If entity linking quality degrades significantly or if users' interests don't align well with entity representations

### Mechanism 2
- Claim: Familiar entity retrieval leads to more relevant suggestions than unfamiliar entities
- Mechanism: Sampling familiar entities based on frequency provides contextually grounded recommendations that align with established user interests
- Core assumption: Users prefer suggestions related to topics they've frequently engaged with
- Evidence anchors:
  - [abstract]: "We particularly explore three strategies for matching entities: familiar (entities the user has frequently encountered)"
  - [section]: "For familiar entities, we sort the entities appearing in the search context by frequency of occurrence in the knowledge store"
  - [corpus]: Weak - related work doesn't specifically analyze familiar vs unfamiliar entity retrieval strategies
- Break condition: When users are in exploration mode and prefer novel suggestions over familiar topics

### Mechanism 3
- Claim: Knowledge augmentation improves usefulness scores without sacrificing validity
- Mechanism: Adding contextually relevant entity knowledge to LLM prompts enables more personalized suggestions while maintaining search result quality
- Core assumption: LLMs can effectively incorporate entity context to generate personalized yet valid queries
- Evidence anchors:
  - [abstract]: "show that our approach is significantly better than several other LLM-powered baselines, generating query suggestions that are contextually more relevant, personalized, and useful"
  - [section]: "Our method revolves around an entity-centric light-weight personalization layer that enables knowledge-augmentation of LLMs"
  - [corpus]: Weak - related papers don't measure the trade-off between personalization and validity
- Break condition: When entity context becomes too specific or when LLM fails to maintain search result quality

## Foundational Learning

- Concept: Entity linking and canonicalization
  - Why needed here: To convert raw text from queries and web pages into structured knowledge atoms that can be aggregated and matched
  - Quick check question: What happens if the entity linker maps two different concepts to the same canonical entity?

- Concept: Contriever embeddings for similarity matching
  - Why needed here: To retrieve relevant historical documents and web pages based on current context when using linear knowledge stores
  - Quick check question: How would retrieval quality change if we used a different dense retriever like DPR?

- Concept: Human evaluation metrics for personalization
  - Why needed here: To assess whether suggestions are not just relevant but also aligned with individual user knowledge and interests
  - Quick check question: How can we ensure annotators have enough context to judge personalization when they're not the original users?

## Architecture Onboarding

- Component map: User interaction logging → Entity extraction → Knowledge store construction → Context retrieval → LLM prompt augmentation → Query generation → Human evaluation
- Critical path: Entity extraction → Knowledge store → Context retrieval → LLM prompt → Query suggestion
- Design tradeoffs: Entity granularity vs. storage efficiency; frequency-based vs. recency-based matching; familiar vs. unfamiliar entity strategies
- Failure signatures: Poor entity linking quality → irrelevant suggestions; empty knowledge store → generic suggestions; context-entity mismatch → low relatedness scores
- First 3 experiments:
  1. Compare familiar vs. unfamiliar entity retrieval strategies on a small user sample
  2. Test entity matching with varying numbers of context entities (1-10)
  3. Measure impact of different entity frequency thresholds on suggestion quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does K-LaMP perform in different user interaction scenarios (e.g., research, exploration, or revision) where user goals vary significantly?
- Basis in paper: [inferred] The paper mentions that users may approach web search with different goals, and judges had difficulty assessing these goals from limited data.
- Why unresolved: The human evaluation did not capture the varying user goals in different search scenarios, limiting the understanding of K-LaMP's performance across diverse user intents.
- What evidence would resolve it: Comparative analysis of K-LaMP's performance in different user interaction scenarios, such as research, exploration, and revision, to determine its adaptability to varying user goals.

### Open Question 2
- Question: What are the limitations of the entity-centric knowledge store K_e in capturing user interests and knowledge, especially in domains where entity linking is less effective?
- Basis in paper: [explicit] The paper acknowledges that the entity linker used in K_e maps onto Wikipedia, which may not cover all domains effectively.
- Why unresolved: The paper does not explore the performance of K-LaMP in domains where entity linking is less effective, leaving the limitations of the entity-centric knowledge store in such scenarios unclear.
- What evidence would resolve it: Evaluation of K-LaMP's performance in domains where entity linking is less effective, such as product graphs for shopping, to identify its limitations in capturing user interests and knowledge.

### Open Question 3
- Question: How can the automatic evaluation metrics for contextual query suggestion be improved to better align with human judgment, particularly for the Usefulness metric?
- Basis in paper: [explicit] The paper mentions that the automatic Usefulness metric does not correlate with human judgment, as contextual query recommendation is not expected to align perfectly with user behavior.
- Why unresolved: The current automatic evaluation metrics do not fully capture the nuances of human judgment, especially for the Usefulness metric, which is crucial for assessing the effectiveness of query suggestions.
- What evidence would resolve it: Development of improved automatic evaluation metrics that better align with human judgment, particularly for the Usefulness metric, to provide a more accurate assessment of query suggestions.

## Limitations

- The method relies heavily on high-quality entity linking, and performance could degrade significantly if entity linking quality drops below 75% accuracy
- The familiar entity retrieval strategy may create filter bubbles by overemphasizing past interests and limiting exposure to novel topics
- Human evaluation requires annotators to make subjective judgments about personalization without being the actual users, potentially introducing bias

## Confidence

**High confidence**: The core mechanism of entity-centric knowledge stores improving over linear search histories is well-supported by experimental results showing K_e outperforming K_s.

**Medium confidence**: The claim that knowledge augmentation improves usefulness without sacrificing validity has strong supporting evidence, but the tradeoff between these metrics in edge cases warrants further investigation.

**Low confidence**: The optimal frequency thresholds for familiar entity retrieval and the ideal number of context entities for matching are determined empirically but lack theoretical grounding.

## Next Checks

1. **Entity linking robustness test**: Systematically degrade entity linking quality (e.g., 90%, 80%, 70% accuracy) and measure the impact on suggestion quality to establish the minimum viable accuracy threshold.

2. **Familiar vs. unfamiliar tradeoff analysis**: Conduct a controlled study comparing suggestion diversity and exploration metrics when varying the ratio of familiar to unfamiliar entities in the knowledge store.

3. **Knowledge graph generalization**: Replicate the entity-centric approach using alternative knowledge graphs (e.g., Wikidata, domain-specific ontologies) to test the method's adaptability beyond Wikipedia-based entity linking.