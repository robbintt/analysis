---
ver: rpa2
title: Are "Hierarchical" Visual Representations Hierarchical?
arxiv_id: '2311.05784'
source_url: https://arxiv.org/abs/2311.05784
tags:
- datasets
- superclass
- hierarchical
- representations
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether "hierarchical" visual representations
  (specifically hyperbolic and Matryoshka embeddings) better capture human-perceived
  hierarchy compared to standard learned representations. The authors create HierNet,
  a benchmark of 12 datasets from ImageNet BREEDs spanning three types of hierarchy.
---

# Are "Hierarchical" Visual Representations Hierarchical?

## Quick Facts
- arXiv ID: 2311.05784
- Source URL: https://arxiv.org/abs/2311.05784
- Reference count: 40
- Primary result: Hierarchical embeddings (hyperbolic, Matryoshka) show no improvement over standard embeddings in capturing human-perceived hierarchy, but offer search efficiency and interpretability benefits.

## Executive Summary
This paper investigates whether hierarchical visual representations, specifically hyperbolic and Matryoshka embeddings, better capture human-perceived hierarchy compared to standard learned representations. The authors create HierNet, a benchmark of 12 datasets from ImageNet BREEDs spanning three types of hierarchy, and evaluate MERU (hyperbolic CLIP variant) against CLIP and MR-ResNet50 against fixed-capacity and PCA-reduced embeddings. Across all datasets, hierarchical embeddings show no improvement in capturing hierarchy as measured by clustering accuracy, adjusted mutual information, purity, and optimal transport distance. However, hierarchical embeddings offer benefits in search efficiency and interpretability. The study concludes that standard Euclidean embeddings are equally capable of capturing hierarchy without explicit hierarchical training.

## Method Summary
The authors create the HierNet benchmark using 12 datasets from ImageNet BREEDs with three hierarchy types. They evaluate MERU (hyperbolic CLIP variant) and MR-ResNet50 (Matryoshka Representations) against standard CLIP and ResNet50 embeddings. Image embeddings are extracted and clustered using agglomerative clustering with Ward linkage. Cluster quality is evaluated using adjusted mutual information, purity, and optimal transport distance (HHOT) to measure alignment with ground truth hierarchy. The comparison reveals whether hierarchical embeddings capture hierarchy better than standard Euclidean embeddings.

## Key Results
- Hierarchical embeddings (MERU, MR-ResNet50) show no improvement over standard embeddings in clustering accuracy, AMI, purity, or HHOT distance
- Hierarchical embeddings offer benefits in search efficiency and interpretability despite clustering parity
- MR embeddings demonstrate potential advantages specifically on fine-grained classification tasks where classes are difficult to separate

## Why This Works (Mechanism)

### Mechanism 1
Standard Euclidean embeddings capture hierarchical relationships as well as explicitly hierarchical embeddings when clustering visual data. The hierarchical structure of visual data is implicitly encoded in standard embeddings through the training process, even without explicit hierarchical loss or geometry constraints.

### Mechanism 2
Hierarchical embeddings offer benefits in search efficiency and interpretability despite not improving hierarchical clustering. Lower-dimensional representations maintain sufficient semantic information for retrieval tasks while reducing computational costs.

### Mechanism 3
Matryoshka representations provide benefits specifically in fine-grained classification tasks where classes are difficult to separate. Adaptive nesting of information allows better separation of similar classes at higher dimensions while maintaining efficiency at lower dimensions.

## Foundational Learning

- Concept: Hierarchical clustering metrics (AMI, purity, HHOT distance)
  - Why needed here: To evaluate whether embeddings capture true hierarchical relationships in visual data
  - Quick check question: What does an AMI score of 0.8 indicate about cluster quality?

- Concept: Hyperbolic geometry and its properties
  - Why needed here: To understand why hyperbolic embeddings were expected to better capture hierarchies
  - Quick check question: How does hyperbolic space handle tree-like structures differently than Euclidean space?

- Concept: Matryoshka representations and adaptive dimension selection
  - Why needed here: To understand the mechanism behind MR embeddings and their potential benefits
  - Quick check question: What advantage does nesting information in MR embeddings provide for downstream tasks?

## Architecture Onboarding

- Component map: HierNet creation -> Embedding generation (CLIP, MERU, MR-ResNet50) -> Agglomerative clustering -> Evaluation metrics (AMI, purity, HHOT) -> Visualization and comparison
- Critical path: 1) Dataset creation from BREEDs hierarchy 2) Embedding generation across all models and dimensions 3) Clustering with appropriate distance metrics 4) Evaluation and comparison 5) Visualization of results
- Design tradeoffs: Agglomerative clustering vs. other clustering methods; Euclidean vs. hyperbolic distance metrics; Fixed vs. adaptive dimensionality in Matryoshka representations
- Failure signatures: Unexpectedly high AMI/purity scores indicating potential overfitting; Large discrepancies between different clustering metrics; Poor performance on datasets expected to be well-suited for hierarchical embeddings
- First 3 experiments: 1) Reproduce clustering accuracy results for CLIP vs. MERU on control datasets 2) Compare MR-ResNet50 performance across all datasets at different dimensions 3) Evaluate impact of different clustering algorithms (k-means, spectral) on same embeddings

## Open Questions the Paper Calls Out

### Open Question 1
Can hierarchical visual representations be improved to better capture human-perceived hierarchy in visual data? The paper concludes hierarchical embeddings do not capture hierarchy better than standard representations and suggests potential for new hierarchical representations with significant performance boosts.

### Open Question 2
What are the fundamental limitations of hyperbolic and Matryoshka representations that prevent them from capturing hierarchy effectively? The paper shows these representations fail to improve hierarchy capture despite theoretical advantages, suggesting underlying limitations in their design or training approaches.

### Open Question 3
How do different types of hierarchical relationships (semantic vs visual, explicit vs implicit) affect the performance of hierarchical representations? The paper created datasets with three types of hierarchies but found no clear patterns in how representation performance varied across these types.

## Limitations

- Evaluation focuses exclusively on clustering metrics, potentially missing other aspects of hierarchical representation quality
- Results limited to visual domain datasets and may not generalize to other hierarchical data types
- Hyperparameters for hierarchical embeddings not fully specified, raising reproducibility concerns
- Only three hierarchy types examined from ImageNet BREEDs, potentially missing other hierarchical patterns

## Confidence

- High Confidence: Standard embeddings perform comparably to hierarchical embeddings on clustering tasks
- Medium Confidence: Hierarchical embeddings offer search efficiency benefits despite clustering parity
- Medium Confidence: MR embeddings show potential advantages specifically on fine-grained classification tasks

## Next Checks

1. Test whether different clustering algorithms (k-means, spectral clustering) yield similar conclusions about hierarchical vs. standard embeddings
2. Evaluate embedding quality on non-visual hierarchical datasets to test domain generalization
3. Investigate the impact of varying embedding dimensionality on the relative performance of hierarchical vs. standard approaches