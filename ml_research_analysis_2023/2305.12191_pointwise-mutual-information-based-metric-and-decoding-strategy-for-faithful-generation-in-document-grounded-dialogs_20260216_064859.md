---
ver: rpa2
title: Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful
  Generation in Document Grounded Dialogs
arxiv_id: '2305.12191'
source_url: https://arxiv.org/abs/2305.12191
tags:
- response
- document
- faithfulness
- faithful
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PMI-FAITH, a novel metric to evaluate the
  faithfulness of responses in document-grounded dialogues. The metric uses conditional
  pointwise mutual information (CPMI) to measure the association between a response
  and the document, conditioned on the dialogue history.
---

# Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs

## Quick Facts
- arXiv ID: 2305.12191
- Source URL: https://arxiv.org/abs/2305.12191
- Authors: 
- Reference count: 17
- Key outcome: Introduces PMI-FAITH metric and PMI-DECODE strategy to improve faithfulness in document-grounded dialogues

## Executive Summary
This paper addresses the challenge of evaluating and generating faithful responses in document-grounded dialogues, where systems must provide accurate information based on given documents. The authors introduce PMI-FAITH, a novel metric that measures faithfulness using conditional pointwise mutual information (CPMI) between responses and documents given dialogue history. They also propose PMI-DECODE, a decoding strategy that combines likelihood and faithfulness to generate more faithful responses. Experiments on three document-grounded dialogue datasets demonstrate that PMI-FAITH correlates better with human judgments than existing metrics, and PMI-DECODE generates more faithful responses than standard greedy decoding while maintaining grammaticality and relevance.

## Method Summary
The method introduces two key components: PMI-FAITH and PMI-DECODE. PMI-FAITH computes conditional pointwise mutual information between a response and document given dialogue history to quantify faithfulness. PMI-DECODE is a decoding strategy that maximizes a weighted combination of response likelihood and PMI-FAITH score during generation. To prevent grammatical errors, PMI-DECODE incorporates top-p masking, restricting the vocabulary to high-likelihood tokens. The approach was evaluated on three document-grounded dialogue datasets using both automated metrics and human evaluation.

## Key Results
- PMI-FAITH shows better correlation with human judgments compared to baseline metrics (Q2, BERTScore) on the BEGIN benchmark
- PMI-DECODE generates more faithful responses than greedy decoding across three document-grounded dialogue datasets
- Top-p masking (p=0.6) effectively prevents grammatical errors while maintaining faithfulness improvements
- The optimal α value of 0.25 balances faithfulness and relevance/grammaticality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PMI-FAITH captures faithfulness by measuring the association between response and document, conditioned on dialogue history.
- Mechanism: The metric computes conditional pointwise mutual information (CPMI) between response r and document d given dialogue history h. CPMI quantifies whether the probability of generating r given both d and h is higher than generating r given only h. A positive CPMI indicates the response is grounded in the document.
- Core assumption: Higher CPMI between response and document (given dialogue history) indicates stronger faithfulness to the document.
- Evidence anchors:
  - [abstract] "PMI quantiﬁes the extent to which the document inﬂuences the generated response – with a higher PMI indicating a more faithful response."
  - [section 4.1] "A positive value of CPMI in eq. (2) implies that the probability of generating the response given the document and the dialogue history is higher than the probability of generating the response given only the dialogue history. Hence, the response is likely to be grounded in the document."
  - [corpus] Weak - corpus neighbors discuss PMI in other contexts but not specifically for faithfulness measurement in dialogues.
- Break condition: If the response contains information that cannot be verified from the document, CPMI would be low or negative, indicating unfaithfulness.

### Mechanism 2
- Claim: PMI-DECODE generates more faithful responses by combining likelihood and faithfulness during decoding.
- Mechanism: The decoding strategy maximizes a weighted combination of response likelihood and PMI-FAITH score. At each decoding step, it selects the next token that maximizes (1-α)logP(token|context) + αCPMI(token; document|context), where CPMI is computed between the candidate token and document given the current context.
- Core assumption: Maximizing a combination of likelihood and faithfulness will produce responses that are both relevant and faithful to the document.
- Evidence anchors:
  - [abstract] "We build upon this idea to create a new decoding technique that incorporates PMI into the response generation process to predict more faithful responses."
  - [section 4.2] "The objective of PMI–D ECODE is to select a response that is highly likely and faithful. This is achieved by maximizing a combination of likelihood and faithfulness quantified using an appropriate metric F."
  - [section 4.2] "Our choice of PMI–F AITH as function F for quantification of faithfulness keeps the decoding heuristic tractable as shown below."
- Break condition: If α is set too high, the decoder may prioritize faithfulness over grammaticality and relevance, producing responses that are faithful but unnatural.

### Mechanism 3
- Claim: Top-p masking during PMI-DECODE prevents grammatical errors by restricting vocabulary to high-likelihood tokens.
- Mechanism: Instead of maximizing over the entire vocabulary V, PMI-DECODE restricts the candidate tokens to the top-p subset (Vp,t) - the minimum cardinality subset of tokens with cumulative probability at least p. This ensures that CPMI is only used to select among tokens that are already highly probable according to the language model.
- Core assumption: Restricting CPMI maximization to high-likelihood tokens prevents the selection of document-specific tokens that may disrupt grammatical structure.
- Evidence anchors:
  - [section 4.2] "We observed that using CPMI in the scoring function sometimes results in selecting tokens from the document which may interfere with the grammar. To mitigate this, instead of maximizing over the entire vocabulary V at each step t, we propose to maximize only over the 'top p' subset from the likelihood distribution, Vp,t."
  - [section 5.2] "Masking helps in focusing only on those tokens which are originally ranked high by the model, thereby circumventing this issue."
  - [corpus] Weak - corpus neighbors discuss PMI in other contexts but not specifically for top-p masking in decoding strategies.
- Break condition: If p is set too low, the decoder may have insufficient candidate tokens to form grammatically correct responses.

## Foundational Learning

- Concept: Conditional Pointwise Mutual Information (CPMI)
  - Why needed here: CPMI quantifies the association between response and document given dialogue history, which is essential for measuring faithfulness in document-grounded dialogues.
  - Quick check question: What does a positive CPMI between response r and document d given dialogue history h indicate about the relationship between r and d?

- Concept: Factorizability of CPMI
  - Why needed here: CPMI can be decomposed similarly to likelihood terms in autoregressive models, making it tractable to incorporate into decoding strategies.
  - Quick check question: How does the factorizability of CPMI enable its use in a decoding strategy that generates responses token-by-token?

- Concept: Top-p sampling
  - Why needed here: Top-p sampling restricts the vocabulary during decoding to high-likelihood tokens, preventing grammatical errors when using CPMI in the scoring function.
  - Quick check question: What problem does top-p masking solve when using CPMI in a decoding strategy, and how does it work?

## Architecture Onboarding

- Component map: Document + Dialogue History → PMI-DECODE → Response Generation → PMI-FAITH Evaluation → Human Evaluation
- Critical path: Document + Dialogue History → PMI-DECODE → Response Generation → PMI-FAITH Evaluation → Human Evaluation
- Design tradeoffs:
  - α parameter balances faithfulness vs. relevance/grammaticality
  - Top-p value balances faithfulness gains vs. grammaticality preservation
  - Pre-trained model choice affects PMI-FAITH computation quality
  - Dataset size affects training quality of the underlying language model
- Failure signatures:
  - Low PMI-FAITH scores despite faithful responses - may indicate pre-trained model inadequacy
  - Grammatical errors in PMI-DECODE outputs - may indicate α or top-p values need adjustment
  - Low relevance scores - may indicate faithfulness is being prioritized too heavily
  - Poor correlation with human judgments - may indicate metric or decoding strategy needs refinement
- First 3 experiments:
  1. Compare PMI-FAITH vs. baseline metrics (Q2, BERTScore) on BEGIN benchmark to validate improved correlation with human judgments
  2. Test PMI-DECODE with different α values (0.1, 0.25, 0.5) on MultiDoc2Dial to find optimal faithfulness-relevance tradeoff
  3. Evaluate PMI-DECODE vs. greedy decoding on TopicalChat with human evaluation to measure faithfulness gains and grammar preservation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the PMI-FAITH metric be extended to handle multi-modal inputs, such as text and images, in document-grounded dialogues?
- Basis in paper: [inferred] The paper focuses on text-based document-grounded dialogues, but does not explore multi-modal inputs.
- Why unresolved: The current PMI-FAITH metric is designed for text-based inputs and would need to be adapted to handle other modalities like images.
- What evidence would resolve it: Experiments demonstrating the effectiveness of PMI-FAITH on multi-modal document-grounded dialogues, or theoretical extensions of the metric to handle different modalities.

### Open Question 2
- Question: How can the PMI-DECODE strategy be improved to handle longer dialogue contexts without losing faithfulness?
- Basis in paper: [explicit] The paper mentions that PMI-DECODE may struggle with longer dialogue contexts and proposes top-p masking as a mitigation technique.
- Why unresolved: The paper does not explore other techniques to handle longer dialogue contexts, such as attention mechanisms or hierarchical encoding.
- What evidence would resolve it: Comparative experiments showing the effectiveness of PMI-DECODE with longer dialogue contexts using different techniques, or theoretical analysis of the challenges and potential solutions.

### Open Question 3
- Question: How can the PMI-FAITH metric be used to evaluate and improve the faithfulness of other natural language generation tasks, such as summarization or question answering?
- Basis in paper: [inferred] The paper focuses on document-grounded dialogues, but the PMI-FAITH metric could potentially be applied to other NLG tasks.
- Why unresolved: The paper does not explore the application of PMI-FAITH to other NLG tasks, and it is unclear how the metric would need to be adapted for different tasks.
- What evidence would resolve it: Experiments demonstrating the effectiveness of PMI-FAITH on other NLG tasks, or theoretical analysis of how the metric can be adapted for different tasks.

## Limitations

- The metric's effectiveness relies heavily on the quality of the pre-trained language model used to compute CPMI
- The human evaluation was conducted on a limited sample size (50 responses per system per dataset)
- The approach focuses on English-language document-grounded dialogues and may require adaptation for other languages
- The top-p masking approach introduces an additional hyperparameter (p) that requires careful tuning

## Confidence

**High Confidence:**
- PMI-FAITH correlates better with human judgments than baseline metrics on the BEGIN benchmark
- PMI-DECODE generates more faithful responses than greedy decoding as measured by automated metrics
- Top-p masking effectively prevents grammatical errors during PMI-DECODE

**Medium Confidence:**
- PMI-DECODE maintains relevance while improving faithfulness (based on human evaluation)
- The optimal α value of 0.25 generalizes across different datasets
- PMI-FAITH's performance is robust across different pre-trained language models

## Next Checks

1. **Ablation Study on Top-p Masking**: Conduct an ablation study removing top-p masking from PMI-DECODE to quantify its exact contribution to grammaticality preservation and measure any degradation in response quality.

2. **Cross-Domain Generalization Test**: Evaluate PMI-FAITH and PMI-DECODE on document-grounded dialogue datasets from different domains (e.g., technical support, medical consultations) to assess their robustness and identify domain-specific limitations.

3. **Extended Human Evaluation**: Scale up the human evaluation to 200+ responses per system per dataset and include additional dimensions such as "usefulness" and "coherence" to provide a more comprehensive assessment of response quality beyond faithfulness.