---
ver: rpa2
title: 'SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised
  Learning'
arxiv_id: '2311.10572'
source_url: https://arxiv.org/abs/2311.10572
tags:
- data
- inlier
- outlier
- classes
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SSB improves open-set semi-supervised learning by incorporating
  classifier pseudo-labeling and task-specific feature separation. Instead of filtering
  out-of-distribution (OOD) data, SSB uses high-confidence pseudo-labels for both
  inliers and OOD samples in classifier training, improving unlabeled data utilization.
---

# SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning

## Quick Facts
- arXiv ID: 2311.10572
- Source URL: https://arxiv.org/abs/2311.10572
- Reference count: 40
- Key outcome: SSB significantly improves both inlier classification accuracy and OOD detection (AUROC) over existing methods on CIFAR-10, CIFAR-100, and ImageNet benchmarks.

## Executive Summary
SSB introduces a simple but effective approach to open-set semi-supervised learning that addresses the challenge of unlabeled data containing out-of-distribution samples. The method leverages classifier pseudo-labeling with confidence filtering to utilize high-confidence pseudo-labeled data for both inliers and outliers, improving unlabeled data utilization. Additionally, SSB employs non-linear transformations between task-specific heads and shared encoder features to reduce interference between inlier classification and outlier detection tasks. The approach also introduces pseudo-negative mining, which enhances outlier detection by using confident negatives as pseudo-outliers to increase data diversity.

## Method Summary
SSB addresses open-set semi-supervised learning by implementing a multi-task learning framework with a shared feature encoder, inlier classifier, and outlier detector. The method uses classifier pseudo-labeling with confidence threshold τ=0.95 to incorporate high-confidence pseudo-labeled data into training, regardless of whether samples are inliers or outliers. Non-linear transformations (2-layer MLPs with 1024 hidden dimensions) separate features for classification and detection tasks, preventing mutual interference. Pseudo-negative mining with threshold θ=0.01 leverages confident negatives as pseudo-outliers to enhance outlier detection. The model is trained using SGD with 0.03 learning rate, 64 batch size, and cosine decay for 512 epochs, with detector training deferred until epoch 475.

## Key Results
- SSB achieves 89.2% inlier classification accuracy and 96.5% AUROC on CIFAR-10 with 6/4 inlier/outlier split
- On CIFAR-100 with 55/45 split, SSB reaches 59.3% accuracy and 91.8% AUROC
- Outperforms existing methods including CRUST, TPHD, and STRE by significant margins across all benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Classifier pseudo-labeling with confidence filtering improves inlier classification by incorporating high-confidence pseudo-labeled data regardless of whether they are inliers or outliers.
- Mechanism: The inlier classifier generates pseudo-labels for unlabeled data, and samples with confidence scores above threshold τ are used in training. This approach effectively utilizes unlabeled data and includes many useful OOD data as natural data augmentations of inliers.
- Core assumption: High-confidence pseudo-labels from the inlier classifier are reliable enough to use in training, even when some pseudo-labels may be incorrect for OOD samples.
- Evidence anchors:
  - [abstract] "we find that inlier classification performance can be largely improved by incorporating high-confidence pseudo-labeled data, regardless of whether they are inliers or outliers"
  - [section 3.2] "we propose to incorporate unlabeled data with confident pseudo-labels (as generated by the inlier classifier) into the training, irrespective of whether it is inlier or OOD data"
  - [corpus] Weak - the corpus papers discuss open-set SSL but don't specifically address confidence-based pseudo-labeling for inlier classification
- Break condition: When pseudo-label confidence scores become unreliable (e.g., due to distribution shift or insufficient training), the approach would degrade performance by incorporating incorrect pseudo-labels.

### Mechanism 2
- Claim: Non-linear transformations between task-specific heads and shared encoder features reduce interference between inlier classification and outlier detection.
- Mechanism: Two separate MLP projection heads (hc and hd) transform the shared encoder features before they reach the inlier classifier and outlier detector. This separation prevents the classifier from mixing inlier and outlier representations and allows the detector to maintain specialized features for outlier detection.
- Core assumption: The shared encoder features contain task-irrelevant information that interferes with each task's performance, and separating them through non-linear transformations improves task-specific learning.
- Evidence anchors:
  - [abstract] "we propose to utilize non-linear transformations to separate the features used for inlier classification and outlier detection in the multi-task learning framework, preventing adverse effects between them"
  - [section 3.3] "we add non-linear transformations for the task-specific heads and find that this effectively reduces mutual interference between them, resulting in more specialized features and improved performance for both tasks"
  - [section 3.3] "The addition of the projection heads not only restores the OOD detection performance but also achieves superior results when combined with confidence filtering"
- Break condition: When the projection heads become too complex or when the shared encoder already provides sufficient task separation, adding these transformations may introduce unnecessary complexity without performance gains.

### Mechanism 3
- Claim: Pseudo-negative mining enhances outlier detection by using confident negatives as pseudo-outliers to increase data diversity.
- Mechanism: Unlabeled samples with low inlier scores (below threshold θ) are treated as pseudo-outliers and used as negative samples in training the one-vs-all outlier detectors. This increases the diversity of outlier representations and improves generalization.
- Core assumption: Unlabeled data with low inlier classifier confidence are likely to be outliers, and using them as pseudo-outliers improves the detector's ability to distinguish between inliers and outliers.
- Evidence anchors:
  - [abstract] "we introduce pseudo-negative mining, which further boosts outlier detection performance"
  - [section 3.4] "we propose pseudo-negative mining to further improve the outlier detector training by leveraging confident negatives as pseudo-outliers to enhance the data diversity of OOD data"
  - [section 3.4] "pseudo-negative mining is less susceptible to inaccurate predictions while increasing data utilization"
- Break condition: When the threshold θ is set too high or too low, either too few or too many samples are used as pseudo-outliers, degrading detection performance.

## Foundational Learning

- Concept: Semi-supervised learning (SSL)
  - Why needed here: The paper builds on standard SSL techniques but extends them to handle open-set scenarios where unlabeled data contains outliers.
  - Quick check question: What is the key difference between standard SSL and open-set SSL in terms of data assumptions?

- Concept: Outlier detection and one-vs-all (OVA) classifiers
  - Why needed here: The method uses OVA classifiers for outlier detection, where each classifier distinguishes one inlier class from all other classes (including outliers).
  - Quick check question: How does the one-vs-all approach handle multi-class outlier detection differently from binary outlier detection?

- Concept: Pseudo-labeling and confidence thresholding
  - Why needed here: The method uses confidence-based pseudo-labeling to select high-confidence samples for training, which is crucial for both inlier classification and pseudo-negative mining.
  - Quick check question: What trade-off exists between confidence threshold values and data utilization in pseudo-labeling?

## Architecture Onboarding

- Component map:
  Input image → shared encoder (f) → hc → gc (inlier classifier) and hd → gd (outlier detector) → OVA binary classifiers

- Critical path:
  1. Input image → shared encoder (f)
  2. Encoder output → hc → gc for inlier classification
  3. Encoder output → hd → gd for outlier detection
  4. Pseudo-labels generated from classifier confidence
  5. Pseudo-negative mining selects low-confidence samples as outliers

- Design tradeoffs:
  - Shared vs. separate feature spaces for classification and detection
  - Confidence threshold τ balancing pseudo-label quality vs. data utilization
  - Projection head complexity vs. parameter efficiency
  - Threshold θ for pseudo-negative mining balancing precision vs. data diversity

- Failure signatures:
  - Poor inlier classification: Confidence thresholds too high/low, insufficient pseudo-label quality
  - Poor outlier detection: Inadequate pseudo-negative mining, interference between classifier and detector
  - Overfitting: Too complex projection heads, insufficient regularization

- First 3 experiments:
  1. Baseline comparison: Implement without projection heads to verify their importance for separating classifier and detector features
  2. Threshold sensitivity: Vary τ and θ to find optimal values for your specific dataset
  3. Pseudo-negative mining ablation: Compare with standard pseudo-labeling to verify the effectiveness of using low-confidence samples as pseudo-outliers

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal depth and width configuration for the MLP projection heads that maximizes both inlier classification and OOD detection performance?
- Basis in paper: [explicit] The paper states that a 2-layer MLP with a hidden dimension of 1024 showed the best inlier accuracy and OOD detection performance in experiments, but suggests there is room for further optimization.
- Why unresolved: The paper only provides a comparison of different MLP configurations without conducting a comprehensive search for the optimal architecture.
- What evidence would resolve it: A systematic hyperparameter search exploring various depths (1-4 layers) and widths (128-2048 dimensions) while keeping other factors constant, measuring both inlier accuracy and OOD detection performance.

### Open Question 2
- Question: How does the performance of SSB degrade when the class distribution of unlabeled data becomes increasingly imbalanced or long-tailed?
- Basis in paper: [inferred] The paper mentions that SSB is not able to handle long-tail distributions effectively and would struggle to distinguish inliers of tail classes from OOD data due to data scarcity.
- Why unresolved: The paper only mentions this limitation without providing empirical results on how performance degrades under different levels of class imbalance.
- What evidence would resolve it: Experiments on datasets with varying degrees of class imbalance, measuring both inlier classification accuracy and OOD detection performance as the imbalance ratio changes.

### Open Question 3
- Question: What is the theoretical justification for why non-linear transformations in the projection heads prevent mutual interference between the classifier and detector tasks?
- Basis in paper: [explicit] The paper empirically demonstrates that adding non-linear transformations reduces adverse effects between tasks, but doesn't provide theoretical analysis.
- Why unresolved: The paper relies on empirical observations without explaining the underlying mechanism that makes the non-linear transformations effective.
- What evidence would resolve it: A theoretical analysis showing how the non-linear transformations create task-specific feature subspaces that prevent interference, possibly through gradient analysis or feature space visualization studies.

## Limitations
- Assumes reasonably balanced inlier class distribution and cannot effectively handle long-tail distributions
- Performance may degrade when pseudo-label confidence scores become unreliable due to distribution shift
- Optimal hyperparameter values (τ, θ, projection head architecture) may vary significantly across different datasets and require extensive tuning

## Confidence
- High confidence: The core mechanism of classifier pseudo-labeling with confidence filtering is well-supported by experimental results and theoretical justification.
- Medium confidence: The non-linear transformation approach for feature separation shows consistent improvements but the optimal architecture (number of layers, activation functions) is not explored.
- Medium confidence: Pseudo-negative mining effectiveness is demonstrated but the sensitivity to threshold θ and potential label noise propagation needs further investigation.

## Next Checks
1. Cross-dataset generalization: Test SSB on datasets with different characteristics (e.g., natural vs. synthetic images) to validate robustness across domains.
2. Threshold sensitivity analysis: Systematically vary τ and θ across a wider range to identify optimal values for different data distributions and noise levels.
3. Ablation on projection head complexity: Experiment with different projection head architectures (1-3 layers, different activation functions) to find the minimal sufficient complexity for feature separation.