---
ver: rpa2
title: Towards a Model of Puzznic
arxiv_id: '2310.01503'
source_url: https://arxiv.org/abs/2310.01503
tags:
- step
- forall
- grid
- gcol
- grow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors model and solve Puzznic, a classic video puzzle game,
  using both planning (PDDL) and constraint programming (Essence Prime, Essence) approaches.
  They focus on levels without moving blocks and compare fixed-step and variable-step
  constraint models.
---

# Towards a Model of Puzznic

## Quick Facts
- arXiv ID: 2310.01503
- Source URL: https://arxiv.org/abs/2310.01503
- Reference count: 20
- Key outcome: The authors model and solve Puzznic, a classic video puzzle game, using both planning (PDDL) and constraint programming (Essence Prime, Essence) approaches. They focus on levels without moving blocks and compare fixed-step and variable-step constraint models. The planning approach outperforms the constraint models on a set of benchmark instances, though improvements to the constraint models are proposed. The constraint models use Savile Row to translate to SAT, solved with Kissat. The planning approach uses Fast Downward with blind search. Key results include varying CPU times across instances, with the planning approach generally faster, but some constraint models performing better on certain instances.

## Executive Summary
This paper presents declarative models for solving Puzznic, a classic video puzzle game, using both planning and constraint programming approaches. The authors focus on levels without moving blocks and compare different modeling strategies, including fixed-step and variable-step constraint models. They implement these models using PDDL with Fast Downward planner and Essence Prime with Savile Row and Kissat solver. The work demonstrates that while the planning approach currently outperforms the constraint models, there is potential for improving the constraint programming solutions through various techniques.

## Method Summary
The authors model Puzznic using two main approaches: planning with PDDL and constraint programming with Essence Prime and Essence. The PDDL model uses Fast Downward planner with blind search A* heuristic, while the constraint models are translated to SAT using Savile Row and solved with Kissat. The Essence Prime models include both fixed-step and variable-step variants, with the fixed-step model typically performing better. The Essence specification models the problem as a planning problem with explicit scaffolding, but fails on large instances due to memory constraints in Savile Row when the graph of cells exceeds about 220 vertices.

## Key Results
- The planning approach (PDDL with Fast Downward) outperforms constraint programming approaches on benchmark instances
- Fixed Steps Essence Prime model usually performs better than Variable Steps model
- Essence specification fails for large instances due to Savile Row memory constraints (graph of cells > 220 vertices)
- The planning approach is superior at present, but constraint models show potential for improvement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The planning approach outperforms the constraint models because it avoids modeling intermediate gravity steps explicitly.
- Mechanism: In the PDDL formulation, gravity is implicitly handled through action preconditions and effects, while the constraint models must explicitly track every intermediate state caused by gravity and cascading matches.
- Core assumption: The PDDL model's implicit handling of gravity is computationally cheaper than the constraint model's explicit state tracking.
- Evidence anchors:
  - [abstract] "The planning approach is at present superior to the constraint programming approaches"
  - [section] "We use the declarative nature of constraints to avoid having to explicitly calculate the effects of gravity" (Section 4.1.1)
  - [corpus] Weak evidence - corpus does not directly address this specific performance difference
- Break condition: If PDDL's blind search becomes inefficient on larger instances or if constraint models can be improved to handle gravity more efficiently.

### Mechanism 2
- Claim: The Essence Prime models perform better when the number of patterned blocks is small relative to grid size.
- Mechanism: The Fixed Steps model can efficiently handle problems where the maximum number of steps is predictable, while the Variable Steps model adds overhead by allowing for "dummy" moves.
- Core assumption: The overhead of computing and minimizing the number of moves in the Variable Steps model outweighs its flexibility advantage for small instances.
- Evidence anchors:
  - [section] "The Fixed Steps model described in Section 4.1 still underlies it" (Section 4.2)
  - [section] "The Fixed Steps model usually performs better, and the Variable Steps model never solves an instance within the timeout when the Fixed Steps model fails to do so" (Section 6)
  - [corpus] Weak evidence - corpus does not directly compare these specific model variants
- Break condition: If the problem instances have unpredictable or very large step counts, making the Fixed Steps model's requirement for an exact bound problematic.

### Mechanism 3
- Claim: The Essence specification fails on large instances due to memory constraints in Savile Row.
- Mechanism: The graph of cells in large instances exceeds Savile Row's memory capacity when there are more than about 220 vertices.
- Core assumption: Savile Row has a hard memory limit for processing the graph representation used in the Essence specification.
- Evidence anchors:
  - [section] "The Essence specification fails for large instances, as Savile Row runs out of memory when the graph of cells contains more than about 220 vertices" (Section 6)
  - [corpus] Weak evidence - corpus does not directly address this specific memory constraint
- Break condition: If Savile Row's memory handling is improved or if alternative solvers are used that can handle larger graphs.

## Foundational Learning

- Concept: PDDL planning domain definition
  - Why needed here: The paper uses PDDL to model Puzznic as a planning problem, requiring understanding of how to define states, actions, and goals in PDDL.
  - Quick check question: What are the two main files required in a PDDL problem definition, and what does each contain?

- Concept: Constraint programming with Essence Prime
  - Why needed here: The paper implements Puzznic using Essence Prime, which requires understanding of how to define variables, constraints, and viewpoints for constraint satisfaction problems.
  - Quick check question: How does the Fixed Steps model in Essence Prime handle the transition between player actions and matching steps?

- Concept: SAT translation and solving
  - Why needed here: The constraint models are translated to SAT and solved with Kissat, requiring understanding of how constraint problems are converted to SAT instances.
  - Quick check question: What is the role of Savile Row in the constraint modeling process described in the paper?

## Architecture Onboarding

- Component map:
  - PDDL model (Fast Downward planner)
  - Essence Prime models (Fixed Steps and Variable Steps)
  - Essence specification
  - Savile Row (model translation)
  - Kissat (SAT solving)

- Critical path: PDDL model → Fast Downward planner → solution
  Essence Prime models → Savile Row → Kissat → solution
  Essence specification → Conjure → Savile Row → Kissat → solution

- Design tradeoffs: The PDDL approach trades explicit state representation for implicit handling of complex game mechanics like gravity. The constraint approaches trade model simplicity for computational efficiency, with different variants (Fixed vs Variable Steps) balancing exact bounds against flexibility.

- Failure signatures: Memory overflow in Savile Row for large instances (Essence specification), timeouts in constraint solvers for complex instances, inefficiency in PDDL's blind search for large state spaces.

- First 3 experiments:
  1. Compare solution times for a simple Puzznic instance using both PDDL and Fixed Steps Essence Prime models to verify the planning approach's superiority on easy problems.
  2. Test the memory limits of the Essence specification by gradually increasing grid size to confirm the 220 vertex threshold mentioned in the paper.
  3. Implement the proposed improvements to the constraint models (symmetry breaking, implied constraints) and measure their impact on solving times for a set of benchmark instances.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would incorporating moving blocks into the Puzznic models affect their performance and complexity?
- Basis in paper: [explicit] The paper states that the current work focuses on Puzznic without moving blocks, and some levels of the game also have moving wall blocks which can carry patterned blocks.
- Why unresolved: The paper only considers the simpler variant without moving blocks, and the authors mention that the full version of Puzznic has dynamic elements in the form of moving blocks, but they do not explore this aspect.
- What evidence would resolve it: Extending the current models to include moving blocks and comparing their performance and complexity to the existing models would provide insights into how the presence of moving blocks affects the solvability of Puzznic.

### Open Question 2
- Question: Can the constraint models be further improved by identifying and incorporating symmetries, dominances, and implied constraints?
- Basis in paper: [explicit] The paper discusses potential improvements to the constraint models, including identifying symmetries and dominances, adding implied constraints, and preprocessing instances to remove unnecessary grid cells.
- Why unresolved: The authors mention these potential improvements but do not implement or evaluate them in the current work.
- What evidence would resolve it: Implementing the suggested improvements and comparing the performance of the enhanced constraint models to the current ones would demonstrate the impact of these techniques on solving Puzznic instances.

### Open Question 3
- Question: How does the performance of the constraint models compare to the planning approach when solving more complex Puzznic instances?
- Basis in paper: [explicit] The paper states that the planning approach is currently superior to the constraint programming approaches, but the authors note that they have already observed large improvements in solution time by improving their constraint models and continue to improve them.
- Why unresolved: The paper only presents results on a small set of benchmark instances, and the authors mention that none of their approaches can solve more complex instances, including several levels from the PS1 version of Puzznic.
- What evidence would resolve it: Preparing a larger set of benchmark instances, including more complex levels, and comparing the performance of the improved constraint models to the planning approach would provide a more comprehensive evaluation of the relative strengths and weaknesses of each approach.

## Limitations

- The paper does not provide detailed performance comparisons for different solver configurations or parameter settings, limiting reproducibility of the reported results
- Memory constraints in Savile Row are mentioned but not systematically characterized across different instance types
- The relationship between problem size (grid dimensions) and computational complexity is not fully explored

## Confidence

- High confidence in the planning approach's superiority claim, supported by systematic benchmarking across multiple instances
- Medium confidence in the constraint model improvements' effectiveness, as proposed enhancements are not empirically validated in the paper
- Low confidence in the exact memory thresholds for Savile Row, as only a rough estimate (220 vertices) is provided without systematic testing

## Next Checks

1. Implement and test the proposed constraint model improvements (symmetry breaking, implied constraints) on a representative subset of benchmark instances to verify claimed performance gains
2. Characterize the memory usage patterns of Savile Row systematically by testing the Essence specification across a range of grid sizes to identify precise failure points
3. Compare the PDDL and constraint approaches on instances with varying ratios of patterned blocks to grid size to validate the claim about Essence Prime's performance dependence on block density