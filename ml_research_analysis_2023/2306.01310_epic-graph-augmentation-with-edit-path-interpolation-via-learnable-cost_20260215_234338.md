---
ver: rpa2
title: 'EPIC: Graph Augmentation with Edit Path Interpolation via Learnable Cost'
arxiv_id: '2306.01310'
source_url: https://arxiv.org/abs/2306.01310
tags:
- graph
- edit
- cost
- distance
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EPIC, a novel graph data augmentation technique
  that uses edit path interpolation via a learnable cost function. EPIC constructs
  an edit path between two graphs by applying a series of edit operations, generating
  intermediate graph states that serve as augmented data.
---

# EPIC: Graph Augmentation with Edit Path Interpolation via Learnable Cost

## Quick Facts
- arXiv ID: 2306.01310
- Source URL: https://arxiv.org/abs/2306.01310
- Authors: 
- Reference count: 40
- Key outcome: EPIC consistently improves graph classification accuracy over existing augmentation methods, including mixup-based approaches, across 11 datasets

## Executive Summary
EPIC introduces a novel graph data augmentation technique that uses edit path interpolation via a learnable cost function. The method constructs edit paths between pairs of graphs by applying a series of edit operations, generating intermediate graph states that serve as augmented data. The key innovation is a learned cost model that accounts for the importance of specific edit operations, allowing for more nuanced transformations compared to traditional unit-cost approaches. Experiments demonstrate that EPIC consistently improves classification accuracy over existing augmentation methods and shows robustness to noisy labels.

## Method Summary
EPIC generates augmented graphs by interpolating along edit paths between pairs of graphs. The method learns a cost function that assigns different costs to edit operations based on their semantic importance, computed using graph neural network embeddings. During training, the Sinkhorn-Knopp algorithm provides a differentiable approximation for assignment, while the Hungarian algorithm is used for inference. A triplet loss framework trains the cost function to minimize distances between graphs of the same class while maximizing distances between different classes. The augmented graphs are generated by sampling intermediate states along the edit paths.

## Key Results
- EPIC consistently improves classification accuracy over existing augmentation methods across 11 graph classification datasets
- The method shows robustness to noisy labels, outperforming baselines under label corruption
- Qualitative analysis reveals that the learned cost function effectively captures semantic differences in graph structures, leading to more meaningful augmentations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EPIC's learnable cost function enables context-sensitive graph edit distance computation that outperforms unit-cost approaches
- Mechanism: The method learns a cost matrix parameterized by graph neural network embeddings, where substitution costs are based on embedding distances between nodes. This allows the model to assign higher costs to operations that would significantly alter semantic meaning while keeping less impactful edits cheaper.
- Core assumption: Graph edit operations have varying semantic importance depending on the specific domain and task context
- Evidence anchors:
  - [abstract]: "our method introduces a context-sensitive cost model that accounts for the importance of specific edit operations formulated through a learning framework"
  - [section 3.2]: "changes in a functional group of molecular graphs can lead to larger semantic perturbation than the other parts in a property prediction task"
  - [corpus]: Weak - related works focus on graph edit distance but don't provide direct evidence for learnable costs

### Mechanism 2
- Claim: The triplet loss framework effectively learns to distinguish between graphs of same and different classes
- Mechanism: EPIC uses a triplet loss objective where distances between graphs of the same class are minimized while distances between different classes are maximized. This creates a learned metric space where graph similarity aligns with class labels.
- Core assumption: Graphs belonging to the same class should have smaller edit distances than graphs from different classes
- Evidence anchors:
  - [section 3.2]: "We assume that the pair of graphs within the same class has a relatively shorter distance than those of different classes"
  - [section 4.3, Table 4b]: Distance-based classification results show EPIC achieves higher accuracy (72.69% on NCI1) compared to unit cost (60.49%)
  - [corpus]: Weak - no direct corpus evidence for triplet loss in graph edit distance learning

### Mechanism 3
- Claim: Sinkhorn-Knopp algorithm provides effective differentiable approximation for Hungarian algorithm in cost learning
- Mechanism: The Sinkhorn-Knopp algorithm iteratively converts the cost matrix into a doubly stochastic matrix, providing a smooth approximation that enables gradient-based optimization. This allows the model to learn cost functions while maintaining computational tractability.
- Core assumption: The Sinkhorn-Knopp approximation can effectively replace the Hungarian algorithm during training while preserving solution quality
- Evidence anchors:
  - [section 3.2]: "We instead employ the Sinkhorn-Knopp algorithm to address this issue to obtain a differentiable assignment matrix"
  - [section 4.3, Figure 3]: Training and validation curves show Sinkhorn-Knopp provides more stable learning than Hungarian
  - [corpus]: Weak - related works on graph edit distance learning don't discuss this specific optimization approach

## Foundational Learning

- Concept: Graph Neural Networks for node embedding
  - Why needed here: GNNs provide the embedding representations used to compute substitution costs between nodes. The quality of these embeddings directly impacts the effectiveness of the learned cost function.
  - Quick check question: If two nodes have identical local graph structures, should their embeddings be similar or different in the context of EPIC?

- Concept: Triplet loss and metric learning
  - Why needed here: The triplet loss framework is used to train the cost function such that graphs from the same class have smaller distances than graphs from different classes. This creates a semantically meaningful metric space.
  - Quick check question: In the triplet loss formulation, should the margin γ be larger or smaller when dealing with highly similar classes?

- Concept: Optimal transport and assignment problems
  - Why needed here: Graph edit distance computation is formulated as an assignment problem between nodes of two graphs. Understanding this connection is crucial for grasping how EPIC computes distances.
  - Quick check question: When two graphs have different numbers of nodes, how does the assignment problem formulation handle unmatched nodes?

## Architecture Onboarding

- Component map: Graph neural network (GNN) encoder → Node embeddings → Cost function module → Assignment solver → Graph edit distance → Edit path sampler → Augmented graphs

- Critical path: Input graphs → GNN embeddings → Cost matrix → Assignment matrix → Graph edit distance → Augmentation

- Design tradeoffs:
  - Hungarian vs Sinkhorn-Knopp: Exact vs differentiable solution, computational cost vs training stability
  - Node-only vs full edit operations: Simplified implementation vs capturing edge structure
  - Random vs BFS-ordered operations: Computational simplicity vs preserving graph connectivity

- Failure signatures:
  - Poor augmentation quality: Cost function not learning meaningful semantic differences
  - Unstable training: Sinkhorn-Knopp not converging or Hungarian approximation too coarse
  - Degraded classification performance: Augmentation introducing too much noise or not enough diversity

- First 3 experiments:
  1. Train cost function on a simple synthetic dataset where edit operation importance is known (e.g., lollipop graphs with head nodes being more important)
  2. Compare learned vs unit costs on a small dataset to verify semantic sensitivity
  3. Validate that Sinkhorn-Knopp approximation error is acceptable by comparing with Hungarian on validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of cost function (e.g., unit cost vs. learned cost) affect the interpretability and explainability of the graph edit path?
- Basis in paper: [explicit] The paper compares three cost functions: unit cost, feature-distance cost, and EPIC (learned cost), and shows that EPIC outperforms the other cost functions in terms of classification accuracy.
- Why unresolved: While the paper demonstrates the superiority of EPIC in terms of performance, it does not delve into the interpretability and explainability aspects of the learned cost function and its impact on the generated edit paths.
- What evidence would resolve it: Further analysis of the learned cost function's behavior, such as visualizing the cost values for different types of graph structures and edit operations, could provide insights into its interpretability and explainability.

### Open Question 2
- Question: Can the learned cost function be transferred across different graph datasets or tasks?
- Basis in paper: [inferred] The paper focuses on learning the cost function specific to each dataset and task, without exploring the transferability of the learned cost function.
- Why unresolved: The paper does not investigate whether the learned cost function can be effectively applied to other graph datasets or tasks, which could have practical implications for real-world applications.
- What evidence would resolve it: Conducting experiments on transferring the learned cost function from one dataset or task to another and evaluating its performance could provide insights into its transferability.

### Open Question 3
- Question: How does the choice of graph neural network architecture affect the learned cost function and the overall performance of EPIC?
- Basis in paper: [explicit] The paper mentions using different graph neural network architectures (GIN and GCN) as backbones for the augmentation process.
- Why unresolved: While the paper evaluates the performance of EPIC with different backbone architectures, it does not explore how the choice of architecture influences the learned cost function and the quality of the generated edit paths.
- What evidence would resolve it: Conducting experiments with various graph neural network architectures and analyzing the learned cost functions and the resulting edit paths could provide insights into the impact of architecture choice.

## Limitations
- The method focuses on node edit operations only, potentially missing important edge structure information
- Computational cost of computing graph edit distances for large datasets could be prohibitive in practice
- Effectiveness may depend heavily on the quality of graph neural network embeddings, which can struggle with very large or complex graphs

## Confidence

- **High confidence**: The mechanism of using learned costs for graph edit operations (Mechanism 1) is well-supported by the theoretical framework and experimental results showing improved classification accuracy over unit-cost approaches.
- **Medium confidence**: The effectiveness of the triplet loss framework (Mechanism 2) is supported by distance-based classification results, but the correlation between edit distance and semantic similarity needs further validation across diverse datasets.
- **Medium confidence**: The use of Sinkhorn-Knopp algorithm (Mechanism 3) is theoretically sound and shows training stability, but the approximation error relative to the Hungarian algorithm needs more rigorous analysis.

## Next Checks

1. **Edge operation validation**: Extend EPIC to include edge edit operations and evaluate the impact on classification performance, particularly for datasets where edge structure is semantically important.
2. **Embedding sensitivity analysis**: Test EPIC's performance using different GNN architectures and embedding dimensions to quantify the impact of embedding quality on learned costs.
3. **Computational scaling study**: Measure the runtime complexity of EPIC as graph size increases and evaluate approximation strategies for large-scale applications.