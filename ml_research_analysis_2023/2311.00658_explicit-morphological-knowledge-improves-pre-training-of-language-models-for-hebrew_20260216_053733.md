---
ver: rpa2
title: Explicit Morphological Knowledge Improves Pre-training of Language Models for
  Hebrew
arxiv_id: '2311.00658'
source_url: https://arxiv.org/abs/2311.00658
tags:
- tokenization
- morphological
- hebrew
- language
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work explores the impact of incorporating explicit morphological
  knowledge into the pre-training phase of language models for Hebrew, a morphologically-rich
  language. Two morphologically-driven tokenization methods are proposed: Morphological
  Segmentation and Prefix-Suffix Separation.'
---

# Explicit Morphological Knowledge Improves Pre-training of Language Models for Hebrew

## Quick Facts
- arXiv ID: 2311.00658
- Source URL: https://arxiv.org/abs/2311.00658
- Reference count: 40
- Key outcome: Morphologically-driven tokenization methods outperform baseline on most tasks, achieving up to 3 F1 score improvement in Named Entity Recognition and 1 F1 score improvement in Dependency Parsing.

## Executive Summary
This paper explores how incorporating explicit morphological knowledge into pre-training can improve language models for morphologically-rich languages like Hebrew. The authors propose two morphologically-driven tokenization methods: Morphological Segmentation and Prefix-Suffix Separation. Through extensive experiments on multiple downstream tasks, they demonstrate that these methods consistently outperform standard language-agnostic tokenization baselines, particularly in Named Entity Recognition and Dependency Parsing. The results suggest that morphological knowledge enables better generalization to rare and unseen words in morphologically-rich languages.

## Method Summary
The authors pre-train BERT-based language models using three different tokenization approaches: a standard WordPiece baseline, a Morphological Segmentation method that breaks words into their underlying morphemes using Hebrew morphological analysis, and a Prefix-Suffix Separation method that deterministically separates valid prefixes and suffixes. They use Hebrew Wikipedia and HeDC4 corpus for pre-training, then fine-tune the models on six downstream tasks including Named Entity Recognition, Question Answering, Word Sense Disambiguation, Morphological Parsing, Part-of-Speech Tagging, and Dependency Parsing. The experiments evaluate vocabulary sizes of 16K, 32K, and 64K subwords to understand the impact of vocabulary size on performance.

## Key Results
- Morphological Segmentation tokenization achieves up to 3 F1 score improvement in Named Entity Recognition compared to baseline.
- The method shows 1 F1 score improvement in Dependency Parsing over the standard WordPiece tokenizer.
- Both morphologically-driven methods outperform the baseline on most benchmark tasks, with Prefix-Suffix Separation showing consistent but smaller gains than full morphological segmentation.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Morphological segmentation tokenization allows the model to learn representations that capture morphological relationships between words, enabling better generalization to rare and unseen words.
- Mechanism: By breaking words into their underlying morphemes, the model can learn that words sharing the same lexical host but with different prefixes and suffixes are related. This allows the model to generalize the meaning of rare or unseen words based on their morphological composition.
- Core assumption: The morphological segmentation tool used for preprocessing is accurate enough to provide meaningful morpheme boundaries that the model can leverage.
- Evidence anchors:
  - [abstract] "Through the utilization of morphologically based sub-word tokenization rather than a purely statistical one, our tokenization methods hold the potential for the model to exploit this morphological knowledge during the acquisition of contextualized representations, as well as to demonstrate morphological composition capabilities at inference time."
  - [section] "Morphological Segmentation Tokenization Facing the high ambiguity of Hebrew calls for a process of morphological segmentation for tokenizing a word into its morphemes. In this process, a given word form is disambiguated into its underlying morphemes based on the word's context."
  - [corpus] Weak evidence - The paper mentions evaluating morphological segmentation tools but does not provide quantitative results comparing their accuracy.
- Break condition: If the morphological segmentation tool makes frequent errors in segmenting words, the learned representations will be noisy and may not generalize well.

### Mechanism 2
- Claim: Prefix-suffix separation tokenization improves handling of named entities by consistently separating prefixes and suffixes, allowing the model to focus on the core word.
- Mechanism: Named entities in Hebrew are often unknown words that naturally occur with prefixes like "ו" (and), "ש" (that), "מ" (from), and "ל" (to). By consistently separating these prefixes, the model can learn representations of the core word without the interference of the prefixes, improving its ability to recognize named entities.
- Core assumption: The set of valid prefixes and suffixes is sufficient to cover the majority of cases in named entities.
- Evidence anchors:
  - [abstract] "Our experiments main results are depicted in Table 2. The full results are detailed in Appendix E. Tokenization Methods Impact Both morphologically driven tokenization methods outperform the baseline for NER on NEMO by up-to 3 F1 points in both token and morpheme levels."
  - [section] "When encountering OOV words, contemporary tokenization methods, which are based on frequencies, tokenize them into sub-words that often lack any morphological meaning. As a result, PLMs are unable to effectively represent such words based on the their morphological composition (Hofmann et al., 2021)."
  - [corpus] Weak evidence - The paper mentions improvements in NER but does not provide detailed analysis of how prefix-suffix separation specifically helps with named entities.
- Break condition: If named entities often contain prefixes that are not in the set of valid prefixes, the model will still struggle to represent them accurately.

### Mechanism 3
- Claim: Increasing vocabulary size helps close the performance gap between morphologically-driven tokenization and baseline tokenization, but this may be due to memorization rather than true generalization.
- Mechanism: Larger vocabulary sizes allow the model to have more unique tokens, which can help it represent rare words more accurately. However, this may come at the cost of requiring more training data and potentially overfitting to the training set.
- Core assumption: The larger vocabulary size provides enough unique tokens to represent the majority of words in the training data, including rare and unseen words.
- Evidence anchors:
  - [abstract] "Vocabulary Size Impact Figure 1 demonstrate the positive impact of increasing the vocabulary size, supporting previous studies (Seker et al., 2022; Guetta et al., 2022). This is most evident in NER at token level and QA on both datasets, for almost all tokenization methods (see Appendix E)."
  - [section] "For NER on NEMO at token level and dependency parsing on HTB, where our Morphological Segmentation tokenization demonstrates the most notable improvement over the baseline with a vocabulary size of 32K, it seems as if increasing the vocabulary size to 64K closes this gap. We suggest that this is due to memorization rather than generalization to rare and unseen words, inviting future research focusing on the impact of even larger vocabularies (Feng et al., 2022), purely open-vocabulary approaches (Tay et al., 2021), as well as on measuring the generalization capabilities of PLMs for Hebrew, as done for other MRLs (Moisio et al., 2023)."
  - [corpus] Weak evidence - The paper does not provide quantitative analysis of the trade-off between vocabulary size and generalization.
- Break condition: If the model starts to overfit to the training data as the vocabulary size increases, the improvements in performance may not generalize to unseen data.

## Foundational Learning

- Concept: Morphological segmentation
  - Why needed here: Hebrew is a morphologically-rich language where words are often composed of a root and various prefixes and suffixes. Understanding how to segment words into their constituent morphemes is crucial for building language models that can handle the high ambiguity and productivity of Hebrew morphology.
  - Quick check question: What is the difference between morphological segmentation and simple prefix-suffix separation?

- Concept: Subword tokenization
  - Why needed here: Standard subword tokenization methods like WordPiece and BPE are designed for languages like English where words are relatively simple and do not have a lot of morphological complexity. These methods may not work well for morphologically-rich languages like Hebrew where words can have many different forms.
  - Quick check question: How do WordPiece and BPE tokenization differ from morphological segmentation in handling morphologically-rich languages?

- Concept: Named entity recognition (NER)
  - Why needed here: NER is an important task for many applications and is particularly challenging for morphologically-rich languages like Hebrew where named entities often contain prefixes and suffixes. Understanding how different tokenization methods affect NER performance is crucial for building effective language models.
  - Quick check question: Why is NER particularly challenging for morphologically-rich languages like Hebrew?

## Architecture Onboarding

- Component map: Hebrew Wikipedia and HeDC4 corpus -> Tokenizer (WordPiece, Morphological Segmentation, or Prefix-Suffix Separation) -> BERT-based model -> Fine-tuning tasks (NER, QA, WSD, Morphological Parsing, POS Tagging, Dependency Parsing) -> Evaluation metrics (F1 score, EM, Macro F1, Aligned Multiset F1, UAS F1)

- Critical path: 1. Preprocess the data using the chosen tokenization method 2. Pre-train the BERT model on the preprocessed data 3. Fine-tune the pre-trained model on each downstream task 4. Evaluate the fine-tuned model on the test set

- Design tradeoffs:
  - Vocabulary size: Larger vocabularies can help represent rare words better but may lead to overfitting
  - Tokenization method: Morphological segmentation provides more accurate morpheme boundaries but is slower and more error-prone than prefix-suffix separation
  - Pre-training data: Using more data can improve model performance but increases pre-training time and computational cost

- Failure signatures:
  - Low performance on tasks involving rare or unseen words
  - High variance in performance across different tasks
  - Slow inference time due to complex tokenization

- First 3 experiments:
  1. Compare the performance of the baseline WordPiece tokenizer with the Morphological Segmentation tokenizer on NER and Dependency Parsing tasks
  2. Investigate the impact of vocabulary size on model performance by training models with 16K, 32K, and 64K vocabularies
  3. Analyze the types of errors made by each tokenizer on a held-out validation set to identify areas for improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the morphological segmentation method perform when applied to languages with different morphological complexity than Hebrew?
- Basis in paper: [explicit] The paper focuses on Hebrew as a morphologically-rich language, but the proposed methods are claimed to be applicable to other morphologically-rich languages.
- Why unresolved: The study only evaluates the proposed methods on Hebrew, leaving the generalizability to other morphologically-rich languages untested.
- What evidence would resolve it: Applying the proposed tokenization methods to other morphologically-rich languages (e.g., Arabic, Turkish) and comparing their performance to language-agnostic methods on a similar benchmark of tasks.

### Open Question 2
- Question: What is the impact of increasing vocabulary size beyond 64K subwords on the performance of morphologically-driven tokenization methods?
- Basis in paper: [explicit] The paper explores vocabulary sizes of 16K, 32K, and 64K, but suggests that larger vocabularies might further improve performance.
- Why unresolved: The study only tests up to 64K subwords, leaving the potential benefits of even larger vocabularies unexplored.
- What evidence would resolve it: Pre-training models with vocabulary sizes larger than 64K and evaluating their performance on the same benchmark tasks.

### Open Question 3
- Question: How does the computational efficiency of morphologically-driven tokenization methods compare to language-agnostic methods in terms of training time and inference speed?
- Basis in paper: [inferred] The paper introduces morphologically-driven tokenization methods that require additional preprocessing steps (e.g., morphological segmentation), which might impact computational efficiency.
- Why unresolved: The study does not provide a direct comparison of the computational efficiency between morphologically-driven and language-agnostic tokenization methods.
- What evidence would resolve it: Measuring and comparing the training time and inference speed of models using morphologically-driven tokenization methods versus language-agnostic methods on the same hardware.

### Open Question 4
- Question: How do the proposed morphologically-driven tokenization methods handle out-of-vocabulary words in morphologically-rich languages compared to language-agnostic methods?
- Basis in paper: [explicit] The paper claims that morphologically-driven tokenization methods can better handle rare and unseen words through morphological composition, but this is not directly tested.
- Why unresolved: The study does not explicitly evaluate the performance of the proposed methods on out-of-vocabulary words.
- What evidence would resolve it: Creating a test set with rare and unseen words in morphologically-rich languages and comparing the performance of morphologically-driven tokenization methods to language-agnostic methods on this test set.

## Limitations

- The accuracy of the morphological segmentation tools used is not quantitatively validated, introducing uncertainty about whether improvements stem from true morphological knowledge or tool artifacts.
- The experimental design does not definitively distinguish between memorization and generalization when explaining the impact of increased vocabulary size.
- The magnitude and consistency of improvements vary significantly across tasks, with some tasks showing modest or no clear advantage over the baseline.

## Confidence

**High Confidence Claims**:
- Incorporating morphological knowledge through segmentation improves performance on morphologically-rich languages compared to standard tokenization methods.
- Prefix-suffix separation helps with named entity recognition by consistently handling common Hebrew prefixes.
- Increasing vocabulary size generally improves performance, though with potential trade-offs in generalization.

**Medium Confidence Claims**:
- Morphological segmentation provides superior representations compared to prefix-suffix separation.
- The improvements observed are due to the model learning morphological relationships rather than memorization.
- The proposed methods will generalize to other morphologically-rich languages beyond Hebrew.

**Low Confidence Claims**:
- The specific mechanisms by which morphological knowledge improves model performance.
- The optimal vocabulary size for balancing performance and generalization.
- The long-term stability of improvements when scaling to larger datasets or different domains.

## Next Checks

1. **Segmentation Tool Validation**: Conduct a controlled experiment comparing the output of the morphological segmentation tool against human annotations on a held-out dataset. Measure segmentation accuracy and analyze how segmentation errors correlate with model performance degradation.

2. **Vocabulary Size Scaling Study**: Design an experiment that systematically varies vocabulary size while controlling for model capacity (e.g., using model distillation or regularization techniques). Compare performance on rare word subsets and conduct probing tasks to distinguish memorization from generalization.

3. **Cross-Lingual Generalization Test**: Apply the proposed tokenization methods to another morphologically-rich language (e.g., Arabic or Turkish) using the same experimental protocol. Compare performance gains relative to the Hebrew results to assess whether the improvements are language-specific or generalizable across morphologically-rich languages.