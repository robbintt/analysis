---
ver: rpa2
title: 'Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation
  and Dataset Curation'
arxiv_id: '2310.07397'
source_url: https://arxiv.org/abs/2310.07397
tags:
- dialogue
- user
- dataset
- target
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of constructing high-quality
  datasets for personalized target-oriented dialogue systems, where the system proactively
  steers conversations toward predefined targets while incorporating user personalization.
  The authors propose an automatic dataset curation framework using role-playing with
  multiple large language model agents, including a user agent, system agent, and
  moderator agent, each following specific instructions.
---

# Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation

## Quick Facts
- arXiv ID: 2310.07397
- Source URL: https://arxiv.org/abs/2310.07397
- Reference count: 18
- Key outcome: Automatic dataset curation framework using role-playing with LLM agents produces TOPDIAL dataset achieving higher quality and personalization than existing datasets

## Executive Summary
This work addresses the challenge of constructing high-quality datasets for personalized target-oriented dialogue systems, where systems must proactively steer conversations toward predefined targets while incorporating user personalization. The authors propose an automatic dataset curation framework using role-playing with multiple large language model agents to generate synthetic dialogue data without manual annotation. Based on this framework, they construct TOPDIAL, a large-scale dataset containing approximately 18,000 multi-turn dialogues. Automatic and human evaluations demonstrate that TOPDIAL achieves comparable or slightly higher quality than existing datasets across metrics including proactivity, coherence, personalization, and target success rate, with baseline models trained on TOPDIAL significantly outperforming those trained on existing datasets.

## Method Summary
The authors propose an automatic dataset curation framework using role-playing with three LLM agents: a user agent, system agent, and moderator agent. Each agent follows specific instructions and has access to relevant information through prompt engineering. The user agent simulates human users with simulated profiles and personalities, the system agent proactively steers conversations toward predefined targets, and the moderator agent automatically manages conversation termination based on predefined conditions. The framework generates multi-turn dialogues by having agents interact turn-by-turn, with the resulting conversations stored as synthetic training data. The authors construct TOPDIAL using this approach, grounding user profiles and personalities to improve personalization quality, and evaluate the dataset using automatic metrics and human evaluation.

## Key Results
- TOPDIAL achieves comparable or slightly higher quality than existing datasets across proactivity, coherence, personalization, and target success rate metrics
- Baseline models trained on TOPDIAL significantly outperform those trained on existing datasets, particularly in personalization metrics
- Automatic and human evaluations confirm TOPDIAL's effectiveness for training personalized target-oriented dialogue systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using role-playing with multiple LLM agents creates high-quality synthetic dialogue data without manual annotation.
- Mechanism: The framework assigns specific roles (user, system, moderator) to different LLM agents, each with distinct instructions and knowledge grounding. The agents collaborate through turn-based conversation, with the moderator automatically terminating dialogues based on predefined conditions.
- Core assumption: LLM agents can effectively simulate human conversational behaviors when provided with appropriate role instructions and contextual information.
- Evidence anchors:
  - [abstract] "we propose an automatic dataset curation framework using a role-playing approach"
  - [section] "we employ three ChatGPT (gpt-3.5-turbo version) agents as LLM agents for the above roles"
- Break condition: If LLM agents fail to maintain consistent character behavior or if the moderator cannot accurately detect conversation termination conditions, data quality degrades significantly.

### Mechanism 2
- Claim: Grounding user profiles and personalities during dataset curation improves personalization quality.
- Mechanism: The framework simulates user profiles by sampling from existing datasets and generates personality traits based on Big-5 characteristics. This information is incorporated into the user agent's instructions and passed to the system agent, creating conversations that reflect individual user preferences and behavioral patterns.
- Core assumption: Personality and profile information can be effectively simulated and used to guide conversational behavior in synthetic data.
- Evidence anchors:
  - [abstract] "TOPDIAL is more natural and effective in reflecting personalization" by grounding personality information
  - [section] "we collect all user profiles from one chosen dataset and parse them into a profile slot pool"
- Break condition: If simulated profiles don't represent real user distributions or personality traits don't correlate with actual conversational patterns, personalization benefits diminish.

### Mechanism 3
- Claim: Automatic termination conditions ensure dialogues meet target-oriented objectives.
- Mechanism: The moderator agent monitors conversations and terminates them when specific conditions are met: target achievement with user acceptance, repeated user rejection, or maximum turn limits.
- Core assumption: Automated detection of target completion and user acceptance/rejection can be reliably implemented.
- Evidence anchors:
  - [abstract] "The moderator agent is designed to automatically manage the termination of the conversation"
  - [section] "we set certain conditions to terminate the conversation" including target completion and user acceptance
- Break condition: If termination conditions are too strict, dialogues may end prematurely; if too lenient, irrelevant conversations persist in the dataset.

## Foundational Learning

- Concept: Role-based multi-agent simulation
  - Why needed here: This approach enables scalable synthetic data generation without manual annotation, crucial for building large datasets like TOPDIAL with 18K dialogues
  - Quick check question: How does the moderator agent's termination logic prevent both premature ending and runaway conversations?

- Concept: Personality-grounded conversation generation
  - Why needed here: Incorporating user profiles and Big-5 personality traits creates more natural, personalized dialogues that better reflect real user behavior patterns
  - Quick check question: What happens to personalization quality if personality traits are randomly assigned without correlation to conversational preferences?

- Concept: Target-oriented dialogue evaluation metrics
  - Why needed here: Standard evaluation metrics (BLEU, F1 scores, success rates) must be adapted to assess both the proactive steering toward targets and the incorporation of personalization elements
  - Quick check question: How do you distinguish between a dialogue that mentions the target topic versus one that successfully achieves the target dialogue act?

## Architecture Onboarding

- Component map:
  User Profile Sampling -> User Agent Prompt -> System Agent Prompt -> Knowledge Integration -> Conversation Generation -> Moderator Evaluation -> Data Storage

- Critical path: User Profile Sampling → User Agent Prompt → System Agent Prompt → Knowledge Integration → Conversation Generation → Moderator Evaluation → Data Storage

- Design tradeoffs:
  - Sampling vs. Real Profiles: Simulated profiles enable scalability but may lack real-world diversity
  - GPT-3.5-turbo vs. Higher Models: Balances cost and quality for large-scale generation
  - Termination Conditions: Strict conditions ensure quality but may limit natural conversation flow

- Failure signatures:
  - Conversations consistently terminating before meaningful interaction
  - System agent failing to progress toward target despite multiple turns
  - User agent responses lacking coherence with stated personality traits
  - Moderator incorrectly accepting/rejecting conversation termination

- First 3 experiments:
  1. Test moderator termination accuracy with edge cases (partial target achievement, ambiguous acceptance)
  2. Compare personalization quality with and without personality grounding using human evaluation
  3. Validate target achievement rates across different domain knowledge complexities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the dataset curation framework be improved to ensure factual correctness of synthetic dialogues and prevent hallucinations from LLM agents?
- Basis in paper: [explicit] The authors acknowledge that ChatGPT agents may produce hallucinations and intend to improve the process with post-processing steps like fact-checking based on grounded domain knowledge.
- Why unresolved: The paper mentions this as a limitation but does not provide concrete solutions or evaluate their effectiveness.
- What evidence would resolve it: Experimental results comparing dataset quality with and without post-processing steps, along with quantitative measures of hallucination reduction.

### Open Question 2
- Question: Can the moderator agent's performance in determining conversation termination be improved beyond the current rule-based approach?
- Basis in paper: [explicit] The authors note that the moderator agent sometimes struggles to appropriately terminate conversations due to difficulty understanding target achievement, despite detailed instructions and examples.
- Why unresolved: The paper identifies this limitation but does not explore alternative approaches or provide solutions for improving termination accuracy.
- What evidence would resolve it: Comparative results showing improved termination accuracy using different approaches (e.g., learned policies vs. rule-based), along with analysis of false positive/negative termination cases.

### Open Question 3
- Question: How does the dataset curation framework scale to other domains beyond movies, music, food, and POIs?
- Basis in paper: [inferred] While the authors demonstrate the framework on specific domains, they claim it provides insights for building datasets for many other dialogue tasks without validating this claim.
- Why unresolved: The paper does not experiment with or analyze the framework's applicability to different domains or dialogue tasks.
- What evidence would resolve it: Successful construction and evaluation of datasets for at least two different domains/tasks using the same framework, with comparison of quality metrics to the original TOPDIAL dataset.

## Limitations
- The framework's effectiveness depends on LLM agent behavior quality, which may introduce inconsistency or unrealistic dialogues
- Moderator agent termination decisions lack transparent validation metrics, making it unclear whether conversations are appropriately terminated
- Simulated user profiles and Big-5 personality traits are generated rather than collected from real users, raising questions about ecological validity

## Confidence
- **High confidence**: The dataset curation methodology and evaluation framework are clearly described and technically sound
- **Medium confidence**: The claim that TOPDIAL significantly improves personalization in downstream model training is supported by baseline experiments, but comparisons are limited to a small set of models
- **Low confidence**: The assumption that simulated personality traits effectively translate to meaningful conversational differences remains weakly supported

## Next Checks
1. Conduct ablation studies comparing TOPDIAL with and without personality-grounded user profiles to quantify the actual impact of personalization features on downstream task performance across multiple model architectures

2. Implement human evaluation protocols to assess the moderator agent's termination accuracy, measuring false positive/negative rates for both premature termination and failure to terminate unproductive conversations

3. Perform statistical analysis of personality trait distributions in TOPDIAL against real user datasets to validate that the simulated profiles represent genuine human conversational diversity rather than arbitrary patterns