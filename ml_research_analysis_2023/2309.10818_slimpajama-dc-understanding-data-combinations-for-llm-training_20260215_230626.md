---
ver: rpa2
title: 'SlimPajama-DC: Understanding Data Combinations for LLM Training'
arxiv_id: '2309.10818'
source_url: https://arxiv.org/abs/2309.10818
tags:
- training
- data
- slimpj
- dataset
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents SlimPajama-DC, an empirical analysis on the
  effects of data combinations for training large language models (LLMs). The authors
  investigate two key aspects: global vs.'
---

# SlimPajama-DC: Understanding Data Combinations for LLM Training

## Quick Facts
- arXiv ID: 2309.10818
- Source URL: https://arxiv.org/abs/2309.10818
- Reference count: 40
- Key outcome: Global deduplication and increased data diversity after deduplication improve LLM performance

## Executive Summary
This paper presents an empirical analysis of data combination strategies for training large language models using SlimPajama-DC. The authors investigate how global vs. local deduplication and dataset proportions affect model performance, training 1.3B models with Alibi and SwiGLU. They find that global deduplication across sources yields better results than local deduplication, and that increasing data diversity after deduplication is crucial. The best configuration outperforms a 1.3B model trained on RedPajama using the same number of tokens. The findings are extended to a 7B model with large batch-size training using a novel progressive weight decay scheduling strategy.

## Method Summary
The study constructs six data combination configurations from the SlimPajama dataset (627B tokens) and trains individual 1.3B models using Alibi attention and SwiGLU activation functions. Models are evaluated on multiple benchmarks including ARC, HellaSwag, MMLU, and TruthfulQA. A 7B model is trained using large batch sizes with a progressive weight decay scheduling approach. The analysis compares global deduplication (across sources) versus local deduplication (within sources), examining how different data proportions affect model performance and generalization.

## Key Results
- Global deduplication across datasets yields better model performance than local deduplication
- The best configuration outperforms a 1.3B model trained on RedPajama with the same number of tokens
- Increasing data diversity after global deduplication is crucial for improved performance
- Progressive weight decay scheduling helps mitigate overfitting in large batch training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Global deduplication across datasets yields more diverse training signals than local deduplication.
- Mechanism: Removes duplicates that span multiple sources before training, preventing repeated exposure to the same or similar examples across different domains.
- Core assumption: Cross-source overlaps are non-trivial and impair model generalization if not removed.
- Evidence anchors:
  - [abstract] "Global deduplication vs. local deduplication. We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models."
  - [section] "Instead, global deduplication removes duplication within and between each data source...Global deduplication identifies and removes these overlapping instances irrespective of their source."
- Break condition: If cross-source overlap is negligible or deduplication overhead outweighs gains.

### Mechanism 2
- Claim: Increasing data diversity after global deduplication improves LLM performance.
- Mechanism: Combining multiple sources with adjusted proportions ensures balanced representation of domains, reducing domain-specific bias.
- Core assumption: Different domains encode complementary knowledge; diversity improves generalization.
- Evidence anchors:
  - [abstract] "Increasing data diversity is crucial after global deduplication."
  - [section] "A model trained on diverse data is more likely to generalize well across various tasks...Combining a technical dataset with a general news dataset, for example, would allow the model to understand both in-depth technical details and broad general knowledge."
- Break condition: If domain proportions are poorly balanced, diminishing returns from diversity.

### Mechanism 3
- Claim: Progressive weight decay scheduling during large-batch training mitigates overfitting.
- Mechanism: Initially set weight decay to zero for full convergence, then increase to 0.5 to suppress overfitting, and finally settle at 0.1 for stable training.
- Core assumption: Large-batch training introduces overfitting that can be controlled via dynamic regularization.
- Evidence anchors:
  - [section] "We introduce a novel training strategy...whereby the training process is segmented into various stages...In contrast to this, our approach emphasizes the role of weight decay during large model training."
  - [section] "Models that incorporate this early dropout strategy tend to exhibit reduced final training loss compared to models that do not use dropout."
- Break condition: If training dynamics do not stabilize under progressive decay, or if early convergence already generalizes well.

## Foundational Learning

- Concept: Tokenization and subword vocabularies
  - Why needed here: All training uses a 50,277-token GPT-NeoX tokenizer; correct tokenization directly impacts model input quality.
  - Quick check question: What happens if rare tokens are not split properly?

- Concept: Attention mechanisms and positional biases
  - Why needed here: ALiBi applies linear biases to attention scores instead of learned embeddings, enabling extrapolation to longer sequences.
  - Quick check question: How does ALiBi bias differ from sinusoidal positional embeddings?

- Concept: Large-batch training dynamics
  - Why needed here: Large batch sizes speed training but risk overfitting; understanding convergence behavior is critical.
  - Quick check question: What is the generalization gap in large-batch training and why does it occur?

## Architecture Onboarding

- Component map: Tokenizer → Data pipeline → Model (Cerebras-GPT with ALiBi + SwiGLU) → Optimizer (AdamW) → Loss → Metrics
- Critical path: Data preprocessing → Tokenization → Model forward/backward pass → Gradient clipping → Parameter update
- Design tradeoffs:
  - Global vs. local deduplication: higher compute/memory cost vs. better cross-source coverage
  - Large batch size: faster training vs. potential overfitting
  - ALiBi vs. learned positional embeddings: simpler, extrapolatable vs. more expressive
- Failure signatures:
  - Training loss plateaus early: possible overfitting or insufficient diversity
  - High memory usage: excessive deduplication or large batch size
  - Poor downstream performance: imbalanced data proportions or inadequate preprocessing
- First 3 experiments:
  1. Train a small model with only local deduplication vs. global deduplication to compare convergence and generalization.
  2. Vary domain sampling proportions in a 1.3B model to find optimal diversity mix.
  3. Apply progressive weight decay schedule to a 7B model and measure impact on final loss and validation metrics.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between global and local deduplication strategies for multi-source LLM training datasets?
- Basis in paper: [explicit] The paper discusses global deduplication (across different sources) vs. local deduplication (within single sources) and their effects on model performance, finding that global deduplication generally yields better results but requires more memory.
- Why unresolved: The paper shows global deduplication is preferable but doesn't provide a quantitative framework for balancing deduplication strategies based on specific dataset characteristics or resource constraints.
- What evidence would resolve it: Empirical studies comparing various deduplication ratios and strategies across different dataset combinations and hardware configurations, measuring both performance gains and computational costs.

### Open Question 2
- Question: How does dataset composition affect model specialization vs. generalization capabilities in downstream tasks?
- Basis in paper: [explicit] The paper mentions the specialization vs. generalization trade-off when combining specialized datasets, noting that combining many specialized datasets might create a "jack-of-all-trades" model that lacks depth in specific domains.
- Why unresolved: While the paper identifies this trade-off, it doesn't provide systematic analysis of how different dataset combinations affect task-specific performance across various domains.
- What evidence would resolve it: Controlled experiments training models on different dataset compositions and evaluating their performance on both broad and domain-specific benchmarks, with analysis of the specialization-generalization spectrum.

### Open Question 3
- Question: What is the relationship between training loss curves and final model performance across different data combinations?
- Basis in paper: [explicit] The paper presents training loss curves for different data combinations and notes that lower training loss doesn't necessarily correlate with better model performance, with DC-6 having the highest loss but best average accuracy.
- Why unresolved: The paper observes this discrepancy but doesn't provide theoretical explanation for why certain configurations achieve better performance despite higher training loss.
- What evidence would resolve it: Analysis of the loss landscape characteristics for different data combinations, including examination of convergence patterns, gradient dynamics, and generalization gaps.

## Limitations
- Evaluation focused primarily on 1.3B parameter models with one 7B extension, limiting scaling insights
- Analysis relies on specific dataset (SlimPajama) and tokenizer (GPT-NeoX BPE), potentially limiting generalizability
- Does not provide detailed ablation studies on optimal proportions for data diversity

## Confidence

- **High confidence**: The effectiveness of global deduplication over local deduplication for cross-source overlap removal
- **Medium confidence**: The claim that increasing data diversity after deduplication improves LLM performance
- **Medium confidence**: The progressive weight decay scheduling strategy for large-batch training

## Next Checks

1. **Scaling analysis**: Replicate the data combination experiments across multiple model scales (1B, 7B, 13B) to verify whether the observed benefits of global deduplication and data diversity persist or change with model size.

2. **Ablation on diversity proportions**: Systematically vary the sampling proportions of different domain sources within the dataset combinations to identify optimal diversity mixes and quantify diminishing returns.

3. **Cross-dataset validation**: Apply the same data combination and deduplication pipeline to a different multi-source dataset (e.g., combining C4, The Pile, and domain-specific corpora) to test generalizability beyond SlimPajama.