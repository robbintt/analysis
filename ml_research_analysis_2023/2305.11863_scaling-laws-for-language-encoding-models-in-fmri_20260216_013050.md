---
ver: rpa2
title: Scaling laws for language encoding models in fMRI
arxiv_id: '2305.11863'
source_url: https://arxiv.org/abs/2305.11863
tags:
- encoding
- language
- performance
- figure
- brain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores whether scaling transformer-based language
  models improves their ability to predict brain responses to natural language as
  measured by fMRI. Encoding models were built using representations from a range
  of language models (OPT and LLaMA) and speech models (HuBERT, WavLM, Whisper), and
  their performance was measured by correlation with held-out brain responses.
---

# Scaling laws for language encoding models in fMRI

## Quick Facts
- arXiv ID: 2305.11863
- Source URL: https://arxiv.org/abs/2305.11863
- Reference count: 40
- Primary result: Encoding performance scales log-linearly with both model size and fMRI training data size

## Executive Summary
This paper investigates how scaling transformer-based language and speech models affects their ability to predict brain responses to natural language as measured by fMRI. The authors systematically test encoding models built from representations of language models (OPT and LLaMA) and speech models (HuBERT, WavLM, Whisper) across a wide range of model sizes and training data amounts. Results demonstrate that both model size and fMRI training data scale log-linearly with encoding performance, with similar gains observed across different model types. The findings suggest that current large models are approaching optimal performance for several brain areas, and that further scaling in both models and data will yield increasingly effective models of language processing in the brain.

## Method Summary
The authors extracted hidden states from transformer-based language models (OPT, LLaMA) and speech models (HuBERT, WavLM, Whisper) across multiple size scales. These representations were temporally aligned with fMRI time series data from subjects listening to English language podcast stories using Lanczos interpolation. Voxelwise ridge regression models were trained to predict brain responses, and performance was evaluated using correlation with held-out data. Stacked regression was employed to combine semantic and acoustic model predictions. Noise ceiling analysis was performed to estimate the theoretical maximum achievable correlation for each voxel.

## Key Results
- Encoding performance scales log-linearly with model size (~15% improvement from 125M to 30B parameters)
- Performance also scales log-linearly with fMRI training data size (122% improvement per order of magnitude increase)
- Stacked regression combining semantic and acoustic models improves performance in auditory cortex and mouth motor cortex
- Noise ceiling analysis suggests current models approach optimal performance for several brain areas including precuneus and higher auditory cortex

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Larger language models capture richer linguistic features that align better with brain representations.
- Mechanism: As model size increases, the internal representations span a broader and deeper space of linguistic information, including syntax, semantics, and context, which are reflected in brain activity during language comprehension.
- Core assumption: Brain responses to language are governed by similar computational principles as those learned by large language models.
- Evidence anchors:
  - [abstract]: "Representations from transformer-based unidirectional language models are known to be effective at predicting brain responses to natural language."
  - [section]: "The human brain is the quintessential language processing system, but there is still much to learn about how it processes and represents language."
  - [corpus]: Found 25 related papers. Average neighbor FMR=0.45, average citations=0.0.
- Break condition: If brain language processing mechanisms differ fundamentally from those learned by transformers, scaling will not yield improvements.

### Mechanism 2
- Claim: Scaling the size of fMRI training data improves encoding model performance.
- Mechanism: Larger datasets provide more examples of the relationship between language stimuli and brain responses, allowing encoding models to generalize better and capture finer-grained patterns.
- Core assumption: The relationship between language and brain responses is stable and can be learned from more data.
- Evidence anchors:
  - [abstract]: "Similar log-linear behavior was observed when scaling the size of the fMRI training set."
  - [section]: "Encoding performance for both model types scales log-linearly with the amount of fMRI training data from each subject."
  - [corpus]: Found 25 related papers. Average neighbor FMR=0.45, average citations=0.0.
- Break condition: If the relationship between language and brain responses is highly variable across individuals or sessions, more data will not help.

### Mechanism 3
- Claim: Combining semantic and acoustic models via stacked regression improves encoding performance in auditory regions.
- Mechanism: Acoustic models capture lower-level speech features that complement semantic models, and stacked regression optimally weights these contributions for each voxel.
- Core assumption: Different brain regions process language using distinct feature sets that can be captured by different model types.
- Evidence anchors:
  - [section]: "We used stacked regression... to augment our best semantic model with the Whisper speech model representations... We observe that these benefits are highly localized to auditory cortex and mouth motor cortex."
  - [corpus]: Found 25 related papers. Average neighbor FMR=0.45, average citations=0.0.
- Break condition: If auditory and semantic processing are not sufficiently distinct, the stacked approach will not yield gains.

## Foundational Learning

- Concept: Scaling laws in neural networks
  - Why needed here: Understanding how performance scales with model size and data is central to the paper's findings.
  - Quick check question: What is the relationship between model size and performance according to scaling laws?

- Concept: fMRI signal processing and noise ceiling
  - Why needed here: The paper estimates how close models are to optimal performance using noise ceiling analysis.
  - Quick check question: How is the noise ceiling estimated in fMRI encoding studies?

- Concept: Transformer architecture and self-supervised learning
  - Why needed here: The paper uses transformer-based models and speech models trained with self-supervised learning.
  - Quick check question: What is the key difference between encoder and decoder transformers?

## Architecture Onboarding

- Component map:
  - Language models (OPT, LLaMA) -> Hidden state extraction -> Temporal alignment -> Ridge regression -> Voxel predictions
  - Speech models (HuBERT, WavLM, Whisper) -> Audio feature extraction -> Temporal alignment -> Ridge regression -> Voxel predictions
  - Stacked regression module -> Combines semantic and acoustic predictions

- Critical path:
  1. Extract hidden states from large language or speech models
  2. Align extracted features with fMRI time series using Lanczos interpolation
  3. Train voxelwise ridge regression models
  4. Evaluate performance using correlation with held-out data

- Design tradeoffs:
  - Single-layer vs multi-layer encoding models (memory constraints vs information capture)
  - Static vs dynamic context windows for hidden state extraction (efficiency vs completeness)
  - Semantic vs acoustic models (complementary strengths in different brain regions)

- Failure signatures:
  - Poor performance in early auditory cortex may indicate insufficient acoustic modeling
  - Plateauing performance may indicate model capacity saturation or data limitations
  - High variance in voxel predictions may indicate poor temporal alignment or noise

- First 3 experiments:
  1. Replicate scaling results with a smaller language model family to verify log-linear relationship
  2. Test effect of training data size using OPT-125M on varying amounts of fMRI data
  3. Implement stacked regression with a subset of models to verify improvements in auditory cortex

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do the largest models (30B+ parameters) show a plateau in encoding performance while smaller models continue to improve with scale?
- Basis in paper: [explicit] The paper notes that log-linear scaling of encoding performance with model size tapers off for models with more than 30 billion parameters, hypothesizing this is due to information being spread across more layers.
- Why unresolved: The paper only provides a hypothesis about layer depth distribution without testing alternative explanations or directly measuring information concentration across layers.
- What evidence would resolve it: Experiments comparing single-layer vs. multi-layer encoding models across different model sizes, or measuring information concentration metrics across layers, would clarify whether layer depth or other factors cause the plateau.

### Open Question 2
- Question: What specific linguistic or acoustic features in the later layers of Whisper models contribute to their superior performance in auditory cortex compared to language models?
- Basis in paper: [explicit] The paper observes that Whisper's upper-middle and uppermost layers perform best, with improvements localized to auditory cortex when combined with semantic models.
- Why unresolved: The paper identifies performance patterns but doesn't analyze what specific features these layers capture or why they're particularly effective for auditory processing.
- What evidence would resolve it: Feature importance analysis or ablation studies on Whisper layers, comparing their representations to known acoustic/phonetic features, would reveal which aspects drive the performance gains.

### Open Question 3
- Question: How does the optimal balance between model size and training data size vary across different brain regions or cognitive functions?
- Basis in paper: [inferred] The paper shows different scaling behaviors and noise ceiling values across brain areas like precuneus, auditory cortex, and angular gyrus, suggesting region-specific optimization needs.
- Why unresolved: The analysis treats brain regions uniformly in scaling experiments, without examining whether different areas benefit differently from model/data scaling trade-offs.
- What evidence would resolve it: Region-specific scaling experiments varying both model and data size independently for different brain areas would reveal optimal resource allocation strategies for different cognitive functions.

## Limitations
- Individual Differences: Study uses data from only 3 subjects, limiting generalizability
- Temporal Alignment Assumptions: Lanczos interpolation assumes perfect alignment between stimulus and brain responses
- Model-Behavior Correspondence: Cannot definitively prove larger models capture more brain-like representations versus memorizing patterns

## Confidence

**High Confidence** (Based on robust methodology and clear statistical patterns):
- Log-linear scaling relationship between model size and encoding performance
- Log-linear scaling relationship between fMRI training data size and encoding performance
- Noise ceiling analysis suggesting current models approach optimal performance for certain brain regions

**Medium Confidence** (Based on reasonable methodology but limited sample size):
- Stacked regression improvements in auditory cortex
- Localization of benefits to specific brain regions
- Relative performance differences between language and speech models

**Low Confidence** (Based on limited evidence or assumptions):
- Claims about biological plausibility of scaling relationships
- Predictions about future scaling behavior beyond tested ranges
- Interpretation of noise ceiling as true representational limits

## Next Checks

1. **Cross-Subject Generalization**: Test whether encoding models trained on one subject generalize to others, measuring performance drop as a function of inter-subject variability.

2. **Temporal Alignment Sensitivity**: Systematically vary the temporal alignment parameters (Â±2 seconds) to quantify robustness to misalignment and identify optimal alignment windows.

3. **Alternative Scaling Laws**: Fit alternative scaling relationships (power law, exponential) to determine whether log-linear is truly optimal, and test for deviations at different scale ranges.