---
ver: rpa2
title: Large Language Models Are Zero-Shot Time Series Forecasters
arxiv_id: '2310.07820'
source_url: https://arxiv.org/abs/2310.07820
tags:
- series
- time
- which
- data
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using large language models (LLMs) for zero-shot
  time series forecasting by encoding numerical values as text and framing forecasting
  as next-token prediction. Key innovations include careful tokenization strategies
  and converting LLM discrete distributions into flexible continuous densities.
---

# Large Language Models Are Zero-Shot Time Series Forecasters

## Quick Facts
- arXiv ID: 2310.07820
- Source URL: https://arxiv.org/abs/2310.07820
- Authors: 
- Reference count: 40
- Primary result: LLMs can forecast time series zero-shot by encoding numbers as text, outperforming purpose-built models without training

## Executive Summary
This paper introduces a novel approach to time series forecasting using large language models (LLMs) by encoding numerical values as text and framing forecasting as next-token prediction. The method leverages LLMs' biases for simplicity and repetition, which align well with common time series patterns like seasonality. Through careful tokenization strategies and conversion of discrete token distributions to continuous densities, the approach achieves competitive or superior performance compared to purpose-built time series models across diverse benchmarks, all without any training on time series data.

## Method Summary
The method encodes time series data as strings of numerical digits, treating forecasting as next-token prediction in text. Values are scaled and converted to space-separated digit sequences (e.g., "1 2 3 , 4 5 6"), then input to LLMs like GPT-3 or LLaMA-2 for sampling. Discrete token distributions are converted to continuous densities by placing uniform distributions in each digit bin. The approach uses temperature scaling, logit bias, and nucleus sampling to control generation, and evaluates forecasts using metrics like MAE, NLL, and CRPS. The method is zero-shot, requiring no training or fine-tuning on time series data.

## Key Results
- LLMs outperform or match purpose-built time series models on diverse benchmarks without any training
- Performance scales with model size and benefits from LLMs' biases for simplicity and repetition
- The approach naturally handles missing data and can incorporate side information
- GPT-style tokenization generally outperforms LLaMA-style for time series forecasting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can forecast time series by treating them as sequences of text, using next-token prediction
- Mechanism: By encoding time series values as digit tokens and framing forecasting as next-token prediction, LLMs can extrapolate patterns without task-specific training
- Core assumption: The structure of time series data can be preserved and leveraged when represented as text sequences
- Evidence anchors:
  - [abstract] "By encoding time series as a string of numerical digits, we can frame time series forecasting as next-token prediction in text."
  - [section] "At its core, this method represents the time series as a string of numerical digits, and views time series forecasting as next-token prediction in text."
  - [corpus] Found 25 related papers; average neighbor FMR=0.449. Weak evidence of mechanism validation from peer works.
- Break Condition: If tokenization breaks the numeric structure or if the LLM cannot generalize from text patterns to numerical forecasting, performance degrades.

### Mechanism 2
- Claim: The ability of LLMs to represent multimodal distributions enables flexible modeling of time series uncertainty
- Mechanism: By placing a uniform distribution in each discrete bucket of the tokenized space, LLMs can express continuous densities over numerical values
- Core assumption: The discrete token probabilities can be converted into a continuous density function that accurately reflects uncertainty in the data
- Evidence anchors:
  - [abstract] "we propose procedures for effectively tokenizing time series data and converting discrete distributions over tokens into highly flexible densities over continuous values."
  - [section] "we can easily adapt it to provide a continuous density by placing a uniform distribution in each bin."
  - [corpus] Weak evidence; most corpus papers focus on prompting rather than density modeling.
- Break Condition: If the underlying distribution is too complex for the discrete approximation, or if the conversion to continuous density is inaccurate.

### Mechanism 3
- Claim: LLMs have biases for simplicity and repetition, which align well with common time series patterns like seasonality
- Mechanism: The inductive biases learned during language model pretraining favor simple, repetitive patterns, which correspond to trends and periodicities in time series
- Core assumption: The patterns learned from text data (simplicity, repetition) are transferable to numerical time series data
- Evidence anchors:
  - [abstract] "biases for simplicity, and repetition, which align with the salient features in many time series, such as repeated seasonal trends."
  - [section] "LLMs can forecast effectively because they prefer completions derived from simple rules, adopting a form of Occam’s razor prior."
  - [corpus] Some evidence from related work on LLM biases, but limited specific to time series.
- Break Condition: If time series data is highly complex or non-repetitive, the simplicity bias may lead to poor performance.

## Foundational Learning

- Concept: Tokenization strategies for numerical data
  - Why needed here: Proper tokenization is crucial for preserving the structure of numerical values and enabling the LLM to learn meaningful patterns
  - Quick check question: How does separating digits with spaces affect the tokenization of numbers in GPT models versus LLaMA models?

- Concept: Conversion of discrete distributions to continuous densities
  - Why needed here: To accurately model uncertainty and evaluate probabilistic forecasts, the discrete token probabilities must be adapted to continuous densities
  - Quick check question: How does placing a uniform distribution in each bin enable the representation of continuous densities over numerical values?

- Concept: Bias towards simplicity and repetition in LLMs
  - Why needed here: Understanding the inductive biases of LLMs helps explain their effectiveness in forecasting time series with common patterns like seasonality and trends
  - Quick check question: How do the biases for simplicity and repetition in LLMs align with the salient features of many time series datasets?

## Architecture Onboarding

- Component map: Data preprocessing -> LLM inference -> Density conversion -> Evaluation
- Critical path: 1. Preprocess time series data (scaling and tokenization) 2. Encode data as text and input to LLM 3. Sample from LLM to generate forecasts 4. Convert discrete distributions to continuous densities 5. Evaluate forecasts using appropriate metrics
- Design tradeoffs:
  - Tokenization strategy: Balancing between preserving numeric structure and fitting within the LLM's context window
  - Sampling parameters: Trade-off between diversity of samples and faithfulness to the LLM's predictions
  - Density conversion: Choosing the appropriate method for converting discrete distributions to continuous densities
- Failure signatures:
  - Poor tokenization leading to nonsensical forecasts
  - Inability to capture complex patterns or multimodality in the data
  - Overconfident or poorly calibrated uncertainty estimates
- First 3 experiments:
  1. Test different tokenization strategies on a simple time series dataset and evaluate their impact on forecast accuracy
  2. Compare the performance of LLMs with different sizes and architectures on a benchmark time series dataset
  3. Investigate the effect of density conversion methods on the quality of uncertainty estimates in probabilistic forecasts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the performance characteristics of LLMTIME change when applied to multivariate time series data with high dimensionality (e.g., 100+ variables)?
- Basis in paper: [inferred] The paper mentions that multivariate problems pose a challenge due to context window limitations and suggests future research combining LLMTIME with recent advances in LLM context windows.
- Why unresolved: The paper only briefly mentions this challenge without exploring it experimentally or proposing concrete solutions for high-dimensional multivariate forecasting.
- What evidence would resolve it: Experimental results showing LLMTIME performance on multivariate datasets with varying numbers of variables, comparison with specialized multivariate forecasting methods, and analysis of how performance degrades with increasing dimensionality.

### Open Question 2
- Question: What is the precise relationship between LLM reasoning capabilities (as measured by MMLU) and time series forecasting performance, and does this relationship hold across different types of time series patterns?
- Basis in paper: [explicit] The paper shows a correlation between MMLU accuracy and forecasting performance for base models, but this relationship breaks down for chat models like GPT-4.
- Why unresolved: The paper doesn't explore whether this relationship holds for different types of time series patterns (e.g., seasonal vs. trending vs. stochastic) or whether certain patterns benefit more from reasoning capabilities.
- What evidence would resolve it: Detailed analysis of forecasting performance across different MMLU score ranges, broken down by time series pattern types, and experiments with models specifically fine-tuned for reasoning vs. general capabilities.

### Open Question 3
- Question: How does the tokenization strategy affect LLMTIME's ability to learn and extrapolate complex numerical patterns, and can alternative tokenization methods improve performance?
- Basis in paper: [explicit] The paper discusses the importance of tokenization and shows that GPT-4's altered tokenization leads to worse performance, but doesn't explore alternative tokenization strategies beyond the digit-spacing approach.
- Why unresolved: The paper doesn't investigate whether other tokenization methods (e.g., scientific notation, base-N encoding, or learned tokenization) could better capture numerical patterns or handle larger ranges of values.
- What evidence would resolve it: Comparative experiments testing multiple tokenization strategies on the same forecasting tasks, analysis of which strategies work best for different types of numerical patterns, and evaluation of how tokenization affects the model's ability to learn arithmetic operations.

## Limitations

- The approach struggles with complex, non-repetitive time series patterns where simplicity bias may lead to underfitting
- Performance is highly sensitive to preprocessing hyperparameters (scaling factors α and β) which were tuned per dataset
- No universal tokenization strategy exists - GPT-style works better for some datasets while LLaMA-style is superior for others

## Confidence

**High Confidence:** The core premise that LLMs can perform zero-shot time series forecasting by treating numerical data as text sequences is well-supported by experimental results across multiple benchmarks.

**Medium Confidence:** The claim about LLMs' biases for simplicity and repetition aligning with time series patterns is supported by qualitative reasoning and some empirical evidence.

**Low Confidence:** The effectiveness of the density conversion procedure for representing complex continuous distributions from discrete token probabilities needs further validation.

## Next Checks

1. **Cross-model tokenization robustness:** Systematically compare GPT-style versus LLaMA-style tokenization across all benchmark datasets to identify which approach works best for different time series characteristics.

2. **Density approximation accuracy:** Design experiments to quantify the error introduced by converting discrete token distributions to continuous densities, particularly for multimodal and skewed distributions.

3. **Generalization to noisy and irregular patterns:** Test the approach on synthetic time series with varying levels of complexity, noise, and non-repetitive patterns to characterize the limits of the simplicity bias.