---
ver: rpa2
title: 'A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove
  and Reconstruct (DoRaR)'
arxiv_id: '2310.17945'
source_url: https://arxiv.org/abs/2310.17945
tags:
- feature
- attribution
- features
- methods
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of interpreting deep neural
  network decisions by proposing a novel feature attribution method called Double-sided
  Remove and Reconstruct (DoRaR). The authors tackle two main problems in existing
  methods: artifacts (out-of-distribution masked inputs) and EPITE (encoding prediction
  in the explanation).'
---

# A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove and Reconstruct (DoRaR)

## Quick Facts
- **arXiv ID**: 2310.17945
- **Source URL**: https://arxiv.org/abs/2310.17945
- **Reference count**: 40
- **Key outcome**: DoRaR outperforms state-of-the-art methods on MNIST, CIFAR-10, and synthetic datasets by achieving higher prediction accuracy with selected features and lower accuracy with non-selected features.

## Executive Summary
This paper introduces the Double-sided Remove and Reconstruct (DoRaR) method, a novel feature attribution technique designed to interpret deep neural network decisions. DoRaR addresses two major limitations of existing methods: artifacts (out-of-distribution masked inputs) and EPITE (encoding prediction in the explanation). By training a feature selector alongside generative models to reconstruct samples from both selected and non-selected features, DoRaR achieves more reliable and comprehensive feature attributions. The method is evaluated on MNIST, CIFAR-10, and a synthetic mouse behavior dataset, demonstrating superior performance compared to state-of-the-art methods.

## Method Summary
DoRaR is a feature attribution method that trains a feature selector to identify important explanation units while using generative models to reconstruct samples from both selected and non-selected features. The method addresses the artifacts problem by reconstructing masked inputs using generative models instead of directly feeding them into the classifier. It mitigates the EPITE problem by evaluating both selected and non-selected features' prediction accuracies. Background noise sampled from the empirical data distribution is used to fill non-selected areas, minimizing information leakage through the mask. The feature selector is trained to minimize prediction and reconstruction losses for selected features while maximizing losses for non-selected features.

## Key Results
- On MNIST with 4 chunks, DoRaR achieves 81.30% accuracy for selected features and 88.18% for non-selected features, outperforming other methods.
- DoRaR demonstrates better performance in identifying ground truth explanations in the synthetic mouse behavior dataset.
- The method consistently shows higher prediction accuracy with selected features and lower accuracy with non-selected features compared to state-of-the-art methods.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The DoRaR method avoids the artifacts problem by reconstructing masked inputs using generative models instead of directly feeding them into the pre-trained classifier.
- Mechanism: When a feature selector identifies important features, the remaining features are replaced with background noise