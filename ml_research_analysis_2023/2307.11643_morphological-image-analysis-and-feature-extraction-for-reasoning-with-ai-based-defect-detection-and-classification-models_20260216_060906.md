---
ver: rpa2
title: Morphological Image Analysis and Feature Extraction for Reasoning with AI-based
  Defect Detection and Classification Models
arxiv_id: '2307.11643'
source_url: https://arxiv.org/abs/2307.11643
tags:
- defect
- reasoning
- ai-reasoner
- defchar
- defects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the AI-Reasoner, a novel system for extracting
  and analysing morphological characteristics of defects (DefChars) from images to
  provide transparent reasoning behind predictions made by AI-based defect detection
  and classification models. The AI-Reasoner extracts 38 DefChars from images, including
  colour, shape, and meta characteristics, and uses decision trees to reason with
  these values.
---

# Morphological Image Analysis and Feature Extraction for Reasoning with AI-based Defect Detection and Classification Models

## Quick Facts
- arXiv ID: 2307.11643
- Source URL: https://arxiv.org/abs/2307.11643
- Reference count: 24
- One-line primary result: Introduces AI-Reasoner system that achieves 100% learning score for explaining defect detection model outputs using morphological image analysis

## Executive Summary
This paper presents the AI-Reasoner, a system for extracting and analyzing morphological characteristics of defects from images to provide transparent reasoning behind predictions made by AI-based defect detection and classification models. The system extracts 38 defect characteristics (DefChars) from images, including color, shape, and meta information, and uses decision trees to reason with these values. When tested on explaining the outputs of an IE Mask R-CNN model using a set of 366 defect images, the AI-Reasoner achieved a 100% learning score and successfully identified reasons for undetected and misclassified defects. The results demonstrate the effectiveness of the AI-Reasoner in improving the transparency and trustworthiness of AI models in industrial applications requiring defect analysis.

## Method Summary
The AI-Reasoner system extracts 38 morphological defect characteristics (DefChars) from defect images, including color (HSV values), shape (polygon metrics), and meta characteristics (size, neighbor distance). These features are scaled and used to construct reasoning target vectors based on detection and classification correctness. An ensemble of 200 decision trees with infinite depth, small splits (2), and small leaves (1) is trained on the DefChar matrix and reasoning targets. The system then analyzes tree node importance to generate charts and textual explanations, suggesting mitigation strategies to improve model performance.

## Key Results
- Achieved 100% learning score on 366 defect images from wind turbine blade dataset
- Successfully identified reasons for undetected and misclassified defects
- Suggested effective mitigation strategies including greyscaling to reduce misclassifications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The AI-Reasoner achieves 100% learning score by using an ensemble of 200 decision trees with infinite depth, small splits (2), and small leaves (1), trained on the DefChar matrix and reasoning target vector.
- Mechanism: Decision trees recursively split the feature space based on DefChar values to isolate defects that were misclassified or undetected, creating interpretable paths that map morphological features to prediction errors.
- Core assumption: Decision trees can fully partition the DefChar space to perfectly separate true positives from false negatives or misclassifications when given sufficient depth and minimal stopping criteria.
- Evidence anchors:
  - [abstract]: "The AI-Reasoner achieved a 100% learning score and successfully identified reasons for undetected and misclassified defects."
  - [section II-D]: "200 DTs are created with the untrimmed setting (i.e. max depth = infinite, min split = 2 and min leaf = 1)"
- Break condition: If the DefChar space is not linearly separable by decision boundaries, or if overfitting occurs due to infinite depth, the learning score will degrade.

### Mechanism 2
- Claim: DefChars provide sufficient discriminative power to explain Mask R-CNN model failures by encoding color, shape, and meta information about defects.
- Mechanism: Color characteristics (HSV values) capture perceptual differences; shape characteristics (polygon-based metrics) encode irregularity; meta characteristics (size, neighbor distance) provide contextual severity, enabling trees to isolate prediction failures.
- Core assumption: The 38 DefChars span the relevant feature space needed to distinguish between correct and incorrect Mask R-CNN predictions.
- Evidence anchors:
  - [section II-C]: Lists all 38 DefChars grouped into color, shape, and meta categories.
  - [section IV-A]: "The AI-Reasoner achieved the highest learning score of 100% when using all DefChars"
- Break condition: If critical defect features are missing from DefChars (e.g., texture patterns), the reasoning will be incomplete.

### Mechanism 3
- Claim: The AI-Reasoner generates actionable mitigation strategies by analyzing decision scores, distinguish scores, and node importance indices across the ensemble.
- Mechanism: For each DefChar, the system computes importance indices that reflect its contribution to splitting reasoning targets; charts and textual explanations highlight which DefChar ranges correlate with prediction errors, guiding pre-processing improvements.
- Core assumption: The decision and distinguish scores accurately reflect the DefChar's influence on model errors and can be translated into meaningful mitigation advice.
- Evidence anchors:
  - [section II-D]: Defines DS, TS, IDX, and explains their use in quantifying node importance.
  - [section IV-B]: "Based on these findings, the AI-Reasoner suggests the following mitigation strategies: Greyscaling the defects may reduce misclassified but increase the undetected cases."
- Break condition: If the statistical measures do not correlate with actual model behavior, the suggested strategies will be ineffective.

## Foundational Learning

- Concept: Decision Trees and Ensemble Methods
  - Why needed here: The AI-Reasoner uses an ensemble of decision trees to reason with model outputs; understanding how trees split on features and how ensembles improve stability is essential.
  - Quick check question: What is the difference between a single decision tree and a random forest in terms of variance and bias?

- Concept: Morphological Image Analysis
  - Why needed here: DefChars are extracted from defect images using morphological features; knowledge of HSV color space, polygon metrics, and bounding box analysis is required.
  - Quick check question: How does converting RGB to HSV help in capturing color complexity differences between defect and background areas?

- Concept: Intersection over Union (IoU) and Matching in Object Detection
  - Why needed here: The paper assumes each predicted defect can be matched to at most one true defect using IoU; understanding this matching is key to defining reasoning targets.
  - Quick check question: What IoU threshold would you use to decide if a predicted defect matches a ground truth defect?

## Architecture Onboarding

- Component map: Mask R-CNN -> Feature Extraction -> AI Reasoning (Decision Trees) -> Output Generation

- Critical path:
  1. Run Mask R-CNN on dataset to get predicted masks and labels
  2. Extract DefChars from images and ground truth/predicted masks
  3. Construct reasoning target vectors based on detection/classification correctness
  4. Train ensemble of 200 decision trees on DefChar matrix and reasoning targets
  5. Analyze tree nodes to generate importance scores and value ranges
  6. Produce charts and textual explanations with mitigation strategies

- Design tradeoffs:
  - Using infinite tree depth maximizes learning score but risks overfitting to training data
  - Including all 38 DefChars ensures completeness but increases computational cost
  - Providing detailed mitigation strategies adds value but requires accurate interpretation of feature importance

- Failure signatures:
  - Learning score < 100% indicates incomplete partitioning of DefChar space
  - Inconsistent mitigation strategies with experimental results suggest flawed importance scoring
  - Charts showing uniform importance across DefChars indicate lack of discriminative power

- First 3 experiments:
  1. Run AI-Reasoner on a small subset of 10 defects with known prediction errors to verify chart generation and textual explanations
  2. Test different DT parameter combinations (depth, min split, min leaf) on the full dataset to confirm optimal settings from Table V
  3. Apply suggested mitigation strategies (e.g., greyscaling) to the dataset and retrain Mask R-CNN to verify performance improvements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed DefChars perform when applied to different defect types or industries beyond wind turbine blade defects?
- Basis in paper: [explicit] The paper demonstrates the AI-Reasoner on wind turbine blade defects and suggests future work with additional datasets.
- Why unresolved: The paper only evaluates the DefChars and AI-Reasoner on a single dataset of wind turbine blade defects, leaving their generalizability to other defect types or industries untested.
- What evidence would resolve it: Testing the AI-Reasoner with diverse defect datasets from various industries (e.g., automotive, aerospace, electronics) and comparing performance metrics across these applications.

### Open Question 2
- Question: Can the AI-Reasoner's performance be further improved by incorporating additional feature extraction techniques or more advanced machine learning models?
- Basis in paper: [inferred] The paper uses decision trees and a fixed set of 38 DefChars, suggesting potential for enhancement with more sophisticated methods.
- Why unresolved: The current implementation uses relatively basic machine learning techniques and a predefined feature set, without exploring alternative or more advanced approaches.
- What evidence would resolve it: Comparative studies using different feature extraction methods (e.g., deep learning-based features) and alternative reasoning models (e.g., random forests, gradient boosting) to benchmark against the current AI-Reasoner performance.

### Open Question 3
- Question: How does the AI-Reasoner's explanation quality and utility compare to other XAI methods when evaluated by domain experts?
- Basis in paper: [explicit] The paper mentions that the AI-Reasoner provides charts, textual explanations, and mitigation strategies, and briefly compares it to SHAP, but does not include user studies with domain experts.
- Why unresolved: The paper focuses on technical performance metrics but does not assess the practical usefulness or interpretability of its explanations from the perspective of end-users or domain experts.
- What evidence would resolve it: User studies where domain experts evaluate and compare the AI-Reasoner's explanations against other XAI methods in terms of clarity, usefulness, and impact on decision-making.

## Limitations

- Perfect 100% learning score achieved through infinite tree depth may indicate overfitting rather than true generalization capability
- DefChar feature set, while comprehensive, relies on polygon-based representations that may miss complex texture patterns critical for defect identification
- System effectiveness depends heavily on accurate IoU-based matching between predicted and ground truth defects, with no discussion of matching failures

## Confidence

- Decision tree reasoning mechanism: Medium (perfect training score but potential overfitting)
- DefChar feature sufficiency: Medium (comprehensive but limited to morphological patterns)
- Mitigation strategy effectiveness: Low (suggested based on statistical analysis without empirical validation)

## Next Checks

1. Test AI-Reasoner on an independent defect dataset to evaluate generalization performance and identify overfitting.
2. Compare DefChar-based reasoning with alternative feature extraction methods (e.g., texture analysis, deep features) to assess completeness.
3. Implement and experimentally validate suggested mitigation strategies on the original dataset to confirm their practical effectiveness.