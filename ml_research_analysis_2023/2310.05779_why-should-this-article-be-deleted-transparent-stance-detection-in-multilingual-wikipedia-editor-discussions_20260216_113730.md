---
ver: rpa2
title: Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual
  Wikipedia Editor Discussions
arxiv_id: '2310.05779'
source_url: https://arxiv.org/abs/2310.05779
tags:
- dataset
- stance
- policies
- wikipedia
- policy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the need for transparent content moderation
  by focusing on stance detection in multilingual Wikipedia deletion discussions.
  The authors construct a novel multilingual dataset of editor discussions in English,
  German, and Turkish, containing stance labels (keep, delete, merge, comment) and
  corresponding policies as justifications.
---

# Why Should This Article Be Deleted? Transparent Stance Detection in Multilingual Wikipedia Editor Discussions

## Quick Facts
- arXiv ID: 2310.05779
- Source URL: https://arxiv.org/abs/2310.05779
- Reference count: 14
- Primary result: Multi-task learning improves stance and policy prediction in multilingual Wikipedia deletion discussions, with particular benefits for low-resource languages.

## Executive Summary
This paper addresses transparent content moderation by developing stance detection models for multilingual Wikipedia deletion discussions. The authors construct a novel dataset covering English, German, and Turkish discussions, labeling both editor stances (keep, delete, merge, comment) and the Wikipedia policies justifying those stances. They propose a multi-task learning approach that jointly predicts stance and policy, demonstrating improved performance especially for low-resource scenarios like Turkish. The work provides both practical tools for content moderation and insights into the relationship between stance and policy reasoning across languages.

## Method Summary
The authors construct a multilingual dataset from Wikipedia deletion discussions, extracting comments, article topics, stances, and referenced policies. They implement a multi-task learning framework using transformer models (BERT, mBERT, XLM-R) with hard parameter sharing to jointly predict stance and policy. The model alternates between tasks using a 3:1 loss ratio favoring stance detection. To improve low-resource performance, they leverage multilingual policy alignment across languages. The system is evaluated on English, German, and Turkish test sets using F1-macro for stance detection and accuracy for policy prediction.

## Key Results
- Multi-task learning improves performance over single-task baselines for both stance detection and policy prediction
- Multilingual policy alignment particularly benefits Turkish, improving both stance detection and policy prediction
- Joint prediction achieves high accuracy in identifying both editor stance and the corresponding Wikipedia policy justification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Joint prediction of stance and policy improves accuracy, especially for low-resource languages like Turkish.
- Mechanism: Multi-task learning with hard parameter sharing allows the model to leverage label information across both tasks, improving generalization.
- Core assumption: Stance and policy prediction share relevant underlying features that can be jointly learned.
- Evidence anchors:
  - [abstract]: "We demonstrate that stance and corresponding reason (policy) can be predicted jointly with a high degree of accuracy, adding transparency to the decision-making process."
  - [section]: "We find that the task is feasible and can score comparable scores to the single task model, see multi-task results in Table 4 and 3. In Turkish, the performance improves compared to the single task setup for stance detection."
  - [corpus]: "Average neighbor FMR=0.475" - indicates moderate similarity to related content moderation work, supporting relevance of joint prediction approach.
- Break condition: If the shared parameters become too specialized for one task, harming the other task's performance.

### Mechanism 2
- Claim: Multilingual policy alignment improves performance for lower-resource languages.
- Mechanism: Leveraging aligned policies across languages allows models to learn from higher-resource languages (English) and transfer knowledge to lower-resource ones (Turkish).
- Core assumption: Policies across languages have meaningful semantic overlap that can be exploited for knowledge transfer.
- Evidence anchors:
  - [abstract]: "Additionally, leveraging multilingual alignment of policies further enhances performance for Turkish."
  - [section]: "For Turkish, both stance detection and policy prediction improve, see Table 3 and Table 3 in column multilingual single task. Especially the better policy prediction results point towards the fact that for the Turkish test set, the model can leverage information from the other languages."
  - [corpus]: "Multilingual Content Moderation: A Case Study on Reddit" - related work suggests multilingual approaches are valuable for content moderation.
- Break condition: If policies are not meaningfully aligned across languages, the multilingual approach provides no benefit.

### Mechanism 3
- Claim: Removing explicit policy mentions from comments allows the model to learn implicit policy references.
- Mechanism: By masking policy mentions, the model must infer which policy is being referenced based on context, improving generalization.
- Core assumption: Editors often reference policies implicitly through context rather than explicit mentions.
- Evidence anchors:
  - [abstract]: "Currently, only a few comments explicitly mention those policies â€“ 20% of the English ones, but as few as 2% of the German and Turkish comments."
  - [section]: "To extract policies from the comments, we select comments to any deletion discussion, which mentions a Wikipedia page... We further remove all mentions of policies from the comments, to be able to predict them for a given comment."
  - [corpus]: Weak - no direct corpus evidence supporting this specific mechanism.
- Break condition: If the context alone is insufficient to infer policy references, model performance will degrade.

## Foundational Learning

- Concept: Multi-task learning
  - Why needed here: Allows joint learning of stance and policy prediction, improving performance especially for low-resource scenarios
  - Quick check question: What is the main advantage of multi-task learning over training separate models for each task?

- Concept: Multilingual alignment
  - Why needed here: Enables knowledge transfer from higher-resource languages to lower-resource ones, improving performance for Turkish
  - Quick check question: How does aligning policies across languages help in a low-resource setting?

- Concept: Stance detection
  - Why needed here: Core task of understanding moderator opinions in deletion discussions, essential for transparent content moderation
  - Quick check question: What are the four possible stance labels in this dataset?

## Architecture Onboarding

- Component map: Input comment text and topic -> Transformer encoder (BERT/mBERT/XLM-R) -> Task-specific classification heads for stance and policy -> Output stance (keep, delete, merge, comment) and policy

- Critical path: 1. Preprocess comment by removing policy mentions 2. Encode text using transformer model 3. Apply task-specific classification heads 4. Optimize joint loss (3:1 ratio for stance:policy) 5. Evaluate using F1 macro for stance and accuracy for policy

- Design tradeoffs:
  - Single-task vs multi-task: Multi-task improves performance but increases complexity
  - Language-specific vs multilingual models: Multilingual helps low-resource languages but may reduce performance for high-resource ones
  - Explicit vs implicit policy references: Removing explicit mentions improves generalization but may reduce performance on explicit cases

- Failure signatures:
  - Poor stance detection: Likely issues with stance classification head or imbalanced training data
  - Poor policy prediction: May indicate insufficient alignment of policies across languages or lack of relevant features
  - Overfitting: Early stopping not working or insufficient regularization

- First 3 experiments:
  1. Compare single-task vs multi-task performance for stance detection
  2. Compare language-specific vs multilingual models for policy prediction
  3. Evaluate impact of removing explicit policy mentions on overall performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the multilingual policy alignment be improved to handle cases where policies do not have exact equivalents across languages?
- Basis in paper: [explicit] The authors manually align policies across languages using inter-wiki links, but acknowledge that not all policies have exact matches across languages.
- Why unresolved: The current alignment is done manually and might not capture all relevant policy similarities. Automated alignment methods could potentially improve coverage.
- What evidence would resolve it: Experiments comparing the current manual alignment with an automated alignment method on a subset of policies.

### Open Question 2
- Question: Does the performance of the model degrade significantly when predicting policies for comments that do not explicitly mention any policy?
- Basis in paper: [inferred] The dataset only includes comments that mention at least one policy, but the authors note that many comments in deletion discussions do not refer to policies at all.
- Why unresolved: The model is only evaluated on comments that explicitly mention policies, so its performance on policy-free comments is unknown.
- What evidence would resolve it: Testing the model on a separate dataset of deletion discussion comments that do not mention any policies.

### Open Question 3
- Question: Can the model generalize to predict policies for new deletion discussions that were not seen during training?
- Basis in paper: [explicit] The authors evaluate the model on a held-out test set, but do not test its ability to generalize to completely new deletion discussions.
- Why unresolved: The test set is still drawn from the same distribution as the training data, so the model may not perform as well on truly unseen data.
- What evidence would resolve it: Evaluating the model on a dataset of deletion discussions from a time period after the training data was collected, or from a different Wikipedia language edition.

## Limitations
- Evaluation relies solely on automatic metrics without human validation of model outputs
- Policy alignment assumes semantic equivalence across languages without systematic validation
- Dataset construction removes explicit policy mentions, potentially limiting real-world applicability

## Confidence

- **High confidence**: The multi-task learning approach improves performance over single-task baselines, as evidenced by consistent improvements across languages and tasks in Tables 3 and 4. The experimental setup is clearly described and results are reproducible.

- **Medium confidence**: The multilingual policy alignment benefits Turkish specifically, though the mechanism is somewhat unclear. While results show improvement, the paper doesn't fully explain why German doesn't see similar benefits despite also being low-resource.

- **Medium confidence**: The removal of explicit policy mentions successfully forces the model to learn implicit policy references. This claim is supported by the methodology but lacks direct validation - we don't know if the model is truly learning implicit references or just memorizing patterns.

## Next Checks

1. Conduct human evaluation on a subset of model predictions to verify that the model is correctly identifying implicit policy references, not just memorizing patterns from the training data.

2. Systematically validate the quality of multilingual policy alignments, particularly for Turkish, by having bilingual experts assess whether aligned policies are truly semantically equivalent across languages.

3. Test the model's performance on a dataset where explicit policy mentions are retained to determine if the masking approach genuinely improves generalization or merely changes the task definition.