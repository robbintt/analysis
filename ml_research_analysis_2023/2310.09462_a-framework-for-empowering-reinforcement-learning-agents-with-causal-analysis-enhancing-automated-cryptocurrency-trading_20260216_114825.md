---
ver: rpa2
title: 'A Framework for Empowering Reinforcement Learning Agents with Causal Analysis:
  Enhancing Automated Cryptocurrency Trading'
arxiv_id: '2310.09462'
source_url: https://arxiv.org/abs/2310.09462
tags:
- agent
- trading
- market
- learning
- actions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the CausalReinforceNet (CRN) framework, which
  enhances reinforcement learning (RL) agents with causal analysis for automated cryptocurrency
  trading. The CRN framework incorporates Bayesian networks (BNs) for feature engineering
  and dynamic Bayesian networks (DBNs) for price direction predictions to empower
  RL agents in trade decision-making.
---

# A Framework for Empowering Reinforcement Learning Agents with Causal Analysis: Enhancing Automated Cryptocurrency Trading

## Quick Facts
- arXiv ID: 2310.09462
- Source URL: https://arxiv.org/abs/2310.09462
- Reference count: 40
- Key outcome: CRN framework with causal analysis improves RL agent performance in cryptocurrency trading, with PPO agent achieving 12.93% ROI for Binance Coin and 8.19% ROI for Ethereum versus Buy-and-Hold benchmark.

## Executive Summary
This paper presents the CausalReinforceNet (CRN) framework that enhances reinforcement learning agents with causal analysis for automated cryptocurrency trading. The framework integrates Bayesian Networks for feature engineering and Dynamic Bayesian Networks for price direction predictions to empower RL agents in making trade decisions. Two RL agents based on PPO and DDPG algorithms were developed and tested on five altcoins, showing superior performance compared to the Buy-and-Hold benchmark strategy. The study demonstrates the potential of incorporating causal analysis into RL frameworks for improved cryptocurrency trading performance.

## Method Summary
The CRN framework combines Bayesian Networks for feature selection, Dynamic Bayesian Networks for price direction predictions, and two RL algorithms (PPO and DDPG) with a conservative trading strategy. Daily historical price data for five altcoins (Binance Coin, Ethereum, Litecoin, Ripple, Tether) was collected along with technical indicators, financial assets, and social media data from January 2018 to April 2023. BNs identified relevant features with causal relationships influencing price movements, while DBNs predicted daily price directions. The RL agents used a reward function combining ROI (70%) and Sharpe ratio (30%) to balance profitability with risk management, implementing position size limits of 40-60% of available balance.

## Key Results
- Both CRN-based PPO and DDPG agents outperformed Buy-and-Hold benchmark strategy
- PPO agent achieved 12.93% ROI for Binance Coin and 8.19% ROI for Ethereum
- Framework demonstrated effectiveness across five different altcoins with varying market behaviors
- Conservative position sizing (40-60% threshold) contributed to risk management

## Why This Works (Mechanism)

### Mechanism 1
Bayesian Networks (BNs) in feature engineering improve RL agent state quality by selecting causally relevant features for each altcoin. BNs model conditional dependencies among market variables (OHLCV, technical indicators, financial assets, social media) and prune non-causal or redundant features, reducing state dimensionality and noise.

### Mechanism 2
Dynamic Bayesian Networks (DBNs) provide probabilistic price direction signals that improve RL agent risk-aware decision-making. DBNs predict daily closing price direction (Up/Down) with probabilities, allowing agents to adjust position sizes based on prediction confidence levels.

### Mechanism 3
Reward function combining ROI and Sharpe ratio balances profitability with risk management, improving robustness vs. pure ROI maximization. The weighted sum (70% ROI, 30% Sharpe) encourages profitable trades while penalizing excessive volatility.

## Foundational Learning

- **Markov Decision Process (MDP) formulation**: Defines state, action, reward structure for RL in trading. Quick check: What tuple defines an MDP in RL?
- **Feature selection and causal inference with Bayesian Networks**: Reduces high-dimensional market data noise by identifying causally relevant features. Quick check: How does a BN identify non-causal or redundant features?
- **Sharpe ratio as risk-adjusted performance metric**: Incorporates risk into performance evaluation beyond pure returns. Quick check: What components make up the Sharpe ratio formula?

## Architecture Onboarding

- **Component map**: Market data → BN Feature Engine → DBN Predictor → RL Agent → Position Sizing → Execution
- **Critical path**: Feature extraction → BN selection → DBN prediction → RL decision → Position sizing → Execution
- **Design tradeoffs**: Conservative position sizing reduces risk but may cap upside; BNs add preprocessing overhead but improve state relevance; dual RL algorithms allow comparison but double training cost
- **Failure signatures**: BN selection yields near-empty/noisy feature sets; DBN predictions consistently wrong; reward function too risk-averse
- **First 3 experiments**: 1) Run CRN with BN feature selection disabled; 2) Run CRN with DBN predictions disabled; 3) Swap reward function to pure ROI

## Open Questions the Paper Calls Out
- How would the CRN framework perform with higher-frequency trading strategies (hourly/minute-level data)?
- How does CRN performance compare when using a portfolio strategy combining all five altcoins versus individual trading?
- How would the CRN framework perform with other reinforcement learning algorithms beyond PPO and DDPG?

## Limitations
- No direct empirical validation that Bayesian Networks improve feature selection versus non-causal alternatives
- DBN price direction predictions incorporated without demonstrating contribution to trading performance
- Conservative position sizing (40-60% threshold) may not represent optimal risk management
- Out-of-sample testing includes COVID-19 market crash as potential outlier

## Confidence
- **High Confidence**: CRN framework architecture and methodology reproducibility; RL agents outperform Buy-and-Hold benchmark
- **Medium Confidence**: Bayesian Networks improve feature selection quality; DBN predictions contribute to agent decisions
- **Low Confidence**: Specific causal relationships identified by BNs; optimal reward function weighting

## Next Checks
1. **Ablation Study on Feature Selection**: Remove BN feature selection and compare performance using all features to quantify causal engineering benefit
2. **DBN Prediction Isolation Test**: Disable DBN predictions while keeping other components to determine their influence on agent behavior
3. **Reward Function Sensitivity Analysis**: Systematically vary ROI-to-Sharpe ratio weighting to identify optimal risk-return tradeoffs for different market conditions