---
ver: rpa2
title: RCT Rejection Sampling for Causal Estimation Evaluation
arxiv_id: '2307.15176'
source_url: https://arxiv.org/abs/2307.15176
tags:
- causal
- data
- evaluation
- sampling
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of empirically evaluating causal
  estimation methods, particularly in high-dimensional settings where confounding
  is a significant obstacle. The authors propose a new RCT rejection sampling algorithm
  that theoretically guarantees causal identification in observational data subsampled
  from RCTs.
---

# RCT Rejection Sampling for Causal Estimation Evaluation

## Quick Facts
- arXiv ID: 2307.15176
- Source URL: https://arxiv.org/abs/2307.15176
- Reference count: 27
- Key outcome: Proposed RCT rejection sampling algorithm theoretically guarantees causal identification in observational data subsampled from RCTs, reducing bias compared to previous methods

## Executive Summary
This paper addresses the challenge of empirically evaluating causal estimation methods by proposing a new RCT rejection sampling algorithm. The method creates observational datasets from RCTs where causal effects remain identifiable via backdoor adjustment, unlike previous subsampling approaches. The algorithm ensures the observed data distribution permits identification by constraining the sampling process, and is demonstrated to reduce bias compared to prior methods on synthetic data. The authors also provide a proof-of-concept pipeline using a real-world RCT dataset with text data as high-dimensional covariates.

## Method Summary
The RCT rejection sampling algorithm generates observational data from RCTs where causal effects remain identifiable. It works by specifying a confounding function P*(T|C) and using rejection sampling to ensure P*(C) = P(C) and P*(Y|T,C) = P(Y|T,C), which maintains the backdoor functional's validity. The algorithm can be applied when RCTs contain sufficient pre-treatment covariates satisfying the backdoor criterion. For high-dimensional settings, a proxy strategy is used where low-dimensional confounding variables C are known but only high-dimensional proxies X are available to estimation methods.

## Key Results
- Proposed RCT rejection sampling algorithm theoretically guarantees causal identification in observational data subsampled from RCTs
- Algorithm reduces absolute bias by factor of over 24 compared to previous methods on synthetic data
- Successfully applied to real-world RCT with text data as high-dimensional covariates, highlighting finite data considerations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RCT rejection sampling produces observational data where causal identification holds
- Mechanism: The rejection sampler constrains the selection mechanism such that P*(C) = P(C) and P*(Y|T,C) = P(Y|T,C), which ensures the backdoor functional remains valid
- Core assumption: The confounding function P*(T|C) must be specified and must satisfy positivity and be non-trivially dependent on C
- Evidence anchors:
  - [abstract] "RCT rejection sampling, that is theoretically guaranteed to produce an observational dataset where samples are drawn according to a distribution where the effect is identified via a backdoor functional"
  - [section 3.4] "The intuition behind our algorithm is as follows. Sufficient constraints for maintaining identifiability of the ATE in P*(C,T,Y) via the functional in equation 2 are to ensure that P*(C) = P(C) and P*(Y|T,C) = P(Y|T,C)"
- Break condition: If P*(T|C) does not depend on C in a non-trivial way, or if the positivity assumption is violated, identification fails

### Mechanism 2
- Claim: The algorithm reduces bias compared to prior RCT subsampling methods
- Mechanism: By ensuring the covariate distribution P*(C) matches the RCT distribution P(C), the rejection sampler avoids the selection bias that plagues earlier methods
- Core assumption: The oracle adjustment (using the true structural equations) is correctly specified and applied
- Evidence anchors:
  - [abstract] "Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm."
  - [section 3.5] "Table 2 shows that our proposed RCT rejection sampler results in a reduction of absolute bias compared to Algorithm 2 from Gentzel et al. (2021) by a factor of over 24 for Setting 1"
- Break condition: If the true adjustment set is unknown or mis-specified, the bias reduction may not materialize in practice

### Mechanism 3
- Claim: The rejection sampler is feasible with real-world RCTs that have high-dimensional covariates
- Mechanism: By using a proxy strategy where low-dimensional confounding variables C are known but only high-dimensional proxies X are available to estimation methods, the algorithm sidesteps the difficulty of specifying P*(T|C) for high-dimensional C
- Core assumption: The high-dimensional proxies X have near-perfect predictive accuracy for the low-dimensional confounding variables C
- Evidence anchors:
  - [abstract] "we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets"
  - [section 4.3.1] "We use this structured metadata as the covariates C in our RCT rejection sampler, but provide the causal estimation methods only X,Y and T"
- Break condition: If the proxy accuracy is low, the estimator will not have access to the true confounding structure, leading to bias

## Foundational Learning

- Concept: Causal graphical models and backdoor criterion
  - Why needed here: The entire theoretical framework relies on understanding how to identify causal effects from observational data using backdoor adjustment
  - Quick check question: Given a DAG where T ← C → Y, what set satisfies the backdoor criterion for identifying the effect of T on Y?

- Concept: Rejection sampling
  - Why needed here: The algorithm uses rejection sampling to ensure the observed data distribution permits identification
  - Quick check question: What is the acceptance probability in rejection sampling when the target distribution is P*(V) and the proposal is P(V)?

- Concept: Overlap and positivity
  - Why needed here: These are necessary conditions for the estimator to be well-defined and unbiased
  - Quick check question: What does it mean for a propensity score model to satisfy positivity?

## Architecture Onboarding

- Component map: RCT dataset (C, T, Y) -> Confounding function P*(T|C) -> Rejection sampler -> Observational dataset DOBS -> Base learners -> Causal estimators -> ATE estimates

- Critical path:
  1. Verify C ⊥̸ Y in RCT dataset
  2. Specify P*(T|C)
  3. Run rejection sampler to generate DOBS
  4. Train base learners on DOBS
  5. Apply causal estimators
  6. Compare estimates to RCT ground-truth

- Design tradeoffs:
  - High-dimensional C makes P*(T|C) specification difficult → use proxy strategy
  - Large RCT needed because subsampling reduces sample size by ~half
  - Oracle estimators validate identification theory but aren't practical for real applications

- Failure signatures:
  - Poor overlap in DOBS (some c with P(T=1|C=c) ≈ 0 or 1)
  - Large discrepancy between ATE from DOBS and RCT (indicates identification failed)
  - Base learners with very low average precision for outcome models (class imbalance or insufficient support)

- First 3 experiments:
  1. Verify RCT rejection sampler produces DOBS where C ⊥̸ T and C ⊥̸ Y holds
  2. Compare absolute bias of ATE estimates using RCT rejection sampler vs Gentzel et al. method on synthetic data
  3. Apply baseline causal estimators to DOBS and check if estimates are closer to RCT ATE than naive difference in means

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions do the finite sample properties of RCT rejection sampling become problematic for high-dimensional covariate settings?
- Basis in paper: [explicit] The authors mention that "the sampler can produce finite samples where confounding bias is induced, but difficult to correct for" and recommend running diagnostics on the sampling procedure
- Why unresolved: While the authors provide some guidance on diagnostics, they don't specify precise conditions under which finite sample issues become severe in high-dimensional settings
- What evidence would resolve it: Empirical studies showing failure rates of RCT rejection sampling under different dimensionalities of C, sample sizes, and degrees of confounding induced by various P*(T|C) specifications

### Open Question 2
- Question: How does the performance of RCT rejection sampling compare to other benchmarking strategies (e.g., semi-synthetic approaches) in terms of generalizability to real-world observational data?
- Basis in paper: [explicit] The authors compare RCT subsampling to other strategies like semi-synthetic evaluations and constructed observational studies in Table 1, noting tradeoffs in degrees of freedom, data availability, and DGP realism
- Why unresolved: While the authors argue RCT subsampling has fewer researcher degrees of freedom, they don't provide empirical comparisons of its effectiveness at benchmarking causal estimation methods versus other strategies
- What evidence would resolve it: Direct empirical comparisons of causal estimation performance on data generated via RCT rejection sampling versus semi-synthetic approaches, using a common set of causal estimation methods and real-world RCTs

### Open Question 3
- Question: What are the implications of class imbalance and low average precision for outcome models in finite samples for the validity of causal effect estimates?
- Basis in paper: [explicit] The authors note that for their real-world proof of concept, the outcome models had very low average precision, which they hypothesize is due to finite data issues with class imbalance
- Why unresolved: While the authors mention this as a challenge, they don't explore how class imbalance affects the bias or variance of causal effect estimates, or what strategies might mitigate these issues
- What evidence would resolve it: Simulations or real-data analyses varying the degree of class imbalance and measuring its impact on the bias and variance of causal effect estimates obtained via different estimation strategies

## Limitations
- Requires large initial RCT sample size as rejection sampling approximately halves the dataset size
- Only applicable when RCT contains sufficient pre-treatment covariates to satisfy the backdoor criterion
- Finite-sample performance sensitive to specification of P*(T|C), with poor specification leading to high variance or biased estimates

## Confidence
- High confidence in the theoretical identification guarantees under the stated assumptions
- Medium confidence in the empirical results on synthetic data, as they rely on oracle estimators
- Medium confidence in the proof-of-concept real-world application, given the limited scope and lack of extensive validation

## Next Checks
1. **Robustness to confounding function specification**: Systematically evaluate how different choices of P*(T|C) affect the bias and variance of ATE estimates across multiple synthetic datasets with varying levels of confounding strength

2. **Sample size sensitivity analysis**: Quantify the relationship between initial RCT sample size and the statistical power of downstream causal estimation methods when applied to the rejected samples, particularly focusing on the point where rejection sampling becomes impractical

3. **Real-world applicability assessment**: Apply the method to multiple real RCTs with different covariate types (e.g., tabular, image, text) to evaluate the practical challenges of satisfying the backdoor criterion and specifying appropriate confounding functions in diverse settings