---
ver: rpa2
title: Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization
arxiv_id: '2310.08177'
source_url: https://arxiv.org/abs/2310.08177
tags:
- ho-fmn
- adam
- attacks
- hyperparameter
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to improve the efficacy of fast minimum-norm
  (FMN) attacks on adversarial robustness by treating loss functions, optimizers,
  and step-size schedulers as tunable hyperparameters. The authors develop HO-FMN,
  a framework that uses hyperparameter optimization to select the best combination
  of these components and their associated hyperparameters.
---

# Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization

## Quick Facts
- arXiv ID: 2310.08177
- Source URL: https://arxiv.org/abs/2310.08177
- Reference count: 16
- Key outcome: HO-FMN achieves competitive performance with AutoAttack while computing the full robustness-perturbation curve with a single optimization run.

## Executive Summary
This paper introduces HO-FMN, a framework that improves the efficacy of fast minimum-norm (FMN) attacks by treating loss functions, optimizers, and step-size schedulers as tunable hyperparameters. The authors use hyperparameter optimization to select the best combination of these components and their hyperparameters, evaluating their approach on 9 state-of-the-art robust models from RobustBench. HO-FMN achieves competitive performance with AutoAttack while providing a more thorough evaluation of adversarial robustness by computing the full robustness-perturbation curve in a single optimization run.

## Method Summary
The HO-FMN framework treats the loss function, optimizer, and step-size scheduler as hyperparameters to be optimized. It uses a CFO search algorithm combined with the ASHA scheduler (via Ray Tune) to efficiently explore the search space. The framework is evaluated on 9 robust models from RobustBench, using a subset of 100 CIFAR10 samples for tuning and a separate set of 1000 samples for evaluation. The goal is to minimize the median ℓ∞ perturbation norm while achieving misclassification, and to compute the full robustness-perturbation curve with a single optimization.

## Key Results
- HO-FMN achieves competitive performance with AutoAttack on 9 state-of-the-art robust models from RobustBench.
- The framework computes the full robustness-perturbation curve with a single optimization run, providing a more thorough evaluation of adversarial robustness.
- The logit loss (LL) consistently outperforms the cross-entropy loss (CE) for this attack family.

## Why This Works (Mechanism)

### Mechanism 1
Hyperparameter optimization can find attack configurations that outperform fixed-default settings for adversarial attacks. By treating the loss function, optimizer, and step-size scheduler as tunable hyperparameters, the framework searches over a space of attack configurations to find the one that minimizes the median ℓ∞ perturbation norm for a given model. The core assumption is that the optimal configuration varies significantly across different models, so a one-size-fits-all approach leaves robustness underestimated.

### Mechanism 2
The framework enables evaluation of the full robustness-perturbation curve with a single optimization run. Once the best hyperparameters are found for a model, HO-FMN can compute robust accuracy across all perturbation sizes in one pass, whereas reference AutoAttack would need multiple runs. The core assumption is that the discovered hyperparameters remain effective across the full perturbation range.

### Mechanism 3
The logit loss (LL) consistently outperforms cross-entropy loss (CE) for this attack family. LL provides gradients that better align with the minimum-norm objective, leading to smaller perturbations for the same misclassification rate. The core assumption is that the choice of loss function materially affects the geometry of the optimization landscape in ℓ∞ attacks.

## Foundational Learning

- Concept: Adversarial robustness evaluation
  - Why needed here: The paper's goal is to improve evaluation methods for adversarial robustness, so understanding the threat model and metrics is essential.
  - Quick check question: What is the difference between robust accuracy and standard accuracy in the context of adversarial examples?

- Concept: Hyperparameter optimization in machine learning
  - Why needed here: The core contribution is treating attack components as hyperparameters and optimizing them; familiarity with BO, grid search, or ASHA is necessary.
  - Quick check question: What is the role of the ASHA scheduler in this context?

- Concept: Fast minimum-norm (FMN) attacks and their algorithmic structure
  - Why needed here: HO-FMN is a modification of FMN; understanding its δ-step and ϵ-step is key to knowing what is being optimized.
  - Quick check question: In FMN, what does the δ-step optimize, and how does it differ from the ϵ-step?

## Architecture Onboarding

- Component map:
  - Attack configuration space: loss functions (LL, CE), optimizers (SGD, Adam variants), schedulers (CALR, CAWR, MSLR, RLROP)
  - Hyperparameter optimizer: CFO search algorithm + ASHA scheduler (Ray Tune)
  - Evaluation pipeline: tuning set (100 samples), test set (1000 samples), ℓ∞ perturbation budget
  - External dependencies: RobustBench models, Ray Tune framework

- Critical path:
  1. Define search space for each component's hyperparameters
  2. Run hyperparameter optimization on tuning subset
  3. Select best configuration (smallest median ||δ||∞)
  4. Evaluate on test set and plot full robustness-perturbation curve

- Design tradeoffs:
  - Search space size vs. optimization time: larger spaces improve coverage but increase compute cost
  - Choice of optimizer (CFO + ASHA) vs. alternatives: balances exploration and efficiency
  - Using only 100 samples for tuning vs. full dataset: speeds tuning but may miss edge cases

- Failure signatures:
  - Tuning converges to a suboptimal configuration (e.g., selects CE over LL)
  - Results not reproducible due to stochastic optimization
  - Runtime explodes due to too large a search space or inefficient scheduler

- First 3 experiments:
  1. Run HO-FMN with default SGD+CALR+LL on a single RobustBench model and verify it matches FMN baseline.
  2. Run CFO + ASHA on a small search space (e.g., only loss functions) and confirm it selects LL over CE.
  3. Evaluate HO-FMN with the best hyperparameters on the full test set and plot the robustness-perturbation curve for comparison with AutoAttack.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several are implied by the discussion and future work section. These include the potential for extending the analysis to other perturbation norms (ℓ0, ℓ1, ℓ2), exploring larger hyperparameter search spaces, and comparing computational efficiency with other multi-run methods like AutoAttack.

## Limitations

- The search space for hyperparameters, while covering key attack components, may not be exhaustive enough to capture all potential improvements.
- The evaluation is primarily focused on ℓ∞ perturbations, with other threat models like ℓ2 or ℓ0 not explored.
- The computational overhead of hyperparameter optimization, though mitigated by ASHA, may still be prohibitive for very large models or datasets.

## Confidence

- Core claim (HO-FMN improves FMN attacks): High
- Single-run curve computation advantage: Medium
- Logit loss superiority: High

## Next Checks

1. **Re-evaluate with a broader search space** that includes additional optimizers, schedulers, and loss functions to test the robustness of the findings.
2. **Test HO-FMN on other adversarial threat models** (e.g., ℓ2, ℓ0) to assess generalization beyond ℓ∞.
3. **Compare the computational efficiency** of HO-FMN with other multi-run methods like AutoAttack on the same hardware and dataset to quantify the single-run advantage.