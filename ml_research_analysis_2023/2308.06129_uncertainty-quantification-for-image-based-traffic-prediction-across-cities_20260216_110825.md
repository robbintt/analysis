---
ver: rpa2
title: Uncertainty Quantification for Image-based Traffic Prediction across Cities
arxiv_id: '2308.06129'
source_url: https://arxiv.org/abs/2308.06129
tags:
- uncertainty
- traffic
- prediction
- data
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the need for uncertainty quantification in
  traffic prediction models, which is crucial for their deployment in real-world intelligent
  transportation systems. The authors investigate four uncertainty quantification
  methods - deep ensembles, Monte Carlo batch normalization, test time augmentation,
  and patch-based uncertainty - on a large-scale image-based traffic dataset spanning
  multiple cities and time periods.
---

# Uncertainty Quantification for Image-based Traffic Prediction across Cities

## Quick Facts
- arXiv ID: 2308.06129
- Source URL: https://arxiv.org/abs/2308.06129
- Reference count: 40
- One-line primary result: Proper combination of aleatoric and epistemic uncertainty quantification methods provides accurate and calibrated uncertainty estimates that generalize well across cities and time periods.

## Executive Summary
This paper investigates uncertainty quantification (UQ) methods for image-based traffic prediction, addressing a critical gap in deploying deep learning models for intelligent transportation systems. The authors evaluate four UQ approaches—deep ensembles, Monte Carlo batch normalization, test time augmentation, and patch-based uncertainty—on a large-scale dataset spanning multiple cities and time periods. They demonstrate that combining epistemic and aleatoric uncertainty methods yields well-calibrated predictive uncertainty that generalizes effectively to both temporal and spatial transfer tasks, with practical applications in outlier detection for traffic dynamics changes.

## Method Summary
The authors train U-Net and U-Net++ models on Traffic4cast 2021 data (2019, all cities except Antwerp) and evaluate four UQ methods: deep ensembles (5 members), Monte Carlo batch normalization (10 forward passes), test time augmentation (7 augmentations), and patch-based uncertainty with sliding window. They combine epistemic and aleatoric methods (TTA+Ens and Patches+Ens) for predictive uncertainty, using conformal prediction intervals for calibration. Evaluation metrics include MSE, ENCE, Spearman's rank correlation, and MPIW at 90% coverage across temporal (pre/post-COVID) and spatial (city-to-city) transfer tasks.

## Key Results
- Combination of aleatoric and epistemic methods provides accurate and calibrated uncertainty estimates
- Mean prediction interval width of at most 23 for 90% marginal coverage guarantee
- Expected calibration error below 1 and Spearman's rank correlation above 0.7
- Uncertainty estimates effectively capture both temporal and spatial effects on traffic behavior

## Why This Works (Mechanism)

### Mechanism 1
Combining epistemic and aleatoric uncertainty methods yields better-calibrated predictive uncertainty than either alone. Epistemic uncertainty captures model misspecification (reducible), aleatoric captures inherent data noise (irreducible). Their sum approximates total predictive uncertainty via law of total variance. Core assumption: Epistemic and aleatoric uncertainty sources are additive and independent. Evidence: Abstract states proper combination provides accurate and calibrated estimates; section 3.5 presumes additive decomposition holds equivalently. Break condition: If sources are correlated or not independent, additive model fails.

### Mechanism 2
Monte Carlo batch normalization approximates Bayesian inference by treating mini-batch statistics as Monte Carlo samples. At test time, batch normalization statistics are recomputed per mini-batch, introducing stochasticity that approximates sampling from an approximate posterior over weights. Core assumption: Batch statistics computed on training data approximate draws from the posterior. Evidence: Section 3.2 cites Teye et al. [2018] proposing this for epistemic uncertainty; section 4.4 shows MCBN expresses larger magnitude uncertainties but worse calibration than ensembles. Break condition: If batch size is too large or statistics are deterministic, stochasticity vanishes.

### Mechanism 3
Test-time data augmentation models aleatoric uncertainty by marginalizing over transformations. Reversible augmentations are treated as random variables; model predictions over transformed inputs approximate the predictive distribution. Core assumption: Transformations are reversible and their parameters are drawn from a known distribution. Evidence: Section 3.3 describes augmentations via transformation operator with propagated randomness; section 4.4 shows TTA provides sharp and reasonably calibrated uncertainties when combined with ensembles. Break condition: If augmentations are not reversible or transformation distribution is misspecified, uncertainty estimates become biased.

## Foundational Learning

- Concept: Distinction between epistemic and aleatoric uncertainty
  - Why needed here: Determines which UQ method to apply and how to interpret results.
  - Quick check question: If more data were collected, which type of uncertainty would decrease?

- Concept: Conformal prediction for distribution-free uncertainty calibration
  - Why needed here: Enables sharpness evaluation without distributional assumptions.
  - Quick check question: What is the role of the calibration set in constructing prediction intervals?

- Concept: Monte Carlo approximation of intractable integrals
  - Why needed here: All four UQ methods rely on sampling to estimate predictive distributions.
  - Quick check question: How does the number of Monte Carlo samples affect the variance of the uncertainty estimate?

## Architecture Onboarding

- Component map: Input → U-Net/U-Net++ → Ensemble or single model → UQ method(s) → Uncertainty output
- Critical path: Data loading → model forward pass (possibly with augmentation or multiple batches) → uncertainty aggregation → calibration
- Design tradeoffs: Ensemble size vs. inference time; patch size/stride vs. coverage; augmentation set vs. irreversibility
- Failure signatures: Grid artifacts in patch-based uncertainty; overconfident predictions if epistemic component is omitted; miscalibration if conformal intervals are incorrectly scaled
- First 3 experiments:
  1. Run baseline U-Net without UQ; record MSE on test set.
  2. Apply TTA only; compare calibration metrics (ENCE, ρsp) to baseline.
  3. Combine TTA+Ens; verify MPIW shrinks while maintaining coverage.

## Open Questions the Paper Calls Out

### Open Question 1
How can the patch-based uncertainty method be modified to eliminate the observed grid-like artifact while maintaining computational efficiency? Basis: Authors note patch-based uncertainty exhibits grid-like pattern that is an artifact from sampling procedure, unable to fully eliminate it. Why unresolved: Mentioned but no solution or alternative sampling investigation provided. What evidence would resolve it: Experimental results comparing different sampling methods (e.g., non-overlapping patches, adaptive window sizes) and impact on both artifact and uncertainty quality metrics.

### Open Question 2
What is the optimal combination of UQ methods for capturing predictive uncertainty in traffic prediction tasks, and how does this vary across different urban environments? Basis: Authors combine epistemic and aleatoric methods and find combining performs better than single methods. Why unresolved: Compares limited combinations (TTA+Ens and Patches+Ens) without exploring full space or analyzing city-to-city variation. What evidence would resolve it: Systematic evaluation of all possible pairs and combinations of four UQ methods across multiple cities with analysis of which combinations perform best in different urban contexts.

### Open Question 3
How does the quality of uncertainty estimates from image-based traffic data compare to those obtained from traditional loop-counter data? Basis: Authors note most related work uses loop-counter data while their work uses image-based data, highlighting benefits of their data representation. Why unresolved: No direct comparison between uncertainty estimates from two data types for same prediction task. What evidence would resolve it: Side-by-side experiments applying same UQ methods to both image-based and loop-counter data for same traffic prediction task with comparison of uncertainty quality metrics.

## Limitations
- Additive decomposition of epistemic and aleatoric uncertainty assumes independence between model and data uncertainty sources, which may not hold in real-world traffic scenarios with complex spatiotemporal correlations.
- Monte Carlo batch normalization's theoretical justification as approximate Bayesian inference relies on strong assumptions about training data distribution matching posterior, which may break down in transfer settings.
- Effectiveness of test-time augmentation for aleatoric uncertainty depends critically on choice of augmentation pipeline and may be sensitive to domain shifts across cities.

## Confidence
- High confidence in experimental methodology and evaluation protocol based on established metrics (MSE, ENCE, MPIW, calibration error).
- Medium confidence in mechanism claims for epistemic-aleatoric combination, as they rely on theoretical assumptions that may not fully hold in practice.
- Medium confidence in generalizability of results to cities not included in Traffic4cast dataset, given focus on 8 specific urban areas.

## Next Checks
1. **Independence verification**: Analyze empirical correlation between epistemic and aleatoric uncertainty estimates across different traffic conditions to validate additive decomposition assumption.
2. **Ablation study**: Systematically evaluate impact of augmentation pipeline choices (transformations, parameters) on aleatoric uncertainty calibration across cities.
3. **Out-of-distribution test**: Apply UQ methods to traffic data from cities not included in training set to assess generalization beyond 8 studied urban areas.