---
ver: rpa2
title: 'Break It Down: Evidence for Structural Compositionality in Neural Networks'
arxiv_id: '2301.10884'
source_url: https://arxiv.org/abs/2301.10884
tags:
- inside
- contact
- number
- subroutine
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a new way to study compositional structure in
  neural networks. While prior work on compositionality in neural networks has focused
  on behavioral tests, we focus on studying the internal structure of models.
---

# Break It Down: Evidence for Structural Compositionality in Neural Networks

## Quick Facts
- arXiv ID: 2301.10884
- Source URL: https://arxiv.org/abs/2301.10884
- Reference count: 40
- Primary result: Unsupervised pretraining improves the consistency of structural compositionality in neural networks

## Executive Summary
This paper introduces a novel method to study structural compositionality in neural networks by searching for modular subnetworks within trained models. Rather than focusing on behavioral tests of compositionality, the authors develop a model pruning technique that uses continuous sparsification to isolate subnetworks implementing individual subroutines of compositional tasks. The approach is demonstrated across multiple architectures (ResNet, ViT, BERT), tasks (vision and language), and training regimens, showing that models can indeed implement compositional rules in a modular fashion. The work also reveals that unsupervised pretraining leads to more consistent structural compositionality when fine-tuned on compositional tasks.

## Method Summary
The authors employ a model pruning technique based on continuous sparsification to search for subnetworks within frozen base models that implement individual subroutines of compositional tasks. For a given compositional rule (e.g., inside-contact), they define odd-one-out tasks and train base models to perform them. They then optimize binary masks over the model weights using l0 regularization to find sparse subnetworks that implement specific subroutines while minimizing performance on others. These subnetworks are evaluated on targeted and non-targeted datasets, and ablation studies are performed to test modularity. The method is applied across vision and language tasks, comparing randomly initialized and pretrained models.

## Key Results
- Models exhibit structural compositionality across diverse architectures, tasks, and training regimens
- Unsupervised pretraining improves the consistency of structural compositionality in language tasks
- Subnetworks discovered through continuous sparsification can achieve >90% accuracy on their target subroutines
- Ablation of these subnetworks preserves performance on non-targeted subroutines while degrading performance on targeted ones

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural networks can discover modular subnetworks that implement individual subroutines of a compositional task.
- Mechanism: The method uses continuous sparsification to optimize a binary mask over the weights of a frozen base model. This mask is trained to maximize performance on a dataset requiring only one subroutine (e.g., inside), while minimizing performance on the other (e.g., contact). The l0 regularization encourages sparsity, so the mask isolates a subnetwork that computes only the target subroutine.
- Core assumption: The base model already implements both subroutines in a modular fashion, so the mask can isolate them.
- Evidence anchors:
  - [abstract] "We employ a model pruning technique to search for subnetworks within models that implement each subroutine."
  - [section] "Continuous sparsification reparameterizes the loss function by introducing another variable, s ∈ Rd... During training, we interpolate between a soft mask (σ) and a discrete mask (H)."
- Break condition: If the base model implements the compositional rule via a non-modular solution (e.g., storing a prototype), then no sparse mask will isolate one subroutine without harming the other.

### Mechanism 2
- Claim: Pretraining on unsupervised tasks leads to more consistent structural compositionality when fine-tuned on compositional tasks.
- Mechanism: Pretraining with contrastive learning (e.g., SimCLR) or language modeling establishes richer, more disentangled representations. When fine-tuned on compositional tasks, these representations decompose more cleanly into modular subnetworks for each subroutine.
- Core assumption: Pretraining shapes internal representations in a way that benefits compositional structure.
- Evidence anchors:
  - [abstract] "Additionally, we demonstrate that unsupervised pretraining improves the consistency of structural compositionality."
  - [section] "Across all language tasks, the ablation results indicate that models initialized with pretrained weights reliably produce modular subnetworks."
- Break condition: If the pretraining task does not encourage disentanglement or if fine-tuning overfits to the compositional rule, the benefit may not appear.

### Mechanism 3
- Claim: Structural compositionality can be tested by comparing performance of subnetworks and their ablated complements on targeted vs. non-targeted subroutine datasets.
- Mechanism: A subnetwork is trained to perform well on the "target" subroutine dataset but poorly on the "other" subroutine dataset. If the model is compositional, ablating the subnetwork should preserve performance on the other subroutine but hurt performance on the target.
- Core assumption: The odd-one-out task partitions naturally into examples that depend on each subroutine.
- Evidence anchors:
  - [section] "We define an odd-one-out task on C... For a given architecture and compositional rule, C, we train a base model... We wish to characterize the extent to which MC exhibits structural compositionality."
  - [section] "If MC exhibits structural compositionality, we expect the subnetwork to achieve greater accuracy on Test Target Subroutine than on Test Other Subroutine."
- Break condition: If the task design conflates the two subroutines or if the base model does not truly decompose the rule, the performance differences will be ambiguous.

## Foundational Learning

- Concept: Subroutines and compositional rules
  - Why needed here: The entire method depends on defining tasks as compositions of binary subroutines (e.g., inside and contact) and training models to perform these compositions.
  - Quick check question: In an "inside-contact" task, what are the two subroutines, and how is the rule defined?

- Concept: Model pruning and continuous sparsification
  - Why needed here: The method uses a pruning technique to find sparse subnetworks within a frozen model that implement individual subroutines.
  - Quick check question: What role does the l0 regularization term play in the mask optimization?

- Concept: Ablation studies
  - Why needed here: After finding a subnetwork, the method ablates it to test whether the rest of the model can still perform the other subroutine.
  - Quick check question: If a model is compositional, what should happen to performance on the target subroutine after ablating its subnetwork?

## Architecture Onboarding

- Component map: ResNet/ViT/BERT backbone processes input images/sentences → embeddings passed to MLP or [CLS] token → similarity computation for odd-one-out tasks → continuous sparsification optimizes binary mask over model weights
- Critical path: Train base model → Define target and other subroutine datasets → Optimize mask to find subnetwork → Evaluate subnetwork and ablated model on both datasets → Analyze performance differences
- Design tradeoffs: Using a frozen base model ensures the mask reveals internal structure, but requires careful hyperparameter tuning. Including BatchNorm layers in ResNet would require handling different batch statistics across datasets.
- Failure signatures: If no mask achieves >90% accuracy on its target subroutine, or if ablation does not produce the expected performance difference, the model likely does not exhibit structural compositionality.
- First 3 experiments:
  1. Train a ResNet50 on the inside-contact compositional task and verify >90% accuracy.
  2. Use continuous sparsification to find a subnetwork for the inside subroutine and evaluate on target vs. other datasets.
  3. Ablate the inside subnetwork and evaluate the ablated model on both datasets to check for modularity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does structural compositionality guarantee compositional generalization in neural networks?
- Basis in paper: [inferred] The paper states "it will be important to characterize the relationship between structural compositionality and compositional generalization."
- Why unresolved: The paper demonstrates structural compositionality but does not test whether models with structural compositionality actually generalize compositionally on out-of-distribution tasks.
- What evidence would resolve it: Experimental results showing that models exhibiting structural compositionality consistently outperform models without it on compositional generalization benchmarks.

### Open Question 2
- Question: What specific training dynamics lead to the emergence of structural compositionality?
- Basis in paper: [explicit] "future work might seek to understand how structural compositionality arises during training — what are the dynamics that lead specific subnetworks to functionally differentiate themselves?"
- Why unresolved: The paper demonstrates the presence of structural compositionality but does not analyze the training process to identify what factors contribute to its emergence.
- What evidence would resolve it: Analysis of training trajectories showing correlations between specific training patterns (e.g., learning rate schedules, data properties) and the development of structural compositionality.

### Open Question 3
- Question: How does the scale of models affect the presence and extent of structural compositionality?
- Basis in paper: [inferred] The paper uses relatively small models (ResNet50, BERT-Small) and mentions "Does structural compositionality impose any guarantees about a model's generalization capabilities?" in the discussion.
- Why unresolved: The experiments are limited to small architectures, and the paper suggests future work to understand the relationship between structural compositionality and generalization, which might depend on model scale.
- What evidence would resolve it: Comparative studies showing structural compositionality across models of varying sizes, particularly large language models, and analysis of whether larger models exhibit more or less structural compositionality.

## Limitations
- The method assumes compositional tasks can be cleanly decomposed into binary subroutines, which may not hold for complex real-world problems
- Continuous sparsification depends on specific hyperparameter settings that may not transfer across different architectures or tasks
- The study focuses on synthetic vision tasks and controlled language tasks, limiting generalizability to natural data

## Confidence
- High confidence: The experimental methodology and implementation details for finding subnetworks via continuous sparsification are well-specified and reproducible
- Medium confidence: The claim that unsupervised pretraining improves structural compositionality is supported by experiments but the mechanism is not fully explained
- Low confidence: The generalization of findings to more complex compositional tasks and real-world applications remains uncertain

## Next Checks
1. Transfer to more complex compositional rules: Test the method on tasks with higher-order compositions (e.g., three or more subroutines) to verify whether structural compositionality scales with task complexity

2. Robustness to architectural changes: Apply the continuous sparsification technique to additional architectures (e.g., Vision Transformers, ConvNeXt) and compare the consistency of structural compositionality across models

3. Ablation of pretraining effects: Design a controlled experiment that isolates the effects of pretraining from architectural differences by initializing both randomly initialized and pretrained models with the same architecture and training procedure