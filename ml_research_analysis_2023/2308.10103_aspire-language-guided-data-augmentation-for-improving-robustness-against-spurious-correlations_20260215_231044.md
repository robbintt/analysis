---
ver: rpa2
title: 'ASPIRE: Language-Guided Data Augmentation for Improving Robustness Against
  Spurious Correlations'
arxiv_id: '2308.10103'
source_url: https://arxiv.org/abs/2308.10103
tags:
- aspire
- spurious
- images
- image
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ASPIRE, a language-guided data augmentation
  method designed to mitigate spurious correlations in image classification. ASPIRE
  identifies and removes spurious features (e.g., backgrounds or objects that are
  spuriously correlated with class labels) from images in the training set.
---

# ASPIRE: Language-Guided Data Augmentation for Improving Robustness Against Spurious Correlations

## Quick Facts
- arXiv ID: 2308.10103
- Source URL: https://arxiv.org/abs/2308.10103
- Reference count: 17
- One-line primary result: Improves worst-group classification accuracy by 1% - 38% across four datasets when combined with nine different baseline training methods.

## Executive Summary
This paper introduces ASPIRE, a novel language-guided data augmentation method that addresses spurious correlations in image classification by identifying and removing background features that are spuriously correlated with class labels. The approach leverages Large Language Models (LLMs) to analyze image captions and extract foreground/background information, then uses image editing techniques to remove or replace these spurious features. A personalized text-to-image generation model creates diverse synthetic images without spurious features, which are used to retrain classifiers and improve their robustness. Experiments demonstrate significant improvements in worst-group accuracy across four challenging datasets including Waterbirds, CelebA, SPUCO Dogs, and Hard ImageNet.

## Method Summary
ASPIRE operates through a 6-step pipeline: First, a base ERM classifier is trained on the original dataset to identify spurious correlations. Then, a hold-out set of correctly classified images is selected and captioned using GIT. LLMs analyze these captions to extract foreground and background objects, which are localized in images using Grounding DINO and Segment Anything. Image editing techniques (LaMa inpainter and InstructPix2Pix) remove or replace identified spurious features. A Stable Diffusion model is personalized using these edited images through textual inversion to generate diverse augmentations without spurious features. Finally, these augmentations are added to the training dataset and the classifier is retrained, improving worst-group accuracy by forcing the model to learn core features rather than shortcuts.

## Key Results
- ASPIRE improves worst-group classification accuracy by 1% - 38% when combined with nine different baseline training methods
- Significant improvements demonstrated on four datasets: Waterbirds, CelebA, SPUCO Dogs, and Hard ImageNet
- The method successfully identifies and removes spurious features across diverse image domains and correlation patterns
- ASPIRE outperforms existing data augmentation approaches specifically for mitigating spurious correlations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-guided foreground/background extraction enables precise identification of spurious features by analyzing textual descriptions.
- Mechanism: ASPIRE generates image captions using GIT, then leverages LLMs to extract foreground objects and background from these captions. By analyzing which objects lead to incorrect predictions when removed/replaced, ASPIRE identifies spurious correlations.
- Core assumption: Textual descriptions capture sufficient semantic information to enable accurate foreground/background separation and spurious feature identification.
- Evidence anchors: [abstract] "we employ LLMs to first extract foreground and background features from textual descriptions of an image"; [section 3] "we use LLMs to extract the phrases in the caption that correspond to foreground and background objects"
- Break condition: If image captions fail to capture essential visual features, the LLM-guided extraction will misidentify spurious features.

### Mechanism 2
- Claim: Diffusion model personalization ensures generated augmentations match the original data distribution without spurious features.
- Mechanism: ASPIRE uses textual inversion to fine-tune Stable Diffusion on edited images that exclude spurious features, creating a specialized model for generating non-spurious augmentations.
- Core assumption: The edited images used for personalization represent the true non-spurious distribution and are sufficient for training a specialized diffusion model.
- Evidence anchors: [abstract] "we personalize a text-to-image generation model using the edited images to generate diverse in-domain images without spurious features"; [section 3] "we resort to personalizing a text-to-image generation model" and "we train Stable Diffusion using textual-inversion"
- Break condition: If edited images are of poor quality or insufficient in diversity, the personalized diffusion model will generate low-quality or biased augmentations.

### Mechanism 3
- Claim: The 2-stage training process with augmentations improves robustness by explicitly exposing the model to minority group examples.
- Mechanism: ASPIRE augmentations are added to the training dataset, effectively increasing the representation of non-spurious examples. When combined with baselines, this improves worst-group accuracy by forcing the model to learn core features rather than shortcuts.
- Core assumption: Increasing the proportion of minority group examples in training will improve the model's ability to generalize to minority groups in testing.
- Evidence anchors: [abstract] "We demonstrate the effectiveness of ASPIRE on 4 datasets, including the very challenging Hard ImageNet dataset, and 9 baselines and show that ASPIRE improves the classification accuracy of prior methods by 1% - 38%"; [section 4.2] "For all these baselines, we add ASPIRE augmentations to the set used in the second stage of training"
- Break condition: If the augmentations do not accurately represent the minority group distribution, adding them may not improve worst-group accuracy.

## Foundational Learning

- Concept: Spurious correlations in machine learning
  - Why needed here: Understanding what spurious correlations are and why they're problematic is fundamental to understanding ASPIRE's purpose
  - Quick check question: What is the difference between core features and spurious features in image classification?

- Concept: Large Language Models (LLMs) for feature extraction
  - Why needed here: ASPIRE relies on LLMs to analyze image captions and extract foreground/background information
  - Quick check question: How can LLMs be used to identify objects in text descriptions, and what are the limitations of this approach?

- Concept: Diffusion models and textual inversion
  - Why needed here: ASPIRE uses a diffusion model (Stable Diffusion) with textual inversion for generating non-spurious augmentations
  - Quick check question: What is textual inversion, and how does it differ from standard fine-tuning of diffusion models?

## Architecture Onboarding

- Component map: ERM classifier (E) -> GIT captioner -> LLM extractor -> Grounding DINO -> Segment Anything -> LaMa inpainter -> InstructPix2Pix -> Stable Diffusion with textual inversion

- Critical path: 1. Train ERM classifier on original dataset; 2. Generate captions for hold-out set; 3. Extract foreground/background using LLM; 4. Identify spurious features through editing and prediction; 5. Personalize diffusion model on edited images; 6. Generate augmentations and retrain classifier

- Design tradeoffs: Using LLMs for feature extraction vs. traditional computer vision approaches; Number of augmentations to add (1x vs. more); Top-k selection for spurious features vs. including all identified features

- Failure signatures: Poor worst-group accuracy despite ASPIRE augmentations (indicates augmentations don't represent true minority group); High variance in generation quality (indicates diffusion model personalization issues); Slow training due to LLM calls (indicates computational bottleneck)

- First 3 experiments: 1. Verify LLM-guided foreground/background extraction correctly identifies objects by comparing to human annotations; 2. Test diffusion model personalization by generating images with and without spurious features and checking quality; 3. Validate worst-group accuracy improvement on a simple dataset (like Waterbirds) before scaling to more complex datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact prompt used for the LLaMa model to extract foreground, background, and alternate background from image captions?
- Basis in paper: [explicit] The paper mentions using a single generic prompt for all datasets and references a GitHub repository for the exemplars, but does not provide the exact prompt text in the main paper.
- Why unresolved: The prompt is likely crucial for the performance of ASPIRE and may contain specific instructions or examples that significantly impact the quality of extracted features. Without the exact prompt, it's difficult to reproduce or compare results with ASPIRE.
- What evidence would resolve it: The exact prompt text used for LLaMa in the ASPIRE pipeline.

### Open Question 2
- Question: How does the performance of ASPIRE vary with different values of the hyperparameter 'p' (percentage of correctly classified images used to construct Dhold)?
- Basis in paper: [explicit] The paper mentions that a minimum of p = 20 works well for their experiments but does not provide a detailed analysis of how varying 'p' affects the performance of ASPIRE.
- Why unresolved: The value of 'p' directly impacts the size and composition of Dhold, which in turn affects the quality of spurious correlation detection and the generated augmentations. Understanding the sensitivity of ASPIRE to 'p' is important for practical applications.
- What evidence would resolve it: A comprehensive study of ASPIRE's performance across a range of 'p' values on the datasets used in the experiments.

### Open Question 3
- Question: How does the performance of ASPIRE compare to other data augmentation techniques that do not rely on language guidance?
- Basis in paper: [inferred] The paper focuses on demonstrating the effectiveness of ASPIRE in improving worst-group accuracy when combined with various baseline training methods. However, it does not directly compare ASPIRE to other data augmentation techniques that do not use language guidance.
- Why unresolved: While ASPIRE shows promising results, it's important to understand how it compares to other data augmentation approaches in terms of effectiveness, efficiency, and applicability to different datasets and tasks.
- What evidence would resolve it: A comparison of ASPIRE with other data augmentation techniques (e.g., Mixup, CutMix, AugMix) on the same datasets and tasks, evaluating both worst-group accuracy and overall performance.

## Limitations

- Heavy reliance on LLM performance for foreground/background extraction without validation against human annotations
- Assumption that edited images used for diffusion personalization accurately represent non-spurious distribution is not thoroughly validated
- Computational cost of the 6-step pipeline, particularly LLM calls and diffusion model personalization, is substantial and not thoroughly discussed for practical deployment

## Confidence

**High Confidence**: The general approach of using text-guided image editing to remove spurious features and generate augmentations is technically sound and well-motivated. The experimental results showing 1-38% improvements in worst-group accuracy across four datasets provide strong evidence that the method works as intended when all components function correctly.

**Medium Confidence**: The specific mechanism of using LLMs for foreground/background extraction is plausible but not thoroughly validated. While the paper describes the approach, it doesn't provide rigorous evaluation of whether the LLM-guided extraction actually identifies spurious features more accurately than alternative methods.

**Low Confidence**: The scalability and generalizability claims are not well-supported. The paper demonstrates success on four specific datasets but doesn't address how the method would perform on datasets with more complex spurious correlations or in different domains beyond image classification.

## Next Checks

1. **LLM Extraction Validation**: Compare the LLM-guided foreground/background extraction results against human-annotated segmentations on a subset of images to quantify accuracy and identify failure modes in spurious feature identification.

2. **Generation Quality Analysis**: Perform systematic evaluation of the generated augmentations' quality by measuring distribution matching between original and augmented datasets, including both visual inspection and quantitative metrics like FID scores.

3. **Ablation Study on Components**: Conduct ablation experiments removing individual components (LLM extraction, diffusion personalization, etc.) to isolate which parts of the pipeline contribute most to the observed performance improvements and identify potential bottlenecks.