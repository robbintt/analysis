---
ver: rpa2
title: 'UPFL: Unsupervised Personalized Federated Learning towards New Clients'
arxiv_id: '2307.15994'
source_url: https://arxiv.org/abs/2307.15994
tags:
- clients
- learning
- fedtta
- client
- prediction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of unsupervised personalized federated
  learning (UPFL) for new clients who join after the model is deployed. The key challenge
  is to provide personalized models for these new clients using only their unlabeled
  data, without requiring labeled data or compromising the privacy of existing clients.
---

# UPFL: Unsupervised Personalized Federated Learning towards New Clients

## Quick Facts
- arXiv ID: 2307.15994
- Source URL: https://arxiv.org/abs/2307.15994
- Reference count: 40
- One-line primary result: FedTTA achieves up to 10% higher accuracy on new clients compared to 11 baselines

## Executive Summary
This paper addresses unsupervised personalized federated learning (UPFL) for new clients joining after model deployment, where only unlabeled data is available. The authors propose FedTTA, which extends adaptive risk minimization to federated learning by meta-learning a base prediction model and an adaptation model per client. The method is enhanced with regularization to improve generalization and entropy-based early stopping to prevent overfitting, with a heterogeneous variant using knowledge distillation for clients with different model structures.

## Method Summary
The paper proposes FedTTA for UPFL, where each client trains a base prediction model and an adaptation model that can personalize the base model using only unlabeled data. The method includes FedTTA-Prox with KL regularization to improve adaptation capability, and FedTTA++ with entropy-based early stopping. A heterogeneous variant, HeteroFedTTA, handles varying model structures using knowledge distillation. The approach is evaluated on five datasets (MNIST, CIFAR-10, FEMNIST, CIFAR-100, Fashion-MNIST) with 100 clients each, showing significant improvements over 11 baselines.

## Key Results
- FedTTA achieves up to 10% higher accuracy on new clients compared to baselines
- FedTTA++ shows improved robustness to small dataset sizes and distribution shifts
- HeteroFedTTA successfully handles varying model structures across clients

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Meta-learning a base prediction model and an adaptation model enables quick personalization for new unlabeled clients.
- Mechanism: Each client trains a shared base model and a local adaptation model. At inference, the adaptation model guides one-step updates of the base model using only unlabeled data, producing a personalized prediction model.
- Core assumption: The adaptation model can learn to produce useful personalization directions from unlabeled data without access to labels.
- Evidence anchors:
  - [abstract] "Each client learns a base prediction model and an adaptation model that can quickly personalize the base model for new unlabeled data."
  - [section 3.2] "The adaptation model ð‘” is responsible for customizing the base prediction model to a personalized prediction model."
  - [corpus] No direct evidence; mechanism is derived from the paper's proposed architecture.
- Break condition: If the adaptation model fails to capture meaningful patterns in the unlabeled data, the personalization will be ineffective or harmful.

### Mechanism 2
- Claim: Regularizing the base model's outputs with KL divergence from a server model improves the adaptation model's personalization capability.
- Mechanism: During training, the base model's predictions are regularized to stay close to the server's average predictions, preventing overfitting and making adaptation tasks clearer.
- Core assumption: A more generalizable base model allows the adaptation model to focus on personalization rather than correcting base model errors.
- Evidence anchors:
  - [section 3.3.1] "We constrain the outputs of the local base prediction model to approach that of the server prediction model... which enables the adaptation model to be effectively trained to adapt a general prediction model into a personalized one."
  - [abstract] "We further improve FedTTA with two simple yet effective optimization strategies: enhancing the training of the adaptation model with proxy regularization..."
- Break condition: If regularization is too strong, the base model may lose client-specific information, limiting personalization potential.

### Mechanism 3
- Claim: Early stopping the adaptation process based on entropy of predictions prevents overfitting and improves personalization quality.
- Mechanism: During inference, adaptation continues until prediction entropy stops decreasing, indicating the model has reached optimal personalization without overfitting.
- Core assumption: Personalized models naturally produce lower entropy predictions, and entropy plateaus when optimal personalization is achieved.
- Evidence anchors:
  - [section 3.3.2] "We propose to utilize the entropy of the personalized model's predictions as an unsupervised metric for early stopping of the adaptation process..."
  - [abstract] "...early stopping the adaptation through entropy."
- Break condition: If entropy does not correlate well with personalization quality, early stopping may terminate too early or too late.

## Foundational Learning

- Concept: Adaptive Risk Minimization (ARM)
  - Why needed here: ARM provides the meta-learning framework for training models that can adapt to new tasks with minimal data, which is exactly the goal for new clients in federated learning.
  - Quick check question: What is the key difference between ARM and standard supervised learning in terms of training objectives?

- Concept: Test-Time Adaptation (TTA)
  - Why needed here: TTA techniques allow models to adapt to test data distributions without labels, enabling personalization for unlabeled new clients.
  - Quick check question: How does entropy minimization in TTA relate to the early stopping mechanism used in FedTTA++?

- Concept: Knowledge Distillation (KD)
  - Why needed here: KD enables heterogeneous clients with different model architectures to transfer knowledge, crucial for the HeteroFedTTA variant.
  - Quick check question: Why does the proposed KD loss in HeteroFedTTA separate distillation of base and personalized models?

## Architecture Onboarding

- Component map: Base prediction model (f) -> Adaptation model (g) -> Personalized prediction model
- Critical path: Training phase â†’ Server aggregation â†’ Testing phase (download â†’ adapt â†’ predict)
- Design tradeoffs: Simpler models vs. adaptation capacity; stronger regularization vs. personalization flexibility; entropy patience vs. adaptation time
- Failure signatures: Poor personalization accuracy, unstable entropy curves, overfitting to local data, communication bottlenecks
- First 3 experiments:
  1. Validate base FedTTA training convergence on a single client with known labels
  2. Test adaptation quality on a new client with small unlabeled dataset
  3. Measure entropy-based early stopping effectiveness across different dataset sizes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of FedTTA and its variants scale with increasing numbers of clients and data heterogeneity?
- Basis in paper: [inferred] The paper mentions the practical challenge of handling new clients with varying data distributions and model structures, but does not provide extensive experiments on scaling the methods to large numbers of clients or highly heterogeneous environments.
- Why unresolved: Scaling federated learning methods to large numbers of clients and highly heterogeneous environments is a significant challenge that requires further investigation.
- What evidence would resolve it: Experiments on larger numbers of clients with more diverse data distributions and model structures, and analysis of the computational and communication costs of the methods.

### Open Question 2
- Question: How robust are FedTTA and its variants to concept drift and adversarial attacks in the federated learning setting?
- Basis in paper: [explicit] The paper mentions concept shift as a challenge in federated learning, but does not provide extensive experiments on the robustness of the methods to concept drift or adversarial attacks.
- Why unresolved: Robustness to concept drift and adversarial attacks is crucial for the practical deployment of federated learning methods, and requires further investigation.
- What evidence would resolve it: Experiments on datasets with concept drift and adversarial attacks, and analysis of the methods' performance under these conditions.

### Open Question 3
- Question: How can the knowledge distillation loss function proposed in HeteroFedTTA be further improved to enhance the transfer of knowledge in heterogeneous federated learning settings?
- Basis in paper: [explicit] The paper proposes a novel knowledge distillation loss function for HeteroFedTTA, but mentions that the current loss function is still not optimal and requires further improvement.
- Why unresolved: The knowledge distillation loss function is a crucial component of HeteroFedTTA, and its optimization is essential for achieving better performance in heterogeneous federated learning settings.
- What evidence would resolve it: Experiments on different knowledge distillation loss functions and analysis of their impact on the performance of HeteroFedTTA.

## Limitations
- The paper's evaluation lacks direct ablation studies showing how much performance depends on each proposed mechanism
- The heterogeneous variant's knowledge distillation approach is described but not extensively validated across diverse model architectures
- The paper assumes all new clients can be served by a single global server model, which may not hold in highly heterogeneous deployment scenarios

## Confidence
- **High confidence**: FedTTA's overall framework design and experimental superiority over baselines (10% accuracy gains consistently demonstrated across multiple datasets)
- **Medium confidence**: The specific contributions of each optimization strategy (proximity regularization and entropy early stopping) - while individually described, their isolated impact is not clearly quantified
- **Low confidence**: The scalability and practical deployment considerations for the heterogeneous variant with arbitrary model structures

## Next Checks
1. Conduct ablation studies removing either the regularization proxy or entropy early stopping to quantify their individual contributions to performance gains
2. Test FedTTA's performance when the distribution shift between training and new clients is artificially increased beyond the reported pathological non-IID settings
3. Evaluate the adaptation model's robustness when applied to client datasets significantly smaller than the training client datasets (e.g., <100 samples)