---
ver: rpa2
title: Subpopulation-Specific Synthetic EHR for Better Mortality Prediction
arxiv_id: '2305.16363'
source_url: https://arxiv.org/abs/2305.16363
tags:
- samples
- synthetic
- training
- data
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the problem of poor machine learning model performance
  on underrepresented subpopulations in EHR data, caused by imbalanced representation
  due to factors like demographics and clinical condition prevalence. The authors
  propose a novel ensemble framework that uses generative adversarial networks (GANs)
  to produce subpopulation-specific synthetic data.
---

# Subpopulation-Specific Synthetic EHR for Better Mortality Prediction

## Quick Facts
- arXiv ID: 2305.16363
- Source URL: https://arxiv.org/abs/2305.16363
- Reference count: 26
- Key outcome: GAN-based synthetic data generation improves mortality prediction performance on underrepresented subpopulations in EHR data while maintaining overall model performance

## Executive Summary
This paper addresses the challenge of poor machine learning model performance on underrepresented subpopulations in electronic health record (EHR) data, which often occurs due to imbalanced representation based on demographics and clinical condition prevalence. The authors propose an ensemble framework that generates subpopulation-specific synthetic data using Conditional Tabular Generative Adversarial Networks (CTGANs) to augment training sets for underrepresented groups. The approach demonstrates improved performance on underrepresented subpopulations compared to baseline models and traditional balancing techniques like SMOTE and RUS, while maintaining overall model performance. The method is evaluated on two real-world datasets from the MIMIC database, showing practical potential for improving model generalizability in clinical settings.

## Method Summary
The proposed method involves training a CTGAN for each underrepresented subpopulation separately on the original training data, then generating synthetic samples at varying percentages (0% to 1000%) to augment the training sets. Separate XGBoost prediction models are trained on these augmented datasets for each subpopulation. The framework treats subpopulations as abstract concepts that can be defined by any feature or combination of features, though the experiments focus on ethnicity as the population marker. The approach aims to improve model performance on underrepresented subpopulations by increasing their representation in the training data through realistic synthetic samples while maintaining overall model performance on the full dataset.

## Key Results
- GAN-based synthetic data generation significantly improves ROCAUC performance on underrepresented subpopulations compared to baseline models
- The approach outperforms traditional balancing techniques like SMOTE and RUS for subpopulation-specific modeling
- Performance improvements are maintained across varying levels of synthetic sample augmentation (0% to 1000% of original training set size)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic data generation using GANs improves model performance for underrepresented subpopulations by augmenting training data with realistic synthetic samples
- Mechanism: The Conditional Tabular GAN (CTGAN) is trained on each subpopulation separately, generating synthetic samples that mimic the statistical properties of the real data. These synthetic samples are added to the training set, effectively increasing the representation of underrepresented subpopulations
- Core assumption: The CTGAN can generate realistic synthetic samples that capture the underlying distribution of the real data for each subpopulation
- Evidence anchors:
  - [abstract] "Specifically, we train a GAN-based synthetic data generator for each SP and incorporate synthetic samples into each SP training set"
  - [section] "We trained a Conditional Tabular Generative Adversarial Network (CTGAN) [22] on each of the underrepresented SPs separately until convergence"
- Break condition: If the CTGAN fails to generate realistic synthetic samples that accurately represent the underlying distribution of the real data, the model performance for underrepresented subpopulations may not improve

### Mechanism 2
- Claim: Training subpopulation-specific models on augmented datasets leads to better generalization for underrepresented subpopulations compared to training a single model on the entire dataset
- Mechanism: Separate prediction models are trained on augmented datasets that include both real and synthetic samples for each subpopulation. This allows the models to learn the specific characteristics of each subpopulation, leading to improved performance on underrepresented subpopulations
- Core assumption: The augmented datasets, containing both real and synthetic samples, provide sufficient information for the models to learn the unique characteristics of each subpopulation
- Evidence anchors:
  - [abstract] "Ultimately, we train SP-specific prediction models"
  - [section] "Separate prediction models are then trained on these augmented datasets"
- Break condition: If the augmented datasets do not provide sufficient information for the models to learn the unique characteristics of each subpopulation, the performance improvement for underrepresented subpopulations may be limited

### Mechanism 3
- Claim: The proposed ensemble framework improves model performance for underrepresented subpopulations while maintaining overall performance on the entire dataset
- Mechanism: The ensemble framework combines the subpopulation-specific models trained on augmented datasets. This allows the framework to leverage the improved performance on underrepresented subpopulations while maintaining overall performance on the entire dataset
- Core assumption: The ensemble framework can effectively combine the subpopulation-specific models to achieve improved performance on underrepresented subpopulations without sacrificing overall performance
- Evidence anchors:
  - [abstract] "Our approach shows increased model performance over underrepresented SPs"
  - [section] "Our approach has the potential to improve the generalizability of machine learning models trained on EHRs by addressing the issue of underrepresentation"
- Break condition: If the ensemble framework fails to effectively combine the subpopulation-specific models, the overall performance on the entire dataset may be compromised

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: GANs are used to generate synthetic samples that mimic the statistical properties of the real data for each subpopulation
  - Quick check question: What is the main advantage of using GANs for synthetic data generation in this context?
- Concept: Imbalanced data handling techniques
  - Why needed here: The proposed method aims to address the issue of imbalanced representation of subpopulations in EHR data by generating synthetic samples to augment the training data
  - Quick check question: What are some common techniques for handling imbalanced data, and how does the proposed method differ from these techniques?
- Concept: Subpopulation-specific modeling
  - Why needed here: Training separate models for each subpopulation allows the models to learn the unique characteristics of each subpopulation, leading to improved performance on underrepresented subpopulations
  - Quick check question: Why is it beneficial to train subpopulation-specific models instead of a single model on the entire dataset?

## Architecture Onboarding

- Component map:
  MIMIC database query -> Data preprocessing (dropping missing values, label encoding) -> Subpopulation definition based on patient ethnicity -> Train-test split (65% train, 35% test) -> CTGAN training for each underrepresented subpopulation -> Synthetic sample generation (0% to 1000% of original training set size) -> XGBoost model training on augmented datasets -> Model evaluation using ROCAUC
- Critical path:
  1. Query MIMIC database for use case datasets
  2. Preprocess data and define subpopulations
  3. Split data into train and test sets
  4. Train CTGAN for each underrepresented subpopulation
  5. Generate synthetic samples and augment training sets
  6. Train XGBoost models on augmented datasets
  7. Evaluate model performance using ROCAUC
- Design tradeoffs:
  - Increased training time due to GAN training and synthetic sample generation
  - Potential for overfitting if synthetic samples do not accurately represent the real data
  - Improved performance on underrepresented subpopulations at the cost of increased complexity
- Failure signatures:
  - Poor synthetic sample quality (e.g., mode collapse in GAN training)
  - Overfitting on synthetic samples
  - Limited improvement in model performance for underrepresented subpopulations
- First 3 experiments:
  1. Train and evaluate a baseline XGBoost model on the original training data for each subpopulation
  2. Train CTGAN for each underrepresented subpopulation and generate synthetic samples at various percentages (e.g., 0%, 10%, 50%, 100%, 1000%)
  3. Train XGBoost models on augmented datasets (original + synthetic samples) and evaluate performance using ROCAUC for each subpopulation and the entire dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different subpopulation definitions (e.g., using combinations of features vs single features) affect the performance of the proposed GAN-based ensemble framework?
- Basis in paper: [explicit] The paper states "our approach treats SP as an abstract concept and can be replicated using any feature or combination of features in the dataset, e.g., age group, lab results, vital signs, a combination of demographic features, etc."
- Why unresolved: The experiments only use ethnicity as the population marker, limiting understanding of how different subpopulation definitions impact performance
- What evidence would resolve it: Conducting experiments with various subpopulation definitions (demographic combinations, clinical features, etc.) and comparing performance across these definitions would clarify the framework's generalizability to different subpopulation definitions

### Open Question 2
- Question: What is the optimal amount of synthetic data to generate for underrepresented subpopulations to maximize model performance?
- Basis in paper: [explicit] The paper mentions generating synthetic samples in amounts ranging from 0% to 1000% of the original training set size but doesn't determine an optimal range
- Why unresolved: The paper evaluates a wide range of synthetic sample percentages but doesn't identify a specific optimal percentage or range that consistently maximizes performance across different datasets and subpopulations
- What evidence would resolve it: Conducting experiments with different synthetic data generation ratios and analyzing performance trends would help identify optimal generation amounts for various scenarios

### Open Question 3
- Question: How does the proposed framework compare to other synthetic data generation methods beyond CTGAN?
- Basis in paper: [inferred] The paper only uses CTGAN for synthetic data generation and compares results to SMOTE and RUS, but doesn't explore other synthetic data generation methods
- Why unresolved: The evaluation is limited to one synthetic data generation method (CTGAN), making it unclear how the framework would perform with other state-of-the-art synthetic data generation techniques
- What evidence would resolve it: Implementing and evaluating the framework using different synthetic data generation methods (e.g., other GAN variants, VAEs) and comparing results would provide insights into the framework's flexibility and performance with various synthetic data generation approaches

## Limitations

- The paper's claims about improved subpopulation performance rely heavily on CTGAN's ability to generate realistic synthetic samples, but the quality of synthetic data generation is not directly validated beyond downstream model performance metrics
- The subpopulation definition based solely on ethnicity may not capture the full complexity of clinical heterogeneity, potentially limiting generalizability to other subpopulation definitions or clinical use cases
- The optimal amount of synthetic data to generate for underrepresented subpopulations remains unclear, as the paper evaluates a wide range but doesn't identify a specific optimal percentage or range

## Confidence

- **High confidence**: The methodological framework for GAN-based synthetic data generation and subpopulation-specific modeling is well-established and clearly described
- **Medium confidence**: Performance improvements on underrepresented subpopulations are demonstrated, but the extent of improvement varies significantly across different subpopulations and synthetic sample percentages
- **Medium confidence**: The comparison with SMOTE and RUS baselines shows competitive performance, though the relative effectiveness depends on the specific dataset and subpopulation

## Next Checks

1. **Synthetic Data Quality Validation**: Generate synthetic samples for a held-out validation set and perform statistical similarity tests (e.g., Kolmogorov-Smirnov) to verify that synthetic data distributions match real data distributions for key features
2. **Ablation Study on Subpopulation Definition**: Test alternative subpopulation definitions (e.g., age groups, disease severity) to determine if ethnicity is the optimal dimension for subpopulation-specific modeling
3. **Generalizability Testing**: Apply the framework to a third external EHR dataset with different characteristics to assess whether performance improvements generalize beyond the MIMIC database