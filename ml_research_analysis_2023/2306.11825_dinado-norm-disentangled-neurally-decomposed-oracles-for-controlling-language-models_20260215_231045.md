---
ver: rpa2
title: 'DiNADO: Norm-Disentangled Neurally-Decomposed Oracles for Controlling Language
  Models'
arxiv_id: '2306.11825'
source_url: https://arxiv.org/abs/2306.11825
tags:
- nado
- distribution
- generation
- constraints
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses challenges in the NADO (NeurAlly-Decomposed
  Oracle) approach for controllable text generation with large language models. NADO
  aims to avoid catastrophic forgetting and achieve guaranteed convergence to an entropy-maximized
  solution, but suffers from gradient vanishing for low-probability control signals
  and limited capacity.
---

# DiNADO: Norm-Disentangled Neurally-Decomposed Oracles for Controlling Language Models

## Quick Facts
- arXiv ID: 2306.11825
- Source URL: https://arxiv.org/abs/2306.11825
- Authors: 
- Reference count: 4
- Key outcome: DiNADO improves NADO by disentangling the step-wise global norm over the approximated oracle R-value, enabling better combination with finetuning methods like LoRA and addressing gradient vanishing for low-probability control signals.

## Executive Summary
DiNADO (norm-Disentangled NeurAlly-Decomposed Oracles) addresses fundamental limitations in the NADO framework for controllable text generation with large language models. The original NADO approach suffers from gradient vanishing for low-probability control signals and limited capacity when combined with finetuning methods. DiNADO improves upon NADO through three key innovations: disentangling the step-wise global norm over approximated oracle R-values, employing likelihood re-weighting importance sampling, and enabling guaranteed compositional generalization for multiple constraints. The method demonstrates superior performance on tasks including lexically constrained generation on CommonGen and formality control in machine translation.

## Method Summary
DiNADO builds on the NADO framework by modifying how oracle R-values are parameterized and estimated. The core innovation is disentangling the global normalization factor from per-token oracle estimation, allowing the method to be combined with parameter-efficient finetuning approaches like LoRA. Additionally, DiNADO employs likelihood re-weighting importance sampling to address gradient variance issues, particularly for control signals with low satisfaction rates. The framework also introduces mechanisms for compositional generalization when handling multiple constraints, either through cascading NADO layers or embedding-based transformations. The method is evaluated on the CommonGen dataset for lexically constrained generation and on machine translation tasks for formality control.

## Key Results
- DiNADO achieves better performance than NADO on CommonGen lexically constrained generation tasks, improving BLEU, CIDEr, and Coverage metrics.
- The method demonstrates effective formality control in machine translation while maintaining translation quality.
- DiNADO successfully combines with LoRA finetuning, enhancing model capacity without catastrophic forgetting.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DiNADO improves NADO by disentangling the step-wise global norm over the approximated oracle R-value, enabling better combination with finetuning methods like LoRA.
- Mechanism: The disentanglement separates the scaling factor (global norm) from the per-token oracle estimation, allowing more stable gradient updates and compatibility with parameter-efficient finetuning.
- Core assumption: The per-token oracle R-values can be independently estimated without losing information about the global scaling required for proper normalization.
- Evidence anchors:
  - [abstract]: "DiNADO (norm-Disentangled NeurAlly-Decomposed Oracles), which improves the performance of the NADO algorithm through disentangling the step-wise global norm over the approximated oracle $R$-value for all potential next-tokens, allowing DiNADO to be combined with finetuning methods like LoRA."
  - [section 3.2]: "We hereby proposes a new parameterization of NADO that tackles this problem. In the original NADO algorithm, we directly estimate the expected oracle with a parameterized model RC θ (x, y≤i). In the new parameterization, we try to eliminate the effect of different scaling (i.e. τ in the previous formulation)."

### Mechanism 2
- Claim: DiNADO addresses gradient vanishing for low-probability control signals through importance sampling and likelihood re-weighting.
- Mechanism: Instead of uniform random sampling from the base distribution, DiNADO uses a truncated distribution based on likelihood re-weighting to better represent the true distribution and reduce gradient variance.
- Core assumption: The truncated distribution using likelihood re-weighting can approximate the original distribution sufficiently well while reducing gradient variance.
- Evidence anchors:
  - [section 3.3.1]: "We now consider a better strategy for choosing a proxy distribution and perform importance sampling to reduce the variance of gradient... Specifically, we collect a set (i.e. the collection of unique elements) of decoded data as the truncation basis, and use the original distribution p to assign a normalized weight for each of the unique basis samples."
  - [section 3.3]: "We now concern the variance of gradient w.r.t. RC θ (x, y<i)... For cases where with a high probability C(x, y) >> R θ(x, y≤i), this term in the vanilla parameterization of NADO causes instability due to vanishing/explosive gradient during training."

### Mechanism 3
- Claim: DiNADO enables guaranteed compositional generalization under unitarily i.i.d. constraints by cascading NADO layers for each constraint.
- Mechanism: Each NADO layer handles one constraint independently, and their outputs are multiplied together, maintaining bounds on error accumulation across layers.
- Core assumption: The constraints are either statistically independent or can be made approximately independent through proper embedding transformations.
- Evidence anchors:
  - [section 3.4.1]: "If each constraint within the composition is statistically independent, we can train an individual density ratio function R for each constraint using the base distribution p, until we can bound the generalization error of R under the assumption of unitary i.i.d. by δ on the log-scale. Then, during the test phase, we can directly multiply the corresponding corrective terms induced by the constraints Ci with the base distribution p."
  - [section 3.4]: "Third, we analyze the challenges of directly using NADO in a compositional manner. To address this, we re-adjust the dependencies between different hierarchies of NADOs. With some necessary approximations and assumptions, we can achieve guaranteed compositional generalization."

## Foundational Learning

- Concept: Autoregressive language models and their parameterization
  - Why needed here: DiNADO builds on autoregressive models' ability to generate sequences token-by-token, with each step depending on previous tokens. Understanding this sequential nature is crucial for grasping how NADO and DiNADO modify the generation process.
  - Quick check question: In an autoregressive model, how is the probability of a sequence decomposed across tokens?

- Concept: Importance sampling and variance reduction
  - Why needed here: DiNADO uses importance sampling to address gradient variance issues. Understanding how importance sampling works and why it reduces variance is essential for grasping this improvement.
  - Quick check question: How does importance sampling reduce variance compared to direct sampling from the target distribution?

- Concept: Bellman equations and reinforcement learning
  - Why needed here: NADO's original design is based on the stochastic Bellman equation, and DiNADO modifies this framework. Understanding Bellman equations helps explain why NADO works and what DiNADO changes.
  - Quick check question: What is the relationship between the Bellman equation and the forward-consistency regularization in NADO?

## Architecture Onboarding

- Component map: Base language model (p(y|x)) -> NADO layers -> Constraint functions (C(x,y)) -> Importance sampling module -> Compositional cascade -> Modified distribution -> Generated text

- Critical path: Base model → NADO layer(s) → Constraint satisfaction → Modified distribution → Generated text

- Design tradeoffs:
  - Capacity vs. efficiency: NADO adds layers but aims to avoid full fine-tuning
  - Complexity vs. generalization: More NADO layers improve control but increase error bounds
  - Sampling efficiency vs. approximation accuracy: Importance sampling reduces variance but may miss rare events

- Failure signatures:
  - Gradient vanishing/exploding: Indicates issues with importance sampling or normalization
  - Catastrophic forgetting: Suggests NADO layers are modifying base model behavior too aggressively
  - Poor compositional generalization: Indicates constraint dependencies not properly handled

- First 3 experiments:
  1. Verify DiNADO's disentangled parameterization maintains equivalent output to NADO on simple constraints
  2. Test importance sampling's effectiveness by comparing gradient variance with uniform sampling
  3. Validate compositional generalization by running NADO with multiple constraints and measuring error bounds

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical guarantee for compositional generalization when using NADO to handle multiple weakly-dependent constraints?
- Basis in paper: [explicit] The paper discusses the challenges of directly using NADO in a compositional manner and proposes a solution for weakly-dependent constraints. It mentions that the analysis may not be entirely rigorous or comprehensive, and extensive assumptions and analyses could be intractable naturally.
- Why unresolved: The paper acknowledges that the analysis may not be entirely rigorous or comprehensive due to the highly data-specific nature of the problem. It also mentions that extensive assumptions and analyses could be intractable naturally.
- What evidence would resolve it: A more rigorous theoretical analysis that provides a comprehensive guarantee for compositional generalization when using NADO to handle multiple weakly-dependent constraints.

### Open Question 2
- Question: How does the improved parameterization of NADO, which disentangles the step-wise global norm over the approximated oracle R-value, affect the performance of NADO in terms of capacity, stability, and flexibility?
- Basis in paper: [explicit] The paper proposes an improved parameterization of NADO that disentangles the step-wise global norm over the approximated oracle R-value, allowing DiNADO to be combined with finetuning methods like LoRA. It mentions that this improves the performance of NADO in terms of capacity, stability, and flexibility.
- Why unresolved: While the paper discusses the improvements in capacity, stability, and flexibility, it does not provide a detailed quantitative analysis of how the improved parameterization affects these aspects of NADO's performance.
- What evidence would resolve it: A detailed quantitative analysis that demonstrates the specific improvements in capacity, stability, and flexibility achieved by the improved parameterization of NADO.

### Open Question 3
- Question: How does the likelihood re-weighting importance sampling strategy affect the efficiency and accuracy of training NADO, especially for control signals with low satisfaction rates?
- Basis in paper: [explicit] The paper introduces likelihood re-weighting importance sampling to address the inefficiency of the original random sampling strategy of NADO for training a model to tackle control signals with low satisfaction rates. It mentions that this strategy minimizes the fKL between the truncated distribution and original distribution.
- Why unresolved: While the paper introduces the likelihood re-weighting importance sampling strategy, it does not provide a detailed analysis of how this strategy affects the efficiency and accuracy of training NADO, especially for control signals with low satisfaction rates.
- What evidence would resolve it: A detailed analysis that demonstrates the improvements in efficiency and accuracy achieved by the likelihood re-weighting importance sampling strategy when training NADO for control signals with low satisfaction rates.

## Limitations
- The theoretical guarantees for compositional generalization may not translate to practical performance improvements when constraints have complex dependencies.
- The evaluation is limited to specific domains (CommonGen, formality control) without extensive testing across diverse controlled generation tasks.
- The interaction between multiple technical improvements (norm-disentanglement, importance sampling, compositional generalization) is not fully isolated through ablation studies.

## Confidence
- **High confidence**: The core problem of gradient vanishing in NADO and the basic solution of disentangling global norms is well-supported. The need for importance sampling in low-probability control signals is clearly demonstrated.
- **Medium confidence**: The effectiveness of DiNADO compared to NADO on the specific tasks tested (CommonGen, formality control) is reasonably supported, though the improvements could be partially attributed to increased model capacity rather than the proposed innovations alone.
- **Low confidence**: The theoretical claims about guaranteed compositional generalization and the specific error bounds provided are not adequately validated through extensive empirical testing across diverse constraint compositions.

## Next Checks
1. **Ablation study**: Systematically remove each of the three main DiNADO improvements (norm-disentanglement, importance sampling, compositional generalization) to measure their individual contributions to performance gains.

2. **Cross-domain validation**: Test DiNADO on at least three additional controlled generation tasks beyond CommonGen and formality control (e.g., sentiment-controlled generation, topic-constrained generation) to assess generalizability.

3. **Constraint dependency analysis**: Design experiments specifically targeting cases where constraints have known dependencies, measuring whether the claimed compositional generalization bounds hold or break down in practice.