---
ver: rpa2
title: 'A Survey for Federated Learning Evaluations: Goals and Measures'
arxiv_id: '2308.11841'
source_url: https://arxiv.org/abs/2308.11841
tags:
- learning
- data
- federated
- evaluation
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper surveys evaluation goals and metrics for federated learning
  (FL), highlighting the need for comprehensive assessment across utility, efficiency,
  and security/privacy. It categorizes evaluation goals into utility (effectiveness
  and robustness), efficiency (communication and computation), and security/privacy
  (data privacy and model security).
---

# A Survey for Federated Learning Evaluations: Goals and Measures

## Quick Facts
- arXiv ID: 2308.11841
- Source URL: https://arxiv.org/abs/2308.11841
- Reference count: 40
- Primary result: Comprehensive survey of federated learning evaluation goals and metrics, introducing FedEval platform for standardized assessment across utility, efficiency, and security/privacy dimensions.

## Executive Summary
This survey provides a systematic examination of federated learning evaluation, categorizing assessment goals into three orthogonal dimensions: utility (effectiveness and robustness), efficiency (communication and computation), and security/privacy (data privacy and model security). The authors introduce FedEval, an open-source platform that standardizes FL evaluation through Docker container simulation, built-in datasets and models, and customizable federated training strategies. The paper emphasizes the importance of comprehensive evaluation to understand trade-offs between competing goals and proposes future directions including real-time security monitoring and standardized metrics.

## Method Summary
The survey employs a systematic literature review approach, analyzing existing FL evaluation methodologies across three major goal categories. The authors developed FedEval as a practical implementation of their framework, using Docker containers to simulate FL environments with socket IO communication between clients and servers. The platform provides configurable data settings, model architectures, and federated training strategies, allowing researchers to evaluate FL algorithms across multiple dimensions. The evaluation methodology includes both theoretical analysis and empirical validation through standardized benchmarks.

## Key Results
- Comprehensive categorization of FL evaluation goals into utility, efficiency, and security/privacy dimensions
- Introduction of FedEval platform with 7 standard datasets and multiple ML models for reproducible FL evaluation
- Identification of inherent trade-offs between evaluation goals, such as privacy protection reducing system efficiency
- Documentation of current limitations in FL evaluation, including lack of standardized metrics and real-time security assessment capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Comprehensive evaluation goals categorization (utility, efficiency, security/privacy) enables structured benchmarking of federated learning systems.
- Mechanism: By decomposing FL evaluation into three orthogonal dimensions, the survey provides a mental framework that prevents overlooking critical aspects such as model security or communication overhead.
- Core assumption: All relevant evaluation goals can be captured under these three categories without losing important nuances.
- Evidence anchors:
  - [abstract] explicitly lists "utility, efficiency, and security/privacy" as the three major goals.
  - [section II] further decomposes each goal into sub-aspects like "effectiveness, robustness" for utility and "communication, computation" for efficiency.
  - [corpus] shows related surveys also focus on these three pillars (e.g., "utility, privacy leakage, and communication efficiency").
- Break condition: If new FL scenarios emerge with goals outside these three categories (e.g., regulatory compliance), the framework becomes incomplete.

### Mechanism 2
- Claim: FedEval platform standardizes FL evaluation by providing reusable datasets, models, and evaluation strategies.
- Mechanism: The platform abstracts away the setup complexity so researchers can focus on algorithm design rather than infrastructure, enabling reproducible comparisons.
- Core assumption: The built-in datasets and models are representative of real-world FL scenarios.
- Evidence anchors:
  - [section IV] describes FedEval's architecture: "Data Config and the FedData module," "Model Config and the Keras.Model module," and "Runtime Config and the strategy module."
  - [corpus] lists multiple FL evaluation platforms (FedML, FedScale) indicating community need for standardization.
- Break condition: If FedEval's built-in components do not cover emerging data modalities or model architectures, researchers must implement custom components, reducing standardization benefit.

### Mechanism 3
- Claim: Trade-off analysis between utility, efficiency, and security/privacy helps practitioners make informed design decisions.
- Mechanism: By explicitly documenting that improving one dimension often degrades another (e.g., differential privacy reduces utility), the survey guides balanced system design.
- Core assumption: Practitioners understand these trade-offs and can weigh them based on application requirements.
- Evidence anchors:
  - [section II-D] provides concrete examples: "FedAvg improves communication efficiency by increasing clients' local training rounds before the global synchronization" but "drift the global model away from global optimum under heterogeneous data distributions."
  - [section II-D] also notes "privacy protection generally downgrades the efficiency of the system."
- Break condition: If practitioners lack domain knowledge to evaluate trade-offs, they may make suboptimal choices despite understanding the trade-offs.

## Foundational Learning

- Concept: Non-IID data distribution
  - Why needed here: Non-IID data is a core challenge in FL that affects model convergence and requires specialized evaluation metrics.
  - Quick check question: What are the two main types of non-IID data distribution described in the paper?

- Concept: Byzantine attacks in federated learning
  - Why needed here: Byzantine attacks represent a critical security threat that can poison models and degrade utility, requiring evaluation of defense mechanisms.
  - Quick check question: How do Byzantine attacks differ from backdoor attacks in their objectives?

- Concept: Differential privacy in FL
  - Why needed here: Differential privacy is a key technique for protecting data privacy in FL but introduces trade-offs with utility that must be evaluated.
  - Quick check question: What is the relationship between the amount of noise added for differential privacy and model utility?

## Architecture Onboarding

- Component map:
  Data layer -> FedData module with built-in datasets (MNIST, CIFAR10, FEMNIST, etc.) and configurable non-IID settings
  Model layer -> Keras.Model-based models (MLP, LeNet, StackedLSTM) that can be extended
  Strategy layer -> FedEval strategy module defining upload protocol, server aggregation, client training, and model incorporation
  Runtime layer -> Docker containers for simulating clients and servers with socket IO communication
  Evaluation layer -> Metrics for utility (accuracy, robustness), efficiency (rounds, amount, time), and security/privacy (theoretical proofs, empirical attacks)

- Critical path: Define data config → Select or implement model → Implement strategy callbacks → Run evaluation → Analyze results

- Design tradeoffs:
  - Dataset coverage vs. evaluation comprehensiveness: Built-in datasets may not represent all application domains
  - Model simplicity vs. realism: Simple models are easier to implement but may not reflect complex real-world scenarios
  - Theoretical rigor vs. practical relevance: Formal proofs provide strong guarantees but may not capture all practical attack vectors

- Failure signatures:
  - Low accuracy variance across runs suggests implementation issues or insufficient randomization
  - Disproportionate communication overhead indicates inefficient aggregation strategy
  - Security metrics showing no degradation under attacks suggests inadequate attack implementation

- First 3 experiments:
  1. Compare FedAvg vs. FedSGD on MNIST with IID data to establish baseline utility-efficiency trade-off
  2. Evaluate FedProx vs. FedOpt on FEMNIST with non-IID data to test robustness under data heterogeneity
  3. Implement a simple gradient inversion attack on FedAvg to verify data privacy evaluation capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop standardized evaluation metrics that are compatible across different federated learning scenarios and applications?
- Basis in paper: [explicit] The paper discusses the lack of compatible evaluation metrics in Section V-B, noting that different studies often focus on different aspects (e.g., communication efficiency vs. computation efficiency) making direct comparisons difficult.
- Why unresolved: Different FL applications have varying priorities (e.g., privacy vs. speed), and existing metrics are often tailored to specific use cases, preventing fair cross-study comparisons.
- What evidence would resolve it: A universally accepted set of metrics that can be applied across diverse FL scenarios, validated through extensive benchmarking on multiple datasets and application types.

### Open Question 2
- Question: What are the most effective strategies for conducting real-time and continuous security/privacy evaluations in federated learning systems?
- Basis in paper: [explicit] Section V-C highlights the need for real-time and continuous verification to detect attacks and monitor participant behavior, as threats can occur at any stage of FL training.
- Why unresolved: Existing evaluation methods are often static and post-hoc, failing to provide ongoing protection against evolving attack vectors in dynamic FL environments.
- What evidence would resolve it: Implementation and validation of a real-time monitoring system that can detect and mitigate security/privacy threats during live FL training sessions across various attack scenarios.

### Open Question 3
- Question: How can we effectively balance the trade-offs between utility, efficiency, and security/privacy in federated learning systems for practical applications?
- Basis in paper: [explicit] Section II-D discusses the inherent trade-offs between these three goals, such as the efficiency cost of privacy-preserving techniques and the utility loss from differential privacy.
- Why unresolved: Different applications have different priorities, and there is no one-size-fits-all solution for balancing these competing objectives in a way that satisfies all stakeholders.
- What evidence would resolve it: A comprehensive framework or decision-making tool that allows practitioners to quantify and optimize the trade-offs between utility, efficiency, and security/privacy based on specific application requirements and constraints.

## Limitations
- The three-dimensional evaluation framework may not capture emerging goals like regulatory compliance or environmental impact
- FedEval's built-in datasets and models may not represent all real-world FL scenarios, limiting generalizability
- Security/privacy evaluation section lacks specific attack implementations and metrics, making practical assessment difficult

## Confidence

**High**: The three-dimensional evaluation framework (utility, efficiency, security/privacy) is well-established in the literature
**Medium**: FedEval platform provides useful standardization but may have limited coverage of emerging FL scenarios
**Low**: Security/privacy evaluation mechanisms lack specific implementation details for reproducibility

## Next Checks
1. Test FedEval with custom datasets and models outside the built-in library to assess extensibility
2. Implement and evaluate specific privacy attacks (gradient inversion, membership inference) using FedEval's framework
3. Compare evaluation results between FedEval and other FL platforms (FedML, FedScale) to validate consistency