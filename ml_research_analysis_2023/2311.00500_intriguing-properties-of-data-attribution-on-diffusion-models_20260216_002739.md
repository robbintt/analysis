---
ver: rpa2
title: Intriguing Properties of Data Attribution on Diffusion Models
arxiv_id: '2311.00500'
source_url: https://arxiv.org/abs/2311.00500
tags:
- trak
- d-trak
- timesteps
- training
- attribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates data attribution methods for diffusion models,
  focusing on the trade-off between computational efficiency and effectiveness. It
  introduces D-TRAK, a variant of the TRAK method, which uses theoretically unjustified
  design choices that surprisingly outperform previous baselines.
---

# Intriguing Properties of Data Attribution on Diffusion Models

## Quick Facts
- arXiv ID: 2311.00500
- Source URL: https://arxiv.org/abs/2311.00500
- Reference count: 40
- Primary result: D-TRAK improves attribution performance by using theoretically unjustified design choices that empirically outperform previous baselines

## Executive Summary
This paper investigates data attribution methods for diffusion models, introducing D-TRAK as a variant of the TRAK method. The key finding is that empirically chosen design choices, such as using alternative loss functions (LSquare, L1-norm) instead of the training loss, consistently achieve higher linear datamodeling scores (LDS) and better counterfactual evaluation results. The work challenges the assumption that theoretically justified constructions are always superior in non-convex settings like diffusion models. Extensive experiments on CIFAR-10, CelebA, and ArtBench datasets demonstrate that D-TRAK consistently outperforms TRAK and other baselines, suggesting the need for further research into data attribution mechanisms.

## Method Summary
The paper introduces D-TRAK, a data attribution method for diffusion models that computes training sample importance by constructing attribution scores using gradients of alternative loss functions rather than the training loss. The method employs random projections to reduce computational complexity while preserving inner product relationships. Attribution quality is evaluated using linear datamodeling scores (LDS) based on Spearman rank correlation, and validated through counterfactual evaluation by retraining models with influential samples removed. The approach is tested on pre-trained DDPMs and Stable Diffusion models across multiple datasets.

## Key Results
- D-TRAK using LSquare, LAvg, and Lp-norm consistently achieves higher LDS scores than TRAK using LSimple across all tested datasets
- D-TRAK demonstrates better counterfactual evaluation performance, showing more faithful attribution of model outputs to training data
- The method is less sensitive to checkpoint selection than TRAK, consistently performing best with the final model checkpoint
- Alternative loss functions that lack theoretical justification for attribution tasks empirically outperform the theoretically motivated training loss

## Why This Works (Mechanism)

### Mechanism 1
- Claim: D-TRAK improves LDS scores by using alternative loss functions instead of the training loss in gradient calculation
- Mechanism: Theoretical construction assumes training loss gradients correlate with training data importance, but empirically alternative loss functions measuring different prediction aspects yield better attribution performance
- Core assumption: Theoretically justified constructions may not be optimal for practical attribution tasks in non-convex settings
- Evidence anchors: [abstract] "theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin" and [section 3.1] "using ϕs constructed by LSquare, LAvg, L2-norm, and L1-norm consistently achieve higher values of LDS"
- Break condition: If alternative loss functions no longer improve attribution performance, or if the model becomes convex

### Mechanism 2
- Claim: Random projection matrix P preserves inner products sufficiently for attribution purposes
- Mechanism: Projects high-dimensional gradients onto lower-dimensional space while maintaining essential relationships between training samples and reducing computational complexity
- Core assumption: Johnson-Lindenstrauss lemma holds, allowing random projections to preserve distances with high probability
- Evidence anchors: [section 2.3] "random projection matrix Ps is sampled from N (0, 1)d×k (typically there is k ≪ d)" and [appendix B] "dimension is increased, and the LDS scores of both TRAK and our method initially increase and gradually saturate"
- Break condition: If projection dimension k becomes too small to preserve meaningful relationships, or if random projections introduce systematic bias

### Mechanism 3
- Claim: Attribution performance is sensitive to checkpoint selection during gradient computation
- Mechanism: Different model checkpoints represent different training stages, and gradients at these checkpoints capture different aspects of training dynamics affecting attribution quality
- Core assumption: Model's behavior and gradients evolve meaningfully throughout training in a way that affects attribution quality
- Evidence anchors: [section 4.3] "for TRAK, using the final checkpoint is not the best choice" and "for D-TRAK, the best LDS scores are obtained at the final checkpoint" and [appendix B] "For D-TRAK, the best LDS scores are obtained at the final checkpoint. However, for TRAK, using the final checkpoint is not the best choice"
- Break condition: If model converges to stable state early in training, or if gradients become invariant to checkpoints

## Foundational Learning

- Concept: Diffusion models and denoising processes
  - Why needed here: Paper focuses on attributing diffusion models, so understanding their architecture and training process is essential
  - Quick check question: What is the difference between the forward and reverse diffusion processes in DDPMs?

- Concept: Influence functions and data attribution methods
  - Why needed here: Paper compares various attribution methods, so understanding how influence functions work is crucial
  - Quick check question: How do influence functions approximate the effect of up-weighting a training sample on model outputs?

- Concept: Linear datamodeling score (LDS) as an evaluation metric
  - Why needed here: Paper uses LDS as primary metric for evaluating attribution methods, so understanding its computation and interpretation is essential
  - Quick check question: How is the LDS metric computed using Spearman rank correlation between model outputs and attribution-based predictions?

## Architecture Onboarding

- Component map: Data attribution module -> Gradient computation -> Random projection -> LDS evaluation -> Counterfactual evaluation
- Critical path:
  1. Train diffusion model
  2. Compute gradients using different loss functions
  3. Apply random projections to gradients
  4. Calculate attribution scores
  5. Evaluate using LDS metric
  6. Validate using counterfactual evaluation
- Design tradeoffs:
  - Number of timesteps vs. computational cost
  - Projection dimension k vs. accuracy vs. efficiency
  - Loss function choice vs. theoretical justification vs. empirical performance
  - Checkpoint selection vs. attribution quality
- Failure signatures:
  - Poor LDS scores despite high computational cost
  - Inconsistent attribution across different checkpoints
  - Counterfactual evaluation shows no meaningful difference when removing top influencers
  - Attribution scores that don't correlate with visual similarity
- First 3 experiments:
  1. Implement D-TRAK with different loss functions (LSimple, LSquare, L1-norm) on CIFAR-2 and compare LDS scores
  2. Vary the projection dimension k and measure its effect on attribution performance and computational cost
  3. Test different checkpoint selections and evaluate their impact on attribution quality using both LDS and counterfactual evaluation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do theoretically unjustified design choices like LSquare outperform the theoretically motivated LSimple in D-TRAK for diffusion model attribution?
- Basis in paper: [explicit] Paper directly observes that LSquare and other alternative functions consistently outperform LSimple in linear datamodeling scores across multiple experiments
- Why unresolved: Paper notes this counter-intuitive result but does not provide theoretical explanation for why unjustified choices work better in non-convex settings
- What evidence would resolve it: Mathematical analysis showing how gradient structure of LSquare interacts with non-convex optimization landscape of diffusion models, or ablation studies comparing different loss function formulations

### Open Question 2
- Question: How does choice of checkpoint (epoch) affect attribution performance of TRAK versus D-TRAK, and why?
- Basis in paper: [explicit] Paper observes that D-TRAK consistently performs best with final checkpoint, while TRAK's optimal checkpoint varies and requires computationally expensive searching
- Why unresolved: Paper identifies this difference but doesn't explain underlying reason for why D-TRAK is less sensitive to checkpoint selection
- What evidence would resolve it: Analysis of how gradient stability and noise levels change across training epochs for diffusion models, and how these changes affect attribution quality differently for LSimple versus LSquare-based methods

### Open Question 3
- Question: What is relationship between self-influence scores and memorization in diffusion models, and how does D-TRAK capture this?
- Basis in paper: [explicit] Paper shows visualizations where high self-influence samples appear more unique or high-contrast, suggesting connection to memorization
- Why unresolved: While paper demonstrates visualization, it doesn't provide quantitative analysis of how self-influence relates to memorization or what this means for model behavior
- What evidence would resolve it: Correlation studies between self-influence scores, training loss patterns, and generation quality metrics, or experiments showing how removing high-self-influence samples affects model performance

## Limitations
- Empirical findings lack theoretical explanation for why alternative loss functions outperform training loss
- Experimental scope limited to three datasets and specific diffusion model architectures, limiting generalization claims
- Random projection approach depends on Johnson-Lindenstrauss lemma but doesn't quantify how well inner product preservation translates to attribution quality

## Confidence
**High confidence**: Experimental methodology for LDS computation and counterfactual evaluation is well-specified and reproducible; empirical results showing D-TRAK's superiority are clearly demonstrated across multiple datasets and metrics.

**Medium confidence**: Theoretical justification for why alternative loss functions work better than training loss is speculative; while empirical evidence is strong, lack of mechanistic understanding limits confidence in underlying reasons for observed improvements.

**Low confidence**: Generalization claims to other datasets, model architectures, or attribution tasks are not sufficiently supported by experiments; paper doesn't explore how D-TRAK performs on text models, larger-scale image datasets, or different attribution evaluation metrics.

## Next Checks
1. Conduct ablation studies that systematically vary each design choice (loss function type, projection dimension, checkpoint selection) to isolate their individual contributions to attribution performance, and test whether benefits persist across different model sizes and architectures.

2. Evaluate D-TRAK on additional datasets (e.g., ImageNet, medical imaging datasets) and model architectures (e.g., autoregressive models, transformers) to assess whether empirically superior design choices generalize beyond current experimental scope.

3. Develop theoretical framework explaining why alternative loss functions yield better attribution performance, potentially through analysis of gradient behavior in non-convex optimization landscapes or by establishing connections between attribution quality and specific properties of alternative loss functions.