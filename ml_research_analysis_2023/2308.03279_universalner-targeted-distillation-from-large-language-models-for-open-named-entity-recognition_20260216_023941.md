---
ver: rpa2
title: 'UniversalNER: Targeted Distillation from Large Language Models for Open Named
  Entity Recognition'
arxiv_id: '2308.03279'
source_url: https://arxiv.org/abs/2308.03279
tags:
- entity
- types
- data
- datasets
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of creating efficient, transparent
  models for open-domain named entity recognition (NER) by distilling capabilities
  from large language models (LLMs) like ChatGPT. The core method involves targeted
  distillation using mission-focused instruction tuning, where ChatGPT generates instruction-tuning
  data from diverse unlabeled web text, which is then used to train smaller UniversalNER
  (UniNER) models on LLaMA.
---

# UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition

## Quick Facts
- arXiv ID: 2308.03279
- Source URL: https://arxiv.org/abs/2308.03279
- Reference count: 16
- One-line primary result: UniNER models outperform ChatGPT in NER accuracy across tens of thousands of entity types, achieving 41.7% and 43.4% average F1 scores compared to ChatGPT's 34.9%

## Executive Summary
This paper introduces UniversalNER (UniNER), a novel approach for open-domain named entity recognition that leverages targeted distillation from large language models like ChatGPT. The core innovation involves using ChatGPT to generate instruction-tuning data from diverse unlabeled web text, which is then used to train smaller, efficient LLaMA-based models. UniNER demonstrates remarkable performance across tens of thousands of entity types, significantly outperforming both the original ChatGPT and state-of-the-art multi-task instruction-tuned systems. The approach addresses the challenge of creating efficient, transparent models for open NER by focusing on mission-specific instruction tuning rather than attempting to replicate the full capabilities of large language models.

## Method Summary
The UniversalNER approach employs mission-focused instruction tuning through a two-stage process. First, ChatGPT generates entity mentions and types from diverse passages sampled from the Pile corpus, converting NER annotations into conversation-style templates. Second, a pretrained LLaMA model is fine-tuned using this instruction-tuning data, incorporating frequency-based negative sampling and dataset-specific instruction tuning templates to resolve label conflicts. The method constructs a comprehensive dataset by sampling 50K passages, using ChatGPT to generate entity mentions and types, and applying frequency-based negative sampling to improve performance in closed-world settings. Dataset-specific templates are used during fine-tuning to harmonize label definitions across different NER datasets, enabling the model to learn dataset-specific semantics and resolve conflicts effectively.

## Key Results
- UniNER models achieve 41.7% and 43.4% average F1 scores across tens of thousands of entity types, outperforming ChatGPT's 34.9%
- Frequency-based negative sampling improves performance by 21.9% compared to no sampling and 5.7% compared to uniform sampling
- Dataset-specific instruction tuning templates resolve label conflicts and improve performance on overlapping datasets
- UniNER outperforms state-of-the-art multi-task instruction-tuned systems like InstructUIE by a large margin

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Targeted distillation with mission-focused instruction tuning enables smaller models to surpass the original LLM's performance on a specific application class.
- Mechanism: Instead of generic distillation aiming to approximate the full LLM capability, the approach focuses on maximizing performance within a targeted domain (NER). By generating instruction-tuning data using ChatGPT from diverse, unlabeled web text, and training a smaller LLaMA-based model with conversation-style templates and negative sampling, the student model learns to generalize across tens of thousands of entity types without direct supervision.
- Core assumption: The LLM can generate high-quality, diverse instruction-tuning data that captures the full spectrum of entity types needed for open NER, and this data can be used to effectively train a smaller model to outperform the original.
- Evidence anchors:
  - [abstract] "UniversalNER attains remarkable NER accuracy across tens of thousands of entity types, outperforming general instruction-tuned models such as Alpaca and Vicuna by over 30 absolute F1 points in average."
  - [section 3.1] Describes the data construction process using ChatGPT to generate entity mentions and types from diverse inputs sampled from the Pile corpus.
  - [corpus] Weak evidence; corpus only mentions "targeted distillation" without elaborating on the mechanism of how mission-focused instruction tuning leads to better performance.
- Break condition: If the generated instruction-tuning data is not diverse enough to cover the full range of entity types seen in evaluation, or if the conversation-style template and negative sampling are not effective, the student model will not outperform the original LLM.

### Mechanism 2
- Claim: Frequency-based negative sampling improves model performance by teaching the model to recognize entity types that are not present in a given passage.
- Mechanism: The data construction process only includes entity types that appear in the sampled passages (positive examples). To address this, the approach samples negative entity types from the collection of all entity types not mentioned in the passage, with probabilities proportional to their frequency in the dataset. This helps the model learn to output empty JSON lists for entity types that do not exist in the passage, improving performance in closed-world settings.
- Core assumption: Sampling negative entity types with probabilities proportional to their frequency in the dataset is more effective than uniform sampling or no sampling at all.
- Evidence anchors:
  - [section 3.2] "We sample negative entity types from the collection of all entity types that do not appear in the passage as queries and set the expected outputs as empty JSON lists."
  - [section 5.4] "Among the approaches tested, frequency-based sampling yielded the best results, outperforming no sampling and uniform sampling by 21.9% and 5.7%, respectively."
  - [corpus] Weak evidence; corpus only mentions "negative sampling" without explaining why frequency-based sampling is better.
- Break condition: If the frequency distribution of entity types in the dataset is not representative of the distribution in the evaluation data, frequency-based negative sampling may not be effective.

### Mechanism 3
- Claim: Dataset-specific instruction tuning templates resolve label conflicts between different NER datasets, improving model performance.
- Mechanism: Different NER datasets may have different label definitions for the same entity type (e.g., whether to include pronouns in PERSON). To address this, the approach uses dataset-specific instruction tuning templates that include the dataset name as an additional input. This allows the model to learn the dataset-specific semantics of labels and resolve conflicts during training.
- Core assumption: Including the dataset name as part of the input allows the model to learn the dataset-specific semantics of labels and resolve conflicts during training.
- Evidence anchors:
  - [section 3.2] "We augment the input with an additional field denoting the dataset name D. By doing so, the model can learn the dataset-specific semantics of labels."
  - [section 5.4] "We find that the data-specific template outperforms the original template on most datasets. Datasets with label overlap demonstrate more substantial improvements."
  - [corpus] Weak evidence; corpus only mentions "dataset-specific instruction tuning templates" without explaining how they resolve label conflicts.
- Break condition: If the label conflicts between datasets are too complex or numerous to be resolved by simply including the dataset name as an input, the dataset-specific instruction tuning templates may not be effective.

## Foundational Learning

- Concept: Large Language Models (LLMs) and their capabilities
  - Why needed here: The approach relies on using ChatGPT to generate instruction-tuning data and distilling its capabilities into a smaller model.
  - Quick check question: What are the key capabilities of LLMs that make them suitable for generating instruction-tuning data for NER?

- Concept: Instruction tuning and its effectiveness
  - Why needed here: The approach uses instruction tuning to adapt a pretrained LLaMA model for the specific task of open NER.
  - Quick check question: How does instruction tuning differ from traditional fine-tuning, and why is it effective for adapting models to new tasks?

- Concept: Negative sampling strategies
  - Why needed here: The approach uses frequency-based negative sampling to improve model performance in closed-world settings.
  - Quick check question: What is the purpose of negative sampling in NER, and why is frequency-based sampling more effective than uniform sampling or no sampling?

## Architecture Onboarding

- Component map:
  ChatGPT -> Instruction-tuning data generation -> LLaMA fine-tuning -> UniversalNER model

- Critical path:
  1. Sample passages from the Pile corpus
  2. Use ChatGPT to generate entity mentions and types for each passage
  3. Convert NER annotations into a conversation format using the conversation-style template
  4. Sample negative entity types using frequency-based negative sampling
  5. Fine-tune the LLaMA model using the instruction-tuning data and dataset-specific templates
  6. Evaluate the fine-tuned model on the Universal NER benchmark

- Design tradeoffs:
  - Using ChatGPT to generate instruction-tuning data vs. using human-annotated data: ChatGPT is faster and cheaper but may not be as accurate or diverse as human-annotated data
  - Conversation-style template vs. traditional NER-style template: Conversation-style template may be more effective for instruction tuning but may require more computational resources
  - Frequency-based negative sampling vs. uniform sampling or no sampling: Frequency-based negative sampling may be more effective but may require more computational resources to compute the frequency distribution

- Failure signatures:
  - If the fine-tuned model performs poorly on the evaluation datasets, it may indicate that the instruction-tuning data is not diverse enough or that the conversation-style template and negative sampling are not effective
  - If the fine-tuned model performs well on some datasets but poorly on others, it may indicate that the label conflicts between datasets are not being resolved effectively by the dataset-specific instruction tuning templates

- First 3 experiments:
  1. Evaluate the performance of the fine-tuned model on a small subset of the Universal NER benchmark to ensure that the instruction-tuning data is effective
  2. Compare the performance of the fine-tuned model with and without frequency-based negative sampling to ensure that negative sampling is effective
  3. Compare the performance of the fine-tuned model with and without dataset-specific instruction tuning templates to ensure that label conflicts are being resolved effectively

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of UniversalNER models vary across different entity frequency ranges, and what implications does this have for real-world applications?
- Basis in paper: [explicit] The paper mentions that entity types exhibit a heavy tail distribution, with the top 1% of entities accounting for 74% of total frequencies, and provides examples of entity types across different frequency ranges (top 1%, 1-10%, and 10-100%).
- Why unresolved: The paper does not provide detailed performance analysis across these frequency ranges, nor does it discuss the practical implications of this distribution for real-world applications.
- What evidence would resolve it: Detailed performance metrics of UniversalNER across different entity frequency ranges, along with case studies or simulations showing the impact of this distribution on real-world NER tasks.

### Open Question 2
- Question: What are the specific limitations of using entity type definitions instead of entity types in the instruction tuning process, and how can these limitations be mitigated?
- Basis in paper: [explicit] The paper mentions that using entity type definitions in the instruction tuning process leads to a more diverse set of entity types but performs worse on standard NER benchmarks.
- Why unresolved: The paper does not provide a detailed analysis of the specific limitations of using entity type definitions or suggest potential strategies to mitigate these limitations.
- What evidence would resolve it: Comparative analysis of the performance of UniversalNER models trained with entity type definitions versus entity types, along with proposed modifications to the instruction tuning process to address the identified limitations.

### Open Question 3
- Question: How does the performance of UniversalNER models compare to other state-of-the-art models in terms of computational efficiency and resource utilization?
- Basis in paper: [explicit] The paper highlights that UniversalNER models outperform other models in terms of NER accuracy but does not provide a detailed comparison of computational efficiency or resource utilization.
- Why unresolved: The paper focuses on accuracy improvements but does not discuss the trade-offs between accuracy and computational efficiency, which is crucial for practical deployment.
- What evidence would resolve it: Comparative analysis of the computational efficiency and resource utilization of UniversalNER models versus other state-of-the-art models, including metrics such as inference time, memory usage, and energy consumption.

## Limitations

- External Tool Dependency: The approach relies on ChatGPT's generative capabilities to produce training data, creating a dependency on an external API and raising questions about reproducibility and scalability.
- Evaluation Scope: While claiming performance across "tens of thousands of entity types," the evaluation is limited to 43 specific NER datasets, with unverified generalization to truly novel entity types.
- Negative Sampling Effectiveness: The frequency-based negative sampling strategy shows significant improvement, but the paper doesn't explore alternative sampling strategies or validate whether frequency-based sampling is optimal for all dataset distributions.

## Confidence

**High Confidence Claims:**
- UniNER outperforms ChatGPT in NER accuracy across the 43 evaluated datasets (41.7% vs 34.9% average F1)
- Frequency-based negative sampling improves performance compared to uniform sampling or no sampling
- Dataset-specific instruction tuning templates resolve label conflicts and improve performance on overlapping datasets

**Medium Confidence Claims:**
- The mechanism of mission-focused instruction tuning enabling smaller models to surpass LLM performance is theoretically sound but not extensively validated across diverse domains
- The approach generalizes to "tens of thousands" of entity types based on the diversity of the Pile corpus, though this is not directly tested

**Low Confidence Claims:**
- Claims about performance on entity types not present in the 43 evaluation datasets
- Assertions about the approach being "universal" for all open NER scenarios

## Next Checks

1. **Generalization Test**: Evaluate UniNER on a held-out set of entity types not present in the training data or evaluation datasets to verify true generalization capability.

2. **Alternative Negative Sampling**: Implement and compare alternative negative sampling strategies (e.g., adversarial sampling, class-balanced sampling) to validate whether frequency-based sampling is optimal.

3. **Cross-Domain Robustness**: Test the model's performance when evaluated on datasets from domains not represented in the training data to assess domain generalization.