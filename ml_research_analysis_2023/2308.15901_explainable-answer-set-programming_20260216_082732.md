---
ver: rpa2
title: Explainable Answer-set Programming
arxiv_id: '2308.15901'
source_url: https://arxiv.org/abs/2308.15901
tags:
- programming
- logic
- explanation
- answer-set
- programs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This project addresses the lack of explainability methods for Answer-set
  Programming (ASP) extensions like external computations, neural networks, and abstract
  constraint atoms. The research develops novel explanation approaches including contrastive
  explanations and justifications for complex ASP programs.
---

# Explainable Answer-set Programming

## Quick Facts
- arXiv ID: 2308.15901
- Source URL: https://arxiv.org/abs/2308.15901
- Reference count: 40
- Key outcome: Novel explanation approaches for ASP extensions including contrastive explanations and justifications for Abstract Constraint Atoms

## Executive Summary
This research addresses the critical gap in explainability methods for Answer-set Programming (ASP) extensions. The project develops formal explanation frameworks that support complex ASP features including external computations, neural networks, and abstract constraint atoms. A key innovation is the extension of justification methods to Abstract Constraint Atoms, which unify multiple ASP language extensions under a common semantic framework. The work also introduces contrastive explanations and explores different explanation settings (gray-box, black-box, white-box) for ASP systems.

## Method Summary
The project extends existing justification methods to Abstract Constraint Atoms (ACAs), enabling systematic support for multiple ASP language extensions through a unified semantic framework. It develops contrastive explanation approaches by computing minimal symmetric differences between fact sets that lead to different answer sets. The research also investigates interactive explanation systems that combine semantic and syntactic justification approaches, allowing users to navigate between different explanation perspectives. Implementation focuses on supporting choice rules, aggregates, and disjunctive rules within this framework.

## Key Results
- Successfully extended formal justification methods to Abstract Constraint Atoms, generalizing multiple ASP extensions
- Developed contrastive explanation framework based on minimal difference computation between answer sets
- Created interactive explanation systems supporting both semantic and syntactic justifications for complex ASP programs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The project extends formal justification methods to Abstract Constraint Atoms (ACAs), enabling support for language extensions like aggregates and choice rules.
- Mechanism: ACAs generalize multiple ASP language extensions into a unified semantic framework, allowing existing justification approaches to be systematically extended without redesigning core algorithms.
- Core assumption: The semantic properties of ACAs preserve the minimal model characteristics needed for justification extraction.
- Evidence anchors:
  - [section] "Programs defined over such atoms neatly generalise several language extensions" (Example 2 discusses aggregate justifications over ACAs)
  - [corpus] No direct corpus evidence found for ACA justification methods
- Break condition: If ACA semantics introduce non-monotonic behaviors that break the minimality assumptions of justification extraction.

### Mechanism 2
- Claim: Contrastive explanations in ASP are implemented by finding minimally different instances that change the answer set.
- Mechanism: The system computes symmetric differences between the original facts and alternative facts that lead to different answer sets, providing intuitive "instead of" explanations.
- Core assumption: Minimal symmetric difference between fact sets correlates with human-understandable contrastive explanations.
- Evidence anchors:
  - [section] Example 3 explicitly demonstrates this mechanism: "F' differs minimally from F" and shows symmetric difference calculation
  - [corpus] No corpus evidence found for ASP contrastive explanation implementations
- Break condition: If finding minimal differences becomes computationally intractable for large programs or if the minimal difference doesn't capture the intended contrast.

### Mechanism 3
- Claim: The project develops interactive explanation systems that combine semantic and syntactic justification approaches.
- Mechanism: By integrating both rule-application-based and purely semantic justifications, the system can provide multiple explanation perspectives that users can navigate interactively.
- Core assumption: Different users prefer different explanation styles, and interactive systems can adapt to these preferences.
- Evidence anchors:
  - [section] "we are also working on more syntactic notions that can be used together with the above concept is to use them both in an interactive explanation system"
  - [corpus] No corpus evidence found for interactive ASP explanation systems
- Break condition: If combining multiple justification types creates inconsistent or confusing explanations for users.

## Foundational Learning

- Concept: Answer Set Programming semantics and answer set definition
  - Why needed here: Understanding how answer sets are computed is fundamental to designing explanation methods
  - Quick check question: What makes an answer set "minimal" in the Gelfond-Lifschitz reduct?

- Concept: Contrastive explanation theory from social sciences
  - Why needed here: The project adapts contrastive explanation frameworks to ASP, requiring understanding of human explanation preferences
  - Quick check question: What distinguishes a contrastive explanation from a non-contrastive one according to Miller's framework?

- Concept: Abstract Constraint Atoms and their generalization properties
  - Why needed here: ACAs are the key mechanism for supporting multiple language extensions uniformly
  - Quick check question: How do Abstract Constraint Atoms generalize aggregates, choice rules, and other ASP extensions?

## Architecture Onboarding

- Component map: Core explanation engine -> Contrastive explanation module -> Interactive interface -> Language extension adapter
- Critical path: User query → Fact extraction → ACA translation → Justification computation → Contrastive analysis → Interactive presentation
- Design tradeoffs: Between computational efficiency (finding minimal differences) and explanation quality (human-understandability of contrasts)
- Failure signatures: Explanation generation timeouts, inconsistent justifications across different explanation modes, user confusion with multiple explanation types
- First 3 experiments:
  1. Test ACA justification generation on simple aggregate programs with known answer sets
  2. Implement contrastive explanation for a basic bug classification ASP program
  3. Build interactive interface prototype supporting both semantic and syntactic justifications for choice rules

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we effectively combine semantic-based and syntactic-based justification approaches for programs with abstract constraint atoms to create more comprehensive explanations?
- Basis in paper: [explicit] The paper discusses both semantic-based justifications for abstract constraint atoms and syntactic notions that can be used together with them, but doesn't specify how to effectively combine these approaches.
- Why unresolved: While the paper mentions both approaches, it doesn't provide concrete methods for integrating them or demonstrate how their combination would improve explanation quality compared to using either approach alone.
- What evidence would resolve it: A formal framework showing how semantic and syntactic justifications can be combined, along with empirical evaluation demonstrating improved explanation quality and user understanding when using the combined approach versus individual methods.

### Open Question 2
- Question: What is the optimal difference measure for contrastive explanations in ASP when the contrast set is not limited to facts but can include rules or constraints?
- Basis in paper: [explicit] The paper mentions that minimal symmetric difference is a natural choice for contrastive explanations but notes that this difference is problem-dependent and questions what happens when rules rather than just facts can be relaxed.
- Why unresolved: The paper identifies this as a key consideration for contrastive explanations but doesn't provide a general solution for determining optimal difference measures when the contrast set can include program modifications beyond facts.
- What evidence would resolve it: A principled framework for determining optimal difference measures in contrastive ASP explanations that accounts for both fact and rule modifications, validated through user studies showing improved explanation quality and understanding.

### Open Question 3
- Question: How can proof systems for equilibrium logic be developed that support brave/credulous inference while maintaining human readability and avoiding the complexity issues of tableaux methods?
- Basis in paper: [explicit] The paper identifies that while tableaux-based proof systems exist for equilibrium logic, they contain multiple steps making them difficult to obtain humanly readable explanations, and that existing approaches focus on skeptical rather than brave inference.
- Why unresolved: Despite acknowledging the need for proof systems supporting brave inference with better human readability than tableaux, the paper doesn't propose specific approaches or demonstrate how to overcome the inherent complexity challenges.
- What evidence would resolve it: A concrete proof system design for brave inference in equilibrium logic that maintains human readability, along with formal proofs of its properties and empirical evaluation showing it produces more understandable explanations than tableaux-based approaches.

## Limitations
- Computational complexity of finding minimal differences for contrastive explanations in large programs
- Potential inconsistencies when combining multiple explanation types in interactive systems
- Lack of empirical validation with real-world users and practical implementation details

## Confidence
- High confidence: Theoretical foundations of ACA-based justification methods and contrastive explanation mechanism
- Medium confidence: Interactive explanation system concept and integration of multiple justification types
- Low confidence: Practical effectiveness of gray-box, black-box, and white-box settings for ASP extensions

## Next Checks
1. Implement and test ACA justification generation on programs combining multiple extensions (aggregates + choice rules) to verify the semantic preservation claims
2. Conduct user studies comparing the effectiveness of semantic vs syntactic justifications for different user expertise levels
3. Benchmark contrastive explanation generation on progressively larger ASP programs to establish scalability limits and identify performance bottlenecks