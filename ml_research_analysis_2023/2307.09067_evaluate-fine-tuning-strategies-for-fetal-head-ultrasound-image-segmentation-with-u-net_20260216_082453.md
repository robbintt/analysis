---
ver: rpa2
title: Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image Segmentation
  with U-Net
arxiv_id: '2307.09067'
source_url: https://arxiv.org/abs/2307.09067
tags:
- segmentation
- u-net
- decoder
- fetal
- head
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates fine-tuning strategies for fetal head segmentation
  in ultrasound images using a U-Net architecture with a MobileNet V2 encoder. The
  primary challenge addressed is the difficulty of training deep convolutional neural
  networks from scratch due to limited annotated medical data.
---

# Evaluate Fine-tuning Strategies for Fetal Head Ultrasound Image Segmentation with U-Net

## Quick Facts
- arXiv ID: 2307.09067
- Source URL: https://arxiv.org/abs/2307.09067
- Reference count: 2
- Primary result: Proposed fine-tuning strategy achieves state-of-the-art accuracy on HC18 dataset with 4.4M trainable parameters

## Executive Summary
This study investigates fine-tuning strategies for fetal head segmentation in ultrasound images using a U-Net architecture with MobileNet V2 encoder. The research addresses the challenge of limited annotated medical data by leveraging transfer learning from ImageNet-pretrained models. The proposed approach significantly reduces trainable parameters by 85.8% while maintaining competitive segmentation performance. The most effective strategy involves unfreezing the entire decoder, which improves pixel accuracy by 0.45%, Dice score by 0.75%, and mIoU by 1.4% compared to training from scratch.

## Method Summary
The method employs transfer learning with a pre-trained U-Net architecture featuring MobileNet V2 as the encoder backbone. Seven different fine-tuning strategies were evaluated, varying which decoder layers were unfrozen for training while keeping the encoder frozen. The model was trained on the HC18 dataset (799 training images, 200 test images) with standard data augmentation and Adam optimizer (learning rate 1e-4, batch size 10, 20 epochs). Performance was measured using Pixel Accuracy, Dice coefficient, and Mean Intersection over Union (mIoU).

## Key Results
- Unfreezing the entire decoder provided the best performance, improving mIoU by 1.4% over training from scratch
- The approach achieved state-of-the-art accuracy on HC18 dataset with only 4.4 million trainable parameters
- Fine-tuning reduced trainable parameters by 85.8% compared to full model training
- The lightweight model is suitable for mobile AI applications in medical imaging

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning only the decoder layers significantly reduces trainable parameters while maintaining segmentation performance
- Mechanism: Transfer learning leverages pre-trained convolutional filters from ImageNet, allowing the encoder to capture general visual features without extensive fine-tuning. The decoder adapts these features to the specific segmentation task with minimal parameter updates.
- Core assumption: Encoder features from ImageNet are transferable to fetal ultrasound segmentation
- Evidence anchors: