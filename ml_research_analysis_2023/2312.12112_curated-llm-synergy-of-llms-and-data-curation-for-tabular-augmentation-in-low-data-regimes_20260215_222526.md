---
ver: rpa2
title: 'Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in
  low-data regimes'
arxiv_id: '2312.12112'
source_url: https://arxiv.org/abs/2312.12112
tags:
- data
- samples
- curation
- learning
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLLM leverages the prior knowledge of Large Language Models (LLMs)
  for data augmentation in the low-data regime. It introduces a principled curation
  mechanism based on learning dynamics, confidence, and uncertainty metrics to obtain
  a high-quality dataset.
---

# Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in low-data regimes

## Quick Facts
- arXiv ID: 2312.12112
- Source URL: https://arxiv.org/abs/2312.12112
- Reference count: 40
- Key outcome: CLLM demonstrates superior performance in low-data regimes by leveraging LLM prior knowledge and principled curation mechanisms, showing largest gains for underrepresented subgroups.

## Executive Summary
Curated LLM (CLLM) addresses the challenge of data augmentation in low-data regimes by combining the prior knowledge of Large Language Models (LLMs) with a principled data curation mechanism. The approach generates synthetic tabular data using LLMs with carefully crafted prompts that include contextual information and in-context examples. A curation model then evaluates the generated samples using learning dynamics, confidence, and uncertainty metrics to filter out potentially mislabeled or atypical samples. Empirical results show CLLM outperforms conventional generators across multiple real-world datasets, particularly for underrepresented subgroups and in ultra low-data settings.

## Method Summary
CLLM operates in three stages: first, it generates synthetic tabular data using a pretrained LLM with prompts containing background context, in-context examples, and instructions; second, it trains a downstream model on the original small dataset while tracking learning dynamics, confidence, and aleatoric uncertainty for each synthetic sample; third, it curates the synthetic data by removing samples that fall below confidence and uncertainty thresholds, then trains the final downstream model on the curated synthetic data combined with the original dataset.

## Key Results
- CLLM achieves superior performance compared to conventional generators on multiple real-world datasets in low-data regimes
- The curation mechanism improves downstream performance for all generators, including LLMs
- Largest performance gains are observed for underrepresented subgroups and in ultra low-data settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CLLM uses LLM prior knowledge to extrapolate beyond the limited training data manifold, enabling better coverage of the true data distribution.
- Mechanism: LLMs leverage contextual understanding and vast pretraining to generate samples in regions of the feature space not covered by the small Dtrain, while maintaining correct feature-label relationships.
- Core assumption: The pretraining corpus contains relevant information about the target domain and feature-label relationships.
- Evidence anchors:
  - [abstract] "CLLM leverages the prior knowledge of Large Language Models (LLMs) for data augmentation in the low-data regime."
  - [section 2.1] "LLMs have been pretrained with a vast corpus of information... When prompted to generate samples with limited real data, LLMs can leverage this encoded prior information about similar problems and feature-label relationships to enhance both accuracy and diversity of generation."
  - [corpus] Weak - corpus contains related papers but no direct evidence for this specific mechanism
- Break condition: If pretraining corpus lacks relevant domain knowledge or feature-label relationships are too domain-specific to generalize from pretraining.

### Mechanism 2
- Claim: The curation mechanism improves downstream performance by removing mislabeled or atypical samples based on learning dynamics.
- Mechanism: Samples are evaluated based on their confidence and aleatoric uncertainty across training checkpoints; low-confidence samples with low inherent uncertainty are considered likely mislabeled and removed.
- Core assumption: Samples with high aleatoric uncertainty or low confidence are more likely to be mislabeled or atypical.
- Evidence anchors:
  - [abstract] "we introduce a principled curation mechanism, leveraging learning dynamics, coupled with confidence and uncertainty metrics, to obtain a high-quality dataset."
  - [section 2.2] "samples with variable predictions might be considered ambiguous or other samples might never be learned correctly and could harm a model."
  - [corpus] Moderate - corpus contains related work on learning dynamics and uncertainty quantification
- Break condition: If the curation model overfits to Dtrain or the uncertainty estimates are unreliable due to model capacity limitations.

### Mechanism 3
- Claim: Including contextual information in prompts significantly improves LLM generation quality compared to providing only numerical examples.
- Mechanism: Contextual information provides semantic understanding of features and task context, enabling the LLM to leverage relevant prior knowledge and generate more accurate and diverse samples.
- Core assumption: LLMs can understand and utilize contextual information provided in natural language to improve generation quality.
- Evidence anchors:
  - [abstract] "We further show our curation mechanism improves the downstream performance for all generators, including LLMs."
  - [section 2.1] "Contextual understanding. LLMs can process background and contextual information about the problem via natural language."
  - [corpus] Weak - corpus contains related work on prompting but no direct evidence for this specific mechanism
- Break condition: If the LLM cannot effectively process or utilize the contextual information, or if the contextual information is ambiguous or misleading.

## Foundational Learning

- Concept: In-context learning
  - Why needed here: CLLM relies on LLMs' ability to learn from few examples provided in prompts without fine-tuning, which is crucial for the low-data regime.
  - Quick check question: What is the key difference between in-context learning and traditional fine-tuning?

- Concept: Learning dynamics
  - Why needed here: The curation mechanism analyzes how samples behave during training to identify potentially mislabeled or atypical samples.
  - Quick check question: How do learning dynamics provide information about sample quality?

- Concept: Aleatoric vs epistemic uncertainty
  - Why needed here: CLLM uses aleatoric uncertainty to capture inherent data uncertainty and identify potentially mislabeled samples, distinguishing it from model-dependent epistemic uncertainty.
  - Quick check question: What is the key difference between aleatoric and epistemic uncertainty in the context of sample curation?

## Architecture Onboarding

- Component map: Prompt generator -> LLM -> Curation model -> Downstream model trainer
- Critical path: Prompt generation → LLM generation → Curation analysis → Downstream training
- Design tradeoffs:
  - Using a frozen LLM vs fine-tuning: Frozen LLM is computationally cheaper but may have lower performance
  - Threshold selection for curation: Stricter thresholds may remove too many samples, while lenient thresholds may retain low-quality samples
- Failure signatures:
  - Poor downstream performance despite high-quality LLM generation: Curation thresholds may be too strict or curation model may be overfitting
  - LLM generation fails to extrapolate beyond Dtrain: Prompt may lack sufficient contextual information or LLM may not have relevant pretraining knowledge
- First 3 experiments:
  1. Test LLM generation quality with and without contextual information in prompts
  2. Evaluate curation effectiveness by comparing performance with and without curation
  3. Assess sensitivity of curation thresholds to downstream performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can CLLM be adapted to effectively handle high-dimensional tabular datasets while maintaining performance gains seen in low-dimensional settings?
- Basis in paper: [inferred] The paper focuses on datasets with relatively low feature counts (12-29 features) and demonstrates performance gains in low-data regimes. The authors do not explicitly address scalability to high-dimensional data.
- Why unresolved: The authors demonstrate effectiveness on datasets with up to 29 features but do not investigate how performance scales with dimensionality. High-dimensional data presents challenges like increased sparsity and potential overfitting that may impact CLLM's effectiveness.
- What evidence would resolve it: Experiments on benchmark high-dimensional tabular datasets (e.g., 100+ features) showing CLLM maintains performance advantages over traditional generators, or identifying specific dimensionality thresholds where performance degrades.

### Open Question 2
- Question: What is the optimal balance between in-context examples and LLM prior knowledge for data augmentation across different dataset characteristics?
- Basis in paper: [explicit] The authors discuss the importance of in-context examples and LLM prior knowledge in Section 2.1 and provide some analysis in Appendix C.3, but do not establish a systematic framework for determining the optimal number of examples.
- Why unresolved: The paper shows that performance improves with more in-context examples but doesn't provide guidance on how to determine the optimal number for different dataset types or sizes. The relationship between dataset characteristics and optimal example count remains unclear.
- What evidence would resolve it: A systematic study mapping dataset characteristics (domain, feature types, size) to optimal in-context example counts, potentially through a learning-based approach that predicts optimal prompt composition.

### Open Question 3
- Question: How can CLLM be extended to handle multi-modal tabular data that includes unstructured features (text, images) alongside structured numerical/categorical data?
- Basis in paper: [inferred] The current CLLM framework is designed for structured tabular data only. The authors do not address scenarios where tabular datasets include unstructured components that are increasingly common in real-world applications.
- Why unresolved: The paper focuses exclusively on structured tabular data and does not explore how the LLM-based generation and curation mechanisms could be adapted for multi-modal datasets. The integration of unstructured data with structured tabular data presents unique challenges.
- What evidence would resolve it: A demonstration of CLLM successfully generating and curating multi-modal datasets, showing performance improvements over uni-modal approaches, or a theoretical framework for extending the current methodology to handle unstructured data types.

## Limitations

- The effectiveness of CLLM heavily depends on the relevance of the LLM's pretraining corpus to the target domain, which may limit performance for specialized domains.
- The curation mechanism assumes that high aleatoric uncertainty correlates with mislabeled samples, but this relationship may not hold for all tabular datasets.
- The choice of curation thresholds appears to be dataset-dependent without a systematic method for threshold selection across different domains.

## Confidence

- **High Confidence**: The core mechanism of using LLMs for tabular data generation via in-context learning is well-established. The improvement over conventional generators in low-data regimes is supported by empirical results.
- **Medium Confidence**: The curation mechanism's effectiveness relies on the assumption that learning dynamics can reliably identify mislabeled samples. While the approach is principled, its generalizability across diverse tabular datasets requires further validation.
- **Low Confidence**: The paper claims largest gains for underrepresented subgroups, but the analysis of subgroup performance is limited to specific datasets. Broader validation across diverse datasets with known subgroup biases would strengthen this claim.

## Next Checks

1. **Cross-domain generalization test**: Evaluate CLLM performance across datasets from different domains (e.g., healthcare, finance, social sciences) to assess pretraining corpus relevance requirements.
2. **Threshold sensitivity analysis**: Systematically vary curation thresholds across multiple orders of magnitude and measure the impact on downstream performance to identify optimal threshold selection strategies.
3. **Subgroup bias analysis**: Conduct comprehensive subgroup analysis across multiple datasets with known demographic or feature-based subgroups to validate the claim about benefits for underrepresented populations.