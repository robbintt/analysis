---
ver: rpa2
title: Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian
  Neural Network
arxiv_id: '2303.16564'
source_url: https://arxiv.org/abs/2303.16564
tags:
- bias
- learning
- network
- bayesian
- posterior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of visual bias mitigation in deep
  neural networks, focusing on implicit methods that do not require explicit knowledge
  of bias variables. The authors propose a novel approach using Bayesian neural networks,
  leveraging the relationship between epistemic uncertainties and bias-conflating
  samples.
---

# Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network

## Quick Facts
- arXiv ID: 2303.16564
- Source URL: https://arxiv.org/abs/2303.16564
- Reference count: 40
- Key outcome: Bayesian neural networks with sharpened posterior estimates perform comparably to existing bias mitigation methods on benchmark datasets

## Executive Summary
This paper addresses visual bias mitigation in deep neural networks using an implicit approach that doesn't require explicit knowledge of bias variables. The authors propose a novel method that leverages Bayesian neural networks and their epistemic uncertainties to identify and mitigate spurious correlations in visual datasets. The core innovation is a posterior estimate sharpening procedure that fine-tunes classification layers using a multi-component loss function that penalizes large variance in the posterior, effectively down-weighting features that contribute to high uncertainties for bias-conflating samples.

## Method Summary
The method involves training a Bayesian neural network baseline using cSG-MCMC, then computing posterior predictive means and epistemic uncertainties for all training samples. For each posterior sample, the classification layers are fine-tuned using a sharpening loss that computes divergence from the predictive mean, combined with the original negative log likelihood loss weighted by sample uncertainty. PCGrad is used to handle conflicts between loss gradients during fine-tuning. The approach is tested on three benchmark datasets (Biased MNIST, COCO-on-Places, and Biased Action Recognition) and compared against existing bias mitigation techniques.

## Key Results
- The approach shows competitive performance on Biased MNIST and Biased Action Recognition datasets
- Accuracy improvements are observed in several classes compared to baseline methods
- The method consistently increases model fairness compared to its Bayesian starting point
- Performance on COCO-on-Places is not as strong as other datasets but still demonstrates fairness improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Epistemic uncertainties correlate with bias-conflating samples, and higher uncertainty indicates the presence of spurious correlations that the model is relying on for predictions.
- Mechanism: The sharpening procedure uses the relationship between high epistemic uncertainty and bias-conflating samples to down-weight features that contribute to these uncertainties in the classification layers of the Bayesian neural network.
- Core assumption: Bias-conflating samples inherently have higher epistemic uncertainties than bias-aligned samples, and these uncertainties arise primarily from the classification head rather than the representation layers.
- Break condition: If the correlation between high epistemic uncertainty and bias-conflating samples does not hold for a given dataset, or if uncertainties arise from representation layers rather than classification layers, the mechanism would fail.

### Mechanism 2
- Claim: Penalizing large variance in the posterior estimate of the classification layers effectively down-weights features that contribute to high uncertainties for bias-conflating samples.
- Mechanism: The sharpening loss Ls computes the divergence between the prediction of a single posterior estimate and the mean prediction of the whole posterior, encouraging the network to learn feature weightings that minimize uncertainties for high uncertainty samples.
- Core assumption: Minimizing the variance between individual posterior samples and the overall predictive mean will lead to feature weightings that reduce reliance on spurious correlations.
- Break condition: If the relationship between posterior variance and feature importance is not linear or if other factors contribute more significantly to uncertainties, the mechanism would be ineffective.

### Mechanism 3
- Claim: Weighting each sample by a function of its epistemic uncertainty during the sharpening procedure ensures that high uncertainty samples have larger gradients that shift the distribution, while low uncertainty samples minimally shift the distribution.
- Mechanism: The sample weighting function w_i = (1.0 + σ_i,y_i)^κ assigns larger weights to samples with higher uncertainties, allowing the sharpening procedure to focus on re-weighting features for bias-conflating samples.
- Core assumption: Bias-conflating samples should be prioritized for feature re-weighting because they indicate where the model is relying on spurious correlations, while bias-aligned samples do not need adjustment.
- Break condition: If the uncertainty weighting function does not appropriately distinguish between bias-conflating and bias-aligned samples, or if it causes overfitting to minority samples, the mechanism would fail.

## Foundational Learning

- Concept: Bayesian neural networks and epistemic uncertainty
  - Why needed here: The method relies on leveraging epistemic uncertainties from Bayesian neural networks to identify and mitigate spurious correlations in visual datasets.
  - Quick check question: What is the difference between epistemic and aleatoric uncertainty, and why is epistemic uncertainty more relevant for bias mitigation?

- Concept: Posterior sampling and Monte Carlo integration
  - Why needed here: The method uses Monte Carlo samples from the posterior distribution to estimate predictive means and uncertainties, which are then used for the sharpening procedure.
  - Quick check question: How does Monte Carlo integration approximate the intractable posterior distribution in Bayesian neural networks?

- Concept: Gradient surgery and multi-task learning
  - Why needed here: The method uses PCGrad to handle potential conflicts between the sharpening loss and the original negative log likelihood loss during backpropagation.
  - Quick check question: What is the purpose of gradient surgery in multi-task learning, and how does it apply to the conflict between Ls and Lnll in this method?

## Architecture Onboarding

- Component map:
  Representation network (frozen during sharpening) -> Classification network (fine-tuned during sharpening) -> Posterior sampling module -> Uncertainty estimation module -> Sharpening loss module -> Sample weighting module -> PCGrad module

- Critical path:
  1. Generate posterior samples using cSG-MCMC
  2. Compute predictive mean and uncertainties for all samples
  3. For each posterior sample, compute losses (Ls and Lnll) with sample weighting
  4. Apply PCGrad to resolve gradient conflicts
  5. Update classification layer parameters
  6. Repeat for multiple sharpening iterations

- Design tradeoffs:
  - Freezing representation layers vs. updating them: Freezing reduces complexity and memory requirements but may limit the method's effectiveness if representation layers contribute to bias
  - Sample weighting function parameters: The choice of κ affects the balance between focusing on high uncertainty samples and maintaining overall model stability
  - Number of posterior samples (M): More samples provide better uncertainty estimates but increase computational cost

- Failure signatures:
  - No improvement in fairness metrics despite increased computational cost
  - Performance degradation on unbiased test sets
  - Overfitting to minority samples indicated by increased variance in predictions
  - Gradients becoming too small to effectively update weights

- First 3 experiments:
  1. Verify that epistemic uncertainties correlate with bias-conflating samples on a simple synthetic dataset (e.g., Biased Synbols)
  2. Test the sharpening procedure on Biased MNIST with pbias = 0.95 to observe improvements in accuracy gaps between majority and minority groups
  3. Compare performance on COCO-on-Places biased and unbiased test sets to evaluate trade-offs between fairness and accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Bayesian networks with sharpened posterior estimates compare to deterministic networks on real-world datasets with complex, entangled bias sources?
- Basis in paper: The authors acknowledge that Bayesian neural networks can struggle to match deterministic benchmarks in terms of predictive performance, and this directly affects the sharpening method. They weigh these sacrifices in performance against the added benefit of quantified prediction uncertainty estimates.
- Why unresolved: The paper only provides experimental results on three benchmark datasets, which may not fully represent the complexity and variability of real-world datasets. The authors also note that further exploration is required to better understand when and why Bayesian neural networks struggle with respect to deterministic networks within the context of bias mitigation.
- What evidence would resolve it: Conducting experiments on a diverse set of real-world datasets with known bias sources and comparing the performance of Bayesian networks with sharpened posterior estimates to deterministic networks using various bias mitigation techniques.

### Open Question 2
- Question: Can the posterior estimate sharpening approach be extended to other types of neural networks beyond Bayesian neural networks?
- Basis in paper: The authors propose a novel implicit mitigation method using a Bayesian neural network, but they do not explore the possibility of applying the sharpening procedure to other types of neural networks. The method relies on leveraging the relationship between epistemic uncertainties and bias-conflating samples, which could potentially be applicable to other network architectures.
- Why unresolved: The paper focuses on demonstrating the effectiveness of the sharpening procedure specifically for Bayesian neural networks. The authors do not discuss or experiment with extending the approach to other network types, such as deterministic or ensemble methods.
- What evidence would resolve it: Conducting experiments to apply the sharpening procedure to other neural network architectures, such as deterministic networks or ensemble methods, and comparing the results to the Bayesian approach.

### Open Question 3
- Question: How sensitive is the performance of the sharpening procedure to the choice of hyper-parameters, such as the number of Monte Carlo samples and the scaling constant κ?
- Basis in paper: The authors mention that the optimal parameters for cyclical stochastic gradient MCMC (cSG-MCMC) are determined via grid search, and they fixed the number of moments sampled per sampling phase. They also discuss the scaling constant κ, which controls the steepness of the function used to weight samples by their epistemic uncertainty.
- Why unresolved: While the authors provide some information about the hyper-parameters used in their experiments, they do not conduct a comprehensive sensitivity analysis to determine how the performance of the sharpening procedure varies with different choices of hyper-parameters. This is important for understanding the robustness and generalizability of the method.
- What evidence would resolve it: Conducting a systematic study to evaluate the impact of different choices of hyper-parameters, such as the number of Monte Carlo samples, the scaling constant κ, and other relevant parameters, on the performance of the sharpening procedure across various datasets and bias scenarios.

## Limitations
- The method relies on the assumption that epistemic uncertainties reliably correlate with bias-conflating samples across diverse datasets
- Computational complexity is high due to multiple posterior samples and fine-tuning iterations
- The paper does not thoroughly explore sensitivity to hyper-parameter choices

## Confidence

- High confidence: The Bayesian framework and uncertainty estimation methodology are well-established
- Medium confidence: The effectiveness of posterior sharpening for bias mitigation is demonstrated empirically but could benefit from more extensive ablation studies
- Medium confidence: The claim that the method is truly "implicit" since it doesn't require explicit bias variable specification

## Next Checks

1. **Ablation study on sample weighting**: Systematically vary the κ parameter in the sample weighting function to quantify its impact on both fairness improvements and potential overfitting risks.

2. **Cross-dataset generalization test**: Apply the method to a dataset with a different type of bias (e.g., background-color bias instead of object-background bias) to evaluate whether the uncertainty correlation assumption holds universally.

3. **Computational efficiency analysis**: Compare the method's performance against simpler baselines (like EpiWt) while varying the number of posterior samples to establish the minimum computational overhead required for effectiveness.