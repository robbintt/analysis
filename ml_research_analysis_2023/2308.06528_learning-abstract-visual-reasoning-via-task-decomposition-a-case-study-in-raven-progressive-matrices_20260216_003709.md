---
ver: rpa2
title: 'Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in
  Raven Progressive Matrices'
arxiv_id: '2308.06528'
source_url: https://arxiv.org/abs/2308.06528
tags:
- panels
- task
- panel
- properties
- property
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a transformer-based approach to solving Raven
  Progressive Matrices (RPM) by decomposing the task into property prediction and
  choice stages. The method predicts visual properties of objects and their arrangements,
  then uses these predictions to select the correct answer panel.
---

# Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices

## Quick Facts
- arXiv ID: 2308.06528
- Source URL: https://arxiv.org/abs/2308.06528
- Reference count: 40
- Key outcome: Row tokenizer with Combined masking achieved 82.84% accuracy on RAVEN test set

## Executive Summary
This paper proposes a transformer-based approach for solving Raven Progressive Matrices (RPM) by decomposing the task into property prediction and choice selection stages. The method predicts visual properties of objects (color, size, shape, position) and their arrangements before selecting the correct answer panel. Three different image tokenization strategies (Panel, Task, Row) and masking regimes (Query, Random, Combined) were evaluated. The Row tokenizer with Combined masking achieved the best performance, reaching 82.84% accuracy on the test set and outperforming state-of-the-art methods on both RAVEN and I-RAVEN benchmarks.

## Method Summary
The approach uses a transformer-based architecture that first predicts visual properties of objects in RPM panels, then uses these predictions to select the correct answer. Three image tokenizers convert panels into sequences: Panel tokenizer treats each panel independently, Task tokenizer processes the entire task as one sequence, and Row tokenizer stacks panels from each row into separate channels. During training, random panels are masked and the model must predict their properties, with a Combined masking regime (200 epochs random + 30 epochs query) showing best results. The model predicts property vectors where only certain properties are relevant based on the panel arrangement, and a Direct Choice Maker algorithm selects the answer based on property predictions.

## Key Results
- Row tokenizer with Combined masking achieved 82.84% accuracy on RAVEN test set
- Outperformed state-of-the-art methods on both RAVEN and I-RAVEN benchmarks
- Provided more interpretable results through property prediction visualization
- Self-supervised masking during training improved generalization across RPM puzzles

## Why This Works (Mechanism)

### Mechanism 1
The transformer-based architecture learns abstract visual reasoning patterns by predicting panel properties before choosing answers. Instead of directly selecting from answer panels, the model first predicts the visual properties (color, size, shape) of each object in every panel arrangement. This intermediate property prediction stage forces the model to learn underlying rules that govern object relationships across rows and columns.

### Mechanism 2
Self-supervised masking during training improves the model's ability to generalize across the entire RPM puzzle. During training, random panels are masked out and the model must predict their properties based on context. This forces the model to learn patterns that span the entire puzzle rather than just the final answer position. The Combined masking regime (200 epochs random + 30 epochs query) provides the best results.

### Mechanism 3
The Row tokenizer with Combined masking achieves superior performance by explicitly revealing panel relationships through channel-wise stacking. The Row tokenizer stacks panels from each row into separate color channels before tokenization. This design choice allows the CNN to directly capture differences between panels in the same row, facilitating the discovery of row-wise patterns.

## Foundational Learning

- **Concept: Tokenization and receptive fields**
  - Why needed here: Understanding how the CNN tokenizer converts images to sequences of tokens and how receptive fields span the input is crucial for interpreting model behavior.
  - Quick check question: What is the size of the receptive field for tokens produced by the Row tokenizer, and how does this affect which parts of the RPM task influence each token?

- **Concept: Self-supervised learning with masking**
  - Why needed here: The training process relies on masking panels and predicting their properties, which is a form of self-supervised learning that differs from standard supervised learning.
  - Quick check question: How does the Combined masking regime (random + query) differ from using only random or only query masking, and why does this combination work better?

- **Concept: Multi-label classification with relevance filtering**
  - Why needed here: The model predicts property vectors where only certain properties are relevant based on the panel arrangement. Understanding this relevance filtering is key to interpreting predictions.
  - Quick check question: How does the model determine which properties are relevant for a given panel, and how does this affect the loss calculation and performance metrics?

## Architecture Onboarding

- **Component map**: Image tokenizer (EfficientNetV2B0 CNN) → Transformer (4 blocks, 8 heads) → Property predictor (dense layers) → Choice maker (Direct Choice Maker algorithm)
- **Critical path**: Tokenizer → Transformer → Property predictor → Choice maker
- **Design tradeoffs**: Panel tokenizer provides selective correspondence but has more tokens; Task tokenizer is more entangled but fewer tokens; Row tokenizer balances explicit spatial encoding with manageable token count
- **Failure signatures**: Poor property prediction accuracy → incorrect answer selection; Random masking regime performs poorly → model overfits to specific panel positions
- **First 3 experiments**:
  1. Compare Panel, Task, and Row tokenizers with Combined masking on property prediction accuracy
  2. Test different masking regimes (Query-only, Random-only, Combined) with the best-performing tokenizer
  3. Implement the Direct Choice Maker algorithm and evaluate on RAVEN and I-RAVEN benchmarks

## Open Questions the Paper Calls Out
- Does the Row tokenizer's superior performance stem primarily from its channel-wise stacking of panels, or from other architectural differences?
- How does the performance of ACT models on RPM tasks generalize to other abstract reasoning domains beyond visual pattern completion?
- Can the Direct Choice Maker (DCM) algorithm be trained to better handle classification errors made by the property predictor?

## Limitations
- Performance claims primarily supported by relative comparisons rather than rigorous ablation studies
- Evaluation focused on synthetic RAVEN datasets without testing on more challenging I-RAVEN or real-world abstract reasoning tasks
- Generalizability claims to broader abstract reasoning domains are speculative

## Confidence
**High confidence**: The overall architecture design (property prediction → choice selection) is well-supported by experimental results showing consistent improvement over baseline methods.

**Medium confidence**: Specific mechanism explanations (property prediction as better representation, self-supervised masking benefits, Row tokenizer advantages) are plausible but not definitively proven through ablation studies.

**Low confidence**: Generalizability claims to broader abstract reasoning tasks are speculative and untested beyond RPM benchmarks.

## Next Checks
1. **Ablation Study on Masking Regimes**: Train models using only Random masking, only Query masking, and Combined masking on the same architecture to quantify the exact contribution of each regime to the 82.84% accuracy.

2. **Cross-Dataset Generalization**: Evaluate the trained Row tokenizer + Combined masking model on the I-RAVEN benchmark and real RPM test sets (without training on them) to assess whether the 82.84% performance on RAVEN translates to more challenging datasets.

3. **Interpretability Analysis of Property Predictions**: Systematically visualize and analyze which properties the model correctly predicts for different spatial arrangements (2×2, 3×3 grids) to verify that the model is learning genuine abstract rules rather than exploiting dataset-specific patterns.