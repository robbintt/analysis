---
ver: rpa2
title: 'Viewing the process of generating counterfactuals as a source of knowledge:
  a new approach for explaining classifiers'
arxiv_id: '2309.04284'
source_url: https://arxiv.org/abs/2309.04284
tags:
- variables
- counterfactual
- variable
- knowledge
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes to treat the process of generating counterfactual
  examples for model explanations as a source of knowledge that can be stored and
  later used in various ways. The approach is demonstrated specifically for the naive
  Bayes classifier, showing that it produces "additive trajectories" where individual
  feature changes accumulate to approach decision boundaries.
---

# Viewing the process of generating counterfactuals as a source of knowledge: a new approach for explaining classifiers

## Quick Facts
- arXiv ID: 2309.04284
- Source URL: https://arxiv.org/abs/2309.04284
- Reference count: 22
- Key outcome: Proposes treating counterfactual generation as knowledge creation, demonstrated on naive Bayes with additive trajectories enabling reusable knowledge bases for model understanding

## Executive Summary
This paper introduces a novel perspective on counterfactual explanations by treating the process of generating counterfactual examples as a source of reusable knowledge rather than a one-off explanation tool. The approach is specifically demonstrated for naive Bayes classifiers, which exhibit an "additive trajectory" property where individual feature changes accumulate predictably toward decision boundaries. By storing the impact of feature changes (Δ values) in a knowledge base table, the method enables efficient counterfactual generation with specific properties (minimal changes, business constraints), clustering analysis to discover actionable customer segments, and identification of preventive/reactive actions. The framework is illustrated on a churn prediction problem where clustering reveals interpretable customer segments with distinct intervention strategies.

## Method Summary
The method involves training a naive Bayes classifier, computing and storing Δ values representing the impact of changing each feature to each possible value for all individuals, and then reusing this knowledge base for counterfactual generation and clustering analysis. The approach leverages the additive property of naive Bayes in log-space, where feature changes accumulate to approach decision boundaries. The knowledge base stores these changes as a table that can be queried for counterfactuals with desired properties or used for clustering to discover actionable customer segments. The method is demonstrated on the Telco Customer Churn dataset using the Khiops library for model training and supervised discretization.

## Key Results
- Additive trajectories in naive Bayes enable sequential feature changes that sum predictably toward decision boundaries
- Knowledge base storage allows counterfactual generation with specific properties (minimal changes, business constraints) without re-computation
- Clustering the knowledge base reveals interpretable customer segments with distinct intervention strategies
- The approach transforms counterfactual generation from a one-off explanation tool into a reusable knowledge source

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The additive trajectory property of naive Bayes allows counterfactual generation through sequential univariate feature changes that sum to produce the overall effect.
- Mechanism: The naive Bayes classifier's log-probability formulation makes the distance to decision boundary additive across features, so changing one feature at a time accumulates effects predictably.
- Core assumption: The conditional independence assumption of naive Bayes holds sufficiently well for the problem domain.
- Evidence anchors:
  - [abstract] "additive trajectories" where individual feature changes accumulate to approach decision boundaries
  - [section 3.2] Proposition 1 demonstrates that ∆ values are additive: ∆(X0, X′3) = ∆(X0, X′1) + ∆(X0, X′2)
  - [corpus] Weak evidence - corpus contains no direct citations of this specific additive trajectory mechanism
- Break condition: The additive property breaks when conditional independence assumption is severely violated or when features are highly correlated.

### Mechanism 2
- Claim: Storing ∆ values in a knowledge base enables reuse for counterfactual generation with specific properties like minimal changes or business constraints.
- Mechanism: By pre-computing and storing the impact of changing each feature to each possible value, the system can later query this database to find counterfactuals that satisfy various criteria without re-computing from scratch.
- Core assumption: The stored ∆ values remain valid for the operational period (i.e., the model doesn't change significantly).
- Evidence anchors:
  - [abstract] storing change impacts (Δ values) in a knowledge base table, which can then be used to generate counterfactuals with specific properties
  - [section 4.1] "We now propose to store these ∆ values in a table" and describes the table structure
  - [corpus] No direct evidence - corpus doesn't contain studies of this specific knowledge base approach
- Break condition: Model drift or significant changes in input feature distributions invalidate the stored knowledge base.

### Mechanism 3
- Claim: Clustering the knowledge base reveals interpretable customer segments with distinct intervention strategies.
- Mechanism: By clustering individuals based on their ∆ values (how changes affect their predictions), the system groups people with similar response patterns, revealing actionable segments.
- Core assumption: The ∆ values capture meaningful differences in how individuals respond to feature changes.
- Evidence anchors:
  - [abstract] clustering analysis to discover actionable customer segments
  - [section 5] "Using the knowledge base, it is possible to group individuals according to the impact of each possible change"
  - [corpus] No direct evidence - corpus doesn't contain similar clustering approaches for counterfactual knowledge
- Break condition: If ∆ values don't capture meaningful variation (e.g., all individuals respond similarly), clustering yields uninformative results.

## Foundational Learning

- Concept: Counterfactual reasoning and explanations
  - Why needed here: The paper builds on counterfactual explanations as the foundation for generating knowledge about model behavior
  - Quick check question: What distinguishes a counterfactual example from a semi-factual example?

- Concept: Naive Bayes classifier mechanics and assumptions
  - Why needed here: The additive trajectory property specifically relies on the naive Bayes formulation and its conditional independence assumption
  - Quick check question: How does the naive Bayes equation become additive in log-space?

- Concept: Feature discretization and supervised grouping
  - Why needed here: The knowledge base approach requires discretizing numerical variables and grouping categorical modalities to make the number of ∆ values tractable
  - Quick check question: Why is discretization necessary for the knowledge base approach to be computationally feasible?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training -> Knowledge base generation -> Counterfactual generation -> Clustering analysis -> Business application
- Critical path:
  1. Train naive Bayes model on training data
  2. Preprocess features (discretize/group)
  3. Generate knowledge base by computing all ∆ values
  4. Store knowledge base in database
  5. Query knowledge base for counterfactual generation or clustering
- Design tradeoffs:
  - Storage vs. computation: Pre-computing all ∆ values trades storage space for faster counterfactual generation
  - Granularity vs. tractability: Finer discretization yields more precise counterfactuals but explodes knowledge base size
  - Model fidelity vs. additivity: More complex models may better fit data but lose the additive trajectory property
- Failure signatures:
  - Counterfactuals don't make practical sense: May indicate discretization is too coarse or business constraints aren't properly encoded
  - Clusters don't reveal meaningful segments: May indicate ∆ values don't capture important variation or inappropriate distance metric used
  - Knowledge base generation is too slow: May indicate need for more efficient computation or reduced feature granularity
- First 3 experiments:
  1. Generate knowledge base for a small dataset with 2-3 features, verify ∆ values sum correctly for additive trajectories
  2. Test counterfactual generation with different constraint settings (minimal changes vs. business constraints) on a simple binary classification problem
  3. Apply clustering to knowledge base and manually inspect whether resulting segments align with business intuition about customer behavior

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the limitations section suggests areas for future work.

## Limitations
- The additive trajectory property is specific to naive Bayes and may not generalize to other classifier types
- The knowledge base approach requires pre-computing all possible feature changes, which becomes computationally expensive with high-dimensional data or fine-grained discretization
- The method assumes feature changes are independent, which may not hold in real-world scenarios

## Confidence
- Additive trajectory mechanism (Mechanism 1): High confidence - Proposition 1 provides formal proof within the naive Bayes framework
- Knowledge base storage approach (Mechanism 2): Medium confidence - conceptually sound but lacks empirical validation of storage/reuse benefits
- Clustering for segment discovery (Mechanism 3): Low confidence - demonstrated on one dataset without comparison to alternative approaches

## Next Checks
1. Test additive property degradation across different levels of feature correlation to establish break conditions
2. Compare counterfactual generation speed and quality between on-demand computation vs. knowledge base approach across multiple datasets
3. Validate clustering results with business experts to confirm segments are actionable and distinct from what simple demographic segmentation would reveal