---
ver: rpa2
title: Unified Matrix Factorization with Dynamic Multi-view Clustering
arxiv_id: '2308.04661'
source_url: https://arxiv.org/abs/2308.04661
tags:
- user
- matrix
- item
- cluster
- factorization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of efficiently utilizing the
  latent representation space in matrix factorization for recommender systems while
  maintaining interpretability. It proposes a unified matrix factorization method
  with dynamic multi-view clustering (MFDMC) that combines dynamic clustering and
  matrix decomposition.
---

# Unified Matrix Factorization with Dynamic Multi-view Clustering

## Quick Facts
- **arXiv ID**: 2308.04661
- **Source URL**: https://arxiv.org/abs/2308.04661
- **Reference count**: 34
- **Primary result**: Achieves state-of-the-art performance on six real-world datasets, outperforming baseline methods by up to 0.025 RMSE

## Executive Summary
This paper introduces a unified matrix factorization method with dynamic multi-view clustering (MFDMC) that addresses the challenge of efficiently utilizing the latent representation space in recommender systems while maintaining interpretability. The method represents user/item embeddings as weighted projections of cluster centers across multiple views, with learnable cluster representations that can be dynamically updated during training. Experimental results demonstrate that MFDMC achieves state-of-the-art performance, outperforming baseline methods by up to 0.025 RMSE on datasets like MovieLens-100k (0.911 RMSE vs 0.938 for FunkMF).

## Method Summary
The MFDMC method combines matrix factorization with dynamic multi-view clustering, where each user/item representation is decomposed into sub-vectors across multiple views, each capturing different aspects of preferences. The method employs dynamic clustering to remove redundant centers during training, ensuring only meaningful representations remain. Multi-view clustering captures multiple roles of users/items by decomposing latent vectors into view-specific cluster projections, effectively utilizing the representation space and improving interpretability for downstream tasks.

## Key Results
- Achieves state-of-the-art performance on six real-world datasets
- Outperforms baseline methods by up to 0.025 RMSE
- On MovieLens-100k dataset, MFDMC achieved RMSE of 0.911 compared to 0.938 for FunkMF
- Visualization and ablation studies confirm method's effectiveness in providing meaningful representations

## Why This Works (Mechanism)

### Mechanism 1
Dynamic clustering improves latent space utilization by removing redundant centers during training. The method removes cluster centers with weights below threshold ùúì after every ùêºùëù epochs, ensuring only meaningful centers remain. Core assumption: Cluster centers with low weights are indeed redundant and removing them improves representation quality.

### Mechanism 2
Multi-view clustering captures multiple roles of users/items by decomposing latent vectors into view-specific cluster projections. Each user/item representation is represented as weighted sum of cluster centers across ùë£ views, where each view captures a different aspect of preferences. Core assumption: Users/items can be meaningfully decomposed into multiple distinct roles/views that are captured by separate cluster groupings.

### Mechanism 3
Weight mapping function balances optimization across views with different numbers of centers. The weight mapping function transforms raw weights to account for varying numbers of centers per view, preventing views with more centers from dominating optimization. Core assumption: Without this mapping, optimization would be unbalanced with views having more centers receiving disproportionate attention.

## Foundational Learning

- **Matrix Factorization (MF)**: Why needed here: MFDMC builds on MF by decomposing user-item interaction matrices into lower-dimensional latent representations. Quick check question: What is the basic MF objective function that minimizes reconstruction error between predicted and actual ratings?
- **Clustering algorithms**: Why needed here: The method uses dynamic clustering to group users/items within each view based on their representations. Quick check question: How does the loss function ensure cluster centers are spread out rather than clustered together?
- **Multi-view learning**: Why needed here: The approach represents each user/item across multiple views, with each view capturing different aspects of their behavior. Quick check question: What is the purpose of decomposing latent vectors into sub-vectors across multiple views?

## Architecture Onboarding

- **Component map**: User embeddings ‚Üí Multi-view clustering ‚Üí Cluster centers ‚Üí Weighted projection ‚Üí Item embeddings ‚Üí Rating prediction
- **Critical path**: The forward pass through multi-view clustering to generate representations, followed by inner product prediction and loss computation
- **Design tradeoffs**: 
  - Shared vs. separate cluster centers for users/items
  - Number of views (v) vs. dimension of centers (b)
  - Dynamic center removal frequency (Ip) vs. stability
- **Failure signatures**: 
  - RMSE plateaus or increases during training
  - Cluster centers collapse to identical values
  - Weight distributions become uniform across clusters
- **First 3 experiments**:
  1. Test baseline MF performance (FunkMF) on a small dataset
  2. Implement single-view clustering with static centers
  3. Add multi-view clustering with shared centers between users and items

## Open Questions the Paper Calls Out

### Open Question 1
How does the dynamic clustering mechanism handle cases where cluster weights remain consistently below the threshold across multiple epochs? The paper mentions that clusters with weights below threshold œà are removed after each iteration of I_p epochs, but doesn't specify behavior when weights persistently remain low.

### Open Question 2
What is the optimal strategy for determining the number of views (v) and cluster centers (t) for different types of recommendation datasets? The paper shows experimental results with different v and t values but doesn't provide a principled method for selecting these hyperparameters.

### Open Question 3
How does MFDMC perform when extended to cold-start scenarios where users or items have very few interactions? The paper mentions the cold-start problem in related works but doesn't evaluate MFDMC's performance in cold-start scenarios.

### Open Question 4
How sensitive is MFDMC's performance to the weight decay regularization parameter Œª, and what is the optimal range for different dataset characteristics? The paper mentions that weight decay with regularization parameter Œª is added to the model but doesn't provide sensitivity analysis.

## Limitations
- The dynamic cluster removal mechanism (threshold œà) requires careful tuning and may not generalize well across different dataset characteristics
- The weight mapping function in Equation 9 is described but lacks detailed implementation specifics that could affect reproducibility
- The method assumes users/items can be meaningfully decomposed into multiple distinct views, which may not hold for all recommendation scenarios

## Confidence
- **High Confidence**: The core matrix factorization framework with dynamic clustering and experimental results demonstrating improved RMSE performance
- **Medium Confidence**: The interpretability claims and the specific mechanism of how multi-view clustering captures multiple roles, as this relies on dataset-specific characteristics
- **Medium Confidence**: The weight mapping function's effectiveness in balancing optimization across views, as the exact implementation details are not fully specified

## Next Checks
1. **Implementation Verification**: Replicate the exact weight mapping function w'' from Equation 9 and test its effect on balancing optimization across views with different numbers of centers
2. **Hyperparameter Sensitivity**: Conduct ablation studies on the dynamic cluster removal threshold œà and frequency Ip to determine their impact on different dataset sizes and characteristics
3. **Cross-dataset Generalization**: Test MFDMC on additional recommendation datasets beyond the six used in the paper to validate the robustness of the multi-view clustering approach across different domains