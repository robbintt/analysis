---
ver: rpa2
title: Towards Explainability in Monocular Depth Estimation
arxiv_id: '2310.16457'
source_url: https://arxiv.org/abs/2310.16457
tags:
- depth
- methods
- estimation
- explainability
- monocular
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a preliminary study on explainability in monocular
  depth estimation by connecting modern deep learning methods with human visual depth
  cues, specifically focusing on the relative size cue. The authors designed a new
  dataset of 23,800 synthetic 2D images featuring black cylindrical objects at varying
  distances against a white background, isolating the relative size cue by eliminating
  other depth cues.
---

# Towards Explainability in Monocular Depth Estimation

## Quick Facts
- arXiv ID: 2310.16457
- Source URL: https://arxiv.org/abs/2310.16457
- Authors: 
- Reference count: 9
- Key outcome: A preliminary study isolating the relative size cue in monocular depth estimation, finding that MiDaS partially learns this cue with ~85% δ1 accuracy.

## Executive Summary
This paper presents a preliminary study on explainability in monocular depth estimation by connecting deep learning methods with human visual depth cues, specifically focusing on the relative size cue. The authors designed a new dataset of 23,800 synthetic 2D images featuring black cylindrical objects at varying distances against a white background, isolating the relative size cue by eliminating other depth cues. They tested three state-of-the-art depth estimation methods (DenseDepth, Monodepth2, and MiDaS) on this dataset and evaluated their performance using standard depth estimation metrics. The study found that MiDaS variations achieved the highest accuracy, particularly when rescaling smaller objects for balanced evaluation, suggesting partial learning of the relative size cue.

## Method Summary
The authors created a synthetic dataset of 23,800 2D images with black cylindrical objects at varying distances against a white background to isolate the relative size cue. They tested three pretrained state-of-the-art depth estimation methods (DenseDepth, Monodepth2, and MiDaS) on this dataset, applying binary masks to focus on object pixels and implementing a scale and shift pre-alignment. The evaluation used standard depth estimation metrics (δ1 accuracy and error measures) with a proposed rescaling approach to balance evaluation across different object sizes. The study compared model performance and investigated how training dataset selection affects learning of depth cues relevant to human perception.

## Key Results
- MiDaS variations achieved the highest accuracy (~85% δ1 accuracy) on the relative size cue task
- Rescaling smaller objects in evaluation provides more balanced accuracy metrics across different object sizes
- DenseDepth pretrained on NYU-v2 outperformed the same model pretrained on KITTI, indicating training dataset selection significantly impacts learning depth cues relevant to human perception

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The relative size cue is effectively isolated in synthetic 2D images by removing occlusion, perspective, and other depth cues.
- Mechanism: The synthetic dataset consists of black cylindrical objects against a white background, ensuring that the only depth information comes from the relative size of objects in the image. This controlled environment mimics human perception experiments.
- Core assumption: The removal of other visual depth cues (occlusion, height in visual field, aerial perspective, etc.) will force models to rely solely on relative size for depth estimation.
- Evidence anchors:
  - [abstract] "We designed a specific experiment to mimic the experiments in humans and have tested state-of-the-art methods to indirectly assess the explainability in the context defined."
  - [section] "To create meaningful explainability experiments we tried to mimic the relevant work done in humans... a particular artificial dataset had to be created, using 3D modeling software. The new dataset consists of 23,800 2D images of black cylindrical objects at various distances against a white background."
  - [corpus] Weak - corpus papers do not address the isolation of specific visual depth cues in synthetic datasets.
- Break condition: If other depth cues inadvertently appear in the synthetic images (e.g., through lighting effects or object arrangement), the isolation of the relative size cue would be compromised.

### Mechanism 2
- Claim: Rescaling smaller objects in the evaluation process ensures balanced error metrics across different object sizes.
- Mechanism: The paper observes that smaller objects in the distance contribute less to overall error metrics due to their size. By rescaling these objects to equal size before calculating metrics, the evaluation becomes more balanced and fair.
- Core assumption: The original error metrics disproportionately weight larger objects, leading to an underestimation of model performance on smaller, distant objects.
- Evidence anchors:
  - [abstract] "In addition, we observed that measuring the accuracy required further attention and a particular approach is proposed to this end."
  - [section] "Additionally, we observed that the size of the objects in the images plays a significant role in the estimates of the error and accuracy... This observation led to the introduction. After the objects become equally sized, the metrics are calculated, ensuring equal significance in error estimates for both objects in the scene."
  - [corpus] Weak - corpus papers do not discuss rescaling objects for balanced evaluation metrics.
- Break condition: If the rescaling process introduces artifacts or distortions that affect the model's depth estimation, the evaluation metrics may become unreliable.

### Mechanism 3
- Claim: Training dataset selection significantly impacts a model's ability to learn depth cues relevant to human perception.
- Mechanism: The paper compares models pretrained on different datasets (NYU-v2 for indoor scenes vs. KITTI for outdoor scenes) and finds that the NYU-v2 pretrained model performs better on the relative size cue task.
- Core assumption: The NYU-v2 dataset contains more examples of relative size depth cues in indoor scenes, which helps the model learn this cue better than the KITTI dataset, which focuses on outdoor urban scenes.
- Evidence anchors:
  - [abstract] "In addition, the DenseDepth method pretrained on NYU-v2 also exhibits increased accuracy compared with MiDaS, whereas the same model pretrained on KITTI is among the worst cases. This shows that the training dataset plays a significant role in learning depth cues and this should be considered in situations where a connection with explainable results is required."
  - [section] "From the experiments, it seems possible that MiDaS partially learns the relative size cue, although more experiments are needed to generalise this remark. In addition, the DenseDepth method pretrained on NYU-v2 also exhibits increased accuracy compared with MiDaS, whereas the same model pretrained on KITTI is among the worst cases."
  - [corpus] Weak - corpus papers do not discuss the impact of training dataset selection on learning specific depth cues.
- Break condition: If the relative size cue is not actually more prevalent in the NYU-v2 dataset compared to KITTI, the observed performance difference may be due to other factors.

## Foundational Learning

- Concept: Visual depth cues
  - Why needed here: Understanding the different visual depth cues (occlusion, relative size, relative density, height in visual field, aerial perspective, motion perspective, convergence, accommodation, binocular disparity) is crucial for designing experiments that isolate specific cues and assess model explainability.
  - Quick check question: Can you list the nine visual depth cues classified by Cutting and Vishton [2] and explain how each contributes to human depth perception?

- Concept: Monocular depth estimation
  - Why needed here: Familiarity with monocular depth estimation methods (DenseDepth, Monodepth2, MiDaS) and their architectures is necessary to understand the experimental setup and results.
  - Quick check question: What are the key differences between the DenseDepth, Monodepth2, and MiDaS methods in terms of their architectures and training approaches?

- Concept: Depth estimation evaluation metrics
  - Why needed here: Understanding standard depth estimation metrics (δ1 accuracy, error measures) and their limitations is essential for interpreting the results and the proposed rescaling approach.
  - Quick check question: How do the δ1 accuracy and error measures used in the paper assess the performance of depth estimation models, and what are their limitations in evaluating relative size cue learning?

## Architecture Onboarding

- Component map: 3D modeling software -> Synthetic dataset generation -> Model selection -> Depth estimation testing -> Binary mask application -> Rescaling process -> Metric calculation

- Critical path:
  1. Generate synthetic dataset with isolated relative size cue
  2. Test pretrained depth estimation models on the dataset
  3. Apply binary masks to focus on object pixels
  4. Rescale smaller objects to equal size
  5. Calculate depth estimation metrics on original and rescaled images
  6. Compare model performance and assess explainability

- Design tradeoffs:
  - Synthetic vs. real dataset: Synthetic dataset allows for precise control over depth cues but may not fully capture the complexity of real-world scenes
  - Rescaling vs. original metrics: Rescaling ensures balanced evaluation but may introduce artifacts or distortions
  - Pretrained vs. fine-tuned models: Pretrained models allow for quick testing but may not be optimized for the specific task of learning relative size cues

- Failure signatures:
  - Poor performance on the synthetic dataset may indicate that the model has not learned the relative size cue effectively
  - Significant differences in performance between original and rescaled metrics may suggest issues with the rescaling process or the model's handling of object size
  - Low δ1 accuracy across all models may indicate that the synthetic dataset is too challenging or that the models are not well-suited for the task

- First 3 experiments:
  1. Test the three selected depth estimation models (DenseDepth, Monodepth2, MiDaS) on the synthetic dataset without any modifications to establish a baseline performance
  2. Apply the rescaling process to the synthetic dataset and retest the models to assess the impact of balanced evaluation metrics
  3. Compare the performance of models pretrained on different datasets (NYU-v2 vs. KITTI) to investigate the impact of training data on learning the relative size cue

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different monocular depth estimation methods perform when trained and tested on datasets specifically designed to isolate individual human visual depth cues?
- Basis in paper: [explicit] The authors created a dataset isolating the relative size cue and tested three methods, but note they are expanding to include other depth cues and need more experiments to generalize their findings.
- Why unresolved: This was a preliminary study focusing on only one depth cue (relative size) with three methods. The authors explicitly state they are expanding the dataset and need more experiments to generalize their findings.
- What evidence would resolve it: Comprehensive testing of multiple state-of-the-art depth estimation methods across multiple datasets, each designed to isolate different human visual depth cues (occlusion, relative density, height in visual field, aerial perspective, motion perspective, convergence, accommodation, binocular disparity).

### Open Question 2
- Question: What is the relationship between the size of objects in training data and a model's ability to learn specific depth cues like relative size?
- Basis in paper: [explicit] The authors observed that object size significantly impacts accuracy metrics and introduced a rescaling approach to balance the significance of error estimates for objects at different distances.
- Why unresolved: While the authors identified this issue and proposed a rescaling solution, they don't explore whether training data composition (proportion of large vs small objects) affects the model's ability to learn relative size cues or whether this insight could inform better training dataset design.
- What evidence would resolve it: Controlled experiments varying the size distribution of objects in training datasets and measuring the impact on depth estimation accuracy, particularly for relative size perception across different distance ranges.

### Open Question 3
- Question: How does the choice of training dataset affect a model's ability to learn depth cues that align with human visual perception?
- Basis in paper: [explicit] The authors found that DenseDepth pretrained on NYU-v2 (indoor scenes) performed better than the same model pretrained on KITTI (outdoor scenes) for relative size estimation, suggesting training dataset selection significantly impacts learning depth cues relevant to human perception.
- Why unresolved: The paper only compared two pretrained models on one specific cue. The authors suggest this warrants consideration but don't investigate which types of datasets (indoor vs outdoor, diverse scenes, specific object distributions) are most effective for learning particular depth cues.
- What evidence would resolve it: Systematic comparison of multiple depth estimation models trained on various datasets (different environments, object distributions, scene types) tested on cue-specific evaluation datasets to identify which training data characteristics best support learning human-like depth perception.

## Limitations
- The synthetic dataset may not fully capture the complexity of real-world scenes where multiple depth cues interact simultaneously
- The evaluation approach using rescaled objects introduces a novel methodology that requires further validation
- The claim that MiDaS partially learns the relative size cue lacks comprehensive statistical analysis across multiple runs
- The connection between training dataset selection and depth cue learning is suggestive but not definitively proven

## Confidence
- High confidence: The synthetic dataset successfully isolates the relative size cue by removing other depth cues
- Medium confidence: MiDaS demonstrates partial learning of relative size cue based on δ1 accuracy metrics
- Medium confidence: Training dataset selection impacts model performance on relative size cue tasks

## Next Checks
1. Test the three selected depth estimation models on a more complex synthetic dataset that includes multiple depth cues simultaneously to assess model performance in realistic scenarios
2. Conduct statistical analysis across multiple runs with different random seeds to establish confidence intervals for the reported δ1 accuracy metrics
3. Implement ablation studies by training models from scratch on datasets with varying prevalence of relative size cues to definitively establish the impact of training data on cue learning