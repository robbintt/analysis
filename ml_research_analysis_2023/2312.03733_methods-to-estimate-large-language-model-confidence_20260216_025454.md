---
ver: rpa2
title: Methods to Estimate Large Language Model Confidence
arxiv_id: '2312.03733'
source_url: https://arxiv.org/abs/2312.03733
tags:
- confidence
- gpt-4
- response
- agreement
- diagnosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates methods to measure GPT-4 confidence when suggesting
  diagnoses for challenging clinical vignettes. GPT-4 was asked 191 clinical cases
  using Chain of Thought and Self Consistency prompting.
---

# Methods to Estimate Large Language Model Confidence

## Quick Facts
- arXiv ID: 2312.03733
- Source URL: https://arxiv.org/abs/2312.03733
- Authors: 
- Reference count: 0
- Primary result: SC Agreement Frequency strongly correlates with accuracy (ROC AUC 0.77) for medical diagnosis confidence assessment

## Executive Summary
This study evaluates three methods to measure GPT-4 confidence when suggesting diagnoses for clinical vignettes: Intrinsic Confidence (self-assessment), SC Agreement Frequency (frequency of most common diagnosis across multiple runs), and CoT Response Length (average response length). The study found that SC Agreement Frequency strongly correlated with observed accuracy (ROC AUC of 0.77), outperforming GPT-4's own Intrinsic Confidence assessment (ROC AUC of 0.71) and CoT Response Length (ROC AUC of 0.59). GPT-4's self-assessment showed only a 15 percentage point difference between correct and incorrect answers, while CoT Response Length showed minimal differences. The results indicate that aggregating multiple reasoning paths through Self-Consistency is more reliable than the model's own confidence estimates for medical diagnosis tasks.

## Method Summary
The study evaluated GPT-4's diagnostic confidence on 191 challenging clinical vignettes from the New England Journal of Medicine using Chain of Thought and Self Consistency prompting. Three confidence assessment methods were tested: Intrinsic Confidence (asking GPT-4 to rate its own confidence), SC Agreement Frequency (frequency of most common diagnosis across 11 runs with temperature=1.0), and CoT Response Length (average response length in characters). Physician evaluators graded responses against ground truth, and ROC AUC was calculated for each confidence method to compare their predictive power for actual accuracy.

## Key Results
- SC Agreement Frequency strongly correlated with observed accuracy (ROC AUC of 0.77)
- GPT-4's Intrinsic Confidence showed only 15 percentage point difference between correct and incorrect answers
- CoT Response Length showed minimal differences between correct and incorrect answers (13 character difference)
- SC Agreement Frequency outperformed both other methods in predicting actual diagnostic accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SC Agreement Frequency measures confidence by aggregating multiple reasoning paths, revealing consistency patterns that correlate with correctness.
- Mechanism: When GPT-4 generates multiple diagnoses for the same case with high temperature (randomness), the frequency of the most common diagnosis (SC Agreement Frequency) indicates how strongly the model converges on a single answer. Higher agreement suggests the model's reasoning consistently arrives at that answer across variations, indicating higher confidence and likely correctness.
- Core assumption: Multiple runs with sufficient variation will produce different answers when the model is uncertain, and consistent answers across runs indicate reliable reasoning.
- Evidence anchors:
  - [abstract] "SC Agreement Frequency strongly correlated with observed accuracy (ROC AUC of 0.77), outperforming GPT-4’s own Intrinsic Confidence assessment (ROC AUC of 0.71)"
  - [section] "Cases where GPT-4 responses were unanimous (complete SC agreement) correlated with a high accuracy whereas lower levels of agreement progressively demonstrated less and less accuracy (Figure 5)"
  - [corpus] Weak evidence - corpus contains related work on CoT reasoning but not specifically on agreement frequency as confidence proxy
- Break condition: If the model's reasoning process is fundamentally flawed or the case has ambiguous features that lead to consistent wrong answers across runs.

### Mechanism 2
- Claim: GPT-4 has limited self-awareness of its own uncertainty, leading to poor Intrinsic Confidence assessment.
- Mechanism: When asked to rate its own confidence, GPT-4 provides a numerical estimate that doesn't accurately reflect its actual performance. The model tends to overestimate its accuracy and shows only a small difference (15 percentage points) between correct and incorrect answers, indicating poor calibration of self-assessment.
- Core assumption: A model that can accurately assess its own performance would show large confidence differences between correct and incorrect answers.
- Evidence anchors:
  - [abstract] "GPT-4’s Intrinsic Confidence showed only a 15 percentage point difference between correct and incorrect answers"
  - [section] "GPT-4 consistently over-estimated its accuracy, reporting an average confidence level of 69% percent when its true accuracy was much lower (42% observed accuracy)"
  - [corpus] Weak evidence - corpus contains work on verbalized uncertainty but not specifically on GPT-4's self-assessment limitations
- Break condition: If the model's architecture changes to improve self-awareness or if different prompting strategies elicit more accurate self-assessment.

### Mechanism 3
- Claim: CoT Response Length is not a reliable proxy for reasoning complexity or confidence because correct and incorrect answers produce similar response lengths.
- Mechanism: The hypothesis that longer responses indicate more complex (and correct) reasoning was tested but found to be invalid. The average response length difference between correct and incorrect answers was only 13 characters, with incorrect answers being slightly longer, suggesting length doesn't correlate with answer quality.
- Core assumption: More complex reasoning requires more text to explain, so longer responses should correlate with correctness.
- Evidence anchors:
  - [abstract] "CoT Response Length showed minimal differences" and "ROC AUC of 0.59"
  - [section] "GPT-4 responses contained an average of 1094 characters when the model predicted the correct diagnosis and 1107 characters when predicting the incorrect diagnosis"
  - [corpus] Weak evidence - corpus contains work on CoT reasoning but not specifically on response length as confidence proxy
- Break condition: If the task type changes such that correct answers consistently require more detailed explanation, or if response length is measured differently (e.g., token count vs characters).

## Foundational Learning

- Concept: ROC AUC (Receiver Operating Characteristic Area Under Curve)
  - Why needed here: The study uses ROC AUC to compare the effectiveness of different confidence assessment methods. Understanding ROC curves and AUC values is essential to interpret why SC Agreement Frequency (0.77) outperforms other methods.
  - Quick check question: What does an ROC AUC of 0.77 tell us about SC Agreement Frequency's ability to distinguish between correct and incorrect diagnoses?

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: CoT prompting is used in conjunction with Self-Consistency to generate the model's responses. Understanding how CoT works (breaking problems into smaller steps) is necessary to grasp why the study combines these methods.
  - Quick check question: How does Chain-of-Thought prompting differ from standard prompting, and why might it improve diagnostic accuracy?

- Concept: Self-Consistency prompting
  - Why needed here: Self-Consistency is the core method being evaluated for confidence assessment. Understanding that it involves running the model multiple times with high temperature and selecting the most common answer is crucial to understanding the study's approach.
  - Quick check question: Why does running the model multiple times with high temperature help assess confidence, and what does the frequency of the most common answer represent?

## Architecture Onboarding

- Component map: GPT-4 API -> Chain of Thought prompting -> Self Consistency runs (11x, temperature=1.0) -> Response grouping -> Physician evaluation -> ROC AUC calculation
- Critical path: Generate responses → Evaluate correctness → Calculate confidence metrics (SC Agreement Frequency, Intrinsic Confidence, CoT Length) → Compute ROC AUC → Compare methods → Draw conclusions about which confidence assessment works best
- Design tradeoffs: The study uses only GPT-4 and one dataset (NEJM cases), limiting generalizability. Using 11 runs for Self-Consistency balances computational cost with statistical significance. Manual grouping of similar diagnoses introduces potential subjectivity.
- Failure signatures: If SC Agreement Frequency doesn't correlate with accuracy (low ROC AUC), if Intrinsic Confidence shows large differences between correct/incorrect answers (contradicting findings), or if CoT Length shows strong correlation with correctness (contradicting findings).
- First 3 experiments:
  1. Replicate the study with a different LLM (e.g., Claude or Llama) to test generalizability.
  2. Vary the number of Self-Consistency runs (e.g., 5, 15, 21) to find the optimal balance between computational cost and confidence assessment accuracy.
  3. Test different temperature settings for Self-Consistency to determine if there's an optimal randomness level for confidence assessment.

## Open Questions the Paper Calls Out

The paper does not explicitly call out any open questions.

## Limitations
- The study only tested GPT-4 on NEJM clinical vignettes, limiting generalizability to other models or medical tasks
- Manual diagnosis grouping introduces subjectivity and potential bias in confidence assessment
- The temperature setting of 1.0 and 11 runs were chosen empirically without optimization testing

## Confidence

- SC Agreement Frequency as superior confidence metric: **High**
- GPT-4's poor self-assessment ability: **High**
- CoT Response Length as unreliable confidence proxy: **Medium**

## Next Checks

1. Test SC Agreement Frequency with different temperature settings (0.5, 1.5, 2.0) to determine optimal randomness for confidence assessment
2. Replicate the study using a different LLM (e.g., Claude or Llama) to evaluate method generalizability across models
3. Apply the confidence assessment methods to a different medical domain (e.g., radiology reports or pathology findings) to test domain transferability