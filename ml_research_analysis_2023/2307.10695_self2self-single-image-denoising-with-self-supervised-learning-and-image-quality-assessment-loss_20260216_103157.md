---
ver: rpa2
title: 'Self2Self+: Single-Image Denoising with Self-Supervised Learning and Image
  Quality Assessment Loss'
arxiv_id: '2307.10695'
source_url: https://arxiv.org/abs/2307.10695
tags:
- image
- noise
- denoising
- learning
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study proposes a single-image self-supervised learning method
  for image denoising, addressing the limitations of existing methods that rely on
  external datasets. The proposed method uses gated convolution for feature extraction
  and a no-reference image quality assessment loss to guide training.
---

# Self2Self+: Single-Image Denoising with Self-Supervised Learning and Image Quality Assessment Loss

## Quick Facts
- arXiv ID: 2307.10695
- Source URL: https://arxiv.org/abs/2307.10695
- Authors: 
- Reference count: 13
- Primary result: Achieves state-of-the-art single-image denoising performance using self-supervised learning with Bernoulli sampling and IQA-guided loss

## Executive Summary
This paper proposes Self2Self+, a self-supervised learning method for single-image denoising that eliminates the need for external clean image datasets. The approach uses Bernoulli sampling to create training pairs from a single noisy image, gated convolutions to handle missing pixels, and a no-reference image quality assessment (IQA) loss to guide perceptual quality. The method demonstrates superior performance on both synthetic Gaussian noise and real-world denoising benchmarks compared to existing state-of-the-art approaches.

## Method Summary
Self2Self+ is an autoencoder-based single-image denoising method that uses self-supervised learning with Bernoulli sampling and IQA-guided training. The architecture employs gated convolutions in the encoder to learn soft masks for handling missing pixels, while the decoder uses dropout layers for variance reduction. Training pairs are generated by randomly masking pixels in the noisy input image using Bernoulli sampling with dataset-specific dropout rates. The loss function combines a self-supervised loss (SAE) with an IQA loss (PaQ-2-PiQ) weighted at 2×10^-8. At inference, the method averages 500 predictions from dropout-activated forward passes to produce the final denoised output.

## Key Results
- Achieves state-of-the-art PSNR and SSIM on AWGN denoising (σ=15, 25, 50) on CBSD68
- Outperforms existing methods on real-world denoising benchmarks (SIDD, PolyU)
- Demonstrates effectiveness of IQA-guided training for perceptual quality improvement

## Why This Works (Mechanism)

### Mechanism 1
Bernoulli sampling with dropout prevents the model from learning an identity mapping while still providing sufficient signal for denoising. By randomly masking pixels in the input image and training to reconstruct the unmasked pixels, the model cannot simply copy the input to the output. The dropout layers in the denoising stage reduce prediction variance by creating multiple independent estimators. This works under the assumption that noise components are independent and have zero mean, allowing the expected loss to approximate a clean-reference loss.

### Mechanism 2
Gated convolution learns soft masks that effectively fill in missing pixel values, reducing artifacts compared to vanilla convolutions. Gated convolution uses two parallel convolutional paths - one for gating (sigmoid activation) and one for features - and multiplies them element-wise. This allows the network to learn which pixels to trust and how to fill missing values based on spatial context. This approach overcomes the partial convolution phenomenon where all channels in the same layer share an identical mask.

### Mechanism 3
No-reference image quality assessment loss guides the network toward human perceptual quality rather than just pixel-wise accuracy. The IQA loss (PaQ-2-PiQ) computes a perceptual quality score and penalizes deviations from perfect quality (score of 100). This encourages the network to preserve textures and structures that humans find important. The IQA loss is particularly valuable for single-image learning tasks where no clean reference exists.

## Foundational Learning

- **Concept**: Bernoulli sampling and dropout mechanics
  - Why needed here: Understanding how random masking creates training pairs and prevents identity mapping is crucial for debugging training behavior.
  - Quick check question: What happens to the loss function if we set the dropout probability to 0 or 1?

- **Concept**: No-reference image quality assessment
  - Why needed here: The IQA loss is a key differentiator; understanding how it works helps in tuning λ_IQA and diagnosing quality issues.
  - Quick check question: How does the PaQ-2-PiQ model compute quality scores without a reference image?

- **Concept**: Gated convolution vs. vanilla convolution
  - Why needed here: The choice of GatedConv in the encoder is critical for handling missing pixels; knowing its mechanics helps in architecture modifications.
  - Quick check question: What is the role of the sigmoid activation in gated convolution, and how does it differ from partial convolution?

## Architecture Onboarding

- **Component map**: Noisy image → GatedConv encoder (with skip connections) → Decoder with dropout + vanilla conv → Output. Training uses Bernoulli-sampled pairs with self-supervised + IQA loss. Inference averages 500 dropout-based predictions.
- **Critical path**: Bernoulli sampling → Encoder feature extraction → Decoder reconstruction → IQA-guided refinement. The dropout layers are only in the decoder during both training and inference.
- **Design tradeoffs**: GatedConv adds parameters but handles missing pixels better than vanilla conv. SAE loss is less sensitive to outliers than SSE but may converge slower. IQA loss adds perceptual guidance but requires a pretrained model and careful weight tuning.
- **Failure signatures**: High dropout probability → blurry outputs. Too low IQA weight → loss of texture. Removing GatedConv → visible artifacts in missing regions. Training instability → check learning rate and loss balance.
- **First 3 experiments**:
  1. Train with only self-supervised loss (no IQA) to verify baseline performance and identify quality gaps.
  2. Vary dropout probability p in Bernoulli sampling to find optimal balance between reconstruction quality and artifact suppression.
  3. Replace GatedConv with vanilla conv in the encoder to quantify the impact on artifact reduction.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform on different types of noise distributions beyond AWGN?
- Basis in paper: [inferred] The paper mentions that the method achieves state-of-the-art denoising performance on both synthetic and real-world datasets, but does not explicitly test on various noise distributions.
- Why unresolved: The paper only demonstrates the method's effectiveness on AWGN and real-world noise, leaving the question of its performance on other noise distributions unanswered.
- What evidence would resolve it: Experiments comparing the method's performance on different noise distributions, such as Poisson noise, impulse noise, or mixed noise models, would provide a clearer understanding of its generalizability.

### Open Question 2
- Question: What is the impact of the dropout rate and the number of training steps on the denoising performance?
- Basis in paper: [explicit] The paper mentions that the probabilities of dropout layers and Bernoulli sampling, as well as the training steps, were selected for each dataset, but does not provide a detailed analysis of their impact on the performance.
- Why unresolved: The paper does not provide a systematic study of the relationship between the dropout rate, the number of training steps, and the denoising performance, leaving the optimal configuration unclear.
- What evidence would resolve it: A comprehensive ablation study varying the dropout rate and the number of training steps would help determine the optimal configuration for different noise levels and datasets.

### Open Question 3
- Question: How does the proposed method compare to other state-of-the-art denoising methods in terms of computational efficiency?
- Basis in paper: [inferred] The paper mentions that the proposed method achieves state-of-the-art denoising performance, but does not provide a comparison of computational efficiency with other methods.
- Why unresolved: The paper focuses on the denoising performance of the proposed method, but does not discuss its computational efficiency compared to other state-of-the-art methods.
- What evidence would resolve it: A comparison of the computational time and memory usage of the proposed method with other state-of-the-art denoising methods would provide insights into its practical applicability.

## Limitations
- Theoretical foundation assumes noise independence and zero-mean properties, which may not hold for all noise types
- IQA loss effectiveness depends heavily on the quality and generalization of the pretrained PaQ-2-PiQ model
- Architecture specifics like exact dropout layer positioning and mask concatenation methods are not fully detailed
- Performance on non-Gaussian noise distributions remains unexplored

## Confidence
- **High confidence**: Effectiveness of Bernoulli sampling in preventing identity mapping and overall denoising performance gains
- **Medium confidence**: Contribution of IQA loss to perceptual quality improvement
- **Medium confidence**: Superiority of gated convolution over alternatives

## Next Checks
1. **Component isolation experiment**: Train the model with self-supervised loss only (no IQA loss) to quantify the perceptual quality improvement contribution of the IQA component.
2. **Architecture ablation study**: Replace gated convolution with vanilla convolution in the encoder while keeping all other components constant to measure the specific impact on artifact reduction.
3. **Noise distribution robustness test**: Evaluate the method on non-Gaussian noise patterns (e.g., Poisson, multiplicative noise) to verify the theoretical assumption about noise independence and zero-mean properties.