---
ver: rpa2
title: Extracting Rules from Event Data for Study Planning
arxiv_id: '2310.02735'
source_url: https://arxiv.org/abs/2310.02735
tags:
- course
- semester
- courses
- data
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how event data from campus management systems
  can be used to analyze the study paths of higher education students and offer valuable
  guidance for their study planning. The authors employ process and data mining techniques
  to explore the impact of sequences of taken courses on academic success.
---

# Extracting Rules from Event Data for Study Planning

## Quick Facts
- arXiv ID: 2310.02735
- Source URL: https://arxiv.org/abs/2310.02735
- Reference count: 14
- Key outcome: Decision trees trained on atomic course semester features achieved 67-69% mean accuracy in predicting course grades for RWTH Aachen University computer science students.

## Executive Summary
This study investigates how event data from campus management systems can be used to analyze study paths and offer guidance for study planning in higher education. The authors employ process and data mining techniques to explore how sequences of taken courses impact academic success. Using decision tree models trained on atomic course semester features, they generate data-driven recommendations in the form of rules and compare these to recommended study plans. The evaluation focuses on RWTH Aachen University's computer science bachelor program, demonstrating that the proposed course sequence features effectively explain academic performance measures with mean accuracy of 67-69%.

## Method Summary
The study extracts event data from RWTH Aachen University's CMS system for 1411 computer science bachelor students across 18 courses. Features are extracted including course semester, order, distance, path length, and directly/eventually follows relationships. Decision tree models are trained using 4-fold cross-validation on these features along with KPIs like GPA. The authors compare atomic course semester features with non-atomic lifecycle features that capture course retakes. Rules are extracted from the trained decision trees and compared against the university's recommended study plan for alignment.

## Key Results
- Decision trees achieved 67-69% mean accuracy in predicting course grades using atomic course semester features
- Rules extracted from decision trees generally align with university-recommended study plans
- Non-atomic lifecycle features (start/end events) were introduced to capture course retakes
- The methodology effectively explains academic performance measures for the studied cohort

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decision trees trained on atomic course semester features can predict course grades with mean accuracy 67-69%.
- Mechanism: Features encode whether a course is taken in a specific semester; decision trees split on these features to model grade outcomes.
- Core assumption: Course timing is a strong signal for academic performance, independent of content or student background.
- Evidence anchors:
  - [abstract] "achieved a mean accuracy of 67-69% in predicting course grades using atomic course semester features"
  - [section 6.1] "generally, average accuracy values are observed to be above 65%"
  - [corpus] weak - corpus contains no direct evidence on accuracy
- Break condition: If course sequencing is not correlated with grades, the model accuracy will drop below chance level (~50%).

### Mechanism 2
- Claim: Rules extracted from decision trees align with university-recommended study plans except for specific deviations.
- Mechanism: Decision tree paths become human-readable rules; alignment is measured by comparing rule conditions to official course schedules.
- Core assumption: The university's recommended plan captures optimal sequencing, so extracted rules should largely match it.
- Evidence anchors:
  - [section 5.4] "rule's conditions and the advised study plan is evident, except for course-115"
  - [section 6.2] "alignment between the rule's conditions and the advised study plan"
  - [corpus] weak - no direct alignment evidence in neighbors
- Break condition: If the university plan is suboptimal, extracted rules will systematically deviate and show better accuracy.

### Mechanism 3
- Claim: Non-atomic features (course lifecycles) extend atomic features to capture retakes and multi-semester courses.
- Mechanism: For each course, start and end events are modeled as separate activities in a partial order, allowing retakes to be distinguished.
- Core assumption: Retaking a course creates a distinct lifecycle that influences grade prediction.
- Evidence anchors:
  - [section 5.2] "we introduce two features for each course, representing the start and end"
  - [section 5.2] "extended partial order for the student example" with distinct start/end activities
  - [corpus] weak - corpus lacks lifecycle modeling examples
- Break condition: If retakes do not materially affect grades, the extended lifecycle features will not improve prediction.

## Foundational Learning

- Concept: Event log structure (case-id, activity, timestamp)
  - Why needed here: The CMS data is modeled as event logs to apply process mining techniques.
  - Quick check question: What three attributes are essential to define an event in process mining?

- Concept: Decision tree splitting criteria (Gini Index, Information Gain)
  - Why needed here: Used to select the best atomic course semester feature at each node.
  - Quick check question: Which metric was chosen for splitting in this study?

- Concept: Partial order construction from DFG
  - Why needed here: To model concurrency and path lengths between courses.
  - Quick check question: How are courses taken in the same semester represented in the partial order?

## Architecture Onboarding

- Component map:
  Data extraction -> Feature extraction (atomic + non-atomic) -> Label extraction -> Decision tree training -> Rule extraction

- Critical path:
  Feature extraction -> Decision tree training -> Rule extraction (accuracy prediction is the gating metric)

- Design tradeoffs:
  Atomic features are simpler but ignore course lifecycle; non-atomic add complexity but capture retakes.
  4-fold CV balances bias/variance but limits sample size per fold.

- Failure signatures:
  Accuracy below 55% indicates feature relevance issue.
  Misaligned rules suggest incorrect index mapping or semester encoding errors.

- First 3 experiments:
  1. Train a decision tree using only atomic course semester features on a single course grade; verify accuracy > 60%.
  2. Add non-atomic features for courses with known retakes; compare accuracy gain.
  3. Extract top 3 rules from the model; manually check alignment with the university plan.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do course grade predictions change when incorporating elective courses and non-computer science required courses into the analysis?
- Basis in paper: [inferred] The authors mention that their analysis focused solely on mandatory courses, excluding electives and courses from outside computer science, which could affect GPA.
- Why unresolved: The study did not include elective courses or non-computer science required courses in their analysis, so the impact of these courses on course grade predictions is unknown.
- What evidence would resolve it: Analyzing course grade predictions with a dataset that includes elective courses and non-computer science required courses would provide insights into how these courses affect the predictions.

### Open Question 2
- Question: How does the time between grade publication and the next exam affect student performance?
- Basis in paper: [explicit] The authors mention investigating the impact of the time between grade publication and the next exam on student performance as a future step.
- Why unresolved: The study did not investigate the relationship between the time between grade publication and the next exam and student performance, so the impact of this time interval is unknown.
- What evidence would resolve it: Analyzing student performance in relation to the time between grade publication and the next exam would provide insights into how this time interval affects performance.

### Open Question 3
- Question: How do alternative classification models compare to decision trees in uncovering study planning rules?
- Basis in paper: [explicit] The authors mention considering alternative classification models to uncover additional study planning rules as a future step.
- Why unresolved: The study only used decision trees for rule extraction, so the effectiveness of alternative classification models in uncovering study planning rules is unknown.
- What evidence would resolve it: Comparing the performance of alternative classification models, such as random forests or support vector machines, with decision trees in uncovering study planning rules would provide insights into their effectiveness.

## Limitations
- Single-institution focus on RWTH Aachen University's computer science program limits generalizability
- Two-level grade label may oversimplify grade distinctions and reduce prediction granularity
- 4-fold cross-validation may not fully capture variance in student cohorts across different academic years

## Confidence
- Grade prediction accuracy claims: High
- Rule alignment with study plans: Medium
- Non-atomic feature benefits: Low

## Next Checks
1. Test model performance on a different institution's data to assess generalizability across programs and universities.
2. Implement a multi-level grade prediction system to evaluate if finer-grained predictions improve accuracy.
3. Conduct ablation studies comparing atomic vs. non-atomic features to quantify the lifecycle feature benefits.