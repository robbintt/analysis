---
ver: rpa2
title: 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models'
arxiv_id: '2305.10601'
source_url: https://arxiv.org/abs/2305.10601
tags:
- language
- search
- thought
- thoughts
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Tree of Thoughts (ToT) introduces a deliberate reasoning framework
  that enables large language models to solve complex problems by exploring a tree
  of coherent intermediate steps (thoughts) rather than making purely sequential decisions.
  By allowing models to generate multiple reasoning paths, self-evaluate progress,
  and perform lookahead or backtracking, ToT addresses limitations in standard left-to-right
  inference that struggle with planning and search-intensive tasks.
---

# Tree of Thoughts: Deliberate Problem Solving with Large Language Models

## Quick Facts
- arXiv ID: 2305.10601
- Source URL: https://arxiv.org/abs/2305.10601
- Reference count: 40
- One-line primary result: ToT improves LLM problem-solving by exploring a tree of intermediate reasoning steps rather than making purely sequential decisions

## Executive Summary
Tree of Thoughts (ToT) introduces a deliberate reasoning framework that enables large language models to solve complex problems by exploring a tree of coherent intermediate steps (thoughts) rather than making purely sequential decisions. By allowing models to generate multiple reasoning paths, self-evaluate progress, and perform lookahead or backtracking, ToT addresses limitations in standard left-to-right inference that struggle with planning and search-intensive tasks. Experiments show significant improvements over chain-of-thought prompting: in Game of 24, success rate increased from 4% to 74%; in Creative Writing, human judges preferred ToT outputs 41% vs 21% for chain-of-thought; and in Mini Crosswords, word-level success rose from under 16% to 60%. The method's generality, modularity, and adaptability make it promising for broader problem-solving applications.

## Method Summary
ToT is a reasoning framework that enables LLMs to explore multiple reasoning paths through a tree structure of intermediate steps called "thoughts." The method combines thought generation (proposing multiple next steps), self-evaluation (rating thoughts as sure/maybe/impossible), and search algorithms (BFS or DFS) to systematically explore promising paths while pruning unpromising ones. Unlike standard chain-of-thought prompting which proceeds linearly, ToT allows backtracking and lookahead by maintaining a frontier of candidate thoughts and evaluating their potential to lead to solutions. The framework is implemented using GPT-4 without additional training, with task-specific prompts for generating and evaluating thoughts.

## Key Results
- Game of 24: Success rate improved from 4% (baseline) to 74% (ToT with BFS)
- Creative Writing: Human judges preferred ToT outputs 41% of the time vs 21% for chain-of-thought
- Mini Crosswords: Word-level success increased from under 16% to 60% with ToT

## Why This Works (Mechanism)

### Mechanism 1: Self-evaluation for pruning
The LM can self-evaluate partial solutions and use this to prune unpromising paths in a tree. At each tree node, the LM generates multiple next-step "thoughts" and then applies a self-designed value prompt to rate each candidate as "sure/maybe/impossible" based on whether it can plausibly lead to a solution. States are ranked and the top candidates are kept for further expansion. This works if the LM's commonsense reasoning is sufficiently accurate to recognize whether a partial equation or word fill can eventually succeed.

### Mechanism 2: Higher-level semantic units
Using higher-level semantic units ("thoughts") rather than token-level predictions allows the LM to reason about intermediate goals and backtrack when necessary. A thought is a coherent language sequence (e.g., an equation step, a paragraph outline, a crossword word). The LM generates several such thoughts at once, enabling it to switch to an alternative if the current path looks unpromising, instead of being locked into a single left-to-right token stream. This works if cohesive intermediate steps are comprehensible to the LM for both generation and evaluation.

### Mechanism 3: Search algorithm integration
Incorporating search algorithms (BFS or DFS) over the tree of thoughts leverages systematic exploration to outperform pure sampling or iterative refinement. BFS keeps a breadth-limited frontier of the best candidate states per step, while DFS explores deeply promising states until a threshold is hit, then backtracks. This structure ensures the LM does not get stuck in local minima and can revisit alternative branches. This works if the number of feasible intermediate states is small enough that explicit search is tractable.

## Foundational Learning

- **Concept**: Token-level autoregressive inference vs. step-level reasoning
  - Why needed here: Understanding why ToT departs from standard left-to-right generation is key to grasping its design and limitations
  - Quick check question: Why does left-to-right token generation struggle with tasks requiring planning or lookahead?

- **Concept**: Tree search algorithms (BFS vs. DFS)
  - Why needed here: ToT is built on these algorithms; knowing their trade-offs helps tune breadth/limit and pruning thresholds
  - Quick check question: In what scenario would BFS be preferable to DFS for ToT?

- **Concept**: Prompt engineering for generation and evaluation
  - Why needed here: The LM is used both to propose next thoughts and to evaluate their promise; prompt quality directly affects performance
  - Quick check question: What makes a value prompt effective for distinguishing "sure" vs. "impossible" thoughts?

## Architecture Onboarding

- **Component map**: Input → Thought Generator (with size limit k) → State Evaluator (with voting/value) → Search Algorithm (BFS/DFS) → Output
- **Critical path**: 
  1. Generate k thought candidates from current state
  2. Evaluate all candidates to obtain a ranking
  3. Select top b candidates (or follow DFS to leaf)
  4. Repeat until output or prune
- **Design tradeoffs**:
  - Breadth limit (b) vs. depth of search: Larger b explores more alternatives but costs more LM calls
  - Thought granularity: Smaller thoughts give more flexibility but may be harder to evaluate; larger thoughts are more coherent but less diverse
  - Value prompt complexity vs. speed: More detailed evaluation prompts can be more accurate but take longer to sample
- **Failure signatures**:
  - If b is too small, the method behaves like naive sampling; if too large, cost explodes without performance gain
  - If evaluation prompts are too vague, the ranking becomes random and search fails to guide correctly
  - If thought decomposition is ill-suited (e.g., treating a crossword clue as a full thought), the LM cannot generate meaningful alternatives
- **First 3 experiments**:
  1. Run ToT with b=1 on Game of 24 and measure success rate; compare with baseline IO/CoT
  2. Sweep b from 1 to 5 and plot success rate vs. number of LM calls to find cost-efficiency sweet spot
  3. Swap BFS for DFS and observe performance change on crosswords, where depth-limited backtracking is critical

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the Tree of Thoughts framework be extended to tasks requiring real-time interaction with external environments or humans?
  - Basis in paper: The discussion section mentions that future applications involving interaction with external environments or humans could bring potential danger but also improve interpretability and alignment
  - Why unresolved: The current framework is tested on static tasks like Game of 24, Creative Writing, and Mini Crosswords, which do not involve real-time feedback or environmental interaction
  - What evidence would resolve it: Successful application of ToT to dynamic tasks such as robotics control, real-time decision-making systems, or interactive dialogue systems

- **Open Question 2**: What are the optimal strategies for balancing computational cost and performance in the Tree of Thoughts framework?
  - Basis in paper: The paper discusses the trade-off between resource usage (e.g., GPT-4 API cost) and task performance, noting that ToT requires more resources than sampling methods
  - Why unresolved: The paper does not provide a systematic analysis of how to optimize this trade-off across different tasks or resource constraints
  - What evidence would resolve it: Empirical studies comparing ToT variants with different breadth and depth limits, or adaptive strategies that dynamically adjust search parameters based on task complexity

- **Open Question 3**: How can the Tree of Thoughts framework be improved to handle tasks with ambiguous or uncertain knowledge, such as rare words in crosswords?
  - Basis in paper: The paper notes that GPT-4 sometimes deems rare or obsolete words as "impossible" to fill in crosswords, suggesting limitations in handling knowledge uncertainty
  - Why unresolved: The current framework relies solely on the language model's internal knowledge, which may not cover all domain-specific or rare information
  - What evidence would resolve it: Integration of external retrieval mechanisms (e.g., web search, knowledge bases) into the ToT framework, with evaluation showing improved performance on tasks requiring rare or specialized knowledge

## Limitations
- The method depends heavily on prompt engineering quality, with effectiveness dropping if prompts are not carefully crafted for each new domain
- ToT is only effective for problems that can be decomposed into coherent intermediate steps with tractable search spaces
- The computational cost is higher than single-pass inference, potentially limiting real-world deployment for complex problems

## Confidence

**High Confidence**: The BFS/DFS framework for exploring trees of intermediate states is sound and well-established. The experimental results showing substantial improvements over baselines (4%→74% in Game of 24, 16%→60% in crosswords) are robust within the tested domains.

**Medium Confidence**: The self-evaluation mechanism (sure/maybe/impossible ratings) is empirically effective but relies on LM capabilities that may not generalize. The paper doesn't provide systematic error analysis of when evaluations fail.

**Low Confidence**: Claims about ToT's general applicability to "complex reasoning" are overstated. The three test domains are structurally similar (discrete states, decomposable into coherent steps). Performance on truly open-ended or continuous problems remains unproven.

## Next Checks
1. **Prompt Robustness Test**: Run ToT on Game of 24 with systematically degraded or simplified prompts. Measure the degradation in success rate to quantify how sensitive the method is to prompt quality.

2. **Scaling Experiment**: Increase the complexity of Creative Writing prompts (e.g., from 4 to 8 input sentences) and measure whether ToT maintains its advantage over chain-of-thought prompting as task difficulty scales.

3. **Cross-Domain Transfer**: Apply ToT to a fundamentally different problem type, such as code repair (fixing buggy programs) or logical puzzle solving with different structure than the tested domains. This would test whether the method truly generalizes beyond structurally similar tasks.