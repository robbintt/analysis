---
ver: rpa2
title: 'Augmenting deep neural networks with symbolic knowledge: Towards trustworthy
  and interpretable AI for education'
arxiv_id: '2311.00393'
source_url: https://arxiv.org/abs/2311.00393
tags:
- data
- learning
- knowledge
- training
- educational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a neural-symbolic AI (NSAI) approach for modeling
  learners' computational thinking in educational games, combining symbolic educational
  knowledge with deep neural networks. The approach injects educational knowledge
  into the network architecture and extracts interpretable rules from the learned
  model.
---

# Augmenting deep neural networks with symbolic knowledge: Towards trustworthy and interpretable AI for education

## Quick Facts
- arXiv ID: 2311.00393
- Source URL: https://arxiv.org/abs/2311.00393
- Reference count: 40
- Key outcome: NSAI approach achieves 84.71% accuracy vs 83.53% for traditional DNNs while providing interpretable predictions and addressing data bias

## Executive Summary
This paper proposes a neural-symbolic AI (NSAI) approach for modeling learners' computational thinking in educational games by combining symbolic educational knowledge with deep neural networks. The approach injects educational knowledge into the network architecture using the KBANN framework and extracts interpretable rules from the learned model. Experiments on a computational thinking game dataset show that NSAI outperforms traditional deep neural networks in both generalizability and accuracy, while also addressing data bias issues and providing interpretable predictions. The extracted rules demonstrate that the model effectively incorporates causal relationships between computational thinking skills and concepts, unlike other models that rely on spurious correlations.

## Method Summary
The NSAI approach combines original training data with educational knowledge represented as propositional logic rules about computational thinking skills and concepts. The method uses the KBANN framework to map these symbolic rules to neural network architecture, initializing the network with domain-specific constraints that are then refined during backpropagation. The approach is compared against three deep neural network baselines (standard DNN, DNN with SMOTE augmentation, and DNN with autoencoder augmentation) using 10-fold cross-validation on a dataset of 427 players from an educational game.

## Key Results
- NSAI achieves 84.71% accuracy compared to 83.53% for traditional deep neural networks
- NSAI demonstrates better generalizability on test data compared to data augmentation methods
- The approach effectively handles data bias by relying on causal relationships rather than spurious correlations
- Extracted rules provide interpretable explanations aligned with educational knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The NSAI approach grounds educational knowledge directly into the neural network architecture, enabling the model to learn causal relationships rather than spurious correlations.
- Mechanism: By using the KBANN framework, the NSAI approach translates symbolic educational knowledge (e.g., rules about CT skills and concepts) into network structure. This initializes the network with domain-specific constraints, which are then refined during backpropagation. The result is a model that prioritizes robust representations aligned with causal relationships.
- Core assumption: Symbolic educational knowledge can be accurately represented as propositional logic rules and mapped to neural network architecture.
- Evidence anchors:
  - [abstract] "The NSAI approach injects and extracts educational knowledge into and from deep neural networks to model learners' computational thinking."
  - [section] "The NSAI approach begins with loading the training data and the educational knowledge in the form of rules... it employs the domain knowledge... to initialize the network architecture."
- Break condition: If the symbolic knowledge is incomplete, inaccurate, or cannot be properly mapped to the network structure, the model may fail to capture true causal relationships or introduce bias.

### Mechanism 2
- Claim: The NSAI approach improves generalizability by learning from both training data and explicit educational knowledge, allowing it to perform better on unseen or imbalanced data.
- Mechanism: By incorporating educational knowledge into the model, NSAI provides additional context beyond raw data. This allows the model to understand underlying relationships even when training data is limited or unrepresentative, leading to better performance on test data.
- Core assumption: Explicit educational knowledge provides valuable context that compensates for limitations in the training data.
- Evidence anchors:
  - [abstract] "Our findings reveal that the NSAI approach has better generalizability compared to deep neural networks trained merely on training data."
  - [section] "The incorporation of explicit knowledge in the NSAI model provides it with a deeper understanding of the underlying relationships among training examples."
- Break condition: If the educational knowledge is not relevant to the task or conflicts with the training data, it may hinder rather than help generalizability.

### Mechanism 3
- Claim: The NSAI approach enables interpretability by extracting rules from the learned network, allowing for reasoning about predictions and refining initial knowledge.
- Mechanism: After training, the NSAI approach extracts rules from the network weights and biases. These rules provide human-readable explanations for predictions and reveal how the model combines both learned data patterns and injected knowledge.
- Core assumption: The network structure and weights can be meaningfully translated back into symbolic rules.
- Evidence anchors:
  - [abstract] "the NSAI approach enables the extraction of rules from the learned network, facilitating interpretation and reasoning about the path to predictions."
  - [section] "it applies Backpropagation using training examples and uses weights and biases of the learned network to extract rules, explaining the predictions."
- Break condition: If the extracted rules are too complex or do not align with human understanding, interpretability may be limited.

## Foundational Learning

- Concept: Symbolic knowledge representation
  - Why needed here: The NSAI approach relies on translating educational knowledge into symbolic form (e.g., propositional logic rules) to inject it into the neural network.
  - Quick check question: How would you represent the relationship "CT skills lead to better final performance" as a symbolic rule?

- Concept: Data augmentation techniques (SMOTE, autoencoders)
  - Why needed here: The paper compares NSAI with deep neural networks trained on original data, SMOTE-augmented data, and autoencoder-augmented data to assess the impact of different augmentation methods on performance.
  - Quick check question: What is the main difference between SMOTE and autoencoder-based data augmentation?

- Concept: Spurious correlations and data bias
  - Why needed here: The paper investigates how different models handle data biases, particularly spurious correlations, and their impact on generalizability and interpretability.
  - Quick check question: Why might a model that learns spurious correlations perform poorly on test data with a different distribution?

## Architecture Onboarding

- Component map: Data preprocessing -> Network initialization (KBANN) -> Training (Backpropagation) -> Rule extraction -> Evaluation
- Critical path: Data preprocessing → Network initialization → Training → Rule extraction → Evaluation
- Design tradeoffs:
  - Incorporating educational knowledge improves interpretability and generalizability but may limit flexibility if the knowledge is incorrect or incomplete
  - Data augmentation methods (SMOTE, autoencoder) can help with class imbalance but may introduce distribution mismatch issues
- Failure signatures:
  - Poor performance on test data despite good training performance: Model may be overfitting or relying on spurious correlations
  - Extracted rules are not interpretable or do not align with human understanding: Knowledge injection or rule extraction process may be flawed
  - Model performance is worse than baseline: Educational knowledge may be incorrect or not relevant to the task
- First 3 experiments:
  1. Implement the NSAI approach on a simple educational dataset (e.g., predicting student performance) and compare its performance with a standard deep neural network
  2. Test the impact of different data augmentation methods (SMOTE, autoencoder) on the NSAI approach's performance
  3. Evaluate the interpretability of the NSAI approach by extracting rules and comparing them with the original educational knowledge

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the NSAI approach be extended to handle sequential and temporal data for predicting learner performance in educational games?
- Basis in paper: [explicit] The paper mentions that future work could test the NSAI approach on different educational tasks, such as sequential and temporal analysis.
- Why unresolved: The current study focuses on modeling computational thinking using static data from a single level of an educational game. Extending the approach to handle temporal data would require incorporating sequential modeling techniques and addressing the challenges of temporal dependencies.
- What evidence would resolve it: Experiments applying the NSAI approach to datasets with sequential or temporal information, such as tracking learner progress over multiple game levels or time-based learning activities, would provide evidence for its effectiveness in handling temporal data.

### Open Question 2
- Question: What are the optimal methods for injecting educational knowledge into neural networks, and how do they compare to the KBANN framework used in this study?
- Basis in paper: [explicit] The paper suggests that future work could experiment with different ways to inject educational knowledge into neural networks, potentially leveraging neural symbolic AI methods.
- Why unresolved: While the KBANN framework was effective in this study, there may be other methods that could further improve the performance and interpretability of neural networks in educational settings. Comparing different knowledge injection techniques would provide insights into their relative strengths and weaknesses.
- What evidence would resolve it: Comparative studies evaluating the performance of the NSAI approach using different knowledge injection methods, such as logic tensor networks or constraint-based architectures, on various educational datasets would provide evidence for the most effective approaches.

### Open Question 3
- Question: How does the NSAI approach perform in real-world educational settings, and what are its implications for personalized learning and student support?
- Basis in paper: [explicit] The paper suggests that future work could integrate the NSAI-based learner modeling method into existing digital learning platforms and evaluate its effectiveness in real-world classrooms.
- Why unresolved: While the study demonstrates the potential of the NSAI approach using a controlled dataset, its performance in real-world educational settings with diverse learners and complex learning environments remains to be investigated. Evaluating its impact on personalized learning and student support would provide insights into its practical value.
- What evidence would resolve it: Implementing the NSAI approach in real-world educational platforms and conducting longitudinal studies to assess its impact on student learning outcomes, engagement, and support would provide evidence for its effectiveness in practice.

## Limitations
- The approach relies on a specific dataset (AutoThinking game) that may not generalize to other educational contexts or domains
- The KBANN framework implementation details are not fully specified, limiting reproducibility
- The evaluation focuses primarily on accuracy metrics without exploring other potential benefits or drawbacks of the NSAI approach

## Confidence

- **High confidence**: The experimental results showing NSAI outperforming traditional deep neural networks on the specific dataset
- **Medium confidence**: The claims about improved generalizability and handling of data bias, as these depend on the specific characteristics of the dataset
- **Medium confidence**: The interpretability claims, as rule extraction quality can vary based on implementation details

## Next Checks

1. Test the NSAI approach on a different educational dataset to verify generalizability across domains
2. Conduct ablation studies to determine which components of the educational knowledge base contribute most to performance improvements
3. Compare the NSAI approach with other neural-symbolic frameworks beyond KBANN to establish relative effectiveness