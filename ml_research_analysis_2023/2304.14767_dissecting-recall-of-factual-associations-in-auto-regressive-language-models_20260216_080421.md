---
ver: rpa2
title: Dissecting Recall of Factual Associations in Auto-Regressive Language Models
arxiv_id: '2304.14767'
source_url: https://arxiv.org/abs/2304.14767
tags:
- subject
- last
- position
- information
- attribute
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates how factual associations are extracted from
  language model parameters during inference. Using attention edge interventions,
  it identifies two critical points where subject and relation information propagate
  to the final prediction.
---

# Dissecting Recall of Factual Associations in Auto-Regressive Language Models

## Quick Facts
- **arXiv ID**: 2304.14767
- **Source URL**: https://arxiv.org/abs/2304.14767
- **Reference count**: 40
- **Primary result**: This work identifies two critical points where subject and relation information propagate to the final prediction during factual recall in auto-regressive language models, revealing a three-step mechanism: subject enrichment via early MLP sublayers, relation propagation, and attribute extraction by upper MHSA sublayers.

## Executive Summary
This study investigates how factual associations are extracted from language model parameters during inference by identifying critical points of information flow and analyzing the role of MLP and MHSA sublayers. Using attention edge interventions, it uncovers that subject and relation information propagate to the final prediction in two distinct stages. The research reveals a three-step mechanism where early MLP sublayers enrich the last subject position with many subject-related attributes, relation information flows first, and upper MHSA sublayers extract the correct attribute by attending to the enriched subject representation. Notably, attribute extraction is performed via attention heads that often encode subject-attribute mappings in their parameters.

## Method Summary
The study uses attention knockout experiments to identify critical information flow points by blocking edges from specific positions to the last position and measuring prediction probability changes. Sublayer knockout cancels MHSA or MLP updates for 10 consecutive layers to analyze their contributions to subject enrichment and attribute extraction. The research also employs gradient-based analysis to assess feature attribution and projections to the vocabulary to inspect subject representations. The analysis focuses on GPT-2 (48 layers, 1.5B parameters) and GPT-J (28 layers, 6B parameters) using queries from COUNTER FACT where models predict correct attributes.

## Key Results
- Two consecutive critical points in computation where relation and then subject information are incorporated into the last position
- Early MLP sublayers are the primary source for subject enrichment, encoding many subject-related attributes
- Upper MHSA sublayers achieve 68.2% attribute extraction rate by attending to enriched subject representations
- Attention heads often encode subject-attribute mappings in their parameters

## Why This Works (Mechanism)

### Mechanism 1
Information flows to the prediction in two distinct stages—first from non-subject (relation) positions, then from subject positions. Attention knockout experiments block edges from specific positions to the last position. When non-subject positions are blocked, probability drops early; when subject positions are blocked, probability drops later. This works because critical information must flow through MHSA sublayers, since they are the only inter-position communication mechanism.

### Mechanism 2
Early MLP sublayers enrich the last subject position with many subject-related attributes before extraction. Sublayer knockout cancels MHSA or MLP updates for 10 consecutive layers. Canceling early MLP sublayers drastically reduces attributes rate (88% drop), while canceling MHSA has minor effect (<30% drop). This works because MLP sublayers act as key-value memories storing factual knowledge that gets retrieved during enrichment.

### Mechanism 3
Upper MHSA sublayers extract the correct attribute by attending to the enriched subject representation, often using attention heads that encode subject-attribute mappings. Attribute extraction rate is measured by checking if the top token by MHSA update matches the final prediction. Upper MHSA sublayers achieve 68.2% extraction rate; specific heads encode subject-attribute mappings in their parameters. This works because MHSA parameters can store direct subject-attribute associations usable during inference.

## Foundational Learning

- **Concept**: Information flow analysis via targeted interventions (knockouts)
  - Why needed here: To identify which positions and layers contribute critical information for factual predictions
  - Quick check question: If you block attention edges from non-subject positions at layers 10-20, what happens to prediction probability? (Expect a moderate drop earlier than blocking subject positions.)

- **Concept**: Hidden representation projection to vocabulary space for interpretability
  - Why needed here: To quantify how much subject-related attribute information is encoded in intermediate representations
  - Quick check question: If you project a subject representation at layer 40, what proportion of top tokens should be subject attributes? (Expect ~50% attributes rate in upper layers.)

- **Concept**: Gradient-times-input (or activation) for per-layer attribution
  - Why needed here: To see which positions remain relevant throughout computation and validate enrichment vs. readiness of subject vs. non-subject tokens
  - Quick check question: In gradient attribution plots, which positions should stay relevant deep into the network? (Subject positions, especially the last subject position.)

## Architecture Onboarding

- **Component map**: Input tokens → embeddings → L transformer layers (MHSA + MLP) → final projection → vocabulary distribution
- **Critical path**: Embeddings → early MLP layers (enrich last subject position) → upper MHSA layers (extract attribute via attention to subject) → final prediction
- **Design tradeoffs**: Using early MLP for enrichment vs. MHSA for extraction separates storage from retrieval; storing in MLP parameters allows parallel enrichment across layers, but extraction requires complex attention patterns
- **Failure signatures**: Low attribute extraction rate (~30-40%) if MHSA sublayers fail; low attributes rate in intermediate layers if MLP enrichment fails; prediction probability collapse if either stage is blocked
- **First 3 experiments**:
  1. Run attention knockout on non-subject positions at layers 5-15 and observe early probability drop
  2. Cancel early MLP updates (layers 1-10) and measure drop in attributes rate at layer 40
  3. Inspect top-10 mappings in W_VO of upper MHSA heads to see if they encode subject-attribute pairs

## Open Questions the Paper Calls Out

### Open Question 1
What is the precise mechanism by which early MLP sublayers enrich subject representations with attributes? The paper shows that early MLP sublayers are the primary source for subject enrichment, but does not fully explain how this enrichment process works. The paper mentions that MLP sublayers can be viewed as key-value memories, but does not provide a detailed explanation of how they store and retrieve subject-related attributes.

### Open Question 2
How do attention heads encode subject-attribute mappings in their parameters? The paper shows that attention heads often encode subject-attribute mappings, but does not explain how these mappings are formed. The paper demonstrates the existence of these mappings but does not explore the underlying reasons for their formation.

### Open Question 3
Can the attribute extraction mechanism be generalized across different types of factual queries? The paper focuses on a specific type of factual query (subject-relation), but does not explore whether the mechanism applies to other types. The analysis is limited to a specific query format, leaving open the question of whether the findings extend to other knowledge extraction tasks.

## Limitations
- Analysis is constrained to single-relation queries from COUNTER FACT, leaving unclear whether multi-hop reasoning would follow the same mechanism
- Attention knockout and sublayer intervention methods may not capture all information flow paths, particularly bypass routes through residual connections
- Corpus analysis reveals no highly-cited prior work directly supporting these specific mechanisms, suggesting limited external validation

## Confidence
- **High confidence**: The sequential information flow pattern (relation → subject) is well-supported by attention knockout experiments across multiple layers
- **Medium confidence**: The MLP enrichment hypothesis is strongly supported for early layers, though the "memory storage" interpretation remains mechanistically plausible rather than definitively proven
- **Medium confidence**: The attention head parameter encoding claim is supported by inspection but limited to a subset of heads, with unclear prevalence across the model

## Next Checks
1. Test multi-hop queries (e.g., "Obama was born in Chicago, which is in Illinois") to verify whether the three-step mechanism extends to compositional knowledge retrieval or requires additional mechanisms

2. Perform targeted activation patching between subject positions and prediction positions to quantify the exact information contribution from each enriched subject attribute, validating the enrichment hypothesis beyond knockout effects

3. Analyze attention patterns across all layers for subject-attribute extraction to determine whether the claimed head-specific mappings represent a general mechanism or specialized cases within the broader extraction process