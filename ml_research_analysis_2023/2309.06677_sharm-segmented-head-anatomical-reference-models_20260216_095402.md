---
ver: rpa2
title: 'SHARM: Segmented Head Anatomical Reference Models'
arxiv_id: '2309.06677'
source_url: https://arxiv.org/abs/2309.06677
tags:
- head
- segmentation
- brain
- segmented
- tissues
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces SHARM, an open-access dataset of 196 segmented
  human head models with 15 tissue types, designed to address the shortage of large,
  diverse datasets for computational studies like electromagnetic brain stimulation.
  Using the IXI MRI dataset and a deep learning architecture called ForkNet+, the
  models were generated through a semi-automatic segmentation pipeline.
---

# SHARM: Segmented Head Anatomical Reference Models

## Quick Facts
- arXiv ID: 2309.06677
- Source URL: https://arxiv.org/abs/2309.06677
- Reference count: 19
- Key outcome: Introduces SHARM, a dataset of 196 segmented human head models with 15 tissue types, validated through volume consistency with real measurements.

## Executive Summary
This study introduces SHARM, an open-access dataset of 196 segmented human head models with 15 tissue types, designed to address the shortage of large, diverse datasets for computational studies like electromagnetic brain stimulation. Using the IXI MRI dataset and a deep learning architecture called ForkNet+, the models were generated through a semi-automatic segmentation pipeline. The segmentation results were validated by comparing tissue volumes with real-world measurements, showing consistency with reference values. SHARM is expected to be a valuable resource for electromagnetic dosimetry and other human head segmentation applications, offering a robust foundation for subject variability studies. The trained model and code are publicly available, enabling further customization and model generation.

## Method Summary
The SHARM dataset was generated using a semi-automatic segmentation pipeline that processes T1w and T2w MRI scans from the IXI dataset. The pipeline combines FreeSurfer-based brain segmentation with thresholding and morphological operations to produce ground truth labels for 15 tissue types. These labels were used to train ForkNet+, a deep learning architecture that processes multi-modality MRI inputs through dual encoders and a shared decoder. Three orientation-specific networks (axial, sagittal, coronal) were trained and their outputs combined using majority voting to produce the final segmentations. The dataset includes 196 subjects, with 20 used for training and 176 for evaluation.

## Key Results
- SHARM provides 196 segmented head models with 15 tissue types, validated against real-world tissue volume measurements
- ForkNet+ architecture successfully segments non-brain tissues using dual-modality T1w/T2w MRI inputs
- Tissue volumes in SHARM models show strong consistency with ICRP Reference Man values and real measurements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ForkNet+ uses multi-modality T1w/T2w MRI inputs to improve segmentation accuracy for non-brain tissues.
- Mechanism: The dual-encoder design extracts complementary tissue contrast information from both T1-weighted and T2-weighted MRI scans, allowing the network to distinguish tissues that are difficult to differentiate in single-modality imaging.
- Core assumption: Non-brain tissues (e.g., skull, fat, muscle) have distinct signal characteristics in T1w and T2w modalities that can be leveraged jointly for better segmentation.
- Evidence anchors:
  - [abstract] "The segmented head models are generated using open-access IXI MRI dataset through convolutional neural network structure named ForkNet+."
  - [section] "The deep learning architecture used here is an extension of ForkNet (Rashed et al., 2019) by considering input data from both T1- and T2-weighted MRI scans."
  - [corpus] Weak - no direct evidence in corpus neighbors about multi-modality inputs.
- Break condition: If the T1w and T2w contrast patterns are insufficient to distinguish target tissues, or if the network fails to fuse the complementary information effectively.

### Mechanism 2
- Claim: The semi-automatic segmentation pipeline ensures high-quality ground truth labels for training ForkNet+.
- Mechanism: The pipeline combines FreeSurfer-based brain segmentation with thresholding and morphological operations to generate anatomically consistent labels for all 15 tissue types, which are then used as training targets.
- Core assumption: The semi-automatic pipeline produces labels that are accurate enough to train a deep network that can generalize to unseen subjects.
- Evidence anchors:
  - [section] "The target dataset for the training process was generated using a semi-automatic segmentation pipeline that segments T1- and T2-weighted MR image data into 15 tissue types (Laakso et al., 2015)."
  - [abstract] "These models are segmented into 15 different tissues; skin, fat, muscle, skull cancellous bone, skull cortical bone, brain white matter, brain gray matter, cerebellum white matter, cerebellum gray matter, cerebrospinal fluid, dura, vitreous humor, lens, mucous tissue and blood vessels."
  - [corpus] Weak - no direct evidence in corpus neighbors about semi-automatic segmentation pipelines.
- Break condition: If the semi-automatic pipeline introduces systematic biases or errors that the deep network cannot learn to correct, leading to poor generalization.

### Mechanism 3
- Claim: Ensembling segmentations from axial, sagittal, and coronal views improves spatial consistency and reduces artifacts.
- Mechanism: Three networks trained on different slice orientations are combined using majority voting, leveraging the complementary strengths of each orientation to produce a more robust final segmentation.
- Core assumption: Each orientation captures different aspects of tissue boundaries and structures, and combining them reduces orientation-specific errors.
- Evidence anchors:
  - [section] "To reduce artifacts caused by 2D slice segmentation, a set of three networks are trained using slices of axial, sagittal and coronal directions as shown in Fig. 3."
  - [abstract] No direct mention of ensembling, but implies comprehensive segmentation.
  - [corpus] Weak - no direct evidence in corpus neighbors about 3D ensembling strategies.
- Break condition: If the majority voting rule fails to resolve conflicts effectively, or if the networks overfit to their respective orientations, leading to inconsistent fusion.

## Foundational Learning

- Concept: Convolutional Neural Networks for image segmentation
  - Why needed here: ForkNet+ is a CNN-based architecture designed for voxel-wise tissue classification in 3D MRI volumes.
  - Quick check question: What is the role of the encoder-decoder structure in a segmentation CNN?

- Concept: Multi-modality medical imaging
  - Why needed here: T1w and T2w MRI provide complementary tissue contrast that ForkNet+ leverages for improved segmentation of non-brain tissues.
  - Quick check question: How do T1-weighted and T2-weighted MRI differ in their tissue contrast properties?

- Concept: Semi-automatic segmentation pipelines
  - Why needed here: The ground truth labels for training ForkNet+ are generated using a semi-automatic pipeline that combines FreeSurfer with thresholding and morphological operations.
  - Quick check question: What are the advantages and limitations of using a semi-automatic pipeline for generating ground truth labels?

## Architecture Onboarding

- Component map:
  - Pre-processed T1w/T2w MRI volumes (256x256x256, [0.01, 0.99]) -> ForkNet+ architecture: Dual encoders (T1w, T2w) -> Shared decoder -> 15 tissue outputs -> Three orientation-specific networks (axial, sagittal, coronal) -> Majority vote aggregation -> 15 binary tissue masks

- Critical path:
  - Pre-process MRI -> Train ForkNet+ -> Evaluate on remaining subjects -> Aggregate outputs -> Generate head models

- Design tradeoffs:
  - Multi-modality inputs improve accuracy but require aligned T1w/T2w scans
  - Ensembling reduces artifacts but increases computation and memory requirements
  - Semi-automatic labels ensure quality but may introduce biases

- Failure signatures:
  - Poor segmentation of small or low-contrast tissues (e.g., blood vessels, lens)
  - Artifacts at tissue boundaries or in regions with complex anatomy
  - Inconsistent results across orientations (indicating ensembling issues)

- First 3 experiments:
  1. Train a single-orientation ForkNet+ on a subset of subjects and compare with the three-orientation ensemble.
  2. Evaluate segmentation accuracy on a held-out test set with manual annotations (if available).
  3. Analyze the impact of different tissue weighting schemes in the aggregation process on final segmentation quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of ForkNet+ compare to other state-of-the-art segmentation methods for non-brain tissues in MRI?
- Basis in paper: [inferred] The paper mentions that ForkNet+ was used for segmentation but does not provide a direct comparison with other methods.
- Why unresolved: The paper does not provide a comparative analysis with other segmentation methods, focusing instead on the consistency of segmented models with real measurements.
- What evidence would resolve it: A study comparing ForkNet+ with other segmentation methods on the same dataset, evaluating accuracy, speed, and robustness.

### Open Question 2
- Question: What are the limitations of using ForkNet+ for segmenting neck tissues and how can these be addressed?
- Basis in paper: [explicit] The paper mentions a lack of neck data in T2 images and difficulties in segmenting neck regions.
- Why unresolved: The paper acknowledges the limitation but does not propose specific solutions or improvements.
- What evidence would resolve it: Development and validation of a method to improve neck segmentation, possibly by incorporating additional imaging modalities or advanced algorithms.

### Open Question 3
- Question: How does the variability in MR data acquisition across different manufacturers affect the segmentation accuracy of SHARM models?
- Basis in paper: [explicit] The paper notes that all data were acquired from the same manufacturer and plans to include data from other manufacturers in future versions.
- Why unresolved: The current dataset is limited to one manufacturer, and the impact of this limitation on segmentation accuracy is unknown.
- What evidence would resolve it: A study incorporating MR data from multiple manufacturers, comparing segmentation accuracy and identifying any manufacturer-specific biases or challenges.

## Limitations
- Validation relies primarily on tissue volume comparisons rather than direct manual annotation comparisons
- ForkNet+ architecture details are not fully specified, making exact reproduction challenging
- Dataset diversity is limited by reliance on a single MRI manufacturer

## Confidence

- ForkNet+ architecture effectiveness: **Medium** - The dual-modality approach is theoretically sound, but lacks direct comparative evidence
- Tissue volume validation: **High** - Strong agreement with reference values and regression analysis
- Generalization to new subjects: **Medium** - Limited by dataset diversity and semi-automatic label quality

## Next Checks

1. Conduct direct comparison with manual annotations on a subset of subjects to quantify Dice scores and Hausdorff distances for each tissue type
2. Test the model on external datasets with different acquisition parameters to assess robustness to scanner variability
3. Perform ablation studies to evaluate the contribution of each mechanism (multi-modality inputs, 3D ensembling, tissue weighting) to final segmentation quality