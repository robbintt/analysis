---
ver: rpa2
title: 'Unlocking the Power of Open Set : A New Perspective for Open-Set Noisy Label
  Learning'
arxiv_id: '2305.04203'
source_url: https://arxiv.org/abs/2305.04203
tags:
- open-set
- examples
- learning
- noisy
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles open-set noisy label learning (OSNLL), a realistic
  setting where datasets contain both closed-set noise (mislabeled examples whose
  true class is among known classes) and open-set noise (mislabeled examples whose
  true class is unknown/out-of-distribution). Existing methods typically detect and
  handle these two noise types separately, but identifying open-set examples is especially
  difficult when the dataset is heavily corrupted.
---

# Unlocking the Power of Open Set : A New Perspective for Open-Set Noisy Label Learning

## Quick Facts
- **arXiv ID**: 2305.04203
- **Source URL**: https://arxiv.org/abs/2305.04203
- **Reference count**: 40
- **Primary result**: CECL achieves over 2% accuracy improvement on multiple datasets compared to state-of-the-art OSNLL methods

## Executive Summary
This paper addresses open-set noisy label learning (OSNLL), where datasets contain both closed-set noise (mislabeled examples whose true class is among known classes) and open-set noise (mislabeled examples whose true class is unknown/out-of-distribution). The authors propose CECL (Class Expansion Contrastive Learning), a two-step method that exploits open-set examples rather than discarding them. They observe that some open-set examples get "integrated" into certain known classes during training, which can even benefit model performance. Extensive experiments on synthetic and real-world datasets show CECL consistently outperforms state-of-the-art OSNLL methods, achieving improvements of over 2% accuracy in several cases.

## Method Summary
CECL is a two-step contrastive learning framework. Step 1 applies a standard noisy-label denoising method to get coarse labels and correction records. Step 2 constructs a prototype-based open-set decision to distinguish examples that can be integrated into known classes from those that should be treated as delimiters. The model is then trained using both a standard classification loss on clean examples and a contrastive loss that pulls together integrated open-set examples and pushes apart delimiter examples to improve representation learning.

## Key Results
- CECL achieves 87.23% accuracy on CIFAR-80N with symmetric 20% noise, compared to 67.00% for previous state-of-the-art
- Consistent improvements across multiple datasets including Web-Aircraft, Web-Bird, Web-Car, and Food101N
- Ablation studies confirm the importance of both class expansion and contrastive learning components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Open-set examples can be beneficially integrated into known classes during training.
- Mechanism: Some open-set examples share feature similarity with closed-set classes, allowing them to be "absorbed" into those classes, improving class separation among known classes.
- Core assumption: Feature similarity between open-set and closed-set examples enables meaningful integration.
- Evidence anchors:
  - [abstract] "a part of open-set examples gradually get integrated into certain known classes, which is beneficial for the separation among known classes"
  - [section 3.1] "we observe that some open-set classes get integrated with several closed-set classes, which we call the Class Expansion phenomenon"
  - [corpus] Weak evidence - no direct citations found in neighbor papers supporting this specific mechanism
- Break condition: When open-set examples are completely dissimilar from all known classes, integration becomes impossible and performance degrades.

### Mechanism 2
- Claim: Contrastive learning with delimiter examples improves representation learning.
- Mechanism: Open-set examples that cannot be integrated are used as "delimiters" - their embeddings are pushed away from known class embeddings, creating better class boundaries.
- Core assumption: Delimiter examples occupy space between known classes and can serve as effective negative samples.
- Evidence anchors:
  - [abstract] "treating others as delimiters to improve representative ability"
  - [section 3.3] "by leveraging the nature of these examples, we treat them as delimiters, continuously pushing the known classes away from them"
  - [corpus] No direct evidence in neighbor papers - this appears to be a novel contribution
- Break condition: If delimiter examples are too similar to known classes or too sparse, the contrastive effect becomes negligible.

### Mechanism 3
- Claim: Two-step framework separates denoising from contrastive refinement.
- Mechanism: First step applies noisy-label denoising to get coarse labels, second step uses contrastive learning with prototype-based open-set decision to refine representations.
- Core assumption: Coarse labels from step one provide sufficient quality for prototype construction in step two.
- Evidence anchors:
  - [abstract] "we propose a novel two-step contrastive learning method called CECL"
  - [section 3.3] "In the first step, we perform a pre-training phase to obtain coarse labels for the entire dataset... In the second step, we leverage the predictions from the first step"
  - [corpus] No direct evidence - this two-step separation is a methodological choice not discussed in neighbor papers
- Break condition: If step one produces very poor coarse labels, the prototype-based decision in step two will fail.

## Foundational Learning

- Concept: Open-set vs closed-set noise distinction
  - Why needed here: The paper specifically addresses scenarios with both types of noise, requiring different handling strategies
  - Quick check question: What's the key difference between closed-set noise and open-set noise in terms of label space?

- Concept: Contrastive learning fundamentals
  - Why needed here: The method builds on contrastive learning but modifies it for the open-set noisy label setting
  - Quick check question: In standard contrastive learning, how are positive and negative pairs typically constructed?

- Concept: Prototype-based classification
  - Why needed here: Prototypes are used to make open-set decisions and construct positive sets for contrastive learning
  - Quick check question: How does a prototype-based approach differ from nearest-neighbor classification?

## Architecture Onboarding

- Component map: Input → Augmentation → Query/Key Networks → Momentum Queue → Prototype Generator → Open-set Decision → Loss (Classification + Contrastive) → Output
- Critical path: Data augmentation → Query/key embeddings → Prototype construction → Open-set decision → Loss computation
- Design tradeoffs:
  - Memory vs accuracy: Momentum queue stores recent embeddings but limits historical context
  - Complexity vs performance: Two-step approach adds complexity but enables better handling of open-set examples
  - Threshold sensitivity: Open-set decision threshold affects which examples are integrated vs used as delimiters
- Failure signatures:
  - Poor performance on known classes: May indicate incorrect open-set decision threshold
  - Unstable training: Could suggest momentum queue size is too small or learning rate too high
  - Degraded representation quality: Might indicate prototypes are poorly constructed from coarse labels
- First 3 experiments:
  1. Baseline comparison: Run standard noisy-label learning method on CIFAR-80N with symmetric 20% noise
  2. Ablation test: Remove contrastive learning component and measure impact on CIFAR-100N with asymmetric 40% noise
  3. Threshold sensitivity: Vary open-set decision threshold on Web-Aircraft dataset and plot accuracy curve

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design a unified detection and handling method for both closed-set and open-set noisy labels instead of treating them separately?
- Basis in paper: [explicit] The authors note that existing methods typically identify and handle closed-set and open-set noise separately, but they observe that some open-set examples get integrated into certain known classes, suggesting a unified approach could be beneficial.
- Why unresolved: The paper proposes a two-step method that exploits class expansion and contrastive learning, but it's unclear whether this approach can be further unified or simplified into a single framework that handles both types of noise simultaneously.
- What evidence would resolve it: Developing a single unified framework that matches or exceeds the performance of separate methods across diverse datasets and noise types would demonstrate the feasibility of this approach.

### Open Question 2
- Question: What is the theoretical foundation for why some open-set examples become integrated into known classes (Class Expansion phenomenon) and how can we predict which examples will exhibit this behavior?
- Basis in paper: [explicit] The authors observe that "a part of open-set examples gradually get integrated into certain known classes" and find this beneficial for separation among known classes, but don't provide theoretical explanation for why this occurs.
- Why unresolved: The paper provides empirical observations of class expansion but lacks theoretical analysis of the underlying mechanisms that cause certain open-set examples to integrate with known classes while others remain distinguishable.
- What evidence would resolve it: Mathematical proofs or rigorous theoretical analysis explaining the conditions under which class expansion occurs, potentially including feature space geometry or manifold learning theory, would provide the needed foundation.

### Open Question 3
- Question: How can we optimize the threshold for distinguishing between open-set examples that should be integrated versus those that should be used as delimiters in contrastive learning?
- Basis in paper: [explicit] The authors use a prototype-based open-set decision with a threshold to identify distinguishable open-set examples, but note in the sensitivity analysis that this threshold is critical and explore its impact.
- Why unresolved: The paper treats the threshold as a hyperparameter to be tuned but doesn't provide a principled method for determining the optimal threshold, which could significantly impact performance.
- What evidence would resolve it: Developing an adaptive threshold selection method or theoretical framework for determining optimal thresholds based on dataset characteristics or noise levels would address this gap.

## Limitations
- The paper's central claim about beneficial class expansion lacks direct empirical validation in the literature
- The mechanism relies heavily on qualitative observations rather than quantitative measurements of feature similarity
- The prototype-based open-set decision threshold is critical to performance but not thoroughly explored for sensitivity to different noise levels

## Confidence
- **High Confidence**: The overall experimental results showing CECL outperforming baselines across multiple datasets
- **Medium Confidence**: The two-step framework architecture and its general effectiveness
- **Low Confidence**: The specific mechanism of class expansion and its claimed benefits for class separation

## Next Checks
1. **Class Similarity Analysis**: Quantify feature similarity between integrated open-set examples and their assigned classes using t-SNE visualizations and nearest-neighbor analysis to validate the class expansion hypothesis
2. **Threshold Sensitivity Study**: Systematically vary the open-set decision threshold across noise levels (0%, 20%, 40%, 60%) and plot accuracy curves to identify optimal ranges and failure modes
3. **Deliminator Effectiveness Test**: Measure class boundary quality using metrics like inter-class distance and intra-class compactness with and without the delimiter contrastive loss to quantify its contribution to representation learning