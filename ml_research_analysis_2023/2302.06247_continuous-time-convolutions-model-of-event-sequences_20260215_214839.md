---
ver: rpa2
title: Continuous-time convolutions model of event sequences
arxiv_id: '2302.06247'
source_url: https://arxiv.org/abs/2302.06247
tags:
- event
- time
- neural
- sequences
- intensity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes COTIC, a continuous-time convolution neural
  network for modeling event sequences. COTIC addresses the challenge of handling
  non-uniform and sparse event data by introducing a continuous convolution layer
  that captures complex dependencies, including self-excitement effects, with minimal
  computational expense.
---

# Continuous-time convolutions model of event sequences

## Quick Facts
- arXiv ID: 2302.06247
- Source URL: https://arxiv.org/abs/2302.06247
- Reference count: 40
- Primary result: COTIC achieves average rank of 1.5 for predicting next event time and type, outperforming nearest competitor (rank 3.714)

## Executive Summary
This paper introduces COTIC, a continuous-time convolutional neural network for modeling event sequences. COTIC addresses the challenge of handling non-uniform and sparse event data by introducing a continuous convolution layer that captures complex dependencies, including self-excitement effects, with minimal computational expense. The model is evaluated on eight diverse datasets and demonstrates superior performance in predicting the next event time and type compared to existing approaches. COTIC also produces effective embeddings for event sequences, showing potential for various downstream tasks.

## Method Summary
COTIC uses continuous convolution layers to directly model non-uniform time series without discretization or interpolation. The model employs delta functions over actual event times and learns kernel functions that operate directly on irregularly spaced inputs. Multiple stacked continuous convolution layers with dilation capture both short-term and long-term dependencies. The model is trained using self-supervised likelihood maximization, optimizing intensity functions that accurately predict event timing and types based on sequence history.

## Key Results
- Average rank of 1.5 for predicting next event time and type across eight datasets
- Outperforms nearest competitor (rank 3.714) and significantly improves upon existing methods
- Produces effective embeddings for event sequences suitable for downstream tasks
- Maintains computational efficiency while handling long-term dependencies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuous convolution allows direct modeling of non-uniform time series without time discretization or interpolation
- Mechanism: By defining convolution with delta functions over actual event times, the model learns kernel functions that operate directly on irregularly spaced inputs
- Core assumption: The continuous convolution kernel can effectively capture dependencies between events regardless of their temporal spacing
- Evidence anchors:
  - [abstract] "Our paper introduces a continuous convolution layer, allowing a model to capture complex dependencies... with little computational expense"
  - [section 4.1.3] "Standard 1-dimensional CNNs are designed for equally lagged data, however, we can extend this idea to a nonuniform case"
  - [corpus] Weak - no direct evidence about convolution kernels handling irregular spacing
- Break condition: If the kernel function cannot generalize across widely varying time gaps, performance will degrade on highly sparse sequences

### Mechanism 2
- Claim: Multiple stacked continuous convolution layers with dilation capture both short-term and long-term dependencies
- Mechanism: Deep architecture with dilated convolutions increases receptive field exponentially while maintaining computational efficiency
- Core assumption: Complex event sequence patterns can be decomposed into hierarchical feature representations through convolutional layers
- Evidence anchors:
  - [section 4.1.4] "we use limited kernel size... Also, we use dilated convolution to increase the receptive field"
  - [section 5.4] "There is a tangible dependence on the number of layers" - suggesting depth matters
  - [corpus] Weak - no evidence about how dilation specifically helps with event sequences
- Break condition: If the number of layers is insufficient, the model cannot capture long-range dependencies; if too deep, it becomes hard to train

### Mechanism 3
- Claim: Self-supervised training on likelihood enables the model to learn meaningful embeddings without requiring labeled data
- Mechanism: The negative log-likelihood loss drives the model to learn intensity functions that accurately predict event timing and types based on sequence history
- Core assumption: The log-likelihood function provides sufficient signal for the model to learn useful representations for downstream tasks
- Evidence anchors:
  - [section 4.1.5] "We first train its convolutional part with the log-likelihood loss (13) for ùëÅ0 epochs while the prediction heads are frozen"
  - [section 3.1] "Once a ùëöùëúùëëùëíùëô (ùíî, ùúÉ) which returns the intensity is defined, it is possible to optimize this model via the likelihood maximization"
  - [corpus] Weak - no evidence about whether self-supervised training is sufficient
- Break condition: If the likelihood signal is too weak or noisy, the embeddings will not generalize well to downstream tasks

## Foundational Learning

- Concept: Temporal point processes and intensity functions
  - Why needed here: The model predicts event intensities as continuous functions, so understanding the mathematical foundation is crucial
  - Quick check question: What is the relationship between intensity function Œª(t) and the probability density function f(t) of event occurrence?

- Concept: Continuous convolution and kernel functions
  - Why needed here: The model's core innovation is continuous convolution over non-uniform time series, requiring understanding of how kernel functions operate on irregularly spaced data
  - Quick check question: How does continuous convolution differ from discrete convolution when applied to event sequences?

- Concept: Self-supervised learning and likelihood maximization
  - Why needed here: The model is trained without labeled data using likelihood-based objectives, so understanding this training paradigm is essential
  - Quick check question: Why is optimizing the log-likelihood preferred over the likelihood itself in practice?

## Architecture Onboarding

- Component map: Input event sequences ‚Üí Continuous convolution layers with dilation ‚Üí Embedding matrix ‚Üí Prediction heads (intensity, return time, event type) ‚Üí Loss functions (likelihood, time, type)
- Critical path: The continuous convolution backbone is critical - without it, the model cannot handle non-uniform time series; prediction heads can be modified or removed
- Design tradeoffs: Depth vs. training difficulty (too deep is hard to train, too shallow cannot capture dependencies); kernel size vs. computational efficiency (larger kernels capture more but cost more); parametric vs. non-parametric intensity (more flexible but harder to train)
- Failure signatures: Poor likelihood indicates backbone issues; good likelihood but poor downstream performance suggests embedding quality problems; training instability suggests numerical issues with the continuous convolution implementation
- First 3 experiments:
  1. Train with 1 layer, kernel size 3, no dilation - verify basic functionality on a simple dataset
  2. Increase to 3 layers with dilation factor 2 - test if depth and dilation improve performance
  3. Compare parametric intensity (like in baselines) vs. non-parametric - validate the key innovation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does COTIC perform on datasets with extremely long event sequences compared to its current evaluation on datasets with average sequence lengths up to 3225.2?
- Basis in paper: [inferred] The paper mentions that COTIC is designed to handle long-term dependencies efficiently, but the evaluation only includes datasets with maximum average sequence length of 3225.2 (IPTV dataset). The authors claim COTIC can handle "the vast amount of data and the significant length of each sequence" but do not provide evidence for extremely long sequences.
- Why unresolved: The paper does not test COTIC on datasets with significantly longer sequences than IPTV, nor does it discuss performance degradation or memory requirements for longer sequences.
- What evidence would resolve it: Performance metrics (MAE, accuracy, log-likelihood) on datasets with average sequence lengths exceeding 10,000 events, along with memory usage and training time comparisons.

### Open Question 2
- Question: How sensitive is COTIC to hyperparameter choices such as kernel size, dilation rates, and depth beyond the ablation study results?
- Basis in paper: [explicit] The paper conducts an ablation study on kernel size and number of layers but only for the Retweet dataset. The authors note "one should be careful interpolating this fact to all the datasets" regarding kernel size independence.
- Why unresolved: The ablation study is limited to one dataset and three parameters. The paper does not explore the full hyperparameter space or provide guidelines for optimal settings across different dataset characteristics.
- What evidence would resolve it: Systematic hyperparameter sensitivity analysis across all eight datasets, including learning rate, dilation patterns, and kernel initialization strategies, with performance impact quantified.

### Open Question 3
- Question: How does COTIC's computational complexity scale with the number of event types and sequence length compared to other models?
- Basis in paper: [inferred] The paper mentions that COTIC is efficient and provides training times for all models, but does not analyze the scaling behavior. The authors claim COTIC is "both accurate and efficient" but do not provide complexity analysis.
- Why unresolved: While training times are provided, there is no theoretical analysis or empirical scaling study showing how COTIC's time and memory complexity grow with increasing numbers of event types (ranging from 3 to 4977 in the datasets) and sequence lengths.
- What evidence would resolve it: Empirical plots showing training/inference time and memory usage as functions of sequence length and number of event types, along with Big-O complexity analysis of the continuous convolution operation.

## Limitations
- Limited ablation studies on hyperparameter sensitivity across diverse datasets
- No analysis of performance on extremely long event sequences
- Computational complexity scaling analysis is missing

## Confidence

**High confidence claims:**
- COTIC outperforms existing approaches on the tested datasets (rank 1.5 vs 3.714)
- The model handles non-uniform time series better than discretized approaches
- The code implementation works as described

**Medium confidence claims:**
- Continuous convolution is the primary driver of performance gains
- The specific architectural choices (number of layers, dilation) are optimal
- Embeddings are effective for downstream tasks

**Low confidence claims:**
- The mechanism by which continuous convolution handles irregular spacing
- The sufficiency of self-supervised training for representation learning
- Generalization to datasets substantially different from the eight tested

## Next Checks

1. **Ablation study on kernel function behavior:** Test COTIC's performance on sequences with varying sparsity levels (from dense to extremely sparse) to verify the continuous convolution mechanism handles irregular spacing as claimed.

2. **Deeper architectural analysis:** Conduct controlled experiments varying dilation rates and layer depths systematically across multiple datasets to quantify their individual contributions to performance.

3. **Representation quality validation:** Compare embeddings learned through likelihood maximization against those from supervised alternatives using the same downstream tasks, measuring both task performance and embedding similarity metrics.