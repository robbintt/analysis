---
ver: rpa2
title: 'AI Foundation Models for Weather and Climate: Applications, Design, and Implementation'
arxiv_id: '2309.10808'
source_url: https://arxiv.org/abs/2309.10808
tags:
- weather
- data
- climate
- learning
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reviews recent advances in machine learning for weather
  and climate modeling, focusing on the potential of foundation models. The authors
  analyze various AI approaches, including transformers, graph neural networks, and
  neural operators, and their applications in weather forecasting, downscaling, parameterization,
  and pattern detection.
---

# AI Foundation Models for Weather and Climate: Applications, Design, and Implementation

## Quick Facts
- arXiv ID: 2309.10808
- Source URL: https://arxiv.org/abs/2309.10808
- Reference count: 40
- Key outcome: Comprehensive review of AI foundation models for weather and climate modeling, proposing design criteria for multi-scale, stable, and data-efficient models

## Executive Summary
This paper provides a comprehensive review of recent advances in machine learning for weather and climate modeling, with particular focus on the emerging paradigm of foundation models. The authors analyze various AI approaches including transformers, graph neural networks, and neural operators, examining their applications in weather forecasting, downscaling, parameterization, and pattern detection. They propose specific criteria for designing weather foundation models that can handle multi-scale dynamics, maintain long-term stability, and achieve data efficiency. The paper highlights how foundation models can improve accuracy and efficiency while offering versatility across diverse weather and climate tasks, though it acknowledges significant challenges in implementation including data representation, model architecture, and pre-training regimes.

## Method Summary
The paper surveys existing ML approaches for weather and climate modeling, analyzing their strengths and limitations. It proposes a framework for designing foundation models that leverage self-supervised learning on large datasets (ERA5, MERRA-2, HRRR) to learn general-purpose representations. The proposed architecture would incorporate multi-scale modeling capabilities, long-term stability mechanisms (such as diffusion models), and data-efficient pre-training regimes. The method involves collecting and preprocessing diverse weather datasets, implementing transformer-based or graph neural network architectures with appropriate positional encodings, training through self-supervised objectives, and fine-tuning for specific downstream tasks.

## Key Results
- Foundation models can learn general-purpose representations of weather data that transfer effectively to downstream tasks through self-supervised learning on large datasets
- Multi-scale modeling capability allows a single foundation model to handle different spatial resolutions and temporal scales
- Long-term rollout stability can be achieved through specialized training objectives and architectures like diffusion models and Fourier space operators

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Foundation models can learn general-purpose representations of weather and climate data that transfer effectively to downstream tasks.
- Mechanism: By training on large, diverse datasets (like ERA5) using self-supervised learning, the encoder learns underlying physical relationships and dynamics without being tied to specific prediction tasks.
- Core assumption: The training data contains sufficient variety and richness in meteorological phenomena to capture the underlying physics.
- Evidence anchors:
  - [abstract]: "foundation models are large, consisting of several million or even billions of parameters... trained on large data volumes in a self-supervised manner"
  - [section 2.9]: "Foundation models can integrate physics-informed climate simulation models for pre-training, offering a rich source of data that augments the learning process"
  - [corpus]: Weak evidence - no direct citations to self-supervised learning in weather/climate foundation models in corpus neighbors
- Break condition: If training data lacks diversity or fails to represent key physical processes, transfer learning will fail.

### Mechanism 2
- Claim: Multi-scale modeling capability allows a single foundation model to handle different spatial resolutions and temporal scales.
- Mechanism: The architecture incorporates mechanisms (like positional encodings) that can generalize across different resolutions and scales during inference.
- Core assumption: The model can learn scale-invariant features that remain relevant across different resolutions.
- Evidence anchors:
  - [section 3.1.1]: "a multi-resolution and multi-physics FM should leverage the high spatiotemporal resolution offered by HRRR and the global availability of ERA5 data"
  - [section 4.1.1]: Discussion of coordinate representation and grid choices
  - [corpus]: Weak evidence - no direct citations to multi-scale foundation models in corpus neighbors
- Break condition: If the model cannot effectively handle the transition between different scales, performance will degrade.

### Mechanism 3
- Claim: Long-term rollout stability can be achieved through specialized training objectives and architectures.
- Mechanism: Diffusion models and Fourier space operators can capture long-range dependencies and reduce instabilities that occur in autoregressive predictions.
- Core assumption: The instabilities in long-term predictions are primarily due to subleading modes in frequency space.
- Evidence anchors:
  - [section 3.2]: "Evidence in the literature [80] shows that roll-out instabilities can be caused by errors in subleading modes in frequency space"
  - [section 4.3.3]: "PDE-Refiner [80] uses the diffusion process to improve the predictions by looking at them iteratively to capture the often neglected low amplitude information in data"
  - [corpus]: Weak evidence - no direct citations to diffusion models for weather/climate in corpus neighbors
- Break condition: If the underlying assumption about frequency space errors is incorrect, diffusion approaches may not improve stability.

## Foundational Learning

- Concept: Self-supervised learning
  - Why needed here: Weather and climate data is abundant but labeled data for specific tasks is limited. Self-supervised learning allows the model to learn from unlabeled data.
  - Quick check question: Can the model learn meaningful representations without explicit labels by reconstructing masked inputs or predicting temporal differences?

- Concept: Transfer learning
  - Why needed here: Foundation models are expensive to train. Transfer learning allows the expensive pre-training to be amortized across multiple downstream tasks.
  - Quick check question: Does fine-tuning the pre-trained model on a new task require significantly less data and compute than training from scratch?

- Concept: Multi-scale representation
  - Why needed here: Weather phenomena occur at different spatial and temporal scales. The model needs to handle this heterogeneity.
  - Quick check question: Can the same model architecture effectively process both high-resolution regional data (HRRR) and global reanalysis data (ERA5)?

## Architecture Onboarding

- Component map:
  - Input layer: Tokenization and positional encoding for weather variables
  - Backbone: Transformer/Graph Neural Network/Neural Operator
  - Pre-training head: Reconstruction/forecasting task
  - Fine-tuning head: Task-specific decoder

- Critical path: Data preprocessing → Tokenization → Encoder pre-training → Fine-tuning on downstream task

- Design tradeoffs:
  - Spatial resolution vs. computational cost: Higher resolution requires more parameters and compute
  - Global vs. regional focus: Global models need spherical representations, regional models can use Cartesian grids
  - Forecasting vs. nowcasting: Different temporal scales require different architectural considerations

- Failure signatures:
  - Poor performance on fine-tuning tasks despite good pre-training loss
  - Inability to generalize to different spatial resolutions
  - Rollout instabilities after a few prediction steps

- First 3 experiments:
  1. Train a simple transformer on ERA5 data with masked reconstruction objective and evaluate on downscaling task
  2. Compare Cartesian vs. spherical grid representations on a global forecasting benchmark
  3. Test different positional encoding schemes for handling multiple pressure levels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can foundation models effectively handle sparse observational data in weather forecasting, or is gridded reanalysis data essential for their success?
- Basis in paper: [explicit] The paper mentions that most AI weather forecasting models are based on gridded analysis and cannot consume observations directly. It also discusses the challenges of incorporating sparse data.
- Why unresolved: The paper acknowledges the potential for foundation models to handle sparse data but does not provide concrete evidence or solutions for integrating observational data into these models.
- What evidence would resolve it: Successful implementation of a foundation model that can effectively incorporate and utilize sparse observational data, demonstrating comparable or superior performance to models using gridded data.

### Open Question 2
- Question: What is the optimal balance between computational efficiency and forecast accuracy for foundation models in weather and climate applications?
- Basis in paper: [inferred] The paper discusses the computational advantages of foundation models compared to traditional NWP models but also mentions the high computational cost of training large models.
- Why unresolved: The paper highlights the trade-off between computational efficiency and accuracy but does not provide a clear framework or guidelines for determining the optimal balance for different applications.
- What evidence would resolve it: Comparative studies evaluating the performance and computational requirements of various foundation model architectures and configurations for different weather and climate tasks.

### Open Question 3
- Question: How can foundation models be designed to effectively capture and forecast extreme weather events, given their rarity in training data?
- Basis in paper: [explicit] The paper mentions that current AI emulators have poor performance at longer lead times and fail to capture extremes in the same manner as ensemble NWP forecasts.
- Why unresolved: The paper acknowledges the challenge of capturing extremes but does not provide concrete solutions or design principles for addressing this issue in foundation models.
- What evidence would resolve it: Successful development and evaluation of a foundation model that demonstrates improved skill in forecasting extreme weather events compared to existing AI and NWP models.

## Limitations

- The proposed mechanisms lack direct empirical validation specific to weather and climate applications
- Specific architectural recommendations are speculative without experimental results
- The paper operates primarily at a theoretical level without providing concrete implementation details or experimental results

## Confidence

**High Confidence**: The identification of key challenges in weather and climate modeling (multi-scale dynamics, long-term stability, data efficiency) and the survey of existing ML approaches are well-supported by the literature.

**Medium Confidence**: The proposed criteria for foundation model design (multi-scale modeling, long-term stability, data efficiency) are logically consistent but lack empirical validation specific to weather and climate.

**Low Confidence**: The specific architectural recommendations (e.g., exact combination of transformer layers, graph neural networks, neural operators) and their claimed advantages are speculative without experimental results.

## Next Checks

1. **Pre-training transfer validation**: Implement the proposed self-supervised pre-training on ERA5 data and measure transfer performance across at least three distinct downstream tasks (e.g., downscaling, extreme event detection, medium-range forecasting) compared to task-specific models.

2. **Multi-scale robustness test**: Train the same foundation model architecture on both HRRR (high-resolution regional) and ERA5 (global) datasets, then evaluate performance when fine-tuned on tasks requiring different spatial resolutions than the pre-training data.

3. **Rollout stability benchmark**: Compare the proposed diffusion model approach for long-term stability against standard autoregressive forecasting on a 14-day global weather prediction task, measuring error growth over time and computational efficiency.