---
ver: rpa2
title: 'Diffusion with Forward Models: Solving Stochastic Inverse Problems Without
  Direct Supervision'
arxiv_id: '2306.11719'
source_url: https://arxiv.org/abs/2306.11719
tags:
- otrgt
- image
- forward
- octxt
- proc
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of learning conditional distributions
  over signals that are never directly observed, only measured through a known differentiable
  forward model (e.g., images of 3D scenes). The authors propose a method that integrates
  the forward model directly into the denoising process of conditional diffusion models,
  allowing joint sampling of the signal and its observation.
---

# Diffusion with Forward Models: Solving Stochastic Inverse Problems Without Direct Supervision

## Quick Facts
- arXiv ID: 2306.11719
- Source URL: https://arxiv.org/abs/2306.11719
- Reference count: 40
- Key outcome: Method learns conditional distributions over signals that are never directly observed by integrating differentiable forward models into diffusion denoising, achieving state-of-the-art results in inverse graphics, motion prediction, and GAN inversion tasks.

## Executive Summary
This paper addresses the challenge of learning conditional distributions over signals that are never directly observed, only measured through a known differentiable forward model (e.g., images of 3D scenes). The authors propose a method that integrates the forward model directly into the denoising process of conditional diffusion models, allowing joint sampling of the signal and its observation. Applied to inverse graphics, the model learns to sample 3D scenes from single images without requiring paired image-3D data. The method is proven to asymptotically learn the true conditional distribution over signals.

## Method Summary
The approach involves integrating a differentiable forward model directly into the iterative conditional denoising process of diffusion models. Given noisy target observations and clean context observations, the model predicts the underlying signal, then applies the forward model to estimate the clean target observation. This creates a cycle where signal prediction and observation reconstruction are tightly coupled. The method uses a denoising network that takes context observations, noisy target observations, and time steps as input, predicts the underlying signal, and then renders it through the forward model. The training objective maximizes the likelihood of the target observation given the context, with additional regularization terms including novel view consistency, depth smoothness, and conditioning loss.

## Key Results
- Outperforms baselines in LPIPS, FID, and KID metrics on 3D scene completion tasks
- Generates diverse, high-quality samples consistent with partial observations
- Achieves 3D consistency across different views through novel view loss enforcement
- Learns to sample 3D scenes from single images without requiring paired image-3D data

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The diffusion process learns the correct conditional distribution over signals by integrating the forward model into the denoising steps.
- **Mechanism:** The model learns to predict the underlying signal from noisy target observations conditioned on clean context observations, then applies the forward model to estimate the clean target observation.
- **Core assumption:** The forward model is differentiable and any signal can be uniquely reconstructed from its total set of possible observations.
- **Evidence anchors:**
  - [abstract] "Our approach involves integrating the forward model directly into the denoising process."
  - [section 2.2] "Our key contribution is to directly integrate the differentiable forward model into the iterative conditional denoising process."
  - [corpus] Weak evidence for this specific mechanism - related papers discuss diffusion models for inverse problems but don't explicitly describe this forward model integration approach.
- **Break condition:** If the forward model is not differentiable or if multiple signals can produce identical sets of observations.

### Mechanism 2
- **Claim:** The method achieves 3D consistency across different views by enforcing the novel view loss term.
- **Mechanism:** The model is trained with a novel view reconstruction loss that ensures the generated 3D scene produces consistent observations when rendered from different camera poses.
- **Core assumption:** The training dataset contains at least three observations per signal to enable the novel view loss.
- **Evidence anchors:**
  - [section 2.1] "Lnovel compares the rendering from the 3D reconstruction with an image from a separate, novel viewpointϕnovel."
  - [section 2.1] "This loss avoids degenerate 3D solutions that can arise by only supervising against a monocular input in each training iteration."
  - [corpus] No direct evidence in corpus papers about this specific novel view consistency mechanism.
- **Break condition:** If the training dataset only contains two observations per signal, or if the novel view loss weight is set too low.

### Mechanism 3
- **Claim:** The 3D-structured conditioning approach allows the model to generate plausible unobserved regions by leveraging learned priors from the context image.
- **Mechanism:** The denoising network takes both the context observation and the noisy target observation as input, allowing it to use the context image as a conditioning signal.
- **Core assumption:** The context image contains sufficient information to guide the generation of plausible unobserved regions.
- **Evidence anchors:**
  - [section 4.1] "We propose to generate conditioning information for Otrgt by rendering a deterministic estimate Otrgt det = render (S(· | enct=0(Octxt)), ϕtrgt)."
  - [section 4.1] "We thus propose to additionally render high-dimensional features."
  - [corpus] Weak evidence - related papers discuss conditional generation but not this specific 3D-structured conditioning approach.
- **Break condition:** If the context image is too limited or uninformative.

## Foundational Learning

- **Concept:** Denoising diffusion probabilistic models
  - **Why needed here:** The method builds upon the denoising diffusion framework to learn conditional distributions over unobserved signals.
  - **Quick check question:** How does the forward Markovian process q(xt|xt-1) differ from the reverse process pθ(xt-1|xt) in diffusion models?

- **Concept:** Differentiable rendering and forward models
  - **Why needed here:** The method relies on a differentiable forward model (like differentiable rendering) to connect observations with underlying signals.
  - **Quick check question:** What properties must a forward model have to be compatible with this approach?

- **Concept:** Conditional generative modeling
  - **Why needed here:** The goal is to learn a conditional distribution p(S|O, ϕ) rather than an unconditional distribution.
  - **Quick check question:** How does conditioning on observations change the training objective compared to unconditional generation?

## Architecture Onboarding

- **Component map:** denoiseθ -> forward model (render) -> signal parameterization (NeRF) -> conditioning encoder (enc)

- **Critical path:**
  1. Start with noisy target observation and clean context observation
  2. Denoising network predicts underlying signal
  3. Forward model renders predicted signal to get denoised observation
  4. Loss compares rendered observation with ground truth
  5. Backpropagate through forward model to update denoising network

- **Design tradeoffs:**
  - Memory vs. quality: Rendering full-resolution images is expensive; the paper uses patch-based rendering
  - Training stability: Adding regularization terms (LPIPS, depth smoothness) improves results but requires tuning
  - Generalization: The model may not generalize well to out-of-distribution data

- **Failure signatures:**
  - Blurry results in uncertain regions: May indicate insufficient conditioning or regularization
  - Inconsistent 3D reconstructions: May indicate problems with the novel view loss or 3D-structured conditioning
  - Mode collapse: May indicate training instability or insufficient diversity in the dataset

- **First 3 experiments:**
  1. Train on a simple synthetic dataset with known ground truth signals and observations to verify the basic mechanism works
  2. Test the novel view consistency by rendering the generated 3D scenes from multiple camera poses
  3. Evaluate the effect of different regularization terms by training with and without each term and comparing results

## Open Questions the Paper Calls Out

- **Open Question 1**
  - **Question:** What is the theoretical limit of the proposed method's ability to recover signals when the number of observations per signal is finite rather than infinite?
  - **Basis in paper:** [explicit] The authors state that their model asymptotically learns the true conditional distribution over signals in the limit of infinite observations per signal.
  - **Why unresolved:** The paper only proves asymptotic convergence and does not characterize the finite-sample behavior or error bounds.
  - **What evidence would resolve it:** Empirical studies showing reconstruction quality as a function of observation count, or theoretical bounds on the KL divergence between the learned and true distributions for finite data.

- **Open Question 2**
  - **Question:** How does the quality of the learned conditional distribution degrade when the forward model has numerical or modeling errors?
  - **Basis in paper:** [inferred] The method requires a "known differentiable forward model" but real-world models may have imperfections.
  - **Why unresolved:** The paper assumes an ideal forward model without investigating robustness to model inaccuracies.
  - **What evidence would resolve it:** Experiments where the forward model is intentionally perturbed or simplified, measuring the impact on generated signal quality.

- **Open Question 3**
  - **Question:** What is the optimal balance between context and target observations for training efficiency and sample quality?
  - **Basis in paper:** [explicit] The method uses pairs of "context" and "target" observations per signal, but the optimal ratio is not explored.
  - **Why unresolved:** The paper does not systematically vary the number or quality of context observations during training.
  - **What evidence would resolve it:** Ablation studies comparing performance with different numbers of context observations per signal, or varying their quality or diversity.

## Limitations
- The method fundamentally depends on the differentiability of the forward model, which may not hold for all real-world applications
- Limited empirical evidence about failure modes and robustness to out-of-distribution data
- Absolute performance values suggest room for improvement, particularly in PSNR scores for inverse graphics tasks

## Confidence
- **High confidence in the theoretical framework:** The asymptotic guarantee and core mathematical formulation are well-established
- **Medium confidence in empirical results:** Quantitative metrics show improvements, but qualitative examples are limited
- **Low confidence in generalization:** No systematic evaluation of out-of-distribution performance or failure cases

## Next Checks
1. **Robustness to forward model quality**: Test the method with intentionally degraded or approximate forward models to understand the sensitivity to model accuracy and differentiability requirements.
2. **Out-of-distribution generalization**: Evaluate performance on scenes or signals that differ significantly from the training distribution to assess real-world applicability.
3. **Failure mode analysis**: Systematically generate and analyze failure cases, particularly where the model produces blurry results or inconsistent 3D reconstructions, to identify architectural or training limitations.