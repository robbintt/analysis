---
ver: rpa2
title: 'CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation'
arxiv_id: '2309.06748'
source_url: https://arxiv.org/abs/2309.06748
tags:
- conversational
- retrieval
- dense
- queries
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of training conversational dense
  retrievers when only a few in-domain dialogues are available. The authors propose
  CONVERSER, which uses large language models in a few-shot setting to generate synthetic
  conversational query-passage pairs.
---

# CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation

## Quick Facts
- arXiv ID: 2309.06748
- Source URL: https://arxiv.org/abs/2309.06748
- Reference count: 12
- Primary result: Achieves comparable performance to fully-supervised models using only 6 examples

## Executive Summary
This paper addresses the challenge of training conversational dense retrievers when only a few in-domain dialogues are available. The authors propose CONVERSER, which leverages large language models in a few-shot setting to generate synthetic conversational query-passage pairs. By employing techniques such as two-stage generation, passage switching, and consistency filtering, the method produces high-quality synthetic data that enables training effective conversational dense retrievers without requiring extensive annotated dialogues.

## Method Summary
CONVERSER uses in-context learning with large language models to generate synthetic conversational query-passage pairs from few-shot examples (6 dialogues for OR-QuAC, 5 for TREC CAsT-19). The method employs a two-stage generation approach separating first queries from follow-up queries, applies passage switching with probability pps, and uses consistency filtering via roundtrip retrieval to ensure quality. The synthetic data is then used to train a BERT-base dense retriever using DPR-style training with in-batch negatives. The approach is evaluated on OR-QuAC and TREC CAsT-19 datasets, achieving comparable performance to fully-supervised models.

## Key Results
- Achieves comparable performance to fully-supervised models on OR-QuAC using only 6 examples
- Demonstrates effectiveness of few-shot conversational query generation with LLMs
- Shows two-stage generation and consistency filtering improve synthetic data quality

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Few-shot in-context learning with LLMs enables effective generation of conversational queries without requiring large annotated conversational datasets.
- **Mechanism**: The LLM is prompted with a small set of example (passage, query) pairs and a new passage, then generates a contextually appropriate conversational query by leveraging learned patterns from the examples.
- **Core assumption**: The LLM has sufficient world knowledge and generalization ability to generate coherent conversational queries even when only 6 examples are provided.
- **Evidence anchors**:
  - [abstract] "We utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus."
  - [section 3.1] "We leverage the in-context learning ability of LLMs (Brown et al., 2020) to generate synthetic conversational query-passage pairs with few-shot demonstrations."
  - [corpus] Weak - No direct corpus evidence for this mechanism; relies on general LLM capability claims.
- **Break condition**: If the LLM lacks sufficient domain knowledge or the few-shot examples are unrepresentative, generated queries may be incoherent or irrelevant.

### Mechanism 2
- **Claim**: Two-stage generation (first query vs. follow-up query) improves the quality of conversational query generation by addressing the distinct nature of initial and subsequent turns.
- **Mechanism**: The system uses different prompt templates for generating the first query (context-independent) versus follow-up queries (context-dependent), allowing the LLM to better handle the different characteristics of each type.
- **Core assumption**: The first query in a conversation has fundamentally different properties (needs to be self-contained) compared to follow-up queries (can be context-dependent).
- **Evidence anchors**:
  - [section 3.2] "We propose to split the generations into two-stage: first query generation and follow-up query generation."
  - [section 3.2] "In practice, we found that this two-stage approach reduces the number of generated first queries that are not self-contained and thus ambiguous."
  - [corpus] Weak - No direct corpus evidence; based on internal experimental findings.
- **Break condition**: If the distinction between first and follow-up queries is not clear in the domain, this staged approach may not provide benefits.

### Mechanism 3
- **Claim**: Consistency filtering via roundtrip retrieval ensures high quality of generated conversational queries by validating their relevance to source passages.
- **Mechanism**: After generating synthetic (query, passage) pairs, the system uses an initial retriever to check if the original passage appears in the top-k retrieved results for each generated query. Pairs that fail this test are discarded.
- **Core assumption**: A high-quality initial retriever can accurately assess whether generated queries are truly relevant to their source passages.
- **Evidence anchors**:
  - [section 3.4] "We adopt a filtering mechanism via ensuring roundtrip consistency (Alberti et al., 2019)."
  - [section 3.4] "We keep the pair (ˆq, ˆp) only if ˆp is in the top-k retrieved passages."
  - [corpus] Weak - No direct corpus evidence; relies on established roundtrip consistency concept from prior work.
- **Break condition**: If the initial retriever is not well-trained or the retrieval corpus is too noisy, this filtering mechanism may incorrectly discard valid pairs or retain invalid ones.

## Foundational Learning

- **Concept**: In-context learning with LLMs
  - **Why needed here**: The entire approach relies on the LLM's ability to generate relevant conversational queries from few examples without any parameter updates.
  - **Quick check question**: Can you explain the difference between in-context learning and fine-tuning for LLMs?
- **Concept**: Dense retrieval fundamentals
  - **Why needed here**: The generated synthetic data is used to train dense retrievers, so understanding how dense retrieval works is essential.
  - **Quick check question**: What is the key difference between dense retrieval and traditional sparse retrieval methods like BM25?
- **Concept**: Conversational search characteristics
  - **Why needed here**: The method specifically addresses the challenges of conversational search, including context-dependence and multi-turn interactions.
  - **Quick check question**: What makes conversational queries different from standard search queries in terms of retrieval requirements?

## Architecture Onboarding

- **Component map**: LLM prompt template builder -> LLM inference -> Two-stage generation controller -> Passage switching module -> Consistency filter -> Synthetic dataset -> Dense retriever trainer
- **Critical path**: Passage selection -> LLM prompt construction -> Query generation -> Consistency filtering -> Dataset creation -> Retriever training
- **Design tradeoffs**:
  - Few-shot examples (6) vs. generation quality: Minimal examples reduce annotation burden but may limit diversity
  - Generation volume (427k turns) vs. computational cost: More data generally improves retriever performance but increases training time
  - Consistency filtering threshold (top-k) vs. dataset size: Stricter filtering improves quality but reduces quantity
- **Failure signatures**:
  - Low MRR/R@5 scores despite large synthetic dataset: Indicates poor generation quality or ineffective filtering
  - Degenerated generations (repetitive text): Suggests LLM decoding parameters need adjustment
  - Ambiguous first queries: May indicate two-stage generation not working properly
- **First 3 experiments**:
  1. Generate synthetic data with 1 example vs. 6 examples to quantify few-shot effectiveness
  2. Compare single-stage vs. two-stage generation to validate the design choice
  3. Test different consistency filtering thresholds (top-1, top-5, top-10) to optimize quality vs. quantity tradeoff

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several important research directions emerge from the methodology and results.

## Limitations
- Reliance on manually selected few-shot examples without disclosing their exact content, introducing uncertainty about reproducibility
- Effectiveness depends on the specific characteristics of the selected examples which are not disclosed
- The passage switching mechanism (pps) is mentioned but its exact implementation details are unclear

## Confidence
- **High confidence**: The core methodology of using LLMs for synthetic data generation and the two-stage generation approach are well-established concepts with clear implementation details.
- **Medium confidence**: The effectiveness of few-shot learning with only 6 examples, as the success depends on the specific characteristics of the selected examples which are not disclosed.
- **Medium confidence**: The consistency filtering mechanism's impact, as while the concept is sound, its exact threshold and implementation details are not fully specified.

## Next Checks
1. **Example diversity analysis**: Test the system with varying numbers of few-shot examples (1, 3, 6, 10) to quantify the minimum effective sample size and assess sensitivity to example quality.

2. **Generation quality audit**: Manually evaluate a sample of generated conversational queries for coherence, relevance, and conversational naturalness to verify the effectiveness of the two-stage generation approach.

3. **Ablation on filtering**: Compare retriever performance with different consistency filtering thresholds (no filtering, top-1, top-5, top-10) to determine the optimal tradeoff between dataset size and quality.