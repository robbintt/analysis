---
ver: rpa2
title: 'Large Language Model for Science: A Study on P vs. NP'
arxiv_id: '2309.05689'
source_url: https://arxiv.org/abs/2309.05689
tags:
- problem
- instances
- instance
- constraint
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a pilot study on using large language models
  (LLMs) to tackle the P vs NP problem, one of the most important open problems in
  theoretical computer science. The authors propose Socratic reasoning, a general
  framework that prompts LLMs to recursively discover, solve, and integrate problems
  while facilitating self-evaluation and refinement.
---

# Large Language Model for Science: A Study on P vs. NP

## Quick Facts
- arXiv ID: 2309.05689
- Source URL: https://arxiv.org/abs/2309.05689
- Reference count: 2
- Primary result: Pilot study using LLM Socratic reasoning to produce a proof schema for P vs NP, concluding "P ≠ NP" over 97 dialogue turns

## Executive Summary
This paper presents a pilot study using large language models (LLMs) to tackle the P vs NP problem through a framework called Socratic reasoning. The authors propose a recursive approach that decomposes complex problems into manageable subproblems while facilitating self-evaluation and refinement. Using GPT-4, the study successfully generates a proof schema and engages in rigorous reasoning, concluding that P ≠ NP. This work sheds light on the potential of LLMs for scientific discovery and demonstrates their ability to navigate complex solution spaces through structured reasoning patterns.

## Method Summary
The study employs a Socratic reasoning framework that uses five atomic prompt patterns: deduction, transformation, decomposition, verification, and integration. The method involves recursive problem-solving where GPT-4 is prompted to discover, solve, and integrate problems while self-evaluating its reasoning. The approach includes human-guided prompting with structured dialogue turns, temperature settings of 0.7, and top probabilities of 0.95. The framework requires careful monitoring for hallucinations and context management, with problem decomposition used when the LLM's context window becomes insufficient.

## Key Results
- Successfully generated a proof schema for P vs NP using GPT-4 over 97 dialogue turns
- Demonstrated the LLM's ability to engage in rigorous reasoning and reach the conclusion "P ≠ NP"
- Showed that Socratic reasoning framework can navigate complex solution spaces and produce structured mathematical reasoning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Socratic reasoning framework decomposes complex problems into manageable subproblems and integrates their solutions.
- Mechanism: Uses five atomic prompt patterns (deduction, transformation, decomposition, verification, integration) to recursively navigate solution space.
- Core assumption: LLMs can follow recursive reasoning patterns when prompted with clear, structured instructions.
- Evidence anchors: [abstract] "Socratic reasoning encourages LLMs to recursively discover, solve, and integrate problems"; [section 2] "five atomic prompt patterns in Socratic reasoning"

### Mechanism 2
- Claim: LLMs can extrapolate novel scientific knowledge by transforming and abstracting problems into new domains.
- Mechanism: Transformation pattern reframes problems from computer science into philosophical or conceptual domains.
- Core assumption: LLM's broad knowledge base allows meaningful connections across domains when prompted.
- Evidence anchors: [section 1] "Inspired by the ancient Greek philosopher Socrates"; [corpus] "The Art of SOCRATIC QUESTIONING"

### Mechanism 3
- Claim: LLMs can rigorously verify and refine their own reasoning through self-critique capabilities.
- Mechanism: Verification pattern prompts LLM to check logical consistency, potential errors, and gaps in reasoning.
- Core assumption: LLMs possess sufficient self-critique abilities to identify and correct flaws when explicitly prompted.
- Evidence anchors: [section 2] "verification pattern to leverage the self-critique capabilities"; [corpus] "SSR: Socratic Self-Refine"

## Foundational Learning

- Concept: Problem decomposition
  - Why needed here: Breaking down P vs NP into tractable subproblems
  - Quick check question: Can you identify key subproblems in proving P != NP?

- Concept: Recursive reasoning
  - Why needed here: Framework relies on recursive application of prompt patterns
  - Quick check question: How does integration pattern synthesize solutions from subproblems?

- Concept: Self-verification in reasoning
  - Why needed here: Ensuring proofs are logically consistent and error-free
  - Quick check question: What role does verification pattern play in refining reasoning?

## Architecture Onboarding

- Component map: Human operator providing structured prompts -> LLM (GPT-4) generating responses -> Feedback loop for refinement
- Critical path: Problem transformation -> Subproblem generation/solution -> Integration and verification
- Design tradeoffs: Exploration vs exploitation (diverse subproblems vs promising ones); creativity vs rigorous verification
- Failure signatures: LLM cannot generate coherent subproblems; loses track of integration step; fails to verify reasoning
- First 3 experiments:
  1. Test decomposition pattern on simpler problem (e.g., proving basic theorem)
  2. Test transformation pattern by reframing well-known problem from different domain
  3. Test verification pattern by identifying errors in deliberately flawed proof

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs autonomously generate novel scientific insights and proofs beyond interpolating existing knowledge?
- Basis in paper: [explicit] Demonstrates GPT-4's ability to construct proof schema and engage in rigorous reasoning, concluding "P ≠ NP"
- Why unresolved: Study focuses on single case; further research needed for consistent generation across diverse domains
- What evidence would resolve it: Systematic studies testing LLMs on wide range of open scientific problems with multiple novel proofs/insights

### Open Question 2
- Question: What are limitations of Socratic Reasoning framework for complex problem-solving with LLMs?
- Basis in paper: [inferred] Acknowledges need for human guidance, challenges in reproducibility, potential benefit of external tools
- Why unresolved: Doesn't provide comprehensive analysis or compare to other prompting strategies
- What evidence would resolve it: Empirical studies comparing Socratic Reasoning to other techniques on various complex tasks

### Open Question 3
- Question: Can LLMs be effectively integrated with laboratory automation and external tools for scientific discovery?
- Basis in paper: [inferred] Mentions potential of augmenting LLMs with laboratory automation and tools like Mathematica
- Why unresolved: Doesn't provide concrete examples or empirical results on tool integration
- What evidence would resolve it: Successful demonstrations of LLMs collaborating with laboratory automation to generate hypotheses and design experiments

## Limitations
- Verifiability concerns: Proof correctness cannot be formally verified without domain expert validation
- Human dependency: Success depends on operator's ability to provide appropriate prompts and interpret responses
- Limited scope: Focuses on single complex problem without exploring scalability to other domains

## Confidence
- High: Effectiveness of Socratic reasoning framework in guiding LLMs through recursive problem-solving
- Medium: Ability of LLMs to generate novel scientific insights through problem transformation
- Low: Correctness and rigor of the P vs NP proof produced by the LLM

## Next Checks
1. Formal proof verification by domain experts to assess mathematical validity
2. Replication on simpler problems with known solutions to test generalizability
3. Ablation study of prompt patterns to identify most critical components