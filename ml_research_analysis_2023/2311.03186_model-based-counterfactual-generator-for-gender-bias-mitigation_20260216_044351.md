---
ver: rpa2
title: Model-based Counterfactual Generator for Gender Bias Mitigation
arxiv_id: '2311.03186'
source_url: https://arxiv.org/abs/2311.03186
tags:
- gender
- text
- data
- dataset
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses limitations of dictionary-based counterfactual
  data augmentation (CDA) techniques for mitigating gender bias in language models,
  such as generating ungrammatical text and failing to generalize beyond predefined
  dictionaries. The authors propose a model-based approach that combines data processing
  techniques and a bi-objective training regime.
---

# Model-based Counterfactual Generator for Gender Bias Mitigation

## Quick Facts
- arXiv ID: 2311.03186
- Source URL: https://arxiv.org/abs/2311.03186
- Reference count: 19
- Key outcome: Model-based approach outperforms dictionary-based CDA with improved fluency, gender transfer accuracy, and bias mitigation on Bias-in-Bios and Jigsaw datasets.

## Executive Summary
This paper addresses limitations of dictionary-based counterfactual data augmentation (CDA) for gender bias mitigation, specifically ungrammatical outputs and failure to generalize beyond predefined dictionaries. The authors propose a model-based approach combining data processing techniques with a bi-objective training regime. Their method generates parallel data from dictionary-based CDA outputs and trains a generator-discriminator model to produce counterfactuals that flip gender associations while maintaining grammatical correctness. The approach shows improved fluency (lower perplexity), higher gender transfer accuracy, and better extrinsic and intrinsic bias mitigation compared to traditional CDA methods.

## Method Summary
The method consists of a data processing pipeline followed by bi-objective training. First, dictionary-based CDA generates seed counterfactuals, which are processed using ELECTRA to detect erratic tokens, BART to correct them, and BERT to filter unchanged texts. The cleaned parallel data then trains a generator (BART) to produce counterfactuals and a discriminator (feed-forward network) to ensure gender flipping. The bi-objective loss combines both objectives, making the model more robust to errors in parallel data labels. The generator learns to generalize beyond dictionary terms by capturing latent gender attributes in contextual embeddings.

## Key Results
- MBCDA achieves significantly lower perplexity than dictionary-based methods on both Bias-in-Bios and Jigsaw datasets
- Gender transfer accuracy improves by 15-25% compared to baseline CDA across evaluation datasets
- TPRD and FPRD metrics show better extrinsic bias mitigation while maintaining comparable intrinsic bias scores (WEAT)
- Ablation studies confirm the importance of the discriminator component for robust performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model-based approach can generalize beyond predefined dictionary words by learning latent gender attributes.
- Mechanism: The generator learns mappings between gender words through contextual embeddings, allowing it to identify and swap gender terms not explicitly in the dictionary.
- Core assumption: Gender associations can be captured as latent features in the model's learned representations.
- Evidence anchors:
  - [abstract] "Model-based solutions can alleviate these problems, yet the lack of qualitative parallel training data hinders development in this direction."
  - [section 3] "The primary benefit of a model-based solution is that it allows the model to generalize outside the predefined list of seed words."
- Break condition: If the model fails to learn meaningful gender associations from the training data, it will not generalize beyond dictionary terms.

### Mechanism 2
- Claim: The bi-objective training approach improves robustness to errors in parallel data labels.
- Mechanism: The discriminator constrains the generator to change gender associations while avoiding unlikely tokens, reducing propagation of errors from dictionary-based CDA outputs.
- Core assumption: Combining generator and discriminator objectives creates a more robust training signal than using either alone.
- Evidence anchors:
  - [section 3.2] "A bi-objective approach also makes our model more robust to errors in the parallel data labels."
  - [section 5.6] Ablation studies show models trained with discriminator perform better than those without.
- Break condition: If the discriminator's constraints are too strict or too lenient, the generator may either fail to learn or learn incorrect patterns.

### Mechanism 3
- Claim: The parallel data processing pipeline improves grammatical correctness of counterfactuals.
- Mechanism: The pipeline uses ELECTRA to detect and mask erratic tokens, BART to generate plausible replacements, and BERT to filter out texts that didn't change gender.
- Core assumption: Erratic tokens can be reliably detected and corrected using pretrained language models.
- Evidence anchors:
  - [section 3.1] "This step involves identifying and correcting grammatical inconsistencies from dictionary-based counterfactuals."
  - [section 5.1] "Since many of the grammatical incoherents in the text are successfully resolved, the generated texts tend to be more fluent."
- Break condition: If the threshold for detecting erratic tokens is poorly calibrated, the pipeline may either miss errors or overcorrect, introducing new errors.

## Foundational Learning

- Concept: Counterfactual Data Augmentation (CDA)
  - Why needed here: Understanding CDA is essential as the paper builds upon and improves this technique
  - Quick check question: What is the core idea behind counterfactual data augmentation for bias mitigation?

- Concept: Bi-objective training
  - Why needed here: The proposed model uses this training approach to combine generator and discriminator objectives
  - Quick check question: How does bi-objective training differ from standard adversarial training?

- Concept: Gender bias in language models
  - Why needed here: The paper's entire focus is on mitigating gender bias using counterfactual generation
  - Quick check question: What are the two main types of errors in dictionary-based CDA methods as identified by the paper?

## Architecture Onboarding

- Component map:
  Data Processing Pipeline: Dictionary-based CDA -> ELECTRA (erratic token detection) -> BART (text correction) -> BERT (filtration) -> Parallel data
  Bi-objective Model: Generator (BART) + Discriminator (Feed-forward network) + Combined loss function

- Critical path:
  1. Generate parallel data from dictionary-based CDA outputs
  2. Train discriminator on parallel data
  3. Train generator with bi-objective loss
  4. Generate counterfactuals and evaluate

- Design tradeoffs:
  - Using pretrained models vs. training from scratch
  - Complexity of bi-objective training vs. simpler single-objective approaches
  - Quality of dictionary-based CDA outputs vs. effort to improve them

- Failure signatures:
  - Low gender transfer accuracy indicates discriminator is not effective
  - High perplexity indicates generator is not producing fluent text
  - Similar WEAT scores between original and counterfactual data indicates bias is not being mitigated

- First 3 experiments:
  1. Train MBCDA on Bias-in-Bios dataset and compare perplexity to dictionary-based methods
  2. Evaluate gender transfer accuracy on Jigsaw dataset
  3. Measure extrinsic bias mitigation using TPRD and FPRD on both datasets

## Open Questions the Paper Calls Out
- The paper acknowledges it did not conduct an extensive investigation into the effect of hyperparameter choices on the model's performance, leaving uncertainty about optimal configurations.
- The evaluation focuses on binary gender mitigation, with the authors noting that non-binary cases represent an important direction for future work that was not addressed in this study.

## Limitations
- The model requires high-quality parallel data from dictionary-based CDA, making it dependent on the quality of baseline methods
- Performance on non-binary gender cases is untested, limiting applicability to more complex gender scenarios
- The approach requires significant computational resources due to the multiple pretrained models involved in the pipeline

## Confidence

**High Confidence**: The core methodology for combining dictionary-based CDA outputs with bi-objective training is well-specified and reproducible, with clear improvements in fluency and gender transfer accuracy.

**Medium Confidence**: Claims about bias mitigation are supported by results but require further validation across different datasets and hyperparameter settings to establish robustness.

**Low Confidence**: Qualitative claims about the model's ability to handle complex gender associations are based on limited examples and would benefit from more extensive human evaluation.

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Replicate experiments across different threshold values for erratic token detection and learning rates to establish the robustness of reported improvements.

2. **Human Evaluation Study**: Conduct systematic human evaluation comparing grammaticality, semantic preservation, and naturalness of counterfactuals generated by MBCDA versus dictionary-based methods.

3. **Generalization Benchmark**: Test the model's ability to handle gender associations outside predefined dictionaries by creating a test set with unseen gender terms and occupations.