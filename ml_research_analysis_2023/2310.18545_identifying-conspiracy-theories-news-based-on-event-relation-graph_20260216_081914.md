---
ver: rpa2
title: Identifying Conspiracy Theories News based on Event Relation Graph
arxiv_id: '2310.18545'
source_url: https://arxiv.org/abs/2310.18545
tags:
- event
- conspiracy
- relation
- graph
- relations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first computational model for detecting
  conspiracy theories in long news documents. The key insight is that conspiracy theories
  can be fabricated by mixing uncorrelated events together or presenting an unusual
  distribution of relations between events.
---

# Identifying Conspiracy Theories News based on Event Relation Graph

## Quick Facts
- **arXiv ID**: 2310.18545
- **Source URL**: https://arxiv.org/abs/2310.18545
- **Reference count**: 24
- **Key outcome**: First computational model for detecting conspiracy theories in long news documents using event relation graphs; improves precision and recall over baselines.

## Executive Summary
This paper introduces a novel approach to detect conspiracy theories in long news articles by constructing event relation graphs that capture how events are linked (coreference, temporal, causal, subevent). The core hypothesis is that conspiracy narratives are characterized by unusual distributions of event relations—either mixing uncorrelated events or fabricating implausible linkages. By integrating event-aware language models (via soft labels) with graph neural networks (via hard labels), the method significantly outperforms standard baselines and generalizes better to unseen media sources.

## Method Summary
The method first identifies events in news articles using Longformer, then extracts four types of relations between events (coreference, temporal, causal, subevent) using joint learning. These relations form an event relation graph, which is encoded into the model in two ways: soft labels are used to train an event-aware language model, while hard labels train a heterogeneous graph attention network. The final conspiracy theory classification combines both representations. The model is trained and evaluated on the LOCO dataset, with a media-source-aware split to prevent overfitting to stylistic cues.

## Key Results
- Event relation graph approach improves F1 score over strong BERT and Longformer baselines.
- Media-source splitting yields more realistic performance estimates than random splitting.
- The model generalizes well to unseen media sources, indicating robustness to source-specific stylistic cues.

## Why This Works (Mechanism)

### Mechanism 1
Conspiracy theories are detected by modeling event-level discourse structures through an event relation graph. The model identifies events and extracts four relation types, capturing the logical flow and narrative structure that differs systematically between conspiracy and benign articles. If event extraction fails or relation classification is noisy, the graph will not encode distinguishing patterns.

### Mechanism 2
Two complementary training signals—soft labels from predicted probabilities and hard labels from argmaxed predictions—allow the model to learn both confidence-weighted and discrete structural patterns. Soft labels train an event-aware language model; hard labels train a heterogeneous graph attention network. If the signals are highly correlated or one dominates, the complementary benefit may be lost.

### Mechanism 3
Random splitting inflates performance by allowing the model to learn media-source-specific cues; media-source splitting forces generalization to unseen sources. If content-level conspiracy signals are weak or highly source-dependent, even media-source splitting will not yield high performance.

## Foundational Learning

- **Event identification in text**: Detecting which tokens trigger events is the first step in constructing the event relation graph. *Quick check*: If an event is mis-tagged as non-event, what downstream relation types are lost?
- **Coreference resolution**: Coreference links allow consolidation of multiple mentions of the same event into a single node, simplifying the graph. *Quick check*: How does merging coreferent events affect the density of temporal and causal edges?
- **Temporal, causal, and subevent relation extraction**: These relations encode the logical structure of the narrative; their distribution is a key discriminator between conspiracy and benign articles. *Quick check*: What happens to classification if causal relations are over-predicted due to temporal ambiguity?

## Architecture Onboarding

- **Component map**: Event identifier (BERT/Longformer + classifier) → Four relation extractors (coreference, temporal, causal, subevent) → Event-aware language model (LSTM + soft-label losses) → Heterogeneous graph attention network (hard-label propagation) → Classification head (conspiracy vs benign)
- **Critical path**: Input → Event identification → Relation extraction → Soft-label LM training → Hard-label graph encoding → Feature fusion → Classification
- **Design tradeoffs**: Using Longformer for long documents vs. truncating; joint learning of all relation types vs. training separately; incorporating event-doc edges vs. pure event-event graphs
- **Failure signatures**: Low event recall → sparse graph → weak signal; high relation extraction noise → misleading edges → confused reasoning; overfitting to source style → poor generalization
- **First 3 experiments**: 1) Compare F1 on media-source split with and without event-aware LM component; 2) Ablation: Remove coreference relations and measure impact on recall; 3) Stress test: Evaluate on an unseen conspiracy source not in the original dataset

## Open Questions the Paper Calls Out

- **Open Question 1**: How can the event relation graph construction be improved to better extract implicit event relations, as seen in the example where the causal relation between COVID-19 pandemic and 5G technology was implied but not explicitly stated?
- **Open Question 2**: How can the performance of the conspiracy theory identification model be further improved beyond the current state-of-the-art results, especially in terms of recall as indicated by the gap between the full model and ChatGPT baseline?
- **Open Question 3**: How can the event relation graph method be adapted to handle conspiracy theories in other languages or domains beyond the English language and general-domain news articles used in the current study?

## Limitations

- Performance claims rest on a single dataset (LOCO) and custom split strategy; generalization to other corpora is unproven.
- Several implementation details (joint relation extraction architecture, exact hyperparameters) are omitted, making exact reproduction difficult.
- No direct ablation study quantifies the isolated impact of the heterogeneous graph attention network versus the event-aware language model.

## Confidence

- **High confidence**: Incorporating event-level relational structure improves over strong baselines; intuition about conspiracy narratives is compelling.
- **Medium confidence**: Media-source splitting is methodologically sound, but external validation is lacking.
- **Low confidence**: Attributing performance gains to specific components is speculative due to missing ablations.

## Next Checks

1. **Dataset diversity check**: Evaluate the model on a conspiracy detection dataset from a different domain (e.g., social media misinformation) to test generalization beyond news articles.
2. **Component ablation study**: Systematically remove the event-aware language model, the heterogeneous graph attention network, or both, and report F1 to quantify each component's marginal contribution.
3. **Relation quality analysis**: Measure precision and recall of the four relation extraction types on a held-out subset to determine if noisy relations are degrading the graph's utility.