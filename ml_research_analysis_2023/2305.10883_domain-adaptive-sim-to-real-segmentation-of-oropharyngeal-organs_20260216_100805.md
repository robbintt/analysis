---
ver: rpa2
title: Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs
arxiv_id: '2305.10883'
source_url: https://arxiv.org/abs/2305.10883
tags:
- domain
- segmentation
- images
- training
- sim-to-real
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of semantic segmentation of
  oropharyngeal organs for video-assisted transoral tracheal intubation using robotic
  systems. The main problem is the limited availability of real endoscopic datasets
  due to privacy concerns, making supervised deep learning difficult.
---

# Domain Adaptive Sim-to-Real Segmentation of Oropharyngeal Organs

## Quick Facts
- arXiv ID: 2305.10883
- Source URL: https://arxiv.org/abs/2305.10883
- Reference count: 40
- Key outcome: IRB-AF improves segmentation accuracy and training stability, with mIoU increasing by 4.96%–9.85% and mAcc by 3.62%–7.13% compared to original settings.

## Executive Summary
This paper addresses the challenge of semantic segmentation of oropharyngeal organs for video-assisted transoral tracheal intubation using robotic systems. The main problem is the limited availability of real endoscopic datasets due to privacy concerns, making supervised deep learning difficult. The authors propose a domain adaptive Sim-to-Real framework called IoU-Ranking Blend-ArtFlow (IRB-AF), which combines two techniques: IoU-Ranking Blend (IRB) and ArtFlow. IRB is an image blending strategy that mixes a small batch of real images into the simulation domain based on segmentation performance, while ArtFlow is a style-transfer method that reduces the domain gap between virtual and real images. The framework is evaluated on state-of-the-art domain adaptive segmentation models using a virtual dataset generated by the SOFA framework and real images from a phantom. Results show that IRB-AF improves segmentation accuracy and training stability, with mIoU increasing by 4.96%–9.85% and mean Accuracy (mAcc) by 3.62%–7.13% compared to original settings. The authors also publish an open-source dataset of endoscopic images generated from the SOFA-based oropharynx model with style transfer from the phantom (EISOST).

## Method Summary
The IRB-AF framework combines IoU-Ranking Blend (IRB) and ArtFlow style transfer to address domain adaptation for oropharyngeal organ segmentation. IRB blends a small batch of real images into the virtual training set based on per-class IoU performance, while ArtFlow uses a reversible neural flow network to transfer style from real to virtual images. The method is evaluated on DeepLabV2 with ResNet101 backbone using a virtual dataset generated by SOFA and real phantom images. The dataset is published as EISOST, containing three parts: synthetic images, real phantom images, and style-transferred virtual images.

## Key Results
- IRB-AF improves segmentation accuracy and training stability compared to original settings
- mIoU increases by 4.96%–9.85% and mAcc by 3.62%–7.13% on real test images
- Performance improvement is limited when blending quantity exceeds 40 images (3% of training set)
- Style transfer enhances training stability but has limited impact on mIoU improvement

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IoU-Ranking Blend (IRB) improves segmentation by blending a small set of real images into the training domain based on per-class IoU performance.
- Mechanism: During training, the model is evaluated on held-out target-domain images, IoU is computed per class, classes are ranked by performance, and the blending proportion is adjusted so that lower-performing classes receive more real-image blending.
- Core assumption: Blending real images into the simulation domain improves the domain gap for low-performing classes more than it degrades high-performing ones.
- Evidence anchors:
  - [abstract] "IRB is an image blending strategy that mixes a small batch of real images into the simulation domain based on segmentation performance"
  - [section] "The IoU-Ranking Blend method mixes images based on each class’s segmentation testing results after training the model"
  - [corpus] Weak: no similar blending strategies found in related papers
- Break condition: If blending ratio becomes too large (e.g., > 10%), it may introduce noise and degrade training stability, as noted in the paper's ablation section.

### Mechanism 2
- Claim: ArtFlow style transfer reduces domain gap by converting source-domain images to target-domain appearance while preserving content.
- Mechanism: ArtFlow uses a reversible neural flow network (projection-flow network) to transfer style from real images to virtual images without losing anatomical features.
- Core assumption: Style differences between domains are low-level visual features (color, texture, reflection) that can be aligned without affecting semantic content.
- Evidence anchors:
  - [abstract] "ArtFlow is a style-transfer method that reduces the domain gap between virtual and real images"
  - [section] "ArtFlow establishes the Projection Flow Network (PFN) following the Glow model and replaces the traditional encoder-decoder structure with a projection-reversion strategy"
  - [corpus] Weak: no direct matches found; ArtFlow is cited as a novel contribution
- Break condition: If the style transfer is too aggressive, it may distort anatomical boundaries and harm segmentation accuracy.

### Mechanism 3
- Claim: IRB-AF's two-stage pipeline (style transfer → IRB blending) jointly improves segmentation accuracy and training stability.
- Mechanism: First, ArtFlow aligns image style; then, IRB adjusts content mixing based on class-wise IoU ranking. This combination addresses both low-level appearance and high-level content gaps.
- Core assumption: Sequential application of style transfer and content blending is more effective than either alone.
- Evidence anchors:
  - [abstract] "IRB-AF combines these two methods by first modifying the style of the source domain images and then blending target domain images via IRB"
  - [section] "Therefore, our dataset contains three parts, i.e., endoscopic images generated from SOFA-based oropharynx model, endoscopic images captured from real-world phantom, and style-transferred virtual images"
  - [corpus] Weak: no similar two-stage pipelines found in related work
- Break condition: If either stage fails (e.g., style transfer produces unrealistic images or IRB overfits to blended images), the overall performance will degrade.

## Foundational Learning

- Concept: Domain adaptation in semantic segmentation
  - Why needed here: The paper deals with transferring segmentation knowledge from synthetic (SOFA) to real (phantom) oropharyngeal images.
  - Quick check question: What is the main challenge when training a segmentation model on synthetic images and testing on real images?

- Concept: Intersection over Union (IoU) as a segmentation metric
  - Why needed here: IoU is used to rank classes and decide blending proportions in IRB.
  - Quick check question: How is IoU computed between a predicted segmentation mask and the ground truth?

- Concept: Style transfer and its role in domain adaptation
  - Why needed here: ArtFlow is used to reduce visual discrepancies between domains by transferring real image styles to synthetic ones.
  - Quick check question: What is the difference between content loss and style loss in neural style transfer?

## Architecture Onboarding

- Component map: SOFA virtual images -> ArtFlow style transfer -> IRB blending -> DeepLabV2+ResNet101 segmentation -> real test images
- Critical path:
  1. Generate synthetic dataset with SOFA
  2. Capture real dataset from phantom
  3. Apply ArtFlow to style-transfer synthetic images
  4. Train segmentation model with IRB-adjusted blended dataset
  5. Evaluate on held-out real images
- Design tradeoffs:
  - Blending quantity vs. training stability (more blending → more domain alignment but potential overfitting)
  - Style transfer strength vs. content preservation (stronger style → better appearance match but risk of anatomical distortion)
  - Model complexity vs. inference speed (DeepLabV2 + ResNet101 is accurate but heavy)
- Failure signatures:
  - Sudden drop in mIoU during training → likely overfitting to blended images
  - Low mIoU on specific classes → IRB blending ratio may be insufficient for those classes
  - Style-transferred images look unrealistic → ArtFlow parameters may be too aggressive
- First 3 experiments:
  1. Train baseline DeepLabV2 on only synthetic images; evaluate on real images to measure initial domain gap
  2. Apply ArtFlow to synthetic images; retrain and evaluate to measure style transfer impact
  3. Apply IRB with fixed blending ratio; retrain and evaluate to measure IRB impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of IRB-AF scale with the number of real images blended into the training set, and is there an optimal ratio beyond which additional real images provide diminishing returns?
- Basis in paper: [explicit] The paper states that "the improvement would be significantly weakened when the blending quantity exceeds 40" and that "a blend of 40 images accounts for only 3% of the training set."
- Why unresolved: The paper does not explore the performance impact of blending more than 40 real images or investigate the optimal ratio in detail.
- What evidence would resolve it: Conducting experiments with varying numbers of blended real images (e.g., 10, 20, 40, 60, 80) and analyzing the corresponding segmentation performance metrics (mIoU, mAcc) to identify the point of diminishing returns.

### Open Question 2
- Question: How does the IRB-AF framework perform on different types of medical image segmentation tasks beyond oropharyngeal organs, such as abdominal or cardiac imaging?
- Basis in paper: [inferred] The paper demonstrates IRB-AF's effectiveness on oropharyngeal organ segmentation but does not test its generalizability to other anatomical regions or imaging modalities.
- Why unresolved: The paper focuses specifically on oropharyngeal organs and does not provide evidence of the framework's applicability to other medical imaging tasks.
- What evidence would resolve it: Applying IRB-AF to other medical image segmentation datasets (e.g., abdominal CT, cardiac MRI) and comparing its performance to state-of-the-art domain adaptation methods for those specific tasks.

### Open Question 3
- Question: What is the impact of different style-transfer methods on the performance and stability of the IRB-AF framework, and could alternative methods like CycleGAN or CUT provide better results?
- Basis in paper: [explicit] The paper employs ArtFlow for style transfer and mentions that "the improvement of style-transfer on mIoU is limited" but it "can enhance the stability of semi-supervised domain adaptive segmentation training."
- Why unresolved: The paper does not compare ArtFlow with other style-transfer methods to determine if alternative approaches could yield better segmentation accuracy or stability.
- What evidence would resolve it: Implementing and evaluating other style-transfer methods (e.g., CycleGAN, CUT) within the IRB-AF framework and comparing their segmentation performance and training stability metrics against ArtFlow.

## Limitations
- The paper lacks detailed implementation information for the SOFA-based oropharynx model and ArtFlow configuration, making exact reproduction difficult
- Evaluation is limited to phantom images rather than real clinical data, which may not fully represent the domain gap in practice
- The ablation studies do not provide comprehensive analysis of IRB's class-wise impact or ArtFlow's content preservation

## Confidence
- **High**: IRB's effectiveness in improving mIoU and mAcc through class-wise blending
- **Medium**: ArtFlow's role in reducing domain gap via style transfer
- **Low**: Exact implementation details of SOFA model and ArtFlow configuration

## Next Checks
1. Conduct class-wise ablation to quantify IRB's impact on individual organ segmentation performance
2. Perform visual inspection of ArtFlow outputs to assess anatomical feature preservation
3. Test IRB-AF on a small real clinical dataset (if available) to validate phantom-based results