---
ver: rpa2
title: Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class
  Abstention
arxiv_id: '2310.14770'
source_url: https://arxiv.org/abs/2310.14770
tags:
- loss
- abstention
- alt1
- surrogate
- alt4
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents new theoretical and algorithmic results for
  multi-class classification with abstention in the score-based formulation. It derives
  cross-entropy score-based surrogate losses from first principles and proves non-asymptotic
  H-consistency bounds for these losses, which upper-bound the estimation error of
  the abstention loss in terms of the estimation error of the surrogate loss.
---

# Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention

## Quick Facts
- arXiv ID: 2310.14770
- Source URL: https://arxiv.org/abs/2310.14770
- Authors: 
- Reference count: 40
- Key outcome: This paper presents new theoretical and algorithmic results for multi-class classification with abstention in the score-based formulation. It derives cross-entropy score-based surrogate losses from first principles and proves non-asymptotic H-consistency bounds for these losses, which upper-bound the estimation error of the abstention loss in terms of the estimation error of the surrogate loss. The paper also introduces a novel family of surrogate loss functions in the two-stage setting and proves their strong H-consistency bounds guarantees. Additionally, it shows that the proposed two-stage score-based surrogate loss is realizable H-consistent, effectively addressing an open question in the context of score-based multi-class abstention. Extensive experiments demonstrate the practical significance of the new surrogate losses and the varying relative performance of the state-of-the-art cross-entropy score-based surrogate losses across datasets.

## Executive Summary
This paper introduces theoretically grounded surrogate loss functions for multi-class classification with abstention in the score-based formulation. The authors derive cross-entropy score-based surrogate losses from first principles and prove non-asymptotic H-consistency bounds that relate the estimation error of the abstention loss to the estimation error of the surrogate loss. They also introduce a novel family of surrogate loss functions in the two-stage setting and prove their strong H-consistency bounds guarantees. The paper addresses the open question of achieving both Bayes-consistency and realizable H-consistency by showing that the proposed two-stage score-based surrogate loss is realizable H-consistent.

## Method Summary
The paper proposes a two-stage algorithmic scheme for multi-class classification with abstention. In the first stage, a predictor is learned by minimizing a standard classification loss. In the second stage, an abstention function is learned that defers based on the predictor's confidence, with a loss that vanishes when the first-stage error vanishes. The method is implemented using ResNet and WideResNet architectures with cross-entropy and exponential loss functions, trained on CIFAR-10, CIFAR-100, and SVHN datasets using SGD with cosine decay.

## Key Results
- The cross-entropy score-based surrogate loss is derived from the abstention loss by decomposing the 0-1 loss into a sum of classification error and abstention cost.
- H-consistency bounds provide stronger guarantees than Bayes-consistency by being non-asymptotic and hypothesis set-specific, relating the abstention loss estimation error to the surrogate loss estimation error.
- The two-stage surrogate losses are realizable H-consistent, addressing the open question of achieving both Bayes-consistency and realizable H-consistency.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The cross-entropy score-based surrogate loss can be derived from the abstention loss by decomposing the 0-1 loss into a sum of classification error and abstention cost.
- Mechanism: The abstention loss is rewritten as $1_{h(x)\neq y} + (1-c)1_{h(x)\neq n+1} + c - 1$. Since the last term is constant, any surrogate loss $\ell$ for the 0-1 multi-class loss yields a surrogate $L(h,x,y) = \ell(h,x,y) + (1-c)\ell(h,x,n+1)$ for the abstention loss.
- Core assumption: The abstention loss has the stated additive form and the constant term does not affect minimization.
- Evidence anchors:
  - [abstract] "We introduce new families of surrogate losses for the abstention loss function, which include the state-of-the-art surrogate losses in the single-stage setting..."
  - [section 3.1] Derivation showing $Labs(h,x,y) = 1_{h(x)\neq y} + (1-c)1_{h(x)\neq n+1} + c - 1$
- Break condition: If the abstention loss cannot be decomposed into classification and abstention terms, or if the constant term affects optimization dynamics.

### Mechanism 2
- Claim: H-consistency bounds provide stronger guarantees than Bayes-consistency by being non-asymptotic and hypothesis set-specific.
- Mechanism: The bounds upper-bound the abstention loss estimation error by a concave function of the surrogate loss estimation error, scaled by a calibration gap that depends on the hypothesis set.
- Core assumption: There exists a concave function relating the calibration gaps of the abstention loss and surrogate loss.
- Evidence anchors:
  - [abstract] "We prove strong non-asymptotic and hypothesis set-specific consistency guarantees..."
  - [section 3.2] Theorem 1 showing $ELabs(h) - E^*_{Labs}(H) + MLabs(H) \leq \Gamma_\mu(EL_\mu(h) - E^*_{L_\mu}(H) + ML_\mu(H))$
- Break condition: If the calibration gap cannot be bounded by a concave function, or if the hypothesis set is too restrictive.

### Mechanism 3
- Claim: Two-stage surrogate losses are realizable H-consistent, addressing the open question of achieving both Bayes-consistency and realizable H-consistency.
- Mechanism: The first stage learns a predictor minimizing standard classification loss; the second stage learns an abstention function that defers based on the predictor's confidence, with loss that vanishes when the first-stage error vanishes.
- Core assumption: The hypothesis set is closed under scaling and the second-stage loss satisfies $\lim_{t\to\infty}\Phi(t)=0$ and $\Phi(t)\geq 1_{t\leq 0}$.
- Evidence anchors:
  - [abstract] "Realizable H-consistency guarantees of proposed two-stage score-based surrogate loss..."
  - [section 5] Theorem 8 proving realizable H-consistency under the stated assumptions
- Break condition: If the hypothesis set is not closed under scaling, or if the second-stage loss does not satisfy the limiting conditions.

## Foundational Learning

- Concept: Calibration gap
  - Why needed here: The calibration gap measures the difference between the expected loss of a hypothesis and the minimal possible loss over the hypothesis set, crucial for deriving H-consistency bounds.
  - Quick check question: If the hypothesis set contains the Bayes classifier, what happens to the calibration gap for the abstention loss?

- Concept: Minimizability gap
  - Why needed here: The minimizability gap is the difference between the best-in-class expected loss and the expected pointwise infimum of the loss, appearing in H-consistency bounds and distinguishing them from approximation error bounds.
  - Quick check question: How does the minimizability gap differ from the approximation error, and why is it generally a finer quantity?

- Concept: Symmetric and complete hypothesis sets
  - Why needed here: These properties ensure that the score functions do not depend on label ordering and span the full range of possible scores, enabling the derivation of strong H-consistency bounds.
  - Quick check question: What would happen to the H-consistency bounds if the hypothesis set were not symmetric or complete?

## Architecture Onboarding

- Component map: Input preprocessing -> ResNet/WRN backbone -> Score generation (n+1 outputs) -> Loss computation (cross-entropy or two-stage) -> Optimization (SGD with cosine decay)
- Critical path: Forward pass through network -> Compute score-based loss (either single-stage or two-stage) -> Backpropagation -> Parameter update -> Validation on abstention loss
- Design tradeoffs:
  - Single-stage vs two-stage: Single-stage learns both prediction and abstention jointly; two-stage separates concerns but may require more training steps
  - Choice of $\mu$ in cross-entropy: Affects the trade-off between estimation error and minimizability gap; $\mu=1$ (logistic) vs $\mu=1.7$ (generalized cross-entropy) shows dataset-dependent performance
- Failure signatures:
  - High abstention loss despite low surrogate loss: Minimizability gap is large; hypothesis set may be too restrictive
  - No abstention when expected: Cost $c$ too low; model never finds it worthwhile to abstain
  - High variance in results: Insufficient training epochs or poor hyperparameter tuning
- First 3 experiments:
  1. Train with $\mu=1$ cross-entropy surrogate on CIFAR-10; measure abstention loss and compare to baseline
  2. Implement two-stage loss; train first stage with logistic loss, second with exponential loss; compare performance to single-stage
  3. Sweep $\mu$ values (0.5, 1, 1.5, 2) on CIFAR-100; analyze trade-off between estimation error and minimizability gap

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the two-stage score-based abstention surrogate loss compare to the state-of-the-art cross-entropy score-based surrogate losses across different datasets?
- Basis in paper: The paper reports that the two-stage score-based surrogate loss outperforms the cross-entropy score-based surrogate losses on CIFAR-10, CIFAR-100, and SVHN datasets.
- Why unresolved: The paper provides empirical results for a limited number of datasets, and it is unclear how the performance would generalize to other datasets.
- What evidence would resolve it: Further experiments on a wider range of datasets, including those with different characteristics, would provide a more comprehensive comparison of the two-stage and cross-entropy score-based surrogate losses.

### Open Question 2
- Question: What is the optimal value of the parameter μ for the cross-entropy score-based surrogate loss function, and how does it affect the performance of the algorithm?
- Basis in paper: The paper mentions that the relative performance of the cross-entropy surrogate loss with different values of μ varies across datasets.
- Why unresolved: The paper does not provide a definitive answer on how to select the optimal value of μ, and it is unclear how the choice of μ affects the performance of the algorithm.
- What evidence would resolve it: Further theoretical analysis and empirical experiments to determine the optimal value of μ for different datasets and problem settings would help address this question.

### Open Question 3
- Question: How do the H-consistency bounds for the cross-entropy score-based surrogate losses compare to the excess error bounds in terms of their practical significance and applicability?
- Basis in paper: The paper argues that the H-consistency bounds are stronger guarantees than the excess error bounds, as they are non-asymptotic and hypothesis set-specific.
- Why unresolved: The paper does not provide a direct comparison of the two types of bounds in terms of their practical implications and the conditions under which each type of bound is more useful.
- What evidence would resolve it: Further theoretical analysis and empirical experiments to compare the practical significance and applicability of the H-consistency bounds and excess error bounds would help address this question.

## Limitations

- The theoretical framework relies heavily on the assumption that the hypothesis set is symmetric and complete, which may not hold for practical deep neural network architectures.
- The experiments focus on standard image classification datasets (CIFAR-10, CIFAR-100, SVHN) with relatively moderate class counts, and the performance may not generalize to extreme-scale problems or non-image domains.
- The comparative performance claims across different datasets and surrogate loss variants show strong empirical results but lack comprehensive statistical significance testing.

## Confidence

- High Confidence: The derivation of cross-entropy score-based surrogate losses from first principles is mathematically sound and the non-asymptotic H-consistency bounds are rigorously proven under the stated assumptions.
- Medium Confidence: The realizable H-consistency of the two-stage approach holds under the specific assumptions about hypothesis set properties and loss function characteristics.
- Low Confidence: The comparative performance claims across different datasets and surrogate loss variants show strong empirical results but lack comprehensive statistical significance testing.

## Next Checks

1. Conduct experiments to empirically measure the calibration gap for different hypothesis sets (varying network depths, widths, and architectures) to validate the theoretical assumptions about symmetry and completeness.
2. Test the proposed methods on extreme-scale multi-class problems (e.g., ImageNet-1K or larger taxonomies) to verify whether the theoretical guarantees and empirical performance scale as expected.
3. Apply the framework to non-image domains such as natural language processing or tabular data to assess the generality of the approach beyond the tested image classification scenarios.