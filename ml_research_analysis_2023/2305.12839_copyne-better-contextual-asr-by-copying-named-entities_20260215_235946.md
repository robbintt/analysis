---
ver: rpa2
title: 'CopyNE: Better Contextual ASR by Copying Named Entities'
arxiv_id: '2305.12839'
source_url: https://arxiv.org/abs/2305.12839
tags:
- entities
- dictionary
- copy
- entity
- copyne
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of accurately transcribing named
  entities in contextual automatic speech recognition (ASR). The authors propose CopyNE,
  a novel approach that uses a span-level copying mechanism to directly copy entire
  entities from a contextual entity dictionary, thereby reducing errors caused by
  homophonic or near-homophonic tokens.
---

# CopyNE: Better Contextual ASR by Copying Named Entities

## Quick Facts
- arXiv ID: 2305.12839
- Source URL: https://arxiv.org/abs/2305.12839
- Reference count: 21
- This paper addresses the challenge of accurately transcribing named entities in contextual automatic speech recognition (ASR).

## Executive Summary
This paper introduces CopyNE, a novel approach to improve contextual automatic speech recognition by directly copying named entities from a contextual dictionary rather than predicting them token-by-token. The method addresses homophonic errors that commonly occur when predicting named entities separately. CopyNE uses a span-level copying mechanism combined with a confidence threshold to filter low-confidence copies. Experiments on Aishell and ST-cmds datasets show significant improvements in both overall character error rate and named entity error rate compared to baseline approaches, including the strong Whisper model.

## Method Summary
CopyNE is a span-level copying mechanism for contextual ASR that directly copies entire named entities from a contextual entity dictionary. The model uses a CTC-Transformer architecture with an additional named entity (NE) encoder and a copy loss component. During training, a copy loss guides the model to select appropriate entities from the dictionary for copying, while negative examples help the model discriminate between correct and incorrect entities. During inference, a confidence threshold filters out low-confidence entity copies, falling back to token-level prediction when the threshold is not met.

## Key Results
- CopyNE significantly reduces both overall CER and named entity CER (NE-CER) on Aishell and ST-cmds datasets
- Outperforms baseline models including CTC-Transformer, CLAS, CBA, and the strong Whisper baseline
- The span-level copying mechanism effectively avoids homophonic and near-homophonic errors in named entity transcription

## Why This Works (Mechanism)

### Mechanism 1
CopyNE reduces homophonic errors by copying entire entities rather than predicting tokens individually. The span-level copying mechanism directly copies all tokens of an entity from the contextual entity dictionary at once, avoiding the need to predict each token separately. This works because named entities are more accurately transcribed when copied as a whole rather than generated token-by-token.

### Mechanism 2
The copy loss trains the model to select correct entities from the dictionary for copying. During training, a copy loss guides the model to select the appropriate entity from the contextual entity dictionary for copying based on left-to-right maximum matching of the transcription text. This works by incorporating negative examples during dictionary construction to help the model discriminate between correct and incorrect entities.

### Mechanism 3
The confidence threshold improves copying quality by preventing low-confidence entity copies. During inference, a confidence threshold γ is applied to the copy probabilities. If the maximum copy probability over entities is below γ, the model is prevented from copying and instead generates tokens from the vocabulary. This works because low-confidence entity copies are more likely to be incorrect, and preventing them improves overall transcription quality.

## Foundational Learning

- **Connectionist Temporal Classification (CTC)**: Provides alignment between acoustic frames and output tokens, helping the audio encoder learn better representations and improving stability in noisy environments.
  - Quick check question: What is the main advantage of using CTC loss in end-to-end ASR models compared to attention-only approaches?

- **Transformer architecture**: Provides the attention mechanisms needed for both token prediction and copying operations, while maintaining parallel computation benefits.
  - Quick check question: How does the multi-head attention in the transformer decoder help the model attend to both previous tokens and the dictionary representation simultaneously?

- **Beam search decoding**: Used during inference to select the best sequence of tokens or entities by maintaining multiple hypotheses and expanding them based on probability scores.
  - Quick check question: In the context of CopyNE, what are the two types of elements that can be selected at each decoding step during beam search?

## Architecture Onboarding

- **Component map**: Audio features → Audio Encoder → Decoder (with dictionary attention) → Token/Entity Prediction → Copy Loss Training → Confidence Threshold Filtering → Final Output

- **Critical path**: The model processes acoustic features through a transformer encoder, then uses a decoder with dictionary attention to either predict tokens or copy entities based on copy probabilities and confidence thresholds.

- **Design tradeoffs**: 
  - Span-level copying vs. token-level prediction: Copying entire entities reduces homophone errors but requires entities to be in the dictionary
  - Dictionary size vs. computational cost: Larger dictionaries provide more coverage but increase computation during each batch
  - Confidence threshold value: Higher thresholds improve copy quality but reduce copy frequency, lower thresholds increase copying but may introduce errors

- **Failure signatures**:
  - High NE-CER but low CER: Model is copying incorrect entities or failing to copy correct ones
  - Low performance on entities not in dictionary: Dictionary coverage is insufficient for the test domain
  - Degraded performance when γ is too high: Model rarely copies even when appropriate, reverting to error-prone token prediction

- **First 3 experiments**:
  1. Ablation study: Remove the copy mechanism entirely and compare CER/NE-CER with full CopyNE to quantify the benefit of span-level copying
  2. Dictionary size sweep: Vary the dictionary size (β parameter) to find the optimal tradeoff between coverage and computational cost
  3. Confidence threshold tuning: Test different γ values on the dev set to find the optimal balance between copy frequency and copy quality

## Open Questions the Paper Calls Out

- **Open Question 1**: How does the performance of CopyNE compare to other approaches that utilize both text and speech modalities, such as LM-fusion and joint pre-training?
  - Basis: The paper mentions LM-fusion and joint pre-training as alternative approaches but does not directly compare CopyNE's performance to these methods.
  - Why unresolved: The paper focuses on comparing CopyNE to other contextual ASR approaches and does not include experiments comparing it to LM-fusion or joint pre-training.
  - What evidence would resolve it: Experimental results showing CopyNE compared to LM-fusion and joint pre-training approaches on the same datasets.

- **Open Question 2**: What is the impact of the confidence threshold (γ) on the overall performance of CopyNE, and how does it affect the trade-off between copying entities and predicting tokens from the vocabulary?
  - Basis: The paper discusses the influence of γ on the model's effectiveness and provides results for different γ values.
  - Why unresolved: While the paper shows γ has significant impact, it doesn't explore the optimal value or provide detailed analysis of how it affects the balance between copying and predicting.
  - What evidence would resolve it: A comprehensive study of different γ values on various metrics to determine the optimal γ and its impact on performance.

- **Open Question 3**: How does the size of the contextual entity dictionary affect the performance of CopyNE, and what is the optimal number of negative examples (β) to include during training?
  - Basis: The paper mentions using a smaller dictionary during training and incorporating negative examples to help discrimination.
  - Why unresolved: The paper doesn't provide in-depth analysis of how dictionary size or negative examples affect performance.
  - What evidence would resolve it: Experiments varying dictionary size and β while measuring impact on metrics like CER, NE-CER, and training stability.

## Limitations

- Dictionary coverage is a fundamental limitation - the model cannot copy entities that are not present in the dictionary
- Performance may degrade significantly if the confidence threshold is not properly tuned
- The approach is evaluated only on Mandarin datasets and may not generalize well to other languages or domains

## Confidence

**High Confidence Claims:**
- CopyNE significantly reduces NE-CER compared to baseline models on Aishell and ST-cmds datasets
- Span-level copying is more effective than token-level prediction for named entity transcription
- The copy loss effectively guides entity selection during training

**Medium Confidence Claims:**
- Confidence thresholding improves copying quality by filtering low-confidence predictions
- CopyNE outperforms Whisper on NE-CER despite Whisper's strong overall performance
- Dictionary-based contextual biasing is more effective than phoneme-based approaches for named entities

**Low Confidence Claims:**
- CopyNE would maintain similar relative improvements on datasets with different entity distributions
- The computational overhead of dictionary attention is negligible compared to performance gains
- The model's performance scales linearly with dictionary size improvements

## Next Checks

1. **Dictionary Coverage Analysis**: Systematically evaluate how model performance scales with dictionary coverage by artificially limiting dictionary size and measuring the correlation between coverage percentage and NE-CER improvement.

2. **Cross-Domain Generalization Test**: Evaluate CopyNE on a different domain (e.g., medical transcription or conversational English speech) to assess whether the span-level copying advantage transfers to datasets with different entity characteristics.

3. **Ablation Study on Negative Sampling**: Conduct controlled experiments varying the negative sampling strategy during dictionary construction to determine how this critical component affects the model's ability to discriminate between correct and incorrect entities.