---
ver: rpa2
title: 'ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal,
  and Discourse Relations'
arxiv_id: '2304.14827'
source_url: https://arxiv.org/abs/2304.14827
tags:
- uni00000048
- uni00000051
- uni00000044
- uni00000056
- discourse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study comprehensively evaluates ChatGPT\u2019s proficiency\
  \ in handling inter-sentential relations across 13 datasets, covering temporal,\
  \ causal, and discourse relations, as well as downstream applications of discourse\
  \ relations. Using three prompting strategies\u2014zero-shot prompt templates, zero-shot\
  \ prompt engineering, and in-context learning\u2014the study provides baseline scores\
  \ for widely-used sentence-pair relation classification tasks."
---

# ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations

## Quick Facts
- **arXiv ID**: 2304.14827
- **Source URL**: https://arxiv.org/abs/2304.14827
- **Reference count**: 40
- **Primary result**: ChatGPT excels at causal reasoning but struggles with implicit discourse relations and temporal order extraction.

## Executive Summary
This study comprehensively evaluates ChatGPT's performance on sentence-level relation classification tasks across 13 datasets, covering temporal, causal, and discourse relations as well as downstream applications. Using three prompting strategies—zero-shot templates, zero-shot engineering, and in-context learning—the research establishes baseline performance metrics without fine-tuning. ChatGPT demonstrates strong capabilities in causal reasoning, outperforming fine-tuned RoBERTa on two out of three benchmarks, but faces significant challenges with implicit discourse relations and temporal relation extraction, particularly in long-document contexts.

## Method Summary
The study evaluates ChatGPT (gpt-3.5-turbo) on 13 datasets spanning temporal, causal, and discourse relation tasks using three prompting strategies: zero-shot prompt templates, zero-shot prompt engineering, and in-context learning. The model is accessed via OpenAI API with temperature=0, and no fine-tuning is performed. Datasets include TB-Dense, MATRES, TDDMan for temporal relations; COPA, e-CARE, HeadlineCause for causal relations; PDTB2.0, DiscoGeM, STAC, Molweni for discourse relations; and CKBP v2, DiscoSense for downstream applications. Performance is measured using accuracy and F1 scores for classification tasks and AUC for CKBP v2.

## Key Results
- ChatGPT outperforms fine-tuned RoBERTa on causal reasoning tasks, particularly excelling on the COPA dataset.
- The model achieves strong performance on explicit discourse relations but struggles significantly with implicit discourse relations (24.54% accuracy on PDTB2.0).
- ChatGPT demonstrates poor performance on temporal relation extraction, especially for long-document and discourse-level relations in the TDDMan dataset.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** ChatGPT's ability to detect causal relations is strong due to its training on large corpora containing implicit and explicit causal markers.
- **Mechanism:** The model has learned to associate certain linguistic patterns (e.g., "because", "so") with causal reasoning, allowing it to identify plausible cause-effect pairs without fine-tuning.
- **Core assumption:** The training data includes sufficient examples of causal reasoning in varied contexts.
- **Evidence anchors:**
  - [abstract]: "ChatGPT exhibits strong performance in detecting and reasoning about causal relationships, particularly on the COPA dataset, outperforming fine-tuned RoBERTa on two out of three benchmarks."
  - [section 4]: "ChatGPT demonstrates exceptional performance on the COPA dataset and satisfactory performance on the other two datasets, outperforming fine-tuned RoBERTa on two out of three benchmarks."
  - [corpus]: Weak evidence; no direct citations provided about causal training data.
- **Break condition:** If causal reasoning requires deep world knowledge or counterfactual reasoning not present in the training corpus.

### Mechanism 2
- **Claim:** ChatGPT struggles with implicit discourse relations due to lack of explicit connectives.
- **Mechanism:** Without explicit markers, the model cannot rely on learned patterns and must infer abstract semantic relations, which is harder.
- **Core assumption:** Implicit relations depend more on context understanding than surface cues.
- **Evidence anchors:**
  - [abstract]: "ChatGPT can recognize most discourse relations with existing explicit discourse connectives, but the implicit discourse relation still remains a challenging task."
  - [section 5.1.2]: "ChatGPT's performance demonstrates that implicit discourse relation remains a challenging task for ChatGPT... This LLM cannot understand the abstract sense of each discourse relation and grasp the language features from the text."
  - [corpus]: Moderate evidence; references to PDTB and DiscoGeM datasets which include implicit relations.
- **Break condition:** If provided with explicit connective mapping or in-context examples showing relation patterns.

### Mechanism 3
- **Claim:** ChatGPT performs poorly on dialogue discourse parsing due to need for structural understanding across multiple utterances.
- **Mechanism:** The model lacks capability to track dialogue flow and speaker intentions across turns, leading to incorrect relation predictions.
- **Core assumption:** Multi-party dialogue requires maintaining conversational state and understanding speaker roles.
- **Evidence anchors:**
  - [abstract]: "ChatGPT performs poorly in the dialogue discourse parsing task that requires structural understanding in a dialogue before being aware of the discourse relation."
  - [section 5.3]: "ChatGPT significantly worse than the supervised baselines... It fails to give potential relations between utterances, indicating its poor understanding of the structure of multi-party dialogues."
  - [corpus]: Moderate evidence; references to STAC and Molweni dialogue datasets.
- **Break condition:** If provided with dialogue context summaries or speaker role annotations.

## Foundational Learning

- **Concept:** Temporal relation extraction
  - Why needed here: Understanding how ChatGPT identifies temporal order between events is crucial for evaluating its reasoning capabilities.
  - Quick check question: What are the main temporal relation classes used in TB-Dense dataset?

- **Concept:** Causal reasoning
  - Why needed here: Causal reasoning is central to many NLP tasks and understanding ChatGPT's ability here is key.
  - Quick check question: How does the COPA dataset evaluate causal reasoning?

- **Concept:** Discourse relation recognition
  - Why needed here: Discourse relations are fundamental for text coherence and understanding how ChatGPT handles them is important.
  - Quick check question: What is the difference between explicit and implicit discourse relations?

## Architecture Onboarding

- **Component map:**
  - Input preprocessing (task formatting) -> Prompt template application -> LLM inference -> Output parsing and evaluation

- **Critical path:**
  1. Input preprocessing (task formatting)
  2. Prompt template application
  3. LLM inference
  4. Output parsing and evaluation

- **Design tradeoffs:**
  - Zero-shot vs few-shot learning
  - Prompt complexity vs model performance
  - Evaluation metrics selection (F1 vs accuracy)

- **Failure signatures:**
  - Poor performance on implicit relations
  - Inability to handle long-dependency tasks
  - Inconsistent results across different prompt templates

- **First 3 experiments:**
  1. Test ChatGPT on a simple causal relation task with explicit connectives
  2. Evaluate performance on implicit discourse relations with and without connective mapping
  3. Assess dialogue discourse parsing with varying amounts of context provided

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can ChatGPT be effectively fine-tuned to improve performance on temporal relation extraction tasks, particularly for long-document and discourse-level temporal relations?
- Basis in paper: The paper shows ChatGPT's poor performance on temporal relation extraction tasks, especially on the TDDMan dataset which focuses on long-document and discourse-level temporal relations. The authors note that ChatGPT's performance did not improve through in-context learning and suggest inadequate human feedback during training as a potential cause.
- Why unresolved: The paper only evaluates ChatGPT's zero-shot and in-context learning capabilities without exploring fine-tuning approaches. The specific challenges ChatGPT faces with long-document temporal relations remain unexplored.
- What evidence would resolve it: Experiments comparing ChatGPT's performance before and after fine-tuning on temporal relation datasets, particularly focusing on long-document scenarios, would provide evidence of whether fine-tuning can address these limitations.

### Open Question 2
- Question: What specific prompting strategies or architectural modifications could improve ChatGPT's performance on implicit discourse relation recognition tasks?
- Basis in paper: The paper demonstrates that ChatGPT struggles significantly with implicit discourse relations, achieving only 24.54% accuracy on the PDTB2.0 dataset. The authors note that even with label dependence information and representative connectives in in-context learning settings, performance remains poor.
- Why unresolved: While the paper tests basic prompt engineering and in-context learning, it does not explore more sophisticated prompting techniques, alternative model architectures, or hybrid approaches that might better capture the abstract nature of implicit discourse relations.
- What evidence would resolve it: Comparative experiments testing various advanced prompting strategies (e.g., chain-of-thought prompting, few-shot exemplars with contrastive examples) and architectural modifications would reveal which approaches effectively improve implicit discourse relation recognition.

### Open Question 3
- Question: How does ChatGPT's performance on causal reasoning tasks compare to specialized causal reasoning models when dealing with complex, multi-step causal chains or counterfactual reasoning scenarios?
- Basis in paper: The paper shows ChatGPT excels at detecting and reasoning about simple causal relationships, outperforming fine-tuned RoBERTa on some benchmarks. However, the evaluation focuses on relatively straightforward causal scenarios rather than complex multi-step reasoning or counterfactuals.
- Why unresolved: The paper does not test ChatGPT's ability to handle more complex causal reasoning tasks that require tracking multiple causal relationships or reasoning about hypothetical scenarios. This leaves open the question of whether ChatGPT's strong performance extends to more sophisticated causal reasoning.
- What evidence would resolve it: Benchmarking ChatGPT against specialized causal reasoning models on datasets requiring multi-step causal chains or counterfactual reasoning would reveal its limitations and potential areas for improvement in causal reasoning capabilities.

## Limitations
- The study evaluates only one model version (gpt-3.5-turbo) without exploring hyperparameter variations or comparing against other LLMs.
- The zero-shot approach may not represent optimal performance achievable through fine-tuning or more sophisticated prompting strategies.
- Findings may not generalize to real-world applications or longer texts without further validation.

## Confidence
- **High confidence**: ChatGPT's superior performance on causal reasoning tasks (COPA dataset) and its consistent outperformance of fine-tuned RoBERTa on two benchmarks.
- **Medium confidence**: Performance on explicit discourse relations and temporal relations, though results rely on established metrics without deeper qualitative error analysis.
- **Low confidence**: Generalization of findings to other LLM variants or real-world applications, as the study doesn't explore scalability or domain adaptation.

## Next Checks
1. Test ChatGPT's performance on causal reasoning with counterfactual scenarios and world knowledge questions not present in the training data to verify the robustness of Mechanism 1.
2. Evaluate whether providing connective mapping tables or in-context examples improves performance on implicit discourse relations to validate the assumptions behind Mechanism 2.
3. Assess whether dialogue context summaries or speaker role annotations enable better discourse parsing performance in multi-party dialogues to test the limitations described in Mechanism 3.