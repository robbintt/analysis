---
ver: rpa2
title: Denoising Attention for Query-aware User Modeling in Personalized Search
arxiv_id: '2308.15968'
source_url: https://arxiv.org/abs/2308.15968
tags:
- user
- attention
- search
- information
- personalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses limitations of standard Attention mechanisms
  in query-aware user modeling for personalized search, specifically their tendency
  to skew user representations toward single documents and their inability to filter
  out irrelevant user data. The authors propose Denoising Attention, a variant that
  introduces a filtering mechanism based on Rectified Linear Unit and a threshold
  parameter, combined with a robust normalization scheme that departs from Softmax.
---

# Denoising Attention for Query-aware User Modeling in Personalized Search

## Quick Facts
- arXiv ID: 2308.15968
- Source URL: https://arxiv.org/abs/2308.15968
- Authors: 
- Reference count: 40
- Denoising Attention improves personalized search by 17-57% over baselines

## Executive Summary
This paper addresses limitations of standard Attention mechanisms in personalized search, specifically their tendency to skew user representations toward single documents and their inability to filter out irrelevant user data. The authors propose Denoising Attention, a variant that introduces a filtering mechanism based on Rectified Linear Unit and a threshold parameter, combined with a robust normalization scheme that departs from Softmax. This approach selectively filters noisy user-related information and allows zeroing out the user model when personalization is not beneficial.

## Method Summary
The authors propose Denoising Attention for query-aware user modeling in personalized search, which addresses limitations of standard Attention mechanisms. The method uses cosine similarity alignment scores shifted by a threshold parameter, applies ReLU filtering to remove negative values, and employs plain normalization instead of Softmax. This allows the model to selectively filter noisy user-related information and zero out the user model when personalization is not beneficial. The approach is evaluated on Web Search and Academic Search datasets using MAP@100, MRR@10, and NDCG@10 metrics.

## Key Results
- Denoising Attention outperforms standard Attention-based methods by 17-57% across all metrics
- The method significantly reduces harmful personalizations compared to baseline approaches
- Denoising Attention demonstrates superior robustness to noisy user data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Denoising Attention avoids over-concentration on single user documents by introducing a filtering step based on ReLU and a threshold.
- Mechanism: Before normalization, Denoising Attention shifts alignment scores by subtracting a threshold parameter and then applies ReLU to zero out negative values. This selectively filters out noisy or weakly related user documents, preventing them from influencing the user model.
- Core assumption: Cosine similarity alignment scores in [0,1] can be effectively shifted and filtered to preserve relevance while suppressing noise.
- Evidence anchors:
  - [abstract] "introduces a filtering mechanism based on the Rectifier Linear Unit and a threshold value"
  - [section 4] "We introduce a threshold parameter t that we use to negativize the alignment scores of the user data loosely related to the input query... we apply the Rectifier Linear Unit (ReLU) to the shifted alignment scores"
  - [corpus] Weak: related works do not mention ReLU-based filtering in attention variants.
- Break condition: If threshold tuning fails to distinguish relevant from noisy documents, or if ReLU kills too many useful signals, performance drops.

### Mechanism 2
- Claim: Denoising Attention departs from Softmax to avoid over-smoothing and over-concentration, using plain normalization instead.
- Mechanism: After filtering, Denoising Attention uses simple sum-based normalization (with a small epsilon for stability) instead of Softmax. This preserves the diversity of alignment scores and allows zero weights when all documents are irrelevant.
- Core assumption: Plain normalization maintains relative importance better than Softmax in personalization contexts.
- Evidence anchors:
  - [abstract] "depart from the Softmax function and opt for a more straightforward and robust weighting scheme"
  - [section 4] "Eq. 9 does not suffer from those issues and can produce zero attention weights"
  - [section 3.2] Detailed critique of Softmax causing over-concentration and over-smoothing in user modeling.
- Break condition: If alignment scores are too uniform or noisy, plain normalization could produce unstable or noisy attention weights.

### Mechanism 3
- Claim: Denoising Attention enables zeroing out the user model when no user information is relevant, avoiding harmful personalization.
- Mechanism: By allowing zero attention weights through ReLU filtering and plain normalization, the aggregated user model can become zero when all documents are filtered out, thus skipping personalization.
- Core assumption: Zero user model is better than injecting noise when user documents are unrelated to the query.
- Evidence anchors:
  - [abstract] "allows zeroing out the user model when personalization is not beneficial"
  - [section 4] "the aggregation step can yield a zero context vector, which ultimately allows avoiding personalization when no source of user information is related to her current search"
  - [section 3.2] Explains why Softmax cannot produce zero weights and thus cannot avoid personalization when irrelevant.
- Break condition: If ReLU threshold is set too high, useful documents may be filtered out unnecessarily, leading to missed personalization opportunities.

## Foundational Learning

- Concept: Attention Mechanism in Neural Networks
  - Why needed here: Core building block; understanding how attention weights are computed and used in user modeling.
  - Quick check question: What are the three steps of standard attention and what role does Softmax play?

- Concept: Cosine Similarity and Alignment Models
  - Why needed here: Denoising Attention uses cosine similarity as the base alignment model before filtering.
  - Quick check question: How does cosine similarity behave differently from dot-product when documents are dissimilar?

- Concept: ReLU Activation and Thresholding
  - Why needed here: Central to Denoising Attention's filtering mechanism.
  - Quick check question: What happens to negative values when passed through ReLU, and why is this useful for filtering?

## Architecture Onboarding

- Component map: Query → TinyBERT Encoder → Cosine Similarity → Threshold Shift → ReLU Filter → Plain Normalization → Weighted Aggregation → User Model → Cosine Similarity with Document → Personalized Score
- Critical path: TinyBERT embeddings → Denoising Attention weights → user model → re-ranking score. Failure in any step breaks personalization.
- Design tradeoffs: Denoising Attention trades simplicity for control (no learnable parameters in filtering vs. complex attention heads); may be less expressive than multi-head attention but more robust to noise.
- Failure signatures: Zero or uniform attention weights across all documents; over-aggressive filtering leading to zero user model; poor retrieval if threshold is poorly set.
- First 3 experiments:
  1. Run Denoising Attention with threshold=0 (no filtering) to confirm it behaves like plain normalized attention.
  2. Vary threshold from 0 to 1 in small steps and observe number of filtered documents and retrieval metrics.
  3. Compare Denoising Attention against standard attention with same TinyBERT embeddings on a small query subset to isolate effect of filtering.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the Denoising Attention mechanism perform when integrated into full Transformer architectures beyond simple re-ranking?
- Basis in paper: [inferred] The authors explicitly state they "leave experimentation and comparison with Transformer models for future work" and note their proposed attention variant "could also be used in place of the standard formulation in these complex architectures."
- Why unresolved: The current experiments use Denoising Attention only in a simplified re-ranking framework with TinyBERT embeddings, not within full Transformer architectures.
- What evidence would resolve it: Comparative experiments showing retrieval effectiveness when Denoising Attention replaces standard attention in full Transformer models (e.g., BERT, T5) for various IR tasks.

### Open Question 2
- Question: What is the optimal strategy for dynamically adjusting the threshold parameter t based on query characteristics or user behavior patterns?
- Basis in paper: [explicit] The authors mention the threshold "could be sub-optimal in many cases" and note that "different queries could benefit from more user-related information or require a finer selection of the user-related data employed in the personalization process."
- Why unresolved: The current implementation uses a fixed threshold value that was grid-searched, but the paper acknowledges this may not be optimal for all queries.
- What evidence would resolve it: A model that learns to adjust the threshold parameter dynamically based on query features, user history patterns, or contextual signals, with comparative evaluation against fixed threshold approaches.

### Open Question 3
- Question: How would parameterized alignment models that incorporate additional signals (e.g., temporal information, user demographics) affect the performance of Denoising Attention?
- Basis in paper: [explicit] The authors state "The alignment model we employed, the scaled cosine similarity, could be replaced by a parameterized function that could leverage additional information other than the textual-based representations of a user-related document and the query" and give examples like document dates.
- Why unresolved: The current implementation uses only cosine similarity with a simple shift, without incorporating additional signals that might improve personalization.
- What evidence would resolve it: Comparative experiments using alignment models that incorporate additional features (temporal, demographic, contextual) and measure their impact on retrieval effectiveness across different search scenarios.

## Limitations

- Dataset construction reproducibility issues due to reliance on external tools and manual filtering decisions
- Hyperparameter sensitivity to threshold selection with limited analysis of threshold impact across different query types
- Incomplete specification of baseline implementations (Zero Attention and Multi-Head Attention)

## Confidence

**High Confidence**:
- The mathematical formulation of Denoising Attention is clearly specified and reproducible
- The experimental methodology (datasets, metrics, evaluation framework) is well-documented
- The core finding that Denoising Attention outperforms standard Attention baselines is statistically significant and well-supported

**Medium Confidence**:
- The claim that Denoising Attention "reduces the number of harmful personalizations" - while supported by data, the exact mechanism and consistency across different query types needs more exploration
- The assertion that plain normalization is superior to Softmax for this task - supported by theoretical arguments but would benefit from more empirical ablation studies

**Low Confidence**:
- The generalizability of results beyond the two specific datasets used (Web Search and Academic Search)
- The scalability of Denoising Attention to much larger user document collections or different personalization contexts

## Next Checks

**Check 1: Threshold Sensitivity Analysis**
Run Denoising Attention with threshold values ranging from 0 to 1 in increments of 0.1 on a held-out validation set, plotting both retrieval metrics and the percentage of filtered documents to identify optimal operating points and failure modes.

**Check 2: Baseline Implementation Verification**
Implement and test the Zero Attention and Multi-Head Attention baselines exactly as described in the paper's methodology section, ensuring that all preprocessing steps and training procedures match the original implementation.

**Check 3: Cross-Dataset Generalization**
Test Denoising Attention on a third personalization dataset (such as e-commerce purchase history or social media interaction data) to assess whether the observed improvements generalize beyond search-based personalization tasks.