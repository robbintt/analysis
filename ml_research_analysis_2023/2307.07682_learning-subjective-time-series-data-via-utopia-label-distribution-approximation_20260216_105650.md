---
ver: rpa2
title: Learning Subjective Time-Series Data via Utopia Label Distribution Approximation
arxiv_id: '2307.07682'
source_url: https://arxiv.org/abs/2307.07682
tags:
- label
- distribution
- sample
- samples
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of biased label distributions
  in subjective time-series regression (STR) tasks caused by insufficient annotators.
  The proposed Utopia Label Distribution Approximation (ULDA) method approximates
  the real-world label distribution by convolving the training label distribution
  with a Gaussian kernel.
---

# Learning Subjective Time-Series Data via Utopia Label Distribution Approximation

## Quick Facts
- arXiv ID: 2307.07682
- Source URL: https://arxiv.org/abs/2307.07682
- Reference count: 0
- Key outcome: ULDA improves baseline models and achieves state-of-the-art performance with up to 20.5% relative improvement in Pearson's Correlation Coefficient (PCC) on LIRIS-ACCEDE dataset

## Executive Summary
This paper addresses the problem of biased label distributions in subjective time-series regression (STR) tasks caused by insufficient annotators. The proposed Utopia Label Distribution Approximation (ULDA) method approximates the real-world label distribution by convolving the training label distribution with a Gaussian kernel. Two key components are introduced: Time-slice Normal Sampling (TNS) to generate new samples when needed, and Convolutional Weighted Loss (CWL) to adjust sample weights. Experiments on three benchmark datasets demonstrate that ULDA significantly improves baseline models and achieves state-of-the-art performance, with up to 20.5% relative improvement in Pearson's Correlation Coefficient (PCC) on LIRIS-ACCEDE dataset. The method effectively reduces prediction instability and enhances model fairness by making training and test label distributions more similar.

## Method Summary
ULDA addresses label distribution bias in STR tasks by approximating the real-world label distribution through Gaussian convolution. The method first convolves the training label distribution with a Gaussian kernel to create a smoother distribution. Time-slice Normal Sampling (TNS) generates new samples when the required quantity exceeds the original quantity, maintaining temporal continuity. Convolutional Weighted Loss (CWL) adjusts sample weights when the required quantity is less than the original quantity. The method is evaluated on three benchmark datasets (LIRIS-ACCEDE, SumMe, and TVSum) using various baseline models (PGL-SUM, ET, RMN) and metrics (MSE, PCC, F1-score).

## Key Results
- ULDA achieves up to 20.5% relative improvement in Pearson's Correlation Coefficient (PCC) on LIRIS-ACCEDE dataset
- The method improves baseline models across all three benchmark datasets (LIRIS-ACCEDE, SumMe, TVSum)
- ULDA reduces prediction instability and enhances model fairness by aligning training and test label distributions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Approximating the utopia label distribution through Gaussian convolution reduces prediction instability by aligning training and test label distributions.
- Mechanism: The proposed method convolves the original training label distribution with a Gaussian kernel, smoothing the distribution and reducing bias caused by insufficient annotators. This approximation makes the training label distribution closer to the real-world (utopia) distribution, which is assumed to be Gaussian according to the central limit theorem.
- Core assumption: The real-world label distribution follows a Gaussian distribution when the number of annotators is sufficiently large, and the test data is sampled from this real-world distribution.
- Evidence anchors:
  - [abstract]: "ULDA first convolves the training label distribution by a Gaussian kernel. After convolution, the required sample quantity at each regression label may change."
  - [section]: "The core of ULDA is based on the central limit theorem (CLT), which states the distribution of a sample variable (the label in this study) approximates a Gaussian distribution as the number of annotators becomes sufficiently large."
  - [corpus]: Found 25 related papers, but the specific concept of Gaussian convolution for label distribution approximation is not directly addressed in the corpus.
- Break condition: The assumption of Gaussian distribution for the real-world label distribution breaks down if the number of annotators is not sufficiently large or if the annotators' votes are not independent and identically distributed.

### Mechanism 2
- Claim: Time-slice Normal Sampling (TNS) generates new samples that maintain contextual continuity in time-series data.
- Mechanism: TNS estimates the normal distribution of sample features within a short time slice and uses Monte Carlo sampling to generate new samples. This approach maintains the contextual continuity of time-series data by considering the temporal relationship between samples.
- Core assumption: Samples within a short time slice have similar and continuous labels, and their features can be modeled using a normal distribution.
- Evidence anchors:
  - [abstract]: "We devise the Time-slice Normal Sampling (TNS) to generate new samples when the required sample quantity is greater than the initial sample quantity."
  - [section]: "To address this issue, we propose Time-slice Normal Sampling (TNS) using neighboring samples to maintain the contextual continuity. TNS estimates the feature distribution of local samples in a short time slice using a normal distribution, then augments samples by Monte Carlo sampling on the estimated distribution."
  - [corpus]: The concept of maintaining contextual continuity in time-series data is supported by the corpus, which mentions "Supported Trust Region Optimization for Offline Reinforcement Learning" and "Accurate Scene Text Recognition with Efficient Model Scaling and Cloze Self-Distillation."
- Break condition: The assumption of similar and continuous labels within a short time slice breaks down if the time-series data has abrupt changes or if the labels are not well-defined.

### Mechanism 3
- Claim: Convolutional Weighted Loss (CWL) adjusts sample weights to maintain contextual continuity without undersampling.
- Mechanism: CWL lowers the weights of samples whose required quantity after convolution is less than the original quantity. This approach maintains the contextual continuity of time-series data by keeping all samples but adjusting their importance in the loss function.
- Core assumption: The ratio of sample quantities before and after convolution can be used to determine the appropriate weight for each sample.
- Evidence anchors:
  - [abstract]: "We devise the Convolutional Weighted Loss (CWL) to lower the sample weight when the required sample quantity is less than the initial quantity."
  - [section]: "Convolutional Weighted Loss (CWL) is LossCW = 1/m * sum(wyi * (yi - ŷi)^2), where m is the number of frames in a time-series data, yi and ŷi are the ground truth and the predicted label for xi, respectively."
  - [corpus]: The concept of adjusting sample weights is supported by the corpus, which mentions "Balancing Label Quantity and Quality for Scalable Elicitation."
- Break condition: The assumption of using the ratio of sample quantities to determine weights breaks down if the relationship between the original and convoluted label distributions is not linear or if the weights do not accurately reflect the importance of each sample.

## Foundational Learning

- Concept: Central Limit Theorem (CLT)
  - Why needed here: CLT is the theoretical foundation for assuming that the real-world label distribution follows a Gaussian distribution when the number of annotators is sufficiently large.
  - Quick check question: How does the Central Limit Theorem justify the use of Gaussian convolution in approximating the utopia label distribution?

- Concept: Time-series data continuity
  - Why needed here: Maintaining contextual continuity is crucial for generating new samples and adjusting sample weights in time-series data.
  - Quick check question: Why is it important to maintain contextual continuity when generating new samples or adjusting sample weights in time-series data?

- Concept: Label distribution bias
  - Why needed here: Understanding label distribution bias is essential for recognizing the need for approximating the utopia label distribution and developing appropriate solutions.
  - Quick check question: How does label distribution bias affect the performance of models in subjective time-series regression tasks?

## Architecture Onboarding

- Component map:
  Gaussian Convolution -> Time-slice Normal Sampling (TNS) -> Convolutional Weighted Loss (CWL)

- Critical path:
  1. Perform label statistics on each time-series data in the training set.
  2. Convolve the original label distribution with a Gaussian kernel to approximate the utopia label distribution.
  3. Determine the required sample quantity at each regression label after convolution.
  4. Apply TNS to generate new samples when the required quantity is greater than the original quantity.
  5. Apply CWL to adjust sample weights when the required quantity is less than the original quantity.
  6. Train the model using the approximated utopia label distribution.

- Design tradeoffs:
  - Gaussian kernel size (δ) and standard deviation (σ): Larger values may oversmooth the label distribution, while smaller values may not effectively reduce bias.
  - Time slice length threshold (T): A smaller threshold may lead to insufficient samples for normal distribution estimation, while a larger threshold may include samples with significantly different labels.

- Failure signatures:
  - Poor performance on rare labels: The approximated utopia label distribution may not accurately represent the real-world distribution for rare labels.
  - Increased computational cost: Generating new samples using TNS and adjusting sample weights using CWL may increase the computational cost of training.

- First 3 experiments:
  1. Evaluate the performance of the model with and without ULDA on a small subset of the dataset to verify the effectiveness of the approach.
  2. Vary the Gaussian kernel size (δ) and standard deviation (σ) to find the optimal settings for the dataset.
  3. Test the impact of the time slice length threshold (T) on the performance of TNS and the overall model.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ULDA's performance change when applied to datasets with different annotation quantities, particularly comparing 3-annotator datasets versus 20-annotator datasets?
- Basis in paper: [explicit] The paper discusses how insufficient annotators (e.g., 3 persons for LIRIS-ACCEDE, 15-18 for SumMe, 20 for TVSum) lead to label distribution bias, and ULDA aims to address this by approximating real-world distributions
- Why unresolved: The experiments primarily use datasets with 15-20 annotators, and the paper doesn't explore how ULDA performs with significantly fewer annotators (like the 3-annotator LIRIS-ACCEDE dataset)
- What evidence would resolve it: Experiments comparing ULDA's performance across datasets with varying annotator counts, particularly testing with 3-annotator data versus 20-annotator data

### Open Question 2
- Question: What is the optimal Gaussian kernel size and standard deviation for different types of STR tasks (e.g., video vs. music emotion recognition)?
- Basis in paper: [explicit] The paper shows experiments with different kernel sizes (δ) and standard deviations (σ), finding optimal values of 0.06 and 0.02 for PGL-SUM, but notes these were specific to the datasets used
- Why unresolved: The optimal parameters were determined empirically for specific datasets, but there's no systematic study of how these parameters should vary across different STR task domains
- What evidence would resolve it: A comprehensive study testing ULDA with varying kernel parameters across multiple STR task domains to establish parameter guidelines

### Open Question 3
- Question: How does ULDA's performance compare to traditional sampling methods when maintaining temporal continuity is not a requirement?
- Basis in paper: [inferred] The paper claims TNS maintains temporal continuity better than traditional methods like SMOTE and Mixup, but doesn't compare ULDA's performance against these methods when temporal continuity is irrelevant
- Why unresolved: The experiments focus on STR tasks where temporal continuity is crucial, but don't explore scenarios where this constraint is relaxed
- What evidence would resolve it: Experiments comparing ULDA against traditional sampling methods on non-temporal regression tasks to isolate the benefits of temporal continuity maintenance

## Limitations
- The assumption of Gaussian-distributed real-world labels may not hold for all annotation scenarios, particularly when annotator expertise varies significantly.
- The effectiveness of TNS depends on the quality of normal distribution estimation within time slices, which may be challenging for datasets with abrupt label changes.
- CWL's weight adjustment mechanism assumes linear relationships between original and convoluted distributions that may not always be valid.

## Confidence

- **High Confidence**: The Gaussian convolution mechanism for label distribution smoothing (PCC improvements of 20.5% on LIRIS-ACCEDE dataset)
- **Medium Confidence**: The effectiveness of TNS in maintaining temporal continuity, based on conceptual framework rather than extensive empirical validation
- **Medium Confidence**: The overall claim of state-of-the-art performance across all three datasets, as some baseline comparisons may not represent the most recent methods

## Next Checks

1. **Distribution Validation**: Test the Gaussian assumption by analyzing actual annotator distributions across multiple datasets to verify the central limit theorem applicability
2. **Temporal Continuity Testing**: Conduct ablation studies varying the time slice threshold T to quantify its impact on TNS performance and model stability
3. **Cross-Dataset Generalization**: Apply ULDA to additional STR datasets with different annotation characteristics to evaluate robustness beyond the three benchmark datasets used in the paper