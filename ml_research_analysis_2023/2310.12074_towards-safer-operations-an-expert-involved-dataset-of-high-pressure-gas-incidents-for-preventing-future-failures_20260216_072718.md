---
ver: rpa2
title: 'Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas
  Incidents for Preventing Future Failures'
arxiv_id: '2310.12074'
source_url: https://arxiv.org/abs/2310.12074
tags:
- incident
- dataset
- incidents
- cause
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces a novel dataset for analyzing high-pressure
  gas incidents, focusing on three tasks: named entity recognition, cause-effect extraction,
  and information retrieval. The dataset, annotated by domain experts with extensive
  experience, aims to address the gap in safety-critical areas by providing a high-quality
  resource for preventing future failures.'
---

# Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures

## Quick Facts
- arXiv ID: 2310.12074
- Source URL: https://arxiv.org/abs/2310.12074
- Authors: 
- Reference count: 18
- Key outcome: Expert-annotated dataset for high-pressure gas incident analysis, combining named entity recognition, cause-effect extraction, and information retrieval tasks with strong baseline performance using fine-tuned BERT models.

## Executive Summary
This paper introduces a novel Japanese dataset for analyzing high-pressure gas incidents, annotated by domain experts with extensive practical experience. The dataset addresses a critical gap in safety-critical areas by providing high-quality annotations for three complementary tasks: named entity recognition, cause-effect extraction, and information retrieval. The work demonstrates that even with a relatively small dataset, fine-tuned pre-trained language models can achieve competitive performance, suggesting the potential for NLP techniques to enhance safety prevention in the high-pressure gas industry.

## Method Summary
The dataset consists of 970 incident descriptions for NER and CE tasks, plus 2,159 incident reports for IR task, all annotated by Japanese domain experts with at least six years of practical experience as high-pressure gas conservation managers. Three task-specific models were implemented and evaluated: CNN-Nested-NER, multiple BiLSTM-CRF, BINDER, and Layered nested NER models for named entity recognition; BERT-QA, FastQA, and Guided-QA models for cause-effect extraction; and BERT-based bi-encoder models (both fine-tuned and public) plus OpenAI embedding model for information retrieval. All models were fine-tuned on the dataset and evaluated using task-specific metrics including micro/macro F-scores for NER, SQUAD F-1 for CE, and nDCG@k, mAP@k, and Recall@k for IR.

## Key Results
- CNN-Nested-NER achieved the best performance for named entity recognition with strong micro and macro F-scores
- BERT-QA showed competitive performance for cause-effect extraction with SQUAD F-1 scores
- Fine-tuned BERT encoder significantly outperformed default base model on information retrieval task
- Expert annotation achieved high inter-annotator agreement (Fleiss' Kappa scores of 0.814 for NER and 0.764 for CE)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Expert annotation ensures high data quality for safety-critical tasks
- Mechanism: Domain experts with at least 6 years of experience in high-pressure gas conservation management create annotation guidelines through iterative rounds, achieving strong inter-annotator agreement (Fleiss' Kappa scores of 0.814 for NER and 0.764 for CE).
- Core assumption: Domain experts can identify and label critical safety entities and cause-effect relationships better than non-experts
- Evidence anchors:
  - [abstract]: "The dataset is annotated by domain experts who have at least six years of practical experience as high-pressure gas conservation managers"
  - [section]: "The dataset was created by three Japanese domain experts, each with at least six years of practical experience... These experts possess qualifications as high-pressure gas production safety managers"
  - [corpus]: Found 25 related papers, average neighbor FMR=0.39, suggesting moderate relevance to safety datasets
- Break condition: If experts lack recent practical experience or if safety regulations change significantly, annotation quality may degrade

### Mechanism 2
- Claim: Multi-task dataset addresses comprehensive safety analysis needs
- Mechanism: The dataset combines three tasks (NER, CE, IR) that together enable identification of entities, extraction of cause-effect relationships, and retrieval of relevant historical incidents for risk analysis
- Core assumption: Different safety analysis tasks provide complementary information for preventing future failures
- Evidence anchors:
  - [abstract]: "our dataset comprises three tasks: named entity recognition, cause-effect extraction, and information retrieval"
  - [section]: "This paper introduces a new Japanese dataset that focuses on high-gas incidents and demonstrates the potential NLP applications in analyzing high-gas incident reports"
  - [corpus]: Moderate corpus similarity (FMR=0.39) suggests dataset fills gap in multi-task safety corpora
- Break condition: If any single task becomes obsolete or if safety analysis methods change to require different information

### Mechanism 3
- Claim: Transfer learning enables effective models despite small dataset size
- Mechanism: Pre-trained language models (BERT, multilingual models) fine-tuned on the small but high-quality dataset achieve competitive performance on all three tasks
- Core assumption: Pre-trained models can adapt to domain-specific safety tasks with limited labeled data
- Evidence anchors:
  - [abstract]: "Preliminary results show promising performance, with the CNN-Nested-NER model achieving the best results for named entity recognition, and BERT-QA showing competitive performance for cause-effect extraction"
  - [section]: "It benchmarks the results of AI models on NER, CE, and IR tasks that facilitate future studies in NLP and safety prevention areas"
  - [corpus]: Small dataset size (970 samples) but strong baseline performance suggests effective transfer learning
- Break condition: If domain-specific terminology is too different from pre-training data, or if tasks require reasoning beyond language model capabilities

## Foundational Learning

- Concept: Inter-annotator agreement measurement
  - Why needed here: Ensures annotation quality and consistency across domain experts
  - Quick check question: What does a Fleiss' Kappa score of 0.814 indicate about annotation agreement?

- Concept: Nested named entity recognition
  - Why needed here: Safety entities can contain other entities (e.g., "gas generation equipment" contains both storage and product information)
  - Quick check question: Why would a nested NER approach outperform flat NER for this dataset?

- Concept: Span-based cause-effect extraction
  - Why needed here: Safety incidents require identifying specific cause and effect spans within text for risk analysis
  - Quick check question: How does the BERT-QA approach handle extracting multiple cause-effect pairs from a single incident report?

## Architecture Onboarding

- Component map: Raw incident reports → Expert annotation → Multi-task dataset → Pre-trained encoders → Task-specific fine-tuning → Evaluation → Risk analysis
- Critical path: Annotation quality → Model performance → Safety prevention impact
- Design tradeoffs:
  - Dataset size vs. annotation quality (small dataset but high-quality annotations)
  - Task complexity vs. model simplicity (multiple tasks but straightforward baselines)
  - Domain specificity vs. transfer learning (Japanese language but pre-trained multilingual models)
- Failure signatures:
  - Low inter-annotator agreement indicates unclear guidelines or expert disagreement
  - Poor model performance on any task suggests insufficient fine-tuning or data quality issues
  - Retrieval results unrelated to incidents suggest embedding space misalignment
- First 3 experiments:
  1. Evaluate baseline models on each task separately to identify weakest link
  2. Test data augmentation techniques (synonym replacement, back-translation) to increase dataset size
  3. Compare commercial embeddings (OpenAI) vs. fine-tuned BERT for IR task performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the IncidentAI dataset compare to other incident datasets when applied to different industries or domains?
- Basis in paper: [inferred] The paper introduces a new dataset for high-pressure gas incidents but does not provide a direct comparison with other incident datasets in terms of performance across different industries or domains.
- Why unresolved: The paper focuses on introducing the IncidentAI dataset and its application to high-pressure gas incidents without comparing its performance to other datasets in different industries or domains.
- What evidence would resolve it: Conducting experiments using the IncidentAI dataset and other incident datasets on tasks related to different industries or domains, and comparing their performance metrics.

### Open Question 2
- Question: What are the potential challenges and limitations of using the IncidentAI dataset for real-time incident analysis and prevention?
- Basis in paper: [inferred] The paper discusses the potential of the IncidentAI dataset for analyzing incident reports but does not delve into the specific challenges and limitations of using it for real-time incident analysis and prevention.
- Why unresolved: The paper primarily focuses on introducing the dataset and its tasks without extensively discussing the practical challenges and limitations of implementing it in real-time scenarios.
- What evidence would resolve it: Conducting case studies or simulations to assess the dataset's performance in real-time incident analysis and prevention, and identifying the specific challenges and limitations encountered.

### Open Question 3
- Question: How can the IncidentAI dataset be further expanded and improved to enhance its applicability and effectiveness in safety-critical areas?
- Basis in paper: [inferred] The paper introduces the IncidentAI dataset but does not provide detailed insights into potential future expansions or improvements to enhance its applicability and effectiveness in safety-critical areas.
- Why unresolved: The paper focuses on the current state of the dataset and its tasks without discussing potential future developments or improvements.
- What evidence would resolve it: Conducting research on potential extensions to the dataset, such as incorporating additional tasks, expanding the range of industries covered, or improving the annotation process, and evaluating their impact on the dataset's effectiveness.

## Limitations
- Small dataset size (970 samples) may limit model generalizability despite high-quality expert annotations
- Japanese language constraint restricts broader applicability to other domains or languages
- Baseline models evaluated without comparison to state-of-the-art methods for safety-specific NLP tasks

## Confidence

- **High confidence**: Expert annotation provides high-quality labels (supported by strong inter-annotator agreement scores of 0.814 and 0.764)
- **Medium confidence**: BERT-based models achieve competitive performance on all three tasks (limited by small test set and lack of comparison with state-of-the-art methods)
- **Medium confidence**: Multi-task dataset enables comprehensive safety analysis (assumption that all three tasks are necessary for effective prevention)

## Next Checks

1. Evaluate model performance on held-out test sets from different time periods to assess temporal generalization
2. Test data augmentation techniques (synonym replacement, back-translation) to determine if dataset size can be effectively expanded
3. Compare performance against domain-specific rule-based systems to establish practical utility for safety managers