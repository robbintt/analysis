---
ver: rpa2
title: 'Skills-in-Context Prompting: Unlocking Compositionality in Large Language
  Models'
arxiv_id: '2308.00304'
source_url: https://arxiv.org/abs/2308.00304
tags:
- skill
- prompting
- skills
- skic
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces skills-in-context (SKiC) prompting, a method
  that improves large language models' ability to compose foundational skills for
  solving complex problems. By demonstrating both the skills and compositional examples
  in the same prompt, SKiC enables models to ground reasoning steps on known skills.
---

# Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models

## Quick Facts
- **arXiv ID**: 2308.00304
- **Source URL**: https://arxiv.org/abs/2308.00304
- **Reference count**: 40
- **Key result**: SKiC prompting achieves near-perfect compositional generalization with just two exemplars across diverse tasks

## Executive Summary
Skills-in-Context (SKiC) prompting is a novel one-stage prompting method that significantly improves large language models' ability to compose foundational skills for solving complex problems. The approach demonstrates both basic skills and compositional examples within the same prompt context, teaching models to explicitly ground their reasoning steps on known skills. Experiments show SKiC dramatically outperforms standard prompting and other state-of-the-art methods across multiple domains including symbolic manipulation, arithmetic, question answering, and math reasoning, with particular strength in out-of-distribution generalization.

## Method Summary
SKiC prompting is a zero-shot/few-shot method that constructs prompts by identifying basic skills needed for a task, providing descriptions and examples of these skills, demonstrating how to compose them to solve complex problems, and presenting the target problem. Unlike multi-stage decomposition approaches, SKiC presents skills and compositional examples together in a single prompt, enabling models to ground reasoning steps on provided skills while leveraging pre-existing internal competencies acquired during pretraining. The method is tested across various LLMs including LLAMA-65B, text-davinci-003, ChatGPT, and GPT4 on tasks ranging from last-letter concatenation to dynamic programming and GSM8K math problems.

## Key Results
- SKiC achieves near-perfect generalization across diverse tasks with only two exemplars
- Outperforms standard prompting, Chain-of-Thought, and decomposed prompting by significant margins, particularly on out-of-distribution problems
- Successfully unlocks models' ability to leverage pre-existing internal skills not explicitly shown in prompts
- Shows consistent performance improvements across multiple model types including open-source and closed-source LLMs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SKiC prompts improve compositional generalization by explicitly grounding reasoning steps on known skills
- Mechanism: The prompt structure shows both basic skills and compositional examples within the same context, teaching the model to explicitly reference skills during reasoning
- Core assumption: LLMs can learn to ground their reasoning steps on provided skills when both skills and examples are presented together
- Evidence anchors: [abstract] "It is crucial to demonstrate both the skills and the compositional examples within the same prompt context"; [section 2.2] "The key insight is to teach the LLM to explicitly ground each of its reasoning steps on the (more elementary) skills"

### Mechanism 2
- Claim: SKiC unlocks latent internal skills acquired during pretraining
- Mechanism: By demonstrating how to compose skills, the model learns to activate and combine internal competencies not explicitly shown in the prompt
- Core assumption: LLMs retain and can access skills learned during pretraining when prompted appropriately
- Evidence anchors: [abstract] "SKiC also unlocks the latent potential of LLMs, allowing them to more actively utilize pre-existing internal skills acquired during earlier pretraining"; [section 2.2] "the models successfully learn how to ground each reasoning step on the knowledge and skills that they have already mastered"

### Mechanism 3
- Claim: One-stage prompting with explicit skill grounding outperforms multi-stage decomposition methods
- Mechanism: Concurrent presentation of skills and compositions allows more flexible and grounded reasoning compared to sequential decomposition
- Core assumption: Presenting skills and compositions together enables better skill activation and combination than staged approaches
- Evidence anchors: [section 2.2] "Unlike the Least-to-Most or decomposed prompting, our proposed approach is a one-stage prompting method"; [section 3.3] "our SKiC prompting further boosts the accuracy... by making predictions in one single stage"

## Foundational Learning

- Concept: Compositional generalization
  - Why needed here: The paper's central focus is on enabling models to solve problems requiring skill composition
  - Quick check question: Can you explain the difference between in-distribution and out-of-distribution compositional generalization?

- Concept: Chain-of-Thought prompting
  - Why needed here: SKiC builds upon CoT by adding explicit skill grounding
  - Quick check question: How does SKiC differ from standard Chain-of-Thought prompting in terms of skill utilization?

- Concept: In-context learning
  - Why needed here: SKiC is an in-context learning technique that uses examples within prompts
  - Quick check question: What are the key differences between zero-shot, few-shot, and SKiC prompting approaches?

## Architecture Onboarding

- Component map:
  Skill definitions -> Compositional examples -> Target problem -> LLM inference engine

- Critical path:
  1. Identify relevant skills for the target task
  2. Create skill descriptions with examples
  3. Design compositional examples showing skill usage
  4. Construct SKiC prompt with skills + examples + target problem
  5. Generate solution through LLM inference

- Design tradeoffs:
  - Number of skills vs. prompt length
  - Number of compositional examples vs. context window usage
  - Skill complexity vs. model's ability to reference them
  - Specificity of examples vs. generalization capability

- Failure signatures:
  - Model ignores skill references in reasoning steps
  - Model fails to combine skills even with explicit examples
  - Model struggles with unseen skill combinations
  - Model's output exceeds context window

- First 3 experiments:
  1. Implement SKiC for last-letter-concatenation task and compare with standard CoT
  2. Test SKiC on arithmetic operations with varying digit lengths
  3. Evaluate SKiC on dynamic programming problems with different sequence lengths

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the maximum number of skills that can be effectively included in a SKiC prompt before performance degrades due to context length limitations?
- Basis in paper: [explicit] The paper mentions that "it is infeasible to enumerate all the needed skills to solve all the problems in GSM8k" and only includes limited skills in prompts
- Why unresolved: The paper does not systematically explore the relationship between number of skills, context length, and performance. It only demonstrates that a limited set of skills works well.
- What evidence would resolve it: Controlled experiments varying the number of skills in prompts while measuring performance on increasingly complex tasks would establish the optimal skill set size.

### Open Question 2
- Question: Can SKiC prompting be extended to domains beyond text-based reasoning, such as visual reasoning or multi-modal tasks?
- Basis in paper: [inferred] The paper focuses exclusively on language-based tasks and doesn't explore whether the grounding approach generalizes to other modalities
- Why unresolved: The methodology is tested only on NLP tasks, leaving open whether the skill-grounding principle applies to non-textual reasoning
- What evidence would resolve it: Applying SKiC prompting to visual reasoning tasks or multi-modal datasets and comparing performance to standard prompting would demonstrate generalizability.

### Open Question 3
- Question: How does SKiC prompting affect the internal representations learned by LLMs during fine-tuning compared to other prompting strategies?
- Basis in paper: [explicit] The paper mentions that SKiC "unlocks the latent potential of LLMs" and allows them to use pre-existing internal skills, suggesting changes to internal representations
- Why unresolved: The paper analyzes performance outcomes but doesn't investigate what happens to the model's internal representations or knowledge organization
- What evidence would resolve it: Analyzing activation patterns, probing tasks, or knowledge graph structures in models fine-tuned with SKiC versus other methods would reveal representational differences.

## Limitations
- Requires careful identification and articulation of relevant skills for each task
- Primarily evaluated on constrained tasks; real-world applicability untested
- Doesn't address computational costs or latency implications of longer reasoning chains

## Confidence
- **High confidence**: SKiC improves compositional generalization compared to standard prompting methods
- **Medium confidence**: SKiC unlocks latent internal skills based on performance improvements
- **Medium confidence**: Scalability to complex, real-world problems given current evaluation scope

## Next Checks
1. Test SKiC performance on a broader range of complex, open-ended reasoning tasks to assess real-world applicability beyond the current constrained problems
2. Conduct ablation studies removing specific skills from prompts to measure the actual contribution of each skill and validate the grounding mechanism
3. Implement a systematic analysis of reasoning chain faithfulness by comparing generated solutions against ground truth reasoning paths to ensure SKiC doesn't just improve accuracy through hallucination