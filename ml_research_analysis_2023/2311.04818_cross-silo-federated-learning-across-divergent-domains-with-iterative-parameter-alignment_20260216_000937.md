---
ver: rpa2
title: Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter
  Alignment
arxiv_id: '2311.04818'
source_url: https://arxiv.org/abs/2311.04818
tags:
- learning
- peer
- each
- data
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses two critical limitations in current federated
  learning (FL) approaches: convergence issues when client domains are sufficiently
  different and the production of identical global models for each client. To tackle
  these problems, the authors propose the Iterative Parameter Alignment (IPA) algorithm,
  which learns N models each optimized for a common objective rather than a single
  global model.'
---

# Cross-Silo Federated Learning Across Divergent Domains with Iterative Parameter Alignment

## Quick Facts
- arXiv ID: 2311.04818
- Source URL: https://arxiv.org/abs/2311.04818
- Reference count: 40
- Key outcome: IPA achieves stable convergence in disjoint domain scenarios where existing FL approaches struggle, producing unique peer models without a central orchestrator

## Executive Summary
This paper introduces Iterative Parameter Alignment (IPA), a novel federated learning algorithm designed to address convergence issues when client domains are sufficiently different and the production of identical global models for each client. IPA learns N models each optimized for a common objective rather than a single global model by applying weighted distance minimization to model parameters shared in a peer-to-peer topology. The method demonstrates robust performance in cross-domain settings, achieving stable convergence to baseline accuracy when existing approaches fail, while also producing unique peer models that avoid the vulnerability of a shared global model.

## Method Summary
IPA addresses limitations in federated learning by learning N models, one for each silo, through iterative parameter alignment. Each peer maintains its own parameter set that is updated independently through local training and peer alignment without aggregation into a single shared model. The algorithm minimizes both local empirical loss and an alignment objective that sums the distances between a peer's parameters and all other peers' parameters. This alignment acts as a regularization term that pulls disparate models toward a common solution, enabling convergence even when local data distributions are non-overlapping. The peer-to-peer topology ensures no central model is exposed to all participants, and a built-in fairness mechanism correlates model performance with each peer's standalone model performance.

## Key Results
- IPA achieves stable convergence to baseline accuracy in disjoint domain scenarios where existing FL algorithms struggle
- The method produces unique peer models in a decentralized topology without requiring a central orchestrator
- IPA demonstrates competitive results compared to state-of-the-art FL approaches on homogeneous data partitions while excelling in cross-domain settings
- Model performance correlates with each peer's standalone model performance, providing a built-in fairness mechanism

## Why This Works (Mechanism)

### Mechanism 1
- Claim: IPA achieves stable convergence when client domains are completely disjoint by minimizing the weighted distance between model parameters across peers.
- Mechanism: Each peer iteratively updates its parameters by minimizing both its local empirical loss and an alignment objective that sums the distances between its parameters and all other peers' parameters. This alignment acts as a regularization term that pulls disparate models toward a common solution.
- Core assumption: The optimization landscape of the alignment objective is smooth enough that gradient-based updates will lead to convergence, even when local data distributions are non-overlapping.
- Evidence anchors:
  - [abstract] "To achieve this, we apply a weighted distance minimization to model parameters shared in a peer-to-peer topology."
  - [section] "Specifically, model i holds parameters θ∗ locally, and during each minibatch updates θi by minimizing the distance between θi and each θn."
  - [corpus] Weak: no direct citations found for alignment-based convergence in disjoint domains.
- Break condition: If the alignment objective becomes too large relative to the local loss, parameter updates may become dominated by alignment and fail to optimize the local task effectively.

### Mechanism 2
- Claim: IPA produces unique models for each peer, avoiding the vulnerability of a shared global model.
- Mechanism: Each peer maintains its own parameter set that is updated independently through local training and peer alignment, without aggregation into a single shared model. The peer-to-peer topology ensures no central model is exposed to all participants.
- Core assumption: Peers can exchange parameters securely without revealing their full models to competitors, especially when combined with differential privacy.
- Evidence anchors:
  - [abstract] "IPA also produces unique peer models in a decentralized topology, providing independence from a central orchestrator."
  - [section] "IPA addresses issues of model protection through silo-to-silo federated learning over N unique models."
  - [corpus] Weak: limited literature directly comparing decentralized model sharing to centralized aggregation in FL.
- Break condition: If peers collude or intercept parameter exchanges, they could reconstruct others' models despite the decentralized setup.

### Mechanism 3
- Claim: IPA includes a built-in fairness mechanism where model performance correlates with a peer's standalone model performance.
- Mechanism: Early in training, peers with better local data or initialization converge faster. By stopping training at an iteration where performance is correlated but not yet globally converged, fairness can be enforced across peers.
- Core assumption: The correlation between standalone and federated performance is stable and monotonic during early training phases.
- Evidence anchors:
  - [abstract] "IPA contains built-in fairness: we show that model performance on classification tasks is correlated with a peers standalone model performance."
  - [section] "We enable fairness in the IPA algorithm through the early stopping of training at some iteration t < T."
  - [corpus] Weak: fairness mechanisms in FL often focus on resource allocation rather than model performance correlation.
- Break condition: If the correlation between standalone and federated performance breaks down at later training stages, early stopping may not ensure fairness.

## Foundational Learning

- Concept: Federated Learning and Cross-Silo settings
  - Why needed here: Understanding the distinction between cross-device and cross-silo FL is crucial because IPA is designed for the latter, where peers are reliable organizations with strong computational resources.
  - Quick check question: What are the key differences between cross-device and cross-silo federated learning in terms of participant reliability and data volume?

- Concept: Model parameter distance minimization
  - Why needed here: The alignment objective in IPA relies on minimizing distances between model parameters across peers, which is a form of regularization that encourages convergence.
  - Quick check question: How does minimizing the distance between model parameters help in aligning models trained on different data distributions?

- Concept: Differential Privacy in model sharing
  - Why needed here: IPA shares model parameters across peers, which could expose model details. Differential privacy adds noise to parameters to protect against reconstruction attacks.
  - Quick check question: What is the trade-off between the amount of noise added for privacy and the convergence speed of the federated learning algorithm?

## Architecture Onboarding

- Component map: Peer nodes each hold a local dataset and model, perform local training, and exchange parameters with neighbors in a peer-to-peer topology. A central orchestrator is not required.
- Critical path: Local training → Parameter alignment with neighbors → Update parameters → Repeat until convergence or early stopping.
- Design tradeoffs: Decentralized parameter sharing increases communication overhead per peer but avoids a single point of failure. Differential privacy adds security but may slow convergence.
- Failure signatures: Divergence in parameter updates, failure to reach baseline accuracy, or high variance in peer model performances.
- First 3 experiments:
  1. Run IPA on CIFAR-10 with two peers having completely disjoint label sets (e.g., one has labels 0-4, the other has 5-9) and measure convergence to baseline accuracy.
  2. Compare IPA convergence rates with FedAvg, FedProx, and FedDyn on heterogeneous data splits using Dirichlet distribution with α=0.3.
  3. Evaluate the effect of adding differential privacy noise (σ=0.0005) on convergence speed and final accuracy in a two-peer CIFAR-10 disjoint labels scenario.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Iterative Parameter Alignment (IPA) scale with the number of peers beyond 20 in cross-silo federated learning scenarios?
- Basis in paper: [explicit] The authors note that IPA "does not scale well to many peers as a result of requiring N × θ̄ parameters during training" and tested up to 20 peers on a single GPU.
- Why unresolved: The paper only tests up to 20 peers and acknowledges scaling limitations without providing solutions or thresholds for when performance degrades significantly.
- What evidence would resolve it: Experiments showing convergence rates, communication overhead, and model accuracy for varying numbers of peers (e.g., 50, 100, 500) would clarify the scalability limits of IPA.

### Open Question 2
- Question: What is the impact of different network topologies (beyond the ring topology tested) on the convergence and performance of IPA in cross-silo federated learning?
- Basis in paper: [inferred] The authors mention that "different topologies" are used in experiments and reference Marfoq et al. [32] who examine the effect of topology on communication rounds, but IPA's performance across various topologies is not explored.
- Why unresolved: The paper primarily uses a ring topology and random topologies without systematically comparing different graph structures (e.g., fully connected, star, mesh) and their effects on convergence and fairness.
- What evidence would resolve it: Experiments comparing IPA's performance across multiple network topologies with the same data partitions and hyperparameters would reveal topology's impact on convergence, communication efficiency, and fairness.

### Open Question 3
- Question: How does the choice of distance metric (L1 vs L2) in the parameter alignment objective affect IPA's robustness to different types of domain divergence beyond disjoint classes?
- Basis in paper: [explicit] The authors show that "split label experiments exhibit instability when using squared error (L2) alignment, while absolute error (L1) alignment achieves smooth convergence" in Section V.
- Why unresolved: While L1 is shown to be more stable for disjoint classes, the paper doesn't explore whether this holds for other forms of domain divergence (e.g., overlapping classes with different distributions, feature space differences) or if other metrics might perform better.
- What evidence would resolve it: Experiments testing IPA with different distance metrics (L1, L2, cosine similarity, Wasserstein distance) across various types of domain divergence scenarios would identify the most robust alignment objective.

## Limitations

- IPA requires N × θ̄ parameters during training, which limits scalability to many peers and requires significant computational resources
- The method lacks theoretical convergence guarantees in the most challenging scenario of completely disjoint class distributions, relying primarily on empirical evidence
- Performance may degrade with highly heterogeneous data partitions or a large number of peers, as suggested by the authors' acknowledgment of scaling limitations

## Confidence

- **High confidence**: IPA's ability to produce unique models for each peer and its implementation in a peer-to-peer topology without a central orchestrator. The experimental results on benchmark datasets are clear and reproducible.
- **Medium confidence**: The built-in fairness mechanism and its correlation with standalone model performance. While the correlation is demonstrated, the practical implications and robustness of early stopping for fairness enforcement require further investigation.
- **Low confidence**: The theoretical convergence guarantees in completely disjoint domains. The paper provides empirical evidence but lacks a formal proof or analysis of the optimization dynamics in this scenario.

## Next Checks

1. Conduct a formal analysis of the optimization landscape and convergence properties of IPA, particularly in scenarios with completely disjoint class distributions. This should include both local convergence guarantees and global convergence analysis.

2. Evaluate IPA's performance and communication efficiency with a larger number of peers (e.g., 10-20) and on more complex datasets to assess its scalability and practical limitations.

3. Test IPA's resilience to adversarial attacks, such as gradient inversion or model extraction, especially when differential privacy is applied. Assess the trade-off between privacy guarantees and model performance under attack.