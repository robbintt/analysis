---
ver: rpa2
title: Integrating Stock Features and Global Information via Large Language Models
  for Enhanced Stock Return Prediction
arxiv_id: '2310.05627'
source_url: https://arxiv.org/abs/2310.05627
tags:
- stock
- information
- global
- features
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a framework combining Large Language Models
  (LLMs) with stock features for improved stock return prediction. It addresses the
  challenge of aligning news-derived LLM embeddings with stock features by using a
  Local-Global (LG) model that decomposes returns into idiosyncratic and global components.
---

# Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction

## Quick Facts
- arXiv ID: 2310.05627
- Source URL: https://arxiv.org/abs/2310.05627
- Authors: 
- Reference count: 8
- This paper introduces a framework combining Large Language Models (LLMs) with stock features for improved stock return prediction, achieving a Rank IC of 0.152 ± 0.003 and annual return of 0.288 ± 0.05 on China A-shares data.

## Executive Summary
This paper proposes a novel framework that integrates Large Language Model (LLM) embeddings with traditional stock features for enhanced stock return prediction. The key innovation is the Local-Global (LG) model that decomposes returns into idiosyncratic and global components, combined with Self-Correlated Reinforcement Learning (SCRL) to align news-derived LLM embeddings with stock features in a unified semantic space. Empirical results on China A-shares data demonstrate that this hybrid approach significantly outperforms models using only stock features or only LLM embeddings, validating the effectiveness of combining quantitative features with semantic insights from financial news.

## Method Summary
The proposed framework combines a Local-Global model with Self-Correlated Reinforcement Learning. The Local-Global model decomposes stock return prediction into two sub-models: a Local model capturing stock-specific information (volume, price, technical features) and a Global model capturing broader market, industry, and policy impacts. SCRL aligns financial news embeddings generated by LLMs with stock features using Proximal Policy Optimization (PPO), learning a sparse transformation vector that selectively incorporates global information while mitigating overfitting. The framework is trained on China A-shares data with 3506 stocks and 342 daily features, using Llama 7B fine-tuned on Chinese news corpus to generate embeddings.

## Key Results
- SCRL-LG achieves a Rank Information Coefficient of 0.152 ± 0.003, outperforming models using only stock features
- Annual return of 0.288 ± 0.05 demonstrates practical trading effectiveness
- The hybrid approach significantly improves predictive performance compared to using only stock features or only LLM embeddings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning LLM-generated embeddings with stock features in a unified semantic space improves predictive performance by capturing complementary information.
- Mechanism: SCRL aligns financial news embeddings (Vllm) from LLMs with traditional stock features (Mt-1) using a sparse transformation vector (Vsparse) learned through reinforcement learning, allowing the model to selectively incorporate global information while mitigating overfitting.
- Core assumption: The semantic spaces of LLM-generated news embeddings and stock features can be meaningfully aligned through a learned transformation, and this alignment captures genuinely complementary information about stock returns.
- Evidence anchors:
  - [abstract] "Self-Correlated Reinforcement Learning (SCRL) aligns embeddings of financial news generated by LLMs with stock features within the same semantic space"
  - [section] "The second component, Self-Correlated Reinforcement Learning (SCRL), focuses on aligning the embeddings of financial news generated by LLMs with stock features within the same semantic space"
- Break condition: If the semantic spaces of news embeddings and stock features are fundamentally incompatible or if the learned transformation fails to capture meaningful relationships, the alignment would break and performance would degrade.

### Mechanism 2
- Claim: Decomposing stock returns into idiosyncratic (local) and global components allows the model to separately model stock-specific factors and broader market influences.
- Mechanism: The Local-Global (LG) model splits return prediction into two sub-models - the Local model captures stock-specific information while the Global model captures market, industry, and policy impacts through attention mechanisms or LLM-generated embeddings.
- Core assumption: Stock returns can be meaningfully decomposed into components that represent stock-specific behavior versus broader market/global influences, and these components can be modeled separately and then combined.
- Evidence anchors:
  - [abstract] "introduces three distinct strategies for modeling global information. These approaches are grounded respectively on stock features, the capabilities of LLMs, and a hybrid method combining the two paradigms"
  - [section] "Inspired by classical asset pricing models... we decompose the stock return prediction model into two sub-models: a Local model and a Global model"
- Break condition: If the decomposition assumption is invalid (i.e., returns cannot be meaningfully separated into local and global components), or if the combination method fails to properly integrate the two components.

### Mechanism 3
- Claim: Using attention mechanisms to aggregate stock features into a global representation captures the collective influence of all stocks on individual stock returns.
- Mechanism: Model 1 uses an attention mechanism where a query vector interacts with key-value pairs derived from stock features to produce a weighted aggregation that represents global information influencing returns.
- Core assumption: The relationships between individual stocks can be captured through attention mechanisms applied to their feature representations, and this aggregation represents meaningful global market information.
- Evidence anchors:
  - [section] "Inspired by the work of [Duan et al., 2022], we utilize an attention mechanism to aggregate the stock features Mt into a vector ft, which captures global information that influences stock returns"
- Break condition: If the attention mechanism fails to capture meaningful relationships between stocks, or if the aggregation produces redundant information that overlaps with local features, leading to overfitting.

## Foundational Learning

- Concept: Reinforcement Learning with Proximal Policy Optimization (PPO)
  - Why needed here: SCRL uses PPO to optimize the alignment between Actor and Critic models while maintaining stability through KL divergence constraints
  - Quick check question: What is the purpose of the KL divergence term in the PPO reward function R(x, y) = r(x, y) - θKL(x, y)?

- Concept: Attention Mechanisms in Financial Modeling
  - Why needed here: Model 1 uses attention to aggregate stock features into a global representation that captures collective market influences
  - Quick check question: How does the attention weight calculation aatt = max(0, q · K^T / (||q||^2 · ||K||^2)) ensure non-negative weights while normalizing for vector magnitudes?

- Concept: Large Language Model Embeddings for Financial Analysis
  - Why needed here: LLM-generated embeddings (Vllm) capture semantic information from financial news that complements traditional stock features
  - Quick check question: Why might news headlines about "Ministry of Commerce: Strengthening Business Environment Protection" be more useful for global information than news describing specific stock price movements?

## Architecture Onboarding

- Component map: Stock features (M) -> Local-Global Model -> Predicted returns; LLM + Financial news -> Vllm embeddings -> SCRL -> Aligned embeddings -> Local-Global Model

- Critical path:
  1. Pre-train LLM on news corpus
  2. Train Critic (Local-Global) model on stock features
  3. Initialize Actor model from Critic
  4. Generate Vllm from news using LLM
  5. Align Vllm with stock features using SCRL
  6. Predict returns using combined model

- Design tradeoffs:
  - Using only stock features (LG-STOCK) vs. only LLM embeddings (LG-LLM) vs. hybrid approach
  - Model complexity vs. overfitting risk in SCRL alignment
  - Granularity of news corpus selection (60-day window) vs. computational cost

- Failure signatures:
  - High correlation between daily Vllm indicates insufficient information diversity
  - Vanishing gradients when learning Vsparse transformation
  - Overfitting when dimensionality of Wllm is too large
  - Poor performance improvement over baseline models

- First 3 experiments:
  1. Train Local model only (without Global component) to establish baseline performance
  2. Train LG-STOCK model with attention mechanism only to test stock feature aggregation
  3. Train LG-LLM model with only LLM embeddings to test news information utility

## Open Questions the Paper Calls Out

- How sensitive is the SCRL-LG framework's performance to the choice of LLM architecture and size?
- How does the SCRL-LG framework perform on stock markets outside China?
- What is the optimal frequency for fine-tuning the LLM during the SCRL process?
- How robust is the framework to different types of stock features and their preprocessing methods?

## Limitations

- The framework was only tested on China A-shares market, limiting generalizability to other markets with different characteristics
- The effectiveness of decomposing returns into purely idiosyncratic versus global components may vary across different market regimes and economic conditions
- The SCRL component introduces additional complexity that could potentially lead to overfitting, particularly given the high-dimensional nature of both news embeddings and stock features

## Confidence

- **High Confidence**: The empirical methodology and evaluation metrics are clearly specified and appropriate for the task. The baseline comparisons provide reasonable benchmarks for assessing the hybrid approach's value-add.
- **Medium Confidence**: The theoretical framework for return decomposition and the alignment mechanism are logically sound, but their practical effectiveness depends heavily on implementation details not fully specified in the paper.
- **Low Confidence**: The generalizability of results across different markets, economic conditions, and time periods remains uncertain without additional validation studies.

## Next Checks

1. Cross-market validation: Test the SCRL-LG framework on at least two additional stock markets (e.g., US equities, European markets) to assess generalizability beyond China A-shares.

2. Robustness to market regimes: Evaluate model performance across different market conditions (bull/bear markets, high/low volatility periods) to determine if the decomposition approach remains effective during regime shifts.

3. Ablation study on SCRL components: Systematically disable individual components of the SCRL alignment mechanism (e.g., PPO reward structure, KL divergence regularization) to quantify their individual contributions to predictive performance.