---
ver: rpa2
title: Theory of Hallucinations based on Equivariance
arxiv_id: '2312.14504'
source_url: https://arxiv.org/abs/2312.14504
tags:
- substitution
- language
- equivariance
- text
- ciphers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new theory linking insufficient equivariance
  acquisition in large language models to the occurrence of hallucinations. The author
  introduces a specialized cross-entropy error function to create a hallucination
  scale and tests language models' ability to acquire character-level equivariance
  using a modified T5 model.
---

# Theory of Hallucinations based on Equivariance

## Quick Facts
- arXiv ID: 2312.14504
- Source URL: https://arxiv.org/abs/2312.14504
- Reference count: 3
- One-line primary result: Proposes a new theory linking insufficient equivariance acquisition in large language models to hallucinations, demonstrating moderate success with character-level substitution cipher deciphering.

## Executive Summary
This paper introduces a novel theoretical framework connecting insufficient equivariance acquisition in large language models to the occurrence of hallucinations. The author proposes that when language models cannot uniquely decode token ID sequences back to their original meaning due to inadequate equivariance constraints, they generate outputs inconsistent with intended meaning. To test this hypothesis, the paper develops a specialized cross-entropy error function to create a hallucination scale and uses a modified T5 model to assess character-level equivariance acquisition through deciphering substitution ciphers without explicit dictionaries. The experimental results demonstrate that T5 can learn meta-rules for deciphering character substitution ciphers with moderate success, suggesting that inadequate equivariance leads to incorrect interpretations.

## Method Summary
The methodology involves training a modified T5 model on character-level substitution ciphers where each training example consists of an input sentence encrypted through random reversible character substitution, with the model tasked to predict the substitution rule itself. The training data uses the first 32,768 lines of the CC-100 English corpus, processed with a custom 28-token vocabulary (26 letters plus space and special tokens). The model employs cross-entropy loss on token IDs with AdamW optimizer (learning rate 0.001), batch size 128, and up to 189 epochs. During inference, a high repetition penalty enforces unique outputs. The core hypothesis is that successful decryption without explicit dictionaries demonstrates sufficient equivariance acquisition, while partial success indicates inadequate equivariance leading to potential hallucinations.

## Key Results
- T5 model successfully learned meta-rules for deciphering character-level substitution ciphers with up to 24/26 characters correctly decrypted
- Cross-entropy error function effectively measured equivariance acquisition at character level
- Character-level equivariance acquisition provides a tractable testbed for understanding hallucination mechanisms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Insufficient equivariance acquisition leads to hallucinations because the model cannot uniquely decode token ID sequences back to their original meaning.
- Mechanism: When a tokenizer loses its dictionary, the model must infer the mapping from token IDs to text. Without full equivariance, multiple valid interpretations exist, causing the model to generate outputs inconsistent with the intended meaning.
- Core assumption: Language models trained on small datasets lack sufficient constraints to uniquely determine the correct decoding.
- Evidence anchors:
  - [abstract] "Building on this insight, I propose a new theory suggesting that insufficient equivariance in language models can lead to hallucinations."
  - [section 1.1] "However, the impossibility of recovering a dictionary different from the original also implies that the tokenizer's original dictionary can be uniquely recovered."
  - [corpus] Weak - neighboring papers discuss equivariance and hallucinations separately but don't directly support this specific mechanism.
- Break condition: If the training data volume increases sufficiently, the constraints become strong enough to eliminate ambiguity in decoding, preventing hallucinations.

### Mechanism 2
- Claim: T5 can learn meta-rules for deciphering substitution ciphers by treating the cipher as a reversible transformation problem.
- Mechanism: The model learns to map input token ID sequences (encrypted text) to output token ID sequences (decryption rules) through cross-entropy loss, effectively learning the inverse of the cipher transformation.
- Core assumption: Substitution ciphers are reversible and deterministic, allowing the model to learn the inverse mapping.
- Evidence anchors:
  - [section 4] "I trained T5 using the post-substitution token ID sequence as input and, unlike previous studies, the substitution rule (i.e., the dictionary itself) as output."
  - [section 5] "This implies that despite changing the substitution rules randomly at each step, T5 was able to learn a meta rule, that is, a general method for deciphering character-level substitution ciphers."
  - [corpus] Moderate - related works show sequence-to-sequence models can crack ciphers, supporting this approach.
- Break condition: If the cipher becomes too complex (e.g., word-level substitution with vocabulary >10,000), the model may fail to learn the meta-rule due to computational constraints.

### Mechanism 3
- Claim: Scaling equivariance acquisition from character to word level creates a unified framework for understanding hallucinations in large language models.
- Mechanism: Character-level equivariance provides a tractable testbed for understanding how equivariance constraints affect model behavior. The same principles can be extended to word-level, where the vocabulary size and complexity increase but the fundamental mechanism remains.
- Core assumption: The principles governing character-level equivariance acquisition are scalable to word-level and beyond.
- Evidence anchors:
  - [abstract] "This methodology can be extended to assess equivariance acquisition at the word level, paving the way for very large language models that can comprehensively understand relationships and, consequently, avoid hallucinations."
  - [section 6.3] "Extending the character substitution cipher deciphering models discussed so far to word substitution cipher deciphering seems straightforward, but modeling it may also present challenges."
  - [corpus] Weak - no direct corpus evidence supporting the scalability claim; neighboring papers don't address this specific extension.
- Break condition: If word-level equivariance acquisition introduces non-linear complexities not present in character-level, the scaling assumption may break down.

## Foundational Learning

- Concept: Cross-entropy loss function
  - Why needed here: It measures the difference between predicted token ID sequences and ground truth substitution rules, enabling the model to learn the correct decryption.
  - Quick check question: Why is cross-entropy appropriate for measuring the error in token ID prediction tasks?

- Concept: Equivariance in neural networks
  - Why needed here: The core hypothesis links insufficient equivariance acquisition to hallucinations, making understanding equivariance essential.
  - Quick check question: How does rotational equivariance in image processing relate to semantic equivariance in text processing?

- Concept: Tokenization and dictionary recovery
  - Why needed here: The paper argues that without the tokenizer's dictionary, recovering the original text is ambiguous, which is central to understanding hallucinations.
  - Quick check question: Why can't a token ID sequence be uniquely decoded without knowing the tokenizer's dictionary?

## Architecture Onboarding

- Component map:
  T5 model (google/t5-efficient-tiny) -> Tokenizer with custom 28-token vocabulary -> Random substitution rule generator -> Cross-entropy loss function -> AdamW optimizer

- Critical path: Input text → tokenization → substitution → T5 encoding → output substitution rule prediction → cross-entropy loss calculation → parameter update

- Design tradeoffs: Using character-level instead of word-level simplifies computation but may not capture the full complexity of real-world hallucinations. The custom vocabulary limits the model's ability to handle punctuation and special characters.

- Failure signatures: Partial decryption success (e.g., 24/26 characters correctly decrypted) indicates the model learned most but not all equivariance constraints. High loss values suggest the model hasn't converged to the meta-rule.

- First 3 experiments:
  1. Train T5 on character substitution ciphers with varying substitution complexity (e.g., simple Caesar cipher vs. random permutation) and measure decryption accuracy.
  2. Test the model's ability to generalize to unseen substitution rules by training on a subset of possible ciphers and evaluating on the remaining set.
  3. Scale the vocabulary size from 26 characters to 100+ tokens (including common words) and measure the impact on equivariance acquisition and decryption accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural or algorithmic improvements in large language models could reduce hallucinations related to insufficient equivariance acquisition?
- Basis in paper: [explicit] The paper discusses how insufficient equivariance acquisition leads to hallucinations and proposes a method to test this hypothesis.
- Why unresolved: While the paper identifies a potential cause of hallucinations, it does not provide specific solutions for improving large language models to reduce this issue.
- What evidence would resolve it: Empirical studies comparing hallucination rates in models with different architectures or training methods that explicitly target equivariance acquisition.

### Open Question 2
- Question: How does the proposed cross-entropy error function for measuring equivariance acquisition scale when applied to word-level substitution ciphers compared to character-level ciphers?
- Basis in paper: [explicit] The paper introduces a specialized cross-entropy error function for creating a hallucination scale and mentions extending the methodology to word-level analysis.
- Why unresolved: The paper only tests the method at the character level and does not provide results or analysis for word-level application.
- What evidence would resolve it: Comparative studies showing the effectiveness of the error function at both character and word levels, including computational requirements and accuracy.

### Open Question 3
- Question: What are the limitations of using frequency analysis in deciphering substitution ciphers, and how does the proposed T5-based method overcome these limitations?
- Basis in paper: [explicit] The paper mentions that frequency analysis can lose effectiveness if there is bias in the text content and introduces a T5-based method that does not rely on frequency analysis.
- Why unresolved: The paper does not provide a detailed comparison between frequency analysis and the T5-based method in terms of accuracy and efficiency.
- What evidence would resolve it: Experimental results comparing the success rates and computational efficiency of both methods across various cipher texts with different levels of bias.

## Limitations
- The proposed link between insufficient equivariance acquisition and hallucinations remains theoretical with no direct evidence for real-world large language models
- Scalability claims to word-level analysis face significant computational challenges that are not empirically validated
- The equivariance framework relies on a specific definition in the context of substitution ciphers that may not generalize to other hallucination types

## Confidence
- High confidence: Experimental methodology for character-level equivariance testing is well-defined and reproducible
- Medium confidence: Core hypothesis linking insufficient equivariance to hallucinations is plausible but unproven
- Low confidence: Claims about scaling to word level and creating hallucination-free models are highly speculative

## Next Checks
1. Scale validation: Replicate character substitution cipher experiments using increasingly larger vocabularies (100, 1,000, and 10,000 tokens) to empirically test scalability claims and identify computational limits
2. Real-world hallucination analysis: Analyze actual hallucinations in pre-trained large language models by comparing tokenization patterns and equivariance properties with successful predictions
3. Alternative equivariance measures: Implement and test alternative definitions of equivariance to determine whether character-level substitution equivariance captures essential properties for preventing hallucinations