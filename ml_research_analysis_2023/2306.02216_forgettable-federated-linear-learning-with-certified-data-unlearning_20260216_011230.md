---
ver: rpa2
title: Forgettable Federated Linear Learning with Certified Data Unlearning
arxiv_id: '2306.02216'
source_url: https://arxiv.org/abs/2306.02216
tags:
- data
- learning
- training
- unlearning
- server
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a novel Forgettable Federated Linear Learning\
  \ (F\xB2L\xB2) framework that enables certified data removal in federated learning\
  \ through a linear approximation of the model parameter space. The key contributions\
  \ are: A federated linear training algorithm that uses a first-order Taylor expansion\
  \ to approximate the model as linear, allowing for efficient data removal via a\
  \ Newton step."
---

# Forgettable Federated Linear Learning with Certified Data Unlearning

## Quick Facts
- arXiv ID: 2306.02216
- Source URL: https://arxiv.org/abs/2306.02216
- Reference count: 40
- One-line primary result: A novel F²L² framework enables certified data removal in federated learning via linear approximation, achieving comparable accuracy and unlearning performance to retraining from scratch.

## Executive Summary
This paper proposes a novel Forgettable Federated Linear Learning (F²L²) framework that enables certified data removal in federated learning through a linear approximation of the model parameter space. The key contributions are: (1) A federated linear training algorithm that uses a first-order Taylor expansion to approximate the model as linear, allowing for efficient data removal via a Newton step; (2) A removal method (FedRemoval) that approximates the Hessian using publicly available server data, enabling removal without communication with other clients; (3) Theoretical guarantees on the difference between the removed model weights and weights obtained from retraining from scratch; (4) Extensive experiments on MNIST and Fashion-MNIST datasets demonstrating the effectiveness of F²L² in balancing model accuracy and information removal, outperforming baseline strategies and approaching retraining performance.

## Method Summary
The F²L² framework consists of three main steps: (1) Pretrain a DNN on server data to obtain initial weights; (2) Perform federated linear training using a Taylor expansion approximation with FedAvg; (3) Remove a client's data using FedRemoval, which approximates the Hessian with server data and performs a Newton step. The linear approximation allows efficient removal without retraining, while the Hessian approximation enables removal without client communication.

## Key Results
- F²L² achieves comparable accuracy and unlearning performance to retraining from scratch on MNIST and Fashion-MNIST.
- The method outperforms baseline strategies in balancing model accuracy and information removal.
- F²L² successfully defends against backdoor attacks while maintaining high accuracy.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear approximation of the model parameter space enables efficient data removal without retraining.
- Mechanism: The paper uses a first-order Taylor expansion to approximate the model as linear in the parameter space. This allows data removal via a simple Newton step instead of full retraining.
- Core assumption: The pretrained model is close enough to the optimal model for the linear approximation to be valid.
- Evidence anchors:
  - [abstract]: "F²L² considers a common practice of using pre-trained models to approximate DNN linearly, allowing them to achieve similar performance as the original networks via Federated Linear Training (FLT)."
  - [section]: "At a high level, we propose to use a linear approximation of a deep neural network (DNN) given by the first-order Taylor expansion... This approximation is equivalent to a kernel predictor with a kernel known as the neural tangent kernel (NTK)..."
- Break condition: If the pretrained model is too far from the optimal model, the linear approximation becomes inaccurate and removal performance degrades.

### Mechanism 2
- Claim: Hessian approximation using server data enables removal without client communication.
- Mechanism: Instead of computing the Hessian across all distributed data, the paper approximates it using publicly available server data from the pretrained model. This allows removal to be done solely between the server and target client.
- Core assumption: The server data is representative enough of the overall data distribution for the Hessian approximation to be effective.
- Evidence anchors:
  - [abstract]: "We also introduce FedRemoval, an efficient and effective removal strategy that tackles the computational challenges in FL by approximating the Hessian matrix using public server data from the pretrained model."
  - [section]: "To solve the computational issue, we estimate the Hessian based on the remaining dataset by the Hessian based on server data and update the weight via... The proposed approximation offers several advantages..."
- Break condition: If the server data is not representative (e.g., very different distribution), the Hessian approximation will be poor and removal will fail.

### Mechanism 3
- Claim: Theoretical guarantees on weight difference between removal and retraining.
- Mechanism: The paper provides an upper bound on the difference between model weights obtained from FedRemoval and weights obtained from retraining from scratch. This bound has three terms: error from FedAvg, error from SGD, and error from Hessian approximation.
- Core assumption: The bound accurately captures the true difference between the two methods.
- Evidence anchors:
  - [abstract]: "We provide theoretical guarantees by bounding the differences of model weights by our FedRemoval and that from retraining from scratch."
  - [section]: "We quantify the difference between wc− and bwr c theoretically. Theorem 2... The difference can be decomposed into... T1 corresponds to the error from FedAvg algorithm... T2 corresponds to the error from SGD algorithm... T3 is the error term induced by Hessian approximation..."
- Break condition: If the assumptions underlying the bound (e.g., IID data, bounded variance) are violated, the bound may not hold.

## Foundational Learning

- Concept: Federated Learning (FL)
  - Why needed here: The paper builds on FL as the base framework for collaborative model training across distributed clients.
  - Quick check question: What is the key difference between FL and centralized training? (Answer: In FL, data stays on client devices and only model updates are shared with a central server.)

- Concept: Machine Unlearning
  - Why needed here: The paper focuses on the specific problem of removing a client's data from an FL model, which is a form of machine unlearning.
  - Quick check question: How does machine unlearning differ from retraining from scratch? (Answer: Machine unlearning aims to efficiently remove the influence of specific data without full retraining, while retraining starts over with the remaining data.)

- Concept: Neural Tangent Kernel (NTK)
  - Why needed here: The linear approximation used in the paper is equivalent to a kernel predictor with the NTK, which is a key theoretical concept underlying the approach.
  - Quick check question: What happens to the linear approximation as the network width approaches infinity? (Answer: It becomes exact and remains valid throughout training.)

## Architecture Onboarding

- Component map: Pretrain -> Federated Linear Training -> FedRemoval
- Critical path: Pretrain → Federated Linear Training → FedRemoval
- Design tradeoffs:
  - Pretraining on server data adds overhead but enables linear approximation
  - Using a linear approximation enables efficient removal but may sacrifice some accuracy
  - Approximating the Hessian with server data enables removal without client communication but relies on server data being representative
- Failure signatures:
  - Pretraining fails: Model accuracy is poor even before any removal
  - Linear approximation fails: Removal doesn't significantly reduce unlearning accuracy or MIA success rate
  - Hessian approximation fails: Removal has large impact on remaining accuracy or test accuracy
- First 3 experiments:
  1. Train the linear model using Federated Linear Training and check that it achieves reasonable accuracy on MNIST/Fashion-MNIST
  2. Remove a client using FedRemoval and verify that unlearning accuracy decreases and remaining accuracy stays stable
  3. Compare the weights after FedRemoval to weights from retraining to check that the difference is within the theoretical bound

## Open Questions the Paper Calls Out
- Question: How does the choice of server dataset size impact the theoretical bound on the difference between the model weights obtained from FedRemoval and retraining from scratch?
  - Basis in paper: Explicit, Theorem 2 states that the difference bound includes a term involving the difference between gram matrices G(D-) and G(Ds), which depends on the server dataset size.
  - Why unresolved: The paper doesn't provide a detailed analysis of how varying the server dataset size affects the bound.
  - What evidence would resolve it: Empirical studies showing the relationship between server dataset size and the actual difference in model weights for various federated learning tasks.

- Question: What is the impact of non-IID data distribution among clients on the effectiveness of FedRemoval?
  - Basis in paper: Inferred, the paper assumes IID data distribution among clients, but real-world federated learning scenarios often involve non-IID data.
  - Why unresolved: The paper doesn't explore the performance of FedRemoval under non-IID data conditions.
  - What evidence would resolve it: Experiments comparing FedRemoval's performance on non-IID vs. IID data distributions in various federated learning tasks.

- Question: How does the choice of the linear approximation method affect the overall performance of the 2F2L framework?
  - Basis in paper: Explicit, the paper uses a first-order Taylor expansion for linear approximation, but other methods might exist.
  - Why unresolved: The paper doesn't compare the performance of 2F2L using different linear approximation methods.
  - What evidence would resolve it: Comparative studies of 2F2L using various linear approximation methods on different federated learning tasks.

## Limitations
- The linear approximation may not hold for all DNN architectures and datasets.
- The Hessian approximation using server data could introduce significant errors if the server data distribution differs from the federated data.
- The theoretical bounds rely on assumptions of IID data and bounded variance that may not hold in practice.

## Confidence
- Linear approximation mechanism: Medium
- Hessian approximation mechanism: Medium
- Theoretical guarantees: Low
- Experimental results: Medium

## Next Checks
1. Test F²L² on additional datasets with different data distributions to assess generalizability.
2. Analyze the sensitivity of removal performance to server data quantity and quality.
3. Evaluate the method's robustness to more sophisticated membership inference and backdoor attacks.