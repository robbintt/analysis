---
ver: rpa2
title: Lost in Translationese? Reducing Translation Effect Using Abstract Meaning
  Representation
arxiv_id: '2304.11501'
source_url: https://arxiv.org/abs/2304.11501
tags:
- translationese
- text
- translation
- translated
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper frames the novel task of translationese reduction, which
  aims to reduce the amount of translationese in human-translated text while preserving
  meaning. The authors propose a parse-then-generate approach using Abstract Meaning
  Representation (AMR) as an interlingua.
---

# Lost in Translationese? Reducing Translation Effect Using Abstract Meaning Representation

## Quick Facts
- arXiv ID: 2304.11501
- Source URL: https://arxiv.org/abs/2304.11501
- Reference count: 32
- Primary result: AMR-based approach reduces translationese while preserving meaning

## Executive Summary
This paper introduces translationese reduction as a novel task, aiming to make human-translated text sound more native while preserving meaning. The authors propose using Abstract Meaning Representation (AMR) as an interlingua, parsing translated sentences into semantic graphs and regenerating text from these graphs. Experiments on the ENNTT corpus show that the AMR approach increases lexical richness and reduces cohesive markers compared to original translations. Human evaluation indicates the output is slightly less fluent than original translations but maintains good semantic preservation. The work demonstrates that semantic abstraction through AMR can effectively address translationese patterns that syntactic approaches alone cannot resolve.

## Method Summary
The method uses a parse-then-generate pipeline where translated sentences are first parsed into AMR graphs using amrlib, then new sentences are generated from these graphs. This approach abstracts away from surface-level features that encode translationese patterns while preserving semantic meaning. The system is compared against round-trip machine translation and syntactically controlled generation baselines. The evaluation uses four quantitative measures: type-token ratio for lexical richness, cohesive markers count, Universal Dependencies average summed distance for processing complexity, and unigram bag-of-PoS for source language interference.

## Key Results
- AMR-based approach increases type-token ratio from 0.0890 to 0.1002, indicating greater lexical richness
- Cohesive markers decrease from 461 to 348 when using AMR as interlingua
- Round-trip translation through French actually exacerbates translationese rather than reducing it
- Human evaluation finds output slightly less fluent than original translations but maintains meaning (BERTscore 0.946)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AMR abstracts away from surface-level features that encode translationese patterns
- Mechanism: By parsing translated sentences into AMR graphs, the resulting representation loses surface-level cues like specific word order, function words, and syntactic patterns that are typical of translationese
- Core assumption: The features that distinguish translationese from native text are primarily surface-level and not encoded in the semantic meaning captured by AMR
- Evidence anchors:
  - [abstract] "AMR, a semantic representation which abstracts away from the surface form, can be used as an interlingua to reduce the amount of translationese"
  - [section] "AMR abstracts away from the surface form to isolate the semantic elements of the sentence. Function words and inflectional morphology are not captured in AMR graphs"
- Break condition: If semantic meaning alone doesn't capture what makes text sound native, or if AMR parsing introduces noise that creates new translationese-like patterns

### Mechanism 2
- Claim: Round-trip translation through a second language fails because it amplifies rather than reduces translationese
- Mechanism: The MT system has been trained on data that includes translationese, so when it re-translates the text, it may reinforce the translationese patterns rather than eliminate them
- Core assumption: Machine translation systems perpetuate translationese patterns present in their training data
- Evidence anchors:
  - [section] "Round-trip translation to French and back does not reduce the amount of translationese... but rather exacerbates it. Type-token ratio decreases from 0.0890 to 0.0850, the number of cohesive markers increases from 461 to 483"
- Break condition: If the MT system is trained on high-quality native text without translationese contamination, or if the round-trip translation goes through multiple diverse languages

### Mechanism 3
- Claim: Syntactically controlled generation fails because translationese is not purely a syntactic issue
- Mechanism: Simply changing the syntax to match native patterns doesn't address the semantic and lexical features that characterize translationese
- Core assumption: Translationese is caused by multiple factors beyond syntax, including semantic explicitation and lexical choices
- Evidence anchors:
  - [section] "The generated text does end up being fairly semantically similar to the semantic exemplars... This model is able to remove cohesive markers... Token-type-ratio decreases across generated text, which does not indicate a reduction in the presence of translationese"
- Break condition: If syntactic structure is the primary driver of translationese, or if semantic content could be preserved while forcing native-like syntax

## Foundational Learning

- Concept: Abstract Meaning Representation (AMR)
  - Why needed here: Understanding AMR is essential to grasp why it can serve as an interlingua for translationese reduction
  - Quick check question: What distinguishes AMR from other semantic representations like UCCA or PropBank?

- Concept: Translationese characteristics
  - Why needed here: To understand what specific features the AMR approach is targeting for reduction
  - Quick check question: What are the four quantitative measures used to detect translationese in this paper?

- Concept: Semantic vs. syntactic processing
  - Why needed here: To understand why syntactic-only approaches (like controlled generation) fail while semantic approaches succeed
  - Quick check question: According to the paper, what happens to type-token ratio when using AMR as an interlingua versus syntactic control?

## Architecture Onboarding

- Component map: Input text → AMR parser → AMR graph → Text generator → Output text
- Critical path: The parse-then-generate pipeline where errors in either step can propagate to the final output
- Design tradeoffs: Using AMR as an interlingua sacrifices some syntactic naturalness for semantic preservation; requires two model components (parser and generator) rather than one
- Failure signatures: Output text has semantic drift (meaning changes), fluency issues from AMR generation, or persistent translationese markers
- First 3 experiments:
  1. Run the full parse-then-generate pipeline on a small set of translated sentences and compare TTR and cohesive marker counts to the originals
  2. Test AMR parsing and generation separately by parsing native sentences and checking if generated text maintains meaning
  3. Compare the AMR-based approach against a round-trip translation baseline on the same input to verify the exacerbation claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific syntactic features distinguish translationese from native text, and can these be quantified independently of semantic content?
- Basis in paper: [explicit] The paper discusses syntactic interference from source languages and over-normalization to target language, but doesn't isolate specific syntactic features that could be measured separately from semantic content
- Why unresolved: While the paper mentions syntactic differences, it doesn't systematically identify or measure specific syntactic constructions that characterize translationese
- What evidence would resolve it: A detailed linguistic analysis identifying specific syntactic constructions (e.g., specific word order patterns, preposition usage, clause structures) that are statistically more common in translationese versus native text

### Open Question 2
- Question: How does the effectiveness of AMR-based translationese reduction vary across different source languages and language families?
- Basis in paper: [explicit] The authors note their experiments used only European languages and acknowledge this as a limitation
- Why unresolved: The paper only tested on European languages, leaving open whether the approach works equally well for non-European language pairs
- What evidence would resolve it: Systematic testing of the AMR-based approach across diverse language pairs including Asian, African, and other language families, measuring reduction in translationese features

### Open Question 3
- Question: What is the relationship between translationese reduction and downstream NLP task performance (e.g., NLI, QA, summarization)?
- Basis in paper: [inferred] The paper mentions that translationese can affect model performance but doesn't empirically test whether reducing translationese improves downstream task performance
- Why unresolved: While the paper demonstrates reduction in translationese metrics, it doesn't validate whether this translates to better performance on actual NLP tasks
- What evidence would resolve it: Experiments showing improvements in specific downstream NLP tasks when using AMR-processed translations versus original translations

## Limitations

- The evaluation focuses primarily on quantitative metrics and BERTscore rather than comprehensive human evaluation of naturalness and idiomaticity
- Round-trip translation baseline uses French as intermediate language, making comparison somewhat unfair to the AMR approach
- The paper doesn't address whether generated text sounds more native in terms of collocations and idiomatic expressions
- AMR parser and generator are black boxes whose errors could compound without detailed error analysis

## Confidence

**High confidence**: The claim that AMR-based approach increases lexical richness (TTR increases from 0.0890 to 0.1002) and reduces cohesive markers (from 461 to 348) is supported by direct quantitative evidence from the ENNTT corpus experiments.

**Medium confidence**: The claim that round-trip translation exacerbates translationese rather than reducing it is plausible but could be influenced by the specific choice of French as the intermediate language and the quality of the MT system used.

**Medium confidence**: The claim that syntactic control alone is insufficient for translationese reduction is supported by the experiments, though the specific baseline method (Parse-and-Generate with syntactic control) may not represent the full space of possible syntactic approaches.

## Next Checks

1. **Error Analysis**: Conduct a detailed error analysis of the AMR parse-then-generate pipeline, categorizing types of errors (semantic drift, fluency issues, persistent translationese markers) and measuring their frequency to understand the approach's limitations.

2. **Round-trip Translation Comparison**: Re-run the round-trip translation baseline using English as the intermediate language (back-translation) rather than French, and compare results to the AMR approach to determine if the observed exacerbation is specific to cross-linguistic transfer or a general property of round-trip translation.

3. **Native-like Evaluation**: Design a human evaluation study that specifically measures whether the generated text sounds more native-like in terms of collocations, idiomatic expressions, and naturalness, beyond just fluency and semantic preservation.