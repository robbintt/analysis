---
ver: rpa2
title: Understanding In-Context Learning from Repetitions
arxiv_id: '2310.00297'
source_url: https://arxiv.org/abs/2310.00297
tags:
- learning
- answer
- in-context
- reinforcement
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates in-context learning (ICL) in large language
  models (LLMs) through the lens of surface pattern repetition. It introduces the
  concept of "token co-occurrence reinforcement," where the connection between two
  tokens strengthens with repeated co-occurrence in context.
---

# Understanding In-Context Learning from Repetitions

## Quick Facts
- arXiv ID: 2310.00297
- Source URL: https://arxiv.org/abs/2310.00297
- Authors: 
- Reference count: 40
- One-line primary result: Surface pattern repetition in demonstrations guides ICL but can introduce spurious connections that lead to errors

## Executive Summary
This paper investigates in-context learning (ICL) in large language models through the lens of surface pattern repetition. The authors introduce the concept of "token co-occurrence reinforcement," where repeated co-occurrence of tokens in context strengthens their connection and influences model predictions. They demonstrate both the beneficial effects of this mechanism in constraining output space and following learned patterns, as well as its detrimental effects when introducing spurious connections that lead to errors. Experiments on datasets like MMLU and GSM8K reveal the dual nature of token co-occurrence reinforcement in ICL.

## Method Summary
The study employs self-reinforcement experiments with repeated phrases and token co-occurrence patterns, masked and perturbed demonstrations to isolate surface pattern effects, and analysis of both beneficial (constraining output space, pattern following) and detrimental (spurious connections) effects. The experiments use datasets MMLU (18 tasks, 1140 samples) and GSM8K, with LLaMA models (7B, 13B, 30B, 65B) and OPT (125M-30B). The research varies the number of demonstrations and analyzes effects on accuracy and pattern following.

## Key Results
- Token co-occurrence reinforcement strengthens connections between tokens based on repeated contextual co-occurrence
- Surface patterns from demonstrations guide ICL by constraining output space and helping models follow learned patterns
- Token reinforcement has dual impacts - beneficial for constraining output space but detrimental when introducing spurious connections

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Token co-occurrence reinforcement strengthens connections between tokens based on repeated contextual co-occurrence
- Mechanism: When two tokens appear together multiple times in context, the model increases the probability of generating one token after the other. This forms a reinforcement loop where each repetition strengthens the connection.
- Core assumption: The model learns statistical associations from repeated token patterns rather than deep semantic understanding.
- Evidence anchors:
  - [abstract] "empirically establish the existence of token co-occurrence reinforcement, a principle that strengthens the relationship between two tokens based on their contextual co-occurrences"
  - [section] "We empirically establish the existence of the token co-occurrence reinforcement, where the connection between any two tokens gets reinforced with the number of contextual co-occurrences"
  - [corpus] Found 25 related papers; average neighbor FMR=0.405 (moderate similarity)
- Break condition: If the context changes dramatically or if the model encounters truly novel token combinations not seen in training, the reinforcement effect would weaken.

### Mechanism 2
- Claim: Surface patterns from demonstrations guide in-context learning by constraining output space and helping models follow learned patterns
- Mechanism: Demonstrations provide repeated surface patterns (like "Answer:" → "True/False" or "Input:" → label words) that the model learns to reproduce. These patterns act as features that guide generation.
- Core assumption: The model prioritizes surface-level pattern matching over deeper task understanding when making predictions.
- Evidence anchors:
  - [abstract] "surface patterns from demonstrations guide ICL by constraining output space and helping models follow learned patterns"
  - [section] "the same LLaMA model makes the incorrect prediction 'True' given the input 'Circulation revenue has decreased by 5% in Finland.' which is likely because of the repeated pattern 'Answer:' -> 'True' from the demonstrations"
  - [corpus] "Repetition In Repetition Out: Towards Understanding Neural Text Degeneration from the Data Perspective" suggests related work on repetition effects
- Break condition: If demonstrations contain contradictory or ambiguous patterns, the model may fail to learn consistent guidance.

### Mechanism 3
- Claim: Token reinforcement has dual impacts - beneficial for constraining output space but detrimental when introducing spurious connections
- Mechanism: While reinforcement helps the model learn to output specific labels or follow formatting patterns, it can also create unintended associations between unrelated tokens that lead to errors.
- Core assumption: The same mechanism that enables learning from demonstrations can also cause overfitting to surface features.
- Evidence anchors:
  - [abstract] "it also reveals that these same patterns can introduce spurious connections, leading to errors in predictions"
  - [section] "We see that the non-informative connection overcomes the selection bias and significantly elevates the accuracy choice D with a noticeable gap, in the cost of accuracy of A, B, and C"
  - [corpus] "Scaling Laws and In-Context Learning: A Unified Theoretical Framework" suggests related work on scaling effects
- Break condition: If the dataset contains balanced or diverse demonstrations that don't reinforce spurious connections, the detrimental effects would be minimized.

## Foundational Learning

- Concept: Statistical learning from token co-occurrences
  - Why needed here: The entire mechanism relies on the model learning statistical associations between tokens that appear together repeatedly
  - Quick check question: If a token pair appears together 100 times in training data versus 10 times, how would you expect their conditional probability to differ?

- Concept: Pattern matching in autoregressive generation
  - Why needed here: The model generates text by predicting the next token based on learned patterns, making pattern matching fundamental to the mechanism
  - Quick check question: In an autoregressive model, if "Answer:" is followed by "True" in 90% of training examples, what probability would you expect for "True" given "Answer:"?

- Concept: Surface feature vs. semantic understanding distinction
  - Why needed here: The paper shows that ICL often relies on surface patterns rather than deep semantic comprehension
  - Quick check question: Can you think of an example where a model might correctly answer based on surface patterns but fail on semantically similar questions?

## Architecture Onboarding

- Component map: Demonstrations -> Token co-occurrence reinforcement -> Pattern-guided generation -> Output prediction
- Critical path: Demonstrations → Token co-occurrence reinforcement → Pattern-guided generation → Output prediction. The reinforcement step is where the statistical learning occurs.
- Design tradeoffs: The architecture trades deep semantic understanding for surface pattern matching efficiency. This enables fast adaptation but can lead to spurious connections.
- Failure signatures: Spurious connections manifest as systematic errors on semantically similar questions, over-reliance on formatting patterns, or inability to generalize beyond demonstrated patterns.
- First 3 experiments:
  1. Test token reinforcement with simple repeated phrases to verify the basic mechanism
  2. Test whether masking demonstration content affects performance to isolate surface vs. semantic learning
  3. Test the effect of adding non-informative patterns to demonstrations to demonstrate spurious connections

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the token co-occurrence reinforcement effect be mitigated or controlled to prevent spurious connections in in-context learning?
- Basis in paper: [inferred] The paper discusses how token co-occurrence reinforcement can lead to spurious connections and unintended outcomes in in-context learning, suggesting the need for mitigation strategies.
- Why unresolved: The paper highlights the potential risks of token co-occurrence reinforcement but does not provide specific solutions or strategies to address these issues.
- What evidence would resolve it: Research demonstrating effective methods to mitigate or control the token co-occurrence reinforcement effect, such as novel training techniques or architectural modifications, would provide a resolution.

### Open Question 2
- Question: What are the underlying reasons for the existence of token co-occurrence reinforcement in large language models?
- Basis in paper: [inferred] The paper notes that the cross-entropy objective introduces no inductive bias for token co-occurrence reinforcement, yet it exists and plays a significant role in in-context learning.
- Why unresolved: The paper identifies the presence of token co-occurrence reinforcement but does not explore the theoretical or empirical reasons behind its existence.
- What evidence would resolve it: Studies that investigate the internal mechanisms of large language models, such as detailed analysis of training dynamics or theoretical models, could provide insights into why token co-occurrence reinforcement occurs.

### Open Question 3
- Question: How does the semantic relationship between tokens affect the strength and nature of token co-occurrence reinforcement?
- Basis in paper: [explicit] The paper conducts experiments showing that tokens with different semantic relationships (e.g., same tokens, similar tokens, random tokens) exhibit varying levels of reinforcement, but the underlying reasons are not fully explored.
- Why unresolved: While the paper demonstrates differences in reinforcement based on semantic relationships, it does not delve into the specific factors or mechanisms that influence these variations.
- What evidence would resolve it: Empirical studies that systematically analyze the impact of different semantic relationships on token co-occurrence reinforcement, possibly through controlled experiments or computational models, would help clarify the underlying factors.

## Limitations
- Reliance on observational analysis rather than interventional experiments that could definitively establish causality
- Focus on relatively simple classification tasks and mathematical reasoning, leaving uncertainty about generalization to more complex tasks
- Limited exploration of how different model architectures might exhibit different reinforcement behaviors

## Confidence

**High confidence:** The empirical demonstration that repeated token patterns in demonstrations influence model outputs is well-supported by the experiments.

**Medium confidence:** The claim that ICL primarily operates through surface pattern matching rather than semantic understanding is plausible but not definitively proven.

**Low confidence:** The specific mechanism of "token co-occurrence reinforcement" as a fundamental principle distinct from general statistical learning in language models is not clearly established.

## Next Checks
1. **Ablation study on pattern importance:** Systematically remove or randomize specific patterns in demonstrations (while preserving semantic content) to quantify how much performance depends on exact surface patterns versus semantic similarity.

2. **Cross-linguistic validation:** Test whether the same reinforcement effects appear when demonstrations and test prompts are in different languages, or when using code-switched inputs.

3. **Intervention on training data:** Train language models with controlled variations in token co-occurrence frequencies in the training data, then test whether ICL performance scales with these frequencies.