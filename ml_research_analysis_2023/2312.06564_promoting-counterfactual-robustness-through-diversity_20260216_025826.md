---
ver: rpa2
title: Promoting Counterfactual Robustness through Diversity
arxiv_id: '2312.06564'
source_url: https://arxiv.org/abs/2312.06564
tags:
- counterfactual
- dice
- ours
- distance
- counterfactuals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of generating robust counterfactual
  explanations for black-box models, where minor input perturbations should not lead
  to drastically different explanations. The core method idea involves reporting multiple
  diverse counterfactuals instead of a single one, using an approximation algorithm
  that incrementally builds a set of counterfactuals while filtering candidates based
  on a diversity criterion.
---

# Promoting Counterfactual Robustness through Diversity

## Quick Facts
- arXiv ID: 2312.06564
- Source URL: https://arxiv.org/abs/2312.06564
- Reference count: 33
- Primary result: A diversity-based approximation algorithm outperforms DiCE in generating robust counterfactual explanations while maintaining competitive computational performance

## Executive Summary
This paper addresses the fundamental problem of counterfactual explanation robustness - the tendency for explanations to change drastically under minor input perturbations. The authors propose a novel approach that generates multiple diverse counterfactuals instead of a single explanation, using an approximation algorithm with diversity filtering. The method is evaluated across five binary classification datasets and consistently demonstrates improved robustness compared to the state-of-the-art DiCE algorithm, while also providing theoretical guarantees for certain types of counterfactuals.

## Method Summary
The method generates robust counterfactual explanations by returning a diverse set of counterfactuals rather than a single one. It uses an approximation algorithm that incrementally builds a set of counterfactuals while filtering candidates based on diversity criteria (angle-based or distance-based). For each candidate, a binary search finds the closest counterfactual on the line segment to the reference point. The approach is compared against DiCE, a gradient-based method for diverse counterfactual generation, across five binary classification datasets using neural network classifiers.

## Key Results
- The proposed method consistently achieves lower set distances between counterfactuals for original and perturbed inputs compared to DiCE
- Angle-based diversity filtering outperforms distance-based filtering in maintaining diversity while preserving robustness
- The approximation algorithm provides competitive runtime performance while improving robustness metrics
- Validity remains at 100% across all datasets, ensuring generated counterfactuals actually change classification outcomes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Returning multiple diverse counterfactuals instead of a single one improves robustness by covering the local decision boundary region.
- Mechanism: When an input is near multiple decision boundaries, returning several counterfactuals ensures at least one remains valid under small perturbations. The algorithm builds a set incrementally while filtering candidates based on diversity to avoid redundancy.
- Core assumption: The set of all ϵ-approximate counterfactuals (Eϵ_exh) provides robustness guarantees, and a diverse subset can approximate this set while remaining practically small.
- Evidence anchors:
  - [abstract]: "some interesting robustness guarantees can be given by reporting multiple rather than a single counterfactual"
  - [section]: "One intuitive idea to overcome this fundamental problem is to report multiple counterfactuals instead of a single one"
  - [corpus]: Weak evidence - neighboring papers discuss robustness to model change but not the diversity-based approximation mechanism
- Break condition: If the diversity criterion is too strict or the approximation algorithm fails to capture the boundary region adequately, robustness may not improve.

### Mechanism 2
- Claim: The exhaustive explainer Eϵ_exh is weakly ϵ/2-robust for strong counterfactuals.
- Mechanism: For any input x1 with a strong counterfactual c1, if another input x2 is within ϵ/2 distance, then c1 remains an ϵ-approximate counterfactual for x2. This follows from the triangle inequality and the definition of counterfactual distance.
- Core assumption: The distance measure satisfies symmetry and the triangle inequality.
- Evidence anchors:
  - [section]: "Proposition 1. If d satisfies Symmetry and the Triangle Inequality, then Eϵ_exh is weakly ϵ/2-robust"
  - [section]: "we can conclude that cfd(x1) ≤ d(x1, x2) + cfd(x2)"
  - [corpus]: No direct evidence - this is a theoretical result specific to this work
- Break condition: If the distance measure does not satisfy the required properties, the robustness guarantee fails.

### Mechanism 3
- Claim: δ-safe counterfactuals provide δ/2-robustness guarantees.
- Mechanism: A counterfactual that is δ-safe (close to being a strong counterfactual) remains in the exhaustive explainer when moving by less than δ/2 from the reference point. This extends robustness beyond just strong counterfactuals.
- Core assumption: The triangle inequality holds for the distance measure.
- Evidence anchors:
  - [section]: "Proposition 2. Suppose that d satisfies Symmetry and the Triangle Inequality. If c ∈ Eϵ_exh(Cl, x) is δ-safe, then for all x′ ∈ D such that Cl(x) = Cl(x′) and d(x, x′) < δ/2, we have c ∈ Eϵ_exh(Cl, x′)"
  - [section]: "we have d(x′, c) ≤ d(x′, x) + d(x, c) = δ/2 + (cfd(x) + ϵ − δ)"
  - [corpus]: No direct evidence - this is a novel theoretical contribution
- Break condition: If the counterfactual is not sufficiently close to a strong counterfactual (δ is too small), the robustness guarantee may not hold.

## Foundational Learning

- Concept: Counterfactual explanations
  - Why needed here: The entire paper is about improving the robustness of counterfactual explanations
  - Quick check question: What is the difference between a strong counterfactual and an ϵ-approximate counterfactual?

- Concept: Robustness in explanations
  - Why needed here: The paper addresses the problem of explanations changing drastically with minor input perturbations
  - Quick check question: How does the paper formalize robustness using set distances between counterfactuals?

- Concept: Diversity filtering algorithms
  - Why needed here: The approximation algorithm uses diversity criteria to select a compact set of counterfactuals
  - Quick check question: What are the two diversity criteria considered in the algorithm (angle-based and distance-based)?

## Architecture Onboarding

- Component map:
  Input preprocessing -> Distance computation -> Candidate selection -> Diversity filtering -> Counterfactual generation -> Output set

- Critical path:
  1. Compute distances from input to all examples in dataset
  2. Filter to closest candidates based on distance threshold
  3. Apply diversity criterion to reduce redundancy
  4. For each remaining candidate, perform binary search to find counterfactual
  5. Return set of counterfactuals

- Design tradeoffs:
  - Number of counterfactuals vs. diversity: More counterfactuals provide better coverage but increase cognitive load
  - Angle-based vs. distance-based diversity: Angle-based may capture different directions better, distance-based ensures spatial separation
  - Minimization in binary search: Improves proximity but may reduce diversity of the final set

- Failure signatures:
  - Poor robustness: Set distance between original and perturbed inputs remains high
  - Low diversity: Many counterfactuals are very similar despite filtering
  - High computational cost: Runtime significantly exceeds that of baseline methods
  - Low validity: Generated counterfactuals do not actually change the classification outcome

- First 3 experiments:
  1. Generate counterfactuals for a simple 2D classification problem with clear boundaries and test robustness to perturbations
  2. Compare angle-based vs. distance-based diversity filtering on a small dataset
  3. Measure the effect of removing minimization in the binary search on diversity and robustness metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed approximation algorithm guarantee epsilon-robustness for epsilon-approximate counterfactuals that are not strong?
- Basis in paper: [explicit] The paper states "we cannot give a general robustness guarantee for epsilon-approximate counterfactuals that are not strong" and provides Example 2 showing this limitation.
- Why unresolved: The paper identifies this as a fundamental limitation of the exhaustive explainer and the approximation algorithm, noting that boundary counterfactuals are always lost when making arbitrarily small steps away from them.
- What evidence would resolve it: A theoretical proof showing either that epsilon-robustness cannot be guaranteed for non-strong epsilon-approximate counterfactuals, or an algorithm modification that can guarantee epsilon-robustness for all epsilon-approximate counterfactuals.

### Open Question 2
- Question: What is the optimal tradeoff between diversity and robustness in the approximation algorithm?
- Basis in paper: [inferred] The paper mentions that diversity-based filtering is used to select a compact set of counterfactuals, but notes that "the diversity of our counterfactuals is affected by the minimisation of Step 4, which brings counterfactuals closer together thus leading to a decrease in k-diversity."
- Why unresolved: The paper presents experimental results showing a possible tension between diversity and robustness, but does not provide a theoretical framework for determining the optimal balance between these competing objectives.
- What evidence would resolve it: A theoretical analysis quantifying the relationship between diversity metrics (angle-based or distance-based) and robustness measures, along with experimental validation showing how different diversity parameters affect both objectives.

### Open Question 3
- Question: Can the approximation algorithm be extended to guarantee robustness for other distance measures beyond Euclidean and Manhattan distances?
- Basis in paper: [explicit] The paper states "Let us note that the example can be generalized to many other non-linear classification settings" when discussing the fundamental limitations of single counterfactual explainers.
- Why unresolved: While the paper provides theoretical analysis for the exhaustive explainer using general distance measures, the approximation algorithm is only evaluated experimentally with L1 and L2 distances.
- What evidence would resolve it: Theoretical proofs extending the robustness guarantees of the approximation algorithm to other distance measures, along with experimental validation on classification problems using different distance metrics.

## Limitations

- The theoretical robustness guarantees only apply to strong counterfactuals and δ-safe counterfactuals, not to all ϵ-approximate counterfactuals
- The method's effectiveness depends heavily on proper parameter tuning of diversity filtering thresholds
- The experimental validation is limited to binary classification tasks with relatively small datasets

## Confidence

- Mechanism 1 (Diversity-based robustness): Medium - The intuition is sound, but the approximation algorithm's effectiveness depends heavily on parameter tuning and the specific structure of decision boundaries
- Mechanism 2 (Exhaustive explainer robustness): High - This is a theoretical result with a clear mathematical proof based on triangle inequality
- Mechanism 3 (δ-safe counterfactuals): Medium - The theoretical guarantee is valid, but practical effectiveness depends on finding counterfactuals that are sufficiently close to strong counterfactuals

## Next Checks

1. Test the method on multi-class classification problems to verify if diversity-based robustness generalizes beyond binary cases
2. Evaluate the impact of different distance metrics (e.g., cosine distance) on the robustness guarantees and algorithmic performance
3. Assess the method's behavior with noisy or adversarial inputs to determine if diversity-based approaches provide meaningful robustness in challenging scenarios