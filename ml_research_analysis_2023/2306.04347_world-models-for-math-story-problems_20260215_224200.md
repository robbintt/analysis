---
ver: rpa2
title: World Models for Math Story Problems
arxiv_id: '2306.04347'
source_url: https://arxiv.org/abs/2306.04347
tags:
- world
- quantity
- have
- problems
- entity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces MATHWORLD, a graph-based formalism for representing
  math story problems. It annotates a dataset of 1,019 problems and 3,204 logical
  forms, then demonstrates three use cases: prompting language models with synthetically
  generated questions to probe reasoning, generating new problems from world models,
  and developing interpretable solvers.'
---

# World Models for Math Story Problems

## Quick Facts
- arXiv ID: 2306.04347
- Source URL: https://arxiv.org/abs/2306.04347
- Authors: 
- Reference count: 40
- Key outcome: MATHWORLD improves LLM reasoning on math story problems by using synthetic intermediate questions, but GPT-3 struggles with these even when solving final questions correctly.

## Executive Summary
This paper introduces MATHWORLD, a graph-based semantic formalism for representing math story problems. The authors annotate a dataset of 1,019 problems and 3,204 logical forms, then demonstrate three use cases: improving LLM reasoning through synthetic questions, generating new problems from world models, and developing interpretable solvers. Key findings show GPT-3 benefits from synthetic questions in prompts and achieves improved accuracy, though it struggles with intermediate reasoning steps even when final answers are correct.

## Method Summary
The paper develops MATHWORLD as a directed graph formalism with containers (entities, quantities, units) and four relation types (transfer, rate, comparison, part-whole). The approach involves three phases: annotating math story problems with world models, using these models to generate synthetic intermediate questions, and evaluating LLM performance on original and synthetic questions through in-context learning. The method tests three prompt types (all at once, sentence-by-sentence, original only) across multiple LLMs including GPT-3, GPT-2, BART, Codex, T5, and NT5.

## Key Results
- GPT-3 benefits from synthetic question-answer pairs in prompts, improving accuracy on math story problems
- For problems where GPT-3 answers final questions correctly, it can only answer 64% of intermediate synthetic questions
- MATHWORLD achieves improved accuracy compared to baseline approaches on combined test sets from MAWPS, ASD IV-A, and SVAMP datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph-based world models enable interpretable reasoning by decomposing math story problems into containers and relations
- Mechanism: Directed graph structure captures semantic dependencies and equations implicitly, allowing symbolic parsing and deterministic solving
- Core assumption: Math story problems can be faithfully represented using four basic arithmetic relations and container schema
- Evidence anchors: [abstract] consolidation of previous work on math story problem representation; [section] directed graph as world model; [corpus] weak - no direct citations found

### Mechanism 2
- Claim: Incremental sentence-by-sentence parsing enables robust alignment between text and graph updates
- Mechanism: Building world model incrementally maps each sentence's contribution to distinct subgraph, preserving context
- Core assumption: Sentences are largely independent once coreferences and elliptical constructions are resolved
- Evidence anchors: [section] incremental assignment of logical forms to sentences; [section] external worker annotation following three phases; [corpus] moderate - related work on semantic parsing shows incremental approaches work

### Mechanism 3
- Claim: Synthetic question-answer pairs improve LLM reasoning by scaffolding intermediate inference steps
- Mechanism: Generating intermediate questions probes container states or relation outcomes, providing explicit reasoning guidance
- Core assumption: LLMs benefit from structured intermediate reasoning cues even when final answers are correct
- Evidence anchors: [section] empirical evidence that GPT-3 benefits from structured knowledge; [section] GPT-3 answers 64% of intermediate questions correctly when final questions are correct; [corpus] weak - related papers support prompting but not MATHWORLD-specific

## Foundational Learning

- Concept: Directed graph semantics with containers and relations
  - Why needed here: Core to representing math story problems as structured world models
  - Quick check question: What are the four relation types in MATHWORLD and what equations do they induce?

- Concept: Semantic parsing of incremental logical forms
  - Why needed here: Enables alignment between problem text and world model construction
  - Quick check question: How does the model ensure containers and relations are added in the order they appear in text?

- Concept: First-order logic expressibility of MATHWORLD
  - Why needed here: Allows formal comparison with other semantic formalisms and proof of expressiveness bounds
  - Quick check question: What limitations does MATHWORLD have compared to full first-order logic?

## Architecture Onboarding

- Component map: Corpus → annotation tool → JSON graph storage → Text → incremental logical forms → world model graph → World model + reference var → numeric answer → World model → natural language problem
- Critical path: Annotation → parsing → reasoning → evaluation
- Design tradeoffs: Incremental parsing trades complexity for interpretability; synthetic Q&A trades generation effort for improved LLM reasoning; formal logic expressibility trades coverage for simplicity
- Failure signatures: Incomplete world models (underdetermined equations); syntactic/semantic mismatches in logical forms; LLM reliance on heuristics despite correct answers
- First 3 experiments: 1) Implement and evaluate Codex parser on MAWPS/ASD IV-A test sets; 2) Test synthetic Q&A prompting on GPT-3 with zero/one-shot settings; 3) Generate and evaluate paraphrased problems from test set world models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can we develop stronger semantic parsers for MATHWORLD that can reliably handle challenging cases mentioned in Appendix G?
- Basis in paper: Inferred from discussion of difficult parsing cases in Appendix G
- Why unresolved: Existing models struggle with complex cases requiring further research and innovation
- What evidence would resolve it: A semantic parser that accurately parses a wide range of MATHWORLD problems including those with complex structures

### Open Question 2
- Question: How can we extend MATHWORLD to handle more complex mathematical operations beyond four basic arithmetic operators?
- Basis in paper: Explicit mention of limitation to four basic arithmetic operators
- Why unresolved: Extending formalism requires careful consideration of representing and reasoning about complex operations within graph structure
- What evidence would resolve it: Formal extension of MATHWORLD handling more complex operations with examples of accurately represented and solved problems

### Open Question 3
- Question: Can we leverage MATHWORLD to develop more effective methods for generating math story problems that are both challenging and pedagogically valuable?
- Basis in paper: Inferred from discussion of using MATHWORLD as design space for generating new problems in Section 5.3
- Why unresolved: While paper demonstrates potential for generating problems, further research needed to develop methods producing problems with desired properties
- What evidence would resolve it: Method for generating math story problems using MATHWORLD that consistently produces problems with desired properties, with evaluation of pedagogical value

## Limitations

- MATHWORLD's reliance on four basic arithmetic relations may not capture complex mathematical structures like nested set definitions
- Annotation process depends heavily on human judgment for coreference resolution and entity attribution, introducing potential consistency issues
- Synthetic question generation assumes intermediate reasoning steps are both necessary and sufficient for improving LLM performance, but this relationship is only empirically demonstrated for GPT-3

## Confidence

- High Confidence: MATHWORLD provides interpretable representation for math story problems; GPT-3 struggles with intermediate questions while solving final questions correctly
- Medium Confidence: Synthetic question-answer pairs improve LLM reasoning (effect size and generalizability unclear); MATHWORLD can be expressed in first-order logic (theoretically sound but not rigorously proven)
- Low Confidence: MATHWORLD captures full semantic complexity of math story problems (limited by absence of evaluation on problems requiring higher-order arithmetic)

## Next Checks

1. **Expressiveness Boundary Test**: Systematically evaluate MATHWORLD's ability to represent problems requiring higher-order arithmetic operations or nested set definitions, documenting failure cases and limitations

2. **Generalization Across LLMs**: Replicate synthetic question prompting experiments with multiple LLM architectures (including open-source models) to determine whether observed benefits for GPT-3 extend to other model families and sizes

3. **Parser Robustness Analysis**: Conduct ablation studies on incremental parsing approach by introducing controlled variations in sentence order, coreference ambiguity, and entity attribution to quantify parser's sensitivity to these factors and identify failure modes