---
ver: rpa2
title: Distributionally Robust Post-hoc Classifiers under Prior Shifts
arxiv_id: '2309.08825'
source_url: https://arxiv.org/abs/2309.08825
tags:
- drops
- worst
- prior
- learning
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies improving distributional robustness of pre-trained
  models under controlled prior shifts. It proposes DROPS, a lightweight post-hoc
  method that learns scaling adjustments to model predictions using a held-out validation
  set, allowing the same pre-trained model to be reused for different robustness requirements.
---

# Distributionally Robust Post-hoc Classifiers under Prior Shifts

## Quick Facts
- arXiv ID: 2309.08825
- Source URL: https://arxiv.org/abs/2309.08825
- Reference count: 40
- Primary result: DROPS achieves 89.17% average class accuracy, 86.20% 1.0-worst case accuracy, and 82.22% worst class accuracy on CIFAR-10 with imbalance ratio 10

## Executive Summary
This paper proposes DROPS, a post-hoc method for improving distributional robustness of pre-trained models under controlled prior shifts. DROPS learns scaling adjustments to model predictions using a held-out validation set, allowing the same pre-trained model to be reused for different robustness requirements. The method optimizes a distributionally robust loss within a δ-radius ball around a target distribution, providing finer control over the trade-off between average and worst-case accuracy. On standard benchmarks for class imbalance and group distributionally robust optimization, DROPS outperforms existing methods when evaluated on a range of distribution shifts away from the target prior.

## Method Summary
DROPS is a lightweight post-hoc method that learns scaling adjustments to model predictions using a held-out validation set. The key idea is to optimize a distributionally robust loss within a δ-radius ball around a target distribution, allowing for finer control over the trade-off between average and worst-case accuracy. DROPS computes scaling factors for each class based on the difference between target and empirical class priors, and these scaling factors are learned to minimize the distributionally robust loss. At test time, the learned scaling adjustments are applied to the model predictions, enabling the same pre-trained model to be reused for different robustness requirements without retraining.

## Key Results
- DROPS achieves 89.17% average class accuracy, 86.20% 1.0-worst case accuracy, and 82.22% worst class accuracy on CIFAR-10 with imbalance ratio 10
- DROPS provides finer control over the trade-off between average and worst-case accuracy compared to existing methods by varying the δ parameter
- DROPS outperforms existing methods on standard benchmarks for class imbalance and group distributionally robust optimization when evaluated on a range of distribution shifts away from the target prior

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: DROPS improves distributional robustness by learning scaling adjustments to model predictions using a constrained optimization problem on a validation set.
- **Mechanism**: DROPS computes scaling factors for each class based on the difference between target and empirical class priors. These scaling factors are learned to minimize a distributionally robust loss within a δ-radius ball around the target distribution. The learned scaling is then applied post-hoc during test time.
- **Core assumption**: The pre-trained model's conditional-class probability estimates are reasonably well-calibrated, and scaling adjustments can effectively adapt the model to different robustness requirements without retraining.
- **Evidence anchors**:
  - [abstract]: "DROPS, a lightweight post-hoc method that learns scaling adjustments to model predictions using a held-out validation set"
  - [section 4.2]: "DROPS can be naturally adapted to this setting by learning multiple sets of scaling adjustments, one for each attribute type"
- **Break condition**: If the pre-trained model's probability estimates are severely miscalibrated or if the scaling adjustments cannot adequately compensate for large distribution shifts, DROPS may fail to improve robustness.

### Mechanism 2
- **Claim**: DROPS provides finer control over robustness properties compared to existing methods by optimizing for a spectrum of controlled distribution shifts.
- **Mechanism**: DROPS optimizes a distributionally robust objective that seeks the worst-case performance within a δ-radius ball around the target distribution. This allows interpolation between average accuracy (δ=0) and worst-case accuracy (δ→∞), providing more control than methods optimizing only for average or worst-case performance.
- **Core assumption**: The distributionally robust objective captures the desired trade-off between average and worst-case performance for the specific application.
- **Evidence anchors**:
  - [abstract]: "Our work is motivated by the need for finer control over the robustness properties of the model"
  - [section 3]: "Instead of taking the conventional approach of optimizing for either the average accuracy or the worst-case accuracy, we seek to maximize the minimum accuracy within a δ-radius ball around the specified target distribution"
- **Break condition**: If the δ-radius ball does not adequately represent the range of distribution shifts encountered in practice, DROPS may not achieve the desired robustness.

### Mechanism 3
- **Claim**: DROPS is more efficient than existing DRO methods as it only requires group annotations for a smaller held-out set and works by only scaling model predictions at test time.
- **Mechanism**: Unlike methods that train all model parameters using the robust optimization loss, DROPS only needs to learn scaling adjustments on a validation set. This reduces the computational cost and data requirements compared to full model retraining.
- **Core assumption**: The pre-trained model has learned useful features that can be adapted through scaling adjustments, and the validation set is representative of the target distribution.
- **Evidence anchors**:
  - [abstract]: "A key advantage of our method is that it is able to reuse the same pretrained model for different robustness requirements by simply scaling the model predictions"
  - [section 4.4]: "Our approach only needs group annotations for a smaller held-out set and works by only scaling the model predictions of a pre-trained model at test time"
- **Break condition**: If the pre-trained model's features are not transferable or if the validation set is not representative of the target distribution, DROPS may not improve robustness.

## Foundational Learning

- **Concept**: Distributionally robust optimization (DRO)
  - **Why needed here**: DRO provides a framework for training models that are robust to distribution shifts by optimizing worst-case performance over a set of possible distributions.
  - **Quick check question**: What is the main difference between standard empirical risk minimization and distributionally robust optimization?

- **Concept**: Proper loss functions
  - **Why needed here**: Proper loss functions ensure that the Bayes-optimal predictor is consistent with the true conditional probabilities, which is crucial for the theoretical analysis of DROPS.
  - **Quick check question**: What property must a loss function satisfy to be considered "proper"?

- **Concept**: Lagrange duality
  - **Why needed here**: Lagrange duality is used to convert the constrained optimization problem in DROPS into an unconstrained saddle-point problem, which can be solved using iterative methods.
  - **Quick check question**: How does Lagrange duality help in solving constrained optimization problems?

## Architecture Onboarding

- **Component map**:
  - Pre-trained model -> Scaling adjustments -> Test time predictions

- **Critical path**:
  1. Pre-train a model on the training data
  2. Compute empirical class priors on the training data
  3. Learn scaling adjustments on the validation set using the constrained optimization problem
  4. Apply scaling adjustments to model predictions during test time

- **Design tradeoffs**:
  - Computational efficiency vs. robustness: DROPS is more efficient than full model retraining but may not achieve the same level of robustness
  - Flexibility vs. simplicity: DROPS provides more control over robustness properties but adds complexity compared to simple reweighting schemes
  - Data requirements: DROPS requires a held-out validation set with group annotations, which may not always be available

- **Failure signatures**:
  - If the learned scaling adjustments do not improve robustness, it may indicate that the pre-trained model's features are not transferable or that the validation set is not representative of the target distribution
  - If the scaling adjustments lead to degraded performance on the original distribution, it may indicate that the distributionally robust objective is not well-aligned with the desired trade-off between average and worst-case performance

- **First 3 experiments**:
  1. Evaluate DROPS on a simple class-imbalanced dataset (e.g., CIFAR-10 with imbalance ratio 10) and compare its performance to standard reweighting schemes
  2. Vary the δ parameter in DROPS and observe its effect on the trade-off between average and worst-case accuracy
  3. Apply DROPS to a group robustness task (e.g., Waterbirds dataset) and compare its performance to existing group DRO methods

## Open Questions the Paper Calls Out
The paper does not explicitly call out any open questions.

## Limitations
- The method's performance on more complex, real-world datasets with high-dimensional features is unknown
- The sensitivity of DROPS to the size and quality of the validation set is not extensively studied
- The exact impact of the δ parameter on the trade-off between average and worst-case accuracy is not fully characterized

## Confidence
- **High**: DROPS improves distributional robustness compared to standard reweighting schemes on the tested benchmarks
- **Medium**: DROPS provides finer control over robustness properties through the δ parameter
- **Low**: DROPS is more efficient than full model retraining in terms of computational cost and data requirements

## Next Checks
1. Evaluate DROPS on a more diverse set of datasets, including those with higher-dimensional features and more complex distribution shifts
2. Conduct an ablation study to quantify the impact of the validation set size and quality on DROPS' performance
3. Analyze the computational complexity of DROPS compared to full model retraining on large-scale datasets