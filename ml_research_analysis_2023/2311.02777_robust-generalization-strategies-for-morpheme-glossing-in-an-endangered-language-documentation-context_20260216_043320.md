---
ver: rpa2
title: Robust Generalization Strategies for Morpheme Glossing in an Endangered Language
  Documentation Context
arxiv_id: '2311.02777'
source_url: https://arxiv.org/abs/2311.02777
tags:
- data
- language
- eval
- morpheme
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates strategies for improving generalization
  of automated interlinear glossing models for low-resource languages, where training
  data represents only a small fraction of the language distribution. The authors
  evaluate three techniques: optimizing weight decay for regularization, using a denoising
  model to improve predictions for out-of-vocabulary morphemes, and applying iterative
  pseudo-labeling to adapt the model to out-of-distribution data.'
---

# Robust Generalization Strategies for Morpheme Glossing in an Endangered Language Documentation Context

## Quick Facts
- arXiv ID: 2311.02777
- Source URL: https://arxiv.org/abs/2311.02777
- Reference count: 9
- Key outcome: Combining weight decay optimization, denoising, and iterative pseudo-labeling improves glossing accuracy on unseen genres by 2% over baseline, reducing overall error by 8.2% for Uspanteko language documentation

## Executive Summary
This paper addresses the challenge of improving generalization for automated interlinear glossing models in low-resource language documentation contexts. The authors focus on Uspanteko, an endangered language where training data represents only a small fraction of the language's distribution across different genres and speakers. They evaluate three complementary strategies: optimizing weight decay for regularization, using a denoising model to handle out-of-vocabulary morphemes, and applying iterative pseudo-labeling to adapt models to out-of-distribution data. Their combined approach achieves a 2% improvement on unseen genres while reducing overall error by 8.2%.

## Method Summary
The method involves fine-tuning a smaller RoBERTa model (3 layers, 100 hidden size) on token classification for morpheme glossing in Uspanteko. The approach tests weight decay optimization across values from 0 to 1.0, implements a separate denoiser language model for out-of-vocabulary morphemes, and applies iterative pseudo-labeling using high-confidence predictions on out-of-distribution data. The model is trained with AdamW optimizer, batch size 64, and gradient accumulation steps 3 over 50 epochs, with evaluation on both in-distribution and out-of-distribution test sets.

## Key Results
- Weight decay optimization with value 0.75 improves OOD accuracy by 0.5 percentage points over baseline
- Denoising model provides 1.5-2.1 percentage point improvement on OOV morpheme predictions
- Iterative pseudo-labeling with one-quarter of pseudo-labeled data improves ID accuracy by 1.5 and OOD accuracy by 1.6 percentage points
- Combined approach achieves 2% improvement on unseen genres and 8.2% overall error reduction

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Optimizing weight decay improves generalization to out-of-distribution data by reducing model variance without sacrificing representation power.
- **Mechanism**: Larger weight decay values (0.75) constrain model parameters more aggressively than typical values (0.01), preventing overfitting to in-distribution patterns that don't generalize.
- **Core assumption**: The in-distribution training data contains spurious correlations and patterns that don't transfer to unseen genres, and these can be mitigated through stronger regularization.
- **Evidence anchors**:
  - [abstract] "we use weight decay optimization, output denoising, and iterative pseudo-labeling, and achieve a 2% improvement on a test set containing texts from unseen genres"
  - [section 4.1] "we find that modifying the weight decay does not significantly affect the accuracy on ID data. However, for OOD data, the best-performing weight decay value of 0.75 achieves a 0.5 percentage point improvement over the baseline"
  - [corpus] Weak - only tested on Uspanteko corpus with specific genre splits
- **Break condition**: If the OOD data contains fundamentally different linguistic phenomena (not just genre variation) or if the training data is already too small to benefit from regularization

### Mechanism 2
- **Claim**: Denoising models can recover correct glosses for out-of-vocabulary morphemes by leveraging morphological regularities and contextual patterns.
- **Mechanism**: A separate denoiser language model trained on gloss sequences can predict labels for unknown morphemes based on surrounding known morphemes and their label patterns.
- **Core assumption**: The language has regular morphological patterns and label co-occurrence rules that allow predictions even when specific morphemes are unseen during training.
- **Evidence anchors**:
  - [abstract] "we apply a separate denoiser model to improve performance on out-of-vocabulary inputs"
  - [section 4.2.1] "Using the best-performing model from the previous section... we observe that a large portion of the error on the OOD eval set is a result of OOV morphemes in the input"
  - [section 4.2.2] "The model using the denoiser without masking tokens shows the best performance, although the improvement is small"
  - [corpus] Weak - only tested on Uspanteko which has some morphological regularity but also flexibility
- **Break condition**: If the language has highly irregular morphology, many free morpheme classes, or if OOV morphemes represent entirely new linguistic phenomena not present in training data

### Mechanism 3
- **Claim**: Iterative pseudo-labeling adapts models to target distribution by exposing them to out-of-distribution contexts through self-training on high-confidence predictions.
- **Mechanism**: The model makes predictions on OOD data, selects high-confidence examples, and retrains on both original data and pseudo-labeled OOD data, gradually adapting to the target distribution.
- **Core assumption**: The model's predictions on OOD data contain enough correct examples with high confidence that retraining on them improves performance without introducing too much noise.
- **Evidence anchors**:
  - [abstract] "we apply self-supervised learning on unlabeled texts" and "achieve a 2% improvement on a test set containing texts from unseen genres"
  - [section 4.3.2] "We find that the iterative pseudo-labeled models outperform the previous model, with the model using one-quarter of the pseudo-labeled data performing best on the OOD data"
  - [section 4.3.2] "Overall, iterative pseudo-labeling improves the ID accuracy by 1.5 and the OOD accuracy by 1.6 percentage points"
  - [corpus] Moderate - tested on Uspanteko with clear genre differences and reasonable perplexity gap
- **Break condition**: If the model is poorly calibrated and confidence scores don't reflect actual accuracy, or if OOD data is too dissimilar from training data for any predictions to be reliable

## Foundational Learning

- **Concept**: Regularization and overfitting prevention
  - Why needed here: Low-resource languages have limited training data that may not represent the full distribution of texts, making models prone to overfitting specific patterns
  - Quick check question: Why might a model trained on story-telling data perform poorly on advice-giving texts in the same language?

- **Concept**: Morphological analysis and morpheme labeling
  - Why needed here: The task involves predicting grammatical function labels for each morpheme, requiring understanding of morphological structure and label patterns
  - Quick check question: How does knowing that a morpheme is a plural marker help predict its label even if the specific morpheme hasn't been seen before?

- **Concept**: Self-supervised learning and pseudo-labeling
  - Why needed here: Without additional labeled data, the model must learn from its own predictions to adapt to new text distributions
  - Quick check question: What makes a model prediction "high-confidence" enough to be useful for retraining?

## Architecture Onboarding

- **Component map**: Pretraining (USP MLM) -> Fine-tuning for token classification -> Optional: Denoising step (USP DENOISE) -> Optional: Iterative pseudo-labeling component
- **Critical path**: Data → Pretraining (USP MLM) → Fine-tuning for token classification → Evaluation → Optional: Denoising step → Optional: Iterative pseudo-labeling
- **Design tradeoffs**: Smaller model architecture (3 layers, 100 hidden size) reduces overfitting risk but may limit representation capacity; separate denoiser adds complexity but can handle OOV morphemes; iterative pseudo-labeling requires careful confidence thresholding
- **Failure signatures**: No improvement on OOD data suggests poor generalization despite techniques; performance degradation on ID data after pseudo-labeling indicates too much noise in pseudo-labels; denoiser provides minimal benefit suggests morphological irregularity
- **First 3 experiments**:
  1. Test weight decay values (0, 0.01, 0.1, 0.5, 0.75, 1.0) on the baseline model to identify optimal regularization strength
  2. Implement and evaluate the denoiser model with masked and unmasked variants on OOV morphemes
  3. Run iterative pseudo-labeling with different fractions of high-confidence predictions (top 1/2, 1/3, 1/4) to find optimal selection ratio

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of iterative pseudo-labeling change with different amounts of training data?
- Basis in paper: [inferred] The paper shows iterative pseudo-labeling improves performance on out-of-distribution data, but does not explore how this varies with training set size.
- Why unresolved: The experiments use a fixed training set size, so the relationship between training data and pseudo-labeling effectiveness is unknown.
- What evidence would resolve it: Experiments comparing iterative pseudo-labeling performance across varying training set sizes would show how data availability affects its usefulness.

### Open Question 2
- Question: What is the impact of different types of out-of-distribution data (e.g., speakers, dialects, time periods) on the generalization strategies?
- Basis in paper: [explicit] The paper focuses on genre as a form of out-of-distribution data but acknowledges other types like speakers and dialects exist.
- Why unresolved: The experiments only test genre-based out-of-distribution data, leaving the impact of other types unexplored.
- What evidence would resolve it: Testing the same strategies on data from different speakers, dialects, or time periods would reveal their generalizability across various out-of-distribution scenarios.

### Open Question 3
- Question: How does the effectiveness of denoising vary across languages with different morphological structures?
- Basis in paper: [explicit] The paper notes that Uspanteko has productive and structured morphology but also flexible morpheme classes, which may have affected denoising performance.
- Why unresolved: The experiments are limited to one language, so the denoising strategy's effectiveness across morphologically diverse languages is unknown.
- What evidence would resolve it: Applying the denoising approach to languages with varying morphological structures (e.g., agglutinative vs. fusional) would show how language-specific features impact its utility.

## Limitations

- Evaluation limited to single endangered language (Uspanteko) with small datasets (334 training instances, 190 OOD evaluation instances)
- Denoising approach shows only marginal improvements (1.5-2.1 percentage points) suggesting limited effectiveness for morphologically flexible languages
- Iterative pseudo-labeling requires careful calibration of confidence thresholds not thoroughly explored across different threshold values

## Confidence

**High Confidence**: The effectiveness of weight decay optimization for improving generalization to out-of-distribution data. This is well-supported by clear numerical improvements (0.5 percentage point increase on OOD data) and the mechanism is theoretically sound.

**Medium Confidence**: The iterative pseudo-labeling approach for adapting models to new text distributions. While the study shows improvements (1.6 percentage point increase on OOD data), the technique's sensitivity to confidence threshold selection and potential for negative transfer were not fully explored.

**Low Confidence**: The denoising model's ability to recover correct glosses for out-of-vocabulary morphemes. The improvements were minimal (1.5-2.1 percentage points) and the study suggests this may be due to Uspanteko's morphological flexibility rather than model limitations.

## Next Checks

1. **Cross-linguistic validation**: Test the three techniques (weight decay optimization, denoising, and iterative pseudo-labeling) on at least three additional endangered or low-resource languages with varying degrees of morphological regularity to assess generalizability.

2. **Confidence threshold sensitivity analysis**: Systematically evaluate the impact of different confidence thresholds (e.g., top 10%, 25%, 50%, 75%) in the iterative pseudo-labeling approach on both ID and OOD performance to identify optimal selection criteria.

3. **Ablation study on denoising effectiveness**: Create a controlled experiment with synthetic OOV morphemes in the evaluation data to isolate and measure the denoising model's performance on unseen morphemes versus its performance on in-vocabulary morphemes that might be incorrectly predicted.