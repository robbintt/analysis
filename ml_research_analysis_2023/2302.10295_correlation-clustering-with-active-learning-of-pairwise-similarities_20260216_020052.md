---
ver: rpa2
title: Correlation Clustering with Active Learning of Pairwise Similarities
arxiv_id: '2302.10295'
source_url: https://arxiv.org/abs/2302.10295
tags:
- clustering
- pairwise
- edge
- query
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a flexible active learning framework for
  correlation clustering that allows arbitrary positive or negative pairwise similarity
  values, integrates querying separately from clustering, and handles noisy oracles
  via repeated queries. A local search-based clustering algorithm automatically determines
  the number of clusters by minimizing pairwise similarity violations.
---

# Correlation Clustering with Active Learning of Pairwise Similarities

## Quick Facts
- arXiv ID: 2302.10295
- Source URL: https://arxiv.org/abs/2302.10295
- Reference count: 40
- Key outcome: Active learning framework for correlation clustering that achieves high adjusted Rand scores with fewer queries than baseline methods

## Executive Summary
This paper introduces an active learning framework for correlation clustering that learns pairwise similarity functions through queries to a noisy oracle. The framework uses novel query strategies (maxmin and maxexp) that focus on resolving inconsistent similarity information in "bad" triangles - sets of three objects with conflicting pairwise relations. By separating the querying process from the clustering algorithm, the approach can work with any correlation clustering method while automatically determining the optimal number of clusters. Experiments on synthetic and real-world datasets demonstrate that maxexp consistently outperforms baseline methods, particularly when combined with ϵ-greedy exploration.

## Method Summary
The method iteratively queries pairwise similarities from a noisy oracle to build a similarity matrix, then performs correlation clustering using a local search algorithm that automatically determines the number of clusters. The key innovation is the use of "bad" triangles - sets of three objects with exactly two positive and one negative edge weight - to guide query selection. Two novel strategies, maxmin and maxexp, prioritize edges that resolve the most inconsistency in these triangles. Maxmin selects the triangle with the maximum minimum edge weight, while maxexp uses expected violation scores weighted by clustering probabilities. The framework allows multiple queries per edge to handle noise, and uses ϵ-greedy exploration to balance exploitation of known inconsistencies with exploration of uncertain edges.

## Key Results
- Maxexp query strategy consistently outperforms random, uncertainty, and frequency baselines on CIFAR-10 and 20newsgroups datasets
- The framework achieves high adjusted Rand scores while requiring fewer queries than baseline methods
- Noise robustness is demonstrated through experiments with varying noise levels (γ = 0, 0.2, 0.4)
- ϵ-greedy exploration significantly improves performance of both maxexp and maxmin strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using triangles with inconsistent pairwise similarities (bad triangles) to guide query selection identifies the most informative edges to resolve clustering ambiguities.
- Mechanism: A bad triangle has exactly two positive and one negative edge weight. This configuration creates ambiguity because no clustering can satisfy all three pairwise relations simultaneously. Querying the smallest absolute weight in such a triangle resolves the inconsistency with minimal effort.
- Core assumption: Transitivity of pairwise similarities holds; that is, if two objects are similar to a third, they should be similar to each other, and if one is similar and the other dissimilar to a third, they should be dissimilar to each other.
- Evidence anchors: [abstract] "queries for the pairwise relations between objects"; [section 3.2] "Theorem 1 provides a way to select an edge according to the maxmin query strategy"; [corpus] Weak: no explicit triangle-based querying in corpus; mentions only active correlation clustering generally
- Break condition: If the true similarity function is not transitive (e.g., due to complex semantic relationships), this mechanism may select suboptimal edges.

### Mechanism 2
- Claim: The maxexp query strategy uses expected violation scores to rank triangles, balancing exploitation of highly inconsistent triangles with exploration of uncertain ones.
- Mechanism: For each bad triangle, compute the expected clustering cost weighted by the probability of each possible clustering (using softmax over costs). Select the triangle with the highest expected cost, then query the edge with the smallest absolute weight within it.
- Core assumption: The true pairwise similarity function is noisy but unbiased, and averaging multiple queries reduces noise.
- Evidence anchors: [abstract] "queries are robust to noise by allowing multiple queries for the same pairwise similarity"; [section 3.3] "maxexp defines the probability of a clustering C ∈ Ct as p(C|t) = exp(-β∆(t,σ,C))/∑C′∈Ct exp(-β∆(t,σ,C′))"; [corpus] Weak: corpus lacks detailed expected violation calculations; only mentions active correlation clustering
- Break condition: When noise level γ is very high, expected costs may become unreliable, leading to poor query selection.

### Mechanism 3
- Claim: Separating the query strategy from the clustering algorithm allows flexible integration of different clustering methods while maintaining query efficiency.
- Mechanism: The active learning procedure queries edges independently of how clustering is performed. This separation means any clustering algorithm can be plugged in, and the query strategy can optimize edge selection based on current similarity estimates without being tied to a specific clustering approach.
- Core assumption: Different clustering algorithms can operate effectively on the same similarity matrix, and query strategies can improve similarity estimates regardless of clustering method.
- Evidence anchors: [abstract] "adaptation to any correlation clustering algorithm and query strategy"; [section 2.2] "The process of querying pairwise similarities is separated from the clustering algorithm"; [corpus] Moderate: mentions "Active clustering" and "correlation clustering" but lacks detailed separation mechanisms
- Break condition: If the clustering algorithm has strong dependencies on the querying process (e.g., requires specific intermediate structures), separation may reduce efficiency.

## Foundational Learning

- Concept: Pairwise similarity functions and their role in clustering
  - Why needed here: The framework operates on arbitrary positive or negative similarity values between pairs of objects, which directly influence clustering outcomes.
  - Quick check question: What happens to the clustering if all pairwise similarities are positive versus all negative?

- Concept: Transitivity of similarity relations
  - Why needed here: The bad triangle detection relies on the assumption that if A is similar to B and B is similar to C, then A should be similar to C (unless proven otherwise by a negative edge).
  - Quick check question: Given three objects with pairwise similarities {1, 1, -0.1}, which triangle configuration violates transitivity?

- Concept: Active learning acquisition functions
  - Why needed here: The query strategies (random, uncertainty, frequency, maxmin, maxexp) are all different ways to select which edge to query next based on current information.
  - Quick check question: How does the maxmin strategy differ from random selection in terms of information gain?

## Architecture Onboarding

- Component map:
  - Data objects V (set of N objects)
  - Similarity matrix σ (N×N with entries in [-1,1])
  - Oracle O (provides noisy similarity values)
  - Query matrix Q (tracks all queries made)
  - Clustering algorithm A (e.g., local search correlation clustering)
  - Query strategy S (e.g., maxmin, maxexp, random, uncertainty, frequency)
  - Performance metric (e.g., adjusted Rand score)

- Critical path:
  1. Initialize σ0 with weak prior information
  2. Run clustering algorithm A on current σ
  3. Apply query strategy S to select batch of edges B
  4. Query Oracle O for edge weights in B
  5. Update similarity matrix σ and query matrix Q
  6. Repeat until stopping criterion met

- Design tradeoffs:
  - Batch size vs. convergence speed: Larger batches reduce iterations but may waste queries if similarity estimates change significantly
  - Exploration vs. exploitation: ϵ-greedy selection balances between trying new edges and refining known inconsistencies
  - Noise tolerance vs. query efficiency: Allowing multiple queries per edge increases robustness but requires more queries

- Failure signatures:
  - Query strategies consistently selecting the same edges despite changing similarity estimates (indicates poor exploration)
  - Clustering algorithm failing to converge or oscillating between solutions (indicates numerical instability or poor initialization)
  - Performance metrics plateauing early (indicates local optima or insufficient exploration)

- First 3 experiments:
  1. Verify basic functionality: Run with synthetic dataset, γ=0, and random query strategy; check that clustering improves over iterations
  2. Test noise robustness: Run with γ=0.2 and maxexp strategy; verify that multiple queries per edge improve similarity estimates
  3. Validate triangle detection: Create synthetic bad triangles and verify that maxmin/maxexp correctly identifies and queries the most informative edges

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Transitivity assumption validity: The framework heavily relies on transitivity of similarity relations for triangle-based query selection, but real-world data may violate this assumption, particularly in semantic similarity tasks.
- Noise model realism: The Gaussian noise model with known variance γ may not capture all types of oracle noise, particularly systematic biases or context-dependent errors.
- Query strategy generalization: While maxexp shows strong performance on tested datasets, its effectiveness on datasets with different characteristics (e.g., varying cluster densities, non-spherical clusters) remains untested.

## Confidence
- Transitivity assumption validity: Medium
- Noise model realism: Medium
- Query strategy generalization: Low

## Next Checks
1. **Dataset diversity test**: Apply the framework to datasets with known transitivity violations (e.g., semantic similarity judgments from human annotators) to evaluate performance degradation.

2. **Noise model stress test**: Implement alternative noise models including systematic bias and context-dependent errors, then measure maxexp's performance degradation under these conditions.

3. **Cluster structure sensitivity**: Create synthetic datasets with varying cluster densities and shapes (non-spherical clusters) to test whether query strategies maintain their relative performance rankings.