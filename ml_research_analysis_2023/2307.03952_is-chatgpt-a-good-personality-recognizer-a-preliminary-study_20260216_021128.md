---
ver: rpa2
title: Is ChatGPT a Good Personality Recognizer? A Preliminary Study
arxiv_id: '2307.03952'
source_url: https://arxiv.org/abs/2307.03952
tags:
- personality
- chatgpt
- chatgptcot
- text
- prompting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluates ChatGPT's ability to recognize personality
  traits from text using various prompting strategies. It compares zero-shot, one-shot,
  and chain-of-thought prompting approaches, including a novel level-oriented strategy.
---

# Is ChatGPT a Good Personality Recognizer? A Preliminary Study

## Quick Facts
- arXiv ID: 2307.03952
- Source URL: https://arxiv.org/abs/2307.03952
- Reference count: 40
- Primary result: ChatGPT with zero-shot chain-of-thought prompting outperforms fine-tuned RoBERTa on personality recognition tasks while revealing demographic biases.

## Executive Summary
This study evaluates ChatGPT's ability to recognize personality traits from text using various prompting strategies, including zero-shot, one-shot, and chain-of-thought approaches. The researchers introduce a novel level-oriented prompting strategy that directs analysis at word, sentence, or document levels. Results show ChatGPT achieves competitive accuracy on two real-world datasets (Essays and PAN), outperforming fine-tuned RoBERTa models. The study also demonstrates that ChatGPT can generate interpretable natural language explanations for its predictions and improve performance on downstream tasks like sentiment classification and stress prediction. However, significant demographic biases were discovered, with ChatGPT more likely to assign high Openness, Conscientiousness, and Agreeableness to women, and low Openness to older individuals.

## Method Summary
The study evaluates ChatGPT's personality recognition using zero-shot, one-shot, and chain-of-thought prompting strategies on two datasets: Essays (2,467 essays) and PAN (294 users' tweets). The researchers implement zero-shot CoT and zero-shot level-oriented CoT prompting, where analysis granularity is explicitly directed at word, sentence, or document levels. Performance is compared against baseline models including RNN and fine-tuned RoBERTa. The study also tests whether personality recognition priming improves ChatGPT's performance on downstream tasks (sentiment classification and stress prediction). Demographic bias analysis examines gender and age distributions across personality trait predictions.

## Key Results
- ChatGPT with zero-shot chain-of-thought prompting achieves 78.95% accuracy on PAN and 71.68% on Essays, outperforming fine-tuned RoBERTa
- Zero-shot level-oriented CoT prompting significantly improves accuracy by 4.83% on PAN and 2.84% on Essays
- ChatGPT generates natural language explanations for personality predictions, achieving 71.92% and 75.65% agreement with ground truth on PAN and Essays respectively
- Demographic biases found: women more likely assigned high Openness, Conscientiousness, and Agreeableness; older individuals more likely assigned low Openness

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Zero-shot chain-of-thought prompting elicits ChatGPT's personality recognition ability better than zero-shot or one-shot prompting alone.
- **Mechanism:** By providing step-by-step reasoning guidance ("Let's think step by step"), ChatGPT is prompted to decompose the task into logical inference steps, allowing it to extract nuanced personality cues from text rather than making surface-level judgments.
- **Core assumption:** The underlying language model already encodes relevant psychological knowledge; prompting only needs to trigger structured reasoning.
- **Evidence anchors:**
  - [abstract]: "ChatGPT with zero-shot chain-of-thought prompting exhibits impressive personality recognition ability"
  - [section]: "zero-shot CoT prompting could effectively enhance ChatGPT's ability on text-based personality recognition task"
  - [corpus]: Weak – no direct citations about CoT improving personality tasks, but strong in general NLP performance.
- **Break condition:** If the model's pre-training corpus lacks psychological trait associations, CoT prompting cannot compensate.

### Mechanism 2
- **Claim:** Level-oriented prompting refines analysis granularity, improving accuracy when task context aligns with the chosen level.
- **Mechanism:** By explicitly directing analysis to word, sentence, or document level, ChatGPT can focus on appropriate textual features (e.g., document-level coherence for Essays, sentence-level detail for PAN tweets).
- **Core assumption:** Text structure in a dataset maps to optimal analytical granularity.
- **Evidence anchors:**
  - [section]: "guiding ChatGPT to analyze given text from specified level could help ChatGPT in analyzing given text more targeted and completing personality prediction task precisely"
  - [abstract]: "zero-shot level-oriented CoT prompting enhances the personality prediction ability of ChatGPT"
  - [corpus]: Weak – corpus neighbors discuss prompting strategies but not level-specific refinement.
- **Break condition:** If the dataset's text structure doesn't match the chosen level, performance degrades.

### Mechanism 3
- **Claim:** Personality recognition priming improves ChatGPT's performance on related downstream tasks by contextualizing inputs.
- **Mechanism:** By first inferring personality traits and then feeding them into task-specific prompts (sentiment, stress), ChatGPT tailors its reasoning to individual behavioral patterns.
- **Core assumption:** Personality traits are predictive of sentiment/stress expressions and can be effectively extracted without fine-tuning.
- **Evidence anchors:**
  - [abstract]: "eliciting the personality recognition ability of ChatGPT helps improve its performance on personality-related downstream tasks"
  - [section]: "the personality data generated by ChatGPT could enhance its performance on sentiment classification task and stress prediction task"
  - [corpus]: Weak – corpus shows other ChatGPT capability studies but no personality-to-task priming studies.
- **Break condition:** If personality traits don't correlate with task-specific cues, priming offers no benefit.

## Foundational Learning

- **Concept: Chain-of-thought prompting**
  - Why needed here: Enables step-by-step logical reasoning for complex inference tasks like personality detection.
  - Quick check question: What is the primary benefit of adding "Let's think step by step" to a prompt?
- **Concept: Zero-shot prompting**
  - Why needed here: Allows evaluation without task-specific examples, isolating ChatGPT's innate reasoning.
  - Quick check question: How does zero-shot differ from one-shot prompting in terms of example usage?
- **Concept: Text-level analysis granularity**
  - Why needed here: Determines whether ChatGPT focuses on word features, sentence context, or document coherence.
  - Quick check question: When might document-level analysis be more effective than sentence-level?

## Architecture Onboarding

- **Component map:**
  - Input text → Prompt formatting → ChatGPT API → Trait extraction → Task-specific adaptation → Output predictions
- **Critical path:**
  - Text → Prompt formatting → ChatGPT inference → Trait extraction → Task-specific adaptation
- **Design tradeoffs:**
  - Zero-shot vs. few-shot: Balancing generalization vs. task alignment
  - Prompt length vs. token limits: Choosing concise vs. detailed instructions
  - Fairness vs. accuracy: Detecting bias while maintaining predictive power
- **Failure signatures:**
  - ChatGPT refuses to answer → prompt unclear or too long
  - Trait predictions inconsistent across runs → temperature too high
  - Downstream performance drops → personality inference misaligned with task cues
- **First 3 experiments:**
  1. Compare zero-shot, one-shot, and CoT prompts on a held-out text sample.
  2. Test word-level vs. sentence-level vs. document-level CoT on both datasets.
  3. Inject personality traits into sentiment task prompts and measure accuracy change.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does ChatGPT exhibit bias in personality predictions across other demographic attributes beyond gender and age?
- Basis in paper: [explicit] The paper found biases in personality predictions across gender and age groups but did not explore other demographic attributes like race, socioeconomic status, or education level.
- Why unresolved: The study focused only on gender and age as demographic attributes. It's unclear whether ChatGPT exhibits similar biases for other demographic factors that could also influence personality expression and interpretation.
- What evidence would resolve it: Conducting experiments similar to those in the paper but including additional demographic attributes (race, education level, income bracket, etc.) and analyzing prediction patterns across these groups would reveal whether similar biases exist.

### Open Question 2
- Question: How does ChatGPT's performance on personality recognition tasks vary across different languages and cultural contexts?
- Basis in paper: [inferred] The study used English datasets (Essays and PAN), but ChatGPT is multilingual. Cultural differences in personality expression and language use could affect the model's ability to recognize personality traits accurately across languages.
- Why unresolved: The paper only evaluated ChatGPT on English datasets. Different languages and cultures may have varying norms for personality expression, which could impact the model's performance when dealing with non-English text.
- What evidence would resolve it: Testing ChatGPT's personality recognition performance on multilingual datasets from diverse cultural contexts (e.g., PAN datasets in Dutch, Italian, and Spanish) and comparing results across languages would reveal cultural and linguistic influences on performance.

### Open Question 3
- Question: Can the level-oriented prompting strategy designed in this study be effectively applied to other natural language processing tasks beyond personality recognition?
- Basis in paper: [explicit] The authors mention that the level-oriented prompting strategy "proves the effectiveness of zero-shot level-oriented CoT prompting" for personality recognition and suggest applying it to "more NLP tasks for observing its effectiveness in mining text information."
- Why unresolved: While the strategy showed promise for personality recognition, its generalizability to other NLP tasks (e.g., sentiment analysis, question answering, summarization) remains untested.
- What evidence would resolve it: Applying the level-oriented prompting strategy to various NLP tasks and comparing its performance against standard prompting approaches would determine its broader applicability and effectiveness across different domains.

## Limitations

- Limited dataset diversity with only two text corpora (Essays and PAN)
- Single API call per sample without ensemble methods for robustness
- Demographic bias analysis restricted to surface-level correlations without controlling for confounders
- No exploration of alternative prompting strategies like self-consistency or majority voting

## Confidence

- Performance comparison with fine-tuned models: High
- Chain-of-thought prompting effectiveness: Medium
- Downstream task improvements: Medium
- Demographic bias findings: Medium

## Next Checks

1. Test self-consistency prompting by generating multiple responses per sample and taking majority votes to assess stability
2. Expand demographic bias analysis with regression models controlling for writing quality and topic distribution
3. Conduct cross-dataset validation by training models on one corpus and testing on the other to evaluate generalization