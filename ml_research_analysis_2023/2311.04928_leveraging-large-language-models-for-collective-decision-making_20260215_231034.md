---
ver: rpa2
title: Leveraging Large Language Models for Collective Decision-Making
arxiv_id: '2311.04928'
source_url: https://arxiv.org/abs/2311.04928
tags:
- preferences
- system
- members
- options
- meeting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a system that leverages large language models
  (LLMs) to facilitate collective decision-making by extracting individual preferences
  and suggesting options that satisfy many members. The system is evaluated in the
  context of meeting scheduling using synthetic employee profiles and simulated conversations.
---

# Leveraging Large Language Models for Collective Decision-Making

## Quick Facts
- arXiv ID: 2311.04928
- Source URL: https://arxiv.org/abs/2311.04928
- Authors: 
- Reference count: 40
- One-line primary result: LLM-based system efficiently coordinates group decisions by extracting preferences and generating satisfying options through iterative refinement

## Executive Summary
This paper presents a system that leverages large language models to facilitate collective decision-making by extracting individual preferences from natural language conversations and suggesting options that satisfy multiple members. The system is evaluated in the context of meeting scheduling using synthetic employee profiles and simulated conversations. Results show that the system can efficiently coordinate group decisions with reduced interactions, increasing satisfaction of members' preferences over time while maintaining equitable outcomes across participants.

## Method Summary
The system uses a four-module LLM-based architecture: a knowledge graph stores member metadata and social connections, an intent extraction module processes member messages to distill preferences, a coordination module generates options based on preferences and knowledge graph, and an evaluation module scores options based on how well they satisfy each member's preferences. The system operates in iterative rounds where members provide feedback on proposed options, their preferences are updated, and new options are generated. The evaluation uses synthetic employee profiles and simulated conversations, with performance measured across efficiency, effectiveness, and quality metrics.

## Key Results
- System achieves efficient coordination with reduced average interactions between members and the system over rounds
- Satisfaction ratio and score increase over time, showing the system's ability to satisfy members' preferences
- Human participants rate the system's options and reasoning as high quality, with acceptability scores above 4.0 on a 5-point scale

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can extract individual preferences from natural language messages in group decision contexts.
- Mechanism: The intent extraction module processes each member's free-text conversation with the system and distills compact restatements of their preferences as vectors.
- Core assumption: Natural language conversations contain sufficient information for LLMs to identify and accurately restate individual preferences.
- Evidence anchors: [abstract] "Our system aims to extract individual preferences from each member's conversation with the system"; [section 3.1] "The intent extraction module extracts the members' individual preferences from their free-text messages"
- Break condition: If the LLM cannot accurately extract preferences from natural language, the system will fail to satisfy members' needs.

### Mechanism 2
- Claim: The coordination module can generate options that satisfy members' preferences by balancing individual needs with group consensus.
- Mechanism: The coordination module uses the extracted preferences, knowledge graph, and previous decision candidates to generate a set of options.
- Core assumption: LLMs can reason about how to balance diverse preferences to create mutually agreeable options.
- Evidence anchors: [abstract] "suggest options that satisfy the preferences of the members"; [section 3.1] "the coordinator produces a set of K options"
- Break condition: If the LLM cannot balance diverse preferences effectively, the generated options will not satisfy members.

### Mechanism 3
- Claim: The system can refine proposed options over time through iterative member feedback and preference updates.
- Mechanism: The system operates in rounds where members provide feedback on proposed options, their preferences are updated, and new options are generated based on this updated information.
- Core assumption: Iterative feedback and preference updates lead to improved options that satisfy more members over time.
- Evidence anchors: [abstract] "The system refines and improves its proposed options over time"; [section 3.1] "many rounds of interactions between the members and the system"
- Break condition: If the iterative process does not converge to satisfactory options, the system will fail to reach consensus.

## Foundational Learning

- **Concept**: Preference aggregation
  - Why needed here: The system needs to combine individual preferences into a collective decision that satisfies as many members as possible.
  - Quick check question: How does the system determine which option satisfies the most members?

- **Concept**: Knowledge graphs
  - Why needed here: The knowledge graph provides context about members' roles, responsibilities, and social connections, which helps the system generate more informed options.
  - Quick check question: What information is stored in the knowledge graph and how is it used by the coordination module?

- **Concept**: LLM-based evaluation
  - Why needed here: The evaluation module uses LLMs to assign scores to options based on how well they satisfy each member's preferences, enabling quantitative comparison of options.
  - Quick check question: How does the evaluation module quantify the degree to which an option satisfies a member's preferences?

## Architecture Onboarding

- **Component map**: Intent Extraction -> Coordination -> Evaluation -> Option Presentation -> Member Feedback -> Preference Update
- **Critical path**: Member message → Intent extraction → Coordination → Option generation → Evaluation → Option presentation → Member feedback
- **Design tradeoffs**:
  - Option generation vs. preference satisfaction: Generating more options may lead to better satisfaction but increases complexity
  - Knowledge graph depth vs. processing time: More detailed knowledge graphs provide better context but require more processing
  - Iterative rounds vs. convergence speed: More rounds may lead to better consensus but increase coordination time
- **Failure signatures**:
  - Low satisfaction ratio: System not effectively balancing preferences
  - High number of interactions: System not refining options effectively
  - Declining equity score: System favoring certain members over others
- **First 3 experiments**:
  1. Test preference extraction accuracy with synthetic member profiles
  2. Test option generation with varying knowledge graph complexity
  3. Test iterative refinement with synthetic member feedback loops

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the system's performance change when incorporating real-world calendar availability constraints compared to synthetic preferences?
- Basis in paper: [explicit] The paper mentions that incorporating work calendars into the LLM's reasoning process degraded performance in experiments.
- Why unresolved: The study only tested mathematical encoding of availability constraints, which may not reflect realistic calendar data or integration methods.
- What evidence would resolve it: Comparative experiments using actual calendar APIs or data to test the system's ability to incorporate real-time availability information.

### Open Question 2
- Question: What is the impact of different meeting sizes on the system's ability to balance equity scores while maintaining satisfaction ratios?
- Basis in paper: [explicit] The paper found that larger meetings (n=5) showed better improvements in satisfaction ratio and score compared to smaller meetings (n=3,4).
- Why unresolved: The study did not systematically explore the relationship between meeting size and equity score trends across different coordination rounds.
- What evidence would resolve it: Detailed analysis of equity score changes across multiple meeting sizes (e.g., n=3 to n=10) to identify optimal group sizes for balanced decision-making.

### Open Question 3
- Question: How does the system handle conflicting preferences when members have overlapping but contradictory constraints?
- Basis in paper: [inferred] The paper mentions that members' preferences may change over time and that the system needs to adapt to new constraints.
- Why unresolved: The study used synthetic data with predefined preferences and did not test scenarios where members' preferences directly conflict.
- What evidence would resolve it: Experiments with scenarios where members' preferences create direct conflicts (e.g., one member must attend in the morning, another only in the afternoon) to evaluate the system's conflict resolution strategies.

### Open Question 4
- Question: What is the effect of fine-tuning the LLM on specific organizational contexts and communication styles?
- Basis in paper: [inferred] The paper suggests that incorporating knowledge graphs and attendance constraints affected system performance.
- Why unresolved: The study used a generic LLM without domain-specific fine-tuning, which may limit its effectiveness in different organizational contexts.
- What evidence would resolve it: Comparative experiments using fine-tuned models for specific industries or communication styles to measure improvements in preference aggregation and reasoning quality.

### Open Question 5
- Question: How does the system's performance scale with increasing numbers of participants beyond the tested range (n=3 to n=5)?
- Basis in paper: [explicit] The paper tested meetings with 3, 4, and 5 members but did not explore larger group sizes.
- Why unresolved: The study's synthetic data and evaluation focused on small to medium-sized meetings, leaving uncertainty about performance with larger groups.
- What evidence would resolve it: Experiments with larger meeting sizes (e.g., n=10 to n=50) to evaluate the system's ability to maintain coordination efficiency and preference satisfaction at scale.

## Limitations

- The evaluation relies entirely on synthetic data and simulated interactions, limiting generalizability to real-world scenarios where member preferences are less structured and conversations more complex.
- The knowledge graph construction method remains underspecified, particularly regarding how social relationships are quantified and weighted.
- The study uses a single LLM (gpt-3.5-turbo) without comparing against alternative models or ablations that would isolate the contribution of each system component.

## Confidence

- **High**: The core system architecture (four-module design) is well-specified and reproducible
- **Medium**: The synthetic data generation methodology and simulation framework
- **Low**: The generalizability of results to real-world collective decision-making scenarios

## Next Checks

1. **Ablation study**: Test system performance with individual modules disabled (e.g., remove knowledge graph, use random option generation) to quantify each component's contribution
2. **Real-world pilot**: Deploy the system with actual meeting scheduling scenarios and human participants to validate synthetic data findings
3. **Model comparison**: Evaluate performance using different LLM models (gpt-4, Claude, open-source alternatives) to assess robustness to model choice