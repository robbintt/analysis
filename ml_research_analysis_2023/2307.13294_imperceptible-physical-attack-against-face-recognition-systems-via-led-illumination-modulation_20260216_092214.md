---
ver: rpa2
title: Imperceptible Physical Attack against Face Recognition Systems via LED Illumination
  Modulation
arxiv_id: '2307.13294'
source_url: https://arxiv.org/abs/2307.13294
tags:
- face
- attack
- adversarial
- recognition
- attacks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a practical, executable, and inconspicuous
  physical adversarial attack against face recognition systems. The attack, named
  LIM (LED Illumination Modulation), exploits the rolling shutter effect of CMOS image
  sensors to implant imperceptible luminance perturbations into captured face images.
---

# Imperceptible Physical Attack against Face Recognition Systems via LED Illumination Modulation

## Quick Facts
- arXiv ID: 2307.13294
- Source URL: https://arxiv.org/abs/2307.13294
- Reference count: 38
- Primary result: 97.67% success rate against Dlib face detection, 100% success against MTCNN, RetinaFace, FaceNet, and ArcFace

## Executive Summary
This paper introduces LIM (LED Illumination Modulation), a novel physical adversarial attack that exploits the rolling shutter effect of CMOS cameras to imperceptibly disrupt face recognition systems. By modulating LED illumination at frequencies above human perception (200Hz), LIM generates adversarial perturbations that can either prevent face detection or cause identity mismatches. The attack achieves remarkably high success rates against state-of-the-art face detection and verification models while remaining invisible to human observers. The approach represents a significant advancement in physical adversarial attacks, moving beyond traditional visible perturbations to exploit camera hardware characteristics.

## Method Summary
The LIM method uses high-frequency LED modulation to create imperceptible luminance changes that are captured by CMOS rolling shutter cameras as adversarial perturbations. The attack employs On-Off Keying modulation at frequencies above 200Hz to generate patterns that appear uniform to human eyes but create distinct fringes in camera-captured images. A greedy search algorithm optimizes perturbation parameters (width, interval, angle) to maximize attack effectiveness. The approach targets two stages: DoS attacks on face detection by creating wide dark fringes that obscure facial features, and dodging attacks on face verification by adding narrow fringes that alter facial feature vectors.

## Key Results
- 97.67% success rate against Dlib face detection model
- 100% success rates against MTCNN and RetinaFace models for denial-of-service attacks
- 100% success rates against Dlib, FaceNet, and ArcFace models for dodging attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fast LED flicker beyond human perception (200Hz) can be captured by CMOS camera rolling shutter to create adversarial perturbations
- Mechanism: LED is modulated with On-Off Keying (OOK) at high frequency. Human eye doesn't perceive flicker above 200Hz, but CMOS rolling shutter exposes pixels line-by-line with delay, so each row sees different LED state. This creates bright/dark fringes in image that act as adversarial perturbations.
- Core assumption: CMOS camera uses rolling shutter, not global shutter; and exposure time is long enough to integrate multiple LED states
- Evidence anchors: [abstract] "generates imperceptible luminance changes to human eyes through fast intensity modulation of scene LED illumination and uses the rolling shutter effect of CMOS image sensors"; [section III-B] "Most of the cameras of face recognition systems use CMOS image sensors, which adopt the rolling shutter progressive exposure mode"
- Break condition: If camera uses global shutter, or exposure time is too short to capture modulation pattern

### Mechanism 2
- Claim: Adversarial perturbation patterns can be designed to either block face detection or cause feature mismatch
- Mechanism: Two perturbation strategies: (1) DoS attack - wide dark fringes covering facial features to prevent detection; (2) Dodging attack - narrow fringes adding "pseudo-contour" to facial features to alter landmark positions and feature vectors
- Core assumption: Perturbation patterns are spatially aligned with facial features in image coordinates
- Evidence anchors: [abstract] "we present a denial-of-service (DoS) attack for face detection and a dodging attack for face verification"; [section III-B] "DoS attack for the face detection stage and dodging attack for the face feature matching stage"
- Break condition: If perturbation patterns don't align with facial feature regions in captured image

### Mechanism 3
- Claim: LED modulation parameters can be optimized to maximize attack success against specific face recognition models
- Mechanism: Greedy search algorithm iterates over perturbation parameters (width, interval, angle) and evaluates model output to find parameters that maximize objective function (either prevent detection or cause feature mismatch)
- Core assumption: Model outputs are available for evaluation during parameter search (black-box access)
- Evidence anchors: [abstract] "We formalize the perturbation generation process as an optimization problem, and use a greedy search approach to solve for the optimal attack parameters"; [section III-D] "our optimization problem is actually to find the optimal set of adversarial perturbation pattern parameters Θ(b, s, α)"
- Break condition: If model outputs are not available or search space is too large for greedy search

## Foundational Learning

- Concept: Rolling shutter effect in CMOS cameras
  - Why needed here: Core mechanism relies on line-by-line exposure capturing different LED states
  - Quick check question: How does rolling shutter differ from global shutter in image capture?

- Concept: On-Off Keying (OOK) modulation
  - Why needed here: Method for creating high-frequency LED flicker patterns
  - Quick check question: What is the relationship between OOK modulation frequency and human flicker perception threshold?

- Concept: Face detection vs face verification
  - Why needed here: Two different attack targets with different objectives
  - Quick check question: What is the key difference between face detection and face verification in terms of output?

## Architecture Onboarding

- Component map: LED light source with high-speed modulator -> Target CMOS camera (face recognition system) -> Face detection models (Dlib, MTCNN, RetinaFace) -> Face verification models (Dlib, FaceNet, ArcFace) -> Optimization algorithm for perturbation parameters

- Critical path: 1. Generate LED modulation parameters using optimization algorithm; 2. Modulate LED at calculated frequency/pattern; 3. Camera captures face image with adversarial perturbations; 4. Image fed to face recognition system; 5. System either fails to detect face (DoS) or mismatches identity (dodging)

- Design tradeoffs: Modulation frequency vs. human perceptibility; Perturbation width vs. attack effectiveness; Search space granularity vs. computation time; Attack success rate vs. robustness to different cameras

- Failure signatures: Camera uses global shutter (no rolling shutter effect); LED modulation frequency too low (visible flicker); Perturbation patterns not aligned with facial feature regions; Optimization algorithm fails to find effective parameters

- First 3 experiments: 1. Verify LED modulation creates visible vs. invisible flicker at different frequencies using photodiode; 2. Test camera rolling shutter capture by imaging moving LED with known modulation pattern; 3. Validate perturbation patterns cause model output changes by testing with known good images and varying parameters

## Open Questions the Paper Calls Out

The paper does not explicitly call out specific open questions. However, based on the content, several important questions emerge:

1. How effective is the LIM attack under varying ambient lighting conditions, such as outdoor environments or mixed lighting sources?
2. What is the impact of camera sensor differences (e.g., CCD vs. CMOS, different shutter speeds) on the effectiveness of the LIM attack?
3. Can the LIM attack be adapted to target other computer vision tasks beyond face recognition, such as object detection or facial expression recognition?
4. How does the LIM attack perform against face recognition systems that use 3D or depth-sensing technologies?

## Limitations

- Requires precise control over LED modulation parameters, which may be difficult to achieve in uncontrolled environments
- Results are validated primarily on white male subjects, raising concerns about demographic generalization
- Physical implementation challenges (LED positioning, modulation hardware) are not fully addressed

## Confidence

- **High confidence**: The fundamental mechanism leveraging CMOS rolling shutter to capture high-frequency LED modulation patterns is technically sound and well-supported by camera imaging principles
- **Medium confidence**: The attack success rates (97.67% for face detection, 100% for verification) are impressive but may be specific to the tested models and conditions
- **Low confidence**: The practical feasibility of deploying this attack in real-world scenarios, including environmental factors and camera variations

## Next Checks

1. Test attack robustness across different camera models with varying shutter speeds, resolutions, and global vs rolling shutter implementations
2. Evaluate demographic generalization by testing on diverse subjects across age, gender, and skin tone variations under multiple lighting conditions
3. Assess attack feasibility under realistic deployment scenarios with varying distances, angles, and environmental lighting interference