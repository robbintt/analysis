---
ver: rpa2
title: Self-supervised Adaptive Weighting for Cooperative Perception in V2V Communications
arxiv_id: '2312.10342'
source_url: https://arxiv.org/abs/2312.10342
tags:
- weighting
- channel
- perception
- cooperative
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of severe performance degradation
  in intermediate fusion for cooperative perception due to channel distortion in vehicle-to-vehicle
  (V2V) communications. It proposes a self-supervised adaptive weighting model that
  dynamically adjusts feature fusion weights to mitigate the adverse effects of distorted
  information received from other vehicles.
---

# Self-supervised Adaptive Weighting for Cooperative Perception in V2V Communications

## Quick Facts
- arXiv ID: 2312.10342
- Source URL: https://arxiv.org/abs/2312.10342
- Reference count: 30
- Key outcome: Self-supervised adaptive weighting model dynamically adjusts feature fusion weights to mitigate performance degradation from channel distortion in V2V cooperative perception

## Executive Summary
This paper addresses severe performance degradation in intermediate fusion for cooperative perception due to channel distortion in vehicle-to-vehicle communications. The authors propose a self-supervised adaptive weighting model that dynamically adjusts feature fusion weights based on the quality of received information. The method uses a CNN to generate weights for features from different vehicles, leveraging contrastive information between ego vehicle and received features. A self-supervised training scheme with simulated channel augmentations optimizes the model without requiring manual annotation, significantly improving robustness across various channel conditions.

## Method Summary
The method involves a CNN-based adaptive weighting network that processes concatenated ego and received features to produce per-vehicle weights. The model is trained using a self-supervised loss that compares augmented (distorted) versions of the same features, encouraging high weights for undistorted features and low weights for distorted ones. The approach is evaluated on OPV2V and V2V4Real datasets using SECOND and PointPillars detection backbones with attentive fusion. Three training schemes are compared: ideal communications, distortion-in-loop, and the proposed adaptive weighting.

## Key Results
- Adaptive weighting achieves stable accuracy around 60-65% for IoU=0.7 and 65-88% for IoU=0.3 even under severe channel impairments
- The method outperforms non-weighted baselines across various channel conditions, SNR levels, and path loss factors
- The approach generalizes well to unseen real-world datasets and different detection backbones
- Adaptive weighting maintains competitive performance under good channel conditions while significantly improving robustness under distortion

## Why This Works (Mechanism)

### Mechanism 1
The self-supervised adaptive weighting model mitigates the negative impact of severely distorted V2V channel data on intermediate fusion by dynamically adjusting fusion weights based on feature similarity between ego and received features. A CNN-based network processes concatenated ego and received features to produce per-vehicle weights. Severely distorted features produce low weights, minimizing their interference in the fusion output. Contrastive self-supervised learning optimizes the weights without manual labels by comparing augmented (distorted) versions of the same features.

### Mechanism 2
Self-supervised training with simulated channel augmentations enables the model to generalize across diverse and unseen channel conditions without requiring labeled detection data. The model is trained using positive (lightly distorted) and negative (severely distorted) augmentations of the received features. KL divergence between the weighted augmented features and original features serves as the loss, encouraging the model to assign high weights to undistorted features and low weights to distorted ones.

### Mechanism 3
Adaptive weighting improves cooperative perception robustness across varying path loss factors by reducing the influence of signals from distant vehicles with high path loss. As path loss increases, the received signal quality degrades. The weighting network assigns lower weights to features from vehicles with high path loss, preventing their inclusion when they are likely to be unreliable.

## Foundational Learning

- Concept: Rician fading and multi-path channel models in V2V communications
  - Why needed here: Understanding how V2V channels distort transmitted features is essential for designing and interpreting the adaptive weighting system.
  - Quick check question: What is the difference between Rician fading and AWGN noise, and how does each affect signal quality in V2V communications?

- Concept: Intermediate fusion in cooperative perception
  - Why needed here: The adaptive weighting is specifically designed to improve intermediate fusion performance under channel distortion.
  - Quick check question: How does intermediate fusion differ from early and late fusion in cooperative perception, and what are its advantages and disadvantages?

- Concept: Self-supervised learning and contrastive learning
  - Why needed here: The adaptive weighting model is trained without manual labels using contrastive self-supervised learning.
  - Quick check question: What is the difference between supervised, unsupervised, and self-supervised learning, and how does contrastive learning work in a self-supervised setting?

## Architecture Onboarding

- Component map: LiDAR point clouds → Voxel feature extractor (VFE) → Sparse convolution (SpConv) → Region proposal network (RPN) → Detection head → Attentive fusion module → Adaptive weighting module (CNN + BatchNorm + ReLU + Dense + Softmax) → Fusion output

- Critical path: Feature extraction → Adaptive weighting → Attentive fusion → Detection head

- Design tradeoffs: Adaptive weighting adds computational overhead but improves robustness under distortion; self-supervised training reduces labeling costs but relies on realistic channel simulations; CA V-level weighting improves efficiency but may miss fine-grained distortion patterns

- Failure signatures: Performance degradation under channel conditions not seen during training; weights not adapting to sudden changes in channel quality; weights collapsing to near-zero or near-one for all vehicles, indicating training instability

- First 3 experiments:
  1. Evaluate baseline (no weighting) vs. adaptive weighting under varying SNRs with Rician fading to confirm performance improvement.
  2. Test generalization to unseen WINNER II channel model to assess robustness to different fading models.
  3. Ablation study: remove self-supervised training and replace with supervised training to quantify the benefit of the proposed approach.

## Open Questions the Paper Calls Out

### Open Question 1
How does the self-supervised adaptive weighting model perform under different communication channel models beyond Rician fading and WINNER II, such as vehicle-to-infrastructure (V2I) communications or hybrid channel conditions? The paper evaluates the model under Rician fading and WINNER II channel models but does not explore other realistic channel conditions like V2I communications or hybrid environments.

### Open Question 2
Can the self-supervised adaptive weighting model be extended to other sensor modalities, such as camera-based perception or radar data, and how would it perform in these cases? The paper focuses on LiDAR-based perception and intermediate fusion of point cloud features, but does not explore the applicability of the weighting model to other sensor modalities.

### Open Question 3
How does the computational overhead of the self-supervised adaptive weighting model impact real-time performance in autonomous driving systems, and can it be optimized for lower latency? The paper mentions the use of CNN-BatchNorm-ReLU blocks and Softmax for weighting but does not discuss the computational overhead or latency implications in real-time systems.

## Limitations
- The approach relies on simulated channel distortions for training, with unclear generalization guarantees to real-world fading patterns beyond the tested WINNER II model
- Performance metrics are limited to detection AP without examining computational overhead or latency impacts on real-time deployment
- The evaluation focuses primarily on controlled simulations rather than extensive real-world validation

## Confidence

**Confidence Levels:**
- High: The adaptive weighting architecture design and its integration with intermediate fusion
- Medium: The effectiveness of self-supervised training with simulated augmentations
- Medium: Generalization claims to unseen real-world datasets

## Next Checks
1. Test the model's performance under channel conditions that differ significantly from the Rician and WINNER II models used in training (e.g., Rayleigh fading, different Doppler spreads)
2. Conduct an ablation study comparing self-supervised training with supervised alternatives and varying weight granularity levels (per-vehicle vs. per-pixel)
3. Measure the computational overhead and latency introduced by the adaptive weighting module in real-time cooperative perception scenarios