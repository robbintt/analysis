---
ver: rpa2
title: Do We Fully Understand Students' Knowledge States? Identifying and Mitigating
  Answer Bias in Knowledge Tracing
arxiv_id: '2308.07779'
source_url: https://arxiv.org/abs/2308.07779
tags:
- knowledge
- answer
- bias
- students
- questions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the widespread answer bias in knowledge tracing,
  where models often achieve high performance by exploiting unbalanced distributions
  of correct and incorrect answers rather than genuinely understanding student knowledge
  states. The authors propose a causality-based Counterfactual REasoning (CORE) framework
  that disentangles total and direct causal effects of questions on responses, mitigating
  the influence of answer bias by subtracting the latter from the former during inference.
---

# Do We Fully Understand Students' Knowledge States? Identifying and Mitigating Answer Bias in Knowledge Tracing

## Quick Facts
- arXiv ID: 2308.07779
- Source URL: https://arxiv.org/abs/2308.07779
- Reference count: 40
- Authors propose a causality-based framework that disentangles total and direct causal effects of questions on responses, significantly improving knowledge tracing accuracy by mitigating answer bias.

## Executive Summary
This paper addresses the widespread issue of answer bias in knowledge tracing models, where models often achieve high performance by exploiting the unbalanced distribution of correct and incorrect answers rather than genuinely understanding student knowledge states. The authors propose CORE (Counterfactual REasoning), a model-agnostic framework that uses causal inference to separate the total causal effect of questions on responses from the direct effect attributable to answer bias. By subtracting the direct effect from the total effect during inference, CORE produces debiased predictions that better reflect true student knowledge states. Experiments on three benchmark datasets show significant improvements in accuracy and AUC when evaluated on unbiased test sets.

## Method Summary
The CORE framework addresses answer bias in knowledge tracing by disentangling total and direct causal effects through counterfactual reasoning. It establishes a causal graph with three paths: student-only, question-only, and student-question branches. The question-only branch captures answer bias (direct effect), while the total effect is estimated by the original KT model. CORE subtracts the direct effect from the total effect during inference to produce debiased predictions. The framework is implemented on DKT, DKVMN, and AKT models using multi-task learning with BCE loss and KL divergence constraint to ensure valid counterfactual reasoning.

## Key Results
- CORE significantly improves accuracy and AUC on unbiased test sets across all three benchmark datasets
- DKT-CORE achieves an average 4.75% improvement in accuracy and 5.25% in AUC compared to standard DKT
- The framework maintains effectiveness across different levels of answer bias, with larger improvements observed when bias is stronger
- CORE demonstrates model-agnostic capabilities, working effectively with DKT, DKVMN, and AKT architectures

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CORE reduces answer bias by estimating and subtracting the direct causal effect of questions on responses from the total causal effect.
- Mechanism: CORE uses counterfactual reasoning to simulate a scenario where only the question is known, estimating the pure impact of answer bias (direct causal effect). This estimate is then subtracted from the total effect to produce a debiased prediction.
- Core assumption: The direct causal effect of questions on responses can be isolated and accurately estimated through counterfactual simulation.
- Evidence anchors:
  - [abstract] "The authors propose a causality-based Counterfactual REasoning (CORE) framework that disentangles total and direct causal effects of questions on responses, mitigating the influence of answer bias by subtracting the latter from the former during inference."
  - [section] "We identify that the impact of answer bias lies in the direct causal effect of questions on students' responses from a causality perspective, and propose a model-agnostic counterfactual reasoning framework CORE to eliminate the impact by making the debiased causal inference for KT."
- Break condition: If the counterfactual simulation cannot accurately estimate the direct effect, or if the total effect is not properly captured, the debiasing will fail.

### Mechanism 2
- Claim: CORE improves interpretability by explicitly modeling the causal paths between students, questions, knowledge states, and responses.
- Mechanism: CORE introduces three network branches that capture each causal path (student-only, question-only, student-question), allowing the model to explicitly model how each factor contributes to the final prediction.
- Core assumption: The causal structure of KT can be accurately represented by a directed acyclic graph with three main paths.
- Evidence anchors:
  - [abstract] "A causal graph of KT is first established, from which we identify that the impact of answer bias lies in the direct causal effect of questions on students' responses."
  - [section] "The causal graph is represented by a directed acyclic graph, where each node corresponds to a variable, and each edge signifies a relationship among variables."
- Break condition: If the causal graph is misspecified or if the network branches cannot effectively capture the causal relationships, interpretability gains will be limited.

### Mechanism 3
- Claim: CORE is model-agnostic and can be applied to various existing KT models.
- Mechanism: CORE introduces a separate network branch to capture the direct effect of questions, which can be added to any KT model without modifying its core architecture.
- Core assumption: The direct effect of questions on responses is independent of the specific KT model used.
- Evidence anchors:
  - [abstract] "The CORE framework is applicable to various existing KT models, and we implement it based on the prevailing DKT, DKVMN, and AKT models, respectively."
  - [section] "Our CORE framework is model-agnostic, meaning that it can be implemented with different existing KT models."
- Break condition: If the direct effect is highly model-specific, or if the additional branch interferes with the original model's learning, the approach may not generalize well.

## Foundational Learning

- Concept: Causal inference and counterfactual reasoning
  - Why needed here: CORE relies on counterfactual reasoning to estimate the direct causal effect of questions on responses, which is then subtracted from the total effect to produce a debiased prediction.
  - Quick check question: What is the difference between the total causal effect and the direct causal effect in the context of CORE?

- Concept: Knowledge tracing and student modeling
  - Why needed here: CORE is applied to knowledge tracing models to improve their understanding of students' knowledge states by mitigating the impact of answer bias.
  - Quick check question: How does answer bias affect the performance of traditional knowledge tracing models?

- Concept: Deep learning and neural network architectures
  - Why needed here: CORE uses neural network branches to capture the causal paths and estimate the causal effects, which requires understanding of deep learning concepts.
  - Quick check question: What are the key components of a neural network architecture for knowledge tracing?

## Architecture Onboarding

- Component map: Student-only branch -> Student-question branch -> Question-only branch -> Debiased prediction (Total effect - Direct effect)
- Critical path: Estimate total causal effect (original KT model) → Estimate direct causal effect (question-only branch) → Subtract direct from total → Produce debiased prediction
- Design tradeoffs: CORE trades off some model complexity (due to the additional branches) for improved debiasing and interpretability. The choice of the original KT model and the design of the additional branches are key tradeoffs.
- Failure signatures: CORE may fail if the counterfactual simulation cannot accurately estimate the direct effect, if the total effect is not properly captured, or if the causal graph is misspecified.
- First 3 experiments:
  1. Implement CORE on a simple KT model (e.g., DKT) and evaluate its performance on a benchmark dataset with known answer bias.
  2. Compare the debiased predictions of CORE with the original predictions of the KT model to assess the impact of debiasing.
  3. Analyze the contributions of each causal path by ablating the student-only and question-only branches and evaluating the performance changes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the CORE framework be adapted to handle non-binary responses, such as multiple-choice questions or open-ended answers, while maintaining its effectiveness in mitigating answer bias?
- Basis in paper: [explicit] The paper mentions the potential to extend the method beyond binary correctness prediction and suggests considering multiple-choice questions and open-ended answers.
- Why unresolved: The paper focuses on binary classification tasks, and the adaptation to more complex response types requires further exploration of how the causal effects and debiasing mechanisms would apply.
- What evidence would resolve it: Successful implementation and validation of CORE on datasets with non-binary responses, demonstrating improved performance and reduced answer bias.

### Open Question 2
- Question: Can the CORE framework be integrated with graph-based knowledge tracing models, which incorporate relationships between questions and students, to further enhance its performance and interpretability?
- Basis in paper: [inferred] The paper reviews graph-based deep learning methods for KT but does not explore integrating CORE with these approaches.
- Why unresolved: The integration of CORE with graph-based models could provide new insights into how causal effects propagate through the graph structure and how answer bias is influenced by these relationships.
- What evidence would resolve it: Experimental results showing improved performance and interpretability when CORE is applied to graph-based KT models compared to their standard implementations.

### Open Question 3
- Question: How does the performance of CORE vary across different levels of answer bias in the training data, and what is the optimal strategy for balancing the trade-off between debiasing and maintaining model accuracy?
- Basis in paper: [explicit] The paper discusses how CORE's advantage increases with stronger answer bias and mentions the potential benefits of incorporating additional BCE loss for better modeling the direct impact of questions.
- Why unresolved: The optimal balance between debiasing and accuracy may depend on the specific dataset and the level of answer bias present, requiring further investigation into the trade-offs and the impact on different types of questions.
- What evidence would resolve it: Systematic experiments varying the level of answer bias in the training data and evaluating the performance of CORE across different scenarios, providing insights into the optimal strategy for debiasing.

## Limitations

- The counterfactual simulation mechanism relies heavily on assumptions about cleanly separating direct and total causal effects, with limited analysis of when these assumptions might break down
- Performance gains, while statistically significant, may not translate to real-world educational settings where answer bias is more complex than simple question-level effects
- The paper lacks detailed analysis of how the debiasing approach performs when answer bias is naturally occurring versus artificially created

## Confidence

- High confidence: The CORE framework's model-agnostic nature and its core mechanism of disentangling direct and total causal effects
- Medium confidence: The effectiveness of the debiasing approach on the newly created unbiased test sets
- Medium confidence: The interpretability improvements claimed through explicit causal path modeling

## Next Checks

1. Test CORE's robustness by introducing synthetic answer bias at different levels (10%, 30%, 50%) to verify consistent debiasing performance across bias intensities
2. Conduct ablation studies removing the KL divergence constraint to quantify its contribution to debiasing effectiveness
3. Apply CORE to real-world deployment scenarios with naturally occurring answer bias rather than artificially created unbiased test sets to validate practical utility