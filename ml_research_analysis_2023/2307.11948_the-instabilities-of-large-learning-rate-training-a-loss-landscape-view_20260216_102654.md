---
ver: rpa2
title: 'The instabilities of large learning rate training: a loss landscape view'
arxiv_id: '2307.11948'
source_url: https://arxiv.org/abs/2307.11948
tags:
- learning
- loss
- training
- landscape
- hessian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the instabilities that arise when training
  deep neural networks with large learning rates, an attractive but unstable regime.
  The authors study the loss landscape through the Hessian matrix during training,
  employing a bulk-outlier decomposition to characterize the instabilities of gradient
  descent.
---

# The instabilities of large learning rate training: a loss landscape view

## Quick Facts
- arXiv ID: 2307.11948
- Source URL: https://arxiv.org/abs/2307.11948
- Reference count: 40
- Primary result: Large learning rates cause gradient descent instabilities that reshape the loss landscape through flattening and shifting phenomena

## Executive Summary
This paper investigates the instabilities that arise when training deep neural networks with large learning rates, an attractive but unstable regime. The authors study the loss landscape through the Hessian matrix during training, employing a bulk-outlier decomposition to characterize the instabilities of gradient descent. They observe two key phenomena: landscape flattening, where the worst-case sharpness of solutions decreases as the number of instabilities increases, and landscape shift, where the loss landscape shifts at each training instability. The orientation of the landscape can remain similar at low learning rates, while high learning rates encourage the exploration of new solutions. The authors provide empirical evidence on synthetic datasets and real-world tasks, such as Fashion-MNIST and CIFAR-10, to support their findings.

## Method Summary
The authors compute the Hessian matrix during training using Hessian-vector products and Lanczos iteration, then perform an outlier-bulk decomposition to identify the most informative directions (effective parameters) in the loss landscape. They train models with varying learning rates from stable (η=0.01) to unstable regimes (η up to 0.30) on synthetic and real datasets. The analysis focuses on training trajectories, identifying heating/cooling phases during instabilities, and measuring landscape properties through sharpness (λmax) and similarity metrics. A k-layer approximation to the full Hessian is introduced to scale the analysis to deeper networks.

## Key Results
- Large learning rates cause gradient descent instabilities that lead to landscape flattening, where the worst-case sharpness of solutions decreases as the number of instabilities increases
- The loss landscape shifts at each training instability, with high learning rates encouraging exploration of new solutions compared to low learning rates
- The "effective" parameters of the model, approximated by the top-m sharpest eigenvectors of the Hessian, control important degrees of freedom that correspond to good model performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient descent instabilities in the large learning rate regime cause the loss landscape to flatten over time
- Mechanism: When the learning rate exceeds the stability threshold, gradient descent becomes unstable and undergoes heating and cooling phases. During these phases, the number of instabilities increases, and the worst-case sharpness (λmax) of the loss landscape decreases
- Core assumption: The stability threshold is defined by the largest eigenvalue of the loss Hessian, and exceeding this threshold leads to instabilities that reshape the landscape
- Evidence anchors:
  - [abstract]: "We observe the striking phenomena of landscape flattening and landscape shift, both of which are intimately connected to the instabilities of training."
  - [section]: "As we observe landscape flattening and landscape shift, the constancy of landscape orientation and validation loss provides further evidence for the connection between 'effective' parameters and generalisation."
  - [corpus]: Weak evidence; related papers discuss stability and generalization but do not explicitly confirm landscape flattening
- Break condition: If the learning rate is so high that the model diverges, the landscape flattening effect would not be observable

### Mechanism 2
- Claim: Large learning rates encourage the exploration of new solutions by shifting the loss landscape
- Mechanism: During instabilities, the loss landscape shifts, changing the orientation of the landscape. High learning rates promote these shifts more than low learning rates, leading to the exploration of new solutions
- Core assumption: The orientation of the loss landscape governs the performance of the solutions, and shifting the landscape can lead to the discovery of better solutions
- Evidence anchors:
  - [abstract]: "The orientation of the landscape, which governs the performance of the solutions, can remain similar at low ηs while high ηs encourage the exploration of new solutions."
  - [section]: "As η is increased, the trajectories become less similar to the baseline, until η = 0.20 beyond which the trajectories become extremely dissimilar. The similarity of trajectories with η to the smooth baseline supports the view that low learning rates tend to preserve existing solutions."
  - [corpus]: Weak evidence; related papers discuss training instabilities but do not explicitly confirm landscape shifts
- Break condition: If the learning rate is too low, the landscape shifts may be minimal, and the exploration of new solutions may be limited

### Mechanism 3
- Claim: The "effective" parameters of the model, approximated by the top-m sharpest eigenvectors of the Hessian, control important degrees of freedom that correspond to good model performance
- Mechanism: By perturbing the model weights along the eigen-directions of the Hessian, we can measure the effect on the output space and identify the specific degrees of freedom that control performance
- Core assumption: The sharpest eigenvectors of the Hessian correspond to the most informative directions in the loss landscape, and perturbing along these directions will have the most significant impact on the model's output
- Evidence anchors:
  - [abstract]: "We employ a bulk-outlier decomposition of the Hessian, where each outlier (sharp) eigendirection of the Hessian represents an 'effective' parameter of the model."
  - [section]: "The connection between Hessian eigen-directions to problem-specific degrees-of-freedom... We exploited the connection between Hessian eigen-directions to problem-specific degrees-of-freedom, so strengthening this connection would be beneficial toward generalisation."
  - [corpus]: Weak evidence; related papers discuss Hessian structure but do not explicitly confirm the connection between eigenvectors and effective parameters
- Break condition: If the model is too simple or the dataset is too small, the connection between eigenvectors and effective parameters may not hold

## Foundational Learning

- Concept: Hessian matrix and its role in characterizing the loss landscape
  - Why needed here: The Hessian matrix is used to quantify the curvature of the loss landscape, which is crucial for understanding the stability and generalization of neural networks
  - Quick check question: What is the relationship between the Hessian matrix and the curvature of the loss landscape?

- Concept: Gradient descent and its stability conditions
  - Why needed here: Gradient descent is the optimization algorithm used to train neural networks, and understanding its stability conditions is essential for selecting appropriate learning rates
  - Quick check question: What is the stability threshold for gradient descent, and how is it related to the Hessian matrix?

- Concept: Outlier-bulk decomposition of the Hessian
  - Why needed here: The outlier-bulk decomposition helps identify the most informative directions in the loss landscape, which correspond to the effective parameters of the model
  - Quick check question: What is the difference between the outlier and bulk components of the Hessian, and how are they used in the analysis?

## Architecture Onboarding

- Component map: Synthetic datasets (W-reg, SRC) -> Small MLP/CNN training with varying learning rates -> Hessian computation via HVP and Lanczos iteration -> Outlier-bulk decomposition -> Landscape analysis (sharpness, similarity metrics) -> Observations of flattening and shift
- Critical path: Compute Hessian via HVP and Lanczos iteration → Perform outlier-bulk decomposition → Analyze eigenvectors for landscape properties → Observe training instabilities and their effects on sharpness and orientation
- Design tradeoffs: The tradeoff between using large learning rates (which can lead to instabilities but may find better solutions) and using small learning rates (which are stable but may get stuck in local minima)
- Failure signatures: Diverging loss, non-monotonic loss decrease, and lack of landscape flattening or shift
- First 3 experiments:
  1. Train a simple neural network on a small dataset with a range of learning rates, and analyze the loss landscape using the Hessian matrix
  2. Perform the outlier-bulk decomposition of the Hessian and study the resulting eigenvectors to understand the effective parameters of the model
  3. Compare the loss landscapes of models trained with large and small learning rates to observe the effects of landscape flattening and shift

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the maximum sharpness of solutions evolve over very long timescales when using large learning rates?
- Basis in paper: [explicit] The paper shows that delaying the reduction of the learning rate reduces the worst-case sharpness of solutions, suggesting that the maximum sharpness decreases as the number of instabilities increases
- Why unresolved: The experiments in the paper only observe the trajectory up to a certain point. It is unclear how the maximum sharpness continues to evolve if the training were to continue indefinitely
- What evidence would resolve it: Conducting experiments that run the training for an extended period with large learning rates and observing the evolution of the maximum sharpness of solutions would provide insights into the long-term behavior

### Open Question 2
- Question: What are the specific mechanisms behind the cooling phase of gradient descent instabilities?
- Basis in paper: [explicit] The paper mentions that the cooling phase is less well studied compared to the heating phase, and existing studies like Lewkowycz et al. [20] provide explanations for the heating phase but not the cooling phase
- Why unresolved: While the paper provides evidence for the existence of cooling phases, it does not delve into the specific mechanisms that cause them. Understanding these mechanisms would provide a more comprehensive understanding of the instabilities of gradient descent
- What evidence would resolve it: Conducting detailed analyses of the cooling phase, including studying the behavior of the loss landscape, the eigenvalues of the Hessian, and the gradients during this phase, would help uncover the underlying mechanisms

### Open Question 3
- Question: How does the ratio of the upper and lower learning rates in cyclic learning rate schedules affect the exploration and exploitation of loss landscapes?
- Basis in paper: [explicit] The paper briefly mentions that the ratio of the upper and lower learning rates in cyclic schedules appears to play an important role in the exploration of loss landscapes, but it does not provide a detailed analysis or explanation
- Why unresolved: While the paper acknowledges the significance of the ratio, it does not investigate how different ratios affect the balance between exploration and exploitation. Understanding this relationship would provide insights into designing effective cyclic learning rate schedules
- What evidence would resolve it: Conducting experiments with various cyclic learning rate schedules, systematically varying the ratio of the upper and lower learning rates, and analyzing the resulting exploration and exploitation of loss landscapes would provide evidence to understand the impact of the ratio

## Limitations

- The outlier-bulk decomposition of the Hessian requires careful implementation, and the exact thresholds for detecting heating/cooling phases are not fully specified
- The connection between effective parameters and generalization, while supported by some evidence, needs further validation
- The k-layer approximation for deep networks introduces potential errors that are not thoroughly explored

## Confidence

- Landscape flattening and shift phenomena: Medium confidence
- Outlier-bulk decomposition methodology: Medium confidence
- k-layer approximation for deep networks: Low confidence

## Next Checks

1. Verify the outlier-bulk decomposition implementation by testing on simpler models where analytical solutions are possible
2. Experiment with different thresholds for detecting heating/cooling phases and analyze their impact on observed landscape phenomena
3. Test the landscape flattening and shift effects on additional architectures (e.g., ResNets, Transformers) to assess generalizability