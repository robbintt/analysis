---
ver: rpa2
title: 'Processing Natural Language on Embedded Devices: How Well Do Transformer Models
  Perform?'
arxiv_id: '2304.11520'
source_url: https://arxiv.org/abs/2304.11520
tags:
- bert
- robot
- dataset
- task
- table
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an exploratory study of BERT-based language
  models on resource-constrained embedded systems, focusing on real-world robotic
  platforms. The study evaluates popular BERT variants (BERT, RoBERTa, DistilBERT,
  TinyBERT) across three NLP tasks (intent classification, sentiment classification,
  named entity recognition) on Raspberry Pi hardware configurations.
---

# Processing Natural Language on Embedded Devices: How Well Do Transformer Models Perform?

## Quick Facts
- arXiv ID: 2304.11520
- Source URL: https://arxiv.org/abs/2304.11520
- Reference count: 17
- Key outcome: BERT-based models can run complex NLP tasks on resource-constrained embedded systems, with pruning reducing model size by up to 70% while maintaining 80% accuracy

## Executive Summary
This study evaluates BERT-based language models on resource-constrained embedded systems, specifically Raspberry Pi hardware, across three NLP tasks: intent classification, sentiment classification, and named entity recognition. The research demonstrates that complex NLP tasks are feasible on embedded systems without GPUs by exploring various BERT variants (BERT, RoBERTa, DistilBERT, TinyBERT) and optimization techniques including attention head pruning and layer reduction. A comprehensive performance lookup table is developed to guide system designers in selecting optimal model configurations based on specific accuracy requirements and resource constraints.

## Method Summary
The study fine-tunes pre-trained BERT variants on four datasets (HuRIC for intent classification, GoEmotion for sentiment classification, CoNLL and WNUT17 for named entity recognition) using specific hyperparameters. Custom BERT architectures are created by reducing layers and pruning attention heads based on entropy calculations. Performance is evaluated across multiple metrics including F1 score, model size, memory usage, inference time, and energy consumption on Raspberry Pi boards with different RAM configurations (2GB, 4GB, 8GB).

## Key Results
- Complex NLP tasks like sentiment classification are feasible on embedded systems without GPUs
- Pruning techniques can reduce model size by up to 70% while maintaining 80% of original accuracy
- Smaller BERT variants (DistilBERT, TinyBERT) perform poorly on complex multi-label tasks like sentiment classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pruning attention heads reduces model size while maintaining accuracy for complex NLP tasks.
- Mechanism: The method calculates entropy for each attention head's output distribution, masks heads with lowest entropy (least important), and iteratively prunes until F1 score drops below a threshold.
- Core assumption: Attention heads with lower entropy contribute less to model performance and can be safely removed.
- Evidence anchors:
  - [abstract] "Pruning techniques can reduce model size by up to 70% while maintaining 80% of original accuracy"
  - [section 4.2] "For each attention head, we calculate the head importance by calculating the entropy of each head"
  - [corpus] Weak - no corpus papers specifically address entropy-based attention head pruning in BERT
- Break condition: If pruning causes F1 score to drop below the predefined threshold, or if entropy calculation fails to identify truly unimportant heads.

### Mechanism 2
- Claim: Smaller BERT variants (DistilBERT, TinyBERT) perform poorly on complex multi-label tasks.
- Mechanism: These models use knowledge distillation which works well for simple classification but struggles with tasks requiring nuanced understanding like multi-label sentiment classification.
- Core assumption: Complex tasks require more parameters and deeper architectures than simple tasks.
- Evidence anchors:
  - [abstract] "complex NLP tasks like sentiment classification are feasible on embedded systems even without GPUs"
  - [section 5.1] "DistilBERT and TinyBERT failed drastically, as they achieved a very low F1 Score" for GoEmotion dataset
  - [corpus] Weak - corpus doesn't contain specific studies on multi-label sentiment performance degradation in distilled models
- Break condition: If distilled models show comparable performance to base models on complex tasks, or if dataset complexity is overestimated.

### Mechanism 3
- Claim: Custom BERT architectures with reduced layers can run on resource-constrained devices while maintaining acceptable accuracy.
- Mechanism: By reducing the number of layers (e.g., from 12 to 2-6) and pruning attention heads, models become small enough to fit in memory constraints while preserving essential features for the task.
- Core assumption: Not all layers in BERT are equally important for specific downstream tasks, allowing selective reduction.
- Evidence anchors:
  - [abstract] "where BERT Base model with 12 layers cannot run on a resource-constrained device, using a lesser number of layers enable a model to execute on tiny devices"
  - [section 5.2] "two layers of BERT Base (instead of 12), the model size reduces significantly, but so does the accuracy"
  - [corpus] Weak - corpus lacks studies on layer-reduced BERT variants for embedded deployment
- Break condition: If accuracy drops below acceptable thresholds for the target application, or if reduced models cannot capture task-specific features.

## Foundational Learning

- Concept: Entropy-based attention head importance calculation
  - Why needed here: This metric determines which attention heads can be pruned without significant accuracy loss
  - Quick check question: How does entropy relate to the information content of attention head outputs?

- Concept: Knowledge distillation trade-offs
  - Why needed here: Understanding why distilled models fail on complex tasks helps justify custom architecture development
  - Quick check question: What types of NLP tasks benefit most from full BERT architecture versus distilled variants?

- Concept: Resource-constrained model deployment
  - Why needed here: Critical for selecting appropriate BERT variants based on available memory, processing power, and energy constraints
  - Quick check question: What are the typical memory and computational requirements for running BERT-base versus distilled variants on embedded devices?

## Architecture Onboarding

- Component map: Input speech → Speech-to-text conversion → NLP processing (intent, sentiment, NER) → ROS topic communication → Robot action execution

- Critical path: Input speech → Speech-to-text conversion → NLP processing (intent, sentiment, NER) → ROS topic communication → Robot action execution

- Design tradeoffs: Model accuracy vs. resource constraints (memory, inference time, energy consumption), with pruning providing size reduction at potential accuracy cost, and layer reduction offering more aggressive size reduction with larger accuracy impact.

- Failure signatures: Models failing to load due to memory constraints, excessive inference time causing poor user experience, accuracy dropping below acceptable thresholds for the application, or energy consumption exceeding battery capacity.

- First 3 experiments:
  1. Run BERT-base on 2GB Raspberry Pi to establish baseline performance and identify memory constraints
  2. Implement attention head pruning on BERT-base and measure accuracy retention vs. size reduction
  3. Test reduced-layer BERT variants (2-6 layers) on target hardware to find optimal balance of accuracy and resource usage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the performance of BERT-based models vary when deployed on microcontrollers with even more limited resources than the Raspberry Pi?
- Basis in paper: [explicit] The paper explores BERT-based models on resource-constrained embedded systems, specifically Raspberry Pi boards with 2GB, 4GB, and 8GB RAM configurations. The authors note that their study is limited to these platforms and do not explore microcontrollers.
- Why unresolved: The paper does not extend its analysis to microcontrollers, which typically have significantly less memory and processing power than Raspberry Pi boards. This leaves open the question of whether the observed performance characteristics would hold for even more constrained devices.
- What evidence would resolve it: Experimental results showing the performance of BERT-based models on various microcontroller platforms with different memory and processing constraints, compared to the Raspberry Pi results.

### Open Question 2
- Question: How do the performance trade-offs change when applying pruning techniques to BERT models beyond attention heads, such as pruning weights or neurons?
- Basis in paper: [explicit] The paper mentions that pruning can be applied to weights, neurons, layers, channels, and attention heads, but only focuses on pruning attention heads in their experiments. The authors note that they "focus on pruning attention heads" and do not explore other pruning methods.
- Why unresolved: The paper provides limited information on how other pruning techniques might affect the performance trade-offs of BERT models, leaving uncertainty about whether attention head pruning is the most effective approach.
- What evidence would resolve it: Comparative experimental results showing the performance impact of different pruning techniques (weights, neurons, layers, channels, attention heads) on BERT models, including their effects on model size, accuracy, and resource consumption.

### Open Question 3
- Question: How would the results differ if the study included datasets that are more representative of real-world robotic applications and user interactions?
- Basis in paper: [explicit] The authors acknowledge that their study is limited to four existing datasets (HuRIC, GoEmotion, CoNLL, and WNUT17) and note that "existing datasets either (a) do not have enough examples for training deep learning models or (b) do not provide complex, practical queries to test the robustness of a given model." They suggest that building suitable datasets for IoT-specific robotics applications is an open research problem.
- Why unresolved: The paper's conclusions are based on a limited set of datasets that may not fully capture the complexity and variability of real-world robotic applications, leaving uncertainty about how the results would generalize to more diverse and challenging scenarios.
- What evidence would resolve it: Experimental results using datasets that are specifically designed to represent real-world robotic applications and user interactions, including a wide range of commands, environmental contexts, and user behaviors.

## Limitations

- The entropy-based attention head pruning method lacks comprehensive validation across diverse NLP tasks and model architectures
- Custom layer-reduced BERT variants are tested only on specific hardware configurations, limiting generalizability to other embedded platforms
- The study focuses primarily on accuracy metrics without deeply exploring robustness to real-world noise and variability in robotic environments

## Confidence

**High Confidence**: The observation that complex NLP tasks like sentiment classification are feasible on embedded systems without GPUs is well-supported by experimental results across multiple hardware configurations and BERT variants.

**Medium Confidence**: The claim that pruning techniques can reduce model size by up to 70% while maintaining 80% of original accuracy requires further validation across different task types and model architectures.

**Low Confidence**: The entropy-based attention head pruning mechanism's effectiveness in identifying truly unimportant heads across different NLP tasks remains unproven.

## Next Checks

1. **Cross-task pruning validation**: Apply the entropy-based attention head pruning algorithm to BERT models across diverse NLP tasks (question answering, text summarization, language modeling) beyond the three evaluated tasks to verify if the entropy metric consistently identifies unimportant heads across different task types and model architectures.

2. **Real-world noise robustness testing**: Deploy the optimized BERT models on actual robotic platforms operating in realistic environments with varying background noise levels, speaker accents, and environmental conditions to evaluate performance degradation compared to controlled laboratory conditions.

3. **Alternative embedded platform benchmarking**: Test the same BERT model configurations and pruning techniques on a range of embedded platforms including NVIDIA Jetson series, Google Coral, and microcontroller-based systems to validate the transferability of the performance lookup table and identify platform-specific optimization opportunities.