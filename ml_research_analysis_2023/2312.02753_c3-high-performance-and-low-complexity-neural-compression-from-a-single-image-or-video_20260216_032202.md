---
ver: rpa2
title: 'C3: High-performance and low-complexity neural compression from a single image
  or video'
arxiv_id: '2312.02753'
source_url: https://arxiv.org/abs/2312.02753
tags:
- latent
- neural
- image
- video
- entropy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: C3 is a neural compression method that overfits a small model to
  each image or video separately, achieving high rate-distortion performance with
  low decoding complexity. It builds on COOL-CHIC and introduces several improvements
  for images, such as soft-rounding, Kumaraswamy noise, and GELU activations.
---

# C3: High-performance and low-complexity neural compression from a single image or video

## Quick Facts
- **arXiv ID**: 2312.02753
- **Source URL**: https://arxiv.org/abs/2312.02753
- **Reference count**: 40
- **Key outcome**: C3 is a neural compression method that overfits a small model to each image or video separately, achieving high rate-distortion performance with low decoding complexity. It builds on COOL-CHIC and introduces several improvements for images, such as soft-rounding, Kumaraswamy noise, and GELU activations. For videos, C3 uses 3D latents, wider contexts, and custom masking. On the CLIC2020 image benchmark, C3 matches VTM with less than 3k MACs/pixel for decoding, while on the UVG video benchmark, it matches VCT with less than 5k MACs/pixel for decoding.

## Executive Summary
C3 is a neural image and video compression method that achieves high rate-distortion performance with low decoding complexity by overfitting a small neural network to each image or video separately. Building on the COOL-CHIC framework, C3 introduces several improvements including soft-rounding, Kumaraswamy noise, and GELU activations for images, as well as 3D latents and custom masking for videos. The method demonstrates competitive performance against traditional codecs like VTM and VCT while requiring significantly fewer MACs/pixel for decoding.

## Method Summary
C3 optimizes a small synthesis network and entropy model to fit each image or video individually, rather than training a large shared decoder. The method uses multi-resolution latent grids, soft-rounding for quantization-aware training, and Kumaraswamy noise for better optimization. For videos, C3 extends to 3D latents and learns custom masking to exploit temporal correlations. The approach is evaluated on the Kodak, CLIC2020, and UVG datasets, showing RD performance matching or exceeding traditional codecs with substantially lower decoding complexity.

## Key Results
- On CLIC2020, C3 matches VTM with less than 3k MACs/pixel for decoding
- On UVG video benchmark, C3 matches VCT with less than 5k MACs/pixel for decoding
- Decoding complexity is an order of magnitude lower than neural baselines with similar RD performance
- C3 significantly outperforms COOL-CHICv2, the previous state-of-the-art in learned image compression

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Low decoding complexity is achieved by overfitting small neural networks to each image/video separately rather than using a large shared decoder.
- Mechanism: By fitting a tiny synthesis and entropy network to each individual image or video patch, the decoder only needs to reconstruct one specific instance, avoiding the complexity of a general-purpose decoder that must handle diverse inputs.
- Core assumption: The image/video can be adequately represented by a small neural field without loss of perceptual quality.
- Evidence anchors:
  - [abstract]: "Instead of generalizing across images, COIN overfits a neural network to a single image... As the decoder only needs to reconstruct a single image, the resulting network is significantly smaller than traditional neural decoders."
  - [section]: "The resulting decoding complexity of C3 can be an order of magnitude lower than neural baselines with similar RD performance."
  - [corpus]: Weak - no direct citations about overfitting complexity benefits in related work.
- Break condition: If the single-image model cannot capture enough detail, the decoded image quality will degrade and require a larger network, increasing complexity.

### Mechanism 2
- Claim: Improved RD performance comes from better quantization-aware optimization techniques.
- Mechanism: C3 replaces uniform noise with Kumaraswamy noise and uses soft-rounding with annealed temperature, which better approximates the rounding operation during optimization, leading to more compressible latents.
- Core assumption: The quantization error distribution is not uniform in practice, so alternative noise distributions can improve optimization.
- Evidence anchors:
  - [section]: "We replace uniform noise with samples from the Kumaraswamy distribution... By controlling its shape parameters we can interpolate between a peaked (lower noise) distribution at beginning of stage 1 and a uniform distribution at the end."
  - [section]: "Soft-rounding does not create an information bottleneck as it is an invertible function. Therefore, adding noise is still necessary for reliable compression."
  - [corpus]: Weak - Kumaraswamy noise specific evidence not in related work; assumption based on internal findings.
- Break condition: If noise annealing is too aggressive or temperature schedule is poorly tuned, gradients may vanish or optimization may fail to converge.

### Mechanism 3
- Claim: Enhanced entropy modeling via conditional and resolution-dependent modeling improves compression efficiency.
- Mechanism: C3 optionally includes latents from previous grids in the context and uses separate or FiLM-based networks per resolution, allowing the entropy model to exploit inter-grid correlations.
- Core assumption: Latent grids at different resolutions are correlated and this correlation can be exploited to reduce bitrate.
- Evidence anchors:
  - [section]: "We optionally allow the context at a particular latent location to also include values from the previous grid... We optionally allow the network to be resolution-dependent."
  - [section]: "COOL-CHIC uses the same entropy network to independently model latent grids of starkly varying resolutions."
  - [corpus]: Weak - no citations directly comparing resolution-dependent entropy models; this is an internal extension.
- Break condition: If context expansion adds too many parameters without significant bitrate savings, RD performance may worsen due to increased model size.

## Foundational Learning

- Concept: Quantization-aware training with integrated Laplace distribution
  - Why needed here: Neural compression requires discretizing continuous latents for transmission; without quantization-aware optimization, the continuous model may not perform well when quantized.
  - Quick check question: Why does C3 use an integrated Laplace distribution during optimization instead of directly quantizing the latents?

- Concept: Autoregressive entropy modeling
  - Why needed here: The entropy model must estimate the probability of each latent entry given previously decoded entries to enable lossless compression.
  - Quick check question: How does the causal masking in the entropy model's context prevent information leakage during decoding?

- Concept: Soft-rounding and noise annealing
  - Why needed here: To approximate the hard rounding operation during training while maintaining gradient flow and preventing overfitting to continuous values.
  - Quick check question: What is the role of the Kumaraswamy noise distribution in stage 1 optimization?

## Architecture Onboarding

- Component map:
  Multi-resolution latent grids -> Synthesis network -> Upsampling layer -> Output image
  Entropy network -> Quantization layer -> Latent grids

- Critical path:
  1. Decode entropy parameters for current latent entry using context
  2. Sample/round latent value using Laplace distribution
  3. Upsample all latent grids to full resolution
  4. Apply synthesis network to predict image pixels
  5. Output RGB image

- Design tradeoffs:
  - Small networks → low complexity but limited expressiveness
  - Single-image training → no generalization but high per-instance quality
  - Autoregressive entropy → sequential decoding but high compression efficiency
  - Learned upsampling → better quality but higher complexity vs fixed

- Failure signatures:
  - Poor RD performance → check if quantization step too coarse or entropy model underfits
  - Visible artifacts → check if latent grids lack high-frequency content or synthesis network too shallow
  - Slow encoding → check optimization convergence or hyperparameter settings
  - High decoding complexity → check if synthesis/entropy networks are larger than necessary

- First 3 experiments:
  1. Replace soft-rounding with hard rounding during stage 1 to see impact on RD performance and convergence
  2. Disable conditioning on previous latent grid to measure bitrate increase
  3. Switch from GELU to ReLU activations to quantify expressiveness vs complexity tradeoff

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions. However, several unresolved issues are apparent from the methodology and results, including the impact of different noise distributions during optimization, the scalability of the approach to larger input sizes, and the potential for combining the learned masking approach with other motion estimation techniques in video compression.

## Limitations

- The improvements over COOL-CHIC are incremental rather than fundamental, with many contributions building directly on existing techniques
- The video-specific extensions are less thoroughly validated, with only one video codec (VCT) used as a comparison point
- The claim of "low-complexity" is relative - while decoding complexity is reduced compared to other neural methods, it remains higher than traditional codecs like VTM and HEVC

## Confidence

- **High confidence**: The core claim that overfitting small neural networks to individual images/videos enables low decoding complexity is well-supported by the ablation studies and complexity measurements. The empirical results showing C3's RD performance matching or exceeding traditional codecs are reproducible and convincing.

- **Medium confidence**: The specific technical improvements (Kumaraswamy noise, soft-rounding, GELU activations) are shown to work in practice, but their individual contributions are not fully isolated. The video extensions (3D latents, custom masking) show promise but lack comprehensive validation.

- **Low confidence**: The claim that C3 achieves "high-performance" compression relative to the state-of-the-art in learned image compression is difficult to verify without more extensive comparisons to recent neural methods beyond COOL-CHICv2.

## Next Checks

1. **Ablation study of quantization techniques**: Systematically compare Kumaraswamy noise vs uniform noise, soft-rounding vs hard rounding, and different temperature schedules to quantify their individual contributions to RD performance and convergence stability.

2. **Cross-dataset generalization test**: Train C3 models on Kodak and test on CLIC2020 (and vice versa) to assess how well the overfitting approach generalizes to different image distributions and resolutions.

3. **Complexity breakdown analysis**: Profile the decoding complexity of each component (synthesis network, entropy model, upsampling) separately across different image resolutions to identify bottlenecks and verify the claimed order-of-magnitude reduction versus neural baselines.