---
ver: rpa2
title: 'Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box
  Audio Attacks against Speaker Recognition Models'
arxiv_id: '2311.07780'
source_url: https://arxiv.org/abs/2311.07780
tags:
- speech
- speaker
- target
- attack
- pt-aes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach to generate adversarial examples
  (AEs) against speaker recognition models with minimal knowledge of the target model.
  The attacker only needs a short speech sample of the target speaker, without any
  probing or knowledge of the target model's internals.
---

# Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models

## Quick Facts
- arXiv ID: 2311.07780
- Source URL: https://arxiv.org/abs/2311.07780
- Reference count: 40
- One-line primary result: A novel approach generates adversarial examples against speaker recognition models using only a short speech sample of the target speaker, without knowledge of the target model's internals.

## Executive Summary
This paper introduces a practical method for generating adversarial examples against speaker recognition models with minimal prior knowledge. The approach, called parrot training, uses voice conversion techniques to generate synthetic speech samples that mimic the target speaker's voice from just a short speech sample. These synthetic samples are used to train a surrogate model, from which adversarial examples are generated and shown to effectively transfer to black-box target models while maintaining perceptual quality.

## Method Summary
The method involves using one-shot voice conversion to create synthetic speech samples ("parrot speech") that mimic the target speaker's voice characteristics. These samples are then used to train a surrogate model (PT-surrogate), which serves as an approximation of the target speaker recognition model. Adversarial examples are generated from this PT-surrogate and evaluated for their transferability to black-box target models. The approach achieves high attack success rates while maintaining good perceptual quality through careful selection of carrier types and optimization strategies.

## Key Results
- Achieves attack success rates of 45.8% - 80.8% against open-source models in digital-line scenarios
- Maintains good perceptual quality while achieving high transferability to black-box models
- Introduces a new metric (Transferability-Perception Ratio) to evaluate the joint performance of transferability and perception

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Parrot training can approximate a ground-truth (GT) model using only one short speech sample of the target speaker.
- Mechanism: The one-shot voice conversion (VC) methods generate synthetic speech samples that mimic the target speaker's voice, which are then used to train a surrogate model.
- Core assumption: The one-shot VC methods can effectively convert source speaker's speech to sound like the target speaker's voice.
- Evidence anchors:
  - [abstract]: "we propose to use the one short sentence knowledge to generate more synthetic speech samples that sound like the target speaker, called parrot speech."
  - [section]: "We conduct a comprehensive study on PT-AEs in terms of their generation and quality."
  - [corpus]: No direct evidence found for the effectiveness of parrot training approximation.
- Break condition: If the one-shot VC methods fail to generate speech samples that sound like the target speaker, the parrot training will not be effective.

### Mechanism 2
- Claim: PT-AEs can effectively transfer to black-box target models.
- Mechanism: The transferability of PT-AEs is evaluated using the match rate, which measures the percentage of PT-AEs that can still be misclassified as the same target label on a black-box GT model.
- Core assumption: The transferability of AEs depends on the similarity between the surrogate and target models.
- Evidence anchors:
  - [abstract]: "the resultant PT-AEs achieve the attack success rates of 45.8% - 80.8% against the open-source models in the digital-line scenario."
  - [section]: "We then define a new metric called transferability-perception ratio (TPR) for PT-AEs generated using a specific type of carriers."
  - [corpus]: No direct evidence found for the transferability of PT-AEs to black-box target models.
- Break condition: If the surrogate and target models are significantly different, the transferability of PT-AEs will be reduced.

### Mechanism 3
- Claim: The transferability-perception ratio (TPR) can evaluate the joint performance of transferability and perception for PT-AEs.
- Mechanism: TPR is defined as the ratio of the match rate to the perception score loss, quantifying how much transferability can be achieved by degrading one unit of human perceptual quality.
- Core assumption: A higher TPR indicates a better AE quality from a joint perspective of transferability and perception.
- Evidence anchors:
  - [abstract]: "We then define a new metric called transferability-perception ratio (TPR) for PT-AEs generated using a specific type of carriers."
  - [section]: "We define a joint metric, named Transferability-Perception Ratio (TPR), as TPR(C) = m(C)/(8 - SRS(C))."
  - [corpus]: No direct evidence found for the effectiveness of TPR in evaluating the joint performance of transferability and perception.
- Break condition: If the perception score is not accurately measured, the TPR will not reflect the true joint performance of transferability and perception.

## Foundational Learning

- Concept: Voice conversion (VC) methods
  - Why needed here: To generate synthetic speech samples that mimic the target speaker's voice.
  - Quick check question: How do VC methods convert the source speaker's speech to sound like the target speaker's voice?

- Concept: Adversarial examples (AEs)
  - Why needed here: To create speech samples that can fool the speaker recognition models.
  - Quick check question: What are the key components of an adversarial example in the context of speaker recognition?

- Concept: Transferability of AEs
  - Why needed here: To evaluate the effectiveness of PT-AEs against black-box target models.
  - Quick check question: What factors affect the transferability of adversarial examples from surrogate to target models?

## Architecture Onboarding

- Component map:
  One-shot VC methods -> Parrot speech generation -> PT-surrogate model training -> AE generation using carriers -> Transferability evaluation

- Critical path:
  1. Generate parrot speech samples using one-shot VC methods
  2. Train PT-surrogate models with parrot speech samples
  3. Generate PT-AEs using different carriers
  4. Evaluate the transferability and perception of PT-AEs using TPR

- Design tradeoffs:
  - Tradeoff between the length of the target speaker's speech sample and the effectiveness of parrot training
  - Tradeoff between the type of carrier used for AE generation and the joint performance of transferability and perception

- Failure signatures:
  - Low match rate indicating poor transferability of PT-AEs
  - Low perception score indicating poor perceptual quality of PT-AEs
  - High TPR indicating good joint performance of transferability and perception

- First 3 experiments:
  1. Evaluate the effectiveness of parrot training using different one-shot VC methods
  2. Compare the transferability of PT-AEs with GT-AEs against black-box target models
  3. Investigate the impact of different carriers on the joint performance of transferability and perception using TPR

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions. However, based on the content, several implicit questions remain regarding the broader applicability and limitations of the parrot training approach.

## Limitations
- Attack assumes digital-line scenarios with full control over audio transmission
- Evaluation focuses on open-source models rather than diverse commercial systems
- Perceptual quality assessment relies on signal-based metrics rather than human studies

## Confidence
- Mechanism 1: Medium (relies on unproven effectiveness of specific VC methods)
- Mechanism 2: Medium (lacks comparison against established baselines)
- Mechanism 3: Medium (TPR metric lacks human perception validation)

## Next Checks
1. Conduct a controlled study comparing different one-shot VC methods on their ability to preserve speaker identity characteristics needed for effective adversarial training, measuring both objective metrics and human perception.
2. Evaluate PT-AEs against a broader range of black-box speaker recognition systems including commercial APIs and real-world implementations under realistic attack conditions (including over-the-air scenarios).
3. Perform ablation studies on the parrot training approach by varying the amount and quality of target speaker data to quantify the minimum requirements for successful attacks and identify failure thresholds.