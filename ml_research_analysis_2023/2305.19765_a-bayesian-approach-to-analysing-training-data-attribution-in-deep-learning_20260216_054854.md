---
ver: rpa2
title: A Bayesian Approach To Analysing Training Data Attribution In Deep Learning
arxiv_id: '2305.19765'
source_url: https://arxiv.org/abs/2305.19765
tags:
- training
- methods
- data
- bayesian
- p-values
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a Bayesian perspective on the training data
  attribution (TDA) task, modeling the learned model and the TDA estimates as random
  variables derived from posterior distributions. By treating the TDA values as distributions,
  the analysis shows that ground-truth TDA values are often dominated by noise stemming
  from model initialization and SGD batch composition, with variance often exceeding
  the mean influence.
---

# A Bayesian Approach To Analysing Training Data Attribution In Deep Learning

## Quick Facts
- arXiv ID: 2305.19765
- Source URL: https://arxiv.org/abs/2305.19765
- Authors: 
- Reference count: 40
- Key outcome: This work proposes a Bayesian perspective on the training data attribution (TDA) task, modeling the learned model and the TDA estimates as random variables derived from posterior distributions. By treating the TDA values as distributions, the analysis shows that ground-truth TDA values are often dominated by noise stemming from model initialization and SGD batch composition, with variance often exceeding the mean influence. Experiments confirm that TDA estimates (e.g., influence functions, Grad-Dot, Grad-Cos) frequently disagree with ground-truth LOO and among each other, except for consistently ranking train-test pairs by stability. The authors recommend using TDA methods only when the signal-to-noise ratio is high, i.e., when low-variance train-test pairs exist, and suggest future work evaluate TDA methods by comparing distributions rather than point estimates.

## Executive Summary
This paper introduces a Bayesian perspective on training data attribution (TDA) by treating learned models and TDA estimates as random variables derived from posterior distributions. The authors demonstrate that ground-truth TDA values are often dominated by noise from model initialization and SGD batch composition, with variance frequently exceeding mean influence. Through experiments on small-scale datasets (MNIST3 and CIFAR10) with CNN and ViT+LoRA models, they show that common TDA methods (influence functions, Grad-Dot, Grad-Cos) disagree with ground-truth leave-one-out (LOO) attribution and among themselves, except in consistently ranking train-test pairs by stability. The work recommends using TDA methods only when signal-to-noise ratios are sufficiently high and suggests evaluating methods by comparing distributions rather than point estimates.

## Method Summary
The authors treat the training data attribution task from a Bayesian perspective, modeling the learned model and TDA estimates as random variables derived from posterior distributions. They use Stochastic Weight Averaging (SWA) and Deep Ensemble (DE) with different random seeds and batch compositions to sample from the posterior p(θ|D). For each train-test pair, they compute the ground-truth TDA (leave-one-out) and approximate methods (influence functions, Grad-Dot, Grad-Cos) across these posterior samples to obtain distributions. Statistical significance is evaluated using Student's t-tests, and correlations are computed between mean and variance of TDA distributions across methods. Experiments are conducted on subsampled MNIST3 (150 train / 900 test) and CIFAR10 (500 train / 500 test) datasets using CNN and ViT+LoRA models.

## Key Results
- Ground-truth TDA values are often dominated by noise: Var(τ) > E|τ|, making them unreliable for model attribution
- TDA methods (IF, Grad-Dot, Grad-Cos) frequently disagree with ground-truth LOO and among each other, except for consistently ranking train-test pairs by stability
- High signal-to-noise ratio (Var(τ) ≪ E|τ|) is necessary for reliable TDA usage; authors recommend focusing evaluation on low-noise train-test pairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ground-truth TDA values are dominated by noise when Var(τ) > E|τ|, making them unreliable for model attribution.
- Mechanism: Randomness from model initialization and SGD batch composition creates posterior variance in p(θ|D) and p(θ\j|D\j), propagating into τ via L(z; θ\j) - L(z; θ).
- Core assumption: Deep neural networks lack a deterministic mapping from data to parameters, so training variability directly translates to TDA variability.
- Evidence anchors:
  - [abstract] "the influence of an individual training sample is often overshadowed by the noise stemming from model initialisation and SGD batch composition"
  - [section] "we observe that the ground-truth TDA values are often dominated by the noise:p Var(τ ) > E|τ |"
  - [corpus] Weak: neighbor papers discuss randomness and uncertainty but do not directly measure Var(τ) vs E|τ|.

### Mechanism 2
- Claim: TDA methods approximate local rather than global model changes, explaining their disagreement with ground-truth LOO.
- Mechanism: Methods like Grad-Dot and Grad-Cos compute influence via gradient similarities, capturing immediate parameter shifts (e.g., ATS) rather than full retraining effects.
- Core assumption: Local gradient-based perturbations correlate with but do not equal the global retraining loss difference captured by LOO.
- Evidence anchors:
  - [section] "we observe that they also correspond to a local change in the model"
  - [section] "whereas ATS considers a local scope with a small model change"
  - [corpus] Weak: neighbor work on LoRIF and influence functions mentions scalability but not local/global distinction explicitly.

### Mechanism 3
- Claim: High signal-to-noise ratio (Var(τ) ≪ E|τ|) enables reliable TDA usage.
- Mechanism: When variance is small relative to mean influence, TDA estimates become statistically significant and stable across posterior samples.
- Core assumption: Low-noise train-test pairs exist and can be identified via hypothesis testing on sampled τ distributions.
- Evidence anchors:
  - [abstract] "we argue that TDA can only be reliably used for explaining model predictions that are consistently influenced by certain training data, independent of other noise factors"
  - [section] "we recommend that researchers and practitioners confine their usage to scenarios where the signal-to-noise ratios are expected to be large enough"
  - [corpus] Weak: neighbor papers mention stability but not quantitative SNR thresholds.

## Foundational Learning

- Concept: Bayesian posterior p(θ|D) as distribution over parameters due to stochastic training.
  - Why needed here: Captures inherent randomness in deep learning so TDA can be treated as a random variable.
  - Quick check question: If you train the same model twice with different random seeds, should p(θ|D) be a point mass or a distribution?

- Concept: Hypothesis testing for TDA significance using t-test on sampled τ.
  - Why needed here: Determines whether observed influence exceeds sampling noise, enabling selection of reliable pairs.
  - Quick check question: If p-value > 0.05 for τ, what does that imply about the influence signal?

- Concept: Difference between local (gradient-based) and global (LOO) attribution scopes.
  - Why needed here: Explains why methods like Grad-Dot correlate with ATS but not with full LOO.
  - Quick check question: Which measure—ATS or LOO—captures the effect of removing a sample entirely from training?

## Architecture Onboarding

- Component map: Data sampling → Model training (CNN/ViT+LoRA) → Posterior sampling (DE-Init/DE-Batch/SWA) → TDA computation (LOO, IF, GD, GC, ATS) → Statistical analysis (mean, variance, p-values) → Correlation evaluation
- Critical path: Posterior sampling → τ estimation → p-value computation → pair selection → method comparison
- Design tradeoffs: Larger models increase p-values (less reliable) but may improve accuracy; smaller datasets reduce batch-composition noise but limit generalizability
- Failure signatures: High p-values across all pairs indicate model or dataset size issues; low correlation between mean and variance suggests unstable ranking; mismatched signs between methods reveal local/global scope differences
- First 3 experiments:
  1. Run CNN on MNIST3 with SWA+DE-Init, compute p-values for all pairs, identify low-noise subset
  2. Repeat with CIFAR10, compare p-value distributions and signal-to-noise ratios
  3. Test Grad-Dot vs. LOO on the low-noise pairs from experiment 1, report correlation of means and variances

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we reliably identify low-noise train-test pairs for TDA evaluation in practice?
- Basis in paper: [explicit] The authors observe that low-noise pairs exist but are rare, and recommend focusing evaluation on such pairs. They note identifying them requires treating TDA values as distributions and sampling multiple times from the posterior.
- Why unresolved: The paper identifies the need but doesn't provide concrete criteria or methods for identifying low-noise pairs beyond variance analysis.
- What evidence would resolve it: Development and validation of practical heuristics or statistical tests that can reliably identify low-noise train-test pairs without exhaustive sampling.

### Open Question 2
- Question: Can we develop TDA methods that better approximate the global LOO behavior rather than local perturbations?
- Basis in paper: [explicit] The authors observe that current TDA methods (IF, GD, GC) correlate better with ATS (which measures local change) than with LOO (which measures global change), indicating a gap between local and global TDA perspectives.
- Why unresolved: While the gap is identified, the paper doesn't propose specific architectural or methodological changes to bridge this gap.
- What evidence would resolve it: Novel TDA methods that demonstrate stronger correlation with LOO while maintaining computational efficiency, validated across multiple datasets and model architectures.

### Open Question 3
- Question: How does model architecture beyond size (e.g., depth, connectivity patterns) influence TDA reliability?
- Basis in paper: [inferred] The authors observe that model complexity (CNN vs ViT with LoRA) affects TDA reliability, but only compare a simple CNN to a transformer with LoRA. The analysis doesn't isolate other architectural factors.
- Why unresolved: The paper only examines two specific architectures and attributes differences primarily to parameter count rather than architectural properties.
- What evidence would resolve it: Controlled experiments varying architectural properties (depth, width, connectivity) while holding size constant, measuring their independent effects on TDA reliability.

## Limitations

- The claim that TDA values are "often dominated by noise" relies on specific dataset and model scales (small MNIST3 and CIFAR10 subsets); generalizability to larger or noisier datasets is unclear.
- The distinction between local (gradient-based) and global (LOO) attributions is demonstrated empirically but lacks formal bounds on when they diverge.
- The SNR threshold for reliable TDA usage is heuristic; no rigorous statistical power analysis is provided.

## Confidence

- **High**: Bayesian framing of TDA as random variables is mathematically sound and clearly stated.
- **Medium**: Empirical findings on noise dominance and method disagreements are reproducible given access to code, but may not extend to all domains.
- **Low**: Recommendations for SNR thresholds and pair selection lack quantitative backing and are context-dependent.

## Next Checks

1. **Scale Test**: Reproduce experiments on larger datasets (e.g., ImageNet subsets) to verify noise dominance persists.
2. **Method Scope Analysis**: Design controlled experiments (e.g., convex models) where local/global attributions should align, to test the claimed distinction.
3. **SNR Calibration**: Perform statistical power analysis to derive rigorous SNR thresholds for TDA reliability, rather than heuristic rules.