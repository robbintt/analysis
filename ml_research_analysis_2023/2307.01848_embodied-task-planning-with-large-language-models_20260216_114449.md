---
ver: rpa2
title: Embodied Task Planning with Large Language Models
arxiv_id: '2307.01848'
source_url: https://arxiv.org/abs/2307.01848
tags:
- scene
- task
- object
- arxiv
- objects
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a TAsk Planing Agent (TaPA) for embodied task
  planning with physical scene constraints. The agent generates executable plans by
  aligning large language models with visual perception models, considering existing
  objects in the scene.
---

# Embodied Task Planning with Large Language Models

## Quick Facts
- arXiv ID: 2307.01848
- Source URL: https://arxiv.org/abs/2307.01848
- Reference count: 40
- Primary result: TaPA achieves higher success rates than LLaVA and GPT-3.5 for embodied task planning

## Executive Summary
This paper proposes TaPA, an embodied task planning agent that generates executable plans by aligning large language models with visual perception models. The system grounds LLM-generated plans to physical scenes using object detection to reduce hallucination and improve plan executability. A multimodal dataset of indoor scenes, instructions, and action plans is synthetically generated using GPT-3.5 and used to fine-tune pre-trained LLMs into task planners specialized for embodied scenarios.

## Method Summary
The TaPA system consists of three main components: (1) synthetic dataset generation using GPT-3.5 to create instruction-plan pairs from scene representations, (2) object detection using open-vocabulary detectors on multi-view RGB images collected from the environment, and (3) finetuning pre-trained LLMs (LLaMA) with the generated dataset to create a task planner. During inference, the system detects objects in the scene and constrains the generated plan to only interact with detected objects, ensuring executability in the physical world.

## Key Results
- TaPA achieves higher success rates than LLaVA and GPT-3.5 in embodied task planning
- Block-wise center points for image collection strategy achieve the highest success rate
- Multi-view RGB image collection improves object detection coverage and reduces false positives

## Why This Works (Mechanism)

### Mechanism 1
Grounding LLM-generated plans to physical scenes via object detection reduces hallucination and improves plan executability. The system aligns LLM reasoning with visual perception by detecting objects in the scene and constraining generated actions to only interact with detected objects. This bridges the semantic knowledge of LLMs with physical reality.

### Mechanism 2
Large-scale synthetic dataset generation with GPT-3.5 enables training of task planners for complex, diverse household tasks. GPT-3.5 generates a multimodal dataset containing scene object lists, natural language instructions, and executable action plans. This dataset is used to fine-tune pre-trained LLMs into task planners specialized for embodied scenarios.

### Mechanism 3
Multi-view RGB image collection with strategic sampling improves object detection coverage and reduces false positives. The agent collects images from multiple locations and viewpoints using strategies like traversal, random sampling, and block-wise center points. This comprehensive coverage improves object detection accuracy compared to single-view approaches.

## Foundational Learning

- **Open-vocabulary object detection**: Traditional object detectors require predefined categories, but household environments contain diverse objects. Open-vocabulary detection can identify any object given visual input and text descriptions. *Quick check: How does open-vocabulary detection differ from traditional object detection in terms of category coverage and training requirements?*

- **Multimodal dataset generation**: Training embodied task planners requires diverse examples of instructions, scenes, and corresponding plans. Manually creating such datasets is impractical at scale. *Quick check: What are the key challenges in ensuring the synthetic instructions and plans generated by GPT-3.5 are realistic and executable?*

- **Grounding language to physical actions**: LLMs generate plans based on language understanding alone, which may reference non-existent objects. Grounding ensures plans only use objects actually present in the scene. *Quick check: How does the system verify that each action in a generated plan can be executed with the objects detected in the scene?*

## Architecture Onboarding

- **Component map**: GPT-3.5 -> Object detector (Detic) -> LLM task planner (LLaMA) -> Execution evaluation
- **Critical path**: Image collection → Object detection → Task planning → Plan execution
- **Design tradeoffs**: Dataset scale vs. quality, detection accuracy vs. computational cost, plan complexity vs. executability
- **Failure signatures**: High hallucination rates, missed objects in detection, overly complex instructions, plan-instruct mismatch
- **First 3 experiments**: 1) Evaluate object detection performance with different image collection strategies, 2) Test task planner success rate with ground truth vs. detected object lists, 3) Compare plan executability between TaPA and baseline LLMs on identical tasks

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of TaPA scale with the size and complexity of the indoor environment? The paper mentions that TaPA was tested in 80 indoor scenes, but does not explore performance variations across different environment sizes or complexities.

### Open Question 2
How does the choice of object detection model impact TaPA's performance in terms of accuracy and hallucination reduction? The paper mentions using the Detic open-vocabulary object detection framework, but does not compare its performance to other object detection models.

### Open Question 3
How does TaPA's performance compare to human performance in embodied task planning? The paper mentions that human volunteers were used to evaluate the success of TaPA's generated plans, but does not provide a comparison to human performance.

## Limitations
- Relies on synthetic dataset generation, which may not capture all real-world scenarios
- Evaluation performed in controlled simulator environments rather than real-world settings
- Object detection accuracy directly impacts plan executability but not extensively validated

## Confidence

**Confidence: Medium** - The systematic approach to embodied task planning is well-structured, but relies on assumptions about synthetic dataset quality and object detection accuracy that weren't fully validated.

**Confidence: Low** - The evaluation framework using AI2-THOR simulator provides controlled environments but may not fully capture real-world complexity, limiting generalizability.

## Next Checks

1. **Dataset Quality Analysis**: Conduct detailed analysis of the synthetic dataset generated by GPT-3.5, including statistical properties of instructions, plan complexity distribution, and qualitative assessment of task realism.

2. **Object Detection Robustness**: Systematically evaluate object detection performance across different scene types, lighting conditions, and object configurations in the AI2-THOR simulator. Measure false positive/negative rates and their impact on plan executability.

3. **Cross-Environment Generalization**: Test the TaPA system on multiple different environments within AI2-THOR and ideally on real-world scenarios to assess generalization beyond the training distribution.