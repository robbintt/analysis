---
ver: rpa2
title: Evolving Domain Adaptation of Pretrained Language Models for Text Classification
arxiv_id: '2311.09661'
source_url: https://arxiv.org/abs/2311.09661
tags:
- domain
- dataset
- domains
- target
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study investigates how pre-trained language models (PLMs)\
  \ can be adapted to evolving domain shifts (EDS) in time-series text classification,\
  \ focusing on stance detection. Three evolving domain adaptation (EDA) strategies\u2014\
  self-training, domain-adversarial training, and domain-adaptive pretraining\u2014\
  are evaluated, with an incremental self-training method that uses a dynamic buffer\
  \ and upsampling to handle label shifts."
---

# Evolving Domain Adaptation of Pretrained Language Models for Text Classification

## Quick Facts
- **arXiv ID**: 2311.09661
- **Source URL**: https://arxiv.org/abs/2311.09661
- **Reference count**: 40
- **Primary result**: Incremental self-training outperforms traditional adaptation techniques for evolving domain adaptation in stance detection

## Executive Summary
This study investigates how pre-trained language models (PLMs) can be adapted to evolving domain shifts (EDS) in time-series text classification, focusing on stance detection. Three evolving domain adaptation (EDA) strategies—self-training, domain-adversarial training, and domain-adaptive pretraining—are evaluated, with an incremental self-training method that uses a dynamic buffer and upsampling to handle label shifts. Experiments on four datasets (COVID-19 vaccination, M&A tweets, scientific abstracts, and news publishers) demonstrate that incremental self-training outperforms traditional adaptation techniques, maintaining higher macro F1 scores over time.

## Method Summary
The study compares three domain adaptation techniques—self-training (ST), domain-adaptive pretraining (DAPT), and domain-adversarial training (DANN)—with an incremental self-training method using dynamic buffering and upsampling. The approach involves fine-tuning PLMs (BERT and FLAN-T5) on source domain data, then adapting to target domains through incremental updates. The incremental method maintains a buffer of pseudo-labeled data that is updated over time, with upsampling to address label shifts. Four datasets representing different types of evolving domains are used for evaluation, with macro F1 scores measuring adaptation performance.

## Key Results
- Incremental self-training achieved Favg = 0.611 on COVID dataset vs Favg = 0.509 for unadapted baseline
- Incremental methods consistently outperformed DAPT and DANN across all datasets
- Upsampling was critical for maintaining model effectiveness in the presence of label shift

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Incremental self-training methods (BST and CST) adapt better to evolving domain shifts than single-pass methods (AST)
- **Mechanism**: By maintaining a dynamic buffer of pseudo-labeled data and updating it incrementally, the model can continuously adapt to gradual shifts in data distribution. The FIFO strategy in BST ensures that the buffer always contains the most recent and relevant pseudo-labeled examples, while CST retains all historical data to capture long-term trends.
- **Core assumption**: The domain shift between adjacent time steps is gradual enough that the model can adapt incrementally without catastrophic forgetting.
- **Evidence anchors**: [abstract] "Our analysis across various datasets reveals that this incremental method excels at adapting PLMs to EDS, outperforming traditional domain adaptation techniques."; [section 5] "Incremental self-training outperforms DAPT and DANN"

### Mechanism 2
- **Claim**: Upsampling in self-training methods is critical for maintaining model effectiveness in the presence of label shift.
- **Mechanism**: By ensuring equal representation of each class in the training data, upsampling prevents the model from becoming biased towards the majority class. This is particularly important in evolving domains where the label distribution may change over time.
- **Core assumption**: The label shift in evolving domains can be mitigated by rebalancing the class distribution in the training data.
- **Evidence anchors**: [abstract] "Crucially, we incorporate upsampling in our self-training approach to address label shift that naturally occurs in evolving domains."; [section 5] "Ablation Study: Upsampling in Self-training is Critical"

### Mechanism 3
- **Claim**: The reduced Maximum Mean Discrepancy (MMD) between adjacent domains justifies the incremental adaptation strategy.
- **Mechanism**: By quantifying the covariate shift between domains using MMD, we can show that the shift between adjacent domains is smaller than the shift between the source domain and any target domain. This justifies the use of incremental adaptation methods like CST and BST, which can continuously adjust to gradual domain changes.
- **Core assumption**: The domain shift between adjacent time steps is smaller than the shift between the source domain and any target domain.
- **Evidence anchors**: [section 5] "Analysis of Evolving Domain Shift" and Figure 3 showing MMD matrix for COVID dataset; [section 5] "The reduced MMD between adjacent domains justifies the incremental adaptation strategy like CST and BST"

## Foundational Learning

- **Concept**: Maximum Mean Discrepancy (MMD)
  - **Why needed here**: MMD is used to quantify the covariate shift between domains, which is crucial for understanding the nature of evolving domain shifts and justifying the incremental adaptation strategy.
  - **Quick check question**: What is the intuition behind using MMD to measure the difference between two probability distributions?

- **Concept**: Self-training and pseudo-labeling
  - **Why needed here**: Self-training is a key component of the incremental adaptation methods (BST and CST), where the model generates pseudo-labels for unlabeled data and then fine-tunes on this pseudo-labeled data.
  - **Quick check question**: How does self-training differ from traditional supervised learning, and what are the potential pitfalls of using pseudo-labels?

- **Concept**: Domain adaptation techniques (DANN, DAPT)
  - **Why needed here**: These techniques are compared against the incremental self-training methods to demonstrate their effectiveness in adapting to evolving domain shifts.
  - **Quick check question**: What is the main difference between DANN and DAPT, and in what scenarios might one be preferred over the other?

## Architecture Onboarding

- **Component map**: PLM (BERT or FLAN-T5) -> Classification head (BERT only) -> Buffer for pseudo-labeled data -> Upsampling module -> Domain adaptation components (DANN/DAPT)
- **Critical path**: The incremental self-training loop: generate pseudo-labels → update buffer → fine-tune on buffer → repeat for each target domain
- **Design tradeoffs**: BST vs CST involves tradeoff between computational efficiency (BST) and capturing long-term trends (CST); DANN vs DAPT involves tradeoff between implementation complexity and simplicity of continued pretraining
- **Failure signatures**: Performance degradation over time indicates insufficient adaptation; class imbalance indicates upsampling inadequacy
- **First 3 experiments**:
  1. Implement incremental self-training with fixed-size buffer (BST) and evaluate on COVID dataset
  2. Modify to use cumulative buffer (CST) and compare performance to BST
  3. Implement upsampling strategy and evaluate impact on model performance with label shift

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the text provided.

## Limitations
- Evaluation is limited to stance detection task, limiting generalizability to other text classification problems
- Assumes gradually evolving domain shifts without testing abrupt distributional changes or concept drift scenarios
- Buffer-based methods may struggle with catastrophic forgetting when long-term patterns are important

## Confidence

**High Confidence**: The superiority of incremental self-training over unadapted baselines and traditional domain adaptation techniques (DAPT, DANN) is well-supported by comparative F1 scores across multiple datasets.

**Medium Confidence**: The effectiveness of upsampling for handling label shift is demonstrated through ablation studies, but generalizability to extreme label distribution changes remains unclear.

**Low Confidence**: The assumption that domain shifts between adjacent time steps are always smaller than shifts between source and target domains may not hold in all evolving scenarios.

## Next Checks
1. Test incremental self-training on non-stance classification tasks (sentiment analysis, topic classification) to evaluate generalizability beyond the current scope.

2. Implement stress tests with abrupt domain shifts and concept drift to evaluate failure modes of incremental versus batch adaptation strategies.

3. Conduct ablation studies comparing different buffer management strategies (weighted buffers, age-based decay) against the FIFO approach to optimize long-term adaptation performance.