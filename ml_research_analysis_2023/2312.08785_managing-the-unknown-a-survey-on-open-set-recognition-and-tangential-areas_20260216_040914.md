---
ver: rpa2
title: 'Managing the unknown: a survey on Open Set Recognition and tangential areas'
arxiv_id: '2312.08785'
source_url: https://arxiv.org/abs/2312.08785
tags:
- open
- learning
- recognition
- samples
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey comprehensively reviews Open Set Recognition (OSR),
  which aims to enable classification models to detect unknown classes that emerge
  during testing while maintaining good performance on known classes. The paper examines
  recent literature, identifying common practices and limitations while highlighting
  connections to related areas such as continual learning, out-of-distribution detection,
  novelty detection, and uncertainty estimation.
---

# Managing the unknown: a survey on Open Set Recognition and tangential areas

## Quick Facts
- arXiv ID: 2312.08785
- Source URL: https://arxiv.org/abs/2312.08785
- Reference count: 40
- Primary result: Comprehensive survey identifying key challenges in Open Set Recognition including open space risk reduction and clustering-classification integration

## Executive Summary
This survey comprehensively reviews Open Set Recognition (OSR), a critical paradigm enabling classification models to detect unknown classes during testing while maintaining performance on known classes. The paper examines recent literature, identifying common practices and limitations while highlighting connections to related areas such as continual learning, out-of-distribution detection, novelty detection, and uncertainty estimation. The survey finds that reducing open space risk and combining clustering with classification remain key challenges, with most existing approaches using sequential combinations rather than simultaneous integration. It identifies several future research directions, including addressing complex class distributions, improving incremental learning of new classes, and leveraging temporal correlations between test instances.

## Method Summary
The paper conducts a comprehensive literature review of Open Set Recognition approaches, analyzing discriminative methods (SVM, k-NN, prototype learning), generative methods (GANs), and hybrid clustering-classification approaches. The survey examines common practices, limitations, and connections to related areas through systematic analysis of existing works. While providing detailed theoretical foundations and mechanism analysis, the paper does not include original experimental validation, instead synthesizing findings from the broader OSR literature.

## Key Results
- Open Space Risk (RO) reduction is central to effective OSR performance
- Sequential clustering-classification approaches dominate the field but have inherent limitations
- Prototype-based representations naturally reduce open space risk through compact class boundaries
- Most OSR approaches treat instances independently, missing opportunities for temporal correlation modeling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Open Space Risk (RO) reduction is central to effective OSR performance
- Mechanism: By limiting the feature space assigned to known classes, OSR models create clearer boundaries between known and unknown classes, reducing the probability of misclassifying unknown samples as known classes
- Core assumption: The distribution of unknown classes can be characterized by the open space surrounding known class regions
- Evidence anchors: [abstract] "reducing open space risk and combining clustering with classification remain key challenges"; [section 2.1] "This over-occupation of the space means that any unknown sample will fall in this space and be incorrectly classified as one of the KC"
- Break condition: When unknown classes have distributions that significantly overlap with known classes, making boundary delineation ineffective

### Mechanism 2
- Claim: Combining clustering and classification in sequential fashion improves OSR performance over standalone classifiers
- Mechanism: Clustering first characterizes the feature space of known classes, which is then used to improve the subsequent classification model's robustness against unknown samples
- Core assumption: The feature space characterization from clustering provides valuable information that classification alone cannot capture
- Evidence anchors: [section 3.3] "Many efforts for combining clustering and classification exist for open set scenarios, which can be implemented either sequentially or simultaneously"; [section 3.3] "Although there has been far more research in this line of work... all of them assume a open set scenario"
- Break condition: When clustering algorithms fail to properly characterize complex class distributions or when the computational overhead outweighs the performance benefits

### Mechanism 3
- Claim: Prototype-based representations naturally reduce open space risk by creating more compact class boundaries
- Mechanism: Prototypes serve as representative feature vectors for each class, creating tighter decision boundaries that leave more open space between classes for unknown detection
- Core assumption: Real-world class distributions can be adequately represented by a small number of prototypes
- Evidence anchors: [section 3.1] "The use of prototypes allows for more compact feature representations of classes, which naturally creates clearer boundaries between KC and UC in open set scenarios"; [section 3.1] "In [55] authors introduced a Convolutional Prototype Network (CPN) where prototypes per class are jointly learned during training"
- Break condition: When classes have complex, non-convex distributions that cannot be adequately represented by prototypes

## Foundational Learning

- Concept: Extreme Value Theory (EVT) in OSR
  - Why needed here: EVT provides the statistical foundation for determining decision boundaries that minimize open space risk
  - Quick check question: How does EVT help determine optimal thresholds for unknown class detection?

- Concept: Discriminative vs. Generative approaches in OSR
  - Why needed here: Understanding the fundamental difference between reducing open space through boundary manipulation versus generating synthetic unknown samples
  - Quick check question: What are the key tradeoffs between discriminative and generative approaches for open space risk reduction?

- Concept: Over-occupied space problem
  - Why needed here: This is the core challenge that OSR techniques must address to prevent misclassification of unknown samples
  - Quick check question: How does the over-occupied space problem manifest in traditional closed-set classifiers?

## Architecture Onboarding

- Component map: Input preprocessing → Feature extraction → Classification/Clustering module → Open space risk assessment → Output (known class or unknown)
- Optional: Synthetic data generation module (for generative approaches)

- Critical path: Feature extraction → Classification/Clustering → Open space risk assessment → Decision threshold application

- Design tradeoffs:
  - Sequential clustering-classification: Lower computational complexity but less optimal boundary refinement
  - Simultaneous clustering-classification: Better performance but higher computational cost and implementation complexity
  - Prototype-based: Compact representation but may struggle with complex distributions
  - Generative approaches: Can explicitly model unknowns but require careful synthetic data generation

- Failure signatures:
  - High false positive rate for unknown detection: Thresholds too conservative or feature space not properly characterized
  - High false negative rate for unknown detection: Open space risk not adequately reduced or decision boundaries too permissive
  - Degraded known class performance: Over-aggressive open space reduction or poor prototype selection

- First 3 experiments:
  1. Implement a basic OSR model using nearest neighbor distance ratio with varying threshold values to understand the impact on open space risk
  2. Compare sequential vs. simultaneous clustering-classification approaches on a simple dataset with clear class separation
  3. Evaluate prototype-based OSR against a traditional classifier on a dataset with known unknown classes to quantify open space risk reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can clustering and classification algorithms be combined more effectively in open set recognition, particularly through simultaneous rather than sequential integration?
- Basis in paper: [explicit] "Our literature review has revealed that most OSR approaches relying on clustering and classification combine both techniques in a sequential way... This practice has two inherent limitations... Very scarce works ensure that both processes benefit from each other in an open set scenario."
- Why unresolved: Current sequential approaches prevent clustering algorithms from benefiting from classification information like uncertainty feedback, limiting performance optimization.
- What evidence would resolve it: Novel frameworks demonstrating superior performance over sequential approaches by enabling bidirectional feedback between clustering and classification components in OSR tasks.

### Open Question 2
- Question: What mechanisms can be developed to leverage temporal correlations between test instances for improved open set recognition, particularly for intermittently appearing unknown classes?
- Basis in paper: [explicit] "Performing classification of each new sample in isolation is an standard evaluation protocol in OSR... However, it is often the case that UC arise gradually over time, imprinting a correlation between successive instances that can be modeled..."
- Why unresolved: Most OSR approaches treat instances independently, missing opportunities to use temporal patterns for more accurate detection and characterization of unknown classes.
- What evidence would resolve it: Demonstrated improvements in OSR performance using temporal modeling approaches that track and utilize patterns in unknown class appearances over time.

### Open Question 3
- Question: How can open set recognition systems effectively update their models when encountering new unknown classes, particularly in resource-constrained environments with limited data and time?
- Basis in paper: [explicit] "After UC have been discovered, the model needs to be updated with the new knowledge... Completely re-training the model... may not be a viable strategy in environments with tight time constraints."
- Why unresolved: Current approaches require complete retraining or human annotation, making them impractical for real-world applications with continuous data streams and unknown classes.
- What evidence would resolve it: Efficient incremental learning strategies that can incorporate new classes with minimal computational resources while maintaining performance on known classes.

## Limitations
- Reliance on qualitative analysis rather than empirical validation of proposed mechanisms
- Lack of quantitative evidence comparing sequential vs. simultaneous clustering-classification approaches
- Breadth of coverage comes at the cost of depth in specific technical implementations

## Confidence
- Open Space Risk Reduction Mechanism: Medium - Well-articulated theoretically but lacks quantitative validation
- Clustering-Classification Integration: Medium - Conceptually sound but limited empirical evidence for superiority
- Future Research Directions: High - Well-grounded in identified literature gaps and practical limitations

## Next Validation Checks
1. Conduct empirical experiments comparing sequential vs. simultaneous clustering-classification approaches on benchmark OSR datasets to quantify performance differences
2. Implement prototype-based OSR methods with varying numbers of prototypes to determine the optimal trade-off between compact representation and class distribution fidelity
3. Design experiments testing the open space risk reduction mechanism under varying levels of class overlap to identify failure conditions and boundary effectiveness