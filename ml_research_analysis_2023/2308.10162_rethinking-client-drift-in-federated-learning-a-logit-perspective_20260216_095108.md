---
ver: rpa2
title: 'Rethinking Client Drift in Federated Learning: A Logit Perspective'
arxiv_id: '2308.10162'
source_url: https://arxiv.org/abs/2308.10162
tags:
- local
- global
- learning
- distillation
- federated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the client drift problem in federated learning
  caused by non-IID data across clients. The key observation is that the difference
  in logits between local and global models increases as local training progresses,
  due to catastrophic forgetting on local data.
---

# Rethinking Client Drift in Federated Learning: A Logit Perspective

## Quick Facts
- arXiv ID: 2308.10162
- Source URL: https://arxiv.org/abs/2308.10162
- Reference count: 40
- Key outcome: FedCSD achieves up to 8.47% higher accuracy than FedAvg on FEMNIST by aligning local and global logits using class prototype similarity distillation with an adaptive mask.

## Executive Summary
This paper addresses the client drift problem in federated learning caused by non-IID data distributions across clients. The authors observe that local models diverge from the global model in logit space as local training progresses due to catastrophic forgetting on local data. To address this, they propose FedCSD, which uses class prototype similarity distillation to align local and global logits, combined with an adaptive mask to filter unreliable global logits. The method is evaluated on CIFAR-100, FEMNIST, and Office-Caltech-10, showing significant improvements over FedAvg and other state-of-the-art methods under various non-IID settings.

## Method Summary
FedCSD addresses client drift by introducing class prototype similarity distillation to align local and global model logits. The method computes a global class prototype from local prototypes, then uses the similarity between local logits and this prototype to weight the distillation loss. An adaptive mask filters out unreliable global logits based on teacher confidence. The algorithm employs a temporal moving average teacher model for stability. During local training, each client minimizes both cross-entropy loss and the class prototype similarity distillation loss, with the global model updated via FedAvg aggregation.

## Key Results
- FedCSD achieves up to 8.47% higher accuracy than FedAvg on FEMNIST under non-IID settings
- The method outperforms FedProx, FedNova, FedAvgM, MOON, FedGKD, and FedProto across all tested datasets
- Adaptive mask improves performance by filtering out unreliable global logits, especially in early training rounds
- Class prototype similarity distillation effectively reduces the logit discrepancy between local and global models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Catastrophic forgetting on local non-IID data causes the local model to deviate from the global model in logit space, degrading federated learning performance.
- Mechanism: As the local model trains on biased local data, it forgets the global knowledge it initially had, leading to a shift in the output logits compared to the global model. This shift increases with more local epochs.
- Core assumption: The classifier layer (logits) is more sensitive to data distribution changes than the feature extractor.
- Evidence anchors:
  - [abstract] "we find that the difference in logits between the local and global models increases as the model is continuously updated, thus seriously deteriorating FL performance."
  - [section II, experimental observation] "an increase in the number of local epochs contributes to a higher discrepancy in logits between the local update and the global model."
  - [corpus] Weak/no direct support for classifier sensitivity assumption.
- Break condition: If the feature extractor is also significantly affected by non-IID data, logit alignment alone may be insufficient.

### Mechanism 2
- Claim: Aligning local and global logits using class prototype similarity distillation reduces catastrophic forgetting and improves model generalization.
- Mechanism: By distilling knowledge from the global model to the local model using logits weighted by the similarity to a global class prototype, the local model retains more global knowledge and avoids overfitting to local data.
- Core assumption: The global class prototype provides a stable reference for similarity weighting, and the global model contains useful class similarity information despite being undertrained.
- Evidence anchors:
  - [abstract] "FedCSD introduces a class prototype similarity distillation to align the local logits with the refined global logits that are weighted by the similarity between local logits and the global prototype."
  - [section IV-A] Describes the computation of class prototypes and similarity weighting.
  - [corpus] No direct evidence on the stability of global prototypes in federated settings.
- Break condition: If the global model's class similarity information is too noisy or biased, the distillation may misguide the local model.

### Mechanism 3
- Claim: An adaptive mask that filters out unreliable global logits prevents the local model from being misled by incorrect soft labels, especially in early training rounds.
- Mechanism: The adaptive mask identifies global logits where the teacher's confidence in the true class is below a threshold (1/|Y|) and sets them to zero, effectively removing them from the distillation loss.
- Core assumption: The teacher's class probability output is a reliable indicator of the quality of its soft labels.
- Evidence anchors:
  - [abstract] "To enhance the quality of global logits, FedCSD adopts an adaptive mask to filter out the terrible soft labels of the global models."
  - [section IV-B] Defines the adaptive mask based on the teacher's class probability.
  - [section V-D] Provides empirical evidence that the adaptive mask improves performance compared to a forcible mask.
- Break condition: If the teacher's confidence is not well-calibrated, the mask may incorrectly filter out useful information or fail to remove harmful labels.

## Foundational Learning

- Concept: Knowledge Distillation
  - Why needed here: FedCSD uses knowledge distillation to transfer information from the global (teacher) model to the local (student) model via logits.
  - Quick check question: What is the difference between hard labels and soft labels in knowledge distillation, and why are soft labels useful for transferring "dark knowledge"?
- Concept: Catastrophic Forgetting
  - Why needed here: Catastrophic forgetting is the main cause of the logit shift between local and global models in non-IID federated learning.
  - Quick check question: How does training on a biased local dataset cause a model to forget the knowledge it learned from a global dataset?
- Concept: Prototype Learning
  - Why needed here: FedCSD uses class prototypes to compute similarity weights for the knowledge distillation process.
  - Quick check question: How is a class prototype computed from a set of feature vectors, and what information does it capture about the class distribution?

## Architecture Onboarding

- Component map: Local training loop -> Prototype computation -> Distillation -> Global aggregation -> Teacher update
- Critical path: Local training → Prototype computation → Distillation → Global aggregation → Teacher update
- Design tradeoffs:
  - Using class prototypes vs. direct logits: Prototypes provide a stable reference but may lose fine-grained information.
  - Adaptive mask vs. no mask: Mask prevents noise but may filter out useful information if the teacher's confidence is miscalibrated.
  - Temporal moving average vs. direct global model: TMA provides stability but may slow down adaptation to new knowledge.
- Failure signatures:
  - High variance in local model performance across clients
  - Slow convergence or divergence in the global model
  - Local models overfitting to their biased data
- First 3 experiments:
  1. Compare FedCSD with and without the adaptive mask on a simple non-IID dataset to verify the mask's effectiveness.
  2. Vary the temperature parameter τ in the distillation loss to find the optimal value for balancing soft label smoothness and information content.
  3. Test FedCSD on a feature-skew dataset (e.g., Office-Caltech-10) to verify its generalization to different types of data heterogeneity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the class prototype similarity distillation loss compare to other knowledge distillation methods in terms of convergence speed and final accuracy in federated learning with non-IID data?
- Basis in paper: [explicit] The paper mentions that their proposed method outperforms other state-of-the-art federated learning approaches, including those using knowledge distillation.
- Why unresolved: The paper doesn't provide a direct comparison of convergence speed between their method and other knowledge distillation methods.
- What evidence would resolve it: Conducting experiments to compare the convergence speed and final accuracy of their method with other knowledge distillation methods under various non-IID data settings.

### Open Question 2
- Question: What is the impact of the adaptive mask mechanism on the privacy of the federated learning system?
- Basis in paper: [explicit] The paper mentions that the adaptive mask filters out "terrible soft labels" of the global model to prevent them from misleading local optimization.
- Why unresolved: The paper doesn't discuss the potential privacy implications of the adaptive mask mechanism.
- What evidence would resolve it: Analyzing the privacy-preserving properties of the adaptive mask mechanism and its impact on the overall privacy of the federated learning system.

### Open Question 3
- Question: How does the proposed method perform when applied to federated learning scenarios with a large number of clients or high communication costs?
- Basis in paper: [inferred] The paper mentions that the proposed method increases communication cost slightly compared to FedAvg, but it doesn't discuss the performance under scenarios with a large number of clients or high communication costs.
- Why unresolved: The paper doesn't provide experiments or analysis on the performance of the proposed method under scenarios with a large number of clients or high communication costs.
- What evidence would resolve it: Conducting experiments to evaluate the performance of the proposed method under scenarios with a large number of clients or high communication costs.

## Limitations

- The method is only validated on label-skew non-IID settings and not on feature-skew or quantity-skew scenarios
- The adaptive mask relies on teacher confidence calibration without verification across different datasets and model architectures
- Computational overhead of class prototype computation and temporal moving average maintenance is not discussed

## Confidence

- Mechanism 1: High confidence (well-supported by empirical evidence and catastrophic forgetting literature)
- Mechanism 2: Medium confidence (empirical effectiveness demonstrated but lacks theoretical justification)
- Mechanism 3: Low confidence (adaptive mask relies on unverified teacher confidence calibration assumption)

## Next Checks

1. Test FedCSD's performance on feature-skew non-IID datasets to verify generalization beyond label distribution shifts
2. Conduct ablation studies comparing the temporal moving average teacher against using the global model directly
3. Evaluate the algorithm's sensitivity to the temperature parameter τ and adaptive mask threshold across different dataset sizes and model architectures