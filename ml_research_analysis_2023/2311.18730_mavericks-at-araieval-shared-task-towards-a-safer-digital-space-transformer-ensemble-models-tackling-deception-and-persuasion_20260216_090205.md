---
ver: rpa2
title: 'Mavericks at ArAIEval Shared Task: Towards a Safer Digital Space -- Transformer
  Ensemble Models Tackling Deception and Persuasion'
arxiv_id: '2311.18730'
source_url: https://arxiv.org/abs/2311.18730
tags:
- task
- detection
- dataset
- news
- persuasion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper describes the Mavericks team's participation in the
  ArAIEval 2023 shared task, which focuses on detecting persuasion techniques and
  disinformation in Arabic text. The authors propose using transformer-based models
  fine-tuned on Arabic language data, combined with ensemble methods.
---

# Mavericks at ArAIEval Shared Task: Towards a Safer Digital Space -- Transformer Ensemble Models Tackling Deception and Persuasion

## Quick Facts
- arXiv ID: 2311.18730
- Source URL: https://arxiv.org/abs/2311.18730
- Reference count: 8
- Key outcome: Micro F1 scores of 0.742 (Task 1-A) and 0.901 (Task 2-A) using transformer ensemble approach

## Executive Summary
This paper describes the Mavericks team's participation in the ArAIEval 2023 shared task focused on detecting persuasion techniques and disinformation in Arabic text. The authors propose using transformer-based models fine-tuned on Arabic language data, combined with ensemble methods. They experiment with several pre-trained Arabic BERT models, including AraBERT and MARBERT, as well as AraELECTRA. The ensemble approach uses hard voting to combine predictions from individual models, achieving competitive results on both tasks.

## Method Summary
The approach uses fine-tuning of pre-trained Arabic transformer models (AraBERT variants, MARBERT, AraELECTRA) on the provided datasets for binary classification tasks. Models are trained for 10 epochs with learning rate 1e-5, batch size 32, and AdamW optimizer. Hard voting ensemble combines predictions from individual models by selecting the majority class. Text preprocessing involves removing "@USER", "LINK", and "RT" tokens using regex.

## Key Results
- Task 1-A (persuasion detection): 0.742 micro F1-score, ranked 8th
- Task 2-A (disinformation detection): 0.901 micro F1-score, ranked 7th
- Post-evaluation experiments showed MARBERTv2 achieved the best performance
- Hard voting ensemble improved robustness and minimized variance in results

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ensembling improves performance by aggregating predictions from diverse models, reducing individual model variance.
- Mechanism: The system combines predictions from multiple transformer-based models (AraBERT, MARBERT, AraELECTRA) using hard voting, where the final prediction is the majority class across all models.
- Core assumption: Different models capture complementary features of the data, and their combined predictions are more robust than any single model.
- Evidence anchors:
  - [abstract] "Ensembling is employed to enhance the performance of the systems. We achieved a micro F1-score of 0.742 on task 1-A... and 0.901 on task 2-A"
  - [section] "Hard voting, the majority vote or the 'mode' of all the predictions is selected as the final prediction. It helps improve the robustness of the system and minimizes the variance in the results."
- Break condition: If all models make correlated errors on the same examples, ensembling will amplify those errors rather than mitigate them.

### Mechanism 2
- Claim: Pre-training on large, diverse Arabic corpora enables transformers to capture rich contextual representations.
- Mechanism: Models like AraBERT and MARBERT are pre-trained on millions of sentences from news articles and social media, learning to understand Arabic language patterns before fine-tuning on the specific task data.
- Core assumption: The pre-training data covers sufficient linguistic diversity to generalize to the target task domain.
- Evidence anchors:
  - [section] "The pre-training dataset used for the models comprises 70 million sentences which is about 24GB in size. The data consists of news that spans multiple topics and thus represents a variety that is useful for numerous downstream tasks."
  - [section] "MARBERT (Abdul-Mageed et al., 2021), 1B Arabic tweets were selected at random from a sizable internal dataset of roughly 6B tweets."
- Break condition: If the pre-training data has significant domain shift from the target task, the learned representations may not transfer well.

### Mechanism 3
- Claim: Fine-tuning transformer models on task-specific data adapts pre-trained representations to the classification objective.
- Mechanism: The pre-trained models are further trained on the ArAIEval dataset with binary classification heads, learning to distinguish between classes for persuasion and disinformation detection.
- Core assumption: The task data is representative enough of the problem space that fine-tuning will learn meaningful decision boundaries.
- Evidence anchors:
  - [section] "We fine-tune these state-of-the-art models on the provided dataset."
  - [section] "The models are trained for 10 epochs with a learning rate of 1e-5, a batch size of 32, and the AdamW optimizer."
- Break condition: If the task data is too small or unrepresentative, fine-tuning may overfit or fail to learn generalizable patterns.

## Foundational Learning

- Concept: Binary classification
  - Why needed here: Both tasks involve classifying text as either containing persuasion/disinformation or not
  - Quick check question: What are the two possible output classes for Task 1-A?

- Concept: Transformer architecture
  - Why needed here: The approach relies on transformer-based models like BERT and ELECTRA for text representation
  - Quick check question: What is the key innovation of transformer models compared to previous architectures like RNNs?

- Concept: Ensemble methods
  - Why needed here: The system uses hard voting to combine predictions from multiple models
  - Quick check question: In hard voting, how is the final prediction determined from individual model predictions?

## Architecture Onboarding

- Component map: Input text → Pre-processing (cleaning) → Multiple transformer models (AraBERT variants, AraELECTRA, MARBERT) → Individual predictions → Hard voting ensemble → Final binary output
- Critical path: Text preprocessing → Model inference → Ensemble aggregation → Output
- Design tradeoffs: Using multiple models increases robustness but also computational cost; hard voting is simple but doesn't account for model confidence
- Failure signatures: Poor performance on certain dialects if models weren't trained on diverse Arabic varieties; degradation if pre-training data doesn't match target domain
- First 3 experiments:
  1. Train a single AraBERT model on Task 1-A data and evaluate baseline performance
  2. Implement hard voting ensemble with AraBERT and AraELECTRA, compare to single model
  3. Test MARBERTv2 on Task 2-A data to validate its effectiveness on tweet-based content

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective would hybrid architectures combining BERT with recurrent neural networks or parallel CNNs be for Arabic persuasion and disinformation detection compared to the transformer-only ensemble approach?
- Basis in paper: [inferred] The paper mentions that hybrid architectures like combining BERT with RNN or parallel CNNs have achieved significant scores in other research, suggesting this could be explored for Arabic.
- Why unresolved: The paper only experiments with transformer-based models and ensembles, not exploring hybrid architectures.
- What evidence would resolve it: Experimental results comparing a hybrid BERT-RNN or BERT-CNN model against the transformer ensemble on the same Arabic datasets.

### Open Question 2
- Question: Would longer training durations and larger models significantly improve performance for persuasion and disinformation detection in Arabic text?
- Basis in paper: [explicit] The authors state "In the future, with the availability of better computational resources, we can enhance the system's performance by training it for longer and by using larger models."
- Why unresolved: Computational resource limitations prevented longer training and use of larger models in the current study.
- What evidence would resolve it: Results from experiments using extended training time and larger model variants on the same datasets.

### Open Question 3
- Question: How effective would explainable AI (XAI) approaches be for detecting and understanding persuasion techniques and disinformation in Arabic text?
- Basis in paper: [explicit] The paper mentions that "Recent developments suggest that AI approaches such as explainable AI (XAI) are being experimented with for the task of disinformation and persuasion technique detection."
- Why unresolved: The paper does not implement or evaluate XAI methods for the Arabic detection tasks.
- What evidence would resolve it: Implementation and evaluation of XAI methods applied to the Arabic persuasion and disinformation detection tasks, measuring both performance and interpretability.

## Limitations

- The reported performance metrics are based on competition test sets that may not reflect real-world deployment scenarios
- The ensemble approach assumes equal reliability across models without considering prediction confidence scores
- The post-evaluation finding that MARBERTv2 performed best suggests potential missed optimization opportunities during the competition

## Confidence

**High Confidence**: The effectiveness of transformer-based models for Arabic text classification (AraBERT and MARBERT are well-established in the literature for Arabic NLP tasks).

**Medium Confidence**: The specific F1 scores achieved (0.742 for Task 1-A and 0.901 for Task 2-A) - these are competition-specific metrics that may not generalize to other datasets or evaluation frameworks.

**Low Confidence**: The claim that MARBERTv2 would have been the optimal single model choice, as this was only tested post-competition and may reflect overfitting to the test set.

## Next Checks

1. **Cross-dataset validation**: Test the same ensemble approach on independent Arabic persuasion and disinformation datasets to verify if the 0.742 and 0.901 F1 scores generalize beyond the competition data.

2. **Ablation study**: Systematically remove each model from the ensemble to quantify individual contributions and determine if hard voting provides meaningful improvement over the best single model.

3. **Confidence-weighted voting**: Implement soft voting using model prediction probabilities instead of hard voting to assess whether incorporating confidence scores improves performance over the simple majority approach.