---
ver: rpa2
title: Federated Temporal Difference Learning with Linear Function Approximation under
  Environmental Heterogeneity
arxiv_id: '2302.02212'
source_url: https://arxiv.org/abs/2302.02212
tags:
- learning
- heterogeneity
- where
- have
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies federated reinforcement learning with environmental
  heterogeneity. The authors consider a policy evaluation problem where N agents interact
  with MDPs that share state/action space but differ in reward functions and transition
  kernels.
---

# Federated Temporal Difference Learning with Linear Function Approximation under Environmental Heterogeneity

## Quick Facts
- arXiv ID: 2302.02212
- Source URL: https://arxiv.org/abs/2302.02212
- Reference count: 40
- Primary result: Proves linear speedup in federated TD(0) convergence rate with N agents, converging at rate O(1/NKT) to a heterogeneity-dependent neighborhood of each agent's optimal parameter

## Executive Summary
This paper studies federated reinforcement learning with environmental heterogeneity, where multiple agents share state/action space but have different reward functions and transition kernels. The authors propose FedTD(0), a federated TD(0) algorithm where agents exchange model parameters via a central server. They introduce a virtual MDP construction to analyze the algorithm's dynamics and prove that in low-heterogeneity regimes, FedTD(0) achieves linear speedup in convergence rate with respect to the number of agents. The analysis covers both i.i.d. and Markovian sampling regimes, showing convergence to a neighborhood whose size depends on the level of heterogeneity between agents' MDPs.

## Method Summary
The FedTD(0) algorithm involves N agents each running local TD(0) updates on their own MDP with linear function approximation, followed by periodic parameter averaging at a central server. Each agent performs K local updates using their own transition kernel P(i) and reward function R(i), then sends the difference between their updated and previous parameters to the server. The server computes the average difference and broadcasts the updated global model back to all agents. This process repeats for T communication rounds, with each agent making KT total updates. The algorithm uses a projection step to ensure parameter stability and operates under both i.i.d. and Markovian sampling regimes.

## Key Results
- Proves linear speedup in convergence rate: O(1/NKT) vs O(1/KT) for centralized TD(0)
- Introduces virtual MDP construction to analyze federated dynamics through convex combination of individual MDPs
- Shows heterogeneity creates an inevitable bias term that cannot be eliminated by reducing step size
- Analyzes both i.i.d. and Markovian sampling regimes with mixing time considerations
- Provides perturbation bounds on TD(0) fixed points under heterogeneity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Averaging TD(0) update directions from different MDPs converges to a virtual MDP's fixed point
- Mechanism: By constructing a virtual MDP as the convex combination of individual agents' MDPs, the averaged TD(0) updates follow the dynamics of this virtual MDP, leading to convergence near its fixed point
- Core assumption: The agents' MDPs are close enough (low heterogeneity) that their fixed points are also close
- Evidence anchors:
  - [abstract]: "introducing a virtual MDP to closely approximate the dynamics of the federated TD algorithm"
  - [section]: "We construct an MDP ¯M =⟨S,A, ¯R, ¯P,γ⟩, where ¯P = (1/N) ∑N i=1P(i), and ¯R = (1/N) ∑N i=1R(i)"
  - [corpus]: Weak - no direct citations about virtual MDP construction in related works

### Mechanism 2
- Claim: Linear speedup in convergence rate with respect to number of agents under low heterogeneity
- Mechanism: The variance of the averaged gradient estimate scales as σ²/(NK) instead of σ²/K, enabling N-fold speedup when T≫N
- Core assumption: Agents' observations are independent across agents and the Markovian mixing times don't dominate
- Evidence anchors:
  - [abstract]: "we rigorously prove that in a low-heterogeneity regime, exchanging model estimates leads to linear convergence speedups in the number of agents"
  - [section]: "Our analysis thus reveals that by communicating just T times in KT iterations, each agenti can reduce the noise varianceσ² further by a factor ofN"
  - [corpus]: Weak - related works mention linear speedup but don't provide rigorous finite-time analysis under heterogeneity

### Mechanism 3
- Claim: Heterogeneity introduces a bias term that cannot be eliminated by reducing step size
- Mechanism: The steady-state deterministic version of FedTD(0) converges to a point that depends on the differences between agents' optimal parameters, creating an inherent bias
- Core assumption: The heterogeneity between agents' MDPs is fixed and non-zero
- Evidence anchors:
  - [abstract]: "we prove that a bias term depending on a natural measure of heterogeneity shows up inevitably in the long-term dynamics of FedTD(0)"
  - [section]: "the gap between the limit point of mean-pathFedTD(0) and the optimal parameterθ* i of either of the two MRPs bears a dependence onthe difference in the optimal parameters"
  - [corpus]: Weak - related works focus on speedup but don't analyze the inevitable bias from heterogeneity

## Foundational Learning

- Concept: Perturbation theory of linear equations and Markov chains
  - Why needed here: To bound how differences in MDPs manifest as differences in TD(0) fixed points
  - Quick check question: Can you explain how a small perturbation in a transition matrix affects the stationary distribution?

- Concept: Convex combinations of Markov matrices
  - Why needed here: To prove the virtual MDP inherits properties (aperiodicity, irreducibility) from individual MDPs
  - Quick check question: Given two irreducible Markov chains, is their convex combination always irreducible?

- Concept: Mixing time analysis for Markov chains
  - Why needed here: To handle the correlation structure in Markovian sampling and establish variance reduction bounds
  - Quick check question: How does the mixing time of the slowest agent affect the overall convergence rate?

## Architecture Onboarding

- Component map: Agents -> Server -> All Agents (bidirectional communication)
- Critical path:
  1. Initialize common model and state across all agents
  2. Each agent performs K local TD(0) updates using their own MDP
  3. Agents send model differences to server
  4. Server averages differences and updates global model
  5. Broadcast updated model to all agents
  6. Repeat until convergence

- Design tradeoffs:
  - Local steps (K) vs. communication frequency: More local steps save communication but increase client drift
  - Heterogeneity tolerance vs. convergence accuracy: Higher heterogeneity allows more agents but reduces accuracy
  - Markovian vs. i.i.d. sampling: Markovian is more realistic but requires more complex analysis

- Failure signatures:
  - Slow convergence despite many agents: Likely high heterogeneity or poor mixing times
  - Divergence or exploding parameters: Step sizes too large or projection radius too small
  - Sublinear speedup: Variance reduction not scaling properly, check independence assumptions

- First 3 experiments:
  1. Single-agent baseline: Run standard TD(0) on one MDP to establish convergence rate
  2. Two-agent low heterogeneity: Verify linear speedup with N=2, small heterogeneity
  3. Two-agent high heterogeneity: Confirm bias term appears and dominates when heterogeneity is large

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does FedTD(0) maintain linear speedup with respect to the number of agents in the high heterogeneity regime?
- Basis in paper: [explicit] The paper proves linear speedup in a low-heterogeneity regime but acknowledges that a heterogeneity bias term persists even in the steady-state deterministic version.
- Why unresolved: The paper focuses on low-heterogeneity settings and doesn't analyze performance when heterogeneity is high.
- What evidence would resolve it: Empirical studies or theoretical bounds showing convergence rates for FedTD(0) under varying levels of heterogeneity, particularly in high-heterogeneity regimes.

### Open Question 2
- Question: How does the convergence rate of FedTD(0) compare to centralized TD(0) when the number of agents is large but heterogeneity is moderate?
- Basis in paper: [explicit] The paper shows FedTD(0) achieves O(1/NKT) convergence rate in low-heterogeneity regime, compared to O(1/KT) for centralized TD(0).
- Why unresolved: The paper doesn't provide direct comparison between federated and centralized approaches under different agent counts and heterogeneity levels.
- What evidence would resolve it: Comparative analysis showing trade-offs between communication cost, agent count, and heterogeneity levels for both federated and centralized approaches.

### Open Question 3
- Question: Can personalization techniques from federated optimization be effectively applied to FedRL to handle high heterogeneity?
- Basis in paper: [inferred] The paper mentions this as a potential future direction and notes that FedTD(0) converges to a neighborhood of the virtual MDP's optimal parameter.
- Why unresolved: The paper focuses on finding a common model for all agents rather than personalized models.
- What evidence would resolve it: Experimental results comparing personalized FedRL approaches against the common model approach under varying heterogeneity levels.

## Limitations

- Analysis restricted to low-heterogeneity regime; performance in high heterogeneity settings remains unexplored
- Virtual MDP construction assumes convex combinations preserve convergence properties, which may not hold for non-linear dynamics
- Exact characterization of heterogeneity tolerance thresholds relative to step size and function approximation quality is incomplete

## Confidence

- **High Confidence**: The linear speedup mechanism under low heterogeneity and the fundamental role of variance reduction through averaging
- **Medium Confidence**: The inevitability of the bias term under heterogeneity and the exact characterization of the error neighborhood
- **Low Confidence**: The precise thresholds for heterogeneity where speedup breaks down and the interaction between mixing times and communication frequency

## Next Checks

1. **Perturbation Bound Verification**: Systematically vary the heterogeneity parameter ε and measure how the distance between virtual MDP fixed point and individual agents' optimal parameters scales

2. **Variance Reduction Test**: Compare convergence rates with K=1 vs K>1 under controlled heterogeneity to confirm σ²/(NK) scaling

3. **Mixing Time Impact**: Introduce agents with varying mixing times and quantify how the slowest agent affects the overall convergence rate