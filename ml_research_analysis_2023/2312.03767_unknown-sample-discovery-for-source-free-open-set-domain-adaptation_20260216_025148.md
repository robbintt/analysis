---
ver: rpa2
title: Unknown Sample Discovery for Source Free Open Set Domain Adaptation
arxiv_id: '2312.03767'
source_url: https://arxiv.org/abs/2312.03767
tags:
- target
- domain
- known
- unknown
- adaptation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses open set domain adaptation (OSDA) without
  requiring source domain access. The authors propose a novel source-free OSDA (SF-OSDA)
  method called Unknown Sample Discovery (USD).
---

# Unknown Sample Discovery for Source Free Open Set Domain Adaptation

## Quick Facts
- arXiv ID: 2312.03767
- Source URL: https://arxiv.org/abs/2312.03767
- Reference count: 40
- Primary result: USD achieves 65.9% HOS on Office-Home, outperforming SHOT by ~20% and AaD by ~2%

## Executive Summary
This paper addresses the challenging problem of source-free open set domain adaptation (SF-OSDA), where a model trained on a source domain must adapt to a target domain containing both known and unknown classes without access to source data. The authors propose Unknown Sample Discovery (USD), a teacher-student framework that uses Jensen-Shannon distance (JSD) for known-unknown sample separation, curriculum-guided adaptation, and robust pseudolabel generation. The method demonstrates state-of-the-art performance on Office-31, Office-Home, and VisDA-C datasets, achieving significant improvements over existing SF-OSDA methods.

## Method Summary
USD operates through a teacher-student framework where the student model learns from pseudolabeled target data while the teacher model provides stable guidance through exponential moving averages. The key innovation is using JSD between pseudolabels and teacher predictions to separate known and unknown target samples via a 2-component GMM. The method employs curriculum learning that prioritizes known class adaptation before gradually incorporating unknown classes, and uses multi-view augmentations for robust pseudolabel generation. The overall objective combines cross-entropy, information maximization, triplet, and consistency losses to achieve effective adaptation.

## Key Results
- Achieves 65.9% HOS on Office-Home, outperforming SHOT by ~20% and AaD by ~2%
- Maintains competitive performance with methods requiring source data access
- Shows consistent improvements across Office-31, Office-Home, and VisDA-C datasets
- Demonstrates effective known-unknown sample separation with JSD-based approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Jensen-Shannon distance (JSD) effectively separates known and unknown target samples in source-free OSDA.
- Mechanism: JSD is calculated between pseudolabels and teacher model predictions, producing a bimodal distribution. A 2-component Gaussian Mixture Model (GMM) models this distribution, with the lower-mean mode representing known samples and the higher-mean mode representing unknown samples.
- Core assumption: Unknown class samples in the target domain produce higher JSD values compared to known class samples when compared to their pseudolabels.
- Evidence anchors:
  - [abstract]: "USD proposes the Jensen-Shannon distance between the target pseudolabels and teacher model predictions as an effective criterion for separating target samples in known and unknown classes."
  - [section]: "In USD, we conduct known-unknown sample separation for SF-OSDA based on JSD between the network outputs and their corresponding pseudolabels... We model the JSD distribution with 2-component Multivariate Gaussian Mixture Model (GMM)..."
  - [corpus]: Weak - no direct corpus evidence for JSD specifically, but related work on entropy-based separation exists.
- Break condition: If unknown class samples have similar confidence levels to known class samples, the JSD distributions may overlap significantly, making separation unreliable.

### Mechanism 2
- Claim: Teacher-student co-training with temporal ensembling reduces error accumulation from imperfect known-unknown sample separation.
- Mechanism: The student model is trained with gradient descent using pseudolabeled target data, while the teacher model is updated via exponential moving averages of student parameters. This creates a consistency regularization between weak and strong augmentations.
- Core assumption: Temporal ensembling smooths the teacher model parameters, reducing the impact of noisy pseudolabels and preventing error amplification during adaptation.
- Evidence anchors:
  - [abstract]: "Our teacher-student framework significantly reduces error accumulation resulting from imperfect known-unknown sample separation..."
  - [section]: "USD simultaneously adapts the student and teacher target models... The teacher-student framework in USD helps to mitigate error accumulation induced from any possibly faulty known-unknown sample separation."
  - [corpus]: Weak - related work on temporal ensembling exists but not specifically for SF-OSDA error accumulation.
- Break condition: If the momentum parameter for EMA is too high, the teacher model becomes too slow to adapt to actual data distribution changes, potentially missing important adaptation opportunities.

### Mechanism 3
- Claim: Curriculum-guided adaptation progressively learns known class features before unknown class features, improving overall adaptation performance.
- Mechanism: A curriculum factor γr dynamically adjusts the weight between known and unknown class cross-entropy losses based on the relative performance on each subset. When known class performance degrades, more focus is given to known classes.
- Core assumption: Learning the known class feature space first provides a stable foundation before adapting to the more challenging unknown class subspace.
- Evidence anchors:
  - [abstract]: "USD utilizes curriculum guidance to progressively learn the known class feature space first, and the unknown class feature space later..."
  - [section]: "To encourage individually precise and globally diverse predictions, USD further minimizes the information maximization (IM) loss... The overall objective function is therefore..."
  - [corpus]: Weak - no direct corpus evidence for this specific curriculum approach in SF-OSDA.
- Break condition: If the curriculum factor adjustment is too aggressive, the model may never adequately learn the unknown class features, leading to poor performance on the unknown class subset.

## Foundational Learning

- Concept: Gaussian Mixture Models for bimodal distribution modeling
  - Why needed here: To model the JSD distribution which is expected to be bimodal (known vs unknown samples)
  - Quick check question: What property of GMM makes it suitable for modeling the JSD distribution in USD?

- Concept: Exponential Moving Average (EMA) for model ensembling
  - Why needed here: To create a temporally stable teacher model that reduces noise from imperfect pseudolabels
  - Quick check question: How does EMA help prevent error accumulation in the teacher-student framework?

- Concept: Curriculum learning with dynamic weighting
  - Why needed here: To progressively adapt to known classes before unknown classes for more stable learning
  - Quick check question: What happens to the curriculum factor when known class performance starts degrading?

## Architecture Onboarding

- Component map: Student model (feature extractor + classifier) -> Teacher model (feature extractor + classifier) -> 2-component GMM for JSD modeling -> Augmentation pipeline (weak + strong) -> Curriculum controller
- Critical path: Pseudolabel generation → JSD calculation → GMM fitting → Known-unknown separation → Student training with losses → Teacher update
- Design tradeoffs: JSD vs entropy for separation (JSD is symmetric and bounded), single vs dual branch architecture (co-training provides regularization), fixed vs dynamic curriculum (adaptive curriculum responds to performance)
- Failure signatures: High JSD overlap between modes (poor separation), teacher-student divergence (inconsistent training), curriculum factor stuck at extremes (imbalanced adaptation)
- First 3 experiments:
  1. Verify JSD produces bimodal distribution on Office-31 dataset
  2. Test known-unknown separation accuracy with different δt thresholds
  3. Compare HOS with and without teacher-student co-training on a single domain pair

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of USD vary when using different types of augmentation strategies beyond AutoAugment?
- Basis in paper: [explicit] The paper uses AutoAugment ImageNet policy for weak and strong augmentations. It mentions that USD generates pseudolabels from an ensemble of weak and strong target data augmentations, but doesn't explore other augmentation strategies.
- Why unresolved: The paper focuses on AutoAugment and doesn't investigate the impact of other augmentation techniques on the final performance.
- What evidence would resolve it: Experimental results comparing USD's performance using different augmentation strategies (e.g., RandAugment, CutMix, MixUp) on the same datasets and tasks.

### Open Question 2
- Question: How does the choice of the curriculum factor decay rate (β) affect the adaptation performance, and what is the optimal value for different domain adaptation tasks?
- Basis in paper: [explicit] The paper mentions that the curriculum factor γr decreases based on the ratio Lce_tKr / Lce_tKr-1 and the hyperparameter β, but doesn't provide a systematic analysis of how different β values impact the final results.
- Why unresolved: The paper uses a fixed β value (0.01 for Office/Office-Home, 0.001 for VisDA-C) without exploring the sensitivity of the performance to this hyperparameter.
- What evidence would resolve it: A sensitivity analysis showing USD's performance for different β values on various domain adaptation tasks, identifying the optimal β for each scenario.

### Open Question 3
- Question: Can the teacher-student co-training framework in USD be extended to handle gradual domain adaptation, where the target domain changes over time?
- Basis in paper: [inferred] The paper mentions continual learning in the references but doesn't explore extending USD to gradual domain adaptation scenarios. The teacher-student framework could potentially be adapted to track and adapt to changing target distributions.
- Why unresolved: The paper focuses on static domain adaptation and doesn't investigate the applicability of USD to non-stationary target domains.
- What evidence would resolve it: An extension of USD to gradual domain adaptation, with experimental results demonstrating its effectiveness on datasets with gradually changing target distributions over time.

## Limitations

- The JSD-based separation assumes distinct confidence distributions between known and unknown classes, which may not hold when unknown classes have similar feature distributions to known classes.
- The 2-component GMM assumption could fail with multi-modal unknown class distributions.
- The curriculum guidance mechanism relies on relative performance metrics that may be unstable during early adaptation phases.

## Confidence

- Mechanism 1 (JSD separation): Medium - Strong theoretical justification but limited empirical validation of distribution assumptions
- Mechanism 2 (Teacher-student co-training): High - Well-established technique with clear error accumulation mitigation
- Mechanism 3 (Curriculum guidance): Medium - Conceptually sound but sensitive to hyperparameter choices and performance metric stability

## Next Checks

1. Test JSD separation robustness on datasets with unknown classes that have semantic similarity to known classes (e.g., similar object categories)
2. Evaluate HOS sensitivity to different GMM component numbers and separation threshold values (δt)
3. Compare performance when removing temporal ensembling vs removing curriculum guidance to isolate their individual contributions