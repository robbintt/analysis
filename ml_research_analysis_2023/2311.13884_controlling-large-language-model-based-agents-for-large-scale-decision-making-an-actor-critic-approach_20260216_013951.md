---
ver: rpa2
title: 'Controlling Large Language Model-based Agents for Large-Scale Decision-Making:
  An Actor-Critic Approach'
arxiv_id: '2311.13884'
source_url: https://arxiv.org/abs/2311.13884
tags:
- agents
- arxiv
- feedback
- language
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents LLaMAC, a modular framework for large-scale
  multi-agent decision-making using large language models (LLMs). LLaMAC addresses
  the challenges of LLM hallucination and token inefficiency in multi-agent systems
  by incorporating a triplet critic structure inspired by the human brain's value
  distribution encoding.
---

# Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach

## Quick Facts
- arXiv ID: 2311.13884
- Source URL: https://arxiv.org/abs/2311.13884
- Reference count: 7
- One-line primary result: LLaMAC framework outperforms state-of-the-art in multi-agent decision-making with improved success rate, token efficiency, and policy stability.

## Executive Summary
This paper introduces LLaMAC, a modular framework for large-scale multi-agent decision-making using large language models (LLMs). LLaMAC addresses key challenges in LLM-based multi-agent systems, including hallucination and token inefficiency, by incorporating a triplet critic structure inspired by the brain's value distribution encoding and comprehensive feedback mechanisms. The framework demonstrates superior performance in system resource allocation and robot grid transportation tasks compared to existing methods, achieving higher success rates with fewer steps and tokens.

## Method Summary
LLaMAC is a modular framework that combines a triplet critic structure with internal and external feedback mechanisms to facilitate large-scale multi-agent decision-making. The triplet critic consists of two critics with different exploration-exploitation biases and an assessor that resolves conflicts, inspired by dopamine neuron encoding in the brain. The framework includes a memory module that filters redundant information to improve token efficiency, and an external feedback loop where actors confirm suggestions and provide feedback to the critic if needed. The method is evaluated on system resource allocation and robot grid transportation tasks, demonstrating improved performance, token utilization efficiency, and policy stability compared to existing approaches.

## Key Results
- Achieved 100% success rate with 7.0 steps and 23,921.2 tokens on average for a 2x2 grid robot transportation task, compared to 80% success rate, 9.9 steps, and 49,877.7 tokens for HMAS-2.
- Outperformed existing methods in system resource allocation tasks with varying numbers of agents.
- Demonstrated improved token utilization efficiency and policy stability through the use of memory filtering and external feedback mechanisms.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The TripletCritic structure mitigates hallucination by incorporating internal feedback that balances exploration and exploitation.
- Mechanism: The TripletCritic uses three critics: two with different exploration-exploitation biases and one assessor that resolves conflicts. The assessor performs veracity scrutiny and belief correction to ensure suggestions are robust.
- Core assumption: Different critic preferences can model the value distribution of reward events, inspired by dopamine neuron encoding in the brain.
- Evidence anchors:
  - [abstract] "utilizing internal and external feedback mechanisms to facilitate collaboration and iterative reasoning among its modules."
  - [section] "We introduce a TripletCritic structure inspired by the distributional code for value in the brain (Dabney et al., 2020)."
  - [corpus] Weak evidence; related papers focus on safety and robustness but not on this specific hallucination mitigation mechanism.
- Break condition: If the assessor fails to reconcile critic disagreements or if the internal feedback loop becomes too noisy, the hallucination mitigation effect degrades.

### Mechanism 2
- Claim: External feedback from actors to critic reduces token inefficiency by limiting LLM accesses to only necessary iterations.
- Mechanism: After receiving a suggestion, actors perform Plan Confirmation. If the suggestion is incorrect, external feedback is generated and sent to the TripletCritic, which updates the suggestion. This iterative loop continues until all actors agree.
- Core assumption: The TripletCritic provides reliable initial suggestions, so external feedback is infrequent and token usage is minimized.
- Evidence anchors:
  - [abstract] "We also establish a comprehensive feedback mechanism that incorporates both internal feedback within the TripletCritic and external feedback between the LLM-based actors and the TripletCritic."
  - [section] "Due to the reliability of the TripletCritic, the opportunity for actors to provide external feedback is limited, resulting in minimal access costs."
  - [corpus] No direct evidence; related work focuses on LLM agent robustness but not on token efficiency via feedback loops.
- Break condition: If the TripletCritic is unreliable and actors frequently reject suggestions, the external feedback loop becomes too frequent, negating token savings.

### Mechanism 3
- Claim: The memory module with redundant information filtering reduces context length and improves token efficiency.
- Mechanism: The memory stores only the most recent L steps of state transitions and filters out repeated state-action pairs in single-step decisions. This keeps the context concise for LLM processing.
- Core assumption: Only recent and non-redundant information is necessary for effective decision-making, reducing the need for long context.
- Evidence anchors:
  - [abstract] "To construct a token-efficient planning framework, we incorporate mechanisms such as redundant memory information deletion and external feedback judgment."
  - [section] "During long-term planning processes, it retains only the most recent L steps of state transitions < s t-L+1, at-L+1, rt-L+1, st-L+2, ..., st >."
  - [corpus] Weak evidence; related papers discuss memory management but not this specific filtering mechanism for token efficiency.
- Break condition: If the filtering is too aggressive and removes information needed for decision-making, performance degrades.

## Foundational Learning

- Concept: Multi-Agent Reinforcement Learning (MARL) with Actor-Critic methods
  - Why needed here: The paper builds on MARL frameworks, specifically the centralized critic with decentralized actors (CCDA) structure, to coordinate large-scale LLM-based agents.
  - Quick check question: What is the role of the centralized critic in the CCDA framework, and how does it differ from decentralized critic approaches?

- Concept: Chain-of-Thought (CoT) prompting and feedback mechanisms
  - Why needed here: CoT prompting enhances LLM reasoning, and feedback mechanisms (both internal and external) are used to refine decisions and mitigate hallucinations.
  - Quick check question: How does the Plan Confirmation process in the external feedback mechanism help detect and correct LLM hallucinations?

- Concept: Value distribution encoding and exploration-exploitation trade-offs
  - Why needed here: The TripletCritic's design is inspired by dopamine neuron value distribution encoding, and it explicitly balances exploration and exploitation to avoid local optima.
  - Quick check question: What are the potential risks of using only an exploration-biased critic or only an exploitation-biased critic, and how does the TripletCritic mitigate these risks?

## Architecture Onboarding

- Component map: Execution Module -> Memory Module -> Critic Module (TripletCritic) -> Actors -> Environment

- Critical path:
  1. Environment generates state â†’ Execution Module converts to text.
  2. Critic Module (TripletCritic) receives state and memory, generates suggestions.
  3. Actors receive suggestions and observations, perform Plan Confirmation.
  4. If all agree, execute actions; if not, generate external feedback and update suggestions.
  5. Repeat until task completion.

- Design tradeoffs:
  - Centralized vs. decentralized critics: Centralized allows global coordination but may be a bottleneck; decentralized reduces coordination overhead but may lead to suboptimal joint actions.
  - Aggressive memory filtering vs. retaining information: Aggressive filtering saves tokens but risks losing useful context; retaining more information improves decision-making but increases token usage.
  - Internal feedback complexity vs. simplicity: Complex internal feedback (TripletCritic) mitigates hallucinations but adds computational overhead; simpler feedback is faster but less robust.

- Failure signatures:
  - High external feedback frequency: Indicates TripletCritic is unreliable or suggestions are consistently incorrect.
  - Degraded performance with larger agent counts: Suggests memory filtering or internal feedback mechanisms are not scaling well.
  - Oscillating or premature convergence in optimization tasks: Indicates imbalance in exploration-exploitation trade-off.

- First 3 experiments:
  1. Test TripletCritic with synthetic critics (one always explores, one always exploits) on a simple grid task to verify balance.
  2. Measure token usage with and without memory filtering on a fixed-length trajectory to quantify savings.
  3. Compare success rate and steps on robot grid transportation with and without external feedback to assess its impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the TripletCritic structure compare to other multi-agent coordination methods in terms of scalability and performance?
- Basis in paper: [explicit] The paper mentions that the TripletCritic structure is inspired by the distributional code for value in the brain and is designed to coordinate multiple critics with the same objective but different preferences.
- Why unresolved: The paper does not provide a comprehensive comparison of the TripletCritic structure with other multi-agent coordination methods in terms of scalability and performance.
- What evidence would resolve it: A detailed comparative analysis of the TripletCritic structure with other multi-agent coordination methods, including their scalability and performance, would provide evidence to resolve this question.

### Open Question 2
- Question: What are the limitations of the LLaMAC framework in terms of the number of agents it can handle effectively?
- Basis in paper: [inferred] The paper mentions that the LLaMAC framework is designed for large-scale multi-agent decision-making, but it does not explicitly state the limitations of the framework in terms of the number of agents it can handle effectively.
- Why unresolved: The paper does not provide information on the scalability limitations of the LLaMAC framework in terms of the number of agents it can handle effectively.
- What evidence would resolve it: Experimental results or theoretical analysis demonstrating the scalability limitations of the LLaMAC framework in terms of the number of agents it can handle effectively would provide evidence to resolve this question.

### Open Question 3
- Question: How does the external feedback mechanism from actor to critic contribute to the overall performance of the LLaMAC framework?
- Basis in paper: [explicit] The paper mentions that the LLaMAC framework incorporates an external feedback mechanism from actor to critic to facilitate iterative long-term planning and reduce access costs.
- Why unresolved: The paper does not provide a detailed analysis of the impact of the external feedback mechanism on the overall performance of the LLaMAC framework.
- What evidence would resolve it: A comprehensive evaluation of the impact of the external feedback mechanism on the overall performance of the LLaMAC framework, including its contribution to task completion, token utilization efficiency, and policy stability, would provide evidence to resolve this question.

## Limitations
- Limited ablation studies: The paper does not provide detailed ablation studies to isolate the impact of each component, making it unclear which mechanisms are most critical to the reported improvements.
- Scalability to larger agent counts: The experiments only evaluate up to 25 agents, and the performance and token efficiency for much larger agent counts are unknown.
- Token efficiency claims: The baseline methods' token usage is not clearly specified, making it hard to assess the relative improvement in token efficiency.

## Confidence
- Limited ablation studies: Medium
- Scalability to larger agent counts: Low
- Token efficiency claims: Medium
- Hallucination mitigation: Medium
- Dependency on LLM reliability: Medium

## Next Checks
1. Conduct ablation study on TripletCritic components to quantify individual contributions to performance and hallucination mitigation.
2. Evaluate framework on a larger resource allocation or transportation task with 100+ agents to assess scalability.
3. Measure and compare total token usage of LLaMAC against HMAS-2 and other baselines on the same tasks to validate token efficiency claims.