---
ver: rpa2
title: 'MOLE: MOdular Learning FramEwork via Mutual Information Maximization'
arxiv_id: '2308.07772'
source_url: https://arxiv.org/abs/2308.07772
tags:
- data
- mole
- learning
- information
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Modular Learning Framework (MOLE), a local
  learning framework that modularizes neural networks by layers and trains each module
  via mutual information maximization. Unlike backpropagation, MOLE performs gradient-isolated
  training where early layers maximize mutual information with input (I(Tk;X)) and
  later layers maximize mutual information with labels (I(Tk;Y)).
---

# MOLE: MOdular Learning FramEwork via Mutual Information Maximization

## Quick Facts
- arXiv ID: 2308.07772
- Source URL: https://arxiv.org/abs/2308.07772
- Reference count: 40
- Primary result: MOLE achieves 84.79% accuracy on Adult, 96.85% on MNIST, 76.01% on Mutagenicity, and 68.40% on Cora

## Executive Summary
This paper introduces Modular Learning Framework (MOLE), a local learning framework that modularizes neural networks by layers and trains each module via mutual information maximization. Unlike backpropagation, MOLE performs gradient-isolated training where early layers maximize mutual information with input (I(Tk;X)) and later layers maximize mutual information with labels (I(Tk;Y)). Experiments on vector (Adult), grid (MNIST), and graph (Mutagenicity, Cora) data show MOLE's universal applicability.

## Method Summary
MOLE divides neural networks into modules and trains them sequentially using mutual information maximization. Early modules (encoder-like) maximize I(Tk;X) to extract features from input, while later modules (decoder-like) maximize I(Tk;Y) to cluster representations by class. Each module is trained independently without gradient propagation to earlier layers, making training local and gradient-isolated. The framework uses different mutual information estimators based on data type: matrix-based for vectors, MINE for grids, and GMI for graphs.

## Key Results
- MOLE achieves 84.79% accuracy on Adult dataset
- MOLE achieves 96.85% accuracy on MNIST (vs BP's 99.28%)
- MOLE achieves 76.01% accuracy on Mutagenicity
- MOLE achieves 68.40% accuracy on Cora

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Training by maximizing mutual information between layers and labels clusters representations by class
- Mechanism: I(Tk;Y) maximization pulls representations of same-class samples together while pushing different-class samples apart in representation space
- Core assumption: Mutual information maximization between representations and labels creates class-conditional clusters
- Evidence anchors:
  - [abstract] "The output of the decoder-like layer would cluster by class"
  - [section] "So the effect of I(Tk; Y ) maximization is to cluster the representations"
  - [corpus] Weak connection - no direct corpus evidence for clustering effect
- Break condition: When the data manifold is highly nonlinear and cannot be separated by mutual information maximization alone

### Mechanism 2
- Claim: Early layers trained by maximizing I(Tk;X) extract high-level features while preserving input information
- Mechanism: I(Tk;X) maximization encourages early layers to compress input while retaining task-relevant information
- Core assumption: Information bottleneck principle applies - early layers should retain relevant information about input
- Evidence anchors:
  - [abstract] "the first several layers should perform as the encoder to extract the important information"
  - [section] "the first layer is trained by I(Tk; X) maximization"
  - [corpus] No direct corpus evidence for this specific mechanism
- Break condition: When input data has no meaningful structure to extract or when compression removes task-relevant features

### Mechanism 3
- Claim: Sequential training with gradient isolation prevents interference between layers
- Mechanism: Each module trains independently without backpropagating errors through earlier layers
- Core assumption: Layer-wise training can succeed without global error propagation
- Evidence anchors:
  - [abstract] "MOLE makes the training become local optimization with gradient-isolated across modules"
  - [section] "each module is sequentially and independently trained by optimizing its objective"
  - [corpus] Weak connection - no direct corpus evidence for gradient isolation benefits
- Break condition: When layers are highly interdependent and cannot learn useful representations in isolation

## Foundational Learning

- Mutual Information Maximization
  - Why needed here: Core training objective for both encoder and decoder modules
  - Quick check question: What does maximizing I(Tk;Y) accomplish in the context of classification?

- Information Bottleneck Theory
  - Why needed here: Provides theoretical justification for separating encoder and decoder objectives
  - Quick check question: How does IB theory explain the need for different training objectives in early vs late layers?

- Graph Neural Networks
  - Why needed here: Required for understanding the Cora and Mutagenicity experiments
  - Quick check question: What distinguishes node-level from graph-level tasks in GNNs?

## Architecture Onboarding

- Component map: Encoder modules (I(Tk;X) maximization) -> Decoder modules (I(Tk;Y) maximization) -> Final layer (cross-entropy loss)

- Critical path:
  1. Define module assignment (encoder vs decoder)
  2. Choose appropriate MI estimator
  3. Sequentially train each module
  4. Connect modules and train final layer

- Design tradeoffs:
  - More encoder modules → better representation learning but slower convergence
  - More decoder modules → better class separation but risk of overfitting
  - Parametric vs non-parametric MI estimators → accuracy vs computational cost

- Failure signatures:
  - High train accuracy but low test accuracy → overfitting in decoder modules
  - Poor performance on grid data → inadequate spatial locality capture
  - Similar performance to random guessing → poor MI estimation

- First 3 experiments:
  1. Simple MLP on Adult dataset with matrix-based MI estimator
  2. CNN on MNIST with MINE estimator
  3. GCN on Cora with GMI estimator

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal module assignment between encoder-like and decoder-like components in MOLE?
- Basis in paper: [explicit] The paper states "the allocation of a greater number of layers to the encode-like module and a smaller number of layers to the decode-like module enhances the impact of I(Tk; X) while diminishing the influence of I(Tk; Y), and vice versa" and "These advantages would help the interpretability of DNNs" but doesn't specify the optimal ratio.
- Why unresolved: The paper experimentally demonstrates MOLE works with various assignments but doesn't systematically explore what assignment yields best performance across different data types and architectures.
- What evidence would resolve it: A comprehensive ablation study testing different layer assignments (e.g., 2-2, 3-1, 1-3) across multiple datasets and network architectures, measuring both performance and interpretability metrics.

### Open Question 2
- Question: Can we design an alternative technique to achieve InfoMax in decoder-like modules that's less computationally intensive than mutual information estimation?
- Basis in paper: [explicit] The paper mentions "certain self-supervised representation learning methods (SSRL, Ericsson et al., 2022) would work" and notes that "MI estimator for the high-dimensional data is usually time-consumed and not accurate enough, particularly in the encoder-like module."
- Why unresolved: While the paper suggests SSRL as a potential alternative, it doesn't demonstrate or validate whether such methods can achieve comparable performance to MI-based training.
- What evidence would resolve it: Comparative experiments showing that SSRL-based training achieves similar or better performance than MI estimation on the same datasets, with significantly reduced computational cost.

### Open Question 3
- Question: Can we prove how the parameters of each module span the hyperplane of its output?
- Basis in paper: [explicit] The paper asks "Is it possible to prove how the parameters of each module span the hyperplane of its output?" in the discussion section.
- Why unresolved: This is a theoretical question about the mathematical properties of modules trained via mutual information maximization, which the paper raises but doesn't address.
- What evidence would resolve it: A formal mathematical proof or theorem showing that under MOLE's training objective, the parameters of each module span a specific subspace or hyperplane related to the input or output space.

### Open Question 4
- Question: How does the quality of the mutual information estimator affect MOLE's performance, and can we design better estimators for complex data types?
- Basis in paper: [explicit] The paper shows "the quality of the MI estimator decisively affects the performance of neural networks" with significant performance differences between Matrix-based estimator, MINE, and GMI+MINE on Mutagenicity and Cora datasets.
- Why unresolved: While the paper demonstrates that estimator quality matters, it doesn't systematically investigate what makes a good estimator for MOLE or propose new estimator designs.
- What evidence would resolve it: Development and validation of new MI estimators specifically designed for MOLE's requirements, showing consistent performance improvements across diverse data types and tasks.

## Limitations
- MOLE consistently underperforms backpropagation across all tested datasets
- The mutual information estimation methods are not fully specified, hindering faithful reproduction
- No ablation studies to isolate which components contribute most to performance differences

## Confidence
- Low Confidence: MOLE's ability to match backpropagation performance - empirical results show consistent underperformance across all datasets
- Medium Confidence: The biological plausibility argument - while the gradient-isolated training is biologically motivated, there's no empirical evidence linking this to biological learning mechanisms
- High Confidence: The modular training framework structure - the sequential layer-wise training approach with separate objectives for early and late layers is clearly defined and implemented

## Next Checks
1. Run ablation studies comparing MOLE with variants that use backpropagation for some layers versus pure MI maximization
2. Test multiple mutual information estimation methods on each dataset to determine if estimator choice explains performance gaps
3. Compare training dynamics between MOLE and backpropagation to identify if gradient isolation causes slower convergence or gets stuck in poor local optima