---
ver: rpa2
title: 'CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data
  Synthesis'
arxiv_id: '2307.00384'
source_url: https://arxiv.org/abs/2307.00384
tags:
- data
- synthetic
- output
- auxiliary
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes CasTGAN, a cascaded generative adversarial
  network for synthesizing realistic tabular data. CasTGAN employs a sequential architecture
  with multiple generators, each producing one feature, and auxiliary learners for
  capturing feature dependencies.
---

# CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular Data Synthesis

## Quick Facts
- **arXiv ID**: 2307.00384
- **Source URL**: https://arxiv.org/abs/2307.00384
- **Reference count**: 40
- **Primary result**: CasTGAN outperforms state-of-the-art tabular GANs in ML utility, statistical similarity, and output validity while reducing invalid records

## Executive Summary
This paper proposes CasTGAN, a cascaded generative adversarial network architecture for synthesizing realistic tabular data. The key innovation is a sequential generator design where each feature is generated by a dedicated generator, with auxiliary learners providing feature-specific loss signals. Experiments on six datasets demonstrate that CasTGAN achieves superior performance compared to existing methods in terms of machine learning utility, statistical similarity, and output validity. The method also shows robustness against white-box privacy attacks when perturbing auxiliary learner training.

## Method Summary
CasTGAN employs a cascaded architecture with M generators, each producing one feature sequentially from noise and previous outputs. Each generator is paired with an auxiliary learner (trained with LightGBM) that predicts that feature from all others, providing loss signals during GAN training. The model uses WGAN-GP with gradient penalty, Gumbel-Softmax activations for categorical outputs, and Variational Gaussian Mixture models for numerical feature transformation. Training runs for 300 epochs with batch size 512 and auxiliary loss scaling coefficients from 0.75 to 0.10.

## Key Results
- CasTGAN achieves TSTR scores ranging from 76.8% to 91.1% across six datasets, outperforming existing methods
- Invalid record rates are significantly reduced with CORDV scores of 99.5% to 99.9% compared to 72.3% to 99.5% for baselines
- White-box privacy attacks are mitigated by label perturbation, with attacked samples showing greater distance from training data when ϵ > 0.2

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cascaded architecture with dedicated generators per feature improves validity by capturing dependencies sequentially
- Mechanism: Each generator Gi receives outputs from previous generators ˇGi-1 and noise z, allowing it to condition feature generation on previously generated features
- Core assumption: Feature dependencies in tabular data are hierarchical and can be modeled by generating features in a specific order
- Evidence anchors:
  - [abstract]: "Our key idea entails that employing a cascaded architecture in which a dedicated generator samples each feature, the synthetic output becomes more representative of the real data."
  - [section 4.1]: "Each generator Gi focuses on generating its target feature using a primary neural network, and is laid out sequentially such that it obtains its inputs from a given noise vector... and from the outputs of the previous generator"
- Break condition: If feature dependencies are non-hierarchical or cyclical, the sequential approach may fail to capture them adequately

### Mechanism 2
- Claim: Auxiliary learners for each feature improve synthetic data quality by providing feature-specific loss signals
- Mechanism: Each auxiliary learner ALi is trained to predict feature mi from all other features, providing loss signals λALi that guide each generator
- Core assumption: Auxiliary learners can learn true conditional distributions P(mi|X\i) representing feature dependencies
- Evidence anchors:
  - [section 4.2]: "We craft M auxiliary learners {AL1, . . . , ALM } for learning to predict the individual features... Due to its scalability on large datasets and the relatively fast convergence speed, we focus on building the auxiliary learners using the Light Gradient Boosting decision trees"
  - [abstract]: "Meanwhile, each generator is chained to a corresponding auxiliary learner in order to obtain more insightful losses specific to the individually generated features"
- Break condition: If auxiliary learners are poorly trained or overfit, they may provide misleading loss signals that degrade generation quality

### Mechanism 3
- Claim: White-box privacy attacks can be mitigated by perturbing auxiliary learner training labels
- Mechanism: Introducing label noise with perturbation parameter ϵ during auxiliary learner training makes learned mappings less precise
- Core assumption: Precision of auxiliary learners directly correlates with effectiveness of white-box attacks using them for data reconstruction
- Evidence anchors:
  - [section 5.3.4]: "For evaluating how effective such white-box attacks on our model, we control the training the of the auxiliary learners using a perturbation parameter ϵ. The perturbation parameter translates to the proportion of label samples that are modified when training the auxiliary learners"
  - [section 6.4]: "From Table 6, it can be observed that the perturbation coefficient ϵ greatly impacts the closeness of attacked samples to the training data"
- Break condition: If attackers have access to the perturbation mechanism or can estimate it, they may adapt their attack strategy accordingly

## Foundational Learning

- **Variational Gaussian Mixture models (VGM)**:
  - Why needed here: Used to represent multi-modal numerical features by identifying the number of modes and their magnitudes, helping capture complex distributions in tabular data
  - Quick check question: What is the primary advantage of using VGM over simple normalization for numerical features in GANs?

- **Gumbel-Softmax activation**:
  - Why needed here: Enables differentiable sampling from categorical distributions during generator training, allowing gradients to flow through categorical outputs
  - Quick check question: How does the temperature parameter τ in Gumbel-Softmax affect the diversity of generated categorical outputs?

- **Wasserstein GAN with gradient penalty (WGAN-GP)**:
  - Why needed here: Provides more stable training and smoother gradients compared to standard GANs, crucial for the complex cascaded architecture
  - Quick check question: What problem does gradient penalty solve in WGAN that weight clipping cannot address effectively?

## Architecture Onboarding

- **Component map**: Noise → G1 → G2 → ... → GM → D (discrimination); Noise → G1 → AL1, G2 → AL2, ..., GM → ALM (auxiliary losses)
- **Critical path**: Noise → G1 → G2 → ... → GM → D (discrimination); Noise → G1 → AL1, G2 → AL2, ..., GM → ALM (auxiliary losses)
- **Design tradeoffs**:
  - Sequential generation vs. parallel generation: Sequential allows better dependency modeling but may be slower
  - Auxiliary learners vs. no auxiliary learners: Improves feature quality but adds computational overhead
  - Perturbation vs. no perturbation: Improves privacy but may slightly degrade generation quality
- **Failure signatures**:
  - Mode collapse: Auxiliary learners detect it through poor diversity in generated features
  - Invalid records: High correlation RMSE with low UPCC ratio indicates invalid synthetic data
  - Privacy leaks: Low perturbation leads to attacked samples close to training data
- **First 3 experiments**:
  1. Test cascaded generation on a simple 3-feature dataset with known dependencies
  2. Compare auxiliary learner losses with and without label perturbation
  3. Measure UPCC and correlation RMSE on a toy dataset with artificial categorical dependencies

## Open Questions the Paper Calls Out
- How does CasTGAN perform on datasets with free text or timestamp features, which are not evaluated in the current study?
- What is the impact of varying the noise vector size on CasTGAN's output quality and diversity?
- How does CasTGAN's performance scale with extremely high-dimensional datasets (e.g., thousands of features)?

## Limitations
- The cascaded architecture assumes feature dependencies can be modeled sequentially, which may not hold for all tabular datasets with cyclical dependencies
- Privacy analysis is limited to white-box attacks; robustness against black-box attacks or more sophisticated reconstruction techniques remains unexplored
- Computational overhead of maintaining M separate generators and auxiliary learners may limit scalability to datasets with hundreds of features

## Confidence
- **High confidence**: The cascaded architecture improves validity over existing GAN approaches, as evidenced by consistently lower invalid record rates across all six datasets
- **Medium confidence**: Auxiliary learners significantly improve feature quality through conditional distribution learning, though the exact contribution of each auxiliary learner component could be more precisely quantified
- **Medium confidence**: Privacy perturbation effectively mitigates white-box attacks, though the security guarantees are limited to the specific attack model tested

## Next Checks
1. **Feature Ordering Sensitivity Analysis**: Systematically test different feature orderings in the cascaded architecture to determine if certain sequences consistently outperform others and whether the current random ordering is optimal
2. **Scalability Benchmark**: Evaluate CasTGAN on a dataset with 50+ features to measure the computational overhead and generation quality degradation compared to parallel-generation approaches
3. **Black-box Attack Vulnerability**: Test CasTGAN against black-box reconstruction attacks where the attacker has access to synthetic samples but not the model architecture or parameters, to assess real-world privacy guarantees