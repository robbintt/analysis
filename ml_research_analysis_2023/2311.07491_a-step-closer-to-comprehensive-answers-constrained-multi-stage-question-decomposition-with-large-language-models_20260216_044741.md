---
ver: rpa2
title: 'A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition
  with Large Language Models'
arxiv_id: '2311.07491'
source_url: https://arxiv.org/abs/2311.07491
tags:
- festival
- language
- large
- answer
- qixi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces the "Decompose-and-Query" framework (D&Q)
  to address the susceptibility of large language models to hallucinations in question-answering
  tasks. D&Q guides the model to utilize external knowledge within a constrained and
  reliable context, effectively mitigating the risk of hallucinations.
---

# A Step Closer to Comprehensive Answers: Constrained Multi-Stage Question Decomposition with Large Language Models

## Quick Facts
- **arXiv ID:** 2311.07491
- **Source URL:** https://arxiv.org/abs/2311.07491
- **Reference count:** 3
- **Primary result:** D&Q achieves 59.6% F1 on HotPotQA and wins 67% of human evaluations against ChatGPT on ChitChatQA

## Executive Summary
This paper introduces the "Decompose-and-Query" (D&Q) framework to address hallucinations in large language models during question-answering tasks. The framework guides models to decompose complex questions and consult a reliable external knowledge base, effectively constraining responses to verified information. Experiments show D&Q outperforms baselines on both ChitChatQA and HotPotQA, with the ability to backtrack during reasoning when encountering invalid paths.

## Method Summary
The D&Q framework decomposes complex questions, uses external knowledge retrieval, and avoids hallucinations by restricting the model to reliable information from a QA base. The method involves building a reliable QA base from real dialogue data, annotating 200 training instances with solution trajectories using GPT-4, and fine-tuning LLaMA2-13b with imitation learning on multi-turn dialogue format. During inference, the model calls external tools to query the QA base and supports backtracking to previous states if needed.

## Key Results
- On ChitChatQA, D&Q wins against ChatGPT in 67% of human evaluations
- On HotPotQA, D&Q achieves an F1 score of 59.6%
- The framework demonstrates competitive performance against existing models while reducing hallucination risk

## Why This Works (Mechanism)

### Mechanism 1
- Claim: D&Q reduces hallucination by enforcing consultation with a reliable QA base before generating responses
- Mechanism: When questions are decomposed, each sub-query is routed through a high-quality QA base. If the model's internal knowledge conflicts with the base, the base's answer takes precedence
- Core assumption: The QA base contains sufficiently high-quality, representative question-answer pairs to cover most sub-questions
- Evidence anchors: Abstract mentions framework restricts thinking to reliable information; section 3.2 states base's content takes precedence in conflicts

### Mechanism 2
- Claim: Depth-first search decomposition enables backtracking when reasoning paths fail
- Mechanism: The model explores one decomposition branch at a time and can roll back to previous steps if it encounters dead-ends
- Core assumption: The model can identify invalid paths and revert to prior states without losing context
- Evidence anchors: Abstract mentions ability to backtrack during search; section 3.3 describes example with rollback functionality

### Mechanism 3
- Claim: Imitation learning from annotated trajectories teaches effective tool invocation patterns
- Mechanism: The model is fine-tuned on human-annotated sequences of tool calls that represent optimal reasoning paths
- Core assumption: Annotated trajectories are diverse and representative enough to cover needed tool invocation patterns
- Evidence anchors: Section 3.4 describes using imitation learning with data involving multiple iterations of calling external retrievers

## Foundational Learning

- **Question decomposition and multi-hop reasoning**
  - Why needed: Complex questions require breaking down into sub-questions addressing different aspects or reasoning hops
  - Quick check: Given "Who was the president when the first man landed on the moon?", what are the two sub-questions you would ask?

- **External knowledge retrieval and integration**
  - Why needed: LLMs are prone to hallucination and outdated knowledge; retrieving from reliable sources ensures factual accuracy
  - Quick check: If asked "What is the capital of France?", how would a model use an external retriever versus relying on internal knowledge?

- **Imitation learning and trajectory-based fine-tuning**
  - Why needed: The model needs to learn tool call sequences from expert demonstrations rather than inefficient trial-and-error
  - Quick check: How does supervised fine-tuning on annotated tool invocation sequences differ from reinforcement learning in terms of feedback signal?

## Architecture Onboarding

- **Component map:** Input question → Question Decomposition Engine → Tool Invocation Layer (QuestionRetriever, AnswerRetriever, ArticleRetriever, PageRetriever, Finish) → Reliable QA Base → Aggregated Answer → Output

- **Critical path:** Question → Decomposition → Tool Selection → Retrieval from QA Base → Answer Generation → Aggregation/Completion

- **Design tradeoffs:**
  - Fixed QA base vs. dynamic retrieval: QA base offers consistency and speed but may lack coverage; dynamic retrieval is more flexible but reintroduces hallucination risk
  - Imitation learning vs. reinforcement learning: Imitation is faster to train and more stable but requires high-quality trajectories; RL can adapt to new patterns but is sample-inefficient
  - Depth-first vs. breadth-first search: DFS uses less memory and can backtrack efficiently but may explore deep wrong paths; BFS explores more options in parallel but is memory-intensive

- **Failure signatures:**
  - Repeated failure to find answers in QA base indicates poor decomposition or lack of coverage
  - Getting stuck in loops or failing to backtrack suggests broken state management
  - Wrong tool invocation order or unnecessary calls indicates imitation learning overfitting

- **First 3 experiments:**
  1. Test QA base coverage: Sample 100 decomposed sub-questions from ChitChatQA and check if they exist in the reliable QA base; measure hit rate
  2. Evaluate backtracking: Create test cases where first decomposition path fails; check if model correctly rolls back and tries alternative path
  3. Measure tool invocation accuracy: Compare model's tool call sequence against annotated trajectories on held-out set; compute exact match and edit distance

## Open Questions the Paper Calls Out

- How does constrained question decomposition in D&Q compare to other reasoning strategies like Tree-of-Thought or Graph of Thoughts in terms of computational efficiency and solution quality?
- How does the effectiveness of D&Q vary with the size of the reliable QA base? Is there a point of diminishing returns?
- How does D&Q handle questions requiring real-time or up-to-date information, given that the reliable QA base might not contain latest data?

## Limitations

- QA base construction and trajectory annotation processes lack sufficient detail for exact reproduction
- ChitChatQA dataset is proprietary and not publicly available, limiting independent verification
- No confidence intervals or statistical significance tests reported for human evaluation results

## Confidence

- **High confidence:** Core mechanism of using reliable QA base to constrain outputs and prevent hallucinations
- **Medium confidence:** Effectiveness of imitation learning from annotated trajectories
- **Medium confidence:** Backtracking mechanism's practical impact on performance

## Next Checks

1. Measure QA base coverage by sampling decomposed sub-questions from ChitChatQA and testing retrieval recall
2. Conduct ablation studies removing backtracking mechanism to quantify its contribution to overall performance
3. Test model generalization by evaluating on held-out subset of ChitChatQA not used in training or QA base construction