---
ver: rpa2
title: A Distributed Privacy Preserving Model for the Detection of Alzheimer's Disease
arxiv_id: '2312.10237'
source_url: https://arxiv.org/abs/2312.10237
tags:
- data
- federated
- learning
- alzheimer
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a vertical federated learning model for Alzheimer\u2019\
  s Disease (AD) detection that addresses the challenges of data segmentation and\
  \ privacy regulations in medical research. The model enables collaborative learning\
  \ across distributed sources of multimodal medical data while respecting HIPAA constraints."
---

# A Distributed Privacy Preserving Model for the Detection of Alzheimer's Disease

## Quick Facts
- arXiv ID: 2312.10237
- Source URL: https://arxiv.org/abs/2312.10237
- Reference count: 14
- Primary result: Proposed vertical federated learning model achieves 82.9% accuracy for Alzheimer's disease detection using distributed MRI and demographic data

## Executive Summary
This paper proposes a vertical federated learning (VFL) model for Alzheimer's Disease (AD) detection that addresses data segmentation and privacy challenges in medical research. The framework enables collaborative learning across distributed sources of multimodal medical data while respecting HIPAA privacy constraints. By leveraging both MRI images and demographic features through a distributed architecture, the model demonstrates promising results with 82.9% accuracy on the validation dataset, showcasing potential utility in clinical applications where data sharing is prohibited.

## Method Summary
The proposed method uses vertical federated learning to train a multimodal neural network across distributed data sources. Two federates participate: Federate A holds MRI images processed through a ResNet18 model, while Federate B holds demographic features and labels processed through a DNN. An interactive layer connects these bottom models, enabling feature fusion while keeping raw data local. The model is trained on the OASIS-2 dataset using the FATE framework, with data split across 142 patients (102 for training, 20 for validation, 20 for testing). The approach maintains HIPAA compliance by sharing only model parameters rather than raw patient data.

## Key Results
- Achieved 82.9% classification accuracy on validation dataset for 3-class AD detection
- Demonstrated feasibility of multimodal vertical federated learning for AD detection
- Showed that distributed learning can achieve competitive accuracy while preserving patient privacy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Vertical federated learning enables training across distributed datasets without moving sensitive medical data
- Mechanism: The model splits data across two federates - one holding image data (MRI) and another holding demographic data - and uses an interactive layer to combine features during training while keeping raw data local
- Core assumption: Data segmentation along feature axis (images vs. demographics) matches real-world medical data distribution and FATE library can handle this setup
- Evidence anchors:
  - [abstract] "The model enables collaborative learning across distributed sources of multimodal medical data while respecting HIPAA constraints."
  - [section] "Image data resided on Federate A while demographic data, including the Clinical Dementia Rating used as our label resided on Federate B."
  - [corpus] Weak evidence - corpus papers focus on horizontal federated learning, not vertical approaches for AD detection

### Mechanism 2
- Claim: Multimodal integration improves AD detection accuracy compared to single-modality approaches
- Mechanism: Combining MRI images with demographic features through bottom models (ResNet18 for images, DNN for demographics) and an interactive layer allows the model to capture both structural brain changes and patient-specific risk factors
- Core assumption: Both image and demographic features contain complementary information relevant to AD diagnosis, and the interactive layer effectively combines these representations
- Evidence anchors:
  - [abstract] "By leveraging multiple modalities of data, the robustness and accuracy of AD detection can be enhanced."
  - [section] "Our multimodal vertical federated neural network demonstrated promising results in the detection of Alzheimer's disease, achieving an overall accuracy of 82.9% on the validation dataset."
  - [corpus] Weak evidence - corpus papers use horizontal federated learning on single modalities (plasma data, MRI only) without multimodal integration

### Mechanism 3
- Claim: HIPAA compliance enables practical deployment in clinical settings where data sharing is prohibited
- Mechanism: By keeping patient data at individual healthcare institutions and only sharing model parameters, the approach satisfies HIPAA requirements while still enabling collaborative model improvement
- Core assumption: Sharing model parameters does not violate HIPAA privacy requirements and provides sufficient signal for collaborative learning
- Evidence anchors:
  - [abstract] "enables collaborative learning across diverse sources of medical data while respecting privacy constraints imposed by HIPAA."
  - [section] "This vertical federated model offers a distributed architecture that enables collaborative learning across diverse sources of medical data while respecting privacy constraints imposed by HIPAA."
  - [corpus] Weak evidence - corpus papers mention HIPAA/GDPR but focus on technical implementation rather than privacy compliance validation

## Foundational Learning

- Concept: Federated Learning
  - Why needed here: Enables training on distributed medical data while preserving patient privacy under HIPAA regulations
  - Quick check question: What is the key difference between horizontal and vertical federated learning, and which one applies when different features of the same patient are distributed across multiple institutions?

- Concept: Multimodal Machine Learning
  - Why needed here: Alzheimer's diagnosis benefits from combining multiple data types (imaging and demographics) that capture different aspects of disease progression
  - Quick check question: How does combining MRI images with demographic features potentially improve AD detection compared to using either modality alone?

- Concept: Model Architecture Design
  - Why needed here: The specific architecture (ResNet18 + DNN + interactive layer) must be designed to handle heterogeneous data types and enable federated training
  - Quick check question: Why might a modified ResNet18 be appropriate for MRI image processing in this federated context, and what role does the interactive layer play?

## Architecture Onboarding

- Component map: Federate A (images + ResNet18) -> Interactive Layer -> Top Model -> Output, Federate B (demographics + DNN) -> Interactive Layer
- Critical path: Data preprocessing -> federated training coordination -> interactive layer feature fusion -> model evaluation
- Design tradeoffs: Privacy preservation vs. model performance, computational efficiency vs. accuracy, complexity of federated coordination vs. simplicity
- Failure signatures: Low accuracy indicates poor feature fusion or insufficient predictive information; training instability suggests federated coordination issues
- First 3 experiments:
  1. Test local version with all data on one system to establish baseline accuracy without federated constraints
  2. Train with only image data or only demographic data to measure individual modality contribution
  3. Vary interactive layer size and architecture to optimize feature fusion performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of the proposed vertical federated learning (VFL) model compare to traditional centralized machine learning approaches on the same dataset?
- Basis in paper: [explicit] The paper states that the VFL model achieved an accuracy of 82.9% on the validation dataset, but does not compare this to a centralized model trained on the same data
- Why unresolved: The paper focuses on demonstrating the feasibility of VFL for AD detection, but does not provide a direct comparison to centralized approaches
- What evidence would resolve it: Conducting experiments to train and evaluate a centralized model on the same dataset, and comparing its performance to the VFL model

### Open Question 2
- Question: What is the impact of data segmentation on the performance of the VFL model, and how does it compare to the performance of a model trained on consolidated data?
- Basis in paper: [inferred] The paper discusses the challenges of data segmentation in medical research and proposes VFL as a solution, but does not provide a direct comparison of model performance with and without data segmentation
- Why unresolved: The paper does not provide a clear understanding of how data segmentation affects the model's performance and whether VFL can fully mitigate this issue
- What evidence would resolve it: Conducting experiments to train and evaluate models on consolidated data and segmented data, and comparing their performance to the VFL model

### Open Question 3
- Question: How does the proposed VFL model handle missing or incomplete data, and what is the impact of data quality on its performance?
- Basis in paper: [inferred] The paper mentions that some patient records were excluded due to missing features, but does not discuss how the model handles missing or incomplete data in general
- Why unresolved: The paper does not provide insights into how the model deals with real-world scenarios where data may be incomplete or of varying quality
- What evidence would resolve it: Conducting experiments to evaluate the model's performance on datasets with different levels of missing or incomplete data, and analyzing the impact of data quality on the model's accuracy

## Limitations
- Small dataset size (142 patients) with limited validation set (20 patients) raises concerns about statistical significance
- FATE framework limitations prevent validation loss calculation, hindering model monitoring and optimization
- Image preprocessing approach (extracting specific slices) may not capture full spectrum of AD-related brain changes

## Confidence

- **High Confidence**: The vertical federated learning approach for multimodal AD detection is technically sound and addresses real privacy constraints in medical research. The framework architecture (ResNet18 + DNN + interactive layer) is well-established for this application.
- **Medium Confidence**: The claimed accuracy of 82.9% is achievable based on the experimental setup, though the small validation set size makes precise accuracy assessment difficult. The privacy compliance claims are reasonable but require formal validation.
- **Low Confidence**: The practical deployment feasibility is uncertain due to FATE framework limitations, particularly the inability to monitor validation loss during training and potential issues with image data handling.

## Next Checks
1. **Framework Functionality Test**: Verify that FATE library can properly handle validation loss calculation and image data processing, or identify alternative federated learning frameworks that support these requirements
2. **Statistical Validation**: Conduct cross-validation across multiple random patient splits to establish confidence intervals for the 82.9% accuracy claim and assess model stability
3. **Clinical Utility Assessment**: Evaluate the model's performance on clinically relevant metrics (sensitivity, specificity, F1-score) and compare against established AD diagnostic criteria to determine practical utility in healthcare settings