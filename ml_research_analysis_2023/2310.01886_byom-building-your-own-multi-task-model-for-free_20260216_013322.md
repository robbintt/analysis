---
ver: rpa2
title: 'BYOM: Building Your Own Multi-Task Model For Free'
arxiv_id: '2310.01886'
source_url: https://arxiv.org/abs/2310.01886
tags:
- fine-tuned
- peru-fft
- merging
- task
- peru-lora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of reusing multiple fine-tuned
  models for multi-task learning without retraining. Existing merging methods suffer
  from a large performance gap compared to using individual fine-tuned models.
---

# BYOM: Building Your Own Multi-Task Model For Free

## Quick Facts
- arXiv ID: 2310.01886
- Source URL: https://arxiv.org/abs/2310.01886
- Authors: [Not specified in source]
- Reference count: 8
- Primary result: BYOM-FFT and BYOM-LoRA outperform existing merging methods by 20%+ and match single-task model performance while being more parameter-efficient

## Executive Summary
The paper addresses the problem of reusing multiple fine-tuned models for multi-task learning without retraining. Existing merging methods suffer from significant performance gaps compared to using individual fine-tuned models. The authors propose two parameter-efficient methods, BYOM-FFT and BYOM-LoRA, which inject task-specific knowledge into a merged model through sparse vector pruning and SVD-based LoRA approximation. Extensive experiments on vision and NLP tasks demonstrate that these methods outperform existing approaches while maintaining comparable performance to single-task models with much fewer parameters.

## Method Summary
BYOM provides two parameter-efficient approaches for building multi-task models from fine-tuned models. BYOM-FFT merges fully fine-tuned models and prunes task-specific vectors by keeping only top-m% magnitude values, isolating discriminative features while discarding redundant parameters. BYOM-LoRA approximates LoRA matrices using singular value decomposition, reducing parameters from r×(d_out+d_in) to q×(d_out+d_in+1) while maintaining performance. Both methods are data-free and computation-efficient, working by first merging task models into a shared base, then computing and pruning task vectors as differences from this merged model.

## Key Results
- BYOM-FFT and BYOM-LoRA outperform existing merging methods by over 20% average accuracy across tasks
- Both methods achieve comparable performance to single-task fine-tuned models while being significantly more parameter-efficient
- Merging before pruning (PERU-FFT) outperforms pruning before merging by capturing shared knowledge across tasks
- SVD approximation in PERU-LoRA shows exponential decrease in approximation error with increasing rank q

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Injecting sparse task-specific vectors into a merged model recovers task performance lost in naive merging
- Mechanism: After merging multiple task-specific models into a shared base, the difference between each task's fine-tuned parameters and the merged base captures task-specific knowledge. Pruning this difference vector (keeping only top-m% magnitudes) isolates the most discriminative task features while discarding redundant parameters
- Core assumption: Task-specific information is compressible into a sparse vector without significant loss of task performance
- Evidence anchors: Abstract states BYOM methods inject task-specific knowledge; section shows PERU-FFT outperforms Post-Pruning
- Break condition: If task-specific knowledge cannot be effectively compressed into sparse vectors, performance will degrade significantly

### Mechanism 2
- Claim: Using SVD on LoRA matrices allows parameter-efficient approximation while maintaining task performance
- Mechanism: For LoRA-finetuned models, the product A_t B_t^⊤ can be approximated by U(q)Σ(q)V(q)^⊤ where only the top q singular values and vectors are kept
- Core assumption: The task-specific LoRA matrices have low-rank structure that can be effectively approximated with fewer parameters
- Evidence anchors: Abstract mentions PERU-LoRA uses lower-rank matrix approximation; section shows exponential decrease in approximation error with increasing q
- Break condition: If LoRA matrices don't have assumed low-rank structure or q is too small, approximation quality will degrade

### Mechanism 3
- Claim: Merging before pruning outperforms pruning before merging by capturing shared knowledge
- Mechanism: By first creating a merged model containing shared knowledge from all tasks, then computing task vectors as differences from this merged model, the resulting vectors contain only task-specific information
- Core assumption: Shared knowledge across tasks exists and can be captured in a merged model
- Evidence anchors: Section shows PERU-FFT achieves higher accuracy than Post-Pruning; abstract describes BYOM-FFT merging before pruning
- Break condition: If tasks are too dissimilar or conflicting, the merged model may not capture useful shared knowledge

## Foundational Learning

- Concept: Parameter-efficient fine-tuning (e.g., LoRA)
  - Why needed here: Understanding how LoRA works is essential for grasping why PERU-LoRA's SVD approximation is effective and parameter-efficient
  - Quick check question: What is the key advantage of LoRA over full fine-tuning in terms of parameter count?

- Concept: Model merging and task arithmetic
  - Why needed here: The paper builds on existing model merging techniques, so understanding how uniform averaging and weighted merging work is crucial
  - Quick check question: How does Task-Arithmetic differ from Fisher-Merging in how they combine task models?

- Concept: Singular value decomposition and low-rank approximation
  - Why needed here: PERU-LoRA relies on SVD to approximate LoRA matrices, so understanding the relationship between rank and approximation quality is essential
  - Quick check question: What happens to the approximation error as you increase the rank q in SVD-based matrix approximation?

## Architecture Onboarding

- Component map:
  Pre-trained model (θ₀) -> Task-specific models (θ₁...θₜ) -> Merged model (θ*) -> Task vectors (vₜ or uₜ) -> Pruning mechanism -> Inference with added task vectors

- Critical path:
  1. Merge task-specific models into a shared base
  2. Compute task vectors as differences from the merged model
  3. Prune task vectors to retain only top-m% values
  4. During inference, add pruned task vectors to the merged model

- Design tradeoffs:
  - Parameter efficiency vs. task performance (higher m% or q means more parameters but better accuracy)
  - Computational cost of SVD approximation vs. parameter savings
  - Choice of merging algorithm affects quality of shared knowledge capture

- Failure signatures:
  - Performance close to pre-trained model but far from single-task models suggests insufficient task-specific information retention
  - Large performance gaps between tasks indicate task interference in the merged model
  - SVD approximation with small q showing poor performance suggests task information is not low-rank

- First 3 experiments:
  1. Compare Post-Pruning vs. PERU-FFT with varying m% values on a simple vision task to verify the benefit of merging before pruning
  2. Test PERU-LoRA with different q values on a LoRA-finetuned model to find the optimal rank-accuracy tradeoff
  3. Evaluate both methods on tasks with varying similarity to understand when merging is most effective

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of PERU-FFT and PERU-LoRA scale with an increasing number of tasks? Are there diminishing returns or performance degradation beyond a certain number of tasks?
- Basis in paper: The paper focuses on merging models for 8 tasks but does not explore the performance with a larger number of tasks
- Why unresolved: The paper does not provide experiments or analysis on how the proposed methods perform with a larger number of tasks
- What evidence would resolve it: Conducting experiments with a varying number of tasks and analyzing the performance would provide insights into their scalability

### Open Question 2
- Question: How do PERU-FFT and PERU-LoRA compare to other parameter-efficient fine-tuning methods, such as Adapter-based methods, in terms of performance and parameter efficiency?
- Basis in paper: The paper focuses on comparing the proposed methods to existing merging methods but does not compare them to other parameter-efficient fine-tuning methods
- Why unresolved: The paper does not provide a comparison with other parameter-efficient fine-tuning methods
- What evidence would resolve it: Conducting experiments comparing PERU-FFT and PERU-LoRA to other parameter-efficient fine-tuning methods would provide insights into their relative performance

### Open Question 3
- Question: How does the performance of PERU-FFT and PERU-LoRA vary with different values of the rank parameter q in PERU-LoRA and the percentage of task-specific parameters in PERU-FFT?
- Basis in paper: The paper mentions that the performance increases with rank parameter q and percentage of task-specific parameters
- Why unresolved: The paper does not provide a detailed analysis of how performance varies with different values
- What evidence would resolve it: Conducting experiments with different values would provide insights into their impact on performance

## Limitations
- Experiments limited to 8 vision tasks and 4 NLP tasks, may not generalize to more diverse or numerous task sets
- Computational efficiency claims don't account for initial cost of fine-tuning individual task models
- Performance degradation of existing merging methods (20% lower than single-task models) serves as relative benchmark but lacks absolute performance comparisons against other multi-task learning approaches

## Confidence

- **High Confidence**: The core mechanism of injecting task-specific knowledge through pruned vectors or SVD-approximated LoRA matrices is well-grounded in theoretical framework and supported by empirical results
- **Medium Confidence**: Claims about parameter efficiency and comparable performance to single-task models are supported by experimental results but would benefit from testing across broader range of tasks and model architectures
- **Medium Confidence**: Comparative advantage over existing merging methods is demonstrated on tested datasets, but absolute performance gap relative to training dedicated multi-task model remains unclear

## Next Checks

1. **Generalization Test**: Evaluate BYOM methods on a larger and more diverse set of tasks (e.g., 15+ tasks spanning different modalities) to verify scalability and robustness beyond the initial 12 tasks tested

2. **Ablation Study**: Systematically vary the pruning ratio (m%) and SVD rank (q) across multiple task combinations to understand sensitivity of performance to these hyperparameters and identify optimal configurations

3. **Computational Cost Analysis**: Measure and compare total computational resources required for BYOM (including fine-tuning individual models and merging) versus training dedicated multi-task model from scratch, providing more complete efficiency picture