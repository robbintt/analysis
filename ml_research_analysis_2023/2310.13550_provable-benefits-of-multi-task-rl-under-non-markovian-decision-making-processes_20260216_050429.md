---
ver: rpa2
title: Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes
arxiv_id: '2310.13550'
source_url: https://arxiv.org/abs/2310.13550
tags:
- learning
- multi-task
- tasks
- task
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies multi-task reinforcement learning (MTRL) under
  non-Markovian decision processes, specifically predictive state representations
  (PSRs). The key challenge is characterizing task similarity to reduce model complexity
  and improve sample efficiency.
---

# Provable Benefits of Multi-task RL under Non-Markovian Decision Making Processes

## Quick Facts
- arXiv ID: 2310.13550
- Source URL: https://arxiv.org/abs/2310.13550
- Reference count: 40
- Key outcome: This paper studies multi-task reinforcement learning (MTRL) under non-Markovian decision processes, specifically predictive state representations (PSRs). The key challenge is characterizing task similarity to reduce model complexity and improve sample efficiency. The authors propose using η-bracketing numbers to quantify the complexity of the joint model space across tasks. They develop UMT-PSR, an algorithm that exploits this structure for efficient learning. Theoretical analysis shows UMT-PSR achieves better sample complexity than single-task learning when the joint model space has lower η-bracketing number. Several concrete multi-task PSR examples with small η-bracketing numbers are provided. The authors also study downstream transfer learning, where the agent learns a new task using knowledge from upstream tasks. By leveraging similarity constraints, they show downstream learning can be more sample-efficient than learning from scratch. Overall, this work provides the first theoretical study of MTRL benefits under PSRs, establishing conditions for improved efficiency and providing practical algorithms.

## Executive Summary
This paper provides the first theoretical analysis of multi-task reinforcement learning benefits under predictive state representations (PSRs), a non-Markovian decision process framework. The authors characterize when and how multi-task learning can be more sample-efficient than single-task learning by introducing the concept of η-bracketing numbers to quantify model class complexity. They propose the UMT-PSR algorithm that leverages shared structure across tasks to achieve improved sample complexity. The work also studies downstream transfer learning, showing how knowledge from upstream tasks can accelerate learning of new tasks under similarity constraints. Concrete examples demonstrate how different multi-task PSR structures lead to reduced bracketing numbers and theoretical efficiency gains.

## Method Summary
The paper proposes a unified approach to characterize the effect of task similarity on model complexity in multi-task PSRs by introducing the notion of η-bracketing number. The UMT-PSR algorithm is developed to exploit this structure for efficient learning, using pairwise additive distance-based planning and exploration with confidence set construction based on bracketing numbers. For downstream transfer learning, the OMLE algorithm is proposed with Rènyi divergence-based error bounds. The theoretical analysis shows that when the joint model space has lower η-bracketing number than the product of individual task spaces, UMT-PSR achieves better sample complexity than single-task learning.

## Key Results
- UMT-PSR achieves better sample complexity than single-task learning when the joint model space has lower η-bracketing number
- Concrete multi-task PSR examples demonstrate η-bracketing number reduction: multi-task POMDPs with common transition kernels, multi-task PSRs with perturbed models, and multi-task PSRs with linear combinations of core tasks
- Downstream transfer learning with OMLE can be more sample-efficient than learning from scratch when similarity constraints are satisfied
- The framework provides first theoretical study of MTRL benefits under PSRs, establishing conditions for improved efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: η-bracketing number reduction enables sample efficiency gains in multi-task PSR learning
- Mechanism: By sharing latent structure across tasks, the joint model space has lower η-bracketing number than the product of individual task spaces. This reduced complexity translates directly into fewer samples needed to learn near-optimal policies.
- Core assumption: The similarity among tasks can be quantified by a lower η-bracketing number of the joint model space compared to individual tasks
- Evidence anchors:
  - [abstract]: "We posit a joint model class for tasks and use the notion of η-bracketing number to quantify its complexity"
  - [section 3.3]: "we propose a unified approach to characterize the effect of task similarity on model complexity by introducing the notion of the η-bracketing number"
  - [corpus]: Strong evidence from related work on multi-task learning showing bracketing number reduction improves sample efficiency
- Break condition: If tasks share no similarity structure (Θu = Θ^N), then η-bracketing number equals N times individual task number, eliminating multi-task benefit

### Mechanism 2
- Claim: Pairwise additive distance-based planning enables joint optimization across tasks
- Mechanism: Instead of measuring distance between product distributions, UMT-PSR uses sum of TV distances between individual task distributions. This ensures individual model accuracy while promoting joint planning.
- Core assumption: Pairwise additive distance is sufficient to guarantee individual task model accuracy while enabling joint optimization
- Evidence anchors:
  - [section 4.1]: "a natural choice to measure the distance between two multi-task models is the distance between the two product distributions... However, such a 'distance between product distributions' is not sufficient... Hence, we propose to use the 'pairwise additive distance'"
  - [section 4.2]: "The largest pairwise additive distance serves as an optimistic value of the uncertainty Dπ(θ*, θ) for any multi-task model θ ∈ Bk"
  - [corpus]: Limited direct evidence; this appears to be a novel contribution
- Break condition: If the confidence set Bk does not contain the true model θ* with high probability, pairwise additive distance planning may fail

### Mechanism 3
- Claim: Rènyi divergence provides robust transfer learning bounds in non-realizable downstream settings
- Mechanism: Rènyi divergence upper bounds both TV distance and KL divergence, making it suitable for measuring approximation error when the true model may not lie in the downstream model class.
- Core assumption: Rènyi divergence of order α ≥ 1 can serve as a robust upper bound for TV distance and KL divergence in transfer learning
- Evidence anchors:
  - [section 5.1]: "we employ Rènyi divergence to measure the 'distance' from the model class to the true model as follows, mainly because its unique advantage under the MLE oracle: the Rènyi divergence of order α with α ≥ 1 serves as an upper bound on the TV distance and the KL divergence"
  - [corpus]: Strong theoretical foundation from information theory literature on Rènyi divergence properties
- Break condition: If approximation error ϵ0 approaches ϵ²/4, the transfer benefit diminishes

## Foundational Learning

- Concept: Predictive State Representations (PSRs)
  - Why needed here: PSRs generalize MDPs and POMDPs to handle non-Markovian decision processes, which is the focus of this paper
  - Quick check question: How does a PSR represent the state differently from an MDP's state representation?

- Concept: Bracketing number and its relationship to sample complexity
  - Why needed here: The paper's core theoretical contribution relies on showing that reduced bracketing number leads to improved sample efficiency
  - Quick check question: What is the relationship between bracketing number and the number of samples needed to learn a model within ε accuracy?

- Concept: Low-rank sequential decision making problems
  - Why needed here: The paper focuses on low-rank PSRs, which have polynomial sample complexity rather than exponential
  - Quick check question: What property of the dynamics matrix Dh characterizes a rank-r sequential decision making problem?

## Architecture Onboarding

- Component map: UMT-PSR algorithm -> Confidence set construction -> Model estimation -> Policy optimization -> Transfer to downstream learning

- Critical path: UMT-PSR → Confidence set construction → Model estimation → Policy optimization → Transfer to downstream learning

- Design tradeoffs:
  - Pairwise additive distance vs. product distribution distance: Former ensures individual task accuracy but may be less efficient for joint optimization
  - Rènyi divergence vs. TV distance: Former provides more robust bounds in non-realizable settings but may be looser
  - Bracketing number vs. other complexity measures: Bracketing number provides unified characterization but may be harder to compute for complex task similarities

- Failure signatures:
  - Bracketing number not reducing: Indicates tasks share insufficient similarity structure
  - Confidence sets too large: May indicate insufficient exploration or incorrect bracketing number calculation
  - Transfer learning bounds too loose: May indicate poor choice of Rènyi divergence order α

- First 3 experiments:
  1. Implement UMT-PSR on two simple PSRs with known shared structure (e.g., Example 2 with perturbed models) and verify bracketing number reduction
  2. Compare sample complexity of UMT-PSR vs. single-task learning on multi-task PSRs with varying similarity structures
  3. Implement downstream learning with OMLE on a target PSR that shares structure with upstream tasks and measure transfer benefit

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the η-bracketing number framework be extended to continuous observation and action spaces, and what would be the implications for sample complexity?
- Basis in paper: [inferred] The paper focuses on finite observation and action spaces, but the abstract mentions extending benefits to more general sequential decision making problems.
- Why unresolved: The theoretical analysis relies on discrete combinatorics of brackets, which may not directly translate to continuous spaces where different covering techniques are needed.
- What evidence would resolve it: A formal extension of the UMT-PSR algorithm and theoretical analysis to continuous spaces, including new concentration bounds for continuous likelihood estimation.

### Open Question 2
- Question: How does the performance of multi-task learning scale with the number of tasks when tasks have varying degrees of similarity rather than uniform similarity?
- Basis in paper: [explicit] The paper discusses examples where β(N) < Nβ(1), but doesn't analyze how benefits degrade as similarity decreases across tasks.
- Why unresolved: The analysis assumes a joint model class with uniform properties, but real-world scenarios likely involve heterogeneous task similarities.
- What evidence would resolve it: Empirical studies showing sample complexity as a function of task similarity distribution, and theoretical bounds that account for task similarity variance.

### Open Question 3
- Question: What are the fundamental limits of transfer learning when downstream tasks have limited overlap with upstream tasks in terms of predictive state representations?
- Basis in paper: [explicit] The downstream section assumes similarity constraints but doesn't characterize the minimum overlap needed for transfer benefits.
- Why unresolved: The similarity constraint is abstract (C(θ0, θ1*, ..., θN*) ≤ 0) without specifying what structural properties must be preserved.
- What evidence would resolve it: Formal characterization of minimal representational overlap required for positive transfer, and examples of negative transfer when similarity is insufficient.

## Limitations

- The practical feasibility of computing η-bracketing numbers for complex task similarity structures remains unclear
- The transfer learning analysis assumes a fixed approximation error bound (ϵ0) that may vary significantly across downstream tasks in practice
- The theoretical benefits assume access to an ideal MLE oracle, which may not be achievable in finite-sample settings

## Confidence

- **High confidence**: The core theoretical framework connecting bracketing number reduction to sample efficiency (Mechanism 1), and the use of Rènyi divergence for transfer learning bounds (Mechanism 3)
- **Medium confidence**: The pairwise additive distance planning approach (Mechanism 2), as it's a novel contribution with limited direct evidence
- **Low confidence**: The practical implementation details of confidence set construction based on bracketing numbers

## Next Checks

1. **Empirical bracketing number verification**: Implement the example multi-task PSRs from Section 3.3 and verify that the η-bracketing numbers match theoretical predictions across different similarity structures
2. **Oracle performance comparison**: Compare UMT-PSR against a variant using product distribution distance planning to quantify the practical impact of the pairwise additive choice
3. **Transfer learning sensitivity analysis**: Systematically vary the approximation error bound ϵ0 in downstream transfer experiments to understand its impact on the theoretical benefits