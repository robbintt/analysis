---
ver: rpa2
title: Improving classifier decision boundaries using nearest neighbors
arxiv_id: '2310.03927'
source_url: https://arxiv.org/abs/2310.03927
tags:
- samples
- decision
- networks
- training
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses weaknesses in neural network decision boundaries,
  showing they lie in low data density areas prone to overfitting. The proposed method,
  LaSeNN, combines a sample's prediction with weighted averages of its k-nearest neighbors
  in latent space (layer activations), computed using either L2 or cosine similarity.
---

# Improving classifier decision boundaries using nearest neighbors

## Quick Facts
- arXiv ID: 2310.03927
- Source URL: https://arxiv.org/abs/2310.03927
- Authors: 
- Reference count: 14
- Primary result: LaSeNN improves accuracy, robustness to adversarial attacks, and resistance to label noise by using k-nearest neighbors in latent space

## Executive Summary
This paper addresses weaknesses in neural network decision boundaries, showing they lie in low data density areas prone to overfitting. The proposed method, LaSeNN, combines a sample's prediction with weighted averages of its k-nearest neighbors in latent space (layer activations), computed using either L2 or cosine similarity. This simple approach improves resistance to label noise (up to 3% gain), robustness against adversarial attacks (PGD and BIA), and classification accuracy across various datasets (CIFAR-10/100, ImageNet) and architectures (VGG, ResNet, MobileNet, ConvNext).

## Method Summary
LaSeNN works by computing k-nearest neighbors for each sample in a specified layer's activations using either L2 or cosine similarity. The method then combines the sample's original prediction with a weighted average of its neighbors' predictions, where the weighting parameter wq controls the balance between the original prediction and neighbor influence. The approach requires no architectural changes and can be applied to pretrained models, showing gains even on ImageNet models though improvements are modest.

## Key Results
- Improves resistance to label noise with up to 3% accuracy gain
- Enhances robustness against adversarial attacks (PGD and BIA)
- Increases classification accuracy across CIFAR-10/100, ImageNet datasets
- Works with various architectures including VGG, ResNet, MobileNet, ConvNext
- Best results achieved with deep layers, low k values (k=1), and weights favoring sample (wq≈0.75-0.88)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decision boundaries in neural networks lie in low-density regions where few training samples exist, making them prone to overfitting.
- Mechanism: The proposed method uses weighted averaging of a sample's prediction with its k-nearest neighbors in latent space, effectively smoothing the decision boundary in these sparse regions.
- Core assumption: Layer activations form dense clusters for each class, with sparse regions between them where decision boundaries are placed.
- Evidence anchors:
  - [abstract] "We show that decision boundaries are situated in areas of low training data density."
  - [section] "Classes form dense clusters that are separated by sparse space. The decision boundary runs through the sparse space."
  - [corpus] Weak evidence - corpus neighbors don't directly address decision boundary placement, but show related work on nearest neighbors and explanations.

### Mechanism 2
- Claim: Combining predictions with nearest neighbors improves robustness to adversarial attacks and label noise.
- Mechanism: Samples near decision boundaries (which are more susceptible to perturbations) benefit from neighbor information, while samples in dense regions remain largely unaffected.
- Core assumption: Adversarial examples and noisy labels often push samples toward or across decision boundaries, where neighbor information is most valuable.
- Evidence anchors:
  - [abstract] "This simple approach improves resistance to label noise (up to 3% gain), robustness against adversarial attacks (PGD and BIA)"
  - [section] "We also expect that changes of class predictions due to LaSeNN occur primarily in low density areas (e.g. for large mean distances)"
  - [corpus] Moderate evidence - corpus contains papers on adversarial examples and label noise, though not directly comparing with nearest neighbor approaches.

### Mechanism 3
- Claim: Using nearest neighbors provides interpretability by indicating which training samples most influence predictions.
- Mechanism: The weighted combination reveals the contribution of each neighbor to the final prediction, showing which training samples the model considers similar.
- Core assumption: The latent space similarity computed using layer activations reflects meaningful semantic similarity.
- Evidence anchors:
  - [abstract] "Nearest neighbors provide interpretability by indicating which training samples most influence predictions."
  - [section] "The returned NNs help to better understand classifier decisions, i.e., they are well-interpretable. They indicate which samples of the training data contribute at least the fraction (1 − wq) to the decision"
  - [corpus] Moderate evidence - corpus includes papers on example-based explanations and nearest neighbor classifiers, though not specifically for interpretability.

## Foundational Learning

- Concept: High-dimensional vector spaces and distance metrics
  - Why needed here: The method relies on computing nearest neighbors in latent space using L2 or cosine similarity, which requires understanding how distance behaves in high dimensions.
  - Quick check question: Why might cosine similarity be preferred over L2 distance in sparse high-dimensional spaces?

- Concept: Neural network feature hierarchies and layer activations
  - Why needed here: The method uses layer activations as the latent representation for computing nearest neighbors, requiring understanding of what different layers capture.
  - Quick check question: Why does using deeper layers tend to yield better results for this method?

- Concept: Decision boundary geometry and overfitting
  - Why needed here: The core insight is that decision boundaries in neural networks are suboptimal because they lie in low-density regions, requiring understanding of how decision boundaries form and behave.
  - Quick check question: Why are decision boundaries placed in low-density regions particularly vulnerable to overfitting?

## Architecture Onboarding

- Component map:
  Input -> Forward pass through network -> Compute similarities with training data -> Select k nearest neighbors -> Weighted prediction aggregation -> Final class prediction

- Critical path:
  1. Forward pass through network to get activations
  2. Compute pairwise similarities with training data
  3. Select nearest neighbors
  4. Aggregate predictions with weighted average
  5. Return final prediction

- Design tradeoffs:
  - Layer selection: Deeper layers capture more semantic features but may lose discriminative power; shallower layers preserve more detail but may be less semantically meaningful
  - Number of neighbors (k): Small k values preserve local structure but may be noisy; large k values smooth more but may lose local detail
  - Weighting (wq): Higher weights preserve original model's predictions but reduce neighbor influence; lower weights increase smoothing but may deviate from original model

- Failure signatures:
  - Poor performance on clean data: May indicate inappropriate layer selection or neighbor weighting
  - Increased variance in predictions: May indicate too few neighbors or inappropriate similarity metric
  - Computational bottlenecks: May indicate need for approximate nearest neighbor search or dimensionality reduction

- First 3 experiments:
  1. Baseline comparison: Run original model vs LaSeNN on CIFAR-10/100 with default parameters to verify accuracy gains
  2. Layer sensitivity: Test different layer choices (last conv layer vs pool layer vs dense layer) to find optimal layer for similarity computation
  3. Neighbor sensitivity: Vary k values (1, 3, 5, 8) and weighting (wq) to find optimal balance between original prediction and neighbor influence

## Open Questions the Paper Calls Out
No specific open questions were called out in the provided content.

## Limitations
- Effectiveness depends heavily on latent space structure forming distinct, dense class clusters with sparse boundaries
- Computational overhead of computing nearest neighbors in high-dimensional latent spaces may be prohibitive for real-time applications
- Parameter sensitivity requires careful tuning per architecture and dataset with no clear theoretical guidance
- Modest improvements on pretrained ImageNet models suggest diminishing returns for well-trained networks

## Confidence
- High confidence in core mechanism (decision boundaries in low-density regions benefit from neighbor smoothing)
- Medium confidence in parameter recommendations (wq ≈ 0.75-0.88, k=1, deep layers)
- Low confidence in scalability claims since computational costs are not quantified

## Next Checks
1. Verify latent space cluster structure by measuring class purity and intra-class vs inter-class distances in the chosen layer before applying LaSeNN
2. Benchmark computational overhead by measuring inference time with and without nearest neighbor computation on representative datasets
3. Test the method's effectiveness on out-of-distribution samples and few-shot learning scenarios to evaluate generalization beyond in-distribution accuracy improvements