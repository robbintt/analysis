---
ver: rpa2
title: Generating collective counterfactual explanations in score-based classification
  via mathematical optimization
arxiv_id: '2310.12822'
source_url: https://arxiv.org/abs/2310.12822
tags:
- counterfactual
- explanations
- features
- instances
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method to generate collective counterfactual
  explanations for groups of instances in score-based classification models. It formulates
  the problem as a mathematical optimization model that minimizes the total cost of
  perturbations needed to change the classification of a group of instances, while
  allowing for linking constraints and outlier detection.
---

# Generating collective counterfactual explanations in score-based classification via mathematical optimization

## Quick Facts
- arXiv ID: 2310.12822
- Source URL: https://arxiv.org/abs/2310.12822
- Reference count: 40
- Key outcome: A method to generate collective counterfactual explanations for groups of instances by formulating the problem as a mathematical optimization model that minimizes total perturbation cost while allowing linking constraints and outlier detection.

## Executive Summary
This paper proposes a novel approach to generate collective counterfactual explanations for groups of instances in score-based classification models. The method formulates the problem as a mixed integer convex quadratic program that minimizes the total cost of perturbations needed to change the classification of a group of instances, while allowing for linking constraints and outlier detection. By treating some instances individually and others collectively, the method can identify outliers and critical features for the entire group. The approach is applied to logistic regression and additive tree models, demonstrating its effectiveness on real-world datasets.

## Method Summary
The method generates collective counterfactual explanations by formulating the problem as a mixed integer convex quadratic program. The objective function combines the sum of squared Euclidean distances between original and counterfactual instances, an ℓ0 norm term counting the number of perturbed features per instance, and a global sparsity term counting how many features are ever perturbed across all instances. The classifier constraint is linearized using Fortet's method for linear classifiers or via a MIP reformulation for additive tree models. Binary variables indicate whether features are changed, allowing the ℓ0 and global sparsity terms to be linearized. This results in a tractable optimization problem that can be solved to optimality for moderate-sized datasets.

## Key Results
- The method can identify critical features for classification and detect outliers in the data by minimizing a cost function that balances total perturbation cost and sparsity.
- Collective counterfactual explanations are generated for logistic regression and additive tree models, demonstrating the approach's effectiveness on real-world datasets.
- By treating some instances individually and others collectively, the method can distinguish outliers and handle them appropriately.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Collective counterfactual explanations can be constructed by minimizing a cost function that balances the total perturbation cost across a group of instances and the sparsity of feature changes, subject to classifier constraints.
- Mechanism: The method formulates the collective counterfactual generation as a mixed integer convex quadratic program. The objective combines a sum of squared Euclidean distances between original and counterfactual instances, an ℓ0 norm term counting the number of perturbed features per instance, and a global sparsity term counting how many features are ever perturbed across all instances. Binary variables indicate whether features are changed, allowing the ℓ0 and global sparsity terms to be linearized. The classifier constraint is linearized using Fortet's method for linear classifiers, or via a MIP reformulation for additive tree models. This results in a tractable optimization problem that can be solved to optimality for moderate-sized datasets.
- Core assumption: The classifier score function is known and can be expressed in a form amenable to linearization (e.g., linear for logistic regression, or via tree path encoding for additive trees). The feasible set of counterfactuals is bounded and can be encoded with big-M constraints.
- Evidence anchors:
  - [abstract]: "Under some assumptions on the classifier and the space in which counterfactuals are sought, finding collective counterfactuals is reduced to solving a convex quadratic linearly constrained mixed integer optimization problem..."
  - [section 2.2]: Details the linearization of ℓ0 norms, global sparsity term, and classifier constraints using binary variables and big-M constraints.
  - [corpus]: Weak evidence; no related work directly discusses the MIP formulation or the use of global sparsity to identify critical features across a group.
- Break condition: If the classifier score function cannot be linearized or encoded efficiently, the problem becomes intractable. Similarly, if the feasible set of counterfactuals is not bounded, the big-M constants cannot be defined, leading to weak relaxations.

### Mechanism 2
- Claim: By treating some instances individually and others collectively, the method can identify outliers in the group of interest.
- Mechanism: The optimization model allows specifying the number of instances I* to be included in the collective counterfactual analysis. Instances not selected (i.e., those for which y_i = 0) are not perturbed and retain their original values. By varying I* or solving the model for a subset of the group, one can identify instances that incur high perturbation costs and thus are likely outliers. These outliers are handled separately, as in the single-instance single-counterfactual setting.
- Core assumption: Outliers are defined as instances that require significantly higher perturbation costs than the rest of the group to achieve the desired classification. The method can distinguish these instances by their contribution to the objective function.
- Evidence anchors:
  - [abstract]: "Our methodology allows for some instances to be treated individually, performing the collective counterfactual analysis for a fraction of records of the group of interest. This way, outliers are identified and handled appropriately."
  - [section 2.1]: Discusses the binary variables y_i that indicate whether an instance is allowed to be perturbed.
  - [corpus]: Weak evidence; no related work explicitly discusses outlier detection in the context of collective counterfactual explanations.
- Break condition: If the outlier detection is based solely on the perturbation cost, it may misclassify instances that truly require large changes to achieve the desired outcome, even if they are not outliers in the traditional sense.

### Mechanism 3
- Claim: The method can identify the critical features for the entire group of interest by minimizing the global sparsity term.
- Mechanism: The global sparsity term γ0(x0, x) in the cost function counts the number of features that are ever perturbed across all instances in the group. By setting λglob > 0, the optimization model is incentivized to find counterfactuals that only change a small set of features for all instances. This way, the features that are perturbed are the ones that are critical for the entire group to be classified in the desired class. By solving the model for different values of λglob, one can trace out a Pareto front of solutions with varying levels of global sparsity.
- Core assumption: The global sparsity term accurately captures the features that are critical for the entire group. Setting λglob > 0 will lead the optimization to find counterfactuals that change a small set of features for all instances.
- Evidence anchors:
  - [abstract]: "Making the process of constructing counterfactuals collective instead of individual enables us to detect the features that are critical to the entire dataset to have the individuals classified in the desired class."
  - [section 2.1]: Defines the global sparsity term γ0(x0, x) as the number of features ever perturbed across all instances.
  - [corpus]: Weak evidence; no related work explicitly discusses the use of global sparsity to identify critical features across a group in the context of counterfactual explanations.
- Break condition: If the global sparsity term does not accurately capture the features that are critical for the entire group, or if setting λglob > 0 leads to counterfactuals that are not feasible or do not achieve the desired classification, the method will fail to identify the correct critical features.

## Foundational Learning

- Concept: Linear classifiers and their score functions
  - Why needed here: The method relies on being able to express the classifier's decision boundary in terms of a score function, which for linear classifiers is a linear combination of the input features. This score function is then used to formulate the constraints of the optimization problem.
  - Quick check question: Given a logistic regression model with weights w and bias b, what is the score function that determines the predicted class of an instance x?

- Concept: Mixed integer programming and linearization techniques
  - Why needed here: The optimization problem formulated by the method involves both continuous variables (the counterfactual instances) and binary variables (indicating whether features are perturbed). To solve this problem, it needs to be expressed as a mixed integer program, which requires linearizing the ℓ0 norm and the global sparsity term using binary variables and big-M constraints.
  - Quick check question: How can the ℓ0 norm of a vector v be linearized using binary variables z and big-M constraints?

- Concept: Additive tree models and their representation
  - Why needed here: The method is also applicable to additive tree models, such as random forests or XGBoost. These models can be represented as a sum of tree scores, where each tree assigns a weight to the positive or negative class based on the path the instance takes through the tree. This representation is used to formulate the constraints of the optimization problem.
  - Quick check question: How can the score function of an additive tree model be expressed in terms of the weights of the trees and the leaves that the instance ends up in?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training -> Counterfactual generation -> Outlier detection -> Critical feature identification
- Critical path: The most critical component is the counterfactual generation, as it involves solving a complex optimization problem. The data preprocessing and model training are also important, as they determine the form of the classifier and the feasible set of counterfactuals. The outlier detection and critical feature identification are secondary, as they rely on the results of the counterfactual generation.
- Design tradeoffs: The main tradeoff is between the accuracy of the counterfactual explanations and the computational complexity of the optimization problem. Increasing the number of instances or the complexity of the classifier will make the problem harder to solve. Another tradeoff is between the sparsity of the counterfactual explanations and their feasibility. Increasing the sparsity (by setting λind or λglob to higher values) may lead to counterfactuals that are not feasible or do not achieve the desired classification.
- Failure signatures: If the optimization problem cannot be solved to optimality, the counterfactual explanations may be suboptimal or infeasible. If the linearization of the ℓ0 norm or the global sparsity term is not tight, the problem may have a weak relaxation. If the big-M constants are not chosen properly, the problem may have numerical issues. If the classifier is too complex or the feasible set of counterfactuals is too large, the problem may be intractable.
- First 3 experiments:
  1. Solve the optimization problem for a small dataset with a simple linear classifier (e.g., logistic regression on the Boston housing dataset) and verify that the counterfactual explanations make sense and achieve the desired classification.
  2. Vary the values of λind and λglob and observe how the counterfactual explanations change. Verify that increasing λind leads to sparser explanations for each instance, while increasing λglob leads to explanations that change a smaller set of features globally.
  3. Solve the optimization problem for a dataset with outliers (e.g., the COMPAS dataset) and verify that the method can identify and handle the outliers separately. Observe how the counterfactual explanations change when including or excluding the outliers.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed collective counterfactual explanation method compare to traditional single-instance methods in terms of accuracy and interpretability?
- Basis in paper: [inferred] The paper introduces a novel approach for generating collective counterfactual explanations and demonstrates its effectiveness on real-world datasets, but does not provide a direct comparison to traditional single-instance methods.
- Why unresolved: The paper focuses on the methodology and its application rather than a comparative analysis with existing methods.
- What evidence would resolve it: A comprehensive study comparing the collective approach to single-instance methods in terms of accuracy, interpretability, and computational efficiency.

### Open Question 2
- Question: How does the choice of cost function parameters (λind and λglob) affect the quality and interpretability of the collective counterfactual explanations?
- Basis in paper: [explicit] The paper discusses the impact of different cost function parameters on the results, but does not provide a systematic analysis of their influence on the quality and interpretability of the explanations.
- Why unresolved: The paper presents examples with specific parameter values but does not explore the parameter space comprehensively.
- What evidence would resolve it: A thorough investigation of the sensitivity of the results to different parameter values, including an analysis of the trade-offs between sparsity and interpretability.

### Open Question 3
- Question: How can the proposed method be extended to handle more complex machine learning models, such as deep neural networks or ensemble methods with a large number of base models?
- Basis in paper: [inferred] The paper demonstrates the method for logistic regression and additive tree models, but does not discuss its applicability to more complex models.
- Why unresolved: The paper focuses on specific model types and does not address the challenges and potential adaptations required for more complex models.
- What evidence would resolve it: A study exploring the extension of the method to other model types, including a discussion of the computational and methodological challenges involved.

## Limitations

- The method's performance heavily depends on the choice of big-M constants and the linearization accuracy of the ℓ0 norm and global sparsity terms, which can impact solver performance and solution quality.
- The handling of nominal categorical features through one-hot encoding introduces additional complexity that may affect the optimization models' effectiveness.
- The method's scalability to large datasets and complex models is uncertain due to the computational complexity of mixed integer quadratic programs.

## Confidence

- **High Confidence**: The mathematical formulation of the optimization problem and its ability to generate collective counterfactual explanations for linear classifiers.
- **Medium Confidence**: The extension to additive tree models and the effectiveness of outlier detection through perturbation cost analysis.
- **Low Confidence**: The method's scalability to large datasets and complex models, given the computational complexity of mixed integer quadratic programs.

## Next Checks

1. **Scalability Test**: Evaluate the method's performance on larger datasets (e.g., >10,000 instances) to assess computational tractability and solution quality degradation.

2. **Cross-Model Comparison**: Apply the method to different classifier types (e.g., neural networks) and compare the resulting counterfactual explanations to validate generalizability.

3. **Robustness Analysis**: Conduct sensitivity analysis on the choice of big-M constants and linearization parameters to quantify their impact on solution quality and solver performance.