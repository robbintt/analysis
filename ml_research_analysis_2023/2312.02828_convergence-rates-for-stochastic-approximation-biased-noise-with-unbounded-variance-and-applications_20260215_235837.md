---
ver: rpa2
title: 'Convergence Rates for Stochastic Approximation: Biased Noise with Unbounded
  Variance, and Applications'
arxiv_id: '2312.02828'
source_url: https://arxiv.org/abs/2312.02828
tags:
- convergence
- then
- theorem
- function
- such
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the convergence properties of the Stochastic
  Gradient Descent (SGD) method for finding a stationary point of a given objective
  function $J(\cdot)$. The objective function is not required to be convex.
---

# Convergence Rates for Stochastic Approximation: Biased Noise with Unbounded Variance, and Applications

## Quick Facts
- arXiv ID: 2312.02828
- Source URL: https://arxiv.org/abs/2312.02828
- Reference count: 40
- Primary result: Extends SA convergence theory to biased noise with unbounded variance and derives convergence rates under Polyak-Lojasiewicz condition.

## Executive Summary
This paper studies the convergence properties of Stochastic Gradient Descent (SGD) for finding stationary points of invex functions, which generalize convex functions by ensuring all stationary points are global minimizers. The authors establish almost sure convergence under relaxed assumptions on the noise process, including nonzero conditional mean and unbounded conditional variance. They further derive convergence rate estimates when the objective satisfies the Polyak-Lojasiewicz condition, showing that SGD achieves the same rate as the best possible for convex functions. The results are extended to zeroth-order methods and asynchronous updates.

## Method Summary
The paper analyzes Stochastic Approximation (SA) algorithms with step sizes α_t = O(t^-(1-φ)), where φ is arbitrarily small. The convergence analysis relies on extending the Robbins-Siegmund theorem to handle biased noise with unbounded variance by requiring summability conditions on the bias and variance terms. For rate analysis, a Lyapunov drift approach combined with concave transformations is used. The results are applied to SGD for invex functions, zeroth-order methods using approximate gradients, and asynchronous updating schemes.

## Key Results
- Almost sure convergence of SGD for invex functions under the KL' condition
- Rate estimates of o(t^-λ) for λ arbitrarily close to 1 under the PL condition
- Extension of convergence and rates to biased noise with unbounded variance
- Rate of o(t^-(1/3-ε)) for zeroth-order methods with noisy function measurements
- Convergence preservation under asynchronous updates via time-change arguments

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The extended Robbins-Siegmund theorem enables convergence proofs even with biased noise and unbounded conditional variance.
- Mechanism: By replacing zero-mean and bounded variance assumptions with summability conditions on bias and variance terms, the supermartingale convergence argument still applies.
- Core assumption: Error process {ζ_t+1} has bounded conditional second moments CV_t(ζ_t+1) ≤ M_t²(1 + ∥θ_t∥²), and bias ∥E_t(ζ_t+1)∥² is summable with step sizes.
- Evidence anchors:
  - [abstract] "We extend SA theory to encompass errors with nonzero conditional mean and/or unbounded conditional variance"
  - [section] Theorem 3: Conditions (13)-(14) replace zero-mean and bounded-variance assumptions.
  - [corpus] None of the cited papers directly address this extension; the present work appears novel in this respect.
- Break condition: If summability conditions (15) fail, the martingale convergence argument breaks down.

### Mechanism 2
- Claim: Rate estimates follow from Lyapunov drift analysis combined with concave transformation argument.
- Mechanism: By defining V_t = t^λ∥θ_t∥² and showing E_t(V_{t+1}) ≤ (1 + f_t)V_t - α_tV_t, concavity of t ↦ t^λ ensures V_t → 0, hence ∥θ_t∥² = o(t^-λ).
- Core assumption: Step size α_t = O(t^-(1-φ)) with φ < min{0.5 - δ, γ} where γ, δ bound bias and variance growth.
- Evidence anchors:
  - [section] Theorem 2: Proof uses (t+1)^λ ≤ t^λ + λt^(λ-1) to derive decay rate.
  - [abstract] "derive estimates on the rate of convergence of the SA algorithm under appropriate assumptions"
  - [corpus] None of neighbor papers explicitly use this concave transformation technique.
- Break condition: If φ ≥ min{0.5 - δ, γ}, summability of {α_t} fails and rate bound no longer holds.

### Mechanism 3
- Claim: Asynchronous updates preserve convergence and rates via time-change argument.
- Mechanism: By tracking effective iteration count ν_t and mapping asynchronous process to synchronous one with step sizes α_τ = β_{ν^-1(τ)}, same Robbins-Siegmund and rate arguments apply.
- Core assumption: Update process {κ_t} satisfies ν_t/t → r > 0 almost surely, ensuring ν_t → ∞ and effective step sizes remain summable.
- Evidence anchors:
  - [section] Theorems 5 and 6: Local vs global clock choices preserve convergence under (U1)-(U3).
  - [abstract] "extend both the convergence result and the rate estimate to the case of asynchronous updating"
  - [corpus] None of neighbor papers explicitly treat this asynchronous time-change; this is a novel contribution.
- Break condition: If update process is too sparse (ν_t/t → 0), effective step sizes may fail to be summable.

## Foundational Learning

- Concept: Martingale convergence theorems (Robbins-Siegmund)
  - Why needed here: They provide backbone for proving almost-sure convergence under relaxed noise assumptions.
  - Quick check question: In classic Robbins-Siegmund theorem, what conditions on {f_t}, {g_t}, {h_t} guarantee {z_t} is bounded and ∑h_t < ∞?

- Concept: Lyapunov drift analysis with quadratic Lyapunov functions
  - Why needed here: To bound E_t(J(θ_{t+1})) and relate it to ∥∇J(θ_t)∥² and J(θ_t), enabling rate extraction.
  - Quick check question: In Theorem 7, which inequality combines Lipschitz assumption (J1) and PL-type bound (J2) to bound drift term?

- Concept: Time-change arguments for asynchronous processes
  - Why needed here: To map asynchronous update process to synchronous one with adjusted step sizes.
  - Quick check question: If κ_t = 1 only at times t = ν^-1(τ), what is relationship between α_t and α_τ under local clock?

## Architecture Onboarding

- Component map: θ_t (parameter vector) -> h(θ_t, Y_t) + ξ_{t+1} (stochastic gradient) -> θ_{t+1} = (1-α_t)θ_t + α_t[h(θ_t, Y_t) + ξ_{t+1}] (update rule)
- Critical path: (i) Observe h(θ_t, Y_t) + ξ_{t+1} at each t; (ii) Update θ_{t+1} = (1-α_t)θ_t + α_t[h(θ_t, Y_t) + ξ_{t+1}]; (iii) Check summability of α_t², α_tμ_t, α_tM_t²; (iv) If satisfied, invoke Theorem 3 for convergence.
- Design tradeoffs: (a) Larger α_t speeds initial progress but risks violating summability; (b) Smaller α_t improves stability but slows convergence; (c) Biased noise (μ_t > 0) requires faster decay of α_t to compensate.
- Failure signatures: (i) If ∑α_t = ∞, but ∑α_t² = ∞, iterates may diverge; (ii) If μ_t decays too slowly relative to α_t, bias accumulates; (iii) If M_t grows too fast, variance overwhelms drift term.
- First 3 experiments:
  1. Implement synchronous update with α_t = 1/(t+1)^0.9, μ_t = 1/√(t+2), M_t = √(t+2); verify ∑α_t² < ∞, ∑α_tμ_t < ∞, ∑α_tM_t² < ∞.
  2. Switch to asynchronous updates with κ_t Bernoulli(p=0.1), β_t = 1/(t+1)^0.9; confirm ν_t/t → 0.1 and convergence holds under (U1).
  3. Introduce biased noise μ_t = 1/t^0.6, M_t = 1; choose α_t = 1/(t+1)^0.8; check that φ < min{0.5-δ,γ} still permits o(t^-λ) rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions can SGD achieve convergence rate o(t^-λ) where λ is arbitrarily close to 1, even when gradient measurements are corrupted by noise?
- Basis in paper: [explicit] The paper states optimal step size sequence is α_t = O(t^-(1-φ)), where φ is arbitrarily small, leading to convergence rate o(t^-λ) for λ arbitrarily close to 1.
- Why unresolved: Paper does not provide complete characterization of conditions under which this optimal rate is achievable, particularly regarding trade-off between step size sequence and noise characteristics.
- What evidence would resolve it: Empirical studies or theoretical proofs demonstrating conditions under which convergence rate of o(t^-λ) is achieved, along with corresponding step size sequences and noise characteristics.

### Open Question 2
- Question: How does use of approximate gradients (zeroth-order methods) with noisy function measurements affect convergence rate of SGD compared to using noisy gradient measurements?
- Basis in paper: [explicit] Paper shows using approximate gradients with noisy function measurements leads to convergence rate of o(t^-(1/3-ε)), compared to o(t^-λ) for λ arbitrarily close to 1 with noisy gradient measurements.
- Why unresolved: Paper does not provide detailed analysis of trade-offs between increased computational cost of using approximate gradients and slower convergence rate compared to noisy gradient measurements.
- What evidence would resolve it: Empirical studies or theoretical proofs comparing computational cost and convergence rates of SGD with approximate gradients and noisy function measurements versus noisy gradient measurements.

### Open Question 3
- Question: What are optimal choices for step size sequence and increment used to estimate gradient in zeroth-order methods to maximize convergence rate of SGD with noisy function measurements?
- Basis in paper: [explicit] Paper suggests optimal step size sequence is α_t = Θ(t^-(1-ε)) and optimal increment is c_t = Θ(t^-(1/3-ε)) to achieve convergence rate of o(t^-(1/3-ε)).
- Why unresolved: Paper does not provide rigorous proof or empirical evidence supporting these choices as optimal ones, and impact of different noise characteristics on these choices is not explored.
- What evidence would resolve it: Empirical studies or theoretical proofs demonstrating optimality of suggested step size and increment sequences, as well as their robustness to different noise characteristics.

## Limitations

- Extension to biased noise relies on summability conditions that may be difficult to verify in practice
- Rate estimates depend on specific choices of step sizes and decay rates requiring careful tuning
- Asynchronous update analysis assumes regularity conditions on update process that may not hold in all practical scenarios

## Confidence

- High confidence: Basic convergence results under KL' and PL conditions (Theorems 1-2)
- Medium confidence: Extension to biased noise with unbounded variance (Theorem 3)
- Medium confidence: Rate estimates under PL condition (Theorem 2)
- Medium confidence: Asynchronous update analysis (Theorems 5-6)
- Low confidence: Specific applications to invex functions and SGD without further validation

## Next Checks

1. Implement numerical experiments on synthetic invex functions to verify convergence rates predicted by Theorem 2, testing different values of φ near 0.5
2. Construct examples of biased noise processes satisfying (13)-(14) and verify that Theorem 3's convergence holds empirically
3. Design an asynchronous SGD implementation with realistic update processes and validate the rate estimates from Theorem 6 against synchronous baselines