---
ver: rpa2
title: 'Exposition on over-squashing problem on GNNs: Current Methods, Benchmarks
  and Challenges'
arxiv_id: '2311.07073'
source_url: https://arxiv.org/abs/2311.07073
tags:
- graph
- problem
- node
- rewiring
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The over-squashing (OSQ) problem is a critical issue in graph-based
  message-passing neural networks (MPNNs), where long-range dependencies between nodes
  are lost due to the compression of exponentially growing information into fixed-sized
  vectors. This paper provides a comprehensive exposition on OSQ, summarizing its
  formulations, current mitigation methods, and empirical strategies.
---

# Exposition on over-squashing problem on GNNs: Current Methods, Benchmarks and Challenges

## Quick Facts
- arXiv ID: 2311.07073
- Source URL: https://arxiv.org/abs/2311.07073
- Reference count: 40
- Primary result: Comprehensive exposition on over-squashing (OSQ) problem in GNNs, categorizing mitigation methods and highlighting research challenges

## Executive Summary
This paper provides a comprehensive exposition on the over-squashing problem in graph-based message-passing neural networks (MPNNs), where long-range dependencies are lost due to information compression. The authors categorize mitigation approaches into spatial rewiring, spectral rewiring, and implicit rewiring methods. The work also discusses the trade-off between OSQ and over-smoothing, highlights alignment between OSQ and MPNN expressive power, and reviews empirical strategies for verification. This serves as a foundational resource for understanding and addressing OSQ in MPNNs.

## Method Summary
The paper systematically reviews OSQ mitigation methods through three categories: spatial rewiring (adding edges based on local topological indicators like graph curvature), spectral rewiring (optimizing global graph properties like effective resistance), and implicit rewiring (using attention mechanisms or historical features). The authors also discuss OSQ quantification through Jacobian matrix norms and review benchmark datasets including synthetic graphs, classic citation networks, and long-range benchmarks. Computational complexity of different methods is analyzed, and open research questions are identified.

## Key Results
- OSQ problem arises from exponential information growth compressed into fixed-size node representations
- Three categories of OSQ mitigation methods identified: spatial, spectral, and implicit rewiring
- Trade-off exists between OSQ and over-smoothing problems in deep MPNNs
- Empirical validation strategies include synthetic benchmarks, classic datasets, and long-range tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Over-squashing arises from exponential growth of information compressed into fixed-size node representations
- Mechanism: As MPNNs propagate information through layers, receptive fields grow exponentially but hidden representations remain fixed-size, causing information loss
- Core assumption: OSQ is fundamentally a dimensionality compression issue
- Evidence anchors: Abstract and section 2.2 discussions on OSQ phenomenon; weak corpus evidence

### Mechanism 2
- Claim: OSQ can be quantified through sensitivity measures between node representations at different layers
- Mechanism: Spectral norm of Jacobian matrix between node representations and initial features provides OSQ score
- Core assumption: Jacobian-based OSQ score accurately captures information flow degradation
- Evidence anchors: Section 2.2 OSQ score definition; moderate corpus evidence on effective resistance

### Mechanism 3
- Claim: Rewiring strategies can mitigate OSQ by improving information flow
- Mechanism: Spatial rewiring adds edges based on local topology, spectral rewiring optimizes global properties, implicit rewiring uses attention mechanisms
- Core assumption: Improving graph connectivity addresses information compression problem
- Evidence anchors: Section 3 categorization of rewiring methods; strong corpus evidence

## Foundational Learning

- Concept: Graph Message Passing Neural Networks (MPNNs)
  - Why needed here: Understanding MPNN architecture is fundamental to grasping how information flows through graphs
  - Quick check question: How does the standard MPNN message passing formula work, and what are its key components?

- Concept: Graph Topology and Curvature
  - Why needed here: Different topological indicators are used to identify and quantify OSQ problems
  - Quick check question: What is the relationship between graph curvature measures and information flow efficiency in MPNNs?

- Concept: Spectral Graph Theory
  - Why needed here: Spectral properties are crucial for understanding global graph connectivity
  - Quick check question: How do spectral properties like the spectral gap relate to graph expansion and information propagation efficiency?

## Architecture Onboarding

- Component map: MPNN models -> Graph rewiring modules (spatial/spectral/implicit) -> Benchmark datasets -> OSQ evaluation metrics
- Critical path: Data → Graph Construction → MPNN Training → OSQ Measurement → Rewiring Application → Performance Evaluation
- Design tradeoffs: Spatial rewiring is computationally cheaper but may not address global connectivity; spectral rewiring is more comprehensive but computationally expensive; implicit rewiring avoids explicit graph modification but may require more complex model architectures
- Failure signatures: Poor performance on long-range tasks despite high accuracy on local tasks; inconsistent results across different graph structures; computational bottlenecks during rewiring operations
- First 3 experiments:
  1. Implement basic MPNN with synthetic dumbbell graph to observe OSQ effects
  2. Apply spatial rewiring using graph curvature and measure OSQ score improvement
  3. Compare different rewiring strategies on long-range benchmark datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we measure the over-squashing problem directly and numerically in practice?
- Basis in paper: The paper suggests using Jacobian of trained models but lacks established empirical measurement methods
- Why unresolved: No established method to directly measure and compare over-squashing levels among different strategies
- What evidence would resolve it: Developing and validating a numerical measure for OSQ that can be computed directly from trained models

### Open Question 2
- Question: What is the optimal number of layers for a graph neural network to minimize both over-squashing and over-smoothing?
- Basis in paper: Trade-off between over-squashing and over-smoothing, with layer count affecting both
- Why unresolved: Finding right balance is challenging and likely depends on specific graph topology and task
- What evidence would resolve it: Empirical studies systematically varying layer counts on different datasets and developing theoretical frameworks

### Open Question 3
- Question: How do spatial and spectral rewiring methods affect each other, and can they be combined effectively?
- Basis in paper: Discussion of trade-off between spatial and spectral methods in terms of locality preservation
- Why unresolved: Interaction between spatial and spectral properties is not well understood
- What evidence would resolve it: Empirical studies combining both methods and evaluating joint effects

## Limitations
- Jacobian-based quantification may not fully capture practical performance degradation across diverse graph structures
- Empirical validation primarily relies on synthetic benchmarks with limited real-world graph data testing
- Computational complexity analysis for rewiring methods is theoretical and may not reflect practical implementation challenges

## Confidence

- **High confidence**: The fundamental mechanism of OSQ as information compression in deep MPNNs (supported by multiple papers and theoretical foundations)
- **Medium confidence**: The effectiveness of rewiring strategies to mitigate OSQ (empirical evidence exists but with varying results)
- **Low confidence**: The precise quantification of OSQ through Jacobian matrix norms (limited practical validation and potential sensitivity to implementation details)

## Next Checks

1. **Empirical validation on real-world datasets**: Test OSQ quantification and mitigation methods on large-scale real-world graphs (e.g., social networks, molecular structures) beyond synthetic benchmarks to assess practical applicability.

2. **Comparative analysis of rewiring strategies**: Conduct controlled experiments comparing spatial, spectral, and implicit rewiring methods across diverse graph types, measuring both OSQ reduction and computational overhead.

3. **Robustness testing of OSQ quantification**: Evaluate the sensitivity of Jacobian-based OSQ scores to different initialization schemes, activation functions, and training dynamics to establish reliability across implementation variations.