---
ver: rpa2
title: 'SkillGPT: a RESTful API service for skill extraction and standardization using
  a Large Language Model'
arxiv_id: '2304.11060'
source_url: https://arxiv.org/abs/2304.11060
tags:
- skillgpt
- skill
- arxiv
- language
- esco
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SkillGPT is a RESTful API service for skill extraction and standardization
  from free-style job descriptions and user profiles using a Large Language Model
  (LLM) as backbone. It addresses limitations of previous methods that require supervision,
  heavy preprocessing, or rely on costly and slow conversational LLMs.
---

# SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model

## Quick Facts
- arXiv ID: 2304.11060
- Source URL: https://arxiv.org/abs/2304.11060
- Reference count: 17
- SkillGPT is a RESTful API service for skill extraction and standardization from free-style job descriptions and user profiles using a Large Language Model (LLM) as backbone

## Executive Summary
SkillGPT addresses the challenge of skill extraction and standardization (SES) from free-style job descriptions and user profiles using an open-source Large Language Model (LLM) as backbone. The system leverages Vicuna-13B for summarization and vector similarity search against precomputed ESCO embeddings to retrieve standardized skill codes. By avoiding direct LLM prompting of lengthy documents, SkillGPT balances speed with precision while maintaining cost-effectiveness for academic and prototype development.

## Method Summary
SkillGPT uses a step-by-step process with an LLM to extract and standardize skills from job descriptions and user profiles. The method involves summarizing input text using Vicuna-13B, then using the embedding of this summary as a query for vector similarity search against precomputed ESCO embeddings. This approach avoids the limitations of previous methods that require supervision, heavy preprocessing, or rely on costly and slow conversational LLMs. The system supports 18 use cases across 2 document types, 3 ESCO concept types, and 3 languages (English, French, Dutch).

## Key Results
- SkillGPT supports 18 use cases across 2 document types, 3 ESCO concept types, and 3 languages
- Uses Vicuna-13B LLM backbone, which is open-source and free for academic use
- Balances speed with precision by using summarization and vector similarity search instead of direct LLM prompting
- Provides multi-faceted and multi-lingual support for skill extraction and standardization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Summarization + vector similarity retrieval improves both speed and precision compared to direct LLM prompting of long documents
- Mechanism: First uses LLM to distill the input text into a concise skill summary, then embeds that summary and retrieves similar ESCO terms via vector similarity search instead of feeding entire document to LLM
- Core assumption: Vector similarity search against precomputed embeddings is much faster than direct LLM inference on large documents, and summarization reduces noise without losing relevant skills
- Evidence anchors:
  - [abstract] "SkillGPT utilizes a LLM to perform its tasks in steps via summarization and vector similarity search, to balance speed with precision"
  - [section] "Extracting free-style textual skills from a job description or user resume is achieved by carefully prompting the LLM for summarization. The embedding (via2) of the distilled text is used as a query to retrieve the top-k similar ESCO terms via vector similarity search3."
  - [corpus] No direct evidence; this mechanism is specific to SkillGPT and not mentioned in corpus neighbors
- Break condition: If summarization loses critical skill details, or if vector search fails to retrieve relevant ESCO terms due to embedding quality issues

### Mechanism 2
- Claim: Open-source LLM backbone (Vicuna-13B) enables cost-effective academic and prototype development while maintaining performance
- Mechanism: Uses Vicuna-13B, an open-source LLM based on Llama and fine-tuned with shareGPT data, instead of paid models like GPT-3 or ChatGPT
- Core assumption: Vicuna-13B has sufficient capacity for skill extraction and standardization tasks and can be deployed locally with minimal cost
- Evidence anchors:
  - [abstract] "The backbone LLM of SkillGPT is based on Llama, free for academic use and thus useful for exploratory research and prototype development"
  - [section] "Vicuna is based on Llama, reported to perform comparably to GPT-3, and fine-tuned using data from shareGPT for better alignment with human preferences. Our experiments showed that Vicuna-13B has sufficient capacity for SES."
  - [corpus] No direct evidence; this is specific to SkillGPT's choice of backbone model
- Break condition: If Vicuna-13B's performance degrades significantly for skill extraction tasks or if local deployment becomes impractical

### Mechanism 3
- Claim: Multi-faceted and multi-lingual support (2 document types × 3 ESCO concept types × 3 languages = 18 use cases) increases system utility
- Mechanism: System supports both job descriptions and user profiles, can extract different types of ESCO concepts (Skill/Occupation/Occupation group), and works in English, French, and Dutch
- Core assumption: Supporting multiple document types, concept types, and languages covers most real-world use cases for skill extraction and standardization
- Evidence anchors:
  - [section] "The current version SkillGPT supports 2 document types (job description/user resume), 3 ESCO concept types (Skill/Occupation/Occupation group) and 3 languages (En/Fr/Nl), yielding 18 possible use cases"
  - [section] "SkillGPT has more merits: it is multi-faceted as it can extract multiple ESCO concept types, and it offers multi-lingual support for English, French and Dutch"
  - [corpus] No direct evidence; this is specific to SkillGPT's supported use cases
- Break condition: If performance significantly degrades for non-English languages or if certain ESCO concept types prove less useful in practice

## Foundational Learning

- Concept: Large Language Model capabilities and limitations
  - Why needed here: Understanding what LLMs can and cannot do is crucial for designing effective skill extraction systems
  - Quick check question: What are the main limitations of using LLMs for skill extraction, and how does SkillGPT address them?

- Concept: Vector similarity search and embeddings
  - Why needed here: The system relies on vector similarity search against precomputed ESCO embeddings to retrieve standardized skill codes
  - Quick check question: How does vector similarity search work, and why is it faster than direct LLM inference on large documents?

- Concept: RESTful API design and deployment
  - Why needed here: SkillGPT is delivered as a RESTful API service, requiring understanding of API design principles and deployment considerations
  - Quick check question: What are the key components of a RESTful API, and how does SkillGPT structure its API endpoints?

## Architecture Onboarding

- Component map:
  API Gateway -> LLM Backbone (Vicuna-13B) -> Vector Database -> Vector Similarity Search -> Document Embedding Service -> GUI/Interface

- Critical path:
  1. User submits document through API or GUI
  2. API gateway routes request to LLM for summarization
  3. Summarized text is embedded using document embedding service
  4. Embedding is used as query for vector similarity search against ESCO database
  5. Top-k similar ESCO terms are retrieved and returned to user

- Design tradeoffs:
  - Speed vs. Precision: Summarization + vector search is faster but may lose some nuanced skills
  - Cost vs. Performance: Using open-source LLM reduces cost but may have slightly lower performance than paid models
  - Language Support: Supporting multiple languages increases utility but may reduce performance for non-English inputs

- Failure signatures:
  - Slow response times: Could indicate issues with vector database or LLM inference
  - Inaccurate skill extraction: May suggest problems with summarization quality or vector search relevance
  - High costs: If costs are unexpectedly high, it might indicate inefficient use of LLM resources

- First 3 experiments:
  1. Test the system with a simple English job description to verify basic functionality
  2. Try the same document in French and Dutch to test multi-language support
  3. Submit a complex user profile with multiple skill areas to evaluate handling of diverse input types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SkillGPT's performance vary across the 25 European Union languages not currently supported, and what is the minimum corpus size required for effective skill extraction in a new language?
- Basis in paper: [explicit] The paper mentions optimizing for smaller languages and supporting the full range of 25 EU languages as future work, implying current limitations.
- Why unresolved: The authors acknowledge performance differences between English and other languages (Dutch, French) due to training corpus volume distribution, but haven't tested or quantified performance across all EU languages or established minimum requirements.
- What evidence would resolve it: Comparative evaluation results showing SkillGPT's skill extraction accuracy, precision, and recall across all 25 EU languages, with analysis of corpus size requirements for each language.

### Open Question 2
- Question: What is the optimal balance between summarization granularity and skill extraction completeness in SkillGPT's current design?
- Basis in paper: [explicit] The paper states that treating summarized text as a single document might cause subtle skills to be lost since the synthesized embedding might be dominated by the most salient qualities.
- Why unresolved: The authors identify this as a limitation but haven't experimentally determined whether breaking the document into smaller chunks, using hierarchical summarization, or alternative approaches would better preserve subtle skills while maintaining efficiency.
- What evidence would resolve it: Ablation studies comparing skill extraction completeness and precision across different summarization strategies (single document vs. chunked documents vs. hierarchical summarization) with quantitative metrics.

### Open Question 3
- Question: How would fine-tuning the backbone LLM or advanced prompt engineering techniques improve SkillGPT's skill extraction accuracy and standardization quality?
- Basis in paper: [explicit] The authors state that many options for optimizing LLM performance, such as fine-tuning and prompt engineering, have not been properly examined due to time limitations and the rapidly evolving nature of LLM optimization techniques.
- Why unresolved: The paper acknowledges this optimization opportunity but hasn't explored specific fine-tuning approaches, prompt engineering strategies, or measured their impact on the key performance metrics.
- What evidence would resolve it: Controlled experiments comparing SkillGPT's baseline performance against versions with various fine-tuning approaches (domain-specific training, instruction tuning) and prompt engineering techniques (chain-of-thought prompting, few-shot examples), with quantitative improvements in accuracy and precision metrics.

## Limitations

- Accuracy dependent on LLM summarization quality and vector search effectiveness
- Limited to three languages (English, French, Dutch) with potential performance degradation for non-English inputs
- Speed improvements from vector search may come at cost of losing nuanced skills in summarization

## Confidence

### High Confidence Claims
- The step-by-step architecture combining LLM summarization with vector similarity search is technically sound and feasible
- Vicuna-13B provides sufficient capacity for the skill extraction and standardization tasks
- The RESTful API service architecture is implementable and deployable

### Medium Confidence Claims
- The speed improvements from using vector similarity search instead of direct LLM prompting on full documents
- The cost-effectiveness compared to commercial LLM solutions
- The multi-language support effectiveness across all 18 use cases

### Low Confidence Claims
- The actual precision and recall rates for skill extraction across different document types and languages
- The scalability of the system under high-volume production loads
- The long-term maintenance costs and performance degradation over time

## Next Checks

1. **Performance Benchmark**: Test the system's response time and accuracy across all 18 supported use cases (2 document types × 3 ESCO concept types × 3 languages) using a diverse test corpus of real job descriptions and user profiles.

2. **Cross-Language Consistency**: Evaluate the precision of skill extraction across English, French, and Dutch inputs to identify any language-specific performance degradation patterns.

3. **Cost Analysis**: Measure the actual operational costs under different load scenarios to verify the claimed cost-effectiveness compared to commercial alternatives, including both computation and maintenance expenses.