---
ver: rpa2
title: 'KGEx: Explaining Knowledge Graph Embeddings via Subgraph Sampling and Knowledge
  Distillation'
arxiv_id: '2310.01065'
source_url: https://arxiv.org/abs/2310.01065
tags:
- knowledge
- subgraph
- kgex
- triple
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: KGEx provides faithful post-hoc explanations for knowledge graph
  embedding predictions by training surrogate KGE models on sampled subgraphs of the
  target triple's neighborhood. The method uses predicate neighborhood or random walk
  sampling to extract relevant subgraphs, then applies knowledge distillation to train
  faithful surrogate models.
---

# KGEx: Explaining Knowledge Graph Embeddings via Subgraph Sampling and Knowledge Distillation

## Quick Facts
- arXiv ID: 2310.01065
- Source URL: https://arxiv.org/abs/2310.01065
- Reference count: 40
- Key outcome: KGEx achieves 50-99% fidelity to black-box KGE models across MRR, Hits@1, and Hits@10 metrics while providing interpretable explanations via subgraph sampling and knowledge distillation

## Executive Summary
KGEx addresses the critical challenge of explaining knowledge graph embedding predictions by training surrogate KGE models on sampled subgraphs of the target triple's neighborhood. The method combines predicate neighborhood or random walk sampling to extract relevant subgraphs with knowledge distillation to ensure faithful surrogate models. Monte Carlo sampling ranks influential training triples that contribute most to predictions. Experiments on WN18RR and FB15K-237 demonstrate that KGEx retains substantial performance of the original black-box models while providing interpretable explanations, with predicate neighborhood sampling consistently outperforming random walk approaches.

## Method Summary
KGEx explains individual link predictions by training surrogate KGE models on subgraphs sampled from the target triple's neighborhood. The method extracts subgraphs using either predicate neighborhood sampling (expanding to neighboring predicates up to a specified depth) or random walk sampling (exploring the graph through random walks). Each surrogate is trained using knowledge distillation from the original black-box KGE model, with a loss function that regularizes the student's embeddings to match the teacher's relational patterns. Multiple Monte Carlo runs train different surrogates on random subsets of the subgraph, and triples are ranked by their frequency in high-performing models. The approach maintains faithfulness by constraining surrogates to reproduce the black-box model's predictions while providing interpretable explanations through the ranked triples.

## Key Results
- Surrogate models retain 50-99% of original model performance across MRR, Hits@1, and Hits@10 metrics
- Predicate neighborhood sampling consistently outperforms random walk sampling for explanation quality
- Knowledge distillation significantly improves surrogate faithfulness compared to standalone models
- Monte Carlo sampling successfully identifies influential training triples that explain predictions

## Why This Works (Mechanism)

### Mechanism 1
Subgraph sampling creates a tractable search space while preserving prediction fidelity. By limiting training to a sampled subgraph that includes the target triple's 1-hop neighborhood plus relevant triples, the surrogate can learn representations approximating the original model's behavior. The core assumption is that most influential triples for explaining a prediction are concentrated within a limited neighborhood around the target.

### Mechanism 2
Knowledge distillation enforces faithfulness by constraining surrogate model representations. The RKD-KGE loss regularizes the student's embeddings by matching relational patterns learned by the teacher, ensuring the surrogate captures not just individual triple scores but the relational structure between entities. This preserves the reasoning process encoded in the black-box model.

### Mechanism 3
Monte Carlo sampling ranks triples by their influence on target predictions. By training multiple surrogates on different random subsets and observing which triples consistently appear in high-performing models, the method identifies the most influential training triples. The assumption is that frequently appearing triples in high-performing models are more influential for explaining the prediction.

## Foundational Learning

- Knowledge Graph Embeddings: Why needed - the entire method operates on KGE models and requires understanding how they represent and score triples. Quick check - What is the fundamental difference between distance-based KGE models like TransE and bilinear models like DistMult?

- Knowledge Distillation: Why needed - the method's faithfulness guarantee relies on transferring knowledge from the black-box teacher to the surrogate student. Quick check - How does relational knowledge distillation differ from standard KD in terms of what patterns it tries to match?

- Link Prediction Evaluation: Why needed - faithfulness evaluation compares surrogate and original model performance using standard metrics. Quick check - What is the difference between "filtered" and "unfiltered" metrics in link prediction evaluation?

## Architecture Onboarding

- Component map: Input (black-box model, target triple, KG) -> Sampling module (predicate neighborhood/random walk) -> Distillation module (train surrogates) -> Monte Carlo module (rank triples) -> Output (ranked explanations)

- Critical path: 1) Receive target triple and black-box model, 2) Sample subgraph H, 3) For each MC run: sample Hmc, train surrogate with KD, score triple, 4) Aggregate results to rank explanation triples, 5) Return ranked explanations

- Design tradeoffs: Sampling method (predicate neighborhood provides targeted sampling but may miss long-range dependencies; random walk captures broader context but may include irrelevant triples), subgraph size (larger improves fidelity but increases cost and reduces interpretability), MC runs (more improves stability but increases computation)

- Failure signatures: Low MRR scores indicate unfaithful surrogates, explanations that don't make logical sense suggest sampling missed relevant context, high MC variance indicates insufficient sampling

- First 3 experiments: 1) Run KGEx on single target triple with predicate neighborhood sampling (3 neighbors) and verify explanation triples are topically related, 2) Compare surrogate MRR with and without KD to verify regularization effect, 3) Vary MC runs (10, 50, 100) and measure stability of top-5 explanation triples

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of subgraph sampling method impact faithfulness for different types of knowledge graphs? The paper only tests two datasets without exploring how sampling method choice interacts with graph characteristics like density or relation diversity.

### Open Question 2
What is the optimal subgraph size for balancing faithfulness and computational efficiency across different graph sizes and KGE architectures? The paper observes larger subgraphs decrease performance but doesn't systematically determine optimal sizing.

### Open Question 3
How does knowledge distillation coefficient λ affect the trade-off between faithfulness and surrogate generalization across different KGE architectures? The paper finds performance stable across λ values but doesn't explore the balance between faithfulness and generalization.

## Limitations
- Computational overhead from Monte Carlo sampling requires training multiple surrogates per explanation
- Limited evaluation on only two datasets (WN18RR and FB15K-237) constrains generalizability claims
- Assumes 1-hop neighborhoods contain most explanatory information, which may not hold for complex reasoning chains

## Confidence
- High Confidence: Faithfulness evaluation methodology using established metrics with consistent improvements from KD
- Medium Confidence: Monte Carlo ranking mechanism is intuitive but relies on assumptions about influence measurement
- Low Confidence: Scalability claims lack systematic analysis of performance across graph sizes and computational costs

## Next Checks
1. Measure actual computation time for generating explanations on held-out test set, varying MC runs and subgraph sizes to establish practical limits
2. Apply KGEx to a third KGE model (e.g., RotatE) and knowledge graph from different domain (e.g., biomedical) to validate generalization
3. Have domain experts evaluate top-5 explanation triples for 20 target predictions to assess semantic meaningfulness and debugging utility