---
ver: rpa2
title: 'LMDrive: Closed-Loop End-to-End Driving with Large Language Models'
arxiv_id: '2312.07488'
source_url: https://arxiv.org/abs/2312.07488
tags:
- driving
- instructions
- instruction
- language
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LMDrive, the first language-guided closed-loop
  end-to-end autonomous driving framework that leverages large language models (LLMs)
  to process multi-modal sensor data and natural language instructions. The system
  processes camera and LiDAR inputs along with navigation and notice instructions
  to generate vehicle control signals in real-time.
---

# LMDrive: Closed-Loop End-to-End Driving with Large Language Models

## Quick Facts
- arXiv ID: 2312.07488
- Source URL: https://arxiv.org/abs/2312.07488
- Authors: Not specified
- Reference count: 40
- Key outcome: First language-guided closed-loop end-to-end autonomous driving framework using LLMs, achieving driving scores of 36.2 on LangAuto benchmark with LLaVA-v1.5 backbone.

## Executive Summary
LMDrive introduces a novel approach to autonomous driving by integrating large language models with multi-modal sensor data to process navigation and notice instructions in a closed-loop setting. The system processes camera and LiDAR inputs through a vision encoder and BEV decoder, then uses a pre-trained multi-modal LLM to generate control signals. A new LangAuto benchmark was created using CARLA simulator data to evaluate performance in closed-loop scenarios, addressing the gap in realistic evaluation methods for instruction-following driving systems.

## Method Summary
The LMDrive framework processes multi-view camera images and LiDAR point clouds through separate encoders, fuses them in a Bird's Eye View (BEV) decoder, and combines the resulting visual tokens with natural language instructions via a large language model. The system uses a two-stage training approach: first pre-training the vision encoder on perception tasks, then fine-tuning the entire system with LLaVA-v1.5 backbone and Q-Former for visual token reduction. The model generates control signals executed in the CARLA simulator, with performance evaluated using driving scores, route completion, and infraction metrics.

## Key Results
- LMDrive achieves driving scores of 36.2 on the main LangAuto benchmark and 50.6 on the shorter route version using LLaVA-v1.5 backbone.
- Incorporating notice instructions improves safety by enabling the model to handle adverse events and reduce collisions.
- The system maintains safety by appropriately rejecting misleading instructions that would violate traffic rules.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-modal sensor fusion with LLMs enables contextually aware control signals that adapt to both environmental conditions and human instructions.
- Mechanism: Camera and LiDAR data are processed through separate encoders, fused in a BEV decoder, and combined with language instructions via an LLM to produce control outputs.
- Core assumption: The LLM can effectively integrate visual tokens representing the environment with language tokens representing instructions to generate appropriate driving actions.
- Evidence anchors:
  - [abstract] "LMDrive uniquely processes and integrates multi-modal sensor data with natural language instructions"
  - [section 4.1] "we design a multi-view multi-modality vision encoder to encode/fuse the sensor data"
  - [corpus] "Weak - only 5 papers in corpus, none directly discussing this specific multi-modal fusion approach with LLMs"
- Break condition: The model fails when the LLM cannot properly interpret the visual tokens or when the sensor fusion does not capture critical environmental features needed for safe navigation.

### Mechanism 2
- Claim: Closed-loop evaluation provides a more realistic assessment of autonomous driving performance compared to open-loop methods.
- Mechanism: Actions are executed in the CARLA simulator, allowing assessment of cumulative errors, temporal consistency, and interaction with dynamic environments.
- Core assumption: Executing actions in a simulated environment provides meaningful feedback about real-world performance that cannot be captured through open-loop evaluation alone.
- Evidence anchors:
  - [abstract] "LMDrive achieves driving scores of 36.2 on the main benchmark and 50.6 on the shorter route version"
  - [section 1] "The absence of closed-loop evaluation leads to insufficient consideration of critical issues such as cumulative errors, human-robot interaction, and temporal consistency of actions"
  - [corpus] "Moderate - some papers discuss closed-loop evaluation but not specifically for this LLM-based approach"
- Break condition: The simulation environment does not accurately represent real-world dynamics, leading to overestimated performance that does not translate to real-world deployment.

### Mechanism 3
- Claim: Pre-trained multi-modal LLMs significantly improve instruction-following capabilities compared to LLMs trained only on language data.
- Mechanism: LLaVA-v1.5, pre-trained on both language and visual data, better understands and integrates visual tokens with natural language instructions.
- Core assumption: Pre-training on visual data enables the LLM to better interpret visual tokens and integrate them with language instructions for driving decisions.
- Evidence anchors:
  - [section 6.2] "LLaV A-v1.5 [24] surpasses the other LLM models, which demonstrates the importance of adopting pretrained multi-modal LLMs"
  - [abstract] "LMDrive achieves driving scores of 36.2 on the main benchmark and 50.6 on the shorter route version when using the LLaVA-v1.5 backbone"
  - [corpus] "Moderate - related papers discuss vision-language models but not specifically for autonomous driving with this architecture"
- Break condition: The visual pre-training does not generalize well to the specific sensor data or driving scenarios, leading to poor performance in novel situations.

## Foundational Learning

- Concept: Multi-modal sensor fusion
  - Why needed here: Autonomous driving requires integration of information from multiple sensors (cameras, LiDAR) to create a comprehensive understanding of the environment for safe navigation.
  - Quick check question: How does the BEV decoder combine information from multiple camera views and LiDAR data to create a unified representation?

- Concept: Natural language instruction processing
  - Why needed here: The system must interpret human language instructions (navigation and notice commands) and convert them into executable driving actions.
  - Quick check question: What role does the Q-Former play in reducing the number of visual tokens before they are processed by the LLM?

- Concept: Closed-loop vs open-loop evaluation
  - Why needed here: Closed-loop evaluation executes generated actions in the environment, allowing assessment of real-world performance including cumulative errors and temporal consistency.
  - Quick check question: What are the key differences between closed-loop and open-loop evaluation in autonomous driving, and why is closed-loop more realistic?

## Architecture Onboarding

- Component map: Sensor data → Vision Encoder → BEV Decoder → Q-Former → LLM → Adapters → Control Signals → CARLA Execution → Performance Metrics
- Critical path: Vision encoder processes camera and LiDAR inputs → BEV decoder fuses multi-modal data → Q-Former reduces visual tokens → LLM integrates visual and language tokens → Adapters generate control outputs
- Design tradeoffs:
  - Using a frozen pre-trained LLM vs fine-tuning the entire model: Freezing preserves reasoning capabilities but limits adaptation to driving-specific tasks
  - Number of Q-Former tokens (M=4): Balances computational efficiency with information retention
  - Temporal horizon (Tmax=40): Determines how much historical context is used for decision-making
- Failure signatures:
  - Poor performance on LangAuto-Notice benchmark: Indicates issues with processing notice instructions or handling adversarial events
  - Low infraction score: Suggests problems with traffic rule compliance or collision avoidance
  - High variance in driving scores across runs: May indicate instability in the model or insufficient training
- First 3 experiments:
  1. Replace the frozen LLM with a randomly initialized model to demonstrate the importance of pre-trained language understanding
  2. Remove the Q-Former to show the impact of token reduction on computational efficiency and performance
  3. Disable the BEV decoder to isolate the contribution of multi-modal sensor fusion to overall performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of the number of Q-Former tokens (M) affect the performance of LMDrive in closed-loop autonomous driving?
- Basis in paper: [explicit] The paper mentions that M=4 tokens achieve decent performance but does not explore the impact of different values.
- Why unresolved: The paper does not provide an ablation study on the number of Q-Former tokens, which could reveal the optimal configuration for balancing performance and computational efficiency.
- What evidence would resolve it: Conducting experiments with varying values of M and comparing the driving scores, route completion, and infraction scores would provide insights into the optimal number of Q-Former tokens.

### Open Question 2
- Question: How does the sample rate (fixed interval at which training frames are sampled) impact the performance of LMDrive in handling temporal consistency and cumulative errors?
- Basis in paper: [explicit] The paper mentions that a sample rate of 2 achieves a good trade-off but does not explore the impact of different sample rates on temporal consistency and cumulative errors.
- Why unresolved: The paper does not provide a detailed analysis of how different sample rates affect the model's ability to maintain temporal consistency and mitigate cumulative errors, which are critical for closed-loop driving.
- What evidence would resolve it: Conducting experiments with varying sample rates and analyzing the driving scores, route completion, and infraction scores would provide insights into the optimal sample rate for maintaining temporal consistency and minimizing cumulative errors.

### Open Question 3
- Question: How does the usage rate of notice instructions during training affect the model's ability to handle adverse events and reduce collisions in closed-loop autonomous driving?
- Basis in paper: [explicit] The paper mentions that removing 75% of notice instructions during training avoids overfitting but does not explore the impact of different usage rates on the model's ability to handle adverse events.
- Why unresolved: The paper does not provide a detailed analysis of how different usage rates of notice instructions affect the model's performance in handling adverse events and reducing collisions, which are critical for safe driving.
- What evidence would resolve it: Conducting experiments with varying usage rates of notice instructions and comparing the driving scores, route completion, and infraction scores would provide insights into the optimal usage rate for improving the model's ability to handle adverse events and reduce collisions.

## Limitations
- The evaluation is limited to the CARLA simulator, which cannot fully capture real-world driving complexity and unpredictability.
- The synthetic dataset of approximately 64K instruction-following clips may not represent the diversity of real-world scenarios, particularly rare but critical edge cases.
- The focus on structured, predefined routes with clear navigation instructions limits applicability to more open-world driving scenarios.

## Confidence

**High Confidence (Mechanism 1 - Multi-modal Sensor Fusion):** The paper provides detailed architectural descriptions and experimental results showing improved performance when using multi-modal sensor fusion with LLMs.

**Medium Confidence (Mechanism 2 - Closed-Loop Evaluation):** While the paper establishes a novel closed-loop benchmark (LangAuto) and demonstrates its implementation, the confidence is limited by the fact that this represents the first attempt at such evaluation for LLM-based driving systems.

**Medium Confidence (Mechanism 3 - Pre-trained Multi-modal LLMs):** The experimental results show LLaVA-v1.5 outperforming other LLM variants, but the comparison is limited to a small set of alternatives.

## Next Checks

1. **Cross-Simulator Validation:** Evaluate LMDrive's performance across multiple driving simulators (e.g., CARLA, GTA V-based platforms, and proprietary simulators) to assess robustness to different environmental dynamics and rendering engines.

2. **Real-World Deployment Testing:** Implement a limited real-world test of LMDrive in controlled environments (e.g., private test tracks or geofenced areas) to validate the translation of simulator performance to physical vehicles.

3. **Adversarial Instruction Robustness:** Design and execute systematic adversarial testing with a comprehensive suite of misleading instructions that span multiple safety violation categories, measuring the model's ability to reject these instructions and provide human-understandable explanations for its rejection decisions.