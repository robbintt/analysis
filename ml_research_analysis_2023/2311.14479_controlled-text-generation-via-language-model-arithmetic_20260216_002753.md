---
ver: rpa2
title: Controlled Text Generation via Language Model Arithmetic
arxiv_id: '2311.14479'
source_url: https://arxiv.org/abs/2311.14479
tags:
- arithmetic
- union
- language
- text
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce model arithmetic, a principled framework
  for composing and biasing large language models (LLMs) without model retraining
  or highly specific datasets. By minimizing a linear combination of weighted KL-divergences,
  model arithmetic enables precise control over multiple attributes in generated text.
---

# Controlled Text Generation via Language Model Arithmetic

## Quick Facts
- arXiv ID: 2311.14479
- Source URL: https://arxiv.org/abs/2311.14479
- Reference count: 40
- Key outcome: Achieves up to 64% reduction in toxicity scores through weighted KL-divergence optimization

## Executive Summary
This paper introduces model arithmetic, a principled framework for composing and biasing large language models without retraining or highly specific datasets. By minimizing a linear combination of weighted KL-divergences, the method enables precise control over multiple attributes in generated text. The authors demonstrate that this approach outperforms state-of-the-art toxicity reduction methods while also extending speculative sampling to enable efficient multi-model composition with only marginal overhead.

## Method Summary
Model arithmetic combines multiple pre-trained language models and classifiers by minimizing a weighted sum of KL-divergences between the output distribution and constituent models. The framework supports linear combinations of models, union operations for mutually exclusive attributes, and can incorporate classifier-guided distributions. The method operates by solving an optimization problem that produces token probabilities as a softmax over weighted log probabilities from input models. The authors extend speculative sampling to handle model arithmetic formulas by treating partial formulas as proposal models, significantly reducing inference time.

## Key Results
- Achieves up to 64% reduction in toxicity scores compared to baseline models
- Outperforms state-of-the-art toxicity reduction methods
- Extends speculative sampling to model arithmetic, reducing inference time with only marginal overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Minimizing weighted KL-divergences yields a distribution that smoothly interpolates between input models
- Mechanism: Solving the optimization problem produces token probabilities as a softmax over weighted sum of log probabilities from constituent models
- Core assumption: Functions fi(x, x1:k-1) must be independent of x for proper normalization
- Break condition: Optimization becomes undefined if sum of weights is zero or negative

### Mechanism 2
- Claim: Union operator combines mutually exclusive attributes by preserving high-probability tokens from either model
- Mechanism: Uses indicator functions to create non-linear combination where probability is maximum of log probabilities from two models
- Core assumption: Union operator can be expressed as KL-optimality problem with appropriate indicator functions
- Break condition: Cannot assign non-zero probability if both models assign zero probability

### Mechanism 3
- Claim: Speculative sampling can be extended to model arithmetic by treating partial formulas as proposal models
- Mechanism: Sequential application of speculative sampling to distributions produces sample from final distribution
- Core assumption: Sequential application of speculative sampling produces sample from final distribution
- Break condition: Low acceptance probability reduces efficiency gains

## Foundational Learning

- Concept: KL-divergence as similarity measure between probability distributions
  - Why needed: Core of model arithmetic is minimizing weighted KL-divergences
  - Quick check: What is relationship between KL-divergence and distributions P and Q?

- Concept: Autoregressive language modeling and token-by-token generation
  - Why needed: Model arithmetic operates on token-level probability distributions
  - Quick check: How does autoregressive language model generate text token-by-token?

- Concept: Speculative sampling for faster language model inference
  - Why needed: Extension to model arithmetic is crucial for efficient inference
  - Quick check: What is key insight behind speculative sampling for faster inference?

## Architecture Onboarding

- Component map: Input models -> Formula parser -> KL-optimality solver -> Speculative sampling engine -> Token sampler
- Critical path: Parse formula -> Compute output distribution -> Apply speculative sampling -> Sample tokens
- Design tradeoffs: Precision vs efficiency, flexibility vs simplicity, model diversity vs coherence
- Failure signatures: Low acceptance probability, degraded fluency, incorrect attribute control
- First 3 experiments: 1) Implement simple formula with two linear combinations, 2) Extend speculative sampling and measure efficiency, 3) Add union operator and test attribute combination

## Open Questions the Paper Calls Out

The paper explicitly discusses the potential for extending model arithmetic beyond the linear combinations and union operations presented. It mentions the possibility of additional compositional operations like intersection operators, though these are not explored in detail. The authors also note that model arithmetic could potentially be applied to a broader range of controlled text generation tasks beyond the toxicity reduction and sentiment control examples demonstrated.

## Limitations

- Speculative sampling extension lacks detailed implementation specifications and sensitivity analysis
- Toxicity reduction evaluation based on limited dataset without assessment of collateral effects on text quality
- Union operator's practical utility demonstrated but not rigorously analyzed for complex scenarios with multiple operations

## Confidence

- **High confidence**: Theoretical foundation of KL-optimality for model composition
- **Medium confidence**: Effectiveness of linear combination approach for attribute control
- **Low confidence**: Practical efficiency gains from speculative sampling extension

## Next Checks

1. Reproduce speculative sampling efficiency by implementing extended algorithm with different factors and measuring actual speedup
2. Cross-attribute generalization test by applying model arithmetic to combine attributes beyond toxicity (e.g., formality and creativity)
3. Coherence stress test by generating text using complex formulas with multiple union operators and evaluating fluency with both automated metrics and human evaluation