---
ver: rpa2
title: 'ClusterLLM: Large Language Models as a Guide for Text Clustering'
arxiv_id: '2305.14871'
source_url: https://arxiv.org/abs/2305.14871
tags:
- clustering
- cluster
- datasets
- granularity
- clusters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLUSTER LLM improves text clustering by guiding a small embedder
  with feedback from an instruction-tuned LLM. It uses triplet tasks to refine clustering
  perspective and pairwise tasks to determine granularity.
---

# ClusterLLM: Large Language Models as a Guide for Text Clustering
## Quick Facts
- arXiv ID: 2305.14871
- Source URL: https://arxiv.org/abs/2305.14871
- Reference count: 31
- Improves text clustering by guiding a small embedder with LLM feedback, achieving better clustering accuracy and granularity determination at an average cost of $0.6 per dataset

## Executive Summary
ClusterLLM introduces a framework that leverages large language models (LLMs) to guide text clustering through two key tasks: triplet ranking and pairwise comparison. The method uses entropy-based sampling to select informative instances for LLM querying, then fine-tunes small embedders based on LLM predictions to improve clustering quality. Additionally, it determines optimal cluster granularity by querying LLMs about pairwise relationships across hierarchical clustering levels. Evaluated on 14 diverse datasets, ClusterLLM consistently improves clustering accuracy while determining appropriate granularity at reasonable computational cost.

## Method Summary
ClusterLLM employs a two-stage framework that first improves clustering quality by prompting LLMs to rank triplet relationships between text instances, using these predictions to fine-tune small embedders through a triplet loss objective. Entropy-based sampling identifies the most informative instances for LLM querying. The second stage determines optimal cluster granularity by sampling pairs from hierarchical clustering steps and querying LLMs whether instances belong to the same category, then selecting the granularity level with highest consistency. The method uses pre-trained embedders (Instructor/E5) as starting points and applies both K-means and hierarchical clustering depending on the task.

## Key Results
- Improves clustering accuracy across 14 diverse datasets including intent discovery, domain discovery, information extraction, topic mining, and emotion detection
- Achieves consistent performance gains when using either Instructor or E5 pre-trained embedders
- Determines cluster granularity that aligns with ground truth at reasonable cost ($0.6 per dataset average)

## Why This Works (Mechanism)
- ClusterLLM improves clustering quality by refining the embedding space using LLM-predicted triplets, where LLM predictions on triplet ranking tasks are assumed to be more accurate than the base embedder's implicit distance judgments. If LLM predictions are noisy or biased, fine-tuning may degrade embedding quality.
- Entropy-based sampling selects the most informative triplets for LLM querying by identifying instances with high entropy in cluster assignment probabilities, assuming high-entropy instances provide the most useful signal for LLM refinement. If the base embedder is very poor, high-entropy instances may be outliers rather than informative.
- Pairwise task with hierarchical sampling determines cluster granularity matching user intent by querying LLM whether sampled pairs belong to the same cluster, assuming LLM's in-context understanding of category boundaries aligns with user-specified granularity. If LLM predictions are inconsistent or the hierarchy is poorly formed, granularity determination may fail.

## Foundational Learning
- Concept: Triplet ranking loss in metric learning - Why needed: The fine-tuning objective uses a softmax over similarity scores between anchor and candidates. Quick check: What is the role of the temperature parameter τ in the triplet loss equation?
- Concept: Entropy as a measure of uncertainty - Why needed: Used to identify instances whose cluster assignments are ambiguous and most likely to benefit from LLM input. Quick check: How does high entropy in cluster assignment probabilities indicate ambiguity?
- Concept: Hierarchical clustering and dendrogram analysis - Why needed: Provides candidate pairs at different granularity levels for LLM-based granularity selection. Quick check: Why does merging closest clusters at each step create a hierarchy of granularities?

## Architecture Onboarding
- Component map: Pre-trained embedder (Instructor/E5) → clustering (K-means/hierarchical) → entropy calculation → triplet sampling → LLM triplet querying → fine-tuning embedder → repeat → pairwise sampling from hierarchy → LLM pairwise querying → granularity selection
- Critical path: Embedder → clustering → triplet sampling → LLM → fine-tuning → clustering → pairwise sampling → LLM → granularity
- Design tradeoffs: Using LLM for guidance improves quality but increases cost; entropy sampling reduces queries but may miss some informative triplets. Fine-tuning embedder adds computational overhead but yields better clustering; hierarchical clustering is expensive for large datasets.
- Failure signatures: Clustering accuracy degrades after fine-tuning → LLM predictions are noisy. Granularity selection yields unreasonable number of clusters → LLM pairwise predictions are inconsistent. High API costs without quality gain → sampling strategy is ineffective.
- First 3 experiments: 1) Run baseline K-means on pre-trained embedder embeddings; record clustering accuracy. 2) Apply entropy-based triplet sampling and LLM querying (1024 triplets), then fine-tune embedder and re-cluster; compare accuracy. 3) Use pairwise hierarchical sampling to determine granularity; verify against ground truth number of clusters.

## Open Questions the Paper Calls Out
- How can CLUSTER LLM be adapted to handle privacy-sensitive data without relying on OpenAI APIs? The paper acknowledges that uploading privacy-sensitive data to LLMs accessed through OpenAI APIs can be risky, requiring efforts to remove sensitive information, but does not provide a solution.
- What is the impact of the sampling strategy on the computational cost of CLUSTER LLM, especially for large-scale datasets? While the paper states that the sampling strategy is cost-efficient using a fixed maximum number of triplets regardless of dataset size, it does not provide a detailed analysis of computational cost.
- How does the performance of CLUSTER LLM vary with the choice of pre-trained embedder? The paper only evaluates two specific pre-trained embedders (Instructor and E5), leaving the question of how other embedders would perform unanswered.

## Limitations
- Reliance on LLM predictions introduces uncertainty due to potential noise or bias in predictions, which could degrade embedding quality if the LLM is not well-calibrated
- The entropy-based sampling strategy assumes high-entropy instances are always the most informative, but this may not hold when the base embedder is particularly poor or when outliers dominate the high-entropy set
- The framework requires querying LLMs for a large number of instances, which can be computationally expensive and may raise privacy concerns for sensitive data

## Confidence
- **High Confidence**: The core claim that LLM-guided fine-tuning can improve clustering quality is supported by consistent accuracy improvements across 14 datasets and multiple embedding models (Instructor/E5). The cost estimate of $0.6 per dataset is reasonable given the 1024 triplet and 4000 pairwise queries specified.
- **Medium Confidence**: The assertion that entropy-based sampling effectively selects the most informative triplets is theoretically sound but lacks empirical validation showing that sampled triplets are indeed more informative than random selection.
- **Low Confidence**: The claim that pairwise LLM queries can reliably determine optimal cluster granularity across diverse datasets is the weakest, as the methodology does not address potential inconsistencies in LLM judgments about category boundaries across different domains and labeling conventions.

## Next Checks
1. **Ablation study on sampling strategy**: Compare clustering accuracy when using entropy-based triplet sampling versus random triplet sampling, and versus using all possible triplets. This would validate whether the entropy-based approach is truly more efficient or if it's simply reducing the total number of queries.

2. **Cross-dataset LLM consistency test**: Evaluate whether LLM pairwise predictions for granularity determination are consistent when applied to the same dataset by different annotators or at different time points. This would validate the reliability of the granularity determination mechanism.

3. **Cost-quality tradeoff analysis**: Systematically vary the number of triplet queries (e.g., 256, 512, 1024, 2048) and measure the marginal improvement in clustering accuracy versus the marginal cost increase. This would identify the optimal query budget for different dataset sizes and characteristics.