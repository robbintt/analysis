---
ver: rpa2
title: Active Learning for Multilingual Fingerspelling Corpora
arxiv_id: '2309.12443'
source_url: https://arxiv.org/abs/2309.12443
tags:
- uni00000003
- uni00000055
- uni00000057
- uni00000044
- uni00000051
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper applies active learning to multilingual fingerspelling
  corpora to address data scarcity in sign languages. The authors hypothesize that
  pre-training on linguistically related sign languages can improve learning efficiency.
---

# Active Learning for Multilingual Fingerspelling Corpora

## Quick Facts
- arXiv ID: 2309.12443
- Source URL: https://arxiv.org/abs/2309.12443
- Authors: 
- Reference count: 7
- Key outcome: Active learning with variation ratios outperforms random sampling, achieving near full-data-set performance with just 15% of the data in most cases.

## Executive Summary
This paper applies active learning to multilingual fingerspelling corpora to address data scarcity in sign languages. The authors hypothesize that pre-training on linguistically related sign languages can improve learning efficiency. They conduct experiments on American, Chinese, German, and Irish fingerspelling datasets, using variation ratios as the acquisition function. Results show active learning outperforms random sampling, achieving near full-data-set performance with just 15% of the data in most cases. Transfer learning experiments reveal modest gains, with the most significant improvement observed when pre-training on German and fine-tuning on Irish, likely due to visual similarities. The authors conclude that visual similarity may be more important than linguistic relationship for transfer active learning in this context.

## Method Summary
The authors apply active learning with variation ratios as the acquisition function to four fingerspelling corpora (ASL, CSL, GSL, ISL). They train a neural network with two convolutional layers and two fully-connected layers, starting with 2 samples per class and iteratively querying an oracle for labels. For transfer learning, they pre-train on one corpus and fine-tune on another using the same active learning procedure. Images are standardized to 28×28 pixels and balanced by resampling to match character distribution of corresponding written languages.

## Key Results
- Active learning with variation ratios consistently outperforms random sampling across all four languages
- Near full-data-set performance achieved with just 15% of labeled data in most cases
- Pre-training shows modest benefits, with the most significant improvement from German to Irish (GSL→ISL) due to visual similarities including forearm visibility

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-training on a linguistically related sign language corpus improves transfer learning performance for fingerspelling recognition.
- Mechanism: Transfer learning leverages shared linguistic and visual features between related sign languages to initialize the model with useful representations before fine-tuning on the target language.
- Core assumption: Related sign languages share hand configurations and visual patterns due to their common linguistic ancestry.
- Evidence anchors:
  - [abstract] "Since many sign languages are linguistic descendants of French sign language, they share hand configurations, which pre-training can hopefully exploit."
  - [section 4.2] "We use a ResNet-18 (He et al., 2016) as the backbone with the same structure as the previous experiment. We pre-train the classifier on the full data set from one corpus and then load the backbone of the pre-trained model with a re-initialized classification head."
- Break condition: If the pre-training corpus has significantly different visual characteristics or hand configurations compared to the target language, the transferred features may be less useful or even detrimental to performance.

### Mechanism 2
- Claim: Active learning with variation ratios as the acquisition function outperforms random sampling for fingerspelling recognition in low-resource sign languages.
- Mechanism: The model actively selects the most informative samples from the unlabeled pool by choosing instances where the model is least confident, leading to faster learning with fewer labeled examples.
- Core assumption: The variation ratio acquisition function effectively identifies samples that are most informative for improving the model's performance.
- Evidence anchors:
  - [section 3] "At time step t, a point from the pool set is selecting according to: x* = arg max [1 - max p(y|x, θt-1)]"
  - [section 4.1] "Using variation ratios (blue) as an acquisition function is clearly superior to random sampling (yellow)."
- Break condition: If the model's confidence scores are not reliable or the variation ratio does not correlate well with the actual informativeness of the samples, the active learning approach may not outperform random sampling.

### Mechanism 3
- Claim: Visual similarity between pre-training and target corpora can be more important than linguistic relatedness for transfer learning in fingerspelling recognition.
- Mechanism: When the visual characteristics of hand shapes and gestures are similar between languages, the model can more easily transfer learned features, even if the languages are not closely related linguistically.
- Core assumption: Visual similarity in hand configurations and gestures can be a stronger indicator of transferability than linguistic ancestry.
- Evidence anchors:
  - [abstract] "We do observe a benefit from pre-training, but this may be due to visual rather than linguistic similarities."
  - [section 4.2] "The only clear improvement over no pre-training is demonstrated for ISL pre-trained on GSL (subfigure d, blue line). As these are the only two data sets that include the signer's forearm, we suspect that visual similarly is causing the benefit rather than linguistic relationship."
- Break condition: If the visual features are not transferable or the pre-training corpus has significantly different visual characteristics, the visual similarity may not be sufficient for improved transfer learning.

## Foundational Learning

- Concept: Transfer learning
  - Why needed here: To leverage knowledge gained from related sign language corpora to improve learning efficiency in low-resource target languages.
  - Quick check question: What are the key components of a transfer learning approach, and how do they differ from traditional supervised learning?

- Concept: Active learning
  - Why needed here: To intelligently select the most informative samples from the unlabeled pool, reducing the number of labeled examples required to achieve good performance.
  - Quick check question: How does the variation ratio acquisition function work, and why is it suitable for this task?

- Concept: Fingerspelling recognition
  - Why needed here: Understanding the task and its challenges is crucial for designing effective models and evaluation strategies.
  - Quick check question: What are the key challenges in fingerspelling recognition, and how do they differ from general sign language recognition?

## Architecture Onboarding

- Component map:
  1. Data preprocessing: Standardize image resolution, balance class distribution, and convert to grayscale.
  2. Feature extraction: Use a convolutional neural network (CNN) backbone (e.g., ResNet-18) to learn visual features from the fingerspelling images.
  3. Classification head: Add a fully connected layer on top of the CNN backbone to predict the corresponding alphabetic character.
  4. Active learning loop: Implement the variation ratio acquisition function to select informative samples from the unlabeled pool and retrain the model iteratively.
  5. Transfer learning pipeline: Pre-train the model on a related sign language corpus and fine-tune on the target language.

- Critical path: The critical path for achieving good performance is to first pre-train the model on a related sign language corpus, then apply active learning with the variation ratio acquisition function on the target language.

- Design tradeoffs:
  - Resolution vs. computation: Higher resolution images may provide more detailed information but increase computational requirements.
  - Model complexity vs. data size: More complex models may require more data to avoid overfitting, especially in low-resource settings.
  - Acquisition function choice: Different acquisition functions may perform differently depending on the task and data characteristics.

- Failure signatures:
  - Poor performance on the target language: May indicate insufficient transfer learning or suboptimal active learning strategy.
  - Slow convergence: Could be due to the acquisition function not selecting informative samples or the model not learning effectively from the selected samples.
  - Overfitting: May occur if the model is too complex relative to the available data or if the active learning loop is not balanced properly.

- First 3 experiments:
  1. Single corpus active learning: Apply active learning with variation ratios on a single sign language corpus and compare against random sampling.
  2. Transfer active learning: Pre-train the model on a related sign language corpus and then apply active learning on the target language, comparing against no pre-training.
  3. Ablation study: Analyze the impact of different components (e.g., acquisition function, model architecture) on the performance of the active learning and transfer learning approach.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does visual similarity between fingerspelling datasets consistently lead to better transfer learning performance than linguistic relationships?
- Basis in paper: [explicit] The authors conclude that visual similarity may be more important than linguistic relationship for transfer active learning, noting that the GSL-ISL pairing showed the most improvement due to both datasets including the signer's forearm.
- Why unresolved: The authors only tested a limited number of dataset pairings (4 languages total) and found mixed results. The asymmetry in results (pre-training on ISL didn't improve GSL performance) suggests the relationship is complex.
- What evidence would resolve it: Systematic experiments varying both visual similarity (e.g., forearm presence, hand orientation) and linguistic relationship (e.g., French Sign Language descendants vs non-descendants) while controlling for other factors.

### Open Question 2
- Question: What is the optimal resolution for fingerspelling recognition models when balancing computational efficiency and performance?
- Basis in paper: [inferred] The authors conducted experiments at two resolutions (28×28 and 96×96) and noted that "computation time grows rapidly with the resolution," but didn't provide a comprehensive analysis of the trade-off.
- Why unresolved: The paper only tested two specific resolutions without exploring the full spectrum or providing guidance on when higher resolution becomes beneficial.
- What evidence would resolve it: Systematic experiments varying resolution across a wider range (e.g., 32×32 to 128×128) while measuring both performance and computational costs.

### Open Question 3
- Question: How does the performance of active learning compare to semi-supervised learning methods for low-resource sign language datasets?
- Basis in paper: [inferred] The paper focuses exclusively on active learning without comparing to other data-efficient approaches like semi-supervised learning or self-training.
- Why unresolved: The authors claim active learning "outperforms random sampling" but don't benchmark against alternative methods that could be more effective for extremely low-resource settings.
- What evidence would resolve it: Direct comparison experiments between active learning, semi-supervised learning, and self-training methods using the same fingerspelling datasets and computational constraints.

## Limitations
- Limited experimental scope to only four sign languages with relatively small dataset sizes
- Modest and inconsistent transfer learning benefits across language pairs
- Conclusion about visual similarity vs. linguistic relatedness based on a single notable case rather than systematic analysis

## Confidence
- High Confidence: Active learning with variation ratios outperforms random sampling (replicated across all four corpora)
- Medium Confidence: Transfer learning provides modest benefits, but the mechanism appears more visual than linguistic
- Low Confidence: Generalizability to other sign languages and fingerspelling recognition tasks beyond the tested languages

## Next Checks
1. **Visual Feature Analysis**: Conduct systematic comparison of hand configuration features across all language pairs to quantify visual similarity relationships and validate the visual similarity hypothesis
2. **Cross-Modality Transfer**: Test transfer learning from spoken language written characters (e.g., English alphabet) to fingerspelling recognition to isolate linguistic vs. visual transfer effects
3. **Acquisition Function Comparison**: Evaluate alternative acquisition functions (e.g., entropy, Bayesian active learning) to determine if variation ratios is optimal for this specific task