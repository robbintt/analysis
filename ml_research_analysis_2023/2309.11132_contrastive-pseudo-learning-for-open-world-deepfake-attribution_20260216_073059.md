---
ver: rpa2
title: Contrastive Pseudo Learning for Open-World DeepFake Attribution
arxiv_id: '2309.11132'
source_url: https://arxiv.org/abs/2309.11132
tags:
- uni00000013
- uni00000011
- learning
- novel
- uni00000048
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new benchmark called Open-World DeepFake
  Attribution (OW-DFA) for evaluating attribution performance against various types
  of fake faces in open-world scenarios. The authors propose a novel Contrastive Pseudo
  Learning (CPL) framework that addresses the challenges of OW-DFA through a Global-Local
  Voting module and a Confidence-based Soft Pseudo-labeling strategy.
---

# Contrastive Pseudo Learning for Open-World DeepFake Attribution

## Quick Facts
- arXiv ID: 2309.11132
- Source URL: https://arxiv.org/abs/2309.11132
- Authors: Multiple
- Reference count: 40
- Key outcome: Introduces CPL framework with Global-Local Voting and Confidence-based Soft Pseudo-labeling for open-world deepfake attribution, achieving state-of-the-art performance on the OW-DFA benchmark

## Executive Summary
This paper addresses the challenge of attributing deepfake faces to their source manipulation methods in open-world scenarios where training and test sets have different category distributions. The authors propose a novel Contrastive Pseudo Learning (CPL) framework that combines global and local feature matching with confidence-weighted pseudo-labeling to improve attribution accuracy. The method is validated on a new benchmark called Open-World DeepFake Attribution (OW-DFA) and demonstrates superior performance compared to existing approaches while providing better interpretability.

## Method Summary
The CPL framework addresses open-world deepfake attribution through a multi-stage paradigm: Stage 1 pre-trains on labeled known classes, Stage 2 applies CPL with Global-Local Voting (GLV) module and Confidence-based Soft Pseudo-labeling (CSP) strategy on both labeled and unlabeled data, and Stage 3 refines results using semi-supervised k-means clustering. The GLV module computes cosine similarities for both global features and local patches, using L2-norm-based spatial weighting to prioritize manipulated regions. The CSP strategy uses Gumbel-Softmax to generate probability distributions over classes and weights them by confidence scores to reduce pseudo-noise. The framework is evaluated on the OW-DFA benchmark using accuracy, NMI, and ARI metrics.

## Key Results
- CPL achieves state-of-the-art performance on the OW-DFA benchmark for open-world deepfake attribution
- The Global-Local Voting module improves attribution by combining global and local similarity matching with spatially enhanced weighting
- Confidence-based Soft Pseudo-labeling reduces pseudo-noise by weighting soft labels with prediction confidence scores
- Multi-stage paradigm with pre-training and iterative learning further enhances traceability performance

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Global-Local Voting module improves attribution by combining global and local similarity matching, with spatially enhanced weighting.
- **Mechanism**: The model extracts both global features and q x q local patches from forged faces, computes cosine similarities for both, and uses L2-norm-based spatially enhancing weights to prioritize manipulated regions. It then selects pairs based on consistency between top-1 global and local similarities.
- **Core assumption**: Manipulated regions have higher activation responses and can be weighted by L2-norms to improve similarity matching accuracy.
- **Evidence anchors**:
  - [abstract]: "introducing a Global-Local Voting module to guide the feature alignment of forged faces with different manipulated regions"
  - [section]: "we use L2-norm to reflect the response of local blocks...Combining with spatially enhancing weights, the local similarity sL(xi, xj) is obtained"
  - [corpus]: Weak - no direct evidence about L2-norm effectiveness for manipulated regions in this corpus
- **Break condition**: If manipulated regions do not consistently have higher activation, or if local similarity is less discriminative than global for certain forgery types.

### Mechanism 2
- **Claim**: Confidence-based Soft Pseudo-labeling reduces pseudo-noise by weighting soft labels with prediction confidence.
- **Mechanism**: Instead of using hard pseudo-labels from top-1 predictions, the method uses Gumbel-Softmax to generate probability distributions over all classes, then weights these by the confidence (probability of assigned class) to reduce impact of low-confidence assignments.
- **Core assumption**: Second and third predictions still have meaningful information and low-confidence predictions are more likely to be incorrect.
- **Evidence anchors**:
  - [abstract]: "designing a Confidence-based Soft Pseudo-label strategy to mitigate the pseudo-noise caused by similar methods in unlabeled set"
  - [section]: "we found that the second and the third predictions still have a high probability of being the correct class"
  - [corpus]: Weak - no direct evidence about pseudo-label weighting effectiveness in this corpus
- **Break condition**: If the correlation between confidence and correctness breaks down, or if Gumbel-Softmax introduces too much randomness.

### Mechanism 3
- **Claim**: Multi-stage paradigm with pre-training and iterative learning improves attribution by first learning known classes, then discovering novel classes, then refining with pseudo-labels.
- **Mechanism**: Stage 1 pre-trains on labeled data for known classes, Stage 2 applies CPL to discover novel classes, Stage 3 uses semi-supervised k-means to cluster and refine pseudo-labels through fine-tuning.
- **Core assumption**: Pre-training on known classes provides better initialization for semi-supervised learning on unlabeled data, and iterative refinement with clustering improves feature discriminability.
- **Evidence anchors**:
  - [abstract]: "extend the CPL framework with a multi-stage paradigm that leverages pre-train technique and iterative learning to further enhance traceability performance"
  - [section]: "previous studies [30, 62] have established the effectiveness of pre-training techniques and iterative learning"
  - [corpus]: Weak - no direct evidence about multi-stage paradigm effectiveness in this corpus
- **Break condition**: If pre-training causes overfitting to known classes or if iterative clustering converges to poor solutions.

## Foundational Learning

- **Concept**: Semi-supervised learning with contrastive learning
  - Why needed here: The task involves labeled known classes and unlabeled data containing both known and novel classes, requiring learning from limited labeled data
  - Quick check question: How does contrastive learning help group similar samples without labels?

- **Concept**: Feature extraction and similarity matching
  - Why needed here: Attribution requires comparing facial features across different manipulation methods to identify source models
  - Quick check question: Why might local features be more discriminative than global features for forgery detection?

- **Concept**: Pseudo-labeling with confidence weighting
  - Why needed here: Unlabeled data needs supervision, but incorrect pseudo-labels can harm learning; confidence weighting helps filter noise
  - Quick check question: What happens if you assign pseudo-labels without confidence weighting?

## Architecture Onboarding

- **Component map**: Feature extractor (ResNet-50) -> Global-Local Voting module -> Classifier -> Confidence-based Soft Pseudo-labeling -> Multi-stage training pipeline
- **Critical path**: Input image -> Feature extraction -> Global and local feature computation -> Similarity matching with spatial weighting -> Pair selection -> Contrastive loss + Pseudo-label loss -> Classifier update
- **Design tradeoffs**: Local patches (q x q) provide fine-grained manipulation detection but increase computational cost; confidence weighting reduces noise but may discard useful uncertain samples; multi-stage training improves performance but adds complexity
- **Failure signatures**: Poor known class performance indicates pre-training issues; low novel class accuracy suggests similarity matching problems; inconsistent pseudo-labels indicate confidence weighting issues
- **First 3 experiments**:
  1. Test Global-Local Voting with different patch sizes (3x3, 5x5, 7x7) to find optimal balance
  2. Compare hard vs soft pseudo-labeling with and without confidence weighting
  3. Validate pre-training effectiveness by comparing with random initialization on known classes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CPL scale when applied to other types of image manipulation tasks beyond deepfakes, such as medical image alterations or satellite image tampering?
- Basis in paper: [inferred] The paper demonstrates CPL's effectiveness on various deepfake manipulation types but does not explore its generalizability to other image domains.
- Why unresolved: The current study focuses specifically on facial deepfakes, leaving open whether the Global-Local Voting module and Confidence-based Soft Pseudo-labeling would be equally effective for different types of image manipulation.
- What evidence would resolve it: Experiments applying CPL to medical imaging datasets with different types of alterations (e.g., tumor insertion, organ modification) or satellite imagery with tampering, measuring attribution performance across these domains.

### Open Question 2
- Question: What is the computational overhead introduced by the Global-Local Voting module, and how does it compare to existing methods in terms of training time and inference speed?
- Basis in paper: [explicit] The paper introduces the GLV module but does not provide detailed computational complexity analysis or runtime comparisons with baseline methods.
- Why unresolved: While the paper demonstrates performance improvements, the trade-off between accuracy gains and computational cost is not quantified, which is critical for practical deployment.
- What evidence would resolve it: Benchmark experiments comparing training time, inference speed, and memory usage of CPL against baseline methods across different hardware configurations.

### Open Question 3
- Question: How sensitive is CPL's performance to the choice of patch size in the Global-Local Voting module, and what is the optimal patch size for different types of manipulation?
- Basis in paper: [explicit] The paper includes an ablation study on patch division but only tests three specific sizes (3×3, 5×5, 7×7) and does not explore a broader range of patch sizes or their relationship to specific manipulation types.
- Why unresolved: The paper shows that 3×3 patches work best among tested options, but the optimal patch size may vary depending on the manipulation type and could be task-specific.
- What evidence would resolve it: Systematic experiments testing a wider range of patch sizes (e.g., 2×2, 4×4, 6×6, 8×8) across different manipulation types, along with analysis of how patch size affects performance for specific forgery methods.

### Open Question 4
- Question: How does CPL perform when the unlabeled dataset contains a mix of real faces and deepfakes from unknown manipulation methods, and how does this affect the Confidence-based Soft Pseudo-labeling strategy?
- Basis in paper: [inferred] While Protocol-2 includes real faces, the paper does not specifically analyze how CPL handles unlabeled real faces mixed with unknown deepfake methods, nor does it examine how CSP adapts to this scenario.
- Why unresolved: The presence of real faces and unknown deepfakes in unlabeled data creates a more complex attribution scenario that may challenge the CSP mechanism's ability to distinguish between different types of unknowns.
- What evidence would resolve it: Experiments isolating performance on unlabeled real faces versus unknown deepfakes, with detailed analysis of how CSP confidence scores vary between these categories and how this affects overall attribution accuracy.

## Limitations
- The framework's effectiveness depends on the assumption that manipulated regions consistently have higher activation responses, which may not hold for all forgery types
- The computational overhead of the Global-Local Voting module is not quantified, limiting assessment of practical deployment feasibility
- The proposed methods are primarily validated on the newly introduced OW-DFA benchmark, which may not fully represent all real-world scenarios

## Confidence
- **High confidence**: The CPL framework's general architecture and multi-stage training paradigm are well-specified and follow established semi-supervised learning principles
- **Medium confidence**: The effectiveness of Global-Local Voting and Confidence-based Soft Pseudo-labeling strategies, as they depend on specific implementation details not fully described in the paper
- **Low confidence**: Claims about interpretability improvements and superiority over all baseline methods, as the paper doesn't provide detailed ablation studies or error analysis

## Next Checks
1. Implement ablation studies to isolate the contribution of each component (GLV, CSP, multi-stage training) on known vs novel class performance
2. Test the framework on additional open-world benchmarks beyond OW-DFA to assess generalization
3. Analyze failure cases to identify scenarios where the L2-norm weighting or confidence-based pseudo-labeling break down