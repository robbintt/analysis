---
ver: rpa2
title: 'GeoLLM: Extracting Geospatial Knowledge from Large Language Models'
arxiv_id: '2310.06213'
source_url: https://arxiv.org/abs/2310.06213
tags:
- knowledge
- https
- geospatial
- language
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GeoLLM, a method that extracts geospatial
  knowledge from large language models (LLMs) using auxiliary map data from OpenStreetMap.
  The authors demonstrate that while LLMs embed significant spatial information, naive
  querying using geographic coordinates alone is ineffective for predicting indicators
  like population density.
---

# GeoLLM: Extracting Geospatial Knowledge from Large Language Models

## Quick Facts
- arXiv ID: 2310.06213
- Source URL: https://arxiv.org/abs/2310.06213
- Authors: 
- Reference count: 15
- Key outcome: Demonstrates a 70% improvement in geospatial prediction performance (measured by Pearson's r²) by extracting knowledge from LLMs using map-augmented prompts

## Executive Summary
This paper introduces GeoLLM, a novel method that extracts geospatial knowledge from large language models (LLMs) by constructing prompts with auxiliary map data from OpenStreetMap. The authors demonstrate that while LLMs contain substantial spatial information in their weights, naive querying using geographic coordinates alone is ineffective for predicting key indicators like population density. GeoLLM overcomes this by incorporating reverse-geocoded addresses and nearby place information into prompts, achieving significant improvements over baseline methods. The approach shows particular success with GPT-3.5, which outperforms other models like Llama 2 and RoBERTa, suggesting that performance scales with model size and pretraining dataset.

## Method Summary
GeoLLM extracts geospatial knowledge from LLMs by constructing enhanced prompts that combine geographic coordinates with reverse-geocoded addresses and nearby place information from OpenStreetMap. The method fine-tunes LLMs (GPT-3.5, Llama 2, RoBERTa) on these prompts with classification targets scaled from 0.0-9.9, rather than using prompting alone. The approach transforms abstract coordinates into concrete geographic context that the model can process using its learned spatial relationships. The method is evaluated across multiple geospatial prediction tasks including population density, asset wealth, mean income, and women's education, showing substantial improvements over baselines using k-NN and XGBoost methods.

## Key Results
- 70% improvement in Pearson's r² compared to baseline methods for geospatial predictions
- GPT-3.5 outperforms Llama 2 by 19% and RoBERTa by 51% on geospatial tasks
- LLMs are sample-efficient, requiring only 10,000 training samples to achieve strong performance
- The approach is robust across different geographic regions globally
- GeoLLM provides a promising complement to existing geospatial covariates

## Why This Works (Mechanism)

### Mechanism 1
- Language models contain compressed geospatial knowledge from their training corpus, but naive geographic coordinate queries are ineffective because LLMs cannot map numeric coordinates to real-world locations.
- The model's weights encode spatial relationships learned from text descriptions of places, but these relationships are not directly accessible through raw coordinates.
- Core assumption: The training corpus contains sufficient textual descriptions of geographic locations that the model can learn spatial patterns from.
- Evidence: Abstract states "LLMs embed remarkable spatial information about locations, but naively querying LLMs using geographic coordinates alone is ineffective in predicting key indicators like population density."

### Mechanism 2
- Constructing prompts with reverse-geocoded addresses and nearby place information enables LLMs to access their embedded geospatial knowledge by providing the spatial context they need.
- The prompt construction transforms abstract coordinates into concrete geographic context that the model can process using its learned spatial relationships.
- Core assumption: The model's learned spatial knowledge is organized in a way that can be accessed through place-based contextual information rather than numeric coordinates.
- Evidence: Section 3.2 describes prompts consisting of address and nearby places components constructed using map data.

### Mechanism 3
- Fine-tuning LLMs on the constructed prompts with classification targets (0.0-9.9 scale) is more effective than prompting alone because it adapts the model's output layer to the specific prediction task while preserving the spatial knowledge in the weights.
- The fine-tuning process adjusts the model's final layers to map the activated spatial knowledge to specific prediction outputs, while the base spatial understanding remains in the frozen weights.
- Core assumption: The model's spatial knowledge can be preserved during fine-tuning while adapting the output layer for specific prediction tasks.
- Evidence: Section 3.3 reports that fine-tuning for 4 epochs with QLoRA and various regularization techniques works well.

## Foundational Learning

- **Geospatial data representation and coordinate systems**
  - Why needed here: Understanding how geographic coordinates map to real-world locations is fundamental to designing effective prompts and interpreting results.
  - Quick check question: How do latitude and longitude coordinates translate to specific addresses, and why might this translation be challenging for LLMs?

- **Language model architecture and knowledge compression**
  - Why needed here: Understanding how LLMs compress and organize knowledge from their training corpus is crucial for designing effective fine-tuning strategies and interpreting performance.
  - Quick check question: How do LLMs compress information from their training data, and what implications does this have for accessing specific types of knowledge like geospatial information?

- **Evaluation metrics for geospatial predictions**
  - Why needed here: Understanding metrics like Pearson's r² and their interpretation is essential for evaluating model performance and comparing with baselines.
  - Quick check question: What does Pearson's r² measure, and why is it an appropriate metric for evaluating geospatial prediction tasks?

## Architecture Onboarding

- **Component map**: OpenStreetMap (Nominatim for reverse-geocoding, Overpass API for nearby places) -> LLM models (GPT-3.5, Llama 2, RoBERTa) -> Prompt construction (Basic prompt, Enhanced prompt) -> Fine-tuning pipeline -> Inference on test data -> Evaluation with Pearson's r²
- **Critical path**: Prompt construction → LLM fine-tuning → Inference on test data → Evaluation
- **Design tradeoffs**: Using classification instead of regression for compatibility with LLM architectures vs. potential information loss; using OpenStreetMap vs. Google Maps for cost vs. quality; fine-tuning entire model vs. parameter-efficient methods like QLoRA.
- **Failure signatures**: Poor performance on specific geographic regions might indicate training data bias; inconsistent performance across sample sizes might indicate overfitting; large gaps between training and test performance might indicate insufficient fine-tuning.
- **First 3 experiments**:
  1. Test basic prompt with coordinates only on a small sample to confirm the baseline ineffectiveness.
  2. Test enhanced prompt with address and nearby places on the same sample to measure improvement.
  3. Compare different LLM models (GPT-3.5, Llama 2, RoBERTa) with the enhanced prompt on a small task to establish performance hierarchy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How much additional performance could be gained by incorporating additional spatial context like amenities, roads, or temporal data into the GeoLLM prompts?
- Basis in paper: The authors mention this as a potential extension, stating "Additional dimensions could extend the applicability of our method. For instance, one could augment prompts with names of amenities or roads to enrich the geospatial context and allow for even higher-resolution knowledge extraction."
- Why unresolved: The paper only tests prompts with basic address and nearby places data. The authors suggest but do not test incorporating more detailed spatial context.
- What evidence would resolve it: Conduct experiments testing GeoLLM performance with prompts including additional spatial context like amenities, roads, and temporal data, and compare results to the current approach.

### Open Question 2
- Question: How would GeoLLM performance compare to state-of-the-art satellite-based methods if trained on similar sample sizes?
- Basis in paper: The authors note that "LLMs not only match but also exceed the performance of methods that use satellite imagery" when evaluated on their benchmark tasks. However, they also note that satellite-based methods like Jean et al. (2016) achieved Pearson's r² of 0.56 when evaluated on Africa, while GeoLLM achieved 0.72 when evaluated on Africa with 10,000 training samples.
- Why unresolved: The paper does not directly compare GeoLLM to satellite-based methods trained on similar sample sizes. The 10,000 samples for GeoLLM is noted as "a fraction of the over 87,000 data points available from the DHS" used by some satellite methods.
- What evidence would resolve it: Train GeoLLM and a comparable satellite-based method on the same sample sizes and directly compare their performance on the same tasks.

### Open Question 3
- Question: How does GeoLLM's performance scale with model size beyond GPT-3.5, such as with GPT-4?
- Basis in paper: The authors state "Since LLMs are trained on internet data, they likely have biases similar to the ones present in this data. One could even potentially use our method to better understand the biases of LLMs and their training corpora." They also note that "GPT-4 would likely outperform GPT-3.5" based on the trend of performance scaling with model size.
- Why unresolved: The paper only tests GeoLLM with GPT-3.5, Llama 2, and RoBERTa. While they suggest GPT-4 would likely perform better, they do not test this.
- What evidence would resolve it: Test GeoLLM with larger models like GPT-4 and compare its performance to GPT-3.5 on the same tasks.

## Limitations

- The internal workings of GPT-3.5 are not publicly documented by OpenAI, making it difficult to fully understand why it outperforms other models by such a large margin
- The paper doesn't provide detailed analysis of how performance varies by region or socioeconomic context, despite noting that LLMs are "geographically biased"
- The strong correlation between LLM predictions and ground truth indicators doesn't necessarily imply that the model is using valid geospatial reasoning

## Confidence

**High Confidence**
- LLMs contain compressed geospatial knowledge from their training corpus
- Naive coordinate queries are ineffective for geospatial prediction
- Fine-tuning with map-augmented prompts improves performance
- GPT-3.5 outperforms smaller models on these tasks

**Medium Confidence**
- The 70% improvement in Pearson's r² represents meaningful real-world utility
- The approach is sample-efficient and robust across different geographic regions
- The method provides a viable complement to existing geospatial covariates

**Low Confidence**
- The specific mechanisms by which LLMs compress and organize geospatial knowledge
- The generalizability of results to other LLM architectures beyond those tested
- The long-term stability and reliability of LLM-based geospatial predictions

## Next Checks

1. **Geographic Bias Analysis**: Conduct detailed performance analysis across different world regions, focusing on areas with varying representation in the training corpus. Compare performance on North America/Europe vs. Africa/Asia to quantify geographic bias.

2. **Ablation Study on Prompt Components**: Systematically remove components from the enhanced prompt (address, nearby places, distance/direction information) to determine which elements contribute most to the performance improvement and whether all components are necessary.

3. **Temporal Stability Test**: Evaluate model performance on geospatial prediction tasks using data from different time periods (e.g., comparing predictions with 2020 vs. 2023 ground truth data) to assess whether the LLM's geospatial knowledge remains relevant over time or requires periodic fine-tuning.