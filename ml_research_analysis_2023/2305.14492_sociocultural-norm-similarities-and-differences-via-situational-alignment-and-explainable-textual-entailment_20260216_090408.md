---
ver: rpa2
title: Sociocultural Norm Similarities and Differences via Situational Alignment and
  Explainable Textual Entailment
arxiv_id: '2305.14492'
source_url: https://arxiv.org/abs/2305.14492
tags:
- social
- norms
- norm
- chinese
- cultures
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We propose a novel approach to discover and compare descriptive
  social norms across Chinese and American cultures. We leverage discussions on a
  Chinese Q&A platform (Zhihu) and the existing SocialChemistry dataset as proxies
  for contrasting cultural axes, align social situations cross-culturally, and extract
  social norms from texts using in-context learning.
---

# Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment

## Quick Facts
- arXiv ID: 2305.14492
- Source URL: https://arxiv.org/abs/2305.14492
- Authors: 
- Reference count: 40
- Key outcome: A novel approach to discover and compare descriptive social norms across Chinese and American cultures, building a high-quality dataset of 3,069 situation-aligned norms with explanations

## Executive Summary
This paper introduces a novel framework for discovering and comparing social norms across Chinese and American cultures through cross-cultural situational alignment and explainable textual entailment. The authors leverage discussions from Zhihu (Chinese Q&A platform) and the SocialChemistry dataset to create a dataset of 3,069 aligned social norms with free-text explanations. By using XLM-R for cross-lingual situation alignment, GPT-3 for norm extraction via in-context learning, and Chain-of-Thought prompting for entailment reasoning, the framework creates a human-AI collaborative pipeline. The paper also introduces the task of explainable social norm entailment and demonstrates that existing models under 3B parameters have significant room for improvement in this task.

## Method Summary
The method involves aligning social situations between Chinese and American contexts using XLM-R cross-lingual embeddings with cosine similarity, extracting social norms from free-form answers using GPT-3 with 2-shot prompting, and identifying cross-cultural norm similarities and differences using Chain-of-Thought prompting with human verification. The pipeline creates a dataset of 3,069 social norms aligned with situations across cultures, accompanied by explanations for norm entailment relationships.

## Key Results
- Created a high-quality dataset of 3,069 situation-aligned social norms with explanations across Chinese and American cultures
- Existing models under 3B parameters show significant room for improvement on the explainable social norm entailment task
- Empirical analysis reveals alignment with the social orientations framework, showing situational and descriptive nuances in norms across cultures
- The human-AI collaborative framework successfully generates coherent norm entailments and explanations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual semantic alignment via XLM-R enables accurate matching of culturally equivalent social situations
- Mechanism: XLM-R encodes social situations into cross-lingual embeddings, using cosine similarity to find most semantically similar Chinese Zhihu questions for each English Social-Chemistry situation
- Core assumption: Cross-lingual embeddings capture the same semantic space across English and Chinese
- Evidence anchors: [section] discusses cross-lingual representation alignment; [abstract] demonstrates approach using XLM-R for situation alignment
- Break condition: If semantic similarity falls below threshold or model fails to capture cultural nuances

### Mechanism 2
- Claim: Chain-of-Thought prompting with GPT-3 enables high-quality extraction of social norms from free-form answers
- Mechanism: 2-shot prompt provides examples of rules-of-thumb extracted from answers, allowing GPT-3 to generate novel rules-of-thumb from unseen answers
- Core assumption: GPT-3 can generalize from examples to extract relevant social norms
- Evidence anchors: [section] describes 2-shot prompt design and use with GPT-3; [abstract] mentions in-context learning for norm extraction
- Break condition: If GPT-3 fails to generate coherent rules-of-thumb or generates irrelevant norms

### Mechanism 3
- Claim: Human-AI collaboration framework improves quality and accuracy of final dataset
- Mechanism: GPT-3 with Chain-of-Thought prompting automatically generates most data, verified and edited by human annotators
- Core assumption: Human verification can catch errors and improve automatically generated data quality
- Evidence anchors: [section] describes annotator verification and editing process; [abstract] mentions high-quality dataset building through human-AI collaboration
- Break condition: If human annotators consistently disagree with model outputs or verification becomes impractical

## Foundational Learning

- Concept: Cross-cultural norm differences and their impact on communication
  - Why needed here: Understanding how social norms vary across cultures is crucial for creating systems that can reason across cultures
  - Quick check question: What are examples of cross-cultural norm differences that could lead to pragmatic failure in communication?

- Concept: Textual entailment and natural language inference
  - Why needed here: Identifying cross-cultural norm differences is framed as an explainable textual entailment task
  - Quick check question: How would you determine if two social norms are in entailment, contradiction, or no relation?

- Concept: Large language models and in-context learning
  - Why needed here: GPT-3 is used for norm extraction and inference relation identification using in-context learning
  - Quick check question: What is the difference between few-shot learning and fine-tuning in the context of large language models?

## Architecture Onboarding

- Component map: XLM-R for situation alignment -> GPT-3 with 2-shot prompting for norm extraction -> GPT-3 with Chain-of-Thought prompting for inference relation and explanation generation -> Human verification and editing
- Critical path: Situation alignment and norm extraction are most critical, as errors propagate to final dataset
- Design tradeoffs: GPT-3 allows flexible data generation but may introduce biases and errors requiring human correction
- Failure signatures: Low-quality norm extraction, incorrect inference relations, poor explanation quality, or misaligned situations
- First 3 experiments:
  1. Evaluate alignment accuracy by manually checking a sample of aligned pairs
  2. Assess norm extraction quality by comparing GPT-3 outputs to human annotations on a sample
  3. Test inference relation identification model performance on held-out test set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do cultural differences in social norms affect pragmatic communication failures in real-world interactions?
- Basis in paper: Explicit - discusses how deviance from social norms can cause perceptions of impoliteness and feelings of offense
- Why unresolved: Paper analyzes cultural norm differences but doesn't empirically test how these manifest in actual communication breakdowns
- What evidence would resolve it: Empirical studies measuring miscommunication rates in cross-cultural interactions correlating with specific norm differences

### Open Question 2
- Question: To what extent do intra-cultural variations in social norms contribute to norm disagreements compared to inter-cultural differences?
- Basis in paper: Inferred - acknowledges demographic groups have varying social norms but focuses on cultural-level differences
- Why unresolved: Analysis treats each culture as monolithic without examining demographic subgroup variations
- What evidence would resolve it: Comparative analysis of norm agreement rates within and between demographic subgroups across cultures

### Open Question 3
- Question: How do censorship and content moderation policies on platforms like Zhihu bias the representation of social norms in Chinese society?
- Basis in paper: Explicit - discusses how Chinese social media platforms are subject to content censorship
- Why unresolved: Paper acknowledges limitation but doesn't empirically assess extent of censorship effects
- What evidence would resolve it: Comparative analysis of norm representations across different Chinese platforms with varying censorship levels

## Limitations

- Medium confidence in cross-lingual situation alignment effectiveness due to lack of quantitative validation and unclear threshold justification
- Potential hallucination risks from GPT-3 for norm extraction and entailment reasoning, with limited specification of human correction rates
- Cultural proxy approach using Zhihu for Chinese norms and Social-Chemistry for American norms may not capture full spectrum of cultural norms

## Confidence

- High confidence: Overall framework design (human-AI collaboration for norm extraction and alignment) is methodologically sound
- Medium confidence: Effectiveness of cross-lingual situation alignment and quality of extracted norms
- Medium confidence: Empirical alignment with social orientations framework based on single comparison dataset

## Next Checks

1. **Alignment quality audit**: Randomly sample 50 aligned situation pairs and have bilingual annotators rate alignment quality on 3-point scale, calculating precision and recall
2. **Norm extraction accuracy**: Compare GPT-3 generated norms against human annotations on held-out set of 100 answers, measuring exact match rates
3. **Entailment model evaluation**: Test explainability and accuracy of final entailment model on blind test set of 200 norm pairs, measuring both automatic metrics and human evaluation of explanation quality