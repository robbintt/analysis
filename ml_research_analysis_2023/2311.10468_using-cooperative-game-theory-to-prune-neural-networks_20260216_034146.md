---
ver: rpa2
title: Using Cooperative Game Theory to Prune Neural Networks
arxiv_id: '2311.10468'
source_url: https://arxiv.org/abs/2311.10468
tags:
- neurons
- pruning
- network
- power
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Game Theory Assisted Pruning (GTAP), a novel
  method for reducing neural network size while maintaining predictive accuracy. The
  core idea is to model neurons as agents in a cooperative game, where the network's
  performance is the collective goal.
---

# Using Cooperative Game Theory to Prune Neural Networks

## Quick Facts
- arXiv ID: 2311.10468
- Source URL: https://arxiv.org/abs/2311.10468
- Reference count: 40
- One-line primary result: GTAP outperforms existing pruning techniques on image and NLP tasks, achieving better size-accuracy tradeoffs

## Executive Summary
This paper introduces Game Theory Assisted Pruning (GTAP), a novel method for reducing neural network size while maintaining predictive accuracy. The approach models neurons as agents in a cooperative game, using power indices like Shapley value and Banzhaf index to measure each neuron's relative impact on model accuracy. GTAP first estimates the optimal network size through an uncertainty quantification process similar to Dropout, then applies biased Banzhaf indices to rank and prune neurons. Empirical results demonstrate superior performance compared to existing pruning techniques on both image classification tasks (LeNet5, AlexNet) and natural language processing tasks.

## Method Summary
GTAP uses cooperative game theory to prune neural networks by modeling neurons as agents in a game where network accuracy is the collective goal. The method first estimates the optimal sub-network size using an uncertainty quantification process similar to Dropout, which measures prediction variance when randomly dropping neurons. Power indices (Shapley value, Banzhaf index, and biased Banzhaf index) are then computed to measure each neuron's marginal contribution to accuracy across many random sub-networks. Neurons are ranked by these indices and pruned either through Top-n selection or iterative pruning/building methods. The biased Banzhaf index incorporates a parameter d selected via uncertainty estimation to focus on coalitions near the critical size.

## Key Results
- GTAP outperforms existing pruning techniques on LeNet5 and AlexNet image classification tasks
- Iterated Building achieves 0.916 accuracy at critical network size on LeNet5, compared to 0.871 for Iterated Pruning
- Shapley-based pruning shows particularly strong results on NLP tasks
- The method achieves better trade-offs between network size and accuracy than magnitude or gradient-based pruning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Power indices measure a neuron's marginal contribution to network accuracy across many random sub-networks
- Mechanism: By averaging marginal contributions over sampled coalitions, GTAP estimates each neuron's true influence on predictive performance
- Core assumption: Random sampling of coalitions captures the relationship between neuron inclusion and accuracy well enough for pruning decisions
- Evidence anchors: Abstract mentions using Shapley value or Banzhaf index to measure relative impact; section describes estimating relative impact using cooperative game theory solutions
- Break condition: If marginal contribution estimates are too noisy due to small coalition samples, pruning decisions may misidentify important neurons

### Mechanism 2
- Claim: Uncertainty estimation via Dropout-like sampling identifies the optimal sub-network size for pruning
- Mechanism: By measuring prediction variance when randomly dropping neurons, GTAP finds the "critical network size" where uncertainty spikes
- Core assumption: The point of maximal uncertainty along the p=q diagonal corresponds to the natural size of the winning ticket sub-network
- Evidence anchors: Abstract describes uncertainty estimation process akin to Dropout; section explains characterizing network size where prediction certainty transitions to uncertainty
- Break condition: If the network exhibits high inherent variance unrelated to sub-network size, the critical size estimate may be inaccurate

### Mechanism 3
- Claim: Biased Banzhaf indices with parameter d improve pruning accuracy by focusing on coalitions near the critical size
- Mechanism: By sampling coalitions with probability d of including each neuron, GTAP better estimates importance for neurons likely to appear in the winning ticket
- Core assumption: Neurons important in sub-networks of size ~d are more likely to be critical for the full model's performance
- Evidence anchors: Abstract defines biased process Rd for building coalitions with probability d; section describes selecting solution from cooperative game theory using biased power index Î²d
- Break condition: If d is poorly estimated, biased sampling may over/under-represent important neurons, leading to suboptimal pruning

## Foundational Learning

- Concept: Cooperative game theory and power indices (Shapley value, Banzhaf index)
  - Why needed here: GTAP models neurons as agents in a cooperative game where network accuracy is the collective goal, requiring power indices to measure individual contributions
  - Quick check question: What is the key difference between Shapley value and Banzhaf index in how they average marginal contributions?

- Concept: Dropout and uncertainty quantification
  - Why needed here: GTAP uses a Dropout-like process to estimate model uncertainty when neurons are randomly removed, which guides the pruning target size
  - Quick check question: How does Monte Carlo Dropout provide an uncertainty estimate for neural network predictions?

- Concept: Neural network pruning fundamentals
  - Why needed here: Understanding pruning goals (reduce size while maintaining accuracy) and common approaches (magnitude, gradient-based) contextualizes GTAP's novel contribution
  - Quick check question: What is the main difference between structured and unstructured pruning?

## Architecture Onboarding

- Component map: Uncertainty estimation module (MCUE) -> Power index estimation module (PIE) -> Pruning decision module (Top-n, Iterated Pruning, Iterated Building) -> Model evaluation pipeline

- Critical path:
  1. Train full network
  2. Run MCUE to find critical network size d
  3. Estimate power indices using biased sampling with d
  4. Prune neurons based on power index rankings
  5. Evaluate pruned model accuracy

- Design tradeoffs:
  - Sampling size vs. power index accuracy
  - Computational cost of iterative vs. non-iterative pruning
  - Layer-wise vs. global neuron ranking

- Failure signatures:
  - High variance in power index estimates
  - Sub-network accuracy drops sharply below certain size
  - Uncertainty estimation fails to identify clear critical size

- First 3 experiments:
  1. Run MCUE on LeNet5 to visualize uncertainty bands and verify critical size around 0.225
  2. Compare GTAP pruning (biased Banzhaf) vs. magnitude pruning on LeNet5 at various target sizes
  3. Test Iterated Building vs. Iterated Pruning on LeNet5 to observe convergence behavior

## Open Questions the Paper Calls Out

- Question: Can the performance of GTAP be further improved by using alternative cooperative game solutions beyond power indices, such as the Core, Kernel, or Nucleolus?
- Question: How can GTAP be extended to larger and more complex neural network architectures, such as those used in large language models?
- Question: What is the optimal method for selecting the bias parameter d in the biased Banzhaf index, and how sensitive is the pruning performance to this choice?

## Limitations

- The computational complexity of power index estimation may limit scalability to very large networks like AlexNet
- The uncertainty estimation procedure's sensitivity to Dropout sampling parameters is not thoroughly explored
- Layer-wise vs. global pruning strategies are not systematically compared

## Confidence

- High confidence: The theoretical framework of applying Shapley/Banzhaf indices to measure neuron importance
- Medium confidence: The effectiveness of uncertainty estimation for determining pruning targets, based on LeNet5 results
- Medium confidence: The generalization of GTAP to NLP tasks, though results are promising

## Next Checks

1. Test GTAP on deeper architectures (VGG, ResNet) to assess scalability beyond AlexNet
2. Compare layer-wise vs. global pruning strategies under the GTAP framework
3. Perform ablation studies on the number of Monte Carlo samples needed for stable power index estimates