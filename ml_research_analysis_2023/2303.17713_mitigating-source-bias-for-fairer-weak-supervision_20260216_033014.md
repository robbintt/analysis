---
ver: rpa2
title: Mitigating Source Bias for Fairer Weak Supervision
arxiv_id: '2303.17713'
source_url: https://arxiv.org/abs/2303.17713
tags:
- group
- dataset
- accuracy
- optimal
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates fairness issues in weak supervision (WS),
  where pseudolabels are generated without ground truth labels. The authors observe
  that even when a fair classifier can be built from a dataset with ground-truth labels,
  the corresponding dataset labeled via weak supervision can be arbitrarily unfair.
---

# Mitigating Source Bias for Fairer Weak Supervision

## Quick Facts
- arXiv ID: 2303.17713
- Source URL: https://arxiv.org/abs/2303.17713
- Reference count: 40
- Key outcome: 32% accuracy improvement and 82.5% reduction in demographic parity gap

## Executive Summary
This paper addresses fairness issues in weak supervision (WS) where pseudolabels generated without ground truth labels can be arbitrarily unfair even when fair classifiers exist for the same data. The authors propose a model for source unfairness in WS and introduce a counterfactual fairness-based technique using optimal transport to mitigate these biases. Their approach transforms low-accuracy group data to match high-accuracy group distributions, theoretically showing that it can simultaneously improve both accuracy and fairness metrics—contrasting with standard fairness approaches that require accuracy-fairness trade-offs.

## Method Summary
The method involves identifying groups with different labeling function accuracies, then using optimal transport to find a minimal cost coupling between group distributions. The low-accuracy group's data is transformed to match the high-accuracy group, effectively "undoing" the transformations that cause accuracy disparities. This corrected data is then fed into a label model (Snorkel) to generate improved pseudolabels, which are used to train a downstream logistic regression model. The approach is called Source Bias Mitigation (SBM) and can be combined with other fair ML methods.

## Key Results
- SBM improves accuracy on weak supervision baselines by up to 32%
- SBM reduces demographic parity gap by 82.5%
- Simple extension of SBM produces state-of-the-art results in 5 out of 10 datasets in the WRENCH benchmark

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weak supervision can produce arbitrarily unfair outcomes even when the underlying dataset is perfectly fair
- Mechanism: Labeling functions can have accuracy that varies dramatically across groups due to transformations applied to data points. When these transformations move points far from an optimal center, accuracy degrades and fairness violations occur
- Core assumption: The labeling function accuracy model correctly captures how accuracy depends on distance from a center point, with transformations distorting group distributions
- Evidence anchors:
  - "even when a fair model can be built from a dataset with access to ground-truth labels, the corresponding dataset labeled via weak supervision can be arbitrarily unfair"
  - "As the feature vector x = gk(z) moves away from this center, the LF votes increasingly poorly"

### Mechanism 2
- Claim: Optimal transport can recover fair labeling function performance by reversing group transformations
- Mechanism: By finding a minimal cost coupling between the distributions of two groups using optimal transport, we can effectively "undo" the transformation and make labeling functions equally accurate across groups
- Core assumption: The transformation is invertible or at least can be approximated through optimal transport, and the cost function captures the true transformation between groups
- Evidence anchors:
  - "we propose and empirically validate a model for source unfairness in weak supervision, then introduce a simple counterfactual fairness-based technique that can mitigate these biases"
  - "We use OT to recover the reverse map hk : X → Z by finding a minimal cost coupling"

### Mechanism 3
- Claim: Our approach can simultaneously improve both accuracy and fairness metrics, unlike standard fairness approaches
- Mechanism: By making labeling functions more accurate across groups through the transport-based correction, the label model can produce better pseudolabels, leading to improved downstream accuracy while also reducing fairness gaps
- Core assumption: The label model properly weights the corrected labeling functions, and the downstream model can effectively learn from the improved pseudolabels
- Evidence anchors:
  - "Theoretically, we show that it is possible for our approach to simultaneously improve both accuracy and fairness metrics—in contrast to standard fairness approaches that suffer from tradeoffs"
  - "all of our discussion below holds when considering correlations as well"

## Foundational Learning

- Concept: Weak supervision and label models
  - Why needed here: Understanding how weak supervision works and how label models combine noisy labeling functions is crucial for understanding how SBM improves the input to the label model
  - Quick check question: What is the difference between a labeling function and a label model in weak supervision?

- Concept: Optimal transport theory
  - Why needed here: SBM relies on optimal transport to find the transformation that makes labeling functions equally accurate across groups
  - Quick check question: What is the objective of optimal transport when finding a coupling between two distributions?

- Concept: Fairness metrics (demographic parity and equal opportunity)
  - Why needed here: SBM aims to improve these specific fairness metrics, so understanding what they measure is important
  - Quick check question: How does demographic parity differ from equal opportunity in terms of what fairness they measure?

## Architecture Onboarding

- Component map: Data → Labeling functions → SBM (transport-based correction) → Label model → Pseudolabels → End model → Predictions
- Critical path: The transport-based correction in SBM must be applied before the label model, as it improves the input to the label model
- Design tradeoffs: Using optimal transport vs simpler nearest neighbor approaches for the correction step - OT is more accurate but computationally expensive
- Failure signatures: If the correction step does not improve labeling function accuracy across groups, or if the label model fails to properly weight the corrected labeling functions
- First 3 experiments:
  1. Apply SBM to a synthetic dataset with known group transformations and verify it recovers fair labeling function performance
  2. Apply SBM to a real dataset with known group attributes and verify it reduces demographic parity and equal opportunity gaps
  3. Apply SBM to a real dataset without group attributes, use slice discovery to find groups, and verify it still improves accuracy and fairness

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but several are implied:
1. How to extend the technique to handle more than two groups
2. The impact of different distance metrics in the optimal transport step
3. The effect on fairness metrics beyond demographic parity and equal opportunity

## Limitations

- The empirical validation relies heavily on WRENCH benchmark datasets, which may not capture all real-world weak supervision scenarios
- The optimal transport-based correction assumes that group transformations can be effectively modeled and reversed
- The approach may not generalize well to datasets where the labeling function accuracy does not depend on distance from a center point

## Confidence

**High confidence**: The theoretical framework showing that weak supervision can produce arbitrarily unfair outcomes even from fair ground-truth data

**Medium confidence**: The empirical results demonstrating 32% accuracy improvements and 82.5% reduction in demographic parity gap, as these depend on specific benchmark datasets and labeling function implementations

**Medium confidence**: The claim that SBM can simultaneously improve both accuracy and fairness, as this represents a departure from standard fairness-accuracy trade-offs that may not generalize across all settings

## Next Checks

1. Test SBM on datasets with known adversarial transformations to verify the optimal transport correction accurately recovers the inverse transformation
2. Evaluate SBM's performance when labeling functions have varying degrees of correlation and accuracy distributions across groups
3. Apply SBM to a real-world weak supervision scenario (e.g., medical imaging with expert-defined heuristics) to assess practical effectiveness beyond benchmark datasets