---
ver: rpa2
title: 'Causal Discovery and Prediction: Methods and Algorithms'
arxiv_id: '2309.09416'
source_url: https://arxiv.org/abs/2309.09416
tags:
- causal
- graphs
- hidden
- variables
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis addresses the challenge of discovering causal relationships
  in complex systems, particularly when hidden confounders are present. The author
  proposes a novel method that combines active learning with do-calculus to identify
  causal structures efficiently.
---

# Causal Discovery and Prediction: Methods and Algorithms

## Quick Facts
- arXiv ID: 2309.09416
- Source URL: https://arxiv.org/abs/2309.09416
- Reference count: 0
- Primary result: Novel method combines active learning with do-calculus to identify causal structures using minimal interventions

## Executive Summary
This thesis presents a novel approach to discovering causal relationships in complex systems with hidden confounders. The method uses single-valued interventions combined with do-calculus predictions to efficiently identify causal structures while minimizing real-world experimentation. The approach is theoretically sound and complete, requiring at most O(|G|) interventions where |G| is the number of candidate graphs. Additionally, the thesis extends causal reasoning to dynamic systems through dynamic causal networks, enabling prediction of causal effects over time.

## Method Summary
The core method combines active learning with do-calculus to identify causal structures. It uses a predictor component to compute expected causal effects from candidate graphs, a power-of-intervention metric to quantify distinguishability potential, and an intervention selector to choose the most informative interventions. The algorithm iteratively refines candidate graphs based on intervention results until the true causal structure is identified. For dynamic systems, the method extends to dynamic causal networks, applying do-calculus rules to identify causal effects across time while accounting for static and dynamic hidden confounders.

## Key Results
- Single-valued interventions suffice for causal discovery in most cases, avoiding exhaustive testing
- Active learning minimizes interventions needed while maximizing distinguishability
- Dynamic causal networks enable causal reasoning in time-series settings with do-calculus completeness
- Theoretical bounds show O(|G|) interventions required for graph identification

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Single-valued interventions suffice for causal discovery in most cases, avoiding the need to test all values of intervened variables.
- **Mechanism:** The algorithm uses do-calculus to predict the effects of all possible interventions a priori, systematically comparing these predictions across candidate graphs. This allows identification of the most discriminative interventions without needing to perform them all in the real world.
- **Core assumption:** Computational cost is negligible compared to real-world experimentation costs, and the true causal graph is included in the initial set of candidates.
- **Evidence anchors:**
  - [abstract]: "Our method for the discovery of causal relations introduces several novelties... we use interventions on a single value of the intervened variables."
  - [section]: "By using do-calculus as a tool to predict systematically and numerically the effect of all the interventions that are possible, without having to actually perform them..."
  - [corpus]: Weak - corpus neighbors don't directly discuss single-value interventions.
- **Break condition:** If the candidate graphs differ only in structures requiring conditional independence tests (hedges), single-valued interventions cannot distinguish them, necessitating more expensive tests.

### Mechanism 2
- **Claim:** Active learning minimizes the number of interventions needed to identify the true causal graph.
- **Mechanism:** The algorithm iteratively selects interventions that maximize distinguishability between remaining candidate graphs while minimizing intervention cost, using a power-of-intervention metric to quantify discriminative potential.
- **Core assumption:** Prior knowledge about causal relations can be represented as a set of candidate graphs, and the true graph is among them.
- **Evidence anchors:**
  - [abstract]: "Based on this a-priori assessment, we propose an active learning algorithm that identifies the causal relations in any given causal model, using a least cost sequence of interventions."
  - [section]: "Our method considers that the cost of intervening variables may differ for every variable, or combination of variables, and for every value assignment of the intervened variables."
  - [corpus]: Weak - corpus neighbors don't directly discuss active learning with cost minimization.
- **Break condition:** If multiple candidate graphs remain non-distinguishable after all interventions, additional conditional independence tests become necessary, increasing cost.

### Mechanism 3
- **Claim:** Dynamic Causal Networks extend causal reasoning to time-series settings while maintaining do-calculus completeness.
- **Mechanism:** The framework represents time-evolving causal systems as bi-infinite DAGs with time-sliced variables, applying do-calculus rules to identify causal effects across time while accounting for static and dynamic hidden confounders.
- **Core assumption:** The observation timescale is sufficiently small compared to system dynamics, and causal dependencies are stable across time.
- **Evidence anchors:**
  - [abstract]: "This thesis introduces a comprehensive causal reasoning method for models recurrent in time."
  - [section]: "The definition of Dynamic Causal Network... is an extension of Pearl's causal model definition, by specifying that the variables are sampled over time."
  - [corpus]: Weak - corpus neighbors don't directly discuss dynamic causal networks with do-calculus.
- **Break condition:** If dynamic hidden confounders create time-dependent transition matrices, the identification becomes more complex and may require additional computational steps.

## Foundational Learning

- **Concept:** Causal effect identifiability and do-calculus
  - **Why needed here:** The algorithm relies on determining whether P(Y|do(X)) can be computed from observational data using do-calculus rules, which is fundamental to both discovery and prediction.
  - **Quick check question:** If applying do-calculus rules transforms P(Y|do(X)) into an expression without do operators, what does this tell us about the identifiability of the causal effect?

- **Concept:** Hidden confounders and their impact on causal discovery
  - **Why needed here:** The thesis specifically addresses causal discovery in the presence of hidden confounders, which is more realistic than assuming causal sufficiency and affects the distinguishability conditions.
  - **Quick check question:** How does the presence of a hidden confounder between two observed variables affect the ability to distinguish causal graphs using single-valued interventions?

- **Concept:** Transition matrices and time-invariant vs. time-varying systems
  - **Why needed here:** The dynamic causal network analysis requires understanding how interventions affect transition matrices over time, particularly distinguishing between static and dynamic hidden confounders.
  - **Quick check question:** What is the key difference in how interventions affect transition matrices in systems with static versus dynamic hidden confounders?

## Architecture Onboarding

- **Component map:** Predictor -> PowerOfIntervention -> SelectIntervention -> Oracle -> SelectGraphs -> (repeat until convergence) -> idEdges/idHidden if needed

- **Critical path:** Predictor → PowerOfIntervention → SelectIntervention → Oracle → SelectGraphs → (repeat until convergence) → idEdges/idHidden if needed

- **Design tradeoffs:**
  - Computational complexity vs. real-world experimentation cost (favoring computation)
  - Single-valued vs. multi-valued interventions (favoring single-valued for cost efficiency)
  - Complete vs. partial causal graph identification (favoring complete when possible)

- **Failure signatures:**
  - No progress in reducing candidate graphs despite multiple interventions (suggests need for conditional independence tests)
  - High computational load during Predictor phase (suggests need for optimization)
  - Oracle responses don't match any predictions (suggests errors in model specification)

- **First 3 experiments:**
  1. Test the Predictor component on a simple 3-variable causal graph to verify do-calculus computations
  2. Implement PowerOfIntervention metric and validate it correctly identifies distinguishing interventions
  3. Run a complete discovery on a small synthetic dataset with known hidden confounders to verify the full algorithm pipeline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of interventions required to learn a causal graph with hidden confounders?
- Basis in paper: [explicit] The paper states that the number of interventions performed by the algorithm can be bounded by the number of causal model candidates, but does not provide a specific optimal bound.
- Why unresolved: The paper discusses the theoretical bounds for the number of interventions but does not provide empirical evidence or a specific optimal bound for the algorithm.
- What evidence would resolve it: Empirical studies comparing the algorithm's performance with different numbers of interventions on various causal models with hidden confounders.

### Open Question 2
- Question: How does the presence of dynamic hidden confounders affect the complexity of causal identification algorithms?
- Basis in paper: [explicit] The paper introduces dynamic hidden confounders and discusses their impact on the complexity of causal identification algorithms.
- Why unresolved: The paper provides a theoretical framework for understanding the impact of dynamic hidden confounders but does not offer empirical evidence or a detailed analysis of how they affect algorithm complexity.
- What evidence would resolve it: Empirical studies comparing the performance of causal identification algorithms on models with and without dynamic hidden confounders.

### Open Question 3
- Question: Can the ALCAM algorithm be generalized to handle a mix of observational and interventional data?
- Basis in paper: [inferred] The paper focuses on active learning using interventions but does not discuss the potential integration of observational data.
- Why unresolved: The paper does not address the potential benefits or challenges of incorporating observational data into the ALCAM algorithm.
- What evidence would resolve it: Studies demonstrating the performance of the ALCAM algorithm when applied to datasets containing both observational and interventional data.

## Limitations

- Computational tractability may become prohibitive for large candidate graph sets
- Method assumes true causal graph is included in initial candidate set
- Reliance on do-calculus predictions assumes accurate probabilistic models
- Sensitivity to model misspecification and sampling errors in practice

## Confidence

- **High**: Theoretical guarantees of algorithm completeness and intervention complexity
- **Medium**: Practical implementation details and empirical performance claims
- **Medium**: Applicability to real-world scenarios with model uncertainty

## Next Checks

1. Implement the ALCAM algorithm on synthetic datasets with known hidden confounders and measure actual intervention counts versus theoretical O(|G|) bound
2. Test algorithm robustness to probabilistic model misspecification by adding noise to transition matrices and measuring identification accuracy
3. Benchmark computational performance on progressively larger candidate graph sets to identify scalability thresholds