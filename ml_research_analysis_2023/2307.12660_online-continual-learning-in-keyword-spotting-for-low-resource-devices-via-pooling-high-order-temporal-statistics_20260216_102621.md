---
ver: rpa2
title: Online Continual Learning in Keyword Spotting for Low-Resource Devices via
  Pooling High-Order Temporal Statistics
arxiv_id: '2307.12660'
source_url: https://arxiv.org/abs/2307.12660
tags:
- class
- learning
- pooling
- feature
- slda
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of online continual learning (OCL)
  for keyword spotting (KWS) on embedded devices with limited computational and storage
  resources. The proposed method, Temporal Aware Pooling (TAP)-Streaming Linear Discriminant
  Analysis (SLDA), uses a pre-trained speech recognition backbone to extract features,
  which are then pooled using TAP.
---

# Online Continual Learning in Keyword Spotting for Low-Resource Devices via Pooling High-Order Temporal Statistics

## Quick Facts
- arXiv ID: 2307.12660
- Source URL: https://arxiv.org/abs/2307.12660
- Reference count: 0
- One-line primary result: TAP-SLDA achieves 11.3% relative average gain over competitors on Google Speech Commands dataset

## Executive Summary
This paper addresses online continual learning (OCL) for keyword spotting (KWS) on embedded devices with limited computational and storage resources. The proposed method, Temporal Aware Pooling (TAP)-Streaming Linear Discriminant Analysis (SLDA), uses a pre-trained speech recognition backbone to extract features, which are then pooled using TAP. TAP computes and concatenates the first five statistical moments of the speech features to capture rich temporal statistics. These enriched features are then used by SLDA, which updates a Gaussian model for each class with a shared covariance matrix. The method is evaluated on the Google Speech Commands (GSC) dataset and Multilingual Spoken Words Corpus (MSWC) across multiple backbone architectures. TAP-SLDA achieves state-of-the-art results, outperforming other OCL methods with a relative average gain of 11.3% on the GSC dataset.

## Method Summary
TAP-SLDA extracts speech features using a frozen pre-trained backbone (e.g., Wav2Vec2, HuBERT, Emformer), pools them using TAP to compute the first five statistical moments, and applies SLDA with a shared covariance matrix for online classification. The method processes single samples in an online fashion without storing past data, making it suitable for embedded devices. SLDA maintains running mean vectors and updates a shared covariance matrix recursively. The approach is evaluated on class-incremental tasks with both class-incremental and random data orderings.

## Key Results
- TAP-SLDA achieves 11.3% relative average gain over competitors on Google Speech Commands dataset
- Strong performance across multiple backbone architectures (Wav2Vec2, HuBERT, Emformer)
- Robust results across 5 languages in Multilingual Spoken Words Corpus
- Outperforms baseline methods in both class-incremental and random data ordering scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temporal Aware Pooling (TAP) captures richer temporal dynamics than simple average pooling by computing and concatenating higher-order statistical moments of the speech features.
- Mechanism: TAP computes the first five statistical moments (mean, variance, skewness, kurtosis, and 5th moment) of the feature vectors output by the frozen backbone. These moments encode information about the evolution of phonetic sounds within each word, providing a richer representation than just averaging over time.
- Core assumption: The distribution of higher-order moments differs more between classes than the first moment alone, making them more discriminative for keyword spotting.
- Evidence anchors:
  - [abstract]: "TAP computes and concatenates the first five statistical moments of the speech features to capture rich temporal statistics."
  - [section]: "To perform pooling P (·), we propose a Temporal Aware Pooling (TAP) which computes and concatenates the firstR statistical moments from the output of G(·)."
  - [corpus]: Weak evidence. The corpus includes related work on KWS and pooling, but no direct mention of high-order moment pooling or TAP.

### Mechanism 2
- Claim: Streaming Linear Discriminant Analysis (SLDA) with a shared covariance matrix effectively models class representations in the enriched feature space, enabling efficient online learning on embedded devices.
- Mechanism: SLDA maintains a running mean feature vector (prototype) for each class and a single shared covariance matrix updated online. This allows the classifier to model the relationships between the temporal statistics of different words, aiding in recognizing new unseen words.
- Core assumption: Features of different classes have similar distributions of first moments, while higher moments capture the differences between classes. A shared covariance matrix can capture common relationships between temporal statistics across classes.
- Evidence anchors:
  - [abstract]: "Our method, TAP-SLDA, updates a Gaussian model for each class on the enriched feature space to effectively use audio representations."
  - [section]: "TAP-SLDA shows strong Acc gains on every backbone, improving on average by relative 37.8% compared to SLDA (76.7% vs. 85.5%)."
  - [corpus]: Weak evidence. The corpus includes related work on SLDA, but no direct mention of using SLDA with TAP or on embedded devices.

### Mechanism 3
- Claim: The combination of TAP and SLDA enables effective online continual learning for keyword spotting on low-resource devices without storing samples or updating the large backbone model.
- Mechanism: TAP extracts rich temporal statistics from the frozen backbone features, and SLDA models class representations in this enriched space with minimal computational overhead. This allows the model to adapt to new keywords online without forgetting previous ones, while complying with the constraints of embedded devices.
- Core assumption: The frozen backbone provides sufficiently discriminative features for keyword spotting, and the online updates to SLDA are sufficient to adapt to new keywords without storing past samples.
- Evidence anchors:
  - [abstract]: "Keyword Spotting (KWS) models on embedded devices should adapt fast to new user-defined words without forgetting previous ones... Our method, TAP-SLDA, updates a Gaussian model for each class on the enriched feature space to effectively use audio representations."
  - [section]: "Our method (TAP-SLDA) employs a new statistical pooling to extract enriched temporal information from speech features extracted by a pre-trained backbone. Our method, TAP-SLDA, updates a Gaussian model for each class on the enriched feature space to effectively use audio representations."
  - [corpus]: Weak evidence. The corpus includes related work on online continual learning and keyword spotting, but no direct mention of the specific combination of TAP and SLDA or its effectiveness on embedded devices.

## Foundational Learning

- Concept: Online Continual Learning (OCL)
  - Why needed here: KWS models on embedded devices need to adapt to new user-defined words without forgetting previous ones, and without storing past samples due to memory constraints.
  - Quick check question: What is the key challenge in OCL that this paper addresses?

- Concept: Statistical Moments and Their Discriminative Power
  - Why needed here: TAP relies on computing and concatenating higher-order statistical moments to capture rich temporal dynamics. Understanding why higher moments are more discriminative than lower ones is crucial.
  - Quick check question: How do the distributions of higher-order moments differ between classes compared to the first moment?

- Concept: Gaussian Discriminant Analysis and Covariance Matrices
  - Why needed here: SLDA models class representations as Gaussian distributions with a shared covariance matrix. Understanding how this works and why a shared matrix is effective is important.
  - Quick check question: Why does SLDA use a shared covariance matrix instead of a separate one for each class?

## Architecture Onboarding

- Component map:
  - Audio → Frozen Backbone → TAP → SLDA → Prediction

- Critical path:
  - Audio → Backbone → TAP → SLDA → Prediction
  - The backbone is frozen and not updated. Only the SLDA parameters are updated online with each new sample.

- Design tradeoffs:
  - Using a frozen backbone reduces computational overhead but relies on the backbone's features being sufficiently discriminative.
  - TAP increases the feature dimensionality, which may increase computational cost, but provides richer temporal information.
  - SLDA with a shared covariance matrix is memory-efficient but assumes that the feature distributions across classes have similar covariances.

- Failure signatures:
  - If the model's accuracy plateaus or degrades over time, it may indicate forgetting of previous classes or insufficient adaptation to new ones.
  - If the model's performance is highly sensitive to the order of classes, it may indicate instability in the online updates.
  - If the model's performance is significantly worse on certain classes, it may indicate that those classes are not well-represented by the higher-order moments.

- First 3 experiments:
  1. Verify that TAP improves performance over simple average pooling by running SLDA with both pooling methods on a small subset of the GSC dataset.
  2. Test the online learning capability by training SLDA incrementally on a sequence of classes and measuring accuracy and forgetting on held-out data.
  3. Evaluate the memory and computational efficiency of SLDA compared to other online classifiers (e.g., NCM, SOvR) on a resource-constrained device or simulation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of TAP-SLDA change when applied to longer audio clips beyond single keywords, and what modifications might be necessary to maintain effectiveness?
- Basis in paper: [inferred] The paper focuses on keyword spotting with short audio clips, but does not explore longer audio sequences or continuous speech.
- Why unresolved: The method was specifically designed and tested for short keyword spotting tasks, and its effectiveness for longer audio sequences remains unexplored.
- What evidence would resolve it: Experimental results comparing TAP-SLDA's performance on datasets with longer audio clips or continuous speech would clarify its effectiveness in these scenarios.

### Open Question 2
- Question: Can the TAP-SLDA method be effectively adapted for real-time applications on resource-constrained devices, and what trade-offs in accuracy or computational requirements might arise?
- Basis in paper: [explicit] The paper mentions the method's suitability for embedded devices with limited resources, but does not provide a detailed analysis of real-time performance or trade-offs.
- Why unresolved: While the method is designed for low-resource devices, its real-time performance and any necessary trade-offs are not explored.
- What evidence would resolve it: Implementation and testing of TAP-SLDA on actual embedded devices with real-time constraints, along with a detailed analysis of accuracy and computational requirements, would provide insights into its real-world applicability.

### Open Question 3
- Question: How does the choice of the number of statistical moments (R) in TAP affect the performance of the model across different languages and audio conditions, and is there an optimal value for R?
- Basis in paper: [explicit] The paper uses R=5 moments and mentions that R=5 always brings the highest accuracy, but does not explore the impact of varying R across different languages or audio conditions.
- Why unresolved: The optimal value of R may vary depending on the language and audio conditions, and its impact on performance across different scenarios is not fully explored.
- What evidence would resolve it: Systematic experiments varying R across different languages and audio conditions, along with an analysis of performance trends, would help determine the optimal value of R for various scenarios.

## Limitations

- The paper lacks ablation studies isolating the contribution of each moment order in TAP
- Evaluation focuses on accuracy without adequately addressing latency or memory usage on actual embedded devices
- Online learning setup assumes perfect class ordering knowledge, which may not reflect realistic deployment scenarios

## Confidence

**High confidence**: The SLDA implementation and its shared covariance matrix approach are well-established techniques. The superiority of TAP-SLDA over baseline methods (11.3% relative gain) is supported by experiments across multiple datasets and backbone architectures.

**Medium confidence**: The claim that TAP captures richer temporal dynamics is plausible but under-supported. The paper demonstrates improved performance but doesn't directly validate that the higher-order moments are the causal mechanism for this improvement.

**Low confidence**: The robustness claims across languages are based on only five languages in MSWC, with no analysis of language-specific challenges or performance degradation patterns.

## Next Checks

1. Conduct ablation studies removing individual higher-order moments (3rd, 4th, 5th) to quantify their marginal contribution and identify the optimal number of moments.

2. Implement TAP-SLDA on a real embedded device (e.g., Raspberry Pi or microcontroller) to measure actual memory usage, inference latency, and power consumption, comparing against theoretical estimates.

3. Test the model's performance under non-ideal conditions: random class arrival order, noisy audio inputs, and scenarios where new classes partially overlap with previous keywords phonetically.