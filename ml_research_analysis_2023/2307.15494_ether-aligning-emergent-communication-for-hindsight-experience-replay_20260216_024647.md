---
ver: rpa2
title: 'ETHER: Aligning Emergent Communication for Hindsight Experience Replay'
arxiv_id: '2307.15494'
source_url: https://arxiv.org/abs/2307.15494
tags:
- agent
- goal
- learning
- language
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses two key limitations of HIGhER: (1) reliance
  on an oracle predicate function for HER and (2) use of only successful trajectories.
  The proposed solution, ETHER, uses a visual referential game as an unsupervised
  auxiliary task to learn a predicate function, and employs semantic co-occurrence
  grounding to align the emergent language with the natural language of the instruction-following
  task.'
---

# ETHER: Aligning Emergent Communication for Hindsight Experience Replay

## Quick Facts
- arXiv ID: 2307.15494
- Source URL: https://arxiv.org/abs/2307.15494
- Reference count: 40
- One-line primary result: ETHER achieves nearly twice the performance of HIGhER on BabyAI PickUpDist task, reaching 27.63% success ratio vs 14.84%

## Executive Summary
ETHER addresses two key limitations of HIGhER in natural language instruction following: reliance on an oracle predicate function and inability to leverage unsuccessful trajectories. The method uses a visual referential game as an unsupervised auxiliary task to learn a predicate function, combined with semantic co-occurrence grounding to align emergent language with natural language. ETHER achieves a success ratio of 27.63% on the BabyAI PickUpDist task, nearly twice that of the baseline HIGhER at 14.84%.

## Method Summary
ETHER combines language-conditioned reinforcement learning with emergent communication via visual referential games. The approach learns a predicate function through a discriminative visual referential game, where the listener agent outputs confidence scores analogous to what a predicate function does. A semantic co-occurrence grounding loss aligns the emergent language with natural language by bringing token embeddings closer to visual embeddings of observed features that co-occur with goals. This enables ETHER to leverage unsuccessful trajectories by using the RG predicate function to provide feedback on what was actually achieved.

## Key Results
- ETHER achieves 27.63% success ratio on BabyAI PickUpDist-v0, nearly twice HIGhER's 14.84%
- RG speaker accuracy reaches 92.63% on held-out evaluation set
- ETHER shows improved sample efficiency compared to baselines using oracle predicates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ETHER learns a predicate function via a visual referential game that aligns emergent language with natural language.
- Mechanism: The listener agent of the RG acts as a predicate function by outputting confidence scores for whether a message describes attributes within a stimulus. This replaces the oracle predicate function required by HIGhER.
- Core assumption: The emergent language from the RG speaker/listener agents will align semantically with the natural language goal descriptions.
- Evidence anchors:
  - [abstract] "we propose the Emergent Textual Hindsight Experience Replay (ETHER) agent...by means of (i) a discriminative visual referential game...used here as an unsupervised auxiliary task"
  - [section 3.2.1] "the listener agent of a visual discriminative RG...outputs a likelihood for the message to be clearly describing some attributes within the one and only stimulus provided. This is analogous to what a predicate function does."
  - [corpus] Weak - no direct corpus evidence for this specific alignment mechanism.

### Mechanism 2
- Claim: Semantic co-occurrence grounding aligns emergent language with natural language by leveraging environmental structure.
- Mechanism: The semantic co-occurrence grounding loss brings token embeddings closer to visual embeddings of observed features that co-occur with the current goal, biasing the emergent language toward natural language semantics.
- Core assumption: Goals and observations in successful and unsuccessful trajectories share semantic components due to the underlying environmental structure.
- Evidence anchors:
  - [section 3.2.2] "we hypothesise that if it is indeed the case that the goal can always be fulfilled, then upon specifying a goal, agent observations will be biased to contain semantic components present in said goal."
  - [section 4.3] "Table 1(bottom) shows the extent to which the RG's speaker agent has been using any of the natural language colour words to describe stimuli containing said colour as a visual feature"
  - [corpus] Weak - corpus lacks direct evidence for this specific grounding mechanism.

### Mechanism 3
- Claim: ETHER leverages unsuccessful trajectories by using the RG predicate function to provide feedback on what was actually achieved.
- Mechanism: The RG predicate function can evaluate whether a message describes the achieved state in unsuccessful trajectories, providing structured linguistic feedback that HER alone cannot use.
- Core assumption: The emergent language is expressive enough to describe unsuccessful states in terms meaningful to the natural language goal descriptions.
- Evidence anchors:
  - [abstract] "we show that the referential game's agents make an artificial language emerge that is aligned with the natural-like language...and that it is expressive enough so as to also describe unsuccessful RL trajectories"
  - [section 3.2.2] "ETHER...addresses both of its limitations by means of...a semantic grounding scheme to align the emergent language with the natural language of the instruction-following benchmark"
  - [corpus] Weak - no direct corpus evidence for this specific use of emergent language in unsuccessful trajectories.

## Foundational Learning

- Concept: Visual referential games
  - Why needed here: They provide an unsupervised way to learn a predicate function and emergent language that can describe states in terms aligned with natural language.
  - Quick check question: How does the listener agent of a visual referential game output a distribution over stimuli given a message?

- Concept: Semantic grounding
  - Why needed here: It aligns the emergent language with natural language by leveraging the co-occurrence of visual and textual concepts in the environment.
  - Quick check question: What is the key assumption behind using semantic co-occurrence for grounding emergent language?

- Concept: Hindsight Experience Replay
  - Why needed here: It allows leveraging unsuccessful trajectories by relabeling them with goals that were actually achieved, but requires a predicate function.
  - Quick check question: What are the two strategies HER offers for inferring alternative goals in unsuccessful trajectories?

## Architecture Onboarding

- Component map: BabyAI Environment -> R2D2 Agent (with language conditioning) -> HER relabeling -> RG Speaker/Listener -> Semantic Grounding Loss
- Critical path: 1) Train the RG speaker and listener agents on state observations. 2) Use the listener agent as predicate function in HER. 3) Train the RL agent with HER using the emergent predicate function.
- Design tradeoffs: Using a RG for predicate function learning trades off some alignment accuracy for the ability to deploy HER without an oracle. The semantic grounding loss trades off some emergent language expressivity for better alignment with natural language.
- Failure signatures: 1) Poor RG accuracy indicates the emergent language is not aligning with natural language. 2) Low RL success ratio indicates the emergent predicate function is not effective. 3) High variance in success ratio across seeds indicates instability.
- First 3 experiments:
  1. Train RG agents only on successful trajectories and evaluate accuracy on a held-out set to verify alignment with natural language.
  2. Replace the oracle predicate function in HIGhER with the RG listener agent and evaluate if RL success ratio improves.
  3. Add the semantic grounding loss and evaluate if RG accuracy and RL success ratio improve further.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can emergent languages be effectively constrained to closely resemble natural languages?
- Basis in paper: [inferred] The authors note that despite using the semantic co-occurrence grounding loss, the issue of constraining emergent languages to be as close as possible to benchmark or natural languages remains unresolved.
- Why unresolved: While the semantic co-occurrence grounding loss improves alignment of emergent language with natural language for certain semantic components (e.g., color), it does not fully resolve the challenge of constraining the emergent language to closely match the natural language used in instruction-following benchmarks.
- What evidence would resolve it: Experiments demonstrating emergent languages that consistently align with natural language semantics across diverse instruction-following tasks, with quantifiable measures of alignment.

### Open Question 2
- Question: Can the listener agent of the referential game be used to learn a predicate function for hierarchical reinforcement learning?
- Basis in paper: [explicit] The authors suggest that future work could use the listener agent of the referential game to learn a predicate function in an unsupervised fashion, which could then be used in place of the partial predicate function for hierarchical reinforcement learning.
- Why unresolved: While the idea is proposed, the paper does not provide experimental results or further exploration of this potential application of the listener agent.
- What evidence would resolve it: Implementation and evaluation of hierarchical reinforcement learning architectures using predicate functions learned by the listener agent, with comparisons to baseline methods.

### Open Question 3
- Question: What is the impact of semantic co-occurrence on the generalization abilities of the resulting agent?
- Basis in paper: [explicit] The authors mention that the current study did not investigate the systematic generalization abilities of the resulting agent, which they identify as an important task for future work.
- Why unresolved: The paper does not provide experimental results or analysis on how the semantic co-occurrence grounding affects the agent's ability to generalize to new tasks or environments.
- What evidence would resolve it: Experiments evaluating the agent's performance on tasks or environments not seen during training, with comparisons to agents without semantic co-occurrence grounding.

## Limitations

- The proposed semantic co-occurrence grounding mechanism lacks detailed implementation specifications and rigorous ablation studies.
- Evaluation is limited to a single BabyAI task (PickUpDist) with limited generalization claims to other instruction-following benchmarks.
- Claims about generality to more complex environments are not substantiated due to the narrow experimental scope.

## Confidence

**High confidence**: The core claim that ETHER achieves approximately twice the success ratio of HIGhER on BabyAI PickUpDist-v0 (27.63% vs 14.84%) is well-supported by experimental results and represents a clear quantitative improvement.

**Medium confidence**: The mechanism by which visual referential games learn an emergent predicate function that aligns with natural language is conceptually sound, but the effectiveness of the semantic co-occurrence grounding component lacks rigorous validation through ablation studies.

**Low confidence**: Claims about the generality of ETHER to other instruction-following tasks or more complex environments are not substantiated, as the evaluation is limited to a single relatively simple BabyAI task.

## Next Checks

1. **Ablation on semantic grounding**: Remove the semantic co-occurrence grounding loss and measure the impact on both RG speaker accuracy and RL success ratio to isolate whether this component provides meaningful benefit beyond the visual RG alone.

2. **Predicate function comparison**: Implement an oracle predicate function for HER and compare sample efficiency (learning curves) against the emergent predicate from the RG listener to quantify the alignment gap.

3. **Multi-task generalization**: Evaluate ETHER on at least two additional BabyAI instruction-following tasks (e.g., GoToObj and PutNextLocal) to assess whether the performance gains transfer beyond the PickUpDist environment.