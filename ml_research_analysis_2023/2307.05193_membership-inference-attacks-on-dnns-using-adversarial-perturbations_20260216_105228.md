---
ver: rpa2
title: Membership Inference Attacks on DNNs using Adversarial Perturbations
arxiv_id: '2307.05193'
source_url: https://arxiv.org/abs/2307.05193
tags:
- amia
- attacks
- emia
- membership
- e-amia
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents Adversarial Membership Inference Attack (AMIA)
  and Enhanced AMIA (E-AMIA) to address the limitations of existing membership inference
  attacks on simpler datasets like Fashion-MNIST and MNIST. The authors propose a
  unified framework of membership inference attacks and introduce two novel attacks:
  AMIA, which utilizes both membership and non-membership information of subjects
  while adversarially minimizing a novel loss function, and E-AMIA, which combines
  EMIA and AMIA.'
---

# Membership Inference Attacks on DNNs using Adversarial Perturbations

## Quick Facts
- arXiv ID: 2307.05193
- Source URL: https://arxiv.org/abs/2307.05193
- Reference count: 37
- Key outcome: AMIA and E-AMIA achieve 6% TPR on Fashion-MNIST and MNIST, outperforming existing attacks

## Executive Summary
This paper addresses the limitations of existing membership inference attacks on simpler datasets by proposing a unified framework and two novel attacks: AMIA and E-AMIA. The authors demonstrate that their approach achieves significantly better performance on Fashion-MNIST and MNIST datasets compared to existing methods, while also introducing augmented indicators that leverage loss information in the Gaussian neighborhood of subjects.

## Method Summary
The paper presents Adversarial Membership Inference Attack (AMIA) and Enhanced AMIA (E-AMIA) to improve membership inference performance on simpler datasets. AMIA computes adversarial perturbations that maximize the loss difference between member and non-member shadow DNNs, while E-AMIA combines EMIA and AMIA. The approach involves training shadow DNNs on sampled datasets, computing adversarial perturbations for each subject, calculating likelihood ratios, and applying thresholds for membership decisions.

## Key Results
- AMIA and E-AMIA achieve 6% TPR on both Fashion-MNIST and MNIST datasets
- Proposed attacks outperform existing attacks on simpler datasets
- Two novel augmented indicators improve TPR by 2.5% and 0.25% respectively on Fashion-MNIST and MNIST at 1% FPR

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial perturbations adversarially optimized to maximize the loss difference between member and non-member shadow DNNs improve membership inference performance.
- Mechanism: AMIA computes small magnitude perturbations that maximize the expected loss difference between member and non-member shadow DNNs, leveraging the transferability property of adversarial perturbations to the target DNN.
- Core assumption: Adversarial perturbations optimized on shadow DNNs transfer effectively to the target DNN for membership inference.
- Evidence anchors:
  - [abstract] "AMIA then adversarially computes small magnitude perturbations to the input of each subject that maximizes the difference between the loss of the member and the non-member shadow DNNs."
  - [section] "We leverage the transferability property to transfer the adversarial perturbations computed over member and non-member shadow DNNs to ft"
  - [corpus] Weak evidence - no direct citations on transferability in membership inference context
- Break condition: If adversarial perturbations do not transfer effectively to the target DNN, the membership inference performance will degrade.

### Mechanism 2
- Claim: Utilizing both membership and non-membership information in shadow DNN training improves membership inference performance.
- Mechanism: AMIA trains member shadow DNNs on subject batches augmented with original training data, while training non-member shadow DNNs on separate data, allowing the attack to leverage both membership and non-membership information.
- Core assumption: Training member shadow DNNs on subject batches provides useful membership information for inference.
- Evidence anchors:
  - [abstract] "AMIA efficiently utilizes the membership and the non-membership information of the subjects while being computationally efficient"
  - [section] "each shadow DNN is trained with k/2 randomly selected subjects augmented with the original training set as a batch for computational efficiency"
  - [corpus] Weak evidence - no direct citations on dual information utilization in membership inference
- Break condition: If the computational efficiency gain from batch training outweighs the membership information loss, performance will degrade.

### Mechanism 3
- Claim: Examining loss values in the Gaussian neighborhood of subjects improves membership inference performance.
- Mechanism: The proposed augmented indicators compute likelihood ratios for each subject and its Gaussian noise-perturbed versions, leveraging local loss landscape information.
- Core assumption: Loss values in the local neighborhood of a subject contain useful information for membership inference.
- Evidence anchors:
  - [abstract] "we introduce two novel augmented indicators that positively leverage the loss information in the Gaussian neighborhood of a subject"
  - [section] "We contribute towards a better I by extending the likelihood ratio indicator... to define two augmented indicators that exploit the loss landscape in the Gaussian neighborhood of a subject"
  - [corpus] Weak evidence - no direct citations on Gaussian neighborhood analysis in membership inference
- Break condition: If the local loss landscape does not contain discriminative information, the augmented indicators will not improve performance.

## Foundational Learning

- Concept: Adversarial machine learning and transferability of adversarial examples
  - Why needed here: Understanding how adversarial perturbations transfer between models is crucial for AMIA's effectiveness
  - Quick check question: What is the key property that allows adversarial perturbations computed on shadow DNNs to be effective on the target DNN?

- Concept: Membership inference attacks and their threat models
  - Why needed here: Understanding the different types of MI attacks and their assumptions is essential for evaluating AMIA's approach
  - Quick check question: What is the main difference between online and offline likelihood ratio attacks in terms of computational efficiency?

- Concept: Loss landscape analysis and its application to privacy attacks
  - Why needed here: Understanding how loss values vary in the local neighborhood of data points is key to the augmented indicator approach
  - Quick check question: Why might examining loss values in the Gaussian neighborhood of a subject provide additional information for membership inference?

## Architecture Onboarding

- Component map: Preparation stage -> Indication stage -> Decision stage
- Critical path:
  1. Train shadow DNNs on sampled datasets
  2. Compute adversarial perturbations for each subject
  3. Calculate likelihood ratios using member and non-member shadow DNNs
  4. Apply threshold to determine membership

- Design tradeoffs:
  - Computational efficiency vs. utilization of membership information
  - l∞ norm of perturbations vs. capturing local loss trends
  - Number of shadow DNNs vs. approximation accuracy

- Failure signatures:
  - Poor performance on simpler datasets (e.g., Fashion-MNIST, MNIST)
  - Low transferability to unknown DNNs
  - Degraded performance with DP-SGD training

- First 3 experiments:
  1. Evaluate AMIA performance on Fashion-MNIST and MNIST datasets compared to f-LiRA and EMIA
  2. Test the effect of varying ϵ (perturbation magnitude) on AMIA performance
  3. Assess the transferability of AMIA variables to unknown DNNs trained on the same dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the effectiveness of MI attacks be improved for datasets where the target DNN is well-trained and does not overfit?
- Basis in paper: [explicit] The paper states that current MI attacks perform poorly on simpler datasets (e.g., MNIST and Fashion-MNIST) where the target DNN does not overfit, and proposes AMIA and E-AMIA to address this limitation.
- Why unresolved: While AMIA and E-AMIA show improved performance, the paper does not explore all possible methods to enhance MI attacks for well-trained models, and further research could lead to even more effective techniques.
- What evidence would resolve it: Empirical studies comparing the performance of AMIA, E-AMIA, and other proposed methods on a wide range of datasets and DNN architectures, demonstrating significant improvements in MI attack effectiveness for well-trained models.

### Open Question 2
- Question: How transferable are MI attacks across different DNN architectures and datasets?
- Basis in paper: [explicit] The paper discusses the transferability of MI attacks, showing that AMIA and E-AMIA are more transferable than f-LiRA and EMIA. However, it does not explore transferability across different DNN architectures or datasets in depth.
- Why unresolved: The paper focuses on transferability within the same dataset and architecture, but does not investigate how MI attacks perform when transferred to different architectures or datasets, which is an important aspect of practical applicability.
- What evidence would resolve it: Extensive experiments evaluating the transferability of AMIA, E-AMIA, f-LiRA, and EMIA across various DNN architectures and datasets, providing insights into the generalizability of these attacks.

### Open Question 3
- Question: How can the computational efficiency of MI attacks be further improved while maintaining or enhancing their effectiveness?
- Basis in paper: [explicit] The paper proposes AMIA and E-AMIA as more computationally efficient alternatives to n-LiRA, but acknowledges that they still require training multiple shadow DNNs.
- Why unresolved: The paper does not explore all possible methods to reduce computational overhead, such as using fewer shadow DNNs or leveraging techniques like universal adversarial perturbations.
- What evidence would resolve it: Empirical studies comparing the computational efficiency and effectiveness of AMIA, E-AMIA, and other proposed methods, demonstrating significant improvements in efficiency while maintaining or enhancing attack performance.

## Limitations
- Limited empirical validation of adversarial perturbation transferability across different architectures
- Computational efficiency gains from batch training may compromise membership information quality
- Lack of sufficient ablation studies to isolate contributions of Gaussian neighborhood analysis versus adversarial perturbations

## Confidence
- AMIA's superior performance on simple datasets: **Medium** - Results are presented but validation on complex datasets is limited
- Transferability of adversarial perturbations: **Low** - Mechanism described but empirical evidence is weak
- Computational efficiency claims: **Medium** - Supported by description but not benchmarked against alternatives

## Next Checks
1. Test AMIA performance on more complex datasets (e.g., CIFAR-100, ImageNet) to validate scalability beyond simple image datasets
2. Conduct ablation studies to isolate the individual contributions of adversarial perturbations versus Gaussian neighborhood analysis
3. Evaluate the sensitivity of AMIA to shadow DNN architecture choices and training hyperparameters to assess robustness