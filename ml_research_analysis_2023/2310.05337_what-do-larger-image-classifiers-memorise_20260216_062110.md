---
ver: rpa2
title: What do larger image classifiers memorise?
arxiv_id: '2310.05337'
source_url: https://arxiv.org/abs/2310.05337
tags:
- memorisation
- score
- examples
- training
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive empirical analysis of how memorisation
  varies with model size for image classifiers. Using a theoretically-grounded metric
  from Feldman, the authors find that larger models exhibit increasingly bi-modal
  memorisation score distributions, with most samples having scores close to 0 or
  1.
---

# What do larger image classifiers memorise?

## Quick Facts
- arXiv ID: 2310.05337
- Source URL: https://arxiv.org/abs/2310.05337
- Authors: 
- Reference count: 40
- Primary result: Larger models exhibit increasingly bi-modal memorisation score distributions with most samples having scores close to 0 or 1

## Executive Summary
This paper presents a comprehensive empirical analysis of how memorisation varies with model size for image classifiers. Using a theoretically-grounded metric from Feldman, the authors find that larger models exhibit increasingly bi-modal memorisation score distributions, with most samples having scores close to 0 or 1. Surprisingly, they identify four distinct types of memorisation trajectories across model sizes, including examples with increasing memorisation even after interpolation. They show that commonly used proxies for the memorisation score fail to capture these fundamental trends. Finally, they find that knowledge distillation tends to inhibit memorisation, particularly on examples with increasing memorisation trajectories, thus providing insight into how distillation improves generalisation.

## Method Summary
The authors train ResNet and MobileNet models of varying depths on image classification datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet). For each training example, they compute a stability-based memorisation score by measuring the model's performance change when that example is excluded from training. This involves training multiple models on sub-samples of the training data. They analyze the distribution of memorisation scores across model sizes and identify distinct memorisation trajectory patterns. They also apply knowledge distillation with ResNet-110 teachers to smaller student models and observe its effect on memorisation scores.

## Key Results
- Larger models exhibit increasingly bi-modal memorisation score distributions
- Four distinct memorisation trajectory types are identified across model sizes
- Commonly used proxies for memorisation scores fail to capture fundamental trends
- Knowledge distillation inhibits memorisation, particularly on examples with increasing memorisation trajectories

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Larger neural networks exhibit increasingly bi-modal memorisation score distributions, with most training samples having scores close to 0 or 1.
- **Mechanism:** As model capacity increases, the network's ability to perfectly fit (memorise) individual training samples improves. This leads to two distinct groups: samples that are easily generalised (low memorisation score) and those that require memorisation (high memorisation score).
- **Core assumption:** The stability-based memorisation score accurately captures whether a model relies on a specific training sample to make correct predictions.
- **Evidence anchors:**
  - [abstract] "We find that training examples exhibit an unexpectedly diverse set of memorisation trajectories across model sizes: most samples experience decreased memorisation under larger models, while the rest exhibit cap-shaped or increasing memorisation."
  - [section] "Our finding is that this bi-modality is exaggerated with model depth: larger models have a higher fraction of samples with both memorisation score close to 0 and 1."
  - [corpus] "Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation" suggests similar continuum concepts.
- **Break Condition:** If the stability-based memorisation score does not accurately reflect reliance on training samples, the bi-modal distribution may not hold.

### Mechanism 2
- **Claim:** Knowledge distillation tends to inhibit memorisation, particularly on examples with increasing memorisation trajectories.
- **Mechanism:** During distillation, the student model learns from the teacher's softened probability distribution rather than the hard one-hot labels. This encourages the student to learn generalisable patterns rather than memorising specific training examples.
- **Core assumption:** The teacher model's softened probability distribution contains more generalisable information than the one-hot labels.
- **Evidence anchors:**
  - [abstract] "we find that knowledge distillation — an effective and popular model compression technique — tends to inhibit memorisation, while also improving generalisation."
  - [section] "Specifically, memorisation is mostly inhibited on examples with increasing memorisation trajectories, thus pointing at how distillation improves generalisation."
  - [corpus] "Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning" suggests distillation as a method for reducing memorisation.
- **Break Condition:** If the teacher model has already memorised the training examples, distillation may not inhibit memorisation in the student.

### Mechanism 3
- **Claim:** Commonly used proxies for the Feldman memorisation score fail to capture the fundamental trends of increasing bi-modality and diverse memorisation trajectories.
- **Mechanism:** Proxies like cprox and prediction depth are computationally efficient but do not fully capture the nuanced ways in which memorisation changes with model size. They may correlate with memorisation scores but do not exhibit the same distributional properties.
- **Core assumption:** The computationally efficient proxies are designed to approximate memorisation scores but may miss key aspects of how memorisation evolves.
- **Evidence anchors:**
  - [abstract] "We show that various proxies for the Feldman [29] memorization score fail to capture these fundamental trends."
  - [section] "Consequently, we do not observe many of the unexpected trends exhibited by stability-based memorisation, e.g., the possibility of cprox systematically decreasing for some samples as depth increases."
  - [corpus] "Causal Estimation of Memorisation Profiles" suggests causal estimation as a more accurate method, implying limitations of proxies.
- **Break Condition:** If the proxies are refined to better capture the nuances of memorisation evolution, they may exhibit the same trends as the Feldman score.

## Foundational Learning

- **Concept:** Stability-based memorisation score
  - **Why needed here:** This metric is the foundation for quantifying how much a model relies on specific training examples to make correct predictions.
  - **Quick check question:** How is the stability-based memorisation score calculated, and what does it represent?

- **Concept:** Knowledge distillation
  - **Why needed here:** Understanding how distillation works is crucial for interpreting its effect on reducing memorisation in student models.
  - **Quick check question:** What is the difference between training a model with one-hot labels versus training it with a teacher's softened probability distribution?

- **Concept:** Bi-modal distribution
  - **Why needed here:** Recognising the bi-modal nature of memorisation scores is key to understanding the diverse memorisation trajectories observed across model sizes.
  - **Quick check question:** What does it mean for a distribution to be bi-modal, and how does this relate to the memorisation behaviour of neural networks?

## Architecture Onboarding

- **Component map:** ResNet and MobileNet models of varying depths → Training on image classification datasets → Computation of memorisation scores via sub-sampling and retraining → Analysis of distribution and trajectories
- **Critical path:** The critical path is the computation of the memorisation score, which requires training multiple models on sub-samples of the training data.
- **Design tradeoffs:** The tradeoff is between the breadth of results across settings and the precision of the memorisation scores estimated for any individual result. The paper favours breadth by estimating the score with fewer sub-samples.
- **Failure signatures:** If the bi-modal distribution of memorisation scores is not observed, or if distillation does not inhibit memorisation as expected, it may indicate issues with the experimental setup or the metric itself.
- **First 3 experiments:**
  1. Train ResNet models of varying depths on CIFAR-100 and compute the average memorisation score.
  2. Analyse the distribution of memorisation scores across training examples for each model depth.
  3. Apply knowledge distillation with a ResNet-110 teacher and observe its effect on the memorisation scores of smaller student models.

## Open Questions the Paper Calls Out
None

## Limitations
- The study focuses on image classification datasets, and generalizability to other domains remains uncertain
- The subsampling procedure represents a trade-off between computational feasibility and measurement precision
- The findings rely heavily on the Feldman memorisation score as the ground truth metric

## Confidence

| Claim | Confidence Level |
| --- | --- |
| Larger models exhibit increasingly bi-modal memorisation score distributions | High |
| Four distinct memorisation trajectory types are identified | Medium |
| Knowledge distillation inhibits memorisation | Medium |

## Next Checks
1. **Replication across domains:** Apply the same analysis framework to a natural language processing task (e.g., text classification) to verify whether the bi-modal distribution and trajectory patterns hold beyond image data.

2. **Metric sensitivity analysis:** Systematically vary the subsampling parameters (K and M) to quantify how measurement precision affects the observed memorisation trends and trajectory classifications.

3. **Causal analysis of distillation:** Design controlled experiments to isolate whether the reduction in memorisation from distillation is primarily due to the softened labels or other factors like reduced model capacity in student models.