---
ver: rpa2
title: An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental
  Learning
arxiv_id: '2308.11677'
source_url: https://arxiv.org/abs/2308.11677
tags:
- learning
- initial
- incremental
- training
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes the impact of different initial training strategies
  on exemplar-free class-incremental learning (EFCIL). The authors conduct a comprehensive
  experimental study comparing 16 target datasets, 2 EFCIL scenarios, 3 CIL algorithms,
  and various combinations of neural architectures, training methods, and supervision
  modes.
---

# An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning

## Quick Facts
- **arXiv ID**: 2308.11677
- **Source URL**: https://arxiv.org/abs/2308.11677
- **Reference count**: 40
- **Primary result**: Pre-training with external data and self-supervision improves exemplar-free class-incremental learning accuracy

## Executive Summary
This paper analyzes how different initial training strategies impact exemplar-free class-incremental learning (EFCIL) performance. Through comprehensive experiments across 16 datasets, 2 scenarios, and 3 algorithms, the authors find that pre-training with external data and self-supervised learning significantly boost incremental learning accuracy. The study reveals that while initial training strategy is the dominant factor for average incremental accuracy, the choice of CIL algorithm is more crucial for preventing forgetting. Based on these findings, the paper provides practical recommendations for selecting optimal initial training strategies based on specific use cases.

## Method Summary
The authors conduct experiments using 16 target datasets with three EFCIL algorithms (BSIL, DSLDA, FeTrIL) under two scenarios. They evaluate various initial training strategies including supervised learning, self-supervised learning, fine-tuning with different depths, and transfer learning approaches. The experiments measure average incremental accuracy (Acc), average forgetting (F), initial accuracy (Acc1), and final accuracy (AccK). The study systematically varies neural architectures (CNNs vs. Transformers) and training methods to understand their interactions with initial training strategies.

## Key Results
- Pre-training with external data significantly improves accuracy in EFCIL tasks
- Self-supervised learning during initial training boosts incremental learning, especially when combined with fine-tuning on initial classes
- EFCIL algorithms based on transfer learning (freezing feature extractors) outperform fine-tuning-based approaches in preventing forgetting
- Initial training strategy is the dominant factor for average incremental accuracy, while CIL algorithm choice is more important for preventing forgetting

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Initial training strategy dominates average incremental accuracy because it shapes the feature space before incremental learning begins.
- **Mechanism**: Pre-training on large external datasets or using self-supervised learning produces generalizable features. These features provide a stable foundation for incremental learning, reducing catastrophic forgetting.
- **Core assumption**: Features learned during initial training transfer well to new classes and tasks encountered in incremental steps.
- **Evidence anchors**:
  - [abstract] "pre-training with external data improves accuracy"
  - [section] "The main findings are that: (1) pre-training with external data improves accuracy"
  - [corpus] Weak evidence: related papers focus on exemplar-free CIL but don't directly analyze initial training strategy dominance.
- **Break condition**: If the initial training dataset is too dissimilar from target datasets, or if fine-tuning degrades the learned features, the strategy loses its advantage.

### Mechanism 2
- **Claim**: The choice of CIL algorithm is more important in preventing forgetting than in achieving high average incremental accuracy.
- **Mechanism**: Algorithms that freeze the feature extractor and only update the classifier (e.g., DSLDA, FeTrIL) prioritize stability over plasticity, leading to less forgetting but potentially lower adaptation to new classes.
- **Core assumption**: Freezing feature extractors preserves learned representations better than fine-tuning-based approaches.
- **Evidence anchors**:
  - [abstract] "the choice of CIL algorithm is more important in preventing forgetting"
  - [section] "However, the distribution of best performance... shows that no combination of an EFCIL algorithm and an initial training strategy is best in all cases."
  - [corpus] No direct evidence; related papers focus on CIL algorithms but not the forgetting vs. accuracy trade-off in the context of initial training.
- **Break condition**: If the initial feature extractor is not transferable, freezing it may hinder performance on new classes.

### Mechanism 3
- **Claim**: Self-supervised learning during initial training boosts incremental learning, especially when combined with fine-tuning on the initial classes.
- **Mechanism**: Self-supervised methods learn robust features without relying on labels. Fine-tuning these features on the initial classes adapts them to the specific task while preserving generalization.
- **Core assumption**: Self-supervised features are more adaptable and transferable than purely supervised features.
- **Evidence anchors**:
  - [abstract] "(2) self-supervision in the initial step boosts incremental learning, particularly when the pre-trained model is fine-tuned on the initial classes"
  - [section] "Self-Supervised Learning (SSL) has recently gained interest thanks to its ability to produce diverse, reusable features for downstream tasks."
  - [corpus] Weak evidence: related papers mention self-supervised learning in CIL but don't specifically analyze its impact when combined with fine-tuning on initial classes.
- **Break condition**: If the self-supervised model overfits to the initial data during fine-tuning, or if the initial data is insufficient for effective fine-tuning, the benefit diminishes.

## Foundational Learning

- **Concept: Catastrophic Forgetting**
  - Why needed here: Understanding why EFCIL is challenging and why initial training strategy and CIL algorithm choice matter.
  - Quick check question: What is catastrophic forgetting, and why does it occur in neural networks during incremental learning?

- **Concept: Transfer Learning**
  - Why needed here: Explains how pre-trained models are used as starting points and why feature transferability is crucial.
  - Quick check question: What are the main types of transfer learning (e.g., feature extraction, fine-tuning), and when is each appropriate?

- **Concept: Self-Supervised Learning**
  - Why needed here: Clarifies how SSL methods generate features without labels and why they might be beneficial for initial training in EFCIL.
  - Quick check question: How does self-supervised learning differ from supervised learning, and what are its advantages in scenarios with limited labeled data?

## Architecture Onboarding

- **Component map**: Initial training strategy (pre-training method, fine-tuning depth, external data use) → CIL algorithm (fine-tuning vs. fixed representation) → Neural architecture (CNN vs. Transformer) → Target dataset (domain, size, class distribution)
- **Critical path**: The interaction between initial training strategy and CIL algorithm is the most critical. The initial training strategy shapes the feature space, and the CIL algorithm determines how much the model adapts to new data.
- **Design tradeoffs**: Stability (less forgetting) vs. plasticity (adaptation to new classes). Using pre-trained models improves stability but may reduce adaptability if not fine-tuned. Transformers may offer better representation learning but are harder to fine-tune.
- **Failure signatures**: Low accuracy on new classes despite high initial accuracy suggests poor adaptability. High forgetting despite using a stable CIL algorithm suggests poor initial feature transferability.
- **First 3 experiments**:
  1. Compare ResNet50 with and without pre-training on a small target dataset to isolate the effect of pre-training.
  2. Compare fine-tuning vs. feature extraction (freezing the backbone) using the same pre-trained model and CIL algorithm.
  3. Compare supervised vs. self-supervised pre-training on the initial classes, using the same fine-tuning and CIL algorithm.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What are the specific dataset characteristics that most significantly influence the effectiveness of pre-trained models in exemplar-free class-incremental learning?
- **Basis in paper**: [explicit] The paper discusses how the effectiveness of pre-trained models varies based on dataset characteristics such as domain gap, number of classes, and size of initial batch, but does not provide a detailed analysis of which specific characteristics are most influential.
- **Why unresolved**: The paper mentions the influence of dataset characteristics but does not conduct a detailed analysis to identify the most significant ones.
- **What evidence would resolve it**: A comprehensive study that systematically varies dataset characteristics (e.g., domain similarity, number of classes, class balance) and measures their impact on the effectiveness of pre-trained models in EFCIL.

### Open Question 2
- **Question**: How does the choice of neural architecture (CNN vs. transformer) interact with different pre-training and fine-tuning strategies to affect EFCIL performance?
- **Basis in paper**: [explicit] The paper compares CNNs and transformers but finds that the difference in performance is small when CNNs are pre-trained in a self-supervised manner and then partially fine-tuned. However, it does not explore the interaction between architecture choice and pre-training/fine-tuning strategies in depth.
- **Why unresolved**: The paper provides a high-level comparison but does not delve into the specific interactions between architecture and training strategies.
- **What evidence would resolve it**: A detailed analysis that systematically varies the neural architecture and training strategies to measure their combined effects on EFCIL performance.

### Open Question 3
- **Question**: What are the optimal strategies for balancing stability and plasticity in exemplar-free class-incremental learning, particularly when using pre-trained models?
- **Basis in paper**: [explicit] The paper discusses the trade-off between stability (preventing forgetting) and plasticity (adapting to new classes) but does not provide a detailed framework for optimizing this balance, especially in the context of pre-trained models.
- **Why unresolved**: The paper identifies the trade-off but does not offer a concrete method for balancing these two aspects in EFCIL.
- **What evidence would resolve it**: A study that develops and evaluates strategies for optimizing the balance between stability and plasticity, particularly focusing on the use of pre-trained models in EFCIL.

## Limitations

- The study lacks ablation experiments isolating the effects of self-supervised pre-training from fine-tuning depth
- Results may not generalize to domains outside natural images and fine-grained classification tasks
- The paper doesn't address computational costs of different training strategies, which could be crucial for practical deployment

## Confidence

- **High confidence**: Pre-training with external data improves accuracy (based on strong experimental evidence across multiple datasets)
- **Medium confidence**: Initial training strategy dominates average incremental accuracy (aggregated results may hide dataset-specific interactions)
- **Low confidence**: Self-supervision specifically boosts incremental learning (lacks isolation of self-supervision effects from other factors)

## Next Checks

1. Conduct ablation studies isolating self-supervised pre-training effects by controlling for fine-tuning depth and dataset characteristics
2. Perform per-dataset analysis to identify when initial training strategy vs. CIL algorithm choice dominates performance
3. Test the recommended strategies on out-of-domain datasets (e.g., medical imaging or audio) to assess generalizability