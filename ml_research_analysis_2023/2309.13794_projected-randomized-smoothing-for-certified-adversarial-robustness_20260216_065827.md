---
ver: rpa2
title: Projected Randomized Smoothing for Certified Adversarial Robustness
arxiv_id: '2309.13794'
source_url: https://arxiv.org/abs/2309.13794
tags:
- certified
- smoothing
- randomized
- volume
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses certified adversarial robustness by combining
  dimensionality reduction with randomized smoothing. The core idea is to first project
  inputs onto a low-dimensional approximation of the data manifold using PCA, then
  apply standard randomized smoothing in this projected space, and finally map the
  certified region back to the original high-dimensional space.
---

# Projected Randomized Smoothing for Certified Adversarial Robustness

## Quick Facts
- arXiv ID: 2309.13794
- Source URL: https://arxiv.org/abs/2309.13794
- Authors: 
- Reference count: 40
- One-line primary result: Certified regions with 706-2453 orders of magnitude larger volume than baselines through PCA-based dimensionality reduction with randomized smoothing

## Executive Summary
This paper addresses certified adversarial robustness by combining dimensionality reduction with randomized smoothing. The core innovation is projecting inputs onto a low-dimensional approximation of the data manifold using PCA, then applying standard randomized smoothing in this projected space, and finally mapping the certified region back to the original high-dimensional space. This approach yields certified regions that capture perturbations normal to the data manifold, which standard methods miss. Experiments on CIFAR-10 and SVHN show that the method produces certified regions with orders of magnitude larger volume compared to baselines, improving on state-of-the-art by 706 to 2453 orders of magnitude.

## Method Summary
The method projects inputs onto a low-dimensional subspace using PCA, applies randomized smoothing with Gaussian noise in the projected space, and maps the certified region back to the original space. The certified region in input space is the Minkowski sum of a low-dimensional ball (from RS in projected space) and the nullspace of the projection. A tractable lower bound on the volume is computed using an ℓ∞-norm linear regression. The method is empirically robust to attacks in the subspace of low-variance principal components.

## Key Results
- Certified regions with 706-2453 orders of magnitude larger volume than standard randomized smoothing
- Empirical robust accuracy remains constant over increasing attack magnitude for a fixed projection dimension
- Classifiers without initial projection are vulnerable to perturbations normal to the data manifold
- Provides certifiable robustness against perturbations in the subspace of low-variance principal components

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Projecting inputs onto a low-dimensional subspace captures the data manifold while eliminating perturbations normal to it.
- Mechanism: The PCA projection retains components explaining most variance (99% for CIFAR-10, 95% for SVHN), effectively filtering out directions orthogonal to the data manifold where adversarial perturbations often lie.
- Core assumption: The data manifold is approximately low-dimensional and can be captured by principal components.
- Evidence anchors:
  - [abstract] "This work considers a classifier architecture that first projects onto a low-dimensional approximation of the data manifold"
  - [section] "We show experimentally on CIFAR-10 and SVHN that classifiers without the initial projection are vulnerable to perturbations that are normal to the data manifold"
  - [corpus] "Randomized smoothing is a leading approach for constructing classifiers that are certifiably robust against adversarial examples" (weak evidence - general RS context)
- Break condition: If the data manifold is not low-dimensional or if adversarial perturbations align with principal components, this mechanism fails.

### Mechanism 2
- Claim: Randomized smoothing in low-dimensional space yields larger certified regions than in high-dimensional space due to factorial scaling advantages.
- Mechanism: The certified region in input space is the Minkowski sum of a low-dimensional ball and the nullspace of the projection. The volume of this region scales factorially in the projected dimension p rather than the input dimension d.
- Core assumption: The certified radius in projected space is comparable to standard RS radii in input space.
- Evidence anchors:
  - [section] "we characterize the geometry of the certified region in the input space and prove a tractable lower bound on the volume of this certified region"
  - [section] "the volume of our certified regions decay factorially in the low dimension of the projected space, while competing methods decay factorially in the high dimension of the input space"
  - [corpus] "However how to design an efficient classifier with an associated certified radius?" (weak evidence - general RS context)
- Break condition: If the certified radius in projected space is much smaller than in input space, the volume advantage disappears.

### Mechanism 3
- Claim: The method provides certifiable robustness against perturbations in the subspace of low-variance principal components.
- Mechanism: The certified region explicitly includes the nullspace of the projection matrix, which contains low-variance principal components. The paper demonstrates vulnerability of unprotected classifiers to such attacks and provides theoretical guarantees for the proposed method.
- Core assumption: Adversarial examples can exploit low-variance features that are statistically insignificant but still vulnerable.
- Evidence anchors:
  - [section] "classifiers without the initial projection are vulnerable to perturbations that are normal to the data manifold"
  - [section] "we show experimentally on CIFAR-10 and SVHN that classifiers without the initial projection are vulnerable to perturbations that are normal to the data manifold"
  - [corpus] "Randomized smoothing has become a leading approach for constructing classifiers that are certifiably robust against adversarial examples" (weak evidence - general RS context)
- Break condition: If adversarial examples cannot exploit low-variance features or if the projection does not capture these features, this mechanism fails.

## Foundational Learning

- Concept: Principal Component Analysis (PCA) and dimensionality reduction
  - Why needed here: PCA is used to project inputs onto a low-dimensional approximation of the data manifold, which is central to the method's effectiveness.
  - Quick check question: What percentage of variance do the first p principal components explain in the CIFAR-10 dataset used in the experiments?

- Concept: Randomized smoothing and its certification guarantees
  - Why needed here: The method builds upon standard randomized smoothing by performing it in the projected space, inheriting its certification properties while extending them.
  - Quick check question: What is the relationship between the certified radius in the projected space and the certified region in the original high-dimensional space?

- Concept: Volume calculations and Lebesgue measure in high-dimensional spaces
  - Why needed here: The paper's metric of comparison is the volume of certified regions, requiring understanding of how volumes scale with dimension.
  - Quick check question: How does the volume of a d-dimensional ℓ2-ball scale with dimension d?

## Architecture Onboarding

- Component map: Input -> PCA projection -> Neural network classifier -> Randomized smoothing -> Volume calculation -> Certified region mapping
- Critical path:
  1. Project input using PCA basis (U ⊺x)
  2. Apply randomized smoothing in projected space
  3. Compute certified radius R in projected space
  4. Solve ℓ∞-norm regression to find t
  5. Calculate volume lower bound using R and t
  6. Map certified region back to input space

- Design tradeoffs:
  - Higher p increases reconstruction fidelity but reduces volume gains
  - Larger σ increases robustness but may hurt clean accuracy
  - More principal components capture more variance but reduce nullspace robustness
  - Tradeoff between clean accuracy and certified volume (Figures 3b, 3d)

- Failure signatures:
  - If volume lower bound is negative or NaN, check R and t values
  - If certified accuracy is much lower than clean accuracy, check PCA projection quality
  - If ℓ∞-regression fails to converge, check conditioning of V matrix
  - If results are similar to standard RS, verify that p << d and that the projection captures meaningful variance

- First 3 experiments:
  1. Verify that standard classifier is vulnerable to low-variance PCA attacks using SubspacePGD
  2. Test volume calculation with synthetic data where ground truth is known
  3. Compare certified radii in projected vs. input space to validate mechanism 2 assumptions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of projection method (PCA vs random projections) affect the certified volume bounds?
- Basis in paper: [explicit] The paper compares PCA projections with random projections and finds PCA provides superior certificates.
- Why unresolved: The comparison is limited to CIFAR-10 and only considers one random projection dimension (1500). It's unclear if these results generalize to other datasets or if there's an optimal projection dimension.
- What evidence would resolve it: Systematic experiments comparing different projection methods (PCA, random, autoencoders) across multiple datasets with varying projection dimensions would provide clearer guidance on optimal projection choices.

### Open Question 2
- Question: What is the theoretical relationship between the subspace attack success rate and the certified volume improvements?
- Basis in paper: [inferred] The paper shows that classifiers are vulnerable to attacks in the subspace of low-variance principal components and that projected randomized smoothing provides certified robustness against these attacks.
- Why unresolved: While the paper demonstrates that subspace attacks are successful and that projected randomized smoothing is robust, it doesn't provide a theoretical framework linking attack success rates to certified volume improvements.
- What evidence would resolve it: A theoretical analysis that quantifies how attack success rates in different subspaces relate to the volume of the certified region would help understand the practical significance of the certified volume improvements.

### Open Question 3
- Question: How does the choice of projection dimension p affect the empirical robustness against manifold-perpendicular attacks?
- Basis in paper: [explicit] The paper shows that empirical robust accuracy remains constant over increasing attack magnitude for a fixed projection dimension p, indicating robustness to off-manifold components.
- Why unresolved: The experiments only consider one projection dimension (p=450 for CIFAR-10 and p=150 for SVHN). It's unclear how the empirical robustness varies with different choices of p.
- What evidence would resolve it: Empirical experiments evaluating the robust accuracy against manifold-perpendicular attacks for a range of projection dimensions would clarify the relationship between p and empirical robustness.

## Limitations
- Method depends on the low-dimensional manifold assumption, which may not hold for all datasets
- Computational overhead of PCA preprocessing and the sensitivity to hyperparameter choices
- Lack of direct baseline comparisons in some experimental configurations

## Confidence
- Core claims about factorial volume advantages and manifold-based robustness: High confidence
- Experimental results demonstrating vulnerability to low-variance perturbations: Medium confidence
- Comparison to state-of-the-art methods showing orders of magnitude improvement: Medium confidence

## Next Checks
1. **Baseline Verification**: Implement direct comparisons with state-of-the-art randomized smoothing methods on identical architectures and compute certified volumes for fair comparison.
2. **Manifold Assumption Testing**: Evaluate performance on datasets with varying intrinsic dimensionality to test the limits of the low-dimensional manifold assumption.
3. **Robustness to Distribution Shift**: Test certified robustness under domain shift conditions where the training and test distributions differ, which could affect PCA projection quality.