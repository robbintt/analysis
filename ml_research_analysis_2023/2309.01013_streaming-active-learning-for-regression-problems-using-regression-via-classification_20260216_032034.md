---
ver: rpa2
title: Streaming Active Learning for Regression Problems Using Regression via Classification
arxiv_id: '2309.01013'
source_url: https://arxiv.org/abs/2309.01013
tags:
- uni00000013
- learning
- uni00000011
- active
- regression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using regression-via-classification (RvC) for
  streaming active learning in regression tasks. RvC transforms regression into classification,
  enabling application of existing classification-based active learning methods.
---

# Streaming Active Learning for Regression Problems Using Regression via Classification

## Quick Facts
- arXiv ID: 2309.01013
- Source URL: https://arxiv.org/abs/2309.01013
- Reference count: 0
- Key outcome: Proposes RvC-based streaming active learning for regression, outperforming random and QBC baselines

## Executive Summary
This paper addresses the challenge of streaming active learning for regression problems where model performance degrades over time due to concept drift. The authors propose using Regression-via-Classification (RvC) to transform regression into classification, enabling application of established classification-based active learning methods. By averaging uncertainties from multiple RvC classifiers with different numbers of classes, the approach balances discretization error and classification accuracy. Experiments on four real datasets demonstrate superior performance compared to random and query-by-committee baselines.

## Method Summary
The proposed method uses RvC to discretize continuous target variables into discrete classes using K-means clustering, then trains multiple classifiers with different numbers of classes. The utility of samples for labeling is estimated by averaging the uncertainties (maximum class probabilities) from these classifiers. This utility estimation feeds into streaming active learning algorithms that select samples for labeling within a fixed budget. The main regression model is trained separately on the labeled data, while the RvC classifiers serve only for utility estimation.

## Key Results
- RvC-based utility estimation outperforms random selection and QBC-based baselines on four real datasets
- Lower RMSE achieved with the same annotation budget compared to baselines
- Averaging uncertainties across different numbers of classes provides robust utility estimates
- Method successfully applies classification active learning techniques to regression problems

## Why This Works (Mechanism)

### Mechanism 1
RvC transforms regression problems into classification problems, enabling direct application of classification-based active learning methods. The framework discretizes continuous targets into discrete classes, allowing any classifier to be used. The key assumption is that discretization error can be mitigated by averaging uncertainties across different class numbers.

### Mechanism 2
Averaging uncertainties from RvC classifiers with different numbers of classes balances classification accuracy and discretization error. Different class numbers have complementary strengths, and averaging produces more robust uncertainty estimates. This assumes that the combination of multiple discretizations captures the underlying uncertainty better than any single discretization.

### Mechanism 3
The RvC-based utility estimation outperforms QBC-based methods in offline evaluation. RvC uses bounded utilities (0 to 1) based on maximum class probabilities, while QBC uses unbounded variances from ensemble predictions. The bounded nature of RvC utilities provides more stable and interpretable uncertainty estimates.

## Foundational Learning

- **Streaming active learning**: Needed because the paper focuses on non-stationary environments with sequential data arrival and concept drift. Quick check: What is the key difference between streaming and pool-based active learning approaches?

- **Concept drift**: Critical as the paper addresses model degradation over time due to changing operating environments. Quick check: How does concept drift affect model performance in streaming scenarios?

- **Utility estimation in active learning**: Central to the contribution of developing a method to estimate sample informativeness in regression tasks. Quick check: What makes utility estimation particularly challenging in regression compared to classification?

## Architecture Onboarding

- **Component map**: Data pipeline → RvC utility estimator → Budget manager → Label acquisition → Regression model → Evaluation module

- **Critical path**: Data arrival → Utility estimation → Budget manager decision → Label acquisition (if approved) → Model update → Performance evaluation

- **Design tradeoffs**:
  - Number of classes in RvC: More classes reduce discretization error but may decrease classification accuracy
  - Window size for budget management: Larger windows provide smoother budget control but slower adaptation
  - Utility estimator complexity: More complex estimators may improve accuracy but increase computational cost

- **Failure signatures**:
  - Consistently low utility values despite high error: May indicate poor RvC discretization or classifier performance
  - Rapid budget exhaustion: Budget manager parameters may need adjustment
  - Degrading RMSE over time: Possible concept drift not being handled effectively

- **First 3 experiments**:
  1. Compare RvC utility estimation with random selection on a simple synthetic regression dataset
  2. Test different numbers of classes (K values) in RvC to find optimal range
  3. Evaluate budget manager performance with different window sizes and adjustment parameters on real-world datasets

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions but leaves several important areas unexplored: the impact of alternative discretization methods beyond K-means clustering, performance under severe concept drift conditions, computational complexity analysis for large-scale applications, and behavior in high-dimensional feature spaces.

## Limitations

- Discretization process introduces approximation errors that are not fully characterized
- Optimal number of classes remains an empirical choice rather than principled derivation
- Experiments focus on regression problems without explicit concept drift
- Comparison with QBC-based methods limited to single offline evaluation metric

## Confidence

- **High**: RvC framework successfully transforms regression to classification, enabling direct application of classification active learning methods
- **Medium**: Averaging uncertainties across different class numbers improves utility estimation robustness
- **Medium**: RvC-based method outperforms QBC-based baseline on the tested datasets

## Next Checks

1. **Discretization sensitivity analysis**: Systematically vary the number of classes in RvC and measure the impact on both classification accuracy and final regression performance to quantify discretization error bounds.

2. **Streaming concept drift test**: Implement a synthetic streaming regression dataset with controlled concept drift and evaluate how RvC-based active learning maintains performance compared to passive learning.

3. **Computational complexity evaluation**: Measure the runtime overhead of maintaining multiple RvC classifiers with different class numbers and compare against the baseline QBC approach for equivalent performance.