---
ver: rpa2
title: Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual
  Machine Translation
arxiv_id: '2305.14016'
source_url: https://arxiv.org/abs/2305.14016
tags:
- gender
- translation
- bias
- language
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses gender bias in multilingual machine translation,
  focusing on unambiguous cases where there is a single correct translation. The authors
  propose a novel method called Gender-Aware Contrastive Learning (GACL) that injects
  gender information into encoder representations using contrastive learning with
  gender pseudo-labels.
---

# Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual Machine Translation

## Quick Facts
- arXiv ID: 2305.14016
- Source URL: https://arxiv.org/abs/2305.14016
- Reference count: 12
- GACL improves gender accuracy by 25.6 and 12.6 percentage points on WinoMT and MT-GenEval benchmarks

## Executive Summary
This paper addresses gender bias in multilingual machine translation, focusing on unambiguous cases where there is a single correct translation. The authors propose Gender-Aware Contrastive Learning (GACL), a novel method that injects gender information into encoder representations using contrastive learning with gender pseudo-labels. The approach shows significant improvements in gender accuracy (25.6 and 12.6 percentage points on WinoMT and MT-GenEval respectively) while maintaining translation performance. Notably, the debiasing effects transfer to target languages not seen during fine-tuning, demonstrating the target-agnostic nature of the approach. Experiments across different model architectures confirm GACL's effectiveness and robustness.

## Method Summary
The Gender-Aware Contrastive Learning (GACL) method addresses gender bias in multilingual machine translation by injecting gender information into encoder representations. The approach uses contrastive learning with gender pseudo-labels to pull together representations of same-gender sentences and push apart those of different-gender sentences. During fine-tuning, the model combines machine translation loss, knowledge distillation loss (to prevent catastrophic forgetting), and gender-aware contrastive loss. The method processes parallel training data filtered for sentences containing gendered words, balances male and female samples, and applies gender re-inflection. The fine-tuning process is target-agnostic, allowing debiasing effects to transfer to target languages not explicitly trained on.

## Key Results
- GACL improves gender accuracy by 25.6 percentage points on WinoMT and 12.6 percentage points on MT-GenEval benchmarks
- The method demonstrates target-agnostic debiasing, with gender information transferring to target languages not seen during fine-tuning
- GACL is effective across different model architectures (SMaLL-100 and NLLB-200) without significant degradation in translation performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gender bias in unambiguous translation settings stems from lack of gender information in encoder representations for non-explicit gender words.
- Mechanism: Contrastive learning with gender pseudo-labels injects gender-specific information into encoder embeddings by pulling together representations of same-gender sentences and pushing apart those of different-gender sentences.
- Core assumption: Gender information is primarily encoded in the encoder rather than the decoder, and contrastive learning can effectively separate gender-related representations.
- Evidence anchors:
  - [abstract]: "We hypothesize that the gender bias in unambiguous settings is due to the lack of gender information encoded into the non-explicit gender words"
  - [section 3.2]: "We devise a contrastive loss that incorporates gender information into the encoder embeddings"
  - [corpus]: Weak - corpus neighbors focus on gender bias mitigation but don't specifically discuss encoder-side contrastive learning mechanisms
- Break condition: If gender information is not primarily encoded in the encoder or if contrastive learning fails to separate gender representations effectively

### Mechanism 2
- Claim: Target-agnostic debiasing is possible because gender information is language-independent and can be transferred across target languages.
- Mechanism: Fine-tuning the encoder on gender-balanced data for one target language transfers debiasing effects to other target languages that weren't fine-tuned.
- Core assumption: Gender-related information is abstracted in a language-agnostic way in the encoder representations, allowing transfer across languages.
- Evidence anchors:
  - [abstract]: "We also observe that incorporated gender information transfers and benefits other target languages regarding gender accuracy"
  - [section 5.2]: "gender bias mitigation strategies also have a positive effect on the target languages not seen during fine-tuning"
  - [corpus]: Moderate - corpus includes related work on multilingual translation but doesn't specifically address cross-language gender information transfer
- Break condition: If gender information is language-specific or if encoder representations don't abstract gender in a transferable way

### Mechanism 3
- Claim: Knowledge distillation helps maintain translation performance while applying debiasing by keeping the model similar to the original pre-trained model.
- Mechanism: Adding knowledge distillation loss with frozen teacher model during fine-tuning prevents catastrophic forgetting of translation capabilities.
- Core assumption: The original translation model contains valuable knowledge that can be preserved through knowledge distillation while adding gender information.
- Evidence anchors:
  - [section 3.2]: "we train our model with the original machine translation loss to prevent forgetting. We also add knowledge distillation loss"
  - [section 5.4]: "incorporating the knowledge distillation loss LKD helps maintain translation performance"
  - [corpus]: Weak - corpus neighbors discuss various debiasing methods but don't specifically mention knowledge distillation for maintaining translation performance
- Break condition: If knowledge distillation doesn't effectively preserve translation capabilities or if the model forgets too much without it

## Foundational Learning

- Concept: Contrastive learning and supervised contrastive loss
  - Why needed here: The method relies on contrastive learning with gender pseudo-labels to inject gender information into encoder representations
  - Quick check question: How does supervised contrastive loss differ from standard contrastive loss, and why is it appropriate for this gender debiasing task?

- Concept: Gender morphology and morphological analysis
  - Why needed here: The evaluation metrics require detecting gender inflections in target languages, which depends on understanding morphological gender markers
  - Quick check question: What are the key differences in how gender is expressed morphologically across languages like German, French, and Turkish?

- Concept: Knowledge distillation in NLP
  - Why needed here: The method uses knowledge distillation to prevent catastrophic forgetting while fine-tuning for debiasing
  - Quick check question: How does knowledge distillation work in the context of fine-tuning pre-trained models, and what are its benefits for maintaining performance?

## Architecture Onboarding

- Component map: Encoder-decoder architecture with contrastive learning module added to encoder training loop; gender pseudo-label generation module; knowledge distillation component
- Critical path: Data filtering → Gender pseudo-label generation → Contrastive loss computation → Encoder update with contrastive loss + MT loss + KD loss
- Design tradeoffs: Target-agnostic vs. target-specific debiasing (chose target-agnostic for broader applicability), single dropout vs. in-batch samples for contrastive pairs (chose in-batch for better performance)
- Failure signatures: Significant drop in translation performance (catastrophic forgetting), minimal improvement in gender accuracy metrics, performance degradation for low-resource languages
- First 3 experiments:
  1. Run baseline evaluation on WinoMT and MT-GenEval to establish gender bias metrics for the pre-trained model
  2. Fine-tune with only contrastive loss (LGC) to verify if gender information can be encoded without preserving translation
  3. Fine-tune with contrastive loss + MT loss (no KD) to observe catastrophic forgetting and establish baseline degradation

## Open Questions the Paper Calls Out
The paper does not explicitly call out specific open questions, but based on the limitations and scope of the research, several areas remain unexplored that could be considered implicit open questions.

## Limitations
- The evaluation focuses on unambiguous gender cases where there is a single correct translation, which represents a limited scope of the broader gender bias problem in machine translation
- The use of pseudo-labels for gender information introduces potential noise and error propagation that could affect contrastive learning effectiveness
- Experiments primarily demonstrate benefits for a limited set of target languages (German, French, Russian, Turkish), leaving uncertainty about generalization to other language families and scripts

## Confidence

- **High Confidence**: The core mechanism of using contrastive learning to inject gender information into encoder representations is well-supported by the results, showing consistent improvements in gender accuracy across multiple architectures and evaluation datasets.

- **Medium Confidence**: The target-agnostic transfer claim is supported by experimental results but would benefit from broader language coverage and more systematic analysis of which language pairs benefit most from the transfer.

- **Low Confidence**: The scalability and effectiveness of the method for low-resource languages and the impact of pseudo-label quality on contrastive learning performance remain uncertain based on the current experimental scope.

## Next Checks

1. **Ablation Study on Pseudo-Label Quality**: Systematically vary the quality and generation method of gender pseudo-labels to quantify their impact on contrastive learning effectiveness and overall gender accuracy improvements.

2. **Broader Language Family Testing**: Extend experiments to include target languages from different language families (e.g., Asian languages, Semitic languages) to validate the claimed target-agnostic nature across more diverse linguistic structures.

3. **Ambiguous Case Evaluation**: Design and conduct experiments specifically targeting ambiguous gender cases where multiple valid translations exist to assess whether the method can handle the full spectrum of gender bias scenarios in translation.