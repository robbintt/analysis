---
ver: rpa2
title: 'HeteFedRec: Federated Recommender Systems with Model Heterogeneity'
arxiv_id: '2307.12810'
source_url: https://arxiv.org/abs/2307.12810
tags:
- federated
- clients
- learning
- hetefedrec
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HeteFedRec, the first federated recommendation
  framework that enables personalized model sizing for participants. The key challenge
  addressed is that existing federated recommender systems (FedRecs) require all clients
  to collaboratively train a recommendation model of the same size, which leads to
  suboptimal performance since clients possess varying resources such as data amounts
  and computing power.
---

# HeteFedRec: Federated Recommender Systems with Model Heterogeneity

## Quick Facts
- arXiv ID: 2307.12810
- Source URL: https://arxiv.org/abs/2307.12810
- Reference count: 40
- Key outcome: First federated recommendation framework enabling personalized model sizing for participants

## Executive Summary
This paper introduces HeteFedRec, the first federated recommendation framework that enables personalized model sizing for participants. The key challenge addressed is that existing federated recommender systems (FedRecs) require all clients to collaboratively train a recommendation model of the same size, which leads to suboptimal performance since clients possess varying resources such as data amounts and computing power. HeteFedRec allows clients with limited data to train smaller models and clients with abundant data to train larger models, while still enabling effective knowledge sharing among heterogeneous models.

## Method Summary
HeteFedRec divides clients into three groups (small, medium, large) based on interaction numbers. It uses unified dual-task learning, dimensional decorrelation regularization, and relation-based ensemble knowledge distillation to aggregate heterogeneous recommendation models. The framework supports both NCF and LightGCN base models and demonstrates significant improvements over homogeneous and heterogeneous baselines across three real-world recommendation datasets.

## Key Results
- Achieves up to 15.9% and 16.9% improvements in NDCG@20 compared to the best baseline on MovieLens-1M and Anime datasets respectively
- Outperforms all homogeneous and heterogeneous baselines by a significant margin
- Ablation study confirms the importance of each key component in HeteFedRec

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Unified dual-task learning enables effective knowledge aggregation across heterogeneous recommendation models by ensuring submatrices of large embedding tables share the same objective as small embedding tables.
- Mechanism: Each client uses multiple loss terms corresponding to different embedding sizes. For example, a medium client optimizes losses for both its assigned medium embedding and the small embedding sub-matrix, ensuring gradients for different-sized embeddings are trained on the same task.
- Core assumption: Different-sized embeddings can learn complementary information if trained with aligned objectives, and gradients from larger embeddings can improve smaller embeddings through shared loss functions.
- Break condition: If the relationship between embedding dimensions is not task-aligned (e.g., different semantic meanings), the unified objective may create conflicting gradients that prevent convergence.

### Mechanism 2
- Claim: Dimensional decorrelation regularization prevents large item embeddings from degrading to smaller ones during heterogeneous aggregation.
- Mechanism: Adds a regularization term that penalizes the correlation matrix of embedding dimensions, maintaining the importance of each dimension and preventing larger embeddings from collapsing to smaller ones.
- Core assumption: Without explicit regularization, the optimization process will naturally cause larger embeddings to converge toward smaller ones when trained with unified objectives, losing the benefits of larger model capacity.
- Break condition: If the regularization strength is too high, it may prevent useful knowledge transfer between embedding sizes; if too low, dimensional collapse still occurs.

### Mechanism 3
- Claim: Relation-based ensemble knowledge distillation effectively merges knowledge from heterogeneous item embeddings without requiring a public reference dataset.
- Mechanism: Calculates distances between item embeddings of different sizes, creates an ensemble distance by averaging, and uses this ensemble as a distillation target to update all embedding sizes.
- Core assumption: The ensemble spatial information derived from various embedding sizes contains more reliable knowledge than any single embedding size, and distance metrics can capture meaningful relationships in embedding space.
- Break condition: If item embeddings from different sizes represent fundamentally different latent spaces, the ensemble distance may not provide meaningful distillation targets.

## Foundational Learning

- Concept: Federated Learning basics (client-server architecture, local training with global aggregation)
  - Why needed here: HeteFedRec builds directly on federated learning principles but extends them to handle model heterogeneity, so understanding the standard FedAvg protocol is essential
  - Quick check question: In standard federated learning, what parameters are typically kept private versus shared among clients?

- Concept: Knowledge distillation techniques (response-based, feature-based, relation-based)
  - Why needed here: HeteFedRec uses relation-based knowledge distillation specifically designed for heterogeneous models, requiring understanding of different distillation approaches
  - Quick check question: What is the key difference between response-based and relation-based knowledge distillation?

- Concept: Matrix operations and regularization (covariance matrices, Frobenius norm, singular value decomposition)
  - Why needed here: The dimensional decorrelation regularization relies on matrix operations to prevent embedding collapse, requiring understanding of these mathematical concepts
  - Quick check question: How does penalizing the Frobenius norm of a correlation matrix relate to maintaining singular value diversity?

## Architecture Onboarding

- Component map: Central server -> Client groups (Us, Um, Ul) -> Embedding tables (Vs, Vm, Vl) -> Aggregation pipeline -> Communication protocol
- Critical path: Client local training → Upload gradients → Server heterogeneous aggregation → Server knowledge distillation → Download updated parameters → Next round
- Design tradeoffs: Model heterogeneity vs. communication overhead (larger models require more bandwidth), regularization strength vs. convergence speed, client grouping strategy vs. performance balance
- Failure signatures: Poor convergence (check unified dual-task learning), dimensional collapse (verify decorrelation regularization), ineffective distillation (ensure distance calculations correct)
- First 3 experiments: 1) Baseline test with only unified dual-task learning, 2) Regularization sweep for α values, 3) Client grouping validation with different ratios

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal client division strategy to maximize performance in HeteFedRec?
- Basis in paper: [explicit] The paper notes that finding an optimal client division estimation can be explored in future research and shows experimental results for different division ratios (5:3:2, 1:1:1, 2:3:5).
- Why unresolved: The paper acknowledges that determining the optimal division strategy is important but does not provide a method to determine it beyond empirical testing of different ratios.
- What evidence would resolve it: A theoretical framework or heuristic for determining optimal client division ratios based on dataset characteristics, or empirical results showing performance across a wider range of division strategies.

### Open Question 2
- Question: How does HeteFedRec perform when applied to more complex recommendation models beyond NCF and LightGCN?
- Basis in paper: [explicit] The paper demonstrates HeteFedRec's effectiveness using NCF and LightGCN as base models, but explicitly states the need to showcase generalization to other models.
- Why unresolved: The experiments are limited to two specific recommendation models, and it's unclear whether the heterogeneous aggregation strategies would work as effectively with more complex architectures.
- What evidence would resolve it: Experimental results applying HeteFedRec to other popular recommendation models (e.g., Wide&Deep, Transformer-based models) and comparing performance.

### Open Question 3
- Question: What is the optimal model size configuration for different recommendation scenarios and datasets?
- Basis in paper: [explicit] The paper explores different model size settings ({2,4,8}, {8,16,32}, {32,64,128}) and notes that finding an optimal model size set can be explored in future work.
- Why unresolved: While the paper demonstrates that model size affects performance, it does not provide a principled approach for determining optimal sizes beyond empirical testing.
- What evidence would resolve it: A method to automatically determine optimal model sizes based on dataset characteristics, or empirical results showing performance across a broader range of size configurations.

### Open Question 4
- Question: How does HeteFedRec perform in scenarios with extremely imbalanced client data distributions (e.g., power-law distributions)?
- Basis in paper: [inferred] The paper analyzes performance across user groups but doesn't explicitly test with extreme data imbalance scenarios that might better reflect real-world conditions.
- Why unresolved: The experimental setup uses relatively moderate data distribution variations, and it's unclear how the framework would handle scenarios where a small number of clients have vastly more data than others.
- What evidence would resolve it: Experimental results with datasets exhibiting extreme data imbalance (e.g., Zipfian distributions) and comparison of HeteFedRec performance against homogeneous approaches under these conditions.

## Limitations
- Framework assumes clients can be clearly categorized into discrete groups, which may not reflect real-world continuous variations in client capabilities
- Computational overhead of heterogeneous aggregation process compared to standard FedAvg is not explicitly quantified
- Experimental results based on three datasets may not generalize to all recommendation scenarios

## Confidence
- High confidence: The core mechanism of unified dual-task learning and dimensional decorrelation regularization
- Medium confidence: The effectiveness of relation-based ensemble knowledge distillation
- Medium confidence: The scalability claims across different datasets

## Next Checks
1. Test HeteFedRec with different client grouping ratios (1:1:1, 2:3:5) to understand the impact of client distribution on performance
2. Conduct a comprehensive study of the decorrelation regularization strength α to identify optimal values and understand its impact on convergence
3. Evaluate HeteFedRec on datasets with continuous rather than discrete client capabilities to test framework robustness in realistic scenarios