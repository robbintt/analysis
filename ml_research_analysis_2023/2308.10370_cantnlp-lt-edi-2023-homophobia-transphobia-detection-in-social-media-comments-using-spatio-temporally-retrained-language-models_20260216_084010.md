---
ver: rpa2
title: 'cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media Comments
  using Spatio-Temporally Retrained Language Models'
arxiv_id: '2308.10370'
source_url: https://arxiv.org/abs/2308.10370
tags:
- language
- data
- task
- performance
- classi
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addressed homophobia/transphobia detection in social
  media comments across five languages using transformer-based models. The core method
  involved retraining the multilingual XLM-RoBERTa model with spatio-temporally relevant
  social media data from the CGLU corpus, supplemented with simulated script-mixed
  data for some languages.
---

# cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media Comments using Spatio-Temporally Retrained Language Models

## Quick Facts
- arXiv ID: 2308.10370
- Source URL: https://arxiv.org/abs/2308.10370
- Reference count: 1
- One-line primary result: Spatio-temporally retrained XLM-RoBERTa models improved weighted macro F1 scores across five languages for homophobia/transphobia detection, with Malayalam achieving highest performance.

## Executive Summary
This study addresses homophobia/transphobia detection in social media comments across five languages using transformer-based models. The core method involved retraining the multilingual XLM-RoBERTa model with spatio-temporally relevant social media data from the CGLU corpus, supplemented with simulated script-mixed data for some languages. The models were then fine-tuned on labeled training data with class balancing. Results showed consistent improvements in weighted macro F1 scores across all languages when using the retrained models compared to the baseline, with Malayalam achieving the highest performance (0.95 F1, ranked first). However, script-mixed data yielded mixed results—improving Hindi and Malayalam but reducing Tamil performance. The findings demonstrate that register- and language-specific retraining enhances detection accuracy, particularly for underrepresented languages, though script-mixing effects vary by language.

## Method Summary
The method involves retraining the multilingual XLM-RoBERTa model on spatio-temporally relevant social media language data from the CGLU corpus (India, 2019), creating simulated script-mixed data for Hindi, Malayalam, and Tamil, and fine-tuning on labeled training data with class balancing using RandomOverSampler. The approach combines domain adaptation through register-specific retraining with language-specific handling of script variation, followed by standard transformer fine-tuning with oversampling to address class imbalance.

## Key Results
- Spatio-temporally retrained models consistently outperformed baseline across all five languages
- Malayalam achieved highest performance (0.95 weighted macro F1, ranked first)
- Script-mixed data improved Hindi and Malayalam performance but decreased Tamil performance
- Weighted macro F1 scores showed clear improvement over baseline for all languages with CGLU retraining

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retraining XLM-RoBERTa on spatio-temporally relevant social media language data improves classification performance for homophobia/transphobia detection.
- Mechanism: The pretrained model is adapted to the register and linguistic features of social media discourse specific to the geographic and temporal context of the target languages, reducing domain mismatch.
- Core assumption: The language used in social media comments from a specific region and time period is sufficiently similar to the target homophobia/transphobia detection task.
- Evidence anchors:
  - [abstract]: "We retrained a transformer-based cross-language pretrained language model, XLMRoBERTa, with spatially and temporally relevant social media language data."
  - [section]: "We controlled the spatial and temporal window of the sampled tweets by restricting the sample of tweets to those originating in India produced between 1 January 2019 and 31 December 2019."
  - [corpus]: Weak. The corpus signals show related papers focus on social media detection but not specifically on spatio-temporal retraining. No direct citation support for this retraining approach.
- Break condition: If the social media register or temporal context diverges significantly from the target task, the retraining benefit may not materialize.

### Mechanism 2
- Claim: Simulated script-mixed data improves performance for languages like Hindi and Malayalam but not Tamil.
- Mechanism: Romanized script mixing is underrepresented in the original XLM-RoBERTa pretraining; adding it during retraining helps the model handle script variation.
- Core assumption: Script-mixed forms are frequent enough in the target social media data to warrant inclusion in the retraining corpus.
- Evidence anchors:
  - [abstract]: "We also retrained a subset of models with simulated script-mixed social media language data with varied performance."
  - [section]: "A major motivation to retrain the model with the simulated script-mixed retraining data is the lack of Romanised Malayalam in XLM-RoBERTa."
  - [corpus]: Weak. Corpus signals show related work on hate speech detection but no direct evidence about script-mixing performance effects.
- Break condition: If the script-mixed forms do not reflect actual usage in the target data, the added noise could degrade performance.

### Mechanism 3
- Claim: Class balancing via oversampling minority classes improves model robustness for imbalanced homophobia/transphobia detection.
- Mechanism: Synthetic minority over-sampling ensures the model does not ignore rare but important classes such as explicit homophobic or transphobic content.
- Core assumption: Oversampling does not introduce unrealistic synthetic examples that confuse the model.
- Evidence anchors:
  - [section]: "We used the RandomOverSampler class from the library to oversample the minority classes."
  - [corpus]: No direct evidence; the assumption is common in imbalanced classification literature.
- Break condition: If oversampling creates synthetic examples that are too far from real data distribution, it may hurt generalization.

## Foundational Learning

- Concept: Domain adaptation in NLP
  - Why needed here: The study explicitly retrains a general-purpose PLM on task-specific social media data to reduce domain mismatch.
  - Quick check question: What is the main difference between pretraining and retraining in the context of PLMs?

- Concept: Script mixing in multilingual NLP
  - Why needed here: Simulated script-mixed data is used to handle Romanized text in Malayalam and Hindi, which is under-represented in the original model.
  - Quick check question: Why might Romanized script mixing be important for social media text in some languages?

- Concept: Class imbalance handling
  - Why needed here: The training data for homophobia/transphobia detection is highly imbalanced across classes, requiring oversampling to avoid bias toward majority classes.
  - Quick check question: What is a common risk of not addressing class imbalance in classification tasks?

## Architecture Onboarding

- Component map:
  XLM-RoBERTa baseline model -> CGLU social media corpus -> Simulated script-mixed corpus (Hindi, Malayalam, Tamil) -> RandomOverSampler -> Fine-tuning pipeline using simpletransformers

- Critical path: Pretrain -> Retrain with CGLU -> Retrain with script-mixed (optional) -> Oversample -> Fine-tune on labeled data -> Evaluate

- Design tradeoffs:
  - Using a single multilingual model vs. language-specific models: simpler but potentially less optimal per language.
  - Script-mixed data inclusion: improves Hindi/Malayalam but may hurt Tamil; needs per-language tuning.
  - Oversampling vs. other imbalance methods: easier to implement but may introduce synthetic noise.

- Failure signatures:
  - Degraded performance on script-mixed languages when script data is noisy.
  - Overfitting to synthetic minority examples if oversampling is too aggressive.
  - Model collapse if retraining data is too small or unrepresentative.

- First 3 experiments:
  1. Train baseline XLM-RoBERTa on original data; measure weighted macro F1 per language.
  2. Add CGLU retraining only; compare performance gains.
  3. Add script-mixed retraining subset; measure per-language changes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does script-mixing consistently improve model performance across all languages or are there language-specific factors that determine its effectiveness?
- Basis in paper: [explicit] The paper found that script-mixing improved Hindi and Malayalam performance but decreased Tamil performance.
- Why unresolved: The study only tested script-mixing on three languages (Hindi, Malayalam, Tamil) with Hindi showing improvement, Malayalam mixed results, and Tamil decreased performance. The underlying linguistic or technical reasons for these differences were not explored.
- What evidence would resolve it: Systematic testing of script-mixing effects across a wider range of languages with varying linguistic characteristics (phonetic vs logographic scripts, degree of transliteration use in social media, etc.) while controlling for other variables.

### Open Question 2
- Question: How does the performance of spatio-temporally retrained models compare to models retrained with other types of domain-specific data (e.g., topic-specific, register-specific)?
- Basis in paper: [explicit] The paper demonstrates improvements from spatio-temporal retraining but doesn't compare to other domain adaptation approaches.
- Why unresolved: The study only evaluated spatio-temporal retraining without benchmarking against alternative domain adaptation methods that might yield different performance characteristics.
- What evidence would resolve it: Head-to-head comparison of spatio-temporal retraining versus other domain adaptation strategies (topic-specific corpora, register-specific data, etc.) across the same set of languages and tasks.

### Open Question 3
- Question: What is the optimal balance between the amount of retraining data and model performance, particularly for low-resource languages?
- Basis in paper: [inferred] The paper used 50,000 tweets per language for retraining but doesn't explore how performance scales with different amounts of retraining data.
- Why unresolved: The study used a fixed amount of retraining data without investigating the relationship between data volume and performance gains, especially important for resource-constrained scenarios.
- What evidence would resolve it: Systematic experiments varying the amount of retraining data from minimal to maximal while measuring performance changes, particularly focusing on resource-limited languages.

## Limitations
- The effectiveness of spatio-temporal retraining relies heavily on the assumption that the social media register from a specific region and time period is representative of the target detection task, but this is not empirically validated.
- Script-mixing effects are inconsistent across languages—while improving Hindi and Malayalam, they reduce Tamil performance, suggesting language-specific considerations are critical but underexplored.
- Class balancing via oversampling is applied without detailed validation of synthetic example quality, risking overfitting to unrealistic data.

## Confidence
- High confidence: General improvement from retraining on social media data (weighted macro F1 gains observed across all languages).
- Medium confidence: Language-specific effects of script-mixing (improvement for Hindi/Malayalam, degradation for Tamil), due to limited analysis of why effects differ.
- Low confidence: Generalization to other social media tasks or time periods, as the study focuses narrowly on homophobia/transphobia in 2019 Indian social media.

## Next Checks
1. Conduct ablation studies to isolate the contribution of spatio-temporal retraining versus script-mixing versus class balancing on performance.
2. Perform cross-temporal validation by retraining on data from a different year to test robustness of the approach over time.
3. Evaluate the quality and realism of synthetic examples generated during oversampling to ensure they do not introduce noise or bias.