---
ver: rpa2
title: 'Automated speech audiometry: Can it work using open-source pre-trained Kaldi-NL
  automatic speech recognition?'
arxiv_id: '2312.12269'
source_url: https://arxiv.org/abs/2312.12269
tags:
- speech
- test
- kaldi-nl
- decoding
- errors
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an automated speech audiometry setup using
  the open-source Kaldi-NL automatic speech recognition (ASR) system to score spoken
  responses in the Dutch Digits-in-Noise (DIN) test. The authors evaluated Kaldi-NL's
  performance on 30 normal-hearing adults and found an average word error rate (WER)
  of 5.0% (range 0-48%, SD=8.8%), with an average of three decoding errors per participant.
---

# Automated speech audiometry: Can it work using open-source pre-trained Kaldi-NL automatic speech recognition?

## Quick Facts
- arXiv ID: 2312.12269
- Source URL: https://arxiv.org/abs/2312.12269
- Reference count: 0
- Primary result: Kaldi-NL achieves 5.0% WER on Dutch digit triplets, making automated DIN testing feasible

## Executive Summary
This paper presents an automated speech audiometry setup using the open-source Kaldi-NL automatic speech recognition (ASR) system to score spoken responses in the Dutch Digits-in-Noise (DIN) test. The authors evaluated Kaldi-NL's performance on 30 normal-hearing adults and found an average word error rate (WER) of 5.0% (range 0-48%, SD=8.8%), with an average of three decoding errors per participant. A simulation study showed that up to four triplets with decoding errors produce speech reception threshold (SRT) variations within 0.70 dB, matching the typical within-subject SRT variability for normal-hearing adults. These results suggest the automated setup is feasible for clinical applications.

## Method Summary
The study implemented a Python-based DIN test algorithm that integrates the pre-trained Kaldi-NL ASR system. Thirty normal-hearing Dutch adults were tested in a quiet room with fixed 65 dB SPL background noise. The system presented 24 digit-triplets adaptively with 2 dB step sizes, recording spoken responses via an external cardioid microphone. Kaldi-NL decoded the audio to text, and word error rates were calculated by comparing decoded digits to manually annotated reference transcripts. A bootstrapping simulation assessed how decoding errors affected the final SRT measurements.

## Key Results
- Kaldi-NL achieved an average WER of 5.0% (SD=8.8%) on Dutch digit triplets from 30 normal-hearing adults
- The system produced an average of three decoding errors per participant
- Simulation showed that up to four triplets with decoding errors result in SRT variations within 0.70 dB, matching the typical within-subject variability for normal-hearing adults

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Kaldi-NL's low WER (5.0%) on Dutch digit triplets is due to its large vocabulary training data (250k words) from the Spoken Dutch Corpus.
- Mechanism: The ASR system leverages acoustic and language models trained on ~1000 hours of adult Dutch speech across 16 regions, enabling robust digit recognition in quiet conditions.
- Core assumption: The test environment (quiet room, no speaker instructions) and the simplicity of Dutch digits (0-9) make the task similar to ASR training data.
- Evidence anchors:
  - [abstract] "The acoustic and language models used the non-telephone part of the Spoken Dutch Corpus... with recordings of nearly 5000 adult speakers from all educational levels and sexes, as well as from 16 regions across the Netherlands."
  - [section] "Kaldi-NL showed one of the best performances on the NBest BN-NL benchmark set... with around 10% word error rate (WER)."
  - [corpus] Weak—corpus neighbors focus on ASR for hearing assessment but don't validate the specific WER claim for Dutch digits.
- Break condition: Introducing noise, non-native speakers, or children would likely increase WER beyond acceptable clinical limits.

### Mechanism 2
- Claim: The DIN test's adaptive staircase design limits the impact of ASR decoding errors on the final SRT.
- Mechanism: By presenting 24 triplets with 2 dB step sizes and requiring multiple correct responses, the test inherently smooths out occasional recognition errors.
- Core assumption: The adaptive algorithm's redundancy (multiple presentations at varying SNRs) compensates for up to ~3 decoding errors per participant.
- Evidence anchors:
  - [section] "Study 2 showed that up to four triplets with decoding errors produce SRT variations within this range, suggesting that our proposed setup could be feasible for clinical applications."
  - [section] "The reported within-subject variability for young normal-hearing individuals... was 0.70 dB."
  - [corpus] Weak—neighbors discuss ASR in hearing tests but don't address adaptive test design mitigating recognition errors.
- Break condition: If decoding errors cluster in early trials or exceed 4 triplets, SRT accuracy may fall outside the 0.70 dB variability threshold.

### Mechanism 3
- Claim: Using a pre-trained off-the-shelf ASR (Kaldi-NL) without retraining simplifies clinical deployment compared to custom-trained systems.
- Mechanism: Eliminates the need for language model training, feature extraction pipelines, and pronunciation dictionaries specific to the DIN test.
- Core assumption: The test material (digits) is a subset of the ASR's vocabulary, so no domain adaptation is required.
- Evidence anchors:
  - [abstract] "The use of a pre-trained off-the-shelf ASR (e.g., Kaldi-NL) and simpler speech audiometry test materials, such as the digits in the DIN test, avoids such complexity."
  - [section] "The main advantages of the use of Kaldi-NL with the DIN test are the relative simplicity of its implementation and its accessibility."
  - [corpus] Weak—neighbors focus on ASR model improvements, not deployment simplicity.
- Break condition: If test vocabulary expands beyond digits or includes non-native speech, pre-trained models may require retraining.

## Foundational Learning

- Concept: Automatic Speech Recognition (ASR) pipeline
  - Why needed here: Understanding how Kaldi-NL processes audio to text is essential for debugging decoding errors and optimizing microphone placement.
  - Quick check question: What are the three main components of an ASR system, and which one is most likely to fail when background noise increases?

- Concept: Speech reception threshold (SRT) and adaptive testing
  - Why needed here: The DIN test's adaptive algorithm determines how speech level changes based on responses, directly affecting test duration and accuracy.
  - Quick check question: In a 2-down/1-up adaptive paradigm, what happens to the speech level after a correct response versus an incorrect response?

- Concept: Word error rate (WER) calculation
  - Why needed here: WER quantifies ASR performance and is used to determine if the system meets clinical accuracy thresholds.
  - Quick check question: How is WER computed when comparing a reference transcript to an ASR-generated transcript?

## Architecture Onboarding

- Component map:
  - Python test controller → DIN algorithm (adaptive staircase) → Kaldi-NL ASR wrapper → Digit-only transcript processor → Response scorer
  - External: Laptop speakers (65 dB SPL noise), external cardioid mic (16 kHz), Kaldi-NL v0.3 (TDNN-based)

- Critical path:
  1. Present triplet → Record response → Decode with Kaldi-NL → Extract digits → Compare to reference → Update SNR → Repeat
  2. Final SRT = mean SNR of trials 5-24

- Design tradeoffs:
  - Simplicity vs. accuracy: Pre-trained Kaldi-NL avoids retraining but may underperform on non-native speech.
  - Hardware choice: Laptop speakers save calibration effort but limit frequency response below 630 Hz.
  - Scoring strictness: Requiring all three digits correct reduces false positives but may inflate WER.

- Failure signatures:
  - High WER (>20%): Likely due to poor microphone placement, excessive background noise, or non-native speech.
  - SRT drift >0.7 dB: Indicates decoding errors are not being adequately compensated by the adaptive algorithm.
  - System hangs: Kaldi-NL shell scripts may fail if Python environment paths are misconfigured.

- First 3 experiments:
  1. Measure WER on clean speech from native Dutch speakers to establish baseline.
  2. Introduce controlled background noise (e.g., 65 dB SPL cafeteria noise) and measure WER degradation.
  3. Simulate ASR decoding errors in the DIN algorithm and verify SRT remains within 0.7 dB of true value.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well would Kaldi-NL perform with non-native Dutch speakers, considering the system was trained primarily on native Dutch speech data?
- Basis in paper: [explicit] The paper notes that ASR systems are usually trained using speech material from healthy young to middle-aged adults, and speech varies markedly within and between populations. It specifically mentions that "specific tailoring of Kaldi-NL might be required" for non-native speakers.
- Why unresolved: The study only tested native Dutch speakers, so the performance with non-native speakers remains unknown. Different pronunciation patterns, accents, and language processing abilities could significantly affect the system's accuracy.
- What evidence would resolve it: Testing Kaldi-NL with a diverse group of non-native Dutch speakers representing various language backgrounds and proficiency levels, comparing WER results to native speakers, and potentially training the system on multilingual data to improve performance.

### Open Question 2
- Question: Can the DIN test setup be effectively adapted for children, considering their different speech characteristics compared to adults?
- Basis in paper: [explicit] The paper mentions that ASR systems are usually trained on adult speech and that speech varies markedly between populations, including children. It suggests that "specific tailoring of Kaldi-NL might be required" for children.
- Why unresolved: The study only included adults, and children have distinct speech patterns (e.g., different vocal tract lengths, pitch, pronunciation) that could affect the ASR's performance. The adaptive staircase procedure might also need adjustment for children's attention spans and understanding.
- What evidence would resolve it: Conducting a study with children of different age groups, comparing Kaldi-NL's WER and SRT accuracy to adult results, and potentially modifying the ASR system or test parameters to better suit children's speech characteristics.

### Open Question 3
- Question: How would the DIN test setup perform with hearing-impaired individuals, and what adaptations might be necessary?
- Basis in paper: [explicit] The paper notes that "specific tailoring of Kaldi-NL might be required" for different populations, including hearing-impaired individuals. It also references other studies that tested ASR with hearing-impaired listeners but used different speech tests.
- Why unresolved: The study only included self-reported normal-hearing adults, so the performance with hearing-impaired individuals is unknown. Their speech might be affected by their hearing loss, potentially impacting the ASR's ability to accurately decode responses.
- What evidence would resolve it: Testing the DIN setup with hearing-impaired individuals of varying degrees of hearing loss, comparing WER and SRT results to normal-hearing adults, and exploring potential adaptations like speaker adaptation in the ASR system or modified test parameters to accommodate their needs.

## Limitations
- The evaluation was conducted in a controlled laboratory setting with normal-hearing Dutch speakers, so clinical performance with hearing-impaired or non-native speakers remains unknown.
- The reported WER of 5.0% was measured in quiet conditions without speaker instructions, which may not reflect real-world clinical environments.
- The test required an external cardioid microphone and specific hardware setup, which may not be readily available in all clinical settings.

## Confidence
- **High Confidence**: The core finding that Kaldi-NL achieves low WER (5.0%) on Dutch digit triplets in quiet conditions, supported by direct measurement and comparison to reference transcripts.
- **Medium Confidence**: The claim that up to four decoding errors per participant are acceptable for clinical use, based on simulation studies rather than actual clinical trials with diverse populations.
- **Low Confidence**: The assertion that the automated setup will perform similarly in noisy clinical environments or with hearing-impaired patients, as these conditions were not tested.

## Next Checks
1. **Environmental robustness test**: Evaluate WER performance when introducing background noise at 65 dB SPL (cafeteria noise) to simulate realistic clinical waiting room conditions.
2. **Population generalizability test**: Test the automated system with 30 non-native Dutch speakers and 30 hearing-impaired adults to assess performance degradation and determine if WER remains below the 20% threshold for clinical accuracy.
3. **Clinical workflow validation**: Implement the system in a clinical setting with 50 patients, comparing automated SRT measurements against manual scoring to verify that within-subject variability remains within the 0.70 dB threshold and to identify any operational challenges in real-world use.