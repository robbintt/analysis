---
ver: rpa2
title: Generalized Neural Collapse for a Large Number of Classes
arxiv_id: '2310.05351'
source_url: https://arxiv.org/abs/2310.05351
tags:
- softmax
- features
- classes
- classifier
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extends the concept of neural collapse to cases where
  the number of classes is much larger than the feature dimension. It introduces generalized
  neural collapse, where the features and classifier weights maximize the minimum
  one-vs-rest margin.
---

# Generalized Neural Collapse for a Large Number of Classes

## Quick Facts
- arXiv ID: 2310.05351
- Source URL: https://arxiv.org/abs/2310.05351
- Authors: 
- Reference count: 40
- Key outcome: Extends neural collapse to cases where the number of classes exceeds the feature dimension, introducing generalized neural collapse where features and classifier weights maximize the minimum one-vs-rest margin.

## Executive Summary
This paper extends the neural collapse phenomenon to scenarios where the number of classes (K) is much larger than the feature dimension (d), a common situation in language models, retrieval systems, and face recognition applications. The authors introduce a generalized neural collapse (GN C) where the softmax code maximizes the minimum one-vs-rest margin rather than the simplex ETF used in classical neural collapse. They provide both theoretical analysis and empirical validation across multiple datasets, demonstrating that this phenomenon occurs under spherical constraints and small temperature settings. The paper also addresses the class assignment problem arising from non-uniform distances in softmax codes and proposes using class-mean features as classifier weights to reduce training costs.

## Method Summary
The method extends unconstrained feature models to the K >> d regime, enforcing spherical constraints on both features and classifier weights while using cross-entropy loss with small temperature. The theoretical analysis establishes the equivalence between the softmax code and optimal classifier arrangements through connections to the Tammes problem. Empirically, the approach is validated using ResNet18, DenseNet121, and ResNeXt50 architectures on CIFAR100, Tiny-ImageNet, and BUPT-CBFace-50 datasets. The key innovation involves training with spherical constraints and small temperature, then demonstrating that classifier weights align with class-mean features, enabling parameter reduction through the class-mean features (CMF) classifier approach.

## Key Results
- Generalized neural collapse (GN C1, GN C2, GN C3) metrics converge to their theoretical limits under spherical constraints and small temperature
- The softmax code emerges as the optimal arrangement for classifier weights when K > d, maximizing the minimum one-vs-rest margin
- Semantic similarity between classes influences classifier weight assignment, with similar classes tending to be assigned to closer classifier weights
- Class-mean features (CMF) classifier achieves comparable performance to standard training while reducing trainable parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural collapse generalizes to cases where the number of classes is much larger than the feature dimension, and this generalized form is described by the softmax code.
- Mechanism: The softmax code maximizes the minimum one-vs-rest margin, which is a more general definition than the simplex ETF used in classical neural collapse. This allows the phenomenon to occur even when the number of classes exceeds the feature dimension.
- Core assumption: The feature and classifier weights are constrained to lie on a unit sphere, and the temperature parameter in the cross-entropy loss is sufficiently small.
- Evidence anchors:
  - [abstract] This paper extends neural collapse to cases where the number of classes are much larger than the dimension of feature space, which broadly occur for language models, retrieval systems, and face recognition applications. We show that the features and classifier exhibit a generalized neural collapse phenomenon, where the minimum one-vs-rest margins is maximized.
  - [section] We empirically validate the GN C phenomenon on practical DNNs that are trained with a small temperature in the CE loss and subject to spherical constraints on the features and classifiers.
  - [corpus] The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a vertices of a simplex Equiangular Tight Frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We remove NC's key assumption...
- Break condition: If the temperature is not small enough, or if the spherical constraint is not enforced, the generalized neural collapse phenomenon may not occur.

### Mechanism 2
- Claim: The softmax code leads to an implicit regularization effect based on the semantic similarity of classes.
- Mechanism: When the number of classes is larger than the feature dimension, not all pairs of classifier weights are equally distant in the softmax code. This leads to a "class assignment" problem, where similar classes tend to be assigned to closer classifier weights.
- Core assumption: The classes have some inherent semantic similarity or dissimilarity.
- Evidence anchors:
  - [section] We also conduct experiments with the classifier fixed to be one of the three arrangements, and present the results in Figures 4b to 4d. Among them, we observe that the case where Cat and Dog are far apart achieves a testing accuracy of 89.95%, which is lower than the other two cases with testing accuracies of 91.90% and 92.13%. This demonstrates the important role of class assignment to the generalization of DNNs, and that the implicit bias of the learned classifier is benign, i.e., leads to a more generalizable solutions.
  - [corpus] There is a recently discovered and intriguing phenomenon called Neural Collapse: at the terminal phase of training a deep neural network for classification, the within-class penultimate feature means and the associated classifier vectors of all flat classes collapse to the vertices of a simplex Equiangular Tight Frame...
- Break condition: If the classes do not have any semantic similarity or dissimilarity, the implicit regularization effect may not be beneficial.

### Mechanism 3
- Claim: The class-mean features (CMF) classifier can reduce training costs and improve fine-tuning performance.
- Mechanism: The universality of alignment between classifier weights and class-mean features (i.e., GN C3) implies that training the classifier is unnecessary, and the weight can be simply replaced by the class-mean features. This reduces the number of trainable parameters and simplifies the fine-tuning process.
- Core assumption: The class-mean features are a good approximation of the optimal classifier weights.
- Evidence anchors:
  - [section] Our experiments in Section 5 demonstrate that such a strategy achieves comparable performance to classical training methods, and even better out-of-distribution performance than classical fine-tuning methods with significantly reduced parameters.
  - [corpus] How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity...
- Break condition: If the class-mean features are not a good approximation of the optimal classifier weights, or if the number of classes is too large to compute the class-mean features efficiently, the CMF classifier may not be beneficial.

## Foundational Learning

- Concept: Unconstrained Feature Model (UFM)
  - Why needed here: The UFM simplifies the analysis of neural collapse by treating the last-layer features as free optimization variables, allowing for theoretical proofs of the phenomenon.
  - Quick check question: In the UFM, what are the only constraints on the feature matrix H and the classifier weight matrix W?

- Concept: Softmax Code
  - Why needed here: The softmax code is the key concept that generalizes neural collapse to cases with a large number of classes. It describes the optimal arrangement of classifier weights that maximizes the minimum one-vs-rest margin.
  - Quick check question: How does the softmax code differ from the simplex ETF used in classical neural collapse?

- Concept: Tammes Problem
  - Why needed here: The Tammes problem is a related optimization problem that maximizes the minimum one-vs-one distance between points on a unit sphere. It is used in the theoretical analysis of neural collapse to establish the equivalence between the softmax code and the optimal classifier weights.
  - Quick check question: What is the relationship between the Tammes problem and the softmax code in the context of neural collapse?

## Architecture Onboarding

- Component map: Input -> Feature Encoder -> Classifier -> Softmax with small temperature -> Cross-Entropy Loss
- Critical path:
  1. Preprocess the input data (normalization, augmentation)
  2. Pass the data through the feature encoder to obtain the features
  3. Compute the logits by multiplying the features with the classifier weights
  4. Calculate the cross-entropy loss with a small temperature parameter
  5. Backpropagate the gradients and update the feature encoder and classifier weights
  6. Repeat steps 2-5 until convergence

- Design tradeoffs:
  - Feature dimension: A larger feature dimension may improve the separability of classes but also increases the computational cost
  - Temperature parameter: A smaller temperature parameter may lead to a more pronounced neural collapse but also makes the optimization more challenging
  - Spherical constraint: Enforcing a spherical constraint on the features and classifier weights is crucial for the occurrence of generalized neural collapse, but it may also limit the expressiveness of the model

- Failure signatures:
  - If the feature dimension is too small, the classes may not be well-separated, leading to poor classification performance
  - If the temperature parameter is too large, the neural collapse phenomenon may not occur, and the model may not generalize well
  - If the spherical constraint is not enforced, the classifier weights may not align with the class-mean features, leading to suboptimal performance

- First 3 experiments:
  1. Train a ResNet18 on CIFAR100 with a feature dimension of 10 and a small temperature parameter (e.g., 0.1). Measure the GN C1, GN C2, and GN C3 metrics to verify the occurrence of generalized neural collapse
  2. Fix the classifier weights to be the class-mean features and compare the training and fine-tuning performance with the standard approach
  3. Vary the feature dimension and temperature parameter and observe their effects on the GN C metrics and classification accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Is the equivalence between the Tammes problem and the Softmax Code true in general for all K and d?
- Basis in paper: [explicit] Theorem 3.7 states that the equivalence holds if both the Tammes problem and the Softmax Code have no rattlers. Theorem 3.8 proves the equivalence for d=2 and K≤d+1, but the general case remains open.
- Why unresolved: The proof relies on a technical condition (no rattlers) that is only verified for specific cases.
- What evidence would resolve it: A proof showing that the Tammes problem and the Softmax Code always have the same optimal solutions for any K and d, or a counterexample demonstrating their difference.

### Open Question 2
- Question: How does the choice of temperature τ affect the occurrence of Generalized Neural Collapse (GN C)?
- Basis in paper: [explicit] Section 2.2 and Figure 2 show that GN C occurs with small temperature τ, and Figure B.4 demonstrates that GN C2 increases monotonically as τ decreases.
- Why unresolved: The paper does not provide a theoretical analysis of the relationship between temperature and GN C, only empirical observations.
- What evidence would resolve it: A theoretical study establishing the conditions under which GN C occurs as a function of temperature τ.

### Open Question 3
- Question: What is the optimal class assignment strategy for Softmax Codes when K > d+1?
- Basis in paper: [inferred] Section 4 discusses the "assignment problem" arising from the non-uniform distances in Softmax Codes and shows that semantically similar classes are often assigned to closer classifier weights. However, it does not provide a method for finding the optimal assignment.
- Why unresolved: The problem is NP-hard, and the paper only provides empirical observations without a theoretical solution.
- What evidence would resolve it: A method for finding the optimal class assignment that maximizes classification performance or a theoretical analysis of the assignment problem's complexity.

## Limitations
- Limited empirical validation beyond specific datasets and architectures, with broad claims about applicability to language models and face recognition extending beyond presented evidence
- Single experiment on semantic similarity-based class assignment provides suggestive but not conclusive evidence for implicit regularization effects
- Class-mean features classifier not thoroughly validated under challenging real-world conditions including data distribution shifts and noisy labels

## Confidence
- Mechanism 1: Medium confidence - Strong theoretical foundation but limited empirical breadth
- Mechanism 2: Low-Medium confidence - Single experiment provides suggestive but not conclusive evidence
- Mechanism 3: Medium confidence - Promising results but needs more extensive validation

## Next Checks
1. **Cross-Domain Validation:** Test generalized neural collapse on diverse datasets including language models (e.g., BERT embeddings), retrieval systems (e.g., metric learning benchmarks), and face recognition datasets to verify the broad applicability claim.

2. **Semantic Similarity Robustness:** Conduct systematic experiments varying semantic relationships between classes (not just binary pairs) across multiple datasets to establish the reliability of implicit regularization effects.

3. **CMF Classifier Stress Testing:** Evaluate the class-mean features classifier under challenging conditions including few-shot learning scenarios, noisy label settings, and domain shift situations to assess robustness limitations.