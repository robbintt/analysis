---
ver: rpa2
title: 'Detach-ROCKET: Sequential feature selection for time series classification
  with random convolutional kernels'
arxiv_id: '2309.14518'
source_url: https://arxiv.org/abs/2309.14518
tags:
- features
- time
- feature
- rocket
- series
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Time series classification models like ROCKET achieve state-of-the-art
  performance using thousands of random convolutional kernels, but many are redundant
  or non-informative, adding computational overhead and risking overfitting. To address
  this, we propose Sequential Feature Detachment (SFD), a feature selection method
  that prunes non-essential kernels by iteratively training a Ridge classifier and
  removing features with the smallest coefficients.
---

# Detach-ROCKET: Sequential feature selection for time series classification with random convolutional kernels

## Quick Facts
- arXiv ID: 2309.14518
- Source URL: https://arxiv.org/abs/2309.14518
- Authors: 
- Reference count: 40
- Key outcome: Detach-ROCKET reduces model size by 98.9% and increases test accuracy by 0.6% on the largest binary UCR dataset

## Executive Summary
Detach-ROCKET addresses the computational overhead and overfitting risks in time series classification models like ROCKET by proposing a feature selection method called Sequential Feature Detachment (SFD). SFD prunes non-essential features from ROCKET models by iteratively training a Ridge classifier and removing features with the smallest coefficients. This approach can efficiently handle large feature sets without complex hyperparameter tuning. The end-to-end Detach-ROCKET procedure finds the optimal model size by balancing accuracy and feature count on a validation set, significantly improving computational efficiency and interpretability.

## Method Summary
Detach-ROCKET introduces Sequential Feature Detachment (SFD) to prune non-essential features from ROCKET models. SFD iteratively trains a Ridge classifier on the active feature set, ranks features by coefficient magnitude, and removes the lowest 5% of features at each step. This process continues for 150 iterations or until no further improvement is observed. The end-to-end Detach-ROCKET procedure then uses a validation set to evaluate pruned models at different stages and selects the configuration that optimizes a trade-off function between accuracy and feature count. This approach significantly reduces model size while maintaining or improving classification accuracy.

## Key Results
- SFD can produce models with 10% of original features while improving accuracy on UCR archive datasets
- Detach-ROCKET reduces model size by 98.9% on the largest binary UCR dataset
- Detach-ROCKET increases test accuracy by 0.6% while achieving significant model size reduction

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Sequential Feature Detachment (SFD) can identify and remove non-informative features from ROCKET models without complex hyperparameter tuning.
- **Mechanism:** At each pruning step, a Ridge classifier is trained on the active feature set, and features are ranked by the absolute value of their coefficients. The lowest 5% of features are discarded iteratively.
- **Core assumption:** Feature importance correlates with coefficient magnitude in the linear classifier.
- **Evidence anchors:**
  - [abstract] "SFD estimates feature importance using model coefficients and can handle large feature sets without complex hyperparameter tuning."
  - [section] "During each step, a Ridge classifier is trained on the active set of features. The training yields a set of optimal coefficients (θf), each of them associated with one particular active feature."
- **Break condition:** If feature importance does not correlate with coefficient magnitude, or if the features are highly correlated, the method may fail to prune effectively.

### Mechanism 2
- **Claim:** Pruning non-informative features reduces overfitting and improves test accuracy without sacrificing model performance.
- **Mechanism:** By removing redundant or non-informative kernels, the model is less prone to overfitting on the training data, leading to better generalization on unseen data.
- **Core assumption:** Many ROCKET-generated features are redundant or non-informative for the classification task.
- **Evidence anchors:**
  - [abstract] "Due to their random nature, most of the generated features are redundant or non-informative, adding unnecessary computational load and compromising generalization."
  - [section] "Conversely, after 95% feature reduction, there is a noticeable drop in the number of pruned models that outperform the full model."
- **Break condition:** If most features are actually informative, or if the dataset is too small, pruning may lead to underfitting and reduced performance.

### Mechanism 3
- **Claim:** The end-to-end Detach-ROCKET procedure can find the optimal balance between model size and accuracy using a validation set.
- **Mechanism:** Detach-ROCKET uses a validation set to evaluate pruned models at different stages and selects the configuration that optimizes a trade-off function between accuracy and feature count.
- **Core assumption:** A validation set can accurately estimate the generalization performance of pruned models.
- **Evidence anchors:**
  - [abstract] "We also present an end-to-end procedure for determining an optimal balance between the number of features and model accuracy, called Detach-ROCKET."
  - [section] "Evaluation of Detach-ROCKET on the largest binary UCR dataset reveals that it can reduce model size by 98.9%, while delivering an average increase in test accuracy of 0.6%."
- **Break condition:** If the validation set is not representative of the test data, or if the trade-off function is poorly chosen, the optimal model may not generalize well.

## Foundational Learning

- **Concept:** Ridge regression and its relationship to feature importance
  - **Why needed here:** SFD relies on Ridge classifier coefficients to estimate feature importance, so understanding how Ridge regression works and how coefficients relate to feature importance is crucial.
  - **Quick check question:** In Ridge regression, how does the regularization parameter λ affect the magnitude of the coefficients and their interpretability as feature importance?

- **Concept:** Feature selection and its impact on model complexity and generalization
  - **Why needed here:** The core idea of SFD is to prune non-informative features to reduce model complexity and improve generalization, so understanding the trade-offs between model complexity and performance is essential.
  - **Quick check question:** What are the potential risks of removing too many features during the pruning process, and how can these risks be mitigated?

- **Concept:** Time series classification and the ROCKET algorithm
  - **Why needed here:** SFD is specifically designed for ROCKET models, which are used for time series classification, so understanding the ROCKET algorithm and its limitations is important for effectively applying SFD.
  - **Quick check question:** How does the ROCKET algorithm generate features from time series data, and why might many of these features be redundant or non-informative?

## Architecture Onboarding

- **Component map:** Time series data -> ROCKET transformation -> SFD pruning -> Ridge classifier training -> Prediction
- **Critical path:** ROCKET transformation -> SFD pruning -> Ridge classifier training -> Prediction
- **Design tradeoffs:**
  - Aggressive pruning (higher p) leads to faster execution but risks removing informative features
  - Conservative pruning (lower p) is safer but computationally more expensive
  - The choice of the trade-off function in Detach-ROCKET (c parameter) affects the balance between accuracy and model size
- **Failure signatures:**
  - If pruning too aggressively, the model may underfit and perform poorly on the test set
  - If the validation set is not representative, the selected optimal model may not generalize well
  - If the features are highly correlated, SFD may not effectively identify and remove redundant features
- **First 3 experiments:**
  1. Apply SFD to a simple ROCKET model on a small time series dataset and visualize the feature importance ranking
  2. Compare the performance of the pruned model to the full ROCKET model on a validation set to verify the effectiveness of SFD
  3. Experiment with different pruning aggressiveness (p parameter) and observe its impact on model performance and computational cost

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the performance of Detach-ROCKET compare to other leading time series classification methods like InceptionTime or HIVE-COTE when applied to datasets with high complexity or noise?
- **Basis in paper:** [explicit] The paper discusses that while models like InceptionTime and HIVE-COTE are successful, they face scalability issues due to computational requirements. Detach-ROCKET aims to address these limitations by reducing model size and computational load while maintaining accuracy.
- **Why unresolved:** The paper focuses on comparing Detach-ROCKET to ROCKET models and does not provide a direct comparison with other state-of-the-art methods like InceptionTime or HIVE-COTE.
- **What evidence would resolve it:** Experimental results comparing Detach-ROCKET to InceptionTime, HIVE-COTE, and other leading methods on datasets with varying complexity and noise levels would provide insights into its relative performance and scalability.

### Open Question 2
- **Question:** What is the theoretical basis for the effectiveness of Sequential Feature Detachment (SFD) in identifying and pruning non-essential features in ROCKET-based models?
- **Basis in paper:** [inferred] The paper mentions that SFD uses model coefficients to estimate feature importance and can handle large feature sets without complex hyperparameter tuning. However, it does not provide a detailed theoretical explanation for why this approach is effective.
- **Why unresolved:** While the paper demonstrates the practical effectiveness of SFD through experiments, it lacks a comprehensive theoretical analysis of the underlying principles and assumptions that make SFD successful in pruning non-essential features.
- **What evidence would resolve it:** A theoretical analysis of the SFD algorithm, including mathematical proofs or statistical justifications for its effectiveness in feature selection and pruning, would provide a deeper understanding of its principles and limitations.

### Open Question 3
- **Question:** How does the choice of the hyperparameter c in the Detach-ROCKET end-to-end procedure affect the trade-off between model accuracy and feature reduction, and what are the implications for different use cases?
- **Basis in paper:** [explicit] The paper introduces an end-to-end procedure for finding the optimal model size in Detach-ROCKET, which involves a hyperparameter c that controls the trade-off between accuracy and model size. It mentions that smaller values of c favor accuracy while larger values favor size, but does not provide detailed insights into how different choices of c impact the results.
- **Why unresolved:** The paper presents the Detach-ROCKET procedure and mentions the role of the hyperparameter c, but does not explore the specific effects of different c values on the trade-off between accuracy and feature reduction or discuss the implications for different use cases.
- **What evidence would resolve it:** A systematic study of the impact of different c values on the performance of Detach-ROCKET, including sensitivity analysis and visualizations of the accuracy-feature reduction trade-off, would provide insights into the optimal choice of c for different use cases and data characteristics.

## Limitations
- The effectiveness of SFD depends on the assumption that feature importance correlates with Ridge classifier coefficients, which may not hold for all datasets
- The 5% pruning rate and 150-step limit are heuristic choices that may not be optimal across all datasets
- The end-to-end validation procedure's effectiveness depends heavily on having a sufficiently large and representative validation set

## Confidence
- **High confidence:** The SFD mechanism for pruning ROCKET features using Ridge coefficients is well-defined and theoretically sound
- **Medium confidence:** The claim that 10% feature retention can maintain or improve accuracy, as this depends heavily on dataset characteristics
- **Medium confidence:** The 98.9% reduction with 0.6% accuracy improvement on FordB, as this is based on a single dataset result

## Next Checks
1. Test SFD on datasets with known non-linear decision boundaries to assess whether coefficient-based feature importance remains effective
2. Systematically vary the pruning rate (p parameter) and step limit to determine optimal settings across different dataset sizes and characteristics
3. Apply Detach-ROCKET to multiple binary UCR datasets and report variance in performance improvements to assess generalizability of the results