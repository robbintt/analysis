---
ver: rpa2
title: 'Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the
  Case of Information Extraction'
arxiv_id: '2303.04132'
source_url: https://arxiv.org/abs/2303.04132
tags:
- triplets
- rebel
- data
- text
- relation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work proposes a method to generate synthetic training data
  for structured NLP tasks by exploiting asymmetry: prompting a large language model
  (LLM) to generate input text given a target output structure. This allows generating
  high-quality data even for tasks that cannot be solved directly by the LLM.'
---

# Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction

## Quick Facts
- arXiv ID: 2303.04132
- Source URL: https://arxiv.org/abs/2303.04132
- Reference count: 25
- SynthIE models outperform prior state-of-the-art by 57 absolute points in micro-F1 and 79 points in macro-F1

## Executive Summary
This paper introduces a method to generate high-quality synthetic training data for structured NLP tasks by exploiting asymmetry in task difficulty. The key insight is that for tasks with structured outputs, prompting a large language model (LLM) to generate input text from target structures (the inverse task) is often easier than directly extracting structured outputs from text. This approach is demonstrated on closed information extraction (cIE), where synthetic data is generated by sampling coherent triplet sets from a knowledge graph and using an LLM to produce text that expresses these structures. The resulting 1.8M synthetic data points are used to finetune small models (220M and 770M parameters) called SynthIE, which achieve state-of-the-art performance on both synthetic and real test sets, with human evaluation confirming the superior quality of the synthetic data compared to existing datasets.

## Method Summary
The method involves three main steps: (1) Construct a knowledge graph by filtering Wikidata to create entity and relation catalogs, (2) Sample coherent triplet sets using random walk with backtracking and aggressive reweighting to ensure uniform coverage of relations and entities, and (3) Generate synthetic text by prompting an LLM to produce text that expresses the sampled triplet structures. The synthetic data is then used to finetune Flan-T5 models using teacher forcing and constrained beam search inference with entity/relation validation. The approach is specifically applied to closed information extraction, where the goal is to extract structured triplets (subject, relation, object) from text.

## Key Results
- SynthIE models achieve 57 absolute points improvement in micro-F1 and 79 points in macro-F1 over prior state-of-the-art
- Synthetic test set accuracy reaches 56.2% compared to 4.4% on REBEL dataset
- Human evaluation shows synthetic data has significantly higher precision and recall than REBEL annotations
- Zero-shot transfer to REBEL achieves 29.2% micro-F1 compared to 12.4% for existing models

## Why This Works (Mechanism)

### Mechanism 1
Reversing structured output tasks makes them easier for LLMs to handle. For structured output tasks Y, the inverse task (Y→X) is often easier for LLMs than the forward task (X→Y), even when the forward task is too complex for the LLM to solve directly. This works because LLMs are better at generating plausible input text from a target structure than at directly extracting structured outputs from text.

### Mechanism 2
Synthetic data quality depends on controlling the distribution of output structures. By sampling coherent triplet sets from a knowledge graph with uniform coverage using random walk with backtracking and aggressive reweighting, the synthetic data generation process creates high-quality training pairs where the text faithfully expresses the target structure.

### Mechanism 3
Synthetic data can overcome dataset quality issues in real-world annotations. Human evaluation reveals that REBEL has 70% of information in text not present in target triplets and 45% of target triplets not expressed in text, while synthetic data has much higher precision and recall, providing better training signal than noisy real-world annotations.

## Foundational Learning

- Concept: Task inversion for structured output problems
  - Why needed here: Understanding that some structured output tasks can be reformulated as input generation tasks is the core insight enabling synthetic data generation for problems LLMs cannot solve directly
  - Quick check question: Given a structured output task Y, how would you determine if the inverse task (Y→X) is feasible for an LLM?

- Concept: Knowledge graph sampling for uniform coverage
  - Why needed here: The quality of synthetic data depends critically on sampling coherent triplet sets that cover all relations uniformly, which requires understanding random walk with backtracking and aggressive reweighting strategies
  - Quick check question: Why does uniform edge sampling from a knowledge graph fail to produce coherent triplet sets?

- Concept: Output linearization strategies for sequence models
  - Why needed here: Converting set-structured outputs to sequence format requires choosing between fully expanded (FE) and subject-collapsed (SC) linearizations, each with tradeoffs in sequence length and model complexity
  - Quick check question: What are the advantages and disadvantages of fully expanded versus subject-collapsed linearization for structured output tasks?

## Architecture Onboarding

- Component map: Knowledge graph construction -> Triplet sampling -> Text generation -> Model training -> Evaluation
- Critical path: Triplet sampling → Text generation → Model training → Evaluation
- Design tradeoffs:
  - Sampling bias vs. coherence: Higher bias factor creates more coherent triplet sets but reduces diversity
  - Generation parameters: Temperature and top-p control creativity vs. faithfulness
  - Linearization method: FE vs. SC affects sequence length and model performance
  - Model size: 220M vs 770M parameters trade off efficiency vs. performance
- Failure signatures:
  - Poor coherence in generated text: Indicates issues with triplet sampling or LLM prompting
  - Low precision/recall on test sets: Suggests problems with text generation faithfulness or model training
  - Performance gap between training and test: May indicate overfitting or distribution shift
- First 3 experiments:
  1. Test different bias factors (1, 3, 7, 10) in triplet sampling to find optimal coherence-diversity tradeoff
  2. Compare zero-shot vs few-shot prompting with different demonstration formats for text generation
  3. Evaluate FE vs SC linearization on a small synthetic dataset to measure impact on model performance

## Open Questions the Paper Calls Out

### Open Question 1
How does the quality of synthetic data vary when using different large language models (LLMs) for the generation process? The paper uses code-davinci-002 and text-davinci-003 models but only briefly mentions their differences without detailed comparison of synthetic data quality.

### Open Question 2
How does the performance of SynthIE models change when trained on larger synthetic datasets? The paper mentions 1.8M training samples but doesn't explore the impact of training on even larger synthetic datasets.

### Open Question 3
How does the synthetic data generation approach perform on other structured NLP tasks beyond closed information extraction? The paper mentions potential applications to entity linking, open information extraction, and AMR parsing but doesn't provide experiments or results for these tasks.

## Limitations

- The approach requires access to a comprehensive knowledge graph and may not generalize well to domains with limited structured knowledge
- Synthetic data generation quality is highly dependent on the LLM's ability to generate coherent text from structured inputs
- The method may struggle with tasks requiring complex reasoning or understanding of implicit information not easily expressed in structured formats

## Confidence

High Confidence: The core insight that structured output tasks can be reversed for synthetic data generation is well-supported by experimental results and aligns with established LLM capabilities.

Medium Confidence: The KG sampling methodology is technically sound but lacks hyperparameter sensitivity analysis and relies on a single knowledge graph.

Medium Confidence: The human evaluation showing REBEL's annotation quality issues is compelling but would benefit from additional validation across multiple annotator pools.

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Systematically vary the bias factor, dampening parameter d, and frequency of reweighting recomputation to establish the stability of synthetic data quality and downstream model performance across different sampling configurations.

2. **Cross-Domain Generalization Test**: Evaluate SynthIE models trained on synthetic data from one knowledge domain on test sets from completely different knowledge bases or domains to assess the generality of the synthetic data generation approach.

3. **Generation Parameter Ablation**: Conduct controlled experiments varying LLM generation parameters (temperature, top_p, frequency_penalty, presence_penalty) to quantify their impact on synthetic data quality and downstream model performance, establishing optimal settings for different task types.