---
ver: rpa2
title: 'Computation-efficient Deep Learning for Computer Vision: A Survey'
arxiv_id: '2308.13998'
source_url: https://arxiv.org/abs/2308.13998
tags:
- pages
- networks
- deep
- efficient
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper provides a comprehensive survey of computation-efficient
  deep learning techniques for computer vision, focusing on methods that maintain
  high accuracy while reducing computational costs. The survey systematically reviews
  four key areas: 1) design of lightweight backbone networks, 2) task-specialized
  efficient models, 3) model compression techniques, and 4) efficient hardware deployment
  strategies.'
---

# Computation-efficient Deep Learning for Computer Vision: A Survey

## Quick Facts
- arXiv ID: 2308.13998
- Source URL: https://arxiv.org/abs/2308.13998
- Reference count: 40
- This paper provides a comprehensive survey of computation-efficient deep learning techniques for computer vision, focusing on methods that maintain high accuracy while reducing computational costs.

## Executive Summary
This survey systematically reviews computation-efficient deep learning techniques for computer vision, covering four key areas: lightweight backbone network design, task-specialized efficient models, model compression approaches, and hardware deployment strategies. The paper examines both static and dynamic network architectures, automatic architecture search methods, and various compression techniques including pruning, quantization, and knowledge distillation. It identifies key challenges and future research directions in developing efficient models that maintain high accuracy while reducing computational costs.

## Method Summary
The survey follows a literature review methodology, systematically categorizing over 40 referenced papers across four main areas of efficient deep learning. The approach involves extracting key contributions from each paper, organizing them into a coherent framework based on architectural design principles, compression techniques, and deployment considerations. The survey provides cross-references between related work and identifies open challenges, though specific selection criteria for paper inclusion are not explicitly detailed.

## Key Results
- Comprehensive framework for understanding computation-efficient deep learning techniques across four major categories
- Systematic analysis of how static and dynamic architectures achieve efficiency through architectural optimization
- Identification of model compression as orthogonal approaches (pruning, quantization, knowledge distillation) that can be combined
- Discussion of challenges in bridging the gap between theoretical efficiency and practical deployment

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Efficient backbone networks achieve high accuracy while minimizing computational cost by optimizing both micro-architecture (individual layers/operators) and macro-architecture (system-level organization).
- **Mechanism:** The survey systematically reviews how efficient ConvNets replace dense connections with split-transform-merge strategies, which reduce computational complexity by processing lower-dimensional embeddings separately and merging them. At the macro level, works like RegNets and EfficientNets propose principles for depth-width relationships and compound scaling.
- **Core assumption:** That optimizing individual components and their organization can achieve significant efficiency gains without sacrificing accuracy.
- **Evidence anchors:**
  - [abstract] "This review offers an extensive analysis of this rapidly evolving field by examining four key areas: 1) the development of static or dynamic light-weighted backbone models for the efficient extraction of discriminative deep representations"
  - [section 2.1.1] "Many works seek to attain higher computational efficiency by improving them. Notably, these works usually serve as off-the-shelf plug-in components"
  - [corpus] Weak evidence - neighbor papers don't directly address backbone architecture efficiency mechanisms
- **Break Condition:** If the split-transform-merge strategy introduces information bottlenecks that cannot be compensated by other architectural improvements.

### Mechanism 2
- **Claim:** Dynamic neural networks adapt their architecture/parameters to different inputs, reducing redundant computation on "easy" samples.
- **Mechanism:** The survey categorizes dynamic networks into sample-wise (dynamic depth/width/dynamic routing), spatial-wise (pixel/region/resolution-level adaptation), and temporal-wise (dynamic recurrent models/key frame sampling) approaches. Each adapts computation based on input complexity.
- **Core assumption:** That different samples have varying complexity and can be processed with adaptive computation.
- **Evidence anchors:**
  - [abstract] "developing dynamic networks is an important emerging research direction for improving computational efficiency"
  - [section 3.1] "networks with dynamic depth process each sample xi with an adaptive number of layers"
  - [corpus] Weak evidence - neighbor papers don't discuss dynamic network mechanisms
- **Break Condition:** If the overhead of determining which computations to skip exceeds the savings from skipping them.

### Mechanism 3
- **Claim:** Model compression techniques (pruning, quantization, knowledge distillation) can significantly reduce inference costs while maintaining accuracy.
- **Mechanism:** The survey reviews network pruning (removing channels/filters/connections), quantization (reducing bit representation), and knowledge distillation (transferring knowledge from large to small models). These orthogonal approaches can be combined for maximum effect.
- **Core assumption:** That deep networks contain redundancy that can be removed without significant accuracy loss.
- **Evidence anchors:**
  - [abstract] "many algorithms have been proposed to compress relatively large models with minimal accuracy loss"
  - [section 5.1] "Network pruning is one of the most prevalent techniques for reducing the size of a deep learning model by eliminating inadequate components"
  - [corpus] Weak evidence - neighbor papers don't directly address model compression mechanisms
- **Break Condition:** If aggressive compression leads to irregular network architectures that perform poorly on practical hardware.

## Foundational Learning

- **Concept: Computational complexity analysis**
  - Why needed here: Understanding FLOPs, latency, and memory requirements is crucial for evaluating efficiency improvements
  - Quick check question: Can you calculate the theoretical speedup from replacing a dense layer with a depthwise separable convolution?

- **Concept: Neural architecture search (NAS)**
  - Why needed here: Many efficient architectures are discovered through automated search rather than manual design
  - Quick check question: What's the difference between discrete and differentiable NAS, and why does it matter for efficiency?

- **Concept: Vision transformer fundamentals**
  - Why needed here: Modern efficient architectures often combine CNNs and Transformers
  - Quick check question: How does self-attention work in ViTs, and why is it computationally expensive?

## Architecture Onboarding

- **Component map:** Backbone networks (static/dynamic) → Task-specific heads → Model compression → Hardware deployment
- **Critical path:** Efficient backbone design → Task-specific optimization → Compression → Hardware-aware deployment
- **Design tradeoffs:**
  - Theoretical vs. practical efficiency (FLOPs vs. actual latency)
  - Accuracy vs. speed (often non-linear relationship)
  - Flexibility vs. specialization (general backbones vs. task-specific models)
- **Failure signatures:**
  - High theoretical efficiency but poor practical performance (irregular architectures)
  - Significant accuracy drop after compression
  - Dynamic networks that are slower than static counterparts due to overhead
- **First 3 experiments:**
  1. Implement a basic split-transform-merge block and compare with dense layer on a small dataset
  2. Apply channel pruning to a pretrained model and measure accuracy-latency tradeoff
  3. Implement a simple dynamic depth network and evaluate early exiting performance on easy/hard samples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design efficient, general-purpose backbone networks that effectively extract discriminative representations from raw inputs while maintaining computational efficiency?
- Basis in paper: [explicit] The paper states this is a critical cornerstone for practical deep learning applications and identifies it as a significant challenge.
- Why unresolved: While the paper reviews various techniques for designing efficient backbones, there is no definitive solution that universally works across all vision tasks and input types.
- What evidence would resolve it: A comprehensive evaluation showing a backbone architecture that consistently achieves state-of-the-art performance across multiple vision tasks (image classification, object detection, semantic segmentation, etc.) while maintaining significantly lower computational costs than existing solutions.

### Open Question 2
- Question: How can we develop task-specialized models that streamline multi-stage visual tasks (like two-stage object detection) into end-to-end paradigms without significant performance compromises?
- Basis in paper: [explicit] The paper identifies the streamlining of multi-stage visual tasks as an important research challenge, particularly mentioning the need to remove time-consuming components like non-maximum suppression.
- Why unresolved: While some progress has been made in end-to-end object detection, many vision tasks still rely on multi-stage approaches that are computationally intensive. Creating truly efficient end-to-end solutions remains challenging.
- What evidence would resolve it: A demonstrated framework that can handle multiple complex vision tasks (e.g., object detection, instance segmentation, and pose estimation) in an end-to-end manner with performance comparable to or better than state-of-the-art multi-stage approaches while significantly reducing computational costs.

### Open Question 3
- Question: How can we leverage large-scale training data to improve the performance of computationally efficient models, particularly in self-supervised learning scenarios?
- Basis in paper: [explicit] The paper notes that current efficient models struggle to capitalize on large-scale training data to the same extent as larger models, both in supervised and self-supervised learning scenarios.
- Why unresolved: The paper highlights that while large models show remarkable scalability with increasing data, efficient models with fewer parameters typically show inferior improvements when pre-trained on expansive datasets.
- What evidence would resolve it: Empirical results demonstrating that an efficient model can achieve performance gains comparable to large models when trained on massive datasets (e.g., JFT-300M or larger), particularly in self-supervised learning scenarios where the gap is most pronounced.

## Limitations

- Coverage focuses primarily on mainstream approaches, potentially underrepresenting emerging or niche techniques
- Many efficiency claims are based on reported results without independent verification of experimental setups
- Limited discussion of real-world deployment challenges such as power consumption and thermal constraints

## Confidence

- High confidence in the systematic categorization framework and identification of major research directions
- Medium confidence in reported efficiency metrics due to potential inconsistencies in measurement methodologies across cited works
- Low confidence in the completeness of coverage for dynamic network approaches, which represent an emerging and rapidly evolving research area

## Next Checks

1. Select 5 representative efficient architectures from different categories and independently reproduce their reported accuracy-efficiency tradeoffs on standardized benchmarks
2. Analyze the gap between theoretical FLOPs reduction and actual latency improvement across 3 hardware platforms (CPU, GPU, mobile)
3. Investigate the robustness of compressed models to domain shift by testing across 2-3 related but distinct datasets within the same task domain