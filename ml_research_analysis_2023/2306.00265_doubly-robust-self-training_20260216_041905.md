---
ver: rpa2
title: Doubly Robust Self-Training
arxiv_id: '2306.00265'
source_url: https://arxiv.org/abs/2306.00265
tags:
- labeled
- loss
- data
- robust
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a novel doubly robust loss function for self-training
  in semi-supervised learning. The key idea is to design a loss that balances between
  two extremes: when pseudo-labels are incorrect, the method reduces to using labeled
  data only, while when pseudo-labels are accurate, it effectively increases the sample
  size by incorporating all data.'
---

# Doubly Robust Self-Training

## Quick Facts
- arXiv ID: 2306.00265
- Source URL: https://arxiv.org/abs/2306.00265
- Reference count: 40
- This paper proposes a novel doubly robust loss function for self-training in semi-supervised learning.

## Executive Summary
This paper introduces a doubly robust loss function for self-training that addresses the challenge of pseudo-label noise in semi-supervised learning. The method draws inspiration from causal inference and missing data inference, creating a loss that balances between two extremes: when pseudo-labels are incorrect, it reduces to using labeled data only, while when pseudo-labels are accurate, it effectively increases the sample size by incorporating all data. Through empirical evaluations on ImageNet and nuScenes datasets, the authors demonstrate consistent improvements over standard self-training baselines in both image classification and 3D object detection tasks.

## Method Summary
The doubly robust self-training method combines a teacher model, student model, labeled and unlabeled datasets, and a novel doubly robust loss function. The loss function is designed to be unbiased when either the importance weights or the teacher model's predictions are accurate, providing a doubly robust estimator. The method uses curriculum-based loss with linear or quadratic growth of αt to address training instability. The approach handles distribution mismatch between labeled and unlabeled datasets through importance weighting, and demonstrates consistent improvements across different network architectures and dataset sizes.

## Key Results
- On ImageNet100 with 20% labeled data, achieves 5.5% gain in top-1 accuracy over baseline
- On ImageNet100 with 80% labeled data, achieves 5.3% gain in top-1 accuracy over baseline
- Shows consistent improvements across ResNet-50 and PointPillars architectures
- Outperforms standard self-training baselines in both image classification and 3D object detection tasks

## Why This Works (Mechanism)

### Mechanism 1
When pseudo-labels are accurate, the method effectively increases the sample size by incorporating all data. The doubly robust loss removes the labeled data penalty and treats all samples uniformly, reducing to an empirical risk minimizer over the full dataset when the pseudo-labels are perfect. This works under the assumption that covariate distributions of labeled and unlabeled datasets match, and the teacher model's predictions are accurate. The method breaks when covariate distributions do not match or teacher model predictions are significantly biased.

### Mechanism 2
When pseudo-labels are incorrect, the method reduces to using labeled data only. The difference between the first two terms of the loss vanishes as the labeled samples come from the same distribution as the unlabeled samples, focusing only on the labeled dataset. This mechanism assumes covariate distributions match and teacher model predictions are poor. The method breaks when covariate distributions do not match or teacher model predictions are systematically biased.

### Mechanism 3
The estimator is consistent and doubly robust, meaning it is always consistent no matter whether the teacher model is accurate or not. The loss function is designed such that it is unbiased when either the importance weights or the teacher model's predictions are accurate, providing a doubly robust estimator. This requires either the importance weights to be correctly specified or the teacher model's predictions to be accurate. The method breaks when both the importance weights and the teacher model's predictions are significantly inaccurate.

## Foundational Learning

- Concept: Causal inference and missing data inference
  - Why needed here: The paper draws inspiration from doubly robust estimation in causal inference to design a loss function that is consistent even when the teacher model is inaccurate.
  - Quick check question: What is the key property of a doubly robust estimator in causal inference?

- Concept: Semi-supervised learning
  - Why needed here: The paper addresses the problem of learning from a small labeled dataset and a large unlabeled dataset, which is a fundamental problem in semi-supervised learning.
  - Quick check question: What are the main challenges in semi-supervised learning, and how does self-training address them?

- Concept: Importance weighting
  - Why needed here: The paper introduces an importance weight π(x) to handle the case when the labeled and unlabeled datasets have different distributions.
  - Quick check question: How does importance weighting help in handling distribution mismatch between labeled and unlabeled datasets?

## Architecture Onboarding

- Component map: Teacher model -> Pseudo-labels -> Doubly robust loss -> Student model update
- Critical path: Generate pseudo-labels using teacher model → Compute doubly robust loss → Update student model
- Design tradeoffs: Balance between teacher model accuracy and unlabeled dataset size; tradeoff between stability and effectiveness
- Failure signatures: Instability during training, poor performance when both importance weights and teacher predictions are inaccurate, distribution mismatch issues
- First 3 experiments:
  1. Implement the doubly robust loss function and verify that it reduces to the labeled-only loss when the teacher model is inaccurate.
  2. Implement the doubly robust loss function and verify that it increases the effective sample size when the teacher model is accurate.
  3. Implement the doubly robust loss function with importance weights and verify that it handles distribution mismatch between labeled and unlabeled datasets.

## Open Questions the Paper Calls Out

### Open Question 1
What is the theoretical justification for using curriculum-based loss in practical applications of doubly robust self-training? The paper mentions that directly minimizing the doubly robust loss with stochastic gradient can lead to instability, and proposes using a curriculum-based loss instead. This remains unresolved as the paper does not provide a rigorous theoretical analysis of why curriculum-based loss would be more stable or effective than the original doubly robust loss.

### Open Question 2
How does the performance of doubly robust self-training scale with the size of the unlabeled dataset? The paper states that when the predictor is accurate, the doubly robust loss increases the effective sample size by incorporating all data, implying potential benefits from larger unlabeled datasets. This remains unresolved as the paper does not provide empirical results showing how the performance changes as the size of the unlabeled dataset varies.

### Open Question 3
Can the doubly robust loss function be extended to handle more complex prediction tasks beyond classification and object detection? The paper focuses on image classification and 3D object detection tasks but does not discuss the applicability of the doubly robust loss to other domains. This remains unresolved as the paper does not explore the potential of the doubly robust loss in other areas such as natural language processing, speech recognition, or recommendation systems.

## Limitations

- Theoretical claims rely heavily on assumptions about covariate distribution matching that may not hold in real-world scenarios
- Empirical validation is limited to specific datasets (ImageNet variants and nuScenes) and architectures (ResNet-50 and PointPillars)
- Ablation studies for hyperparameter sensitivity are not comprehensive, particularly regarding the curriculum-based αt parameter and importance weight π(x)
- Does not address potential failure modes when both teacher model and importance weights are inaccurate simultaneously

## Confidence

**High confidence** in the core mathematical formulation of the doubly robust loss and its theoretical properties. The mechanism showing how the loss reduces to labeled-only training when pseudo-labels are poor is well-supported by the derivation.

**Medium confidence** in the practical effectiveness, as the empirical results show consistent improvements but with varying magnitudes across different settings. The 5.5% and 5.3% gains on ImageNet100 are significant but need replication on diverse datasets.

**Low confidence** in the scalability and robustness claims, as the paper does not test on larger-scale datasets or with more challenging distribution mismatches. The assumption of covariate distribution matching is critical but not thoroughly validated.

## Next Checks

1. **Distribution mismatch stress test**: Evaluate the method on datasets with deliberately mismatched covariate distributions between labeled and unlabeled data to test the importance weighting mechanism under realistic conditions.

2. **Teacher model failure analysis**: Systematically vary the quality of the teacher model (from excellent to random) and measure how the doubly robust loss performs compared to baselines, particularly focusing on the transition region where the teacher is neither excellent nor random.

3. **Ablation study on curriculum parameter**: Conduct a comprehensive hyperparameter sweep on the αt curriculum parameter, including non-linear schedules and adaptive methods, to identify optimal settings across different dataset sizes and architectures.