---
ver: rpa2
title: Multiscale Feature Attribution for Outliers
arxiv_id: '2310.20012'
source_url: https://arxiv.org/abs/2310.20012
tags:
- spectrum
- attribution
- feature
- baseline
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of feature attribution for detected
  outliers in galaxy spectra, aiming to automatically identify which spectral features
  make an input anomalous without human intervention. The authors propose Inverse
  Multiscale Occlusion (IMO), a new feature attribution method specifically designed
  for outliers where the type of anomalous features is unknown and model performance
  is questionable due to the input being outside the training distribution.
---

# Multiscale Feature Attribution for Outliers

## Quick Facts
- arXiv ID: 2310.20012
- Source URL: https://arxiv.org/abs/2310.20012
- Reference count: 3
- This paper proposes Inverse Multiscale Occlusion (IMO) for feature attribution in outlier detection, successfully identifying both calibration problems and double-peaked emission lines in a DESI spectrum.

## Executive Summary
This paper addresses the challenge of feature attribution for detected outliers in galaxy spectra, where traditional attribution methods fail because the input is outside the training distribution. The authors propose Inverse Multiscale Occlusion (IMO), a novel method that uses multiple baseline spectra redshifted to match the input, performing occlusion with variable window sizes to detect both localized and broad anomalies. When applied to a DESI Bright Galaxy Survey outlier spectrum showing both a large-scale calibration problem and double-peaked emission lines, IMO successfully identifies both anomalies - the calibration offset is detected by moderate window sizes while the double-peaked emission lines produce the highest attribution scores, particularly with small window sizes.

## Method Summary
The method creates occluded spectra by replacing segments from baseline spectra (redshifted to match the input) with corresponding segments from the input spectrum. Attribution scores are calculated as the difference in model output probability between the baseline and occluded spectra. The multiscale approach uses multiple window sizes (W = 1, 4, 16, 64, 256, 1024) to capture different scales of anomalies. Results are combined across window sizes using a minimum-variance weighting scheme that emphasizes the most significant discrepancies. The method is specifically designed for outlier detection where model performance is questionable due to inputs being outside the training distribution.

## Key Results
- Successfully identified both large-scale calibration problems and localized double-peaked emission lines in a DESI outlier spectrum
- IMO outperformed gradient-based methods and standard occlusion approaches in detecting and localizing anomalous features
- Small window sizes (W=1,4) were most effective at detecting double-peaked emission lines, while moderate window sizes detected the calibration problem
- The minimum-variance weighting scheme effectively combined attributions across different scales

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Inverse Multiscale Occlusion (IMO) successfully identifies anomalous features in outlier spectra by comparing occluded versions to a baseline spectrum at the same redshift.
- Mechanism: The method creates occluded spectra by replacing segments from a baseline spectrum (redshifted to match the input) with corresponding segments from the input spectrum. The attribution score is calculated as the difference in model output probability between the baseline and occluded spectra. This approach is more robust for outliers because the baseline is typically not anomalous, making the occluded vector likely in the region of good model performance.
- Core assumption: The model's performance is reasonable when applied to non-anomalous spectra, and the baseline spectra can be properly redshifted to match the input spectrum.
- Evidence anchors:
  - [abstract] "IMO uses multiple baseline spectra (randomly sampled from the dataset) that are redshifted to match the input spectrum, then performs occlusion with variable window sizes to detect both localized and broad anomalies."
  - [section 3] "We therefore perform 'inverse occlusion', which replaces a segment of length W, centered at position i, of the baseline spectrum xb with the corresponding segment of the input spectrum to form the modified spectrum ˆxWi, and use the probability of the baseline, rather than the input spectrum, as the reference."

### Mechanism 2
- Claim: The multiscale approach with variable window sizes allows detection of both localized and broad anomalous features without requiring prior knowledge of feature types.
- Mechanism: By performing occlusion with multiple window sizes (W = 1, 4, 16, 64, 256, 1024), the method captures different scales of anomalies. Small windows detect localized features like double-peaked emission lines, while large windows detect broad features like calibration problems across entire spectral arms.
- Core assumption: Anomalous features in galaxy spectra can vary significantly in spatial extent, and different window sizes will emphasize different types of anomalies.
- Evidence anchors:
  - [abstract] "IMO uses multiple baseline spectra...then performs occlusion with variable window sizes to detect both localized and broad anomalies."
  - [section 3] "Taking inspiration from wavelet filtering, we perform occlusion with variable window sizes, i.e., we get IMOW for each choice of window size W. Smaller window sizes respond to local features, while larger windows sizes are sensitive to broad or even global features."

### Mechanism 3
- Claim: The minimum-variance weighting scheme across baselines and window sizes produces a robust combined attribution score that emphasizes the most significant discrepancies.
- Mechanism: The method combines attributions across window sizes using a weighted sum where weights are inversely proportional to the variance across baselines: IMO = ΣW(IMOW ⊙ σ−2W) / ΣW σ−2W. This emphasizes, at every location, the window size for which the most significant discrepancies are found in the ensemble.
- Core assumption: Variance across baselines is a good indicator of the reliability of attribution scores, and combining across window sizes appropriately weights different scales of anomalies.
- Evidence anchors:
  - [abstract] "The method combines attributions across window sizes using a minimum-variance weighting scheme."
  - [section 3] "The use of an ensemble of baselines B also enables us to form a single feature attribution result as the minimum-variance combination across all window sizes"

## Foundational Learning

- Concept: Redshift correction for spectral comparison
  - Why needed here: Galaxy spectra from different redshifts have their spectral features stretched by different amounts, so baselines must be redshifted to match the input spectrum for meaningful comparison.
  - Quick check question: How would you transform a spectrum observed at redshift z=0.1 to match the rest-frame wavelength scale?

- Concept: Autoencoder latent space representation
  - Why needed here: The outlier detection model uses an autoencoder to compress spectra into a low-dimensional latent space, and the feature attribution methods operate on the model's output probabilities in this space.
  - Quick check question: What information is preserved and what is lost when compressing a high-dimensional spectrum into a low-dimensional latent representation?

- Concept: Normalizing flow probability estimation
  - Why needed here: The model uses a normalizing flow in the latent space to determine objects that have low probability relative to the rest of the data, which is the basis for identifying outliers.
  - Quick check question: How does a normalizing flow model estimate the probability density of data points in a latent space?

## Architecture Onboarding

- Component map:
  Input spectrum preprocessing -> Redshift correction module -> Multiple baseline sampling -> Inverse occlusion engine (with variable window sizes) -> Model probability evaluation -> Variance calculation -> Weighted combination -> Attribution output

- Critical path:
  1. Load input spectrum and its redshift
  2. Sample M baseline spectra from dataset
  3. Redshifted baselines to input redshift
  4. For each window size W and baseline:
     - Create occluded spectra by replacing segments
     - Compute model probabilities for baseline and occluded versions
     - Calculate attribution scores
  5. Compute variance across baselines for each window size
  6. Apply minimum-variance weighting to combine across window sizes
  7. Output combined attribution map

- Design tradeoffs:
  - Multiple baselines vs. single baseline: Multiple baselines provide more robust variance estimates but increase computational cost
  - Window size range: Larger range captures more scales but increases computation and may introduce noise
  - Redshift correction accuracy: Critical for meaningful comparison but may introduce errors if spectra are noisy

- Failure signatures:
  - Uniform attribution scores across all wavelengths: May indicate poor model performance or inappropriate baseline sampling
  - Attribution peaks at redshift boundaries: Could indicate errors in redshift correction
  - No sensitivity to known anomalies: May suggest window sizes are mismatched to feature scales

- First 3 experiments:
  1. Apply IMO to a simple synthetic spectrum with known localized anomaly (e.g., single emission line) to verify small window sizes detect the feature
  2. Test on a spectrum with known broad calibration issue to verify large window sizes detect the problem
  3. Compare attribution results using different numbers of baselines (M=5, 10, 20) to assess impact on variance estimates and final attribution quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of window sizes in IMO affect the detection of different types of anomalous features across various astrophysical datasets beyond galaxy spectra?
- Basis in paper: [explicit] The authors discuss using multiple window sizes inspired by wavelet filtering to detect both localized and broad anomalies, noting that smaller windows respond to local features while larger windows are sensitive to broad features.
- Why unresolved: The paper only demonstrates IMO on a single DESI spectrum with known anomalies. The optimal window size selection for different types of spectra and anomaly characteristics remains unexplored.
- What evidence would resolve it: Systematic testing of IMO across diverse spectroscopic datasets (quasars, stars, emission line objects) with controlled experiments varying window size ranges and step sizes to establish guidelines for different anomaly types.

### Open Question 2
- Question: What is the theoretical justification for using minimum-variance weighting across baselines in the IMO method, and are there alternative aggregation schemes that might perform better?
- Basis in paper: [explicit] The authors use minimum-variance combination across window sizes and baselines, but do not provide theoretical justification for this choice over other possible aggregation methods.
- Why unresolved: The paper presents the minimum-variance approach as a practical choice but does not compare it to alternatives like maximum likelihood estimation, median aggregation, or learned weighting schemes.
- What evidence would resolve it: Comparative studies testing different aggregation methods across multiple outlier detection scenarios with known ground truth, measuring both detection accuracy and computational efficiency.

### Open Question 3
- Question: How does the performance of IMO scale with dataset size and computational resources compared to gradient-based methods?
- Basis in paper: [inferred] While the authors demonstrate IMO's effectiveness on a single outlier spectrum, they do not discuss computational complexity or scalability to massive datasets where ML methods are typically applied.
- Why unresolved: The paper focuses on attribution quality but doesn't address the computational trade-offs of using multiple baselines and window sizes versus faster gradient-based methods for large-scale applications.
- What evidence would resolve it: Benchmarking studies measuring runtime, memory usage, and attribution quality as a function of dataset size, number of baselines, and window size combinations across different hardware configurations.

## Limitations
- Method relies on proper redshift correction, which can introduce errors if spectra are noisy
- Computational cost increases with number of baselines and window sizes
- Effectiveness depends on the quality of the underlying outlier detection model

## Confidence
- High confidence in the multiscale occlusion mechanism's theoretical soundness
- Medium confidence in the practical implementation effectiveness given the complexity of spectral data and redshift corrections
- Low confidence in the robustness of results without access to the specific dataset and model implementations

## Next Checks
1. Implement a synthetic test case with known anomalous features at different scales to verify that IMO correctly identifies both localized and broad anomalies across the window size range
2. Compare attribution results using different numbers of baseline spectra (M=5, 10, 20) to quantify the impact of baseline sampling on variance estimates and final attribution quality
3. Apply the method to a spectrum with known calibration issues and verify that the attribution correctly highlights the affected wavelength regions across appropriate window sizes