---
ver: rpa2
title: 'An Empirical study of Unsupervised Neural Machine Translation: analyzing NMT
  output, model''s behavior and sentences'' contribution'
arxiv_id: '2312.12588'
source_url: https://arxiv.org/abs/2312.12588
tags:
- source
- translation
- training
- sentences
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper empirically studies unsupervised neural machine translation
  (UNMT) by training NMT models for French, Gujarati, and Kazakh to and from English.
  It analyzes the output quality, word order, semantic similarity, and model behavior
  across different supervision levels.
---

# An Empirical study of Unsupervised Neural Machine Translation: analyzing NMT output, model's behavior and sentences' contribution

## Quick Facts
- arXiv ID: 2312.12588
- Source URL: https://arxiv.org/abs/2312.12588
- Reference count: 11
- One-line primary result: UNMT models produce more monotonic translations aligned with source sentences but are more semantically distant, while exhibiting higher robustness and consistency than supervised models.

## Executive Summary
This paper conducts an empirical study of unsupervised neural machine translation (UNMT) by training models for French, Gujarati, and Kazakh to and from English. The study analyzes translation output quality, word order, semantic similarity, and model behavior across different supervision levels using layer-wise relevance propagation (LRP). The core findings reveal that UNMT models produce more monotonic translations aligned with source sentences in terms of word order but are more semantically distant. UNMT models also exhibit higher robustness and consistency compared to supervised models, especially when handling sentence perturbations, and rely more heavily on source sentences for translation generation, particularly with limited training data.

## Method Summary
The study uses a 6-layer 8-head transformer-based XLM model with Byte Pair Encoding (60k vocabulary) and an embedding size of 1024. Language models are pretrained using the MLM objective, then NMT models are trained using Back-Translation (BT), denoising auto-encoding (AE), and supervised objectives. The study evaluates models on English-French (23M parallel sentences), English-Gujarati (22K sentences), and English-Kazakh (22K sentences) using BLEU, FRS, TER, RMSS, and robustness/consistency metrics. LRP is adapted to measure source and target sentence contributions to the translation output.

## Key Results
- UNMT models produce more monotonic translations aligned with source sentences in terms of word order but are more semantically distant
- UNMT models exhibit higher robustness and consistency compared to supervised models, especially when handling sentence perturbations
- UNMT models rely more heavily on source sentences for translation generation, particularly with limited training data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layer-wise Relevance Propagation (LRP) can effectively measure the contribution of source and target sentences to the NMT output in UNMT.
- Mechanism: LRP calculates the relevance of input neurons to the top-1 logit predicted by the model, and token contribution is the sum of the input neurons' relevance. This allows for evaluating the source and target sentences' contribution to the NMT output.
- Core assumption: The relevance can be propagated inversely through the decoder and the encoder, up to the input model layer, and the conservation principle holds across processed tokens.
- Evidence anchors:
  - [abstract]: "We also use Layer-wise Relevance Propagation to evaluate the source and target sentences' contribution to the result"
  - [section]: "We follow their setup, with LRP to be propagated first inversely through the decoder and the encoder, up to the input model layer, and without assuming the conservation principle holds per layer, but only across processed tokens."
- Break condition: If the relevance cannot be accurately propagated through the layers or the conservation principle does not hold across processed tokens.

### Mechanism 2
- Claim: Back-translation (BT) boosts the influence of source sentences, particularly in low-resource settings, and helps generate translations more aligned with references in terms of word order.
- Mechanism: BT translates monolingual data between languages, creating pseudo-parallel training corpora. This helps the model rely more on source tokens for sequence generation and produces more monotonic alignments between source sentences and translations.
- Core assumption: BT provides additional training signal that helps the model learn better alignments between source and target languages.
- Evidence anchors:
  - [abstract]: "Our results highlight the importance of supervision for output quality, yet outline the superiority of UNMT in generating sentences highly aligned to references and in preserving models' robustness."
  - [section]: "For En–Fr and Fr–En, FRS (Fig. 2) values are stable throughout training, and BT, BT-MT experiments' results imply highly monotonic alignments; with BT, translations are closer to source sentences in terms of word order."
- Break condition: If the quality of the back-translated data is too low, it may introduce noise and hurt the model's performance.

### Mechanism 3
- Claim: UNMT models exhibit higher robustness and consistency compared to supervised models, especially when handling sentence perturbations.
- Mechanism: UNMT models learn to generate translations without relying on parallel data, which may lead to more robust and consistent behavior when the input is perturbed.
- Core assumption: Learning without parallel data forces the model to rely more on the internal representations learned from monolingual data, which may be more robust to perturbations.
- Evidence anchors:
  - [abstract]: "UNMT models tend to show higher Robustness and Consistency, and can more easily recover from sentence perturbations."
  - [section]: "A similar behavior is observed for En–Kk, Kk–En. Models are highly robust on case-changing in all unsupervised, supervised and semi-supervised scenarios, and as the amount parallel sentences increases, we see an expected increased robustness to sentences' misspelling."
- Break condition: If the monolingual data used for training is not representative of the target domain, the model may not generalize well to perturbed inputs.

## Foundational Learning

- Concept: Layer-wise Relevance Propagation (LRP)
  - Why needed here: LRP is used to evaluate the source and target sentences' contribution to the NMT output, which is a key aspect of the analysis.
  - Quick check question: What is the conservation principle in LRP, and how is it applied in the context of NMT?

- Concept: Back-translation (BT)
  - Why needed here: BT is a key component of the UNMT approach used in the experiments, and its effectiveness is analyzed in the results.
  - Quick check question: How does BT create pseudo-parallel training corpora, and what are the potential benefits and drawbacks of this approach?

- Concept: Robustness and Consistency metrics
  - Why needed here: These metrics are used to evaluate the model's performance on perturbed inputs, which is an important aspect of the analysis.
  - Quick check question: How are the Robustness and Consistency metrics defined, and what do they measure in the context of NMT?

## Architecture Onboarding

- Component map: Monolingual data -> Language model pretraining -> NMT model initialization -> NMT training with BT/AE/MT -> Evaluation with BLEU/FRS/TER/RMSS/Robustness/Consistency/LRP

- Critical path:
  1. Pre-train language models for each language using the MLM objective
  2. Initialize the encoder and decoder of the NMT model with the pre-trained language models
  3. Train NMT models using Back-Translation (BT) and denoising auto-encoding (AE) for UNMT, the Machine Translation (MT) objective for supervised NMT, and BT-MT for joint unsupervised and supervised approaches
  4. Analyze the output quality, word order, semantic similarity, and model behavior using the various metrics and methods described in the paper

- Design tradeoffs:
  - Using UNMT allows for training without parallel data, but may result in lower output quality compared to supervised methods
  - Back-translation can help improve the quality and word order of translations, but relies on the quality of the back-translated data
  - LRP and other analysis methods provide insights into the model's behavior, but may be computationally expensive and require careful interpretation

- Failure signatures:
  - Low BLEU scores or other quality metrics may indicate issues with the model architecture, training data, or training process
  - High entropy in source or target contributions may suggest the model is not confident in its predictions or relies too heavily on certain parts of the input
  - Low Robustness or Consistency scores may indicate the model is sensitive to input perturbations and may not generalize well to new data

- First 3 experiments:
  1. Train a supervised NMT model on a high-resource language pair (e.g., English-French) and evaluate its performance using BLEU, FRS, TER, and other metrics.
  2. Train an unsupervised NMT model on a low-resource language pair (e.g., English-Gujarati) and compare its performance to the supervised model on the same language pair.
  3. Apply LRP to analyze the source and target sentence contributions for both the supervised and unsupervised models, and compare the results to understand the differences in their behavior.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do unsupervised neural machine translation (UNMT) models perform in terms of translation quality, word order, and semantic similarity compared to supervised models?
- Basis in paper: [explicit] The paper discusses the performance of UNMT models and compares them to supervised models in terms of translation quality, word order, and semantic similarity.
- Why unresolved: The paper provides empirical results for specific language pairs (French, Gujarati, and Kazakh to and from English), but does not offer a comprehensive evaluation of UNMT performance across a broader range of languages or datasets.
- What evidence would resolve it: Further studies evaluating UNMT performance across diverse language pairs and datasets, including low-resource languages, would provide a more comprehensive understanding of the strengths and limitations of UNMT compared to supervised models.

### Open Question 2
- Question: What are the specific stages of training in UNMT models, and how do they differ from supervised models?
- Basis in paper: [explicit] The paper mentions the existence of distinct stages in transformer-based NMT models, including UNMT, and aims to analyze their behavior and differences compared to supervised models.
- Why unresolved: While the paper identifies the existence of stages in UNMT models, it does not provide a detailed analysis of the specific stages and their characteristics, nor does it compare them to supervised models.
- What evidence would resolve it: Detailed analysis of the training stages in UNMT models, including their characteristics and differences from supervised models, would provide insights into the unique behavior of UNMT during training.

### Open Question 3
- Question: How does the robustness and consistency of UNMT models compare to supervised models, especially in handling sentence perturbations?
- Basis in paper: [explicit] The paper evaluates the robustness and consistency of NMT models, including UNMT, in handling sentence perturbations and compares their performance.
- Why unresolved: While the paper provides some insights into the robustness and consistency of UNMT models, it does not offer a comprehensive evaluation of their performance across different types of perturbations or in comparison to supervised models.
- What evidence would resolve it: Further studies evaluating the robustness and consistency of UNMT models across various types of sentence perturbations and comparing their performance to supervised models would provide a clearer understanding of their strengths and limitations in handling perturbed inputs.

## Limitations
- The exact implementation details of the LRP adaptation for the Transformer model are not fully specified in the paper
- The reported robustness advantages of UNMT models are based on synthetic perturbations that may not reflect real-world noise patterns
- The semantic similarity analysis using RMSS depends on embedding quality, which is not evaluated in the paper

## Confidence

- High: Output quality differences between supervised and unsupervised models (BLEU scores)
- Medium: Word order analysis using FRS and TER metrics
- Low: Semantic similarity claims based on RMSS and the interpretation of LRP relevance scores

## Next Checks

1. Re-implement the LRP method following V oita et al. (2020, 2021) and verify that relevance scores sum to 1 across all layers
2. Test model robustness on real-world noisy data rather than synthetic perturbations to confirm the reported advantages
3. Evaluate RMSS performance on a held-out reference set to establish baseline semantic similarity expectations