---
ver: rpa2
title: Mechanism of feature learning in convolutional neural networks
arxiv_id: '2309.00570'
source_url: https://arxiv.org/abs/2309.00570
tags:
- convolutional
- deep
- learning
- layer
- agop
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the Convolutional Neural Feature Ansatz (CNFA),
  which states that covariances of filters in any convolutional layer are proportional
  to the average gradient outer product (AGOP) taken with respect to patches of the
  input to that layer. The authors provide extensive empirical evidence for their
  ansatz, including identifying high correlation ( 0.9) between covariances of filters
  and patch-based AGOPs for convolutional layers in standard neural architectures
  such as AlexNet, VGG, and ResNets pre-trained on ImageNet.
---

# Mechanism of feature learning in convolutional neural networks

## Quick Facts
- arXiv ID: 2309.00570
- Source URL: https://arxiv.org/abs/2309.00570
- Authors: 
- Reference count: 40
- Key outcome: Convolutional Neural Feature Ansatz (CNFA) proposes covariances of filters are proportional to average gradient outer product (AGOP) over input patches, enabling feature learning in convolutional kernel machines

## Executive Summary
This paper introduces the Convolutional Neural Feature Ansatz (CNFA), a fundamental relationship between filter covariances in convolutional neural networks and the average gradient outer product (AGOP) computed over input patches. The authors provide extensive empirical evidence showing high correlation (>0.9) between these quantities across multiple standard architectures (AlexNet, VGG, ResNets) pre-trained on ImageNet. They demonstrate that this relationship enables feature learning in convolutional kernel machines through a novel algorithm called Deep ConvRFM, which recovers similar features to deep convolutional networks including edge detectors. This work bridges the gap between fixed convolutional kernels and learned features, overcoming previous limitations of kernel methods.

## Method Summary
The authors propose a two-part approach: first, empirically validating the CNFA by computing filter covariances (CNFM) and comparing them to AGOP matrices for various pre-trained and trained models; second, using this insight to develop ConvRFM and Deep ConvRFM algorithms that learn feature transformations in kernel machines. ConvRFM replaces inner products with Mahalanobis distances parameterized by AGOP matrices, while Deep ConvRFM extends this to multiple layers. The algorithms are evaluated on standard image classification datasets and compared against convolutional neural networks and fixed convolutional kernel methods.

## Key Results
- Empirical correlation between CNFM and AGOP exceeds 0.9 for convolutional layers in AlexNet, VGG, and ResNets pre-trained on ImageNet
- Deep ConvRFM recovers edge detector features similar to those learned by deep convolutional networks
- ConvRFM and Deep ConvRFM achieve significant performance improvements over fixed convolutional kernels on multiple image classification datasets
- The mechanism overcomes limitations of convolutional kernels in adapting to local image structure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Filter covariances in convolutional layers are proportional to the average gradient outer product (AGOP) taken with respect to input patches
- Mechanism: During training, the optimization process adjusts filter weights so that their empirical covariance matrix aligns with the AGOP, which captures which input features most affect the network output
- Core assumption: The network is trained for at least one epoch of gradient descent on standard loss functions
- Evidence anchors:
  - [abstract] "covariances of filters in any convolutional layer are proportional to the average gradient outer product (AGOP) taken with respect to patches of the input to that layer"
  - [section] "W⊤ℓ Wℓ ∝ (1/n)∑p∑(i,j)∈S(∇hℓ−1(x)[i,j]Gℓ(x))(∇hℓ−1(x)[i,j]Gℓ(x))⊤"
  - [corpus] Weak/no direct match; related papers discuss feature learning but not this specific proportionality
- Break condition: If training doesn't use standard loss functions, or if the network architecture prevents gradient flow through patches

### Mechanism 2
- Claim: Edge detectors emerge as eigenvectors of the AGOP matrix
- Mechanism: The AGOP naturally identifies linear combinations of input pixels that most strongly influence network output, which correspond to edge-like features in images
- Core assumption: Images contain meaningful edge structures that are important for classification tasks
- Evidence anchors:
  - [abstract] "Deep ConvRFM recovers similar features to deep convolutional networks including the notable emergence of edge detectors"
  - [section] "the mathematical origin of edge detectors in convolutional neural networks is the average gradient outer product"
  - [corpus] Weak/no direct match; related papers discuss feature extraction but not edge detector emergence from AGOP
- Break condition: If input data lacks spatial structure or edges are not informative for the task

### Mechanism 3
- Claim: Feature learning in convolutional kernel machines can be enabled by replacing inner products with Mahalanobis distances parameterized by AGOP matrices
- Mechanism: By learning a positive semi-definite matrix M through AGOP computation, the kernel adapts to local image structure similarly to learned convolutional filters
- Core assumption: Kernel machines can approximate the behavior of trained neural networks when using appropriately learned feature transformations
- Evidence anchors:
  - [abstract] "We refer to the resulting algorithm as ConvRFM... show that our algorithm recovers similar features to deep convolutional networks"
  - [section] "KM(x,z):=1/PQ∑iPXj=1ˇϕ(x[i,j]TMz[i,j],x[i,j]TMx[i,j],z[i,j]TMz[i,j])"
  - [corpus] Weak/no direct match; related papers discuss kernel methods but not AGOP-based adaptation
- Break condition: If the kernel function cannot be modified to incorporate learned Mahalanobis distances

## Foundational Learning

- Concept: Average Gradient Outer Product (AGOP)
  - Why needed here: AGOP is the mathematical object that captures feature learning in both neural networks and kernel machines
  - Quick check question: What is the mathematical definition of AGOP and how does it relate to the Fisher information matrix?

- Concept: Convolutional Neural Feature Matrix (CNFM)
  - Why needed here: CNFM represents the learned features as the empirical covariance of filters, which the ansatz claims is proportional to AGOP
  - Quick check question: How is the CNFM computed from filter weights and what does it represent geometrically?

- Concept: Patch-based feature extraction
  - Why needed here: The entire mechanism operates on image patches rather than full images, making local feature learning possible
  - Quick check question: How does treating images as collections of patches enable translation-invariant feature learning?

## Architecture Onboarding

- Component map: Input images → Patch extraction → AGOP computation → Feature matrix M → Kernel evaluation (for ConvRFM) or filter covariance analysis (for CNNs)
- Critical path: Training data → Kernel regression or neural network training → AGOP computation over patches → Feature matrix update → Repeat until convergence
- Design tradeoffs: Using AGOP enables feature learning but requires computing gradients with respect to patches, which can be memory-intensive; kernel methods are slower to evaluate but don't require backpropagation
- Failure signatures: Low correlation between CNFM and AGOP indicates the ansatz doesn't hold; poor performance on edge detection tasks suggests AGOP isn't capturing the right features
- First 3 experiments:
  1. Compute correlation between CNFM and AGOP for a pre-trained AlexNet on ImageNet
  2. Implement ConvRFM on SVHN and visualize the top eigenvectors of the learned feature matrix
  3. Compare performance of CNTK vs Deep ConvRFM on a synthetic task with embedded digits in noise

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How general is the Convolutional Neural Feature Ansatz (CNFA) across different architectures and datasets?
- Basis in paper: [explicit] The paper provides empirical evidence for the CNFA on AlexNet, VGG, ResNet pre-trained on ImageNet, SimpleNet trained on various datasets, and shallow CNNs across 10 standard computer vision datasets.
- Why unresolved: The paper does not exhaustively explore all possible architectures and datasets. There may be specific architectures or datasets for which the CNFA does not hold or exhibits significantly different behavior.
- What evidence would resolve it: Further empirical studies on a wider range of architectures (e.g., different types of convolutions, attention mechanisms, etc.) and datasets (e.g., medical images, natural language processing, etc.) to validate the generalizability of the CNFA.

### Open Question 2
- Question: What is the theoretical explanation for the emergence of edge detectors as features learned by ConvRFM and Deep ConvRFM?
- Basis in paper: [inferred] The paper observes that the eigenvectors of the AGOP from ConvRFM and Deep ConvRFM trained on standard image classification datasets resemble edge detectors, suggesting a connection to classical edge detection approaches.
- Why unresolved: The paper does not provide a rigorous theoretical analysis of why edge detectors emerge as features learned by ConvRFM and Deep ConvRFM. It only provides empirical evidence and conjectures a connection to classical edge detection.
- What evidence would resolve it: A formal mathematical proof or analysis that explains the emergence of edge detectors as features learned by ConvRFM and Deep ConvRFM, potentially drawing connections to classical edge detection theory.

### Open Question 3
- Question: How can the computational complexity of evaluating convolutional kernels be reduced to make Deep ConvRFM more scalable?
- Basis in paper: [explicit] The paper acknowledges that evaluating effective CNTKs can be computationally intensive, and Deep ConvRFM involves constructing kernel matrices and computing AGOP at each layer, further increasing computational demands.
- Why unresolved: The paper does not provide concrete solutions for reducing the computational complexity of Deep ConvRFM. It only mentions the potential use of random feature approximations as a future direction.
- What evidence would resolve it: Implementation and evaluation of specific techniques for reducing the computational complexity of Deep ConvRFM, such as random feature approximations, sparse approximations, or distributed computing strategies.

## Limitations
- The mechanism may not extend to attention-based architectures or transformer models
- AGOP computation requires storing full gradient information over all patches, creating memory constraints for high-resolution images
- The proportionality relationship may break down for extremely deep networks where gradient flow becomes unstable

## Confidence
- CNFA correlation > 0.9 in standard architectures: High confidence
- Edge detector emergence from AGOP: Medium confidence
- Generalization to kernel machines: Medium confidence

## Next Checks
1. Scale Test: Compute CNFM-AGOP correlation for deeper networks (ResNet-152, DenseNet) and measure correlation decay with network depth.
2. Architecture Test: Apply CNFA to vision transformers and compare feature emergence patterns with convolutional networks using the same datasets.
3. Robustness Test: Evaluate ConvRFM performance under varying levels of input noise and adversarial perturbations to assess the stability of AGOP-based feature learning.