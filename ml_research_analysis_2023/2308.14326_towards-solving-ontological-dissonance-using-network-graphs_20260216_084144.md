---
ver: rpa2
title: Towards solving ontological dissonance using network graphs
arxiv_id: '2308.14326'
source_url: https://arxiv.org/abs/2308.14326
tags:
- data
- domains
- different
- spaces
- ontologies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how ontological dissonance can be measured
  and described between domains to support interoperable Data Spaces. The authors
  crawl Smart Data Models from 13 domains, building a network graph with 3,630 nodes
  and 212,871 edges representing domains, data models, types, and attributes.
---

# Towards solving ontological dissonance using network graphs

## Quick Facts
- arXiv ID: 2308.14326
- Source URL: https://arxiv.org/abs/2308.14326
- Reference count: 2
- The paper investigates how ontological dissonance can be measured and described between domains to support interoperable Data Spaces using network graphs.

## Executive Summary
This paper addresses the challenge of semantic interoperability in Data Spaces by investigating ontological dissonance between domains. Using network graph analysis on Smart Data Models from 13 domains, the authors identify shared semantic attributes and quantify domain similarity to enable automated alignment. The approach combines centrality metrics with heatmap analysis to reveal both structural patterns and element-level semantic relationships, providing a foundation for interoperable Data Spaces where domains maintain self-determination while achieving semantic alignment.

## Method Summary
The authors crawl Smart Data Models from 13 domains, building a network graph with 3,630 nodes and 212,871 edges representing domains, data models, types, and attributes. They apply centrality metrics (degree and betweenness) to identify attributes used across domains, and create a heatmap showing domain similarity based on shared data models. The methodology involves extracting hierarchical relationships from the Smart Data Models repository, constructing a graph where nodes represent different levels of the ontology hierarchy, and analyzing both node importance and domain relationships through quantitative metrics.

## Key Results
- Centrality metrics identified 14 attributes used across domains, demonstrating cross-domain semantic alignment opportunities
- Heatmap analysis revealed domain similarity patterns, with some domains sharing many more common data models than others
- Most attributes remain domain-specific, indicating significant ontological dissonance between domains
- Graph analysis successfully describes dissonance at both structural and element levels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Network graph centrality metrics reveal shared semantic attributes across domains.
- Mechanism: By representing domains, data models, types, and attributes as nodes in a graph with edges denoting relationships, degree and betweenness centrality highlight attributes that connect multiple domains.
- Core assumption: Shared attributes across domains indicate semantic alignment opportunities.
- Evidence anchors:
  - [section]: "Centrality metrics such as Degree Centrality and Betweeness Centrality are recognized methods to identify central (important) nodes within a graph (Zhang and Luo 2017). Using these two metrics, 14 attributes were identified that are used across domains in many DataModels."
  - [corpus]: Weak evidence for general centrality-method effectiveness; no specific citations for data model alignment.
- Break condition: If domain-specific attributes dominate, centrality metrics will fail to identify cross-domain alignment points.

### Mechanism 2
- Claim: Heatmap analysis quantifies domain similarity based on shared data models.
- Mechanism: The matrix intersection of domains by shared data models reveals which domains have high semantic overlap, guiding alignment priorities.
- Core assumption: Data model overlap correlates with semantic similarity.
- Evidence anchors:
  - [section]: "Figure 2 shows the use of common data models and attributes (vocabularies) at the domain level. ... One can see that there are domains that have many more common data models than others."
  - [corpus]: No corpus evidence for heatmap validity in semantic alignment; weak support.
- Break condition: If domains share data models for technical rather than semantic reasons, similarity measures mislead.

### Mechanism 3
- Claim: Graph representation enables both structural and element-level ontology alignment.
- Mechanism: The graph captures not just node presence but edge relationships, allowing similarity at the type and attribute level, not just model level.
- Core assumption: Edge relationships encode meaningful semantic proximity.
- Evidence anchors:
  - [section]: "To achieve semantic interoperability of Data Spaces (each with a high degree of self-determination), the ontologies used are augmented with data about the data (metadata)."
  - [corpus]: Weak evidence; no specific citations linking graph edges to semantic alignment.
- Break condition: If edges represent only technical references rather than semantic relationships, alignment will fail.

## Foundational Learning

- Concept: Network graphs and centrality metrics
  - Why needed here: The entire approach relies on graph-theoretic methods to identify important nodes (attributes) that bridge domains.
  - Quick check question: What is the difference between degree centrality and betweenness centrality in identifying cross-domain attributes?

- Concept: Semantic interoperability and ontological dissonance
  - Why needed here: The paper addresses how different domains interpret and use data differently, requiring explicit alignment methods.
  - Quick check question: Why is ontological dissonance a problem for interoperable Data Spaces?

- Concept: Data model hierarchies (domains → data models → types → attributes)
  - Why needed here: Understanding the nested structure is essential to interpreting the graph topology and node relationships.
  - Quick check question: How do attributes relate to types, and how do types relate to data models in the Smart Data Models hierarchy?

## Architecture Onboarding

- Component map: Crawler → MongoDB storage → Network graph construction → Centrality calculation → Heatmap generation → Analysis
- Critical path: Data crawling → Graph construction → Centrality metrics → Similarity analysis
- Design tradeoffs: Manual Python crawling allows flexibility but lacks automation; MongoDB supports complex queries but may not scale efficiently; graph centrality metrics are computationally heavy for large graphs.
- Failure signatures: Empty or sparse graphs indicate crawling failures; centrality metrics returning uniform values suggest poor differentiation; heatmap showing mostly zeros indicates no semantic overlap.
- First 3 experiments:
  1. Crawl a single domain and verify graph node/edge counts match expectations.
  2. Compute centrality metrics on a small subgraph and validate against manual inspection.
  3. Generate heatmap for two domains with known overlap and confirm similarity score.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the number of shared attributes between domains correlate with their semantic similarity?
- Basis in paper: [explicit] The paper identifies 14 central attributes used across domains and creates a heatmap showing domain similarity based on shared data models
- Why unresolved: The paper presents domain similarity through shared data models but does not explicitly analyze the correlation between attribute overlap and semantic similarity
- What evidence would resolve it: Quantitative analysis comparing attribute overlap percentages with semantic similarity scores between domain pairs

### Open Question 2
- Question: What is the optimal threshold for attribute similarity that enables automated semantic alignment between ontologies?
- Basis in paper: [inferred] The paper discusses the need for automated ontology alignment approaches but doesn't specify quantitative thresholds for successful alignment
- Why unresolved: While the paper identifies central attributes and domain similarities, it doesn't establish specific similarity metrics or thresholds for automated alignment
- What evidence would resolve it: Experimental results showing alignment success rates at different similarity threshold levels across various domain pairs

### Open Question 3
- Question: How does the inclusion of metadata in network graphs affect the accuracy of semantic alignment?
- Basis in paper: [explicit] The paper mentions the possibility of extending graphs with metadata but doesn't explore this in the current analysis
- Why unresolved: The paper identifies opportunities for graph analysis with metadata but doesn't test or quantify the impact on alignment accuracy
- What evidence would resolve it: Comparative analysis of alignment accuracy with and without metadata inclusion in network graphs across multiple domain pairs

### Open Question 4
- Question: What is the computational complexity of scaling the network graph approach to thousands of domains?
- Basis in paper: [inferred] The paper analyzes 13 domains but doesn't address scalability challenges
- Why unresolved: The current analysis uses a limited dataset without examining performance implications for larger-scale implementations
- What evidence would resolve it: Performance metrics and complexity analysis for progressively larger domain networks, including timing and resource requirements

## Limitations
- The correlation between shared data models and true semantic alignment remains untested
- Most attributes remain domain-specific, suggesting limited semantic overlap between domains
- Qualitative interpretation of dissonance relies heavily on visual inspection rather than quantitative thresholds

## Confidence
- **High Confidence**: The network graph construction methodology and centrality metric calculations are technically sound and reproducible.
- **Medium Confidence**: The identification of 14 cross-domain attributes through centrality metrics is supported by the data, though the semantic significance of these attributes requires further validation.
- **Low Confidence**: The claim that heatmap similarity directly translates to semantic alignment opportunities lacks empirical validation.

## Next Checks
1. Conduct manual semantic validation of the 14 identified central attributes to verify they represent true semantic alignment opportunities rather than coincidental naming similarities.
2. Test the heatmap similarity metric against a ground truth dataset where domain relationships are known, to validate whether shared data models correlate with actual semantic alignment.
3. Perform ablation studies by removing different types of edges (attribute-to-type, type-to-model) to assess which relationships most strongly contribute to identifying cross-domain alignment points.