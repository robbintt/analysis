---
ver: rpa2
title: Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy
arxiv_id: '2311.01002'
source_url: https://arxiv.org/abs/2311.01002
tags:
- training
- re-labeling
- data
- subset
- examples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of data pruning under label noise
  for re-labeling methods, which aims to find a small subset that maximizes the re-labeling
  accuracy and generalization performance. The core idea is to maximize the total
  neighborhood confidence of the training examples, which is the sum of the prediction
  confidence of each neighbor example in the selected subset.
---

# Robust Data Pruning under Label Noise via Maximizing Re-labeling Accuracy

## Quick Facts
- arXiv ID: 2311.01002
- Source URL: https://arxiv.org/abs/2311.01002
- Reference count: 40
- Key outcome: Proposed Prune4ReL achieves up to 9.1% higher re-labeling accuracy than baselines with re-labeling models and up to 21.6% higher accuracy than baselines with standard models.

## Executive Summary
This paper addresses the problem of data pruning under label noise for re-labeling methods, aiming to find a small subset that maximizes re-labeling accuracy and generalization performance. The core idea is to maximize the total neighborhood confidence of training examples, defined as the sum of prediction confidences from neighboring examples in the selected subset. The authors propose Prune4ReL, a greedy algorithm that finds subsets maximizing this objective, and demonstrate significant improvements over existing data pruning methods across four real and one synthetic noisy datasets.

## Method Summary
The paper proposes Prune4ReL, a data pruning algorithm that maximizes re-labeling accuracy by selecting a subset that maximizes total neighborhood confidence. Neighborhood confidence for each example is computed as the sum of prediction confidences from neighboring examples in the selected subset, where neighbors are defined by high cosine similarity between augmented views. The algorithm uses a greedy approximation to solve the NP-hard set coverage problem, achieving a (1-1/e)-approximation guarantee. A class-balanced variant Prune4ReLB is also introduced to ensure fairness across classes.

## Key Results
- Prune4ReL outperforms baselines with re-labeling models by up to 9.1% on CIFAR-10N, CIFAR-100N, WebVision, and Clothing-1M datasets
- Prune4ReL outperforms baselines with standard models by up to 21.6% on the same datasets
- The algorithm shows consistent improvements across different selection ratios and noise types
- Neighborhood confidence demonstrates strong correlation with actual re-labeling accuracy in empirical evaluations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neighborhood confidence directly estimates the likelihood of correct re-labeling for a noisy example.
- Mechanism: For a noisy example x, the probability of being correctly re-labeled by self-consistency regularization is proportional to the sum of prediction confidences from its neighboring examples in the selected subset. Neighbors are defined as examples whose augmented versions have high cosine similarity to x's augmented versions.
- Core assumption: Self-consistency regularization corrects noisy labels by forcing them to match confident predictions from clean neighboring examples in representation space.
- Evidence anchors:
  - [abstract] "we first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset"
  - [section 3.1] "we define the concept of the neighborhood confidence which is the sum of the prediction confidence of each neighbor example in the selected subset"
  - [corpus] Weak - no direct corpus evidence for this specific neighborhood confidence mechanism
- Break condition: If the augmentation function A does not preserve semantic similarity in embedding space, or if self-consistency regularization fails to leverage neighboring predictions for re-labeling.

### Mechanism 2
- Claim: Maximizing total neighborhood confidence maximizes re-labeling accuracy across the entire training set.
- Mechanism: The data pruning objective is to find subset S that maximizes the sum of neighborhood confidences for all training examples. This creates a feedback loop where confident examples help re-label their noisy neighbors, which in turn become confident and help re-label others.
- Core assumption: The reduced neighborhood confidence in Eq. (4) accurately approximates the true neighborhood confidence that would exist after full training on subset S.
- Evidence anchors:
  - [abstract] "Therefore, we propose a novel data pruning algorithm, Prune4ReL, that finds a subset maximizing the total neighborhood confidence of all training examples, thereby maximizing the re-labeling accuracy"
  - [section 3.1] "the overall re-labeling accuracy is maximized by selecting a subset that maximizes the sum of its reachable neighborhood confidence for all training examples"
  - [corpus] Weak - no corpus evidence directly supporting this specific sum-maximization approach
- Break condition: If the neighborhood structure becomes too sparse or disconnected, preventing confident examples from reaching and correcting noisy ones.

### Mechanism 3
- Claim: Greedy approximation achieves near-optimal solution for NP-hard set coverage problem.
- Mechanism: The greedy algorithm selects examples that provide maximum marginal increase in total neighborhood confidence at each step, leveraging the monotonicity and submodularity of the objective function to guarantee (1-1/e) approximation ratio.
- Core assumption: The objective function in Eq. (6) satisfies both monotonicity and submodularity conditions required for greedy approximation guarantees.
- Evidence anchors:
  - [section 3.2] "Because enumerating all possible subsets is a combinatorial optimization problem which is NP-hard, we provide an efficient greedy selection algorithm"
  - [section 3.2] "In Theorem 3.5, we guarantee the selected subset S obtained by our greedy solution achieves a (1 - 1/e)-approximation of the optimum"
  - [corpus] Weak - no corpus evidence for this specific greedy approximation approach to data pruning
- Break condition: If the utility function σ deviates significantly from the assumed concave, non-decreasing form, breaking the submodularity property.

## Foundational Learning

- Concept: Self-consistency regularization in noisy label learning
  - Why needed here: Understanding how Re-labeling methods like DivideMix use augmented views to implicitly correct noisy labels through consistency loss
  - Quick check question: How does self-consistency regularization differ from standard supervised loss in handling noisy labels?

- Concept: Submodular optimization and greedy approximation guarantees
  - Why needed here: The greedy algorithm's theoretical guarantee relies on the objective being both monotone and submodular
  - Quick check question: What mathematical properties must an objective function have to guarantee (1-1/e) approximation with greedy selection?

- Concept: Neighborhood structures in embedding space
  - Why needed here: The method depends on defining and computing neighborhoods based on cosine similarity between augmented examples
  - Quick check question: How does the choice of τ threshold affect the trade-off between neighborhood size and noise robustness?

## Architecture Onboarding

- Component map: Warm-up classifier -> Augmentation function A -> Neighborhood confidence calculator -> Greedy selector -> Utility function σ
- Critical path:
  1. Warm-up training to obtain initial classifier
  2. Compute all pairwise similarities and confidences
  3. Greedy selection loop until subset size reached
  4. Return selected subset for downstream training

- Design tradeoffs:
  - τ threshold: Higher values create smaller, more reliable neighborhoods but may miss useful connections; lower values capture more connections but risk including noise
  - Utility function σ: Linear vs. concave affects exploration vs. exploitation balance
  - Class-balanced variant: Improves fairness but adds complexity and potential noise from minority class selection

- Failure signatures:
  - Poor performance with very low selection ratios: Greedy may prematurely select easy examples
  - Sensitivity to τ choice: Wrong threshold can severely degrade performance
  - Computational bottleneck: O(md) complexity per iteration may be prohibitive for very large datasets

- First 3 experiments:
  1. Baseline comparison: Run Prune4ReL vs. random selection on CIFAR-10N with DivideMix to establish performance gain
  2. τ sensitivity: Test multiple τ values on CIFAR-100N to find optimal threshold for neighborhood size
  3. Greedy vs. optimal: Compare greedy solution to brute-force optimal on small dataset to verify (1-1/e) approximation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the neighborhood confidence metric in Prune4ReL generalize to other noisy label scenarios, such as open-set noise or out-of-distribution examples?
- Basis in paper: [inferred] The paper mentions that Prune4ReL has not been validated in datasets with open-set noise or out-of-distribution examples, suggesting a limitation in the generalizability of the approach.
- Why unresolved: The paper does not provide any theoretical or empirical evidence to support the claim that the neighborhood confidence metric can be effectively applied to other types of noisy label scenarios.
- What evidence would resolve it: Conducting experiments on datasets with open-set noise or out-of-distribution examples and comparing the performance of Prune4ReL to other data pruning methods would provide evidence for the generalizability of the approach.

### Open Question 2
- Question: How does Prune4ReL perform when applied to state-of-the-art deep learning models, such as large language models or vision-language models?
- Basis in paper: [inferred] The paper mentions that Prune4ReL has not been validated on state-of-the-art deep learning models, such as large language models and vision-language models, indicating a potential limitation in the applicability of the approach.
- Why unresolved: The paper does not provide any theoretical or empirical evidence to support the claim that Prune4ReL can be effectively applied to state-of-the-art deep learning models.
- What evidence would resolve it: Conducting experiments on datasets with large language models or vision-language models and comparing the performance of Prune4ReL to other data pruning methods would provide evidence for the applicability of the approach.

### Open Question 3
- Question: How does Prune4ReL perform in other realistic applications of data pruning, such as continual learning or neural architecture search?
- Basis in paper: [inferred] The paper mentions that Prune4ReL has not been validated in other realistic applications of data pruning, such as continual learning or neural architecture search, suggesting a potential limitation in the applicability of the approach.
- Why unresolved: The paper does not provide any theoretical or empirical evidence to support the claim that Prune4ReL can be effectively applied to other realistic applications of data pruning.
- What evidence would resolve it: Conducting experiments on datasets with continual learning or neural architecture search tasks and comparing the performance of Prune4ReL to other data pruning methods would provide evidence for the applicability of the approach.

## Limitations

- The method relies on neighborhood structures in embedding space, which may not generalize well to all types of noisy label scenarios or out-of-distribution examples
- The greedy approximation's effectiveness depends critically on the utility function choice, but ablation studies on different σ forms are limited
- The algorithm has not been validated on state-of-the-art deep learning models such as large language models or vision-language models

## Confidence

- **High confidence**: The empirical results showing Prune4ReL outperforming baselines on multiple datasets are robust and well-documented. The greedy algorithm implementation and approximation guarantees are theoretically sound.
- **Medium confidence**: The neighborhood confidence mechanism's effectiveness is supported by experiments but lacks direct ablation studies isolating its contribution from other factors like class balancing.
- **Low confidence**: The theoretical claims about neighborhood confidence directly estimating re-labeling accuracy and the greedy approximation's optimality depend heavily on assumptions that are not thoroughly validated.

## Next Checks

1. **Neighborhood structure ablation**: Systematically vary the similarity threshold τ and augmentation strategy to test whether neighborhood confidence remains predictive of re-labeling accuracy across different neighborhood configurations.

2. **Utility function sensitivity**: Replace the current concave utility function with linear and convex alternatives to verify that submodularity is necessary for the greedy approximation's effectiveness.

3. **Cross-dataset robustness**: Test Prune4ReL on additional noisy datasets with different domain characteristics (medical imaging, satellite data) to evaluate whether the neighborhood confidence mechanism generalizes beyond the tested image classification tasks.