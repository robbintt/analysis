---
ver: rpa2
title: Large Language Models are Complex Table Parsers
arxiv_id: '2312.11521'
source_url: https://arxiv.org/abs/2312.11521
tags:
- table
- header
- column
- tuple
- complex
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We propose to incorporate GPT-3.5 to address Complex Table QA tasks,
  in which complex tables are reconstructed into tuples and specific prompt designs
  are employed for dialogues. Extensive experiments and results on Complex Table QA
  datasets, i.e., the open-domain dataset HiTAB and the aviation domain dataset AIT-QA
  show that our approach significantly outperforms previous work on both datasets,
  leading to state-of-the-art (SOTA) performance.
---

# Large Language Models are Complex Table Parsers

## Quick Facts
- arXiv ID: 2312.11521
- Source URL: https://arxiv.org/abs/2312.11521
- Reference count: 40
- Key outcome: Tuple-based table reconstruction with GPT-3.5 achieves SOTA performance on HiTAB and AIT-QA datasets

## Executive Summary
This paper proposes a novel approach to Complex Table Question Answering (QA) that leverages GPT-3.5 as a table parser. The method reconstructs complex tables into structured tuples encoding hierarchical cell information, position ranges, and content, then uses carefully designed prompts with chain-of-thought reasoning to guide the model through multi-step table understanding tasks. The approach significantly outperforms previous methods on both open-domain (HiTAB) and aviation domain (AIT-QA) datasets.

## Method Summary
The method converts JSON tables into structured tuples that encode each cell's hierarchical structure, position information, and content. For tables within token limits, single-turn dialogue prompts guide GPT-3.5 through the reasoning process using chain-of-thought templates. For larger tables, the approach breaks questions into sub-questions and employs a multi-turn dialogue scheme with code assistance to manage token constraints while maintaining reasoning continuity. The system handles complex hierarchical tables with merged cells by explicitly representing their structure in the tuple format.

## Key Results
- Achieves SOTA performance on both HiTAB and AIT-QA Complex Table QA datasets
- Single-turn dialogue significantly outperforms multi-turn dialogue, especially on HiTAB
- The tuple-based reconstruction approach effectively captures hierarchical table structures
- Code-assisted multi-turn dialogue successfully addresses token limit constraints

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Tuple-based table reconstruction enables precise hierarchical cell representation
- **Mechanism**: Encoding each cell as a structured tuple captures both content and structural relationships that flat representations lose
- **Core assumption**: GPT-3.5 can parse and reason about structured tuples as effectively as natural language
- **Evidence anchors**: [abstract] mentions tuple reconstruction; [section 3.1] details tuple encoding
- **Break condition**: If GPT-3.5's attention mechanism cannot maintain coherence across tuple sequences

### Mechanism 2
- **Claim**: Chain-of-thought prompting guides hierarchical reasoning through table structure
- **Mechanism**: Prompt templates explicitly direct the model to traverse from top-level headers to sub-headers and locate cells using position information
- **Core assumption**: GPT-3.5 can follow step-by-step reasoning instructions when provided with structured context
- **Evidence anchors**: [abstract] mentions enhancing prompt templates with CoT; [section 3.2] provides CoT details
- **Break condition**: If reasoning steps become too complex, the model may lose track of the logical flow

### Mechanism 3
- **Claim**: Multi-turn dialogue with code assistance overcomes token limit constraints while maintaining accuracy
- **Mechanism**: Breaking questions into sub-questions and using code to extract cell positions reduces input length while preserving necessary information
- **Core assumption**: GPT-3.5 can maintain reasoning continuity across dialogue turns with appropriate context passing
- **Evidence anchors**: [abstract] mentions multi-turn dialogue scheme; [section 3.3] describes code assistant module
- **Break condition**: If context loss between turns accumulates faster than information reduction gains

## Foundational Learning

- **Concept**: Hierarchical table structure representation
  - Why needed here: Complex tables have multi-level headers and merged cells that require structural awareness beyond simple row/column relationships
  - Quick check question: How would you encode a cell that spans rows 2-4 and columns 1-3 in a hierarchical table?

- **Concept**: Chain-of-thought reasoning in structured contexts
  - Why needed here: Complex table QA requires multi-step reasoning that benefits from explicit decomposition into sub-tasks
  - Quick check question: What are the key differences between applying CoT to text-only tasks versus table-based tasks?

- **Concept**: Token limit management in LLM API calls
  - Why needed here: GPT-3.5's 4,096 token limit constrains how much table information can be provided in a single prompt
  - Quick check question: If a table requires 6,000 tokens to represent fully, what strategies could you use to work within the limit?

## Architecture Onboarding

- **Component map**: Table → Tuple Reconstruction → Prompt Generation → GPT-3.5 Call → Answer Extraction → Evaluation
- **Critical path**: JSON table input flows through tuple reconstruction, prompt generation, GPT-3.5 API call, answer extraction, and evaluation
- **Design tradeoffs**:
  - Single-turn vs multi-turn: Trade accuracy for token efficiency
  - Tuple verbosity vs completeness: More detailed tuples improve accuracy but consume more tokens
  - Prompt guidance vs flexibility: More explicit instructions improve reliability but may constrain creative reasoning
- **Failure signatures**:
  - Excessive "I don't know" responses: Likely indicates token limit issues or insufficient prompt guidance
  - Inconsistent answers to identical questions: Suggests hallucination or insufficient context
  - Answers that reference non-existent table content: Indicates context truncation or parsing errors
- **First 3 experiments**:
  1. Test tuple reconstruction accuracy on tables with varying hierarchical depths
  2. Compare single-turn vs multi-turn performance on tables just below and just above token limit
  3. Evaluate impact of different levels of prompt detail on answer accuracy and hallucination rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of GPT-3.5's multi-turn dialogue approach compare to the single-turn approach on the HiTAB dataset?
- Basis in paper: Explicit - The paper states that single-turn accuracy is significantly higher than multi-turn, especially on HiTAB
- Why unresolved: The paper provides overall accuracy but lacks detailed comparison or analysis of performance differences
- What evidence would resolve it: Detailed comparison of single-turn and multi-turn accuracy on HiTAB with analysis of performance differences

### Open Question 2
- Question: How does GPT-3.5's attention to row headers and column headers affect its performance on complex table QA tasks?
- Basis in paper: Inferred - The paper mentions GPT-3.5 focuses more on column headers than row headers
- Why unresolved: The paper lacks detailed analysis of how attention to headers impacts performance or mitigation strategies
- What evidence would resolve it: In-depth analysis of the relationship between header attention and performance, including manipulation experiments

### Open Question 3
- Question: How can GPT-3.5's inability to retain historical information in multi-turn dialogue be addressed to improve performance?
- Basis in paper: Explicit - The paper states GPT-3.5 cannot automatically retain historical conversations
- Why unresolved: The paper does not propose or evaluate strategies to address this limitation
- What evidence would resolve it: Experiments testing strategies like memory mechanisms or explicit context guidance with performance impact analysis

## Limitations

- The paper lacks detailed specifications of prompt templates and code implementation, making exact reproduction difficult
- Performance improvements may be partially attributable to careful prompt engineering rather than tuple reconstruction alone
- Evaluation focuses on accuracy metrics without examining reasoning transparency or potential biases in decision-making

## Confidence

- **High confidence**: Tuple-based reconstruction mechanism for encoding hierarchical table structure is well-founded
- **Medium confidence**: Chain-of-thought prompting approach shows promise but requires validation across diverse table structures
- **Low confidence**: Multi-turn dialogue with code assistance needs more rigorous testing for context preservation and accuracy

## Next Checks

1. Conduct ablation studies testing performance with different levels of tuple detail to isolate structural representation contribution
2. Test the approach on tables with varying levels of complexity and hierarchy depth to identify breaking points
3. Implement systematic hallucination detection protocol to quantify false positives and measure output control effectiveness