---
ver: rpa2
title: 'Prompting a Large Language Model to Generate Diverse Motivational Messages:
  A Comparison with Human-Written Messages'
arxiv_id: '2308.13479'
source_url: https://arxiv.org/abs/2308.13479
tags:
- messages
- arxiv
- https
- gpt-4
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We found that prompting GPT-4 using crowdsourcing instructions
  that include specific examples caused it to produce more diverse motivational messages
  than two baseline prompts (simple request and diversity-request). Specifically,
  using the crowdsourcing pipeline increased message diversity from 4.13 to 5.66 (mean
  pairwise Euclidean distance).
---

# Prompting a Large Language Model to Generate Diverse Motivational Messages: A Comparison with Human-Written Messages

## Quick Facts
- **arXiv ID**: 2308.13479
- **Source URL**: https://arxiv.org/abs/2308.13479
- **Reference count**: 35
- **Primary result**: GPT-4 generated more diverse motivational messages when prompted with crowdsourcing-style instructions including specific examples, but still less diverse than human writers.

## Executive Summary
This paper investigates whether prompting techniques from crowdsourcing can improve the diversity of motivational messages generated by GPT-4. The authors compare three prompting approaches: simple request, diversity request, and a crowdsourcing-style approach using specific examples. They find that the crowdsourcing-style prompt significantly increases message diversity (from 4.13 to 5.66 mean pairwise Euclidean distance) compared to simpler prompts, though human-written messages remain more diverse (6.90). The study demonstrates that few-shot prompting with semantically diverse examples is an effective strategy for generating varied outputs from LLMs.

## Method Summary
The study compared motivational messages generated by GPT-4 using three different prompts against human-written messages from a prior study. The prompts were: Simple-GPT (basic request), Diverse-Naïve-GPT (explicit diversity request), and Phrase-GPT (crowdsourcing-style with 250 diverse phrases as examples). Messages were evaluated using mean pairwise Euclidean distance in embedding space as a diversity metric. Human writers took an average of 73 seconds per message, while GPT-4 generated messages in 6 seconds on average.

## Key Results
- Phrase-GPT prompt produced messages with mean pairwise Euclidean distance of 5.66, significantly higher than Simple-GPT (4.13) and Diverse-Naïve-GPT (4.38)
- Human-written messages showed highest diversity at 6.90 mean pairwise Euclidean distance
- GPT-4 messages averaged 18.7 words compared to 24.0 words for human-written messages
- Phrase-GPT messages had slightly higher semantic similarity to phrases than human messages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Including specific examples in prompts increases output diversity by guiding the model toward distinct semantic clusters.
- Mechanism: Few-shot prompting with curated phrases creates multiple reference points that the model maps to diverse output trajectories, reducing convergence to similar responses.
- Core assumption: The LLM's embedding space has sufficient resolution to maintain distinct semantic distances between example-driven outputs.
- Evidence anchors:
  - [abstract] "more specific prompts that incorporate examples generally producing better results"
  - [section] "we used the same pipeline to generate messages using GPT-4" with 250 unique phrases
  - [corpus] Weak - corpus lacks diversity metrics per phrase type
- Break condition: If example phrases are semantically similar, the model will converge toward uniform outputs regardless of quantity.

### Mechanism 2
- Claim: Atomized task instructions reduce cognitive load on the model, allowing more focused generation per example.
- Mechanism: Breaking the task into discrete phrase-to-message mappings prevents the model from attempting holistic coherence across all outputs simultaneously.
- Core assumption: The model can maintain context isolation between individual generation steps within a single session.
- Evidence anchors:
  - [abstract] "instructions written for crowdsourcing tasks... could prove effective LLM prompts"
  - [section] Phrase-GPT condition explicitly paired each message with one phrase
  - [corpus] Weak - no comparative analysis of per-phrase vs holistic generation quality
- Break condition: If model attention mechanisms cannot maintain separate contexts, outputs may blend across examples.

### Mechanism 3
- Claim: Semantic diversity of example phrases constrains the output space, forcing the model to explore non-overlapping regions.
- Mechanism: Phrases selected for semantic distance create boundaries in embedding space that the model must respect when generating corresponding messages.
- Core assumption: The model's internal representation of phrase semantics directly influences message generation patterns.
- Evidence anchors:
  - [abstract] "phrases were chosen to be semantically diverse"
  - [section] "phrases to inspire them when writing each message" with diverse topics
  - [corpus] Weak - corpus doesn't report phrase diversity metrics
- Break condition: If phrase embeddings overlap significantly, output diversity will not improve despite apparent variety in wording.

## Foundational Learning

- Concept: Few-shot learning in LLMs
  - Why needed here: The paper demonstrates that providing examples dramatically improves output quality and diversity compared to zero-shot prompting.
  - Quick check question: What is the key difference between few-shot and zero-shot prompting in terms of model performance?

- Concept: Semantic distance in embedding spaces
  - Why needed here: The study relies on measuring message diversity through Euclidean distance in embedding space, which requires understanding how semantic similarity translates to numerical distance.
  - Quick check question: How does increasing semantic distance between examples affect the diversity of generated outputs?

- Concept: Crowdsourcing task design principles
  - Why needed here: The pipeline adapts crowdsourcing instructions (specific, example-rich) to LLM prompting, leveraging established human task design patterns.
  - Quick check question: What crowdsourcing instruction elements are most effective when adapted for LLM prompting?

## Architecture Onboarding

- Component map: LLM interface (ChatGPT web-UI) -> Prompt templates (Simple-GPT, Diverse-Naïve-GPT, Phrase-GPT) -> Output collection -> Diversity measurement (pairwise Euclidean distance) -> Human-written baseline comparison
- Critical path: Phrase selection -> Prompt construction -> Message generation -> Diversity calculation -> Comparative analysis
- Design tradeoffs: Phrase quantity (250) vs generation time (6s vs 73s for humans), output length (18.7 vs 24.0 words), semantic distance vs phrase comprehensibility
- Failure signatures: Low diversity scores despite many examples, generation errors, context blending across examples, hallucinated content
- First 3 experiments:
  1. Test single phrase prompting with GPT-4 and measure output diversity vs zero-shot
  2. Vary temperature parameter while keeping phrase-based prompting constant
  3. Compare diversity when using semantically similar vs dissimilar phrases as examples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different LLM parameters (e.g., temperature, max tokens) affect the diversity of generated messages compared to human-written messages?
- Basis in paper: [explicit] The paper mentions that further investigation could alter LLM parameters such as temperature (default 1.0 on ChatGPT [22]).
- Why unresolved: The paper only used the default temperature setting for GPT-4. Different parameter settings could potentially increase message diversity.
- What evidence would resolve it: Running experiments with varying temperature and max token settings to measure their impact on message diversity metrics.

### Open Question 2
- Question: How effective are LLM-generated motivational messages compared to human-written messages in actually motivating people to exercise?
- Basis in paper: [explicit] The paper mentions that further human evaluations of message efficacy (e.g., motivation [7, 8]) could be conducted.
- Why unresolved: The study only compared diversity metrics between LLM and human messages, not their actual effectiveness in motivating behavior change.
- What evidence would resolve it: Conducting randomized controlled trials where participants are exposed to different message types and their exercise behavior is tracked over time.

### Open Question 3
- Question: What is the optimal way to incorporate domain knowledge and personal experiences into LLM prompts to match human creativity in motivational messaging?
- Basis in paper: [inferred] The paper notes that human writers incorporate personal experiences into messages [6] that may not necessarily be available to an LLM.
- Why unresolved: The study used a generic crowdsourcing pipeline without incorporating specific domain knowledge or personal experiences into the prompts.
- What evidence would resolve it: Testing different prompt engineering techniques that explicitly incorporate domain knowledge, personal experiences, or role-playing scenarios to enhance message quality and diversity.

## Limitations
- Unknown composition of the 250 phrases used in Phrase-GPT condition creates uncertainty about whether diversity improvements are due to prompt design or specific phrase selection
- Paper does not report temperature or other generation parameters that could substantially influence output diversity
- Diversity metric (pairwise Euclidean distance) may not fully capture semantic or stylistic diversity that humans would consider distinct

## Confidence
- Confidence in few-shot prompting effectiveness: Medium - results show clear increase from Simple-GPT (4.13) to Phrase-GPT (5.66), but cannot verify robustness without phrase data
- Confidence in human messages being more diverse: High - human baseline (6.90) consistently exceeds all GPT-4 conditions
- Confidence in Euclidean distance as diversity metric: Medium - standard technique but not validated against human perception

## Next Checks
1. **Phrase Sensitivity Test**: Generate messages using Phrase-GPT with 3 different sets of 250 phrases (low, medium, high semantic diversity) to determine whether output diversity correlates with phrase diversity rather than prompt structure alone.

2. **Parameter Sensitivity Analysis**: Replicate the study while varying temperature from 0.0 to 1.0 in increments of 0.2, keeping the Phrase-GPT prompt constant, to isolate the effect of generation parameters on diversity outcomes.

3. **Human Perception Validation**: Conduct a human evaluation study where raters assess message diversity independently of the embedding-based metric, comparing human-perceived diversity with the calculated Euclidean distances to validate the measurement approach.