---
ver: rpa2
title: 'Large Language Models Meet Open-World Intent Discovery and Recognition: An
  Evaluation of ChatGPT'
arxiv_id: '2310.10176'
source_url: https://arxiv.org/abs/2310.10176
tags:
- chatgpt
- intent
- discovery
- number
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper evaluates ChatGPT''s performance on out-of-domain (OOD)
  intent discovery and generalized intent discovery (GID) tasks. Three prompt-based
  methods are designed: direct clustering (DC), zero-shot discovery (ZSD), and few-shot
  discovery (FSD).'
---

# Large Language Models Meet Open-World Intent Discovery and Recognition: An Evaluation of ChatGPT

## Quick Facts
- arXiv ID: 2310.10176
- Source URL: https://arxiv.org/abs/2310.10176
- Reference count: 14
- ChatGPT shows competitive zero-shot performance on OOD intent discovery but struggles with scalability and domain-specific understanding

## Executive Summary
This paper evaluates ChatGPT's performance on open-world intent discovery and generalized intent discovery (GID) tasks. The authors design three prompt-based methods - direct clustering (DC), zero-shot discovery (ZSD), and few-shot discovery (FSD) - and propose a pipeline framework for GID. Experiments on the Banking dataset reveal that ChatGPT outperforms BERT without IND prior but falls short of fine-tuned models (DeepAligned, DKT) as OOD ratio increases. Key challenges include poor scalability for large-scale clustering, difficulty with domain-specific understanding, and limited cross-domain in-context learning.

## Method Summary
The study evaluates ChatGPT on OOD intent discovery and GID tasks using the Banking dataset with 77 intent classes. Three dataset partitions are created (IND/OOD=3:1, 3:2, 1:1) with 15 classes sampled as IND and 15 as OOD. Three prompt-based methods are implemented: DC for direct clustering, ZSD for zero-shot discovery, and FSD for few-shot discovery. For GID, a pipeline framework generates pseudo-intents for clusters before joint classification. Performance is compared against fine-tuned baselines (DeepAligned, DKT) and BERT using clustering metrics (ACC, NMI, ARI) and classification metrics (F1, ACC).

## Key Results
- ChatGPT outperforms BERT in zero-shot OOD discovery without IND prior knowledge
- Performance degrades as OOD ratio increases, with ChatGPT falling behind fine-tuned models
- ChatGPT exhibits unique recall errors including missing and repeated cluster assignments

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** ChatGPT can perform OOD intent discovery without any IND prior due to its powerful semantic understanding ability
- **Mechanism:** The model leverages its pre-trained knowledge from large-scale general text corpus to understand semantic similarities between OOD samples and cluster them based on intent
- **Core assumption:** The semantic patterns learned during pre-training are sufficient to capture intent similarities in the target domain without fine-tuning
- **Evidence anchors:**
  - [abstract] "ChatGPT exhibits consistent advantages under zero-shot settings"
  - [section 4.4] "without any IND prior knowledge, i.e., direct clustering, ChatGPT's performance is significantly better than BERT"
  - [corpus] Weak - the related papers focus on continual learning and hybrid architectures rather than zero-shot semantic understanding

### Mechanism 2
- **Claim:** ChatGPT's recall errors in OOD discovery stem from its generative architecture
- **Mechanism:** The model's token-by-token generation process can lead to assigning the same sample to multiple clusters or missing assignments entirely, unlike discriminative models that output a single label per sample
- **Core assumption:** The generative nature of the model introduces uncertainty in cluster assignment that doesn't exist in discriminative approaches
- **Evidence anchors:**
  - [section 5.3] "ChatGPT has the problem of missing and repeated recall, which is a unique problem of generative LLMs"
  - [section 4.3] "ChatGPT has the phenomenon that some samples are not assigned any cluster or intent (missing recall), while some are assigned multiple clusters or intents (repeated recall)"
  - [corpus] Weak - related work focuses on clustering frameworks but doesn't address generative recall errors specifically

### Mechanism 3
- **Claim:** ChatGPT struggles with cross-domain in-context learning because it treats IND demonstrations as noise
- **Mechanism:** The model fails to extract transferable knowledge from IND samples when the domain distribution differs significantly from OOD samples, leading to degraded performance
- **Core assumption:** In-context learning requires similar distribution between demonstrations and test samples to be effective
- **Evidence anchors:**
  - [section 5.1] "IND Demos result in a performance decline in clustering and almost no improvement in classification"
  - [section 5.1] "the different distribution between demonstration and testing causes ChatGPT not only unable to bring performance gains through in-context learning but also regard demonstrations as in-context noise"
  - [corpus] Weak - related papers discuss knowledge integration but not specifically cross-domain in-context learning failures

## Foundational Learning

- **Concept:** Semantic understanding in pre-trained language models
  - Why needed here: Understanding how pre-training enables zero-shot performance is crucial for explaining ChatGPT's advantage over BERT
  - Quick check question: What aspect of pre-training allows models to perform tasks without fine-tuning on domain-specific data?

- **Concept:** Clustering algorithms and evaluation metrics
  - Why needed here: The paper uses ACC, NMI, and ARI to evaluate clustering performance, requiring understanding of these metrics
  - Quick check question: How does the Hungarian algorithm enable computing clustering accuracy when cluster labels are arbitrary?

- **Concept:** In-context learning mechanisms
  - Why needed here: The paper explores how demonstrations affect performance, requiring understanding of how models use context
  - Quick check question: Why does the distribution mismatch between IND demonstrations and OOD test samples lead to degraded performance?

## Architecture Onboarding

- **Component map:** Prompt construction -> LLM API call (ChatGPT) -> Response parsing -> Evaluation metric calculation
- **Critical path:** Prompt construction → LLM API call → Response parsing → Evaluation metric calculation
- **Design tradeoffs:** Using a generative model enables zero-shot performance but introduces recall errors; providing demonstrations can help or hurt depending on domain alignment
- **Failure signatures:** High missing/duplicate recall rates indicate context window limitations; poor performance with increasing OOD ratio suggests semantic understanding limits
- **First 3 experiments:**
  1. Test direct clustering performance on a small OOD sample set to verify zero-shot capability
  2. Compare performance with and without IND prior to understand knowledge transfer limits
  3. Vary the number of samples per cluster to identify robustness boundaries

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can ChatGPT's clustering performance be improved for large-scale OOD intent discovery tasks?
- Basis in paper: [explicit] The paper discusses challenges with large-scale clustering, including input token limitations, recall errors, and poor robustness to sample numbers.
- Why unresolved: The paper only suggests potential approaches like summarizing samples into topic words or using multi-round dialogue for remediation, but does not implement or test these solutions.
- What evidence would resolve it: Empirical results comparing ChatGPT's clustering performance on large-scale datasets using the proposed remediation approaches versus current methods.

### Open Question 2
- Question: What is the optimal way to inject domain-specific knowledge into ChatGPT prompts to improve GID performance without increasing inference costs?
- Basis in paper: [explicit] The paper identifies lack of domain knowledge as the main limitation for GID and suggests using demonstration examples or describing label sets, but notes that long prompts increase inference costs.
- Why unresolved: The paper does not explore methods to efficiently adapt ChatGPT to specific domains without increasing inference costs, such as using intermediate knowledge or chain-of-thought reasoning.
- What evidence would resolve it: Comparative results showing the performance of different domain knowledge injection methods on GID tasks, along with their impact on inference costs.

### Open Question 3
- Question: How can cross-domain in-context learning be improved to enable ChatGPT to effectively leverage IND demonstrations for OOD tasks?
- Basis in paper: [explicit] The paper finds that cross-domain in-context learning fails for current LLMs and questions how IND demonstrations can be used to improve OOD task performance.
- Why unresolved: The paper only suggests a preliminary idea of using manual chains of thought to provide inference paths from IND demonstrations to labels, but does not implement or test this approach.
- What evidence would resolve it: Experimental results comparing ChatGPT's performance on OOD tasks using different cross-domain in-context learning techniques, including the proposed chain-of-thought approach.

## Limitations

- Poor scalability with increasing OOD sample volumes, with performance degrading substantially beyond 1:1 OOD ratio
- Inability to effectively leverage IND demonstrations for cross-domain in-context learning, often leading to performance decline
- Unique recall errors (missing and repeated assignments) due to generative architecture that don't exist in discriminative models

## Confidence

**High Confidence Claims:**
- ChatGPT outperforms BERT in zero-shot OOD discovery without IND prior
- ChatGPT exhibits recall errors (missing and repeated assignments) unique to generative models
- Performance degrades as OOD ratio increases, particularly beyond 1:1
- IND demonstrations do not improve and often harm cross-domain performance

**Medium Confidence Claims:**
- ChatGPT shows competitive performance with fine-tuned models at lower OOD ratios (3:1, 3:2)
- The proposed pipeline framework improves GID performance by generating pseudo-intents
- Domain-specific terminology poses challenges for zero-shot semantic understanding

**Low Confidence Claims:**
- The exact scaling limits of ChatGPT's clustering capability are unclear
- The specific mechanisms behind cross-domain in-context learning failures are not fully understood
- The relationship between context window size and recall error rates remains unquantified

## Next Checks

1. **Scalability Boundary Test:** Systematically evaluate ChatGPT's clustering performance across a wider range of OOD ratios (1:4, 1:10, 1:20) to precisely identify the scalability breaking point and quantify the relationship between sample volume and clustering accuracy.

2. **Domain Alignment Experiment:** Test whether carefully curated IND demonstrations with semantic similarity to OOD samples can overcome the cross-domain learning barrier, or whether the model fundamentally cannot transfer knowledge across domain boundaries.

3. **Recall Error Analysis:** Conduct ablation studies varying context window size and prompt formatting to determine whether recall errors are primarily caused by generation uncertainty, context limitations, or prompt design issues.