---
ver: rpa2
title: An FPGA-Based Accelerator for Graph Embedding using Sequential Training Algorithm
arxiv_id: '2312.15138'
source_url: https://arxiv.org/abs/2312.15138
tags:
- graph
- training
- proposed
- embedding
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents an FPGA-based accelerator for graph embedding
  using a sequential training algorithm. The authors propose combining the node2vec
  algorithm with an online sequential training approach (OS-ELM) to handle dynamic
  graph structures, which is particularly relevant for IoT environments.
---

# An FPGA-Based Accelerator for Graph Embedding using Sequential Training Algorithm

## Quick Facts
- arXiv ID: 2312.15138
- Source URL: https://arxiv.org/abs/2312.15138
- Reference count: 14
- The proposed FPGA implementation achieves up to 205.25× speedup compared to the original model on ARM Cortex-A53 CPU.

## Executive Summary
This paper presents an FPGA-based accelerator for graph embedding using a sequential training algorithm that combines node2vec with online sequential training (OS-ELM). The approach addresses the challenge of dynamic graph structures in IoT environments by enabling incremental updates to graph embeddings without catastrophic forgetting. The authors replace the traditional skip-gram model's input-side weights with trainable output-side weights, significantly reducing model size and memory consumption while maintaining accuracy.

## Method Summary
The method combines node2vec with OS-ELM to create a sequential training algorithm for dynamic graphs. Instead of using both input-side and output-side weights as in traditional skip-gram models, the proposed approach uses only output-side weights (β) scaled by a factor µ, eliminating the need for large random weight matrices. The FPGA implementation uses dataflow optimization by accumulating weight updates outside the training loop, enabling parallel processing. The system uses negative sampling with Walker's alias method for efficient computation, and random walks are generated on the CPU with training performed on the FPGA.

## Key Results
- FPGA implementation achieves up to 205.25× speedup compared to CPU baseline
- Model size is up to 3.82× smaller than the original skip-gram model
- Sequential training maintains accuracy even when graph structure changes
- F1 scores achieved: Cora (0.8390), Amazon Photo (0.8505), Amazon Computers (0.9053)

## Why This Works (Mechanism)

### Mechanism 1
Sequential training using OS-ELM avoids catastrophic forgetting when graph structure changes. The mechanism works by updating output-side weights β incrementally without backpropagating through input-side weights, so new edges can be added without overwriting previously learned node relationships. The core assumption is that hidden layer outputs depend only on the center node's row in β, preserving embeddings for existing nodes. Evidence shows accuracy is maintained during incremental edge addition, but drops significantly when sampling frequency is too low (every 10,000 edges).

### Mechanism 2
Replacing input-side weights α with a scaled version of output-side weights β reduces model size and memory use. Since hidden layer output Hi is computed as Hi = β[center node] × µ instead of G(xiα + b), only β and scalar µ need to be stored. The scaling factor µ compensates for loss of random initialization without hurting embedding quality. The model achieves 3.82× size reduction, but accuracy collapses when µ is set too low (e.g., 0.001).

### Mechanism 3
FPGA dataflow optimization via modified β and P update order increases throughput without accuracy loss. By accumulating ∆β and ∆P outside the loop and only updating β and P at the end, data dependencies between iterations are removed, enabling pipeline parallelism. This modification enables up to 205.25× speedup, though accuracy drops up to 1.09% at small embedding dimensions (32), suggesting parallelization may under-update weights in low-data regimes.

## Foundational Learning

- Concept: Online sequential learning (OS-ELM)
  - Why needed here: Allows incremental updates to graph embeddings as edges are added, avoiding retraining from scratch
  - Quick check question: In OS-ELM, are the input-side weights updated during training? (Answer: No, they are fixed at random initialization.)

- Concept: Negative sampling in skip-gram models
  - Why needed here: Reduces the number of weight updates per training sample, making FPGA implementation feasible on resource-limited devices
  - Quick check question: How many negative samples are typically used for large graphs in word2vec? (Answer: 2 to 5.)

- Concept: FPGA dataflow optimization
  - Why needed here: Eliminates loop dependencies so that parallel pipelines can process multiple samples simultaneously, increasing throughput
  - Quick check question: What is the key change in the modified algorithm that enables this optimization? (Answer: ∆β and ∆P are accumulated outside the loop and applied after.)

## Architecture Onboarding

- Component map: CPU -> DRAM -> FPGA PL -> DRAM
- Critical path: Random walk generation → Negative sampling → Weight transfer to BRAM → Sequential update computation → Weight write-back
- Design tradeoffs:
  - Using β instead of α saves memory but requires careful scaling; too small µ → low accuracy
  - Negative sampling reduces computation but requires frequent table updates; too infrequent → accuracy drop
  - High parallelism on FPGA uses more DSP slices; limited by BRAM partitioning
- Failure signatures:
  - Accuracy degradation when µ < 0.005
  - Large accuracy drop when sampling table is updated every 10,000 edges
  - Resource exhaustion on FPGA if embedding dimension > 96 without more BRAM
- First 3 experiments:
  1. Measure training time and accuracy on Cora with embedding dimension 32, varying µ from 0.001 to 0.1
  2. Run sequential training with incremental edge addition on Cora and measure accuracy vs. original model
  3. Implement FPGA dataflow optimization on a small graph (Cora) and verify speedup and any accuracy loss

## Open Questions the Paper Calls Out

### Open Question 1
What is the impact of increasing the number of negative samples on the accuracy and resource utilization of the proposed model? The paper mentions that 5-20 negative samples are sufficient for small datasets and 2-5 for large datasets, but does not explore the impact of varying the number of negative samples. Experimental results showing the accuracy and resource utilization with different numbers of negative samples would resolve this.

### Open Question 2
How does the proposed model perform on other graph embedding tasks beyond node classification? The paper evaluates performance on node classification using F1 score but does not explore performance on tasks such as link prediction or graph classification. Experimental results on these tasks would resolve this question.

### Open Question 3
How does the proposed model compare to other sequential training algorithms for graph embedding, such as GraphSAGE or Graph Attention Networks? The paper compares only to the original skip-gram model, not providing comparison to other sequential training algorithms. Experimental results comparing the proposed model to these alternatives would resolve this.

## Limitations

- Experimental validation limited to three datasets and controlled edge addition scenarios
- Accuracy degradation at small embedding dimensions (32) suggests optimization limitations
- Real-world graph dynamics including edge deletions and complex structural changes not fully explored
- Resource utilization scaling for larger graphs remains unclear

## Confidence

1. **Speedup Claims**: High - Multiple experiments across three datasets demonstrate consistent and substantial speedups with clear methodology
2. **Accuracy Preservation**: Medium - Sequential training maintains accuracy in controlled scenarios, but real-world graph dynamics are not fully explored
3. **Memory Efficiency**: Medium-High - Model size reduction is well-quantified, though the impact on different graph types needs more exploration
4. **FPGA Implementation**: High - Hardware design is detailed and results are reproducible, though resource utilization at scale is unclear

## Next Checks

1. **Graph Evolution Robustness Test**: Implement a comprehensive test where the graph undergoes both edge additions and deletions in realistic patterns (e.g., bursty activity, community evolution) and measure if the sequential training maintains accuracy over extended periods, particularly focusing on the 10,000-edge sampling threshold.

2. **Cross-Domain Generalization Study**: Apply the proposed method to fundamentally different graph types (social networks, biological networks, citation networks) and evaluate whether the µ scaling parameter requires domain-specific tuning or if the 0.005-0.01 range generalizes across domains.

3. **Resource Utilization Scaling Analysis**: Implement the FPGA design on a larger graph (10× nodes and edges) and measure actual BRAM and DSP utilization, identifying at what graph size the current hardware partitioning strategy fails and what architectural changes would be needed to maintain performance.