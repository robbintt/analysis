---
ver: rpa2
title: 'Towards Responsible Generative AI: A Reference Architecture for Designing
  Foundation Model based Agents'
arxiv_id: '2311.13148'
source_url: https://arxiv.org/abs/2311.13148
tags:
- agents
- architecture
- agent
- reference
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a pattern-oriented reference architecture for
  designing foundation model-based agents, addressing the lack of systematic exploration
  in agent architecture design and responsible AI considerations. The authors conducted
  a systematic literature review to collect design patterns and components, then developed
  a reference architecture incorporating prompt engineering, memory, planning, execution
  engine, and responsible AI plugins.
---

# Towards Responsible Generative AI: A Reference Architecture for Designing Foundation Model based Agents

## Quick Facts
- arXiv ID: 2311.13148
- Source URL: https://arxiv.org/abs/2311.13148
- Reference count: 30
- Primary result: Pattern-oriented reference architecture for foundation model-based agents incorporating responsible AI considerations

## Executive Summary
This paper addresses the challenge of designing foundation model-based agents by presenting a pattern-oriented reference architecture that serves as a systematic template for practitioners. The authors conducted a systematic literature review to collect architectural patterns and components, then developed a comprehensive reference architecture incorporating prompt engineering, memory, planning, execution engine, and responsible AI plugins. The architecture was evaluated by mapping it to two real-world agents, MetaGPT and HuggingGPT, demonstrating its completeness and utility. The work emphasizes responsible AI-by-design principles through integrated patterns ensuring accountability, transparency, and safety throughout the agent lifecycle.

## Method Summary
The authors employed a pattern-oriented reference architecture design methodology, beginning with empirical acquisition of data through systematic literature review to identify architectural patterns and components for LLM-based agents. They constructed the reference architecture by integrating these collected patterns across six major components: Prompt Engineering, Memory, Planning, Execution Engine, RAI Plugins, and AI Models. The evaluation involved mapping the reference architecture to two real-world agent implementations (MetaGPT and HuggingGPT) to demonstrate completeness and practical applicability. The methodology emphasizes responsible AI integration at the architectural level rather than as an afterthought.

## Key Results
- Pattern-oriented reference architecture provides systematic template for designing foundation model-based agents
- Architecture incorporates responsible AI patterns across all components (continuous risk assessor, verifier, black box recorder, explainer, guardrails)
- Mapping to MetaGPT and HuggingGPT validates completeness and utility of reference architecture
- Reference architecture serves as template for practitioners to design agents while considering responsible AI principles

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The pattern-oriented reference architecture provides a systematic template for designing foundation model-based agents while addressing responsible AI concerns.
- Mechanism: By collecting architectural patterns and components through systematic literature review, the architecture offers reusable solutions for common challenges in agent design, including prompt engineering, memory management, planning, execution, and responsible AI plugins.
- Core assumption: The systematic literature review captured sufficient architectural patterns and components to cover the essential aspects of agent design.
- Evidence anchors:
  - [abstract]: "This paper presents a pattern-oriented reference architecture that serves as guidance when designing foundation model based agents."
  - [section]: "Based on the acquired data, in the next step, we constructed a reference architecture for LLM-based agents by integrating the architectural patterns and components identified during the systematic literature review."
  - [corpus]: Corpus shows 5 related papers on foundation model architecture design, indicating active research in this area.
- Break condition: If new architectural patterns emerge that are not captured by the current literature review, the reference architecture may become incomplete or outdated.

### Mechanism 2
- Claim: The reference architecture enables responsible-AI-by-design through integrated responsible AI plugins across all components.
- Mechanism: The architecture incorporates responsible AI patterns such as continuous risk assessor, verifier, black box recorder, explainer, guardrails, co-versioning registry, and AIBOM registry into each major component, ensuring accountability, transparency, and safety throughout the agent lifecycle.
- Core assumption: Embedding responsible AI patterns at the architectural level will effectively address accountability, traceability, and trustworthiness concerns in autonomous agents.
- Evidence anchors:
  - [abstract]: "Also, while there are significant benefits of using autonomous agents for planning and execution, there are serious considerations regarding responsible AI related software quality attributes, such as security and accountability."
  - [section]: "To ensure responsible AI, a set of patterns can be adopted across different components in the architecture of an agent [18]: continuous risk assessor, verifier, black box recorder, explainer, guardrails, co-versioning registry, and AIBOM registry."
  - [corpus]: Corpus contains papers specifically addressing AI safety and guardrails for foundation model agents.
- Break condition: If responsible AI plugins are not properly implemented or configured, the architecture may fail to ensure accountability and safety.

### Mechanism 3
- Claim: The reference architecture's evaluation through mapping to real-world agents demonstrates its completeness and utility.
- Mechanism: By mapping the architecture to MetaGPT and HuggingGPT, the paper validates that the reference architecture can be instantiated into meaningful concrete architectures, proving its practical applicability.
- Core assumption: MetaGPT and HuggingGPT are representative examples of LLM-based agents whose architectures can validate the completeness of the reference architecture.
- Evidence anchors:
  - [abstract]: "The reference architecture serves as a template for practitioners to design their own agents while considering responsible AI principles."
  - [section]: "We evaluate the correctness and utility of the proposed reference architecture by mapping it to the architecture of two real-world agents: MetaGPT [2] and HuggingGPT [3]."
  - [corpus]: Corpus contains papers on MetaGPT and HuggingGPT architectures, supporting their relevance as evaluation subjects.
- Break condition: If the two evaluated agents do not represent the full diversity of agent architectures, the reference architecture may not be universally applicable.

## Foundational Learning

- Concept: Systematic literature review methodology
  - Why needed here: The reference architecture is built on patterns and components identified through systematic literature review, so understanding this methodology is crucial for comprehending how the architecture was developed.
  - Quick check question: What are the key steps in conducting a systematic literature review for software architecture patterns?

- Concept: Pattern-oriented software architecture
  - Why needed here: The reference architecture uses architectural patterns as its fundamental building blocks, so understanding pattern-oriented architecture is essential for understanding how the architecture is structured.
  - Quick check question: How do architectural patterns differ from design patterns in software engineering?

- Concept: Responsible AI principles and patterns
  - Why needed here: The architecture specifically addresses responsible AI considerations, so understanding responsible AI principles and how they translate into architectural patterns is crucial.
  - Quick check question: What are the key responsible AI principles that should be considered when designing autonomous agents?

## Architecture Onboarding

- Component map: User goal → Prompt Engineering → Planning → Execution Engine → Result, with RAI Plugins integrated throughout each component
- Critical path: User goal → Prompt Engineering → Planning → Execution Engine → Result, with RAI Plugins integrated throughout each component
- Design tradeoffs: External vs. fine-tuned vs. sovereign LLMs (cost, control, and accuracy), single-path vs. multi-path planning (efficiency vs. flexibility), and short-term vs. long-term memory (context window limitations vs. storage capacity)
- Failure signatures: Prompt engineering failures result in misaligned goals, memory failures cause context loss, planning failures lead to inefficient task execution, execution engine failures result in task failures, and RAI plugin failures compromise accountability and safety
- First 3 experiments:
  1. Implement the prompt engineering component with passive goal creator and guardrails to test goal understanding and safety constraints
  2. Set up the memory component with short-term memory to test context management within LLM context window limits
  3. Deploy the planning component with single-path plan generator and self-reflection to test task decomposition and refinement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we systematically evaluate the effectiveness of different responsible AI patterns in LLM-based agents across various domains and use cases?
- Basis in paper: [explicit] The paper mentions that different RAI patterns can be adopted across different components but does not provide a systematic evaluation methodology.
- Why unresolved: The paper focuses on proposing patterns but lacks empirical studies comparing their effectiveness in different contexts.
- What evidence would resolve it: Comparative studies measuring the impact of different RAI patterns on metrics like accountability, transparency, and trustworthiness across multiple agent deployments.

### Open Question 2
- Question: What are the optimal memory management strategies for balancing context window limitations with the need for long-term memory in LLM-based agents?
- Basis in paper: [explicit] The paper describes short-term and long-term memory but doesn't provide guidelines for when to use each or how to optimize their interaction.
- Why unresolved: The paper acknowledges the challenge but doesn't propose specific algorithms or decision frameworks for memory management.
- What evidence would resolve it: Empirical studies comparing different memory management approaches in terms of performance, resource usage, and task completion rates.

### Open Question 3
- Question: How can we develop standardized metrics and benchmarks for evaluating the planning capabilities of LLM-based agents, particularly when comparing single-path versus multi-path planning approaches?
- Basis in paper: [inferred] The paper describes different planning patterns (single-path vs multi-path) but doesn't provide evaluation criteria for comparing their effectiveness.
- Why unresolved: Planning effectiveness likely depends on task complexity and domain, but no framework exists for systematic comparison.
- What evidence would resolve it: A standardized benchmark suite with tasks of varying complexity and metrics for measuring planning efficiency, accuracy, and adaptability.

## Limitations
- Limited corpus size with only 5 related papers identified in systematic literature review
- Evaluation relies on mapping to only two real-world agents (MetaGPT and HuggingGPT)
- Responsible AI patterns lack detailed specification of implementation approaches and evaluation metrics

## Confidence

- **High confidence**: Systematic methodology for developing reference architecture and empirical validation through mapping to real-world agents
- **Medium confidence**: Claim that reference architecture can serve as comprehensive template for all foundation model-based agents due to limited corpus size and narrow scope of evaluated agents
- **Low confidence**: Claim that reference architecture will effectively address all responsible AI concerns in practice without empirical evidence of pattern effectiveness

## Next Checks

1. **Expand corpus and pattern validation**: Conduct a broader systematic literature review with updated search terms and inclusion criteria to capture additional architectural patterns and components from emerging agent architectures.

2. **Multi-agent architecture mapping**: Evaluate the reference architecture against a diverse set of 5-10 real-world agent implementations, including multi-agent systems and agents with different primary capabilities (e.g., creative, analytical, autonomous decision-making).

3. **Responsible AI pattern effectiveness**: Design and execute controlled experiments to evaluate the effectiveness of responsible AI patterns (e.g., guardrails, continuous risk assessor, black box recorder) in detecting and preventing harmful agent behaviors, with measurable safety metrics and failure rates.