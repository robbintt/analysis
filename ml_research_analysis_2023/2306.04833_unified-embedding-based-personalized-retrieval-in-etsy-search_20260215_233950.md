---
ver: rpa2
title: Unified Embedding Based Personalized Retrieval in Etsy Search
arxiv_id: '2306.04833'
source_url: https://arxiv.org/abs/2306.04833
tags:
- product
- retrieval
- search
- query
- user
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Unified Embedding Based Personalized Retrieval in Etsy Search introduces
  a neural retrieval system called UPPER that combines graph, transformer, and term-based
  embeddings to address both the semantic gap problem for tail queries and personalization
  for head queries. The model uses a two-tower architecture with a product encoder
  and a joint query-user encoder, trained end-to-end with hard negative mining and
  a multi-part hinge loss.
---

# Unified Embedding Based Personalized Retrieval in Etsy Search

## Quick Facts
- arXiv ID: 2306.04833
- Source URL: https://arxiv.org/abs/2306.04833
- Reference count: 40
- Primary result: 5.58% increase in search purchase rate and 2.63% increase in site-wide conversion rate

## Executive Summary
Etsy's UPPER system addresses the dual challenges of semantic gap for tail queries and personalization for head queries in e-commerce search through a unified embedding approach. The system combines graph, transformer, and term-based embeddings within a two-tower architecture to enable efficient semantic retrieval. By incorporating user context and employing sophisticated negative mining strategies, UPPER significantly improves both recall and conversion metrics compared to traditional keyword-based approaches.

## Method Summary
The UPPER system uses a two-tower neural retrieval architecture with a product encoder and a joint query-user encoder. The model learns unified embeddings by combining multiple feature types: T5-small pre-trained representations for product text, bipartite graph embeddings for query-product relationships, and comprehensive location encoders. Training employs hard negative mining from multiple sources with dynamic weighting, while online serving uses ANN indexing with product quality boosting via black-box optimization. The system is evaluated using both offline recall metrics and online A/B tests measuring purchase rate and conversion.

## Key Results
- 5.58% increase in search purchase rate and 2.63% increase in site-wide conversion rate in A/B testing
- 3.51% improvement in Recall@100 and 4.05% improvement in Recall@1000 for personalized queries compared to non-personalized baseline
- Significant gains across both head and tail queries, with the largest improvements seen in head query personalization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The unified embedding model resolves both the vocabulary gap for tail queries and personalization needs for head queries by jointly encoding query, user, and product features in a shared semantic space.
- Mechanism: The two-tower architecture learns embeddings that maximize cosine similarity between relevant query-product pairs while incorporating user context, location, and historical behavior. This enables retrieval of semantically relevant items even when query terms don't match product text exactly.
- Core assumption: Semantic similarity learned from historical interaction data generalizes to unseen queries and users.
- Evidence anchors: [abstract] "Embedding-based neural retrieval is a prevalent approach to address the semantic gap problem which often arises in product search on tail queries."

### Mechanism 2
- Claim: Hard negative mining with dynamic weighting improves retrieval performance by focusing training on difficult examples.
- Mechanism: The system samples hard negatives from in-batch positives, uniform negatives, and dynamically selected candidates using current model parameters. Loss weights are adjusted during training to balance the contribution of each negative type.
- Core assumption: The hardest negatives during training are representative of real retrieval challenges.
- Evidence anchors: [section 4.4] "Our negative mining strategy employs three difference sources of negative products: Hard in-batch negatives, Uniform negatives, Dynamic Hard Negatives from large batch."

### Mechanism 3
- Claim: ANN-based product boosting balances relevance and quality by incorporating product quality scores into the ANN search process.
- Mechanism: The system hydrates product embeddings with quality features and uses black-box optimization to learn static query-side weights that maximize purchase recall. This allows the ANN to retrieve items that are both semantically relevant and high-quality.
- Core assumption: Quality features are independent of query and can be optimized separately from semantic relevance.
- Evidence anchors: [section 5] "We implement additive boosting within ANN-based semantic retrieval by enriching our model-derived product vectors with additional numerical features and add corresponding feature weights to query vectors."

## Foundational Learning

- Concept: Semantic gap in information retrieval
  - Why needed here: The system specifically addresses the vocabulary mismatch between user queries and product descriptions, which is fundamental to understanding why embedding-based approaches are needed.
  - Quick check question: What's the difference between a tail query with vocabulary gap and a head query with broad intent?

- Concept: Two-tower architecture for neural retrieval
  - Why needed here: The UPPER system uses a two-tower design to enable efficient ANN search while learning semantic representations for both queries and products.
  - Quick check question: Why does the two-tower architecture enable offline indexing of product embeddings?

- Concept: Negative sampling strategies in contrastive learning
  - Why needed here: The training approach relies on multiple negative sampling strategies to improve the model's ability to distinguish relevant from irrelevant products.
  - Quick check question: How do hard negatives differ from uniform negatives in their impact on model training?

## Architecture Onboarding

- Component map: Product features → Product encoder → Unified embedding → ANN index ← Query features → Query-user encoder ← User context
- Critical path: Query → Feature extraction → Joint encoding → ANN lookup → Product boosting → Results
- Design tradeoffs:
  - Transformer vs lightweight encoders: Transformers provide better semantic understanding but increase latency; the system uses lightweight encoders for the query tower to maintain real-time performance.
  - Hard vs uniform negatives: Hard negatives improve top-K performance but may overfit; uniform negatives improve overall ranking quality.
  - Static vs dynamic quality weights: Static weights are simpler and more stable; dynamic weights could adapt to query context but add complexity.
- Failure signatures:
  - Low cache hit rate: Indicates issues with feature extraction or cache key design
  - High recall loss in ANN: Suggests ANN parameters need tuning or the model embedding space isn't well-suited for ANN
  - Degradation in head query performance: May indicate overfitting to tail queries or issues with personalization components
- First 3 experiments:
  1. Compare recall@100 with and without hard negative mining to validate the impact of different negative sampling strategies
  2. Test different ANN algorithms (HNSW vs IVF variants) with the same model to find the best latency-recall tradeoff
  3. Evaluate the impact of location embeddings by comparing domestic vs international purchase recall

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the discussion and limitations, several important questions emerge:

### Open Question 1
- Question: How does the UPPER model perform on highly ambiguous or exploratory search queries that don't clearly indicate product intent?
- Basis in paper: [inferred] The paper discusses UPPER's performance on head and tail queries but doesn't explicitly address ambiguous or exploratory queries. These types of queries could be challenging for the model since they may lack clear context or intent.
- Why unresolved: The paper focuses on demonstrating improvements for both head and tail queries but doesn't specifically analyze performance on ambiguous or exploratory queries. This represents a gap in understanding the model's robustness across different query types.
- What evidence would resolve it: A/B testing results showing UPPER's performance on queries with high ambiguity scores, or a dedicated analysis of recall/precision metrics for exploratory queries compared to more specific queries.

### Open Question 2
- Question: What is the impact of UPPER on long-tail sellers or niche products that may not have high historical interaction data?
- Basis in paper: [inferred] The paper discusses the semantic gap problem for tail queries but doesn't explicitly address how UPPER affects visibility for products from long-tail sellers or niche categories that may have limited historical data.
- Why unresolved: The paper focuses on overall performance improvements but doesn't provide a breakdown of how different seller tiers or product categories are affected by the model. This is important for understanding potential equity implications.
- What evidence would resolve it: Analysis showing changes in search visibility and purchase rates for products from sellers with different sales volumes or from niche categories before and after UPPER implementation.

### Open Question 3
- Question: How does the model's performance degrade when user history features are sparse or unavailable, such as for new users or incognito sessions?
- Basis in paper: [explicit] The paper mentions that UPPER incorporates user history features and shows improved performance on signed-in users, but doesn't explicitly analyze performance when these features are unavailable.
- Why unresolved: The paper demonstrates the benefits of personalization but doesn't quantify the fallback performance when personalization features are missing. This is crucial for understanding the model's reliability across different user scenarios.
- What evidence would resolve it: A/B test results comparing UPPER's performance for users with rich history versus new users or incognito sessions, or an analysis of how the model weights personalization features versus query relevance when user history is sparse.

## Limitations

- Limited ablation studies: The paper presents overall system performance but provides limited analysis of individual component contributions, making it unclear how much each component contributes to the final performance.
- Offline evaluation methodology: The paper relies on relative recall metrics compared to an existing baseline system rather than absolute performance measures, which makes it difficult to assess practical impact without full system context.
- External validity concerns: As an industry paper from Etsy, the results may be specific to their particular product catalog, user base, and search patterns, and may not generalize to other e-commerce domains.

## Confidence

- High confidence: The core technical approach of using a unified embedding with two-tower architecture for semantic retrieval is well-established in the literature and the implementation details are clearly described.
- Medium confidence: The claimed improvements in purchase rate and conversion rate from A/B testing, while impressive, are specific to Etsy's environment and may not generalize directly to other contexts.
- Low confidence: The specific hyperparameter choices and training schedules that led to optimal performance are not fully specified, making exact reproduction challenging.

## Next Checks

1. Conduct component ablation study to isolate the impact of each major component (unified embedding, ANN boosting, hard negative mining) on recall performance to understand their relative contributions.

2. Apply the UPPER approach to a different e-commerce dataset or search task to validate whether the improvements in semantic gap resolution and personalization generalize beyond the Etsy environment.

3. Systematically vary the product quality features and their weights in the ANN boosting to understand the robustness of the approach to different quality signal formulations and to identify potential overfitting to Etsy's specific quality metrics.