---
ver: rpa2
title: What's the Magic Word? A Control Theory of LLM Prompting
arxiv_id: '2310.04444'
source_url: https://arxiv.org/abs/2310.04444
tags:
- prompt
- length
- control
- controllability
- question
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors present a control-theoretic analysis of large language
  models (LLMs), focusing on the controllability of these models through prompting.
  They formalize LLMs as discrete stochastic dynamical systems and introduce the concept
  of k-epsilon controllability, which measures the ability to steer the model's output
  distribution using prompts of length k.
---

# What's the Magic Word? A Control Theory of LLM Prompting

## Quick Facts
- arXiv ID: 2310.04444
- Source URL: https://arxiv.org/abs/2310.04444
- Reference count: 40
- Key outcome: The authors demonstrate that LLMs exhibit high controllability through prompting, finding that magic words of 10 tokens or less exist for over 97% of instances surveyed, with controllability following a log-linear relationship with prompt length.

## Executive Summary
This paper introduces a control-theoretic framework for analyzing the controllability of large language models (LLMs) through prompting. The authors formalize LLMs as discrete stochastic dynamical systems and introduce the concept of k-epsilon controllability, which measures the ability to steer model outputs using prompts of length k. Through mathematical analysis of self-attention mechanisms and empirical evaluation on multiple LLM models, they demonstrate that these models are highly controllable, with magic words existing for the vast majority of test cases. The work establishes a theoretical foundation for understanding how input prompts can influence LLM behavior and provides practical algorithms for finding optimal prompts.

## Method Summary
The authors formalize LLMs as discrete stochastic dynamical systems and introduce k-epsilon controllability as a metric for measuring how well prompts can steer model outputs. They propose two greedy optimization algorithms—greedy back-generation and greedy coordinate gradient (GCG)—to find optimal prompts (magic words) that maximize the probability of desired outputs. The controllability of self-attention heads is analyzed through singular value decomposition of weight matrices, establishing bounds on when controllability is possible. The methods are evaluated on three LLM models (Falcon-7b, Llama-7b, and Falcon-40b) using 5,000 WikiText causal language modeling tasks, measuring the fraction of instances where correct outputs can be achieved with prompts of varying lengths.

## Key Results
- Magic words of 10 tokens or less exist for over 97% of Wikipedia causal language modeling instances surveyed
- A log-linear relationship exists between prompt length and controllability fraction
- The greedy coordinate gradient (GCG) algorithm outperforms greedy back-generation for longer prompts
- Controllability is consistently high across different model families (Falcon and Llama)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM controllability can be measured by k-epsilon controllability, which quantifies the probability that a prompt of length k can steer the model to output the correct next token.
- Mechanism: The authors formalize LLMs as discrete stochastic dynamical systems and define controllability as the ability to find a "magic word" (prompt) that forces the model to predict the correct final token. They compute this by optimizing prompts using greedy algorithms and measuring the fraction of instances where the correct token becomes the most likely output.
- Core assumption: The LLM's output distribution is sufficiently sensitive to input prompts that a short sequence of tokens can dramatically alter the likelihood of specific outputs.
- Evidence anchors:
  - [abstract] "we find that the 'correct' next token is reachable at least 97% of the time, and that the top 75 most likely next tokens are reachable at least 85% of the time"
  - [section 3.2] "k −ϵ controllability measures the probabilityϵ that there there is no optimal prompt u∗ of length k or less that will force the final token prediction arg maxy′ P (y′|u + x) to be the correct value"

### Mechanism 2
- Claim: The controllability of self-attention heads can be bounded as a function of the singular values of their weight matrices.
- Mechanism: The authors analyze self-attention as a linear system where controllable inputs (prompt tokens) mix with uncontrolled inputs (base sequence tokens). They derive a bound showing that controllability fails when the ratio of uncontrolled to controllable tokens is too high relative to the singular values of the weight matrices.
- Core assumption: The self-attention mechanism can be approximated as a linear system for the purpose of controllability analysis.
- Evidence anchors:
  - [section 4] "we prove a bound on controllability as a function of the singular values of its weight matrices"
  - [section 4] "If this condition is met for any i ∈ 1 . . . M, then the attention head is not state controllable" with the specific bound involving σmax(Wv), σmax(Wq), σmax(Wk), and the ratio of controllable to uncontrolled tokens

### Mechanism 3
- Claim: Greedy optimization algorithms can effectively find magic words that achieve controllability.
- Mechanism: The authors propose two algorithms: greedy back-generation, which builds prompts token-by-token by selecting the token that maximizes the probability of the correct final token at each step, and greedy coordinate gradient (GCG), which iteratively swaps tokens in a random prompt to improve performance based on a first-order approximation of the loss gradient.
- Core assumption: The loss landscape with respect to prompt tokens has local optima that can be reached through greedy search.
- Evidence anchors:
  - [section 5] "We use two techniques for inferring magic words: greedy back-generation and greedy coordinate gradient (GCG, Zou et al. (2023))"
  - [section 6] "Remarkably, we find that there generally exists a magic word of length 10 or less for over 97% of Wikipedia causal language modelling instances surveyed"

## Foundational Learning

- Concept: Control theory and controllability of dynamical systems
  - Why needed here: The paper applies control-theoretic concepts to analyze LLM controllability, requiring understanding of state controllability, output controllability, and controllability metrics
  - Quick check question: What is the difference between state controllability and output controllability in control theory?

- Concept: Self-attention mechanism in transformers
  - Why needed here: The mathematical analysis of controllability focuses on self-attention heads, requiring understanding of how queries, keys, and values interact to produce output representations
  - Quick check question: How does the softmax normalization in self-attention create dependencies between controllable and uncontrollable components?

- Concept: Optimization algorithms for discrete sequences
  - Why needed here: The paper uses greedy algorithms to optimize discrete token sequences, requiring understanding of search strategies and gradient-based optimization in discrete spaces
  - Quick check question: How does the GCG algorithm use gradient information to guide discrete token substitutions?

## Architecture Onboarding

- Component map:
  - LLM system as discrete stochastic dynamical system with state space (token sequences), input space (prompts), and output space (next token predictions)
  - Self-attention heads as linear systems with weight matrices Wq, Wk, Wv
  - Optimization pipeline with greedy back-generation and GCG algorithms
  - Evaluation framework with Wikitext causal language modeling tasks

- Critical path:
  1. Sample base token sequences from Wikitext
  2. For each sequence, attempt to find magic words of increasing length using greedy algorithms
  3. Measure k-epsilon controllability by computing the fraction of solved instances at each prompt length
  4. Analyze results to understand controllability scaling and the effectiveness of optimization algorithms

- Design tradeoffs:
  - Prompt length vs. controllability: Longer prompts provide more control but are more costly to generate and apply
  - Algorithm choice: Greedy back-generation is faster for short prompts but GCG performs better for longer prompts
  - Model selection: Larger models may have different controllability characteristics but require more computational resources

- Failure signatures:
  - If epsilon does not decrease with increasing prompt length, the model may have uncontrollable subspaces
  - If greedy algorithms fail to find magic words for simple sequences, the optimization landscape may be too rugged
  - If controllability is very low across all models, the fundamental assumption about prompt sensitivity may be incorrect

- First 3 experiments:
  1. Implement k-epsilon controllability metric and verify it produces reasonable values on a small set of simple sequences
  2. Compare greedy back-generation and GCG algorithms on sequences where the correct next token is easily predictable
  3. Test controllability bounds by artificially modifying self-attention weight matrices and measuring the effect on controllability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the log-linear relationship between prompt length k and controllability fraction epsilon (ϵ) hold for longer prompts and questions?
- Basis in paper: [explicit] The authors observe a log-linear relationship between k and log(ϵ) within their studied domain and suggest it raises the question of whether this relationship is robust outside their current exploratory scope.
- Why unresolved: The study only tested prompt lengths up to 10 tokens and question lengths up to 32 tokens. Longer prompts and questions may behave differently.
- What evidence would resolve it: Testing the relationship with much longer prompts (e.g., 100+ tokens) and questions (e.g., 1000+ tokens) to see if the log-linear relationship persists or changes.

### Open Question 2
- Question: How does the controllability of different model families (e.g., Llama vs. Falcon) compare when accounting for differences in tokenization?
- Basis in paper: [explicit] The authors note that direct comparison of controllability scores across model families is challenging due to different tokenizers, with Llama having 30,000 tokens and Falcon having 65,536 tokens.
- Why unresolved: The current study uses different tokenizers for different model families, making it difficult to compare controllability directly.
- What evidence would resolve it: Developing a method to normalize or compare controllability scores across models with different tokenizers, or testing the same model family with different tokenizers.

### Open Question 3
- Question: Can we control the output distribution P(y|x+u) to a desired distribution P* beyond just controlling the argmax?
- Basis in paper: [explicit] The authors mention this as an open problem in the discussion section, noting that while they've demonstrated the ability to control the argmax of P(y|u+x), it's unclear how much they can modulate this distribution beyond that.
- Why unresolved: The current study focuses on controlling the most likely output token, but doesn't investigate the ability to shape the entire output distribution.
- What evidence would resolve it: Experiments that attempt to match the model's output distribution to a specific target distribution P* for various inputs and prompts, measuring the divergence (e.g., KL divergence) between the actual and target distributions.

## Limitations

- The controllability analysis assumes self-attention can be treated as a linear system with fixed weights, ignoring non-linear activation functions and layer normalization
- The greedy optimization algorithms may not find globally optimal magic words and could get stuck in local optima
- The experimental evaluation is limited to three models and a single dataset (WikiText), raising questions about generalizability to other architectures and tasks

## Confidence

**High Confidence**:
- The mathematical framework for defining k-epsilon controllability and its relationship to control theory
- The observation of a log-linear relationship between prompt length and controllability across multiple models
- The finding that magic words of 10 tokens or less exist for over 97% of tested instances

**Medium Confidence**:
- The controllability bounds derived for self-attention mechanisms in terms of singular values
- The relative performance comparison between greedy back-generation and GCG algorithms
- The claim that controllability scaling follows a potential scaling law

**Low Confidence**:
- The assumption that self-attention can be adequately modeled as a linear system for controllability analysis
- The generalizability of controllability findings to non-causal language modeling tasks
- The robustness of greedy optimization algorithms across diverse prompting scenarios

## Next Checks

1. **Singular Value Sensitivity Analysis**: Systematically vary the singular values of attention weight matrices through controlled modifications and measure the impact on k-epsilon controllability. This would validate whether the theoretical bounds accurately predict empirical controllability.

2. **Algorithm Comparison on Diverse Tasks**: Evaluate greedy back-generation and GCG on a broader range of tasks including question answering, reasoning, and code generation to determine if the algorithms' relative performance is consistent across domains.

3. **Controllability in Multi-Head Settings**: Extend the controllability analysis to the full multi-head attention mechanism used in practical LLMs, accounting for the interactions between heads and the final output projection. This would test whether the single-head analysis generalizes to real architectures.