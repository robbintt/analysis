---
ver: rpa2
title: Zero-Shot Detection of Machine-Generated Codes
arxiv_id: '2310.05103'
source_url: https://arxiv.org/abs/2310.05103
tags:
- code
- detection
- arxiv
- codes
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a training-free approach for detecting code
  generated by advanced large language models (LLMs) like ChatGPT. The key idea is
  to use a surrogate white-box model to estimate the probability of the rightmost
  tokens in a given code snippet, allowing identification of machine-generated code.
---

# Zero-Shot Detection of Machine-Generated Codes

## Quick Facts
- arXiv ID: 2310.05103
- Source URL: https://arxiv.org/abs/2310.05103
- Reference count: 11
- Key outcome: A training-free approach detects machine-generated code with average AUROC of 78.65 and TPR of 43.71

## Executive Summary
This paper introduces a novel training-free method for detecting code generated by large language models (LLMs) like ChatGPT, GPT-4, and GPT-3.5. The approach leverages a surrogate white-box model to estimate probability curvature by analyzing the rightmost tokens in code snippets, exploiting the more deterministic nature of machine-generated code endings. Extensive experiments on Python and Java code demonstrate state-of-the-art detection performance while being robust against revision attacks. The method also identifies that smaller code language models, such as PolyCoder-160M, can serve as effective universal detectors across various models and datasets.

## Method Summary
The method adapts the DetectGPT framework to the code domain by using a surrogate white-box code language model to estimate the probability curvature of black-box LLMs. It focuses on the rightmost tokens of code snippets, assuming that machine-generated code endings are more deterministic given sufficient preceding context. The approach employs Incoder-6B to generate perturbations through fill-in-the-middle tasks, creating multiple perturbed versions of the code to compare probability divergences. By analyzing the curvature between original and perturbed code probabilities, the method distinguishes machine-generated code from human-written code without requiring any training data or labeled examples.

## Key Results
- Achieves state-of-the-art detection performance with average AUROC of 78.65 and TPR of 43.71
- Outperforms existing text detectors on GPT-3.5, GPT-4, and other models across Python and Java datasets
- Demonstrates robustness against revision attacks while maintaining competitive detection accuracy
- Identifies PolyCoder-160M as a universal code detector that works well across multiple models and datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Machine-generated code tends to have more deterministic end tokens given sufficient preceding context compared to human-written code.
- Mechanism: The proposed method uses a surrogate white-box model to estimate probability curvature by comparing the original code's probability with perturbed versions. By focusing on rightmost tokens with a high preceding text ratio (γ), the method exploits the more deterministic nature of machine-generated code endings.
- Core assumption: The ending tokens of machine-generated code are more predictable given the preceding context than those of human-written code.
- Evidence anchors:
  - [abstract]: "we use a surrogate white-box model to estimate the probability of the rightmost tokens"
  - [section]: "the ending tokens are more deterministic given enough preceding text and thus are better indicators"
  - [corpus]: Weak evidence. The corpus does not provide direct support for this mechanism.
- Break condition: If human-written code also exhibits deterministic endings in certain contexts, the method's discrimination ability would be compromised.

### Mechanism 2
- Claim: Perturbing code through fill-in-the-middle tasks introduces variations that make machine-generated code distinguishable from human-written code.
- Mechanism: The method uses Incoder-6B to mask and refill spans of code, creating perturbed versions. Machine-generated code is assumed to lie in negative curvature regions, making it distinguishable from human-written code based on probability divergence.
- Core assumption: Perturbations applied to machine-generated code will result in larger probability divergences compared to perturbations applied to human-written code.
- Evidence anchors:
  - [abstract]: "we opt for a free open-sourced model for simulating perturbations"
  - [section]: "under the assumption that machine-generated text usually lies in the negative curvature regions"
  - [corpus]: Weak evidence. The corpus does not provide direct support for this mechanism.
- Break condition: If perturbations do not consistently produce distinguishable probability divergences between machine-generated and human-written code, the method's effectiveness would be reduced.

### Mechanism 3
- Claim: Smaller code language models can serve as effective universal detectors for machine-generated code across various models, datasets, and programming languages.
- Mechanism: The method experiments with different surrogate models of varying sizes, finding that smaller models like PolyCoder-160M outperform larger counterparts in detecting machine-generated code.
- Core assumption: Smaller code language models, when specifically trained on the target programming languages, can effectively estimate probability curvature for detection purposes.
- Evidence anchors:
  - [abstract]: "we also find that the smaller code language model like PolyCoder-160M performs as a universal code detector"
  - [section]: "PolyCoder-160M achieves universal best results on three datasets"
  - [corpus]: Weak evidence. The corpus does not provide direct support for this mechanism.
- Break condition: If larger models or models not specifically trained on the target languages prove to be more effective, the method's reliance on smaller models would be challenged.

## Foundational Learning

- Concept: Probability curvature estimation using surrogate models
  - Why needed here: The method relies on estimating the probability curvature of black-box models using a white-box surrogate model to detect machine-generated code.
  - Quick check question: How does using a surrogate model to estimate probability curvature help in distinguishing machine-generated code from human-written code?

- Concept: Fill-in-the-middle (FIM) tasks for code perturbation
  - Why needed here: The method uses FIM tasks to create perturbations in the code, which are then used to estimate probability curvature and detect machine-generated code.
  - Quick check question: Why is the fill-in-the-middle approach chosen for code perturbation instead of other perturbation methods?

- Concept: Rightmost token focus in probability estimation
  - Why needed here: The method focuses on the probability of rightmost tokens given sufficient preceding context, as these tokens are assumed to be more deterministic in machine-generated code.
  - Quick check question: How does focusing on rightmost tokens improve the detection of machine-generated code compared to considering the entire code sequence?

## Architecture Onboarding

- Component map:
  - Black-box LLMs (GPT-4, GPT-3.5-turbo, text-davinci-003) -> Generate machine-generated code
  - Surrogate white-box models (PolyCoder-160M, Incoder-6B, etc.) -> Estimate probability curvature
  - Incoder-6B -> Generate perturbations through FIM tasks
  - Detection algorithm -> Compare original and perturbed code probabilities
  - Evaluation datasets (CodeContest, APPS) -> Test the detection performance

- Critical path:
  1. Generate machine-generated code using black-box LLMs
  2. Create perturbations using Incoder-6B
  3. Estimate probability curvature using surrogate models
  4. Compare original and perturbed code probabilities
  5. Make detection decision based on probability divergence

- Design tradeoffs:
  - Model size vs. detection performance: Smaller models like PolyCoder-160M may be more effective as universal detectors, but larger models might capture more nuanced patterns.
  - Perturbation number vs. computational cost: Increasing the number of perturbations improves detection quality but requires more computational resources.
  - Rightmost token ratio (γ) vs. detection accuracy: Higher γ values focus on more deterministic tokens but may miss important patterns in earlier tokens.

- Failure signatures:
  - Poor performance on Java code compared to Python
  - Decreased effectiveness when human-written code exhibits deterministic endings
  - Reduced accuracy when perturbations do not produce distinguishable probability divergences

- First 3 experiments:
  1. Test the detection performance on a small subset of the CodeContest dataset using GPT-4-generated code and PolyCoder-160M as the surrogate model.
  2. Compare the detection accuracy when using different rightmost token ratios (γ) on the APPS dataset.
  3. Evaluate the impact of increasing the number of perturbations on detection performance using the CodeContest-Java dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop a universal code detector that works effectively across all programming languages?
- Basis in paper: [explicit] The paper discusses the challenges of programming languages and mentions the need for more extensive experimentation to develop a universal code detector.
- Why unresolved: The paper acknowledges the difficulty in developing a universal code detector due to the diverse range of programming languages and the varying performance of surrogate models across different languages.
- What evidence would resolve it: Developing and testing a universal code detector that achieves high performance across a wide range of programming languages, including those not specifically trained on by the surrogate models, would provide evidence to resolve this question.

### Open Question 2
- Question: How can we improve the detection of revised code attacks?
- Basis in paper: [explicit] The paper mentions conducting experiments on revised code attacks and notes that the overall performance decreases, but the drop is not significant.
- Why unresolved: The paper suggests that more sophisticated revisions need to be explored in future work, indicating that the current methods may not be sufficient to detect more advanced code revisions.
- What evidence would resolve it: Developing and testing more advanced methods to detect revised code attacks, including more sophisticated revision techniques, would provide evidence to resolve this question.

### Open Question 3
- Question: How can we improve the detection performance of code detectors compared to text detectors?
- Basis in paper: [explicit] The paper mentions that the overall code detection results are still lagging behind text detection by a substantial margin.
- Why unresolved: The paper suggests that the topic is relatively new and underexplored, indicating that more research is needed to bridge the performance gap between code and text detectors.
- What evidence would resolve it: Developing and testing code detectors that achieve performance levels comparable to or exceeding those of text detectors would provide evidence to resolve this question.

## Limitations

- Performance varies significantly across programming languages, with notably worse results on Java compared to Python
- Method's robustness against sophisticated revision attacks remains unclear and requires more comprehensive testing
- Computational cost of generating multiple perturbations is not thoroughly analyzed, raising concerns about practical deployment

## Confidence

- **High Confidence**: Experimental results demonstrating superior AUROC and TPR compared to baseline detectors on tested datasets are well-supported by provided metrics. Finding that smaller code language models like PolyCoder-160M can serve as effective universal detectors is substantiated through systematic comparisons.
- **Medium Confidence**: Claim that the method is "robust against revision attacks" is supported by some experimental evidence but lacks comprehensive testing against advanced adversarial techniques. Assertion that focusing on rightmost tokens improves detection accuracy is theoretically justified but would benefit from more direct empirical validation.
- **Low Confidence**: Generalization claim to "various black-box models" is based primarily on testing with three GPT variants and may not extend to other types of language models or non-GPT architectures. Assertion that perturbations consistently produce distinguishable probability divergences between machine-generated and human-written code lacks thorough validation across diverse code styles and domains.

## Next Checks

1. **Cross-Language Robustness Test**: Evaluate the detection performance on a diverse set of programming languages beyond Python and Java, including dynamically-typed languages (JavaScript, Ruby) and lower-level languages (C, Rust) to assess the method's generalization across language paradigms.

2. **Advanced Attack Resilience**: Design and implement sophisticated adversarial attacks specifically targeting the probability curvature estimation mechanism, such as controlled token substitution that maintains syntactic validity while reducing probability determinism in machine-generated endings.

3. **Computational Efficiency Analysis**: Measure and analyze the relationship between the number of perturbations, surrogate model size, and detection accuracy to establish practical deployment guidelines, including the minimum viable perturbation count for acceptable performance in real-time applications.