---
ver: rpa2
title: 'Everybody Needs a Little HELP: Explaining Graphs via Hierarchical Concepts'
arxiv_id: '2311.15112'
source_url: https://arxiv.org/abs/2311.15112
tags:
- graph
- https
- concepts
- dblp
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces HELP (Hierarchical Explainable Latent Pooling),
  a novel graph neural network (GNN) pooling method that produces interpretable hierarchical
  concepts. Unlike previous interpretable GNNs that discover concepts only in the
  final layer, HELP repeatedly pools the input graph through multiple GNN layers and
  clustering steps, revealing how concepts from earlier layers compose to new ones
  in later steps.
---

# Everybody Needs a Little HELP: Explaining Graphs via Hierarchical Concepts

## Quick Facts
- arXiv ID: 2311.15112
- Source URL: https://arxiv.org/abs/2311.15112
- Reference count: 40
- Primary result: HELP achieves accuracy on par with standard GNNs while yielding significantly more precise and less noisy concepts

## Executive Summary
This paper introduces HELP (Hierarchical Explainable Latent Pooling), a novel graph neural network pooling method that produces interpretable hierarchical concepts. Unlike previous interpretable GNNs that discover concepts only in the final layer, HELP repeatedly pools the input graph through multiple GNN layers and clustering steps, revealing how concepts from earlier layers compose to new ones in later steps. The method learns to partition graphs into a variable number of arbitrary connected components end-to-end, preserving sparsity and increasing the receptive field beyond the number of GNN layers. HELP is more than 1-WL expressive, making it capable of distinguishing graphs that message-passing GNNs cannot.

## Method Summary
HELP is a hierarchical graph pooling method that applies multiple pool blocks to progressively create coarser versions of the input graph. Each pool block applies several GNN layers to generate node embeddings, clusters these embeddings using k-means, and merges connected components within each cluster into single nodes. The method preserves sparsity by pooling connected components rather than arbitrary node clusters, increases receptive field beyond the number of GNN layers, and achieves more than 1-WL expressiveness through its connected component pooling approach. The algorithm is end-to-end learnable and produces hierarchical concepts that can be interpreted at each pooling layer.

## Key Results
- HELP achieves accuracy comparable to standard GNNs and popular pooling methods like DiffPool and ASAP
- The method discovers concepts that are significantly more interpretable and less noisy than previous approaches, as measured by concept conformity scores
- HELP is more than 1-WL expressive, successfully distinguishing graphs that message-passing GNNs cannot differentiate
- Qualitative analysis shows HELP discovers concepts aligned with expert domain knowledge in chemistry and social networks

## Why This Works (Mechanism)

### Mechanism 1: Sparsity Preservation and Receptive Field Growth
HELP preserves sparsity and increases receptive field by pooling connected components within clusters rather than arbitrary node groupings. When nodes are clustered based on embeddings, only structurally connected nodes within each cluster are merged into single nodes. This structural pooling ensures the resulting graphs remain sparse (avoiding fully connected graphs) while enabling distant nodes to influence each other through intermediate pooling steps. The new node embeddings are averages of merged nodes, maintaining gradient flow from inputs to final predictions.

### Mechanism 2: Beyond 1-WL Expressiveness
HELP achieves more than 1-WL expressiveness by combining GNN layers with clustering and connected component merging. While standard message-passing GNNs are limited to 1-WL expressiveness and cannot distinguish certain non-isomorphic graphs (like a single cycle versus two separate cycles), HELP can. After GNN layers generate node embeddings, clustering and connected component merging can encode information about graph connectivity that 1-WL tests miss. For example, graphs with different numbers of connected components can be mapped to different numbers of pooled nodes, enabling distinction.

### Mechanism 3: Interpretable Concept Discovery
HELP produces interpretable concepts by defining them as clusters of structurally connected nodes with similar embeddings. The concept conformity metric measures concept purity by calculating the percentage of subgraphs within a concept that appear frequently enough to be relevant. This penalizes concepts containing many rare or noisy subgraphs. By pooling connected components, each concept represents a coherent subgraph, and the hierarchical nature allows concepts to be composed from lower-level concepts, providing deeper understanding of model decisions.

## Foundational Learning

- **Graph Neural Networks and message passing**: Understanding how GNNs work is crucial for understanding HELP, as it builds upon GNNs by adding hierarchical pooling. Quick check: What is the difference between a GNN that follows the message-passing framework and one that uses spectral methods?

- **Graph pooling methods**: HELP is a graph pooling method, so understanding different pooling approaches (spectral vs. non-spectral, differentiable vs. non-differentiable) is essential for appreciating its novelty. Quick check: What are the main challenges in designing a differentiable graph pooling method that preserves graph structure?

- **Concept-based explanations in machine learning**: HELP aims to provide interpretable explanations by discovering hierarchical concepts in graphs. Understanding how concept-based explanations work in other domains can provide insights into HELP's approach. Quick check: How do concept-based explanations differ from other interpretability methods like saliency maps or feature importance scores?

## Architecture Onboarding

- **Component map**: Input Graph -> GNN Layers -> K-means Clustering -> Connected Component Merging -> Pooled Graph -> Final Prediction

- **Critical path**: 
  1. Apply GNN layers to generate node embeddings
  2. Cluster node embeddings using k-means
  3. Identify connected components within each cluster
  4. Merge connected components into single nodes
  5. Update graph structure and node features
  6. Repeat steps 1-5 for multiple pooling layers
  7. Apply final GNN layers and global pooling
  8. Generate final prediction

- **Design tradeoffs**:
  - Fixed vs. variable number of clusters: Fixed is simpler but may not capture true concepts; variable is more flexible but requires complex clustering logic
  - Local vs. global clustering: Local is faster but may lead to inconsistent concepts; global is more consistent but requires storing all embeddings
  - Exact vs. approximate gradients: Exact gradients are more accurate but computationally expensive; approximate gradients are faster but may introduce noise

- **Failure signatures**:
  - Poor clustering leading to wrong concept assignments and poor performance
  - Over-smoothing causing similar embeddings and inability to distinguish concepts
  - Disconnected concepts resulting from failed merging of structurally connected nodes

- **First 3 experiments**:
  1. Synthetic hierarchical dataset: Test HELP on synthetic data with known hierarchical structure to verify correct concept discovery
  2. Expressive power benchmark: Test on datasets with graphs indistinguishable by 1-WL methods to verify HELP's expressiveness advantage
  3. Concept conformity analysis: Analyze concept conformity scores on real-world data to verify less noisy, more interpretable concepts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the concept conformity metric perform on larger, more complex datasets where graph isomorphism testing becomes computationally prohibitive?
- Basis in paper: The authors acknowledge that concept conformity becomes infeasible for larger datasets like REDDIT-BINARY due to computational complexity of graph isomorphism testing
- Why unresolved: The paper only provides conformity scores for smaller datasets and acknowledges the metric's limitations without exploring optimizations
- What evidence would resolve it: Empirical evaluation on larger benchmark datasets with analysis of computational scaling

### Open Question 2
- Question: Can HELP be extended to settings requiring node-level predictions while maintaining interpretability?
- Basis in paper: The authors mention extending HELP to node-level predictions as future work
- Why unresolved: The paper focuses on graph-level classification and doesn't explore how hierarchical concept discovery would adapt to node-level prediction
- What evidence would resolve it: Developing and evaluating a node-level version of HELP with experiments demonstrating interpretable node-level concepts

### Open Question 3
- Question: How sensitive is HELP's performance to the choice of hyperparameters, particularly the number of clusters in k-means clustering?
- Basis in paper: The authors note HELP is "not overly sensitive" to cluster number but don't provide systematic hyperparameter sensitivity analysis
- Why unresolved: While acknowledging hyperparameter choice, the paper doesn't investigate robustness or propose automatic selection methods
- What evidence would resolve it: Comprehensive hyperparameter sensitivity analysis with different cluster numbers and automatic k-selection strategies

## Limitations

- The concept conformity metric, while novel, has limited validation against established interpretability metrics and uses an arbitrary threshold
- Computational complexity scales poorly with graph size due to the need for global clustering and connected component searches at each pooling layer
- Empirical validation of the more than 1-WL expressiveness claim relies heavily on synthetic datasets rather than real-world scenarios

## Confidence

- **High Confidence**: The hierarchical pooling mechanism is clearly described and appears correctly implemented based on architectural details
- **Medium Confidence**: Empirical results showing comparable accuracy and improved interpretability are convincing, but synthetic datasets may not fully represent real-world complexity
- **Low Confidence**: Theoretical expressiveness claims and novel concept conformity metric require more rigorous validation beyond current experimental setup

## Next Checks

1. **Real-World Expressiveness Test**: Design a real-world dataset where 1-WL expressiveness limitation matters (e.g., molecular graphs with isomorphic substructures conveying different properties) to empirically verify HELP's expressiveness advantage

2. **Concept Conformity Sensitivity Analysis**: Systematically vary the threshold parameter t in concept conformity across a range of values and analyze how it affects interpretability metrics and downstream performance

3. **Scalability Benchmark**: Implement HELP on large-scale graph datasets (e.g., OGB datasets with thousands of nodes) and measure computational overhead and memory requirements compared to non-hierarchical pooling methods