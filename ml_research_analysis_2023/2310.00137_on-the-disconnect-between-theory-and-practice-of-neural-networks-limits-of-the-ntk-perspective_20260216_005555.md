---
ver: rpa2
title: 'On the Disconnect Between Theory and Practice of Neural Networks: Limits of
  the NTK Perspective'
arxiv_id: '2310.00137'
source_url: https://arxiv.org/abs/2310.00137
tags:
- neural
- task
- kernel
- networks
- regime
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether the neural tangent kernel (NTK)
  framework accurately describes the behavior of practical neural networks used in
  real-world applications. While NTK theory suggests that wide neural networks converge
  to a kernel regime with desirable properties (e.g., faster optimization, better
  uncertainty quantification, reduced catastrophic forgetting), the authors empirically
  demonstrate that these theoretical predictions do not hold for common architectures.
---

# On the Disconnect Between Theory and Practice of Neural Networks: Limits of the NTK Perspective

## Quick Facts
- arXiv ID: 2310.00137
- Source URL: https://arxiv.org/abs/2310.00137
- Reference count: 24
- Key outcome: NTK theory's predictions fail to hold for practical neural networks in optimization, uncertainty quantification, and continual learning tasks

## Executive Summary
This paper empirically investigates whether the neural tangent kernel (NTK) framework accurately describes practical neural networks used in real-world applications. While NTK theory suggests that wide neural networks converge to a kernel regime with desirable properties, the authors demonstrate that these theoretical predictions fail for common architectures. The study examines three key areas: optimization (where second-order methods fail to achieve predicted fast convergence), uncertainty quantification (where NTK-based methods perform poorly), and continual learning (where increasing width doesn't reduce catastrophic forgetting). The authors conclude that NTK framework assumptions are too restrictive for practical networks, calling into question the relevance of NTK theory for guiding architectural and algorithmic choices in deep learning.

## Method Summary
The paper conducts systematic experiments across three problem domains using standard datasets and architectures. For optimization, they train fully connected networks and WideResNets with varying widths, computing Jacobian conditions and testing natural gradient descent convergence. For uncertainty quantification, they implement neural bandit algorithms using NTK-based exploration parameters on UCI benchmark datasets. For continual learning, they train networks on sequential tasks using RotatedMNIST, SplitCIFAR10, SplitCIFAR100, and SplitTinyImageNet, measuring forgetting and accuracy metrics. The experiments systematically vary network width and depth while tracking NTK approximation quality and performance metrics to evaluate theoretical predictions.

## Key Results
- Natural gradient descent fails to achieve faster convergence than standard gradient descent due to non-linear behavior of practical networks
- Neural bandit algorithms using NTK-based exploration parameters perform poorly compared to simpler methods
- Increasing network width does not reduce catastrophic forgetting in continual learning unless networks are undertrained
- NTK framework assumptions break down even at very large widths (up to 10^7 parameters for some architectures)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The NTK framework predicts that wide neural networks converge to a linear model with fixed features, enabling simplified optimization and uncertainty quantification.
- Mechanism: As network width increases, the Jacobian becomes stable and gradients align with the NTK, causing the network to behave like a kernel method. This allows convex optimization, closed-form solutions, and GP-based uncertainty.
- Core assumption: The network remains close to its initialization during training (lazy training), so the linear approximation holds.
- Evidence anchors:
  - [abstract] "By approaching infinite width, NNs effectively converge to a linear model with features characterized by the neural tangent kernel (NTK)."
  - [section 2] "For infinitely wide fully connected NNs, the parameters remain sufficiently close to their initialization θ0 during training via gradient descent."
- Break condition: If the Jacobian changes significantly during training (non-lazy behavior), the linear approximation breaks down and the NTK no longer describes the network.

### Mechanism 2
- Claim: In the kernel regime, natural gradient descent (NGD) converges faster than standard gradient descent due to the near-convex loss landscape.
- Mechanism: NGD uses the Fisher information matrix (approximated by the NTK) to precondition gradients, effectively performing kernel gradient descent. This exploits the quadratic nature of the loss in the kernel regime.
- Core assumption: The network is sufficiently close to the kernel regime, satisfying the stable Jacobian and full row-rank conditions.
- Evidence anchors:
  - [section 3.1] "Du et al. (2019) have shown that gradient descent, a first-order method, can achieve zero training loss in spite of non-convexity."
  - [section 3.1] "In the kernel regime, NGD has favorable convergence over GD in theory."
- Break condition: If either the Gram matrix lacks full row-rank or the Jacobian is unstable (changes too much), NGD loses its convergence advantage.

### Mechanism 3
- Claim: The empirical NTK provides uncertainty quantification in neural bandits via the linearized Laplace approximation, enabling exploration-exploitation trade-offs.
- Mechanism: The empirical NTK at the MAP estimate approximates the posterior covariance, quantifying uncertainty for action selection in bandit problems.
- Core assumption: The finite-width NTK is a good approximation of the true NTK, which requires the network to be in the kernel regime.
- Evidence anchors:
  - [section 3.2] "This can be thought of as a finite-width approximation to the limiting GP in the kernel regime, or equivalently from a weight space view as a linearized Laplace approximation (LLA)."
  - [section 3.2] "Recent works prove (near-)optimal regret bounds for the neural bandit setting by choosing γt based on the kernel regime."
- Break condition: If the network is not in the kernel regime, the empirical NTK poorly approximates the true NTK, leading to overexploration or underexploration.

## Foundational Learning

- Concept: Gaussian Processes and Kernel Methods
  - Why needed here: The NTK framework connects neural networks to GPs, so understanding GP priors, posteriors, and kernel regression is essential.
  - Quick check question: Can you explain how a GP posterior mean and covariance are computed using a kernel matrix?

- Concept: Linearization and Taylor Approximation
  - Why needed here: The NTK arises from linearizing the neural network around its initialization, so understanding first-order Taylor expansions is crucial.
  - Quick check question: What is the first-order Taylor expansion of f(x; θ) around θ0, and what role does the Jacobian play?

- Concept: Optimization Landscape Analysis
  - Why needed here: The paper investigates whether networks are close enough to the kernel regime for optimization benefits, requiring understanding of convexity, gradient descent, and second-order methods.
  - Quick check question: How does the convexity of a quadratic loss differ from the non-convexity of a typical neural network loss?

## Architecture Onboarding

- Component map: Data preprocessing -> Neural network model -> NTK computation -> Optimization -> Uncertainty quantification -> Continual learning setup
- Critical path: 1. Load dataset and preprocess, 2. Initialize neural network with specified architecture, 3. Compute empirical NTK at initialization, 4. Train network using chosen optimizer, 5. Evaluate performance and NTK approximation quality, 6. Compute forgetting metrics for continual learning
- Design tradeoffs: Width vs. depth (wider networks approach kernel regime faster but are computationally expensive), training duration (undertraining may show kernel benefits but reduces accuracy), parametrization (standard vs NTK parametrization affects kernel regime convergence rate)
- Failure signatures: Large difference between empirical NTK and theoretical predictions, Jacobian instability during training, poor NGD performance vs GD, overexploration in neural bandits using NTK parameters
- First 3 experiments: 1. Verify NTK approximation by comparing network predictions with GP using computed NTK, 2. Test NGD convergence vs GD on same network, 3. Measure forgetting across task sequences

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact width threshold at which practical neural networks begin to exhibit NTK-like behavior in terms of optimization, uncertainty quantification, and continual learning?
- Basis in paper: [inferred] The paper shows that practical networks do not exhibit NTK-like behavior even at very large widths (up to 10^7 for some architectures), but does not establish a precise threshold where behavior might start to change.
- Why unresolved: The paper demonstrates that practical architectures fail to show NTK-like behavior at realistic widths, but does not systematically map out the relationship between width and NTK regime convergence across different architectures and tasks.
- What evidence would resolve it: Systematic empirical studies varying width across multiple orders of magnitude for various architectures, tracking NTK approximation quality and the three performance metrics (optimization speed, uncertainty calibration, catastrophic forgetting) to identify any potential transition points.

### Open Question 2
- Question: Are there specific architectural modifications or training procedures that could enable practical networks to exhibit NTK-like behavior without requiring unrealistic width scaling?
- Basis in paper: [explicit] The authors note that achieving competitive performance with wide architectures is challenging due to reduced representation learning, suggesting architectural factors beyond just width may be relevant.
- Why unresolved: The paper identifies the disconnect between NTK theory and practice but does not explore whether architectural innovations could bridge this gap while maintaining practical performance.
- What evidence would resolve it: Empirical testing of modified architectures (different depth-width ratios, alternative activation functions, architectural constraints) and training procedures that maintain NTK-like properties while achieving state-of-the-art performance on standard benchmarks.

### Open Question 3
- Question: How do different neural network parametrizations (e.g., standard vs neural tangent parametrization) affect the convergence to the NTK regime in practical architectures?
- Basis in paper: [explicit] The authors briefly mention that the standard parametrization is the de facto standard in practice and show similar results for both standard and neural tangent parametrizations in their bandit experiments.
- Why unresolved: While the paper demonstrates similar performance for both parametrizations, it does not systematically investigate how different parametrizations affect the rate of convergence to the NTK regime across various architectures and tasks.
- What evidence would resolve it: Comparative studies of different parametrizations across multiple architectures and tasks, measuring NTK approximation quality, optimization dynamics, and other relevant metrics to identify if certain parametrizations better facilitate NTK-like behavior.

## Limitations

- Limited to standard architectures (MLPs, WideResNets) and common benchmark datasets, reducing generalizability
- Optimization experiments focus on shallow networks, potentially missing behavior in deeper architectures
- Does not provide alternative theoretical frameworks to explain observed phenomena beyond identifying NTK breakdown

## Confidence

- Confidence in core claims: **High** - Empirical methodology is sound with consistent results across multiple problem settings
- Confidence in specific failure mechanisms: **Medium** - Identifies symptoms but doesn't fully characterize why practical networks deviate from kernel regime
- Confidence in broader implications: **Low** - Only tests subset of architectures and tasks, limiting generalizability

## Next Checks

1. Test deeper networks (ResNets, transformers) to determine if NTK breakdown is architecture-dependent or universal
2. Vary initialization schemes and learning rates to identify conditions under which NTK assumptions might hold
3. Compare NTK-based uncertainty quantification against modern Bayesian neural network methods on the same bandit tasks