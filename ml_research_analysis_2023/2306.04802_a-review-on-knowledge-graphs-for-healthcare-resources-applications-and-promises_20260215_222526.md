---
ver: rpa2
title: 'A Review on Knowledge Graphs for Healthcare: Resources, Applications, and
  Promises'
arxiv_id: '2306.04802'
source_url: https://arxiv.org/abs/2306.04802
tags:
- knowledge
- data
- graph
- drug
- healthcare
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides the first comprehensive overview of Healthcare
  Knowledge Graphs (HKGs), covering their construction methodologies, utilization
  approaches, and applications across biomedical research, pharmaceutical development,
  clinical decision support, and public health. The review highlights two primary
  construction approaches: building HKGs from scratch using entity extraction and
  ontology mapping, or integrating existing datasets through knowledge graph fusion
  techniques.'
---

# A Review on Knowledge Graphs for Healthcare: Resources, Applications, and Promises

## Quick Facts
- arXiv ID: 2306.04802
- Source URL: https://arxiv.org/abs/2306.04802
- Reference count: 40
- This survey provides the first comprehensive overview of Healthcare Knowledge Graphs (HKGs), covering construction methodologies, utilization approaches, and applications across biomedical research, pharmaceutical development, clinical decision support, and public health.

## Executive Summary
This survey presents the first comprehensive overview of Healthcare Knowledge Graphs (HKGs), examining their construction methodologies, utilization approaches, and applications across multiple healthcare domains. The review categorizes HKGs into two primary construction approaches: building from scratch using entity extraction and ontology mapping, or integrating existing datasets through knowledge graph fusion techniques. Utilization is organized into model-free approaches (query languages, fact-checking) and model-based methods (embedding models, symbolic logic reasoning). The survey compiles existing HKG resources across various domains and emphasizes their potential to revolutionize healthcare by integrating diverse biomedical knowledge and enabling personalized medicine, while identifying key challenges such as data heterogeneity and limited coverage.

## Method Summary
This survey paper reviews existing literature on Healthcare Knowledge Graphs (HKGs) by systematically categorizing construction methodologies and utilization approaches. The review identifies two primary construction approaches: building HKGs from scratch using entity extraction and ontology mapping techniques, or integrating existing datasets through knowledge graph fusion methods. Utilization approaches are categorized into model-free methods (query languages, fact-checking) and model-based techniques (embedding models, symbolic logic reasoning). The paper compiles existing HKG resources across various biomedical domains and examines their applications in drug discovery, clinical decision support, and public health. While the survey provides a comprehensive overview, it does not present original experimental results or implement specific HKG systems.

## Key Results
- HKGs can improve clinical decision support by integrating heterogeneous data sources into structured representations that enable comprehensive reasoning
- Model-based utilization through embeddings enables downstream ML tasks by learning low-dimensional vector representations of entities and relations
- Integration of HKGs with LLMs shows promise for improving reliability and accuracy of healthcare applications through knowledge grounding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HKGs improve clinical decision support by integrating heterogeneous data sources into structured representations
- Mechanism: HKGs provide a unified semantic framework that connects disparate biomedical data (EHR, literature, clinical guidelines) enabling comprehensive reasoning
- Core assumption: Structured knowledge representation enables more accurate clinical reasoning than isolated data sources
- Evidence anchors:
  - [abstract] "facilitates an interpretable representation of medical concepts such as drugs and disease, which enables context-aware insights and enhances clinical research, decision-making, and healthcare delivery"
  - [section] "HKGs can be used to develop clinical decision support systems that provide clinicians with relevant information, improving clinical workflows and patient outcomes"
- Break condition: When data heterogeneity is too complex to resolve into consistent semantic relationships

### Mechanism 2
- Claim: Model-based utilization of HKGs through embeddings enables downstream ML tasks
- Mechanism: HKG embedding models learn low-dimensional vector representations of entities and relations that can be plugged into neural networks for prediction tasks
- Core assumption: Graph structure contains predictive information that can be captured in learned embeddings
- Evidence anchors:
  - [section] "HKG embedding models are a class of machine learning models that aim to learn low-dimensional vector representations, or embeddings, of the entities and relations in a knowledge graph"
  - [section] "After obtaining HGK embeddings, they can be plugged into any kind of deep neural network and further fine-tuned toward downstream objectives"
- Break condition: When the graph structure becomes too sparse or the embedding space fails to capture meaningful relationships

### Mechanism 3
- Claim: Integration of HKGs with LLMs improves reliability and accuracy of healthcare applications
- Mechanism: HKGs provide up-to-date, trustworthy knowledge that can augment LLM outputs, reducing hallucinations and improving factual accuracy
- Core assumption: LLMs benefit from structured knowledge grounding to improve reliability in knowledge-intensive tasks
- Evidence anchors:
  - [abstract] "The synergy between HKGs and LLMs offers promising opportunities for constructing more comprehensive knowledge graphs and improving the accuracy of healthcare applications"
  - [section] "HKGs can also be utilized as an up-to-date and trustworthy augmentation to large language models (LLMs) for many applications"
- Break condition: When the integration complexity outweighs the benefits or when LLMs can learn patterns directly from unstructured data

## Foundational Learning

- Concept: Knowledge Graph Structure and Semantics
  - Why needed here: Understanding how HKGs represent medical concepts and relationships is fundamental to grasping their construction and utilization approaches
  - Quick check question: What distinguishes a healthcare knowledge graph from a general knowledge graph?

- Concept: Graph Neural Networks and Embeddings
  - Why needed here: Model-based utilization approaches rely on learning representations from graph structure for downstream ML tasks
  - Quick check question: How do HKG embeddings differ from traditional node embeddings in homogeneous graphs?

- Concept: Natural Language Processing for Biomedical Text
  - Why needed here: Entity extraction and relation extraction from medical literature and EHRs are critical steps in HKG construction
  - Quick check question: What specialized challenges arise in biomedical named entity recognition compared to general domain NER?

## Architecture Onboarding

- Component map: Data sources layer → Construction pipeline → Embedding generation → Downstream application deployment
- Critical path: Construction pipeline → Embedding generation → Downstream application deployment
- Design tradeoffs:
  - Granularity vs coverage: Fine-grained HKGs capture more detail but may have limited coverage
  - Model-free vs model-based: Query languages offer interpretability but limited reasoning complexity; embeddings enable complex tasks but reduce transparency
  - Scratch construction vs integration: Building from scratch offers control but high cost; integration leverages existing resources but faces alignment challenges
- Failure signatures:
  - Data quality issues manifesting as incomplete or inconsistent entity representations
  - Embedding collapse where graph structure is not preserved in learned representations
  - Integration failures due to schema mismatches or terminology differences
- First 3 experiments:
  1. Implement basic entity extraction from medical literature using BioBERT and evaluate precision/recall on benchmark datasets
  2. Build a small-scale HKG from existing biomedical databases and test basic SPARQL queries for drug-disease relationships
  3. Apply a simple graph embedding method (TransE) to the constructed HKG and evaluate link prediction performance on held-out edges

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can large language models (LLMs) be optimally integrated into the HKG construction pipeline to improve entity extraction, relation extraction, and knowledge fusion while maintaining accuracy and reliability?
- Basis in paper: [explicit] The paper discusses how LLMs have shown great utility in various steps of HKG construction, including named entity recognition, relation extraction, entity linking, and KG completion, but notes that ensuring the quality of extracted knowledge remains an open challenge.
- Why unresolved: While LLMs have demonstrated potential in automating various HKG construction tasks, there is a need to develop robust methods for validating the accuracy and reliability of LLM-generated knowledge, particularly for complex biomedical concepts and relationships.
- What evidence would resolve it: Comparative studies evaluating the performance of LLM-based HKG construction methods against traditional approaches, using metrics such as precision, recall, and F1-score, would provide evidence of their effectiveness. Additionally, qualitative assessments of the interpretability and explainability of LLM-generated HKGs would be valuable.

### Open Question 2
- Question: What are the most effective techniques for resolving conflicts and integrating heterogeneous data sources when constructing comprehensive HKGs?
- Basis in paper: [explicit] The paper mentions that healthcare KG integration is challenging due to different terminologies, schemas, and data formats, and highlights the need for techniques such as ontology matching, schema alignment, entity resolution, and conflict resolution.
- Why unresolved: Integrating diverse biomedical data sources into a unified HKG requires addressing complex issues such as semantic heterogeneity, data quality, and scalability, which remain active areas of research.
- What evidence would resolve it: Empirical evaluations of different integration techniques on real-world biomedical datasets, measuring factors such as integration accuracy, coverage, and scalability, would provide insights into the most effective approaches.

### Open Question 3
- Question: How can HKGs be leveraged to improve clinical decision support systems and enable personalized medicine?
- Basis in paper: [explicit] The paper discusses the potential of HKGs to revolutionize healthcare by integrating diverse biomedical knowledge and enabling personalized medicine, but acknowledges that challenges such as data heterogeneity and limited coverage need to be addressed.
- Why unresolved: While HKGs offer a promising framework for organizing and integrating medical knowledge, their practical application in clinical decision support and personalized medicine requires further research to address issues such as data privacy, interpretability, and integration with existing clinical workflows.
- What evidence would resolve it: Clinical studies evaluating the impact of HKG-based decision support systems on patient outcomes, as well as user studies assessing the usability and interpretability of these systems for clinicians, would provide evidence of their effectiveness in real-world settings.

## Limitations
- Heterogeneous quality and coverage across different HKGs making direct comparisons difficult
- Lack of standardized evaluation protocols for HKG applications
- Potential scalability issues when integrating large-scale biomedical datasets

## Confidence
- HKG effectiveness in clinical decision support and drug discovery applications: **Medium confidence** - Limited empirical validation across surveyed literature
- Integration of HKGs with LLMs: **Low confidence** - Primarily theoretical discussion without concrete implementations or benchmarks

## Next Checks
1. **Benchmark Development**: Create a standardized evaluation framework for HKG applications in clinical decision support, including common datasets, performance metrics, and baseline models for fair comparison across studies.

2. **Integration Feasibility Study**: Implement and evaluate a prototype system combining an existing HKG (e.g., HetioNet) with an LLM for a specific healthcare task (e.g., drug repurposing), measuring improvements in factual accuracy versus LLM alone.

3. **Coverage Analysis**: Conduct a systematic assessment of knowledge coverage gaps across major HKGs in different biomedical domains, identifying specific areas where current HKGs fail to capture critical relationships needed for clinical applications.