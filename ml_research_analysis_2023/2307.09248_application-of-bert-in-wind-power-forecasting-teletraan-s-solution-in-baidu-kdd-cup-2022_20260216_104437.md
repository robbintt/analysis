---
ver: rpa2
title: Application of BERT in Wind Power Forecasting-Teletraan's Solution in Baidu
  KDD Cup 2022
arxiv_id: '2307.09248'
source_url: https://arxiv.org/abs/2307.09248
tags:
- wind
- power
- prediction
- bert
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents a solution to wind power forecasting using a
  BERT model for the Baidu KDD Cup 2022 competition. The authors address the challenge
  of predicting wind power for 142 turbines over a 2-day horizon with 10-minute intervals,
  given up to 14 days of historical data.
---

# Application of BERT in Wind Power Forecasting-Teletraan's Solution in Baidu KDD Cup 2022

## Quick Facts
- arXiv ID: 2307.09248
- Source URL: https://arxiv.org/abs/2307.09248
- Authors: 
- Reference count: 22
- 3rd place in Baidu KDD Cup 2022 wind power forecasting competition

## Executive Summary
This paper presents a solution to the wind power forecasting challenge in the Baidu KDD Cup 2022 competition. The authors develop a BERT-based model to predict wind power generation for 142 turbines over a 2-day horizon with 10-minute intervals, using up to 14 days of historical data. Their approach achieves 3rd place out of 2490 teams with a leaderboard score of 44.6 in phase II. The solution uses a single BERT encoder block with self-attention, followed by three dense layers, and incorporates a post-processing step to correct for daily periodicity that the model doesn't capture automatically.

## Method Summary
The method employs a single BERT encoder block to process sequences of wind power data, leveraging self-attention to capture long-range dependencies across the 14-day input window. The model takes wind speed and direction as inputs (excluding temperature and spatial features to prevent overfitting) and outputs predictions for 288 10-minute intervals (2 days). A post-processing step adds calculated daily fluctuation patterns to the predictions to compensate for the model's inability to capture daily periodicity. The model is trained using Adam optimizer with learning rate 0.005 for 3 epochs, with batch size 1024, and predictions are made at the turbine level.

## Key Results
- Achieved 3rd place out of 2490 teams in Baidu KDD Cup 2022
- Leaderboard score of 44.6 in phase II of the competition
- Successfully predicts wind power for 142 turbines over 2-day horizon with 10-minute intervals
- Uses minimal feature engineering (wind speed and direction only) while maintaining competitive performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The BERT encoder captures long-term dependencies in wind power sequences, enabling accurate 2-day ahead predictions
- Mechanism: Self-attention layers allow each time step to directly attend to all other time steps in the 14-day input window, modeling complex temporal patterns without vanishing gradients
- Core assumption: Wind power sequences exhibit meaningful long-range dependencies that can be modeled by self-attention
- Evidence anchors:
  - [abstract] "To utilize the advantage of its capturing long dependencies, we implement a BERT model for wind power future prediction"
  - [section 4.3] "We choose a single BERT model [2] as our final model to handle the long dependencies for long sequence prediction"
- Break condition: If wind power generation patterns are primarily driven by very short-term weather dynamics rather than long-range seasonal patterns, the transformer's long-range attention may be overkill

### Mechanism 2
- Claim: Post-processing with daily fluctuation correction compensates for the model's inability to perfectly capture daily periodicity
- Mechanism: The model predicts the base trend, then a calculated daily fluctuation pattern is added to align predictions with observed daily cycles in historical data
- Core assumption: Daily periodicity is strong in historical data but not automatically captured by the model architecture
- Evidence anchors:
  - [section 4.5] "We know it's important for better prediction to capture the trend, seasonality, and spatial information. However, we find our forecasting results don't have obvious daily periodicity, while the descriptive analysis in historical data shows it's strong for most days"
  - [section 4.5] "The first one is to add the daily fluctuation by post-processing. The daily average fluctuation is calculated and added to the prediction result directly"
- Break condition: If daily periodicity is weak or inconsistent across the test period, this correction could introduce errors rather than reduce them

### Mechanism 3
- Claim: Minimal feature engineering with only wind speed and direction prevents overfitting while capturing essential predictive information
- Mechanism: The authors deliberately avoid complex engineered features (lag, rolling, time-based) that might overfit the training data, relying on the model's capacity to extract patterns from raw features
- Core assumption: Wind speed and direction contain sufficient information to predict wind power when combined with the model's attention mechanisms
- Evidence anchors:
  - [section 4.2] "To avoid over-fitting, we try to use as fewer features as possible... So finally we only choose the wind speed and wind direction to train the model"
  - [section 4.2] "The temperature is noisy, so the temperature feature is not involved"
- Break condition: If other features (temperature, spatial information) contain critical predictive signal not captured by wind speed/direction, this minimal approach will limit performance

## Foundational Learning

- Concept: Transformer architecture and self-attention mechanism
  - Why needed here: Understanding how self-attention allows the model to weigh the importance of different time steps in the 14-day input window for predicting each 10-minute interval
  - Quick check question: How does the self-attention mechanism in a transformer differ from recurrent neural network processing of sequences?

- Concept: Time series forecasting evaluation metrics (RMSE, MAE)
  - Why needed here: The competition uses a specific evaluation metric (average of RMSE and MAE) that affects how model performance is measured and optimized
  - Quick check question: What is the difference between RMSE and MAE, and why might averaging them provide a balanced evaluation for wind power forecasting?

- Concept: Data preprocessing for time series (handling missing values, normalization)
  - Why needed here: The dataset contains NaN values and requires standardization, which directly impacts model training and performance
- Quick check question: What are the potential risks of filling missing values with previous values versus using more sophisticated imputation methods?

## Architecture Onboarding

- Component map: Input (10-minute intervals, 14-day window) → Token embedding → Single BERT encoder block (self-attention, feed-forward, layer norm) → Three dense layers (512→1024→288 units) → Output (288 predictions for 2 days) → Post-processing (daily fluctuation addition)
- Critical path: Data preprocessing → Model inference → Post-processing → Metric calculation
- Design tradeoffs: Single BERT block vs. deeper architectures (simplicity and efficiency vs. potential capacity), post-processing vs. end-to-end learning of periodicity (explicit control vs. model autonomy)
- Failure signatures: Large errors on specific times of day (post-processing issue), degradation on longer sequences (attention mechanism limitation), overfitting signs (training much better than validation)
- First 3 experiments:
  1. Test model performance with and without positional encoding to validate the authors' finding that it doesn't significantly impact results
  2. Compare predictions with ground truth to identify systematic patterns in errors (e.g., consistent over/under-prediction at certain times)
  3. Run ablation study removing the post-processing step to quantify its contribution to final performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Would incorporating additional features like temperature and spatial information improve the model's performance if better feature engineering techniques were applied?
- Basis in paper: [inferred] The authors explicitly state that they tried using temperature and spatial information as features but found them unhelpful in their experiments. They attribute this to noisy temperature data and difficulties in capturing spatial relationships.
- Why unresolved: The paper does not explore advanced feature engineering techniques or more sophisticated ways to incorporate spatial information (e.g., using graph neural networks more effectively).
- What evidence would resolve it: Experiments comparing the BERT model's performance with and without enhanced feature engineering techniques or improved spatial information incorporation would provide clarity on the impact of these features.

### Open Question 2
- Question: How would the model's performance change if the temporal granularity of the predictions were altered (e.g., predicting every 30 minutes instead of every 10 minutes)?
- Basis in paper: [explicit] The authors mention that the task requires predictions every 10 minutes for 2 days, but they do not explore the impact of changing this granularity on model performance.
- Why unresolved: The paper focuses on the specific 10-minute interval requirement of the competition and does not investigate the effects of different temporal granularities.
- What evidence would resolve it: Training and evaluating the model on datasets with different temporal granularities (e.g., 30-minute intervals) and comparing the results to the 10-minute predictions would provide insights into the model's performance across different time scales.

### Open Question 3
- Question: Would a more complex BERT architecture (e.g., deeper layers, more attention heads) lead to better performance in wind power forecasting?
- Basis in paper: [explicit] The authors use a single BERT encoder block with a relatively simple configuration (1 encoder layer, 1 attention head, etc.). They mention that their solution is both accurate and efficient but do not explore more complex architectures.
- Why unresolved: The paper focuses on a simple and efficient BERT model and does not investigate the potential benefits of more complex architectures.
- What evidence would resolve it: Experiments comparing the performance of the current BERT model with more complex variants (e.g., deeper layers, more attention heads) would determine if increased model complexity leads to improved forecasting accuracy.

## Limitations

- Model Architecture Simplicity: Uses only a single BERT encoder block, which is unusual and may limit performance compared to deeper architectures
- Limited Feature Set: Excludes temperature and spatial information, potentially missing important predictive signals
- Post-Processing Reliance: Requires manual daily fluctuation correction, indicating the base model doesn't fully capture periodicity

## Confidence

**High Confidence**: The 3rd place competition ranking and the described methodology are verifiable facts. The technical implementation details (BERT with single encoder, three dense layers, specific hyperparameters) appear to be accurately reported.

**Medium Confidence**: The effectiveness of the post-processing step and the decision to exclude temperature features are reasonable based on the authors' experimentation, but could be suboptimal. The claim that temperature is "noisy" lacks quantitative justification.

**Low Confidence**: The assertion that minimal feature engineering prevents overfitting is presented without systematic ablation studies. The choice of a single BERT block versus deeper architectures is not thoroughly justified through comparative experiments.

## Next Checks

1. **Ablation Study**: Run the model with and without the post-processing daily fluctuation addition to quantify its exact contribution to the 44.6 score. This would reveal whether the base model architecture is fundamentally sound or critically dependent on this correction.

2. **Feature Impact Analysis**: Test the model performance when including temperature and spatial features that were excluded. This would validate whether the "minimal features prevent overfitting" hypothesis or reveal missed predictive signals.

3. **Architecture Depth Comparison**: Implement versions with 2-4 BERT encoder blocks with appropriate regularization to determine if the single-block limitation is a genuine architectural choice or a constraint imposed by computational resources or overfitting concerns.