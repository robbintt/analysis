---
ver: rpa2
title: Endogenous Macrodynamics in Algorithmic Recourse
arxiv_id: '2308.08187'
source_url: https://arxiv.org/abs/2308.08187
tags:
- recourse
- have
- shifts
- counterfactual
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the impact of endogenous dynamics in Algorithmic
  Recourse (AR), focusing on how repeated implementation of recourse affects other
  individuals in the group. It proposes a generalized framework that extends the existing
  AR framework to account for external costs incurred by the collective.
---

# Endogenous Macrodynamics in Algorithmic Recourse

## Quick Facts
- arXiv ID: 2308.08187
- Source URL: https://arxiv.org/abs/2308.08187
- Reference count: 40
- Key outcome: Algorithmic Recourse implementation causes domain and model shifts that can impede its applicability; mitigation strategies can reduce these shifts.

## Executive Summary
This paper investigates how repeated implementation of Algorithmic Recourse affects not just individuals but the broader population. Through simulation experiments with various counterfactual generators and datasets, the authors demonstrate that endogenous dynamics create substantial domain and model shifts that can degrade classifier performance over time. They propose a framework that extends individual recourse to account for collective impacts and evaluate several mitigation strategies. The findings suggest a paradigm shift from individual to collective recourse is necessary to ensure long-term effectiveness of algorithmic decision-making systems.

## Method Summary
The study uses a simulation framework where counterfactuals are generated for individuals in the negative class, implemented (effectively adding them to the training data), and the model is retrained. Experiments run for 50 rounds with 5% of the negative class receiving recourse per round. The framework benchmarks five counterfactual generators (Wachter, REVISE, CLUE, DiCE, Greedy) across three classifier types (Logistic Regression, MLP, Deep Ensemble) on both synthetic and real-world datasets. Domain shifts are measured using Maximum Mean Discrepancy (MMD), while model shifts are evaluated through parameter perturbations, F-score changes, and other metrics. The study also tests three mitigation strategies: higher decision thresholds, ClaPROAR, and Gravitational generator.

## Key Results
- Domain and model shifts induced by recourse implementation are substantial enough to likely impede Algorithmic Recourse applicability in some situations
- Latent Space generators (REVISE/CLUE) induce smaller shifts compared to direct feature space generators like Wachter
- All three proposed mitigation strategies effectively reduce both domain and model shifts
- The impact of shifts varies significantly across different classifier types and datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Repeated individual recourse triggers domain and model shifts that degrade classifier performance.
- Mechanism: Each time a counterfactual is generated and "implemented" by an individual, the training distribution changes (domain shift) and the model parameters must be updated (model shift), leading to a cascade of shifts that compound over time.
- Core assumption: The recourse implementation changes the underlying data distribution used for training.
- Evidence anchors:
  - [abstract] "Through simulation experiments involving various state-of-the-art counterfactual generators and several benchmark datasets, we generate large numbers of counterfactuals and study the resulting domain and model shifts."
  - [section V-A] "Along with any other fixed parameters affecting the counterfactual search, the parameters T and B are assumed as given in Algorithm 1. Still, it is worth noting that the higher these values, the more factual instances undergo recourse throughout the entire experiment."

### Mechanism 2
- Claim: Different counterfactual generators have varying impacts on endogenous dynamics.
- Mechanism: Latent Space generators produce counterfactuals closer to the original data distribution, thus inducing smaller domain and model shifts compared to direct feature space generators like Wachter.
- Core assumption: Counterfactuals that are more realistic (closer to the true data-generating process) will cause less disruption to the classifier.
- Evidence anchors:
  - [abstract] "Through simulation experiments... we generate large numbers of counterfactuals and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability of Algorithmic Recourse in some situations."
  - [section VII-A] "ClaPROAR appears to be particularly effective, which is positively surprising since it is designed to explicitly address model shifts, not domain shifts."

### Mechanism 3
- Claim: Mitigation strategies can reduce endogenous shifts by penalizing counterfactuals that deviate from the original data distribution.
- Mechanism: By incorporating penalties that measure the impact of counterfactuals on the classifier (ClaPROAR) or their distance from typical target instances (Gravitational), the search process is steered toward counterfactuals that are less disruptive.
- Core assumption: The mitigation penalties effectively capture the "external cost" of recourse to other individuals.
- Evidence anchors:
  - [abstract] "Fortunately, we find various strategies to mitigate these concerns."
  - [section VII] "Our findings indicate that all three mitigation strategies are at least at par with LS generators with respect to their effectiveness at mitigating domain and model shifts."

## Foundational Learning

- Concept: Maximum Mean Discrepancy (MMD) as a non-parametric measure of domain shift.
  - Why needed here: MMD provides a kernel-based method to quantify differences between the original and counterfactual data distributions without parametric assumptions.
  - Quick check question: If two datasets are drawn from the same distribution, what should the MMD value be? (Answer: 0)

- Concept: Predictive Uncertainty in probabilistic classifiers.
  - Why needed here: Uncertainty measures help generate counterfactuals that the model is confident about, reducing the chance of model shifts.
  - Quick check question: How does predictive entropy relate to the confidence of a classifier's prediction? (Answer: Higher entropy means lower confidence)

- Concept: Reproducing Kernel Hilbert Space (RKHS) and kernel methods.
  - Why needed here: RKHS provides the mathematical framework for MMD and other kernel-based methods used to measure distributional differences.
  - Quick check question: What property of a kernel ensures that MMD=0 if and only if the two distributions are identical? (Answer: Characteristic kernel)

## Architecture Onboarding

- Component map: Data → Counterfactual Generator → Implemented Counterfactual → Retrained Classifier → Evaluation Metrics → Repeat
- Critical path: Generate counterfactual → Implement (update data) → Retrain model → Measure shifts → Compare generators
- Design tradeoffs: Simple linear classifiers are more sensitive to shifts but faster to train; deep ensembles capture uncertainty but are computationally heavier
- Failure signatures: Large increase in MMD with no corresponding increase in model F-score indicates domain shift without model adaptation
- First 3 experiments:
  1. Run Wachter generator on synthetic overlapping data for T=50 rounds with B=5% per round, measure MMD and F-score
  2. Compare Latent Space generators (REVISE/CLUE) on the same setup to quantify relative shift reduction
  3. Apply ClaPROAR mitigation to Wachter generator and measure impact on domain and model shifts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the trade-off between private costs to individuals and external costs to the collective be optimally resolved in practice?
- Basis in paper: [explicit] The paper acknowledges the existence of this trade-off but does not provide a definitive answer on how to resolve it.
- Why unresolved: The paper suggests the potential for Pareto optimal Algorithmic Recourse but does not explore this concept in detail.
- What evidence would resolve it: A formal analysis of Pareto optimal Algorithmic Recourse and its practical implementation would provide a definitive answer to this question.

### Open Question 2
- Question: How do endogenous shifts interact with exogenous shifts in real-world scenarios?
- Basis in paper: [inferred] The paper acknowledges that its experimental design is a simplification of real-world scenarios and that endogenous shifts may be entangled with exogenous shifts.
- Why unresolved: The paper does not conduct experiments to explore the interaction between endogenous and exogenous shifts.
- What evidence would resolve it: Experiments that simulate real-world scenarios with both endogenous and exogenous shifts would provide insights into their interaction.

### Open Question 3
- Question: How can causal knowledge be incorporated into counterfactual generators to prevent gaming?
- Basis in paper: [explicit] The paper suggests that incorporating causal knowledge into counterfactual generators may help prevent gaming.
- Why unresolved: The paper does not explore this concept in detail or provide examples of how it could be implemented.
- What evidence would resolve it: The development and testing of counterfactual generators that incorporate causal knowledge would provide evidence of their effectiveness in preventing gaming.

### Open Question 4
- Question: How do different machine learning models, such as boosted decision trees, perform in terms of endogenous macrodynamics compared to deep neural networks?
- Basis in paper: [inferred] The paper focuses on deep neural networks and logistic regression, but acknowledges that other models may have an edge in certain scenarios.
- Why unresolved: The paper does not conduct experiments to compare the performance of different machine learning models in terms of endogenous macrodynamics.
- What evidence would resolve it: Experiments that compare the performance of different machine learning models in terms of endogenous macrodynamics would provide insights into their relative strengths and weaknesses.

## Limitations
- The simulation relies on synthetic data where domain shifts are explicitly controlled, which may not fully capture real-world dynamics
- The study assumes all counterfactuals are successfully implemented, ignoring potential implementation barriers
- Mitigation strategies, while effective in simulation, may face practical deployment challenges

## Confidence
- Core finding (endogenous dynamics exist and cause measurable shifts): **High**
- Comparative effectiveness of generators and mitigation strategies: **Medium**
- Practical applicability of findings to real-world systems: **Medium**

## Next Checks
1. Test the simulation framework on a real-world dataset with naturally occurring data drift to assess the external validity of the endogenous shift findings
2. Implement one mitigation strategy (e.g., ClaPROAR) in a deployed ML system to evaluate its practical effectiveness and computational overhead
3. Conduct a sensitivity analysis on the recourse implementation rate (B) and retraining frequency (T) to identify the threshold where endogenous shifts become prohibitive