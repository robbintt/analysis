---
ver: rpa2
title: 'Representation Learning for Person or Entity-centric Knowledge Graphs: An
  Application in Healthcare'
arxiv_id: '2305.05640'
source_url: https://arxiv.org/abs/2305.05640
tags:
- https
- data
- graph
- knowledge
- graphs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel end-to-end framework for extracting
  entity-centric knowledge graphs from structured and unstructured healthcare data.
  The framework uses a star-shaped ontology (HSPO) to model a comprehensive view of
  patients, capturing clinical, demographic, and social factors.
---

# Representation Learning for Person or Entity-centric Knowledge Graphs: An Application in Healthcare

## Quick Facts
- arXiv ID: 2305.05640
- Source URL: https://arxiv.org/abs/2305.05640
- Reference count: 40
- Primary result: GNN-based framework for entity-centric KG extraction and representation learning outperforms traditional classifiers on ICU readmission prediction

## Executive Summary
This paper introduces a novel end-to-end framework for extracting entity-centric knowledge graphs from structured and unstructured healthcare data. The framework uses a star-shaped ontology (HSPO) to model a comprehensive view of patients, capturing clinical, demographic, and social factors. Graphs are generated and transformed into formats suitable for graph neural networks (GNNs), which are then used to learn patient representations for predictive tasks. Experiments on ICU readmission prediction demonstrate that the approach outperforms traditional machine learning classifiers, achieving 68.06% F1-score and 62.16% accuracy. The method is robust to missing data and generalizable across domains. The framework is open-sourced, scalable, and has potential applications in various healthcare predictive tasks.

## Method Summary
The method extracts entity-centric knowledge graphs from MIMIC-III ICU data using a Health & Social Person-centric Ontology (HSPO). Structured data (demographics, diagnoses, medications) and unstructured clinical notes are processed to create patient-centered graphs. These graphs are transformed into PyTorch Geometric format with bag-of-words node embeddings. Two GNN architectures (GraphSage and Graph Attention Network) are trained to learn patient representations for predictive tasks. The framework handles missing data through the star-shaped structure and message-passing mechanism. Experiments include ablation studies to test robustness.

## Key Results
- GNN models (PKGSage, PKGA) outperform traditional classifiers (KNN, SVM, DT, AdaBoost, NB, GP) on ICU readmission prediction
- Best model achieves 68.06% F1-score and 62.16% accuracy on test set
- Framework shows robustness to missing data, with limited performance deterioration in ablation studies
- Performance varies across four graph versions, with directed structures showing different characteristics than undirected ones

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Star-shaped ontology design improves patient representation by centering all features around a single patient node.
- Mechanism: By enforcing a central "person" node with directed edges to clinical, demographic, and social facets, the graph ensures all information is directly or indirectly connected to the patient, simplifying representation learning.
- Core assumption: The patient node acts as a consistent anchor that captures the full scope of a person's health context.
- Evidence anchors:
  - [abstract] "We introduce a star-shaped ontology to represent the multiple facets of a person and use it to guide KG creation."
  - [section 3] "The HSPO defines a schema for a star-shaped Personal Knowledge Graph [3] with a person as a central node of the graph and corresponding characteristics or features linked to the central node."
  - [corpus] Weak; corpus neighbors are about general KG construction, not entity-centric schemas.
- Break condition: If the central patient node becomes disconnected from some relevant features, the representation may lose critical context.

### Mechanism 2
- Claim: Graph Neural Networks (GNNs) effectively learn patient representations by aggregating information across the star-shaped graph.
- Mechanism: GNNs perform message passing across nodes and edges, propagating and combining node features (initialized via bag-of-words) to update the patient node representation.
- Core assumption: Message passing can handle the heterogeneity of relation types and sparse initial embeddings without overfitting.
- Evidence anchors:
  - [abstract] "Compact representations of the graphs are created leveraging graph neural networks (GNNs)."
  - [section 5.1] "We experiment with 2 different GNN architectures... The first model (PKGSage) is based on Sage Graph Convolution Network... and the second (PKGA) utilizes the Graph Attention Network (GAT) architecture."
  - [corpus] Weak; corpus focuses on KG construction, not GNN-based learning.
- Break condition: If the graph becomes too sparse or highly heterogeneous, message passing may fail to propagate useful signals to the patient node.

### Mechanism 3
- Claim: The framework is robust to missing data due to its star-shaped structure and the way GNNs aggregate information.
- Mechanism: Missing attributes in structured data are handled by the inherent sparsity of the initial node representations and the message-passing mechanism, which can infer missing context from connected nodes.
- Core assumption: GNNs can generalize effectively even when some nodes or edges are missing.
- Evidence anchors:
  - [section 4.2] "Information may be missing for multiple reasons... More precisely, we observe that for some fields... there is a significant percentage of missing information."
  - [section 5.5] "The robustness of the models in handling missing information is profound as the performance deterioration is limited."
  - [corpus] Weak; corpus does not address missing data in KG learning explicitly.
- Break condition: If too many critical nodes (e.g., diagnoses) are missing, the GNN may not be able to infer enough context for accurate predictions.

## Foundational Learning

- Concept: Knowledge Graphs and Ontologies
  - Why needed here: Understanding how entities, relations, and schemas are structured in KGs is foundational to building and querying person-centric graphs.
  - Quick check question: What is the difference between a node and an edge in a knowledge graph?
- Concept: Graph Neural Networks (GNNs)
  - Why needed here: GNNs are the core model used to learn embeddings from the patient-centric graphs; understanding message passing and aggregation is key.
  - Quick check question: How does a Graph Attention Network differ from a Graph Convolution Network in terms of node feature aggregation?
- Concept: RDF and SPARQL
  - Why needed here: The framework outputs KGs in RDF format, and SPARQL is used to query them; familiarity with these is needed for integration and evaluation.
  - Quick check question: What is the purpose of the triple format in RDF?

## Architecture Onboarding

- Component map:
  - Data Preprocessing Pipeline → HSPO Ontology → RDF-based KG Extraction → Graph Transformation (RDF→PyTorch Geometric) → GNN Models (PKGSage, PKGA) → Prediction Task
- Critical path:
  1. Load and preprocess MIMIC-III data (demographic, clinical, social).
  2. Apply HSPO schema to create RDF-based person-centric KGs.
  3. Transform RDF graphs into PyTorch Geometric format.
  4. Train GNN models on transformed graphs for ICU readmission prediction.
- Design tradeoffs:
  - Heterogeneous vs. simplified graph structures: More relations increase expressiveness but also model complexity and risk of overfitting.
  - BOW initialization vs. language model embeddings: BOW is simple but sparse; language models could provide richer initial features.
- Failure signatures:
  - Poor performance when directed vs. undirected edges are not chosen appropriately.
  - Instability during training when introducing group nodes (as seen in the fourth graph version).
  - Limited improvement over baseline models if the graph structure is too simplified.
- First 3 experiments:
  1. Train PKGSage on the simplest directed graph version (V1) and evaluate accuracy/F1.
  2. Train PKGA on the undirected third graph version (V3) to compare architecture impact.
  3. Perform ablation by removing disease nodes to test model robustness to missing clinical data.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed star-shaped Health & Social Person-centric Ontology (HSPO) perform in terms of scalability and generalizability when applied to new healthcare domains or expanded with additional facets?
- Basis in paper: [explicit] The paper mentions the HSPO is designed to be expanded with additional domains and facets and the framework is generalizable across domains, but does not provide empirical evidence of its performance in new domains or with expanded facets.
- Why unresolved: The paper focuses on a single use case (ICU readmission prediction) and does not explore the ontology's performance in other healthcare domains or with additional facets.
- What evidence would resolve it: Empirical studies applying the HSPO to new healthcare domains (e.g., oncology, mental health) or expanded with new facets (e.g., behavioral, biological) and evaluating its performance in those contexts.

### Open Question 2
- Question: What is the optimal level of heterogeneity for the person-centric knowledge graphs in terms of relation types and node initialization for different downstream tasks?
- Basis in paper: [explicit] The paper experiments with different graph structures and levels of heterogeneity, but notes that finding the optimal level is an open and challenging research question that depends on the available data, the downstream task, and the model architecture.
- Why unresolved: The paper does not provide a definitive answer on the optimal level of heterogeneity, as it varies based on the specific task and data.
- What evidence would resolve it: Systematic studies comparing the performance of person-centric knowledge graphs with varying levels of heterogeneity across different downstream tasks and datasets.

### Open Question 3
- Question: How do the proposed person-centric knowledge graph representations compare to traditional feature-based approaches in terms of robustness to missing data and ability to capture complex patient characteristics?
- Basis in paper: [explicit] The paper demonstrates the robustness of the proposed approach to missing data through an ablation study, but does not directly compare it to traditional feature-based approaches in this aspect.
- Why unresolved: The paper focuses on the performance of the proposed approach but does not provide a direct comparison to traditional methods in terms of robustness to missing data and ability to capture complex patient characteristics.
- What evidence would resolve it: Comparative studies between the proposed person-centric knowledge graph approach and traditional feature-based approaches, evaluating their performance in handling missing data and capturing complex patient characteristics.

## Limitations
- Performance evaluation limited to one dataset (MIMIC-III) and one predictive task (ICU readmission)
- Claims about scalability and generalizability are asserted but not empirically validated
- BOW initialization may be suboptimal compared to language model embeddings
- Impact of different graph topologies on message passing effectiveness not fully analyzed

## Confidence

- **High confidence**: The framework's ability to extract entity-centric KGs using HSPO and RDF, and its application to ICU readmission prediction.
- **Medium confidence**: The superiority of GNN-based models over traditional classifiers, and the framework's robustness to missing data.
- **Low confidence**: Claims about generalizability to other healthcare tasks and scalability to larger datasets.

## Next Checks
1. **Generalization Test**: Apply the framework to a different healthcare prediction task (e.g., sepsis detection) using MIMIC-III or another EHR dataset to validate cross-task applicability.
2. **Missing Data Robustness**: Systematically vary the percentage and types of missing data (structured, unstructured, social determinants) and measure impact on model performance to better understand robustness.
3. **Graph Topology Analysis**: Compare model performance across the four graph versions (V1-V4) with detailed analysis of message passing effectiveness and feature propagation in each topology.