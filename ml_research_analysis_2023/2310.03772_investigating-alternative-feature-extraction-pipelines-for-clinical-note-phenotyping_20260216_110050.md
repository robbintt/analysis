---
ver: rpa2
title: Investigating Alternative Feature Extraction Pipelines For Clinical Note Phenotyping
arxiv_id: '2310.03772'
source_url: https://arxiv.org/abs/2310.03772
tags:
- investigatingalternativefeatureextractionpipelinesforclinicalnotephenotyping
- page
- clinical
- attributes
- additionally
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates alternative feature extraction pipelines
  for clinical note phenotyping, focusing on extracting medical attributes from clinical
  notes. The authors propose a method using ScispaCy to identify common medical diseases
  and conditions in clinical notes, followed by training supervised learning models
  to associate the presence of these conditions with patient attributes.
---

# Investigating Alternative Feature Extraction Pipelines For Clinical Note Phenotyping

## Quick Facts
- arXiv ID: 2310.03772
- Source URL: https://arxiv.org/abs/2310.03772
- Reference count: 2
- The alternative ScispaCy pipeline moderately underperforms ClinicalBERT+LSTM but offers significant runtime advantages (4 vs 24 hours)

## Executive Summary
This paper proposes an alternative feature extraction pipeline for clinical note phenotyping using ScispaCy for medical entity extraction and simple supervised learning models. The approach extracts common medical diseases and conditions from clinical notes, then trains classifiers to associate these conditions with patient attributes. While moderately underperforming the ClinicalBERT+LSTM baseline (F1-score 0.7561 vs 0.9278), the ScispaCy method offers substantial runtime advantages and can detect medical conditions not present in training notes.

## Method Summary
The proposed method uses ScispaCy's en_ner_bc5cdr_md model to extract the 250 most common medical terms from clinical notes, creating binary feature vectors indicating term presence. Principal component analysis reduces these features to 7 components, and simple classifiers (K-NN with K=27, SVM, MLP) are trained to predict patient attributes. This is compared against a ClinicalBERT+LSTM approach that uses embeddings from tokenized clinical notes passed through an LSTM with early stopping and dynamic learning rate adjustment.

## Key Results
- K-NN achieves highest F1-score (0.7561) among simple supervised algorithms
- ClinicalBERT+LSTM achieves superior F1-score (0.9278)
- ScispaCy pipeline requires only 4 hours vs 24 hours for ClinicalBERT+LSTM
- The alternative method can detect medical conditions not present in training notes

## Why This Works (Mechanism)

### Mechanism 1
- Using ScispaCy for medical entity extraction enables faster runtime and broader condition detection compared to embedding-based approaches
- Core assumption: Medical entity extraction can be effectively decoupled from the downstream classification task
- Break condition: Poor entity extraction quality due to medical terms not well-represented in ScispaCy's training corpus

### Mechanism 2
- Simple supervised learning models with PCA dimensionality reduction achieve reasonable performance with minimal computational resources
- Core assumption: The relationship between medical term presence and patient attributes is linearly separable or can be approximated by simple nonlinear models
- Break condition: Feature space requires complex nonlinear relationships that simple models cannot capture

### Mechanism 3
- Early stopping and dynamic learning rate adjustment prevent LSTM models from memorizing single class labels
- Core assumption: LSTM's tendency to memorize can be detected through F1-score monitoring and corrected through model reinitialization
- Break condition: Severe class imbalance or small dataset size overwhelms these stabilization measures

## Foundational Learning

- **Principal Component Analysis**
  - Why needed here: Reduces dimensionality of extracted medical term features while preserving variance
  - Quick check question: If you have 250 extracted medical terms but want to reduce to 7 components, what percentage of variance should you aim to preserve?

- **Medical Named Entity Recognition**
  - Why needed here: Identifies medical conditions in clinical text that can be used as features for classification
  - Quick check question: What's the difference between using a rule-based NER system versus a trained model like ScispaCy for medical entity extraction?

- **F1-score as Classification Metric**
  - Why needed here: Balances precision and recall, critical for medical diagnosis tasks
  - Quick check question: If a classifier has precision of 0.8 and recall of 0.6, what is its F1-score?

## Architecture Onboarding

- **Component map**: Data preprocessing → ScispaCy entity extraction → Feature matrix construction → PCA dimensionality reduction → Classification model → Evaluation
- **Alternative path**: Tokenization → ClinicalBERT embedding → LSTM classification → Evaluation

- **Critical path**: ScispaCy entity extraction → Feature matrix creation → PCA → Classification training
  - The ScispaCy step is critical because poor entity extraction directly impacts downstream classification performance

- **Design tradeoffs**:
  - Speed vs accuracy: ScispaCy + simple classifiers (4 hours) vs ClinicalBERT + LSTM (24 hours)
  - Generality vs specificity: Detecting conditions not in training notes vs focusing on known conditions
  - Interpretability vs performance: K-NN provides explainable predictions vs LSTM's black-box nature

- **Failure signatures**:
  - Low entity extraction recall → Sparse feature matrices → Poor classifier performance
  - Overfitting in LSTM → Single-class predictions → Need for F1-score monitoring and reinitialization
  - High class imbalance → SVM underperformance → Consider weighted loss functions

- **First 3 experiments**:
  1. Run ScispaCy entity extraction on training data and verify top 250 terms cover known medical conditions
  2. Train K-NN classifier with varying K values (start with K=27) and evaluate F1-score on validation set
  3. Implement F1-score monitoring during LSTM training and test reinitialization when initial F1 > 0.6

## Open Questions the Paper Calls Out

- **How does the proposed ScispaCy-based method perform on clinical notes containing rare or uncommon medical conditions that are not well-represented in the BC5CDR corpus?**
- **How would performance change if more advanced feature extraction techniques like attention mechanisms or graph neural networks were used instead of simple supervised learning algorithms?**
- **How does the proposed method's performance on smoking status classification compare to other binary classification tasks like detecting diabetes or hypertension?**

## Limitations
- Evaluation based on single dataset (N2C22006 smoking status) with small sample sizes
- Lacks ablation studies to determine which pipeline components contribute most to performance
- No formal analysis of computational resource requirements beyond wall-clock time

## Confidence
- **High Confidence**: Runtime performance comparison (4 hours vs 24 hours) and F1-score measurements
- **Medium Confidence**: Claims about detecting conditions not present in training notes
- **Low Confidence**: Claims about general applicability to other clinical phenotyping tasks

## Next Checks
1. Test the ScispaCy pipeline on at least two additional clinical phenotyping tasks to verify performance across different medical domains
2. Conduct comprehensive resource utilization study comparing GPU memory usage, CPU load, and wall-clock time for both pipelines
3. Perform ablation study systematically removing or modifying components of the ScispaCy pipeline to identify performance contributors