---
ver: rpa2
title: 'unORANIC: Unsupervised Orthogonalization of Anatomy and Image-Characteristic
  Features'
arxiv_id: '2308.15507'
source_url: https://arxiv.org/abs/2308.15507
tags:
- uni00000052
- unoranic
- uni00000056
- image
- anatomy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents unORANIC, an unsupervised approach to orthogonalize
  anatomy and image-characteristic features for robust medical image analysis. The
  method trains two encoder-decoder branches simultaneously: one for anatomy features
  and another for characteristic features.'
---

# unORANIC: Unsupervised Orthogonalization of Anatomy and Image-Characteristic Features

## Quick Facts
- arXiv ID: 2308.15507
- Source URL: https://arxiv.org/abs/2308.15507
- Authors: 
- Reference count: 29
- Primary result: Unsupervised approach orthogonalizing anatomy and image-characteristic features achieves robust medical image reconstruction and classification without labels

## Executive Summary
unORANIC presents an unsupervised method for separating anatomical features from image acquisition characteristics in medical imaging. The approach trains two encoder-decoder branches simultaneously, enforcing consistency across corrupted image variants to learn distortion-invariant anatomical features while preserving corruption-specific details. The method demonstrates strong performance across five medical imaging datasets, achieving robust reconstruction quality and effective corruption detection capabilities. Notably, unORANIC achieves these results without requiring labels, paired data, or domain-specific knowledge, making it a versatile solution for medical image analysis applications.

## Method Summary
The method employs a two-branch encoder-decoder architecture with a shared anatomy encoder and separate characteristic encoder. During training, input images are distorted using augmentation to generate multiple variants, which are passed through the anatomy encoder alongside the original image. The anatomy decoder reconstructs corruption-free images using only anatomy features, while the image decoder reconstructs corrupted images using concatenated anatomy and characteristic features. The training objective combines consistency loss between anatomy embeddings of different variants with reconstruction losses for both original and corrupted images, enforcing the orthogonalization of anatomical and characteristic information.

## Key Results
- Achieves PSNR improvements of 0.9-1.6 dB over vanilla autoencoders across five medical imaging datasets
- Demonstrates competitive classification accuracy (AUC 0.691-0.961) while excelling at corruption detection (AUC 0.612-0.961)
- Maintains stable performance across varying corruption severity levels
- Successfully removes common image corruptions including Gaussian noise, blur, and compression artifacts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Orthogonalization of anatomy and image-characteristic features improves robustness to image corruptions.
- Mechanism: By training two encoder-decoder branches with an adapted loss function, the anatomy encoder learns to extract features invariant to image distortions, while the characteristic encoder retains corruption-specific details. The consistency loss enforces distortion-invariant anatomy features across multiple corrupted variants of the same image.
- Core assumption: Anatomical features are separable from image acquisition characteristics and corruptions in the feature space.
- Evidence anchors:
  - [abstract] "This feature orthogonalization further improves generalization and robustness against corruptions."
  - [section] "By applying the consistency loss LC given as: LC = 1/Z * Σ ∀ {vi,vj } ∈ V, vi≠vj ||EA(vi) − EA(vj)||² on the resulting feature maps, the anatomy encoder is forced to learn distortion-invariant features."
  - [corpus] Weak evidence; corpus papers focus on related topics but do not directly confirm the orthogonalization mechanism.
- Break condition: If anatomical features cannot be separated from acquisition characteristics, the orthogonalization will fail and robustness gains will be minimal.

### Mechanism 2
- Claim: The concatenation of anatomy and characteristic features enables reconstruction of both corruption-free and corrupted images.
- Mechanism: The characteristic decoder reconstructs the corrupted image using concatenated anatomy and characteristic features, while the anatomy decoder reconstructs only the anatomy using anatomy features alone. This dual reconstruction enforces the separation of anatomical and corruption-related information.
- Core assumption: Both anatomy and characteristic features are necessary and sufficient for accurate image reconstruction.
- Evidence anchors:
  - [abstract] "This feature orthogonalization further improves generalization and robustness against corruptions."
  - [section] "To further guide the anatomy encoder to learn representative anatomy features, the consistency loss is assisted by a combination of the reconstruction loss of the synthetic image LRS and the reconstruction loss of the original, distortion-free image LRI."
  - [corpus] Weak evidence; corpus papers do not provide direct support for the dual reconstruction mechanism.
- Break condition: If either branch cannot accurately reconstruct its respective image type, the orthogonalization will be incomplete and reconstruction quality will suffer.

### Mechanism 3
- Claim: The unsupervised nature of the approach allows it to work across diverse modalities and datasets without requiring labels or paired data.
- Mechanism: By using only reconstruction and consistency losses without explicit supervision, the network learns to separate features based on their inherent properties rather than relying on labeled data. This makes the approach generalizable to various medical imaging modalities.
- Core assumption: Anatomical features and image characteristics have inherent properties that can be separated through unsupervised learning.
- Evidence anchors:
  - [abstract] "The method is versatile for diverse modalities and tasks, as it does not require domain knowledge, paired data samples, or labels of any kind."
  - [section] "During each iteration, the input image I is distorted using augmentation AS to generate S and subsequently passed through the shared anatomy encoder EA in combination with two different distorted variants V1 and V2."
  - [corpus] Weak evidence; corpus papers do not provide direct support for the unsupervised generalization capability.
- Break condition: If the inherent properties of features are not separable in an unsupervised manner, the approach will require explicit supervision to work effectively.

## Foundational Learning

- Concept: Feature orthogonality and its importance in representation learning
  - Why needed here: Understanding how orthogonal features can capture distinct aspects of data is crucial for grasping why separating anatomy from characteristics improves robustness
  - Quick check question: Why might separating features into orthogonal components be beneficial for handling corruptions?

- Concept: Autoencoder architecture and loss functions
  - Why needed here: The method builds upon autoencoder principles but modifies the loss function to enforce orthogonality between feature branches
  - Quick check question: How does the consistency loss differ from a standard reconstruction loss in an autoencoder?

- Concept: Data augmentation and its role in training robust models
  - Why needed here: The method relies on generating multiple corrupted variants of the same image to enforce distortion-invariant features
  - Quick check question: Why is it important to use multiple corrupted variants of the same image when training the anatomy encoder?

## Architecture Onboarding

- Component map:
  Input image → augmentation (AS) → shared anatomy encoder (EA) + characteristic encoder (EC)
  Anatomy encoder output → anatomy decoder (DA) → corruption-free reconstruction
  Concatenated anatomy + characteristic features → image decoder (D) → corrupted reconstruction
  Loss functions: consistency loss (LC), reconstruction loss for original (LRI), reconstruction loss for synthetic (LRS)

- Critical path: Input image → EA → DA (for anatomy reconstruction) OR EA ⊕ EC → D (for corrupted reconstruction)

- Design tradeoffs:
  - Number of encoder blocks: More blocks increase feature extraction capacity but also computational cost
  - Latent dimension: Larger dimensions allow more expressive features but increase risk of overfitting
  - Number of corrupted variants: More variants improve consistency but increase training time

- Failure signatures:
  - Poor reconstruction quality: Check consistency loss weight and augmentation diversity
  - Anatomy decoder fails to remove corruptions: Verify anatomy encoder is learning distortion-invariant features
  - Characteristic decoder fails to reconstruct corrupted images: Check if characteristic encoder is capturing corruption details

- First 3 experiments:
  1. Train with only LRI and LRS (no consistency loss) to establish baseline reconstruction capability
  2. Add consistency loss and verify anatomy decoder can remove simple corruptions (e.g., Gaussian noise)
  3. Test corruption detection capability by training a linear classifier on characteristic features

## Open Questions the Paper Calls Out

- Question: How does the performance of unORANIC scale with different latent dimensions beyond the tested 256 dimensions?
- Basis in paper: [explicit] The paper mentions the approach is adaptable to images of any size and uses a latent dimension of 256 in experiments, but does not explore other dimensions
- Why unresolved: The paper only tested one latent dimension value and did not perform ablation studies on this hyperparameter
- What evidence would resolve it: Systematic experiments varying the latent dimension size and measuring performance metrics like PSNR and classification accuracy

- Question: What is the impact of using more than three image variants during training on the model's ability to learn distortion-invariant features?
- Basis in paper: [explicit] The paper states "The number of variants used for the anatomy encoder training is flexible, and in our experiments, three variants were utilized"
- Why unresolved: The paper only tested with three variants and did not explore whether increasing this number improves performance
- What evidence would resolve it: Experiments comparing model performance with different numbers of variants (e.g., 2, 3, 4, 5) while keeping other parameters constant

- Question: How does unORANIC perform on 3D medical imaging data compared to its 2D performance?
- Basis in paper: [inferred] The paper uses 2D MedMNIST datasets and mentions adaptability to images of any size, but does not test on 3D data
- Why unresolved: The method was only evaluated on 2D datasets, and its extension to 3D volumes is not explored
- What evidence would resolve it: Experiments applying unORANIC to 3D medical imaging datasets (e.g., MRI volumes) and comparing performance metrics to 2D results

## Limitations
- Performance heavily dependent on augmentation diversity and quality for generating realistic corruptions
- Assumes clean separation of anatomical and characteristic features, which may not hold for all imaging modalities
- Tested on relatively small 28x28 resolution images, limiting applicability to higher-resolution clinical images

## Confidence
- High confidence: Reconstruction quality improvements (PSNR gains of 0.9-1.6 dB) and basic corruption removal capabilities
- Medium confidence: Generalization across diverse modalities without supervision
- Medium confidence: Robustness claims across varying corruption severity levels

## Next Checks
1. Test the method on higher-resolution clinical images (e.g., 256x256 or 512x512) to verify scalability and anatomical detail preservation
2. Evaluate performance when trained on one modality and tested on another (cross-modal transfer) to assess true generalization capability
3. Conduct ablation studies removing the consistency loss to quantify its specific contribution to robustness improvements