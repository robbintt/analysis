---
ver: rpa2
title: Learning Linear Gaussian Polytree Models with Interventions
arxiv_id: '2311.04636'
source_url: https://arxiv.org/abs/2311.04636
tags:
- data
- causal
- polytree
- skeleton
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of learning causal structures
  represented by linear Gaussian polytrees from both observational and interventional
  data, where the intervention targets are known. The key challenge lies in developing
  scalable algorithms that can handle high-dimensional problems, a common scenario
  in biological applications.
---

# Learning Linear Gaussian Polytree Models with Interventions

## Quick Facts
- arXiv ID: 2311.04636
- Source URL: https://arxiv.org/abs/2311.04636
- Reference count: 40
- One-line primary result: Proposed methods learn polytree structures from interventional data with high accuracy and efficiency, outperforming GIES in high-dimensional settings

## Executive Summary
This paper addresses the problem of learning causal structures represented by linear Gaussian polytrees from both observational and interventional data, where intervention targets are known. The authors propose a two-step approach that first learns the skeleton using a modified Chow-Liu algorithm with aggregated correlation matrices, then orients edges using either invariance of regression coefficients or BIC scores. The primary results demonstrate that these methods are fast and accurate, achieving competitive performance with more general methods while maintaining computational efficiency even for graphs with thousands of nodes.

## Method Summary
The authors develop a two-step approach for learning linear Gaussian polytree models from interventional data. First, they learn the skeleton by aggregating pairwise correlations from multiple experimental settings into a G-valid weight matrix, then apply a modified Chow-Liu algorithm. Second, they orient the edges using one of two procedures: testing invariance of regression coefficients across interventions where endpoints aren't intervened upon, or using BIC scores to identify collider structures. The methods are designed to handle high-dimensional problems efficiently while maintaining accuracy in both low and high-dimensional settings.

## Key Results
- The proposed methods achieve high accuracy in terms of structural Hamming distance even for graphs with thousands of nodes
- Algorithms outperform GIES in high-dimensional settings while maintaining competitive accuracy in low-dimensional scenarios
- Application to gene expression interventional data shows comparable results to more general methods despite the simplicity of the polytree assumption

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aggregation of correlation matrices from multiple interventional datasets yields a G-valid weight matrix that enables correct skeleton recovery via Chow-Liu.
- Mechanism: Each interventional setting I provides a G-valid correlation matrix |RI|. By applying a monotone transformation (e.g., weighted mean of -log(1 - (ρI_ij)^2)) across all settings, the resulting aggregated matrix preserves the property that for any triplet u - v - w in the true polytree, min{W(u,v), W(v,w)} ≥ W(u,w), ensuring Kruskal's algorithm selects the correct tree.
- Core assumption: The interventions are conservative (include the observational setting ∅) and the true graph is a polytree.
- Evidence anchors:
  - [abstract] "Our methods first learn the skeleton of the polytree and then orient its edges."
  - [section 4.1] "To efficiently learn from available interventional data, we wish to form a single weight matrix that encodes the information of all the experimental settings."
  - [corpus] Weak - neighbors discuss general interventional learning but don't specifically address polytree aggregation mechanisms.
- Break condition: If interventions are not conservative or the true graph contains cycles, the aggregation may not preserve G-validity.

### Mechanism 2
- Claim: Edge orientation is possible by exploiting the invariance of regression coefficients across interventional settings where neither endpoint is intervened upon.
- Mechanism: For an edge u → v, if u is not intervened upon in setting I0 = ∅ and v is not intervened upon in setting I, then λI_uv = λ∅_uv. Testing H: λI_uv = λ∅_uv using an F-test or BIC allows orientation of the edge based on which direction shows coefficient invariance.
- Core assumption: The intervention targets are known and at least one observational setting (∅) is available.
- Evidence anchors:
  - [section 4.3.1] "To orient the edge {u, v}, we assume there exists I0 ∈ I where no intervention took place, i.e., I0 = ∅."
  - [section 4.3.2] "Under the model Hu→v we can write in each dataset Xv = λI_u,vXu + ϵI_v|u where... we can see that ϵI_v|u is independent from Xu."
  - [corpus] Weak - neighbors focus on general causal discovery but don't detail polytree-specific orientation via coefficient invariance.
- Break condition: If no observational setting is available or if interventions always target both endpoints of an edge, orientation becomes impossible.

### Mechanism 3
- Claim: Colliders can be identified by testing conditional independence of non-adjacent nodes given their common parent across interventional settings.
- Mechanism: For a triplet u - v - w where v is the middle node, if v → u ← w forms a collider, then u ⊥⊥ w given v in all interventional settings. Testing this independence (via BIC score or likelihood ratio) allows identification of collider structures and their orientation.
- Core assumption: The skeleton is known and the graph is a polytree (ensuring at most one trek between any two nodes).
- Evidence anchors:
  - [section 4.4.1] "If the skeleton has a triplet u − v − w, we can decide whether it forms a collider or not by testing for the independence of u and w in all the environments."
  - [section 3.3] "In a polytree G there is at most one trek between any two vertices."
  - [corpus] Weak - neighbors discuss collider identification in general but not specifically for polytrees with known interventions.
- Break condition: If the skeleton is incorrect or the graph contains hidden variables, collider identification may fail.

## Foundational Learning

- Concept: Chow-Liu algorithm and G-valid weight matrices
  - Why needed here: The skeleton recovery relies on Kruskal's algorithm with a G-valid weight matrix to correctly identify the polytree structure from aggregated correlations.
  - Quick check question: What property must a weight matrix satisfy to guarantee that Kruskal's algorithm recovers the correct polytree skeleton?

- Concept: Interventional Markov equivalence classes (I-MECs)
  - Why needed here: The algorithms output an I-CPDAG representing the I-MEC of the true polytree, which encodes the causal information common to all DAGs in the equivalence class given the known intervention targets.
  - Quick check question: How does knowing the intervention targets refine the Markov equivalence class compared to using only observational data?

- Concept: Local Markov property and trek-rule for linear Gaussian models
  - Why needed here: The correlation structure of the polytree is characterized by the trek-rule, which relates correlations to products of edge coefficients along simple treks, enabling the use of second-order statistics for learning.
  - Quick check question: How does the trek-rule simplify the computation of correlations in a polytree compared to a general DAG?

## Architecture Onboarding

- Component map: Data preprocessing -> Skeleton recovery module -> Orientation module -> Output I-CPDAG
- Critical path:
  1. Compute correlation matrices for each interventional setting
  2. Aggregate correlations using chosen function (weighted mean recommended)
  3. Apply Chow-Liu to obtain skeleton
  4. Apply orientation procedure (P.1 or P.2) to orient edges
  5. Return I-CPDAG

- Design tradeoffs:
  - Aggregation function: Weighted mean is faster but median may be more robust to outliers
  - Orientation procedure: P.1 (collider-first) may be more statistically oriented, P.2 (edge-first) more causally oriented
  - Collider search: Simple method uses general independence testing, refined method exploits known edge orientations for more efficient likelihood computation

- Failure signatures:
  - Incorrect skeleton: Check if intervention targets are conservative and correlations are properly aggregated
  - Poor orientation accuracy: Verify that observational data is available and regression coefficients are computed correctly
  - Slow runtime: Profile aggregation and orientation steps; consider using weighted mean and IRC instead of BIC

- First 3 experiments:
  1. Verify skeleton recovery on a small polytree with perfect interventions using weighted mean aggregation
  2. Test orientation accuracy on a known polytree structure using both P.1 and P.2 procedures
  3. Benchmark runtime and accuracy against GIES on a high-dimensional polytree dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed methods be extended to handle unknown intervention targets?
- Basis in paper: [explicit] The authors mention that "A natural extension of our work is to allow for unknown intervention targets" and suggest that the Ψ-Markov equivalence class could replace the I-MEC.
- Why unresolved: The current methods rely on the characterization of I-Markov equivalence which requires explicit knowledge of intervention targets.
- What evidence would resolve it: Successful application of the proposed skeleton recovery and collider search procedures to data with unknown intervention targets, along with development of new orientation procedures that work with Ψ-Markov equivalence.

### Open Question 2
- Question: How can the proposed methods be adapted to handle hidden variables in the polytree model?
- Basis in paper: [explicit] The authors note that "The algorithms we propose do not address the case where some variables remain hidden" and suggest that the Ψ-Markov equivalence class could be used to handle hidden variables.
- Why unresolved: The current methods assume all variables are observed and measured, and do not account for the presence of hidden variables.
- What evidence would resolve it: Development of new algorithms that can learn the structure of polytrees with hidden variables using interventional data, and demonstration of their effectiveness on simulated and real-world data.

### Open Question 3
- Question: How can the proposed methods be extended to learn more general graph structures beyond polytrees?
- Basis in paper: [explicit] The authors state that "It will be interesting to seek extensions to broader classes of graphs in future work" and mention that "Undirected forests have been studied by Edwards et al. [16], but their construction does not carry over naturally to the directed case, and new research is needed."
- Why unresolved: The current methods are specifically designed for polytree models and may not be directly applicable to more complex graph structures.
- What evidence would resolve it: Development of new algorithms that can learn the structure of more general graph classes (e.g., DAGs, chain graphs) using interventional data, and demonstration of their effectiveness on simulated and real-world data.

## Limitations

- The strong assumption of known intervention targets may not hold in many real-world scenarios
- The polytree assumption significantly restricts the class of causal structures that can be learned
- Requirement for conservative interventions (including the observational setting) may not always be satisfied in practice

## Confidence

- High Confidence: Skeleton recovery using modified Chow-Liu algorithm with G-valid weight matrices
- Medium Confidence: Edge orientation procedures relying on coefficient invariance assumptions
- Low Confidence: Performance guarantees in presence of model misspecification or non-conservative interventions

## Next Checks

1. Test sensitivity to violations of the polytree assumption by evaluating performance on datasets with cycles
2. Assess robustness of orientation procedures when observational data is limited or unavailable
3. Evaluate methods on real-world interventional data with unknown or partially known intervention targets to test practical applicability