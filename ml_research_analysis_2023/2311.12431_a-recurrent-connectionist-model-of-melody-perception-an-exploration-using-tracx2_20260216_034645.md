---
ver: rpa2
title: 'A recurrent connectionist model of melody perception : An exploration using
  TRACX2'
arxiv_id: '2311.12431'
source_url: https://arxiv.org/abs/2311.12431
tags:
- words
- tracx2
- interval
- input
- intervals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TRACX2, a recursive autoencoder model, successfully simulates elementary
  melody perception by recognizing frequently encountered sequences of musical intervals.
  The model's internal representations cluster in a human-recognizable manner, showing
  sensitivity to both melodic contour and interval proximity.
---

# A recurrent connectionist model of melody perception : An exploration using TRACX2

## Quick Facts
- arXiv ID: 2311.12431
- Source URL: https://arxiv.org/abs/2311.12431
- Authors: 
- Reference count: 0
- Primary result: Recursive autoencoder model successfully simulates elementary melody perception phenomena including end-of-word superiority effects

## Executive Summary
This paper presents TRACX2, a recursive autoencoder model that simulates elementary melody perception by recognizing frequently encountered sequences of musical intervals. The model uses ordinal encoding to capture both melodic contour and interval proximity, demonstrating an "end-of-word" superiority effect similar to human listeners. TRACX2 successfully generalizes to new musical input and shows prior learning effects, outperforming simpler models like first-order Markov chains and PARSER in simulating these melodic perception phenomena.

## Method Summary
The study employs a three-layer autoencoder architecture (input LHS/RHS, hidden, output) with ordinal encoding of musical intervals ranging from -19 to +19 semitones. The model was trained on two sets of 10 French children's songs (437 intervals total) for 30 epochs using mean absolute difference error and modified ReLU activation. Context-dependent input combines hidden-unit activations with right-hand side activations weighted by error-based delta parameter. Internal representations were analyzed using principal components analysis to visualize clustering patterns, and performance was evaluated through error calculations comparing full words to their sub-word components.

## Key Results
- TRACX2 demonstrates end-of-word superiority effect, with internal representations of full musical phrases being closer to their final sub-words than initial sub-words
- Internal representations cluster in a human-recognizable manner, showing sensitivity to both melodic contour and interval proximity when using ordinal encoding
- The model generalizes well to new musical input, with prior learning effects showing that exposure to simple melodies facilitates learning more complex patterns

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Recursive autoencoder architecture enables automatic discovery of frequent musical interval sequences (chunks) without external supervision.
- Mechanism: TRACX2 processes sequences of intervals, encoding frequently encountered subsequences in its hidden layer. When reconstruction error falls below a threshold, the system treats the subsequence as a chunk and reuses its internal representation in subsequent processing.
- Core assumption: Musical perception can be modeled as sequence segmentation where boundaries emerge from statistical regularities in interval patterns rather than predefined word units.
- Evidence anchors: [abstract] "TRACX2, a recognition-based, recursive connectionist autoencoder model of chunking and sequence segmentation" [section] "The TRACX2 architecture consists of three layers... recognizes 'chunks' of short sequences of intervals that have been frequently encountered on input"

### Mechanism 2
- Claim: Ordinal encoding preserves interval proximity information, enabling the model to capture both contour and interval similarity in its internal representations.
- Mechanism: Instead of one-hot encoding, intervals are represented as ordinal vectors where the position of positive values encodes interval size and direction. This allows the network to learn that intervals like +2 and +3 are more similar than +2 and +12.
- Core assumption: Human melodic perception relies on relative pitch relationships, not absolute pitch values, requiring a distance metric in the input encoding.
- Evidence anchors: [section] "We, therefore, replaced the traditional one-hot encoding by what we called an 'ordinal' encoding of the input" [section] "Ordinal encoding reflects both the size and direction of the intervals... approximates, what a human would perceive"

### Mechanism 3
- Claim: End-of-word superiority effect emerges naturally from the chunk accretion mechanism where new items are added to the right-hand side of the input.
- Mechanism: As chunks are built incrementally, the final interval of a chunk remains explicitly on the right-hand side of the input, while earlier intervals become subsumed in the hidden representation. This creates better preservation of the chunk ending in the internal representation.
- Core assumption: The order of processing (left-to-right accretion) creates systematic differences in how chunk boundaries are represented, independent of transitional probabilities.
- Evidence anchors: [section] "The chunk-accretion mechanism used by TRACX2... involves adding individual items to the RHS of the input" [section] "Consider the word ayj... the final interval, j, remains explicitly on the RHS of the input"

## Foundational Learning

- Concept: Autoencoder reconstruction error as learning signal
  - Why needed here: TRACX2 uses reconstruction error to determine when to treat a subsequence as a chunk, replacing frequent patterns with compressed representations
  - Quick check question: What happens to the reconstruction error when a frequently encountered interval pair is presented to TRACX2 after sufficient training?

- Concept: Principal component analysis for cluster visualization
  - Why needed here: PCA is used to project high-dimensional internal representations onto 2D space to visualize how similar melodic contours cluster together
  - Quick check question: Why does PCA of hidden-unit representations reveal contour-based clustering only when ordinal encoding is used?

- Concept: Chebyshev distance for interval similarity
  - Why needed here: Chebyshev distance measures the maximum interval difference between two words, used to define when words are "close" or "far" for testing generalization effects
  - Quick check question: How does Chebyshev distance between intervals [-2, 3, 0] and [1, -1, 0] differ from cityblock distance?

## Architecture Onboarding

- Component map: Input sequence → interval encoding → autoencoder processing → error calculation → weight update → internal representation reuse on next timestep
- Critical path: Input sequence → interval encoding → autoencoder processing → error calculation → weight update → internal representation reuse on next timestep
- Design tradeoffs: Fixed hidden layer size limits chunk complexity vs. computational efficiency; ordinal encoding captures interval relationships but increases input dimensionality vs. one-hot simplicity
- Failure signatures: High reconstruction errors across all test sequences indicate insufficient training or inappropriate encoding; poor contour clustering suggests encoding issues; end-of-word effects disappearing may indicate weight initialization problems
- First 3 experiments:
  1. Train TRACX2 on simple ascending/descending interval sequences and verify that it learns to recognize these as chunks
  2. Test ordinal vs one-hot encoding by comparing PCA clustering of 2-interval words
  3. Create a test sequence with part-words and measure end-of-word advantage using error calculations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does TRACX2's performance scale with increasing melodic complexity beyond simple children's songs?
- Basis in paper: [explicit] The authors note that their model is limited to "simple elements of music perception" and suggest future work should use "more complex musical information" including note duration, timbre, and harmonic information.
- Why unresolved: The current study only tested the model on simple children's songs with basic pitch intervals, leaving uncertainty about its ability to handle more complex musical structures.
- What evidence would resolve it: Testing TRACX2 on progressively more complex musical pieces (e.g., with varying note durations, chords, multiple voices) while measuring performance metrics would clarify its limitations and capabilities.

### Open Question 2
- Question: What specific neural mechanisms in the human brain correspond to the recursive autoencoder architecture of TRACX2?
- Basis in paper: [inferred] The authors propose TRACX2 as a "cognitively plausible" model of melody perception but do not provide direct neural evidence linking their model to specific brain regions or processes.
- Why unresolved: While the model successfully simulates behavioral phenomena, the paper lacks empirical neural data to validate its biological plausibility.
- What evidence would resolve it: Neuroimaging studies comparing brain activity during melody perception tasks with TRACX2's internal representations could establish neural correlates of the model's processes.

### Open Question 3
- Question: How do top-down cognitive influences like musical expertise or cultural background affect TRACX2's learning and perception compared to humans?
- Basis in paper: [explicit] The authors acknowledge that "purely bottom-up models will not be able to capture the full range of human music perception" and that modeling "will necessarily involve an interaction between bottom-up learning and top-down control."
- Why unresolved: The current model lacks mechanisms for incorporating prior knowledge or cultural context, which are known to influence human music perception.
- What evidence would resolve it: Comparing TRACX2's performance with human listeners from different musical backgrounds on the same melodic tasks would reveal the importance of top-down influences not captured by the model.

## Limitations

- Model performance on more complex musical structures beyond simple children's melodies remains unverified
- Claims about superiority over simpler models are based on limited comparisons with specific test cases
- Lack of direct neural evidence linking the recursive autoencoder architecture to specific brain mechanisms

## Confidence

- High confidence: The model's ability to learn chunk representations and demonstrate end-of-word superiority effects, as these are directly observable in the internal representations and error calculations
- Medium confidence: Claims about prior learning effects and generalization to Bach sonatas, as these rely on indirect measurements through error differences
- Low confidence: The broader claim that recursive autoencoder architecture is a general cognitive mechanism across domains, which extends beyond the musical perception scope of this study

## Next Checks

1. Test TRACX2 on polyphonic music or more complex melodic structures to verify if the chunk-accretion mechanism scales beyond simple monophonic melodies
2. Implement alternative interval encoding schemes (e.g., log-frequency spacing, pitch-class profiles) to compare their impact on contour clustering and generalization performance
3. Conduct ablation studies by disabling the context-dependent input mechanism to isolate its contribution to the end-of-word superiority effect and compare performance with standard autoencoder implementations