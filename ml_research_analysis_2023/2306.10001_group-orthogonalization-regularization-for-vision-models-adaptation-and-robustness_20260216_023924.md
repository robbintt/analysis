---
ver: rpa2
title: Group Orthogonalization Regularization For Vision Models Adaptation and Robustness
arxiv_id: '2306.10001'
source_url: https://arxiv.org/abs/2306.10001
tags:
- regularization
- group
- training
- filters
- groups
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes Group Orthogonalization Regularization (GOR),
  a computationally efficient regularization technique that encourages orthonormality
  between groups of filters within the same layer. The method aims to reduce the redundancy
  within deep neural network parameters, which increases as networks become deeper.
---

# Group Orthogonalization Regularization For Vision Models Adaptation and Robustness

## Quick Facts
- arXiv ID: 2306.10001
- Source URL: https://arxiv.org/abs/2306.10001
- Reference count: 40
- Key outcome: GOR improves performance on downstream tasks when incorporated into recent adaptation methods for diffusion models and vision transformers

## Executive Summary
Group Orthogonalization Regularization (GOR) is a computationally efficient regularization technique that encourages orthonormality between groups of filters within the same layer. The method addresses the increasing redundancy in deep neural network parameters as networks become deeper. GOR has been demonstrated to improve classification accuracy on downstream datasets when used with AdaptMLP for ViT adaptation, enhance FID scores for diffusion model fine-tuning with LoRA adapters, and increase model robustness under various adversarial attacks.

## Method Summary
GOR partitions filters into N groups within each layer and enforces orthonormality constraints within each group, reducing redundancy at lower computational complexity than full-layer orthogonality. The method is applied to convolutional layers, ViT adapter up-projection layers, and LoRA up matrices with regularization strength λ typically set between 10⁻⁴ and 10⁻⁶. For adversarial training, GOR is combined with TRADES and FAT methods to enhance robustness against white-box and black-box attacks.

## Key Results
- Improved classification accuracy on CIFAR-10 and downstream datasets when used with AdaptMLP for ViT adaptation
- Enhanced FID scores on Pokemon-BLIP and Oxford102 datasets when combined with LoRA adapters for diffusion models
- Improved adversarial robustness under various attacks on CIFAR-10 when enforcing group orthogonality during adversarial training

## Why This Works (Mechanism)

### Mechanism 1
Grouping filters and applying orthogonality regularization within each group reduces redundancy without the full computational cost of full-layer orthogonality. By partitioning filters into N groups and enforcing orthonormality within each group, the method reduces redundancy at lower computational complexity. The core assumption is that filter ordering is arbitrary and does not affect model performance.

### Mechanism 2
Enforcing orthogonality within groups increases the diversity and expressivity of filters, leading to better generalization and robustness. Orthonormal filters span the space more efficiently and capture diverse features, reducing redundancy and improving the model's ability to adapt to new tasks or resist adversarial attacks.

### Mechanism 3
Applying GOR to adapter modules improves adaptation performance by encouraging the adapters to explore new directions in parameter space. GOR regularization on the up-sampling block of adapters encourages the learned low-rank updates to be more orthogonal, increasing the effective capacity of the adapter without increasing rank.

## Foundational Learning

- **Concept**: Group normalization and its interaction with filter grouping
  - Why needed here: GOR's effectiveness depends on how filter groups align with normalization groups, affecting whether "inter-group" or "intra-group" regularization is used.
  - Quick check question: If a layer has 64 channels and GN uses 16 groups, how many filters are in each GOR group when N=16 for "inter-group" regularization?

- **Concept**: Low-rank adaptation (LoRA) and bottleneck modules
  - Why needed here: GOR is applied to adapter modules in both ViT adaptation (AdaptMLP) and diffusion model fine-tuning (LoRA), requiring understanding of how these adapters work.
  - Quick check question: In LoRA, which matrix (down-projection A or up-projection B) is typically regularized with GOR and why?

- **Concept**: Adversarial training and robustness evaluation
  - Why needed here: The paper evaluates GOR's effect on adversarial robustness using TRADES and FAT training methods with various attack types.
  - Quick check question: What is the difference between white-box and black-box attacks in the context of adversarial robustness evaluation?

## Architecture Onboarding

- **Component map**: Main model layers -> Normalization layers (BN or GN) -> GOR regularization layer -> Adapter modules (for adaptation experiments)

- **Critical path**: 
  1. Forward pass through model layers
  2. Compute feature maps and apply normalization
  3. Calculate GOR regularization loss on grouped filter weights
  4. Combine task loss with GOR regularization weighted by λ
  5. Backward pass and parameter update

- **Design tradeoffs**: 
  - GOR group size N vs. computational efficiency: larger N reduces computation but may weaken regularization effect
  - λ value vs. task performance: higher λ increases regularization strength but may interfere with task learning
  - Inter-group vs. intra-group regularization: affects interaction with GN and orthogonality between normalization groups

- **Failure signatures**: 
  - Performance degradation when N is too small (overly strong regularization)
  - No improvement when λ is too low (insufficient regularization)
  - Inconsistent results across seeds when group partitioning interacts poorly with GN groups

- **First 3 experiments**: 
  1. CIFAR-10 classification with ResNet110: Compare CE baseline vs. GOR with varying N and λ values
  2. ViT adaptation with AdaptMLP: Fine-tune pre-trained ViT on CIFAR-100 with and without GOR regularization
  3. Diffusion model fine-tuning: Fine-tune Stable Diffusion on Oxford102 with LoRA + GOR vs. LoRA baseline

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of GOR scale with increasing group sizes (N) and what is the optimal group size for different model architectures? The paper doesn't provide a systematic study of how group size affects performance across different model architectures or provide theoretical justification for choosing specific group sizes.

### Open Question 2
What is the theoretical explanation for why GOR improves adversarial robustness more significantly in GN models compared to BN models? The paper presents empirical results showing GN models benefit more from GOR for adversarial robustness but doesn't provide theoretical analysis of the interaction between group normalization and orthogonal regularization.

### Open Question 3
How does GOR affect the interpretability and feature diversity of learned representations across different layers of deep networks? The paper focuses on quantitative performance metrics but doesn't examine the qualitative aspects of how GOR affects the internal representations learned by the network.

## Limitations
- Performance highly sensitive to choice of group size N and regularization strength λ with no clear guidelines for hyperparameter selection
- Claims about orthonormal filters being inherently more "diverse, expressive, and less redundant" lack rigorous theoretical justification
- Computational complexity claims need verification through implementation as practical overhead of grouping operations is not fully characterized

## Confidence
- **High Confidence**: The computational efficiency improvement from O(C²_out C_in) to O(C²_out C_in / N) when using group orthogonality is mathematically sound and verifiable through implementation.
- **Medium Confidence**: The observed improvements in classification accuracy and FID scores with GOR regularization are supported by empirical results, but the generality across different model architectures and tasks remains to be fully established.
- **Low Confidence**: The claim that orthonormal filters are inherently "more diverse, expressive, and less redundant" lacks rigorous theoretical justification and relies primarily on observed performance improvements rather than fundamental analysis.

## Next Checks
1. Implement GOR with Different Group Sizes: Test the sensitivity of GOR performance to group size N by systematically varying it across different layers and architectures, measuring both performance impact and computational overhead.

2. Analyze Filter Ordering Effects: Design experiments to test whether filter ordering affects GOR performance by permuting filters within groups and measuring the impact on task accuracy and regularization effectiveness.

3. Compare Against Alternative Regularization Methods: Benchmark GOR against other orthogonalization and diversity-promoting regularizations (e.g., full-layer orthogonality, spectral normalization) to quantify its unique benefits and limitations.