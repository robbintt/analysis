---
ver: rpa2
title: Unsupervised Discovery of Interpretable Directions in h-space of Pre-trained
  Diffusion Models
arxiv_id: '2310.09912'
source_url: https://arxiv.org/abs/2310.09912
tags:
- directions
- process
- latent
- samples
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We propose the first unsupervised and learning-based method to
  identify interpretable directions in the h-space of pre-trained diffusion models.
  Our method is derived from an existing technique that operates on the GAN latent
  space.
---

# Unsupervised Discovery of Interpretable Directions in h-space of Pre-trained Diffusion Models

## Quick Facts
- arXiv ID: 2310.09912
- Source URL: https://arxiv.org/abs/2310.09912
- Reference count: 40
- We propose the first unsupervised and learning-based method to identify interpretable directions in the h-space of pre-trained diffusion models

## Executive Summary
This paper introduces the first unsupervised learning approach to discover interpretable directions in the h-space of pre-trained diffusion models. The method builds upon techniques from GAN latent space manipulation and employs a shift control module that operates on h-space to manipulate samples, followed by a reconstructor that reproduces both the type and strength of the manipulation. By jointly optimizing these components, the model spontaneously discovers disentangled and interpretable directions while maintaining sample fidelity through a discriminator.

## Method Summary
The method uses a shift control module that works on h-space of pre-trained diffusion models to manipulate samples into shifted versions, followed by a reconstructor that reproduces both the type and strength of the manipulation. The key innovation is the VRAM-efficient training algorithm based on gradient checkpointing, which allows back-propagating gradients through the entire generative process while maintaining acceptable VRAM usage. The approach is validated across multiple datasets including MNIST, AnimeFaces, CelebAHQ, and AFHQ-dog, demonstrating effective discovery of interpretable directions without requiring additional complicated procedures.

## Key Results
- First unsupervised method to identify interpretable directions in h-space of pre-trained diffusion models
- Inherently discovers global and scalable directions without additional procedures
- VRAM-efficient training algorithm enables training on larger models
- Extensive experiments demonstrate effectiveness across multiple datasets

## Why This Works (Mechanism)

### Mechanism 1
The shift control module discovers disentangled directions by jointly optimizing with the reconstructor to minimize reconstruction loss of both direction index and magnitude. Random sampling of direction index k and magnitude s forces the shift block to learn distinct transformations for each k, with the reconstructor providing gradient signals that push the shift block to produce easily distinguishable outputs for different k values. This relies on the linearity assumption of h-space, where linearly scaling a shift vector results in proportionally scaled attribute changes.

### Mechanism 2
The discriminator prevents discovery of meaningless directions by maintaining shifted samples within the data manifold. Without the discriminator, the shift block could generate out-of-distribution samples that are trivially distinguishable from the original, making the reconstruction task easier. The discriminator loss forces the shift block to produce realistic-looking samples, constraining it to discover semantically meaningful directions within the data manifold.

### Mechanism 3
The VRAM-efficient training algorithm enables training on larger models by back-propagating gradients node-by-node through the reverse process chain. Instead of storing all intermediate tensors for the full reverse process, the algorithm records nodes during a forward pass, then back-propagates gradients sequentially from the output node backward through the chain. This trades training time for memory efficiency.

## Foundational Learning

- **Diffusion probabilistic models and their forward/reverse processes**: Understanding how DDIM generates samples iteratively from noise is crucial for implementing the asymmetric DDIM process used for shifting. *Quick check: What is the mathematical difference between the forward process q(xt|xt-1) and the reverse process pθ(xt-1|xt) in DDPMs?*

- **h-space as the deepest bottleneck feature in UNet**: The entire method operates on h-space, so understanding its properties (homogeneity, linearity, consistency) is essential for implementing the shift control module. *Quick check: Why is h-space considered a "local semantic latent space" compared to the full latent sequence {xt}T t=1?*

- **Gradient checkpointing technique**: The VRAM-efficient training algorithm is based on gradient checkpointing, so understanding how to trade memory for computation is crucial for implementation. *Quick check: How does gradient checkpointing reduce memory usage at the cost of increased computation?*

## Architecture Onboarding

- **Component map**: Pre-trained diffusion model (frozen) -> Shift block fϕ t -> Asymmetric DDIM shifting -> Reconstructor Rω -> Discriminator Dψ -> Training loop
- **Critical path**: Forward DDIM sampling → Asymmetric DDIM shifting → Reconstruction → Discriminator feedback → Backward gradient propagation (via checkpointing)
- **Design tradeoffs**: Memory vs. computation (VRAM-efficient algorithm trades training speed for memory usage); Realism vs. discovery (discriminator strength affects whether discovered directions are meaningful or purely reconstructive); Direction granularity (larger K values may discover more directions but could lead to redundancy or entanglement)
- **Failure signatures**: All samples shift to the same pattern (discriminator too weak or reconstructor too strong); Discovered directions are not semantically meaningful (lack of proper discriminator guidance or poor initialization); Training fails due to memory (M value too large for available VRAM)
- **First 3 experiments**: Verify h-space properties by implementing homogeneity/linearity tests from Figure 9; Ablation study on discriminator by training with and without discriminator; VRAM efficiency validation by benchmarking the VRAM-efficient algorithm against vanilla approach across different M values

## Open Questions the Paper Calls Out

### Open Question 1
How does the number of discovered interpretable directions (K) affect the quality and diversity of the learned directions? The paper mentions setting K to a sufficiently large value but does not explore the relationship between K and quality of discovered directions.

### Open Question 2
Can the discovered interpretable directions be used for downstream tasks beyond image manipulation? The paper focuses on image manipulation but does not explore potential applications in other domains or tasks.

### Open Question 3
How does the choice of shifting interval (tstop) impact the interpretability and fidelity of the discovered directions? The paper uses tstop as a hyperparameter but does not explore its effect on quality of discovered directions.

## Limitations
- Core assumption of h-space linearity lacks direct experimental validation within this work
- Effectiveness of the discriminator is acknowledged as difficult to balance in practice
- Method requires substantial GPU VRAM even with optimization, limiting accessibility
- VRAM-efficient algorithm trades training efficiency for memory savings

## Confidence
- **High**: The VRAM-efficient training algorithm is well-specified and demonstrates clear memory usage improvements
- **Medium**: The discriminator's role in preventing meaningless directions is theoretically sound but practically challenging to implement
- **Low**: The linearity assumption of h-space and its impact on discovered direction scaling lacks direct empirical validation

## Next Checks
1. **Linearity validation**: Conduct controlled experiments varying magnitude s on discovered directions to verify monotonic, smooth attribute changes
2. **Discriminator ablation**: Systematically compare direction quality and fidelity metrics with varying discriminator strengths
3. **Computational cost analysis**: Measure actual training time overhead of the VRAM-efficient algorithm across different model scales and M values