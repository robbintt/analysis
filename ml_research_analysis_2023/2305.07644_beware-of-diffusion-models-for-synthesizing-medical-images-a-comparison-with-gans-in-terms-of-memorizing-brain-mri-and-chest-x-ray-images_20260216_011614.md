---
ver: rpa2
title: Beware of diffusion models for synthesizing medical images -- A comparison
  with GANs in terms of memorizing brain MRI and chest x-ray images
arxiv_id: '2305.07644'
source_url: https://arxiv.org/abs/2305.07644
tags:
- images
- diffusion
- training
- synthetic
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Researchers have shown that diffusion models can memorize training
  images, especially for small datasets. Using BRATS20 (313 training subjects) and
  BRATS21 (1195 training subjects), they trained both StyleGAN and diffusion models
  to generate synthetic brain tumor images.
---

# Beware of diffusion models for synthesizing medical images -- A comparison with GANs in terms of memorizing brain MRI and chest x-ray images

## Quick Facts
- arXiv ID: 2305.07644
- Source URL: https://arxiv.org/abs/2305.07644
- Reference count: 0
- Diffusion models show higher memorization rates than GANs when generating synthetic medical images

## Executive Summary
This study reveals that diffusion models are significantly more prone to memorizing training images compared to GANs, particularly when working with smaller medical imaging datasets. Using brain tumor MRI datasets (BRATS20 with 313 subjects and BRATS21 with 1195 subjects), researchers found that diffusion models produced synthetic images with correlation coefficients as high as 0.985 compared to training data, versus 0.890 for StyleGAN. This memorization problem is especially concerning for medical imaging where patient privacy is paramount. The authors caution against using diffusion models for medical image synthesis without privacy-preserving modifications and recommend exploring differential privacy or data augmentation techniques to mitigate this risk.

## Method Summary
The researchers compared StyleGAN and diffusion models for generating synthetic brain tumor MRI images using BRATS20 (313 subjects) and BRATS21 (1195 subjects) datasets. Both models were modified to handle 5-channel input (4 MRI modalities plus segmentation). The preprocessing pipeline involved splitting 3D volumes into 2D slices, selecting slices with at least 15% tumor pixels, zero-padding to 256x256, and rescaling intensities. The study generated 100,000 synthetic images from each model and calculated correlations between synthetic and training images to detect memorization. FID and IS metrics were also computed to assess image quality and diversity.

## Key Results
- Diffusion models trained on BRATS20 showed mean highest correlation of 0.985 with training images versus 0.890 for StyleGAN
- The memorization problem was more severe with smaller datasets (BRATS20) compared to larger ones (BRATS21)
- Diffusion models required approximately 22 days of training versus 3 days for StyleGAN, indicating significant computational cost

## Why This Works (Mechanism)

### Mechanism 1
Diffusion models memorize training images more readily than GANs, especially with smaller datasets. The denoising objective in diffusion models creates a direct path for memorizing training data, unlike GANs where the generator never sees training images directly. The study found that diffusion models produced much higher correlations with training data, indicating direct copying rather than novel generation.

### Mechanism 2
Correlation metrics reveal memorization that FID and IS cannot detect. High correlation between synthetic and training images indicates direct copying, while traditional metrics only assess image quality and diversity. The study used correlation as the primary tool to detect memorization, finding that diffusion models had correlation coefficients approaching 1.0 with training data.

### Mechanism 3
Dataset size critically affects memorization likelihood. Smaller datasets provide fewer unique patterns for diffusion models to learn from, forcing them to reproduce training samples. The study demonstrated that BRATS20 (313 subjects) showed higher memorization rates than BRATS21 (1195 subjects), confirming that larger datasets reduce memorization risk.

## Foundational Learning

- **Generative model architectures (GANs vs diffusion models)**: Understanding the fundamental differences in how these models generate images is crucial for interpreting memorization results. Quick check: How does the training objective differ between GANs and diffusion models?
- **Image correlation metrics**: Correlation is the primary tool used to detect memorization in this study. Quick check: What does a correlation coefficient close to 1.0 indicate about the relationship between two images?
- **Medical imaging privacy regulations (GDPR, HIPAA)**: The memorization problem is particularly concerning in medical imaging due to privacy requirements. Quick check: Why might synthetic medical images still pose privacy risks even if they don't directly contain patient data?

## Architecture Onboarding

- **Component map**: Data preprocessing pipeline (3D volumes → 2D slices with 5 channels) → StyleGAN implementation (modified for 5-channel output) → Diffusion model implementation (modified for 5-channel output) → Correlation analysis pipeline (100 synthetic images × all training images)
- **Critical path**: Load and preprocess BRATS20/BRATS21 datasets → Train StyleGAN and diffusion models → Generate 100 synthetic images from each model → Calculate correlations between synthetic and training images → Compare memorization rates
- **Design tradeoffs**: 2D vs 3D models (2D models are more common but may lose volumetric context) → Training time (diffusion models take ~22 days vs 3 days for StyleGAN) → Memory usage (5-channel images require more GPU memory than standard RGB)
- **Failure signatures**: High correlation between synthetic and training images (>0.95) → Sudden drops in FID/IS metrics during training → Inability to generate anatomically plausible variations
- **First 3 experiments**: Train both models on BRATS20 and calculate correlation metrics → Repeat with BRATS21 to test dataset size effects → Apply data augmentation and retrain to test memorization prevention

## Open Questions the Paper Calls Out

- **How do different hyperparameters of diffusion models affect the degree of memorization in medical imaging?**: The authors mention that memorization is likely to depend on hyperparameters, but training many different models is computationally challenging. A comprehensive study with various hyperparameter configurations would provide insights.

- **Can techniques like differential privacy (DP) or model gradient similarity effectively prevent memorization in diffusion models?**: Recent work showed DP-trained diffusion models didn't converge. Experiments applying DP and gradient similarity to measure effectiveness would provide evidence.

- **How does the size of the training dataset affect the degree of memorization in diffusion models for medical imaging?**: While the study showed dataset size affects memorization, it didn't investigate the relationship in detail. A systematic study with datasets of varying sizes would provide insights.

## Limitations

- The findings are limited to specific medical imaging datasets (BRATS20/21 and chest X-rays) and may not generalize to all modalities
- The study only compares StyleGAN versus diffusion models, potentially missing other generative architectures
- Memorization detection relies solely on correlation metrics, which may not capture all forms of memorization

## Confidence

- **High Confidence**: Correlation-based memorization detection methodology and finding that diffusion models show higher correlation with training data than StyleGAN
- **Medium Confidence**: Claim that diffusion models inherently memorize more due to their denoising objective, as this mechanism could be mitigated with proper regularization
- **Medium Confidence**: Recommendation against using diffusion models for medical imaging synthesis, pending exploration of privacy-preserving modifications

## Next Checks

1. **Replication with alternative metrics**: Replicate the study using additional memorization detection methods such as SSIM, gradient similarity, or membership inference attacks to confirm the correlation findings
2. **Privacy-preserving modifications**: Test whether applying differential privacy or strong regularization to diffusion models reduces the memorization problem while maintaining generation quality
3. **Cross-domain validation**: Validate the findings across additional medical imaging datasets and modalities (CT, ultrasound, pathology slides) to assess generalizability of the memorization concerns