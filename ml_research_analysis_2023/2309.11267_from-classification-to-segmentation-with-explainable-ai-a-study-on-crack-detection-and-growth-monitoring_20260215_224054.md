---
ver: rpa2
title: 'From Classification to Segmentation with Explainable AI: A Study on Crack
  Detection and Growth Monitoring'
arxiv_id: '2309.11267'
source_url: https://arxiv.org/abs/2309.11267
tags:
- crack
- segmentation
- methods
- image
- severity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a methodology to generate segmentation masks
  of surface cracks in images by leveraging classifier explanations obtained through
  explainable AI (XAI) methods. The approach aims to reduce the need for labor-intensive
  pixel-level annotations by utilizing weak image-level supervision.
---

# From Classification to Classification to Segmentation with Explainable AI: A Study on Crack Detection and Growth Monitoring

## Quick Facts
- **arXiv ID**: 2309.11267
- **Source URL**: https://arxiv.org/abs/2309.11267
- **Reference count**: 40
- **Key outcome**: Proposes using XAI attribution maps from image-level classifiers to generate segmentation masks for crack monitoring, reducing need for pixel-level annotations.

## Executive Summary
This paper presents a methodology that leverages explainable AI (XAI) to generate segmentation masks for surface cracks using only image-level supervision. By training a binary classifier and extracting attribution maps through various XAI methods, the approach approximates pixel-level segmentations without requiring labor-intensive annotations. The methodology is evaluated on a stone masonry crack dataset, showing that while segmentation quality is lower than fully supervised methods, it remains effective for monitoring crack severity and growth. Layerwise Relevance Propagation (LRP) demonstrates the best balance between segmentation quality, computational efficiency, and applicability to crack growth monitoring.

## Method Summary
The methodology trains a binary classifier (VGG11-128) on image-level labels to distinguish cracked from non-cracked images. Eight XAI methods (Input×Gradient, Integrated Gradients, DeepLift variants, LRP, NN-Explainer, B-cos) extract pixel-level attribution maps from the classifier's decision. These maps undergo post-processing through binarization and morphological operations (closing, area opening) to produce clean segmentation masks. For methods sensitive to baselines (Integrated Gradients, DeepLift), damage-free images serve as more representative references than standard zero/random baselines. The resulting masks enable crack severity quantification and growth monitoring through metrics like crack-per-patch (CPP), area, and width.

## Key Results
- LRP method achieved the best balance between segmentation quality and computational efficiency for crack monitoring
- Using damage-free images as baselines improved Integrated Gradients F1-score from 11.13% to 18.91%
- Segmentation masks, while lower quality than fully supervised methods, remain effective for monitoring crack severity and growth
- Morphological post-processing significantly improves mask quality by closing gaps and removing noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: A binary classifier trained only on image-level labels can produce pixel-level segmentation masks through attribution maps from XAI methods.
- Mechanism: The classifier learns discriminative features between crack and non-crack regions during training. XAI attribution methods extract pixel-level relevance scores from the classifier's decision, highlighting which pixels contributed most to the crack class prediction. These scores approximate the segmentation mask.
- Core assumption: The discriminative regions learned by the classifier for crack classification correspond to the actual crack pixels in the image.
- Evidence anchors:
  - [abstract] "leverage explainable artificial intelligence (XAI) to derive segmentations from the explanations of a classifier, requiring only weak image-level supervision."
  - [section 2.2] "the principle is to approximate segmentation masks by explanations"
- Break condition: If the classifier fails to learn meaningful discriminative features for cracks, or if XAI methods fail to localize the relevant pixels accurately, the segmentation masks will be poor.

### Mechanism 2
- Claim: Using damage-free images as baselines in Integrated Gradients and DeepLift-based methods significantly improves attribution quality.
- Mechanism: Standard baselines (zero or random) create attributions that spread over large areas around cracks. Damage-free images serve as more representative references, focusing attributions specifically on crack regions by comparing to known crack-free textures.
- Core assumption: The baseline distribution of damage-free images better represents the absence of cracks than generic baselines.
- Evidence anchors:
  - [section 3.4] "We propose an alternative approach of sampling a set of images from the damage-free class... This modification significantly improves the quality of attributions"
  - [section 4.1] "when using the standard baseline, IntGrad obtained an F1-score of only 11.13%... whereas it increased to 18.91% when using the mean damage-free image baseline"
- Break condition: If the damage-free image baseline is not representative of the true crack-free background in test images, or if the method is sensitive to baseline choice in other ways.

### Mechanism 3
- Claim: Morphological post-processing operations improve segmentation masks by closing gaps and removing noise while trading off between precision and recall.
- Mechanism: Binarization converts continuous attribution scores to binary masks, but creates holes and noise. Morphological closing (dilation followed by erosion) merges dense regions and fills small gaps. Area opening removes small noisy regions. A second closing closes larger gaps. These operations create cleaner masks suitable for severity quantification.
- Core assumption: The attribution maps contain dense regions around cracks with some gaps and noise that can be improved by morphological operations.
- Evidence anchors:
  - [section 2.3] "The attribution maps undergo post-processing in two stages... (1) Binarize... (2) Apply morphological operations... (1) Closing... (2) Area opening... (3) Second closing"
  - [section 4.1] "In terms of post-processing, the GMM thresholding strategy generally yields the best performance. However, when morphological operations are applied, the simple strategy produces superior results"
- Break condition: If attribution maps are too scattered or noisy, morphological operations may not sufficiently improve them, or may introduce artifacts that reduce segmentation quality.

## Foundational Learning

- Concept: Weakly-supervised segmentation vs fully supervised segmentation
  - Why needed here: The paper's core contribution is avoiding pixel-level annotation by using image-level labels plus XAI. Understanding the difference is essential to grasp the value proposition.
  - Quick check question: What is the key labeling difference between weakly-supervised and fully supervised segmentation methods?

- Concept: Explainable AI (XAI) attribution methods
  - Why needed here: The paper evaluates multiple XAI methods (LRP, Integrated Gradients, DeepLift, etc.) for generating segmentation masks. Understanding how these methods work is crucial for interpreting results.
  - Quick check question: How do post-hoc attribution methods differ from inherently explainable architectures like B-cos networks?

- Concept: Morphological operations in image processing
  - Why needed here: Post-processing of attribution maps relies heavily on morphological operations (closing, area opening) to improve mask quality. Understanding these operations is essential for implementation.
  - Quick check question: What is the effect of morphological closing on a binary mask, and why is it useful for crack segmentation?

## Architecture Onboarding

- Component map: Data collection → Binary classifier training → XAI attribution extraction → Post-processing → Severity quantification → Growth monitoring
- Critical path: Data → Classifier → Attribution → Post-processing → Severity metrics
- Design tradeoffs:
  - Classifier accuracy vs. explainability: Some XAI methods (LRP) require specific architectures without skip connections
  - Baseline choice: Damage-free images improve attributions but add complexity
  - Post-processing parameters: Radius for closing, area threshold for opening affect precision-recall tradeoff
  - Runtime vs. quality: Augmentation smoothing improves results but increases computation

- Failure signatures:
  - Poor classifier performance → Scattered attributions across entire image
  - Wrong baseline choice → Attributions spread over background textures
  - Over-aggressive morphological operations → Masks become too large, reducing precision
  - Under-aggressive operations → Masks remain fragmented with holes

- First 3 experiments:
  1. Train VGG11-128 classifier on DIC dataset, evaluate TPR/TNR to ensure it can distinguish crack vs non-crack
  2. Extract attributions using LRP on test set, apply simple thresholding, visualize results against ground truth
  3. Apply full post-processing pipeline (binarization + morphological operations) to attributions, measure F1 score improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed weakly-supervised methodology using XAI compare to traditional semi-supervised learning approaches for crack segmentation, in terms of both performance and computational efficiency?
- Basis in paper: [inferred] The paper focuses on weakly-supervised methods using XAI and compares them to fully supervised (U-Net) and unsupervised approaches. However, it does not explore semi-supervised learning techniques.
- Why unresolved: The paper does not provide a comparison with semi-supervised learning methods, which could leverage both labeled and unlabeled data to improve segmentation performance.
- What evidence would resolve it: Conducting experiments comparing the proposed XAI-based methodology to semi-supervised learning approaches on the same crack segmentation dataset, evaluating both segmentation quality and computational efficiency.

### Open Question 2
- Question: Can the proposed methodology be extended to handle multi-class crack segmentation, where different types of cracks (e.g., vertical, horizontal, diagonal) are classified and segmented separately?
- Basis in paper: [explicit] The paper mentions that the methodology can be extended to handle multi-class and multi-label classification, but does not explore this aspect in the experiments.
- Why unresolved: The paper focuses on binary crack classification (cracked vs. non-cracked) and does not investigate the performance of the methodology for multi-class crack segmentation.
- What evidence would resolve it: Applying the proposed methodology to a dataset with multiple crack types, evaluating the segmentation quality for each crack class and comparing the results to fully supervised multi-class segmentation methods.

### Open Question 3
- Question: How does the performance of the proposed methodology vary with the size and diversity of the training dataset, and what are the implications for real-world applications with limited data?
- Basis in paper: [inferred] The paper uses a relatively small dataset (530 cracked images) and does not investigate the impact of dataset size and diversity on the performance of the proposed methodology.
- Why unresolved: The paper does not explore the scalability and robustness of the proposed methodology when applied to larger and more diverse datasets, which is crucial for real-world applications.
- What evidence would resolve it: Conducting experiments with varying dataset sizes and levels of diversity, evaluating the segmentation quality and severity quantification performance of the proposed methodology, and comparing the results to fully supervised methods trained on the same datasets.

## Limitations

- The methodology's effectiveness depends heavily on classifier performance, with errors propagating to segmentation masks
- Segmentation masks exhibit lower quality compared to fully supervised methods, though remaining sufficient for severity monitoring
- Morphological post-processing parameters are not fully specified, potentially affecting reproducibility
- The approach's effectiveness across diverse crack types, imaging conditions, and material surfaces remains unexplored beyond stone masonry

## Confidence

**High Confidence:** The core mechanism of using classifier attributions for segmentation (Mechanism 1) is well-supported by the paper's results and aligns with established XAI literature. The improvement from damage-free image baselines (Mechanism 2) shows clear quantitative evidence with specific F1-score improvements.

**Medium Confidence:** The effectiveness of morphological operations (Mechanism 3) is demonstrated but relies on specific parameter choices that are not fully detailed. The superiority of LRP for this application is supported but could benefit from more extensive comparison across diverse datasets.

## Next Checks

1. **Classifier Validation:** Verify that the VGG11-128 classifier achieves reasonable TPR/TNR (>80%) on the test set before trusting XAI attributions, as classifier errors propagate to segmentation.

2. **Baseline Sensitivity Analysis:** Test the impact of different baseline choices (zero, random, mean damage-free) on attribution quality across multiple XAI methods to quantify the claimed improvement.

3. **Parameter Sensitivity:** Systematically vary morphological operation parameters (closing radius, area opening threshold) to determine their impact on precision-recall tradeoff and identify optimal settings for crack segmentation.