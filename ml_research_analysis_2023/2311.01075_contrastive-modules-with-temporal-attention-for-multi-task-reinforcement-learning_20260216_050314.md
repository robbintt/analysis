---
ver: rpa2
title: Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning
arxiv_id: '2311.01075'
source_url: https://arxiv.org/abs/2311.01075
tags:
- learning
- task
- modules
- tasks
- multi-task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Contrastive Modules with Temporal Attention
  (CMTA), a novel multi-task reinforcement learning method designed to mitigate negative
  transfer between tasks and within tasks. CMTA employs a modular architecture where
  multiple encoders are trained using contrastive learning to ensure distinctiveness,
  and a temporal attention mechanism dynamically combines these encoders based on
  task information and temporal context.
---

# Contrastive Modules with Temporal Attention for Multi-Task Reinforcement Learning

## Quick Facts
- arXiv ID: 2311.01075
- Source URL: https://arxiv.org/abs/2311.01075
- Reference count: 40
- This paper introduces Contrastive Modules with Temporal Attention (CMTA), a novel multi-task reinforcement learning method designed to mitigate negative transfer between tasks and within tasks. CMTA employs a modular architecture where multiple encoders are trained using contrastive learning to ensure distinctiveness, and a temporal attention mechanism dynamically combines these encoders based on task information and temporal context. Experiments on the Meta-World benchmark demonstrate that CMTA outperforms existing methods, achieving up to 34% improvement in mixed task environments and even surpassing single-task learning performance for the first time. The method's effectiveness is attributed to its ability to dynamically adapt module combinations, reducing redundancy and improving generalization.

## Executive Summary
This paper introduces Contrastive Modules with Temporal Attention (CMTA), a novel multi-task reinforcement learning method designed to mitigate negative transfer between tasks and within tasks. CMTA employs a modular architecture where multiple encoders are trained using contrastive learning to ensure distinctiveness, and a temporal attention mechanism dynamically combines these encoders based on task information and temporal context. Experiments on the Meta-World benchmark demonstrate that CMTA outperforms existing methods, achieving up to 34% improvement in mixed task environments and even surpassing single-task learning performance for the first time. The method's effectiveness is attributed to its ability to dynamically adapt module combinations, reducing redundancy and improving generalization.

## Method Summary
CMTA is a multi-task reinforcement learning method that addresses negative transfer by using a modular architecture with contrastive learning and temporal attention. The method employs multiple expert encoders that learn distinct feature representations through a contrastive loss, an LSTM to encode temporal context, and a task encoder to represent task identity. At each time step, temporal and task embeddings are combined to compute attention weights over the expert outputs, allowing dynamic selection of module combinations. The approach is evaluated on Meta-World's MT10-Mixed and MT50-Mixed variants using Soft Actor-Critic (SAC) as the backbone algorithm.

## Key Results
- CMTA achieves up to 34% improvement in success rate over existing multi-task RL methods on mixed task environments.
- For the first time, CMTA surpasses single-task learning performance in multi-task settings.
- The method demonstrates consistent improvement across both MT10-Mixed and MT50-Mixed variants of the Meta-World benchmark.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive learning between encoder outputs enforces module distinctiveness.
- Mechanism: At each time step, the output of each encoder serves as a query, while the next-step output of the same encoder is treated as the positive key and all other encoders' outputs as negative keys. The contrastive loss maximizes the similarity between a query and its positive key while minimizing it with negative keys.
- Core assumption: Encoders learning similar functions will produce similar embeddings, so pushing embeddings apart reduces functional redundancy.
- Evidence anchors:
  - [abstract] "constrains the modules to be different from each other by contrastive learning"
  - [section] "use contrastive learning to encourage the modules to be different from each other"
  - [corpus] Weak/no direct corpus support for contrastive module separation; only general contrastive learning mentions.
- Break condition: If encoder outputs are already highly dissimilar due to architectural constraints or input differences, contrastive loss may plateau without improving distinctiveness.

### Mechanism 2
- Claim: Temporal attention dynamically selects module combinations per time step, reducing within-task negative transfer.
- Mechanism: An LSTM encodes temporal context, a task encoder encodes task identity, and their concatenation is used to compute soft attention weights over the encoder outputs. These weights are applied at every time step to form the final representation.
- Core assumption: Within a task, different sub-goals or phases require different combinations of feature extractors; fixed module combinations cause interference.
- Evidence anchors:
  - [abstract] "combining shared modules at a finer granularity than the task level with temporal attention"
  - [section] "we propose combining the modules with finer granularity at each time step by using temporal attention"
  - [corpus] No corpus mention of temporal attention for multi-task RL; evidence is internal to paper.
- Break condition: If temporal context is uninformative or task encoder output is constant across steps, attention weights will be static, negating the benefit.

### Mechanism 3
- Claim: Mixing all position variants during training improves generalization by forcing the model to learn task structure rather than memorizing positions.
- Mechanism: In MT10-Mixed and MT50-Mixed, 50 sets of initial positions are shuffled together, preventing the policy from overfitting to a fixed configuration.
- Core assumption: Exposure to varied initial states during training leads to better generalization than a single fixed state.
- Evidence anchors:
  - [section] "we mix all 50 sets of positions together for tasks in MT10 and MT50 at training stage, and name them as MT10-Mixed and MT50-Mixed"
  - [section] "it becomes more difficult because the agent have to deduce patterns or objectives of tasks (e.g., moving an object to a goal) rather than merely memorizing fixed positions"
  - [corpus] No corpus evidence of this specific position-mixing strategy.
- Break condition: If task semantics are tightly coupled to specific positions, mixing may degrade performance by removing crucial context.

## Foundational Learning

- Concept: Multi-task reinforcement learning objective
  - Why needed here: CMTA optimizes a shared policy across multiple tasks; understanding the joint loss is essential for correct implementation.
  - Quick check question: What is the form of the total loss function in multi-task RL and how does it differ from single-task RL?

- Concept: Contrastive learning (InfoNCE loss)
  - Why needed here: The distinctiveness of modules is enforced via a contrastive loss over encoder outputs; implementation requires correct positive/negative pair construction.
  - Quick check question: In the context of CMTA, how are positive and negative pairs defined across encoders and time steps?

- Concept: Temporal attention and LSTM encoding
  - Why needed here: The model uses an LSTM to encode temporal dynamics; correct hidden state handling is critical for dynamic module selection.
  - Quick check question: How does the attention weight computation combine temporal and task embeddings at each step?

## Architecture Onboarding

- Component map:
  - Task encoder: maps one-hot task ID to a dense embedding
  - k experts (encoders): each produces a feature representation from the state
  - LSTM: encodes temporal context from state and previous hidden state
  - Attention module: computes soft weights over expert outputs using concatenated temporal and task embeddings
  - Contrastive loss module: enforces dissimilarity between expert outputs
  - SAC backbone: policy and Q-function learning from combined representation

- Critical path:
  1. State → k expert encodings
  2. State + prev hidden → temporal embedding
  3. Task ID → task embedding
  4. Temporal + task → attention weights
  5. Attention weights → weighted sum of expert encodings
  6. Combined embedding → SAC policy/value updates
  7. Contrastive loss computed on expert outputs

- Design tradeoffs:
  - More experts → higher expressiveness but quadratic growth in contrastive loss computation
  - Task encoder from scratch vs pretrained: faster convergence vs better task relationships
  - Inclusion of contrastive loss vs simpler regularization: improved distinctiveness vs lower compute

- Failure signatures:
  - All attention weights collapse to near-zero except one → attention may be degenerate
  - Contrastive loss plateaus at high value → modules may already be dissimilar or loss is ineffective
  - Performance worse than single-task SAC → negative transfer persists or architecture too complex

- First 3 experiments:
  1. Replace temporal attention with fixed module weights and compare performance
  2. Remove contrastive loss and measure similarity between expert embeddings via t-SNE
  3. Vary number of experts (2, 4, 6, 12) and record trade-off between success rate and compute

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CMTA's performance scale with the number of tasks and modules in extremely large-scale multi-task RL scenarios?
- Basis in paper: [inferred] The paper mentions that CMTA's advantages become more apparent as task variety increases from MT10 to MT50, but doesn't explore scaling to hundreds or thousands of tasks.
- Why unresolved: The experiments were limited to 50 tasks, and computational cost of contrastive learning grows quadratically with the number of experts.
- What evidence would resolve it: Systematic experiments varying both task count and module count, along with computational complexity analysis and performance scaling curves.

### Open Question 2
- Question: Can CMTA effectively handle negative transfer between tasks that are fundamentally unrelated or contradictory?
- Basis in paper: [explicit] The authors acknowledge this as a limitation, stating "humans struggle to extract mutually beneficial information from entirely unrelated tasks."
- Why unresolved: The Meta-World benchmark consists of related robotics manipulation tasks, not truly unrelated tasks.
- What evidence would resolve it: Experiments on diverse tasks from different domains (e.g., combining Atari games with robotics tasks) to test robustness to unrelated task combinations.

### Open Question 3
- Question: How critical is the temporal attention mechanism compared to static task-level module combinations?
- Basis in paper: [explicit] The ablation study shows temporal information improves performance, but doesn't compare against task-level fixed combinations with contrastive learning.
- Why unresolved: The paper only compares full CMTA against baselines, not isolated components.
- What evidence would resolve it: A controlled experiment comparing static task-level module combinations with and without contrastive learning against the full temporal attention approach.

### Open Question 4
- Question: What is the optimal balance between module specialization (contrastive learning) and task similarity in multi-task RL?
- Basis in paper: [inferred] The authors mention "dependence on task similarity" as a limitation but don't explore the relationship between task similarity and module distinctiveness requirements.
- Why unresolved: The paper uses fixed contrastive learning strength (β=2500) without analyzing sensitivity to this hyperparameter or task similarity.
- What evidence would resolve it: Systematic experiments varying task similarity (using different task subsets from Meta-World) and contrastive learning strength to identify optimal operating regimes.

## Limitations
- Limited architectural detail for task and expert encoders, making exact reproduction challenging.
- No evidence provided for performance on truly unrelated tasks or beyond 50 tasks.
- Claim of being first to surpass single-task learning requires verification against comprehensive prior work.

## Confidence
- **High**: The core architectural design (modular encoders + temporal attention + contrastive loss) is clearly specified and logically sound.
- **Medium**: The effectiveness of the method is demonstrated on Meta-World, but the ablation studies could be more extensive to isolate the contributions of each component.
- **Low**: The claim of being the first to surpass single-task learning is difficult to verify without a comprehensive survey of prior work.

## Next Checks
1. **Ablation Study**: Conduct a more thorough ablation study by systematically removing the temporal attention and contrastive loss components to quantify their individual contributions to performance gains.
2. **Generalization Test**: Evaluate CMTA on a different multi-task RL benchmark (e.g., Atari 57 or DMLab) to assess its generalizability beyond Meta-World.
3. **Hyperparameter Sensitivity**: Perform a sensitivity analysis on the number of experts and the weight of the contrastive loss to identify the optimal configuration and robustness of the method.