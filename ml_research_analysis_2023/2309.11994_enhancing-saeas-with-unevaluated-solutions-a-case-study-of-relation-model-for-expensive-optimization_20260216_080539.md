---
ver: rpa2
title: 'Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model
  for Expensive Optimization'
arxiv_id: '2309.11994'
source_url: https://arxiv.org/abs/2309.11994
tags:
- solutions
- relation
- algorithm
- solution
- population
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of high-quality offspring degradation
  in surrogate-assisted evolutionary algorithms (SAEAs) caused by evaluating only
  a limited number of solutions per generation, which reduces variance between adjacent
  populations. The proposed method, DRSO, introduces unevaluated solutions into the
  reproduction process using a relation model-based surrogate framework.
---

# Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model for Expensive Optimization

## Quick Facts
- arXiv ID: 2309.11994
- Source URL: https://arxiv.org/abs/2309.11994
- Reference count: 40
- Key outcome: DRSO achieves best mean rank (2.29 in 20D, 1.47 in 50D) across 17 test instances, outperforming state-of-the-art SAEAs.

## Executive Summary
This paper addresses the problem of high-quality offspring degradation in surrogate-assisted evolutionary algorithms (SAEAs) caused by evaluating only a limited number of solutions per generation, which reduces variance between adjacent populations. The proposed method, DRSO, introduces unevaluated solutions into the reproduction process using a relation model-based surrogate framework. Two relation models (fitness-based and category-based) are trained to select the best evaluated solution (Qbest) and a set of high-quality unevaluated solutions (Pu). The algorithm combines these evaluated and unevaluated solutions to generate new offspring via a variable-width histogram (VWH) model and local search. Experiments on two test suites (LZG and YLL) in 20D and 50D show that DRSO outperforms state-of-the-art SAEAs, Bayesian optimization (BO), and basic EAs. Wilcoxon rank sum tests confirm its statistical superiority.

## Method Summary
DRSO introduces unevaluated solutions into the reproduction process of SAEAs to address the issue of reduced variance between adjacent populations when only limited solutions are evaluated per generation. The method uses two relation models (fitness-based and category-based) trained via XGBoost to select the best evaluated solution (Qbest) and a set of high-quality unevaluated solutions (Pu). These solutions are combined with evaluated solutions (Pe) to generate new offspring using a variable-width histogram (VWH) model and local search. The approach aims to improve exploration and exploitation balance while minimizing function evaluations in expensive optimization problems.

## Key Results
- DRSO achieves the best mean rank (2.29 in 20D, 1.47 in 50D) across 17 test instances on LZG and YLL benchmark suites.
- Wilcoxon rank sum tests confirm statistical superiority over state-of-the-art SAEAs, BO, and basic EAs.
- Ablation studies demonstrate the importance of Qbest selection, Pu incorporation, and the relation model in achieving these results.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using unevaluated solutions alongside evaluated ones improves population diversity and avoids local optima.
- Mechanism: DRSO uses a surrogate model to identify high-quality unevaluated solutions (Pu) and integrates them into the offspring generation process via the VWH model, without incurring evaluation costs.
- Core assumption: Surrogate models can reliably predict solution quality for unevaluated solutions, and these predictions are sufficiently accurate to guide search.
- Evidence anchors:
  - [abstract]: "The surrogate model is employed to identify high-quality solutions for direct generation of new solutions without evaluation."
  - [section 3.3.3]: "In each iteration, the process of generating the offspring population, using a combination of VWH and local search with both Pe and Pu, will be executed."
  - [corpus]: Weak; corpus neighbors focus on surrogate ensembles and LLM-driven SAEAs but do not directly support the unevaluated solution mechanism.
- Break condition: If surrogate model predictions are inaccurate, the algorithm may waste budget exploring poor-quality regions or miss the global optimum.

### Mechanism 2
- Claim: The dual relation model approach (fitness-based and category-based) provides more accurate solution selection than traditional regression or classification models.
- Mechanism: The fitness-based criterion (C1) selects the best solution (Qbest) by comparing predicted fitness relationships, while the category-based criterion (C2) selects a set of high-quality unevaluated solutions (Pu) by classifying solutions into good/bad categories.
- Core assumption: Learning the relative relationship between solutions (superiority/inferiority) is more informative than learning absolute fitness values or discrete categories.
- Evidence anchors:
  - [abstract]: "We have introduced two tailored relation models for the selection of the optimal solution and the unevaluated population."
  - [section 3.2]: Detailed explanation of C1 and C2 criteria and their construction.
  - [section 4.4.2]: Experimental comparison showing relation models outperform XGBR and XGBC in selecting Qbest and Pu.
- Break condition: If the relationship data is noisy or insufficient, the relation model may not outperform simpler regression or classification approaches.

### Mechanism 3
- Claim: Combining VWH (global distribution modeling) with local search (individual exploitation) balances exploration and exploitation in expensive optimization.
- Mechanism: VWH models the joint distribution of evaluated (Pe) and unevaluated (Pu) solutions to generate diverse offspring, while local search refines promising individuals using objective values.
- Core assumption: The VWH model can effectively capture the distribution of both evaluated and unevaluated solutions, and local search can improve solution quality without excessive function evaluations.
- Evidence anchors:
  - [section 3.3.1]: "VWH emphasizes promising areas, reducing probabilities in other regions to prevent premature convergence."
  - [section 3.3.2]: "In order to compensate for the lack of local solution information, EDA/LS [36] proposes incorporating the results of local search into the offspring generated by the VWH model."
  - [section 4.3]: Ablation study shows DRSO-Gen-1 and DRSO-Gen-2 (variants without Pu or local search) perform worse than DRSO.
- Break condition: If the VWH model fails to capture the true distribution or local search gets stuck in local optima, the algorithm may converge prematurely or inefficiently.

## Foundational Learning

- Concept: Surrogate models and their types (regression, classification, relation)
  - Why needed here: Understanding how different surrogate models work and their strengths/weaknesses is crucial for appreciating why the relation model is effective in DRSO.
  - Quick check question: What is the key difference between a regression model and a relation model in the context of SAEAs?
- Concept: Expensive optimization problems (EOPs) and the need for efficient sampling
  - Why needed here: Recognizing the computational cost of evaluating solutions in EOPs explains why unevaluated solutions are valuable and why surrogate models are essential.
  - Quick check question: Why is it important to minimize the number of function evaluations in expensive optimization?
- Concept: Estimation of Distribution Algorithms (EDAs) and their components (VWH, local search)
  - Why needed here: Understanding how EDAs work, particularly the VWH model and local search, is necessary for grasping how DRSO generates new solutions.
  - Quick check question: How does the VWH model differ from traditional crossover and mutation operators in EAs?

## Architecture Onboarding

- Component map:
  - Population (Pe) -> Archive (A) -> Unevaluated Population (Pu) -> Offspring Population (Q)
  - Surrogate Models (M1, M2) -> Relation models for selecting Qbest and Pu
  - Evaluation Budget (FEs) -> Limited function evaluations
- Critical path:
  1. Initialize population and evaluate solutions
  2. Generate offspring using VWH and local search with Pe and Pu
  3. Train relation models (M1, M2) on archive
  4. Select Qbest (best solution) and Pu (high-quality unevaluated solutions) using M1 and M2
  5. Evaluate Qbest and update archive
  6. Repeat until budget exhausted
- Design tradeoffs:
  - Model accuracy vs. evaluation cost: More accurate models require more training data, which increases evaluation cost.
  - Exploration vs. exploitation: Using unevaluated solutions increases exploration but may introduce noise.
  - Population size vs. budget: Larger populations provide better diversity but consume more evaluations.
- Failure signatures:
  - Poor convergence: Surrogate model predictions are inaccurate, leading to wasted evaluations.
  - Premature convergence: Insufficient exploration due to over-reliance on surrogate predictions.
  - High evaluation cost: Surrogate model training requires too many evaluations, leaving insufficient budget for actual optimization.
- First 3 experiments:
  1. Verify relation model accuracy: Compare M1 and M2 predictions against ground truth on a small test set.
  2. Test unevaluated solution integration: Run DRSO with and without Pu on a simple benchmark to measure impact on convergence.
  3. Evaluate VWH and local search balance: Vary the ratio of VWH to local search and observe effects on solution quality and diversity.

## Open Questions the Paper Calls Out
- Question: How does the performance of DRSO scale with increasing dimensionality beyond 50D, particularly in high-dimensional problems (100D+)?
  - Basis in paper: [inferred] The paper tests DRSO on 20D and 50D problems but does not explore scalability to higher dimensions. The authors mention this as a direction for future work.
  - Why unresolved: High-dimensional problems pose unique challenges for surrogate models (e.g., curse of dimensionality, computational complexity), which may affect DRSO's effectiveness.
  - What evidence would resolve it: Comparative experiments of DRSO against state-of-the-art methods on benchmark problems with dimensions ≥100D, measuring convergence speed, solution quality, and computational efficiency.

- Question: Can the relation model-based surrogate framework be extended to multi-objective optimization problems, and how would it compare to existing multi-objective SAEAs?
  - Basis in paper: [explicit] The authors state that "the relation model can be tried on more algorithm frameworks and problem types" in the conclusion, suggesting potential for multi-objective applications.
  - Why unresolved: Multi-objective optimization introduces additional complexity, such as Pareto front approximation and trade-off handling, which may require modifications to the relation model.
  - What evidence would resolve it: Implementation and evaluation of DRSO or a modified version on standard multi-objective benchmark problems (e.g., DTLZ, WFG), comparing hypervolume, generational distance, and spread metrics against leading multi-objective SAEAs.

- Question: What is the impact of different classification thresholds (t) in the category-based relation model on the diversity and convergence of the population in DRSO?
  - Basis in paper: [explicit] The authors analyze t = 10%, 30%, and 50% in ablation studies and observe performance differences, but do not provide a systematic sensitivity analysis or theoretical justification for optimal threshold selection.
  - Why unresolved: The threshold t directly influences the balance between exploration and exploitation, but its optimal value likely depends on problem characteristics (e.g., modality, landscape ruggedness).
  - What evidence would resolve it: A comprehensive study varying t across a range of values (e.g., 5%–95%) on diverse benchmark problems, coupled with analysis of population diversity metrics (e.g., entropy, crowding distance) and convergence behavior.

## Limitations
- Dependency on surrogate model accuracy for selecting unevaluated solutions, which may vary across problem domains.
- Experimental validation confined to synthetic benchmark problems without real-world expensive optimization applications.
- Computational overhead of training relation models (particularly with XGBoost) and sensitivity to hyperparameter settings.

## Confidence
- **High Confidence**: The fundamental observation that evaluating too few solutions per generation degrades population variance is well-established. The experimental results showing DRSO's superior performance on benchmark suites are statistically significant and reproducible.
- **Medium Confidence**: The mechanism by which unevaluated solutions improve search (via surrogate-guided selection) is theoretically sound but relies on surrogate model accuracy that may vary across problem domains. The claim that relation models outperform traditional regression/classification approaches is supported by ablation studies but lacks comparison against other advanced surrogate strategies.
- **Low Confidence**: The assertion that DRSO achieves the best mean rank across all test instances may be influenced by benchmark selection bias, as the method has not been validated on real-world expensive optimization problems.

## Next Checks
1. **Cross-domain validation**: Test DRSO on at least two real-world expensive optimization problems (e.g., aerodynamic design, material science simulations) to verify generalizability beyond synthetic benchmarks.
2. **Surrogate model comparison**: Conduct head-to-head comparisons between DRSO's relation models and alternative surrogate approaches (e.g., Gaussian processes, neural network ensembles) on identical problem sets to quantify relative performance gains.
3. **Budget sensitivity analysis**: Systematically vary the evaluation budget (FEs) to determine DRSO's performance threshold and identify the minimum budget required for consistent improvement over baseline SAEAs.