---
ver: rpa2
title: 'Fabricator: An Open Source Toolkit for Generating Labeled Training Data with
  Teacher LLMs'
arxiv_id: '2309.09582'
source_url: https://arxiv.org/abs/2309.09582
tags:
- dataset
- examples
- prompt
- generation
- few-shot
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces FABRICATOR, an open-source Python toolkit
  for dataset generation using large language models (LLMs). The tool enables researchers
  to generate labeled training data for various NLP tasks, addressing the challenge
  of limited human-annotated data.
---

# Fabricator: An Open Source Toolkit for Generating Labeled Training Data with Teacher LLMs

## Quick Facts
- **arXiv ID**: 2309.09582
- **Source URL**: https://arxiv.org/abs/2309.09582
- **Reference count**: 20
- **Primary result**: FABRICATOR is an open-source Python toolkit that enables dataset generation for NLP tasks using LLMs, supporting three workflows: generating unlabeled data, generating label-conditioned data, and annotating existing unlabeled data.

## Executive Summary
FABRICATOR is an open-source Python toolkit designed to address the bottleneck of limited human-annotated data in NLP by enabling researchers to generate labeled training data using large language models (LLMs). The toolkit integrates with HuggingFace's DATASETS library and offers a flexible interface for customizing prompts and leveraging few-shot examples. Experiments demonstrate that FABRICATOR can generate high-quality datasets for simple tasks like binary sentiment classification, achieving comparable performance to human-annotated data. However, for more complex tasks like multi-class classification and question answering, the performance of models trained on LLM-generated data falls short. The paper also explores the impact of few-shot examples on dataset generation quality, showing improvements when more examples are included.

## Method Summary
The method involves using FABRICATOR to generate labeled datasets for various NLP tasks by prompting an LLM with task descriptions, label options, and few-shot examples. The generated datasets are then used to fine-tune smaller pre-trained language models (PLMs) like BERT or RoBERTa, and their performance is compared against models trained on human-annotated data. The toolkit supports three workflows: generating unlabeled data, generating label-conditioned data, and annotating existing unlabeled data. The experiments vary the number of few-shot examples per prompt and class to assess their impact on dataset quality and model performance.

## Key Results
- FABRICATOR successfully generates high-quality datasets for simple NLP tasks like binary sentiment classification, achieving comparable performance to human-annotated data.
- For complex tasks like multi-class classification and question answering, models trained on LLM-generated data fall short compared to those trained on human-annotated data.
- Including few-shot examples in prompts generally improves dataset generation quality, with a positive trend observed when increasing the number of examples per prompt.
- Instruction-tuned LLaMA models can significantly improve annotation quality for structured tasks like entity recognition compared to general-purpose LLMs like GPT-3.5.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dataset generation with LLMs reduces dependency on human-annotated data.
- Mechanism: By prompting an LLM to generate labeled data for a specific task, researchers can bypass the costly process of manual annotation while still obtaining training data for downstream NLP models.
- Core assumption: The LLM can generate realistic and task-appropriate text that matches the semantic requirements of the target labels.
- Evidence anchors:
  - [abstract] "Current research addresses this bottleneck by exploring a novel paradigm called zero-shot learning via dataset generation. Here, a powerful LLM is prompted with a task description to generate labeled data..."
  - [section] "Recent years, natural language processing (NLP) has witnessed remarkable progress... However, real-world applications of this approach face the bottleneck that sufficient amounts of human-annotated data are often unavailable and too costly to produce manually..."
- Break condition: If the LLM generates text that does not align semantically with the intended labels, the generated dataset will be of low quality and harm model performance.

### Mechanism 2
- Claim: Few-shot examples improve the quality of generated datasets.
- Mechanism: Including examples of labeled data in the prompt provides the LLM with concrete reference points for the expected output format and semantic style, leading to better alignment with human-annotated data.
- Core assumption: The few-shot examples are representative of the target distribution and do not introduce bias.
- Evidence anchors:
  - [section] "We find that for simple tasks such as binary sentiment classification (IMDB), models trained on the annotations by LLMs achieve similar accuracy on the gold-labeled test split..."
  - [section] "We note a generally positive trend in that both increasing the number of available few-shot examples and increasing the number of examples used in each prompt improves model performance."
- Break condition: If the few-shot examples are unrepresentative or too few, the LLM may generate data that deviates significantly from the intended label semantics.

### Mechanism 3
- Claim: Instruction-tuned open-source models can outperform general-purpose LLMs for structured annotation tasks.
- Mechanism: Fine-tuning an open-source model on instruction-following datasets enables it to better understand and execute structured annotation tasks (e.g., token-level NER) compared to models without such fine-tuning.
- Core assumption: The instruction-tuning dataset covers the types of structured outputs needed for the target task.
- Evidence anchors:
  - [section] "We observe that using the dataset as-is results in often unusable annotation outputs, primarily due to imprecise formatting. To address this, we convert the token-level labels into spans and prompt the LLM to extract all named entities..."
  - [section] "Our findings indicate that the annotation quality of instruction-tuned LLMs can significantly improve over OpenAI’s GPT, as evident from the higher F1 score."
- Break condition: If the instruction-tuning data does not cover the target task's output format, the model may still produce unusable annotations.

## Foundational Learning

- **Concept: Prompt engineering**
  - Why needed here: The quality of generated datasets depends heavily on how the prompt is constructed, including task description, label options, and few-shot examples.
  - Quick check question: How does including few-shot examples in the prompt affect the LLM's ability to generate task-appropriate data?

- **Concept: Dataset interoperability (HuggingFace DATASETS)**
  - Why needed here: FABRICATOR integrates with HuggingFace's DATASETS library to ensure generated datasets can be easily used for training and shared with the community.
  - Quick check question: What is the benefit of using the HuggingFace DATASETS format for generated datasets?

- **Concept: Few-shot learning**
  - Why needed here: Few-shot examples guide the LLM's generation process, improving the alignment between generated and human-annotated data.
  - Quick check question: Why might using too many few-shot examples in a single prompt degrade performance?

## Architecture Onboarding

- **Component map**: DatasetGenerator -> BasePrompt -> PromptNode -> Dataset (HuggingFace DATASETS format)

- **Critical path**:
  1. Load or create a few-shot dataset.
  2. Define a BasePrompt with task description and label options.
  3. Initialize a PromptNode with the desired LLM.
  4. Create a DatasetGenerator with the PromptNode.
  5. Call generate() with the prompt, few-shot dataset, and generation parameters.
  6. Use the generated Dataset for training or further analysis.

- **Design tradeoffs**:
  - Using few-shot examples improves generation quality but increases prompt complexity and cost.
  - Instruction-tuned models may perform better on structured tasks but require additional fine-tuning resources.
  - Integrating with HuggingFace DATASETS ensures compatibility but may limit flexibility for non-standard data formats.

- **Failure signatures**:
  - Generated data does not match expected label semantics → Check prompt construction and few-shot example quality.
  - Generation fails or produces incomplete data → Verify LLM API availability and prompt length limits.
  - Generated dataset causes training instability → Inspect data distribution and balance across classes.

- **First 3 experiments**:
  1. Generate a binary sentiment dataset using GPT-3.5 with 2 few-shot examples per class.
  2. Re-annotate the TREC-6 dataset with varying numbers of few-shot examples to assess impact on quality.
  3. Compare instruction-tuned LLaMA models with GPT-3.5 on a structured task like CoNLL-03 NER.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of few-shot examples to include in prompts for dataset generation across different NLP tasks?
- Basis in paper: [explicit] Section 3.2 and Table 2 discuss experiments varying the number of few-shot examples per prompt.
- Why unresolved: The paper shows that including few-shot examples generally improves performance, but the optimal number varies by task and the results are uneven, especially when exceeding 3 examples per class.
- What evidence would resolve it: Systematic experiments across a wider range of NLP tasks with different complexities, testing various numbers of few-shot examples per prompt and per class.

### Open Question 2
- Question: How does the quality of datasets generated by LLMs compare to human-annotated data for complex NLP tasks like multi-class classification and entity recognition?
- Basis in paper: [explicit] Section 3.1 shows that for complex tasks like SNLI and SQuAD, models trained on LLM-generated data fall short compared to human-annotated data.
- Why unresolved: The paper provides initial comparisons but does not explore ways to bridge the performance gap or identify specific reasons for the disparity.
- What evidence would resolve it: Experiments testing different prompt strategies, LLM models, and post-processing techniques to improve the quality of generated datasets for complex tasks.

### Open Question 3
- Question: Can instruction-tuned open-source models outperform proprietary models like GPT-3.5 in dataset generation tasks?
- Basis in paper: [explicit] Section 3.5 compares GPT-3.5 with instruction-tuned LLaMA models on the CoNLL-03 dataset.
- Why unresolved: While the paper shows that instruction-tuned LLaMA models have higher F1 scores, it does not explore a broader range of tasks or provide a comprehensive comparison.
- What evidence would resolve it: Extensive benchmarking of various instruction-tuned open-source models against proprietary models across multiple NLP tasks, including text classification, question answering, and entity recognition.

## Limitations

- The quality of LLM-generated datasets degrades significantly for complex NLP tasks like multi-class classification and question answering, limiting their applicability in these domains.
- The study does not explore the impact of dataset generation on real-world applications or test with smaller, resource-constrained LLMs.
- Potential biases introduced during dataset generation and the long-term stability of models trained on synthetic data are not addressed.

## Confidence

**High confidence**: The core claim that FABRICATOR successfully generates labeled datasets for simple NLP tasks and integrates well with existing NLP pipelines is well-supported by the experimental results and the open-source nature of the toolkit.

**Medium confidence**: The assertion that few-shot examples improve dataset quality is supported by trend analysis, but the relationship between example quantity and quality is not rigorously quantified across all task types. The observation that instruction-tuned LLaMA models outperform GPT-3.5 for structured tasks is based on a limited comparison and may not generalize to all annotation scenarios.

**Low confidence**: The claim that dataset generation with LLMs reduces dependency on human-annotated data is overstated, as the quality gap for complex tasks remains substantial. The paper does not provide evidence that synthetic datasets can fully replace human annotations in practical applications.

## Next Checks

1. **Task Complexity Validation**: Systematically evaluate FABRICATOR's performance across a broader range of NLP tasks, including sequence labeling and abstractive summarization, to determine the precise boundaries of task complexity where LLM-generated datasets become unreliable.

2. **Bias and Distribution Analysis**: Analyze the generated datasets for systematic biases, class imbalance, and distribution shifts compared to human-annotated data, particularly focusing on how these factors affect model generalization to unseen data.

3. **Real-World Application Test**: Apply models trained on FABRICATOR-generated datasets to a real-world NLP problem (e.g., customer support ticket classification) and compare their performance to models trained on human-annotated data in terms of accuracy, robustness, and practical utility.