---
ver: rpa2
title: 'The Next Chapter: A Study of Large Language Models in Storytelling'
arxiv_id: '2301.09790'
source_url: https://arxiv.org/abs/2301.09790
tags:
- story
- stories
- gpt3
- generation
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a comprehensive empirical study comparing the
  story generation capabilities of GPT-3 using prompt-based learning with state-of-the-art
  story generation models across three datasets differing in style, register, and
  length. GPT-3 generates significantly higher quality stories than other models and
  even rivals human-authored stories in most aspects according to both automatic and
  human evaluations.
---

# The Next Chapter: A Study of Large Language Models in Storytelling

## Quick Facts
- **arXiv ID**: 2301.09790
- **Source URL**: https://arxiv.org/abs/2301.09790
- **Reference count**: 40
- **Primary result**: GPT-3 generates significantly higher quality stories than other models and rivals human-authored stories in most aspects, but tends to plagiarize real stories when world knowledge is required

## Executive Summary
This paper presents a comprehensive empirical study comparing the story generation capabilities of GPT-3 using prompt-based learning with state-of-the-art story generation models across three datasets differing in style, register, and length. GPT-3 generates significantly higher quality stories than other models and even rivals human-authored stories in most aspects according to both automatic and human evaluations. However, preliminary investigation reveals GPT-3 tends to plagiarize real stories in scenarios involving world knowledge, raising questions about the extent of creative generation versus recycling from training data.

## Method Summary
The study uses prompt-based learning with GPT-3 text-davinci-001 to generate stories across three datasets: ROCStories, WritingPrompts, and CNN News. The model is compared against KGGPT2, PROGEN, MTCL, HINT, and BART baselines. Story quality is evaluated using both automatic metrics (BLEU, BERTScore, BARTScore, BLEURT, etc.) and human evaluation across five aspects: fluency, coherence, relatedness, logicality, and interestingness. The human evaluation was conducted via Amazon Mechanical Turk with five AMT workers per story.

## Key Results
- GPT-3 outperforms all baseline models on both automatic metrics and human evaluation
- GPT-3's story quality rivals human-authored stories in most evaluation aspects
- GPT-3 shows a tendency to plagiarize real stories when generating content requiring world knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3's large-scale pretraining on diverse web text provides strong world knowledge that improves story generation.
- Mechanism: The model's vast training data includes varied narratives, enabling it to recall and recombine story elements effectively.
- Core assumption: GPT-3's pretraining data contains sufficient coverage of story-like content across domains.
- Evidence anchors:
  - [abstract] "preliminary observation also reveals that they tend to 'plagiarise' real stories in situations involving world knowledge"
  - [section 7.1] "This means that in order to do the task well, having strong world knowledge is important"
- Break Condition: If GPT-3's pretraining data lacks coverage of specific domains, its story generation quality degrades significantly in those domains.

### Mechanism 2
- Claim: GPT-3's few-shot learning capability through prompt-based learning enables it to adapt to story generation tasks without explicit fine-tuning.
- Mechanism: Providing examples in the prompt allows GPT-3 to infer the desired task and generate stories accordingly.
- Core assumption: The prompt examples provided are representative of the target story domain.
- Evidence anchors:
  - [abstract] "Prompt-based learning using very large pre-trained language models (VLPLMs) such as GPT3 has demonstrated impressive performance"
  - [section 3.1] "we use prompt-based learning to adapt it to a story domain without any explicit fine-tuning"
- Break Condition: If the prompt examples are too few or not representative, GPT-3's generation quality drops significantly.

### Mechanism 3
- Claim: GPT-3's generation tends to recycle content from training data rather than purely generating novel content.
- Mechanism: When faced with prompts requiring specific world knowledge, GPT-3 retrieves and modifies existing story elements from its training data.
- Core assumption: GPT-3's training data contains substantial overlap with real-world stories in certain domains.
- Evidence anchors:
  - [abstract] "they tend to 'plagiarise' real stories in situations involving world knowledge"
  - [section 6] "we find 7 out of 10 instances are based on real stories from news articles"
- Break Condition: If the domain requires highly novel content creation without clear training data parallels, GPT-3's performance deteriorates.

## Foundational Learning

- Concept: Few-shot learning through prompt engineering
  - Why needed here: GPT-3 adapts to story generation tasks without explicit fine-tuning by learning from provided examples
  - Quick check question: How many examples are typically needed in the prompt for effective few-shot learning in story generation?

- Concept: Automatic evaluation metrics for text generation
  - Why needed here: The paper uses various automatic metrics (BLEU, BERTScore, etc.) to assess story quality
  - Quick check question: What's the key difference between reference-based and reference-free evaluation metrics?

- Concept: World knowledge integration in story generation
  - Why needed here: GPT-3's performance depends on its ability to incorporate world knowledge into stories
  - Quick check question: Why might GPT-3 struggle with generating completely novel stories versus recycling training data?

## Architecture Onboarding

- Component map: GPT-3 model -> Prompt-based learning interface -> Story generation output -> Evaluation pipeline (automatic metrics + human evaluation)
- Critical path: Prompt construction -> GPT-3 API call -> Response filtering -> Quality assessment
- Design tradeoffs: GPT-3 vs. fine-tuned models - trade-off between zero-shot/few-shot capability and task-specific optimization
- Failure signatures: Content recycling from training data, inability to generate stories beyond certain length, occasional non-English generation
- First 3 experiments:
  1. Test GPT-3 with varying numbers of prompt examples to find optimal few-shot performance
  2. Compare GPT-3's output quality with and without world knowledge requirements
  3. Evaluate GPT-3's ability to generate novel content vs. content similar to training data

## Open Questions the Paper Calls Out
- How does GPT-3's performance compare to other large language models like GPT-4 or PaLM in story generation tasks?
- Can prompt engineering significantly improve GPT-3's story generation performance beyond the simple approach used in this paper?
- How does GPT-3's tendency to "plagiarize" real stories impact the perceived quality and originality of its generated stories?

## Limitations
- The preliminary plagiarism investigation has a limited sample size (7 out of 10 instances)
- The study doesn't provide specific prompt examples used for GPT-3's few-shot learning
- Direct performance comparisons with fine-tuned models may be unfair due to GPT-3's vastly larger parameter count

## Confidence
- **High confidence**: GPT-3 outperforms other story generation models on automatic metrics
- **Medium confidence**: GPT-3 rivals human-authored stories in most aspects
- **Medium confidence**: GPT-3 tends to plagiarize real stories in world knowledge scenarios
- **Low confidence**: GPT-3 generates "significantly higher quality stories"

## Next Checks
1. Conduct a systematic analysis of GPT-3's story outputs across all three datasets to determine the frequency and patterns of content recycling versus novel generation
2. Systematically vary the number and quality of examples in GPT-3 prompts to quantify the relationship between prompt engineering quality and generation performance
3. Evaluate GPT-3's performance on story generation tasks in domains not well-represented in its pretraining data to determine whether its superior performance is due to genuine understanding or memorization of frequently occurring patterns