---
ver: rpa2
title: Approximating ReLU on a Reduced Ring for Efficient MPC-based Private Inference
arxiv_id: '2309.04875'
source_url: https://arxiv.org/abs/2309.04875
tags:
- relu
- bits
- hummingbird
- secret
- search
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HummingBird accelerates MPC-based private inference by reducing
  ReLU communication overhead. It uses a theoretical insight that only a subset of
  bits in secret shares is needed for accurate ReLU evaluation, discarding high- and
  low-order bits to reduce ring size.
---

# Approximating ReLU on a Reduced Ring for Efficient MPC-based Private Inference

## Quick Facts
- arXiv ID: 2309.04875
- Source URL: https://arxiv.org/abs/2309.04875
- Authors: Not specified
- Reference count: 40
- Key outcome: HummingBird accelerates MPC-based private inference by reducing ReLU communication overhead through bit-discarding, achieving 2.03-2.67× speedup without accuracy loss and up to 8.64× speedup with minor accuracy degradation

## Executive Summary
HummingBird addresses the communication bottleneck in MPC-based private inference by identifying and discarding bits in secret shares that don't affect ReLU evaluation accuracy. The framework uses theoretical insights to safely remove high-order and low-order bits, reducing the ring size and communication overhead. An efficient search algorithm finds optimal bit subsets for each ReLU layer, achieving significant speedups without sacrificing accuracy or with controlled accuracy degradation for maximum performance.

## Method Summary
HummingBird operates by theoretically analyzing which bits in secret shares are crucial for accurate ReLU evaluation and which can be safely discarded. It implements an efficient search engine that finds optimal bit retention configurations for each ReLU layer, then integrates these optimizations into the CrypTen MPC framework. The approach involves model finetuning to recover any accuracy lost due to bit reduction, and uses bit-packing optimizations to minimize communication overhead during online inference.

## Key Results
- Achieves 2.03-2.67× end-to-end speedup without accuracy loss
- Reduces total communication by 2.68-8.76×
- Up to 8.64× speedup with minor accuracy degradation
- Discards 87-91% of bits during ReLU evaluation while maintaining high accuracy

## Why This Works (Mechanism)

### Mechanism 1
Discarding high-order and low-order bits in secret shares approximates ReLU without accuracy loss. The framework identifies bits that don't affect sign estimation (DReLU output) and removes them to reduce communication overhead while preserving essential information. The sign of a value remains unchanged when removing certain bits as long as the inequality relationship between secret shares stays the same. This breaks if the secret value range isn't properly bounded or if discarded bits affect sign determination.

### Mechanism 2
Circuit adder complexity reduces from O(N log N) to O((k-m) log(k-m)) with reduced bit usage. By processing only a subset of bits (k-m instead of N), the depth of the circuit adder during arithmetic-to-binary conversion decreases logarithmically, directly reducing communication rounds and bytes. This breaks if other communication components become bottlenecks, preventing proportional performance improvements.

### Mechanism 3
The search engine efficiently finds optimal bit subsets for each ReLU layer. HummingBird uses depth-first search with early stopping and local optimization to find k and m values that maximize accuracy within bit budget constraints. Different ReLU layers can tolerate different amounts of bit reduction, and the search space can be pruned effectively using optimistic accuracy estimates. This breaks if the search space is too large or early stopping criteria are too aggressive.

## Foundational Learning

- **Secret sharing in multi-party computation**: Understanding how secret shares work is fundamental to grasping why bit reduction preserves correctness. Quick check: If two parties hold secret shares ⟨x⟩Q0 and ⟨x⟩Q1 such that ⟨x⟩Q0 + ⟨x⟩Q1 ≡ x (mod Q), can either party determine x from their share alone?

- **Goldreich-Micali-Wigderson (GMW) protocol for secure computation**: The optimizations are built on GMW protocol, specifically how DReLU is evaluated through arithmetic-to-binary conversion. Quick check: In GMW protocol, why does arithmetic-to-binary (A2B) conversion require O(N log N) communication when dealing with N-bit secret shares?

- **Circuit adder depth and communication complexity**: The performance improvement comes from reducing circuit adder depth by using fewer bits. Quick check: If a circuit adder for N-bit addition has depth O(log N), how does reducing to k bits change the depth to O(log k)?

## Architecture Onboarding

- **Component map**: Offline search engine -> MPC simulator -> Runtime library (CrypTen extension) -> Communication layer
- **Critical path**: User data → Secret share generation → Bit extraction (keep bits [k:m]) → DReLU evaluation on smaller ring → Bit packing for communication → Communication → Result reconstruction
- **Design tradeoffs**: Bit budget vs accuracy (tighter budgets reduce communication but may degrade accuracy); search time vs configuration quality (more thorough search finds better configurations but takes longer); bit packing efficiency vs implementation complexity (efficient packing reduces overhead but adds complexity)
- **Failure signatures**: Accuracy degradation (if discarded bits affect sign determination); performance regression (if bit packing overhead exceeds savings); search failure (if search cannot find valid configuration within time budget)
- **First 3 experiments**: 1) Baseline comparison: CrypTen (64-bit) vs HummingBird-eco (reduced bits, no accuracy loss) on ResNet18/CIFAR10; 2) Bit budget sensitivity: HummingBird-8/64 vs HummingBird-6/64 to measure accuracy vs performance tradeoff; 3) Search engine validation: Compare configurations found by search engine vs naive fixed-bit approach

## Open Questions the Paper Calls Out

- **Open Question 1**: How does accuracy degradation scale with different network bandwidths beyond the WAN setup tested (352 Mbps)? The paper only tests three specific network configurations without exploring extreme bandwidth limitations or satellite internet scenarios.

- **Open Question 2**: Can HummingBird's approximation techniques be extended to other non-linear operations like sigmoid or tanh in addition to ReLU? The theoretical analysis focuses on ReLU/DReLU but the approximation concept could potentially apply to other activation functions.

- **Open Question 3**: What is the optimal ring size (N) for different types of neural network architectures beyond CNNs (e.g., Transformers, RNNs)? The paper uses N=64 bits but notes intermediate activations are usually close to zero, suggesting potential for optimization.

- **Open Question 4**: How does HummingBird's performance scale with the number of parties in multi-server setups beyond the 2-party configuration? The framework is described as applicable to any number of parties p≥2, but all evaluations use only 2 parties.

## Limitations

- Empirical validation of theoretical claims is incomplete due to unspecified implementation details
- Search engine effectiveness lacks detailed empirical validation of efficiency
- Critical implementation details like MPC simulator, bit-packing optimization, and CrypTen integration are not fully specified

## Confidence

**High Confidence** in theoretical foundation - Mathematical proofs for safe bit discarding are sound and communication complexity analysis follows established MPC literature.

**Medium Confidence** in search engine effectiveness - Methodology is described but lacks detailed implementation specifics and empirical validation.

**Low Confidence** in practical implementation details - Critical aspects like MPC simulator, bit-packing implementation, and CrypTen integration are not fully specified.

## Next Checks

1. **Theoretical validation**: Implement bit extraction and DReLU evaluation on reduced ring as described in Theorems 1 and 2, then verify sign determination remains correct for various input distributions and secret share sizes.

2. **Search engine validation**: Implement search algorithm with ReLU grouping and early stopping, then compare its performance and configuration quality against baseline approaches using a validation dataset.

3. **Communication overhead validation**: Measure actual communication reduction and speedup on a LAN/WAN setup, comparing theoretical predictions with empirical measurements across different network conditions and model architectures.