---
ver: rpa2
title: Depth-bounded Epistemic Logic
arxiv_id: '2307.07448'
source_url: https://arxiv.org/abs/2307.07448
tags:
- depth
- agents
- agent
- knowledge
- announcement
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DBEL, an extension of S5 epistemic logic
  that models agents with bounded modal depth, addressing the limitation of existing
  logics that assume unbounded reasoning ability. The authors define a semantics where
  each agent has a depth in each state, requiring them to know formulas only up to
  their assigned depth, and introduce depth atoms to enable reasoning about agent
  depths.
---

# Depth-bounded Epistemic Logic

## Quick Facts
- arXiv ID: 2307.07448
- Source URL: https://arxiv.org/abs/2307.07448
- Reference count: 27
- Key outcome: Introduces DBEL, a depth-bounded extension of S5 epistemic logic that models agents with bounded reasoning depth, providing sound and complete axiomatizations and applications to the muddy children problem.

## Executive Summary
This paper introduces Depth-Bounded Epistemic Logic (DBEL), an extension of S5 epistemic logic that models agents with bounded reasoning depth. Unlike traditional epistemic logics that assume unbounded reasoning ability, DBEL assigns each agent a depth in each state, requiring them to know formulas only up to their assigned depth. The authors provide a sound and complete axiomatization for DBEL and extend it to support public announcements (DPAL). They prove several key properties including knowledge preservation and traditional announcement behavior, and demonstrate the practical utility by applying these logics to the muddy children problem.

## Method Summary
The authors develop DBEL by extending standard S5 epistemic logic with depth atoms and a depth assignment function that maps agents to states with natural numbers representing their reasoning depth. They define the semantics such that an agent knows a formula only if their depth is at least the modal depth of that formula. The public announcement extension (DPAL) creates state duplications and adjusts agent depths proportionally to announcement depth, preventing both amnesia and knowledge leakage. The paper provides axiomatizations for DBEL, DPAL, and two alternative logics with undesirable properties, proving soundness and completeness for each.

## Key Results
- DBEL provides a sound and complete axiomatization for reasoning about agents with bounded modal depth
- DPAL correctly implements public announcements while preserving knowledge and preventing information leakage
- The muddy children problem requires specific depth bounds for agents to solve it, with proven upper and lower bounds
- DBEL satisfiability is PSPACE-complete, while DPAL model checking is NP-hard with an EXPTIME upper bound

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DBEL enforces bounded reasoning by requiring agents to know a formula ψ only if their assigned depth is at least the modal depth of ψ.
- Mechanism: The semantics directly ties knowledge to depth, so that knowing deeper formulas requires more "reasoning budget". The operator Kaϕ is defined as Pd(ϕ)a ∧ K∞a ϕ, enforcing both depth and classical knowledge.
- Core assumption: Depth assignments in each state are fixed and can be compared to modal depth of formulas.
- Evidence anchors:
  - [abstract] states "the semantics assigns each agent a depth in each state, requiring them to know formulas only up to their assigned depth"
  - [section] Definition 2 defines the semantics as "(M, s)|= Kaϕ ⇐⇒ (M, s)|= Pd(ϕ)a ∧ K∞a ϕ"
- Break condition: If depth assignment does not reflect actual reasoning capability, or if depth varies unpredictably within a single agent's equivalence class, the mechanism fails.

### Mechanism 2
- Claim: Public announcements in DPAL consume an agent's depth budget proportionally to the depth of the announcement.
- Mechanism: The depth adjustment rule in Definition 3 reduces an agent's depth by d(ϕ) when they perceive an announcement ϕ, modeling limited reasoning resources.
- Core assumption: Each announcement has a measurable depth and agents can only reason as far as their remaining depth allows.
- Evidence anchors:
  - [abstract] says "an agent must 'consume' d(ϕ) of its depth every time an announcement ϕ is made"
  - [section] Definition 3 includes the rule "d′(a, (1, s)) = d(a, s) - d(ϕ) otherwise"
- Break condition: If announcements can have unbounded depth or agents have no depth constraints, the mechanism collapses to standard PAL.

### Mechanism 3
- Claim: DPAL prevents both amnesia and knowledge leakage through its state duplication and depth adjustment rules.
- Mechanism: States are duplicated into negative (announcement not perceived) and positive (announcement perceived) versions. Agents not deep enough to perceive the announcement see both versions as equivalent, preventing them from learning what deeper agents know.
- Core assumption: Agents cannot distinguish between negative and positive versions if their depth is insufficient, and depth reduction only happens in the positive version.
- Evidence anchors:
  - [abstract] mentions "agents who are not deep enough to perceive the announcement see the negative and positive version of the world as equivalent"
  - [section] Definition 3 shows "(1, s) Ra (0, s) ⇐⇒ (M, s)̸|= Pd(ϕ)a" and depth reduction only in the positive branch
- Break condition: If agents can somehow distinguish the versions despite insufficient depth, or if depth is incorrectly adjusted, the mechanism fails.

## Foundational Learning

- Concept: Modal depth and its role in complexity
  - Why needed here: DBEL's core innovation is tying knowledge to modal depth; understanding how modal depth measures formula complexity is essential.
  - Quick check question: What is the modal depth of the formula Ka(Kb p ∧ Kc q)?

- Concept: Public announcement logic (PAL) axioms and semantics
  - Why needed here: DPAL extends PAL, so understanding how [ϕ]Kaψ ↔ (ϕ → Ka[ϕ]ψ) works in PAL is prerequisite for grasping DPAL's generalizations.
  - Quick check question: In PAL, if ϕ is true in all states, what does [ϕ]Kaψ simplify to?

- Concept: Kripke semantics for multi-agent epistemic logic
  - Why needed here: DBEL and DPAL are built on S5 Kripke models; understanding equivalence relations and valuation functions is crucial for grasping the semantics.
  - Quick check question: In a Kripke model, if s ~a t and (M,s)|= p, what must be true about (M,t)|= p?

## Architecture Onboarding

- Component map:
  - DBEL core: depth assignment function d: A × S → N, depth atoms E d a and Pd a, knowledge operator Ka defined via depth and K∞a
  - DPAL extension: public announcement operator [ϕ]ψ with state duplication, depth adjustment, and relation updates
  - Axiomatization: sound and complete axiom sets for DBEL, DPAL, EDPAL, and ADPAL
  - Complexity analysis: PSPACE-complete for DBEL and EDPAL, EXPTIME for DPAL model checking

- Critical path:
  1. Parse formula and determine modal depth d(ψ) for each subformula
  2. For each agent a in each state s, check if d(a,s) ≥ d(ψ)
  3. For public announcements, create duplicated states and adjust depths/relations accordingly
  4. Apply axiomatization rules to verify or derive formulas

- Design tradeoffs:
  - Memory vs. expressiveness: DPAL's state duplication can exponentially increase model size but enables precise modeling of bounded reasoning
  - Simplicity vs. realism: DBEL's depth bounds are simple to implement but may not capture all aspects of bounded cognition
  - Generality vs. tractability: Adding depth atoms increases expressiveness but also complexity of model checking

- Failure signatures:
  - Incorrect depth assignments leading to agents knowing formulas beyond their capacity
  - Missing state duplication in DPAL causing amnesia or knowledge leakage
  - Depth adjustment errors where agents lose more depth than intended or gain depth they shouldn't have
  - Incomplete axiomatization leading to unprovable valid formulas

- First 3 experiments:
  1. Model a simple scenario with two agents of different depths and verify knowledge constraints using DBEL
  2. Implement a public announcement in DPAL and check that depth is correctly consumed and state duplication occurs
  3. Test the muddy children problem with varying depths to confirm the upper and lower bounds proven in the paper

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise computational complexity of model checking for DPAL on finite models?
- Basis in paper: [explicit] The paper states model checking for DPAL is NP-hard and provides an upper bound of EXPTIME, but does not establish a precise complexity class between these bounds.
- Why unresolved: The authors provide an EXPTIME upper bound but acknowledge this is not tight, leaving the exact complexity class unknown.
- What evidence would resolve it: A complete complexity classification showing whether DPAL model checking is NP-complete, PSPACE-complete, or falls in some other complexity class between NP and EXPTIME.

### Open Question 2
- Question: How can the depth-bounded epistemic logic framework be extended to handle other types of public announcements beyond the PAL-style announcements studied?
- Basis in paper: [inferred] The paper focuses on PAL-style announcements and mentions "more general announcements" in DEL as related work, suggesting room for extending DPAL to handle richer announcement types.
- Why unresolved: The paper only explores PAL-style announcements and does not investigate how other announcement types (private announcements, group announcements, etc.) might be incorporated into the depth-bounded framework.
- What evidence would resolve it: Formal definitions and axiomatizations of depth-bounded versions of other announcement logics, along with proofs of their properties and complexity results.

### Open Question 3
- Question: Can the depth-bounded framework be applied to other multi-agent reasoning problems beyond the muddy children puzzle?
- Basis in paper: [explicit] The paper concludes by suggesting the framework could be applied to "other multi-agent reasoning problems" but does not demonstrate this.
- Why unresolved: The paper only applies the framework to the muddy children problem, leaving open whether it can effectively model other epistemic reasoning scenarios with bounded depth agents.
- What evidence would resolve it: Successful applications of DPAL to other classical epistemic puzzles (e.g., sum-and-product, wise men, etc.) with formal proofs of solution bounds and complexity analyses.

## Limitations
- The practical implementation of state duplication in DPAL may lead to exponential model size growth in complex scenarios
- The relationship between depth bounds and realistic cognitive limitations in human-like agents is not empirically validated
- The framework focuses on theoretical properties without addressing dynamic environments where depth requirements might change unpredictably

## Confidence
- High Confidence: The theoretical soundness and completeness of DBEL and DPAL axiomatizations
- Medium Confidence: The complexity bounds (PSPACE-completeness for DBEL satisfiability, P-completeness for model checking)
- Medium Confidence: The application to the muddy children problem

## Next Checks
1. Implement a comparative model checking experiment between DBEL and standard epistemic logic on a non-trivial multi-agent scenario to measure the practical impact of depth bounds on reasoning complexity.
2. Create a dynamic environment where agent depths can change during execution and test whether DPAL's state duplication mechanism correctly handles depth transitions without information loss or leakage.
3. Design a formal verification of the depth satisfaction algorithm mentioned in the complexity proof, implementing it and testing against randomly generated DBEL formulas to confirm PSPACE complexity empirically.