---
ver: rpa2
title: Multiple Different Black Box Explanations for Image Classifiers
arxiv_id: '2309.14309'
source_url: https://arxiv.org/abs/2309.14309
tags:
- explanations
- image
- explanation
- input
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel algorithm, REX, for computing multiple
  explanations of image classifications produced by black-box neural networks. The
  core idea leverages causal theory to rank image pixels by their importance and then
  uses a floodlight search strategy to explore the image for diverse, spatially distinct
  explanations.
---

# Multiple Different Black Box Explanations for Image Classifiers

## Quick Facts
- arXiv ID: 2309.14309
- Source URL: https://arxiv.org/abs/2309.14309
- Authors: 
- Reference count: 10
- Key outcome: Novel algorithm REX computes multiple diverse explanations for image classifier outputs, outperforming state-of-the-art tools in both diversity and efficiency.

## Executive Summary
This paper introduces REX, a novel algorithm for computing multiple diverse explanations of image classifications produced by black-box neural networks. REX leverages causal theory to rank image pixels by importance and uses a floodlight search strategy to explore the image for diverse, spatially distinct explanations. The key innovation is REX's ability to produce significantly more diverse and numerous explanations compared to the existing state-of-the-art tool SAG, while also achieving a 17X speedup compared to DEEP COVER. The algorithm is modular, parallelized, and configurable, offering a principled approach to understanding and debugging image classifiers through multiple, diverse explanations.

## Method Summary
REX addresses the challenge of computing multiple diverse explanations for image classifier outputs by combining causal ranking with a floodlight search strategy. The algorithm first generates a saliency landscape by ranking pixels based on their causal responsibility for the classification. It then uses a floodlight search to explore the image from random starting positions, expanding and contracting the search area dynamically to find spatially distinct explanations. The explanations are further refined through a drain component that minimizes them via local ablation, and an extract component that filters and selects a subset of maximally different explanations based on overlap bounds. REX is designed as a modular, parallelized system that can be configured with different ranking and exploration strategies.

## Key Results
- REX found multiple explanations for 7 times more images than SAG on standard benchmarks
- REX terminated successfully on all images tested, whereas SAG timed out on nearly half of ImageNet-mini
- REX achieved a 17X speedup compared to DEEP COVER baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: REX finds more diverse explanations by exploring spatially distinct regions using a floodlight search over a saliency landscape
- Mechanism: Constructs a saliency landscape ranking pixels by causal importance, then uses floodlight search to explore for explanations from random positions, expanding and contracting dynamically
- Core assumption: Saliency landscape accurately ranks pixels by causal importance, and spatial diversity corresponds to human perception of different explanations
- Break condition: Inaccurate saliency ranking or poorly tuned floodlight parameters may miss important explanations or generate similar ones

### Mechanism 2
- Claim: REX achieves computational efficiency through parallelized, modular architecture
- Mechanism: Modular design allows swapping ranking procedures and configuring floodlight search parameters for efficient resource use
- Core assumption: Parallelization and modularity don't introduce significant overhead that negates performance gains
- Break condition: Excessive communication overhead or poor component integration may eliminate efficiency benefits

### Mechanism 3
- Claim: REX produces explanations aligned with human perception using superpixel-based approach
- Mechanism: Uses atomic superpixels (smallest distinguishable sets of contiguous pixels) and defines explanations as spatially distinct regions
- Core assumption: Human perception of different explanations correlates with spatial distinctness of superpixels
- Break condition: Poorly tuned superpixel size or mismatch between spatial distinctness and human perception may produce explanations not perceived as different

## Foundational Learning

- Concept: Causal responsibility and actual causality theory
  - Why needed here: Used to rank pixels by their importance in causing the classification, forming the basis for the saliency landscape
  - Quick check question: How does the degree of responsibility of a pixel relate to its importance in causing the classification outcome?

- Concept: NP-completeness and intractability in explanation generation
  - Why needed here: The paper proves computing multiple explanations is NP-complete, motivating approximation algorithms like REX
  - Quick check question: What is the complexity of finding a second explanation given the first one, and why is this important for understanding REX's limitations?

- Concept: Human perception of image differences and superpixels
  - Why needed here: Algorithm defines "different" explanations in terms of human perception using superpixels as basic units of distinction
  - Quick check question: Why is considering human perception important when defining "different" explanations, and how do superpixels help achieve this?

## Architecture Onboarding

- Component map: Ranking -> Floodlight Search -> Drain -> Extract
- Critical path: Ranking must complete first to provide saliency landscape, then floodlight search explores for explanations, which are minimized and filtered
- Design tradeoffs:
  - Fixed grid (SAG) vs. random grid (REX): Fixed grid is computationally simpler but may miss explanations; random grid is more intensive but finds more diverse explanations
  - Single vs. multiple iterations: Single iteration is faster but may produce less detailed landscapes; multiple iterations are slower but produce smoother, more accurate landscapes
- Failure signatures:
  - Low number of explanations: Poor ranking quality, inadequate floodlight parameters, or overly strict overlap bounds
  - Similar explanations: Insufficient floodlight diversity or poor overlap bound tuning
  - High computational time: Inefficient parallelization, poor parameter choices, or complex saliency landscapes
- First 3 experiments:
  1. Test REX with simple binary classifier and small dataset to verify multiple explanation finding
  2. Compare REX explanations with SAG on same dataset and model to quantify diversity improvement
  3. Vary iterations and floodlight parameters to find optimal configuration for given dataset and model

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does REX's performance change when using different pixel ranking mechanisms (e.g., SFL-based, LIME, SHAP)?
- Basis in paper: [explicit] Paper mentions any pixel ranking mechanism can be used and discusses causal responsibility-based ranking as an example
- Why unresolved: Only implements and tests REX with causal responsibility-based ranking
- What evidence would resolve it: Experiments comparing REX performance using various ranking mechanisms and analyzing impact on explanation quality and quantity

### Open Question 2
- Question: What is the effect of minimum superpixel size parameter on diversity and quality of explanations?
- Basis in paper: [explicit] Paper mentions REX allows minimum superpixel size as parameter and discusses this in Section 5
- Why unresolved: No experimental results on how varying minimum superpixel size affects explanations
- What evidence would resolve it: Experiments with different minimum superpixel sizes evaluating resulting explanations for diversity and quality

### Open Question 3
- Question: How does REX's performance scale with number of iterations and floodlights in terms of computational cost and explanation quality?
- Basis in paper: [explicit] Paper mentions iterative refinement and multiple floodlights but lacks detailed analysis of trade-off between computational cost and explanation quality
- Why unresolved: Paper doesn't explore relationship between iterations/floodlights and resulting explanations
- What evidence would resolve it: Experiments varying iterations and floodlights, measuring computational cost and evaluating explanation quality

### Open Question 4
- Question: Can REX be effectively applied to non-image classification tasks like text or tabular data classification?
- Basis in paper: [explicit] Paper focuses on image classification and doesn't discuss REX applicability to other data types
- Why unresolved: Paper doesn't explore or test REX on non-image classification tasks
- What evidence would resolve it: Adapting REX for non-image classification tasks and evaluating its performance and effectiveness in generating explanations

## Limitations
- Evaluation limited to specific model architectures and datasets, uncertain generalizability to other domains
- Claim about human perception alignment based on qualitative assessment rather than systematic human studies
- Exact implementation details and hardware configurations not specified, affecting comparison reproducibility

## Confidence
- **High confidence**: REX's modular and parallelized architecture allows configurable exploration strategies (verifiable from code implementation)
- **Medium confidence**: REX finds more diverse explanations than SAG (based on empirical results but uncertain generalizability)
- **Medium confidence**: REX achieves 17X speedup compared to DEEP COVER (based on reported timing but lacking implementation details)

## Next Checks
1. Evaluate REX on diverse image classification tasks (medical imaging, satellite imagery) to assess robustness and generalizability across domains
2. Conduct systematic user study to evaluate whether REX explanations are perceived as more diverse and meaningful by humans compared to other methods
3. Test REX scalability on larger datasets (full ImageNet) and complex model architectures (transformers) to assess computational efficiency under demanding conditions