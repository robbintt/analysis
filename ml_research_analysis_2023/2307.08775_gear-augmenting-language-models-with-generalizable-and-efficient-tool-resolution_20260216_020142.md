---
ver: rpa2
title: 'GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution'
arxiv_id: '2307.08775'
source_url: https://arxiv.org/abs/2307.08775
tags:
- tool
- tools
- gear
- grounding
- pattern
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "GEAR improves language model tool use by replacing LLM-based tool\
  \ grounding with a small LM, leveraging semantic and pattern-based scores for efficient,\
  \ generalizable tool selection. This reduces computational cost by 4\xD7 compared\
  \ to prior few-shot prompting methods while maintaining or improving downstream\
  \ task accuracy across 14 datasets and 6 tasks."
---

# GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution

## Quick Facts
- arXiv ID: 2307.08775
- Source URL: https://arxiv.org/abs/2307.08775
- Reference count: 14
- Key outcome: GEAR improves language model tool use by replacing LLM-based tool grounding with a small LM, leveraging semantic and pattern-based scores for efficient, generalizable tool selection. This reduces computational cost by 4× compared to prior few-shot prompting methods while maintaining or improving downstream task accuracy across 14 datasets and 6 tasks. It generalizes to novel tools and tasks without task-specific demonstrations, achieving high grounding accuracy even with small LMs.

## Executive Summary
GEAR addresses the challenge of grounding queries to appropriate tools in LLM-augmented systems. By replacing expensive LLM-based tool selection with a combination of semantic similarity scoring (using embeddings) and pattern-based scoring (comparing preliminary answer patterns to tool response patterns), GEAR achieves 4× computational efficiency while maintaining or improving accuracy across diverse tasks. The framework uses small language models for grounding and reserves LLM calls only for final API execution, enabling effective tool resolution even with limited computational resources.

## Method Summary
GEAR is a two-module framework that augments LLMs with external tools through efficient query-tool grounding. The first module uses semantic similarity (cosine distance between query embeddings and tool description embeddings via MPNet) and pattern similarity (cross-entropy between preliminary answer patterns and tool response patterns via GPT-Neo) to score and select the most appropriate tool. The second module uses an LLM (GPT-J or GPT-3) to generate the API call and execute the selected tool. GEAR operates without task-specific demonstrations, enabling generalization to novel tools and tasks while significantly reducing computational cost by delegating grounding to small language models.

## Key Results
- 4× computational efficiency improvement compared to few-shot prompting methods
- Maintains or improves downstream task accuracy across 14 datasets and 6 tasks
- Achieves high grounding accuracy even with small language models (GPT-Neo)
- Generalizes to novel tools and tasks without task-specific demonstrations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic similarity scores effectively match queries to tool descriptions by capturing semantic alignment.
- Mechanism: GEAR computes semantic similarity between the query and each tool's description using an SLM (MPNet), measuring alignment via cosine distance of their embeddings.
- Core assumption: Tool descriptions are sufficiently expressive to semantically align with queries requiring that tool.
- Evidence anchors:
  - [abstract]: "GEAR achieves better efficiency by delegating tool grounding and execution to small language models (SLM) and LLM, respectively; while leveraging semantic and pattern-based evaluation at both question and answer levels for generalizable tool grounding."
  - [section 3.1]: "Semantic similarity measures the alignment between the provided question to the language description of a tool."
- Break condition: If tool descriptions are ambiguous, underspecified, or fail to capture the semantic intent of queries, grounding accuracy will drop.

### Mechanism 2
- Claim: Pattern similarity scores capture answer-level alignment between preliminary LLM outputs and tool responses.
- Mechanism: GEAR generates a preliminary answer with an SLM, then compares its encoded pattern (e.g., number vs. text) to the actual tool response patterns, scoring alignment via cross-entropy.
- Core assumption: Tool responses exhibit consistent, distinguishable patterns that correlate with the query's needs, and preliminary answers from SLMs reliably reflect these patterns.
- Evidence anchors:
  - [abstract]: "while leveraging semantic and pattern-based evaluation at both question and answer levels for generalizable tool grounding."
  - [section 3.2]: "Pattern similarity provides an answer-level alignment score... computes an alignment between a preliminary guess and the response generated by each tool."
- Break condition: If tool responses are highly variable, lack distinctive patterns, or preliminary answers poorly reflect tool output patterns, pattern scores will be unreliable.

### Mechanism 3
- Claim: Using SLMs for grounding and LLMs only for execution reduces computational cost while maintaining accuracy.
- Mechanism: GEAR delegates all grounding computations (semantic and pattern scores) to SLMs (e.g., GPT-Neo), and reserves LLM calls (e.g., GPT-J or GPT-3) solely for final API execution, reducing total LLM calls from O(n) to 1.
- Core assumption: SLMs can effectively approximate LLM grounding performance when evaluating semantic and pattern alignment, especially when aided by a robust scoring formula.
- Evidence anchors:
  - [abstract]: "GEAR achieves better efficiency by delegating tool grounding and execution to small language models (SLM) and LLM, respectively."
  - [section 5.2]: "GEAR significantly reduces the workload on the LLM to do tool grounding, subtask decomposition and API call generation across all tools by assigning query-tool grounding to SLM."
- Break condition: If SLMs lack sufficient representational power or pattern recognition ability, grounding accuracy will degrade compared to LLM-only grounding.

## Foundational Learning

- Concept: Cosine similarity between embeddings as a semantic alignment metric.
  - Why needed here: Semantic similarity scores rely on embedding-based cosine distance to quantify how closely a query aligns with tool descriptions.
  - Quick check question: What happens to the cosine similarity score if two embeddings are orthogonal (perpendicular)?

- Concept: Pattern encoding and cross-entropy scoring for alignment.
  - Why needed here: Pattern similarity scores use regex-based pattern encoding of tool responses and preliminary answers, then compute cross-entropy to measure alignment.
  - Quick check question: If a tool's response and preliminary answer share no patterns, what is the pattern similarity score?

- Concept: Small language models (SLMs) as efficient semantic and pattern evaluators.
  - Why needed here: SLMs (e.g., GPT-Neo) are used to generate preliminary answers and compute both semantic and pattern similarity scores, reducing reliance on expensive LLM calls.
  - Quick check question: Why might an SLM be sufficient for grounding tasks even if it's less capable than an LLM at final reasoning?

## Architecture Onboarding

- Component map: Input Query → SLM (preliminary answer generation) → SLM (semantic and pattern scoring) → Tool Selection → LLM (API call generation) → Tool Execution → Final Answer
- Critical path: Generate preliminary answer with SLM → For each tool: compute semantic similarity (query vs. tool description) and pattern similarity (preliminary answer vs. tool response) → Select tool with highest combined score → Generate API call with LLM and execute tool
- Design tradeoffs: SLM vs. LLM for grounding: SLMs reduce cost but may sacrifice some accuracy; however, pattern similarity scores help mitigate this. Pattern set size and priors: Must be general enough for diverse tools but specific enough to distinguish them; requires careful tuning.
- Failure signatures: Low grounding accuracy despite correct tool descriptions: likely pattern encoding or SLM generation issues. High cost despite SLM use: possibly inefficient SLM calls or excessive tool library size. Wrong tool selected: possible semantic or pattern score miscalibration.
- First 3 experiments: 1) Verify semantic similarity scores align with manual query-tool matches on a small tool set. 2) Test pattern similarity scoring by comparing SLM-generated preliminary answers to known tool responses. 3) Measure grounding accuracy on a held-out dataset with increasing tool library sizes to assess scalability.

## Open Questions the Paper Calls Out

The paper doesn't explicitly call out open questions, but based on the content, several key uncertainties remain regarding scalability, robustness to poor-quality tool descriptions, and performance with multimodal tool outputs.

## Limitations

- Tool description quality dependency: GEAR's performance critically depends on the expressiveness and clarity of tool descriptions, which the paper doesn't thoroughly investigate under poor-quality conditions.
- Pattern set generalization: Limited validation that the pattern set works well for novel tools, especially those with variable or complex response patterns.
- SLM reliability: Performance degradation with smaller or simpler SLMs is not systematically explored.

## Confidence

- High Confidence: Computational efficiency improvements (4× reduction)
- Medium Confidence: Generalization to novel tools and tasks
- Medium Confidence: Semantic and pattern similarity effectiveness

## Next Checks

1. **Description Quality Stress Test**: Systematically degrade tool descriptions (make them ambiguous, underspecified, or overly technical) and measure grounding accuracy degradation to reveal true sensitivity to description quality.

2. **Pattern Set Robustness Evaluation**: Create a benchmark of tools with deliberately variable response patterns and test whether GEAR's pattern similarity scoring still functions reliably, addressing the assumption of consistent tool response patterns.

3. **SFT-3 Performance Floor Analysis**: Evaluate GEAR with progressively smaller and simpler SLMs to identify the minimum viable model size for maintaining acceptable grounding accuracy, quantifying the trade-off between efficiency gains and accuracy loss.