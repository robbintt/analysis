---
ver: rpa2
title: Composing Task Knowledge with Modular Successor Feature Approximators
arxiv_id: '2301.12305'
source_url: https://arxiv.org/abs/2301.12305
tags:
- learning
- msfa
- tasks
- generalization
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Modular Successor Feature Approximators (MSFA),
  a neural network architecture that learns modular functions for computing state
  features and successor features to enable zero-shot transfer with Successor Features
  and Generalized Policy Improvement (SF&GPI). The key insight is that using an inductive
  bias for modularity enables reward-driven discovery of state features useful for
  zero-shot transfer, without requiring hand-designed features.
---

# Composing Task Knowledge with Modular Successor Feature Approximators

## Quick Facts
- arXiv ID: 2301.12305
- Source URL: https://arxiv.org/abs/2301.12305
- Reference count: 32
- Modular Successor Feature Approximators (MSFA) achieve zero-shot transfer to novel tasks without hand-designed features

## Executive Summary
This paper introduces Modular Successor Feature Approximators (MSFA), a neural network architecture that learns modular functions for computing state features and successor features to enable zero-shot transfer with Successor Features and Generalized Policy Improvement (SF&GPI). The key insight is that using an inductive bias for modularity enables reward-driven discovery of state features useful for zero-shot transfer, without requiring hand-designed features. MSFA is shown to match or exceed the transfer performance of prior methods that used hand-designed features, across three challenging domains requiring generalization to novel environment configurations and task combinations.

## Method Summary
MSFA combines successor features with a modular neural network architecture. The agent maintains n state modules, each with its own recurrent function for updating module state, cumulant computation, and successor feature estimation. Modules share information through an attention mechanism with gating to enforce sparse inter-module interactions. The architecture outputs concatenated modular cumulants and successor features. During training, modules are updated using an attention mechanism that allows sparse information sharing, with each module learning cumulants and successor features that specialize in different aspects of the environment. During testing, policies are computed using GPI by combining the learned successor features with novel task vectors.

## Key Results
- MSFA achieves strong zero-shot transfer to novel environment configurations and task combinations without requiring hand-designed features
- MSFA matches or exceeds transfer performance of prior methods using hand-designed features across BabyAI, Procgen, and Minihack domains
- Ablations show that learning modular functions for both state features and successor features is critical for strong transfer performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modular architecture enables reward-driven discovery of state features useful for zero-shot transfer
- Mechanism: By decomposing the value function into modular components, each module learns cumulants that respond to different aspects of the environment. The reward-driven learning signal encourages modules to specialize in predicting aspects of the environment that are correlated with reward, naturally discovering useful features without hand-design.
- Core assumption: Modules can specialize in different environmental aspects when given sparse inter-module information flow and a reward signal that guides learning
- Evidence anchors:
  - [abstract] "the key insight is that using an inductive bias for modularity enables reward-driven discovery of state features useful for zero-shot transfer"
  - [section 4.2] "Module cumulants depend on the module-state from the current and next time-step... Module SFs depend on the current module-state and on their subset of the task description"
  - [corpus] Moderate correlation with related papers (avg FMR 0.51), suggesting this is a novel contribution building on successor features literature

### Mechanism 2
- Claim: Modular successor features improve generalization to novel environment configurations
- Mechanism: The modular architecture allows each module to maintain its own state representation that evolves independently, with limited information sharing through attention. This prevents catastrophic interference when environments change, as modules can adapt to new configurations while maintaining learned representations for familiar aspects.
- Core assumption: Independent module evolution with sparse inter-module information flow prevents catastrophic interference when generalizing to novel environments
- Evidence anchors:
  - [section 4.2] "they update at each time-step with the observation xt, the previous module-states, and information from other modules Aθ(s(k)t−1, St−1)"
  - [section 5] "Generalizing to novel object appearances and layouts tests how well MSFA's modular construction supports generalization to novel environment configurations"
  - [corpus] Limited direct evidence in corpus, but moderate FMR suggests novelty in this application of modularity

### Mechanism 3
- Claim: GPI leverages modular successor features for zero-shot transfer to novel task combinations
- Mechanism: By computing Q-values as the dot product between modular successor features and task vectors, GPI can combine learned policies without additional training. The modular structure ensures that each component of the task vector has a corresponding set of features to combine, enabling principled transfer.
- Core assumption: The task vector can be decomposed into components that correspond to the modular structure, allowing each module to contribute appropriately to the combined policy
- Evidence anchors:
  - [section 3] "Qπ,w(st, at) = Eπ[∑∞t=0 γtrwt]" and the subsequent derivation showing how successor features enable task decomposition
  - [section 4.3] "During testing, we compute policies with GPI as π(st, wtest)∈ arg maxa maxz∈Mtrain{ψθ(st, a, z)⊤wtest}"
  - [corpus] Strong correlation with "Combining Behaviors with the Successor Features Keyboard" paper, suggesting this mechanism is well-established in the literature

## Foundational Learning

- Concept: Successor Features and Generalized Policy Improvement
  - Why needed here: MSFA builds directly on SF&GPI framework, using successor features to enable transfer and GPI to combine policies
  - Quick check question: How does GPI guarantee that the combined policy performs at least as well as individual training policies?

- Concept: Modular Reinforcement Learning
  - Why needed here: The paper integrates modular architectures with successor features, requiring understanding of how modules can learn value functions independently
  - Quick check question: What is the key difference between learning modular Q-values versus modular successor features?

- Concept: Attention Mechanisms in Recurrent Networks
  - Why needed here: MSFA uses transformer-style attention with gating to enable sparse inter-module information flow
  - Quick check question: How does the gating mechanism in MSFA's attention prevent information overload between modules?

## Architecture Onboarding

- Component map: State → Module updates (with attention) → Cumulant computation → Successor feature estimation → Q-value computation (for GPI)
- Critical path: State → Module updates (with attention) → Cumulant computation → Successor feature estimation → Q-value computation (for GPI)
- Design tradeoffs: Modularity vs. parameter efficiency (more modules = more parameters), attention mechanism complexity vs. specialization benefits, disentangled vs. entangled function representations
- Failure signatures: Poor generalization to novel tasks suggests modules aren't specializing properly; high reward prediction error on test tasks indicates cumulants aren't learning useful features; training instability may indicate improper loss masking
- First 3 experiments:
  1. Implement basic MSFA with 2 modules on BabyAI environment, verify cumulant specialization through visualization
  2. Test ablations: monolithic vs. modular cumulants and successor features, measure impact on generalization
  3. Implement GPI with learned modular successor features, compare to USFA with hand-designed cumulants on novel task combinations

## Open Questions the Paper Calls Out

- How to extend MSFA to more expressive task encodings, such as language embeddings
- How to scale MSFA to domains with larger numbers of tasks and more complex task structures

## Limitations

- Missing specific architectural details for attention mechanism and gating components
- Limited ablation studies examining attention mechanism design choices
- No comparison against more recent modular RL architectures

## Confidence

- High confidence in the general framework combining SF&GPI with modularity
- Medium confidence in the specific implementation details due to missing architectural specifications
- Medium confidence in transfer performance claims, though results are compelling across multiple domains

## Next Checks

1. Implement ablations testing different attention mechanisms (full vs. sparse attention) to verify the importance of sparse inter-module information flow
2. Add baselines using modern modular architectures (e.g., Transformer-based RL agents) to establish stronger comparison points
3. Conduct systematic hyperparameter sensitivity analysis for module count and attention gating strength to understand their impact on specialization and transfer performance