---
ver: rpa2
title: 'The Feature Speed Formula: a flexible approach to scale hyper-parameters of
  deep neural networks'
arxiv_id: '2311.18718'
source_url: https://arxiv.org/abs/2311.18718
tags:
- feature
- learning
- alignment
- backward
- pass
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the notion of alignment between feature updates
  and the backward pass in deep neural networks, showing it is crucial for feature
  learning. The authors derive a simple formula relating the magnitude of aligned
  feature updates to the forward and backward pass magnitudes, enabling automatic
  tuning of initialization scales and learning rates.
---

# The Feature Speed Formula: a flexible approach to scale hyper-parameters of deep neural networks

## Quick Facts
- arXiv ID: 2311.18718
- Source URL: https://arxiv.org/abs/2311.18718
- Authors: 
- Reference count: 32
- Key outcome: Introduces alignment between feature updates and backward pass, enabling automatic tuning of initialization scales and learning rates in deep neural networks.

## Executive Summary
This paper presents a new framework for understanding and controlling feature learning in deep neural networks by analyzing the alignment between feature updates and the backward pass. The authors derive a simple formula relating the magnitude of aligned feature updates to forward and backward pass magnitudes, enabling automatic hyperparameter tuning. Through theoretical analysis of MLPs and ResNets in the large width-then-depth limit, they show that alignment degenerates with depth in MLPs but can be maintained in ResNets with appropriate scaling. This work provides both theoretical insights and practical techniques for improving feature learning in deep networks.

## Method Summary
The paper analyzes deep neural networks by decomposing them into one-dimensional subspaces and studying the alignment between feature updates and the backward pass. The method involves computing the angle θ_ℓ between feature updates and backward pass at each layer, which is controlled by the conditioning of layer-to-layer Jacobians. At initialization, this angle is determined by the spectrum of a kernel related to the Neural Tangent Kernel. The authors derive the Backward Aligned Feature Update (BAFU) formula and propose FSC-A criteria (Forward, Sensitivities, Contributions, Alignment) that can be enforced through techniques like forward/backward layer normalization and adaptive learning rates to ensure stable feature learning.

## Key Results
- Alignment between feature updates and backward pass can be quantified by angle θ_ℓ and controlled through proper initialization and learning rates
- The feature speed formula relates aligned feature update magnitudes to forward and backward pass magnitudes
- In ReLU MLPs, alignment degenerates with depth at rate Θ(1/√L), while ResNets can maintain alignment with β = Θ(1/√L) branch scaling
- FSC-A criteria provide a framework for automatic hyperparameter tuning to achieve desired feature learning behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The alignment between feature updates and the backward pass can be quantified by the angle θ_ℓ, which determines the magnitude of aligned feature updates via the feature speed formula.
- Mechanism: When feature updates and backward pass are aligned, the magnitude of feature updates after one gradient descent step is related to the magnitudes of the forward and backward passes by a simple formula. This allows automatic tuning of initialization scales and learning rates to achieve desired feature learning behavior.
- Core assumption: The angle θ_ℓ is controlled by the conditioning of the layer-to-layer Jacobians and at random initialization, it is determined by the spectrum of a kernel related to the Neural Tangent Kernel.
- Evidence anchors:
  - [abstract]: "We introduce a key notion to predict and control feature learning: the angle θ_ℓ between the feature updates and the backward pass (at layer index ℓ)."
  - [section]: "We show that when alignment holds, the magnitude of feature updates after one SGD step is related to the magnitude of the forward and backward passes by a simple and general formula."
  - [corpus]: Weak - no direct evidence in corpus neighbors, but related to concepts in "Better NTK Conditioning: A Free Lunch from (ReLU) Nonlinear Activation in Wide Neural Networks"
- Break condition: If the layer-to-layer Jacobians become ill-conditioned or the spectrum of the kernel becomes degenerate, the alignment breaks down.

### Mechanism 2
- Claim: The Backward Aligned Feature Update (BAFU) formula provides a way to measure and control feature learning with negligible computational cost.
- Mechanism: The projections of feature updates in one SGD step on the backward pass can be expressed purely in terms of the magnitudes of the forward and backward passes. This allows feature learning to be measured and controlled at any time during training.
- Core assumption: The backward-aligned feature updates are related to the contributions and sensitivities of the weight matrices and features.
- Evidence anchors:
  - [abstract]: "On the one hand, we show that when alignment holds, the magnitude of feature updates after one SGD step is related to the magnitude of the forward and backward passes by a simple and general formula."
  - [section]: "This angle θ_ℓ is controlled by the conditioning of the layer-to-layer Jacobians and at random initialization, it is determined by the spectrum of a certain kernel, which coincides with the Neural Tangent Kernel when ℓ=depth."
  - [corpus]: Weak - no direct evidence in corpus neighbors, but related to concepts in "Near-Linear Time Projection onto the $\\ell_{1,\\infty}$ Ball; Application to Sparse Autoencoders"
- Break condition: If the backward pass becomes orthogonal to the feature updates, the BAFU formula breaks down.

### Mechanism 3
- Claim: The FSC-A criteria provide a way to automatically adjust hyperparameters to satisfy natural desiderata for feature learning.
- Mechanism: The FSC-A criteria (Forward, Sensitivities, Contributions, Alignment) can be enforced by techniques such as forward and backward layer normalization and adaptive learning rates. This allows the hyperparameters to be tuned to achieve stable feature learning and alignment.
- Core assumption: The FSC-A criteria imply the natural desiderata for feature learning, including non-explosion of the forward pass, feature learning, stability, and backward alignment of feature updates.
- Evidence anchors:
  - [abstract]: "This leads to techniques to automatically adjust HPs (initialization scales and learning rates) to attain a desired feature learning behavior."
  - [section]: "We now recast these desiderata into convenient criteria... In a ReLU MLP the following four criteria... imply desiderata (D1-4)."
  - [corpus]: Weak - no direct evidence in corpus neighbors, but related to concepts in "Invariant Risk Minimization Is A Total Variation Model"
- Break condition: If the activation function is not positively homogeneous, the FSC-A criteria may not be sufficient to ensure the desired feature learning behavior.

## Foundational Learning

- Concept: Neural Tangent Kernel (NTK)
  - Why needed here: The NTK is used to determine the alignment between feature updates and the backward pass at random initialization.
  - Quick check question: What is the relationship between the spectrum of the NTK and the alignment angle θ_ℓ?

- Concept: Dynamical isometry
  - Why needed here: Dynamical isometry, the concentration of the singular spectrum of the layer-to-layer Jacobians around 1, guarantees alignment between feature updates and the backward pass.
  - Quick check question: How does the conditioning of the layer-to-layer Jacobians affect the alignment angle θ_ℓ?

- Concept: ReLU activation function
  - Why needed here: The ReLU activation function is assumed in the analysis, and its properties are used to derive the BAFU formula and the FSC-A criteria.
  - Quick check question: How does the ReLU activation function affect the scale covariance or invariance of the neural network?

## Architecture Onboarding

- Component map: Input -> Hidden layers (with ReLU activation) -> Output layer
- Critical path: Input -> Hidden layers -> Output -> Loss computation -> Backward pass -> Weight updates
- Design tradeoffs:
  - Depth vs. width: Deeper networks can learn more complex features but may suffer from vanishing or exploding gradients
  - Initialization scales: Proper initialization scales can ensure dynamical isometry and alignment
  - Learning rates: Adaptive learning rates can enforce the FSC-A criteria and ensure stable feature learning
- Failure signatures:
  - Degenerate alignment: The angle θ_ℓ approaches π/2, indicating that feature updates are orthogonal to the backward pass
  - Ill-conditioned Jacobians: The singular spectrum of the layer-to-layer Jacobians becomes spread out, indicating a lack of dynamical isometry
  - Non-converging loss: The loss fails to decrease during training, indicating that the hyperparameters are not properly tuned
- First 3 experiments:
  1. Verify the BAFU formula: Compute the magnitudes of the forward and backward passes and the aligned feature updates for a small MLP on a simple dataset, and verify that they satisfy the BAFU formula.
  2. Test the FSC-A criteria: Implement the FSC-control technique and verify that it enforces the FSC-A criteria on a small MLP, leading to stable feature learning and alignment.
  3. Study the effect of depth: Train MLPs of varying depths on a simple dataset and study how the alignment angle θ_ℓ and the performance vary with depth.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact rate at which alignment degenerates in ReLU MLPs with depth?
- Basis in paper: [explicit] The paper states that "cos( \bL−1, δfL−1) = Θ(1/√L)" in ReLU MLPs, but it is unclear if this is the precise rate for all layers or just the output layer.
- Why unresolved: The paper only provides a lower bound on alignment using the BFK spectrum, which is not tight enough to determine the exact rate of alignment degeneration with depth.
- What evidence would resolve it: A more refined analysis of the BFK spectrum or numerical experiments showing the alignment angle as a function of depth for all layers would resolve this question.

### Open Question 2
- Question: Can the FSC criteria be all satisfied at initialization in ResNets with arbitrary branch scale β?
- Basis in paper: [explicit] The paper shows that alignment holds uniformly in depth for ResNets with β = Θ(1/√L), but it is unclear if the FSC criteria can be satisfied for other values of β.
- Why unresolved: The paper only considers the case of β = 1/√L, and it is not clear if the FSC criteria can be satisfied for other branch scales.
- What evidence would resolve it: Numerical experiments or theoretical analysis showing the behavior of the FSC criteria as a function of β would resolve this question.

### Open Question 3
- Question: What is the effect of scale covariance or invariance on the number of effective degrees of freedom in deep networks?
- Basis in paper: [inferred] The paper shows that in scale covariant networks, the relative sensitivities Srel_v and contributions Cℓ are related by Srel_v ∝ (αβP)^-1 and Cℓ ∝ (αβP)^2 · ηℓ / σℓ^2, where P is the product of scales. This suggests that there is only one degree of freedom, the product of scales P, to adjust sensitivities.
- Why unresolved: The paper only provides a partial analysis of the effect of scale covariance on the FSC criteria, and it is not clear if this result extends to other aspects of deep learning, such as feature learning or generalization.
- What evidence would resolve it: A more comprehensive analysis of the effect of scale covariance on deep learning, including feature learning and generalization, would resolve this question.

## Limitations
- The analysis relies heavily on large-width-then-depth limits and ReLU assumptions, which may not hold for practical networks
- The alignment framework requires careful hyperparameter tuning that may not generalize across diverse architectures
- The theoretical results are primarily validated on synthetic data and simple architectures

## Confidence
- High confidence: Basic alignment formula and its theoretical derivation
- Medium confidence: Claims about FSC-A criteria controlling alignment
- Low confidence: Empirical validation across diverse architectures

## Next Checks
1. Verify alignment dynamics in finite-width networks beyond the theoretical limit
2. Test the framework with different activation functions (GELU, Leaky ReLU, etc.)
3. Evaluate the approach on practical architectures like transformers and vision models with batch normalization