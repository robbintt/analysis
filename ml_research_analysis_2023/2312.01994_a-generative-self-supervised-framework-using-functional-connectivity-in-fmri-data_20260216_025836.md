---
ver: rpa2
title: A Generative Self-Supervised Framework using Functional Connectivity in fMRI
  Data
arxiv_id: '2312.01994'
source_url: https://arxiv.org/abs/2312.01994
tags:
- graph
- data
- node
- graphs
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ST-MAE, a generative self-supervised learning
  framework for dynamic functional connectivity graphs derived from fMRI data. Unlike
  contrastive methods that perturb graph structure, ST-MAE uses a masked autoencoding
  approach that preserves spatial and temporal information.
---

# A Generative Self-Supervised Framework using Functional Connectivity in fMRI Data

## Quick Facts
- arXiv ID: 2312.01994
- Source URL: https://arxiv.org/abs/2312.01994
- Reference count: 35
- Primary result: State-of-the-art gender classification AUROC up to 77.89% using generative self-supervised learning on fMRI data

## Executive Summary
This paper introduces ST-MAE, a generative self-supervised learning framework for dynamic functional connectivity graphs derived from fMRI data. Unlike contrastive methods that perturb graph structure, ST-MAE employs masked autoencoding to reconstruct both node features and adjacency matrices while preserving spatial and temporal information. The framework achieves state-of-the-art performance on six downstream datasets for gender classification, age regression, and psychiatric disorder classification, demonstrating the effectiveness of generative SSL in capturing meaningful fMRI representations.

## Method Summary
ST-MAE is a generative self-supervised learning framework for dynamic functional connectivity graphs. It uses a masked autoencoding approach where node features and adjacency matrices are randomly masked at each time step, and the model learns to reconstruct both. The model incorporates both spatial and temporal reconstruction: spatial reconstruction recovers masked features and adjacency matrices at each time point, while temporal reconstruction infers intermediate time steps using representations from nearby time points. Pre-trained on large-scale UK Biobank data (>50,000 samples), the model is then fine-tuned on downstream tasks including gender classification, age regression, and psychiatric disorder classification.

## Key Results
- Gender classification achieves AUROC up to 77.89% on downstream datasets
- Age regression achieves MAE as low as 1.86 when fine-tuned from pre-trained model
- Psychiatric disorder classification achieves AUROC up to 69.03% with limited labeled data
- Outperforms contrastive methods like ST-DGI across all benchmark tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ST-MAE captures temporal dependencies by reconstructing intermediate time steps using representations from nearby time points.
- Mechanism: The model encodes node features at two surrounding timestamps (ta, tb) and decodes them to reconstruct the masked node features at an intermediate timestamp (tm). This forces the encoder to learn meaningful temporal transitions.
- Core assumption: Nearby time points contain sufficient information to infer intermediate states, and the temporal dynamics are smooth enough to allow reconstruction.
- Evidence anchors:
  - [abstract]: "reconstructing intermediate time steps from nearby time points"
  - [section]: "encode representations from different time points to perform temporal reconstruction"
- Break condition: If temporal dynamics are highly non-linear or discontinuous, reconstruction from nearby points may fail.

### Mechanism 2
- Claim: Masked autoencoding on dynamic graphs preserves spatial connectivity patterns while learning node representations.
- Mechanism: Random masking of node features and adjacency matrices is applied at each time step, and the model learns to reconstruct both, forcing it to encode spatial structure without losing temporal context.
- Core assumption: The graph structure is informative and masking does not destroy the essential spatial patterns needed for reconstruction.
- Evidence anchors:
  - [abstract]: "reconstructing masked features and adjacency matrices"
  - [section]: "masked autoencoding objective to train an encoder for spatio-temporal graphs"
- Break condition: If too much masking is applied, the spatial structure becomes unrecoverable and learning degrades.

### Mechanism 3
- Claim: Pre-training on large-scale UK Biobank data provides robust representations that transfer well to small labeled datasets in downstream tasks.
- Mechanism: Generative SSL learns general fMRI graph features without requiring phenotype labels, which are expensive to obtain. These features are then fine-tuned on smaller labeled datasets.
- Core assumption: Large unlabeled datasets contain sufficient variability to learn generalizable representations.
- Evidence anchors:
  - [abstract]: "large-scale (>50,000) UKB data" and "learns valuable representations"
  - [section]: "pre-train our model on a large-scale UKB dataset... demonstrate the capability of SSL in capturing meaningful fMRI representations"
- Break condition: If downstream tasks are too different from the pre-training distribution, transfer may fail.

## Foundational Learning

- Concept: Dynamic graph representation learning
  - Why needed here: fMRI data naturally forms dynamic functional connectivity graphs; static methods miss temporal evolution.
  - Quick check question: What is the difference between a static graph and a dynamic graph in this context?

- Concept: Masked autoencoding
  - Why needed here: It allows the model to learn meaningful representations without requiring labels by reconstructing missing information.
  - Quick check question: How does masking help in learning useful node or edge features?

- Concept: Functional connectivity construction from fMRI
  - Why needed here: Understanding how BOLD time series are converted into adjacency matrices is key to implementing the method.
  - Quick check question: How is the adjacency matrix A(t) computed from the ROI-time series matrix P?

## Architecture Onboarding

- Component map: GNN encoder -> Spatial reconstruction decoder + Temporal reconstruction decoder
- Critical path: Input dynamic graph -> Masked encoder -> Z(t) -> Spatial decoder -> ˆX(t), ˆA(t) AND Temporal decoder -> ˆX_a,b(t), ˆA_a,b(t)
- Design tradeoffs: Masking ratio vs reconstruction quality; pre-training data size vs fine-tuning performance; choice of reconstruction loss (SCE vs BCE vs MSE).
- Failure signatures: Poor reconstruction loss indicates masking too aggressive or encoder capacity insufficient; poor downstream performance suggests poor transfer or mismatch in graph structure.
- First 3 experiments:
  1. Train ST-MAE with only spatial reconstruction (no temporal) and evaluate on gender classification.
  2. Vary the masking ratio (e.g., 10%, 30%, 50%) and measure effect on downstream task accuracy.
  3. Compare different reconstruction criteria (MSE vs SCE for nodes, MSE vs BCE for edges) on ABIDE dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does ST-MAE's performance scale with dataset size compared to contrastive methods like ST-DGI?
- Basis in paper: [explicit] The paper states "we confirmed our intuition that performance increases as the amount of data used for SSL increases" and shows ST-MAE outperforms ST-DGI on gender classification with varying data sizes.
- Why unresolved: While the paper demonstrates ST-MAE's effectiveness with large-scale UKB data (>50,000 samples), it doesn't provide a systematic comparison of how different SSL methods scale with dataset size, particularly for smaller datasets.
- What evidence would resolve it: Comparative experiments showing performance curves of ST-MAE and ST-DGI across datasets of varying sizes, with statistical significance testing.

### Open Question 2
- Question: What is the optimal masking ratio for ST-MAE in different fMRI tasks and why does performance vary with masking ratio?
- Basis in paper: [explicit] The paper states "Since performance can vary depending on the masking ratio, it is important to specify the appropriate masking ratio according to the task" and shows performance variation with masking ratio in Figure 4.
- Why unresolved: The paper doesn't provide a theoretical explanation for why certain masking ratios work better than others, nor does it offer a systematic method for selecting optimal masking ratios across different tasks.
- What evidence would resolve it: A comprehensive study linking masking ratios to task characteristics, plus a principled method for selecting optimal masking ratios based on graph properties or task requirements.

### Open Question 3
- Question: How do different reconstruction loss combinations affect ST-MAE's performance on various downstream tasks?
- Basis in paper: [explicit] The paper compares MSE and BCE losses for node and edge reconstruction, finding SCE+BCE to be optimal, but only reports results for two datasets (ABIDE and ADHD200).
- Why unresolved: The study is limited to two psychiatric datasets and doesn't explore whether these reconstruction criteria generalize across different types of downstream tasks or whether task-specific loss combinations might yield better results.
- What evidence would resolve it: Systematic ablation studies across diverse task types (classification, regression, clinical diagnosis) using various loss combinations to identify task-specific optimal reconstruction strategies.

## Limitations
- Masking ratio sensitivity requires task-specific tuning, but optimal values are not specified in main experiments
- Performance depends on large-scale pre-training data, limiting applicability to smaller datasets
- Temporal reconstruction assumes smooth transitions, which may not capture all fMRI dynamics

## Confidence
- ST-MAE achieves state-of-the-art performance on gender classification, age regression, and psychiatric disorder classification: **High**
- Generative SSL approach outperforms contrastive methods in fMRI representation learning: **Medium**
- Temporal reconstruction mechanism effectively captures temporal dependencies: **Medium**

## Next Checks
1. Conduct ablation study comparing ST-MAE performance with varying masking ratios (10%, 30%, 50%) on UK Biobank pre-training to identify optimal configuration
2. Test model transfer across different brain parcellation schemes (e.g., 200 vs 400 regions) to assess robustness to anatomical granularity
3. Evaluate performance degradation when temporal smoothness assumption is violated by introducing artificial temporal discontinuities in the training data