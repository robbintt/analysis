---
ver: rpa2
title: Learning to Compose Representations of Different Encoder Layers towards Improving
  Compositional Generalization
arxiv_id: '2305.12169'
source_url: https://arxiv.org/abs/2305.12169
tags:
- encoder
- transformer
- information
- different
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of compositional generalization
  (CG) in sequence-to-sequence models, where models struggle to generalize to unseen
  compositions of seen components. The authors hypothesize that the source keys and
  values representations passing into different decoder layers are entangled, in addition
  to the previously identified encoder uppermost layer entanglement.
---

# Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization

## Quick Facts
- **arXiv ID**: 2305.12169
- **Source URL**: https://arxiv.org/abs/2305.12169
- **Reference count**: 39
- **Primary result**: COMPO SITION achieves state-of-the-art results on CoGnition machine translation benchmark and outperforms other techniques on CFQ semantic parsing benchmark for compositional generalization

## Executive Summary
This paper addresses the problem of compositional generalization (CG) in sequence-to-sequence models, where models struggle to generalize to unseen compositions of seen components. The authors hypothesize that the source keys and values representations passing into different decoder layers are entangled, in addition to the previously identified encoder uppermost layer entanglement. To address this, they propose COMPO SITION, an extension to seq2seq models that introduces a composed layer between the encoder and decoder. This layer dynamically composes representations of different encoder layers to generate specific keys and values passing into different decoder layers. Experiments on two benchmarks, CoGnition (machine translation) and CFQ (semantic parsing), demonstrate the effectiveness of COMPO SITION, achieving significant improvements in instance-level and aggregate-level error reduction rates. Notably, COMPO SITION achieves state-of-the-art results on CoGnition and outperforms other techniques on CFQ, highlighting its potential for improving compositional generalization in various seq2seq tasks.

## Method Summary
The COMPO SITION method introduces a composed layer between the encoder and decoder in standard Transformer architectures. This layer contains 2N learnable vectors (where N is the number of decoder layers) that dynamically weight the representations from all M encoder layers to generate specific keys and values for each decoder layer. During the forward pass, each encoder layer's output is weighted by the corresponding composed vector components, then summed to create the final key/value representations for each decoder layer's attention mechanism. The model is trained with standard cross-entropy loss, and the composed layer weights are learned end-to-end. This approach is designed to address the entanglement problem where different decoder layers receive the same source representations, preventing them from focusing on task-appropriate syntactic-semantic information.

## Key Results
- COMPO SITION achieves state-of-the-art results on CoGnition machine translation benchmark, significantly outperforming baseline Transformer models
- On CFQ semantic parsing benchmark, COMPO SITION achieves higher exact-match accuracy than other compositional generalization techniques across all three MCD splits
- Instance-level and aggregate-level error reduction rates show substantial improvements compared to baseline models
- The approach demonstrates that dynamic composition of encoder layers is more effective than using fixed representations from the top encoder layer

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Encoder uppermost layer entanglement limits compositional generalization by mixing syntactic and semantic information inappropriately
- Mechanism: Different syntactic and semantic information is entangled in the same high-level representation, preventing proper composition when generating novel structures
- Core assumption: Transformer encoder uppermost layer representations conflate syntactic and semantic information that should be processed separately
- Evidence anchors:
  - [abstract] "the syntactic and semantic representations of sequences are entangled" and "the source keys and values representations passing into different decoder layers are also entangled"
  - [section] "different semantic factors (e.g., lexical meaning (semantic information) and syntactic patterns (syntactic information)) required by CG are twisted inappropriately"
  - [corpus] Weak evidence - related work focuses on layer-wise fusion but not specifically on this entanglement hypothesis
- Break condition: If different encoder layers do not have distinct syntactic vs semantic information distributions as assumed

### Mechanism 2
- Claim: Dynamic composition of different encoder layers enables appropriate syntactic-semantic mixing for each decoder layer
- Mechanism: The composed layer generates different key/value representations for each decoder layer by weighting encoder layer outputs differently, allowing task-appropriate syntactic-semantic composition
- Core assumption: Bottom encoder layers contain more syntactic information while top layers contain more semantic information
- Evidence anchors:
  - [abstract] "we propose COMPO SITION... which learns to compose representations of different encoder layers appropriately"
  - [section] "the bottom layers of the Transformer encoder contain more syntactic information and the top ones contain more semantic information"
  - [corpus] Strong evidence - multiple related works confirm distinct information distributions across encoder layers
- Break condition: If decoder layers do not benefit from different source key/value representations, or if the learned composition weights are random

### Mechanism 3
- Claim: Keys/values entanglement problem exists when the same encoder representation passes into all decoder layers
- Mechanism: Using different dynamically composed source representations for keys and values of each decoder layer allows each layer to focus on relevant information for its specific role
- Core assumption: Each decoder layer has different information needs for its attention mechanism
- Evidence anchors:
  - [abstract] "source keys and values representations passing into different decoder layers are also entangled"
  - [section] "keys and values of multi-head attention module of decoder layer l are defined" with different weights per decoder layer
  - [corpus] Weak evidence - related work focuses on encoder layer fusion but not on decoder-specific key/value representations
- Break condition: If decoder layers perform equally well with identical source representations

## Foundational Learning

- Concept: Transformer encoder-decoder architecture
  - Why needed here: Understanding how information flows from encoder to decoder is essential to grasp why COMPO SITION modifies this flow
  - Quick check question: What is the difference between encoder and decoder self-attention in a Transformer?

- Concept: Compositional generalization in NLP
  - Why needed here: The entire motivation for COMPO SITION is improving compositional generalization, so understanding what this means is fundamental
  - Quick check question: Can you give an example of a composition that a model might fail to generalize to?

- Concept: Multi-head attention mechanism
  - Why needed here: COMPO SITION modifies how keys and values are generated for multi-head attention, so understanding the standard mechanism is crucial
  - Quick check question: How do keys, queries, and values interact in multi-head attention?

## Architecture Onboarding

- Component map:
  - Standard Transformer encoder with M layers
  - Composed layer (2N learnable vectors, where N is decoder layers)
  - Standard Transformer decoder with N layers
  - Modified attention mechanism using composed representations

- Critical path:
  1. Encoder produces M layers of representations
  2. Composed layer dynamically combines these into 2N vectors
  3. Each decoder layer uses its corresponding composed vectors as keys/values
  4. Decoder generates output sequence

- Design tradeoffs:
  - Additional composed layer adds minimal parameters (2N vectors of size 2M) compared to full model
  - Dynamic composition allows adaptation to task vs fixed layer fusion
  - Trade-off between model complexity and generalization performance

- Failure signatures:
  - If composed weights converge to uniform values across encoder layers
  - If performance degrades compared to baseline on non-compositional tasks
  - If training becomes unstable due to additional layer

- First 3 experiments:
  1. Replace composed layer with simple averaging of all encoder layers to test if dynamic composition is essential
  2. Fix composed weights to use only top encoder layer to test if low-level information is beneficial
  3. Use same composed weights for all decoder layers to test if decoder-specific composition is important

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the discussion section, potential open questions include:

- How does the proposed COMPO SITION model perform on other types of compositional generalization tasks beyond machine translation and semantic parsing?
- What is the impact of the number of encoder layers and decoder layers on the performance of COMPO SITION?
- How does the proposed COMPO SITION model handle out-of-vocabulary (OOV) words and rare words in the source and target languages?

## Limitations

- The approach assumes distinct syntactic vs semantic information distributions across encoder layers, which may not hold for all architectures or domains
- Computational overhead, while minimal, adds complexity to the model architecture
- The dynamic composition mechanism may not generalize well to tasks where encoder layers don't exhibit clear syntactic-semantic stratification

## Confidence

- High confidence: The empirical results showing COMPO SITION outperforms baseline models on both CoGnition and CFQ datasets
- Medium confidence: The mechanism explaining why key/value entanglement limits compositional generalization
- Medium confidence: The claim that dynamic composition is superior to fixed layer fusion approaches

## Next Checks

1. **Cross-domain validation**: Test COMPO SITION on non-translation tasks like summarization or dialogue to verify the approach generalizes beyond the tested domains.

2. **Layer sensitivity analysis**: Systematically vary the number of encoder layers and decoder layers to determine the minimum architecture requirements for COMPO SITION to be effective.

3. **Ablation on composition weights**: During inference, fix the composed weights to uniform values versus learned values to quantify how critical the dynamic adaptation is versus simply having access to multiple encoder layers.