---
ver: rpa2
title: Multi-Granularity Click Confidence Learning via Self-Distillation in Recommendation
arxiv_id: '2309.16322'
source_url: https://arxiv.org/abs/2309.16322
tags:
- confidence
- user
- clsd
- learning
- click
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of treating all clicks equally
  in recommendation systems, which ignores the different intensities of user interests
  in different clicks. The proposed method, CLSD, applies self-supervised learning
  to obtain click confidence scores via a global self-distillation method, and then
  defines a local confidence function to adapt confidence scores at the user group
  level.
---

# Multi-Granularity Click Confidence Learning via Self-Distillation in Recommendation

## Quick Facts
- arXiv ID: 2309.16322
- Source URL: https://arxiv.org/abs/2309.16322
- Authors: 
- Reference count: 40
- Key outcome: CLSD improves recommendation performance by distinguishing click confidence through self-distillation and local adaptation, deployed on a system with 400M+ users

## Executive Summary
This paper addresses the problem of treating all user clicks equally in recommendation systems, which ignores the varying intensities of user interests across different clicks. The proposed CLSD method applies self-supervised learning via global self-distillation to obtain click confidence scores, then adapts these scores at the user group level through a local confidence function. The approach requires no extra data or model structures beyond standard CTR prediction models, and has been successfully deployed in industrial systems.

## Method Summary
CLSD tackles click confidence modeling by first warming up a CTR prediction model using standard loss. It then employs self-distillation where the model's own predictions serve as teacher scores to weight positive samples, with higher-confidence samples receiving more emphasis during training. To address bias across user groups, an Adaptive Gate (AdGate) module takes user profile features as input and outputs correction factors that adjust the teacher predictions. The final training objective combines both global distillation and local adaptation, enabling the model to distinguish click quality and model user interests more accurately without requiring additional data or structural changes to existing models.

## Key Results
- Significant improvements over different backbone models on industrial offline and online experiments
- Successfully deployed on a large-scale recommender system affecting over 400 million users
- Demonstrates effectiveness across multiple recommendation scenarios including subscriptions and news feeds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Global self-distillation assigns higher weights to positive samples with higher predicted CTR, improving click confidence estimation.
- Mechanism: The model first warms up using standard CTR loss. Then, it uses its own predictions from the previous batch as teacher scores to weight the current batch's positive samples. Samples with higher predicted CTR (assumed to reflect stronger user interest) receive higher loss weights, amplifying their influence during training.
- Core assumption: Teacher predictions reliably reflect true click confidence, and higher predictions correspond to higher user interest intensity.
- Evidence anchors:
  - [abstract] "Due to the lack of supervised signals in click confidence, we first apply self-supervised learning to obtain click confidence scores via a global self-distillation method."
  - [section] "we suppose that reliable CTR prediction scores of instances can reflect the user click confidence."
  - [corpus] No direct corpus evidence; claim is derived from paper text.
- Break condition: If teacher predictions become unstable or overfit, confidence scores may mislead training, causing performance degradation.

### Mechanism 2
- Claim: Local granularity adaptation via AdGate corrects group-level bias introduced by global distillation.
- Mechanism: AdGate takes prior user features (e.g., age) as input and outputs a correction factor that is added to the teacher prediction before computing the weighted loss. This personalizes the confidence adjustment for each user group.
- Core assumption: User group features (e.g., age) correlate with prediction bias, and correcting for these features reduces unfair emphasis on overrepresented groups.
- Evidence anchors:
  - [abstract] "we define a local confidence function to adapt confidence scores at the user group level, since the confidence distributions can be varied among user groups."
  - [section] "we observe the remarkable influence of the user's age on our industrial datasets... we find that prior user information can influence the prediction distribution, involving the unfairness of Global-GD."
  - [corpus] No direct corpus evidence; claim is derived from paper text.
- Break condition: If chosen group features do not correlate with prediction bias, AdGate may add noise instead of correcting it.

### Mechanism 3
- Claim: Combining global and local confidence learning improves model performance over standard CTR objectives.
- Mechanism: The final loss blends global distillation and local adaptation. This multi-granularity approach captures both overall click confidence trends and user group-specific patterns, leading to more accurate user interest modeling.
- Core assumption: Multi-granularity modeling is more effective than single-granularity approaches because user interests are both sample-level and group-level dependent.
- Evidence anchors:
  - [abstract] "With the combination of multi-granularity confidence learning, we can distinguish the quality of clicks and model user interests more accurately..."
  - [section] "Finally, we combine the global granularity distillation and the local granularity adaption to obtain the final loss function..."
  - [corpus] No direct corpus evidence; claim is derived from paper text.
- Break condition: If one granularity dominates the other excessively, the complementary benefits may be lost.

## Foundational Learning

- Concept: Self-distillation in recommendation
  - Why needed here: Standard supervised learning lacks explicit labels for click confidence; self-distillation provides a way to generate pseudo-labels from model predictions.
  - Quick check question: In this method, what role does the model's own predictions play during training?
- Concept: Feature interaction modeling
  - Why needed here: CTR prediction depends on capturing complex interactions between user and item features; the backbone models (e.g., DeepFM, DCN) are designed to learn these interactions.
  - Quick check question: Which backbone models in the experiments are specifically designed to capture high-order feature interactions?
- Concept: User group bias in predictions
  - Why needed here: Different user groups (e.g., by age) can have systematically different prediction distributions, leading to unfair emphasis during training if not corrected.
  - Quick check question: What user attribute was found to have a significant impact on prediction distribution in the experiments?

## Architecture Onboarding

- Component map:
  - Backbone CTR model (e.g., DeepFM, DCN)
  - Global distillation module: teacher model (previous batch predictions), weighted loss for positives
  - Local adaptation module: AdGate (MLP taking user group features), bias correction factor
  - Final loss: combines global and local components
- Critical path:
  1. Warmup: train backbone with standard CTR loss
  2. Global distillation: compute teacher scores, apply weighted loss
  3. Local adaptation: compute AdGate correction, add to teacher score
  4. Final training: optimize combined loss
- Design tradeoffs:
  - Memory: using current model as teacher avoids storing extra parameters but may introduce instability
  - Complexity: AdGate adds minimal overhead but requires selecting meaningful user group features
  - Risk: if teacher predictions are poor, global distillation may amplify errors
- Failure signatures:
  - Performance drops after warmup: teacher predictions may be unstable
  - Bias toward certain user groups persists: AdGate features may be insufficient or incorrectly chosen
  - No improvement over baseline: confidence learning may not be effective for the dataset
- First 3 experiments:
  1. Verify warmup stabilizes backbone performance before applying CLSD
  2. Test global distillation alone (without AdGate) to confirm confidence learning helps
  3. Add AdGate with a simple user group feature (e.g., age) and measure improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the AdGate module be further optimized to handle a wider range of user group features beyond age?
- Basis in paper: [explicit] The paper mentions that the AdGate module currently uses age as the adaptive feature, but suggests it could be extended to other prior features that introduce bias.
- Why unresolved: The paper only explores age as the adaptive feature and does not investigate the performance of other features or more complex AdGate structures.
- What evidence would resolve it: Experiments comparing the performance of CLSD with different adaptive features and AdGate structures would provide insights into the optimal configuration.

### Open Question 2
- Question: How does the performance of CLSD vary across different recommendation domains and user demographics?
- Basis in paper: [inferred] The paper demonstrates CLSD's effectiveness in two feed recommender systems (Subscriptions and TopStory) but does not explore its performance across diverse domains or user groups.
- Why unresolved: The experiments are limited to specific domains and do not provide insights into the generalizability of CLSD across different recommendation scenarios.
- What evidence would resolve it: Conducting experiments on a broader range of recommendation domains and user demographics would reveal the versatility and limitations of CLSD.

### Open Question 3
- Question: How can the self-distillation process in CLSD be further improved to capture more nuanced user interests?
- Basis in paper: [explicit] The paper introduces a self-distillation approach to obtain click confidence scores but does not explore advanced techniques to enhance the distillation process.
- Why unresolved: The paper uses a simple self-distillation method and does not investigate alternative approaches to refine the confidence scores and better capture user interests.
- What evidence would resolve it: Exploring different self-distillation techniques and evaluating their impact on the quality of click confidence scores would provide insights into potential improvements.

## Limitations

- The assumption that higher predicted CTR directly reflects stronger user interest intensity is not empirically validated
- The selection of user group features for AdGate (specifically age) appears arbitrary without systematic feature importance analysis
- Online results are only reported as relative improvements without absolute baselines or statistical significance tests

## Confidence

- **High Confidence**: The basic premise that clicks have different confidence levels and that self-distillation can provide pseudo-labels for this supervision
- **Medium Confidence**: The effectiveness of combining global and local confidence learning, as supported by offline and online experiments
- **Low Confidence**: The specific design choices (e.g., AdGate structure, warmup schedule) and their optimality for different datasets

## Next Checks

1. Conduct ablation studies to isolate the contribution of global distillation vs. local adaptation on diverse datasets
2. Test alternative user group features beyond age to validate the generality of AdGate's bias correction
3. Implement statistical significance testing for online A/B results and report absolute metric values alongside relative improvements