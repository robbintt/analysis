---
ver: rpa2
title: Toward Design of Synthetic Active Inference Agents by Mere Mortals
arxiv_id: '2307.14145'
source_url: https://arxiv.org/abs/2307.14145
tags:
- inference
- minimization
- agents
- message
- reactive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues for a reactive programming-based approach to implementing
  Active Inference (AIF) agents that minimize free energy in factor graphs. The key
  idea is to use reactive message passing (RMP) rather than procedural control flow,
  enabling real-time, robust, and power-efficient inference on edge devices.
---

# Toward Design of Synthetic Active Inference Agents by Mere Mortals

## Quick Facts
- arXiv ID: 2307.14145
- Source URL: https://arxiv.org/abs/2307.14145
- Reference count: 27
- Primary result: Introduces reactive message passing (RMP) as a programming paradigm for implementing Active Inference agents that minimize free energy in factor graphs, enabling real-time, robust, and power-efficient inference on edge devices.

## Executive Summary
This paper proposes a reactive programming-based approach to implementing Active Inference (AIF) agents that minimize free energy (FE) in factor graphs. The key innovation is using reactive message passing (RMP) instead of procedural control flow, enabling interruptible inference that supports real-time, robust, and power-efficient operation on edge devices. The authors introduce RxInfer, a toolbox-in-progress that implements this reactive approach, aiming to democratize AIF agent development for competent engineers. The paper positions RxInfer as a step towards enabling the design of intelligent ecosystems of AIF agents as proposed in recent work by Friston et al.

## Method Summary
The method involves implementing Active Inference agents using reactive message passing in Forney-style factor graphs through the RxInfer toolbox. Instead of prescribing a fixed control flow, the reactive approach allows the agent to react to any opportunity to minimize free energy. This enables interruptible inference, online model structure adaptation, and real-time processing. RxInfer currently supports fast and robust automated free energy minimization for states and parameters in a large set of models, with plans to extend support for model structure adaptation and real-time processing.

## Key Results
- Reactive message passing enables interruptible inference that supports real-time, robust FE minimization
- The reactive programming paradigm enables online model structure adaptation without requiring system resets
- FE minimization drives both problem representation refinement and solution proposal optimization simultaneously

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reactive message passing enables interruptible inference that supports real-time, robust FE minimization
- Mechanism: By structuring inference as a series of small, independent message updates rather than a prescribed control flow, the process can be halted or resumed at any point without loss of intermediate state. This allows scaling inference complexity to match available computational resources while maintaining guaranteed progress.
- Core assumption: Message passing in factor graphs can be decomposed into atomic, stateless operations that do not depend on a global execution schedule.
- Evidence anchors:
  - [abstract] "reactive message passing (RMP) rather than procedural control flow, enabling real-time, robust, and power-efficient inference on edge devices"
  - [section 3.2] "Crucially, the inference process consists entirely of a (parallelizable) series of small steps (messages) that individually and independently contribute to FE minimization. As a result, a message passing-based FE minimization process can be interrupted at any time without loss of important intermediate computational results."
  - [corpus] Weak evidence; corpus papers focus on edge inference optimization but not reactive message passing specifically.

### Mechanism 2
- Claim: Reactive programming enables online model structure adaptation without requiring system resets
- Mechanism: Since reactive inference does not prescribe a fixed control flow, changes to the generative model structure (e.g., adding or removing nodes) can be incorporated dynamically by simply updating the factor graph. The inference process continues to minimize FE with the new structure without needing to reinitialize or reprogram control logic.
- Core assumption: The inference engine can detect and adapt to structural changes in the factor graph at runtime without restarting.
- Evidence anchors:
  - [section 3.2] "In a reactive programming paradigm, there is no control flow. Rather, the only inference instruction is for the agent to react to any opportunity to minimize FE."
  - [section 4] "In a procedural programming style, we would need to reset the system and reprogram the inference code... As discussed above, a reactive programming style solves this issue since the application inference code is independent of the model structure."
  - [corpus] No direct evidence; corpus neighbors discuss edge computing but not structural adaptation in AIF.

### Mechanism 3
- Claim: FE minimization drives both problem representation refinement and solution proposal optimization simultaneously
- Mechanism: The FE functional decomposes into surprise (negative log-evidence) and a bound term (KL divergence). Minimizing FE over latent variables improves solution proposals (q(z)), while minimizing over model structure p improves problem representation. This dual optimization leads to nested sub-models reflecting environmental causal structure and efficient inference paths.
- Core assumption: The FE decomposition is valid and that both components can be minimized jointly without one dominating the other.
- Evidence anchors:
  - [section 2.2] "FE functional is a universal cost function that can be interpreted as the sum of problem representation and solution proposal costs. FE minimization leads toward improving both the problem representation and solving the problem through inference over latent variables."
  - [section 2.2] "FE decomposition into problem plus solution costs is that a relatively poor problem representation with a superior inference process may be preferred... FE is actually a more principled performance score for a model."
  - [corpus] No relevant corpus evidence; neighbors do not discuss FE decomposition.

## Foundational Learning

- Concept: Free Energy Principle (FEP) and Active Inference (AIF)
  - Why needed here: These form the theoretical foundation for why agents minimize FE and how this leads to adaptive, goal-directed behavior.
  - Quick check question: What is the relationship between surprise and the bound term in the FE decomposition?

- Concept: Factor graphs and message passing
  - Why needed here: These provide the computational framework for efficient inference in large, sparse models by decomposing joint distributions into local computations.
  - Quick check question: How does the distributive law enable computational savings in message passing?

- Concept: Reactive vs procedural programming paradigms
  - Why needed here: This distinction explains why reactive message passing enables real-time, robust, and adaptive inference on edge devices.
  - Quick check question: What is the key difference in control flow between reactive and procedural inference implementations?

## Architecture Onboarding

- Component map:
  - Factor graph representation of the generative model
  - Reactive message passing engine (RxInfer)
  - Variational posterior beliefs over nodes and edges
  - Online model structure adaptation module
  - Real-time data stream processor
  - Power/resource management interface

- Critical path:
  1. Model specification (probabilistic model in RxInfer syntax)
  2. Reactive message passing initialization
  3. Streaming data input and belief update
  4. FE minimization and policy selection
  5. Action execution and environment interaction
  6. Model structure adaptation (if enabled)

- Design tradeoffs:
  - Accuracy vs computational complexity: More messages improve accuracy but increase latency and power consumption
  - Model complexity vs real-time capability: Larger models provide better representation but may require aggressive approximation
  - Adaptation frequency vs stability: Frequent structural changes improve responsiveness but may destabilize inference

- Failure signatures:
  - Non-convergence: FE stops decreasing despite ongoing message passing
  - Memory overflow: Factor graph grows beyond available memory during adaptation
  - Real-time violation: Inference cannot keep pace with data stream frequency
  - Numerical instability: Messages produce NaN or infinite values

- First 3 experiments:
  1. Implement a simple linear Gaussian state-space model and verify reactive message passing produces correct posteriors
  2. Add a non-linear observation model and test real-time processing with streaming synthetic data
  3. Enable online model structure adaptation on a toy POMDP and observe emergence of sub-tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can reactive message passing be scaled to support real-time processing of large-scale AIF agents with trillions of latent variables?
- Basis in paper: [explicit] The paper discusses the need for real-time processing and the benefits of reactive message passing for interruptibility, but doesn't provide concrete solutions for scaling to very large models like the human brain.
- Why unresolved: Current implementations like RxInfer support large models but not guaranteed real-time processing. Scaling reactive message passing to trillions of variables while maintaining real-time guarantees remains an open challenge.
- What evidence would resolve it: A working implementation demonstrating real-time reactive message passing on models with trillions of latent variables, or formal proofs of computational complexity bounds showing this is feasible.

### Open Question 2
- Question: How can online structural adaptation be efficiently implemented in reactive message passing frameworks without requiring system resets?
- Basis in paper: [explicit] The paper identifies that online structural adaptation is crucial for problem representation refinement and efficient inference, but notes it remains an "ongoing research issue" with technical difficulties.
- Why unresolved: Changing model structure during deployment may invalidate existing message passing schedules, and procedural approaches would require resets which contradicts the reactive framework's requirements.
- What evidence would resolve it: A reactive message passing algorithm that can dynamically restructure factor graphs and automatically adjust message passing schedules in real-time without resetting the inference process.

### Open Question 3
- Question: What is the optimal balance between model complexity and inference accuracy in AIF agents under varying resource constraints?
- Basis in paper: [inferred] The paper discusses how reactive message passing allows trading computational complexity for accuracy, and how FE minimization naturally balances accuracy vs resource consumption, but doesn't provide concrete optimization criteria.
- Why unresolved: While the decomposition of FE into complexity and accuracy terms is provided, the paper doesn't specify how to determine when to stop message passing or how to adapt this balance dynamically based on changing resource availability.
- What evidence would resolve it: Formal optimization frameworks or empirical studies demonstrating how to set resource consumption thresholds that optimize the accuracy-complexity trade-off for different application scenarios.

## Limitations
- RxInfer's structural model adaptation capabilities are still under development and not yet fully validated
- The reactive programming approach requires careful consideration of message scheduling to ensure efficient real-time performance
- No empirical validation on actual edge hardware or comparison with existing AIF implementations

## Confidence
- Reactive message passing for interruptible inference: **High** (well-established in probabilistic programming literature)
- Real-time capability on edge devices: **Medium** (plausible given the reactive approach but not yet empirically demonstrated)
- Structural model adaptation without system resets: **Low** (theoretical promise but implementation still in progress)

## Next Checks
1. Benchmark reactive message passing inference speed against traditional procedural implementations on standard AIF models
2. Deploy RxInfer on a real edge device (e.g., Raspberry Pi) with streaming sensor data to validate real-time performance claims
3. Implement a simple structural adaptation scenario (e.g., online discovery of sub-tasks) and verify the reactive engine handles dynamic model changes correctly