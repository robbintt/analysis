---
ver: rpa2
title: Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss with
  Imbalanced Data
arxiv_id: '2309.09725'
source_url: https://arxiv.org/abs/2309.09725
tags:
- collapse
- then
- where
- neural
- mean
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the neural collapse phenomenon in unconstrained
  feature models with imbalanced data under cross-entropy loss. It proves that the
  within-class feature collapse still occurs, but the mean feature vectors no longer
  form an equiangular tight frame - instead their pairwise angles depend on sample
  sizes.
---

# Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss with Imbalanced Data

## Quick Facts
- **arXiv ID**: 2309.09725
- **Source URL**: https://arxiv.org/abs/2309.09725
- **Reference count**: 40
- **Key outcome**: Within-class feature collapse occurs under cross-entropy loss with imbalanced data, but mean feature vectors form block-structured patterns rather than an equiangular tight frame, with minority collapse occurring at sharp thresholds.

## Executive Summary
This paper studies neural collapse in unconstrained feature models (UFM) under cross-entropy loss with imbalanced data. The authors prove that within-class feature collapse persists despite data imbalance, but the mean feature vectors no longer form an equiangular tight frame - instead they exhibit a block structure where pairwise angles depend on class sample sizes. The paper characterizes the sharp threshold for minority collapse, where minority class features collapse to a single vector, and shows that the effect of imbalance diminishes as sample size grows. Experiments on deep neural networks confirm these theoretical findings, demonstrating that neural collapse behavior changes significantly under data imbalance.

## Method Summary
The study analyzes unconstrained feature models with cross-entropy loss and nuclear norm regularization. The model parameters include a feature matrix H, a weight matrix W, and a bias vector b. The authors use SGD with momentum to train the model, monitoring within-class collapse via the NC1 metric. They analyze the mean prediction matrix structure and vary the regularization parameter Î»Z to study minority collapse thresholds. Synthetic imbalanced data is generated following a cluster structure with multiple classes having different sample sizes, and real datasets like CIFAR-10 and FMNIST are partitioned accordingly.

## Key Results
- Within-class feature collapse persists under cross-entropy loss even with imbalanced data
- Mean feature vectors form a block-structured pattern dependent on sample sizes rather than an equiangular tight frame
- Minority collapse occurs at a sharp threshold determined by the ratio of sample sizes and regularization parameter
- The effect of imbalance diminishes as sample size grows

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Within-class feature collapse persists under cross-entropy loss even with imbalanced data
- **Mechanism**: Jensen's inequality ensures that when features from the same class are replaced by their mean, the cross-entropy loss does not increase, creating a monotonic descent path toward collapsed features
- **Core assumption**: Cross-entropy loss is convex in the prediction direction for fixed features
- **Evidence anchors**:
  - [abstract]: "we show that the feature vectors exhibit collapse phenomenon, i.e., the features within the same class collapse to the same mean vector"
  - [section 5.2]: Proof explicitly uses Jensen's inequality to show that the loss decreases when replacing individual features with their class mean
  - [corpus]: Neural collapse literature confirms this collapse pattern under various loss functions
- **Break condition**: If cross-entropy loss were replaced with a non-convex or non-separable loss function that doesn't satisfy Jensen's inequality conditions

### Mechanism 2
- **Claim**: Mean feature vectors form a block-structured pattern dependent on sample sizes rather than an equiangular tight frame
- **Mechanism**: The optimal solution must be invariant under permutations within each cluster (classes with same sample size), forcing all mean vectors within a cluster to have identical pairwise angles
- **Core assumption**: The nuclear norm regularization and cross-entropy loss create a symmetric landscape where permutation-invariant solutions are optimal
- **Evidence anchors**:
  - [abstract]: "the mean feature vectors no longer form an equiangular tight frame. Instead, their pairwise angles depend on the sample size"
  - [section 5.2]: Theorem 3.1(b) explicitly proves the block structure emerges from permutation invariance arguments
  - [corpus]: Similar block structures observed in other constrained optimization problems with symmetry
- **Break condition**: If regularization strength becomes zero or if class sample sizes are all distinct (no clusters)

### Mechanism 3
- **Claim**: Minority collapse occurs at a sharp threshold determined by the ratio of sample sizes and regularization parameter
- **Mechanism**: As the regularization parameter increases, the nuclear norm penalty forces singular values to zero sequentially, with minority class mean vectors collapsing first when their effective sample size constraint is violated
- **Core assumption**: The nuclear norm acts as a soft rank constraint that thresholds singular values based on the ratio of regularization to sample size
- **Evidence anchors**:
  - [abstract]: "we also precisely characterize the sharp threshold on which the minority collapse (the feature vectors of the minority groups collapse to one single vector) will take place"
  - [section 5.3]: Theorem 3.2 provides explicit threshold formulas based on singular value analysis
  - [corpus]: Neural collapse literature shows similar threshold phenomena under different loss functions
- **Break condition**: If regularization parameter is fixed and sample size imbalance becomes extreme enough that minority class samples become negligible

## Foundational Learning

- **Concept**: Jensen's inequality for convex functions
  - **Why needed here**: Used to prove that replacing individual features with their class mean doesn't increase cross-entropy loss, enabling the collapse proof
  - **Quick check question**: If f is convex and x_i are random variables, what inequality relates f(E[x]) to E[f(x)]?

- **Concept**: Nuclear norm and its subdifferential
  - **Why needed here**: The nuclear norm regularization creates the optimization landscape that enables feature collapse and determines when collapse occurs
  - **Quick check question**: What is the subdifferential of the nuclear norm at a rank-deficient matrix?

- **Concept**: Permutation invariance and symmetry in optimization
  - **Why needed here**: The block structure of mean feature vectors emerges from invariance under permutations within clusters of same-sized classes
  - **Quick check question**: If a function is invariant under a group of permutations, what can we say about its critical points?

## Architecture Onboarding

- **Component map**: Data preparation (imbalanced datasets) -> Model (UFM with cross-entropy loss) -> Training (SGD optimization) -> Analysis (mean feature vectors and collapse patterns)
- **Critical path**: 1. Define class clusters based on sample sizes, 2. Initialize parameters and set regularization strength, 3. Train until convergence (loss near zero), 4. Extract mean feature vectors from trained model, 5. Analyze block structure and collapse patterns
- **Design tradeoffs**:
  - Higher regularization: Stronger feature collapse but potential underfitting
  - Lower regularization: Weaker collapse, more flexible representations
  - More clusters: Richer block structure but harder to analyze
  - Fewer clusters: Simpler analysis but less realistic data representation
- **Failure signatures**:
  - No collapse observed: Regularization too weak or data too balanced
  - Unexpected block patterns: Cluster assignment incorrect or class sizes miscomputed
  - Training instability: Learning rate too high or batch size too small
- **First 3 experiments**:
  1. Balanced case verification: Set all class sizes equal and verify ETF formation
  2. Two-cluster minority collapse: Create majority/minority clusters and vary imbalance ratio
  3. Multi-cluster block structure: Create 3+ clusters with different sizes and analyze emerging patterns

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: What is the precise threshold for minority collapse under cross-entropy loss in general UFM settings beyond the two-cluster case?
- **Basis in paper**: [explicit] The paper characterizes the sharp threshold for minority collapse in the two-cluster case but notes this is a special setting and asks how it generalizes.
- **Why unresolved**: The paper only provides exact threshold for the simplified two-cluster setting where majority and minority classes each form one cluster. General imbalanced data with multiple classes in each cluster remains uncharacterized.
- **What evidence would resolve it**: Rigorous derivation of the threshold condition for minority collapse in the general cluster-structured imbalanced data setting, showing how it depends on cluster sizes and class distributions.

### Open Question 2
- **Question**: How does the neural collapse phenomenon change when moving beyond UFM to models with nonlinear activations or multiple hidden layers?
- **Basis in paper**: [explicit] The paper discusses limitations of UFM in capturing DNN behavior and mentions several works that add linear layers or nonlinearity but notes that adding even one layer of nonlinearity remains unexplored.
- **Why unresolved**: UFM assumes features are free variables optimized directly, ignoring network depth and nonlinearity. The paper acknowledges this limitation and suggests more complex models are needed to explain DNNs.
- **What evidence would resolve it**: Theoretical analysis of neural collapse under models that incorporate nonlinearity (e.g., ReLU activations) or multiple layers, showing how collapse behavior differs from UFM predictions.

### Open Question 3
- **Question**: What is the relationship between neural collapse and generalization error on test data, particularly for imbalanced datasets?
- **Basis in paper**: [explicit] The paper concludes by noting that most studies on the relation between neural collapse and generalization remain empirical and addressing this theoretically would lead to deeper understanding.
- **Why unresolved**: While the paper characterizes neural collapse structure, it does not investigate how this relates to generalization performance. The authors explicitly state this connection remains empirical.
- **What evidence would resolve it**: Theoretical bounds or analysis connecting the degree of neural collapse (particularly under imbalance) to generalization error on test data, showing whether collapse is beneficial or detrimental for generalization.

## Limitations

- The analysis assumes unconstrained features and specific nuclear norm regularization, which may not directly translate to standard deep neural networks with architectural constraints
- The theoretical results are asymptotic and may not hold for finite sample sizes commonly used in practice
- The symmetric cluster assumption (classes grouped by sample size) is restrictive compared to real-world imbalanced datasets with arbitrary class sizes

## Confidence

- **Within-class collapse**: High confidence - rigorous mathematical proofs in the appendix using Jensen's inequality
- **Block structure characterization**: Medium confidence - proven using symmetry and permutation invariance arguments, but relies on specific regularization assumptions
- **Minority collapse threshold**: Medium-Low confidence - characterization depends on nuclear norm regularization behavior that may not fully capture practical training dynamics

## Next Checks

1. **Robustness to initialization**: Test whether the claimed collapse patterns and thresholds are sensitive to different parameter initialization schemes, particularly for deep networks where initialization can significantly impact optimization dynamics.

2. **Generalization to arbitrary imbalance**: Validate the theoretical predictions on datasets with non-uniform class size distributions (beyond the symmetric cluster assumption) to assess whether the block structure and collapse thresholds generalize to realistic imbalanced scenarios.

3. **Cross-loss function comparison**: Compare the collapse behavior and threshold phenomena under alternative loss functions (e.g., focal loss, class-weighted cross-entropy) to determine whether the observed patterns are specific to the cross-entropy loss or represent more general principles of imbalanced learning.