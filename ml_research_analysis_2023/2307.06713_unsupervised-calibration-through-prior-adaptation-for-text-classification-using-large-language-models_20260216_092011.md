---
ver: rpa2
title: Unsupervised Calibration through Prior Adaptation for Text Classification using
  Large Language Models
arxiv_id: '2307.06713'
source_url: https://arxiv.org/abs/2307.06713
tags:
- calibration
- training
- task
- class
- prior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes UCPA, a method to adapt LLM posteriors to text
  classification tasks without labelled data. The method adjusts the prior class distribution
  of the LLM to the task of interest using only unlabelled in-domain samples.
---

# Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models

## Quick Facts
- arXiv ID: 2307.06713
- Source URL: https://arxiv.org/abs/2307.06713
- Authors: 
- Reference count: 14
- One-line primary result: Method adapts LLM posteriors to text classification tasks without labeled data by adjusting class priors using unlabelled in-domain samples.

## Executive Summary
This paper proposes UCPA, a method to adapt LLM posteriors to text classification tasks without labelled data. The method adjusts the prior class distribution of the LLM to the task of interest using only unlabelled in-domain samples. Two variants are proposed: UCPA, which assumes uniform priors, and SUCPA, which uses class priors estimated from unlabelled data. The method is compared with a content-free baseline and supervised affine calibration. Results show that UCPA/SUCPA outperform the un-adapted model and the content-free baseline in most cases, even with few training samples. SUCPA performs similarly to supervised calibration, without the need for labelled data.

## Method Summary
The method treats the LLM as a black box and applies a transformation to the output posteriors based on a recalibrated prior. The recalibrated prior is estimated from unlabelled in-domain data by averaging the LLM's outputs across many samples. Two variants are proposed: UCPA, which assumes uniform priors, and SUCPA, which uses class priors estimated from unlabelled data. The method is evaluated using normalized cross-entropy, which measures how well the adjusted posteriors match true class probabilities. The method is compared with a content-free baseline and supervised affine calibration.

## Key Results
- UCPA and SUCPA consistently improve over the un-adapted LLM and content-free baseline across all datasets and few-shot settings.
- SUCPA matches supervised calibration performance when class priors are non-uniform and adaptation data is sufficient.
- The mathematical derivation linking UCPA to supervised calibration with α=1 is sound.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The LLM's posteriors can be improved by adjusting the prior class distribution to match the target task.
- Mechanism: The method treats the LLM as a black box and applies a transformation to the output posteriors based on a recalibrated prior. The recalibrated prior is estimated from unlabelled in-domain data by averaging the LLM's outputs across many samples.
- Core assumption: The mismatched prior P(y|e) in the LLM's outputs can be removed and replaced with an in-domain prior ˆP(y|e) without destroying the task-relevant information in the likelihood ratio P(q|y,e)/P(q|e).
- Evidence anchors:
  - [abstract]: "The proposed approach treats the LLM as a black box, adding a stage where the model posteriors are calibrated to the task."
  - [section]: "This is done by assuming the following expression for the in-domain posterior: ˆP(y|q,e) = δ P(y|q,e) ˆP(y|e)/P(y|e)"
- Break condition: If the likelihood ratio term P(q|y,e)/P(q|e) is not stable across the unlabelled adaptation data, the adjustment will misalign the posteriors.

### Mechanism 2
- Claim: UCPA approximates supervised calibration without using labels by matching the form of affine calibration when α=1.
- Mechanism: By setting βk = log(Nk/N) - log(1/N Σ_i P(yk|q(i),e)e^γ(i)), the method implicitly learns a shift in log-odds that mimics the effect of logistic regression calibration with fixed scaling.
- Core assumption: The iterative computation of γ(i) and βk converges to values that yield posteriors close to those from supervised calibration.
- Evidence anchors:
  - [section]: "Comparing the expressions for βk and β'k we can see that they coincide if we take ˆP(yk|q)=Nk/N as we assume in our experiments for the SUCPA approach"
  - [section]: "we can also estimate the βk that satisfies Equation (10) exactly using an iterative approach"
- Break condition: If the adaptation dataset is too small or unrepresentative, the empirical class frequencies Nk/N will be noisy, leading to poor estimates of the shift term.

### Mechanism 3
- Claim: SUCPA benefits from incorporating known class priors, while UCPA defaults to uniform priors, allowing a trade-off between prior knowledge and adaptation data.
- Mechanism: SUCPA estimates ˆP(y|e) = Nk/N from the adaptation set, while UCPA assumes ˆP(y|e) = 1/K. This affects the posterior adjustment in the same affine form.
- Core assumption: When the test priors are not uniform, SUCPA will outperform UCPA, but if the adaptation set is too small, the empirical estimate will be unreliable.
- Evidence anchors:
  - [abstract]: "SUCPA performs similarly to supervised calibration, without the need for labelled data."
  - [section]: "SUCPA works better than UCPA when the test priors are not uniform"
- Break condition: If the adaptation set has very few samples per class, the estimated prior will be inaccurate and SUCPA may underperform UCPA.

## Foundational Learning

- Concept: Conditional probability and Bayes' theorem
  - Why needed here: The core of the method relies on decomposing P(y|q,e) into prior, likelihood, and evidence terms, then adjusting the prior.
  - Quick check question: Given P(y|e)=0.3, P(q|y,e)=0.7, P(q|e)=0.5, what is P(y|q,e)?

- Concept: Cross-entropy as a proper scoring rule
  - Why needed here: The method is evaluated using normalized cross-entropy, which measures how well the adjusted posteriors match true class probabilities.
  - Quick check question: If a model always outputs the prior distribution, what is its normalized cross-entropy?

- Concept: Logistic regression and affine calibration
  - Why needed here: The paper connects its approach to supervised affine calibration with α=1, so understanding the form of that transformation is key.
  - Quick check question: In affine calibration with α=1, what does the parameter βk control?

## Architecture Onboarding

- Component map:
  - Input: Unlabelled in-domain queries (Qtrain) + optional labelled subset for supervised comparison
  - LLM: Black-box model that outputs token-level posteriors
  - Prior estimator: Computes P(y|e) by averaging LLM outputs over Qtrain
  - Label prior estimator (SUCPA only): Computes ˆP(y|e) = Nk/N from adaptation set
  - Calibration engine: Applies affine transformation to LLM posteriors using prior terms
  - Output: Calibrated posteriors for test queries

- Critical path:
  1. Sample unlabelled queries Qtrain
  2. Run LLM on each query to get P(y|q(i),e)
  3. Compute P(y|e) = 1/N Σ_i P(y|q(i),e)
  4. If SUCPA, compute ˆP(y|e) = Nk/N
  5. For each test query, compute P(y|q,e) from LLM
  6. Apply Equation (5) or its iterative variant to get calibrated posteriors

- Design tradeoffs:
  - UCPA vs SUCPA: UCPA avoids dependence on class frequencies but may miss improvements from skewed priors; SUCPA can be better if priors are known but risks overfitting with small data.
  - Iterative vs naive prior estimation: Iterative may be more accurate but adds computation; naive is simpler and empirically similar.
  - Number of shots: More shots in the prompt usually help but increase cost; very few may lead to unstable posteriors.

- Failure signatures:
  - High normalized cross-entropy (>1.0) indicates posteriors are worse than naive prior output.
  - Large variance across seeds when subsetting training data signals instability.
  - SUCPA degrading performance with <80 samples on 14-class datasets suggests unreliable prior estimation.

- First 3 experiments:
  1. Run LLM on a small Qtrain set, compute P(y|e), and check if it matches expected task priors.
  2. Apply naive UCPA to a 0-shot classification task and compare error rate to un-adapted model.
  3. Implement the iterative βk computation and verify it matches logistic regression with α=1 on a synthetic dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of UCPA and SUCPA scale with larger language models beyond GPT-2 XL?
- Basis in paper: [inferred] The paper states "a more detailed analysis should be done in terms of the model size, and newer LLMs should be tested in addition of GPT-2 XL."
- Why unresolved: The experiments were only conducted with GPT-2 XL (1.5B parameters). The authors explicitly suggest that testing with larger or newer models is an open direction.
- What evidence would resolve it: Empirical results comparing UCPA/SUCPA performance across a range of LLM sizes and architectures (e.g., GPT-3, GPT-4, LLaMA, etc.) using the same datasets and protocols.

### Open Question 2
- Question: What is the minimum amount of in-domain unlabelled data required for UCPA/SUCPA to outperform the non-adapted baseline reliably across different datasets?
- Basis in paper: [inferred] The paper notes that UCPA/SUCPA works well "even when very few (as low as 10) training samples are available," but also shows performance degradation in some cases (e.g., DBPedia with <80 samples).
- Why unresolved: The paper tests only a few specific sample sizes (10, 40, 80, 600). The relationship between dataset complexity (e.g., number of classes, class balance) and the minimum effective sample size is not systematically studied.
- What evidence would resolve it: A systematic study varying the number of in-domain samples across diverse datasets to identify the sample size threshold for consistent gains.

### Open Question 3
- Question: How sensitive is SUCPA to inaccuracies in the prior distribution estimates when such priors are derived from external knowledge rather than training data?
- Basis in paper: [explicit] The paper states "SUCPA performance would in fact depend on how good that estimate is" and discusses using knowledge of the task to estimate priors.
- Why unresolved: The experiments only estimate priors from training data (Nk/N). The paper acknowledges but does not test scenarios where priors are estimated from external, potentially imperfect, sources.
- What evidence would resolve it: Experiments where SUCPA is run with intentionally perturbed or inaccurate prior estimates to measure the impact on performance, compared to UCPA.

### Open Question 4
- Question: Can UCPA/SUCPA be effectively extended to generative tasks such as question answering and summarization, as suggested by the authors?
- Basis in paper: [explicit] The conclusion states "we would like to extend this method to more elaborated tasks that involves text generation like question answering and summarization."
- Why unresolved: The current work only evaluates classification tasks. The method's applicability to tasks with different output structures (e.g., free-form text) is untested.
- What evidence would resolve it: Implementation and evaluation of UCPA/SUCPA on generative tasks, measuring both output quality and calibration metrics.

### Open Question 5
- Question: How does UCPA/SUCPA compare to more computationally intensive adaptation methods like full fine-tuning in terms of performance trade-offs?
- Basis in paper: [explicit] The conclusion mentions "a comparison could be done between this kind of domain adaptation and more complex techniques like (full or selective) fine-tuning."
- Why unresolved: The paper only compares UCPA/SUCPA to content-free calibration and affine calibration. Direct comparison with fine-tuning, which was not feasible due to computational constraints, is missing.
- What evidence would resolve it: Head-to-head experiments comparing UCPA/SUCPA performance, calibration, and computational cost against fine-tuning methods on the same tasks.

## Limitations

- Dataset coverage and generalizability: The evaluation covers four datasets spanning binary to 14-class problems, but all are in English and cover only sentiment, question-type, news topic, and fine-grained ontology classification. The performance of UCPA/SUCPA on non-English text, code, or structured data classification remains unknown.
- Prior estimation stability: The core mechanism assumes that averaging posteriors over unlabelled queries yields a stable and meaningful in-domain prior. This relies on the LLM producing consistent likelihood ratios P(q|y,e)/P(q|e) across the adaptation set. If the unlabelled queries are unrepresentative or the LLM's outputs are unstable with respect to prompt formatting or sampling noise, the recalibrated priors may misalign the posteriors.
- Comparison scope: The method is only compared against a content-free baseline (arithmetic mean of LLM outputs) and supervised affine calibration. It is unclear how UCPA/SUCPA performs relative to other unsupervised calibration methods (e.g., histogram binning, temperature scaling without labels) or semi-supervised approaches that leverage a small labelled set.

## Confidence

- High confidence: UCPA and SUCPA consistently improve over the un-adapted LLM and content-free baseline across all datasets and few-shot settings. SUCPA matches supervised calibration performance when class priors are non-uniform and adaptation data is sufficient. The mathematical derivation linking UCPA to supervised calibration with α=1 is sound.
- Medium confidence: The iterative estimation of βk converges and is comparable to the naive method, but the paper does not provide convergence diagnostics or error bounds. SUCPA's degradation with <80 samples on 14-class datasets is observed but not formally explained.
- Low confidence: The claim that the method works "without destroying task-relevant information" is supported only by empirical performance, not by analysis of the likelihood ratio term's stability. The generalizability to other languages, domains, or model families (e.g., decoder-only LLMs) is not demonstrated.

## Next Checks

1. **Prior stability analysis**: Run the prior estimation step multiple times with different random seeds for Qtrain. Measure the variance in P(y|e) and evaluate whether this variance correlates with downstream calibration performance. If high variance is observed, investigate whether stratified sampling or larger Qtrain mitigates the issue.

2. **Cross-lingual and cross-domain transfer**: Apply UCPA/SUCPA to a multilingual sentiment dataset (e.g., XNLI or ML-SentiMUD) or a domain-shifted version of one of the tested datasets (e.g., using Amazon reviews for SST-2). Compare performance to in-domain calibration and report changes in normalized cross-entropy.

3. **Comparison with alternative unsupervised calibration**: Implement and evaluate at least one alternative unsupervised calibration method (e.g., temperature scaling using held-out validation set, or ensemble-based calibration). Compare error rate and normalized cross-entropy against UCPA/SUCPA on the same few-shot splits to assess relative gains.