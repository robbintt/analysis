---
ver: rpa2
title: 'Augmenting LLMs with Knowledge: A survey on hallucination prevention'
arxiv_id: '2309.16459'
source_url: https://arxiv.org/abs/2309.16459
tags:
- knowledge
- language
- search
- text
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey examines approaches to augmenting large language models
  (LLMs) with external knowledge sources to mitigate hallucinations and improve factuality.
  It covers retrieval-augmented generation (RAG), which retrieves relevant documents
  from a knowledge base and conditions generation on them; REALM, which jointly pre-trains
  retriever and generator; Fusion-in-Decoder (FiD), which encodes retrieved passages
  separately and fuses their embeddings before decoding; and search engine-augmented
  models like SeeKeR and LaMDA, which use search queries to augment responses.
---

# Augmenting LLMs with Knowledge: A survey on hallucination prevention

## Quick Facts
- arXiv ID: 2309.16459
- Source URL: https://arxiv.org/abs/2309.16459
- Reference count: 40
- This survey examines approaches to augmenting large language models (LLMs) with external knowledge sources to mitigate hallucinations and improve factuality.

## Executive Summary
This survey examines approaches to augmenting large language models (LLMs) with external knowledge sources to mitigate hallucinations and improve factuality. It covers retrieval-augmented generation (RAG), which retrieves relevant documents from a knowledge base and conditions generation on them; REALM, which jointly pre-trains retriever and generator; Fusion-in-Decoder (FiD), which encodes retrieved passages separately and fuses their embeddings before decoding; and search engine-augmented models like SeeKeR and LaMDA, which use search queries to augment responses. These methods aim to ground LLM outputs in verifiable knowledge, reducing hallucinations and improving accuracy on knowledge-intensive tasks. The survey finds that knowledge augmentation is a promising direction for addressing limitations of standard LLMs.

## Method Summary
The survey reviews multiple knowledge-augmented LLM architectures including retrieval-augmented generation (RAG), REALM (joint retriever-generator pre-training), Fusion-in-Decoder (FiD), and search engine-augmented models. These approaches retrieve relevant documents from knowledge bases or search engines and condition the LLM's generation on this external information. The methods vary in retrieval strategy (dense vs. sparse, static vs. dynamic), fusion approach (token-level vs. sequence-level vs. encoder fusion), and knowledge source (structured knowledge graphs vs. unstructured text vs. live web search). Implementation typically involves setting up a retriever (e.g., DPR), a knowledge base (FAISS or search API), and a seq2seq generator (BART, T5) with appropriate fusion mechanisms.

## Key Results
- Knowledge augmentation significantly reduces hallucinations by grounding generation in retrieved external evidence
- Search engine augmentation provides broader, more up-to-date knowledge than static knowledge bases but introduces safety risks
- Joint pre-training of retriever and generator enables better knowledge integration but is computationally expensive
- Fusion-in-Decoder allows efficient parallel encoding of multiple retrieved passages

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Knowledge augmentation reduces hallucinations by conditioning generation on retrieved external evidence.
- **Mechanism**: The augmented model retrieves relevant documents or passages based on the input query and fuses this information into the generation process, replacing or supplementing the model's parametric memory. This provides verifiable, current knowledge to ground the response.
- **Core assumption**: The retrieved documents are relevant and factually accurate; the model can effectively integrate this information without losing coherence.
- **Evidence anchors**:
  - [abstract]: "This survey delves into the realm of language models (LMs) augmented with the ability to tap into external knowledge sources, including external knowledge bases and search engines... holds the potential to address prevalent issues in traditional LMs, such as hallucinations, un-grounded responses, and scalability challenges."
  - [section]: "RAG [6] uses both parametric and non-parametric memory to generate more accurate and informative responses to an input query... fusion is performed right after the decoder."
  - [corpus]: Weak - corpus lacks direct evidence on hallucination reduction rates; this is inferred from paper claims.
- **Break condition**: If retrieval relevance is low or documents contain misinformation, the augmented model may produce mixed or incorrect responses.

### Mechanism 2
- **Claim**: Joint pre-training of retriever and generator enables better knowledge integration and retrieval accuracy.
- **Mechanism**: Unlike methods that use frozen retrievers, approaches like REALM and Atlas jointly train both components so that retrieval quality improves as the generator learns to condition on retrieved content, closing the training loop.
- **Core assumption**: Retriever updates can be performed efficiently without prohibitive computational cost; gradients flow effectively through both components.
- **Evidence anchors**:
  - [section]: "REALM was the first method that managed to pre-train jointly the retriever and the generator... training the Retriever can be computationally expensive, because while the document encoder becomes better, the embeddings for each passage in the database need to be recomputed."
  - [corpus]: Missing - no corpus data on joint pre-training performance; assumption based on paper description.
- **Break condition**: If retriever updates are too costly or slow, the joint training loop stalls and performance plateaus.

### Mechanism 3
- **Claim**: Search engine augmentation provides broader, more up-to-date knowledge than static knowledge bases.
- **Mechanism**: Models like SeeKeR and LaMDA query live search engines to retrieve current information, enabling generation that reflects the latest facts rather than outdated static corpora.
- **Core assumption**: Search engine results are relevant, reliable, and safe; the model can filter out harmful or misleading content.
- **Evidence anchors**:
  - [abstract]: "Another strategy involves enabling LLMs to leverage external tools [12], such as search engines [13] [14] [12], allowing them to augment the current context with crucial missing information not contained within the model’s weights."
  - [section]: "Search engines empower models with a gateway to an expansive universe of knowledge that far surpasses what external knowledge bases can access... the information landscape of the internet is diverse, encompassing both valuable knowledge and, regrettably, harmful or malicious content."
  - [corpus]: Weak - corpus lacks direct evidence on real-time accuracy; assumption based on paper description.
- **Break condition**: If search results are noisy, outdated, or malicious, the augmented model's responses degrade in quality and safety.

## Foundational Learning

- **Concept**: Vector embeddings and similarity search
  - Why needed here: Retrieval relies on encoding documents and queries as vectors, then finding nearest neighbors efficiently (e.g., via FAISS or MIPS).
  - Quick check question: How does cosine similarity differ from inner product in vector retrieval, and when would you choose one over the other?

- **Concept**: Attention mechanisms and cross-attention
  - Why needed here: Generators use attention to integrate retrieved passages; cross-attention allows the decoder to focus on relevant parts of multiple retrieved documents.
  - Quick check question: What is the difference between self-attention and cross-attention in sequence-to-sequence models?

- **Concept**: Transformer encoder-decoder architecture
  - Why needed here: Most augmented models use seq2seq transformers; understanding how encoder outputs feed into decoder cross-attention is essential for implementing fusion strategies.
  - Quick check question: How does a decoder-only transformer differ from an encoder-decoder transformer, and what implications does this have for retrieval-augmented generation?

## Architecture Onboarding

- **Component map**: Input query -> Retriever (DPR/Contriever) -> Knowledge base (FAISS/ScaNN/search index) -> Generator (BART/T5) -> Output response
- **Critical path**: Input query → Retriever → Knowledge base → Generator (with fusion) → Output response
- **Design tradeoffs**:
  - Static vs. dynamic knowledge: Static (FAISS) is faster but stale; dynamic (search) is current but slower and riskier
  - Retrieval granularity: Sentence vs. chunk vs. document affects context richness and retrieval cost
  - Fusion timing: Pre-decoder fusion (FiD) vs. post-decoder (RAG) vs. iterative (SeeKeR)
- **Failure signatures**:
  - Low retrieval recall → generic or ungrounded responses
  - Retrieval noise → contradictory or incorrect facts
  - Slow retrieval → latency spikes in generation
  - Outdated KB → stale knowledge in responses
- **First 3 experiments**:
  1. Set up a small FAISS index with Wikipedia passages; implement a basic DPR retriever and FiD generator; measure ROUGE scores on SQuAD
  2. Replace static index with Bing Search API; compare response accuracy and latency on recent events
  3. Implement RAG-token vs. RAG-sequence; evaluate hallucination rates using a fact-checking dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the retrieval-augmented generation approach handle conflicting information from different knowledge sources?
- Basis in paper: [explicit] The paper mentions that "Instances arise where conflicting retrievals result in mixed answers" as a limitation of knowledge-augmented language models.
- Why unresolved: The paper acknowledges this issue but does not provide a detailed solution or evaluation of how different approaches handle conflicting information.
- What evidence would resolve it: Comparative studies evaluating the performance of different retrieval-augmented models on datasets with conflicting information, along with proposed methods for resolving conflicts.

### Open Question 2
- Question: What is the impact of using internet search engines versus external knowledge bases on the quality and timeliness of generated responses?
- Basis in paper: [explicit] The paper discusses the advantages of search engines (access to vast and up-to-date information) but also mentions potential risks (exposure to harmful content).
- Why unresolved: While the paper highlights the trade-offs, it does not provide empirical evidence comparing the performance of models using search engines versus those using external knowledge bases.
- What evidence would resolve it: Comparative studies evaluating the performance of models using search engines versus external knowledge bases on various tasks, considering factors like accuracy, timeliness, and safety.

### Open Question 3
- Question: How can the interplay between reasoning augmentation and knowledge integration be further explored and improved in augmented language models?
- Basis in paper: [inferred] The paper mentions that "the limited exploration of the interplay between reasoning augmentation and knowledge integration in current research highlights a promising avenue for future endeavors."
- Why unresolved: The paper does not provide specific approaches or methods for integrating reasoning augmentation with knowledge integration.
- What evidence would resolve it: Research papers proposing and evaluating methods for combining reasoning augmentation with knowledge integration, along with empirical results demonstrating improved performance.

## Limitations

- Absence of ablation studies comparing static vs. dynamic knowledge sources
- No analysis of retrieval noise impact on factuality
- Limited discussion of safety filtering for live search augmentation

## Confidence

- Retrieval-augmented generation (RAG): Medium - well-documented but lacks hallucination reduction metrics
- Joint retriever-generator pre-training: Low - computationally expensive and under-specified
- Search engine augmentation: Low - safety and reliability concerns not quantified

## Next Checks

1. Implement a controlled RAG experiment comparing hallucination rates on fact-checking datasets with and without augmentation
2. Benchmark retrieval accuracy decay when scaling from static FAISS indices to live search APIs
3. Measure factuality trade-offs in FiD-style fusion vs. token-level RAG on ambiguous queries