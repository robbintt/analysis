---
ver: rpa2
title: Alignment of Density Maps in Wasserstein Distance
arxiv_id: '2305.12310'
source_url: https://arxiv.org/abs/2305.12310
tags:
- algorithm
- which
- alignment
- loss
- distance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a novel method for aligning 3D density maps,
  motivated by applications in cryo-electron microscopy (cryo-EM). The proposed algorithm
  minimizes the 1-Wasserstein distance between density maps after rigid transformation,
  which provides a more benign loss landscape compared to traditional Euclidean distance.
---

# Alignment of Density Maps in Wasserstein Distance

## Quick Facts
- arXiv ID: 2305.12310
- Source URL: https://arxiv.org/abs/2305.12310
- Reference count: 9
- This paper presents a novel method for aligning 3D density maps using 1-Wasserstein distance, achieving improved accuracy over L2-based methods on cryo-EM protein datasets.

## Executive Summary
This paper introduces a novel approach for aligning 3D density maps using 1-Wasserstein distance, motivated by applications in cryo-electron microscopy (cryo-EM). The method employs Bayesian optimization to minimize the Wasserstein distance between density maps after rigid transformation, providing a more benign loss landscape compared to traditional Euclidean distance. The algorithm achieves improved accuracy and efficiency over existing methods on real protein molecule datasets from cryo-EM.

## Method Summary
The method uses Bayesian optimization to minimize the wavelet earth mover's distance (WEMD) between rotated 3D density maps. The approach employs a Gaussian process surrogate to approximate the loss function landscape and select candidate rotations for evaluation. The WEMD is computed using wavelet decomposition with sym3 wavelet and maximum scale levels of 6. The algorithm iterates for 200 evaluations, optionally followed by local refinement using Nelder-Mead optimization on L2 loss.

## Key Results
- Recovers relative rotation with 5-degree error using only 200 loss function evaluations
- Outperforms L2-based alignment on heterogeneous protein pairs from EMDB
- Achieves better accuracy than exhaustive search methods while being computationally efficient

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The 1-Wasserstein distance provides a more benign loss landscape than L2 distance for rotation estimation in cryo-EM alignment.
- Mechanism: Wasserstein distance is translation-invariant for pure translations and rotation-invariant for pure rotations, creating convex or flatter basins of attraction compared to L2.
- Core assumption: Density maps have irregular shapes where L2 distances vary rapidly with small rotations.
- Evidence anchors: [section] "For instance, it is shown by (Hamm et al., 2022, Lemma 3.5) that for p∈ (1,∞), Wp(φ(·),φ(·+v))=|v|, ∀v∈R3" and "The landscape of the loss associated with WEMD is flatter or has a larger basin of attraction compared with that for the Euclidean distance" and [abstract] "The induced loss function enjoys a more benign landscape than its Euclidean counterpart"

### Mechanism 2
- Claim: Bayesian optimization can efficiently find global optimizers of the Wasserstein-based alignment objective without requiring gradients.
- Mechanism: Uses Gaussian process surrogate models to approximate the loss function landscape, enabling exploration with fewer function evaluations than exhaustive search.
- Core assumption: The loss function is smooth enough that a GP surrogate with squared exponential covariance provides a good approximation.
- Evidence anchors: [section] "Bayesian optimization is an iterative procedure that searches for an optimizer of (6) by solving instead a sequence of simpler surrogate problems" and "our numerical experiments in Section 4.2 show that a total of T=200 iterations would suffice for accurate rotational alignment" and [abstract] "Bayesian optimization is employed for computation" and "achieves improved accuracy and efficiency over existing algorithms"

### Mechanism 3
- Claim: Wavelet approximation of W1 distance enables practical computation for large 3D volumes.
- Mechanism: Replaces exact W1 computation with a wavelet-based approximation that scales as O(N) instead of O(N³ log N).
- Core assumption: The wavelet approximation preserves the essential properties of W1 distance while being computationally tractable.
- Evidence anchors: [section] "the wavelet earth mover's distance (WEMD) (Shirdhonkar and Jacobs, 2008) is defined as ∥φ1-φ2∥WEMD = ∑λ 2^(-j(1+n/2))|Wφ1(λ)-Wφ2(λ)|" and "Such an approximation has the additional advantage that the distance (14) can be defined for density maps that take negative values" and [abstract] "The method employs Bayesian optimization for efficient computation without requiring gradient information"

## Foundational Learning

- Gaussian Processes:
  - Why needed here: To model the unknown loss function and construct acquisition functions for Bayesian optimization
  - Quick check question: How does the choice of covariance function affect the smoothness assumptions of the GP model?

- Manifold Optimization:
  - Why needed here: To optimize the acquisition function over the non-Euclidean space SO(3)
  - Quick check question: What is the relationship between the Euclidean gradient and the Riemannian gradient on SO(3)?

- Optimal Transport:
  - Why needed here: To understand why Wasserstein distance is more appropriate than L2 for measuring similarity between rigid transformations
  - Quick check question: How does the W1 distance between a function and its translation relate to the translation magnitude?

## Architecture Onboarding

- Component map:
  Input 3D density maps V1, V2 -> Preprocessing (downsampling, centering) -> Bayesian optimization loop with GP surrogate and acquisition function -> WEMD (wavelet approximation of W1) or L2 distance loss -> Output estimated rotation matrix Rest (with optional local refinement)

- Critical path:
  1. Initialize GP model and first candidate rotation
  2. Evaluate loss function at candidate rotations
  3. Update GP surrogate with new observations
  4. Optimize acquisition function to select next candidate
  5. Repeat until convergence or max iterations
  6. Return best candidate with optional local refinement

- Design tradeoffs:
  - Accuracy vs. speed: More iterations improve accuracy but increase computation time
  - WEMD vs. L2: WEMD better for clean data, L2 more robust to noise
  - Downsampling level: Higher resolution improves accuracy but increases computational cost

- Failure signatures:
  - Poor convergence: GP surrogate fails to capture loss landscape complexity
  - Incorrect alignment: Loss function is not rotation-invariant enough or heterogeneous volumes cause issues
  - High variance in results: Insufficient sampling of SO(3) or unstable optimization of acquisition function

- First 3 experiments:
  1. Test on a simple rotation of a known volume (e.g., EMD-3683) with clean data to verify basic functionality
  2. Compare WEMD vs. L2 versions on the same dataset to observe differences in accuracy and robustness
  3. Evaluate performance under different downsampling levels (32 vs 64) to understand the accuracy-speed tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the Bayesian optimization framework be extended to handle translation estimation alongside rotation?
- Basis in paper: [explicit] The paper mentions that translation can be recovered by centering the density maps, but discusses the possibility of extending the framework to the product space B×SO(3) for joint estimation.
- Why unresolved: The authors note that Bayesian optimization is known to work better in lower dimensions, and adding the translation search space doubles the dimensionality, potentially leading to slow exploration and poor recovery.
- What evidence would resolve it: Experiments comparing the performance of the extended framework with separate translation and rotation estimation on both synthetic and real datasets, showing the trade-offs in accuracy and computational efficiency.

### Open Question 2
- Question: What loss functions are most effective for aligning heterogeneous pairs of volumes, and how can they be incorporated into the Bayesian optimization framework?
- Basis in paper: [explicit] The authors discuss the potential need for new distance functions that only compare the shared components in heterogeneous volumes, and note that their algorithmic framework can be applied to arbitrary loss functions.
- Why unresolved: The paper does not propose specific loss functions for heterogeneous alignment or test them in the Bayesian optimization framework.
- What evidence would resolve it: Development and testing of novel loss functions designed for heterogeneous pairs, implemented within the Bayesian optimization framework, with comparisons to existing methods on real cryo-EM datasets with conformational heterogeneity.

### Open Question 3
- Question: How does the choice of wavelet basis affect the performance of the WEMD approximation in the alignment algorithm?
- Basis in paper: [explicit] The authors use the sym3 wavelet with maximum scale levels = 6 for computing the WEMD distance, but do not explore other wavelet choices.
- Why unresolved: The paper does not investigate the impact of different wavelet bases on alignment accuracy or computational efficiency.
- What evidence would resolve it: Systematic experiments comparing alignment performance using different wavelet bases (e.g., Haar, Daubechies, Coiflets) on the same datasets, analyzing both accuracy and runtime.

## Limitations
- Method relies on strong assumptions about density map smoothness and may struggle with heterogeneous volumes or highly noisy data
- Wavelet approximation of W1 distance may not capture all relevant features for certain protein structures
- Bayesian optimization framework requires careful tuning of hyperparameters for different datasets

## Confidence
- **High Confidence**: The theoretical foundation linking Wasserstein distance to benign loss landscapes (Mechanisms 1 and 3) is well-supported by mathematical analysis and numerical experiments
- **Medium Confidence**: Claims about improved accuracy and efficiency on real cryo-EM data are supported by experiments but may be dataset-dependent
- **Low Confidence**: The method's limitations with heterogeneous volumes are mentioned but not thoroughly explored, and the impact of GP hyperparameters on different datasets is not fully characterized

## Next Checks
1. Evaluate the algorithm on a diverse set of protein pairs with significant structural differences to assess its limitations and compare WEMD vs. L2 performance
2. Systematically vary noise levels and types (Gaussian, Poisson) to quantify the method's robustness and identify failure thresholds
3. Perform a grid search over GP kernel hyperparameters (σ, ℓ) and acquisition function parameters to understand their impact on convergence and accuracy across different protein datasets