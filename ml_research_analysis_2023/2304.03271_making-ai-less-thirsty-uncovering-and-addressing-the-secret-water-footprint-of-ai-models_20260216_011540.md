---
ver: rpa2
title: 'Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint
  of AI Models'
arxiv_id: '2304.03271'
source_url: https://arxiv.org/abs/2304.03271
tags:
- water
- footprint
- data
- carbon
- on-site
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper estimates the water footprint of AI models like GPT-3
  and LaMDA, finding that training GPT-3 in US data centers consumes 700,000 liters
  of clean freshwater, while LaMDA training can consume millions of liters. The study
  presents a principled methodology that accounts for the spatial-temporal diversity
  of water usage effectiveness (WUE) in data centers, considering both on-site cooling
  and off-site electricity generation.
---

# Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models

## Quick Facts
- arXiv ID: 2304.03271
- Source URL: https://arxiv.org/abs/2304.03271
- Reference count: 40
- Key outcome: Training GPT-3 consumes 700,000 liters of clean freshwater; LaMDA training can consume millions of liters, with significant spatial-temporal variation

## Executive Summary
This paper reveals the substantial water footprint of AI model training, estimating that GPT-3 training consumes 700,000 liters of freshwater and LaMDA training millions of liters. The study presents a principled methodology that accounts for spatial-temporal diversity in water usage effectiveness (WUE) in data centers, considering both on-site cooling and off-site electricity generation. Crucially, the research demonstrates that "when" and "where" AI models are trained significantly impacts their water footprint, with potential variations up to 3x. The paper calls for increased transparency from AI developers and data center operators regarding runtime WUE and training locations, emphasizing that addressing water footprint alongside carbon footprint is essential for truly sustainable AI.

## Method Summary
The paper develops a methodology to estimate AI models' water footprint by accounting for both on-site direct water consumption for cooling and off-site indirect water consumption through electricity generation. The approach uses an empirical model for on-site WUE based on wet bulb temperature and cycles of concentration, while off-site WUE is calculated using weighted average electricity generation water intensity factors (EWIF) based on local energy fuel mixes. The methodology applies these models to estimate the total water footprint of AI training by multiplying energy consumption with the respective WUEs across different times and locations.

## Key Results
- GPT-3 training in US data centers consumes approximately 700,000 liters of clean freshwater
- LaMDA training water footprint varies by up to 3x depending on training location and month
- Water and carbon efficiency optimizations can be in conflict, requiring simultaneous consideration of both metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Water footprint varies by location and time due to spatially-temporal diversity in WUE
- Mechanism: The paper models on-site WUE as a function of wet bulb temperature and off-site WUE as a function of local energy fuel mix. By exploiting these variations, scheduling AI training/inference at optimal times and locations can reduce total water footprint.
- Core assumption: WUE can be accurately modeled using wet bulb temperature and energy fuel mix data, and these factors vary significantly enough to create exploitable differences.
- Evidence anchors:
  - [abstract] "reveals that 'when' and 'where' AI models are trained significantly impacts their water footprint, with potential variations up to 3x"
  - [section] "We now use Google's large language model — LaMDA [...] and consider four different locations [...] Our estimate shows that the total water footprint of training LaMDA is in the order of million liters. Crucially, we see that different training months and data center locations can significantly affect the water footprint"

### Mechanism 2
- Claim: On-site and off-site water footprints must be considered separately for accurate estimation
- Mechanism: On-site water is consumed directly for cooling data center servers, while off-site water is consumed indirectly through electricity generation. These have different drivers (temperature vs. energy fuel mix) and must be modeled separately.
- Core assumption: The separation of on-site and off-site water consumption is meaningful and that their drivers are independent enough to model separately.
- Evidence anchors:
  - [abstract] "accounts for the spatial-temporal diversity of water usage effectiveness (WUE) in data centers, considering both on-site cooling and off-site electricity generation"
  - [section] "Data center water footprint. We first would like to distinguish water consumption from withdrawal... The water consumption in data centers has two parts: on-site direct water and off-site indirect water"

### Mechanism 3
- Claim: Carbon-efficient scheduling may not align with water-efficient scheduling
- Mechanism: Solar energy abundance (good for carbon) often coincides with high temperatures (bad for water), creating conflicts between carbon and water optimization objectives.
- Core assumption: The temporal patterns of energy generation and temperature are sufficiently decoupled to create optimization conflicts.
- Evidence anchors:
  - [abstract] "It also emphasizes the necessity of addressing water footprint alongside carbon footprint to achieve truly sustainable AI, as carbon-efficient scheduling may not align with water efficiency"
  - [section] "While it is impossible to know the actual water footprint without detailed information from Google, our estimate shows that the total water footprint of training LaMDA is in the order of million liters. Crucially, we see that different training months and data center locations can significantly affect the water footprint... For comparison, we also show in Figure 4 the estimated carbon footprint for training LaMDA... While our estimated carbon footprint differs from the value reported by [34], the key message we would like to highlight is that the most carbon-efficient training months and data center location may not be water-efficient"

## Foundational Learning

- Concept: Water Usage Effectiveness (WUE) and Energy Water Intensity Factor (EWIF)
  - Why needed here: These metrics are the foundation for quantifying water footprint in data centers, distinguishing between direct cooling water and indirect generation water
  - Quick check question: If a data center uses 1000 kWh of electricity with a WUE of 3.8 L/kWh and an EWIF of 1.8 L/kWh, what is the total water footprint?
  - Answer: On-site: 1000 × 3.8 = 3800 L; Off-site: 1000 × 1.8 = 1800 L; Total: 5600 L

- Concept: Spatial-temporal diversity in resource consumption
  - Why needed here: The paper's core insight is that resource consumption varies by location and time, creating opportunities for optimization
  - Quick check question: Why might training an AI model in Nevada have lower carbon footprint but higher water footprint than training in Oregon?
  - Answer: Nevada has high solar energy penetration (good for carbon) but also high temperatures (bad for water cooling efficiency)

- Concept: Supply-side vs. demand-side management
  - Why needed here: The paper contrasts traditional engineering approaches to improve supply-side water efficiency with demand-side management through scheduling
  - Quick check question: What is the key difference between improving cooling tower efficiency and scheduling training during water-efficient hours?
  - Answer: Supply-side improves the efficiency of water use for a given demand, while demand-side reduces the total demand by choosing optimal times

## Architecture Onboarding

- Component map: Weather data collection -> Energy fuel mix data collection -> WUE modeling -> Water footprint calculation -> Scheduling optimization
- Critical path: 1) Collect real-time weather and energy grid data 2) Estimate AI model energy consumption 3) Calculate WUE for each time/location 4) Optimize scheduling to minimize total water footprint
- Design tradeoffs: Accuracy vs. complexity in WUE models; carbon vs. water optimization conflicts; real-time vs. batch processing requirements
- Failure signatures: Inaccurate water footprint estimates from poor WUE models; suboptimal scheduling from stale energy consumption data; missed optimization opportunities from delayed weather/grid data
- First 3 experiments: 1) Implement basic WUE model using temperature data and validate against known data center consumption 2) Create simple scheduler shifting training to nighttime hours and measure water savings 3) Compare carbon vs. water efficiency for different geographic locations using public API data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can AI model developers effectively balance water efficiency and carbon efficiency when scheduling training across different geographic locations and times?
- Basis in paper: [explicit] The paper highlights that carbon-efficient scheduling of AI model training may not enable truly sustainable AI due to the spatial-temporal diversity of water usage effectiveness (WUE).
- Why unresolved: The paper demonstrates that water and carbon footprints do not align well temporally or spatially, presenting a conflict between "follow the sun" for carbon efficiency and "unfollow the sun" for water efficiency. No clear solution is provided for reconciling these conflicts.
- What evidence would resolve it: Empirical studies comparing different scheduling strategies that optimize both water and carbon footprints, and analysis of trade-offs between the two metrics across various geographic locations and time periods.

### Open Question 2
- Question: What specific operational data and transparency measures are needed from data center operators to enable accurate estimation of AI models' water footprints?
- Basis in paper: [explicit] The paper emphasizes the need for increased transparency from AI model developers and data center operators regarding runtime WUE and training locations.
- Why unresolved: While the paper suggests the importance of transparency, it does not specify which exact metrics or data points would be most valuable for accurate water footprint estimation.
- What evidence would resolve it: Detailed case studies of data centers providing comprehensive operational data, and analysis of how different data points impact the accuracy of water footprint calculations.

### Open Question 3
- Question: How can federated learning be optimized to reduce water footprint while maintaining model performance?
- Basis in paper: [explicit] The paper mentions that federated learning can leverage the spatial-temporal diversity of off-site WUE to reduce the total water footprint, but doesn't provide specific optimization strategies.
- Why unresolved: The paper only briefly mentions the potential of federated learning for water efficiency without exploring how to actually implement water-conscious scheduling in local AI model training.
- What evidence would resolve it: Comparative studies of federated learning implementations with and without water-conscious scheduling, and analysis of the trade-offs between water efficiency, model performance, and communication overhead.

## Limitations
- Critical runtime data (WUE, PUE, exact training locations/times) are not publicly disclosed by major AI companies and data center operators
- The on-site WUE model based on wet bulb temperature may not capture the full complexity of real-world data center operations
- Water footprint estimates rely on empirical models rather than measured values, introducing uncertainty

## Confidence
- High confidence: The fundamental insight that AI training has substantial water footprints, and that "when" and "where" training occurs matters significantly
- Medium confidence: The specific water footprint estimates (700,000 liters for GPT-3, millions for LaMDA)
- Medium confidence: The claim that carbon-efficient scheduling may conflict with water-efficient scheduling

## Next Checks
1. Obtain actual runtime WUE measurements from data center operators for at least one major AI training run to validate the empirical models used in this paper
2. Conduct a controlled experiment training the same AI model in different geographic locations and seasons to empirically measure the spatial-temporal variation in water footprint
3. Develop and validate a comprehensive model that simultaneously optimizes for both carbon and water efficiency to quantify the true magnitude of potential conflicts between these objectives