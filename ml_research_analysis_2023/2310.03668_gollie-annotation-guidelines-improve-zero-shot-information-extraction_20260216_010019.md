---
ver: rpa2
title: 'GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction'
arxiv_id: '2310.03668'
source_url: https://arxiv.org/abs/2310.03668
tags:
- guidelines
- https
- language
- computational
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GoLLIE, a large language model fine-tuned
  to follow annotation guidelines for zero-shot information extraction. By representing
  tasks as Python code and adding regularization techniques, GoLLIE achieves state-of-the-art
  zero-shot results on 15 datasets across 5 domains, outperforming baselines by an
  average of 13 F1 points.
---

# GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction

## Quick Facts
- **arXiv ID**: 2310.03668
- **Source URL**: https://arxiv.org/abs/2310.03668
- **Reference count**: 40
- **Primary result**: Achieves state-of-the-art zero-shot IE results, outperforming baselines by an average of 13 F1 points

## Executive Summary
This paper introduces GoLLIE, a large language model fine-tuned to follow annotation guidelines for zero-shot information extraction. By representing tasks as Python code with docstrings for guidelines and adding regularization techniques, GoLLIE achieves state-of-the-art zero-shot results on 15 datasets across 5 domains. The method enables high-performance information extraction without costly manual annotations, reducing dependence on task-specific data.

## Method Summary
GoLLIE fine-tunes Code-LLaMA using QLoRA on 12 datasets where tasks are represented as Python code with schema definitions, guidelines as docstrings, and representative candidates as comments. The model is trained with regularization techniques including class order shuffling, dropout, paraphrasing, candidate sampling, and masking to prevent memorization. The fine-tuning process uses batch size 32, learning rate 3e-4, and cosine scheduler for 3 epochs. Zero-shot evaluation is performed on 15 held-out datasets spanning 5 domains.

## Key Results
- Outperforms baseline Code-LLaMA by an average of 13 F1 points on zero-shot IE tasks
- Shows consistent improvements across all 5 task types (NER, RE, EE, EAE, SF)
- Ablation study confirms that detailed guidelines are key for good performance

## Why This Works (Mechanism)

### Mechanism 1: Guidelines as Explicit Task Specification
LLMs struggle to follow annotation guidelines out-of-the-box, but fine-tuning them to attend to guidelines improves zero-shot performance. GoLLIE fine-tunes the model on tasks where guidelines are explicitly represented as docstrings and representative candidates as code comments, forcing the model to learn to parse and apply the guidelines rather than relying on implicit label knowledge.

### Mechanism 2: Python Code Representation as Unified Format
Representing tasks as Python code provides a clear, human-readable, and easily parsed structure that LLMs can handle effectively. GoLLIE uses Python dataclasses to represent labels, docstrings for guidelines, and lists of instances for annotations, making it easier for the model to understand task structure.

### Mechanism 3: Regularization Techniques to Prevent Memorization
Applying noise during training prevents the model from memorizing specific datasets and encourages it to learn to follow guidelines. GoLLIE uses class order shuffling, class dropout, guideline paraphrasing, representative candidate sampling, and class name masking to prevent overfitting to specific task definitions.

## Foundational Learning

**Concept: Fine-tuning vs. Pretraining**
- Why needed here: Understanding the difference between pretraining and fine-tuning is crucial for grasping how GoLLIE improves zero-shot performance. Pretraining gives the model general language understanding, while fine-tuning adapts it to specific tasks.
- Quick check question: What is the main difference between pretraining and fine-tuning a language model?

**Concept: Information Extraction (IE) Tasks**
- Why needed here: GoLLIE is designed for IE tasks, so understanding the different types of IE tasks (NER, RE, EE, EAE, SF) and their characteristics is essential.
- Quick check question: What are the main types of Information Extraction tasks, and how do they differ?

**Concept: Zero-shot Learning**
- Why needed here: GoLLIE aims to improve zero-shot IE, so understanding what zero-shot learning means and its challenges is important.
- Quick check question: What is zero-shot learning, and why is it challenging for Information Extraction tasks?

## Architecture Onboarding

**Component map**:
- Backbone LLM (Code-LLaMA) -> Fine-tuning dataset (diverse IE tasks with guidelines) -> Input representation (Python code with docstrings and comments) -> Output representation (Python code with annotations) -> Regularization techniques (shuffling, dropout, paraphrasing, masking) -> Evaluation datasets (diverse IE tasks without guidelines)

**Critical path**:
1. Prepare fine-tuning data with guidelines represented as Python code
2. Fine-tune the backbone LLM on the fine-tuning data using QLoRA
3. Evaluate the fine-tuned model on zero-shot IE tasks
4. Analyze the results and identify areas for improvement

**Design tradeoffs**:
- Using Python code representation provides a clear and structured format but may limit the model's ability to handle more complex or nuanced guidelines
- Regularization techniques prevent memorization but may also hinder the model's ability to learn effectively
- Fine-tuning on a diverse set of tasks improves generalization but may also introduce noise and complexity

**Failure signatures**:
- If the model generates invalid Python code, it may indicate issues with the input representation or the fine-tuning process
- If the model performs poorly on zero-shot tasks, it may suggest that the fine-tuning data is not diverse enough or that the regularization techniques are too strong
- If the model overfits to the fine-tuning data, it may indicate that the regularization techniques are too weak or that the fine-tuning process needs to be adjusted

**First 3 experiments**:
1. Fine-tune the model on a small subset of the fine-tuning data and evaluate its performance on a held-out validation set
2. Gradually increase the size of the fine-tuning data and monitor the model's performance on the validation set
3. Experiment with different regularization techniques and evaluate their impact on the model's zero-shot performance

## Open Questions the Paper Calls Out

1. How does the performance of GoLLIE compare to fine-tuned encoder-only models like XLM-RoBERTa and mDEBERTA on IE tasks?
2. How does GoLLIE perform on IE tasks with very ambiguous or coarse-grained labels, such as the "MISCELLANEOUS" category in CoNLL03?
3. What is the impact of increasing the diversity and size of the fine-tuning datasets on GoLLIE's performance, particularly for labels with strong preconceptions like "POLITICAL PARTY"?

## Limitations

- Fine-tuning datasets are heavily skewed toward News and Biomedical domains, raising concerns about generalizability
- The paper doesn't directly compare against encoder-only models which remain most effective for IE tasks
- Regularization techniques are applied together without isolating individual impacts on performance

## Confidence

**Confidence: Medium** on the core claim that guidelines-as-code representation is the primary driver of performance gains
**Confidence: Low** regarding the generalizability of results across different domains
**Confidence: Medium** in the effectiveness of regularization techniques

## Next Checks

1. **Cross-domain transfer validation**: Evaluate GoLLIE's performance when fine-tuned on non-News/Biomedical datasets and tested on News/Biomedical domains
2. **Alternative representation comparison**: Implement the same fine-tuning pipeline using alternative task representations (JSON schema, XML, or plain text instructions)
3. **Fine-tuning data efficiency analysis**: Systematically reduce the amount of fine-tuning data while maintaining regularization techniques to identify minimum effective training set size