---
ver: rpa2
title: Creating Multi-Level Skill Hierarchies in Reinforcement Learning
arxiv_id: '2306.09980'
source_url: https://arxiv.org/abs/2306.09980
tags:
- hierarchy
- skills
- learning
- louvain
- level
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes an approach to discover multi-level skill hierarchies
  in reinforcement learning by leveraging graph partitioning. The key idea is to partition
  the state-transition graph using modularity maximization to expose the structure
  of the environment at multiple scales.
---

# Creating Multi-Level Skill Hierarchies in Reinforcement Learning

## Quick Facts
- arXiv ID: 2306.09980
- Source URL: https://arxiv.org/abs/2306.09980
- Reference count: 40
- One-line primary result: Proposes a principled approach to discover multi-level skill hierarchies in reinforcement learning using modularity maximization and graph partitioning.

## Executive Summary
This paper presents a method for discovering multi-level skill hierarchies in reinforcement learning by leveraging graph partitioning techniques. The core idea is to use modularity maximization to partition the state-transition graph into clusters that are densely connected internally but sparsely connected externally, creating natural bottleneck structures. These partitions define regions of the state space that are easy to navigate within but difficult to navigate between. Skills are then defined to efficiently move the agent between neighboring clusters, with lower-level skills naturally composing into higher-level ones. The approach is evaluated across multiple environments and demonstrates improved learning performance compared to baselines.

## Method Summary
The method converts reinforcement learning environments into state-transition graphs, then applies the Louvain algorithm to find partitions that maximize modularity. This produces a hierarchical clustering of the state space. Skills are defined for each level of the hierarchy to navigate between neighboring clusters. Lower-level skills move agents between fine-grained clusters (e.g., regions within a room), while higher-level skills compose these to move between coarse-grained clusters (e.g., between rooms). The resulting skill hierarchies are then used with macro-Q learning and intra-option learning to train agents. The approach is evaluated across seven environments of varying complexity.

## Key Results
- Louvain skills outperform baselines (Eigenoptions, Node Betweenness, Label Propagation, Edge Betweenness, Primitive actions) in most environments
- The full Louvain hierarchy achieves the best learning performance across environments
- The approach scales well to larger domains, with Louvain algorithm successfully applied to graphs with millions of nodes and billions of edges
- Individual levels of the hierarchy show improved learning speed compared to primitive actions, though not as fast as the full hierarchy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modularity maximization partitions the state-transition graph into clusters that are densely connected internally but sparsely connected externally, creating natural bottleneck structures.
- Mechanism: The Louvain algorithm iteratively optimizes modularity by moving nodes between clusters to maximize the difference between actual and expected intra-cluster edge density. This produces partitions where clusters represent well-connected regions of the state space.
- Core assumption: The state-transition graph accurately captures the structure of the environment's navigability.
- Evidence anchors:
  - [abstract] "Our approach uses modularity maximisation as a central organising principle to expose the structure of the interaction graph at multiple levels of abstraction."
  - [section 4] "A partition that maximises modularity will have dense connections within its clusters but sparse connections between them."

### Mechanism 2
- Claim: Skills defined to navigate between neighboring clusters at each hierarchical level naturally compose into higher-level skills.
- Mechanism: Lower-level skills move agents between fine-grained clusters (e.g., regions within a room), while higher-level skills compose these to move between coarse-grained clusters (e.g., between rooms). This composition follows the hierarchical cluster structure produced by Louvain.
- Core assumption: The cluster hierarchy produced by Louvain has meaningful parent-child relationships where higher-level clusters are unions of lower-level clusters.
- Evidence anchors:
  - [section 4] "Taking advantage of the natural hierarchical structure of the partitions produced by the Louvain algorithm, we compose the skills at one level of the hierarchy to define the skills at the next level."
  - [section 5] "Moving up the hierarchy, at the fourth level, two of these rooms are joined together into a single cluster."

### Mechanism 3
- Claim: Multi-level skill hierarchies improve learning performance by enabling modular updates and temporal abstraction.
- Mechanism: When lower-level skills improve through learning, all higher-level skills that call them automatically benefit. Additionally, skills provide temporal abstraction, allowing agents to plan and learn at multiple time scales.
- Core assumption: The reinforcement learning algorithm (macro-Q and intra-option learning) can properly utilize hierarchical skill structures.
- Evidence anchors:
  - [section 3] "Multi-level action hierarchies naturally support the ability to act, plan, explore, and learn over varying timescales, offering many concrete benefits over unstructured collections of actions."
  - [section 5] "Furthermore, the agents using individual levels of the Louvain hierarchy learn more quickly than the primitive agent but not as quickly as the agent using the full Louvain hierarchy."

## Foundational Learning

- Concept: Modularity maximization in graph theory
  - Why needed here: The core technique for discovering meaningful partitions in the state-transition graph relies on understanding modularity as a quality measure for graph clustering.
  - Quick check question: What does modularity measure in the context of graph partitioning?

- Concept: Markov Decision Processes and state-transition graphs
  - Why needed here: The method converts MDPs into state-transition graphs, so understanding this conversion and the properties of such graphs is essential.
  - Quick check question: How is a state-transition graph constructed from an MDP?

- Concept: Hierarchical reinforcement learning and temporal abstraction
  - Why needed here: The proposed approach creates multi-level hierarchies of skills, which requires understanding how temporal abstraction works in RL and why hierarchies are beneficial.
  - Quick check question: What are the benefits of organizing skills into a hierarchy rather than using a flat collection?

## Architecture Onboarding

- Component map: State-transition graph construction → Louvain clustering → Skill definition (per level) → Skill hierarchy assembly → RL agent with hierarchical options → Training with macro-Q and intra-option learning
- Critical path: The bottleneck is the Louvain clustering step, which determines the quality of the skill hierarchy. The entire pipeline depends on producing meaningful partitions.
- Design tradeoffs: Using more partitions (lower resolution parameter ρ) creates deeper hierarchies with more levels but increases computational cost and may produce overly fine-grained skills. Fewer partitions (higher ρ) are computationally cheaper but may miss important hierarchical structure.
- Failure signatures: Poor learning performance could indicate either bad clustering (wrong ρ value, disconnected graph) or implementation errors in skill composition. If all skills perform similarly to primitive actions, the hierarchy may be too shallow or the partitions too coarse.
- First 3 experiments:
  1. Verify Louvain clustering produces expected partitions in a simple gridworld (e.g., Rooms environment) with ρ=0.05
  2. Test skill definition by manually verifying that skills move agents between correct cluster boundaries
  3. Compare learning performance of a flat skill arrangement versus hierarchical arrangement using the same set of skills

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of Louvain skills compare to other skill discovery methods in environments with sparse rewards?
- Basis in paper: [inferred] The paper compares Louvain skills to other methods in various environments, but does not explicitly mention environments with sparse rewards.
- Why unresolved: The paper does not provide experiments or analysis on how Louvain skills perform in environments with sparse rewards, which is a common challenge in reinforcement learning.
- What evidence would resolve it: Experiments comparing Louvain skills to other methods in environments with sparse rewards would provide evidence of their performance in such scenarios.

### Open Question 2
- Question: Can the Louvain algorithm be modified to handle dynamic environments where the state-transition graph changes over time?
- Basis in paper: [inferred] The paper discusses incremental learning of Louvain skills, but does not explicitly address dynamic environments where the state-transition graph changes.
- Why unresolved: The paper does not provide a method or analysis for adapting the Louvain algorithm to dynamic environments, which is an important consideration for real-world applications.
- What evidence would resolve it: Experiments demonstrating the effectiveness of a modified Louvain algorithm in dynamic environments would provide evidence of its applicability in such scenarios.

### Open Question 3
- Question: How do the computational requirements of Louvain skills scale with the size and complexity of the state space?
- Basis in paper: [explicit] The paper mentions that the Louvain algorithm has been successfully applied to graphs with millions of nodes and billions of edges, but does not provide a detailed analysis of computational requirements.
- Why unresolved: The paper does not provide a comprehensive analysis of the computational complexity of Louvain skills, which is important for understanding their scalability and applicability to large-scale problems.
- What evidence would resolve it: Experiments measuring the computational requirements of Louvain skills as the size and complexity of the state space increase would provide evidence of their scalability.

## Limitations

- The approach assumes the state-transition graph accurately represents the environment's structure, which may not hold in stochastic or partially observable environments.
- The Louvain algorithm's resolution parameter ρ requires careful tuning - too low produces overly fine-grained hierarchies, while too high may miss important hierarchical structure.
- The paper lacks comparisons to recent unsupervised skill discovery methods beyond the cited baselines.

## Confidence

- **High confidence**: The mechanism of modularity maximization producing bottleneck structures (Mechanism 1) is well-established in graph theory literature.
- **Medium confidence**: The skill composition mechanism (Mechanism 2) is theoretically sound but depends heavily on the quality of Louvain partitions, which can vary with hyperparameters.
- **Medium confidence**: The learning performance benefits (Mechanism 3) are demonstrated empirically but could be influenced by implementation details of the RL algorithms.

## Next Checks

1. **Hyperparameter sensitivity analysis**: Systematically vary the resolution parameter ρ across environments to quantify its impact on learning performance and skill quality.
2. **Scalability test**: Apply the approach to environments with 10x more states than the current largest domain to verify the claimed scaling properties.
3. **Baselines comparison**: Implement and compare against more recent unsupervised skill discovery methods (e.g., DIAYN, DADS) to establish the relative performance of the modularity-based approach.