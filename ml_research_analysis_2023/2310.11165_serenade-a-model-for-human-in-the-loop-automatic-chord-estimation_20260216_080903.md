---
ver: rpa2
title: 'Serenade: A Model for Human-in-the-loop Automatic Chord Estimation'
arxiv_id: '2310.11165'
source_url: https://arxiv.org/abs/2310.11165
tags:
- chord
- oracle
- music
- root
- annotations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes SERENADE, a novel human-in-the-loop approach
  to automatic chord estimation that leverages autoregressive modeling. By having
  a human annotate parts with low model confidence and then adjusting predictions
  based on this guidance, SERENADE achieves improved harmonic analysis performance
  over a model-only approach.
---

# Serenade: A Model for Human-in-the-loop Automatic Chord Estimation

## Quick Facts
- arXiv ID: 2310.11165
- Source URL: https://arxiv.org/abs/2310.11165
- Reference count: 34
- One-line result: Novel human-in-the-loop approach using autoregressive modeling achieves ROI > 1 for automatic chord estimation

## Executive Summary
This paper introduces SERENADE, a novel human-in-the-loop approach to automatic chord estimation that leverages autoregressive modeling. The method involves having a human annotate parts with low model confidence, then adjusting predictions based on this guidance. Experiments on popular music datasets show that the human contribution is amplified by the second, constrained prediction of the model, resulting in a Return On Investment larger than 1. This suggests that a human-in-the-loop approach can lead to more accurate and efficient chord annotation.

## Method Summary
SERENADE uses a three-layer autoregressive model (two hidden, one visible) with bidirectional processing to predict 6 sub-labels of chord information simultaneously. The model employs teacher forcing during training and uses 1D DenseNet CRNN for feature extraction from chroma features. Human intervention is triggered based on low-confidence predictions, and corrections are propagated through the model's hidden state via autoregressive modeling. The approach is evaluated on a dataset of 60-second audio excerpts from Billboard and Beatles songs, comparing against traditional ACE methods.

## Key Results
- SERENADE achieves ROI > 1 by amplifying human corrections through autoregressive propagation
- Confidence-based human intervention strategy improves accuracy over model-only approach
- Joint prediction of sub-labels (key root, chord root, quality, etc.) improves harmonic coherence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The autoregressive model improves accuracy by propagating corrections through its hidden state, enabling ROI > 1.
- Mechanism: When a human corrects a low-confidence prediction, the model's hidden state is updated via teacher forcing, allowing the correction to influence future predictions at the same and subsequent timesteps.
- Core assumption: The model's hidden state effectively captures and propagates harmonic context over time.
- Evidence anchors:
  - [abstract]: "The human contribution is amplified by the second, constrained prediction of the model."
  - [section]: "Due to its autoregressive nature, a correction at one specific sub-label can be propagated to different sub-labels at the same time step and also to other time steps."
  - [corpus]: Weak. No direct citations on ROI amplification in autoregressive chord estimation found.
- Break condition: If the hidden state fails to maintain coherence over time, corrections may not propagate effectively, reducing ROI.

### Mechanism 2
- Claim: Using low-confidence predictions as cues for human intervention improves annotation efficiency.
- Mechanism: The model identifies predictions where its confidence is below a threshold (e.g., 0.35), suggesting these are likely errors and prioritizing them for human review.
- Core assumption: Low-confidence predictions correlate with higher error rates.
- Evidence anchors:
  - [section]: "The assumption that the outputs with low probability are the ones that are most likely to be wrong is verified: a threshold up to 0.35 always provides ROI larger than 1."
  - [corpus]: Missing. No direct evidence from corpus on confidence-error correlation in chord estimation.
- Break condition: If the model's confidence estimates are poorly calibrated, low-confidence predictions may not reliably indicate errors.

### Mechanism 3
- Claim: Joint prediction of sub-labels (key root, chord root, quality, etc.) improves overall harmonic coherence.
- Mechanism: The model's architecture predicts multiple related harmonic features simultaneously, allowing constraints between them (e.g., chord root and key root determine droot) to enforce consistency.
- Core assumption: Harmonic features are interdependent and benefit from joint modeling.
- Evidence anchors:
  - [section]: "A small positive effect has been The Beatles by our experiments in Section IV-B."
  - [section]: "the choice of the quality of the chord at timestep t was informed by the sampled key, tonicisation, and droot, therefore avoiding incoherent outputs."
  - [corpus]: Weak. No direct citations on joint sub-label prediction benefits in chord estimation.
- Break condition: If sub-labels are incorrectly modeled as independent, joint prediction may not improve coherence.

## Foundational Learning

- Concept: Autoregressive modeling
  - Why needed here: To propagate corrections through time and enable ROI > 1.
  - Quick check question: How does the hidden state update when a new prediction is sampled?
- Concept: Confidence calibration
  - Why needed here: To determine when human intervention is most likely to improve accuracy.
  - Quick check question: What is the relationship between model confidence and prediction error rate?
- Concept: Multi-label classification
  - Why needed here: To jointly predict related harmonic features and enforce consistency.
  - Quick check question: How do constraints between sub-labels (e.g., chord root and key root) affect model design?

## Architecture Onboarding

- Component map: Chroma features (24-dim) -> 1D DenseNet encoder -> Separable NADE (bidirectional) -> 6 sub-labels
- Critical path: Feature extraction → NADE prediction → human correction (if needed) → updated prediction
- Design tradeoffs:
  - Separable vs. flattened NADE: Separable performs better but increases complexity.
  - Bidirectional vs. unidirectional: Bidirectional improves accuracy but doubles computation.
  - Confidence threshold: Lower thresholds increase human workload; higher thresholds reduce ROI.
- Failure signatures:
  - Low ROI: Human corrections not propagating through hidden state.
  - High false positive rate: Model flagging correct predictions as low-confidence.
  - Incoherent predictions: Sub-labels not respecting harmonic constraints.
- First 3 experiments:
  1. Train model on a small subset of data and verify basic accuracy metrics.
  2. Simulate oracle corrections and measure ROI at different confidence thresholds.
  3. Test model's ability to propagate corrections across time steps.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the human-in-the-loop formalism be improved to better represent the actual effort provided by a human annotator?
- Basis in paper: [explicit] The paper mentions that the current oracle cost may not be a fair representation of the actual effort provided by a human annotator, as it treats frames independently and all harmonic elements equally.
- Why unresolved: The current cost metric does not account for the varying effort required to annotate different harmonic elements or segments of contiguous frames.
- What evidence would resolve it: Developing and testing a refined oracle cost metric that accounts for the effort required to annotate different harmonic elements and segments of contiguous frames, and demonstrating that it provides a more accurate representation of human effort.

### Open Question 2
- Question: Can hierarchical architectures and representations improve the long-term coherence of the SERENADE model?
- Basis in paper: [inferred] The paper suggests that hierarchical architectures and representations have shown promising improvements in long-term coherence modeling in generative models, which may also benefit SERENADE.
- Why unresolved: The current SERENADE model does not incorporate hierarchical architectures and representations, and it is unclear whether such an approach would improve long-term coherence.
- What evidence would resolve it: Implementing hierarchical architectures and representations in the SERENADE model and evaluating its performance on long-term coherence tasks, comparing the results to the current model.

### Open Question 3
- Question: How can the SERENADE model be adapted to handle modal keys and more diverse chord qualities?
- Basis in paper: [explicit] The paper mentions that the current model excludes modal keys and maps less common chord qualities to more common ones, which may limit its applicability to a wider range of music.
- Why unresolved: The current model's limitations in handling modal keys and diverse chord qualities may restrict its performance on a broader range of musical pieces.
- What evidence would resolve it: Extending the SERENADE model to include support for modal keys and a more comprehensive set of chord qualities, and evaluating its performance on a diverse dataset of music with varying harmonic structures.

## Limitations

- The ROI > 1 claim relies on simulated oracle corrections rather than actual human annotation experiments
- The 11-class chord quality reduction may oversimplify the problem space and affect generalizability
- No ablation studies are provided to isolate the contribution of the autoregressive component versus the human-in-the-loop mechanism

## Confidence

- **High confidence**: The core autoregressive architecture and its bidirectional implementation appear technically sound and are well-described.
- **Medium confidence**: The claim that human corrections propagate through the hidden state is plausible but not empirically validated beyond the ROI metric.
- **Low confidence**: The generalization of ROI > 1 to real human annotation scenarios, as no actual human studies are reported.

## Next Checks

1. Conduct a user study with actual human annotators to verify ROI > 1 holds with real human behavior and not just simulated corrections.
2. Perform ablation experiments comparing the full Serenade model against: (a) a non-autoregressive baseline, (b) a model with human corrections but no autoregressive propagation, and (c) a model with autoregressive propagation but no human corrections.
3. Test the model on a held-out dataset with different musical styles to assess robustness of the confidence-based human intervention strategy across diverse musical contexts.