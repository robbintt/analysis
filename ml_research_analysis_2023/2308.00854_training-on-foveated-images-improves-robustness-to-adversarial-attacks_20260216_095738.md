---
ver: rpa2
title: Training on Foveated Images Improves Robustness to Adversarial Attacks
arxiv_id: '2308.00854'
source_url: https://arxiv.org/abs/2308.00854
tags:
- r-blur
- accuracy
- robustness
- adversarial
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "R-Blur, a foveation-based image preprocessing technique, improves\
  \ robustness of deep neural networks (DNNs) to adversarial attacks by simulating\
  \ the human retina\u2019s loss of fidelity in peripheral vision. It adaptively blurs\
  \ and desaturates images based on distance from a fixation point."
---

# Training on Foveated Images Improves Robustness to Adversarial Attacks

## Quick Facts
- arXiv ID: 2308.00854
- Source URL: https://arxiv.org/abs/2308.00854
- Reference count: 39
- Primary result: R-Blur preprocessing improves DNN robustness to adversarial attacks by up to 25 percentage points.

## Executive Summary
R-Blur is a foveation-based image preprocessing technique that improves deep neural network robustness to adversarial attacks by simulating human peripheral vision. The method adaptively blurs and desaturates image regions based on their distance from a fixation point, forcing networks to rely on low-frequency, globally distributed visual cues rather than local, texture-specific patterns. Trained ResNet models using R-Blur achieved up to 25 percentage points higher accuracy on adversarially perturbed data compared to standard training across CIFAR-10, Ecoset, and ImageNet datasets.

## Method Summary
R-Blur transforms input images by simulating peripheral vision degradation through spatially varying Gaussian blur and color desaturation. The technique uses a foveation transform that calculates eccentricity from fixation points, maps this to visual acuity, and applies corresponding blur levels and desaturation weights. During training, images are processed through this transform, creating foveated representations that force the network to learn features invariant to local texture variations. Multi-fixation inference further improves robustness by aggregating predictions from multiple scanpaths across the image.

## Key Results
- R-Blur achieves up to 25 percentage points higher accuracy on adversarially perturbed data compared to standard training
- Outperforms biologically inspired baselines (VOneBlock, R-Warp) on adversarial robustness
- Matches or exceeds adversarial training on non-adversarial corruptions while maintaining certified robustness comparable to randomized smoothing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adaptive foveation reduces reliance on high-frequency features that are often targeted by adversarial perturbations.
- Mechanism: R-Blur blurs and desaturates peripheral regions, forcing the network to rely on low-frequency, globally distributed visual cues rather than local, texture-specific patterns.
- Core assumption: Adversarial attacks exploit vulnerabilities in high-frequency feature detection; reducing reliance on these features improves robustness.
- Evidence anchors:
  - [abstract] "R-Blur... simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point."
  - [section 2.5] "We map the estimated visual acuity at each pixel location... to the standard deviation of the Gaussian kernel... σ(xp,yp) = βWV (1 − D(ex,y))."
- Break condition: If adversarial attacks shift to exploit low-frequency cues, robustness gains would diminish.

### Mechanism 2
- Claim: Training on multiple levels of visual fidelity increases model invariance to corruptions.
- Mechanism: By exposing the model to both high-fidelity foveal and low-fidelity peripheral representations, it learns to classify objects using features that are stable across varying perceptual conditions.
- Core assumption: Human visual robustness is partly due to constant exposure to low-fidelity peripheral vision, which can be mimicked in training data.
- Evidence anchors:
  - [abstract] "we hypothesize that the experience of viewing the world at multiple levels of fidelity... causes human vision to be invariant to low-level features, such as textures, that can be exploited by adversarial attacks."
  - [section 3.3] "Removing the biologically-motivated components of R-Blur harms the robustness."
- Break condition: If low-fidelity features become a new attack vector, robustness may collapse.

### Mechanism 3
- Claim: Multi-fixation inference aggregates diverse viewpoints, improving accuracy under adversarial attacks.
- Mechanism: Scanning the image at multiple fixation points and aggregating logits ensures the model captures information from different regions, mitigating localized adversarial corruptions.
- Core assumption: Adversaries often target localized features; aggregating predictions from multiple scanpaths dilutes their impact.
- Evidence anchors:
  - [section 3.3] "the next most significant factor is evaluating at multiple fixation points which improved robustness significantly compared to a single fixation point in the center of the image."
  - [section 2.4] "To increase the viewing distance we drop the k lowest acuity bins and shift the pixels assigned to them k bins ahead such that the pixels that were in bins 1 through k − 1 are now assigned to bin 1."
- Break condition: If an attack corrupts multiple fixation regions simultaneously, aggregation may fail to recover accuracy.

## Foundational Learning

- Concept: Gaussian blur and its parameterization via standard deviation
  - Why needed here: R-Blur applies spatially varying Gaussian kernels; understanding kernel sizing is crucial to tuning β and acuity mapping.
  - Quick check question: How does changing σ in a Gaussian kernel affect the spread of blur across image regions?

- Concept: Color desaturation and its impact on model feature learning
  - Why needed here: R-Blur modulates color presence based on eccentricity; knowing how CNNs process color vs grayscale informs design choices.
  - Quick check question: What is the effect on CNN activations when grayscale input is mixed with color in different spatial regions?

- Concept: Adversarial training and gradient obfuscation
  - Why needed here: Comparing R-Blur's robustness to AT and ensuring gradients remain usable is essential for fair evaluation.
  - Quick check question: What is the difference between gradient obfuscation and genuine adversarial robustness, and how can it be tested?

## Architecture Onboarding

- Component map: Image -> Gaussian noise -> Color & grayscale copies -> Adaptive Gaussian blur (via eccentricity-acuity mapping) -> Pixel-wise weighted combination -> CNN backbone
- Critical path: The foveation transform (eccentricity calculation, acuity estimation, blurring, desaturation, combination) must be differentiable and applied consistently during training and inference.
- Design tradeoffs: Adaptive blur improves robustness but reduces clean accuracy; multi-fixation increases inference time but improves robustness; desaturation trades color sensitivity for invariance.
- Failure signatures: Severe accuracy drop on clean images suggests over-blurring; lack of robustness improvement suggests blur is too mild or non-adaptive.
- First 3 experiments:
  1. Train a baseline ResNet on CIFAR-10 and measure clean vs adversarial accuracy.
  2. Apply R-Blur with fixed σ blur (non-adaptive) and compare robustness.
  3. Introduce adaptive blur and evaluate accuracy and robustness changes.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does R-Blur improve robustness to adversarial attacks in architectures other than ResNets?
- Basis in paper: [explicit] The paper evaluates R-Blur on MLP-Mixer and ViT architectures in addition to ResNets.
- Why unresolved: While the paper shows improved robustness for MLP-Mixer and ViT, it doesn't extensively compare R-Blur's performance across different architectures or analyze the reasons for any differences.
- What evidence would resolve it: A comprehensive study comparing R-Blur's effectiveness across a wider range of architectures, including analysis of why certain architectures may benefit more from R-Blur than others.

### Open Question 2
- Question: How does R-Blur's robustness generalize to other types of image corruptions beyond those tested in the paper?
- Basis in paper: [explicit] The paper evaluates R-Blur's robustness against common image corruptions but only tests a subset of the 19 proposed by Hendrycks and Dietterich (2019).
- Why unresolved: The paper doesn't explore R-Blur's performance on the full range of common corruptions or on domain-specific corruptions that might be relevant in real-world applications.
- What evidence would resolve it: Testing R-Blur on all 19 common corruptions and additional domain-specific corruptions to assess its generalizability across a broader range of perturbations.

### Open Question 3
- Question: Can the optimal fixation point selection algorithm be improved to further enhance R-Blur's performance?
- Basis in paper: [explicit] The paper mentions that an optimal fixation point selection algorithm could potentially improve R-Blur's performance but doesn't develop one.
- Why unresolved: The paper uses a heuristic approach based on DeepGaze-III for fixation point selection, which may not be optimal. The potential for improvement is acknowledged but not explored.
- What evidence would resolve it: Developing and testing various fixation point selection algorithms, including learned approaches, to determine if they can significantly improve R-Blur's accuracy and robustness compared to the current heuristic method.

## Limitations
- R-Blur implementation details are not fully specified, particularly the foveation transform parameters and multi-fixation inference implementation
- The claim of matching adversarial training is only validated on CIFAR-10, Ecoset, and ImageNet, not larger or more complex datasets
- Hyperparameter tuning details for β scaling and acuity mapping are not provided

## Confidence
- High confidence: Adaptive foveation reduces reliance on high-frequency features targeted by adversarial attacks.
- Medium confidence: Multi-fixation inference aggregates diverse viewpoints to improve robustness.
- Medium confidence: R-Blur improves robustness while maintaining performance on common corruptions.

## Next Checks
1. Implement the R-Blur preprocessing and verify the adaptive blur and desaturation components function as described.
2. Evaluate robustness improvements on a held-out test set not used during hyperparameter tuning.
3. Compare R-Blur's performance against other defense methods (e.g., adversarial training, randomized smoothing) on additional datasets to confirm scalability.