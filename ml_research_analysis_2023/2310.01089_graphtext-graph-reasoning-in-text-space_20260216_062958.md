---
ver: rpa2
title: 'GraphText: Graph Reasoning in Text Space'
arxiv_id: '2310.01089'
source_url: https://arxiv.org/abs/2310.01089
tags:
- graph
- text
- reasoning
- language
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GraphText, a novel framework that bridges
  the gap between large language models (LLMs) and graph machine learning by translating
  graphs into natural language. GraphText constructs a graph-syntax tree for each
  graph, encapsulating both node attributes and inter-node relationships, and traverses
  the tree to generate a graph text sequence.
---

# GraphText: Graph Reasoning in Text Space

## Quick Facts
- arXiv ID: 2310.01089
- Source URL: https://arxiv.org/abs/2310.01089
- Authors: 
- Reference count: 31
- Primary result: GraphText enables training-free graph reasoning by translating graphs into natural language, achieving on par with or surpassing supervised GNNs through in-context learning.

## Executive Summary
This paper introduces GraphText, a novel framework that bridges the gap between large language models (LLMs) and graph machine learning by translating graphs into natural language. GraphText constructs a graph-syntax tree for each graph, encapsulating both node attributes and inter-node relationships, and traverses the tree to generate a graph text sequence. This sequence is then processed by an LLM to treat graph tasks as text generation tasks. The framework offers several advantages, including training-free graph reasoning, where GraphText with ChatGPT achieves on par with or surpassing the performance of supervised-trained graph neural networks through in-context learning. Additionally, GraphText enables interactive graph reasoning, allowing humans and LLMs to communicate using natural language. The method demonstrates the potential of LLMs in graph machine learning and opens up new avenues for research and applications.

## Method Summary
GraphText transforms graph-structured data into sequential natural language by constructing graph-syntax trees that encode node attributes and inter-node relationships. The framework traverses these trees to produce text sequences processed by LLMs via in-context learning or instruction tuning. Key innovations include incorporating graph inductive biases through text attributes (raw features, labels, synthetic propagated features) and relationships (original adjacency, shortest-path distance, feature similarity, personalized pagerank). The method supports both in-context learning for zero-shot performance and instruction tuning for enhanced accuracy across diverse graph datasets.

## Key Results
- GraphText with ChatGPT achieves on par with or surpassing supervised GNNs on node classification tasks without training on graph data
- Incorporating synthetic relationships (feature similarity, shortest-path distance, personalized pagerank) significantly boosts LLM performance across all tested datasets
- Instruction-tuned Llama-2 with GraphText outperforms standard fine-tuned GNNs on text-attributed graphs like Amazon and OGB-MOLPCBA

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GraphText transforms graph-structured data into a sequential natural language representation by constructing a graph-syntax tree.
- Mechanism: The framework first builds a graph-syntax tree that encodes both node attributes and inter-node relationships. Traversal of this tree produces a text sequence in natural language, which an LLM can process as a text generation task.
- Core assumption: A tree structure can capture hierarchical relationships in a graph while producing a one-dimensional sequence when traversed.
- Evidence anchors:
  - [abstract] "GraphText derives a graph-syntax tree for each graph that encapsulates both the node attributes and inter-node relationships. Traversal of the tree yields a graph text sequence..."
  - [section] "Inspired by linguistic syntax trees, we introduce graph-syntax trees as a bridge between relational and sequential data."
  - [corpus] "Found 25 related papers... Average neighbor FMR=0.485, average citations=0.0."
- Break condition: If the tree traversal order fails to preserve meaningful relational information, the LLM cannot correctly infer graph structure from the sequence.

### Mechanism 2
- Claim: Incorporating graph inductive biases into both text attributes and relationships significantly boosts LLM performance on graph tasks.
- Mechanism: GraphText includes text attributes derived from propagated features and labels, and relationships such as feature similarity, shortest-path distance, and personalized pagerank. These elements encode the structural and semantic information that standard GNNs use.
- Core assumption: LLMs can learn to reason with graph structure when provided with text representations that encode common GNN biases like feature propagation and similarity-based aggregation.
- Evidence anchors:
  - [section] "GRAPH TEXT easily incorporates the inductive biases of GNNs through the construction of node text attributes F and relationships R."
  - [section] "The addition of synthetic relationships significantly boosts performance across all datasets."
  - [corpus] "Top related titles: Graph-DPEP... From Nodes to Narratives: Explaining Graph Neural Networks with LLMs..."
- Break condition: If the LLM lacks sufficient training on such structured text representations, it may ignore the graph biases and perform at random chance.

### Mechanism 3
- Claim: Training-free graph reasoning via in-context learning allows a single pre-trained LLM to generalize across diverse graph datasets without task-specific training.
- Mechanism: GraphText encodes each graph into text prompts and uses a single LLM to perform in-context learning, where demonstrations guide the model to infer labels for new nodes or graphs.
- Core assumption: The LLM's pre-training on vast text corpora provides sufficient general reasoning ability to interpret and solve graph tasks when the input is expressed in natural language.
- Evidence anchors:
  - [abstract] "even without training on graph data, GraphText with ChatGPT can achieve on par with, or even surpassing, the performance of supervised-trained graph neural networks through in-context learning."
  - [section] "Setting itself apart from GNNs, GraphText approaches graph reasoning in a graph-shared domain..."
  - [corpus] "Top related titles: UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks..."
- Break condition: If the LLM's parametric knowledge does not cover graph-like reasoning patterns, in-context learning will fail regardless of prompt quality.

## Foundational Learning

- Concept: Graph Syntax Trees
  - Why needed here: They serve as the intermediary structure that translates the non-sequential relational data of graphs into a sequence of natural language nodes, which an LLM can process.
  - Quick check question: How does traversing a graph-syntax tree differ from flattening a graph into a list of nodes and edges?

- Concept: In-Context Learning (ICL)
  - Why needed here: ICL allows the LLM to perform graph reasoning tasks without explicit training on graph data by using a few demonstrations within the prompt.
  - Quick check question: What is the difference between in-context learning and fine-tuning in terms of parameter updates?

- Concept: Graph Inductive Biases
  - Why needed here: These biases (like feature propagation and similarity-based aggregation) are encoded in the text attributes and relationships to guide the LLM's reasoning toward correct graph interpretations.
  - Quick check question: Why does adding synthetic relationships improve LLM performance on graph tasks?

## Architecture Onboarding

- Component map:
  Graph -> Graph-Syntax Tree Builder -> Text Prompt Generator -> LLM -> Text Output -> Label Predictor

- Critical path:
  1. Build graph-syntax tree with selected F and R
  2. Traverse tree to generate prompt text
  3. LLM processes prompt with demonstrations (ICL) or fine-tuning
  4. Output text is mapped back to graph labels

- Design tradeoffs:
  - Choice of tree hierarchy impacts interpretability and performance
  - Including more relations increases prompt complexity but may improve accuracy
  - Trade-off between synthetic text attributes (more info) vs prompt length

- Failure signatures:
  - Random or near-random predictions indicate the LLM failed to capture graph structure
  - Consistent mispredictions on certain node types suggest bias in tree construction or relations
  - Very long prompts causing context truncation may lose important graph information

- First 3 experiments:
  1. Compare performance using only raw features vs adding propagated features in F
  2. Test different relation sets (e.g., only shortest-path vs including similarity) on Cora dataset
  3. Evaluate tree hierarchy variations (e.g., attribute-first vs relation-first) on Citeseer dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can continuous features be effectively discretized for use in GraphText?
- Basis in paper: [explicit] The paper notes that the effectiveness of discretization is a primary concern, with most optimal settings being label-based, and posits that the observed trend might be attributed to the ineffectiveness of the discretization process and the discord between feature and label spaces.
- Why unresolved: The paper acknowledges this as a limitation but does not provide a solution or explore alternative methods for discretization.
- What evidence would resolve it: Developing and testing new discretization methods or exploring ways to align feature and label spaces could provide insights into more effective discretization for GraphText.

### Open Question 2
- Question: What is the optimal design space for the graph-proxy tree in GraphText?
- Basis in paper: [explicit] The paper mentions that the design space of the graph-proxy tree is extensive and often requires expert knowledge or hyperparameter optimization, leading to a vast search space.
- Why unresolved: While the paper acknowledges the importance of the graph-proxy tree design, it does not provide a comprehensive exploration of the design space or guidelines for selecting optimal configurations.
- What evidence would resolve it: Conducting extensive experiments to explore different tree designs, identifying patterns or principles for optimal configurations, and developing automated methods for tree design could help resolve this question.

### Open Question 3
- Question: How can GraphText be improved to better leverage prior knowledge and reduce biases in graph reasoning?
- Basis in paper: [inferred] The paper discusses how LLMs can sometimes struggle with recalling prior knowledge and remain anchored to their pre-existing beliefs, leading to errors in graph reasoning. It suggests that human interaction can help refine the reasoning approach.
- Why unresolved: While the paper demonstrates the potential of human interaction in improving GraphText's performance, it does not explore systematic methods for incorporating prior knowledge or reducing biases in graph reasoning.
- What evidence would resolve it: Developing techniques to better integrate prior knowledge, such as using knowledge graphs or pre-training on graph data, and exploring methods to mitigate biases, such as adversarial training or fairness-aware learning, could provide insights into improving GraphText's graph reasoning capabilities.

## Limitations

- Performance degradation with continuous-valued features, as LLMs like ChatGPT struggle with non-discretized numerical data
- Limited validation on diverse graph types beyond citation networks and a few text-attributed graphs
- Significant dependence on LLM capabilities and context window constraints for larger graphs

## Confidence

- High confidence: The core mechanism of translating graphs to natural language sequences through graph-syntax trees is well-founded and supported by the paper's results.
- Medium confidence: The claim that GraphText can match or exceed GNN performance on standard benchmark datasets is supported by experiments, though the magnitude of improvement varies by dataset and LLM choice.
- Medium confidence: The assertion that GraphText enables interactive graph reasoning through natural language communication is theoretically sound but lacks extensive empirical validation in the paper.

## Next Checks

1. **Cross-dataset generalization test**: Evaluate GraphText on graphs from different domains (e.g., social networks, biological networks, knowledge graphs) to assess whether performance degradation occurs as graph characteristics diverge from citation networks.

2. **Scalability analysis**: Test GraphText on graphs with 10K+ nodes and edges to identify practical limits of prompt length and LLM context window constraints, measuring the trade-off between graph size and accuracy.

3. **Ablation study on synthetic relationships**: Systematically remove each synthetic relationship (feature similarity, shortest-path distance, personalized pagerank) individually and in combinations to quantify their individual contributions to performance gains.