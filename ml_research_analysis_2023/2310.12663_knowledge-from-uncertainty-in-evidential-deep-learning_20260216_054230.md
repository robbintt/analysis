---
ver: rpa2
title: Knowledge from Uncertainty in Evidential Deep Learning
arxiv_id: '2310.12663'
source_url: https://arxiv.org/abs/2310.12663
tags:
- dirichlet
- uncertainty
- evidential
- strength
- networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper critically examines the \u201Cevidential signal\u201D\
  \ observed in Evidential Deep Learning (EDL) and compares it with Prior Networks\
  \ and EDL-GEN, all of which quantify uncertainty in classification tasks. The study\
  \ reveals that the Dirichlet strength output by EDL is strongly coupled with misclassification\
  \ bias due to its KL regularisation term, causing it to conflate aleatoric and epistemic\
  \ uncertainty."
---

# Knowledge from Uncertainty in Evidential Deep Learning

## Quick Facts
- arXiv ID: 2310.12663
- Source URL: https://arxiv.org/abs/2310.12663
- Reference count: 29
- EDL's Dirichlet strength is strongly coupled with misclassification bias due to KL regularisation

## Executive Summary
This paper critically examines the "evidential signal" observed in Evidential Deep Learning (EDL) and compares it with Prior Networks and EDL-GEN, all of which quantify uncertainty in classification tasks. The study reveals that the Dirichlet strength output by EDL is strongly coupled with misclassification bias due to its KL regularisation term, causing it to conflate aleatoric and epistemic uncertainty. Empirically, the authors demonstrate that the evidential signal is highly correlated with recall and can discriminate between classes, particularly in natural language tasks like IMDB sentiment analysis. However, this signal is absent in Prior Networks and EDL-GEN, which use out-of-distribution samples during training. The findings highlight the need for careful design of uncertainty-aware models to avoid coupling different sources of uncertainty, which can undermine the reliability of AI systems in safety-critical applications.

## Method Summary
The authors implement EDL, EDL-GEN, and Prior Networks using PyTorch with BERT for NLP tasks and LeNet/VGG16 for computer vision tasks. They train models on natural language datasets (IMDB, Blog, Amazon, Newsgroups) and computer vision datasets (MNIST, EMNIST) using specified loss functions and annealing coefficients. The evaluation focuses on Pearson's and Spearman's correlation coefficients between recall and Dirichlet strength, class discrimination accuracy from Dirichlet strength, and visual inspection of cumulative distribution functions. Simple machine learning methods (SVM, Decision Tree, XGBoost) are used to measure the separability of classes based on the Dirichlet strength alone.

## Key Results
- EDL's Dirichlet strength shows strong correlation with recall (misclassification rate) due to KL regularisation coupling aleatoric and epistemic uncertainty
- The evidential signal can discriminate between classes in some cases, with NLP models showing stronger discrimination than computer vision models
- EDL-GEN and Prior Networks do not exhibit the same evidential signal because they use out-of-distribution samples during training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EDL's Dirichlet strength is strongly correlated with misclassification bias due to its KL regularisation term.
- Mechanism: The KL regularisation term in EDL's loss function reduces all evidence near decision boundaries where training data classes overlap. This causes the Dirichlet strength to reflect misclassification likelihood rather than pure epistemic uncertainty.
- Core assumption: Misclassification bias exists in the dataset and affects the evidence generated by the model.
- Evidence anchors:
  - [abstract] "We hypothesise that the KL regularisation term causes EDL to couple aleatoric and epistemic uncertainty."
  - [section] "We hypothesise a high correlation for EDL and weaker or no correlation for EDL-GEN and Prior Networks, which would indicate a coupling of aleatoric and epistemic uncertainty in the EDL loss function."
  - [corpus] Weak - corpus focuses on applications of EDL rather than theoretical mechanisms of uncertainty coupling.
- Break condition: If out-of-distribution samples are used during training, the correlation weakens significantly as seen with EDL-GEN and Prior Networks.

### Mechanism 2
- Claim: The Dirichlet strength computed by EDL carries sufficient information to discriminate between classes in some cases.
- Mechanism: Since misclassification bias varies between classes, the Dirichlet strength becomes coupled with the ground truth class. This coupling is strong enough in some datasets that simple classifiers can achieve high accuracy using only the Dirichlet strength.
- Core assumption: The misclassification bias is not uniform across all classes in the dataset.
- Evidence anchors:
  - [abstract] "the 'evidential signal' arising from the Dirichlet strength in EDL can, in some cases, discriminate between classes"
  - [section] "we train a set of simple models on the Dirichlet strength and record the accuracy across a test set to measure the separability of the classes"
  - [corpus] Weak - corpus mentions EDL applications but not class discrimination through uncertainty signals.
- Break condition: When datasets have balanced misclassification rates across classes, the separability decreases significantly.

### Mechanism 3
- Claim: EDL-GEN and Prior Networks do not exhibit the same evidential signal because they use out-of-distribution samples during training.
- Mechanism: These approaches explicitly train to increase epistemic uncertainty for out-of-distribution samples, which breaks the coupling between Dirichlet strength and misclassification bias seen in standard EDL.
- Core assumption: Out-of-distribution samples provide a reference point that helps the model distinguish between aleatoric and epistemic uncertainty.
- Evidence anchors:
  - [abstract] "EDL-GEN and Prior Networks, which use out-of-distribution samples during training. The findings highlight the need for careful design of uncertainty-aware models to avoid coupling different sources of uncertainty"
  - [section] "These methods learn to reduce the Dirichlet strength (or increase the epistemic uncertainty) over the out-of-distribution data."
  - [corpus] Weak - corpus focuses on applications rather than comparing EDL variants.
- Break condition: If the out-of-distribution dataset is poorly chosen or unrepresentative, the mechanism may fail to properly decouple uncertainties.

## Foundational Learning

- Concept: Dirichlet distribution and its parameters
  - Why needed here: EDL transforms classification into estimating Dirichlet parameters, where the Dirichlet strength (sum of parameters) becomes the key uncertainty metric.
  - Quick check question: What happens to the Dirichlet strength when a model is very confident about a single class?

- Concept: Aleatoric vs epistemic uncertainty
  - Why needed here: The paper's core contribution is showing how EDL unintentionally couples these two types of uncertainty, which is problematic for reliable AI systems.
  - Quick check question: Can aleatoric uncertainty be reduced by collecting more data? Why or why not?

- Concept: KL divergence and its role in regularisation
  - Why needed here: The KL regularisation term in EDL's loss function is the mechanism that causes the coupling between misclassification and uncertainty.
  - Quick check question: What is the effect of the KL regularisation term when a sample is misclassified?

## Architecture Onboarding

- Component map:
  Input layer → Neural network backbone → Evidence estimation layer → Dirichlet parameter computation → KL regularisation term → Loss function
  For EDL-GEN: Input layer → VAE encoder → Latent space perturbation → Discriminator training loop → Evidence estimation

- Critical path:
  1. Evidence generation from neural network output
  2. Dirichlet parameter computation (α = evidence + 1)
  3. KL divergence calculation between predicted and uniform Dirichlet
  4. Final loss computation incorporating both classification error and KL term

- Design tradeoffs:
  - EDL trades computational simplicity (single forward pass) for potential coupling of uncertainties
  - EDL-GEN adds computational overhead (VAE training) to avoid the need for explicit OOD datasets
  - Prior Networks require manual OOD dataset selection but maintain cleaner uncertainty separation

- Failure signatures:
  - Strong correlation between recall and Dirichlet strength (indicates coupling problem)
  - High accuracy achievable using only Dirichlet strength as features (indicates class discrimination signal)
  - Poor performance on truly out-of-distribution samples despite high confidence

- First 3 experiments:
  1. Train EDL on MNIST and plot recall vs Dirichlet strength to observe correlation
  2. Train SVM classifier using only Dirichlet strength as features and measure accuracy
  3. Repeat experiments with EDL-GEN and Prior Networks to compare uncertainty signals

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the coupling of aleatoric and epistemic uncertainty in EDL be mitigated while preserving its computational efficiency?
- Basis in paper: [explicit] The paper discusses how EDL's KL regularisation term causes coupling of aleatoric and epistemic uncertainty, which undermines reliability in safety-critical applications.
- Why unresolved: The paper identifies the problem but does not propose a concrete solution to decouple these uncertainties in EDL.
- What evidence would resolve it: A modified EDL architecture or loss function that demonstrates reduced coupling while maintaining comparable performance metrics (accuracy, computational efficiency) to standard EDL.

### Open Question 2
- Question: Why do NLP models exhibit significantly stronger discriminatory power from the evidential signal compared to computer vision models, even in multi-class settings?
- Basis in paper: [explicit] The paper observes that NLP models (e.g., IMDB sentiment analysis) show much stronger class discrimination from the Dirichlet strength compared to computer vision models (e.g., MNIST), even in multi-class cases like Newsgroups.
- Why unresolved: The paper identifies this discrepancy but does not investigate the underlying causes of why NLP models show stronger discrimination.
- What evidence would resolve it: Comparative analysis of dataset characteristics, model architectures, or training dynamics that explains why NLP tasks exhibit stronger class discrimination in the evidential signal.

### Open Question 3
- Question: Can the 'evidential signal' phenomenon observed in EDL be replicated in other uncertainty estimation approaches beyond Prior Networks and EDL-GEN?
- Basis in paper: [explicit] The paper explores EDL, Prior Networks, and EDL-GEN, finding that the 'evidential signal' is unique to EDL. The authors mention future work will explore other approaches.
- Why unresolved: The paper only examines three Dirichlet-based approaches and does not extend the investigation to other uncertainty quantification methods.
- What evidence would resolve it: Empirical testing of additional uncertainty estimation methods (e.g., Ensemble Distribution Distillation, Posterior Networks) to determine if they exhibit similar 'evidential signal' characteristics or remain decoupled from misclassification bias.

## Limitations

- The coupling analysis assumes misclassification stems from inherent data ambiguity rather than model capacity issues
- Class discrimination results may be dataset-specific and may not generalize to all domains
- The paper doesn't investigate whether the evidential signal persists across different train-test splits or hyperparameter settings

## Confidence

- Mechanism 1: Medium-High - Strong empirical correlations but could benefit from more rigorous statistical testing
- Mechanism 2: Medium - Promising results but potential dataset-specific effects not fully explored
- Mechanism 3: Medium-High - Supported by absence of correlations in EDL-GEN/Prior Networks, though edge cases not fully examined

## Next Checks

1. Test whether the misclassification-uncertainty coupling persists when using balanced datasets where all classes have equal misclassification rates
2. Evaluate whether adding more model capacity (deeper networks, different architectures) reduces or eliminates the observed correlations
3. Conduct ablation studies removing the KL regularisation term to isolate its specific contribution to the coupling effect