---
ver: rpa2
title: 'Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation'
arxiv_id: '2312.00645'
source_url: https://arxiv.org/abs/2312.00645
tags:
- arxiv
- answers
- might
- would
- correct
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the need to evaluate language model capabilities
  on sensitive topics like bioterrorism without exposing the correct answers, which
  traditional benchmarks do by publishing them in cleartext. To solve this, it proposes
  hashmarking, a protocol where experts hash the correct answers using the questions
  as salt before publishing, allowing third parties to verify their knowledge without
  revealing the actual answers.
---

# Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation

## Quick Facts
- arXiv ID: 2312.00645
- Source URL: https://arxiv.org/abs/2312.00645
- Reference count: 40
- Primary result: Hashmarks enable privacy-preserving evaluation of high-stakes AI capabilities by hashing answers with questions as salt, preventing exposure of sensitive information while allowing third-party verification

## Executive Summary
Hashmarks address the challenge of evaluating language model capabilities on sensitive topics like bioterrorism without exposing correct answers. The protocol uses slow cryptographic hashing (argon2id) with questions as salt to create a privacy-preserving benchmark where experts hash answers before publication. This allows third parties to verify their knowledge without accessing the cleartext answers, protecting against misuse while maintaining evaluation utility. The approach includes consensus checks among experts and filtering for answer quality, representing a novel step toward secure AI capability assessment in high-stakes domains.

## Method Summary
The hashmark protocol involves domain experts creating question-answer pairs on sensitive topics, then hashing the answers using argon2id with questions as salt. A second round requires experts to answer each other's questions, with consensus checking and filtering for non-empty answers before publication. The resulting hashmarks publish only cleartext questions and hashed answers, allowing third parties to verify their knowledge by hashing their own answers and comparing against published hashes. The method balances security needs with evaluation utility through computational burden and scale-based dilution of attention hazards.

## Key Results
- Slow hashing algorithms like argon2id effectively mitigate brute-force and dictionary attacks when combined with question-based salting
- Consensus requirements among experts and filtering for non-empty answers ensure answer quality without revealing cleartext solutions
- Likelihood prioritization attacks can be mitigated by the computational burden of slow hashing and dilution through scaling the benchmark
- Hashmarks represent an initial step toward secure evaluation of high-stakes AI capabilities but are not a complete solution to all security challenges

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cryptographic hashing with slow algorithms and salting prevents both brute-force attacks and rainbow table attacks on the correct answers.
- Mechanism: The protocol hashes answers using a slow algorithm (argon2id) with questions as salt, making brute-force and precomputed attacks computationally expensive.
- Core assumption: Slow hashing algorithms remain effective against current computational capabilities, and the salt is unique per question.
- Evidence anchors:
  - [section]: "slow hashing algorithms like argon2id can mitigate brute-force and dictionary attacks, while salting with questions prevents rainbow table attacks"
  - [abstract]: "experts hash the correct answers using the questions as salt"
  - [corpus]: Weak - corpus does not directly address cryptographic security mechanisms
- Break condition: Advances in computing power or novel attack techniques that can reverse cryptographic hashes or bypass slow hashing constraints.

### Mechanism 2
- Claim: The consensus requirement among experts and filtering for non-empty answers ensures answer quality without revealing cleartext solutions.
- Mechanism: Experts answer each other's questions and consensus is required before publishing, with empty answers filtered out.
- Core assumption: Multiple independent experts will converge on correct answers, and empty answers indicate lack of knowledge.
- Evidence anchors:
  - [section]: "the auditor discards those question-answer pairs that have less than a threshold number of non-empty answers. Then, the auditor also discards those question-answer pairs that do not exhibit consensus among the hashed answers"
  - [abstract]: "includes consensus checks among experts and filtering for quality"
  - [corpus]: Weak - corpus does not discuss consensus mechanisms in detail
- Break condition: Experts collude or systematically provide incorrect answers, or the threshold for consensus is set too low.

### Mechanism 3
- Claim: Likelihood prioritization attacks can be mitigated by the computational burden of slow hashing and the dilution effect of scaling up the benchmark.
- Mechanism: Even if models can generate likely answers, the slow hashing and large scale make exhaustive searching impractical.
- Core assumption: The computational cost of slow hashing plus the scale of the benchmark creates a barrier to systematic searching.
- Evidence anchors:
  - [section]: "the computational and memory burden associated with evaluating performance before optimizing for it further can help mitigate this risk by rendering it even more expensive"
  - [section]: "By incorporating entries according to a skewed distribution of expert-perceived sensitivity, as well as by simply scaling up the published artifacts, third-party resources – attentional or otherwise – would inevitably be diluted"
  - [corpus]: Weak - corpus does not specifically address likelihood prioritization attacks
- Break condition: Computational resources become cheap enough that even slow hashing cannot deter systematic searching, or models become capable of generating correct answers with minimal attempts.

## Foundational Learning

- Cryptographic hashing:
  - Why needed here: To irreversibly transform correct answers into a form that can be verified but not easily reversed
  - Quick check question: What property of cryptographic hash functions makes them suitable for password storage and hashmarks?

- Slow hashing algorithms (argon2id):
  - Why needed here: To make brute-force attacks computationally expensive and impractical
  - Quick check question: How does argon2id differ from traditional hash functions in terms of security properties?

- Salting:
  - Why needed here: To prevent precomputed rainbow table attacks by making each hash unique to its question
  - Quick check question: Why is using the question as salt effective against rainbow table attacks?

## Architecture Onboarding

- Component map: Experts (answer generation and hashing) -> Auditor (consensus checking and filtering) -> Hashmark (published cleartext questions and hashed answers) -> Third-party evaluators (answer verification)
- Critical path: Expert question generation → Expert answer hashing → Auditor consensus checking → Publication → Third-party verification
- Design tradeoffs: Security vs. usability (slow hashing vs. quick verification), scale vs. effectiveness (more entries dilute attention but reduce average stakes)
- Failure signatures: Empty answers from experts, lack of consensus among experts, high FMR scores in related papers indicating security concerns
- First 3 experiments:
  1. Implement a small-scale hashmark with 10 questions and 3 experts to test the consensus mechanism
  2. Measure verification time for third-parties using different slow hashing configurations
  3. Test resistance to brute-force attacks using current computational resources and projected future capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can hashmarks be further secured against likelihood prioritization attacks without compromising the ability to verify knowledge?
- Basis in paper: [explicit] The paper discusses the challenge of likelihood prioritization attacks, where an attacker could use a generative model to rerank candidate answers based on their likelihood, making it easier to uncover the correct answers.
- Why unresolved: The paper suggests that slow hashing and salting are the only features that can help mitigate these attacks, but acknowledges that more sophisticated protocols might be needed to address this issue.
- What evidence would resolve it: Development and testing of new protocols that can effectively prevent likelihood prioritization attacks while maintaining the integrity of knowledge verification.

### Open Question 2
- Question: Can cryptographic accumulators or other zero-knowledge proofs be adapted to enable more granular verification of hashmark answers without revealing the answers themselves?
- Basis in paper: [explicit] The paper mentions that cryptographic accumulators could potentially be used to map a set of elements to a single hash, enabling membership queries without disclosing the actual members, but notes that this alone would be insufficient.
- Why unresolved: While cryptographic accumulators offer a promising direction, the paper highlights the challenge of ensuring that queries about individual question-answer pairs cannot be made, which would compromise the security of the hashmarks.
- What evidence would resolve it: Successful implementation and validation of a protocol using cryptographic accumulators or zero-knowledge proofs that allows for granular verification without revealing the answers.

### Open Question 3
- Question: How can hashmarks be designed to mitigate attention hazards and the Streisand effect while still providing valuable insights into AI capabilities?
- Basis in paper: [explicit] The paper discusses the potential for hashmarks to draw attention to sensitive topics, which could lead to attention hazards and the Streisand effect, where attempts to suppress information inadvertently increase interest in it.
- Why unresolved: The paper suggests scaling up the published artifacts and incorporating entries with a skewed distribution of sensitivity, but acknowledges that these measures might limit the informformativeness of the hashmarks.
- What evidence would resolve it: Development of a balanced approach that effectively mitigates attention hazards while maintaining the utility of hashmarks as indicators of AI risk.

## Limitations

- Security analysis relies heavily on assumptions about computational resources remaining prohibitive for attackers
- Consensus mechanism lacks specification of critical parameters and collusion resistance measures
- Novel attack vectors like likelihood prioritization and reward shaping remain largely theoretical without empirical validation
- Protocol does not address all potential security challenges, particularly attention hazards and the Streisand effect

## Confidence

- High confidence: The basic cryptographic mechanism (slow hashing with salting) is well-established and the protocol design follows standard security practices
- Medium confidence: The consensus mechanism and quality filtering approach is sound but lacks specification of critical parameters and collusion resistance
- Low confidence: The analysis of novel attack vectors like likelihood prioritization and reward shaping remains largely theoretical without empirical validation

## Next Checks

1. Conduct computational feasibility analysis to determine the exact break-even point where slow hashing becomes ineffective against projected future computational capabilities, updating security parameters accordingly.

2. Implement a controlled experiment testing the consensus mechanism with simulated malicious experts attempting to provide incorrect answers while maintaining plausible deniability, measuring false acceptance rates.

3. Develop and test a prototype verification tool that quantifies the likelihood prioritization attack surface by measuring how efficiently models can generate candidate answers that hash to values near published hashes, establishing practical attack difficulty metrics.