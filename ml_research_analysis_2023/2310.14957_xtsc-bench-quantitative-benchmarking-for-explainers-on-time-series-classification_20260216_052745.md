---
ver: rpa2
title: 'XTSC-Bench: Quantitative Benchmarking for Explainers on Time Series Classification'
arxiv_id: '2310.14957'
source_url: https://arxiv.org/abs/2310.14957
tags:
- time
- series
- explanation
- data
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces XTSC-Bench, a benchmarking tool for evaluating
  explainability methods on time series classification. The tool addresses the challenge
  of systematically comparing explainers due to a lack of standardized metrics and
  datasets in this domain.
---

# XTSC-Bench: Quantitative Benchmarking for Explainers on Time Series Classification

## Quick Facts
- arXiv ID: 2310.14957
- Source URL: https://arxiv.org/abs/2310.14957
- Reference count: 40
- Primary result: Introduces XTSC-Bench, a tool for quantitative evaluation of explainability methods on time series classification, addressing the lack of standardized metrics and datasets.

## Executive Summary
This paper introduces XTSC-Bench, a benchmarking tool for evaluating explainability methods on time series classification. The tool addresses the challenge of systematically comparing explainers due to a lack of standardized metrics and datasets in this domain. XTSC-Bench provides synthetic datasets with known ground truths, pre-trained models, and a suite of metrics measuring complexity, reliability, robustness, and faithfulness. The authors evaluate 11 explainers, including gradient-based, perturbation-based, and example-based methods, using their tool. Results show that current explainers struggle with multivariate data, particularly in reliability, and that traditional and time-series-specific methods have room for improvement. No single explainer dominates across all metrics, highlighting the need for further research to enhance explainers' robustness and reliability, especially for complex multivariate time series classification tasks.

## Method Summary
XTSC-Bench is a benchmarking tool for evaluating explainability methods on time series classification (TSC). It addresses the challenge of systematically comparing explainers due to a lack of standardized metrics and datasets in this domain. The tool provides synthetic datasets with known ground truths, pre-trained models, and a suite of metrics measuring complexity, reliability, robustness, and faithfulness. XTSC-Bench includes implementations of 11 explainers (gradient-based, perturbation-based, and example-based) and metrics to measure their performance. The tool generates synthetic time series with controlled informative features and trains models to 90%+ accuracy, creating known ground truth masks for reliability metrics.

## Key Results
- Current explainers struggle with multivariate data, particularly in reliability metrics.
- Traditional and time-series-specific methods have room for improvement in explaining TSC.
- No single explainer dominates across all metrics, highlighting the need for further research to enhance explainers' robustness and reliability.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Standardized synthetic datasets with known ground truths enable quantitative evaluation of explainers where qualitative human assessment fails.
- Mechanism: The tool generates synthetic time series with controlled informative features and trains models to 90%+ accuracy, creating known ground truth masks for reliability metrics.
- Core assumption: Time series humans cannot intuitively parse ground truth relevance; synthetic data with ground truth is therefore necessary for objective evaluation.
- Evidence anchors:
  - [abstract] "resorting to qualitative assessment and user studies to evaluate explainers for TSC is difficult since humans have difficulties understanding the underlying information contained in time series data."
  - [section IV-A] "XTSC-Bench provides 60 uni- and 60 multivariate synthetic datasets with 50 time steps generated according to Ismail et al. [22]... a binary label is added for each dataset... by highlighting informative features with the addition of a constant for positive classes and subtraction for negative classes."
  - [corpus] Weak evidence; corpus neighbors do not explicitly discuss synthetic ground truth datasets, though one paper mentions "ground truth evaluation."
- Break condition: If the classifier fails to learn the synthetic patterns reliably, the ground truth masks become invalid for evaluation.

### Mechanism 2
- Claim: Time-series-specific metrics (robustness, reliability, faithfulness, complexity) are required because traditional image/tabular metrics misalign with time series structure.
- Mechanism: Metrics like relevance rank accuracy and max sensitivity are tailored to sequential feature importance, accounting for temporal dependencies and the lack of "blank" reference baselines.
- Core assumption: Standard baselines (e.g., zeros or means) may be informative in time series, so synthetic reference baselines are used instead.
- Evidence anchors:
  - [abstract] "traditional metrics not being directly applicable" and "implementation and adaption of traditional metrics for time series in the literature vary."
  - [section IV-C] "Most faithfulness metrics rely on so called reference baselines... for time series data those baselines might contain information... therefore, on the proposed synthetic data the reference baseline Ëœx is sampled from the generation process."
  - [corpus] Weak evidence; corpus neighbors discuss interpretability but do not explicitly address metric misalignment for time series.
- Break condition: If the synthetic baseline fails to represent uninformative features in a given time series domain, faithfulness metrics become unreliable.

### Mechanism 3
- Claim: Decoupling feature and time domains via Temporal Saliency Rescaling (TSR) improves interpretability and reduces complexity.
- Mechanism: TSR averages attributions over time and features, eliminating isolated small relevance scores and producing smoother, more comprehensible explanations.
- Core assumption: Time series explanations benefit from aggregation over time to highlight sustained importance rather than momentary spikes.
- Evidence anchors:
  - [section V] "TSR contains slightly fewer attributions than the plain gradient- and perturbation-based methods... averaging the obtained relevance scores on both the feature and time domain with TSR leads to a complexity decrease."
  - [corpus] Weak evidence; corpus neighbors mention explainers but do not discuss TSR specifically.
- Break condition: If temporal patterns are highly localized, TSR may obscure critical short-duration features.

## Foundational Learning

- Concept: Time series classification (TSC) and its unique challenges (temporal ordering, multivariate dependencies).
  - Why needed here: XTSC-Bench targets TSC explainability, so understanding how TSC differs from image/tabular classification is essential to grasp why specialized metrics and datasets are required.
  - Quick check question: What structural property of time series makes "blank" reference baselines (e.g., all zeros) potentially informative?

- Concept: Feature attribution vs. example-based explainers.
  - Why needed here: XTSC-Bench evaluates both types; knowing how they differ (attribution scores vs. manipulated instances) explains why different metrics apply.
  - Quick check question: How does XTSC-Bench convert example-based method outputs into relevance scores for consistency with other metrics?

- Concept: Metrics for XAI (faithfulness, robustness, complexity, reliability).
  - Why needed here: XTSC-Bench implements and adapts these metrics for time series; understanding each metric's intent clarifies what XTSC-Bench measures.
  - Quick check question: Which XTSC-Bench metric compares the sum of top attribution values to the known ground truth mask?

## Architecture Onboarding

- Component map:
  - Data Generation Module -> Model Training Module -> Metric Evaluation Modules -> Integration Layer -> TSInterpret Bridge

- Critical path:
  1. Load or generate synthetic dataset.
  2. Load pre-trained classifier.
  3. Run explainer on input time series.
  4. Evaluate output with selected metrics.
  5. Aggregate and visualize results.

- Design tradeoffs:
  - Synthetic vs. real data: Synthetic enables ground truth but may not reflect real-world noise.
  - Metric choice: Adapted metrics avoid misalignment but require synthetic baselines.
  - Complexity vs. granularity: TSR reduces complexity but may smooth out short-duration signals.

- Failure signatures:
  - Classifier accuracy <90%: Invalid ground truth masks.
  - Non-uniform synthetic baselines: Faithfulness metrics misrepresent.
  - Inconsistent TSR behavior: Complexity and reliability metrics diverge.

- First 3 experiments:
  1. Run XTSC-Bench with synthetic "Middle" feature type on CNN; verify reliability rank mass >0.5.
  2. Compare faithfulness with uniform vs. generation baseline; confirm no significant difference.
  3. Apply TSR wrapper to gradient-based explainer; check complexity reduction by >20%.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the reliability and faithfulness of explainers change when applied to real-world multivariate time series datasets compared to synthetic datasets?
- Basis in paper: [inferred] The paper shows that current explainers perform worse on multivariate data compared to univariate data in synthetic datasets, but does not test on real-world data.
- Why unresolved: Real-world datasets often have more complex structures and noise compared to synthetic data, which could impact explainer performance differently.
- What evidence would resolve it: Empirical evaluation of XTSC-Bench on real-world multivariate time series datasets with varying levels of complexity and noise.

### Open Question 2
- Question: Can the complexity of explanations be further reduced without compromising reliability and faithfulness, particularly for multivariate time series data?
- Basis in paper: [explicit] The paper shows that gradient- and perturbation-based methods provide less complex explanations than example-based methods, but complexity remains high for multivariate data.
- Why unresolved: While some methods reduce complexity, there is still a trade-off between simplicity and the quality of explanations, especially in complex data scenarios.
- What evidence would resolve it: Development and testing of new explainers or modifications to existing ones that achieve lower complexity while maintaining or improving reliability and faithfulness metrics.

### Open Question 3
- Question: How do different temporal saliency rescaling (TSR) techniques impact the performance of gradient-based explainers on multivariate time series data?
- Basis in paper: [explicit] The paper includes TSR as a wrapper for gradient-based methods and shows varying impacts on different metrics, but does not compare different TSR techniques.
- Why unresolved: TSR is used to decouple time and feature domains, but the effectiveness of different TSR approaches on multivariate data is not explored.
- What evidence would resolve it: Comparative analysis of multiple TSR techniques applied to gradient-based explainers, evaluating their impact on reliability, faithfulness, and robustness in multivariate time series data.

## Limitations
- The paper's primary limitation is its reliance on synthetic datasets with known ground truths, which may not fully capture the complexity and noise present in real-world time series data.
- The exact implementation details of the explainers and metrics used in XTSC-Bench are not fully specified in the paper.
- The hyperparameters and training details for the pre-trained models are not provided.

## Confidence

- **High**: XTSC-Bench provides a standardized framework for evaluating explainers on TSC, as clearly demonstrated through the tool's architecture and evaluation results.
- **Medium**: Time-series-specific metrics are necessary, as the paper provides theoretical justification but limited empirical evidence comparing these metrics to traditional ones on real data.
- **Low**: No single explainer dominates across all metrics, as the evaluation is limited to the 11 methods tested on synthetic data.

## Next Checks

1. **Reproduce reliability metrics**: Run XTSC-Bench on synthetic "Rare" feature type and verify that reliability rank mass exceeds 0.5, confirming the tool's ability to capture ground truth relevance.
2. **Compare faithfulness baselines**: Evaluate faithfulness metrics using both uniform and synthetic generation baselines to confirm that no significant differences arise, validating the baseline choice.
3. **Test TSR complexity reduction**: Apply TSR to gradient-based explainers and measure complexity reduction; ensure it exceeds 20% to validate the effectiveness of temporal aggregation.