---
ver: rpa2
title: How To Build Competitive Multi-gender Speech Translation Models For Controlling
  Speaker Gender Translation
arxiv_id: '2310.15114'
source_url: https://arxiv.org/abs/2310.15114
tags:
- gender
- translation
- multi-gender
- speech
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of gender bias in speech translation
  (ST) models when translating from English (notional gender) to Italian (grammatical
  gender). The issue arises when the speaker's gender is not explicitly conveyed in
  the source sentence, leading to potentially biased or stereotypical gender assignments.
---

# How To Build Competitive Multi-gender Speech Translation Models For Controlling Speaker Gender Translation

## Quick Facts
- arXiv ID: 2310.15114
- Source URL: https://arxiv.org/abs/2310.15114
- Reference count: 40
- Primary result: Training multi-gender ST models from scratch outperforms gender-specialized models with up to 12.9 points gain in feminine translation gender accuracy

## Executive Summary
This paper tackles gender bias in speech translation when translating from English to Italian, where the target language requires grammatical gender agreement. The key challenge is that existing models rely on speaker vocal traits to determine gender, leading to biased translations when the notional gender isn't explicitly stated. The authors propose building a single multi-gender neural ST model that can control speaker gender translation more effectively than previous approaches. Through systematic experimentation, they demonstrate that training such models from scratch with gender tags outperforms both fine-tuning from existing models and gender-specialized approaches, particularly for feminine translations.

## Method Summary
The authors build multi-gender ST models using a Conformer encoder (12 layers) and Transformer decoder (6 layers) architecture. They explore two main approaches: fine-tuning existing gender-unaware ST models and training from scratch with gender tags. For fine-tuning, they implement gradient reversal with a discriminator to create gender-invariant encoder representations and manipulate input audio to break correlations between vocal characteristics and gender tags. The gender tag is prepended to target text as a discrete token (<bos> token). Training from scratch involves generating target text with gender tags from the start, allowing the model to learn tag-dependent representations rather than relying on acoustic features.

## Key Results
- Training multi-gender models from scratch achieves up to 12.9 points higher gender accuracy for feminine translations compared to specialized models
- Fine-tuning from existing ST models fails to achieve competitive results due to persistent reliance on vocal traits
- Gradient reversal and audio manipulation techniques provide slight improvements but cannot close the performance gap with specialized models in fine-tuning scenarios
- Multi-gender models from scratch achieve better BLEU scores while maintaining superior gender accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning from an existing gender-unaware ST model perpetuates reliance on vocal traits, making gender control ineffective
- Mechanism: The pre-trained encoder learns strong correlations between speaker acoustic features (pitch, formants) and gender. During fine-tuning, these correlations are not overridden because the training objective still encourages leveraging these cues for translation quality
- Core assumption: The base model's representations are too strongly tied to vocal traits to be re-purposed for gender control via tags alone
- Evidence anchors:
  - [abstract]: "fine-tuning from existing ST models does not lead to competitive results"
  - [section]: "low accuracy of multi-gender models comes from the initialization with the weights of a gender-unaware ST system and the inability to override the behavior of the base ST model"
- Break condition: If the fine-tuning data is highly gender-balanced and the task is simplified, the encoder might be more easily re-trained to ignore vocal traits

### Mechanism 2
- Claim: Training from scratch with gender tags enables the model to learn to follow tags instead of vocal cues
- Mechanism: Without pre-existing bias from a gender-unaware model, the encoder can learn representations that are conditionally dependent on the gender tag rather than the acoustic input. The decoder learns to use the tag as the sole gender signal
- Core assumption: The model architecture and training process are sufficiently expressive to learn tag-dependent representations when not pre-constrained by prior gender-unaware training
- Evidence anchors:
  - [abstract]: "training a multi-gender model from scratch outperforms gender-specialized models in terms of gender accuracy, with gains of up to 12.9 points for feminine translations"
  - [section]: "training multi-gender models from scratch yields competitive results, outperforming the specialized approach with gender accuracy gains of up to 12.9 points for feminine translations"
- Break condition: If the dataset is extremely small or the model architecture is too shallow, the model might revert to exploiting any available gender signal, including vocal traits

### Mechanism 3
- Claim: Gradient reversal and audio manipulation techniques partially reduce reliance on vocal traits but are insufficient to close the gap with specialized models in fine-tuning scenarios
- Mechanism: Gradient reversal trains a discriminator to predict speaker gender from encoder outputs and uses the reversed gradient to make the encoder invariant to gender. Audio manipulation breaks the correlation between gender tags and acoustic features by altering pitch and formants
- Core assumption: Making the encoder gender-invariant or breaking acoustic-gender correlations will force the model to rely on tags, but the fine-tuning initialization still biases the model toward vocal cues
- Evidence anchors:
  - [abstract]: "Despite the slight improvements brought by these solutions in gender accuracy and overall translation quality, none of them effectively close the performance gap with the specialized solution"
  - [section]: "techniques aimed at avoiding the exploitation of speakers' vocal traits seem ineffective"
- Break condition: If the techniques are applied during training from scratch rather than fine-tuning, or if more aggressive manipulation is used, the effect might be stronger

## Foundational Learning

- Concept: Sequence-to-sequence neural translation models (encoder-decoder with attention/transformers)
  - Why needed here: The paper builds on this architecture to implement multi-gender ST models with tag-based gender control
  - Quick check question: What are the three inputs to the decoder in a multi-gender ST model as described in the paper?

- Concept: Adversarial training and gradient reversal for bias mitigation
  - Why needed here: The paper uses gradient reversal to create gender-invariant encoder representations as a method to reduce reliance on vocal traits
  - Quick check question: In gradient reversal, what happens to the gradient during the backward pass?

- Concept: Acoustic feature manipulation (pitch, formants) for speaker attribute control
  - Why needed here: The paper manipulates audio to break the correlation between vocal traits and gender tags, forcing the model to rely on the tag
  - Quick check question: Which two acoustic parameters are altered in the Opposite pitch manipulation strategy?

## Architecture Onboarding

- Component map: Speech audio features (80-dim log mel-filterbank) -> Conformer encoder (12 layers) with gradient reversal discriminator (optional) -> Gender tag (discrete token) -> Transformer decoder (6 layers) -> Translated text

- Critical path: 1. Extract and normalize audio features 2. Encode with Conformer (with or without gradient reversal) 3. Generate target with gender tag as <bos> token 4. (Optional) Apply audio manipulation during training

- Design tradeoffs:
  - Fine-tuning vs. training from scratch: Fine-tuning is faster but perpetuates vocal trait reliance; training from scratch is more effective but requires more data and compute
  - Gradient reversal strength (λ): Higher values enforce invariance more strongly but can destabilize training
  - Audio manipulation probability (p): Higher values break correlations more but may harm translation quality if too aggressive

- Failure signatures:
  - Model consistently defaults to masculine forms regardless of tag → likely still relying on vocal traits
  - Gender accuracy drops when tag conflicts with vocal traits → model prioritizes acoustic cues over tag
  - BLEU score drops significantly with gender control → model struggles to balance translation quality and gender control

- First 3 experiments:
  1. Train a multi-gender model from scratch and evaluate gender accuracy vs. specialized models
  2. Fine-tune a base ST model with gradient reversal and compare to from-scratch results
  3. Apply audio manipulation with p=0.5 and p=0.8 during fine-tuning and measure impact on gender accuracy and BLEU

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why do gradient reversal and audio manipulation techniques consistently reduce the effectiveness of multi-gender models during fine-tuning, but not during training from scratch?
- Basis in paper: [explicit] The paper notes that these techniques "consistently improve both masculine and feminine translations compared to the simple fine-tuned multi-gender model" during fine-tuning, but "neither gradient reversal nor audio manipulations increase the reliance on the tag and the resulting models are more biased toward masculine forms" during training from scratch
- Why unresolved: The paper does not provide a clear explanation for this difference in behavior between fine-tuning and training from scratch
- What evidence would resolve it: Further experiments isolating the effects of gradient reversal and audio manipulation on the base model's reliance on vocal traits during fine-tuning versus training from scratch

### Open Question 2
- Question: Can we develop more effective techniques to reduce the reliance on vocal traits during fine-tuning of multi-gender models?
- Basis in paper: [inferred] The paper mentions that "further research is needed in this direction" after noting that existing techniques only partially improve gender accuracy and overall translation quality during fine-tuning
- Why unresolved: The paper does not propose or test any new techniques beyond gradient reversal and audio manipulation
- What evidence would resolve it: Development and testing of novel techniques that successfully reduce reliance on vocal traits during fine-tuning, leading to improved gender accuracy comparable to training from scratch

### Open Question 3
- Question: How can we build multi-gender models from scratch more efficiently, given the computational cost and data requirements?
- Basis in paper: [explicit] The paper recommends "building multi-gender models from scratch" as it outperforms gender-specialized models, but acknowledges that "training from scratch is not always feasible"
- Why unresolved: The paper does not address the practical challenges of training from scratch, such as computational resources and data availability
- What evidence would resolve it: Research into methods for efficient training of multi-gender models from scratch, such as transfer learning from related tasks or data augmentation techniques

## Limitations

- Fine-tuning approaches consistently fail to overcome the base model's reliance on vocal traits, limiting practical applicability when training from scratch is not feasible
- The paper focuses on a single language pair (English-Italian), raising questions about generalizability to other language pairs with different gender systems
- Limited ablation studies on the effectiveness of gradient reversal strength and audio manipulation parameters make it difficult to optimize these techniques

## Confidence

- Fine-tuning methods: Low confidence - consistently poor results across all experiments
- Training from scratch: Medium confidence - strong results but limited to one language pair and benchmark
- Vocal trait reliance limitation: High confidence - well-supported by experimental evidence across multiple approaches

## Next Checks

1. **Replication on different language pairs**: Train and evaluate the from-scratch multi-gender ST model on English-to-Spanish and English-to-German to test generalizability beyond Italian

2. **Ablation study on fine-tuning**: Systematically test fine-tuning from scratch versus fine-tuning from gender-unaware models with varying amounts of adaptation data to quantify the initialization effect

3. **Detailed analysis of gender control failures**: Analyze specific translation errors where the model fails gender control despite correct tags to identify whether these stem from encoder bias, decoder confusion, or training data imbalances