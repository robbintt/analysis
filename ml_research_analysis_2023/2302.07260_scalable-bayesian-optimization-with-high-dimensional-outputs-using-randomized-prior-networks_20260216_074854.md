---
ver: rpa2
title: Scalable Bayesian optimization with high-dimensional outputs using randomized
  prior networks
arxiv_id: '2302.07260'
source_url: https://arxiv.org/abs/2302.07260
tags:
- optimization
- function
- acquisition
- bayesian
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a Bayesian optimization framework for high-dimensional
  output spaces using bootstrapped ensembles of Randomized Prior Networks (RPNs).
  The approach maps inputs to high-dimensional outputs rather than directly optimizing
  the objective, enabling scalability.
---

# Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks

## Quick Facts
- **arXiv ID:** 2302.07260
- **Source URL:** https://arxiv.org/abs/2302.07260
- **Reference count:** 40
- **Primary result:** Demonstrates faster convergence and better optima than state-of-the-art Gaussian process methods for high-dimensional output Bayesian optimization

## Executive Summary
This paper introduces a deep learning framework for Bayesian optimization (BO) that addresses the challenge of high-dimensional output spaces. The method uses bootstrapped ensembles of Randomized Prior Networks (RPNs) to map inputs to high-dimensional outputs rather than directly optimizing the objective in the high-dimensional space. This approach enables scalable BO while maintaining well-calibrated uncertainty estimates through the combination of empirical risk minimization and randomized prior networks.

## Method Summary
The approach trains an ensemble of RPNs to map input variables to high-dimensional outputs (s-dimensional), then evaluates the objective function on these lower-dimensional representations. Bootstrapped ensembles provide uncertainty quantification, while reparameterized Monte Carlo approximations enable gradient-based acquisition function optimization. The framework extends to constrained multi-fidelity problems by propagating uncertainty from low-fidelity to high-fidelity models. Experiments demonstrate improved convergence and final objective values compared to Gaussian process-based methods across environmental models, PDEs, and engineering design problems.

## Key Results
- Achieves faster convergence than state-of-the-art GP methods on high-dimensional output optimization benchmarks
- Maintains robust performance across different neural network architectures (MLP and DeepONet)
- Successfully handles constrained multi-fidelity optimization problems
- Shows resilience with sparse training data compared to traditional GP approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** RPN-BO avoids the curse of dimensionality by mapping high-dimensional outputs instead of directly optimizing them.
- **Mechanism:** Instead of using Gaussian processes to model the objective function directly in high-dimensional space, RPN-BO trains an ensemble of randomized prior networks to approximate the vector-valued output of a black-box function. The objective is then evaluated on these low-dimensional latent representations, which preserves information while enabling tractable optimization.
- **Core assumption:** The high-dimensional output space contains sufficient information to reconstruct the objective function without direct modeling in that space.
- **Evidence anchors:**
  - [abstract] "we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors."
  - [section 2.1] "unlike most existing BO approaches, the RPN surrogate model is not used to emulate the objective function directly, but rather a physical quantity y that depends on the input x via a mapping noted g(·)"
- **Break condition:** If the mapping g(·) is highly non-injective or the objective f(·) is not well-behaved with respect to the high-dimensional output, the surrogate may fail to capture critical dependencies.

### Mechanism 2
- **Claim:** Bootstrapped ensembles with randomized priors provide well-calibrated uncertainty estimates in sparse data regimes.
- **Mechanism:** Each RPN in the ensemble is trained on a bootstrap sample of the data, and the randomized prior network component captures epistemic uncertainty by acting as a fixed "belief" network. This combination allows the ensemble to produce calibrated predictive distributions even when training data is limited.
- **Core assumption:** The randomized prior network component effectively encodes prior knowledge that regularizes predictions in data-sparse regions.
- **Evidence anchors:**
  - [abstract] "RPNs were developed as an improvement over the classical deep ensembles by taking advantage of exiting prior belief to improve the model predictions in regions where limited or no training data is available."
  - [section 2.1] "Data bootstrapping (i.e. sub-sampling and randomization of the data each network in the ensemble sees during training), enables the efficient statistical estimation of well-calibrated confidence intervals"
- **Break condition:** If the prior network is poorly chosen relative to the true function structure, the uncertainty estimates may be overconfident or underconfident.

### Mechanism 3
- **Claim:** Re-parameterized Monte Carlo approximations enable scalable gradient-based acquisition function optimization.
- **Mechanism:** Standard acquisition functions involve intractable integrals over the posterior. By re-parameterizing these integrals using samples from a base distribution (e.g., standard normal), unbiased gradient estimators are obtained, allowing gradient-based optimization of acquisition functions even for complex multi-point criteria.
- **Core assumption:** The re-parameterization trick can be applied to the posterior predictive distribution induced by the RPN ensemble.
- **Evidence anchors:**
  - [section 2.3] "Reparameterization is needed in order to obtain an unbiased gradient estimator for the MC approximation of the acquisition function... Such re-parameterized MC approximation was proposed for different myopic maximal acquisition functions including: Probability of Improvement [44, 45], Simple Regret [46], Expected Improvement (EI) [47, 48, 49] and Lower Confidence Bound (LCB) [50, 51, 52]"
- **Break condition:** If the posterior is too complex or multimodal, the re-parameterization may not yield low-variance gradient estimates, degrading optimization performance.

## Foundational Learning

- **Concept: Bayesian Optimization**
  - Why needed here: The entire framework is built around BO for expensive black-box optimization; understanding acquisition functions, surrogate modeling, and the exploration-exploitation tradeoff is essential.
  - Quick check question: What is the role of the acquisition function in Bayesian optimization, and how does it balance exploration vs. exploitation?

- **Concept: Randomized Prior Networks (RPNs)**
  - Why needed here: RPNs are the core surrogate model; knowing how they combine trainable and fixed prior networks is critical for implementation and debugging.
  - Quick check question: How does the fixed prior network in an RPN contribute to uncertainty estimation, and why is this beneficial in low-data regimes?

- **Concept: Multi-fidelity modeling**
  - Why needed here: The paper extends to constrained multi-fidelity problems; understanding how low-fidelity data can accelerate optimization is key to applying the method.
  - Quick check question: In a multi-fidelity BO setting, how can uncertainty from a low-fidelity model be propagated to a high-fidelity model?

## Architecture Onboarding

- **Component map:** Input (d-dimensional) -> RPN Ensemble -> High-dimensional outputs (s-dimensional) -> Acquisition function -> Next query point(s)
- **Critical path:**
  1. Initialize training data (initial design points)
  2. Train RPN ensemble on current data
  3. Optimize acquisition function (via re-parameterized MC) to select next point(s)
  4. Evaluate true black-box function at selected point(s)
  5. Update dataset and repeat until convergence
- **Design tradeoffs:**
  - Ensemble size vs. computational cost: Larger ensembles give better uncertainty estimates but increase training time
  - Architecture complexity (MLP vs. DeepONet): Deeper/more complex networks can model richer functions but require more data
  - Acquisition function choice: Different criteria (EI, LCB, TS) offer different exploration-exploitation balances
- **Failure signatures:**
  - Poor convergence: Could indicate insufficient ensemble size, bad prior network initialization, or acquisition function not well-suited to the problem
  - Overconfident predictions in data-sparse regions: May suggest the prior network is too strong or not well-calibrated
  - High variance in acquisition function gradients: Could indicate re-parameterization is not effective for the posterior shape
- **First 3 experiments:**
  1. Reproduce the Environmental Model Function experiment with a small ensemble (e.g., 16 networks) to verify basic functionality
  2. Test the multi-fidelity extension on a synthetic problem with known low/high-fidelity relationship
  3. Compare acquisition functions (EI vs. LCB) on a simple 2D benchmark to understand their impact on convergence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RPN-BO compare to other deep ensemble methods (e.g., Deep Ensembles with deterministic priors or Monte Carlo dropout) for high-dimensional Bayesian optimization?
- Basis in paper: [inferred] The paper introduces RPN-BO as an improvement over classical deep ensembles by incorporating randomized priors, but does not directly compare to other deep ensemble variants.
- Why unresolved: The paper focuses on comparing RPN-BO to GP-based methods and does not explore alternative deep ensemble approaches.
- What evidence would resolve it: Experiments comparing RPN-BO to other deep ensemble methods on the same high-dimensional optimization benchmarks.

### Open Question 2
- Question: What is the impact of the choice of prior distribution (e.g., Gaussian, uniform, or problem-specific priors) on the performance of RPN-BO?
- Basis in paper: [explicit] The paper mentions that RPNs use randomized priors to improve predictions in data-sparse regions, but does not explore different prior distributions.
- Why unresolved: The paper uses a fixed prior distribution without investigating the sensitivity of RPN-BO to different prior choices.
- What evidence would resolve it: Experiments testing RPN-BO with various prior distributions on the same benchmarks.

### Open Question 3
- Question: How does RPN-BO scale with increasing input dimensionality (d) and output dimensionality (s) beyond the tested examples?
- Basis in paper: [inferred] The paper demonstrates RPN-BO on problems with d up to 8 and s up to 65536, but does not explore scalability limits.
- Why unresolved: The paper does not provide theoretical or empirical analysis of RPN-BO's scalability with respect to d and s.
- What evidence would resolve it: Experiments testing RPN-BO on problems with significantly higher d and s values, along with theoretical analysis of computational complexity.

## Limitations
- Limited ablation studies on ensemble size and prior network architecture choices
- No explicit discussion of computational scaling beyond theoretical O(N²d) complexity
- Multi-fidelity extension assumes known low-fidelity-high-fidelity relationships
- Uncertainty quantification quality not validated against ground truth in synthetic experiments

## Confidence
- Ensemble-based uncertainty estimation: Medium
- Dimensionality reduction via output mapping: High
- Multi-fidelity extension: Medium
- Acquisition function optimization: Medium

## Next Checks
1. Conduct synthetic experiments with known ground truth to validate uncertainty calibration across different data regimes
2. Test performance degradation as dimensionality increases beyond the reported benchmarks (s > 20)
3. Compare against established high-dimensional BO methods on problems with known challenging geometries (e.g., strongly correlated inputs)