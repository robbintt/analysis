---
ver: rpa2
title: 'From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small
  Language Models'
arxiv_id: '2311.06754'
source_url: https://arxiv.org/abs/2311.06754
tags:
- system
- reasoning
- reflective
- language
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Cognitive Tree (CogTree), a framework inspired
  by dual process theory in cognitive science, to enhance reasoning capabilities in
  smaller language models (1.5B-7B parameters). The approach decomposes complex reasoning
  problems into manageable sub-problems using an iterative tree structure.
---

# From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with Small Language Models

## Quick Facts
- arXiv ID: 2311.06754
- Source URL: https://arxiv.org/abs/2311.06754
- Reference count: 10
- Primary result: CogTree achieves comparable performance to GPT-3.5 on challenging reasoning tasks with up to 10% accuracy improvement using smaller models

## Executive Summary
This paper introduces Cognitive Tree (CogTree), a framework inspired by dual process theory in cognitive science, to enhance reasoning capabilities in smaller language models (1.5B-7B parameters). The approach decomposes complex reasoning problems into manageable sub-problems using an iterative tree structure. It employs two systems: an intuitive system for rapid generation using in-context examples and a reflective system for scoring and validating responses through comparative learning. Experimental results demonstrate that CogTree achieves comparable performance to GPT-3.5 (175B parameters) on two challenging reasoning tasks (Entailment Bank and GSM8K), with improvements of up to 10% in accuracy.

## Method Summary
CogTree is a framework that enhances reasoning in small language models by decomposing complex problems into simpler sub-problems through a tree structure. It uses an intuitive system (decoder-only model like GPT2-XL or LLaMA-7B) for rapid candidate generation with in-context examples, and a reflective system for validation through contrastive learning. The framework iteratively builds a cognitive tree where each node represents a decomposed sub-problem, with the reflective system scoring and validating each decomposition to guide the reasoning process toward correct solutions.

## Key Results
- Achieves comparable performance to GPT-3.5 (175B parameters) on Entailment Bank and GSM8K reasoning tasks
- Shows up to 10% accuracy improvement over baseline approaches
- Particularly effective for mathematical reasoning tasks
- Demonstrates the effectiveness of problem decomposition and result validation in enhancing smaller model performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing complex problems into manageable sub-problems enables smaller models to achieve performance comparable to much larger models.
- Mechanism: The Cognitive Tree (CogTree) framework systematically breaks down complex reasoning tasks into simpler sub-problems, allowing the model to focus on solving each component separately rather than attempting to solve the entire problem in one step.
- Core assumption: Smaller language models can effectively handle simpler sub-problems when provided with appropriate decomposition and in-context examples.
- Evidence anchors:
  - [abstract] "Experimental results demonstrate that CogTree achieves comparable performance to GPT-3.5 (175B parameters) on two challenging reasoning tasks... with improvements of up to 10% in accuracy"
  - [section 3.1] "To enhance the effectiveness of the Intuitive System, we employ an in-context approach"
  - [corpus] Found 25 related papers, but only 8 were used for analysis. The top related paper "ReasonGraph: Visualisation of Reasoning Paths" has an FMR score of 0.558, suggesting moderate relevance to problem decomposition visualization.

### Mechanism 2
- Claim: Dual-system cognitive approach (intuitive + reflective) improves reasoning accuracy by combining rapid generation with validation.
- Mechanism: The framework employs two distinct systems - an intuitive system for rapid generation of candidate solutions using in-context examples, and a reflective system for scoring and validating responses through comparative learning.
- Core assumption: The reflective system can effectively distinguish between correct and incorrect reasoning paths, guiding the intuitive system to improve over successive iterations.
- Evidence anchors:
  - [abstract] "This construction involves two main components: the implicit extraction module (referred to as the intuitive system) and the explicit reasoning module (referred to as the reflective system)"
  - [section 3.2] "The Reflective System differs from the Intuitive System in terms of its approach of generating insights. While the Intuitive System relies on quick intuition, the Reflective System's role is to evaluate the decompositions"
  - [corpus] The related paper "CAC-CoT: Connector-Aware Compact Chain-of-Thought for Efficient Reasoning Data Synthesis Across Dual-System Cognitive Tasks" suggests growing interest in dual-system approaches, though it has no citations yet.

### Mechanism 3
- Claim: Contrastive learning enhances the reflective system's ability to distinguish correct from incorrect reasoning paths.
- Mechanism: The framework employs a contrastive learning approach where the reflective system learns to maximize the distance between representations of correct decisions and representations of incorrect or ambiguous decisions in vector space.
- Core assumption: Exposing the model to contrastive examples of correct versus incorrect decisions improves its decision-making capabilities more effectively than traditional classification approaches.
- Evidence anchors:
  - [section 3.3] "To augment the model's ability to evaluate the state s, we propose the implementation of a comparative reinforcement approach. This approach entails introducing a new training objective, whereby the model is tasked with maximizing the disparity in vector space between representations of correct decisions and representations of incorrect or ambiguous decisions"
  - [section 3.3] "Let g(v′, ·) be a matching function between negative sample v′ and the positive sample v. The loss function for contrastive learning can be expressed as follows"
  - [corpus] The related paper "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks" has an FMR score of 0.597, suggesting strong relevance to dual-system cognitive approaches.

## Foundational Learning

- Concept: Dual Process Theory in Cognitive Science
  - Why needed here: The entire framework is inspired by this theory, which distinguishes between intuitive (System 1) and reflective (System 2) thinking processes in human cognition.
  - Quick check question: What are the key differences between System 1 and System 2 thinking, and how do they relate to the intuitive and reflective systems in CogTree?

- Concept: In-Context Learning and Few-Shot Prompting
  - Why needed here: The intuitive system relies heavily on in-context examples to generate candidate solutions, requiring understanding of how to effectively retrieve and utilize relevant examples.
  - Quick check question: How does in-context learning differ from traditional fine-tuning, and what are the key considerations when selecting examples for in-context prompting?

- Concept: Contrastive Learning and Representation Learning
  - Why needed here: The reflective system employs contrastive learning to improve its ability to distinguish between correct and incorrect reasoning paths.
  - Quick check question: What is the fundamental principle behind contrastive learning, and how does it differ from traditional classification approaches in terms of learning representations?

## Architecture Onboarding

- Component map:
  - Input problem -> Intuitive System (in-context retrieval and candidate generation) -> Cognitive Tree structure -> Reflective System (evaluation and validation) -> Selected decomposition -> Repeat until solution

- Critical path:
  1. Input problem to intuitive system
  2. Retrieve relevant in-context examples from decomposition set
  3. Generate candidate decompositions
  4. Pass candidates to reflective system for evaluation
  5. Select highest-scoring decomposition
  6. Repeat until problem is fully decomposed or maximum iterations reached

- Design tradeoffs:
  - Model size vs. performance: Smaller models (1.5B-7B) can achieve comparable results to much larger models (175B) through the framework
  - Number of in-context examples (K): Higher K improves retrieval quality but increases computational cost
  - Tree depth: Deeper trees allow more complex problem decomposition but increase inference time
  - Score granularity: Three-category system (sure/likely/impossible) vs. more fine-grained scoring

- Failure signatures:
  - Model gets stuck in infinite loops of decomposition without reaching a solution
  - Reflective system consistently approves incorrect decompositions
  - In-context retrieval returns irrelevant examples leading to poor candidate generation
  - Performance degrades significantly on problems requiring more than 10 decomposition steps

- First 3 experiments:
  1. Compare performance of intuitive system alone vs. full CogTree framework on a simple mathematical reasoning task
  2. Test different values of K (number of in-context examples) to find optimal retrieval performance
  3. Evaluate the impact of contrastive learning vs. traditional classification for the reflective system using a held-out validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CogTree's performance scale with larger model sizes beyond 7B parameters?
- Basis in paper: [inferred] The paper notes that "Due to the limitation of computational resources, we did not test our method on larger scale models" and suggests "As the model size increases, using our approach may lead to further improvement in the accuracy of answers to these questions."
- Why unresolved: The paper only tested CogTree on models up to 7B parameters and explicitly acknowledges this limitation without providing empirical evidence for larger models.
- What evidence would resolve it: Systematic experiments testing CogTree on models with 10B, 20B, and 50B+ parameters would provide empirical data on performance scaling and whether accuracy improvements plateau or continue to increase.

### Open Question 2
- Question: How does the contrastive learning approach specifically impact the Reflective System's performance compared to traditional classification training?
- Basis in paper: [explicit] The paper states "the effectiveness of this training method is found to be unsatisfactory" and describes implementing a contrastive learning approach to "enhance the model's ability to distinguish between different states" and "maximize the disparity in vector space between representations of correct decisions and representations of incorrect or ambiguous decisions."
- Why unresolved: While the paper mentions adopting contrastive learning, it does not provide ablation studies or quantitative comparisons showing the performance difference between contrastive learning and traditional classification training for the Reflective System.
- What evidence would resolve it: Direct comparison experiments showing performance metrics (accuracy, F1 score) for the Reflective System trained with contrastive learning versus traditional classification would quantify the impact of this approach.

### Open Question 3
- Question: What is the impact of varying the number of candidate decompositions generated at each step on final performance?
- Basis in paper: [inferred] The paper mentions generating "top_beam=3 answers" during inference and sampling "5 times for each step" in different contexts, suggesting beam size and sampling count are hyperparameters that could affect performance.
- Why unresolved: The paper does not systematically explore how different numbers of candidate decompositions (e.g., top-1, top-3, top-5, top-10) affect the quality of the reasoning process or final accuracy, leaving this as an unexplored design choice.
- What evidence would resolve it: Experiments varying the number of candidate decompositions generated at each step (e.g., testing beam sizes of 1, 3, 5, 10) with corresponding performance metrics would reveal the optimal balance between computational cost and reasoning accuracy.

## Limitations

- Performance heavily depends on quality of in-context examples and contrastive learning implementation details
- Framework's scalability to more complex reasoning tasks beyond mathematical problems and entailment reasoning remains unproven
- Computational overhead of iterative decomposition and validation may offset benefits for real-time applications

## Confidence

- High Confidence: The core premise that problem decomposition can enhance reasoning performance in smaller models is well-supported by the empirical results showing 10% accuracy improvements over baseline approaches.
- Medium Confidence: The dual-system cognitive approach (intuitive + reflective) shows promise, but the specific implementation details of contrastive learning and validation scoring are insufficiently detailed for complete replication.
- Low Confidence: The framework's generalization capability to domains outside of mathematical reasoning and structured entailment tasks remains largely speculative based on the current evidence.

## Next Checks

1. **Cross-Domain Transferability Test**: Evaluate CogTree performance on scientific reasoning tasks (e.g., physics problem-solving or logical inference in non-mathematical domains) to assess generalization beyond mathematical reasoning.

2. **Ablation Study on Core Components**: Systematically remove or modify key components (in-context learning, contrastive validation, tree decomposition depth) to quantify their individual contributions to the observed performance gains.

3. **Computational Efficiency Analysis**: Measure wall-clock inference time and memory usage for the iterative CogTree approach versus direct prompting with larger models across varying problem complexities to determine practical deployment viability.