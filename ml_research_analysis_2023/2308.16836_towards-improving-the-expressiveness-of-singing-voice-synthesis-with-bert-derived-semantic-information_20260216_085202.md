---
ver: rpa2
title: Towards Improving the Expressiveness of Singing Voice Synthesis with BERT Derived
  Semantic Information
arxiv_id: '2308.16836'
source_url: https://arxiv.org/abs/2308.16836
tags:
- singing
- voice
- pitch
- semantic
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a BERT-derived semantic embedding approach
  for improving expressiveness in singing voice synthesis. The system introduces a
  semantic extraction module using pre-trained BERT to incorporate lyrics semantics,
  an energy predictor to model expressive energy variations, and a redesigned pitch
  predictor that predicts pitch ratios rather than absolute values.
---

# Towards Improving the Expressiveness of Singing Voice Synthesis with BERT Derived Semantic Information

## Quick Facts
- arXiv ID: 2308.16836
- Source URL: https://arxiv.org/abs/2308.16836
- Reference count: 0
- Primary result: BERT-derived semantic embeddings improve expressiveness in singing voice synthesis, with MOS improvement of 0.492 over VISinger

## Executive Summary
This paper proposes a novel approach to enhance expressiveness in singing voice synthesis by incorporating BERT-derived semantic embeddings from lyrics. The system introduces a semantic extraction module using pre-trained BERT, an energy predictor to model expressive energy variations, and a redesigned pitch predictor that predicts pitch ratios rather than absolute values. Objective metrics show improvements across pitch prediction (F0 MAE reduced from 13.193 to 12.897), duration accuracy (Dur MAE from 8.451 to 6.682), and energy modeling (Energy MAE from 21.974 to 16.523). Subjective listening tests demonstrate a MOS improvement of 0.492 over VISinger, with 62.9% preference for expressiveness, achieving more natural pitch variations and better energy modeling in synthesized singing voices.

## Method Summary
The system builds on VISinger architecture with three key modifications: (1) a semantic extraction module that uses pre-trained BERT to extract bidirectional contextual embeddings from Chinese lyrics, which are upsampled to phoneme-level and encoded into the prior encoder; (2) an energy predictor module that takes frame-level hidden sequences and predicts energy for each frame, converted to logarithmic domain; and (3) a redesigned pitch predictor that predicts the ratio of synthesized pitch to note pitch rather than absolute values. The model is trained for 200k steps on 8 GPUs with AdamW optimizer on the Opencpop dataset (3,756 utterances, 5.2 hours total).

## Key Results
- F0 MAE reduced from 13.193 to 12.897, showing improved pitch prediction accuracy
- Subjective MOS improvement of 0.492 over VISinger baseline
- 62.9% preference for expressiveness in ABX tests compared to baseline
- Energy MAE improved from 21.974 to 16.523, indicating better energy modeling

## Why This Works (Mechanism)

### Mechanism 1
- Claim: BERT-derived semantic embeddings provide meaningful context about lyric content that guides more expressive singing voice synthesis.
- Mechanism: The pre-trained BERT model extracts bidirectional contextual embeddings from Chinese lyrics, which are upsampled to phoneme-level and encoded into the prior encoder. These semantic representations help the model capture linguistic nuances and emotional cues that influence expressiveness.
- Core assumption: The semantic information in lyrics (word types, meanings) contains useful signals for determining appropriate expressiveness in synthesized singing.
- Evidence anchors: [abstract] "We use text representation of lyrics extracted from pre-trained BERT as additional input to the model. The representation contains information about semantics of the lyrics, which could help SVS system produce more expressive and natural voice." [section 2.1] "We hypothesize that the semantic information contains useful information to guide the SVS model synthesize more natural and expressive singing voice."
- Break condition: If the semantic embeddings don't correlate with perceptible expressiveness differences, or if the upsampling process introduces noise that overwhelms semantic signals.

### Mechanism 2
- Claim: Predicting pitch ratios rather than absolute values reduces off-key issues and enables more natural pitch variations.
- Mechanism: Instead of directly predicting the final pitch, the system predicts the ratio of synthesized pitch to note pitch, then multiplies by the given note pitch. This constrains predictions to reasonable deviations around target notes.
- Core assumption: Natural singing involves controlled deviations around target pitches, and modeling these as ratios is more stable than predicting absolute values.
- Evidence anchors: [abstract] "to attenuate the off-key issues, the pitch predictor is re-designed to predict the real to note pitch ratio" [section 2.2] "our method predicts the ratio of given note pitch with the aims to synthesize more natural singing voice and avoid the out-of-tune issue"
- Break condition: If the ratio prediction becomes unstable for extreme pitch ranges or if the multiplication step amplifies small prediction errors into large pitch deviations.

### Mechanism 3
- Claim: Explicit energy prediction models the wider range of energy variations in singing compared to speech, improving expressiveness.
- Mechanism: An energy predictor module takes frame-level hidden sequences and predicts the energy of each frame, which is converted to logarithmic domain. This predicted energy is added to the synthesis process alongside pitch and semantic information.
- Core assumption: Singing voice has more dynamic energy variations than speech, and modeling these explicitly helps capture expressiveness.
- Evidence anchors: [abstract] "we further introduce an energy predictor to stabilize the synthesized voice and model the wider range of energy variations that also contribute to the expressiveness of singing voice" [section 2.3] "Compared with speech, singing voice have a wider range of energy variations. It is vital to model the energy changes of the singing voice to improve the expressiveness of synthesized singing voice."
- Break condition: If energy prediction errors cause unnatural volume fluctuations or if the model becomes overly sensitive to energy signal noise.

## Foundational Learning

- Concept: Bidirectional transformer architectures and BERT embeddings
  - Why needed here: Understanding how BERT extracts contextual semantic information from text is crucial for implementing and troubleshooting the semantic extraction module
  - Quick check question: How does BERT's bidirectional attention mechanism differ from traditional left-to-right language models in capturing context?

- Concept: Variational inference and normalizing flows in generative models
  - Why needed here: The system builds on VISinger which uses VAE-based posterior encoder with normalizing flow-based prior encoder - understanding these concepts is essential for model architecture comprehension
  - Quick check question: What role do normalizing flows play in improving the flexibility of the prior distribution in variational autoencoders?

- Concept: MIDI pitch representation and frequency conversion
  - Why needed here: The pitch predictor works with MIDI pitch IDs and converts them to frequencies using the standard formula, requiring understanding of musical pitch representation
  - Quick check question: How does the MIDI pitch ID system map to actual frequencies, and what is the significance of the 440 Hz reference point?

## Architecture Onboarding

- Component map: Text → BERT → semantic embeddings → upsampling → text encoder → semantic information → prior encoder → pitch ratio prediction + energy prediction → latent variable estimation → decoder → waveform
- Critical path: Text → BERT → semantic embeddings → upsampling → text encoder → semantic information → prior encoder → pitch ratio prediction + energy prediction → latent variable estimation → decoder → waveform
- Design tradeoffs: Using BERT adds computational overhead but provides rich semantic context; predicting pitch ratios constrains the model but may limit extreme expressiveness; explicit energy prediction adds control but requires careful normalization.
- Failure signatures: Poor MOS scores indicate general quality issues; high F0 MAE suggests pitch prediction problems; high Energy MAE indicates energy modeling issues; low preference scores in ABX tests suggest expressiveness deficits.
- First 3 experiments:
  1. Implement the semantic extraction module with a simplified upsampling approach to verify semantic information integration works
  2. Test the pitch ratio predictor independently by comparing it against a baseline absolute pitch predictor on a validation set
  3. Evaluate the energy predictor's impact by synthesizing samples with and without energy prediction enabled

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several implicit questions arise from the methodology and results presented.

## Limitations
- Limited training corpus (5.2 hours total) may not capture full diversity of expressive singing styles
- Evaluated only on Mandarin Chinese singing, limiting generalizability to other languages
- Reliance on BERT assumes pre-trained embeddings contain sufficient linguistic nuance for musical expressiveness

## Confidence

- **High Confidence**: The architectural modifications (pitch ratio prediction, energy predictor) are technically sound and the objective metric improvements are statistically measurable and directly attributable to the proposed changes
- **Medium Confidence**: The subjective MOS improvement of 0.492 over VISinger is meaningful, though the preference test showing 62.9% for expressiveness suggests the improvement is noticeable but not overwhelming
- **Low Confidence**: The assumption that BERT-derived semantic embeddings significantly contribute to expressiveness improvements, as this mechanism is less directly validated compared to the architectural changes

## Next Checks

1. **Cross-linguistic validation**: Test the BERT semantic extraction approach on non-Chinese lyrics (e.g., English or other languages) to verify if the semantic embedding approach generalizes beyond Mandarin

2. **Ablation study on semantic components**: Systematically remove the BERT semantic module while keeping all other components constant to isolate its specific contribution to the MOS improvement

3. **Expressive range stress test**: Evaluate the system's performance on highly expressive singing styles (opera, emotional ballads) versus more constrained styles (pop, choral) to identify where the pitch ratio and energy prediction mechanisms show their strengths and limitations