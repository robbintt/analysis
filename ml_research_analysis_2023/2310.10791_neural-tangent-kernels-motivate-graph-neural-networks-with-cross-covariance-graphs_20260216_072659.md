---
ver: rpa2
title: Neural Tangent Kernels Motivate Graph Neural Networks with Cross-Covariance
  Graphs
arxiv_id: '2310.10791'
source_url: https://arxiv.org/abs/2310.10791
tags:
- equation
- have
- graph
- where
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper studies the role of neural tangent kernels (NTKs) in\
  \ graph neural networks (GNNs) for regression tasks. It establishes that for a two-layer\
  \ GNN with tanh activation, using the cross-covariance matrix between input and\
  \ output data as the graph shift operator (GSO) maximizes alignment\u2014a measure\
  \ of correlation between the NTK and data that governs training convergence and\
  \ generalization."
---

# Neural Tangent Kernels Motivate Graph Neural Networks with Cross-Covariance Graphs

## Quick Facts
- arXiv ID: 2310.10791
- Source URL: https://arxiv.org/abs/2310.10791
- Reference count: 40
- Key outcome: Using cross-covariance matrix as GSO maximizes NTK alignment, leading to faster convergence and better generalization in GNNs

## Executive Summary
This paper establishes theoretical guarantees that using the cross-covariance matrix between input and output data as the graph shift operator (GSO) maximizes alignment—a measure of correlation between the neural tangent kernel (NTK) and data—for graph neural networks (GNNs). The analysis focuses on two-layer GNNs with tanh activation and extends to deeper architectures empirically. Experiments on resting-state fMRI data demonstrate that GNNs with cross-covariance graphs converge faster and achieve lower training and test errors compared to those using only input covariance.

## Method Summary
The method involves constructing graph neural networks where the graph shift operator is chosen as the cross-covariance matrix between input and output data rather than traditional graph structures. For two-layer GNNs with tanh activation, the NTK analysis shows that this choice maximizes alignment, which governs training convergence and generalization. The implementation uses graph filters with K=2 filter taps, F=50 hidden units, and Adam optimization. The theoretical framework extends from linear graph filters to non-linear GNNs through Hermite polynomial expansions of the activation function.

## Key Results
- Theorem 2 proves that alignment for graph filters is maximized when GSO S is proportional to cross-covariance matrix CXY
- Theorem 3 establishes lower bounds on alignment for two-layer GNN with tanh, showing CXY-based GSO is optimal
- Experiments on HCP-Y A resting-state fMRI data show GNNs with CXY GSO converge faster and achieve lower training/test errors than CXX-based GNNs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: For two-layer GNN with tanh, using cross-covariance CXY as GSO maximizes alignment
- Mechanism: NTK depends on GSO and input data through Hermite expansion; first non-zero term B in tanh expansion is proportional to CXY; alignment optimization over bounded-norm GSOs leads to S* ∝ CXY
- Core assumption: NTK constant during training (infinite width) and second term ∆B small relative to first term B
- Evidence anchors:
  - [abstract]: "theoretical guarantees on the optimality of the alignment for a two-layer GNN...characterized by the graph shift operator being a function of the cross-covariance"
  - [section]: "Theorem 3...A ≥ (c − d/ξ) Alin"
  - [corpus]: Weak
- Break condition: If NTK varies during training, or ∆B not small relative to B, or Alin ≥ ξ · ||Q||F ||Blin||F assumption fails

### Mechanism 2
- Claim: For graph filter, alignment maximized when GSO proportional to CXY
- Mechanism: Alignment Afilt = sum of (tr(Sk CXY))²; by Cauchy-Schwarz, maximized when all Sk aligned with CXY, achieved when S* ∝ CXY (Theorem 2)
- Core assumption: Frobenius norm constraint on sum of Sk ensures gradient descent convergence
- Evidence anchors:
  - [abstract]: "theoretical guarantees on the optimality of the alignment for a two-layer GNN"
  - [section]: "Theorem 2 clearly demonstrates...optimal GSO that optimizes AL(S, X, Y) and CXY"
  - [corpus]: Weak
- Break condition: If Frobenius norm constraint violated, or graph filter inappropriate model

### Mechanism 3
- Claim: Larger alignment leads to faster convergence and better generalization
- Mechanism: Theorem 1 shows training error bounds inversely proportional to alignment A; Lemma 8 and Theorem 4 extend to generalization error
- Core assumption: NTK constant during training and loss function is quadratic
- Evidence anchors:
  - [abstract]: "association between the eigenvectors of the NTK kernel and given data...govern the rate of convergence of gradient descent, as well as generalization"
  - [section]: "Equation (9) shows that the convergence of gradient descent is positively correlated with A"
  - [corpus]: Weak
- Break condition: If NTK not constant, or loss not quadratic, or data violates theorem assumptions

## Foundational Learning

- Concept: Neural Tangent Kernels (NTKs)
  - Why needed here: Provides framework to analyze learning/generalization of over-parameterized networks including GNNs; alignment between NTKs and data governs gradient descent convergence and generalization
  - Quick check question: What is the NTK for a two-layer GNN with tanh activation in the infinite width limit?

- Concept: Graph Neural Networks (GNNs) and Graph Shift Operators (GSOs)
  - Why needed here: GNNs operate on graph-structured data; choice of GSO (adjacency, Laplacian, covariance) significantly impacts performance; paper shows cross-covariance is optimal GSO for maximizing alignment
  - Quick check question: How does choice of GSO affect NTK and alignment for GNN?

- Concept: Hermite Polynomials and their expansions
  - Why needed here: Hermite expansion of activation function (e.g., tanh) used to analyze NTK and alignment for non-linear GNNs; first non-zero term proportional to cross-covariance matrix
  - Quick check question: What is Hermite expansion of tanh function, and how does it relate to NTK and alignment?

## Architecture Onboarding

- Component map: Input data (multi-variate time series) -> Graph Neural Network (two-layer GNN with tanh) -> Graph Shift Operator (cross-covariance matrix) -> Training (gradient descent with Adam) -> Evaluation (training/test loss, convergence rate, generalization)

- Critical path:
  1. Prepare input data and construct cross-covariance matrix
  2. Initialize GNN parameters
  3. Train GNN using gradient descent with Adam optimizer
  4. Evaluate training and test loss, convergence rate, and generalization

- Design tradeoffs:
  - Choice of activation function: tanh vs. other non-linear functions
  - Depth of GNN: Two-layer vs. deeper architectures
  - Number of filter taps: K = 2 vs. larger values
  - Graph shift operator: Cross-covariance vs. input covariance matrix

- Failure signatures:
  - Slow convergence or poor generalization: Check if cross-covariance matrix is appropriate GSO for data
  - Unstable training: Check if NTK constant during training (infinite width limit) and if second term in NTK expansion small relative to first term

- First 3 experiments:
  1. Train two-layer GNN with tanh using cross-covariance matrix as GSO vs. input covariance matrix; compare performance
  2. Vary GNN depth (two-layer, three-layer, four-layer) and assess impact on training/test loss, convergence rate, and generalization
  3. Experiment with different activation functions (ReLU, sigmoid) and evaluate impact on GNN's performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How tight are the lower bounds derived for alignment in both graph filters and GNNs, and how does this tightness affect the practical performance gap between cross-covariance and covariance-based GNNs?
- Basis in paper: [explicit] Paper derives lower bounds on alignment (e.g., Lemma 1 and Corollary 1) but acknowledges "lack of thorough analysis of the tightness of the lower bounds"
- Why unresolved: Theoretical analysis focuses on optimizing these lower bounds, but paper doesn't quantify how close bounds are to true alignment values or impact on real-world performance
- What evidence would resolve it: Empirical studies comparing actual alignment values for cross-covariance vs covariance-based GNNs, along with theoretical proofs establishing bounds on gap between derived lower bounds and true alignment

### Open Question 2
- Question: Does optimality of cross-covariance as GSO extend to regression tasks where input and output data have different dimensionalities, and if so, how should cross-covariance matrix be defined in such cases?
- Basis in paper: [inferred] Theoretical results and experiments focus on same-dimensionality cases (e.g., predicting future time steps of same multivariate time series); discussion mentions "restricted focus on a dataset with input and output vectors of the same dimensionalities"
- Why unresolved: Cross-covariance matrix naturally defined when input/output spaces have same dimension, but generalization to mismatched dimensions unclear
- What evidence would resolve it: Theoretical extensions of alignment analysis to mismatched dimensionalities, along with experiments on regression tasks with different input/output feature spaces

### Open Question 3
- Question: How does eigenvalue spread of NTK (λmax/λmin) vary across different GSO choices (cross-covariance vs covariance), and does this variation explain generalization performance differences observed in experiments?
- Basis in paper: [explicit] Paper mentions "question remains that for the classes of predictors discussed...how much does λmax(Θ)/λmin(Θ) vary between predictors"
- Why unresolved: While paper establishes larger alignment correlates with better generalization, doesn't investigate whether NTK eigenvalue spread differences across GSO choices contribute to this effect
- What evidence would resolve it: Empirical analysis of NTK eigenvalue spectra for different GSOs across multiple datasets, combined with theoretical bounds on how eigenvalue spread affects generalization error term in Theorem 4

## Limitations

- Theoretical analysis relies heavily on infinite-width NTK regime which may not hold in practical finite-width settings
- Gap between theory (two-layer GNN) and practice (deeper GNNs) bridged only through empirical observation without formal guarantees for deeper architectures
- Assumption that second-order term in NTK expansion is negligible compared to first term is critical but not rigorously verified in experiments

## Confidence

- High confidence in Theorem 2 (alignment maximization for graph filters)
- Medium confidence in Theorem 3 (two-layer GNN optimality bound) due to reliance on Alin ≥ ξ · ||Q||F ||Blin||F assumption
- Medium confidence in empirical claims about deeper GNNs, as theoretical guarantees don't extend beyond two layers

## Next Checks

1. Measure actual NTK dynamics during training (not just at initialization) to verify constant NTK assumption holds for chosen architecture widths
2. Quantify relative magnitude of first and second terms in NTK expansion for different activation functions and network widths
3. Test whether alignment maximization principle extends to other GNN architectures (graph attention networks, graph transformers) beyond spectral GNN framework