---
ver: rpa2
title: Has It All Been Solved? Open NLP Research Questions Not Solved by Large Language
  Models
arxiv_id: '2305.12544'
source_url: https://arxiv.org/abs/2305.12544
tags:
- language
- data
- research
- such
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper compiles research directions in NLP that remain rich
  for exploration despite the rise of large language models (LLMs). It identifies
  14 research areas and 45 specific research directions, organized into themes such
  as multilingual models, reasoning, knowledge bases, language grounding, computational
  social science, online environments, child language acquisition, non-verbal communication,
  synthetic datasets, interpretability, efficient NLP, NLP in education and healthcare,
  and ethics.
---

# Has It All Been Solved? Open NLP Research Questions Not Solved by Large Language Models

## Quick Facts
- arXiv ID: 2305.12544
- Source URL: https://arxiv.org/abs/2305.12544
- Reference count: 40
- Key outcome: This paper compiles 14 research areas and 45 specific research directions in NLP that remain rich for exploration despite LLM advances, organized into themes spanning multilingual models, reasoning, knowledge bases, language grounding, computational social science, online environments, child language acquisition, non-verbal communication, synthetic datasets, interpretability, efficient NLP, NLP in education and healthcare, and ethics.

## Executive Summary
This paper addresses the misconception that large language models (LLMs) have solved most NLP problems by systematically identifying research directions that remain rich for exploration. The authors argue that public discourse conflates LLM progress with overall NLP progress, potentially discouraging junior researchers from pursuing important but LLM-independent research areas. Through a structured brainstorming process involving PhD students, the paper identifies 14 research themes encompassing 45 specific research directions that require capabilities beyond current LLMs, including areas demanding reasoning, grounding, specialized data, or human-centered solutions.

## Method Summary
The authors compiled NLP research directions through a brainstorming process involving PhD students who wrote ideas on sticky notes, followed by a clustering process to group initial ideas into main themes. The resulting taxonomy identifies 14 research areas with 45 specific research directions, categorized by their dependency on LLMs as either LLM-independent, LLM-limited, or LLM-enhancing based on requirements for data, reasoning, or grounding capabilities.

## Key Results
- Identified 14 research themes encompassing 45 specific research directions in NLP that remain unsolved by LLMs
- Categorized research areas by LLM dependency: LLM-independent (Sections 2-6, 8, 12), data-limited (Sections 9, 13, 14), and LLM-enhancing (Sections 7, 10, 11, 15)
- Highlighted key LLM limitations including reasoning capabilities, grounding in physical environments, and data requirements for specialized domains
- Provided guidance for junior researchers to identify impactful research areas beyond LLM-centric work

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs "suck the air out of the room" by displacing attention from other NLP research areas
- Mechanism: Public discourse conflates entire field with LLMs, making junior researchers anxious about thesis topics
- Core assumption: Junior researchers equate LLM progress with overall NLP progress
- Evidence anchors:
  - [abstract] "recent progress in large language models (LLMs) has enabled the deployment of many generative NLP applications. At the same time, it has also led to a misleading public discourse that 'it's all been solved'"
  - [section] "Replacing NLP with LLMs is problematic for two main reasons. First, the space of language insights, methods, and broad applications in NLP is much more vast than what can be accomplished by simply predicting the next word."
- Break condition: If discourse separates LLM progress from broader NLP achievements

### Mechanism 2
- Claim: The paper creates a structured taxonomy of unexplored NLP research areas
- Mechanism: Systematic brainstorming by diverse PhD students identifies 14 themes with 45 specific research directions
- Core assumption: PhD students can identify novel research directions outside LLM scope
- Evidence anchors:
  - [abstract] "This paper compiles NLP research directions that are rich for exploration... We identify fourteen different research areas encompassing 45 research directions"
  - [section] "Our brainstorming process started with ideas written on sticky notes by all the authors of this document, followed by a 'clustering' process where we grouped the initial ideas and identified several main themes"
- Break condition: If taxonomy becomes outdated as LLM capabilities expand

### Mechanism 3
- Claim: Research directions are categorized by dependency on LLMs
- Mechanism: Areas classified as LLM-independent, LLM-limited, or LLM-enhancing based on data, reasoning, or grounding requirements
- Core assumption: Research areas can be meaningfully categorized by LLM dependency
- Evidence anchors:
  - [section] "These areas could be broadly divided into areas that cannot be addressed by LLMs for being too data-hungry or for lacking reasoning or grounding abilities (Sections 2â€“6, 8, 12); areas for which we cannot use LLMs because of not having the right data (Sections 9, 13, 14); or areas that could contribute to improving the abilities and quality of LLMs (Sections 7, 10, 11, 15)"
- Break condition: If LLM capabilities blur these distinctions

## Foundational Learning

- Concept: Research direction identification
  - Why needed here: Paper relies on systematic identification of novel NLP research areas
  - Quick check question: What systematic methods were used to identify research directions?

- Concept: Taxonomy construction
  - Why needed here: Research directions organized into 14 themes with 45 specific areas
  - Quick check question: How were the 14 research themes determined?

- Concept: LLM limitations analysis
  - Why needed here: Understanding what LLMs cannot do drives identification of research gaps
  - Quick check question: What are the key limitations of LLMs identified in the paper?

## Architecture Onboarding

- Component map:
  - Brainstorming session -> Sticky notes -> Clustering -> Theme grouping -> Research direction specification -> Taxonomy creation
  - Corpus neighbor analysis -> FMR scoring -> Related paper identification
  - Public discourse analysis -> LLM progress assessment -> Research gap identification

- Critical path:
  1. PhD student brainstorming session
  2. Clustering of initial ideas into themes
  3. Research direction specification for each theme
  4. Categorization by LLM dependency
  5. Corpus neighbor analysis for validation

- Design tradeoffs:
  - Breadth vs depth: 14 themes with 45 directions vs fewer themes with more detail
  - LLM focus vs broader NLP: Emphasizes LLM-independent areas but acknowledges LLM-enhanced directions
  - Academic vs industry perspective: Focuses on academic research directions

- Failure signatures:
  - Taxonomy becomes outdated as LLM capabilities expand
  - Over-reliance on current LLM limitations that may be overcome
  - Insufficient coverage of emerging NLP applications

- First 3 experiments:
  1. Replicate brainstorming session with different research group
  2. Update taxonomy based on 1-year LLM capability changes
  3. Conduct validation survey with junior NLP researchers on research direction relevance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs be trained to perform robust formal reasoning, such as numerical and logical reasoning, at a level comparable to human performance?
- Basis in paper: [explicit] The paper discusses the current limitations of LLMs in formal reasoning tasks, such as numerical reasoning and logical reasoning, and suggests exploring ways to integrate external reasoning systems or combine neural networks with symbolic AI to improve their performance.
- Why unresolved: LLMs currently struggle with formal reasoning tasks and often make obvious mistakes that a formal or symbolic system would not make. There is a need to develop new techniques to enable LLMs to generalize and perform robust formal reasoning.
- What evidence would resolve it: Empirical studies demonstrating the effectiveness of new techniques in improving the formal reasoning abilities of LLMs, as well as comparisons with human performance on standardized reasoning tasks.

### Open Question 2
- Question: How can we develop NLP models that can effectively handle code-switching, considering the unique challenges posed by the phenomenon?
- Basis in paper: [explicit] The paper highlights the challenges of code-switching (CS) in NLP, including the creation of "new" words, the difficulty in obtaining training data, and the need for models to be robust to out-of-vocabulary tokens. It also mentions the potential of using LLMs to generate synthetic CS data and the need for more comprehensive benchmarks to evaluate performance.
- Why unresolved: Current NLP models struggle with code-switching due to the unique challenges it presents. There is a lack of effective techniques for handling CS data, and the development of comprehensive benchmarks to evaluate CS-specific models is still an ongoing effort.
- What evidence would resolve it: Successful development and evaluation of NLP models that can effectively handle code-switching, as demonstrated by their performance on comprehensive benchmarks and their ability to generate fluent and contextually appropriate CS text.

### Open Question 3
- Question: How can we ensure that NLP models and applications are fair and unbiased, and do not perpetuate or amplify existing societal inequalities?
- Basis in paper: [explicit] The paper discusses the importance of fairness in NLP and mentions the need for methods to evaluate the fairness of models, detect and mitigate bias, and examine the correlation between dataset creation practices and model bias. It also highlights the potential for NLP to exacerbate inequalities if not developed and deployed responsibly.
- Why unresolved: NLP models can inherit and amplify biases present in the data they are trained on, leading to unfair outcomes for certain groups. There is a need for effective techniques to ensure fairness and mitigate bias in NLP models and applications.
- What evidence would resolve it: Empirical studies demonstrating the effectiveness of techniques in reducing bias and ensuring fairness in NLP models, as well as real-world evaluations of the impact of these techniques on reducing inequalities.

## Limitations

- The specific methods used to compile the list of research directions are not fully detailed, limiting reproducibility of the taxonomy creation process
- The categorization of research areas by LLM dependency may become outdated as LLM capabilities rapidly evolve
- The identified 45 research directions may be biased by the particular perspectives of the contributing PhD students rather than representing a comprehensive view

## Confidence

- **High confidence**: The overall thesis that many NLP research areas remain unexplored despite LLM advances is well-supported
- **Medium confidence**: The taxonomy creation process through PhD student brainstorming is reasonable but not fully detailed
- **Medium confidence**: The categorization framework by LLM dependency is conceptually sound but boundaries may shift with evolving capabilities

## Next Checks

1. **Replicate the brainstorming methodology**: Conduct the same sticky-note clustering exercise with a different NLP research group to assess whether similar research directions emerge, testing the robustness of the taxonomy creation process.

2. **Update test for temporal validity**: After one year, reassess whether the identified research areas remain LLM-independent or if LLM capabilities have encroached on these domains, measuring how quickly the taxonomy becomes outdated.

3. **Junior researcher survey validation**: Survey 50+ junior NLP researchers to determine whether the compiled research directions align with their perceptions of viable thesis topics and whether the taxonomy helps them identify research opportunities.