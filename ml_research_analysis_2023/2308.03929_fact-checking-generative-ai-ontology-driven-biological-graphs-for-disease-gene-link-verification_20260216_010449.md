---
ver: rpa2
title: 'Fact-Checking Generative AI: Ontology-Driven Biological Graphs for Disease-Gene
  Link Verification'
arxiv_id: '2308.03929'
source_url: https://arxiv.org/abs/2308.03929
tags:
- graphs
- pubmed
- chatgpt
- knowledge
- nodes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrates an ontology-driven approach for verifying
  disease-gene relationships extracted from ChatGPT-generated biomedical texts. Using
  knowledge graphs constructed from PubMed literature and ChatGPT-3.5 Turbo outputs,
  the authors applied a fact-checking algorithm that compares link structures between
  the two sources.
---

# Fact-Checking Generative AI: Ontology-Driven Biological Graphs for Disease-Gene Link Verification

## Quick Facts
- arXiv ID: 2308.03929
- Source URL: https://arxiv.org/abs/2308.03929
- Reference count: 20
- Accuracy of disease-gene link verification ranged from 70% to 86%

## Executive Summary
This study presents an ontology-driven approach for verifying disease-gene relationships extracted from ChatGPT-generated biomedical texts. The method constructs knowledge graphs from both PubMed literature and ChatGPT-3.5 Turbo outputs, then compares link structures using a fact-checking algorithm. By analyzing overlapping nodes and edges between the two sources, the approach quantifies the accuracy of AI-generated biomedical content while leveraging network centrality metrics to identify potentially novel relationships. The results demonstrate that ChatGPT can generate biomedical content with accuracy comparable to established literature while occasionally suggesting new connections for further investigation.

## Method Summary
The methodology involves constructing knowledge graphs from PubMed abstracts and ChatGPT-generated biomedical text using ontology-driven feature extraction. Disease and symptom terms from Human Disease Ontology (DOID) and Symptom Ontology (SYMP) are chunked into bigrams and used to identify relationships in both datasets. Graphs are built based on co-occurrence and proximity measures, then compared using a fact-checking algorithm that calculates overlapping nodes and edges. Network centrality metrics (degree, closeness, betweenness) are applied to distinguish reliable information from potential noise, with accuracy measured as the ratio of verified links between sources.

## Key Results
- Accuracy of disease-gene link verification ranged from 70% to 86% across 10 samples of 250 records each
- ChatGPT-generated graphs contained more links than PubMed counterparts in some cases, suggesting potential for discovering novel biomedical relationships
- Network centrality analysis helped identify factual knowledge versus potential noise in AI-generated content
- The approach successfully verified existing biomedical relationships while maintaining sensitivity to potentially novel connections

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ontology-driven knowledge graph construction enables systematic comparison between ChatGPT-generated and PubMed biomedical data
- Mechanism: The method uses structured ontologies (DOID and SYMP) to chunk terms into bigrams, extract features from both datasets, and construct graphs based on co-occurrence and proximity
- Core assumption: Ontology terms can be effectively chunked into bigrams that capture the essential meaning for matching across different text sources
- Evidence anchors:
  - [abstract] "We designed an ontology-driven fact-checking algorithm that compares biological graphs constructed from approximately 200,000 PubMed abstracts with counterparts constructed from a dataset generated using the ChatGPT-3.5 Turbo model."
  - [section] "We adopted a biological networks approach that enables the systematic interrogation of ChatGPT's linked entities."

### Mechanism 2
- Claim: Network centrality metrics can distinguish factual knowledge from potential noise in AI-generated content
- Mechanism: The approach calculates degree, closeness, and betweenness centrality for overlapping nodes between PubMed and ChatGPT graphs
- Core assumption: Centrality metrics provide meaningful signals about the reliability and importance of nodes in biomedical knowledge graphs
- Evidence anchors:
  - [abstract] "Results show ChatGPT-generated graphs contained more links than PubMed counterparts in some cases, suggesting potential for discovering novel biomedical relationships while maintaining high accuracy in verified facts."
  - [section] "The first reason, is that the total number of disease-symptom links (40) of the GPT graph exceeds the total number of disease-symptom links (30) of the Pubmed graph which is the only unique case among all the 10 graphs."

### Mechanism 3
- Claim: Comparing link structures between knowledge graphs enables quantitative fact-checking accuracy measurement
- Mechanism: The fact-checking algorithm counts overlapping nodes and edges between PubMed and ChatGPT graphs, then calculates ratios of actual links to possible links
- Core assumption: The PubMed-derived knowledge graph represents a reliable ground truth that can be used to evaluate AI-generated content
- Evidence anchors:
  - [abstract] "accuracy of disease-gene link verification ranged from 70% to 86%"
  - [section] "Out of all the graphs, the factual link ratio between any two graphs reached its peak at 60%."

## Foundational Learning

- Concept: Graph theory and network centrality metrics
  - Why needed here: Understanding how degree, closeness, and betweenness centrality work is essential for interpreting the results and designing experiments
  - Quick check question: What does a high betweenness centrality value indicate about a node's role in a network?

- Concept: Ontology-based text processing and chunking
  - Why needed here: The method relies on converting ontology terms into searchable bigrams, requiring understanding of natural language processing techniques
  - Quick check question: Why might ontology terms need to be broken into bigrams rather than searched as complete phrases?

- Concept: Knowledge graph construction from text
  - Why needed here: The entire approach depends on building comparable graphs from different text sources using consistent methods
  - Quick check question: What are the key differences between co-occurrence-based and proximity-based graph construction methods?

## Architecture Onboarding

- Component map: Text → Ontology chunking → Graph construction → Link comparison → Accuracy calculation
- Critical path: Data ingestion → Ontology processing → Graph construction → Analysis pipeline → Evaluation
- Design tradeoffs:
  - Using bigrams vs full terms: Bigrams increase matching flexibility but may reduce precision
  - Co-occurrence vs proximity links: Co-occurrence is simpler but proximity captures more nuanced relationships
  - Manual vs automated ChatGPT data collection: Manual ensures quality but limits scale
- Failure signatures:
  - Low overlap ratios suggest either poor ontology matching or fundamental differences between sources
  - High centrality in ChatGPT but not PubMed may indicate hallucination or novel discoveries
  - Inconsistent node counts across runs suggest randomization issues
- First 3 experiments:
  1. Verify ontology chunking works correctly by testing with known term variations
  2. Compare graph structures using a small, manually verified dataset to validate the approach
  3. Test the fact-checking algorithm on synthetic data with known ground truth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the accuracy of fact-checking generative AI outputs be improved beyond the current 70-86% range?
- Basis in paper: [explicit] The paper states that accuracy ranged from 70% to 86% and suggests further investigation is needed to improve verification
- Why unresolved: The study demonstrates a proof-of-concept approach but does not explore optimization strategies or alternative methodologies to enhance accuracy
- What evidence would resolve it: Comparative studies testing different fact-checking algorithms, larger datasets, or alternative knowledge graph construction methods that show improved accuracy metrics

### Open Question 2
- Question: Can ChatGPT-generated knowledge graphs consistently discover novel disease-gene relationships that are later validated by experimental research?
- Basis in paper: [explicit] The paper notes that ChatGPT graphs sometimes contained more links than PubMed counterparts, suggesting potential for discovering novel relationships
- Why unresolved: The study focuses on comparing existing knowledge graphs but does not track whether novel links identified by ChatGPT are subsequently validated through laboratory experiments or clinical studies
- What evidence would resolve it: Longitudinal studies tracking ChatGPT-generated novel links over time to see if they appear in subsequent peer-reviewed publications or are confirmed through experimental validation

### Open Question 3
- Question: How does the fact-checking methodology scale when applied to different biomedical domains beyond disease-gene relationships?
- Basis in paper: [explicit] The authors mention that future work may involve introducing new ontologies (Gene ontology, Drug, Chemical Entity, and drug target ontologies) to expand the approach
- Why unresolved: The current study is limited to disease-gene relationships, and it remains unclear whether the same methodology would be equally effective for other biomedical relationships
- What evidence would resolve it: Application of the same fact-checking framework to different biomedical relationship types (e.g., drug-disease, protein-protein interactions) with comparable accuracy metrics

## Limitations
- The study used a relatively small sample size (10 datasets with 250 records each) which may not capture full variability in ChatGPT output quality
- Accuracy measurements depend heavily on the completeness and accuracy of the PubMed-derived ground truth, which may contain gaps or biases
- The methodology may not scale effectively to domains with rapidly evolving knowledge or where ground truth is less established

## Confidence
- **High confidence**: The core methodology of using ontology-driven knowledge graphs for fact-checking is well-established and the basic accuracy measurements are reliable within the tested scope
- **Medium confidence**: The generalizability of the accuracy rates to larger, more diverse datasets and other biomedical domains
- **Low confidence**: The ability to reliably distinguish novel discoveries from hallucinations based solely on centrality metrics and link structure comparisons

## Next Checks
1. **Scale validation**: Replicate the experiment using 10x larger datasets (2,500 records per sample) to verify if accuracy rates remain consistent as the volume of AI-generated content increases
2. **Cross-domain testing**: Apply the same fact-checking approach to ChatGPT-generated content in different biomedical subdomains (e.g., drug-gene interactions, pathway analysis) to assess domain-specific performance variations
3. **Ground truth robustness**: Compare results using multiple knowledge bases (not just PubMed) as ground truth to determine how sensitive the accuracy measurements are to the choice of reference source