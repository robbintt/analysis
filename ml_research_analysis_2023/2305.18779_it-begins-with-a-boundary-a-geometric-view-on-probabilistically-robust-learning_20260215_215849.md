---
ver: rpa2
title: 'It begins with a boundary: A geometric view on probabilistically robust learning'
arxiv_id: '2305.18779'
source_url: https://arxiv.org/abs/2305.18779
tags:
- which
- adversarial
- probper
- theorem
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the geometric structure of probabilistically
  robust learning (PRL) and identifies a flaw in the original PRL formulation by Robey
  et al. [2022].
---

# It begins with a boundary: A geometric view on probabilistically robust learning

## Quick Facts
- arXiv ID: 2305.18779
- Source URL: https://arxiv.org/abs/2305.18779
- Reference count: 40
- Key outcome: Corrected probabilistically robust learning formulation using geometric perimeter functionals improves adversarial robustness on MNIST and CIFAR-10

## Executive Summary
This paper studies the geometric structure of probabilistically robust learning (PRL) and identifies a flaw in the original PRL formulation by Robey et al. [2022]. The authors propose a corrected version using probabilistic perimeter functionals that penalize misclassified points likely to be corrected by adversarial attacks. They prove existence of solutions for both hard and soft classifiers under weak conditions using novel relaxation methods. The corrected PRL is interpreted as regularized empirical risk minimization where the decision boundary length acts as a regularizer. Numerical experiments on MNIST and CIFAR-10 show that the geometric modification improves adversarial robustness without sacrificing clean accuracy for moderate p values, while maintaining comparable performance for extreme p values.

## Method Summary
The method implements a geometric correction to probabilistically robust learning by introducing a probabilistic perimeter functional that penalizes decision boundaries where high-probability adversarial attacks can flip classification. The approach uses concave, non-decreasing functions Ψ to create submodular perimeter functionals, enabling relaxation techniques to prove existence of solutions. For computational tractability, the CVaR relaxation is shown to be equivalent to using a specific piecewise linear concave function Ψp. The algorithm alternates between solving an inner CVaR problem and optimizing the classifier, implemented using AdaDelta for MNIST and SGD with momentum for CIFAR-10 with CNN and ResNet-18 architectures respectively.

## Key Results
- Geometric modification improves adversarial robustness without sacrificing clean accuracy for moderate p values
- Existence of solutions proven for both hard and soft classifiers under weak conditions using relaxation methods
- CVaR relaxation equivalent to specific piecewise linear concave function Ψp, enabling computational tractability
- Decision boundary length acts as a regularizer in the corrected PRL formulation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The probabilistic perimeter functional ProbPer(A) acts as a regularizer that penalizes decision boundaries where high-probability adversarial attacks can flip the classification, effectively smoothing the decision surface.
- Mechanism: By integrating the probability that a random perturbation x' from distribution px changes the class prediction, the functional creates a cost for maintaining thin or spiky regions of the decision boundary that are vulnerable to probabilistic attacks.
- Core assumption: The distribution px centered at each point captures the attack model's uncertainty, and the function Ψ appropriately scales this penalty.
- Evidence anchors: [abstract], [section 2.1]
- Break condition: If px does not accurately model the attack distribution or if Ψ is not chosen to properly scale the penalty, the regularization may fail to improve robustness.

### Mechanism 2
- Claim: The existence of solutions to the probabilistically robust learning problem is guaranteed through novel relaxation techniques that convexify the perimeter functional.
- Mechanism: By introducing a concave and non-decreasing function Ψ, the perimeter functional ProbPerΨ becomes submodular, allowing the use of convex relaxation methods and coarea formulas to prove existence of minimizers.
- Core assumption: The concavity and monotonicity of Ψ enable the submodularity of ProbPerΨ, which is crucial for the relaxation argument.
- Evidence anchors: [section 2.2], [section 2.3]
- Break condition: If Ψ is not concave or not non-decreasing, the submodularity fails, and the relaxation techniques may not apply.

### Mechanism 3
- Claim: The CVaR relaxation of PRL is equivalent to using a specific piecewise linear concave function Ψp, making the problem computationally tractable while preserving theoretical guarantees.
- Mechanism: By defining Ψp(t) := min{t/p, 1}, the CVaR at level p for the loss 1A equals Ψp(Px'∼p[1A(x')≠y]). This equivalence allows the use of convex optimization techniques for CVaR to solve the PRL problem.
- Core assumption: The equivalence between CVaR and the specific Ψp holds for the 0-1 loss in binary classification.
- Evidence anchors: [section 3], [section A.5]
- Break condition: If the loss function is not the 0-1 loss or if the classification is not binary, the equivalence may not hold, and the computational benefits of CVaR may be lost.

## Foundational Learning

- Concept: Submodularity and its role in optimization
  - Why needed here: Submodularity of ProbPerΨ under concavity and monotonicity of Ψ is crucial for proving existence of solutions and for the relaxation techniques used.
  - Quick check question: What property of a set function ensures that the greedy algorithm provides a constant-factor approximation to the optimal solution?

- Concept: Gamma-convergence and its application to variational problems
  - Why needed here: Gamma-convergence is used to study the asymptotic behavior of the probabilistic perimeter as the adversarial budget ε approaches zero, linking PRL to local perimeter regularization.
  - Quick check question: How does Gamma-convergence ensure that minimizers of a sequence of functionals converge to minimizers of the limiting functional?

- Concept: Conditional Value at Risk (CVaR) and its optimization properties
  - Why needed here: CVaR is used as a relaxation of the probabilistic essential supremum to make the PRL problem computationally tractable while preserving theoretical guarantees.
  - Quick check question: Why is CVaR considered a coherent risk measure, and how does this property aid in optimization?

## Architecture Onboarding

- Component map: Input space X -> Hypothesis class H -> Loss function ℓ -> Attack model family {px} -> Perimeter functional ProbPerΨ -> CVaR relaxation

- Critical path:
  1. Define the probabilistic perimeter functional ProbPerΨ based on the chosen Ψ and attack model px.
  2. Formulate the PRL problem as minimization of the regularized risk using ProbPerΨ.
  3. Apply relaxation techniques (e.g., convexification via Ψ, relaxation to soft classifiers) to prove existence of solutions.
  4. Use CVaR relaxation for computational tractability.
  5. Implement the algorithm (e.g., alternating minimization of inner CVaR problem and outer classifier optimization).
  6. Validate on datasets (e.g., MNIST, CIFAR-10) and compare with baseline methods.

- Design tradeoffs:
  - Choice of Ψ: Concave and non-decreasing functions ensure submodularity but may limit expressiveness; linear functions like Ψp enable CVaR equivalence but may not capture all nuances.
  - Choice of px: Should accurately model the attack distribution; overly conservative models may hurt clean accuracy, while too permissive models may not improve robustness.
  - Relaxation to soft classifiers: Enables broader applicability but may introduce additional complexity in the hypothesis class.

- Failure signatures:
  - Degraded clean accuracy without significant improvement in adversarial robustness.
  - Computational intractability if CVaR relaxation is not used or if the hypothesis class is too complex.
  - Failure to converge if the relaxation techniques do not apply (e.g., if Ψ is not concave).

- First 3 experiments:
  1. Implement the PRL algorithm for binary classification on a simple dataset (e.g., synthetic data with known decision boundary) using Ψ(t) = 1t>p and compare with standard empirical risk minimization.
  2. Vary the parameter p and observe the tradeoff between clean accuracy and adversarial robustness.
  3. Replace Ψ(t) = 1t>p with Ψp(t) = min{t/p, 1} and verify the equivalence with CVaR relaxation by comparing the results.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise relationship between probabilistically robust learning (PRL) and adversarial training in the limit as p approaches 0, and how does this convergence manifest in practical algorithms?
- Basis in paper: [explicit] The paper discusses the formal limit of PRL as p → 0 being the worst-case adversarial problem, and mentions that Proposition 1 indicates that for very small adversarial budgets the regularization effect of both probabilistically robust learning and adversarial training is dominated by the same local perimeter.
- Why unresolved: The paper acknowledges that algorithms for solving PRL exhibit limitations for very small values of p (in the computation of CVaRp), suggesting that the theoretical limit may not be practically achievable. Additionally, the paper states that proving Gamma-convergence for general sets (not just smooth ones) is beyond the scope of the current work.
- What evidence would resolve it: Numerical experiments demonstrating the behavior of PRL algorithms as p approaches 0, comparing the solutions and regularization effects with adversarial training. A proof of Gamma-convergence for the probabilistic perimeter to the local perimeter for general sets.

### Open Question 2
- Question: How does the choice of function Ψ in the probabilistic perimeter functional ProbPerΨ affect the learnability and generalization properties of probabilistically robust classifiers?
- Basis in paper: [explicit] The paper introduces the function Ψp(t) = min{t/p, 1} which allows for deep connections between theoretical and computational aspects, and mentions that Raman et al. [2023] proved PAC learnability if Ψ is Lipschitz. The paper also states that concavity of Ψ is needed for existence proofs using relaxation techniques.
- Why unresolved: The paper suggests that the choice of Ψ affects both the theoretical properties (existence of solutions) and practical aspects (learnability), but does not provide a comprehensive analysis of how different Ψ functions impact the performance of PRL classifiers. The paper also raises the question of whether concavity of Ψ suffices to guarantee PAC learnability.
- What evidence would resolve it: Empirical studies comparing the performance of PRL classifiers using different Ψ functions (e.g., Ψ(t) = 1t>p, Ψp(t), and other concave functions) on various datasets. Theoretical analysis of the learnability properties of PRL for different classes of Ψ functions.

### Open Question 3
- Question: What is the precise nature of the trade-off between accuracy and robustness in probabilistically robust learning, and how does it depend on the parameter p?
- Basis in paper: [explicit] The paper discusses the interpolation between clean and adversarial accuracy offered by PRL, and mentions that increasing p interpolates between low and high clean accuracies. However, the paper also states that it does not necessarily result in a direct interpolation between high and low adversarial or probabilistic accuracy.
- Why unresolved: The paper provides empirical evidence suggesting that the relationship between p and the accuracy-robustness trade-off is not straightforward, but does not offer a theoretical explanation for this behavior. The paper also notes that PRL does not completely solve the accuracy vs. robustness trade-off, which remains a challenging problem.
- What evidence would resolve it: A theoretical analysis of the accuracy-robustness trade-off in PRL, potentially using concepts from statistical learning theory or game theory. Extensive empirical studies examining the behavior of PRL classifiers across a wide range of p values and datasets, including analysis of the probabilistic and adversarial accuracy metrics.

## Limitations

- The connection to practical implementation remains partially speculative due to limited details in the experimental setup
- Computational overhead introduced by the geometric modification compared to standard PRL is not fully characterized
- Results may not generalize beyond MNIST and CIFAR-10 datasets
- Theoretical analysis of Gamma-convergence for general sets is beyond the scope of the current work

## Confidence

- Medium confidence in the core claims regarding the geometric interpretation of PRL and the proposed correction
- The theoretical framework is well-grounded in geometric measure theory and convex optimization
- Limited corpus evidence discussing the geometric aspects of PRL or the specific relaxation techniques employed
- Uncertainties remain about numerical behavior across different dataset geometries and computational overhead

## Next Checks

1. Verify the equivalence between CVaR relaxation and the piecewise linear Ψp function through numerical experiments on synthetic data with known decision boundaries.

2. Test the algorithm's sensitivity to the choice of Ψ by comparing performance across multiple concave, non-decreasing functions beyond the linear case.

3. Implement the geometric PRL method on a simple binary classification problem and compare convergence behavior and solution quality against standard empirical risk minimization.