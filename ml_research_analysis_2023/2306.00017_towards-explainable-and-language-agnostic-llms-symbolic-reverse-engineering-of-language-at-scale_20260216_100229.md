---
ver: rpa2
title: 'Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering
  of Language at Scale'
arxiv_id: '2306.00017'
source_url: https://arxiv.org/abs/2306.00017
tags:
- language
- llms
- have
- these
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a symbolic approach to reverse engineering
  language at scale, combining the strengths of symbolic representations with bottom-up
  reverse engineering. The core idea is to analyze linguistic communication to discover
  primitive relations and construct an ontology implicit in language use.
---

# Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale

## Quick Facts
- arXiv ID: 2306.00017
- Source URL: https://arxiv.org/abs/2306.00017
- Reference count: 24
- Primary result: Proposes symbolic approach combining bottom-up reverse engineering with symbolic representations to create explainable, language-agnostic LLMs

## Executive Summary
This paper proposes a novel approach to creating explainable and language-agnostic large language models through symbolic reverse engineering of language at scale. The core idea involves discovering primitive relations from linguistic communication to construct an implicit ontology, then representing word meanings as dimensions defined by these relations. By analyzing massive corpora to find concept-property pairs, nominalizing concepts into entities, and relating them via primitive relations derived from copular verb analysis, the method aims to overcome the explainability limitations of current subsymbolic LLMs.

## Method Summary
The proposed method involves analyzing massive corpora to discover concept-property pairs, then nominalizing concepts into entities and relating them via primitive relations derived from copular verb analysis. This process constructs an ontology implicit in language use, with word meanings represented as dimensions defined by primitive relations. The approach claims to enable explainable and systematic compositionality unlike subsymbolic approaches, potentially solving issues like logical paradoxes and semantic riddles through reversible composition operations.

## Key Results
- Theoretical framework for symbolic representation of word meanings using primitive relations
- Claims of language-agnostic primitive relations derived from copular verb analysis
- Proposal for explainable compositionality through set-based representations
- No specific metrics provided, focuses on conceptual advantages over subsymbolic approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bottom-up reverse engineering of language at scale reveals ontological structures embedded in linguistic communication
- Mechanism: Analyzing massive corpora to discover concept-property pairs, nominalizing concepts into entities, and relating them via primitive relations uncovers implicit ontology in language use
- Core assumption: Language contains implicit ontological structures that can be systematically extracted through distributional analysis
- Evidence anchors: Abstract and section 4 describe the methodology; weak evidence from neighbor papers discussing related symbolic approaches
- Break condition: Distributional analysis fails to reveal consistent concept-property patterns or nominalization cannot be systematically applied across languages

### Mechanism 2
- Claim: Primitive relations derived from copular verb analysis provide language-agnostic dimensions for word meanings
- Mechanism: Analyzing copular verb constructions systematically uncovers primitive relations that serve as dimensions defining word meanings
- Core assumption: Copular verb analysis can systematically uncover all necessary primitive relations for language understanding
- Evidence anchors: Section 4 and 5 discuss primitive relation discovery and application; no direct empirical evidence provided
- Break condition: Copular verb analysis misses important semantic relations or primitive relations prove insufficient for cross-linguistic generalization

### Mechanism 3
- Claim: Symbolic representation enables explainable and systematic compositionality unlike subsymbolic approaches
- Mechanism: Set-based representations preserve semantic maps through composition in ways that distributed representations cannot
- Core assumption: Set-based representations enable reversible composition operations
- Evidence anchors: Section 2 and 5 discuss explainability and compositionality advantages; theoretical claim based on architectural differences
- Break condition: Set-based composition operations fail to scale to complex linguistic phenomena or introduce new forms of brittleness

## Foundational Learning

- **Distributional semantics and the distributional hypothesis**
  - Why needed here: The entire approach builds on Harris's distributional semantics hypothesis that "similarity in meaning is similarity in linguistic distribution"
  - Quick check question: Can you explain how word embeddings approximate word meanings through co-occurrence patterns?

- **Nominalization and reification of properties**
  - Why needed here: The method requires converting properties like "articulate" into abstract entities like "articulation" to create primitive relations
  - Quick check question: What is the difference between saying "Mary is wise" and "Mary has the property of wisdom" in terms of ontological commitment?

- **Type hierarchies and subset relationships**
  - Why needed here: Discovered concept-property pairs must be organized into hierarchies to represent the implicit ontology
  - Quick check question: If "old" applies to "car" and "car" is a subtype of "vehicle", what can you infer about the applicability of "old" to "vehicle"?

## Architecture Onboarding

- **Component map**: Corpus analysis pipeline -> Nominalization engine -> Primitive relation discoverer -> Ontology constructor -> Similarity calculator
- **Critical path**: 1. Corpus analysis to discover app(p,c) pairs 2. Nominalization of properties into entities 3. Primitive relation identification 4. Ontology construction through hierarchy building 5. Similarity computation for word meanings
- **Design tradeoffs**: Symbolic vs. subsymbolic (explainability vs. flexibility), Universality vs. specificity (language-agnostic relations vs. language-specific nuances), Completeness vs. tractability (comprehensive ontology vs. computational resources)
- **Failure signatures**: Inconsistent concept-property patterns across corpora, inability to systematically nominalize properties, primitive relations that don't generalize across languages, similarity measures that don't align with human judgments
- **First 3 experiments**: 1. Test corpus analysis on small controlled dataset to verify concept-property pair discovery 2. Validate nominalization engine on properties with clear abstract entity counterparts 3. Verify primitive relation discovery using copular verb constructions across multiple languages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we empirically validate the effectiveness of the symbolic approach in capturing the full complexity of natural language semantics compared to current LLM approaches?
- Basis in paper: [inferred] The paper proposes a symbolic approach but does not provide specific metrics or comparative studies against LLM performance
- Why unresolved: The symbolic approach is theoretical and requires empirical testing to determine its practical effectiveness and scalability
- What evidence would resolve it: Comparative studies showing the symbolic approach's performance on standard NLP benchmarks, along with qualitative analyses of explainability and bias reduction

### Open Question 2
- Question: What are the specific computational challenges and resource requirements for implementing the proposed symbolic reverse engineering process at scale?
- Basis in paper: [explicit] The paper mentions the need for massive corpus analysis but does not discuss computational feasibility or resource requirements
- Why unresolved: The scale of analysis required for discovering all relevant concept-property pairs and constructing the ontology is not addressed
- What evidence would resolve it: Detailed computational complexity analysis and resource estimation for implementing the symbolic approach on large-scale language data

### Open Question 3
- Question: How can the proposed symbolic approach handle polysemy and context-dependent meanings of words more effectively than current distributional methods?
- Basis in paper: [inferred] The paper discusses word meanings as dimensions but does not explicitly address the challenge of polysemy
- Why unresolved: The symbolic approach's ability to capture multiple meanings and contextual variations is not demonstrated or discussed
- What evidence would resolve it: Case studies and examples showing how the symbolic approach handles polysemous words and context-dependent meanings compared to current methods

## Limitations
- Lack of empirical validation for the proposed symbolic approach
- Uncertainty about computational feasibility for massive corpus analysis
- Potential failure of nominalization process across diverse linguistic contexts

## Confidence

- **Low confidence** in core mechanism of ontology discovery through distributional analysis (no empirical evidence)
- **Medium confidence** in theoretical value of symbolic representations for explainability (general consensus on subsymbolic limitations)
- **Low confidence** in language-agnostic primitive relations (cross-linguistic validation not demonstrated)
- **Low confidence** in systematic compositionality claims (mathematical properties not rigorously examined)

## Next Checks

1. **Controlled corpus validation**: Test concept-property pair discovery mechanism on a small, annotated corpus with known ontological relationships, measuring precision and recall against human annotations

2. **Cross-linguistic primitive relation validation**: Implement copular verb analysis across multiple languages (English, Mandarin, Arabic) to verify primitive relations are truly language-agnostic and capture equivalent semantic distinctions

3. **Compositionality benchmark**: Evaluate set-based composition operations on benchmark linguistic tasks involving intensional contexts, logical paradoxes, and semantic riddles to verify claimed advantages over subsymbolic approaches