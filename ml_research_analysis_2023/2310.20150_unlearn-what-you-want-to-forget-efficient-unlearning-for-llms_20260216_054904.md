---
ver: rpa2
title: 'Unlearn What You Want to Forget: Efficient Unlearning for LLMs'
arxiv_id: '2310.20150'
source_url: https://arxiv.org/abs/2310.20150
tags:
- data
- unlearning
- arxiv
- language
- preprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EUL, an efficient unlearning method for LLMs
  that can unlearn user-requested data by learning lightweight unlearning layers through
  a selective teacher-student objective. The authors also introduce a fusion mechanism
  to merge different unlearning layers into a single unified layer, allowing the model
  to handle a sequence of unlearning requests.
---

# Unlearn What You Want to Forget: Efficient Unlearning for LLMs

## Quick Facts
- **arXiv ID**: 2310.20150
- **Source URL**: https://arxiv.org/abs/2310.20150
- **Reference count**: 11
- **Primary result**: EUL achieves 65.6% accuracy on forgot set while maintaining 93.0% test accuracy and 100% retained accuracy with 1/6 of the updating time compared to re-training

## Executive Summary
This paper proposes EUL, an efficient unlearning method for LLMs that can unlearn user-requested data by learning lightweight unlearning layers through a selective teacher-student objective. The authors introduce a fusion mechanism to merge different unlearning layers into a single unified layer, allowing the model to handle a sequence of unlearning requests. Experiments on classification and generation tasks with T5 models of different scales show that EUL outperforms state-of-the-art baselines in terms of unlearning effectiveness while maintaining task performance and reducing update time.

## Method Summary
EUL introduces lightweight unlearning layers that are inserted after feed-forward networks in each transformer layer of a frozen LLM. These layers are trained using a selective teacher-student objective that minimizes KL divergence between the original model and updated model on retained data while maximizing it on forgotten data. A fusion mechanism uses linear regression to combine multiple unlearning layers when handling sequential unlearning requests. The method also incorporates negated original training objectives to enhance forgetting of requested information.

## Key Results
- On IMDB dataset, EUL achieved the lowest accuracy (65.6%) on the forgot set while keeping the best test accuracy (93.0%)
- Maintained 100% retained accuracy with only 1/6 of the updating time compared to full re-training
- Successfully handled sequential unlearning requests through the fusion mechanism

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Selective teacher-student objective allows the model to retain knowledge for retained data while forgetting specific requested data
- Mechanism: The unlearning layer is trained to minimize KL divergence between the original model and the updated model on retained data, while maximizing KL divergence on forgotten data
- Core assumption: The original model's outputs on retained data can serve as effective teacher signals
- Break condition: If retained data is too similar to forgotten data, the selective objective may fail to properly distinguish between them

### Mechanism 2
- Claim: Fusion mechanism enables efficient handling of sequential unlearning requests by merging multiple unlearning layers
- Mechanism: Individual unlearning layers are trained separately and then merged into a single layer using linear regression that minimizes squared error between their outputs on forgotten data
- Core assumption: Linear combination can effectively merge the effects of multiple unlearning layers without additional training
- Break condition: If forgotten data sets have high overlap or contradictory requirements, the linear combination may not adequately satisfy all unlearning objectives

### Mechanism 3
- Claim: Adding negated original training objectives helps ensure complete forgetting of requested information
- Mechanism: The method includes a negated masked language modeling loss on forgotten data, pushing the model to unlearn knowledge patterns present in that data
- Core assumption: Original pre-training objective contains information about forgotten data that can be explicitly negated
- Break condition: If forgotten data contains patterns too distributed across model parameters, negating a single objective may not fully remove the information

## Foundational Learning

- **Concept: Teacher-student learning framework**
  - Why needed here: The unlearning approach relies on having the original model serve as a teacher for retained data while the unlearning layer learns to deviate from it for forgotten data
  - Quick check question: What would happen if the teacher model's outputs on retained data were inaccurate or outdated?

- **Concept: Parameter-efficient fine-tuning**
  - Why needed here: The method introduces small unlearning layers instead of updating the entire model, making the approach computationally feasible for large LLMs
  - Quick check question: How does the number of parameters in the unlearning layer affect both unlearning effectiveness and computational efficiency?

- **Concept: Linear regression for weight fusion**
  - Why needed here: The fusion mechanism uses a closed-form solution to merge multiple unlearning layers, enabling efficient sequential unlearning without additional training
  - Quick check question: Under what conditions might the linear regression approach fail to properly combine unlearning layers?

## Architecture Onboarding

- **Component map**: Original LLM (T5-base/3b) -> Unlearning layers (0.5% of parameters) -> Selective objectives (KL divergence, task loss, negated LLM loss) -> Fusion mechanism (linear regression)

- **Critical path**: 1) Insert unlearning layers into transformer architecture, 2) Train unlearning layers using selective teacher-student objective, 3) For sequential requests, apply fusion mechanism to merge layers, 4) Validate effectiveness on test, retained, and forgot sets

- **Design tradeoffs**: Smaller unlearning layers (0.5% of parameters) provide faster updates but may limit unlearning capacity; more unlearning layers improve granularity but complicate fusion; linear fusion approach is efficient but may not capture complex interactions

- **Failure signatures**: High accuracy on forgot set but low accuracy on test set suggests over-forgetting; low accuracy on both forgot and test sets indicates under-forgetting or poor adaptation; slow convergence during training may indicate insufficient capacity in unlearning layers

- **First 3 experiments**: 1) Single unlearning request on IMDB with 0.5% forgotten data, measuring test/retained/forgot accuracy, 2) Sequential unlearning with 2 requests on IMDB, comparing EUL vs EUL-fuse, 3) Ablation study removing each objective term to assess individual contributions to performance

## Open Questions the Paper Calls Out

- **Open Question 1**: How does EUL perform when unlearning data from larger backbone models like GPT-4 or LLAMA models? (Basis: The authors note experiments were conducted primarily on T5-base/3b models and suggest exploring EUL's performance on larger models in future work)

- **Open Question 2**: What are the long-term effects of using EUL on model generalization and robustness to adversarial attacks? (Basis: The paper does not discuss long-term impact of unlearning on model generalization or robustness)

- **Open Question 3**: How does EUL handle unlearning in multimodal models that process both text and images? (Basis: The paper focuses on text-based language models and does not explore application to multimodal models)

## Limitations

- Fusion mechanism's effectiveness for handling sequential unlearning requests beyond the tested 2-3 requests remains uncertain
- The linear regression approach for combining unlearning layers may fail when forgotten data sets have significant overlap or contradictory requirements
- The claim that negating original training objectives ensures complete forgetting lacks comprehensive empirical validation

## Confidence

- **High confidence**: Basic unlearning effectiveness and computational efficiency improvements compared to retraining
- **Medium confidence**: Fusion mechanism's effectiveness for handling sequential unlearning requests
- **Medium confidence**: Negating original training objectives ensures complete forgetting

## Next Checks

1. **Stress test the fusion mechanism** by creating unlearning scenarios with high overlap between forgotten data sets and measuring how well the fused layer satisfies all forgetting requirements

2. **Benchmark against emerging unlearning methods** that have been published since this paper, particularly those using more sophisticated techniques like knowledge distillation or data augmentation

3. **Test scalability** by applying EUL to a larger model (e.g., T5-XXL) and measuring whether computational efficiency gains and unlearning effectiveness scale proportionally with model size