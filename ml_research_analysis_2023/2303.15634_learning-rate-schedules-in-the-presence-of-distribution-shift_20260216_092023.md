---
ver: rpa2
title: Learning Rate Schedules in the Presence of Distribution Shift
arxiv_id: '2303.15634'
source_url: https://arxiv.org/abs/2303.15634
tags:
- learning
- rate
- distribution
- regret
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how to set learning rates for stochastic gradient
  descent when the data distribution changes over time. The authors model the problem
  as minimizing dynamic regret against a changing sequence of optimal models.
---

# Learning Rate Schedules in the Presence of Distribution Shift

## Quick Facts
- arXiv ID: 2303.15634
- Source URL: https://arxiv.org/abs/2303.15634
- Reference count: 40
- Key outcome: Proposes adaptive learning rate schedules that increase with distribution shift to minimize regret in online learning

## Executive Summary
This paper addresses the challenge of setting learning rates for stochastic gradient descent when data distributions change over time. The authors develop a framework for optimizing learning rates in the presence of distribution shift by minimizing dynamic regret against changing optimal models. They derive novel learning rate schedules for linear regression, general convex losses, and non-convex losses, all of which adapt to the magnitude of distribution shifts. The key insight is that optimal learning rates should increase as distribution shift increases, to maintain exploration and adapt quickly to changing environments.

## Method Summary
The paper models online learning under distribution shift as minimizing dynamic regret against a sequence of optimal models. For linear regression, they derive a stochastic differential equation that approximates SGD behavior and characterize the optimal learning rate schedule. For general convex losses, they propose adaptive schedules that minimize an upper bound on regret. For non-convex losses, they modify the regret notion to use gradient norms and derive an optimal learning rate that minimizes an upper bound. Across all settings, the learning rate schedules are designed to increase with the magnitude of distribution shifts.

## Key Results
- Derived a novel SDE approximation for SGD under distribution shift in linear regression
- Proved upper and lower bounds on regret for convex losses that differ only by constants
- Demonstrated through experiments that adaptive learning rates outperform fixed rates in high-dimensional regression and medical flow cytometry applications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Learning rate schedules should increase with distribution shift to maintain exploration and adapt quickly
- Mechanism: The SDE shows that larger distribution shifts increase drift in both mean and variance of the process. Larger learning rates counteract this drift to keep regret low
- Core assumption: The SDE accurately approximates discrete SGD updates
- Evidence anchors: Abstract confirms optimal rates increase with distribution shift; Section 3 shows larger shifts require larger learning rates to reduce drift
- Break condition: If SDE approximation breaks down (very large step sizes or batch sizes)

### Mechanism 2
- Claim: For convex losses, optimal learning rate balances tracking oracle model vs controlling gradient variance
- Mechanism: Regret bound includes terms for distance to oracle, gradient variance, and distribution shift. Optimal rate increases with shift to track oracle faster while controlling variance
- Core assumption: Convexity allows for tight regret bound that can be minimized analytically
- Evidence anchors: Abstract states upper and lower bounds differ only by constants; Proposition 4.3 gives schedule that increases with distribution shift Î³t
- Break condition: If loss function is not convex or gradient variance assumptions violated

### Mechanism 3
- Claim: For non-convex losses, optimal learning rate minimizes upper bound on cumulative gradient norm regret
- Mechanism: Regret defined using gradient norms since SGD can get stuck in local minima. Learning rate increases with distribution shift to encourage exploration
- Core assumption: Gradient norm is reasonable regret measure for non-convex losses
- Evidence anchors: Abstract defines regret based on gradient norm; Theorem 5.1 gives learning rate formula based on batch size, smoothness, and distribution shifts
- Break condition: If non-convex landscape has many local minima or distribution shifts are very large

## Foundational Learning

- Concept: Stochastic Differential Equations (SDEs)
  - Why needed here: SDEs model and analyze SGD behavior under distribution shift for linear regression
  - Quick check question: What is the main advantage of using SDEs to analyze SGD compared to analyzing discrete updates directly?

- Concept: Regret Minimization
  - Why needed here: Frames learning rate optimization as minimizing difference between learner's cumulative loss and best fixed model in hindsight
  - Quick check question: How does regret minimization framework differ from traditional optimization framework in machine learning?

- Concept: Convex Analysis
  - Why needed here: Enables derivation of regret bounds and optimal learning rates for convex loss functions
  - Quick check question: What are key properties of convex functions that make them easier to optimize than non-convex functions?

## Architecture Onboarding

- Component map: Data stream -> Model -> Loss function -> Optimizer -> Regret calculator
- Critical path: Data stream -> Model -> Loss function -> Optimizer -> Regret calculator
- Design tradeoffs:
  - Exploration vs. exploitation: Learning rate schedule balances exploring new parameter space areas with exploiting current best model
  - Computational efficiency: Regret calculator and learning rate scheduler must be efficient for large-scale online learning
  - Robustness: System must handle noise and outliers in data stream
- Failure signatures:
  - High regret: Learning rate schedule not adapting well to distribution shifts
  - Diverging loss: Learning rate too high, causing model to overshoot optimal parameters
  - Converging to suboptimal model: Learning rate too low, causing model to get stuck in local minimum
- First 3 experiments:
  1. Linear regression with synthetic data: Compare regret of proposed schedule vs fixed learning rates
  2. Logistic regression on real dataset: Apply proposed schedule to model with distribution shifts
  3. Neural network on medical application: Train neural network for flow cytometry with changing data distribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does optimal learning rate schedule behave with time-varying batch sizes Bt?
- Basis in paper: [explicit] Paper studies fixed batch sizes and mentions learning rate depends on Bt in various formulas
- Why unresolved: Paper does not explore scenario where Bt varies over time
- What evidence would resolve it: Analyze regret bounds and optimal schedules when Bt varies over time

### Open Question 2
- Question: Can SDE approximation extend to handle non-linear regression models with time-varying parameters?
- Basis in paper: [explicit] Paper uses novel SDE for linear regression with time-varying coefficients, question is generalization to non-linear models
- Why unresolved: Paper focuses on linear regression, doesn't discuss non-linear models
- What evidence would resolve it: Derive SDE approximation for non-linear regression models and analyze resulting optimal schedules

### Open Question 3
- Question: How do distribution shifts affect SGD convergence to local minima in non-convex loss functions?
- Basis in paper: [explicit] Paper defines modified regret based on gradient norm for non-convex losses but doesn't discuss convergence properties
- Why unresolved: Paper focuses on regret bounds rather than convergence analysis for non-convex losses
- What evidence would resolve it: Conduct convergence analysis of SGD under distribution shifts for non-convex losses

### Open Question 4
- Question: Can regret bounds be improved using more sophisticated learning rate schedules?
- Basis in paper: [explicit] Paper proposes adaptive schedules that minimize regret upper bounds but doesn't explore more complex schedules
- Why unresolved: Paper focuses on simple adaptive schedules, doesn't investigate advanced techniques
- What evidence would resolve it: Develop and analyze sophisticated learning rate schedules (e.g., based on adaptive moment estimation) and compare regret bounds

## Limitations
- Theoretical guarantees rely on strong assumptions about loss functions and data distributions
- SDE approximation assumes infinitesimal step sizes that may not hold in practice
- Experiments limited in scale and scope, using synthetic data and lacking detailed comparisons to baselines

## Confidence

- Linear regression with SDE analysis: Medium
- Convex losses with regret bounds: Medium
- Non-convex losses with gradient norm regret: Low

## Next Checks

1. **Scale up experiments**: Evaluate proposed learning rate schedules on larger-scale datasets and more complex models (e.g., deep neural networks) to assess practical effectiveness
2. **Relax assumptions**: Investigate robustness of theoretical guarantees under weaker assumptions on loss functions and data distributions
3. **Compare to baselines**: Conduct thorough comparison of proposed schedules against state-of-the-art methods for online learning under distribution shift