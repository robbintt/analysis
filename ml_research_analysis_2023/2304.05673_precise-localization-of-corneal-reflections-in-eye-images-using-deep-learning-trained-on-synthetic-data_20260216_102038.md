---
ver: rpa2
title: Precise localization of corneal reflections in eye images using deep learning
  trained on synthetic data
arxiv_id: '2304.05673'
source_url: https://arxiv.org/abs/2304.05673
tags:
- center
- images
- methods
- localization
- image
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We developed a CNN-based method for localizing corneal reflection
  centers in eye images. Unlike previous methods, we trained the CNN solely on synthetic
  data, eliminating the need for manual annotation.
---

# Precise localization of corneal reflections in eye images using deep learning trained on synthetic data

## Quick Facts
- **arXiv ID**: 2304.05673
- **Source URL**: https://arxiv.org/abs/2304.05673
- **Reference count**: 18
- **Primary result**: CNN-based CR center localization trained solely on synthetic data achieves sub-pixel accuracy and 10% improvement in gaze signal precision

## Executive Summary
This paper presents a deep learning approach for localizing corneal reflection (CR) centers in eye images using synthetic training data. The method employs a two-stage training process where a CNN learns to map intensity profiles to precise center coordinates. Unlike previous methods, no manual annotation of real eye images is required for training. The approach achieves sub-pixel accuracy on synthetic validation data and demonstrates a 10% improvement in gaze signal precision compared to traditional thresholding methods on real eye images.

## Method Summary
The method uses a CNN trained entirely on synthetic data generated with DeepTrack 2.1 to locate CR centers with sub-pixel accuracy. The process involves two training stages: first training on diverse CR locations and parameters, then fine-tuning with frozen early layers on centered patches. Input images are 180×180 patches centered on initial threshold-based estimates. The CNN outputs Cartesian coordinates of the CR center. For real images, a pre-processing step extracts regions of interest using thresholding and masks to isolate the CR from other reflections.

## Key Results
- Achieved sub-pixel accuracy of 0.072 pixels on synthetic validation data
- Reduced RMS precision by 35% compared to thresholding on real eye images
- Demonstrated 10% improvement in gaze signal precision through CR localization

## Why This Works (Mechanism)

### Mechanism 1
The CNN achieves sub-pixel accuracy because it learns to exploit the full intensity profile of the corneal reflection rather than relying on binary thresholding. By training on simulated images with varied Gaussian amplitudes and noise levels, the CNN learns to map the continuous intensity distribution to precise center coordinates. The use of 180×180 patches centered on initial threshold estimates provides sufficient context for the network to infer sub-pixel offsets.

### Mechanism 2
Two-stage training enables the CNN to first learn general CR patterns then refine to precise sub-pixel localization. Stage 1 trains on a wide range of CR locations and parameters to learn general features. Stage 2 freezes early layers and fine-tunes on centered patches, allowing the network to specialize in precise localization within a narrow region.

### Mechanism 3
Synthetic data generation with controlled parameters allows training on edge cases that are rare in real data. By systematically varying CR radius, Gaussian amplitude, background positions, and noise levels across the Cartesian product of parameters, the model encounters diverse scenarios including CRs on different backgrounds and varying signal-to-noise ratios.

## Foundational Learning

- **Concept: Gaussian distribution modeling of corneal reflections**
  - Why needed here: The method assumes CR intensity follows a Gaussian profile, which is fundamental to both the synthetic data generation and the theoretical accuracy limits
  - Quick check question: What parameters define a 2D Gaussian distribution used to model corneal reflections?

- **Concept: Sub-pixel localization theory**
  - Why needed here: Understanding the theoretical limits of CR localization based on pixel resolution and intensity distribution is crucial for evaluating the method's performance
  - Quick check question: How does the number of pixels spanned by a CR and its bit-depth affect the maximum achievable localization accuracy?

- **Concept: Two-stage training methodology**
  - Why needed here: The paper uses a novel two-stage approach where early layers are frozen during fine-tuning, which is key to achieving sub-pixel accuracy
  - Quick check question: Why would freezing early convolutional layers during fine-tuning help achieve better sub-pixel localization performance?

## Architecture Onboarding

- **Component map**: Input layer (180×180 grayscale image) → 7 convolutional layers (64→512 filters) → 2 dense layers → output (x,y coordinates)
- **Critical path**: Pre-processing (ROI extraction, masking) → Thresholding for initial estimate → 180×180 patch extraction → CNN inference → Sub-pixel coordinates
- **Design tradeoffs**: Larger patches provide more context but increase computational cost; deeper networks can learn more complex features but risk overfitting
- **Failure signatures**: High validation error indicates poor synthetic-real domain transfer; inconsistent predictions across similar inputs suggest overfitting; systematic bias suggests training data imbalance
- **First 3 experiments**:
  1. Test CNN on simulated images with known ground truth to verify sub-pixel accuracy claims
  2. Compare thresholding vs CNN performance on real eye images with manual verification
  3. Evaluate sensitivity to initial threshold estimate by perturbing patch center positions

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of the CNN-based CR center localization method compare to other deep learning methods when applied to more challenging eye tracking scenarios, such as those involving lower quality images or complex backgrounds? The paper only tested the method on high-quality eye images in a controlled laboratory setting. The performance of the method in more challenging scenarios remains unknown.

### Open Question 2
Can the CNN-based method be extended to accurately localize the pupil center in addition to the CR center, and if so, how would this impact the overall gaze signal precision? The paper only focused on CR center localization, and the performance of the method for pupil center localization remains unknown.

### Open Question 3
How can the CNN-based method be adapted to handle multiple CRs and match their positions in the eye image to the corresponding physical configuration of light sources? The paper only focused on localizing a single CR center, and the performance of the method for handling multiple CRs remains unknown.

## Limitations

- Performance gain on real images (10% improvement) is modest despite achieving sub-pixel accuracy on synthetic data
- Limited evaluation with only 3 participants in controlled laboratory conditions
- No comparison to other deep learning methods trained on real annotated data

## Confidence

- **High confidence**: The synthetic data generation methodology and CNN architecture are well-specified and reproducible
- **Medium confidence**: The 10% improvement claim on real eye images, given limited participant data (3 subjects) and absence of comparison to other deep learning approaches
- **Low confidence**: The generalization of results to different eye tracking setups and corneal reflection configurations not captured in the synthetic data

## Next Checks

1. Test the method on eye images from different eye tracking systems with varying corneal reflection intensities and backgrounds to assess robustness
2. Compare against state-of-the-art deep learning methods trained on real annotated data to quantify the synthetic data approach's relative performance
3. Evaluate the impact of different thresholding parameters on the initial patch extraction to determine sensitivity to this critical pre-processing step