---
ver: rpa2
title: 'Beyond Distribution Shift: Spurious Features Through the Lens of Training
  Dynamics'
arxiv_id: '2302.09344'
source_url: https://arxiv.org/abs/2302.09344
tags:
- spurious
- training
- features
- learning
- shortcut
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes monitoring early training dynamics using instance
  difficulty metrics to detect shortcut learning in deep neural networks. The authors
  define shortcuts as spurious features that are easier to learn than core features
  and demonstrate that not all spurious correlations lead to shortcut learning.
---

# Beyond Distribution Shift: Spurious Features Through the Lens of Training Dynamics

## Quick Facts
- arXiv ID: 2302.09344
- Source URL: https://arxiv.org/abs/2302.09344
- Reference count: 27
- Primary result: Shortcut learning can be detected within two epochs by monitoring early training dynamics using instance difficulty metrics like Prediction Depth.

## Executive Summary
This paper proposes a novel approach to detect shortcut learning in deep neural networks by monitoring early training dynamics using instance difficulty metrics. The authors define shortcuts as spurious features that are easier to learn than core features, distinguishing between "benign" and "harmful" shortcuts based on their relative learnability. Using the Prediction Depth metric, they demonstrate that models relying on shortcuts exhibit skewed PD plots with peaks in early layers, especially for challenging classification tasks. The framework is validated across medical and vision datasets, showing that shortcut detection is possible within the first two epochs of training.

## Method Summary
The method involves monitoring Prediction Depth (PD) during training to detect shortcut learning. PD measures the minimum number of layers required for correct classification of an instance. The approach trains models while simultaneously computing PD at each epoch using k-NN classifiers on intermediate layer embeddings. Grad-CAM visualizations help interpret model focus on spurious features. The theoretical foundation connects PD with V-usable information, showing that datasets with spurious features have higher usable information, causing models to prefer learning shortcuts. The method is tested across various datasets including Dominoes (simulated), medical imaging (NIH, Chex-MIMIC), and vision datasets with controlled spurious features.

## Key Results
- Shortcut learning can be detected within two epochs by observing early layer convergence patterns
- Datasets with easy spurious features have higher V-usable information, making them more attractive to models
- PD plots show characteristic peaks in early layers when models rely on shortcuts, distinct from uniform distributions in non-shortcut scenarios
- The method successfully identifies harmful shortcuts in medical imaging datasets where traditional accuracy metrics fail to reveal the issue

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Shortcuts are defined as spurious features that are easier to learn than core features, and this ease is relative to the model's architecture and training dynamics.
- **Mechanism:** The model preferentially learns spurious features when they require less representational capacity (fewer layers) to achieve classification accuracy compared to core features. This is detected through the Prediction Depth (PD) metric, which measures the minimum number of layers required for correct classification.
- **Core assumption:** The PD metric reliably captures the relative difficulty of learning features for a given model architecture.
- **Evidence anchors:**
  - [abstract] "Spurious features can be 'benign' or 'harmful' depending on whether they are 'harder' or 'easier' to learn than the core features for a given model."
  - [section] "We show that a mismatch in the joint distribution of the input, spurious feature, and label between test and training data is insufficient to explain the shortcut learning phenomenon. It also depends on the model's architecture and training dynamics."
  - [corpus] Weak - related papers discuss spurious correlations but don't specifically address the ease-of-learning criterion.
- **Break condition:** If the PD metric fails to accurately reflect the actual difficulty of learning features (e.g., due to architectural biases or training artifacts).

### Mechanism 2
- **Claim:** Early training dynamics, specifically the convergence of initial layers, reveal shortcut learning patterns within the first two epochs.
- **Mechanism:** Initial layers learn easier features first and converge earlier in training. When spurious features are easier than core features, they are learned by initial layers early in training, creating peaks in the PD plot at early layers. These peaks are stable across epochs, while later layers continue to learn harder features.
- **Core assumption:** Initial layers of deep networks learn easier features first, and this is observable through the PD metric.
- **Evidence anchors:**
  - [abstract] "We empirically show that shortcut learning can be detected by observing the learning dynamics of the DNN's early layers."
  - [section] "We empirically show that easy features learned by the initial layers of a DNN early during the training are potential shortcuts."
  - [corpus] Weak - related work on training dynamics focuses on different goals (selective classification, studying SGD dynamics) rather than shortcut detection.
- **Break condition:** If the model architecture or training procedure causes initial layers to learn complex features first, or if the PD metric fails to capture this dynamic.

### Mechanism 3
- **Claim:** Datasets with easy spurious features have higher V-usable information, causing models to prefer learning shortcuts.
- **Mechanism:** V-usable information measures the amount of information about the label that can be extracted by functions from a restricted model class. Datasets with easy spurious features have higher usable information because these features can be extracted by simpler functions, making them more attractive to the model than harder core features.
- **Core assumption:** V-usable information is a valid measure of feature learnability and correlates with shortcut preference.
- **Evidence anchors:**
  - [abstract] "We theoretically connect PD with V-usable information, showing that datasets with spurious features have higher usable information, causing models to prefer learning shortcuts."
  - [section] "Datasets with spurious features have more 'usable information' compared to their counterparts without such features. Due to higher usable information, the model requires fewer layers to classify the images with spurious features."
  - [corpus] Weak - no direct evidence in corpus about V-usable information and shortcut learning relationship.
- **Break condition:** If the V-usable information measure doesn't accurately reflect what the model can actually learn, or if other factors dominate the shortcut learning decision.

## Foundational Learning

- **Concept:** Distribution shift and spurious correlations
  - Why needed here: The paper distinguishes between general spurious correlations and shortcut learning, requiring understanding of how feature-label relationships can change between training and test distributions.
  - Quick check question: What is the difference between a spurious correlation and a shortcut in the context of this paper?

- **Concept:** Information theory and usable information
  - Why needed here: The theoretical justification for the PD metric relies on V-usable information, which requires understanding of information-theoretic measures of learnability.
  - Quick check question: How does V-usable information differ from mutual information, and why is this distinction important for measuring task difficulty?

- **Concept:** Deep network internal representations and layer-wise feature learning
  - Why needed here: The PD metric depends on understanding how different layers of deep networks learn features of varying complexity, and how this relates to instance difficulty.
  - Quick check question: Why do initial layers of deep networks tend to learn easier features first, according to the paper's premises?

## Architecture Onboarding

- **Component map:** Dataset (Dominoes/medical/vision) -> Deep neural network (ResNet18/VGG16/DenseNet121) -> Intermediate layer embeddings -> k-NN classifiers -> Prediction Depth computation -> Grad-CAM visualization -> Monitoring infrastructure
- **Critical path:** Training the model while simultaneously computing PD at each epoch, monitoring for early peaks in initial layers, and visualizing Grad-CAM outputs to identify spurious features
- **Design tradeoffs:** Using k-NN classifiers on intermediate representations provides interpretability but adds computational overhead; the choice of k in k-NN affects stability; downsampling high-resolution embeddings to 8x8 balances accuracy and efficiency
- **Failure signatures:** PD plots that are uniformly distributed across layers (no shortcut), high test accuracy with suspicious early-layer peaks (potential false positives), undefined PD values accumulating in later layers (challenging samples)
- **First 3 experiments:**
  1. Reproduce the dominoes dataset experiment to verify that models learn easy spurious features but not hard ones.
  2. Test the NIH dataset with chest drain annotations to observe shortcut learning in medical imaging.
  3. Create a synthetic dataset with controlled spurious features to validate the PD detection mechanism.

## Open Questions the Paper Calls Out

- **Question:** Can the proposed shortcut detection method be extended to multi-class classification tasks?
  - Basis in paper: [inferred] The paper only demonstrates the method on binary classification tasks, but the underlying principles of monitoring early training dynamics could potentially apply to multi-class scenarios.
  - Why unresolved: The authors don't explore or discuss the applicability of their approach to multi-class settings, which are more common in real-world applications.
  - What evidence would resolve it: Experiments applying the Prediction Depth and V-usable information metrics to multi-class datasets, showing similar early detection of shortcuts.

- **Question:** How does the choice of neural network architecture affect the effectiveness of shortcut detection?
  - Basis in paper: [explicit] The authors mention that their hypothesis works regardless of DNN architecture, but they only test with CNN architectures like ResNet, VGG, and DenseNet.
  - Why unresolved: The experiments are limited to specific CNN architectures, leaving open the question of how well the method generalizes to other architectures like Transformers or graph neural networks.
  - What evidence would resolve it: Applying the method to diverse architecture families and comparing detection performance across them.

- **Question:** What are the limitations of using Prediction Depth as a proxy for example difficulty in shortcut detection?
  - Basis in paper: [explicit] The authors acknowledge that Prediction Depth is well-suited for their work because it's defined for easy inputs even when the DNN is not fully trained, but they don't discuss its limitations.
  - Why unresolved: While the authors justify their choice of metric, they don't explore scenarios where PD might fail to detect shortcuts or give false positives/negatives.
  - What evidence would resolve it: Identifying edge cases or specific dataset characteristics where PD fails to accurately reflect shortcut learning, possibly by comparing with other instance difficulty metrics.

## Limitations
- The theoretical connection between PD and V-usable information requires strong assumptions about the model class and may not generalize to all network architectures
- The empirical validation shows somewhat variable results, particularly in medical imaging experiments where Grad-CAM visualizations don't consistently align with PD predictions
- Implementation details of PD computation (particularly k-NN parameters and undefined PD handling) remain underspecified

## Confidence
- **High Confidence:** The observation that not all spurious correlations lead to shortcut learning is well-supported by the dominoes experiments and aligns with existing literature on dataset bias.
- **Medium Confidence:** The claim that early training dynamics can detect shortcuts within two epochs is supported by the experimental results, but the generalizability across different architectures and training regimes needs further validation.
- **Medium Confidence:** The theoretical connection between PD and V-usable information provides a compelling framework, but the practical implications and limitations require more rigorous examination.

## Next Checks
1. **Parameter Sensitivity Analysis:** Systematically vary k-NN parameters (neighbor count, distance metrics) and undefined PD thresholds across different architectures to quantify their impact on shortcut detection reliability.

2. **Architecture Generalization Study:** Test the shortcut detection framework on transformer-based architectures and vision transformers to assess whether the early-layer convergence patterns observed in CNNs hold across different model families.

3. **Temporal Stability Investigation:** Track PD evolution beyond the initial training phase to understand whether shortcuts that emerge early remain stable or evolve, and how this affects long-term model reliability.