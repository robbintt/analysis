---
ver: rpa2
title: Grokking as the Transition from Lazy to Rich Training Dynamics
arxiv_id: '2310.06110'
source_url: https://arxiv.org/abs/2310.06110
tags:
- grokking
- loss
- network
- learning
- weight
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes that the grokking phenomenon in neural networks,
  where training loss decreases much earlier than test loss, can be explained by a
  transition from lazy training dynamics to rich feature learning. The authors demonstrate
  this mechanism using a simple two-layer neural network on polynomial regression
  tasks.
---

# Grokking as the Transition from Lazy to Rich Training Dynamics

## Quick Facts
- **arXiv ID**: 2310.06110
- **Source URL**: https://arxiv.org/abs/2310.06110
- **Reference count**: 40
- **Primary result**: Explains grokking as transition from lazy to rich training dynamics, controllable via output scaling parameter

## Executive Summary
This paper provides a mechanistic explanation for the grokking phenomenon in neural networks, where training loss decreases much earlier than test loss. The authors propose that grokking occurs when a network transitions from lazy training dynamics (operating in the kernel regime) to rich feature learning. Using a simple two-layer neural network on polynomial regression tasks, they demonstrate that this transition can be precisely controlled by parameters that scale the network output. Their framework explains grokking without requiring explicit regularization and provides methods to induce or eliminate grokking by manipulating key parameters.

## Method Summary
The authors use a two-layer neural network with polynomial activation functions to study grokking behavior. They vary the output scaling parameter α to control the rate of feature learning and measure the alignment between the initial neural tangent kernel (NTK) and target function using centered-kernel alignment (CKA). Experiments are conducted on synthetic polynomial regression tasks, MNIST dataset, one-layer Transformers, and student-teacher networks. The training procedure uses vanilla gradient descent with variations including momentum and AdamW optimizers. The key insight is that larger α induces lazy training, while misalignment between initial features and task labels forces the network to learn generalizing features.

## Key Results
- Grokking occurs when networks transition from lazy training (kernel regime) to rich feature learning
- Output scaling parameter α controls the rate of feature learning and grokking intensity
- Two key determinants of grokking: laziness rate (controlled by α) and NTK alignment with target function
- Demonstrated framework across multiple architectures including MNIST and Transformers

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Grokking occurs when a network transitions from lazy training dynamics to rich feature learning.
- **Mechanism**: Initially, the network fits training data using kernel regression with its initial features. Later, it learns generalizing features that improve test performance.
- **Core assumption**: The network can operate in two distinct regimes - lazy (linearized) and rich (feature learning) - and the transition between them can be controlled by specific parameters.
- **Evidence anchors**: [abstract] "grokking phenomenon... can arise due to a neural network transitioning from lazy training dynamics to a rich, feature learning regime"

### Mechanism 2
- **Claim**: Two key parameters control grokking: network laziness (controlled by output scaling α) and alignment between initial NTK and target function.
- **Mechanism**: Larger α increases the timescale separation between train and test loss reduction, while misalignment between initial features and task labels forces feature learning.
- **Core assumption**: The output scaling parameter α directly controls the rate of feature learning by inducing lazy training when large.
- **Evidence anchors**: [abstract] "key determinants of grokking are the rate of feature learning -- which can be controlled precisely by parameters that scale the network output"

### Mechanism 3
- **Claim**: There exists a "goldilocks" dataset size that enables grokking - large enough for eventual generalization but small enough to prevent immediate generalization.
- **Mechanism**: When dataset size is in this intermediate range, the network first memorizes using initial features, then later learns generalizing features.
- **Core assumption**: Generalization is possible but not immediate at certain dataset sizes, creating the conditions for delayed generalization.
- **Evidence anchors**: [abstract] "dataset size is large enough so that it is possible for the network to generalize eventually, but not so large that train loss perfectly tracks test loss at all epochs"

## Foundational Learning

- **Concept: Neural Tangent Kernel (NTK)**
  - Why needed here: The NTK determines how the network behaves in the lazy regime and its alignment with the target function controls whether feature learning is necessary.
  - Quick check question: What is the relationship between the NTK and the behavior of infinitely wide networks?

- **Concept: Feature learning vs. Lazy training**
  - Why needed here: The paper's central thesis is that grokking occurs when a network transitions from lazy training (using initial features) to rich feature learning.
  - Quick check question: How does the parameter α control whether a network operates in lazy or rich training regime?

- **Concept: Centered-kernel alignment (CKA)**
  - Why needed here: CKA measures the alignment between the initial NTK and the task labels, which determines how much feature learning is necessary.
  - Quick check question: How does CKA relate to the difficulty of a task for a given kernel?

## Architecture Onboarding

- **Component map**: Two-layer perceptron -> polynomial activation -> output scaling α -> NTK alignment -> feature learning transition
- **Critical path**: Initialize network with random weights → Train using vanilla gradient descent → Monitor train and test loss separately → Identify transition point from lazy to rich dynamics → Analyze feature alignment with task
- **Design tradeoffs**: Larger α creates more dramatic grokking but poorer final performance; smaller α eliminates grokking but may prevent feature learning; dataset size must be carefully chosen
- **Failure signatures**: Train and test loss track each other perfectly (infinite data limit); no feature learning occurs (perfectly aligned initial features); grokking never appears (α too small or features already aligned)
- **First 3 experiments**: Vary α while keeping all other parameters fixed to observe its effect on grokking intensity; change dataset size to find the "goldilocks" zone where grokking occurs; modify task labels to change NTK alignment and observe effect on feature learning necessity

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the precise theoretical characterization of the required sample size or training time to transition from memorization to grokking behavior?
- **Open Question 2**: How do adaptive optimizers like AdamW amplify grokking effects beyond what would occur with vanilla gradient descent?
- **Open Question 3**: What is the relationship between initial weight norm, laziness, and the onset of feature learning in deeper networks?

## Limitations
- Theoretical framework primarily developed for two-layer networks with polynomial activation
- Extensions to other architectures are empirical rather than theoretical
- Does not fully explore the role of explicit regularization in grokking

## Confidence
- **High confidence**: Core mechanism explaining grokking as transition from lazy to rich training dynamics in controlled two-layer network setting
- **Medium confidence**: Extension of framework to other architectures where grokking is induced through output scaling
- **Low confidence**: Claim that this mechanism explains all instances of grokking across different architectures and tasks

## Next Checks
1. Test the lazy-to-rich transition hypothesis on original grokking datasets (modular arithmetic tasks) to verify if output scaling can induce or eliminate grokking
2. Directly measure NTK alignment between initial NTK and target functions across different grokking experiments
3. Develop mathematical framework for lazy-to-rich transitions in deeper networks beyond the two-layer case