---
ver: rpa2
title: 'Enhancing Health Data Interoperability with Large Language Models: A FHIR
  Study'
arxiv_id: '2310.12989'
source_url: https://arxiv.org/abs/2310.12989
tags:
- fhir
- data
- code
- snomed
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study leveraged Large Language Models (LLMs) to streamline
  the conversion of clinical text into FHIR (Fast Healthcare Interoperability Resources)
  format, a critical step toward improving health data interoperability. Using GPT-4,
  the researchers transformed 3,671 clinical snippets into structured FHIR resources,
  bypassing traditional multi-step NLP pipelines.
---

# Enhancing Health Data Interoperability with Large Language Models: A FHIR Study

## Quick Facts
- arXiv ID: 2310.12989
- Source URL: https://arxiv.org/abs/2310.12989
- Authors: 
- Reference count: 0
- Key outcome: GPT-4 achieved over 90% exact match accuracy and F1 scores above 0.96 in converting clinical text to FHIR MedicationStatement resources

## Executive Summary
This study demonstrates how Large Language Models (LLMs) can streamline health data interoperability by directly converting clinical text into FHIR (Fast Healthcare Interoperability Resources) format. Using GPT-4, the researchers bypassed traditional multi-step NLP pipelines and achieved exceptional accuracy in generating structured medication data from clinical snippets. The approach showed particular strength in terminology coding, mathematical conversions, and JSON format compliance, outperforming previous methods by at least 8% in F1 scores.

## Method Summary
The researchers used GPT-4 to transform 3,671 clinical snippets from MIMIC-III discharge summaries into FHIR MedicationStatement resources. The method involved creating prompt templates with task instructions, FHIR output templates in JSON format, conversion examples, and curated code lists for terminology mapping. The LLM performed named entity recognition, terminology mapping, mathematical conversions, and JSON formatting in a single pass without fine-tuning or domain-specific adaptation. Performance was evaluated using exact match accuracy and F1 scores against human annotations from the n2c2 medication extraction dataset.

## Key Results
- Achieved over 90% exact match accuracy and F1 scores above 0.96 across medication, dosage, route, and timing elements
- Outperformed previous methods by at least 8% in F1 scores
- Successfully maintained JSON format compliance and terminology coding accuracy
- Demonstrated capability for mathematical conversions (e.g., inferring 10-day duration from "TID, dispense 30 tablets")

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can bypass multi-step NLP pipelines by directly generating FHIR resources from free text
- Mechanism: GPT-4 uses instruction-tuned prompting to perform named entity recognition, terminology mapping, mathematical conversions, and JSON formatting in a single pass
- Core assumption: The LLM's internal knowledge of medical terminology and FHIR structure is sufficient without fine-tuning
- Evidence anchors:
  - [abstract] "The LLM achieved over 90% exact match accuracy and F1 scores above 0.96 across key elements"
  - [section] "Previous studies have attempted to transform clinical notes into FHIR resources using a combination of natural language processing and machine learning tools through multi-step processes"
- Break condition: When clinical text contains highly domain-specific terminology or complex nested relationships that exceed the LLM's implicit knowledge

### Mechanism 2
- Claim: High accuracy in terminology coding through classification without access to full code lists
- Mechanism: The LLM maps clinical concepts to standard codes (RxNorm, SNOMED) by understanding semantic relationships in context, using a curated subset of codes in the prompt
- Core assumption: The provided code subsets are representative enough for the LLM to generalize correctly
- Evidence anchors:
  - [section] "The accuracy of the output is highly dependent on the instruction prompts used"
  - [table] High F1 scores across medicationCode, doseForm, route, and timing elements suggest successful classification
- Break condition: When encountering rare medications or newly approved drugs not represented in the provided code subsets

### Mechanism 3
- Claim: Mathematical conversion accuracy (e.g., inferring 10-day duration from "TID, dispense 30 tablets")
- Mechanism: The LLM applies arithmetic reasoning within the context of clinical knowledge to derive quantitative values
- Core assumption: The LLM's reasoning capability extends to practical clinical calculations when properly prompted
- Evidence anchors:
  - [section] "mathematical conversion (e.g., inferring a duration of 10 days when the input mentions 'TID, dispense 30 tablets')"
  - [table] High F1 scores in timing.repeat and doseQuantity suggest accurate quantitative extraction
- Break condition: When clinical instructions involve complex dosing schedules or ambiguous quantity descriptions

## Foundational Learning

- Concept: FHIR MedicationStatement resource structure
  - Why needed here: Understanding the target format helps in crafting effective prompts and evaluating output quality
  - Quick check question: What are the required vs optional fields in a MedicationStatement resource?

- Concept: Clinical terminology systems (RxNorm, SNOMED, NDC)
  - Why needed here: The LLM must map clinical terms to standardized codes for interoperability
  - Quick check question: How does RxNorm differ from SNOMED in representing medication concepts?

- Concept: JSON format compliance and validation
  - Why needed here: Ensuring output conforms to FHIR standards requires understanding JSON structure and FHIR validation rules
  - Quick check question: What makes a JSON resource "FHIR-compliant" versus just syntactically valid JSON?

## Architecture Onboarding

- Component map: Clinical text → LLM API call → FHIR JSON output → FHIR validator → Storage/Integration
- Critical path: Text → Prompt construction → LLM processing → Output validation → Storage
- Design tradeoffs:
  - Single LLM call vs modular pipeline: Simpler but less transparent, harder to debug individual components
  - Static code lists vs dynamic retrieval: Faster but potentially less complete coverage
  - Exact match evaluation vs element-level evaluation: More stringent but may penalize minor formatting differences
- Failure signatures:
  - JSON parsing errors → Invalid structure or syntax
  - Code mismatches → Terminology mapping issues or out-of-vocabulary terms
  - Missing fields → Prompt instructions unclear or LLM misinterpretation
- First 3 experiments:
  1. Test LLM with single-element prompts (medication only) to establish baseline accuracy
  2. Test with edge cases (complex dosing, multiple medications) to identify failure modes
  3. Compare exact match vs element-level F1 scores to understand where precision drops

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would LLM performance change when scaling to more complex FHIR resources beyond MedicationStatement, such as Condition, Procedure, or Observation?
- Basis in paper: [explicit] The authors explicitly state "Future studies will aim to build upon these successes by extending the generation to additional FHIR resources"
- Why unresolved: The study only tested on MedicationStatement resources, and no data is provided on performance with other FHIR resource types
- What evidence would resolve it: Direct comparison of LLM performance across multiple FHIR resource types using the same methodology and evaluation metrics

### Open Question 2
- Question: What is the impact of different prompt engineering strategies on LLM accuracy for FHIR conversion?
- Basis in paper: [explicit] The authors provide recommendations for prompt engineering but do not systematically compare different approaches
- Why unresolved: The study used a single refined prompt template without comparing alternative prompt structures or instructions
- What evidence would resolve it: Controlled experiments testing multiple prompt variations while holding other variables constant

### Open Question 3
- Question: How does LLM performance compare to other LLM models beyond GPT-4 for FHIR conversion tasks?
- Basis in paper: [explicit] The authors mention "comparing the performance of various LLM models" as a future direction
- Why unresolved: Only GPT-4 was tested, with no baseline comparisons to other LLMs or traditional NLP approaches
- What evidence would resolve it: Head-to-head performance comparison of multiple LLM models using identical evaluation criteria

## Limitations

- LLM accuracy heavily depends on prompt construction and provided code subsets, with no clear guidance on optimal prompt engineering strategies
- The research focuses exclusively on medication-related data, leaving uncertainty about performance on other FHIR resource types
- Evaluation relies on a specific dataset (MIMIC-III with n2c2 annotations), and real-world clinical text may present greater complexity and variability

## Confidence

**High Confidence** (80-100%):
- The LLM achieved over 90% exact match accuracy and F1 scores above 0.96 for core medication elements (dosage, route, timing)
- The approach successfully bypasses traditional multi-step NLP pipelines by using a single LLM call
- JSON format compliance was maintained across the dataset

**Medium Confidence** (50-80%):
- The terminology coding accuracy for RxNorm, SNOMED, and NDC codes (exact performance depends on provided code subsets)
- The mathematical conversion capabilities for inferring durations and quantities from clinical instructions
- The robustness of results across different clinical domains beyond medication statements

**Low Confidence** (0-50%):
- Performance with rare medications or newly approved drugs not represented in provided code subsets
- Scalability to full clinical notes with multiple, nested clinical concepts
- Long-term reliability without domain-specific fine-tuning

## Next Checks

1. **Prompt Engineering Validation**: Systematically test how different prompt structures and example selections affect accuracy across the 3,671 clinical snippets to establish best practices for optimal performance.

2. **Edge Case Analysis**: Evaluate the LLM's performance on clinical text containing rare medications, newly approved drugs, and complex dosing instructions not represented in the provided code subsets.

3. **Cross-Domain Testing**: Apply the same methodology to other FHIR resource types (e.g., Condition, Observation) to assess generalizability beyond medication statements.