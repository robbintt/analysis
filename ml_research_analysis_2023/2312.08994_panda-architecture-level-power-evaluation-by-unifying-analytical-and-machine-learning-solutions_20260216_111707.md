---
ver: rpa2
title: 'PANDA: Architecture-Level Power Evaluation by Unifying Analytical and Machine
  Learning Solutions'
arxiv_id: '2312.08994'
source_url: https://arxiv.org/abs/2312.08994
tags:
- power
- panda
- design
- configurations
- configuration
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PANDA unifies analytical and machine learning techniques to achieve
  highly accurate architecture-level power modeling, even with very limited training
  data. It decomposes power into components, each modeled by combining an analytical
  resource function with an ML regressor.
---

# PANDA: Architecture-Level Power Evaluation by Unifying Analytical and Machine Learning Solutions

## Quick Facts
- arXiv ID: 2312.08994
- Source URL: https://arxiv.org/abs/2312.08994
- Reference count: 25
- Key outcome: PANDA achieves 5-30% lower error than prior methods in architecture-level power modeling with limited training data

## Executive Summary
PANDA introduces a novel approach to architecture-level power modeling that combines analytical resource functions with machine learning regressors. By decomposing power into component-level models, PANDA achieves highly accurate predictions even with very limited training data. The method learns power/F_i^res instead of raw power, creating more uniform distributions that ML models can learn effectively from few samples.

## Method Summary
PANDA decomposes power into N components, each modeled by combining an analytical resource function F_i^res(C_i) with an ML regressor F_i^ml(C_i, E_i). The resource function captures primary, roughly proportional relationships between configuration parameters and power, while the ML model learns residuals and complex interactions. This design enables accurate prediction of area, performance, energy, and power for new technology nodes, with experimental results on a RISC-V out-of-order CPU core showing less than 10% error even with only 1 known configuration for training.

## Key Results
- Achieves 5-30% lower error than prior ML and analytical methods across configurations
- Maintains less than 10% error in power prediction with only 1 known configuration for training
- Successfully predicts area, performance, energy, and power for new technology nodes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing power into component-level models allows analytical resource functions to capture simple, monotonic relationships while ML models handle complex variations
- Core assumption: Power consumption of each component is approximately proportional to one or more key configuration parameters, with secondary effects captured by ML
- Evidence: Abstract states PANDA "decomposes power into components, each modeled by combining an analytical resource function with an ML regressor"

### Mechanism 2
- Claim: Learning power/F_i^res instead of raw power creates more uniform distributions that ML models can learn from limited data
- Core assumption: Power/F_i^res has more consistent statistical properties across different configuration domains than raw power
- Evidence: Paper shows that learning power/F_i^res provides "obviously more similar distributions" when training data is limited

### Mechanism 3
- Claim: Component-level modeling with resource functions enables accurate prediction for special configurations that don't follow general trends
- Core assumption: Individual component power characteristics are independent enough that unusual combinations can be handled by component-level modeling
- Evidence: PANDA maintains MAPE <5% for special-case designs with unusual parameter combinations

## Foundational Learning

- Concept: CPU architecture components and their configuration parameters
  - Why needed: PANDA requires identifying which configuration parameters affect each component's power consumption
  - Quick check: What are the key configuration parameters for the I-Cache component and how do they affect power?

- Concept: Analytical modeling of resource consumption
  - Why needed: PANDA uses simple analytical functions to capture primary power relationships
  - Quick check: For a set-associative cache, what configuration parameter most directly affects power consumption?

- Concept: Machine learning for tabular data with limited samples
  - Why needed: PANDA needs to learn complex patterns from few training examples
  - Quick check: Why might Gradient Boosting Trees be preferred over neural networks for this application?

## Architecture Onboarding

- Component map: BP -> IFU -> I-TLB -> I-Cache -> RNU -> ROB -> ISU -> Regfile -> FU Pool -> LSU -> D-TLB -> D-Cache -> Other Logic

- Critical path: 1) Identify component configuration parameters and event parameters 2) Design resource functions for each component 3) Train ML models for each component 4) Combine predictions using multiplication 5) Validate on test configurations

- Design tradeoffs: Simple resource functions vs. complex analytical models (simpler captures primary patterns but may miss nuances), component-level vs. holistic modeling (component-level handles special cases but requires more models)

- Failure signatures: High MAPE on special configurations, degradation when training data decreases significantly, poor cross-technology node predictions, component power predictions that don't correlate with resource functions

- First 3 experiments:
  1. Validate resource functions by plotting ground-truth component power vs. F_i^res values
  2. Test component-level ML models with all training data to establish baseline
  3. Compare PANDA prediction accuracy vs. baseline methods with n=1 training sample

## Open Questions the Paper Calls Out

None explicitly called out in the paper.

## Limitations
- Evaluation limited to a single RISC-V out-of-order CPU core design
- Training dataset of 15 configurations may not generalize to all CPU architectures
- Method requires accurate component-level power data, which may not be readily available for all designs

## Confidence
- General methodology and component decomposition: High
- Specific resource function implementations: Medium
- Cross-technology node prediction accuracy: Medium

## Next Checks
1. Verify the resource function implementations by plotting ground-truth component power against F_i^res values to confirm the claimed proportional relationships
2. Test PANDA's cross-technology node prediction accuracy on additional technology nodes beyond the two evaluated
3. Evaluate PANDA's performance on a different CPU architecture (e.g., in-order or different microarchitecture) to assess generalizability