---
ver: rpa2
title: Controlled Text Generation for Black-box Language Models via Score-based Progressive
  Editor
arxiv_id: '2311.07430'
source_url: https://arxiv.org/abs/2311.07430
tags:
- scope
- generation
- domain
- text
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ScoPE, a method for controlled text generation
  with black-box language models. It modifies intermediate output tokens during generation
  to guide subsequent text toward target domain attributes, addressing the challenge
  of controlling text while maintaining fluency in black-box scenarios.
---

# Controlled Text Generation for Black-box Language Models via Score-based Progressive Editor

## Quick Facts
- arXiv ID: 2311.07430
- Source URL: https://arxiv.org/abs/2311.07430
- Reference count: 24
- This paper presents ScoPE, a method for controlled text generation with black-box language models that modifies intermediate output tokens during generation to guide subsequent text toward target domain attributes.

## Executive Summary
This paper introduces ScoPE, a method for controlled text generation with black-box language models by modifying intermediate output tokens during generation. The approach trains an editor to maximize the difference between target domain scores of edited and original text using token-level scoring, incorporating both domain-specific and repetition scores. Experimental results demonstrate that ScoPE effectively improves target domain attribute incorporation while maintaining the fluency of large language models, achieving significant increases in MAUVE scores compared to baselines.

## Method Summary
ScoPE is a score-based method for controlled text generation with black-box language models. It works by modifying blocks of tokens generated by the backbone language model to incorporate target domain attributes. The editor is trained using teacher forcing with ground truth target domain data as input, and optimizes a token position-wise weighted log-likelihood loss that maximizes the score disparity between input and edited text. The method incorporates iterative editing during training to address distributional mismatches, and includes a repetition score to mitigate issues from non-autoregressive generation. The overall approach combines domain-specific MLM scoring, repetition scoring, and optional external discriminator scores to guide the editing process.

## Key Results
- ScoPE achieves significant increases in MAUVE scores compared to baselines, with up to 62.02 for out-of-domain conditions
- The method demonstrates effectiveness across different model types (GPT2-XL, LLaMA-7B, ChatGPT)
- ScoPE maintains the fluency of large language models while incorporating target domain attributes
- Iterative editing and token block size optimization improve performance, with smaller blocks performing better for out-of-domain conditions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ScoPE modifies intermediate output tokens during generation to guide subsequent text toward target domain attributes.
- Mechanism: The editor performs block-wise editing on tokens generated by the black-box language model, enhancing target domain scores through iterative refinement. This modification steers the language model's subsequent generation toward the target domain.
- Core assumption: Modifying a small block of tokens is sufficient to shift the language model's generation trajectory toward the target domain.
- Evidence anchors:
  - [abstract]: "ScoPE modifies the context at the token level during the generation process of a backbone language model."
  - [section 2.1]: "We aim to perform controlled generation by editing the output ˜y generated by the language model to incorporate the target attribute, resulting in ˆy."
  - [corpus]: Weak - no direct corpus evidence for token-level modification effectiveness.
- Break condition: If the target domain and input domain are too dissimilar, the editor's burden becomes significant, leading to instability.

### Mechanism 2
- Claim: The target domain score is decomposed at the token level and used as a training objective for the editor.
- Mechanism: The editor is trained to maximize the disparity in target domain scores between edited and original text using token-level scoring. This is implemented through a weighted log-likelihood loss where the weighting factor is the score difference.
- Core assumption: Token-level score decomposition provides a more refined training signal than sequence-level scoring.
- Evidence anchors:
  - [section 2.2.2]: "The objective of editor training as maximizing the difference between the scores of the input text and the edited text."
  - [section 2.2.2]: "To ensure that the edited text has a higher target domain score than the input text."
  - [corpus]: Weak - no direct corpus evidence for token-level scoring effectiveness.
- Break condition: If the editor receives training signals for all token positions, training becomes unstable.

### Mechanism 3
- Claim: Iterative editing improves the quality of edits in the auto-regressive inference scenario.
- Mechanism: The editor performs multiple iterations of editing on the same token block during training, allowing for refinement of edits. This iterative process helps the editor learn to make more precise modifications.
- Core assumption: Iterative editing during training translates to better performance in the inference scenario.
- Evidence anchors:
  - [section 2.2.2]: "To address this distributional mismatch, we perform N iterations of the iterative process during training."
  - [section 4.1]: "As the number of iterations increases, the scores consistently improve in all cases."
  - [corpus]: Weak - no direct corpus evidence for iterative editing benefits.
- Break condition: If the number of iterations N is too large, training cost increases significantly without proportional benefit.

## Foundational Learning

- Concept: Teacher forcing training setup
  - Why needed here: Ensures that the input sequence for each training step already contains target domain attributes, preventing the editor from learning to generate content from scratch.
  - Quick check question: Why does the paper use teacher forcing instead of auto-regressive training for the editor?

- Concept: Masked Language Model (MLM) as energy-based model
  - Why needed here: The domain-specific MLM fine-tuned on target data provides a score that indicates how well the text incorporates target domain attributes.
  - Quick check question: How does the MLM score relate to the target domain attribute?

- Concept: Non-autoregressive generation and repetition issue
  - Why needed here: The editor uses non-autoregressive generation, which can lead to repetitive text due to conditional independence assumptions.
  - Quick check question: Why does the paper introduce a repetition score specifically for the editor?

## Architecture Onboarding

- Component map:
  Black-box language model -> Editor -> Domain-specific MLM scorer -> Repetition scorer (optional) -> External discriminator (optional)

- Critical path:
  1. Generate b tokens from black-box LM
  2. Editor modifies these tokens to improve target domain score
  3. Modified tokens become input for next generation step
  4. Repeat until desired text length is reached

- Design tradeoffs:
  - Block size b: Larger blocks may capture more context but reduce editing precision; smaller blocks allow finer control but may miss broader context
  - Number of iterations N: More iterations improve edit quality but increase training cost
  - Score components: Including repetition and external discriminator scores improves quality but adds complexity

- Failure signatures:
  - High repetition in generated text (indicates need for repetition score)
  - Generated text doesn't match target domain (indicates editor isn't learning effectively)
  - Training instability (indicates issues with training setup or score calculation)

- First 3 experiments:
  1. Test ScoPE with different block sizes (b=4, 8, 16, 32) to find optimal balance between context and precision
  2. Compare performance with and without repetition score to validate its necessity
  3. Test different numbers of iterative editing steps (N=1, 5, 10) to find optimal training configuration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of ScoPE vary when applied to extremely large language models (e.g., models with hundreds of billions of parameters) compared to the smaller models tested in the paper?
- Basis in paper: [inferred]
- Why unresolved: The paper primarily evaluates ScoPE on GPT2-XL and LLaMA-7B, which are significantly smaller than the largest available models. The authors mention that ScoPE can be combined with ChatGPT (gpt-3.5-turbo), but do not provide detailed performance comparisons across different model sizes or types.
- What evidence would resolve it: Comparative experiments testing ScoPE's performance across a range of model sizes, from smaller models like GPT2-XL up to the largest available models, would provide insights into how model size affects ScoPE's effectiveness.

### Open Question 2
- Question: What is the impact of the token block size (b) on the quality and fluency of the generated text, and is there an optimal block size for different types of controlled generation tasks?
- Basis in paper: [explicit]
- Why unresolved: The paper presents an analysis of different token block sizes, showing that smaller block sizes perform better for out-of-domain conditions in challenging scenarios. However, it does not explore the full range of potential block sizes or provide a comprehensive analysis of how block size affects text quality and fluency across various tasks.
- What evidence would resolve it: A systematic study varying the token block size across a wider range and for different controlled generation tasks would help determine the optimal block size for balancing edit granularity and generation quality.

### Open Question 3
- Question: How does the inclusion of additional domain-specific scores, beyond the MLM and repetition scores, affect the performance of ScoPE in various controlled generation tasks?
- Basis in paper: [explicit]
- Why unresolved: The paper mentions the possibility of incorporating additional domain-specific scores, such as raw logits from a domain-specific discriminator, and demonstrates improved performance in the sentiment controlled generation task when using an external sentiment discriminator. However, it does not explore the effects of other potential scores or combinations of scores across different domains.
- What evidence would resolve it: Experiments testing ScoPE with various combinations of domain-specific scores across multiple controlled generation tasks would reveal the impact of additional scores on performance and identify the most effective scoring strategies.

### Open Question 4
- Question: What are the limitations of ScoPE when dealing with highly divergent target and input domains, and how can these limitations be addressed?
- Basis in paper: [inferred]
- Why unresolved: The paper acknowledges that when the target domain and the input domain are too different, the editor's burden increases significantly, leading to instability in training and increased costs. However, it does not provide a detailed analysis of these limitations or propose solutions for handling highly divergent domains.
- What evidence would resolve it: A thorough investigation of ScoPE's performance with increasingly divergent domain pairs, along with experiments testing potential solutions such as domain adaptation techniques or more sophisticated editor architectures, would shed light on the limitations and possible improvements for handling highly divergent domains.

## Limitations

- The effectiveness of token-level score decomposition is not empirically validated through ablation studies comparing it to sequence-level scoring methods.
- The method's performance is fundamentally constrained by the capabilities and biases of the underlying black-box language model, which introduces significant uncertainty.
- The paper doesn't test scenarios where target and input domains are extremely dissimilar to validate the claimed limitation about editor burden and instability.

## Confidence

**High Confidence**: The core mechanism of using token-level scoring for editor training is well-founded theoretically and supported by experimental results showing improved MAUVE scores. The iterative editing process as a training strategy is also well-supported by the evidence presented.

**Medium Confidence**: The claim that ScoPE maintains the fluency of large language models while incorporating target domain attributes is supported by experimental results, but the evaluation methodology (particularly the MAUVE metric) has limitations in fully capturing fluency and naturalness. The assertion that ScoPE works across different model types is supported but could benefit from testing on a broader range of architectures.

**Low Confidence**: The claim that modifying a small block of tokens is sufficient to shift the language model's generation trajectory toward the target domain lacks direct empirical validation. The paper doesn't test scenarios where target and input domains are extremely dissimilar to validate the claimed limitation. The effectiveness of the repetition score component, while claimed to address non-autoregressive generation issues, lacks thorough ablation studies.

## Next Checks

1. **Ablation Study on Score Decomposition**: Conduct experiments comparing token-level score decomposition against sequence-level scoring to empirically validate the claimed advantage of the token-level approach. This should include quantitative comparisons of training stability, convergence speed, and final performance metrics.

2. **Domain Dissimilarity Stress Test**: Design experiments with deliberately dissimilar source and target domains (e.g., scientific papers to poetry) to test the claimed limitation about editor burden and instability. Measure at what point the method breaks down and identify failure modes.

3. **Cross-Architecture Generalization**: Test ScoPE with a wider range of language model architectures including smaller models (like GPT-2 Small), different transformer variants, and encoder-decoder models to validate the claim of working across different model types. This should include both performance and computational efficiency comparisons.