---
ver: rpa2
title: Detecting out-of-distribution text using topological features of transformer-based
  language models
arxiv_id: '2311.13102'
source_url: https://arxiv.org/abs/2311.13102
tags:
- attention
- topological
- samples
- data
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes using Topological Data Analysis (TDA) on attention
  maps from transformer-based language models to detect out-of-distribution (OOD)
  text. The method extracts topological features from attention graphs and uses distance-based
  OOD scoring functions.
---

# Detecting out-of-distribution text using topological features of transformer-based language models

## Quick Facts
- arXiv ID: 2311.13102
- Source URL: https://arxiv.org/abs/2311.13102
- Reference count: 18
- Primary result: TDA-based OOD detection using attention maps significantly outperforms CLS embeddings for far domain shifts (FPR95: 8-9% vs 87-91%)

## Executive Summary
This work proposes using Topological Data Analysis (TDA) on attention maps from transformer-based language models to detect out-of-distribution (OOD) text. The method extracts topological features from attention graphs and uses distance-based OOD scoring functions. Experiments on BERT show TDA-based OOD detection significantly outperforms CLS embeddings at distinguishing far out-of-domain samples (e.g., IMDB reviews vs news), with FPR95 of 8-9% vs 87-91%. However, performance deteriorates for near or same-domain datasets. The TDA approach captures structural textual patterns but is less sensitive to semantic meaning, which limits its effectiveness on near or same-domain shifts.

## Method Summary
The method extracts topological features from attention maps using Persistent Homology and Vietoris-Rips filtration. Attention maps from BERT are converted to undirected weighted graphs, then filtrations are applied to generate persistence diagrams. Topological features (entropy and amplitude per homology dimension) are extracted and used with distance-based scoring functions (Mahalanobis or KNN) to classify OOD samples. The approach was evaluated on HuffPost news as in-distribution data and IMDB reviews, CNN/Dailymail news, and Business news articles as OOD data, measuring FPR95 and AUROC.

## Key Results
- TDA-based OOD detection achieves FPR95 of 8-9% on far out-of-domain samples (IMDB reviews vs news) compared to 87-91% for CLS embeddings
- Performance deteriorates significantly for near or same-domain datasets
- Fine-tuning does not improve TDA-based OOD detection because the method captures structural rather than semantic features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Topological features from attention maps are better at distinguishing structurally distinct text (far OOD) than semantic embeddings.
- Mechanism: The attention graph construction converts high-dimensional attention weights into a distance-based graph where strong inter-token relationships become short edges. TDA then captures topological invariants (connected components, holes) that reflect grammatical and structural patterns rather than semantic content.
- Core assumption: Far OOD samples (e.g., IMDB reviews) have sufficiently different structural patterns in attention maps compared to in-distribution news text, making topological differences pronounced.
- Evidence anchors:
  - [abstract] "Our results show that our approach outperforms CLS embeddings in distinguishing in-distribution samples from far out-of-domain samples (IMDB reviews)"
  - [section] "The TDA approach accentuates features associated with textual flow or grammatical structures rather than lexical semantics"
  - [corpus] Weak evidence; neighbor papers focus on general OOD detection but do not specifically discuss attention-map TDA.
- Break condition: If near or same-domain OOD samples have similar grammatical structure, the topological features will not provide enough separation.

### Mechanism 2
- Claim: Distance-based OOD scoring functions (Mahalanobis and KNN) work effectively when topological feature vectors form compact, well-separated clusters.
- Mechanism: The persistence diagrams are reduced to low-dimensional feature vectors (entropy, amplitude) that project OOD samples far from ID centroids in feature space, allowing distance metrics to classify them reliably.
- Core assumption: The dimensionality reduction and feature extraction preserve discriminative topological differences while reducing noise.
- Evidence anchors:
  - [abstract] "TDA-based OOD detection significantly outperforms CLS embeddings at distinguishing far out-of-domain samples"
  - [section] "TDA feature vectors project the data into well-separated and compact clusters"
  - [corpus] No direct evidence; neighbor papers discuss OOD scoring but not TDA-based features.
- Break condition: When OOD samples project into overlapping regions with ID clusters in the reduced feature space.

### Mechanism 3
- Claim: Fine-tuning does not improve TDA-based OOD detection because the method captures structural rather than semantic features.
- Mechanism: Fine-tuning adjusts attention weights to optimize for semantic classification tasks, but the resulting attention maps still encode similar grammatical structures for in-domain and near-domain text, leaving topological features unchanged.
- Core assumption: The structural patterns in attention maps are invariant to fine-tuning for classification tasks when near-domain OOD samples are considered.
- Evidence anchors:
  - [abstract] "performance deteriorates for near or same-domain datasets"
  - [section] "Fine-tuning induces a model to divide a single domain cluster into class clusters... For the TDA approach, fine-tuning did not present any considerable benefits."
  - [corpus] No direct evidence; neighbor papers do not address fine-tuning effects on TDA features.
- Break condition: If fine-tuning significantly alters attention head behavior for grammatical processing, topological features might change.

## Foundational Learning

- Concept: Simplicial homology and persistence diagrams
  - Why needed here: The method relies on extracting Betti numbers and persistence features from Vietoris-Rips filtrations of attention graphs.
  - Quick check question: What topological feature represents the number of connected components in a persistence diagram?
- Concept: Transformer attention mechanisms
  - Why needed here: Understanding how attention maps encode inter-token relationships is essential for interpreting the input to TDA.
  - Quick check question: How is the attention weight matrix normalized across tokens in each head?
- Concept: Out-of-distribution detection metrics (FPR95, AUROC)
  - Why needed here: Evaluation of the proposed method requires interpreting these metrics in the context of OOD performance.
  - Quick check question: What does an FPR95 of 8% indicate about the detector's performance?

## Architecture Onboarding

- Component map:
  Input -> Tokenizer -> BERT model -> Attention graph builder -> Filtration engine -> Persistence diagram extractor -> Feature vectorizer -> Distance scorer -> Threshold calibrator
- Critical path:
  1. Tokenize input → 2. Forward pass through BERT → 3. Extract attention maps → 4. Build attention graphs → 5. Compute filtrations → 6. Generate persistence diagrams → 7. Extract features → 8. Standardize → 9. Compute distances → 10. Apply threshold
- Design tradeoffs:
  - Using full attention maps vs. CLS embedding: richer structural info but higher computational cost
  - Number of homology dimensions: more dimensions capture complex topology but increase feature space
  - Distance metric choice: Mahalanobis assumes Gaussian distribution; KNN is non-parametric but may be sensitive to k
- Failure signatures:
  - High FPR95 on far OOD but low on near OOD: topological features not capturing subtle semantic shifts
  - Degraded performance after fine-tuning: semantic shifts in attention maps not reflected in topological features
  - NaN or constant features: filtration producing no simplices in certain dimensions
- First 3 experiments:
  1. Verify attention graph construction by visualizing edge weights for a simple sentence
  2. Test persistence diagram generation on synthetic graphs with known topology
  3. Compare TDA features vs. CLS embeddings on a small balanced ID/OOD dataset to confirm relative performance trends

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does combining TDA-based structural features with semantic embeddings improve OOD detection performance, especially for near and same-domain shifts?
- Basis in paper: [explicit] Authors conclude that TDA captures structural textual patterns but not semantic meaning, and suggest combining topological features with semantic embeddings in an ensemble model could boost OOD detection ability.
- Why unresolved: The paper only tested TDA features and CLS embeddings separately, without exploring any combination approach. No empirical evidence is provided for whether such a combination would improve performance.
- What evidence would resolve it: Experimental results comparing OOD detection performance using TDA features alone, semantic embeddings alone, and various combinations of the two approaches across different types of domain shifts.

### Open Question 2
- Question: How does the effectiveness of TDA-based OOD detection vary across different transformer architectures (e.g., GPT, RoBERTa, smaller BERT variants)?
- Basis in paper: [explicit] The authors state "our methodology is applicable to any transformer-based language model with multihead self-attention" and tested only BERT, suggesting the need to validate across architectures.
- Why unresolved: Experiments were conducted only on BERT, leaving open whether the approach generalizes to other transformer models with different attention mechanisms or training objectives.
- What evidence would resolve it: Comparative studies applying the same TDA methodology to attention maps from multiple transformer architectures, measuring OOD detection performance and analyzing how architectural differences affect the topological features extracted.

### Open Question 3
- Question: Can TDA-based features be effectively adapted for other NLP tasks where textual structure is important, such as authorship attribution or sentiment analysis?
- Basis in paper: [explicit] The authors mention "there is an opportunity to investigate the effectiveness of TDA in other NLP tasks where the textual structure might be important" as future work.
- Why unresolved: The paper only evaluated TDA for OOD detection, providing no evidence about its utility for other tasks that might benefit from structural textual information.
- What evidence would resolve it: Experimental results showing TDA feature performance on various NLP tasks compared to traditional methods, along with analysis of which types of structural patterns captured by TDA are most relevant to each task.

## Limitations

- Poor performance on near and same-domain OOD detection due to focus on structural rather than semantic differences
- Limited evaluation to only BERT architecture, leaving generalization to other transformers unverified
- No ablation studies on fine-tuning effects or comparison with combined structural-semantic approaches

## Confidence

- Mechanism 1 (Structural vs semantic distinction): Medium
- Mechanism 2 (Cluster separation enabling distance metrics): Low  
- Mechanism 3 (Fine-tuning invariance): Low

## Next Checks

1. **Attention pattern visualization**: Extract and visualize attention weights for both in-distribution news text and out-of-distribution IMDB reviews to identify specific structural differences that create topological features. This would validate whether the claimed structural differences actually exist in the attention maps.

2. **Dimensionality reduction analysis**: Apply t-SNE or UMAP to the TDA feature vectors from both in-distribution and out-of-distribution samples to verify the claim that they form "well-separated and compact clusters." This would provide visual evidence for mechanism 2.

3. **Fine-tuning ablation study**: Train a BERT model on the in-distribution task and extract TDA features from both the original and fine-tuned models on the same out-of-distribution samples. Compare FPR95 values to test whether fine-tuning affects TDA-based detection as claimed in mechanism 3.