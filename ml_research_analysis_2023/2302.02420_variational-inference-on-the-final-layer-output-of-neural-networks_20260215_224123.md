---
ver: rpa2
title: Variational Inference on the Final-Layer Output of Neural Networks
arxiv_id: '2302.02420'
source_url: https://arxiv.org/abs/2302.02420
tags:
- duq-mean
- duq-mv
- duq-eb
- directuq
- swag
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Direct Uncertainty Quantification (DirectUQ),
  a method that combines the advantages of traditional neural networks and Bayesian
  neural networks by performing variational inference in the final-layer output space
  rather than the parameter space. DirectUQ uses a neural network to directly output
  the mean and variance of the last layer, enabling simple training like non-Bayesian
  models while providing uncertainty quantification like Bayesian methods.
---

# Variational Inference on the Final-Layer Output of Neural Networks

## Quick Facts
- arXiv ID: 2302.02420
- Source URL: https://arxiv.org/abs/2302.02420
- Reference count: 40
- This paper introduces Direct Uncertainty Quantification (DirectUQ), a method that combines the advantages of traditional neural networks and Bayesian neural networks by performing variational inference in the final-layer output space rather than the parameter space.

## Executive Summary
This paper proposes Direct Uncertainty Quantification (DirectUQ), a novel approach that performs variational inference directly in the output space of neural networks rather than the parameter space. By modeling the mean and variance of the final layer output using a neural network, DirectUQ achieves computational efficiency comparable to traditional neural networks while providing uncertainty quantification similar to Bayesian neural networks. The method is theoretically grounded as an alternative variational lower bound and benefits from collapsed variational inference techniques for improved regularization.

## Method Summary
DirectUQ uses a neural network to directly output the mean and variance of the last layer, enabling simple training like non-Bayesian models while providing uncertainty quantification like Bayesian methods. The method can be derived as an alternative variational lower bound and benefits from collapsed variational inference. Experiments show that DirectUQ provides a good tradeoff in terms of run time and uncertainty quantification, especially for out-of-distribution data, with ensembles of DirectUQ being competitive with ensembles of standard variational inference methods in terms of in-distribution log loss while outperforming them on out-of-distribution data.

## Key Results
- DirectUQ achieves competitive in-distribution log loss while providing better uncertainty quantification for out-of-distribution data
- Ensembles of DirectUQ models outperform single models and are competitive with VI ensembles
- DirectUQ provides better runtime efficiency compared to traditional variational inference methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DirectUQ performs variational inference directly in output space rather than parameter space, dramatically reducing computational complexity.
- Mechanism: By modeling the mean and variance of the final layer output directly, DirectUQ avoids sampling over all network weights. Instead, it uses a neural network to output the mean (μq(x)) and diagonal covariance (σq(x)) of the last layer, requiring only one forward pass plus sampling from a low-dimensional output space.
- Core assumption: The distribution of the final layer output can be approximated by a Gaussian, and this approximation is sufficient for uncertainty quantification.
- Evidence anchors:
  - [abstract] "DirectUQ uses a neural network to directly output the mean and variance of the last layer, enabling simple training like non-Bayesian models while providing uncertainty quantification like Bayesian methods."
  - [section 2] "DirectUQ pursues this in a direct manner. It has two sets of weights, W1 and W2 (with shared components), to model the mean and variance of z."
  - [corpus] Weak - the corpus neighbors focus on variational inference in weight space or functional space, not output space.

### Mechanism 2
- Claim: DirectUQ can be derived as an alternative variational lower bound, enabling collapsed variational inference and improved regularizers.
- Mechanism: DirectUQ can be formulated as maximizing the evidence lower bound (ELBO) with priors and posteriors placed on the output layer rather than weights. This connection allows applying collapsed variational inference techniques to learn optimal prior parameters, providing better regularization.
- Core assumption: The ELBO formulation is valid when priors and posteriors are placed on the output layer instead of weights.
- Evidence anchors:
  - [abstract] "DirectUQ can be derived as an alternative variational lower bound, and hence benefits from collapsed variational inference that provides improved regularizers."
  - [section 2] "Using the Bayesian formulation we incorporate collapsed variational inference with VIFO which significantly improves the performance in practice."
  - [section 5] "We model the prior mean μp and variance σp² as Bayesian parameters... Then the objective becomes: log p(y|x) ≥ Eq(z|x)q(μp,σp²)[log p(y, z, μp, σp²|x)/q(z|x)q(μp, σp²)]"
  - [corpus] Weak - corpus neighbors discuss variational inference but not collapsed variational inference on output space.

### Mechanism 3
- Claim: DirectUQ provides better uncertainty quantification for out-of-distribution data compared to standard variational inference while maintaining competitive in-distribution performance.
- Mechanism: By explicitly modeling both aleatoric and epistemic uncertainty in the output space, DirectUQ can better capture the increased uncertainty present in out-of-distribution samples. The ensembles of DirectUQ further improve this capability.
- Core assumption: The explicit modeling of output space uncertainty captures distributional shifts better than weight-space uncertainty.
- Evidence anchors:
  - [abstract] "Experiments show that DirectUQ provides a good tradeoff in terms of run time and uncertainty quantification, especially for out of distribution data."
  - [section 6.3] "Figure 1 shows the entropy of predictive distribution of OOD data for all methods. Here single-model DirectUQ outperforms SGD and Dropout and ensembles of DirectUQ outperform VI."
  - [section 6.4] "Ensembles of DirectUQ are competitive with VI and other methods in terms of in-distribution loss, they outperform VI for out of distribution data."
  - [corpus] Moderate - corpus neighbors discuss uncertainty quantification but not specifically for OOD data.

## Foundational Learning

- Concept: Variational Inference and ELBO
  - Why needed here: DirectUQ is derived as an alternative variational lower bound, so understanding standard VI and ELBO is crucial for grasping the theoretical foundation.
  - Quick check question: What is the relationship between the ELBO and the KL divergence in variational inference?

- Concept: Bayesian Neural Networks and Uncertainty Quantification
  - Why needed here: DirectUQ aims to combine the simplicity of traditional NNs with the uncertainty quantification of BNNs, so understanding how BNNs model uncertainty is essential.
  - Quick check question: What are the two types of uncertainty (aleatoric and epistemic) that Bayesian methods can quantify?

- Concept: Rademacher Complexity and Generalization Bounds
  - Why needed here: The paper provides generalization bounds for DirectUQ through Rademacher complexity, which is a key theoretical contribution showing the model's learnability.
  - Quick check question: How does Rademacher complexity relate to the generalization ability of a hypothesis class?

## Architecture Onboarding

- Component map:
  - Input processing network (shared weights W1, W2)
  - Mean prediction head (W1 → μq(x))
  - Variance prediction head (W2 → σq(x))
  - Sampling module (samples z ~ N(μq(x), diag(σq(x)²)))
  - Loss computation (likelihood + KL regularization)
  - Optional collapsed VI module (hierarchical priors on μp, σp²)

- Critical path:
  1. Forward pass through shared network to get intermediate features
  2. Separate heads compute mean and variance predictions
  3. Sample from predictive distribution
  4. Compute likelihood loss and KL regularization
  5. Backpropagate gradients through reparameterization

- Design tradeoffs:
  - Simplicity vs. expressiveness: DirectUQ is simpler than VI but potentially less expressive
  - Output space vs. weight space: Output space is lower dimensional but may miss some uncertainty patterns
  - Diagonal covariance assumption: Computationally efficient but may not capture full correlations

- Failure signatures:
  - Poor calibration on shifted data (high ECE)
  - Low entropy on OOD data (overconfident predictions)
  - High variance in predictions (unstable training)
  - Degraded in-distribution performance (over-regularization)

- First 3 experiments:
  1. Verify DirectUQ can reproduce standard NN predictions with η=0 (no regularization)
  2. Test calibration on a simple shifted dataset (e.g., CIFAR10 → STL10)
  3. Compare runtime of DirectUQ vs. VI with same network architecture and dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does DirectUQ maintain its advantage over VI and SGD when scaling to much larger models and datasets?
- Basis in paper: [inferred] The paper evaluates DirectUQ on AlexNet and PreResNet20 with CIFAR10, CIFAR100, SVHN, and STL10 datasets, showing competitive performance. However, the paper does not explore performance on significantly larger models or datasets beyond these.
- Why unresolved: The experiments focus on moderate-sized image datasets and models. It remains unclear whether DirectUQ's benefits in terms of uncertainty quantification and computational efficiency persist when scaling to state-of-the-art deep learning architectures and massive datasets.
- What evidence would resolve it: Extensive experiments on larger models (e.g., ResNet-50/101, Vision Transformers) and datasets (e.g., ImageNet, JFT-300M) comparing DirectUQ's uncertainty quantification, log loss, and computational efficiency against VI, SGD, and other baselines.

### Open Question 2
- Question: How does the choice of prior distribution in DirectUQ affect its performance, especially in non-linear cases?
- Basis in paper: [explicit] The paper mentions using simple priors (independent of input) for DirectUQ and acknowledges that the choice of prior parameters can significantly affect performance. It also references collapsed variational inference and empirical Bayes as methods to improve prior selection.
- Why unresolved: While the paper uses simple priors and explores some variants, it does not comprehensively investigate the impact of different prior distributions (e.g., correlated priors, data-dependent priors) on DirectUQ's performance, especially in deep non-linear networks.
- What evidence would resolve it: Systematic experiments varying the prior distribution (e.g., Gaussian with different covariances, hierarchical priors) in DirectUQ and measuring the impact on uncertainty quantification, log loss, and computational efficiency across multiple datasets and network architectures.

### Open Question 3
- Question: Can DirectUQ be effectively combined with other uncertainty quantification methods, such as ensembling or Monte Carlo dropout, to further improve performance?
- Basis in paper: [inferred] The paper demonstrates that ensembles of DirectUQ models outperform single models and are competitive with ensembles of VI. However, it does not explore combining DirectUQ with other established uncertainty quantification techniques.
- Why unresolved: The paper focuses on DirectUQ as a standalone method and its comparison with VI and SGD. The potential synergies or trade-offs of combining DirectUQ with other methods like Monte Carlo dropout or deep ensembles are not explored.
- What evidence would resolve it: Experiments combining DirectUQ with other uncertainty quantification methods (e.g., Monte Carlo dropout layers, deep ensembles of DirectUQ models) and evaluating their performance on uncertainty quantification, log loss, and computational efficiency compared to individual methods and their ensembles.

## Limitations
- The theoretical analysis relies on assumptions about the output distribution being well-approximated by Gaussian, which may not hold for all architectures or datasets.
- The collapsed variational inference component adds complexity that may be difficult to scale to larger models.
- The empirical evaluation focuses primarily on classification tasks, with limited exploration of regression or other problem types.

## Confidence

**High confidence**: The mechanism of reducing computational complexity by operating in output space rather than parameter space is clearly articulated and experimentally validated through runtime comparisons.

**Medium confidence**: The claim that DirectUQ provides better out-of-distribution uncertainty quantification is supported by experiments but could benefit from additional datasets and distribution shift scenarios.

**Medium confidence**: The connection to variational lower bounds and collapsed inference is theoretically sound but the practical benefits depend heavily on implementation details and hyperparameter tuning.

## Next Checks

1. Test DirectUQ on regression tasks with heteroscedastic noise to verify uncertainty quantification beyond classification problems.

2. Conduct ablation studies varying the dimensionality of the output space to determine the minimum viable dimension for effective uncertainty quantification.

3. Compare calibration metrics (ECE, reliability diagrams) across all datasets to systematically evaluate the quality of uncertainty estimates rather than just their magnitude.