---
ver: rpa2
title: 'EWasteNet: A Two-Stream Data Efficient Image Transformer Approach for E-Waste
  Classification'
arxiv_id: '2311.12823'
source_url: https://arxiv.org/abs/2311.12823
tags:
- e-waste
- classification
- image
- dataset
- stream
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of e-waste classification for
  efficient recycling and waste management, which is critical due to the environmental
  and health risks posed by improper e-waste disposal. The authors introduce the E-Waste
  Vision Dataset, a comprehensive dataset consisting of 1053 images from eight different
  classes of electronic devices.
---

# EWasteNet: A Two-Stream Data Efficient Image Transformer Approach for E-Waste Classification

## Quick Facts
- arXiv ID: 2311.12823
- Source URL: https://arxiv.org/abs/2311.12823
- Reference count: 28
- Primary result: Achieves 96% accuracy on e-waste classification using a novel two-stream DeiT architecture with Sobel edge detection and ASPP

## Executive Summary
This paper addresses the critical problem of e-waste classification for efficient recycling and waste management, which is essential due to the environmental and health risks posed by improper e-waste disposal. The authors introduce the E-Waste Vision Dataset, a comprehensive dataset consisting of 1053 images from eight different classes of electronic devices. They propose EWasteNet, a novel two-stream data-efficient image transformer approach for precise e-waste image classification. The first stream uses a Sobel operator to detect edges, while the second stream employs Atrous Spatial Pyramid Pooling and an attention block to capture multi-scale contextual information. Both streams are trained simultaneously, and their features are merged at the decision level. The proposed method achieves an impressive accuracy of 96% on the test dataset, demonstrating its effectiveness in addressing the global concern of e-waste management.

## Method Summary
The EWasteNet architecture consists of two parallel streams that process input images of size 348×384 pixels. The first stream applies a Sobel operator for edge detection, followed by convolution and a DeiT backbone. The second stream passes through an Atrous Spatial Pyramid Pooling (ASPP) block with five parallel convolutional layers using dilation rates from 1 to 5, followed by a Convolutional Block Attention Module (CBAM), convolution, and another DeiT backbone. Features from both streams are concatenated and passed through an MLP with two fully connected layers (512→256→256 neurons), dropout layers (30% and 20%), ReLU activation, and a softmax output layer. The model is trained for 20 epochs with less than 1M parameters on the E-Waste Vision Dataset, which contains 1053 images across eight classes split in a 70:10:20 ratio for training, validation, and testing.

## Key Results
- Achieved 96% test accuracy on the E-Waste Vision Dataset
- Demonstrated effective multi-scale feature capture through ASPP with varying dilation rates
- Showed successful decision-level fusion of edge and contextual features

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sobel operator enhances edge detection for small e-waste datasets by providing precise structural boundaries.
- Mechanism: The Sobel operator computes gradients at each pixel location to extract edge features, which helps the DeiT backbone focus on structural details of e-waste items.
- Core assumption: Edge information is more discriminative than raw pixel values for e-waste classification when dataset size is limited.
- Evidence anchors: [abstract] "The first stream of EWasteNet passes through a sobel operator that detects the edges"; [section] "The sobel operator plays a crucial role in this stream by enabling the extraction of edge features from input images"
- Break condition: If e-waste items have very similar shapes, edge information alone becomes insufficient.

### Mechanism 2
- Claim: Atrous Spatial Pyramid Pooling (ASPP) captures multi-scale contextual information essential for recognizing e-waste of varying sizes.
- Mechanism: ASPP uses parallel convolutional layers with different dilation rates (1, 2, 3, 4, 5) to aggregate features at multiple scales, allowing the model to handle e-waste items of different dimensions.
- Core assumption: E-waste items in the dataset vary significantly in size and scale, requiring multi-scale feature aggregation.
- Evidence anchors: [abstract] "the second stream is directed through an Atrous Spatial Pyramid Pooling and attention block where multi-scale contextual information is captured"; [section] "The ASPP block... accomplishes this by using parallel convolutional layers with various dilation rates"
- Break condition: If all e-waste items are roughly similar in scale, ASPP complexity may be unnecessary.

### Mechanism 3
- Claim: Decision-level fusion of edge and pyramid streams leverages complementary information for improved classification accuracy.
- Mechanism: Features from both streams are concatenated and passed through an MLP with dropout layers to prevent overfitting, combining structural edge information with contextual multi-scale features.
- Core assumption: Edge features and contextual features contain complementary information that improves overall classification when fused.
- Evidence anchors: [abstract] "We train both of the streams simultaneously and their features are merged at the decision level"; [section] "In our research work, the two streams are fused to improve the overall classification performance by integrating their distinct features"
- Break condition: If one stream consistently dominates the other, simple averaging or weighted fusion might be more efficient.

## Foundational Learning

- Concept: Data-efficient image transformers (DeiT)
  - Why needed here: DeiT can achieve good performance with limited training data, which is critical given the E-Waste Vision Dataset has only 1053 images
  - Quick check question: How does DeiT achieve data efficiency compared to standard Vision Transformers?

- Concept: Atrous Spatial Pyramid Pooling (ASPP)
  - Why needed here: ASPP captures multi-scale features necessary for classifying e-waste items that vary in size and complexity
  - Quick check question: What is the relationship between dilation rate and receptive field size in ASPP?

- Concept: Convolutional Block Attention Module (CBAM)
  - Why needed here: CBAM helps the model focus on the most informative parts of e-waste images by applying spatial and channel attention
  - Quick check question: How does CBAM differ from other attention mechanisms like squeeze-and-excitation?

## Architecture Onboarding

- Component map: Input → Sobel operator → Convolution → DeiT (Edge stream); Input → ASPP (5 parallel conv layers with dilation rates 1-5) → CBAM → Convolution → DeiT (Pyramid stream); Concatenated features → MLP with 512→256 neurons + dropout → Softmax classification

- Critical path: Input → Two parallel streams (Edge + Pyramid) → Fusion → MLP → Classification

- Design tradeoffs:
  - Two-stream approach vs single-stream: Higher accuracy but increased complexity
  - Sobel operator vs learned edge detection: Deterministic edge extraction vs data-driven approach
  - ASPP with 5 dilation rates vs fewer rates: Better multi-scale coverage vs reduced computation

- Failure signatures:
  - High validation accuracy but low test accuracy: Overfitting to validation set
  - Both streams underperforming: Insufficient feature extraction or poor DeiT integration
  - One stream dominating: Imbalanced contribution requiring weighted fusion

- First 3 experiments:
  1. Train only edge stream with Sobel preprocessing and compare to baseline DeiT
  2. Train only pyramid stream with ASPP and CBAM, evaluate multi-scale effectiveness
  3. Test different fusion strategies (early fusion vs decision-level fusion) to optimize complementary feature utilization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the EWasteNet architecture perform on datasets with more classes or significantly larger sample sizes compared to the current E-Waste Vision Dataset?
- Basis in paper: [explicit] The paper notes that the dataset used has a limited number of samples (1053 images across 8 classes), and the authors emphasize the use of a data-efficient model (DeiT) to handle this limitation.
- Why unresolved: The current evaluation is based on a relatively small dataset, and it is unclear whether the model's performance would scale to larger or more diverse datasets.
- What evidence would resolve it: Testing EWasteNet on larger, more diverse e-waste datasets and comparing its performance metrics (accuracy, precision, recall, F1-score, MCC) with those from the current dataset.

### Open Question 2
- Question: What is the impact of using different edge detection operators (e.g., Canny, Laplacian) instead of the Sobel operator in the edge stream of EWasteNet?
- Basis in paper: [explicit] The paper uses the Sobel operator for edge detection in the edge stream but does not explore other edge detection methods.
- Why unresolved: The choice of edge detection operator could significantly influence the model's ability to capture relevant features, and the paper does not compare the performance of different operators.
- What evidence would resolve it: Conducting experiments with alternative edge detection operators and comparing their impact on the model's classification accuracy and feature extraction capabilities.

### Open Question 3
- Question: How does the fusion strategy of the two streams (edge and pyramid) in EWasteNet affect the model's performance compared to using a single-stream architecture?
- Basis in paper: [explicit] The paper describes the fusion of features from the edge and pyramid streams but does not provide a comparative analysis with single-stream architectures.
- Why unresolved: While the paper demonstrates the effectiveness of the two-stream approach, it does not quantify the specific benefits of fusion over single-stream models.
- What evidence would resolve it: Implementing and evaluating single-stream versions of EWasteNet (using only the edge or pyramid stream) and comparing their performance metrics with the two-stream model.

### Open Question 4
- Question: How does the model's performance change with varying levels of image preprocessing, such as different resizing dimensions or augmentation techniques?
- Basis in paper: [inferred] The paper mentions specific preprocessing steps (background removal, resizing to 348×384 pixels, and augmentation techniques) but does not explore the impact of alternative preprocessing methods.
- Why unresolved: Preprocessing can significantly affect model performance, and the paper does not investigate the sensitivity of the model to different preprocessing configurations.
- What evidence would resolve it: Experimenting with different image sizes, augmentation strategies, and preprocessing techniques, and analyzing their impact on the model's classification accuracy and robustness.

## Limitations

- The dataset size (1053 images) is relatively small, which may limit generalization to real-world conditions
- Claims about Sobel operator and ASPP superiority lack empirical validation through ablation studies
- No comparison with established e-waste classification methods or state-of-the-art computer vision approaches

## Confidence

- High confidence: The overall framework design and dataset creation process are clearly specified and reproducible
- Medium confidence: The reported 96% accuracy is plausible given the controlled dataset conditions, but may not generalize well to diverse real-world e-waste images
- Low confidence: Claims about the superiority of Sobel and ASPP components over alternative feature extraction methods lack empirical validation through ablation studies

## Next Checks

1. Conduct ablation study by removing Sobel operator and ASPP individually to quantify their contribution to the 96% accuracy, determining if simpler architectures could achieve similar results

2. Evaluate the model on a separate dataset of e-waste images collected from actual recycling facilities under varying lighting, backgrounds, and device conditions

3. Compare EWasteNet performance against standard computer vision approaches (CNNs, single-stream transformers) and established e-waste classification methods using the same dataset splits