---
ver: rpa2
title: Multi-Objective Optimization for Sparse Deep Multi-Task Learning
arxiv_id: '2308.12243'
source_url: https://arxiv.org/abs/2308.12243
tags:
- learning
- pareto
- optimization
- tasks
- sparsity
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a multi-objective optimization algorithm for
  training deep neural networks (DNNs) that balances multiple conflicting objectives
  such as loss minimization, sparsity, and task-specific performance. The approach
  uses a modified Weighted Chebyshev scalarization technique combined with an Augmented
  Lagrangian method to identify all optimal solutions of the original problem while
  reducing complexity to a sequence of single-objective problems.
---

# Multi-Objective Optimization for Sparse Deep Multi-Task Learning

## Quick Facts
- arXiv ID: 2308.12243
- Source URL: https://arxiv.org/abs/2308.12243
- Reference count: 10
- Primary result: Presents a multi-objective optimization algorithm that balances loss minimization, sparsity, and task-specific performance in deep neural networks, achieving up to 57.26% sparsity with 2.7x compression while maintaining task performance.

## Executive Summary
This paper introduces a multi-objective optimization framework for training deep neural networks that simultaneously optimizes loss minimization, sparsity, and task-specific performance. The approach employs a Modified Weighted Chebyshev scalarization technique combined with an Augmented Lagrangian method to transform the multi-objective problem into a sequence of single-objective problems. This enables the use of standard optimizers like Adam and SGD while effectively handling constraints. Experiments on MultiMNIST and Cifar10Mnist datasets demonstrate the feasibility of adaptively sparsifying models during training without significantly impacting performance, addressing sustainability concerns in deep learning by reducing model complexity and computational cost.

## Method Summary
The method combines Modified Weighted Chebyshev scalarization with Augmented Lagrangian optimization to handle multi-objective optimization for sparse deep multi-task learning. The scalarization transforms the multi-objective problem into a sequence of single-objective problems by minimizing the maximum weighted deviation from a reference point across all objectives. The Augmented Lagrangian method then handles the constraints introduced by this transformation, enabling the use of standard optimizers like Adam and SGD. A Group Ordered Weighted l1 (GrOWL) regularizer is applied to promote sparsity and parameter tying across the network layers. The approach is evaluated on two datasets using a Multi-Domain Multi-Task Network (MDMTN) architecture that shares representations across tasks while maintaining task-specific components.

## Key Results
- Achieves sparsity rates up to 57.26% with compression rates up to 2.7x
- Demonstrates adaptive model sparsification during training without significant performance degradation
- Outperforms baseline methods (HPS and MGDA) in sparsity-accuracy trade-offs on MultiMNIST and Cifar10Mnist datasets

## Why This Works (Mechanism)

### Mechanism 1
The Modified Weighted Chebyshev scalarization transforms a multi-objective problem into a sequence of single-objective problems that can be solved efficiently. By introducing a reference point and weights, the method minimizes the maximum weighted deviation from the reference across all objectives, reducing the complexity of the original problem. The core assumption is the existence of a reference point strictly dominated by all objective values across the feasible set.

### Mechanism 2
The Augmented Lagrangian method handles the constraints introduced by the scalarization, enabling the use of standard optimizers like Adam and SGD. The AL method transforms the constrained optimization problem into an unconstrained one by adding a penalty term that depends on the Lagrange multipliers and constraint violation. The approach assumes continuously differentiable objective functions and constraints.

### Mechanism 3
The Group Ordered Weighted l1 (GrOWL) regularizer promotes sparsity and parameter tying, reducing model complexity without significantly impacting performance. GrOWL encourages groups of parameters to share the same values by penalizing the norm of each group with a learned weight, leading to sparse and compressed models. The approach assumes the DNN has a layered structure where parameters can be meaningfully grouped.

## Foundational Learning

- **Concept: Multi-Objective Optimization (MOO)**
  - Why needed here: The paper addresses scenarios where multiple conflicting objectives need to be optimized simultaneously, such as loss minimization, sparsity, and task-specific performance.
  - Quick check question: What is the difference between Pareto optimal and weakly Pareto optimal solutions in MOO?

- **Concept: Scalarization Techniques**
  - Why needed here: Scalarization methods like Weighted Chebyshev are used to transform the multi-objective problem into a single-objective problem that can be solved more efficiently.
  - Quick check question: How does the Weighted Chebyshev scalarization differ from a simple weighted sum approach?

- **Concept: Augmented Lagrangian Method**
  - Why needed here: The AL method is used to handle the constraints introduced by the scalarization, enabling the use of standard optimizers like Adam and SGD.
  - Quick check question: What is the role of the Lagrange multipliers in the Augmented Lagrangian method?

## Architecture Onboarding

- **Component map**: Input Layer -> Shared Network -> Task-specific Monitors -> Task-specific Output Networks, with GrOWL Regularization applied to all layers except input and task-specific output layers.

- **Critical path**:
  1. Initialize the model with the MDMTN architecture
  2. Set the importance vector k and reference point a for the Modified Weighted Chebyshev scalarization
  3. Use the Augmented Lagrangian method to solve the resulting sequence of single-objective problems
  4. Apply the GrOWL regularizer to promote sparsity and parameter tying
  5. Train the model using popular optimizers like Adam or SGD

- **Design tradeoffs**:
  - Sparsity vs. Performance: Increasing sparsity may lead to a decrease in model performance, especially for dissimilar tasks
  - Shared vs. Task-specific Representations: Balancing the amount of shared and task-specific representations is crucial for effective multi-task learning
  - Regularization Strength: The strength of the GrOWL regularizer determines the degree of sparsity and parameter tying

- **Failure signatures**:
  - Poor Performance on Individual Tasks: If the model is too sparse or the shared representations are not well-learned
  - Lack of Convergence: If the constraints are not properly handled or the penalty parameter is not tuned
  - Overfitting: If the model is not sufficiently regularized

- **First 3 experiments**:
  1. Train the MDMTN model on the MultiMNIST dataset with different sparsity rates and compare the performance on the main tasks
  2. Evaluate the effectiveness of the GrOWL regularizer in promoting sparsity and parameter tying on the Cifar10Mnist dataset
  3. Investigate the impact of the importance vector k on the trade-off between sparsity and performance on both datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the degree of sparsity induced by the multi-objective optimization approach vary across multiple repetitions of the training process, especially when the acceptable range is large?
- Basis in paper: The authors mention that "One limitation of our approach is that, when considering a specific preference vector, the degree of sparsity induced might exhibit variation across multiple repetitions of the training process, especially when the acceptable range is too large."
- Why unresolved: This limitation is acknowledged but not thoroughly investigated in the paper.
- What evidence would resolve it: Conducting multiple training runs with the same preference vector and measuring the variability in the induced sparsity levels would provide insights into the reproducibility of the approach.

### Open Question 2
- Question: How does the impact of sparsity on model performance differ for tasks with dissimilar characteristics compared to tasks with similar characteristics?
- Basis in paper: The authors observe that the effect of sparsity on model performance could display randomness when dealing with significantly dissimilar tasks, as seen in the Cifar10Mnist dataset experiments.
- Why unresolved: The paper does not delve into the underlying reasons behind the different behavior of sparsity on model performance for tasks with dissimilar characteristics.
- What evidence would resolve it: Conducting experiments with a diverse set of datasets containing tasks with varying degrees of similarity could help in understanding the relationship between task similarity and the impact of sparsity on model performance.

### Open Question 3
- Question: Can the proposed multi-objective optimization approach be extended to handle more than three objectives effectively?
- Basis in paper: The paper focuses on a multi-objective optimization approach with three objectives: loss minimization, sparsity, and task-specific performance.
- Why unresolved: The authors do not provide any theoretical analysis or empirical evidence regarding the scalability of the approach to handle more than three objectives.
- What evidence would resolve it: Conducting experiments with a higher number of objectives would help assess the scalability of the approach.

## Limitations

- The approach relies on carefully tuned reference points and importance vectors for the Modified Weighted Chebyshev scalarization, but the paper provides limited guidance on selecting these parameters.
- The convergence guarantees depend on differentiability assumptions that may not hold for all deep learning architectures, particularly those using non-smooth activation functions or discrete operations.
- The claims about achieving Pareto optimality are theoretically sound but practically limited, as the discretization of DNN training means only approximate Pareto solutions are found in practice.

## Confidence

**High Confidence**: The fundamental mathematical framework of using Augmented Lagrangian methods with scalarization techniques is well-established in optimization theory. The empirical results demonstrating sparsity-accuracy trade-offs are clearly presented and reproducible.

**Medium Confidence**: The effectiveness of the GrOWL regularizer in promoting parameter tying while maintaining task performance is supported by experiments, but the sensitivity to regularization strength and grouping strategies requires further investigation.

**Low Confidence**: The paper's claims about achieving Pareto optimality are theoretically sound but practically limited, as the discretization of DNN training and the sequential nature of the optimization process mean only approximate Pareto solutions are found in practice.

## Next Checks

1. **Sensitivity Analysis**: Systematically vary the importance vector k and reference point a across multiple orders of magnitude to assess their impact on convergence and solution quality.

2. **Architecture Transferability**: Test the approach on architectures beyond MDMTN (e.g., transformer-based models) to evaluate generalizability of the scalarization + AL method combination.

3. **Constraint Violation Monitoring**: During training, track constraint violation metrics alongside the augmented Lagrangian objective to verify that the penalty method is effectively handling the constraints as intended.