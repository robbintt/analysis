---
ver: rpa2
title: 'Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers
  to Detect Hate Speech on Social Media'
arxiv_id: '2307.09312'
source_url: https://arxiv.org/abs/2307.09312
tags:
- hate
- graph
- speech
- discussion
- layers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel multi-modal transformer architecture
  called mDT for detecting hate speech in online social media discussions. Unlike
  previous methods that only analyze individual comments or ignore images, mDT holistically
  analyzes the complete discussion context by integrating text, images, and graph
  transformers.
---

# Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media

## Quick Facts
- arXiv ID: 2307.09312
- Source URL: https://arxiv.org/abs/2307.09312
- Reference count: 36
- Primary result: mDT achieves 14.5% higher accuracy and 21% higher F1 score than state-of-the-art hate speech detection methods

## Executive Summary
This paper introduces mDT, a novel multi-modal transformer architecture for detecting hate speech in online social media discussions. Unlike previous methods that only analyze individual comments or ignore images, mDT holistically analyzes the complete discussion context by integrating text, images, and graph transformers. The key innovation is interweaving fusion layers that combine text and image embeddings with graph transformer layers that capture contextual relationships between comments. This allows mDT to create rich, contextualized multi-modal representations of discussions. The authors also propose a novel graph structure encoding tailored to social media discussions and introduce a new dataset called HatefulDiscussions containing over 18,000 labeled comments from Reddit discussions.

## Method Summary
The mDT model consists of three main components: initial pre-fusion using frozen BERT and ViT layers for text and image encoding, modality fusion with shared bottleneck tokens for combining representations, and graph transformer layers with hierarchical spatial encoding for modeling discussion context. The model interweaves Z fusion layers with G graph transformer layers, using shared bottleneck tokens to force information exchange between modalities while preserving conversation structure. A novel hierarchical spatial encoding based on Cantor's pairing function captures the conversational hierarchy better than traditional shortest-path encoding. The model is trained on the HatefulDiscussions dataset using 7-fold cross-validation with a learning rate schedule from 3e-5 to 3e-7.

## Key Results
- mDT achieves 14.5% higher accuracy than previous state-of-the-art methods
- The model shows 21% improvement in F1 score compared to text-only baselines
- Ablation studies demonstrate that removing any component (text, image, or graph) significantly degrades performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating text, image, and graph transformers with shared bottleneck tokens enables richer, context-aware hate speech representations.
- Mechanism: The mDT model interweaves fusion layers that combine text and image embeddings with graph transformer layers that capture relationships between comments. Shared bottleneck tokens force both modalities to compress and exchange information, grounding fusion models in the discussion context.
- Core assumption: Bottleneck tokens can effectively mediate information exchange between text and image transformers while graph transformers can leverage these shared representations to model contextual relationships.
- Evidence anchors:
  - [abstract] "This is done by leveraging graph transformers to capture the contextual relationships in the discussion surrounding a comment and grounding the interwoven fusion layers that combine text and image embeddings"
  - [section 3.1.2] "We adopt the bottleneck mechanism proposed by [21] and add ð‘ shared modality bottleneck tokens ðµ âˆˆ ð‘…ð‘ Ã—ð‘‘ to ð‘¡ð‘ and ð‘–ð‘"
  - [section 3.1.3] "After ðº graph transformer layers, the final representation of â„Žðºð‘ replaces ð‘0ð‘ for the next set of ð‘ modality fusion layers"
- Break condition: If the bottleneck size is too small, modality representations may lose critical information, reducing detection accuracy. If too large, compression benefits are lost and model efficiency decreases.

### Mechanism 2
- Claim: The hierarchical spatial encoding using Cantor's pairing function better captures the conversational structure of social media discussions than traditional shortest-path encoding.
- Mechanism: The proposed encoding maps the number of upward and downward hops between nodes to a unique index, allowing the model to distinguish between direct replies and more distant comments that are the same shortest-path distance apart.
- Core assumption: Social media discussion graphs have hierarchical structure where the relationship between comments depends on their relative positions in the reply chain, not just shortest-path distance.
- Evidence anchors:
  - [section 3.1.3] "However, this metric does not lend itself well to the hierarchical structure of discussions, where equivalent distances can represent different interactions"
  - [section 3.1.3] "To account for this, we propose a novel hierarchical spatial encoding based on Cantor's pairing function"
  - [section 4.4] "Our findings suggest that a balance is required when constraining graph attention for optimal performance"
- Break condition: If the hierarchical spatial encoding is not properly learned or if the graph structure is too shallow, the encoding may not provide meaningful advantages over simpler approaches.

### Mechanism 3
- Claim: Constraining graph attention to a limited number of hops improves hate speech detection by reducing the impact of irrelevant discussion context.
- Mechanism: The graph transformer network's attention mechanism is limited to nodes within a maximum number of hops from a source node, preventing the model from being overwhelmed by distant, potentially misleading context.
- Core assumption: Distant comments in a discussion are less relevant to understanding the context of a specific comment for hate speech detection, and may even introduce noise.
- Evidence anchors:
  - [section 4.4] "A recent study by Hebert et al. explored the limitations of graph transformers for hate speech prediction, finding that discussion context can sometimes mislead graph models into making incorrect predictions"
  - [section 4.4] "Our findings suggest that a balance is required when constraining graph attention for optimal performance"
- Break condition: If the attention window is too constrained, important contextual information may be missed, reducing the model's ability to understand nuanced hate speech.

## Foundational Learning

- Concept: Transformer architectures and attention mechanisms
  - Why needed here: The mDT model is built upon transformer layers for both modality fusion and graph modeling, requiring a deep understanding of self-attention, multi-head attention, and positional encodings.
  - Quick check question: What is the purpose of the attention mechanism in transformer models, and how does it differ from traditional recurrent neural networks?

- Concept: Graph neural networks and graph transformers
  - Why needed here: The mDT model incorporates graph transformer layers to model the relationships between comments in a discussion, requiring knowledge of graph convolutions, node embeddings, and graph attention.
  - Quick check question: How do graph neural networks differ from traditional neural networks, and what are the advantages of using graph transformers for modeling relational data?

- Concept: Multi-modal learning and fusion techniques
  - Why needed here: The mDT model combines text and image representations through modality fusion layers, requiring an understanding of techniques for aligning and fusing information from different modalities.
  - Quick check question: What are the main challenges in multi-modal learning, and how do bottleneck fusion mechanisms address these challenges?

## Architecture Onboarding

- Component map: Initial Pre-Fusion -> Modality Fusion -> Graph Transformer -> Prediction
- Critical path:
  1. Encode initial text and image representations using frozen BERT and ViT layers
  2. Iteratively fuse text and image representations using shared bottleneck tokens
  3. Apply graph transformer layers to incorporate discussion context
  4. Combine final text, image, and graph representations for hate speech prediction

- Design tradeoffs:
  - Bottleneck size: Larger bottlenecks allow more information exchange but reduce compression benefits and efficiency
  - Number of fusion layers: More fusion layers can improve performance but increase computational complexity
  - Graph attention window: Larger windows capture more context but may introduce noise and reduce performance

- Failure signatures:
  - Poor performance on discussions with predominantly neutral context: The model may be misled by irrelevant discussion context
  - Degradation when images are removed: The model relies heavily on image information for hate speech detection
  - Inconsistent results with different graph structures: The model may not generalize well to very different discussion formats

- First 3 experiments:
  1. Evaluate the impact of bottleneck size on model performance and efficiency
  2. Compare the proposed hierarchical spatial encoding with traditional shortest-path encoding
  3. Assess the importance of image information by training a text-only version of the model and comparing performance

## Open Questions the Paper Calls Out
- How does mDT perform when applied to other online platforms beyond Reddit, such as Twitter or Facebook? (Basis: paper mentions future work could explore other platforms)
- How does mDT handle discussions that contain multiple languages or code-switching between languages? (Basis: paper doesn't discuss multilingual support but hate speech detection is global)
- How does mDT handle discussions that contain sarcasm, irony, or other forms of figurative language that can be difficult to detect? (Basis: paper doesn't discuss figurative language but it's common in NLP challenges)

## Limitations
- The model's performance on other discussion platforms beyond Reddit remains untested
- Computational requirements (48-hour training on 4 GPUs) may limit practical deployment
- The model's behavior with degraded or missing images is not explored

## Confidence
- Performance claims: High confidence (consistent improvements across all metrics with ablation support)
- Mechanism claims: Medium confidence (theoretical support with partial empirical evidence)
- Dataset claims: High confidence (clear construction methodology and balanced labeling)

## Next Checks
1. Cross-platform validation: Test mDT on hate speech data from Twitter, Facebook, or other platforms to assess generalizability beyond Reddit's discussion structure.
2. Ablation with varying bottleneck sizes: Systematically evaluate model performance across different bottleneck token counts (1-16) to identify the optimal compression level and understand information loss tradeoffs.
3. Missing modality robustness: Train and evaluate the model on datasets where images are randomly removed or corrupted to quantify the model's dependence on visual information and its performance degradation patterns.