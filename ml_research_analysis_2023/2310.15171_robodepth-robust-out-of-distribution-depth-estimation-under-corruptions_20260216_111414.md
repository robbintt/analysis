---
ver: rpa2
title: 'RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions'
arxiv_id: '2310.15171'
source_url: https://arxiv.org/abs/2310.15171
tags:
- depth
- estimation
- monocular
- https
- monodepth2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces RoboDepth, a robustness evaluation suite\
  \ for monocular depth estimation (MDE) models under out-of-distribution (OoD) corruptions.\
  \ The suite comprises three benchmarks\u2014KITTI-C, NYUDepth2-C, and KITTI-S\u2014\
  featuring 18 corruption types across weather/lighting, sensor/movement, and data\
  \ processing categories."
---

# RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions

## Quick Facts
- arXiv ID: 2310.15171
- Source URL: https://arxiv.org/abs/2310.15171
- Reference count: 40
- Key outcome: RoboDepth benchmarks 42 state-of-the-art monocular depth estimation models under 18 corruption types, revealing transformer-based models as most robust and highlighting critical design considerations for OoD performance.

## Executive Summary
RoboDepth introduces a comprehensive evaluation suite for monocular depth estimation models under out-of-distribution corruptions. The framework includes three benchmarks (KITTI-C, NYUDepth2-C, KITTI-S) with 18 corruption types spanning weather/lighting, sensor/movement, and data processing categories. Through extensive benchmarking of 42 state-of-the-art models, the study reveals that many leading models exhibit significant performance degradation under typical corruptions despite strong clean data performance. Key findings include the superior robustness of transformer-based models, the benefits of high-resolution training for noise resilience, and the limitations of larger model sizes for robustness. The study establishes RoboDepth as a foundational platform for advancing robust depth estimation in safety-critical applications.

## Method Summary
RoboDepth is a benchmarking framework that evaluates monocular depth estimation models under out-of-distribution corruptions. The method involves simulating 18 corruption types across three categories on established depth estimation datasets (KITTI, NYUDepth2) to create corrupted benchmarks (KITTI-C, NYUDepth2-C, KITTI-S). The evaluation uses depth estimation error metrics (Abs Rel, δ1) combined into a unified DEE metric, along with robustness metrics (mCE for mean corruption error and mRR for mean resilience rate). The study benchmarks 42 pre-trained MDE models without additional training, analyzing performance across different corruption severities and model architectures to derive design recommendations for robust depth estimation.

## Key Results
- Transformer-based models show superior robustness to corruptions compared to CNN-based models across all benchmark datasets
- High-resolution training provides approximately 30% better noise resilience on corruption-contaminated data
- Models without ImageNet pretraining demonstrate better performance on motion blur and sensor-related corruptions
- Larger models generally show decreased robustness despite higher capacity on clean data
- RoboDepth Challenge results confirm community interest in addressing OoD depth estimation robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer-based models exhibit superior robustness to out-of-distribution corruptions compared to CNN-based models in monocular depth estimation.
- Mechanism: Transformers have global receptive fields that capture long-range spatial dependencies, allowing them to better generalize across distribution shifts caused by weather, lighting, and sensor noise.
- Core assumption: Corruption types primarily affect local pixel patterns, and models with larger receptive fields can compensate for these disruptions.
- Evidence anchors:
  - [abstract]: "Key findings include the superior robustness of transformer-based models, the benefits of high-resolution training for noise resilience, and the limitations of larger model sizes for robustness."
  - [section]: "Diving deeper, we can observe from the per-severity error rates in Fig. 9 that the above conclusion holds true for most corruption types under different severity levels."
  - [corpus]: Weak evidence - no direct corpus support for this specific mechanism.

### Mechanism 2
- Claim: Training on high-resolution images improves depth estimation model robustness against noise-contaminated corruptions.
- Mechanism: High-resolution inputs provide more fine-grained information that helps the model suppress degradation caused by Gaussian, impulse, shot, and ISO noises.
- Core assumption: Noise-contaminated corruptions primarily affect global pixel distributions rather than local spatial patterns.
- Evidence anchors:
  - [abstract]: "Key findings include the superior robustness of transformer-based models, the benefits of high-resolution training for noise resilience, and the limitations of larger model sizes for robustness."
  - [section]: "From Fig. 6 (bottom) we observe that MDE models trained with higher resolution inputs will likely yield more robust feature learning (relative 30% better) on noise-contaminated corruptions."
  - [corpus]: Weak evidence - no direct corpus support for this specific mechanism.

### Mechanism 3
- Claim: Models without ImageNet pretraining are more robust to motion blur and sensor-related corruptions.
- Mechanism: ImageNet-pretrained models become shape-biased and rely heavily on texture cues, making them vulnerable to motion blur and sensor failure that distort edges and object boundaries.
- Core assumption: Motion blur and sensor-related corruptions primarily affect shape and structural information rather than texture.
- Evidence anchors:
  - [abstract]: "We probe queries about the resilience of MDE models to real-world corruptions, the influence of training input modalities, and learning paradigms."
  - [section]: "Fig. 6 (top) highlights that MDE models pre-trained on object-centric datasets, e.g. ImageNet, are more robust against weather and lighting changes (except for 'snow') and data processing noises, which are mostly texture-shifted corruptions. Motion and sensor corruptions, however, contain more edge and object distortions and could be eased by models without ImageNet pre-training."
  - [corpus]: Weak evidence - no direct corpus support for this specific mechanism.

## Foundational Learning

- Concept: Out-of-distribution (OoD) robustness evaluation
  - Why needed here: Understanding how models perform under real-world corruptions is critical for safety-critical applications like autonomous driving.
  - Quick check question: What are the three main categories of corruptions evaluated in RoboDepth?

- Concept: Depth estimation error metrics (Abs Rel, δ1)
  - Why needed here: These metrics quantify both error rate and accuracy, providing a comprehensive evaluation of model performance.
  - Quick check question: How is the unified depth estimation error (DEE) metric calculated from Abs Rel and δ1?

- Concept: Corruption simulation and severity levels
  - Why needed here: Realistic corruption simulation is essential for creating meaningful OoD benchmarks.
  - Quick check question: How many severity levels are used for KITTI-C and NYUDepth2-C respectively?

## Architecture Onboarding

- Component map: RoboDepth consists of corruption simulation toolkit, three benchmark datasets (KITTI-C, NYUDepth2-C, KITTI-S), evaluation metrics (mCE, mRR), and benchmarking framework
- Critical path: Data preparation → Corruption simulation → Model evaluation → Robustness analysis → Design recommendations
- Design tradeoffs: High-resolution inputs improve noise robustness but increase computational cost; ImageNet pretraining helps with texture corruptions but hurts motion blur robustness
- Failure signatures: Models showing high sensitivity to specific corruption types indicate architectural limitations in handling those perturbations
- First 3 experiments:
  1. Run baseline MonoDepth2 R18 on KITTI-C and verify mCE/mRR scores match published results
  2. Test a transformer-based model (MonoViT) on KITTI-C to confirm superior robustness
  3. Evaluate a high-resolution variant of MonoDepth2 on noise corruptions to verify 30% improvement claim

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can monocular depth estimation models be designed to maintain robustness when multiple corruption types occur simultaneously, as the current RoboDepth benchmark only evaluates individual corruption types?
- Basis in paper: [explicit] The paper acknowledges that "our current framework does not accommodate scenarios wherein multiple corruptions manifest simultaneously" as a potential limitation.
- Why unresolved: The paper focuses on evaluating individual corruption types in isolation, leaving the behavior of MDE models under compound corruptions unexplored.
- What evidence would resolve it: Creating datasets that combine multiple corruption types and benchmarking MDE models on these compound corruption scenarios would reveal whether existing models maintain robustness or if new architectures are needed.

### Open Question 2
- Question: What is the optimal balance between model size and robustness in monocular depth estimation, given that larger models often show decreased robustness despite higher capacity?
- Basis in paper: [explicit] The paper observes that "MDE models with more trainable parameters are getting less robust, mainly because they are deliberately tuned towards clean distribution and thus losing generalizability."
- Why unresolved: While the paper identifies a negative correlation between model size and robustness, it doesn't establish what constitutes an optimal model size or architectural design that balances performance and robustness.
- What evidence would resolve it: Systematic experiments varying model architectures, parameter counts, and training strategies while measuring both clean performance and corruption robustness would identify the optimal trade-off.

### Open Question 3
- Question: How do continuous severity levels for corruptions compare to the discrete five-level system used in RoboDepth for evaluating depth estimation robustness?
- Basis in paper: [inferred] The paper notes that "evolving from rigidly defined five severity levels to a more nuanced, continuous scale might offer deeper insights into MDE robustness" as an unexplored avenue.
- Why unresolved: The current benchmark uses discrete severity levels, which may not capture the gradual degradation in performance that occurs with increasing corruption intensity.
- What evidence would resolve it: Implementing continuous severity scaling and comparing model performance metrics across both discrete and continuous corruption intensities would reveal whether continuous scaling provides more informative robustness evaluations.

## Limitations

- Weak corpus evidence support for proposed mechanisms, with average neighbor FMR of 0.472
- Benchmark focuses on specific corruption categories that may not capture all real-world scenarios
- Current framework evaluates individual corruption types in isolation, not compound corruption scenarios
- Assumes direct translation of architectural properties (global receptive fields, high resolution) to robustness without comprehensive empirical validation

## Confidence

- High confidence: The benchmark results showing transformer-based models outperforming CNNs on corruption robustness, as this is directly measured across multiple datasets and corruption types
- Medium confidence: The claim about high-resolution training improving noise resilience, supported by specific quantitative results (30% improvement) but lacking broader corpus validation
- Low confidence: The mechanism linking ImageNet pretraining to motion blur vulnerability, which is proposed but lacks strong empirical or corpus support

## Next Checks

1. **Cross-dataset validation**: Test the proposed mechanisms on additional datasets beyond KITTI and NYU Depth to verify if the observed patterns generalize to other environments and camera types

2. **Ablation studies on pretraining**: Conduct controlled experiments comparing models with and without ImageNet pretraining on the specific motion blur and sensor corruption types to isolate the pretraining effect from other architectural differences

3. **Real-world corruption comparison**: Collect and analyze real-world corrupted depth data from deployed systems to validate that the simulated corruptions accurately represent actual deployment scenarios and that the benchmark predictions hold in practice