---
ver: rpa2
title: 'Distilling Large Language Models for Biomedical Knowledge Extraction: A Case
  Study on Adverse Drug Events'
arxiv_id: '2307.06439'
source_url: https://arxiv.org/abs/2307.06439
tags:
- extraction
- knowledge
- distillation
- biomedical
- drug
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how large language models (LLMs) can be used
  to scale biomedical knowledge curation, focusing on adverse drug event (ADE) extraction
  as a case study. The authors find that while LLMs already have decent competency
  in structuring biomedical text, substantial gains can be attained by distilling
  them into task-specific student models through self-supervised learning.
---

# Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events

## Quick Facts
- arXiv ID: 2307.06439
- Source URL: https://arxiv.org/abs/2307.06439
- Reference count: 4
- Key outcome: GPT-3.5 distilled PubMedBERT model achieves comparable accuracy to supervised state-of-the-art models for ADE extraction without labeled data, outperforming both GPT-3.5 and GPT-4 teachers

## Executive Summary
This paper demonstrates that large language models can be effectively distilled into smaller, domain-specific models for biomedical knowledge extraction tasks. The authors focus on adverse drug event (ADE) extraction as a case study, showing that GPT-3.5 can generate self-supervised labels for unlabeled biomedical text, which are then used to train smaller PubMedBERT models. Despite being over 1,000 times smaller than GPT-3.5, the distilled model achieves comparable performance to supervised state-of-the-art methods and outperforms its teacher model by over 6 F1 points. The approach extends to other biomedical tasks including gene-disease associations and protected health information extraction.

## Method Summary
The method involves using GPT-3.5 to generate noisy self-supervised labels for unlabeled biomedical text containing drug mentions, then distilling this knowledge into smaller, domain-specific student models like PubMedBERT. The authors propose a drug-centric neural architecture that processes each drug entity once, concatenating its pooled representation to every token's embedding before classification. This converts the traditional two-task approach (named entity recognition and relation extraction) into a single unified task, reducing computational complexity from O(NM) to O(M) while improving accuracy. The distilled PubMedBERT model is fine-tuned using the GPT-3.5 generated labels without requiring any human-annotated training data.

## Key Results
- GPT-3.5 distilled PubMedBERT achieves comparable accuracy to supervised state-of-the-art models for ADE extraction without using labeled data
- Despite being 1,000x smaller, the distilled model outperforms GPT-3.5 by over 6 F1 points and GPT-4 by over 5 F1 points
- The drug-centric architecture improves computational efficiency by reducing complexity from O(NM) to O(M)
- Similar distillation gains observed for other biomedical tasks: gene-disease associations, protected health information, and MedNLI

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM distillation outperforms raw LLM performance in biomedical knowledge extraction tasks
- Mechanism: GPT-3.5 generates noisy self-supervised labels for unlabeled biomedical text, which are then used to train smaller, domain-specific student models that generalize better than the original teacher LLM
- Core assumption: GPT-3.5's language understanding is sufficient to generate useful, if imperfect, labels for downstream tasks, and the student model can learn robust patterns from these noisy annotations
- Evidence anchors: "by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs" and "with distillation and without required any labeled data, this gap can be substantially reduced"

### Mechanism 2
- Claim: The proposed drug-centric neural architecture reduces computational complexity and improves accuracy for joint ADE NER and relation extraction
- Mechanism: Instead of enumerating all pairwise drug-ADE combinations (O(NM)), the model processes each drug entity once, concatenating its pooled representation to every token's embedding before classification
- Core assumption: Drug information can be meaningfully summarized by pooling across all its token embeddings, and this representation is sufficient to condition the prediction of ADE spans for that drug
- Evidence anchors: "The proposed architecture substantially simplifies the problem, converting the original two tasks (NER and RE) into a single, unified task... enabling our end-to-end model to perform more efficiently and accurately"

### Mechanism 3
- Claim: Domain-specific pretraining (PubMedBERT) combined with LLM distillation yields better performance than generic LLMs alone
- Mechanism: PubMedBERT's biomedical vocabulary and pretraining corpus provide a strong inductive bias, which is then fine-tuned using GPT-3.5's self-supervised labels, resulting in a model that is both domain-adapted and task-specialized
- Core assumption: The combination of domain pretraining and task-specific distillation is more effective than either alone, because the former captures biomedical semantics and the latter captures task structure
- Evidence anchors: "A GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data" and "Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over six absolute points in F1"

## Foundational Learning

- Concept: Self-supervised learning via knowledge distillation
  - Why needed here: Labeled biomedical data is scarce and expensive, but LLMs can generate large-scale noisy labels cheaply; distillation leverages these labels to train smaller, more efficient models
  - Quick check question: What is the role of the teacher model in distillation, and why is GPT-3.5 chosen as the teacher rather than a smaller model?

- Concept: Named Entity Recognition (NER) and Relation Extraction (RE) in biomedical text
  - Why needed here: ADE extraction requires identifying drug and adverse event entities (NER) and linking them causally (RE); understanding these subtasks is critical for designing and evaluating the unified architecture
  - Quick check question: How does the paper's drug-centric architecture differ from traditional pairwise enumeration in joint NER-RE?

- Concept: Evaluation metrics for information extraction (lenient vs. strict F1)
  - Why needed here: ADE annotation boundaries are inconsistent, so lenient F1 (partial matches count) is more appropriate; strict F1 is used for cross-validation to match prior work
  - Quick check question: Why might lenient F1 be more suitable than strict F1 for evaluating ADE extraction on this dataset?

## Architecture Onboarding

- Component map: Input biomedical text sentences with drug mentions -> PubMedBERT encoder producing token embeddings -> Drug representation through mean-pooled embeddings of drug mention tokens -> Concatenation of drug representation to each token embedding -> Linear layer + sigmoid for binary token classification (ADE vs. non-ADE) -> Predicted ADE spans for each drug entity

- Critical path: 1. Tokenize input and run through encoder 2. Identify drug entities and pool their embeddings 3. Augment token embeddings with drug representation 4. Apply classifier and threshold predictions 5. Map predictions back to original text spans

- Design tradeoffs: PubMedBERT vs. BioGPT (BERT-based models better at structured extraction; GPT-based models excel at generation), Drug pooling vs. per-token drug encoding (pooling is efficient but may lose fine-grained drug information), Lenient vs. strict evaluation (lenient is more forgiving of boundary inconsistencies; strict is stricter but may underrepresent true performance)

- Failure signatures: Low precision (model predicts too many spurious ADE mentions; check if drug representation is too generic or if classifier threshold is too low), Low recall (model misses ADEs; check if drug pooling loses key contextual cues or if self-supervised labels are too noisy), High variance across folds (dataset may have annotation inconsistencies; consider cross-validation with lenient F1)

- First 3 experiments: 1. Ablation: train without drug augmentation (plain NER) and compare F1 to full model; this isolates the benefit of the drug-centric architecture 2. Distillation source: replace GPT-3.5 with GPT-4 as teacher and measure change in distilled PubMedBERT performance; tests sensitivity to teacher quality 3. Architecture swap: replace PubMedBERT with BioGPT in the same distillation pipeline; isolates the effect of encoder choice

## Open Questions the Paper Calls Out

- Question: How does GPT-4 distillation compare to GPT-3.5 distillation for biomedical knowledge extraction?
- Basis in paper: The paper mentions that GPT-4 was released after the study and not used for distillation, but that GPT-4 slightly outperformed GPT-3.5 in few-shot settings
- Why unresolved: The authors did not have time to conduct distillation experiments with GPT-4 before publication
- What evidence would resolve it: Running the same distillation experiments with GPT-4 as the teacher model and comparing the performance to the GPT-3.5 distilled models

- Question: How would using a larger unlabeled dataset (e.g., from PubMed) impact distillation performance for tasks like gene-disease associations and protected health information?
- Basis in paper: The paper notes that for tasks other than ADE extraction, they only used the training corpus text for distillation and did not fully explore the potential due to small corpus size
- Why unresolved: Limited data restricts the effectiveness of the distillation process
- What evidence would resolve it: Running distillation experiments using a much larger unlabeled corpus like PubMed and comparing performance to models distilled from smaller corpora

- Question: How do different biomedical-specific pretrained models (e.g., BioBERT, ClinicalBERT) compare to PubMedBERT when distilled from LLMs?
- Basis in paper: The paper conducts an ablation study comparing PubMedBERT and BioGPT for distillation but notes other models like BioBERT and ClinicalBERT exist
- Why unresolved: The study did not test all available biomedical pretrained models
- What evidence would resolve it: Running distillation experiments using different biomedical pretrained models (e.g., BioBERT, ClinicalBERT) and comparing their performance to PubMedBERT

## Limitations

- The self-supervised distillation approach depends heavily on GPT-3.5's annotation quality, which is not independently verified against human annotations
- The substantial performance gains may reflect architectural improvements specific to the drug-centric design rather than distillation per se
- The study focuses on a single biomedical task (ADE extraction) and three other tasks without providing comprehensive error analysis or ablation studies on the quality of self-supervised labels

## Confidence

**High confidence**: The observation that PubMedBERT distilled from GPT-3.5 achieves comparable performance to supervised state-of-the-art models without labeled data is well-supported by the experimental results. The finding that the distilled model outperforms its teacher (GPT-3.5) by 6+ F1 points is directly measurable and clearly demonstrated.

**Medium confidence**: The claim that the drug-centric architecture improves accuracy by reducing computational complexity from O(NM) to O(M) is plausible given the design, but the paper doesn't provide direct computational complexity measurements or runtime comparisons. The superiority of PubMedBERT over BioGPT for this task is demonstrated but may be architecture-specific rather than a general finding about BERT vs. GPT models.

**Low confidence**: The assertion that similar distillation gains apply to gene-disease associations and PHI extraction tasks is extrapolated from limited experiments. The paper doesn't provide detailed analysis of whether the self-supervised approach generalizes across different biomedical knowledge extraction tasks or whether performance gains are consistent across domains.

## Next Checks

1. **Independent quality assessment of self-supervised labels**: Sample 100 GPT-3.5 generated annotations and have them annotated by two independent human annotators. Calculate inter-annotator agreement and compare against GPT-3.5's consistency to quantify the noise level in the distillation training data.

2. **Teacher model sensitivity analysis**: Replicate the distillation experiment using GPT-4 as the teacher model instead of GPT-3.5, keeping all other components (PubMedBERT, architecture, hyperparameters) constant. This isolates the effect of teacher model quality on distilled student performance.

3. **Architecture ablation with ground truth labels**: Train the same PubMedBERT architecture using ground truth annotations from the original dataset rather than GPT-3.5 generated labels. Compare performance to the self-supervised approach to determine whether gains come from distillation or from the architectural improvements alone.