---
ver: rpa2
title: Robust Domain Misinformation Detection via Multi-modal Feature Alignment
arxiv_id: '2311.14315'
source_url: https://arxiv.org/abs/2311.14315
tags:
- domain
- detection
- alignment
- target
- misinformation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of multi-modal misinformation detection
  on social media, where misinformation often spreads quickly and appears more credible
  when accompanied by images. Existing supervised methods struggle with domain shifts
  and require large amounts of labeled data across events, making them impractical
  for real-time applications.
---

# Robust Domain Misinformation Detection via Multi-modal Feature Alignment

## Quick Facts
- arXiv ID: 2311.14315
- Source URL: https://arxiv.org/abs/2311.14315
- Reference count: 40
- Multi-modal misinformation detection framework achieving >1% accuracy improvement over baselines

## Executive Summary
This paper addresses the challenge of detecting misinformation in social media posts that contain both text and images, particularly when these posts come from different domains or events. The proposed method, RDCM, tackles the problem of domain shifts by aligning both the joint distributions of text and image features across domains and bridging the semantic gap between modalities using contrastive learning. The framework is designed to work in both scenarios where target domain data is unavailable (domain generalization) and where it is available but unlabeled (domain adaptation).

## Method Summary
The method extracts text features using TextCNN with RoBERTa embeddings and image features using ResNet50. It then aligns the joint distributions of these features across source domains using kernel mean embedding-based Maximum Mean Discrepancy (MMD) to reduce domain shift. A cross-modality alignment module uses contrastive learning with a custom sampling strategy to bridge the semantic gap between text and images. The framework handles both domain generalization (target data unavailable) and domain adaptation (unlabeled target data available) scenarios, combining these losses with classification loss for binary misinformation detection.

## Key Results
- Achieves state-of-the-art results on Pheme and Twitter datasets with over 1% accuracy improvement
- Demonstrates effectiveness in handling cross-dataset scenarios and robustness against domain shifts
- Shows that joint distribution alignment performs better than aligning modalities separately
- Validated through leave-one-domain-out experiments showing consistent performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning joint distributions of text and image modalities across domains reduces domain shift more effectively than aligning each modality separately.
- Mechanism: The method uses kernel mean embedding in reproducing kernel Hilbert space (RKHS) to measure and minimize Maximum Mean Discrepancy (MMD) between joint distributions of text and image features across source domains.
- Core assumption: The joint distribution of text and image features captures cross-modal correlations that are important for misinformation detection and domain invariance.
- Evidence anchors:
  - [abstract]: "It reduces the domain shift by aligning the joint distribution of textual and visual modalities through an inter-domain alignment module"
  - [section]: "We propose to align the joint feature distribution upon textual and visual modalities where the kernel mean embedding can be formulated through the covariance operator âŠ— on RKHS"
  - [corpus]: Weak evidence - no directly relevant papers found in corpus
- Break condition: If the cross-modal correlations captured by joint distribution alignment do not generalize across domains, or if the computational cost of joint distribution alignment outweighs the benefits.

### Mechanism 2
- Claim: Cross-modality alignment using contrastive learning with a novel sampling strategy bridges the semantic gap between text and image modalities.
- Mechanism: The method employs a contrastive loss that pulls together semantically similar text-image pairs (real news) and pushes apart dissimilar pairs, using a custom weighting function to filter out negative samples with high visual similarity.
- Core assumption: In misinformation detection, cross-modal correspondence or similarity is more likely to exist in real news rather than fake news, and semantic similarity on the visual modality can be used to identify inappropriate negative samples.
- Evidence anchors:
  - [abstract]: "bridges the semantic gap between both modalities through a cross-modality alignment module using contrastive learning with a novel sampling strategy tailored for misinformation detection"
  - [section]: "The cross-modality alignment module exploits contrastive learning to bridge the modality gap with a novel sampling strategy tailored for multi-modal misinformation detection"
  - [corpus]: Weak evidence - no directly relevant papers found in corpus
- Break condition: If the assumption about cross-modal correspondence in real vs. fake news does not hold for the target domain, or if the weighting function fails to effectively filter inappropriate negative samples.

### Mechanism 3
- Claim: The unified framework handles both domain generalization (DG) and domain adaptation (DA) scenarios, making it applicable to real-time and offline misinformation detection.
- Mechanism: The framework aligns distributions among multiple source domains for DG and between each source and the target domain for DA, while always performing cross-modal alignment.
- Core assumption: The target domain data may not be readily available in early stages of misinformation dissemination, but when available, it can be leveraged to improve detection performance.
- Evidence anchors:
  - [abstract]: "We also propose a framework that simultaneously considers application scenarios of domain generalization (in which the target domain data is unavailable) and domain adaptation (in which unlabeled target domain data is available)"
  - [section]: "The unified framework can be applied to two application scenarios: 1) real-time misinformation detection (i.e., when target domain data are not accessible during training, corresponding to domain generalization); and 2) offline misinformation detection (i.e., when unlabeled target domain data are available during training, which corresponds to domain adaptation)"
  - [corpus]: Weak evidence - no directly relevant papers found in corpus
- Break condition: If the distinction between DG and DA scenarios is not relevant for the target application, or if the framework's complexity outweighs the benefits of handling both scenarios.

## Foundational Learning

- Concept: Maximum Mean Discrepancy (MMD) and kernel mean embedding
  - Why needed here: MMD is used to measure and minimize the domain shift by aligning the joint distribution of text and image features across domains
  - Quick check question: How does MMD in RKHS space measure the difference between two probability distributions without requiring density estimation?

- Concept: Contrastive learning and custom sampling strategies
  - Why needed here: Contrastive learning with a novel sampling strategy is used to bridge the semantic gap between text and image modalities by pulling together similar pairs and pushing apart dissimilar pairs
  - Quick check question: How does the custom weighting function in the sampling strategy identify and filter out inappropriate negative samples based on visual similarity?

- Concept: Domain generalization vs. domain adaptation
  - Why needed here: Understanding the difference between DG and DA scenarios is crucial for applying the unified framework to both real-time and offline misinformation detection
  - Quick check question: What are the key differences between DG and DA in terms of data availability and alignment objectives?

## Architecture Onboarding

- Component map:
  TextCNN + ResNet50 encoders -> Inter-domain alignment (joint MMD) -> Cross-modality alignment (contrastive learning) -> Binary classification

- Critical path:
  1. Extract text features using TextCNN with RoBERTa embeddings; image features using ResNet50
  2. Align joint distributions of text and image features across source domains (DG) or source+target (DA)
  3. Bridge semantic gap between text and image modalities using contrastive learning with custom sampling
  4. Concatenate aligned features and perform binary classification for misinformation detection

- Design tradeoffs:
  - Joint distribution alignment vs. marginal distribution alignment: Joint alignment captures cross-modal correlations but is more computationally expensive
  - Custom sampling strategy vs. random sampling: Custom strategy filters inappropriate negative samples but requires careful tuning of the similarity threshold
  - Handling both DG and DA scenarios: Provides flexibility but increases framework complexity

- Failure signatures:
  - Poor performance on target domain: May indicate insufficient domain alignment or failure of cross-modal alignment
  - High computational cost: May indicate inefficiency in joint distribution alignment or contrastive learning
  - Overfitting to source domains: May indicate insufficient regularization or inappropriate sampling strategy

- First 3 experiments:
  1. Ablation study: Remove inter-domain alignment module and evaluate performance drop to assess its importance
  2. Ablation study: Remove cross-modality alignment module and evaluate performance drop to assess its importance
  3. Sensitivity analysis: Vary the similarity threshold in the custom sampling strategy and observe its impact on detection performance

## Open Questions the Paper Calls Out
The paper suggests extending the framework to handle multiple images and long-paragraph texts, exploring various multi-modality scenarios containing video and audio information, and investigating the limitations of MMD for joint distribution alignment in high-dimensional multi-modal data.

## Limitations
- Effectiveness depends on cross-modal correlations generalizing across domains, which may not hold for all misinformation types
- Custom sampling strategy requires careful tuning of similarity threshold with no sensitivity analysis provided
- Computational cost of joint distribution alignment may limit scalability to larger datasets or more complex modalities

## Confidence
- High: The framework's ability to handle both domain generalization and adaptation scenarios is well-supported by the unified architecture and evaluation setup
- Medium: The improvement over baselines (1%+ accuracy gain) is promising but needs validation on additional datasets and misinformation types to confirm generalizability
- Low: The paper lacks ablation studies on the inter-domain alignment module, making it difficult to isolate its contribution to overall performance

## Next Checks
1. Perform ablation study removing the inter-domain alignment module to quantify its contribution to performance gains
2. Test the framework on a third dataset with different misinformation characteristics to assess domain generalization beyond Pheme and Twitter
3. Analyze the computational overhead of joint distribution alignment compared to marginal distribution alignment in terms of training time and memory usage