---
ver: rpa2
title: 'Identifying contributors to supply chain outcomes in a multi-echelon setting:
  a decentralised approach'
arxiv_id: '2307.12157'
source_url: https://arxiv.org/abs/2307.12157
tags:
- data
- process
- decentralised
- uncertainty
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of identifying contributors to
  supply chain outcomes in multi-echelon settings where data privacy prevents centralised
  data sharing. The authors propose a decentralised approach using explainable artificial
  intelligence (XAI) and neural network ensemble uncertainty estimation to compute
  estimated contributions without requiring supply chain actors to share their data.
---

# Identifying contributors to supply chain outcomes in a multi-echelon setting: a decentralised approach

## Quick Facts
- arXiv ID: 2307.12157
- Source URL: https://arxiv.org/abs/2307.12157
- Reference count: 0
- Key outcome: The paper proposes a decentralized approach using neural network ensemble uncertainty estimation to identify supply chain contributors without data sharing, achieving comparable results to centralized SHAP methods while preserving privacy.

## Executive Summary
This paper addresses the challenge of identifying contributors to supply chain outcomes in multi-echelon settings where data privacy prevents centralized data sharing. The authors propose a decentralized approach using explainable artificial intelligence (XAI) and neural network ensemble uncertainty estimation to compute estimated contributions without requiring supply chain actors to share their data. The method involves sending a metric of interest to supply chain actors, who perform local uncertainty computations and return only a single uncertainty value. Results demonstrate that this decentralized approach achieves comparable results to centralized SHAP methods in detecting sources of quality variations while preserving data privacy.

## Method Summary
The authors propose a framework using Explainable Artificial Intelligence (XAI) and neural network ensemble uncertainty to estimate contributions to a metric of interest in a decentralized manner. The approach involves sending a metric of interest to supply chain actors, who perform local uncertainty computations and return only a single uncertainty value. The method uses an ensemble of neural networks to estimate the uncertainty of a prediction instead of Bayesian neural networks, minimizing negative log-likelihood during training to include the optimization of uncertainty estimation. The authors evaluate their approach using multi-stage production data from Mul that was captured at a production line in Detroit.

## Key Results
- The decentralized approach achieves comparable results to centralized SHAP methods in detecting sources of quality variations
- The method preserves data privacy by only sharing single aggregated uncertainty values per actor
- Multicollinearity is identified as a limitation when features from different companies are correlated

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural network ensemble uncertainty estimation can approximate Bayesian uncertainty without requiring complex Bayesian inference, enabling decentralized computation of feature contributions.
- Mechanism: Multiple neural networks with randomly initialized weights estimate both the mean prediction and log-variance for each input. The total uncertainty is computed using the law of total variation, separating epistemic (model) and aleatoric (data) uncertainty. This total uncertainty is then used as a proxy for feature contribution, where lower uncertainty implies higher influence on the target metric.
- Core assumption: The ensemble uncertainty calculation accurately reflects feature importance in a way that is comparable to centralized SHAP values.
- Evidence anchors:
  - [abstract] "We propose the use of explainable artificial intelligence for decentralised computing of estimated contributions to a metric of interest in a multi-stage production process."
  - [section] "Lakshminarayanan et al. ((2017)) therefore designed a neural network ensemble approach that is easier to train and achieves similar performance to Bayesian neural networks."
- Break condition: If feature correlations (multicollinearity) are high between companies, the uncertainty-based ranking may misrepresent true contributions.

### Mechanism 2
- Claim: Decentralizing the computation preserves data privacy by only sharing a single aggregated uncertainty value per actor, not raw feature data.
- Mechanism: Each supply chain actor receives the target metric and performs local uncertainty computation using their own process features. Only the final uncertainty value is returned, preventing raw data exposure. The central coordinator aggregates these values to rank contributors.
- Core assumption: A single uncertainty value per actor is sufficient to capture their contribution without revealing internal process details.
- Evidence anchors:
  - [abstract] "This approach mitigates the need to convince supply chain actors to share data, as all computations occur in a decentralised manner."
- Break condition: If actors collude or if the uncertainty metric leaks information about the underlying data distribution.

### Mechanism 3
- Claim: Adding a pure noise baseline allows the system to distinguish between actors with real influence and those with negligible contribution.
- Mechanism: One ensemble is trained on random noise to establish a baseline uncertainty. This baseline is compared against actor uncertainties to normalize and rank contributions, ensuring actors with no real influence are identified.
- Core assumption: The noise baseline uncertainty will be consistently higher than any actor with actual informative features.
- Evidence anchors:
  - [section] "To determine which ensembles actually contain information beyond noise, we also fit one set of ensembles to random noise as shown in Fig. 4."
- Break condition: If the noise baseline is not properly calibrated, it may incorrectly rank some actors as non-contributors.

## Foundational Learning

- Concept: Neural network ensemble uncertainty estimation
  - Why needed here: Provides a scalable, decentralized alternative to Bayesian methods for estimating feature contributions without requiring centralized data.
  - Quick check question: How does the negative log-likelihood loss function in ensemble training differ from standard regression loss?

- Concept: Shapley values and SHAP
  - Why needed here: Serves as the centralized benchmark for evaluating the effectiveness of the decentralized uncertainty-based approach.
  - Quick check question: What is the key theoretical foundation of SHAP values that makes them suitable for feature contribution estimation?

- Concept: Multicollinearity and its impact on feature importance
  - Why needed here: Explains why downstream actors (e.g., OEM) may appear more influential than they truly are due to correlated upstream features.
  - Quick check question: How does high multicollinearity between features from different companies affect the interpretation of contribution rankings?

## Architecture Onboarding

- Component map: Metric sender (central coordinator) -> Actor nodes (supply chain participants) -> Neural ensemble trainer (per actor) -> Uncertainty aggregator (central coordinator) -> Baseline noise generator

- Critical path:
  1. Central coordinator sends metric and identifiers to actors
  2. Each actor trains local ensemble and computes total uncertainty
  3. Actors return only uncertainty values
  4. Central coordinator adds noise baseline and ranks contributions

- Design tradeoffs:
  - Privacy vs. accuracy: More noise for privacy reduces accuracy
  - Centralization vs. decentralization: Centralized SHAP is more accurate but requires data sharing
  - Complexity vs. scalability: Ensemble method is more complex but scales better across companies

- Failure signatures:
  - High variance in uncertainty rankings across runs (indicates instability)
  - Noise baseline uncertainty similar to actor uncertainties (indicates poor discrimination)
  - Multicollinearity causing inflated downstream actor rankings

- First 3 experiments:
  1. Run the decentralized method on a synthetic dataset with known feature contributions and compare rankings to ground truth
  2. Test sensitivity by varying the number of ensembles and dropout rate
  3. Introduce controlled multicollinearity and observe impact on downstream actor rankings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed decentralised approach perform compared to centralised SHAP in terms of accuracy and runtime efficiency when applied to larger and more complex supply chain networks?
- Basis in paper: [explicit] The paper demonstrates the effectiveness of the decentralised approach compared to SHAP using a real multi-stage manufacturing process data, but does not explore larger and more complex networks.
- Why unresolved: The paper only uses a single case study and does not evaluate the scalability of the decentralised approach to larger and more complex supply chain networks.
- What evidence would resolve it: Empirical results showing the performance of the decentralised approach compared to SHAP on larger and more complex supply chain networks.

### Open Question 2
- Question: How does the proposed decentralised approach handle multicollinearity between features in different companies, and what are the implications for the accuracy of the contribution estimation?
- Basis in paper: [explicit] The paper identifies multicollinearity as a limitation when features from different companies are correlated, and suggests that companies further downstream in the supply chain are more prone to have inflated influence estimations.
- Why unresolved: The paper does not provide a solution to handle multicollinearity, and the implications for the accuracy of the contribution estimation are not explored.
- What evidence would resolve it: Empirical results showing the impact of multicollinearity on the accuracy of the contribution estimation, and a proposed solution to handle multicollinearity.

### Open Question 3
- Question: How can the proposed decentralised approach be extended to handle non-linear relationships between features and the target variable, and what are the implications for the accuracy of the contribution estimation?
- Basis in paper: [inferred] The paper uses neural network ensemble uncertainty estimation, which can handle non-linear relationships, but does not explicitly explore this aspect.
- Why unresolved: The paper does not provide a comprehensive evaluation of the performance of the decentralised approach in handling non-linear relationships.
- What evidence would resolve it: Empirical results showing the performance of the decentralised approach in handling non-linear relationships compared to SHAP, and a proposed extension to handle non-linear relationships.

## Limitations
- The approach's effectiveness depends heavily on the assumption that neural ensemble uncertainty accurately reflects feature importance comparable to SHAP values
- The paper lacks detailed implementation specifications for the neural network architecture, making faithful reproduction difficult
- The performance impact of multicollinearity between features from different companies is identified but not thoroughly quantified

## Confidence
- High confidence in the privacy preservation mechanism (single uncertainty value sharing)
- Medium confidence in the technical feasibility of ensemble uncertainty estimation
- Low confidence in generalizability across different supply chain configurations due to limited empirical validation

## Next Checks
1. Test the decentralized method on synthetic datasets with known ground truth feature contributions to verify ranking accuracy
2. Systematically vary ensemble hyperparameters (number of networks, dropout rate) to assess stability and sensitivity
3. Introduce controlled multicollinearity scenarios to quantify the impact on downstream actor ranking inflation