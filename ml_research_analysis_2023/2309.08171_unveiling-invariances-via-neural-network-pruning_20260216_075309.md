---
ver: rpa2
title: Unveiling Invariances via Neural Network Pruning
arxiv_id: '2309.08171'
source_url: https://arxiv.org/abs/2309.08171
tags:
- learning
- neural
- pruning
- tabular
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method for automatically discovering network
  architectures that preserve data-dependent invariances through pruning. The approach,
  called IUNET, combines one-shot magnitude pruning with an invariance learning objective
  and a proactive initialization scheme to alleviate the lazy training problem.
---

# Unveiling Invariances via Neural Network Pruning

## Quick Facts
- arXiv ID: 2309.08171
- Source URL: https://arxiv.org/abs/2309.08171
- Authors: 
- Reference count: 24
- Key outcome: This paper proposes a method for automatically discovering network architectures that preserve data-dependent invariances through pruning. The approach, called IUNET, combines one-shot magnitude pruning with an invariance learning objective and a proactive initialization scheme to alleviate the lazy training problem. IUNET consistently outperforms dense neural networks on both vision and tabular datasets, improving both efficiency and effectiveness. On vision datasets, IUNET bridges the gap between MLPs and CNNs and reliably boosts ResNet performance. On tabular datasets, IUNET outperforms handcrafted architectures and is competitive with heavily regularized MLPs, despite not requiring costly hyperparameter tuning.

## Executive Summary
This paper addresses the challenge of discovering network architectures that preserve data-dependent invariances through pruning. The proposed method, IUNET, combines one-shot magnitude pruning with an invariance learning objective and a proactive initialization scheme to alleviate the lazy training problem. IUNET consistently outperforms dense neural networks on both vision and tabular datasets, improving both efficiency and effectiveness. The framework is particularly effective at discovering MLP architectures with desirable invariances that perform comparably to CNNs.

## Method Summary
IUNET is a pruning framework that discovers invariance-preserving subnetworks from deep and dense supernetworks. The method consists of three key components: (1) Proactive Initialization Scheme (PI S) which scales initial weights by a small multiplier κ to prevent the lazy training regime, (2) Invariance Learning Objective (ILO) which combines contrastive learning with supervised learning to capture useful invariances, and (3) One-shot Magnitude Pruning (OMP) which prunes weights based on magnitude after training. The supernetwork is first trained with ILO and PI S, then pruned to create a subnetwork architecture. This subnetwork is reinitialized using lottery ticket reinitialization and finetuned with the supervised loss.

## Key Results
- IUNET consistently outperforms dense neural networks on both vision (CIFAR10, CIFAR100, SVHN) and tabular datasets
- On vision datasets, IUNET bridges the gap between MLPs and CNNs and reliably boosts ResNet performance
- On tabular datasets, IUNET outperforms handcrafted architectures and is competitive with heavily regularized MLPs
- The method requires no costly hyperparameter tuning compared to existing approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The proactive initialization scheme (PI S) effectively alleviates the lazy training regime problem by ensuring structurally important weights grow in magnitude during training.
- Mechanism: PI S initializes weights with a small multiplier κ, forcing only weights that contribute to performance improvement to grow in magnitude during training. This creates a coupling between weight importance and magnitude, preventing the lazy training regime where performance improves but weights remain static.
- Core assumption: The lazy training regime decouples weight magnitude from importance, causing pruning to incorrectly remove weights critical for performance.
- Evidence anchors:
  - [abstract]: "We address this with a proactive initialization scheme (PI S), which prevents important weights from being accidentally pruned by assigning low magnitudes to majority of weights."
  - [section]: "We propose a simple solution by scaling the weight initialization by a small multiplier,κ. We find this alleviates the aforementioned issue by forcing the model to assign large values only to important weights prior to lazy training."
  - [corpus]: Weak - no direct citations found about lazy training regime in pruning context
- Break condition: If the lazy training regime is not the primary bottleneck for pruning performance, or if the initial scaling factor κ is not appropriately tuned for the specific architecture.

### Mechanism 2
- Claim: The invariance learning objective (ILO) successfully combines contrastive learning with network pruning by regularizing it with the supervised objective.
- Mechanism: ILO combines the supervised maximum likelihood loss with a contrastive loss that enforces invariance under specified transformations. This prevents the contrastive loss from overfitting and ensures that weights critical for both invariance and supervised learning are preserved during pruning.
- Core assumption: Contrastive learning alone overfits during training, causing critical weights for supervised learning to be pruned away.
- Evidence anchors:
  - [abstract]: "To capture useful invariances, we propose a novel invariance learning objective (ILO), that successfully combines CL with network pruning by regularizing CL with the supervised objective."
  - [section]: "With just LN CE, the supernetwork will overfit the contrastive objective... With just LSU P, the architecture is not explicitly optimized to capture desired invariances."
  - [corpus]: Weak - no direct citations found about contrastive learning failure with pruning
- Break condition: If the supervised loss component is not properly weighted (λ parameter), or if the contrastive objective does not align with the desired invariances for the specific dataset.

### Mechanism 3
- Claim: One-shot magnitude-based pruning (OMP) on the trained supernetwork discovers subnetworks with better inductive biases than the original architecture.
- Mechanism: After training the supernetwork with ILO and PI S, OMP removes weights with smallest magnitudes. The resulting subnetwork, when reinitialized and finetuned, achieves better performance than the original supernetwork because it has learned to preserve desirable invariances.
- Core assumption: The supernetwork architecture has sufficient capacity to capture the desired invariances, and pruning can identify and preserve the relevant weight connections.
- Evidence anchors:
  - [abstract]: "We propose Invariance Unveiling Neural Networks, IUN ET, a pruning framework that discovers invariance-preserving subnetworks from deep and dense supernetworks."
  - [section]: "We construct our new untrained subnetwork, f P (·, θ(0) P ), from the trained supernetwork, f M(·, θ(T) M ), where the subnetwork contains a fraction of the supernetwork's weights"
  - [corpus]: Weak - no direct citations found about one-shot pruning discovering better architectures
- Break condition: If the supernetwork is underparameterized and cannot capture the desired invariances, or if the pruning ratio is too aggressive and removes critical connections.

## Foundational Learning

- Concept: Contrastive Learning
  - Why needed here: Contrastive learning is used in ILO to enforce invariance by maximizing similarity between representations of transformed inputs while minimizing similarity between different inputs
  - Quick check question: How does the contrastive loss component in ILO differ from standard self-supervised contrastive learning approaches?

- Concept: Lazy Training Regime
  - Why needed here: Understanding the lazy training regime is crucial because it explains why pruning fails in deep networks when weights don't grow in magnitude despite performance improvements
  - Quick check question: What is the key characteristic of the lazy training regime that makes it problematic for network pruning?

- Concept: Neural Network Pruning
  - Why needed here: Pruning is the core mechanism for discovering new architectures from the supernetwork, and understanding different pruning strategies (one-shot vs iterative) is essential for implementation
  - Quick check question: What is the fundamental difference between one-shot magnitude pruning and iterative pruning approaches?

## Architecture Onboarding

- Component map:
  - Supernetwork (f M) -> Proactive Initialization Scheme (PI S) -> Invariance Learning Objective (ILO) -> One-shot Magnitude Pruning (OMP) -> Subnetwork (f P)

- Critical path:
  1. Initialize supernetwork with PI S (κ scaling)
  2. Train supernetwork with ILO (LSU P + λLN CE)
  3. Apply OMP to obtain subnetwork architecture
  4. Reinitialize subnetwork weights (lottery ticket reinitialization)
  5. Finetune subnetwork with supervised loss

- Design tradeoffs:
  - κ scaling vs normal initialization: Tradeoff between unpruned performance and pruning effectiveness
  - λ weight in ILO: Tradeoff between invariance preservation and supervised accuracy
  - Pruning ratio: Tradeoff between compression and performance

- Failure signatures:
  - If κ is too small: Weights may remain too small throughout training, preventing effective learning
  - If λ is too large: Model may overfit to invariance objective and underperform on supervised task
  - If pruning ratio is too high: Important connections may be removed, leading to performance degradation

- First 3 experiments:
  1. Implement basic IUN ET on a simple vision dataset (CIFAR-10) with MLP supernetwork, using default hyperparameters (κ=1.0, λ=1.0, pruning ratio=8x)
  2. Compare performance with and without PI S to verify lazy training alleviation
  3. Compare performance with and without ILO to verify invariance learning contribution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the IUNET framework be extended to handle non-classification tasks such as regression or generative modeling?
- Basis in paper: [explicit] The paper focuses solely on classification tasks and does not explore the applicability of IUNET to other task types.
- Why unresolved: The paper does not provide any insights or experiments related to non-classification tasks.
- What evidence would resolve it: Experiments demonstrating the effectiveness of IUNET on regression or generative modeling tasks, along with a discussion of any modifications required to adapt the framework.

### Open Question 2
- Question: Can the IUNET framework be combined with other network pruning methods, such as structured pruning or filter pruning, to further improve efficiency and effectiveness?
- Basis in paper: [inferred] The paper primarily focuses on magnitude-based pruning and does not explore other pruning methods.
- Why unresolved: The paper does not investigate the potential benefits of combining IUNET with other pruning techniques.
- What evidence would resolve it: Experiments comparing the performance of IUNET with and without additional pruning methods, along with an analysis of the trade-offs involved.

### Open Question 3
- Question: How does the choice of invariant transformations impact the performance of IUNET on different datasets and tasks?
- Basis in paper: [explicit] The paper uses different sets of invariant transformations for vision and tabular datasets, but does not explore the impact of alternative transformations.
- Why unresolved: The paper does not provide a systematic analysis of the relationship between invariant transformations and IUNET performance.
- What evidence would resolve it: Experiments evaluating the performance of IUNET with different sets of invariant transformations on various datasets, along with a discussion of the insights gained.

## Limitations

- The paper's core claims about alleviating the lazy training regime and successfully combining contrastive learning with pruning are supported primarily by empirical results rather than theoretical guarantees
- The exact formulation of the contrastive learning component remains underspecified, making faithful reproduction challenging
- The method's sensitivity to hyperparameters like κ and λ is not thoroughly explored across diverse datasets

## Confidence

- High confidence in the empirical performance claims across vision and tabular datasets
- Medium confidence in the theoretical mechanism explanations, particularly regarding lazy training regime alleviation
- Low confidence in the generalizability of results to extremely large-scale problems and complex invariances beyond the tested transformation sets

## Next Checks

1. Conduct ablation studies varying κ across multiple orders of magnitude to identify the optimal scaling regime and test the sensitivity of lazy training alleviation to initialization scale
2. Implement and test the IUNET framework on a larger-scale vision dataset (e.g., ImageNet) to evaluate scalability and performance on more complex invariances
3. Perform a detailed analysis of the learned subnetwork architectures to verify that the pruning process is indeed preserving the desired invariances rather than just removing redundant weights through systematic visualization and interpretation of the pruned weight patterns