---
ver: rpa2
title: Towards guarantees for parameter isolation in continual learning
arxiv_id: '2310.01165'
source_url: https://arxiv.org/abs/2310.01165
tags:
- learning
- forgetting
- task
- network
- hessian
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a unified theoretical framework for understanding
  parameter isolation methods in continual learning, based on the geometry of loss
  landscapes. The authors approximate task losses around their minima and derive a
  constraint on parameter updates to prevent catastrophic forgetting.
---

# Towards guarantees for parameter isolation in continual learning

## Quick Facts
- arXiv ID: 2310.01165
- Source URL: https://arxiv.org/abs/2310.01165
- Reference count: 40
- Key outcome: Presents a unified theoretical framework for parameter isolation methods in continual learning, proving theoretical guarantees for preventing catastrophic forgetting.

## Executive Summary
This paper develops a unified theoretical framework for understanding parameter isolation methods in continual learning by analyzing the geometry of loss landscapes. The authors approximate task losses around their minima using second-order Taylor expansions and derive a constraint on parameter updates that prevents catastrophic forgetting. They demonstrate that many existing algorithms (OGD, GPM, PackNet, Progressive Networks) are special cases of this framework. Theoretical guarantees are established for Orthogonal Gradient Descent and Gradient Projection Method, proving zero forgetting under certain assumptions. The work introduces a perturbation analysis tool to empirically assess the validity of these assumptions across different architectures and validates the theory experimentally on standard benchmarks.

## Method Summary
The core approach approximates each task's loss function around its minimum using a second-order Taylor expansion, expressing forgetting as a function of the alignment between current parameter updates and the average Hessian of previous tasks. The null-forgetting constraint requires parameter updates to be orthogonal to the average Hessian of previous tasks. The paper shows this constraint unifies existing parameter isolation methods: OGD enforces orthogonality between gradients, GPM constrains weight updates, and both can be understood as enforcing the null-forgetting constraint. For practical implementation on large networks, the authors propose SGD†, which approximates the constraint by projecting updates onto the orthogonal complement of the subspace spanned by the top k eigenvectors of each previous task's Hessian.

## Key Results
- Derives a unified theoretical framework for parameter isolation methods based on loss landscape geometry
- Establishes theoretical guarantees proving zero forgetting for OGD and GPM under certain assumptions
- Introduces SGD† as a practical approximation method using top Hessian eigenvectors
- Validates the theory experimentally across MLP, CNN, and Transformer architectures on Rotated MNIST and Split CIFAR benchmarks
- Demonstrates that enforcing the null-forgetting constraint reduces forgetting regardless of architecture or task complexity

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Enforcing orthogonality between parameter updates and previous tasks' loss landscape directions prevents catastrophic forgetting
- Mechanism: Approximates each task's loss around its minimum using second-order Taylor expansion; shows forgetting depends on alignment between parameter updates and average Hessian of previous tasks
- Core assumption: Loss landscape is well-approximated by quadratic function around task minima; algorithm stays close to these minima during learning
- Evidence anchors: [abstract]: "We approximate task losses around their minima and derive a constraint on parameter updates to prevent catastrophic forgetting"; [section 3]: "Using these assumptions we can write the average forgetting in a recursive fashion... E(t) = 1/t [(t-1)·E(t-1) + 1/2∆t⊺ (1/t · ∑H*o)∆t + v⊺∆t] + O(δ·ϵ)"
- Break condition: Quadratic approximation breaks down (updates move too far from minima) or Hessian structure changes significantly during learning

### Mechanism 2
- Claim: Parameter isolation methods like OGD and GPM are special cases of enforcing the null-forgetting constraint
- Mechanism: Shows OGD's orthogonality constraint on gradients and GPM's constraint on weight updates are mathematically equivalent to constraining updates orthogonal to average Hessian of previous tasks
- Core assumption: Hessian of previous tasks' losses is approximately block-diagonal (especially for ReLU networks in GPM's case)
- Evidence anchors: [section 4.1]: "Theorem 3. Let A : [T] → Θ be a continual learning algorithm satisfying Assumption 1. If A(t) = ∆t satisfies Equation 5, then it satisfies Equation 4"; [section 4.2]: "Theorem 4. Let A : [T] → Θ be a continual learning algorithm satisfying Assumption 1. If H*o is block-diagonal for all o ∈ [T], then if A(t) = ∆t satisfies Equation 6 it also satisfies Equation 4"
- Break condition: Hessian is not block-diagonal (invalidating GPM's assumptions) or gradient approximations in OGD become inaccurate

### Mechanism 3
- Claim: Null-forgetting constraint can be approximated efficiently for large networks using top eigenvectors of previous tasks' Hessians
- Mechanism: Proposes SGD†, which enforces approximation of null-forgetting constraint by projecting updates onto orthogonal complement of subspace spanned by top k eigenvectors of each previous task's Hessian
- Core assumption: Top eigenvectors capture most curvature information relevant for forgetting
- Evidence anchors: [section 5.3]: "We augment SGD with a projection step, enforcing orthogonality to the first k eigenvectors of the Hessian of each task"; [section 5.3]: "We observe a reduction in final forgetting when using SGD† during training... regardless of the architecture or the number of tasks"
- Break condition: Spectral gap is small (requiring many eigenvectors) or Hessian approximation becomes poor

## Foundational Learning

- Concept: Second-order Taylor approximation of loss functions
  - Why needed here: Theoretical framework relies on approximating task losses as quadratic functions around their minima to derive null-forgetting constraint
  - Quick check question: What are the first and second order terms in a Taylor expansion of a scalar function f(x) around point x₀?

- Concept: Hessian matrix properties and eigendecomposition
  - Why needed here: Uses Hessian matrix to characterize loss landscape geometry and its eigenvectors to implement null-forgetting constraint efficiently
  - Quick check question: For a symmetric matrix H, what is the relationship between its eigenvalues, eigenvectors, and the quadratic form x⊺Hx?

- Concept: Continual learning benchmarks and evaluation metrics
  - Why needed here: Validates theoretical findings on standard benchmarks (Rotated MNIST, Split CIFAR) using metrics like average forgetting E(t)
  - Quick check question: How is average forgetting E(t) defined in the context of continual learning, and what does it measure?

## Architecture Onboarding

- Component map: Theoretical framework (quadratic loss approximation + null-forgetting constraint) is independent of architecture; implementation details vary by network size and type
- Critical path: 1) Train on task t, 2) Compute/approximate Hessian eigenvectors of previous tasks, 3) Project updates to be orthogonal to these eigenvectors, 4) Update parameters, 5) Measure forgetting on test data
- Design tradeoffs: Exact null-forgetting (SGD†) vs. approximate methods (OGD, GPM) vs. no constraint (SGD). Exact method provides theoretical guarantees but is computationally expensive; approximate methods are more practical but have weaker guarantees
- Failure signatures: 1) Forgetting increases over time despite constraint enforcement, 2) Performance on current task degrades significantly, 3) Computational cost becomes prohibitive for large networks
- First 3 experiments:
  1. Implement SGD† on Rotated MNIST with MLP and compare to SGD baseline
  2. Measure rank of average Hessian H*<t as tasks accumulate to validate capacity usage hypothesis
  3. Evaluate perturbation analysis tool to determine validity region of quadratic approximation for different architectures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do proposed theoretical guarantees extend to activation functions beyond ReLU, particularly those with non-linear second-order derivatives?
- Basis in paper: [explicit] Authors note in Theorem 5 that proof relies on Hessian being block-diagonal and activation functions being piecewise-linear or linear; state that "For a general activation function σ, the diagonal entries of A can have a non-linear dependence on W l(i−1), and a case-by-case evaluation is required."
- Why unresolved: Authors leave case of other activation functions to reader, indicating extension requires further investigation
- What evidence would resolve it: Theoretical analysis demonstrating validity of null-forgetting constraint for broader class of activation functions, or empirical results showing performance with non-linear activations

### Open Question 2
- Question: How does size of perturbation ball (B) scale with network architecture and depth, and what implications does this have for practical applicability of quadratic approximation?
- Basis in paper: [explicit] Authors observe in perturbation analysis that "across tasks and random seeds the size of the ball B appears to be stable, while increasing proportionally to the network size"; note this effect warrants further investigation
- Why unresolved: Authors acknowledge this as interesting direction for future work but don't provide definitive answer on scaling behavior
- What evidence would resolve it: Systematic experiments varying network depth and width, along with theoretical analysis linking perturbation ball size to architectural parameters

### Open Question 3
- Question: What is impact of constructive interference between tasks on effectiveness of null-forgetting constraint, and how can algorithms be designed to exploit it?
- Basis in paper: [inferred] Authors mention in discussion of Theorem 1 that "this formulation ignores potential constructive interference between tasks" and that "exploiting a constructive interference of task may save network capacity for future tasks"; reference follow-up work on GPM addressing this problem
- Why unresolved: Authors highlight this as limitation of current framework and suggest as area for future research but don't provide concrete solution
- What evidence would resolve it: Algorithmic modifications to existing parameter isolation methods that explicitly account for task interactions, along with empirical results demonstrating improved performance on continual learning benchmarks

## Limitations
- Quadratic approximation validity: Theoretical framework relies heavily on approximating loss landscapes as quadratic functions, but validity is limited to small regions around task minima
- Computational scalability: While top-k eigenvector approximation is proposed for large networks, computational cost remains significant for deep architectures
- Task diversity: All experiments use relatively simple, structured task distributions; guarantees may not extend to more complex task distributions or domains

## Confidence
- High Confidence: Mathematical derivations connecting parameter isolation to quadratic loss approximations are rigorous and well-established; relationship between null-forgetting constraint and existing algorithms is mathematically sound
- Medium Confidence: Empirical validation on standard benchmarks is promising but limited in scope; perturbation analysis provides useful insights but doesn't fully characterize breakdown conditions for theoretical assumptions
- Low Confidence: Claims about general applicability to arbitrary architectures and task distributions, particularly for very large-scale models or more complex task sequences

## Next Checks
1. Scale Validation: Test SGD† on larger architectures (full ResNet-50, BERT-base) to evaluate computational scalability and verify eigenvector approximation remains effective at scale
2. Task Complexity Assessment: Evaluate framework on more complex task distributions, such as natural language processing tasks with varying input distributions, to test robustness of quadratic approximation assumptions
3. Break Condition Analysis: Systematically measure distance traveled from task minima during training and correlate with forgetting rates to empirically determine validity region of quadratic approximation across different architectures