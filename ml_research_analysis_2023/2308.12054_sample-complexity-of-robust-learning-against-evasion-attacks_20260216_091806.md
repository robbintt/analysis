---
ver: rpa2
title: Sample Complexity of Robust Learning against Evasion Attacks
arxiv_id: '2308.12054'
source_url: https://arxiv.org/abs/2308.12054
tags:
- learning
- robust
- sample
- complexity
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This thesis studied the robustness of learning algorithms to evasion
  attacks, where data is corrupted at test time. The focus was on the exact-in-the-ball
  notion of robustness, where the hypothesis and ground truth must agree in the perturbation
  region around each test point.
---

# Sample Complexity of Robust Learning against Evasion Attacks

## Quick Facts
- arXiv ID: 2308.12054
- Source URL: https://arxiv.org/abs/2308.12054
- Reference count: 0
- One-line primary result: Adversarial budget is fundamental to determining sample complexity of robust learning, with distributional assumptions often necessary

## Executive Summary
This thesis investigates the sample complexity of robust learning against evasion attacks under the exact-in-the-ball notion of robustness. The key finding is that the adversarial budget ρ fundamentally determines what can be robustly learned: no non-trivial concept class can be learned in distribution-free settings when ρ is unbounded, while under log-Lipschitz distributions, polynomial sample complexity is achievable when ρ = O(log n). The work establishes tight connections between adversarial power, distributional assumptions, and query models in determining robust learnability.

## Method Summary
The research employs theoretical analysis of combinatorial and statistical properties of concept classes under adversarial perturbations. The methodology involves proving sample complexity bounds through VC dimension analysis, Littlestone dimension calculations, and combinatorial arguments about error region expansions. Key techniques include using log-Lipschitz distribution properties to bound ρ-expansions of error regions, analyzing local equivalence query models with varying query radii, and introducing precision-bounded adversaries to handle infinite Littlestone dimensions. The approach systematically explores the interplay between adversary strength, distribution properties, and query access models.

## Key Results
- Exponential sample complexity lower bound for monotone conjunctions under uniform distribution when adversary budget exceeds O(log n)
- Polynomial sample complexity upper bound for conjunctions and decision lists under log-Lipschitz distributions when adversary budget is O(log n)
- Distribution-free robust learning impossibility for concept classes when local equivalence query radius is strictly smaller than adversary budget
- Finite query complexity bounds for halfspaces against precision-bounded adversaries via finite Littlestone dimension

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Adversarial budget ρ controls sample complexity for log-Lipschitz distributions.
- **Mechanism**: Log-Lipschitz distributions ensure nearby points have similar probability masses, keeping ρ-expansion of error regions polynomially bounded when ρ = O(log n), enabling efficient PAC learning.
- **Core assumption**: Log-Lipschitz property prevents sharp distribution changes that would cause exponential growth in robust error regions.
- **Evidence anchors**: Abstract statement about distributional assumptions; Section 4.4.2 bounding robust loss via standard risk; related work limitations.
- **Break condition**: Non-log-Lipschitz distributions cause exponential ρ-expansion of error regions, breaking polynomial sample complexity.

### Mechanism 2
- **Claim**: Local equivalence queries with λ = ρ enable distribution-free robust learning.
- **Mechanism**: When λ = ρ, LEQ queries return whether hypothesis and target agree on Bρ(x), effectively querying robust loss and providing counterexamples for robust ERM algorithms.
- **Core assumption**: Exact-in-the-ball robustness ensures zero empirical robust loss when λ = ρ, enabling logarithmic query complexity.
- **Evidence anchors**: Section 6.3.2 on zero empirical robust loss; Section 6.3.3 on online learning mistake bounds; related work limitations.
- **Break condition**: When λ < ρ, learner cannot access regions the adversary can perturb, making distribution-free learning impossible.

### Mechanism 3
- **Claim**: Precision-bounded adversaries enable finite query complexity for infinite Littlestone dimension classes.
- **Mechanism**: Requiring adversary to return counterexamples where both hypothesis and target are constant on Bτ(z) bounds Littlestone dimension as Litτ(H), enabling finite query complexity.
- **Core assumption**: Precision limitation creates effective margin preventing exploitation of infinite-precision decision boundaries.
- **Evidence anchors**: Section 6.4 definition and bounds for Litτ(THRESHOLDSB); Section 6.4 query upper bound for halfspaces; related work limitations.
- **Break condition**: Insufficient τ relative to instance norm B makes bounds vacuous or allows boundary exploitation.

## Foundational Learning

- **Concept**: VC dimension and variants (restricted VC dimension, VC dimension of robust loss)
  - Why needed here: Characterizes sample complexity for PAC learning and robust learning; restricted VC dimension needed for local query models.
  - Quick check question: What is VC dimension of monotone conjunctions on {0,1}^n? (Answer: n)

- **Concept**: Littlestone dimension and variants (precision-bounded Littlestone dimension)
  - Why needed here: Characterizes mistake bounds for online learning and query complexity for local equivalence queries; precision-bounded variant handles adversaries with limited precision.
  - Quick check question: What is Littlestone dimension of threshold functions? (Answer: infinite)

- **Concept**: Log-Lipschitz distributions
  - Why needed here: Enable polynomial sample complexity bounds by keeping ρ-expansions of error regions manageable under logarithmically-bounded adversaries.
  - Quick check question: What property must a distribution satisfy to be α-log-Lipschitz? (Answer: |log(D(x)) - log(D(x'))| ≤ log(α) for points differing in one bit)

## Architecture Onboarding

- **Component map**: 
  Learning framework (PAC learning with exact-in-the-ball robustness) -> Distribution models (Log-Lipschitz, uniform) -> Query models (Random examples, local membership, local equivalence) -> Adversary models (Unbounded precision, precision-bounded with parameter τ) -> Complexity measures (VC dimension, Littlestone dimension, restricted variants, VC dimension of robust loss)

- **Critical path**: 
  1. Define concept class and distribution
  2. Determine if log-Lipschitz assumptions hold
  3. Calculate adversarial budget ρ and check if O(log n)
  4. If yes, use PAC algorithm as black box with controlled accuracy
  5. If no, check if local equivalence queries with λ = ρ are available
  6. If yes, use sample complexity bounds based on VC(Lρ(C,H))
  7. If no, check if precision-bounded adversary with τ is applicable
  8. If yes, use query complexity bounds based on Litτ(H)

- **Design tradeoffs**:
  - Log-Lipschitz vs uniform distribution: Better sample complexity but stronger assumptions
  - LEQ vs LMQ: LEQ enables distribution-free learning but requires λ = ρ; LMQ cannot improve robustness threshold
  - Unbounded vs precision-bounded adversary: Better theoretical guarantees but may be unrealistic

- **Failure signatures**:
  - Exponential sample complexity when ρ = ω(log n) under uniform distribution
  - Infinite query complexity when Littlestone dimension is infinite and adversary has unbounded precision
  - Distribution-free impossibility when λ < ρ for local equivalence queries

- **First 3 experiments**:
  1. Test sample complexity of monotone conjunctions under log-Lipschitz distribution with ρ = O(log n) using PAC algorithm as black box
  2. Implement LEQ oracle and test distribution-free robust learning for conjunctions with λ = ρ
  3. Test query complexity bounds for halfspaces against precision-bounded adversary with varying τ

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the robustness threshold of linear classifiers (and, more generally, concept classes of polynomially-bounded VC dimension) under log-Lipschitz distributions?
- Basis in paper: Explicit. The paper states this is an open problem in Section 5.4.
- Why unresolved: The paper shows the robustness threshold is O(log n) for monotone conjunctions, decision lists, and parities under log-Lipschitz distributions, but does not extend this to linear classifiers.
- What evidence would resolve it: A proof that linear classifiers are robustly learnable under log-Lipschitz distributions with a robustness threshold of O(log n), or a proof that they are not.

### Open Question 2
- Question: Can we derive tighter sample complexity bounds with access to random examples only?
- Basis in paper: Explicit. The paper mentions this as an open problem in Section 7.1.
- Why unresolved: The paper derives sample complexity bounds for robust learning with random examples only, but these bounds may not be tight.
- What evidence would resolve it: A proof that the sample complexity bounds derived in the paper are tight, or a proof that they are not.

### Open Question 3
- Question: Is there a complexity measure characterizing the robust learnability of robust ERM algorithms under the exact-in-the-ball notion of robustness?
- Basis in paper: Explicit. The paper mentions this as an open problem in Section 7.1.
- Why unresolved: The paper uses the VC dimension of the robust loss as a complexity measure for robust learning, but it is not clear if this is the best measure.
- What evidence would resolve it: A proof that the VC dimension of the robust loss is the best complexity measure for robust learnability, or a proof that it is not.

## Limitations

- Exponential sample complexity lower bounds under uniform distribution suggest fundamental limitations that may not generalize to all concept classes
- Log-Lipschitz distribution assumptions may be too restrictive for many practical applications
- Precision-bounded adversary model introduces complexity that may limit applicability despite enabling finite bounds

## Confidence

- **High confidence**: Impossibility results for distribution-free robust learning and exponential sample complexity lower bounds are mathematically rigorous
- **Medium confidence**: Log-Lipschitz distribution assumptions and their implications for sample complexity are theoretically sound but may be too restrictive
- **Low confidence**: Precision-bounded adversary model and its connection to finite Littlestone dimension is novel but requires further empirical validation

## Next Checks

1. **Empirical validation of log-Lipschitz assumptions**: Test whether common real-world data distributions satisfy log-Lipschitz properties and quantify the impact on robust learning performance when these assumptions are violated.

2. **Experimental verification of query complexity bounds**: Implement the local equivalence query framework and measure actual query complexity against precision-bounded adversaries on synthetic and real datasets, comparing against theoretical predictions.

3. **Distribution adaptation analysis**: Study how robust learning performance degrades when log-Lipschitz distributions are approximated rather than exactly satisfied, and identify practical strategies for achieving near-optimal robustness under realistic distribution assumptions.