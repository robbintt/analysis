---
ver: rpa2
title: 'Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical
  Character Recognition'
arxiv_id: '2308.02369'
source_url: https://arxiv.org/abs/2308.02369
tags:
- text
- udup
- patch
- defensive
- underpainting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel defensive strategy called Universal
  Defensive Underpainting Patch (UDUP) to protect text images from unauthorized OCR
  extraction. Unlike previous methods that distort text characters, UDUP modifies
  the underpainting of text images by optimizing a small, fixed-size patch that can
  be tiled onto any text image.
---

# Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition

## Quick Facts
- arXiv ID: 2308.02369
- Source URL: https://arxiv.org/abs/2308.02369
- Reference count: 40
- Key outcome: Introduces UDUP, a universal adversarial patch that protects text images from OCR by modifying underpainting rather than characters, effective across sizes, colors, languages, and robust to scaling/compression.

## Executive Summary
This paper introduces UDUP, a novel defensive strategy that protects text images from unauthorized OCR extraction by modifying the underpainting rather than the characters themselves. The method employs a small, fixed-size patch optimized through iterative gradient descent to maximize detection loss while minimizing visual impact. UDUP demonstrates effectiveness against multiple state-of-the-art scene text detectors and commercial OCR systems while maintaining visual quality through a controlled mean underpainting intensity metric.

## Method Summary
UDUP modifies the underpainting of text images using a universal adversarial patch optimized through iterative gradient descent. The method employs two random scaling modules (R1 for training diversity and R2 for robustness) and incorporates a multi-layer loss to prevent overfitting. The patch is agnostic to content, size, colors, and languages, and maintains effectiveness across scaling and compression operations. The optimization balances prediction loss with multi-middle-layer feature distance to achieve black-box transferability.

## Key Results
- UDUP achieves high mean underpainting intensity (MUI) while significantly reducing OCR recall and precision rates
- The patch demonstrates robustness to scaling operations and JPEG compression
- UDUP maintains effectiveness across different character sizes, colors, and languages
- The method shows strong black-box transferability to commercial OCR systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: UDUP evades OCR by modifying underpainting instead of characters
- Mechanism: A small fixed-size patch is optimized through iterative gradient descent to maximize detection loss while minimizing visual impact
- Core assumption: Underpainting modification is orthogonal to character content and can generalize across sizes, colors, and languages
- Evidence anchors: [abstract] "modifies the underpainting of text images instead of the characters"; [section 3.1] "we propose a universal adversarial underpainting patch for arbitrary characters"
- Break condition: If the OCR model relies on underpainting features for detection, the patch may fail or require retraining

### Mechanism 2
- Claim: Random scaling modules R1 and R2 provide size and robustness invariance
- Mechanism: R1 enriches training diversity by randomly scaling input text, while R2 simulates pirate attacks by scaling the defensive text
- Core assumption: Random scaling during training forces the patch to generalize to unseen text sizes and scaling operations
- Evidence anchors: [section 3.2] "ğ‘…1 rich character size by randomly scaling the clean input image"; [section 3.2] "ğ‘…2 improves the robustness of scaling for UDUP via randomly scaling defensive text images"
- Break condition: If the scaling factors in practice deviate significantly from the training range, patch effectiveness may degrade

### Mechanism 3
- Claim: Multi-layer loss prevents overfitting to source model architecture
- Mechanism: Minimize distance between defensive text image and defensive underpainting at selected middle layers to avoid local maxima
- Core assumption: Standard adversarial attacks overfit to final prediction maps; intermediate layers encourage feature-level generalization
- Evidence anchors: [section 3.3] "incorporating a multi-middle-layer loss into the optimization objective"; [section 3.3] "minimizing the distance between the defensive text image and the defensive underpainting"
- Break condition: If the target model uses significantly different intermediate features, the multi-layer loss may not transfer well

## Foundational Learning

- Concept: Adversarial patch generation via gradient descent optimization
  - Why needed here: UDUP must iteratively refine a universal patch that generalizes across arbitrary text images
  - Quick check question: What is the role of the Clipğœ– operation in preventing overly large perturbations?

- Concept: Random data augmentation for adversarial robustness
  - Why needed here: R1 and R2 ensure the patch is effective for varying character sizes and scaling attacks
  - Quick check question: How does random scaling during training differ from adversarial training with fixed transformations?

- Concept: Multi-layer feature loss for transferability
  - Why needed here: Lğ‘š ensures the patch generalizes beyond the specific source model architecture
  - Quick check question: Why might minimizing feature distance at intermediate layers improve black-box transferability?

## Architecture Onboarding

- Component map: Text image dataset â†’ Random scaling (R1) â†’ Patch tiling â†’ Defensive text image â†’ Model output â†’ Loss computation
- Critical path: 1. Generate mini-batch of text images 2. Apply random scaling R1 3. Tile UDUP patch to create defensive underpainting 4. Apply random scaling R2 to defensive text image 5. Compute prediction loss Lğ‘ and multi-layer loss Lğ‘š 6. Update patch with momentum-based gradient descent 7. Clip patch to maintain perturbation magnitude
- Design tradeoffs:
  - Patch size vs. universality: Larger patches may provide better defense but reduce tiling efficiency
  - MUI vs. visual quality: Higher MUI increases defense but degrades visual readability
  - Loss balance (ğœ†) vs. convergence: Too much Lğ‘š may slow convergence; too little may overfit to source model
- Failure signatures:
  - Patch produces high MUI but poor Rğ‘‘/Rğ‘: Likely overfitting to source model
  - Low MUI but Rğ‘‘/Rğ‘ close to 1: Patch not disrupting detection features effectively
  - Poor performance on scaled images: Random scaling range too narrow during training
- First 3 experiments:
  1. Train UDUP with MUI=0.06 and patch size=30Ã—30 on a small text dataset; measure Rğ‘‘/Rğ‘ on CRAFT
  2. Apply UDUP to a mixed-color text dataset; verify character-color agnosticism by checking recall drop across colors
  3. Test UDUP against a commercial OCR system (e.g., Baidu OCR); measure black-box transferability via Rğ‘‘/Rğ‘ reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance weight (ğœ†) for different patch sizes to maximize the defensive effect of UDUP?
- Basis in paper: [explicit] The paper discusses the impact of ğœ† on the defensive effect of UDUP and provides specific values for different patch sizes
- Why unresolved: While the paper provides some values for ğœ†, it does not provide a clear methodology or formula for determining the optimal ğœ† for a given patch size
- What evidence would resolve it: A comprehensive study testing various ğœ† values for each patch size and a clear explanation of how to determine the optimal ğœ† would resolve this question

### Open Question 2
- Question: How does the proposed UDUP method perform against more advanced OCR systems that may employ anti-adversarial techniques?
- Basis in paper: [inferred] The paper demonstrates the effectiveness of UDUP against several state-of-the-art scene text detectors and commercial OCR systems, but it does not explicitly test its performance against OCR systems with anti-adversarial techniques
- Why unresolved: The effectiveness of UDUP against OCR systems with anti-adversarial techniques is not directly tested or discussed in the paper
- What evidence would resolve it: Testing UDUP against OCR systems that employ anti-adversarial techniques and comparing the results would provide evidence for this question

### Open Question 3
- Question: How does the visual quality of text images with defensive underpainting change with different character fonts and styles?
- Basis in paper: [inferred] The paper discusses the universality of UDUP in terms of character size, color, and language, but it does not explicitly address the impact of different fonts and styles on visual quality
- Why unresolved: The paper does not provide any experiments or discussions on the impact of different fonts and styles on the visual quality of text images with defensive underpainting
- What evidence would resolve it: Conducting experiments with text images featuring various fonts and styles and evaluating the visual quality would provide evidence for this question

## Limitations

- The universal patch mechanism assumes that modifying underpainting features rather than character pixels will generalize across arbitrary text content, sizes, colors, and languages, but this has not been rigorously validated beyond the tested English dataset
- The two random scaling modules (R1 and R2) are described as critical for robustness, yet the exact scaling factor ranges and implementation details are not specified
- The multi-layer loss approach claims to prevent overfitting and improve black-box transferability, but the specific middle layers used and their selection criteria remain unspecified

## Confidence

- **High confidence**: The mathematical formulation of the optimization problem (gradient descent with momentum, clipping constraints) is clearly specified and reproducible
- **Medium confidence**: The general approach of using adversarial patches for OCR defense is sound, and the reported R_d/R_c metrics show consistent degradation across multiple scene text detectors
- **Low confidence**: Claims about universality across languages and extreme robustness to scaling and compression are not fully validated, as the experiments focus primarily on English text and limited scaling ranges

## Next Checks

1. **Scaling Robustness Test**: Evaluate UDUP against CRAFT and other STDs at scaling factors from 0.5x to 3.0x in 0.1 increments, measuring R_d/R_c at each level to identify exact breakdown points

2. **Cross-Lingual Transferability**: Apply the English-trained UDUP patch to text images containing Chinese, Arabic, and Devanagari scripts, measuring detection recall drop and visual quality degradation across languages

3. **Adaptive Defense Evaluation**: Train a modified version of CRAFT on text images augmented with UDUP patches, then test whether the original UDUP patch remains effective against this adapted model