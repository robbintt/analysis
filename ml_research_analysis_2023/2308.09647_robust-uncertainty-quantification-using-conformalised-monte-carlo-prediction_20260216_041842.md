---
ver: rpa2
title: Robust Uncertainty Quantification Using Conformalised Monte Carlo Prediction
arxiv_id: '2308.09647'
source_url: https://arxiv.org/abs/2308.09647
tags:
- prediction
- mc-cp
- dropout
- mean
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MC-CP, a hybrid uncertainty quantification
  method that combines adaptive Monte Carlo dropout with conformal prediction. The
  key innovation is an adaptive MC dropout technique that dynamically modulates the
  number of forward passes based on prediction variance convergence, significantly
  reducing computational overhead compared to traditional MC dropout.
---

# Robust Uncertainty Quantification Using Conformalised Monte Carlo Prediction

## Quick Facts
- arXiv ID: 2308.09647
- Source URL: https://arxiv.org/abs/2308.09647
- Reference count: 9
- This paper introduces MC-CP, a hybrid uncertainty quantification method that combines adaptive Monte Carlo dropout with conformal prediction.

## Executive Summary
This paper introduces MC-CP, a hybrid uncertainty quantification method that combines adaptive Monte Carlo dropout with conformal prediction. The key innovation is an adaptive MC dropout technique that dynamically modulates the number of forward passes based on prediction variance convergence, significantly reducing computational overhead compared to traditional MC dropout. MC-CP applies this adaptive dropout to generate prediction distributions, which are then used by conformal prediction to create robust prediction sets/intervals with guaranteed coverage. Extensive experiments on five image classification benchmarks (CIFAR-10/100, MNIST, Fashion-MNIST, Tiny ImageNet) and five regression datasets show that MC-CP achieves state-of-the-art accuracy with lower prediction set sizes than competing methods like Naive CP and RAPS.

## Method Summary
MC-CP is a hybrid uncertainty quantification method that combines adaptive Monte Carlo dropout with conformal prediction. The adaptive MC dropout component dynamically modulates the number of forward passes based on prediction variance convergence, reducing computational overhead. The method tracks variance across classes/quantiles across forward passes and terminates early when the difference between consecutive variance estimates falls below a threshold δ for P consecutive passes. The prediction distributions from adaptive MC dropout are then used by conformal prediction to construct prediction sets/intervals with guaranteed coverage. The method is model-agnostic and can be easily integrated into existing deep learning pipelines.

## Key Results
- MC-CP achieves state-of-the-art accuracy with lower prediction set sizes than competing methods like Naive CP and RAPS
- For regression tasks, MC-CP provides higher empirical coverage than CQR while maintaining competitive mean absolute error
- The adaptive dropout component reduces inference time by approximately 50% compared to traditional MC dropout while maintaining prediction quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adaptive MC dropout terminates early when prediction variance converges, reducing inference time without degrading accuracy.
- Mechanism: The method tracks variance across classes/quantiles across forward passes. When the difference between consecutive variance estimates falls below a threshold δ for P consecutive passes, inference stops early.
- Core assumption: Additional forward passes after variance convergence provide diminishing returns in prediction quality.
- Evidence anchors:
  - [abstract]: "adaptive dropout component reduces inference time by approximately 50% compared to traditional MC dropout while maintaining prediction quality"
  - [section]: "Adaptive MC Dropout leverages this observation to reduce the number of wasted forward passes once convergence is diagnosed, thus yielding significant computational savings without impacting the prediction effectiveness"
  - [corpus]: No direct evidence in corpus about early termination saving computation, but related work on MC dropout efficiency exists.
- Break condition: If the variance convergence threshold δ is set too high, early termination may occur before meaningful uncertainty quantification is achieved.

### Mechanism 2
- Claim: Combining adaptive MC dropout with conformal prediction produces smaller prediction sets while maintaining coverage guarantees.
- Mechanism: Adaptive MC dropout provides calibrated uncertainty estimates (variance) that inform the conformal prediction process, allowing it to set more appropriate thresholds for prediction sets/intervals.
- Core assumption: The variance estimates from adaptive MC dropout better reflect true model uncertainty than fixed dropout approaches.
- Evidence anchors:
  - [abstract]: "MC-CP achieves state-of-the-art accuracy with lower prediction set sizes than competing methods like Naive CP and RAPS"
  - [section]: "MC-CP outperforms other state-of-the-art conformal prediction techniques, with modest computational overheads"
  - [corpus]: Weak evidence - corpus papers mention conformal prediction but not the specific combination with adaptive MC dropout.
- Break condition: If the adaptive MC dropout variance estimates are poorly calibrated, the conformal prediction coverage guarantees may be violated.

### Mechanism 3
- Claim: The hybrid approach maintains high empirical coverage while reducing mean absolute error in regression tasks.
- Mechanism: Adaptive MC dropout provides more accurate uncertainty quantification, which conformal prediction uses to construct intervals that better capture true quantiles while avoiding over-conservatism.
- Core assumption: Better uncertainty quantification leads to more efficient interval construction.
- Evidence anchors:
  - [abstract]: "For regression tasks, MC-CP provides higher empirical coverage than CQR while maintaining competitive mean absolute error"
  - [section]: "CQR provide the 1 − α coverage guarantee specified for all datasets, i.e., approximately 90%. Furthermore, CQR achieves this coverage with an MAE comparable to the baseline method... Our method MC-CP reaches the highest empirical coverage across all four datasets, but it does this with slightly higher overall MAE"
  - [corpus]: No direct evidence in corpus about regression performance, but conformal prediction for regression is mentioned.
- Break condition: If the adaptive MC dropout produces overly conservative uncertainty estimates, the resulting prediction intervals may become unnecessarily large.

## Foundational Learning

- Concept: Monte Carlo dropout for uncertainty quantification
  - Why needed here: Forms the base uncertainty estimation method that MC-CP builds upon
  - Quick check question: What does the variance of predictions across MC dropout forward passes represent?
- Concept: Conformal prediction and its coverage guarantee
  - Why needed here: Provides the framework for constructing prediction sets with finite-sample coverage guarantees
  - Quick check question: How does conformal prediction ensure that prediction sets contain the true label with probability (1-α)?
- Concept: Adaptive algorithms and convergence detection
  - Why needed here: Enables the early termination of MC dropout based on variance convergence
  - Quick check question: What criteria determine when an iterative algorithm has converged?

## Architecture Onboarding

- Component map: Input -> Adaptive MC dropout -> Variance convergence check -> Prediction distribution -> Conformal prediction -> Output prediction set/interval
- Critical path: Input → Adaptive MC dropout → Variance convergence check → Prediction distribution → Conformal prediction → Output prediction set/interval
- Design tradeoffs:
  - Lower δ and higher P → More accurate uncertainty but longer inference time
  - Higher δ and lower P → Faster inference but potentially less reliable uncertainty estimates
  - Calibration set size → Larger sets improve coverage guarantees but reduce available training data
- Failure signatures:
  - Prediction sets too small → Coverage guarantees violated (true labels not contained)
  - Prediction sets too large → Loss of efficiency (overly conservative)
  - Runtime similar to traditional MC dropout → Adaptive component not triggering early termination
- First 3 experiments:
  1. Implement adaptive MC dropout alone and compare inference time vs traditional MC dropout on a simple classification task
  2. Add conformal prediction layer and verify coverage guarantees on a held-out test set
  3. Perform sensitivity analysis on δ and P parameters to find optimal balance between accuracy and efficiency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical justification for why MC-CP consistently achieves lower prediction set sizes compared to RAPS and CQR while maintaining or improving accuracy/coverage?
- Basis in paper: [explicit] The paper states MC-CP "delivers significant improvements over advanced methods, like MC dropout, RAPS and CQR" and shows lower prediction set sizes with better accuracy/coverage in experiments, but does not provide theoretical analysis.
- Why unresolved: The paper relies on empirical comparisons but does not explain the mathematical or statistical reasons why MC-CP should outperform these specific baselines in terms of set/interval size.
- What evidence would resolve it: A theoretical analysis showing how adaptive MC dropout's variance convergence criterion combined with conformal prediction's quantile threshold calculation leads to more efficient prediction sets/intervals compared to the mechanisms used by RAPS and CQR.

### Open Question 2
- Question: How does MC-CP's performance scale with increasingly complex deep learning architectures (e.g., transformers, larger CNNs) and datasets with higher dimensionality or more classes?
- Basis in paper: [inferred] The experiments use relatively standard CNN architectures on moderate-scale datasets (CIFAR, MNIST, Tiny ImageNet). The paper claims MC-CP is "model-agnostic" but doesn't test on more complex architectures or extreme-scale problems.
- Why unresolved: The adaptive dropout mechanism and conformal prediction framework may have different computational or statistical properties when applied to very large models or datasets, but this scaling behavior is unexplored.
- What evidence would resolve it: Comprehensive experiments applying MC-CP to state-of-the-art vision architectures (e.g., ViT, ResNet-152) and larger-scale datasets (e.g., ImageNet-1k, JFT-300M) measuring accuracy, set size, coverage, and computational efficiency.

### Open Question 3
- Question: What is the optimal strategy for selecting the threshold δ and patience P hyperparameters in adaptive MC dropout, and how sensitive is MC-CP to these choices across different problem domains?
- Basis in paper: [explicit] The paper performs sensitivity analysis on δ and P values, showing they affect forward passes and performance, but doesn't provide guidance on selection strategies or domain-specific recommendations.
- Why unresolved: The paper demonstrates that δ and P affect performance but doesn't explain how to choose them for new applications, nor whether different domains (classification vs regression, small vs large datasets) require different hyperparameter strategies.
- What evidence would resolve it: A systematic study establishing guidelines for hyperparameter selection based on dataset characteristics, model complexity, and application requirements, possibly including automated selection methods or adaptive schemes that adjust δ and P during inference.

## Limitations
- Performance heavily depends on choice of hyperparameters δ and P for adaptive MC dropout, with limited guidance for optimal selection
- Experimental validation focuses primarily on image classification benchmarks, leaving effectiveness on other data modalities uncertain
- 50% inference time reduction assumes variance convergence is a reliable early stopping criterion, but this assumption may fail in some scenarios

## Confidence
**High confidence**: The hybrid architecture combining adaptive MC dropout with conformal prediction is technically sound and the coverage guarantees from conformal prediction are well-established.

**Medium confidence**: Empirical performance claims are supported by reported experiments, but methodology lacks extensive ablation studies on different model architectures and dataset types.

**Low confidence**: Generalizability to non-image data and complex, multi-modal tasks remains unproven, and sensitivity analysis of adaptive dropout parameters is minimal.

## Next Checks
1. **Ablation on parameter sensitivity**: Systematically vary δ and P across a grid search on a subset of datasets to map the performance landscape and identify robust default values. Measure the impact on both computational efficiency and coverage guarantees.

2. **Cross-domain generalization**: Apply MC-CP to a diverse set of tasks including natural language processing and tabular data regression to assess whether the method's advantages transfer beyond image classification. Compare against specialized uncertainty quantification methods for each domain.

3. **Stress testing convergence criteria**: Design experiments where prediction distributions have multiple modes or heavy tails to test whether variance convergence remains a reliable stopping criterion. Compare against alternative convergence metrics such as entropy of prediction distributions.