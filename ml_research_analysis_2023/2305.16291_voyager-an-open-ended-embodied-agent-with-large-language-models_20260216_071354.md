---
ver: rpa2
title: 'Voyager: An Open-Ended Embodied Agent with Large Language Models'
arxiv_id: '2305.16291'
source_url: https://arxiv.org/abs/2305.16291
tags:
- arxiv
- task
- voyager
- await
- code
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces VOYAGER, the first LLM-powered embodied lifelong
  learning agent in Minecraft that continuously explores, acquires diverse skills,
  and makes novel discoveries without human intervention. It combines an automatic
  curriculum that maximizes exploration, an ever-growing skill library of executable
  code for storing and retrieving complex behaviors, and a new iterative prompting
  mechanism that incorporates environment feedback, execution errors, and self-verification
  for program improvement.
---

# Voyager: An Open-Ended Embodied Agent with Large Language Models

## Quick Facts
- arXiv ID: 2305.16291
- Source URL: https://arxiv.org/abs/2305.16291
- Reference count: 40
- Primary result: First LLM-powered embodied lifelong learning agent in Minecraft that continuously explores and acquires skills without human intervention

## Executive Summary
This paper introduces VOYAGER, a groundbreaking embodied agent that leverages Large Language Models (LLMs) to achieve lifelong learning in the open-ended environment of Minecraft. VOYAGER combines an automatic curriculum for maximizing exploration, an ever-growing skill library for storing executable code, and an iterative prompting mechanism that incorporates environment feedback for continuous improvement. The system demonstrates exceptional proficiency, achieving 3.3× more unique items, traveling 2.3× longer distances, and unlocking key tech tree milestones up to 15.3× faster than prior state-of-the-art methods.

## Method Summary
VOYAGER employs GPT-4 to generate executable code for embodied control in Minecraft through a three-component architecture: an automatic curriculum that proposes exploration objectives based on agent state, a skill library that stores and retrieves executable code representations indexed by embeddings, and an iterative prompting mechanism that refines code using environment feedback, execution errors, and self-verification. The system operates within the MineDojo framework using Mineflayer APIs, with code execution providing observations and error traces that inform subsequent iterations until task completion is verified.

## Key Results
- 3.3× more unique items discovered compared to prior state-of-the-art
- 2.3× longer travel distances achieved in exploration
- 15.3× faster unlocking of key tech tree milestones
- Demonstrated ability to generalize learned skills to new Minecraft worlds for solving novel tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The iterative prompting mechanism with environment feedback, execution errors, and self-verification enables consistent code improvement for embodied control.
- Mechanism: GPT-4 generates initial code, which is executed to obtain observations from the Minecraft simulation and error traces from the code interpreter. This feedback is incorporated into GPT-4's prompt for another round of code refinement. The process repeats until self-verification confirms task completion.
- Core assumption: GPT-4 can effectively use execution errors and environment feedback to iteratively improve its code generation for embodied control tasks.
- Evidence anchors: [abstract]: "a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement." [section]: "To address this challenge, we propose an iterative prompting mechanism that: (1) executes the generated program to obtain observations from the Minecraft simulation (such as inventory listing and nearby creatures) and error trace from the code interpreter (if any); (2) incorporates the feedback into GPT-4's prompt for another round of code refinement; and (3) repeats the process until a self-verification module confirms the task completion..."

### Mechanism 2
- Claim: The automatic curriculum maximizes exploration by suggesting objectives based on the agent's current state and exploration progress.
- Mechanism: GPT-4 generates tasks based on the overarching goal of "discovering as many diverse things as possible", taking into account the agent's inventory, equipment, nearby blocks and entities, biome, time, health and hunger bars, position, and previously completed and failed tasks.
- Core assumption: GPT-4 can generate suitable tasks that progressively increase in difficulty and are achievable based on the agent's current state and exploration progress.
- Evidence anchors: [abstract]: "an automatic curriculum that maximizes exploration" [section]: "The curriculum is generated by GPT-4 based on the overarching goal of 'discovering as many diverse things as possible'. This approach can be perceived as an in-context form of novelty search."

### Mechanism 3
- Claim: The skill library enables lifelong learning by storing and retrieving executable code for complex behaviors, alleviating catastrophic forgetting.
- Mechanism: Each skill is represented by executable code that scaffolds temporally extended actions for completing a specific task. The skill library is indexed by the embedding of each program's description, allowing for retrieval in similar situations in the future. Complex skills can be synthesized by composing simpler programs.
- Core assumption: The skill library can effectively store and retrieve executable code for a wide range of tasks, and the retrieval mechanism can identify relevant skills based on the task description and environment feedback.
- Evidence anchors: [abstract]: "an ever-growing skill library of executable code for storing and retrieving complex behaviors" [section]: "Each program is indexed by the embedding of its description, which can be retrieved in similar situations in the future. Complex skills can be synthesized by composing simpler programs, which compounds VOYAGER's capabilities rapidly over time and alleviates catastrophic forgetting in other continual learning methods."

## Foundational Learning

- Concept: Large Language Models (LLMs) for code generation
  - Why needed here: GPT-4 is used to generate executable code for embodied control in Minecraft, leveraging its emergent capabilities in code generation and complex reasoning.
  - Quick check question: Can GPT-4 generate syntactically correct and semantically meaningful code for Minecraft control tasks based on the given prompt and feedback?

- Concept: Embodied AI and open-ended exploration
  - Why needed here: VOYAGER operates in the open-ended environment of Minecraft, requiring the ability to explore, acquire diverse skills, and make novel discoveries without human intervention.
  - Quick check question: Does the agent exhibit behaviors that go beyond simple goal-directed tasks and demonstrate open-ended exploration and skill acquisition?

- Concept: Lifelong learning and catastrophic forgetting
  - Why needed here: VOYAGER aims to continuously learn and improve its skills over time, while avoiding the problem of catastrophic forgetting where previously learned knowledge is lost.
  - Quick check question: Does the agent's performance improve over time as it accumulates and reuses skills from the skill library, without significant degradation in previously learned tasks?

## Architecture Onboarding

- Component map: Automatic Curriculum -> Iterative Prompting Mechanism -> Skill Library -> Minecraft Environment -> GPT-4
- Critical path: 1. Automatic curriculum proposes a task based on exploration progress and agent state 2. Iterative prompting mechanism generates initial code for the task 3. Code is executed in the Minecraft environment, providing observations and error traces 4. Feedback is incorporated into the prompt for code refinement 5. Process repeats until self-verification confirms task completion 6. Successful code is added to the skill library for future retrieval
- Design tradeoffs: Using GPT-4 for code generation provides high-quality code but incurs significant costs; Relying on environment feedback and execution errors for code refinement may lead to slower progress compared to gradient-based methods; Storing executable code in the skill library allows for complex behaviors but may lead to inefficient retrieval as the library grows
- Failure signatures: Agent gets stuck on a task and fails to generate correct code after multiple iterations; Skill library retrieval fails to identify relevant skills for a given task; Self-verification module incorrectly assesses task completion, leading to premature termination or infinite loops
- First 3 experiments: 1. Test the automatic curriculum by providing a simple agent state and verifying that the generated tasks are suitable and achievable 2. Test the iterative prompting mechanism by providing a simple code generation task and verifying that the feedback is effectively incorporated into the code refinement process 3. Test the skill library by storing and retrieving a few simple skills and verifying that they can be effectively composed to solve more complex tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of automatic curriculum affect VOYAGER's ability to learn and generalize in Minecraft compared to a random or manually designed curriculum?
- Basis in paper: [explicit] The paper compares VOYAGER with a random curriculum and a manually designed curriculum for mining a diamond, highlighting the importance of the automatic curriculum in facilitating the agent's progress and exploration.
- Why unresolved: The paper does not provide a comprehensive comparison of different curriculum designs or their impact on VOYAGER's performance across a wide range of tasks and environments.
- What evidence would resolve it: Systematic experiments comparing VOYAGER's performance with different curriculum designs (random, manual, and automatic) across various tasks and environments, along with a detailed analysis of the learned skills and their generalization capabilities.

### Open Question 2
- Question: What are the limitations of VOYAGER's skill library in terms of scalability and adaptability to new tasks or environments?
- Basis in paper: [inferred] The paper discusses the skill library's role in enabling VOYAGER to learn and reuse complex behaviors, but it does not delve into the limitations or potential challenges of scaling the skill library or adapting it to new tasks or environments.
- Why unresolved: The paper focuses on demonstrating VOYAGER's capabilities in Minecraft but does not extensively explore the limitations or challenges of the skill library in more complex or diverse scenarios.
- What evidence would resolve it: Experiments testing VOYAGER's performance with an expanding skill library, introducing new tasks or environments, and analyzing the scalability and adaptability of the skill library in terms of memory usage, retrieval efficiency, and generalization capabilities.

### Open Question 3
- Question: How does the iterative prompting mechanism contribute to VOYAGER's ability to generate executable code and improve its performance over time?
- Basis in paper: [explicit] The paper introduces the iterative prompting mechanism and its components (environment feedback, execution errors, and self-verification) and discusses their role in refining the generated code and improving VOYAGER's performance.
- Why unresolved: The paper does not provide a detailed analysis of the individual contributions of each component of the iterative prompting mechanism or their combined effect on VOYAGER's performance.
- What evidence would resolve it: Ablation studies systematically removing or modifying each component of the iterative prompting mechanism and analyzing their impact on VOYAGER's code generation quality, task completion rate, and overall performance.

### Open Question 4
- Question: What are the potential applications and limitations of VOYAGER in real-world scenarios beyond Minecraft?
- Basis in paper: [inferred] The paper demonstrates VOYAGER's capabilities in Minecraft, but it does not explore its potential applications or limitations in real-world scenarios, such as robotics, autonomous systems, or other domains requiring embodied agents.
- Why unresolved: The paper focuses on VOYAGER's performance in a simulated environment and does not provide insights into its potential real-world applications or the challenges it may face in more complex or dynamic environments.
- What evidence would resolve it: Experiments testing VOYAGER's performance in real-world scenarios, analyzing its adaptability to different domains, and identifying the limitations and challenges it may encounter in terms of perception, control, and generalization.

## Limitations
- Cost and scalability issues due to heavy reliance on GPT-4 API for multiple components
- Unvalidated skill library retrieval efficiency as the library grows larger
- Limited evidence of generalization beyond Minecraft-specific environments
- Self-verification module reliability remains unvalidated

## Confidence
- **High Confidence**: Basic feasibility of using LLMs for embodied control in Minecraft
- **Medium Confidence**: Reported performance improvements (3.3× items, 2.3× distances, 15.3× milestones)
- **Low Confidence**: Generalizability claims to other environments or real-world scenarios

## Next Checks
1. **Cost Scaling Analysis**: Run the system for extended periods (10× longer duration) and measure GPT-4 API token usage, execution time, and performance metrics to establish scaling relationships and identify potential bottlenecks.
2. **Skill Library Retrieval Benchmarking**: Implement a stress test by artificially inflating the skill library to 10× its normal size and measuring retrieval accuracy, latency, and composition success rates for increasingly complex tasks.
3. **Cross-Environment Transfer Test**: Deploy the learned skill library from one Minecraft seed/world configuration to a substantially different environment (different biome distribution, resource availability) and measure skill reuse effectiveness and adaptation speed.