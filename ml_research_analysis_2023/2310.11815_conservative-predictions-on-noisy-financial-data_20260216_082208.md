---
ver: rpa2
title: Conservative Predictions on Noisy Financial Data
arxiv_id: '2310.11815'
source_url: https://arxiv.org/abs/2310.11815
tags:
- data
- test
- predictions
- noise
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of noisy data in financial market
  prediction, where traditional machine learning models often make unreliable predictions
  due to inherent noise in price movements. The authors propose a cascading model
  approach that abstains from making predictions on data points where it lacks confidence,
  similar to CN2 rule-learning techniques.
---

# Conservative Predictions on Noisy Financial Data

## Quick Facts
- arXiv ID: 2310.11815
- Source URL: https://arxiv.org/abs/2310.11815
- Reference count: 20
- Key outcome: Cascading models that abstain from uncertain predictions significantly improve accuracy and utility while reducing risk in financial market prediction compared to traditional approaches.

## Executive Summary
This paper addresses the challenge of noisy data in financial market prediction by proposing a cascading model approach that learns to abstain from making predictions when confidence is low. The method trains a sequence of models, each on increasingly noisy subsets of data, with pruning based on Gini impurity. Tested on both synthetic and real market data, the approach shows that cascading models can maintain high accuracy while reducing risk through conservative prediction strategies. The paper compares traditional MLPs with differentiable decision trees (DDTs), finding that DDTs generally outperform MLPs in terms of support, utility, and risk-adjusted returns.

## Method Summary
The authors propose a cascading model approach where a sequence of models is trained, each on data points where previous models were uncertain. Gini impurity is used to measure prediction confidence, with data points above a threshold pruned and passed to the next model. Both MLPs and differentiable decision trees are tested, with the DDTs incorporating regularization to encourage balanced splits. The approach is evaluated on synthetic sine wave data with controlled noise and real Indian equity market data, measuring accuracy, support (fraction of confident predictions), utility, downside-risk-adjusted return, and traded Sharpe ratio.

## Key Results
- Cascading models achieved 88-97% accuracy on synthetic data across all noise levels while maintaining 30-100% support
- DDTs outperformed MLPs on real market data, with cascading DDTs achieving 65-81% accuracy and higher utility metrics
- The cascading approach reduced downside risk while maintaining or improving trading performance compared to single models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cascading models improve prediction accuracy on noisy financial data by pruning uncertain predictions at each level.
- Mechanism: The cascading approach trains a sequence of models, each on increasingly noisy subsets of data. At each level, predictions with Gini impurity above a threshold are pruned and passed to the next model. This focuses each subsequent model on harder cases, improving accuracy on the remaining confident predictions.
- Core assumption: The underlying signal exists in the data and can be learned by simpler models when noise is reduced through progressive pruning.
- Evidence anchors:
  - [abstract] "a cascade of models are learned in sequence, similar to rule lists, with each model being trained only on data on which the previous model(s) were uncertain"
  - [section] "The more imbalanced the probabilities, more confident the model is on it's predictions. We useGini Impurity to calculate the imbalance in the probabilities"
  - [corpus] Weak evidence - no direct citations found in corpus, but related to general ensemble learning approaches
- Break condition: If the signal-to-noise ratio is too low, the cascade may prune too aggressively, leaving insufficient data for subsequent models to learn meaningful patterns.

### Mechanism 2
- Claim: Differentiable Decision Trees (DDTs) outperform traditional MLPs in handling noisy financial data through their hierarchical structure and regularization.
- Mechanism: DDTs use fuzzy decisions at each node with sigmoid functions, allowing for gradient-based optimization while maintaining interpretability. The regularization term encourages balanced splits, preventing the model from favoring single paths and improving generalization on noisy data.
- Core assumption: The hierarchical decision structure can capture patterns in financial data better than flat MLP architectures, especially when combined with regularization that prevents overfitting to noise.
- Evidence anchors:
  - [section] "We employ differentiable decision trees (DDT) as introduced in [17] and used in a deep-learning context by [16]. We also used traditional MLPs in our cascaded learning approach, and compare these with DDTs."
  - [section] "The DDT tends to get stuck in a local minima quite often, with one path getting much higher probabilities than the others... To solve this issue, Frrost and Hinton [9] introduced a regularization term which makes the inner nodes make a more balanced split"
  - [corpus] Weak evidence - no direct citations found in corpus, but related to general tree-based model advantages
- Break condition: If the data structure is not hierarchical or if the noise patterns don't align with the tree structure, DDTs may not provide advantages over MLPs.

### Mechanism 3
- Claim: Abstaining from predictions on uncertain data reduces risk in financial trading decisions.
- Mechanism: By only making predictions when the model cascade is confident (low Gini impurity), the system avoids making trades based on unreliable signals. This conservative approach prioritizes risk reduction over maximizing the number of trades.
- Core assumption: In financial trading, avoiding losses from uncertain predictions is more valuable than capturing all possible profitable opportunities, especially when leverage is involved.
- Evidence anchors:
  - [abstract] "In a financial prediction setting, such an approach allows decisions to be taken only when the ensemble model is confident, thereby reducing risk"
  - [section] "it is preferable to have a model with 70% or even 60% accuracy on say 20% or even 10% of the data, on which it makes confident predictions, and abstains on the balance, as this serves to minimise risk in any decisions taken based on the model's predictions"
  - [corpus] Weak evidence - no direct citations found in corpus, but aligns with general risk management principles
- Break condition: If the threshold for abstention is set too high, the system may miss too many trading opportunities, resulting in insufficient trading activity to generate meaningful returns.

## Foundational Learning

- Concept: Gini Impurity
  - Why needed here: Gini Impurity measures the confidence of predictions by quantifying the imbalance in class probability distributions. Lower Gini Impurity indicates higher confidence in predictions.
  - Quick check question: If a model predicts class probabilities of [0.9, 0.1] for a binary classification, what is the Gini Impurity and how confident is this prediction?

- Concept: Cascading Model Architecture
  - Why needed here: Understanding how models can be chained together where each subsequent model learns from the failures of previous ones is crucial for implementing the pruning approach.
  - Quick check question: In a three-level cascade, if the first model prunes 60% of data as uncertain, what percentage of the original data reaches the second model?

- Concept: Differentiable Decision Trees
  - Why needed here: DDTs combine the interpretability of decision trees with the optimization capabilities of neural networks, making them suitable for noisy financial data.
  - Quick check question: How does the sigmoid function in DDTs differ from the hard decisions in traditional decision trees, and what advantage does this provide during training?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Base models (MLPs/DDTs) -> Cascade controller -> Pruning logic -> Evaluation metrics

- Critical path:
  1. Preprocess market data into OHLCV format with technical indicators
  2. Initialize base model (MLP or DDT) and train on full dataset
  3. Calculate Gini Impurity for each prediction
  4. Prune data points with high impurity and pass to next model
  5. Repeat steps 2-4 for cascade levels
  6. Evaluate final model on test data

- Design tradeoffs:
  - Support vs. Accuracy: Higher confidence thresholds increase accuracy but reduce support (fewer predictions)
  - Model complexity: Deeper DDTs capture more complex patterns but risk overfitting to noise
  - Cascade levels: More levels can improve accuracy but increase computational cost and may over-prune data

- Failure signatures:
  - Low support across all noise levels: Confidence threshold may be too high or noise too severe
  - Degrading accuracy with additional cascade levels: Models may be overfitting to noise in their respective subsets
  - DDTs consistently underperform MLPs: Hierarchical structure may not align with data patterns or regularization may be insufficient

- First 3 experiments:
  1. Train a single DDT on synthetic data with low noise ([0, 0.05]) and evaluate accuracy vs support
  2. Implement a two-level cascade with Gini threshold of 0.5 and compare performance to single model
  3. Test cascading approach on market data with varying noise levels to observe degradation patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can meta-learning or continual learning techniques be combined with cascading models via data-pruning to improve performance on unseen distributions?
- Basis in paper: [explicit] "Future work towards addressing this could be to employ meta-learning [7] or continual learning [8] techniques, combining these with the idea of using cascaded models via data-pruning as we have proposed."
- Why unresolved: The paper acknowledges that model performance degrades on unseen distributions but does not explore how meta-learning or continual learning could be integrated with the cascading approach.
- What evidence would resolve it: Experiments comparing cascading models with and without meta-learning/continual learning integration on unseen distributions.

### Open Question 2
- Question: How effective are cascaded models at handling label noise versus feature noise in financial market data?
- Basis in paper: [inferred] The paper focuses on noisy data but does not distinguish between label noise and feature noise, which could have different impacts on model performance.
- Why unresolved: The paper treats all noise similarly without investigating whether cascaded models are more or less effective against specific types of noise.
- What evidence would resolve it: Comparative experiments isolating label noise versus feature noise effects on cascaded versus non-cascaded models.

### Open Question 3
- Question: What is the optimal depth and number of levels for cascading differentiable decision trees in different market conditions?
- Basis in paper: [inferred] The paper uses a depth of 6 and 3 levels for cascading but does not explore how these hyperparameters affect performance across different market conditions.
- Why unresolved: The paper uses fixed hyperparameters without exploring their sensitivity or optimality for different market regimes.
- What evidence would resolve it: Systematic hyperparameter optimization experiments across different market volatility conditions.

### Open Question 4
- Question: How does the cascading approach scale to multi-class financial prediction problems beyond the binary buy/sell decisions explored?
- Basis in paper: [inferred] The experiments focus on binary classification problems, but financial markets often require multi-class predictions (e.g., hold, buy, sell).
- Why unresolved: The paper does not investigate whether cascading models maintain their advantages when extended to multi-class scenarios.
- What evidence would resolve it: Comparative experiments on multi-class financial prediction tasks using cascading versus non-cascading approaches.

## Limitations
- Limited scope of market data: Only Indian equity market data was tested, limiting generalizability to other markets or asset classes
- Synthetic data simplicity: The sine wave model may not capture the complex dynamics of real financial markets
- Single confidence metric: Gini impurity may not be optimal for financial time series where temporal dependencies are important

## Confidence
- Synthetic data results: High confidence - consistent improvements across all noise levels with clear performance metrics
- Real market data results: Medium confidence - variable performance across noise levels with limited market diversity
- DDT vs MLP comparison: Medium confidence - limited ablation studies and unclear impact of cascading architecture itself

## Next Checks
1. Cross-market validation: Test the cascading approach on US equity and cryptocurrency data to assess generalizability across different market structures
2. Alternative confidence metrics: Implement entropy-based uncertainty measures and compare their effectiveness against Gini impurity for financial prediction
3. Ensemble ablation: Compare cascading DDTs vs cascading MLPs vs single deep models to isolate the impact of the cascading architecture itself