---
ver: rpa2
title: Deep Imbalanced Learning for Multimodal Emotion Recognition in Conversations
arxiv_id: '2312.06337'
source_url: https://arxiv.org/abs/2312.06337
tags:
- data
- emotion
- cberl
- recognition
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of imbalanced data in multimodal
  emotion recognition in conversations (MERC), where certain emotion classes have
  very few samples, making it difficult for models to learn discriminative class boundaries.
  The proposed solution, CBERL, is a deep learning model that tackles this issue through
  three key strategies: data augmentation, loss sensitivity, and sampling strategy.'
---

# Deep Imbalanced Learning for Multimodal Emotion Recognition in Conversations

## Quick Facts
- arXiv ID: 2312.06337
- Source URL: https://arxiv.org/abs/2312.06337
- Authors: 
- Reference count: 40
- Key outcome: CBERL achieves significant improvements in emotion recognition accuracy and F1 score, particularly on minority classes like "fear" and "disgust", outperforming existing methods by 10% to 20%.

## Executive Summary
This paper addresses the problem of imbalanced data in multimodal emotion recognition in conversations (MERC), where certain emotion classes have very few samples, making it difficult for models to learn discriminative class boundaries. The proposed solution, CBERL, is a deep learning model that tackles this issue through three key strategies: data augmentation, loss sensitivity, and sampling strategy. CBERL employs a multimodal generative adversarial network to generate new samples, a deep joint variational autoencoder for cross-modal feature fusion, and a multi-task graph neural network with mask reconstruction and classification optimization. The model is evaluated on the IEMOCAP and MELD benchmark datasets, achieving significant improvements in emotion recognition accuracy and F1 score, particularly on minority classes like "fear" and "disgust", where it outperforms existing methods by 10% to 20%.

## Method Summary
CBERL is a deep learning model that addresses class imbalance in multimodal emotion recognition through data augmentation using a bidirectional GAN, multimodal feature fusion with DJVAE, context extraction using Bi-LSTM, graph interaction with MGNN, and emotion classification using Adaboost with focal loss. The model generates synthetic minority samples, fuses multimodal features using KL divergence, and employs a masking strategy in MGNN to prevent majority-class bias. It is trained on IEMOCAP and MELD datasets with weighted accuracy and F1-score as evaluation metrics.

## Key Results
- CBERL significantly improves weighted average accuracy (WAA) and weighted average F1-score (WAF1) on benchmark datasets.
- On the MELD dataset, CBERL achieves 25.0% WAA and 22.2% WAF1 for minority classes like "fear" and "disgust".
- The model outperforms existing methods by 10% to 20% on minority class recognition.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CBERL uses GAN-based data augmentation to generate synthetic minority samples.
- Mechanism: Bidirectional generator-discriminator pairs synthesize multimodal samples matching original data distribution, with identity and classification losses ensuring label alignment.
- Core assumption: GAN-generated samples are realistic and class-balanced.
- Evidence anchors: [abstract] "we first design a multimodal generative adversarial network to address the imbalanced distribution of emotion categories in raw data"; [section IV-B-1] "we will introduce the GAN method and optimize its loss function, adding the identity function as part of the loss function to enable the model to converge during training and generate new samples that conform to the original data distribution"
- Break condition: If generated samples do not match original distribution or introduce artifacts, model performance may degrade or overfit synthetic data.

### Mechanism 2
- Claim: DJV AE fuses multimodal features using KL divergence to capture complementary semantic information.
- Mechanism: DJV AE maps raw multimodal data into a latent space using KL divergence, estimating underlying distributions rather than point-wise reconstruction.
- Core assumption: KL divergence-based latent space estimation yields richer cross-modal semantic embeddings than simple concatenation or V AE.
- Evidence anchors: [abstract] "a deep joint variational autoencoder is proposed to fuse complementary semantic information across modalities"; [section IV-B-2] "we design a Deep Joint Variational Autoencoder... Different from simple V AE, which only performs point-to-point mapping of raw data, inspired by the idea of joint probability distribution, we introduce KL divergence to estimate the underlying distribution law of raw data"
- Break condition: If KL divergence estimation is inaccurate or multimodal features are too heterogeneous, the fused representation may lose discriminative power.

### Mechanism 3
- Claim: MGNN with mask reconstruction and classification optimizes class boundary learning for imbalanced data.
- Mechanism: MGNN randomly masks neighbor nodes during message passing to avoid over-reliance on majority class nodes, then jointly optimizes reconstruction and classification tasks.
- Core assumption: Random masking prevents majority-class bias in GCN aggregation, and joint optimization improves minority class learning.
- Evidence anchors: [abstract] "we implement a multi-task graph neural network with mask reconstruction and classification optimization to solve the problem of overfitting and underfitting in class boundary learning"; [section IV-B-4] "we propose a multi-task graph neural network model, named MGNN, to alleviate the problem of unbalanced distribution... performs two subtasks to improve the generalization ability of GCN: 1) data reconstruction; 2) emotion classification"
- Break condition: If masking is too aggressive or parameter sharing is suboptimal, model may underfit or lose discriminative capacity.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: GANs provide a principled way to synthesize realistic minority-class samples, balancing class distribution without manual labeling.
  - Quick check question: How does adding identity and classification losses help GAN convergence in this multimodal context?

- Concept: Variational Autoencoders (VAEs) and KL Divergence
  - Why needed here: KL divergence-based latent space estimation preserves inter-modal semantic differences, improving discriminative feature fusion over naive concatenation.
  - Quick check question: Why does KL divergence improve over point-wise MSE reconstruction in multimodal fusion?

- Concept: Graph Neural Networks with Masking Strategies
  - Why needed here: Masking prevents GCN from over-relying on majority class neighbors, ensuring minority class nodes are adequately represented in aggregated embeddings.
  - Quick check question: How does random node masking in message passing mitigate majority-class bias?

## Architecture Onboarding

- Component map: Data Augmentation (GAN) → DJV AE → Bi-LSTM → MGNN → Classification
- Critical path: Data Augmentation → DJV AE → Bi-LSTM → MGNN → Classification
- Design tradeoffs:
  - Data augmentation adds computational overhead but improves minority class performance.
  - Masking in MGNN may reduce neighbor aggregation quality if too aggressive.
  - Joint optimization of reconstruction and classification can improve generalization but increases training complexity.
- Failure signatures:
  - If minority class performance does not improve after augmentation, check GAN sample quality.
  - If W AA and W AF1 diverge significantly, masking may be too aggressive or parameter sharing suboptimal.
  - If training loss plateaus early, KL divergence estimation or GAN convergence may be unstable.
- First 3 experiments:
  1. Run CBERL without data augmentation to quantify GAN impact.
  2. Remove masking in MGNN to test majority-class bias mitigation.
  3. Replace DJV AE with simple concatenation to evaluate KL divergence contribution.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the performance of CBERL be improved for minority emotion classes like "fear" and "disgust" in multimodal emotion recognition in conversations?
- Basis in paper: [explicit] The paper highlights that CBERL significantly improves performance on minority classes "fear" and "disgust", achieving 25.0% and 22.2% values on W AA and W AF1 respectively on the MELD dataset.
- Why unresolved: While the paper shows improvement, it does not provide a detailed analysis of how to further optimize the model for these specific classes or explore alternative strategies to enhance performance.
- What evidence would resolve it: Conducting additional experiments with different hyperparameters, loss functions, or data augmentation techniques specifically tailored for minority classes, and comparing the results with the current CBERL model.

### Open Question 2
- Question: Can the data augmentation module be further optimized to generate more diverse and representative samples for minority emotion classes?
- Basis in paper: [explicit] The paper mentions that the data augmentation module can balance the data distribution among different emotion categories, but it does not explore the potential of optimizing the module to generate more diverse samples.
- Why unresolved: The paper does not provide a detailed analysis of how the data augmentation module can be fine-tuned to generate more representative samples for minority classes, which could potentially lead to better performance.
- What evidence would resolve it: Conducting experiments with different data augmentation techniques, such as conditional GANs or variational autoencoders, and comparing the generated samples' diversity and representativeness with the current module.

### Open Question 3
- Question: How does the masking strategy in the graph neural network affect the model's ability to learn unbiased representations of minority class nodes?
- Basis in paper: [explicit] The paper introduces a masking strategy to overcome overfitting or underfitting problems of the random sampling strategy in GNN to minority class samples, but it does not provide a detailed analysis of how the masking strategy affects the model's performance.
- Why unresolved: The paper does not explore the impact of different masking strategies or the optimal masking rate on the model's ability to learn unbiased representations of minority class nodes.
- What evidence would resolve it: Conducting experiments with different masking strategies, such as varying the masking rate or using different masking patterns, and analyzing the impact on the model's performance and the learned representations of minority class nodes.

## Limitations

- The effectiveness of GAN-generated samples is highly dependent on training stability and sample quality, yet the paper does not provide detailed analysis of GAN convergence or sample fidelity metrics.
- The KL divergence-based feature fusion assumes that the underlying distributions of multimodal data can be accurately estimated, but this may not hold for heterogeneous or noisy data.
- The mask reconstruction strategy in MGNN relies on random neighbor masking, but the optimal masking ratio and strategy are not thoroughly explored.

## Confidence

- **High Confidence**: The paper demonstrates clear improvements in weighted accuracy and F1 scores on benchmark datasets, particularly for minority classes. The overall architecture and evaluation metrics are well-defined.
- **Medium Confidence**: The proposed mechanisms (GAN augmentation, DJV AE fusion, mask reconstruction) are theoretically sound, but their individual contributions are not isolated through ablation studies. The paper lacks detailed analysis of hyperparameter sensitivity.
- **Low Confidence**: The paper does not provide sufficient evidence for the long-term generalization of the model across different datasets or real-world applications. The impact of class imbalance on minority classes is only partially addressed.

## Next Checks

1. **GAN Sample Quality Analysis**: Conduct a detailed analysis of the quality and diversity of GAN-generated samples. Evaluate whether the generated samples match the original data distribution and whether they introduce artifacts or bias.
2. **Ablation Study of Masking Strategy**: Perform an ablation study to determine the optimal masking ratio and strategy in MGNN. Test the model with different masking rates and compare performance on minority vs. majority classes.
3. **Cross-Dataset Generalization**: Evaluate the model on additional datasets beyond IEMOCAP and MELD to assess its generalization capability. Test the model on datasets with different class distributions and noise levels to validate robustness.