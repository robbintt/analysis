---
ver: rpa2
title: Rethinking Radiology Report Generation via Causal Inspired Counterfactual Augmentation
arxiv_id: '2311.13307'
source_url: https://arxiv.org/abs/2311.13307
tags:
- report
- counterfactual
- sentence
- which
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses a fundamental issue in radiology report generation
  (RRG): the spurious confounder of disease co-occurrence caused by biased data distributions.
  The authors argue that while co-occurrence relationships between diseases are commonly
  used to improve the linguistic consistency of generated reports, they actually decrease
  the accuracy of the reports.'
---

# Rethinking Radiology Report Generation via Causal Inspired Counterfactual Augmentation

## Quick Facts
- arXiv ID: 2311.13307
- Source URL: https://arxiv.org/abs/2311.13307
- Reference count: 40
- Key outcome: Counterfactual augmentation method significantly improves accuracy and generalization of RRG models by breaking spurious co-occurrence patterns

## Executive Summary
This paper addresses a fundamental issue in radiology report generation (RRG): the spurious confounder of disease co-occurrence caused by biased data distributions. The authors argue that while co-occurrence relationships between diseases are commonly used to improve the linguistic consistency of generated reports, they actually decrease the accuracy of the reports. They identify two aspects of this spurious coupling: the Joint Vision Coupling (Cj) which causes one-to-many visual feature to disease label mappings, and the Conditional Sentence Coherence Coupling (Cc) which introduces spurious coherence between sentences. To address these issues, the authors propose a counterfactual augmentation method that includes two sub-methods: the Prototype-based Counterfactual Sample Synthesis (P-CSS) which randomly masks visual features and their corresponding sentences, and the Magic-Cube-like Counterfactual Report Reconstruction (Cube) which randomly disrupts the order of sentences in the reports. Experimental results on the MIMIC-CXR and IU X-Ray datasets demonstrate that their method significantly improves the accuracy and generalization of RRG models, with CE metrics (Accuracy, Precision, Recall, F1-score) showing substantial improvements compared to baseline models and state-of-the-art methods.

## Method Summary
The method involves a counterfactual augmentation approach for RRG that targets two spurious confounders: Joint Vision Coupling (Cj) and Conditional Sentence Coherence Coupling (Cc). The approach consists of two main components: Prototype-based Counterfactual Sample Synthesis (CSS) that randomly masks binary features and their corresponding sentences, and Counterfactual Report Reconstruction (CRR) that randomly reorders sentences in reports. The method is evaluated on MIMIC-CXR and IU X-Ray datasets using both Clinical Efficacy (CE) metrics and Natural Language Generation (NLG) metrics. The implementation requires a binary feature extraction model using ResNet-101 pre-trained on ImageNet, along with the counterfactual augmentation modules applied during training.

## Key Results
- CE metrics (Accuracy, Precision, Recall, F1-score) show substantial improvements compared to baseline models and state-of-the-art methods
- The method significantly improves the accuracy and generalization of RRG models on both MIMIC-CXR and IU X-Ray datasets
- NLG metrics (BLEU-4, ROUGE-L, METEOR) may decrease due to disrupted sentence coherence, which is expected and acceptable given the focus on accuracy over linguistic consistency

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The Joint Vision Coupling (Cj) is a spurious confounder that causes one-to-many visual feature to disease label mappings, decreasing report accuracy.
- **Mechanism**: Cj introduces indirect backdoor paths from radiographs (X) to generated reports (Y) through spurious co-occurrence relationships (C_j) via intermediate recognition results (F). This causes models to learn spurious correlations between visual features and disease labels rather than causal relationships.
- **Core assumption**: Disease co-occurrence patterns in training data reflect sampling bias rather than true clinical relationships, and these patterns conform to Simpson's paradox.
- **Evidence anchors**:
  - [abstract]: "the independence between diseases-a specific property of RRG-was neglected, yielding the models being confused by the co-occurrence of diseases brought on by the biased data distribution, thus generating inaccurate reports"
  - [section]: "Cj implicitly effects the recognition process... However, as aforementioned, each sentence in the RRG report independently describes certain types of diseases... there should be no sequence order between sentences in the free-text reports"
  - [corpus]: Weak evidence - related papers focus on RRG methods but don't explicitly discuss Cj as a confounder
- **Break condition**: When training data distribution no longer exhibits Simpson's paradox patterns for disease co-occurrence, or when models can perfectly distinguish between causal and spurious correlations.

### Mechanism 2
- **Claim**: The Conditional Sentence Coherence Coupling (Cc) introduces spurious coherence between sentences, breaking the independence assumption of RRG reports.
- **Mechanism**: Cc acts as a confounder during the report generation process, creating backdoor paths through previously generated tokens that cause conditional dependencies between sentences. This leads to generation of sentences based on preceding sentences rather than the visual input and ground truth.
- **Core assumption**: Each sentence in a radiology report should independently describe certain types of diseases without sequence order, but models learn spurious inter-sentence coherence from training data.
- **Evidence anchors**:
  - [abstract]: "the Conditional Sentence Coherence Coupling (Cc) which introduces spurious coherence between sentences"
  - [section]: "This spurious sentence coherence coupling Cc was injected previously for improving the consistency, which leads to the spurious co-occurrence of diseases in certain attributes"
  - [corpus]: Weak evidence - related papers mention report consistency but don't explicitly discuss Cc as a confounder
- **Break condition**: When sentence order no longer influences generation quality, or when evaluation metrics properly account for sentence independence.

### Mechanism 3
- **Claim**: Counterfactual augmentation through CSS and CRR breaks the backdoor paths introduced by Cj and Cc, improving model accuracy and generalization.
- **Mechanism**: CSS randomly masks visual features and their corresponding sentences, forcing models to learn independent visual-disease relationships. CRR randomly disrupts sentence order, forcing models to generate sentences based on visual input rather than learned coherence patterns. Together, they intervene on the backdoor paths created by Cj and Cc.
- **Core assumption**: Random masking and reordering operations can effectively break spurious correlations while preserving essential causal information needed for accurate report generation.
- **Evidence anchors**:
  - [abstract]: "Experimental results on the MIMIC-CXR and IU X-Ray datasets demonstrate that their method significantly improves the accuracy and generalization of RRG models"
  - [section]: "we propose an easy-but-effective general counterfactual augmentation method that contains two strategies, i.e. the Prototype-based Counterfactual Sample Synthesis (P-CSS) and the Magic-Cube-like Counterfactual Report Reconstruction (Cube), to intervene the backdoor paths"
  - [corpus]: Weak evidence - related papers mention augmentation but don't discuss the specific counterfactual approach for breaking Cj and Cc
- **Break condition**: When augmentation operations no longer improve accuracy metrics, or when they introduce too much noise that degrades performance.

## Foundational Learning

- **Concept**: Simpson's paradox and confounding bias
  - Why needed here: Understanding why disease co-occurrence patterns in RRG data create spurious correlations that hurt model accuracy
  - Quick check question: If disease A and B co-occur in 80% of cases overall, but only co-occur in 20% of cases when conditioned on disease C, what type of statistical phenomenon is this?

- **Concept**: Causal graphs and backdoor paths
  - Why needed here: Modeling how spurious confounders like Cj and Cc create indirect paths between input and output that models can exploit incorrectly
  - Quick check question: In a causal graph where X → Y and X ← C → Y, what role does C play and how does it affect the relationship between X and Y?

- **Concept**: Counterfactual reasoning and data augmentation
  - Why needed here: Understanding how randomly masking features and reordering sentences can break spurious correlations while preserving causal information
  - Quick check question: If we randomly mask 50% of disease labels and their corresponding visual features during training, what effect should this have on a model's reliance on spurious co-occurrence patterns?

## Architecture Onboarding

- **Component map**: Binary Feature Extractor -> Counterfactual Sample Synthesis -> Base RRG Model -> Counterfactual Report Reconstruction -> Generated Report
- **Critical path**: Image → Binary Feature Extraction → Counterfactual Sample Synthesis → Base RRG Model → Counterfactual Report Reconstruction → Generated Report
- **Design tradeoffs**:
  - Augmentation rate vs. information preservation: Higher rates break more spurious correlations but risk losing essential information
  - Feature masking strategy: Binary features vs. raw pixels - binary features are more interpretable but may lose fine-grained information
  - Sentence reconstruction vs. token-level reconstruction: Sentence-level is computationally efficient but may not break all spurious coherence patterns
- **Failure signatures**:
  - CE metrics improve but NLG metrics decline significantly (expected due to breaking sentence coherence)
  - Performance degrades when augmentation rate exceeds certain threshold
  - Models become unstable during training with high augmentation rates
- **First 3 experiments**:
  1. Baseline RRG model without augmentation on MIMIC-CXR dataset, measuring CE and NLG metrics
  2. RRG model with CSS only, varying augmentation rate from 0% to 100%, measuring impact on CE metrics
  3. RRG model with both CSS and CRR, comparing CE metrics to baseline and CSS-only variants, testing on both MIMIC-CXR and IU X-Ray datasets for generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different confounding patterns in various medical imaging datasets affect the generalizability of the proposed counterfactual augmentation method?
- Basis in paper: [inferred] The paper mentions evaluating the method on two datasets (MIMIC-CXR and IU X-Ray) but suggests future work on analyzing how different data distributions impact performance.
- Why unresolved: The study only examined two datasets with potentially different confounding structures, limiting understanding of the method's robustness across diverse medical imaging domains.
- What evidence would resolve it: Comparative studies across multiple medical imaging datasets with varying confounding patterns, analyzing the method's performance consistency and required adaptations.

### Open Question 2
- Question: Can the proposed causal framework be extended to handle multi-modal medical data beyond radiology, such as combining radiology with pathology or genomic data?
- Basis in paper: [inferred] The paper focuses on radiology report generation but discusses causal effects in a general way that could apply to other medical domains.
- Why unresolved: The method was developed and tested specifically for radiology images and reports, without exploring its applicability to other medical data types or multi-modal integration.
- What evidence would resolve it: Successful application and validation of the method on other medical imaging modalities and integration studies combining multiple data sources.

### Open Question 3
- Question: What is the optimal balance between counterfactual augmentation rates and model performance across different RRG tasks and datasets?
- Basis in paper: [explicit] The paper mentions exploring different augmentation rates but doesn't provide a systematic analysis of the optimal trade-off.
- Why unresolved: The study only tested a limited range of augmentation rates (25%, 50%, 75%, 100%) without exploring the full spectrum or developing a principled approach to rate selection.
- What evidence would resolve it: Systematic experiments varying augmentation rates across different tasks and datasets, potentially coupled with theoretical analysis of the optimal rate determination.

## Limitations
- The paper doesn't provide rigorous statistical validation that disease co-occurrence patterns actually conform to Simpson's paradox
- The assumption that all sentence coherence patterns are spurious rather than clinically meaningful is not empirically verified
- The method's performance on datasets with different co-occurrence patterns or clinical contexts is unclear, limiting generalizability claims

## Confidence
- **High Confidence**: The identification of disease co-occurrence as a potential confounder and the general intuition that spurious correlations can hurt model accuracy
- **Medium Confidence**: The specific characterization of Cj and Cc as the primary confounders, and the effectiveness of CSS and CRR in breaking these backdoor paths
- **Low Confidence**: The causal graphs' completeness and the assumption that all sentence coherence patterns are spurious rather than clinically meaningful

## Next Checks
1. **Statistical Validation of Simpson's Paradox**: Analyze the MIMIC-CXR dataset to quantify the degree to which disease co-occurrence patterns conform to Simpson's paradox. Compute conditional vs. unconditional co-occurrence rates for multiple disease pairs to empirically validate the spurious confounder claim.

2. **Causal Graph Sensitivity Analysis**: Systematically test the impact of different causal graph structures on model performance. For instance, compare performance when allowing some sentence coherence (vs. complete independence) or when modeling different types of backdoor paths between visual features and generated reports.

3. **Clinical Expert Evaluation**: Conduct a blind evaluation with radiologists comparing reports generated by baseline models versus the counterfactual augmentation method. Assess whether accuracy improvements in CE metrics translate to clinically meaningful improvements in report quality and diagnostic utility.