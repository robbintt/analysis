---
ver: rpa2
title: Fair Text Classification with Wasserstein Independence
arxiv_id: '2311.12689'
source_url: https://arxiv.org/abs/2311.12689
tags:
- fairness
- sensitive
- attributes
- wasserstein
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to improve fairness in text classification
  by minimizing the mutual information between model predictions and sensitive attributes
  using Wasserstein distance. The approach uses a pre-trained "demonic" model to predict
  sensitive attributes and a critic to enforce independence between representations
  for target prediction and sensitive attribute prediction.
---

# Fair Text Classification with Wasserstein Independence

## Quick Facts
- arXiv ID: 2311.12689
- Source URL: https://arxiv.org/abs/2311.12689
- Authors: 
- Reference count: 25
- Key outcome: Improves fairness in text classification by minimizing mutual information between predictions and sensitive attributes using Wasserstein distance, achieving better fairness-accuracy trade-offs without requiring sensitive attribute labels during training or inference.

## Executive Summary
This paper introduces a novel approach to fair text classification that leverages Wasserstein distance to minimize mutual information between model predictions and sensitive attributes. The method uses a pre-trained "demonic" model to predict sensitive attributes and a critic network to enforce independence between representations for target prediction and sensitive attribute prediction. The approach achieves state-of-the-art fairness metrics while maintaining competitive accuracy on benchmark datasets, and uniquely does not require sensitive attribute labels during training or inference, making it more practical for real-world deployment.

## Method Summary
The method employs a three-component architecture consisting of a frozen BERT encoder, a classification model, and a "demonic" model that predicts sensitive attributes. A critic network estimates the Wasserstein-1 distance between the joint distribution of classification and sensitive attribute representations and their product of marginals. This Wasserstein distance serves as a regularization term in the classification loss, encouraging independence between the representations. The demonic model is pre-trained separately and provides sensitive attribute representations without requiring sensitive attribute labels during the main model's training, enabling fairness enforcement without access to sensitive attribute annotations.

## Key Results
- Achieves superior fairness-accuracy trade-offs on Moji dataset, outperforming baselines on GAP fairness metric while maintaining comparable accuracy
- Demonstrates competitive results on Bios dataset with better GAP and Leakage metrics than baseline methods
- Shows that last hidden layer representations provide optimal trade-off between fairness and accuracy compared to intermediate layers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Minimizing mutual information between representation vectors (zy, zs) using Wasserstein distance enforces independence between target prediction and sensitive attributes.
- Mechanism: The critic network estimates the Wasserstein-1 distance between the joint distribution p(zy, zs) and the product of marginals p(zy)p(zs), creating a regularization term that penalizes dependence. During training, this encourages the classification representation zy to avoid encoding information about the sensitive attribute zs.
- Core assumption: The Wasserstein distance between joint and product distributions is a valid proxy for mutual information, and this can be effectively estimated using a neural network critic.
- Evidence anchors:
  - [abstract]: "we take inspiration from adversarial training to induce Wasserstein independence between representations learned to predict our target label and the ones learned to predict some sensitive attribute"
  - [section 3.3]: "Fairness can therefore be cast as MI minimization between ŷ, our prediction (conditioned on y, the ground-truth or not), and s, the sensitive attribute"
  - [corpus]: Weak evidence - no direct citations about Wasserstein-based fairness approaches

### Mechanism 2
- Claim: Pre-training a "demonic" model on sensitive attributes allows fairness enforcement without requiring sensitive attribute labels during main model training.
- Mechanism: The demonic model is trained separately to predict sensitive attributes from text, creating zs representations. During main model training, the critic enforces independence between zs and zy, ensuring the classification model doesn't learn sensitive attribute information from these representations, even without access to the actual sensitive labels.
- Core assumption: The demonic model learns meaningful representations of sensitive attributes that can be used to enforce independence in the main model's representations.
- Evidence anchors:
  - [abstract]: "it does not require annotations of sensitive attributes in both testing and training data"
  - [section 4.2]: "Unlike previous works (Caton and Haas, 2020), we require only limited access to sensitive attributes label at training and we do not need access to the labeling of sensitive attributes in the inference regime"
  - [corpus]: Weak evidence - no direct citations about pre-trained adversarial models for fairness

### Mechanism 3
- Claim: Using last hidden layer representations provides optimal trade-off between fairness and accuracy compared to intermediate representations.
- Mechanism: The last hidden layer contains the most refined representation before classification, balancing sufficient information for prediction while being amenable to independence enforcement. Earlier layers may retain too much sensitive information, while later layers (like logits) may have lost too much information for effective Wasserstein estimation.
- Core assumption: The last hidden layer representation strikes the right balance between containing predictive information and being modifiable for fairness.
- Evidence anchors:
  - [section 6.3]: "On both datasets (Table 3b), accuracy is rather stable regardless of the layers used to compute the Wasserstein distance. Still, the best results are obtained using the last hidden representations"
  - [corpus]: Weak evidence - no direct citations about layer selection for fairness

## Foundational Learning

- Concept: Wasserstein distance and its dual formulation
  - Why needed here: The Wasserstein distance is used as a smooth, theoretically sound alternative to mutual information for measuring dependence between distributions
  - Quick check question: How does the Kantorovich-Rubinstein duality allow Wasserstein distance to be estimated using a neural network critic?

- Concept: Mutual information and its relationship to independence
  - Why needed here: Fairness is framed as minimizing mutual information between predictions and sensitive attributes, requiring understanding of information-theoretic measures
  - Quick check question: Why does minimizing MI(zy, zs) ≥ MI(ŷ, ŝ) help achieve fairness in predictions?

- Concept: Adversarial training and independence enforcement
  - Why needed here: The method uses adversarial-style training where a critic enforces independence between representations from different tasks
  - Quick check question: How does the critic's objective of maximizing the Wasserstein distance between dependent and independent samples help enforce independence in the main model?

## Architecture Onboarding

- Component map: BERT -> demonic model -> zs, classification model -> zy, critic processes [zs, zy] and [zs_shuffled, zy] to estimate Wasserstein distance, this becomes a regularization term in the classification loss
- Critical path: BERT → demonic model → zs, classification model → zy, critic processes [zs, zy] and [zs_shuffled, zy] to estimate Wasserstein distance, this becomes a regularization term in the classification loss
- Design tradeoffs: Using Wasserstein distance instead of KL divergence provides smoother gradients and better scalability, but requires careful critic training. Pre-training the demonic model enables training without sensitive attributes but may limit adaptation to specific datasets
- Failure signatures: If the critic fails to approximate Wasserstein distance accurately, the regularization term becomes ineffective. If the demonic model doesn't capture sensitive attributes well, independence enforcement fails. If β is too high, accuracy drops; if too low, fairness gains are minimal
- First 3 experiments:
  1. Train with β=0 (no regularization) to establish baseline accuracy
  2. Train with moderate β and monitor both accuracy and fairness metrics
  3. Vary which layer's representations are used for Wasserstein computation to find optimal layer

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method scale to continuous sensitive attributes (e.g., age) rather than binary attributes?
- Basis in paper: [explicit] The authors acknowledge this as a limitation, noting they couldn't assess performance for continuous attributes due to lack of available datasets.
- Why unresolved: The paper focuses on binary sensitive attributes due to dataset availability, but doesn't explore or provide methods for continuous attributes.
- What evidence would resolve it: Experiments demonstrating the method's effectiveness on datasets with continuous sensitive attributes, along with any necessary modifications to the approach.

### Open Question 2
- Question: What are the theoretical guarantees for the effectiveness of pre-training the demonic model on different datasets?
- Basis in paper: [explicit] The authors mention this as a limitation, stating they don't provide sufficient generalization guarantees for large-scale deployment.
- Why unresolved: While the paper shows empirical success in transferring the demonic model, it lacks theoretical analysis of when and why this transfer works.
- What evidence would resolve it: Formal theoretical analysis establishing conditions under which pre-training on different datasets maintains or improves fairness performance.

### Open Question 3
- Question: Does representational fairness (as measured by the proposed method) guarantee empirical fairness in downstream tasks?
- Basis in paper: [explicit] The authors reference Shen et al. (2022a) who ask "Does representational fairness imply empirical fairness?" and note this remains an open question.
- Why unresolved: The paper demonstrates improved fairness metrics but doesn't establish a direct causal relationship between improved representations and improved task-specific fairness outcomes.
- What evidence would resolve it: Systematic experiments showing consistent alignment between improvements in representational fairness and improvements in task-specific fairness metrics across diverse datasets and tasks.

## Limitations
- The method requires pre-training a high-accuracy demonic model (99% for Bios, 88.5% for Moji) which may not be achievable on all sensitive attributes
- The bidirectional objective function optimization introduces complexity that may affect stability across different architectures
- The approach assumes that last hidden layer representations are optimal for all tasks, which may not generalize to different model architectures

## Confidence
- High confidence in the theoretical framework and mathematical formulation of Wasserstein independence for fairness
- Medium confidence in the empirical results due to potential dataset-specific optimizations
- Low confidence in the scalability claims without extensive large-scale validation

## Next Checks
1. Test the method on additional datasets with different sensitive attributes (e.g., age, religion) to verify generalizability of the demonic model approach
2. Conduct ablation studies on the critic network architecture to determine minimum requirements for effective Wasserstein distance estimation
3. Evaluate the method's performance when the demonic model accuracy drops to realistic levels (70-80%) rather than the near-perfect performance reported