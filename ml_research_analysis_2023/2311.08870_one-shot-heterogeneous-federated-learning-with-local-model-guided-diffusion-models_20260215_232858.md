---
ver: rpa2
title: One-Shot Heterogeneous Federated Learning with Local Model-Guided Diffusion
  Models
arxiv_id: '2311.08870'
source_url: https://arxiv.org/abs/2311.08870
tags:
- client
- diffusion
- images
- noise
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes FedLMG, a heterogeneous one-shot federated learning
  method that leverages local model-guided diffusion models. The key idea is to use
  locally trained client models to guide a server-side diffusion model in generating
  synthetic datasets that comply with client distributions, eliminating the need for
  foundation models on client devices.
---

# One-Shot Heterogeneous Federated Learning with Local Model-Guided Diffusion Models

## Quick Facts
- **arXiv ID:** 2311.08870
- **Source URL:** https://arxiv.org/abs/2311.08870
- **Reference count:** 30
- **Key outcome:** Proposed FedLMG method generates synthetic datasets that enable aggregated models to outperform baselines and surpass traditional FL performance ceilings in some cases.

## Executive Summary
This paper introduces FedLMG, a novel one-shot federated learning approach that addresses the computational burden on client devices by leveraging locally trained client models to guide a server-side diffusion model in generating synthetic datasets. Unlike existing methods that require foundation models on clients, FedLMG only needs client classifiers, significantly reducing client-side computation while effectively handling heterogeneous client models. The method demonstrates superior performance across three large-scale real-world datasets, with the aggregated model trained on synthetic data outperforming all compared methods and even surpassing traditional FL performance ceilings in some cases.

## Method Summary
FedLMG operates by having clients train local classifiers and upload them to the server, which then uses these classifiers to guide a pre-trained diffusion model in generating synthetic datasets that comply with client distributions. The server employs both classification loss and batch normalization (BN) statistics from client classifiers to guide the diffusion model, with an initial noise editing step to improve generation stability. The generated synthetic datasets are then used to train an aggregated model using various aggregation strategies including fine-tuning, multi-teacher distillation, and specific-teacher distillation. This approach eliminates the need for foundation models on client devices while maintaining high-quality synthetic data generation.

## Key Results
- FedLMG generates synthetic datasets with comparable quality and diversity to original client datasets
- The aggregated model trained on synthetic datasets outperforms all compared methods
- In some cases, FedLMG surpasses the performance ceiling of traditional federated learning approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Local client classifiers guide diffusion model generation to create synthetic datasets that match client distributions.
- **Mechanism:** The server-side diffusion model uses gradients from client classifiers (via cross-entropy and BN statistics) to edit initial noise and iteratively denoise into realistic images.
- **Core assumption:** Client classifiers capture sufficient distributional and semantic information about local data to guide synthesis.
- **Evidence anchors:**
  - [abstract]: "clients do not need access to any foundation models but only train and upload their local models"
  - [section]: "we employ classification loss and BN loss to capture the broad category features and detailed contextual features of the client distributions"
  - [corpus]: Weak; no direct comparison to diffusion-guided synthesis in other FL works.
- **Break condition:** If client classifiers are too weak or biased, synthetic data will misrepresent client distributions.

### Mechanism 2
- **Claim:** Initial noise editing improves generation stability and quality.
- **Mechanism:** Before diffusion denoising, initial noise is iteratively edited using classifier gradients for M steps to embed semantic and distributional information.
- **Core assumption:** Embedding information early reduces the complexity of subsequent denoising steps.
- **Evidence anchors:**
  - [abstract]: "we utilize backpropagation to guide the server's DM in generating synthetic datasets that comply with the client distributions"
  - [section]: "we incorporate a step of initial noise editing before the diffusion denoising process"
  - [corpus]: No direct corpus evidence; assumption based on cited work (Mao et al. 2023).
- **Break condition:** If M is too small, insufficient editing occurs; if too large, noise may overfit classifier bias.

### Mechanism 3
- **Claim:** Synthetic datasets enable aggregation models to surpass performance ceilings of traditional FL.
- **Mechanism:** Generated data, enriched by pre-trained diffusion model knowledge, supplements limited client data, allowing models to learn beyond client samples.
- **Core assumption:** Pre-trained diffusion models contain generalizable knowledge that transfers to client-specific synthesis.
- **Evidence anchors:**
  - [abstract]: "the aggregated model trained on these synthetic datasets outperforms all compared methods and even surpasses the performance ceiling in some cases"
  - [section]: "the FL methods hold the potential to surpass this ceiling"
  - [corpus]: Weak; no corpus evidence of diffusion models breaking FL ceilings.
- **Break condition:** If diffusion model knowledge is irrelevant or biased, synthetic data may mislead rather than help.

## Foundational Learning

- **Concept:** Diffusion models and denoising process
  - **Why needed here:** The server uses a pre-trained diffusion model to generate synthetic data based on client classifier guidance.
  - **Quick check question:** Can you explain the forward and reverse processes in diffusion models and how classifier guidance modifies the sampling?

- **Concept:** Batch normalization statistics as distributional cues
  - **Why needed here:** BN mean/variance statistics from client classifiers provide fine-grained distribution information beyond class labels.
  - **Quick check question:** How do BN statistics reflect data distribution, and why are they useful for guiding synthetic data generation?

- **Concept:** One-shot federated learning aggregation strategies
  - **Why needed here:** FedLMG uses fine-tuning, multi-teacher distillation, and specific-teacher distillation to form the final model from synthetic data.
  - **Quick check question:** What are the differences between these aggregation strategies, and when is each most appropriate?

## Architecture Onboarding

- **Component map:** Clients (train classifier → upload) → Server (diffusion model + classifier guidance → synthetic data generation → model aggregation)
- **Critical path:** Upload classifiers → Generate synthetic dataset → Train aggregated model → Evaluate
- **Design tradeoffs:** No foundation models on clients reduces computation but requires careful guidance; synthetic data quality depends on classifier strength
- **Failure signatures:** Poor synthetic data quality (misaligned semantics/distributions), weak aggregated model performance, high variance across runs
- **First 3 experiments:**
  1. Generate synthetic data using a simple classifier (e.g., ResNet18) and verify image quality/compliance with known client data.
  2. Test aggregation using fine-tuning only and compare performance to baseline FedAvg.
  3. Vary M (initial noise editing steps) and λ (BN loss weight) to find optimal hyperparameters.

## Open Questions the Paper Calls Out

- **Open Question 1:** How does FedLMG perform on extremely heterogeneous client models where architectures vary significantly (e.g., CNN vs transformer)?
  - **Basis in paper:** [inferred] The paper demonstrates FedLMG works with moderate heterogeneity (MobileNetV3, ResNet18, ResNet34, MobileNetV2, VGG16, ShuffleNet) but doesn't test extreme architectural differences.
  - **Why unresolved:** The paper only tests moderate heterogeneity and doesn't explore the performance limits when client models have fundamentally different architectures.
  - **What evidence would resolve it:** Experiments testing FedLMG with client models having vastly different architectures (CNN, transformer, MLP) would show whether the method's performance degrades significantly or remains stable.

- **Open Question 2:** What is the impact of varying the number of synthetic images per category (currently fixed at 30) on final model performance?
  - **Basis in paper:** [inferred] The paper uses a fixed number of 30 synthetic images per category but doesn't explore how performance scales with different amounts of synthetic data.
  - **Why unresolved:** The paper doesn't conduct experiments varying the quantity of synthetic data to determine if there's an optimal amount or if performance plateaus.
  - **What evidence would resolve it:** Systematic experiments varying the number of synthetic images per category (e.g., 5, 15, 30, 60, 120) would show the relationship between synthetic data quantity and final model performance.

- **Open Question 3:** How does FedLMG handle scenarios where clients have overlapping but non-identical label spaces?
  - **Basis in paper:** [inferred] The paper tests feature distribution skew and label distribution skew separately, but doesn't test scenarios where clients have partially overlapping label spaces.
  - **Why unresolved:** Real-world federated learning scenarios often involve clients with partially overlapping label spaces, which isn't explicitly tested in the paper.
  - **What evidence would resolve it:** Experiments where clients have partially overlapping label sets (e.g., some categories in common, some unique to each client) would show how well FedLMG handles this more realistic scenario.

## Limitations
- The effectiveness of classifier guidance lacks strong corpus validation and comparative analysis with other guidance methods.
- Claims about surpassing FL performance ceilings are speculative without rigorous theoretical or empirical justification.
- The method's generalization to real-world data heterogeneity (concept drift, domain shifts) is not thoroughly tested.

## Confidence
- **Medium:** The core mechanism (using client classifiers to guide diffusion models) is plausible and technically sound, but lacks empirical validation beyond controlled experiments.
- **Low:** Claims about surpassing FL performance ceilings are speculative and not rigorously justified with theoretical or empirical evidence.
- **Medium:** The reduction in client computational requirements is straightforward but depends on the strength of client classifiers, which is not thoroughly evaluated.

## Next Checks
1. **Ablation study:** Remove BN statistics guidance and compare synthetic data quality and aggregated model performance to isolate the contribution of each guidance component.
2. **Robustness test:** Evaluate FedLMG on datasets with concept drift or severe domain shifts to assess generalization beyond controlled settings.
3. **Efficiency analysis:** Measure the trade-off between classifier strength (model size/complexity) and synthetic data quality to quantify the practical computational savings on clients.