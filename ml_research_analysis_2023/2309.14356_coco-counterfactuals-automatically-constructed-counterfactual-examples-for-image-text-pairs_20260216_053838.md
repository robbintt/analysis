---
ver: rpa2
title: 'COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for
  Image-Text Pairs'
arxiv_id: '2309.14356'
source_url: https://arxiv.org/abs/2309.14356
tags:
- dataset
- counterfactual
- data
- image
- coco-counterfactuals
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces COCO-Counterfactuals, a dataset of multimodal
  counterfactual examples automatically generated from MS-COCO captions using text-to-image
  diffusion models. The method works by minimally editing captions and then using
  Prompt-to-Prompt Stable Diffusion to generate paired images with only the counterfactual
  change.
---

# COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs

## Quick Facts
- arXiv ID: 2309.14356
- Source URL: https://arxiv.org/abs/2309.14356
- Reference count: 6
- Primary result: Dataset of automatically generated multimodal counterfactual examples showing improved out-of-domain generalization when used for training data augmentation

## Executive Summary
This paper introduces COCO-Counterfactuals, a dataset of multimodal counterfactual examples automatically generated from MS-COCO captions using text-to-image diffusion models. The method works by minimally editing captions and then using Prompt-to-Prompt Stable Diffusion to generate paired images with only the counterfactual change. Human evaluation showed 73% accuracy in matching generated images to their correct captions. The dataset was shown to be challenging for state-of-the-art multimodal models on zero-shot image-text retrieval and matching tasks. Training data augmentation with COCO-Counterfactuals improved out-of-domain generalization on Flickr30k for image-text retrieval and on multiple image recognition datasets.

## Method Summary
COCO-Counterfactuals generates multimodal counterfactual examples by first editing MS-COCO captions through minimal noun substitution using masked language modeling, then generating paired images with Stable Diffusion using Prompt-to-Prompt cross-attention control to preserve non-causal features. The pipeline includes CLIP-based filtering for quality and consistency using a directional similarity metric (CLIP dir) to ensure visual and textual changes align. The resulting dataset pairs each original caption with a counterfactual caption and corresponding image pair, enabling models to learn causal features rather than spurious correlations through data augmentation.

## Key Results
- 73% human evaluation accuracy in matching generated images to their correct counterfactual captions
- State-of-the-art multimodal models showed performance degradation on zero-shot image-text retrieval tasks using COCO-Counterfactuals
- Training data augmentation with COCO-Counterfactuals improved out-of-domain generalization on Flickr30k image-text retrieval and multiple image recognition datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Minimal text edits combined with Prompt-to-Prompt diffusion preserves spurious features while isolating the counterfactual change.
- Mechanism: By editing only a single noun in the caption and using cross-attention control during image generation, the diffusion model keeps the overall image structure similar except for the substituted subject.
- Core assumption: Stable Diffusion can generate semantically consistent images with minimal changes when cross-attention maps are shared across denoising steps.
- Evidence anchors:
  - [section 3.2]: "Hertz et al. (2022) proposed a methodology called Prompt-to-Prompt which injects cross-attention maps during the diffusion process to control the attention between certain pixels and tokens of the prompt during denoising steps."
  - [abstract]: "Our approach minimally edits captions... then leverages Stable Diffusion (Rombach et al., 2021) with cross-attention control (Hertz et al., 2022) to generate a pair of images with minimal differences."
- Break condition: If the diffusion model fails to bind attributes or count objects correctly, the counterfactual image may not match the caption changes.

### Mechanism 2
- Claim: CLIP dir metric ensures visual and textual changes are consistent, improving dataset quality.
- Mechanism: CLIP dir measures the directional similarity between the change vectors in CLIP space for images and text, ensuring that the visual edit aligns with the caption edit.
- Core assumption: CLIP embeddings capture the semantic meaning of both images and text in a way that is consistent across modalities.
- Evidence anchors:
  - [section 3.2]: "The CLIP dir metric measures the consistency in changes between the two images (Is_o, Is_c) and their corresponding captions (Co, Cc)."
  - [abstract]: "Selecting images with a higher CLIP dir improves the overall quality of our generated counterfactuals via greater consistency between the alterations made in both modalities."
- Break condition: If CLIP embeddings do not align well between modalities, the metric may select mismatched image-text pairs.

### Mechanism 3
- Claim: Data augmentation with counterfactuals improves out-of-domain generalization by reducing reliance on spurious correlations.
- Mechanism: Training on counterfactual examples forces the model to learn causal features rather than shortcut correlations, improving robustness on unseen domains.
- Core assumption: Spurious correlations present in training data are not causal and can be mitigated by counterfactual examples.
- Evidence anchors:
  - [abstract]: "We demonstrate the usefulness of COCO-Counterfactuals for improving out-of-domain generalization of multimodal vision-language models via training data augmentation."
  - [section 5]: "Our experiments demonstrate that augmenting training data with COCO-CFs improves OOD generalization on multiple downstream tasks."
- Break condition: If the counterfactual changes do not adequately expose the spurious correlations, the model may not learn the intended robustness.

## Foundational Learning

- Concept: Text-to-image diffusion models and their limitations
  - Why needed here: Understanding how Stable Diffusion generates images and its known failure modes (e.g., object counting, spatial relationships) is critical for evaluating the quality of synthetic counterfactuals.
  - Quick check question: What are two known limitations of current text-to-image diffusion models that could impact counterfactual generation quality?

- Concept: Counterfactual reasoning in machine learning
  - Why needed here: The core idea of counterfactuals is to study the impact of changing a causal feature while holding other factors constant, which is central to this dataset's construction and intended use.
  - Quick check question: How do counterfactual examples differ from standard data augmentation techniques in terms of their intended effect on model learning?

- Concept: Multimodal representation learning and CLIP embeddings
  - Why needed here: CLIP is used both for filtering generated images and as a metric for consistency, so understanding its embedding space and limitations is important for dataset quality assessment.
  - Quick check question: What is the purpose of using CLIP embeddings in the counterfactual image generation pipeline, and how does the CLIP dir metric work?

## Architecture Onboarding

- Component map:
  - Caption editing pipeline: NLTK for POS tagging -> MLM for noun substitution -> sentence transformers for similarity filtering -> GPT-2 for perplexity scoring
  - Image generation pipeline: Stable Diffusion with Prompt-to-Prompt cross-attention control -> CLIP filtering for quality and consistency
  - Dataset construction: MS-COCO validation set + automatically generated counterfactual pairs
  - Evaluation: Human annotation for quality control -> zero-shot retrieval/matching tasks -> training data augmentation experiments

- Critical path:
  1. Extract nouns from original caption
  2. Generate candidate counterfactual captions via MLM
  3. Filter candidates by similarity and perplexity
  4. Generate 100 image pairs per caption pair using Prompt-to-Prompt
  5. Filter image pairs by CLIP similarity and CLIP dir score
  6. Select best image pair for dataset inclusion

- Design tradeoffs:
  - Automation vs. quality: Fully automated generation may introduce noise, but human annotation is not scalable
  - Minimal edits vs. realism: Limiting changes to single nouns preserves spurious features but may produce unnatural captions
  - CLIP dir filtering vs. diversity: Strict consistency metrics may reduce the variety of counterfactual pairs

- Failure signatures:
  - High rate of human annotation errors indicates generation failures
  - Poor performance on zero-shot tasks suggests dataset quality issues
  - Saturation in training improvements indicates diminishing returns from additional counterfactuals

- First 3 experiments:
  1. Run caption editing pipeline on a small subset of MS-COCO captions and manually inspect candidate counterfactuals for naturalness and minimal edit quality
  2. Generate a few image pairs using Prompt-to-Prompt and evaluate whether the counterfactual change is correctly reflected while preserving other details
  3. Compute CLIP dir scores for generated pairs and verify that they align with visual inspection of change consistency

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can multimodal counterfactual data augmentation be effectively extended beyond image-text pairs to video data, and what unique challenges would this present?
- Basis in paper: [explicit] The authors conclude by suggesting extending their image-text counterfactuals to the video domain as a promising future direction for improving video transformers through counterfactual data augmentation.
- Why unresolved: While the authors propose this as a potential direction, they do not investigate or provide insights into how their methodology could be adapted for video data or what specific challenges would arise in generating counterfactual videos compared to images.
- What evidence would resolve it: Successful implementation of their methodology on video datasets, analysis of the challenges unique to video counterfactual generation (e.g., temporal consistency, motion), and evaluation of the impact on video transformer performance would provide evidence.

### Open Question 2
- Question: How can the quality of automatically generated multimodal counterfactual examples be improved to reduce errors associated with known limitations of text-to-image diffusion models, such as failures in generating fine-grained details or spatial relationships?
- Basis in paper: [explicit] The authors acknowledge that their COCO-Counterfactuals dataset may contain errors due to limitations of Stable Diffusion, such as failures to generate fine-grained details or accurately depict spatial relationships. They suggest that improvements in text-to-image generation capabilities could lead to higher-quality counterfactuals.
- Why unresolved: While the authors identify these limitations, they do not explore specific techniques or modifications to their methodology that could mitigate these errors or improve the overall quality of the generated counterfactuals.
- What evidence would resolve it: Demonstration of improved counterfactual quality through techniques such as enhanced prompting strategies, post-generation filtering, or integration of additional models to verify or correct generated images would provide evidence.

### Open Question 3
- Question: How can task-specific multimodal counterfactual examples be generated to target specific model failures or spurious correlations, rather than the task-agnostic approach used in this work?
- Basis in paper: [explicit] The authors propose that future work could adapt their approach to produce task-specific counterfactuals, such as limiting counterfactual changes to a targeted label distribution for image recognition tasks or using model failures to determine which counterfactual changes to consider.
- Why unresolved: The authors do not investigate or provide insights into how their methodology could be modified to generate task-specific counterfactuals or the potential benefits and challenges of such an approach.
- What evidence would resolve it: Successful generation of task-specific counterfactuals using their methodology, analysis of the impact on model performance for the targeted tasks, and comparison to the benefits of task-agnostic counterfactuals would provide evidence.

## Limitations

- Counterfactual generation quality: While human evaluation shows 73% accuracy, ~27% of pairs contain errors or inconsistencies due to limitations of text-to-image diffusion models
- Dataset representativeness: Limited to MS-COCO categories and single noun edits, restricting generalizability to other domains and counterfactual scenarios
- Generalization claims: Improvements demonstrated only on tested datasets (Flickr30k, image recognition), with unknown transfer to other domains or complex multimodal reasoning tasks

## Confidence

**High Confidence**: Technical pipeline reproducibility, human evaluation results (73% accuracy), baseline performance degradation on zero-shot tasks

**Medium Confidence**: Spurious correlation mitigation claims, CLIP dir metric effectiveness, out-of-domain generalization improvements on tested datasets

**Low Confidence**: Long-term robustness impact beyond tested datasets, effectiveness for intersectional bias mitigation, scalability to large-scale training scenarios

## Next Checks

1. Generate and manually verify a small subset (100-200 pairs) of counterfactual examples from scratch using the described pipeline to confirm reproducibility and assess quality beyond the reported 73% accuracy.

2. Test model robustness to known bias types by evaluating whether COCO-Counterfactuals training improves performance on established bias benchmarks like SocialCounterfactuals or other intersectional bias datasets.

3. Conduct ablation studies on filtering criteria by generating counterfactual pairs with different CLIP dir thresholds and analyzing the tradeoff between quality and dataset size on downstream task performance.