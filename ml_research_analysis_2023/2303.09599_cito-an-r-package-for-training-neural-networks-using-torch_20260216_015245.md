---
ver: rpa2
title: 'cito: An R package for training neural networks using torch'
arxiv_id: '2303.09599'
source_url: https://arxiv.org/abs/2303.09599
tags:
- training
- cito
- networks
- learning
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces cito, an R package for training neural networks
  using the torch library. The package aims to make deep learning more accessible
  to R users by providing a user-friendly interface with formula syntax.
---

# cito: An R package for training neural networks using torch

## Quick Facts
- arXiv ID: 2303.09599
- Source URL: https://arxiv.org/abs/2303.09599
- Reference count: 5
- The paper introduces cito, an R package for training neural networks using the torch library, which provides a user-friendly interface with formula syntax.

## Executive Summary
cito is an R package that makes deep learning more accessible to R users by integrating the torch backend with R's familiar formula syntax. The package allows users to specify neural network architectures and training parameters without writing PyTorch code, while providing GPU support, regularization, and explainable AI tools. cito aims to streamline the workflow for building, training, and interpreting deep neural networks in R, making it a valuable tool for ecological data analysis.

## Method Summary
cito is an R package that leverages the torch deep learning framework to train fully-connected neural networks. The package provides a user-friendly interface through the dnn() function, which accepts standard R model formulas to specify architectures and training parameters. cito uses torch's optimized tensor operations and can train models on GPUs for improved performance. The package also includes functions for model plotting, analysis, and explainable AI (xAI) metrics, such as feature importance and partial dependence plots.

## Key Results
- cito provides a streamlined workflow for building, training, and interpreting deep neural networks in R.
- The package's performance is competitive with other R packages for neural networks, especially for larger networks.
- cito includes built-in xAI functions for interpreting model predictions without external tools.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: cito lowers the barrier to entry for R users wanting to train deep neural networks by integrating the torch backend with R's formula syntax.
- Mechanism: The package wraps the torch library behind a simple dnn() function that accepts standard R model formulas, allowing users to specify architectures and training parameters without writing PyTorch code.
- Core assumption: R users are more familiar with formula-based model specification than with explicit deep learning framework APIs.
- Evidence anchors:
  - [abstract] "allows specifying DNNs in the familiar formula syntax used by many R packages"
  - [section] "cito allows R users to specify deep neural networks in the familiar formula syntax used by most modeling functions in R"
- Break condition: If the underlying torch operations are too slow or the formula syntax is insufficient for complex architectures, users may revert to native torch code.

### Mechanism 2
- Claim: cito achieves competitive performance by leveraging GPU acceleration and modern training techniques.
- Mechanism: cito uses torch's optimized tensor operations and can train models on GPUs, which scales well for larger networks, while also providing regularization, learning rate schedulers, and early stopping.
- Core assumption: GPU acceleration provides a significant speedup for large network training compared to CPU-only approaches.
- Evidence anchors:
  - [abstract] "taking advantage of the numerically optimized torch library, including the ability to switch between training models on the CPU or the graphics processing unit (GPU)"
  - [section] "On the GPU, training time in cito is practically independent of the size of the network"
- Break condition: If GPU resources are unavailable or the overhead of the R interface outweighs the benefits for very small networks, performance gains may not materialize.

### Mechanism 3
- Claim: cito provides interpretability features that make deep learning results more accessible to ecological researchers.
- Mechanism: cito includes built-in explainable AI (xAI) functions like feature importance, partial dependence plots, and accumulated local effect plots, allowing users to understand model predictions without external tools.
- Core assumption: Ecologists need interpretable models to validate and explain predictions in their research context.
- Evidence anchors:
  - [abstract] "explainable AI (xAI) metrics for effect sizes and variable importance with CIs and p-values"
  - [section] "cito includes many user-friendly functions for model plotting and analysis, including optional confidence intervals (CIs) based on bootstraps for predictions and explainable AI (xAI) metrics"
- Break condition: If the xAI methods are computationally expensive or not accurate for the given model complexity, users may distrust the interpretations.

## Foundational Learning

- Concept: Torch backend integration
  - Why needed here: Enables leveraging optimized deep learning operations and GPU support within R.
  - Quick check question: What is the primary advantage of using torch as the backend instead of a native R implementation?

- Concept: Formula-based model specification
  - Why needed here: Allows R users to specify neural network architectures in a familiar syntax without learning PyTorch code.
  - Quick check question: How does the dnn() function use the formula syntax to determine input features and target variables?

- Concept: Regularization and training techniques
  - Why needed here: Helps control overfitting and improves generalization, especially important for small ecological datasets.
  - Quick check question: What types of regularization does cito support, and how do they affect the bias-variance tradeoff?

## Architecture Onboarding

- Component map: dnn() function -> model specification (formula, hidden layers, activation) -> training (epochs, batch size, optimizer) -> output (trained model object) -> interpretation (predict, summary, xAI functions)
- Critical path: User specifies model -> cito translates to torch model -> training loop with validation -> model object returned
- Design tradeoffs: High-level interface vs. flexibility; formula syntax vs. complex architectures; R integration vs. native torch performance
- Failure signatures: Training not converging (check learning rate, batch size); GPU not utilized (check device setting); xAI functions slow (check bootstrap settings)
- First 3 experiments:
  1. Train a simple fully-connected network on a small dataset using default parameters to verify basic functionality
  2. Compare training time on CPU vs. GPU for a medium-sized network to assess performance benefits
  3. Generate feature importance and partial dependence plots to verify interpretability functions work as expected

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does cito compare to other R packages for neural networks in terms of prediction accuracy for different types of ecological datasets?
- Basis in paper: [explicit] The paper mentions that cito's performance is competitive with other packages in terms of runtime and accuracy, especially for larger networks.
- Why unresolved: The paper only provides a limited comparison of cito's performance with other packages on a single simulated dataset. It does not explore how cito performs on different types of ecological datasets with varying characteristics.
- What evidence would resolve it: A comprehensive benchmark study comparing cito's prediction accuracy with other R packages on a diverse set of ecological datasets, including different sample sizes, feature dimensions, and data distributions.

### Open Question 2
- Question: How does the inclusion of additional features, such as CNNs and RNNs, in future versions of cito impact its performance and usability for ecological data analysis?
- Basis in paper: [explicit] The authors mention that future versions of cito aim to implement additional functionalities, including the integration of recurrent and convolutional neural networks.
- Why unresolved: The paper does not provide any information on how the inclusion of these features will impact cito's performance or usability. It is unclear whether these additions will enhance cito's capabilities for ecological data analysis.
- What evidence would resolve it: Performance benchmarks and usability evaluations of cito's future versions that include CNNs and RNNs, comparing them to the current version and other existing packages for ecological data analysis.

### Open Question 3
- Question: How does cito's explainable AI (xAI) functionality compare to other xAI methods in terms of interpretability and reliability for ecological models?
- Basis in paper: [explicit] The paper highlights cito's xAI features, including feature importance calculations and partial dependency plots, which are designed to help interpret the trained models.
- Why unresolved: The paper does not provide a detailed comparison of cito's xAI functionality with other xAI methods in terms of interpretability and reliability. It is unclear how cito's xAI tools stack up against other popular xAI techniques in the field.
- What evidence would resolve it: A comparative study evaluating cito's xAI functionality against other xAI methods, focusing on interpretability and reliability, using a variety of ecological models and datasets.

## Limitations

- Performance comparisons rely on specific hardware configurations that may not generalize across all user environments.
- The claimed superiority of cito for larger networks is based on a single species distribution modeling case study, limiting external validity.
- The xAI features' computational cost and accuracy for complex architectures are not fully characterized.

## Confidence

- High confidence: cito successfully integrates torch with R's formula syntax and provides GPU acceleration
- Medium confidence: cito's performance advantages for larger networks and its xAI features are well-demonstrated
- Low confidence: The generalizability of cito's performance across diverse modeling tasks and its handling of extremely large or complex architectures

## Next Checks

1. Benchmark cito against other R deep learning packages on multiple diverse datasets (beyond species distribution modeling) to assess generalizability of performance claims.
2. Test cito's behavior and performance on networks with architectures that push the boundaries of formula syntax (e.g., skip connections, attention mechanisms).
3. Conduct a user study comparing cito's learning curve and productivity against native torch implementations for R users with varying deep learning experience levels.