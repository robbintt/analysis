---
ver: rpa2
title: On Synthetic Data for Back Translation
arxiv_id: '2310.13675'
source_url: https://arxiv.org/abs/2310.13675
tags:
- translation
- data
- synthetic
- sampling
- beam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the role of synthetic data in back translation
  for neural machine translation. It identifies two key factors controlling performance:
  quality and importance of synthetic data.'
---

# On Synthetic Data for Back Translation

## Quick Facts
- **arXiv ID**: 2310.13675
- **Source URL**: https://arxiv.org/abs/2310.13675
- **Reference count**: 23
- **Key outcome**: Proposes a method balancing synthetic data quality and importance for back translation, achieving up to 2.3 BLEU improvement on WMT14 DE-EN.

## Executive Summary
This paper investigates how synthetic data quality and importance impact back translation (BT) performance in neural machine translation. The authors identify that high-quality synthetic data often has low importance weight, and vice versa, making it necessary to balance both factors. They propose a gamma score method that normalizes and interpolates quality and importance across candidate sentences, then sample or select based on this score. Experiments on WMT14 benchmarks show consistent BLEU gains over standard beam search and sampling baselines, demonstrating the effectiveness of the proposed approach.

## Method Summary
The method generates synthetic source sentences for BT by sampling N candidates from a backward model, then computing normalized quality (backward model likelihood) and importance (language model likelihood) scores. These are combined using a gamma interpolation to form a selection score, from which the best candidate is chosen. The authors also propose a data manipulation technique that mixes beam and sampling-generated synthetic data. The forward model is then trained on the original bitext plus the improved synthetic corpus. This approach aims to better balance the trade-off between data quality and importance for improved BT performance.

## Key Results
- Proposed gamma score method outperforms standard beam search and sampling baselines by up to 2.3 BLEU points on WMT14 DE-EN.
- Consistent improvements observed across DE-EN, EN-DE, and RU-EN language pairs.
- Data manipulation (mixing beam and sampling) also provides intermediate gains, validating the importance-quality trade-off.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic data quality and importance are inversely related; balancing them improves BT performance.
- Mechanism: Maximizing log p(y|ˆx; θ) implicitly maximizes importance weight × log p(y|ˆx). Since quality and importance are mutually exclusive, a fixed strategy (beam or sampling) over-optimizes one at the expense of the other.
- Core assumption: Importance weight = p(x)/p(x|y) can be estimated by language model / backward model likelihood, and is correlated with downstream BT gains.
- Break condition: If quality and importance are not inversely correlated (e.g., in a domain where both are high), balancing may hurt.

### Mechanism 2
- Claim: Gamma score sampling achieves better trade-off by normalizing quality and importance across candidates.
- Mechanism: For each y, sample N candidates from backward model, normalize log quality and log importance by sequence length and variance, combine with gamma interpolation, then sample or select by normalized score.
- Core assumption: Normalization removes scale differences so interpolation meaningfully balances the two factors.
- Break condition: If normalization is unstable or if candidate set is too small/large, the interpolation may not reflect true trade-off.

### Mechanism 3
- Claim: Data manipulation (mixing beam and sampling) provides intermediate variety and token frequency distribution.
- Mechanism: Randomly split target corpus into γ and (1-γ) parts, generate beam translations for first part and sampling translations for second, then combine.
- Core assumption: Mixing high-quality/low-importance with low-quality/high-importance synthetic sentences yields a corpus that improves BT more than either alone.
- Break condition: If γ is poorly chosen, synthetic corpus may be dominated by one factor and lose benefit.

## Foundational Learning

- Concept: Marginal likelihood in semi-supervised learning
  - Why needed here: BT leverages monolingual target data; understanding how to maximize log p(y; θ) is central to BT objective.
  - Quick check question: Why is log p(y; θ) lower bounded by E_p(x|y)[p(x)/p(x|y) log p(y|x; θ)] instead of directly using p(x)?

- Concept: Importance sampling and rejection control
  - Why needed here: Importance weight p(x)/p(x|y) determines how much each synthetic sample contributes; low weight samples should be rejected or downweighted.
  - Quick check question: If p(x|y) is high (high quality), why does importance weight become low, and what does that imply for BT?

- Concept: Normalization by sequence length and variance
  - Why needed here: Gamma score normalizes log quality and importance per token and across candidates to make interpolation meaningful.
  - Quick check question: What could go wrong if we skip length normalization when combining quality and importance?

## Architecture Onboarding

- Component map:
  - Forward NMT model (θ) -> Trained on bitext + synthetic corpus
  - Backward NMT model (π) -> Generates synthetic source sentences
  - Language model (ω) -> Estimates p(x) for importance weight
  - Gamma scorer -> Normalizes and interpolates quality/importance
  - Data pipeline -> Splits target corpus, generates synthetic data, merges

- Critical path:
  1. Train backward model π on bitext
  2. Train language model ω on large monolingual source corpus
  3. For each target sentence y:
     - Sample N candidates from π(x|y)
     - Compute normalized quality and importance
     - Compute gamma scores and select or sample candidate
  4. Train forward model on bitext + synthetic corpus

- Design tradeoffs:
  - Beam vs sampling: Beam → high quality, low importance; sampling → low quality, high importance
  - Gamma sampling cost: ~10× slower than beam due to N candidates; but less than full sampling since only N=50
  - Hyperparameter γ in interpolation: Needs tuning; fixed value may not generalize

- Failure signatures:
  - BLEU plateaus or drops when gamma score is applied incorrectly
  - Importance estimates become unstable if language model is weak
  - Candidate set too small → poor approximation of quality/importance distribution

- First 3 experiments:
  1. Train backward model and language model, generate beam and sampling corpora, compare BLEU vs quality/importance
  2. Implement gamma scorer, tune γ on dev set, verify synthetic corpus diversity metrics (spectrum, token frequency)
  3. Train forward NMT with gamma-sampled synthetic corpus, measure BLEU gain over beam/sampling baselines

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of the synthetic data impact the final performance of back translation?
- Basis in paper: The paper discusses how the quality of synthetic data is not the sole factor influencing back translation performance, and that importance weight also plays a crucial role.
- Why unresolved: The paper does not provide a clear answer on how to balance quality and importance weight to achieve the best performance.
- What evidence would resolve it: Experiments comparing the performance of back translation models using synthetic data with varying quality and importance weight.

### Open Question 2
- Question: How does the gamma score method compare to other data augmentation techniques for improving back translation performance?
- Basis in paper: The paper introduces the gamma score method as a way to balance the quality and importance weight of synthetic data.
- Why unresolved: The paper does not provide a direct comparison between the gamma score method and other data augmentation techniques.
- What evidence would resolve it: Experiments comparing the performance of back translation models using the gamma score method and other data augmentation techniques.

### Open Question 3
- Question: How does the gamma score method affect the diversity of the synthetic data?
- Basis in paper: The paper discusses how the gamma score method affects the quality and importance weight of synthetic data, but does not explicitly address its impact on diversity.
- Why unresolved: The paper does not provide a clear answer on how the gamma score method affects the diversity of synthetic data.
- What evidence would resolve it: Experiments analyzing the diversity of synthetic data generated using the gamma score method compared to other methods.

## Limitations

- **Importance Weight Estimation**: Relies on a separately trained language model; quality and domain mismatch could make weights noisy, with no ablation study on sensitivity.
- **Normalization Assumptions**: Heuristic normalization by length and variance is not theoretically justified; could be unstable for small or degenerate candidate sets.
- **Hyperparameter Sensitivity**: γ and gamma interpolation weights are fixed via development set tuning; unclear how robust these are across languages or dataset sizes.

## Confidence

- **High Confidence**: Experimental setup is clearly described; BLEU improvements on WMT14 benchmarks are measurable and consistent across DE-EN, EN-DE, and RU-EN.
- **Medium Confidence**: Theoretical framing linking marginal likelihood, importance sampling, and BT is correct, but practical estimation of importance weights and their correlation with downstream gains is not rigorously validated.
- **Low Confidence**: Claim that quality and importance are universally inversely related is based on anecdotal evidence; no formal proof or extensive empirical study is provided.

## Next Checks

1. **Ablation on Language Model Quality**: Train backward models and language models of varying quality, then measure how sensitive gamma score BT performance is to language model degradation.
2. **Normalization Stability Test**: For each target sentence, generate candidate sets of varying sizes, compute gamma scores with and without normalization, and measure BLEU gain; also test cases where variance is near zero.
3. **Cross-Domain Transfer**: Apply the gamma score method to a different translation domain (e.g., biomedical or legal text) and compare BLEU gains to the WMT news domain.