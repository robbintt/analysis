---
ver: rpa2
title: On Functional Activations in Deep Neural Networks
arxiv_id: '2311.10898'
source_url: https://arxiv.org/abs/2311.10898
tags:
- functional
- networks
- prompts
- each
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work demonstrates that functional neuroimaging techniques
  can be adapted to probe the internal structure of deep neural networks. The authors
  applied a block-design task-based paradigm to the Facebook Galactica-125M model,
  using prompts spanning political science, medical imaging, paleontology, archeology,
  and pathology.
---

# On Functional Activations in Deep Neural Networks

## Quick Facts
- arXiv ID: 2311.10898
- Source URL: https://arxiv.org/abs/2311.10898
- Authors: 
- Reference count: 33
- Key outcome: Functional neuroimaging techniques adapted to identify task-specific sub-networks in deep neural networks with repeatable activations and accurate task prediction.

## Executive Summary
This work demonstrates that functional neuroimaging methods can be adapted to probe the internal structure of deep neural networks. The authors applied a block-design task-based paradigm to the Facebook Galactica-125M model, using prompts spanning political science, medical imaging, paleontology, archeology, and pathology. By saving layer output values for each token and fitting general linear models, they identified distinct, overlapping functional networks associated with each task. These networks were repeatable across multiple runs and could be used to accurately predict the presented task based on activation patterns. This approach offers a new method for interpreting deep neural networks, with potential applications in model alignment, fine-tuning, and understanding failure modes.

## Method Summary
The authors applied functional neuroimaging techniques to the Facebook Galactica-125M model by generating block-designed prompt sequences for five task domains and random strings. During inference, they saved all layer output values for each generated token to create time series data. General linear models were then fit to identify layer outputs that showed task-related activity. The identified functional networks were analyzed for repeatability across runs and used to predict presented tasks by computing overlap with pre-computed network templates.

## Key Results
- Identified distinct, overlapping functional networks for each task domain that were repeatable across multiple runs
- Demonstrated accurate task prediction based on percentage of active elements in pre-computed functional networks
- Showed that networks defined from one set of prompts could predict activations for different prompts within the same task domain

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Functional neuroimaging methods can reveal task-specific sub-networks in deep neural networks.
- Mechanism: By treating layer outputs as analogous to brain voxels, block-designed tasks with on/off patterns allow GLM fitting to identify connections that activate preferentially with specific tasks.
- Core assumption: The relationship between task input and layer outputs is linear or can be modeled linearly over short inference steps.
- Evidence anchors:
  - [abstract] "For the generation of each output token, all layer output values were saved to create an effective time series. General linear models were fit to the data to identify layer output values which were active with the tasks."
  - [section 3.2] "As with a task-based fMRI experiment, the neural network can be probed with a series of inputs related to, or not related to, a specific task in an a priori known pattern."
- Break condition: If the network's internal dynamics introduce strong non-linear temporal dependencies that violate GLM assumptions, the method will fail to isolate task-specific activations.

### Mechanism 2
- Claim: Identified functional networks are repeatable across different prompt sequences within the same task domain.
- Mechanism: Overlapping sets of active layer outputs are consistently found when the same conceptual task (e.g., medical imaging) is probed with different specific prompts, indicating stable semantic sub-networks.
- Core assumption: The internal representations of semantically similar concepts are stable enough to be detected across prompt variations.
- Evidence anchors:
  - [abstract] "These networks were repeatable across repeated performance of related tasks..."
  - [section 4] "Overlap within experimental task across runs is much greater than the overlap identified across tasks."
- Break condition: If the model's representations are highly sensitive to prompt phrasing or if fine-tuning introduces instability, repeatability will degrade.

### Mechanism 3
- Claim: The percentage of active elements in a pre-computed functional network can accurately predict the presented task.
- Mechanism: By computing the intersection of run-specific activations with template networks and normalizing by network size, a discriminative metric is created that peaks when the task matches the network.
- Core assumption: Task-specific networks are sufficiently distinct and the activation patterns are discriminative enough for classification.
- Evidence anchors:
  - [abstract] "...correspondence of identified functional networks and activation in tasks not used to define the functional networks was shown to accurately identify the presented task."
  - [section 4] "There is a clear correspondence of this metric being elevated when the experimental task aligns with the functional network template for that task."
- Break condition: If functional networks have high overlap or if random tasks activate non-trivial networks, the discriminative power will collapse.

## Foundational Learning

- Concept: General Linear Model (GLM) fitting
  - Why needed here: Used to statistically identify layer outputs whose activity correlates with the block-designed task on/off pattern.
  - Quick check question: What is the null hypothesis when fitting a GLM to determine if a layer output is task-active?

- Concept: Block design experimental paradigm
  - Why needed here: Provides a structured on/off pattern of task-relevant vs. task-irrelevant inputs to probe internal network responses.
  - Quick check question: Why is it important that each block contains a single prompt rather than multiple prompts?

- Concept: Multiple comparisons correction (Bonferroni)
  - Why needed here: With 259,744 layer outputs tested, correction is necessary to control false positive rate when declaring activations.
  - Quick check question: How does the Bonferroni correction threshold change if the number of layer outputs doubles?

## Architecture Onboarding

- Component map: Input prompts -> Facebook Galactica-125M model with layer output hooks -> Token-by-token inference -> Time series construction -> GLM fitting -> Functional network identification -> Venn diagram overlap analysis -> Template network creation -> Task prediction metrics

- Critical path:
  1. Generate task-specific prompt sequences (Chat-GPT + NLTK random)
  2. Run inference with hooks saving all layer outputs per token
  3. Concatenate outputs into time series per experiment
  4. Fit GLM per layer output to detect task-related activity
  5. Analyze overlap within and across runs
  6. Create template networks from consensus across runs
  7. Test prediction accuracy on held-out run

- Design tradeoffs:
  - Small model (125M) chosen for computational feasibility vs. larger models with potentially richer functional networks
  - CPU inference for simplicity vs. GPU for speed
  - Simple GLM vs. more complex temporal models that might capture attention dynamics
  - Block design with single prompts vs. continuous stimulus designs

- Failure signatures:
  - No significant activations after GLM fitting (p-value threshold too strict or no true task-related structure)
  - High overlap across all task networks (semantic representations too entangled)
  - Poor repeatability across runs (unstable internal representations)
  - Random tasks activating non-trivial networks (poor discriminative power)

- First 3 experiments:
  1. Run a single task vs. random comparison with 2-3 blocks to verify basic GLM fitting works and produces expected on/off activation patterns
  2. Run the full 5-run design but only for one task domain to check repeatability within that domain before scaling up
  3. Test the template network prediction method on a held-out single run before applying to all tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the size of the deep neural network model affect the effectiveness and reliability of the functional neuroimaging approach described in the paper?
- Basis in paper: [explicit] The paper notes that the current study was limited to a smaller model (Facebook Galactica-125M) due to computational constraints, but suggests that the approach could be scaled to larger models.
- Why unresolved: The authors did not test the method on larger models, leaving open questions about computational feasibility, the number of layer outputs to analyze, and the potential need for different statistical techniques.
- What evidence would resolve it: Applying the same functional neuroimaging approach to larger models like GPT-3 or GPT-4 and comparing the results in terms of identified functional networks, computational resources required, and the interpretability of the findings.

### Open Question 2
- Question: Can the functional neuroimaging approach be used to predict and prevent undesirable outputs or "failure modes" in deep neural networks?
- Basis in paper: [explicit] The authors suggest that identifying functional networks associated with poor alignment or failure modes could allow for intervention, such as restarting inference with a different random state.
- Why unresolved: The paper only presents a proof of concept and does not demonstrate the approach's ability to predict or prevent specific failure modes in practice.
- What evidence would resolve it: Demonstrating that monitoring the activity of identified functional networks can successfully predict and prevent known failure modes in a deep neural network, such as biased outputs or hallucinations.

### Open Question 3
- Question: How can the functional neuroimaging approach be extended to provide more human-interpretable insights into the workings of deep neural networks?
- Basis in paper: [inferred] The authors note that while other techniques for understanding functional networks exist, they often replace one "opaque box" with another. The linear models used in this approach offer a potential for enhanced interpretability.
- Why unresolved: The paper does not explore how to make the findings more accessible to humans, such as through visualization or mapping identified networks to specific concepts or tasks.
- What evidence would resolve it: Developing and demonstrating methods to visualize or explain the identified functional networks in a way that is understandable to humans, potentially by linking them to specific linguistic or semantic concepts.

## Limitations
- Limited to a relatively small 125M parameter model due to computational constraints
- Assumes linear relationships between task inputs and layer outputs may not hold for more complex architectures
- Single prompts per block may not fully capture temporal dynamics of task-related activations

## Confidence

- **High Confidence**: The basic methodology of using GLM fitting on layer outputs to identify task-related activations, supported by the successful application and repeatability results.
- **Medium Confidence**: The generalizability of identified functional networks across different prompt sequences, as the study demonstrates repeatability but within a limited prompt variation space.
- **Low Confidence**: The claim that this approach can scale to larger models or different architectures without modification, given the computational constraints and linear model assumptions.

## Next Checks

1. Apply the same methodology to a larger language model (e.g., 1.3B or 6.7B parameters) to test whether functional networks scale predictably with model size.

2. Replace the block design with continuous stimulus presentation and apply time-series analysis methods (e.g., dynamic causal modeling) to capture non-linear temporal dependencies in activation patterns.

3. Extend the paradigm to include non-textual inputs (e.g., image or audio prompts) to assess whether the GLM-based approach generalizes across different data modalities.