---
ver: rpa2
title: 'GeSS: Benchmarking Geometric Deep Learning under Scientific Applications with
  Distribution Shifts'
arxiv_id: '2310.08677'
source_url: https://arxiv.org/abs/2310.08677
tags:
- shift
- data
- distribution
- learning
- shifts
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces GeSS, a comprehensive benchmark for evaluating
  geometric deep learning (GDL) models under distribution shifts in scientific applications.
  The benchmark covers diverse domains like particle physics, materials science, and
  biochemistry, and includes 30 different experiment settings evaluating 3 GDL backbones
  and 11 learning algorithms across 10 distribution shift types.
---

# GeSS: Benchmarking Geometric Deep Learning under Scientific Applications with Distribution Shifts

## Quick Facts
- **arXiv ID**: 2310.08677
- **Source URL**: https://arxiv.org/abs/2310.08677
- **Reference count**: 40
- **Key outcome**: Introduces GeSS benchmark for evaluating GDL models under distribution shifts across scientific domains, revealing that no single method is optimal for all shift types

## Executive Summary
This paper introduces GeSS, a comprehensive benchmark for evaluating geometric deep learning models under distribution shifts in scientific applications. The benchmark covers diverse domains including particle physics, materials science, and biochemistry, evaluating 3 GDL backbones and 11 learning algorithms across 10 distribution shift types. The authors categorize distribution shifts into conditional, covariate, and concept shifts, and study three levels of out-of-distribution information access. Their analysis yields valuable insights about method effectiveness, demonstrating that transfer learning excels under concept shifts while domain adaptation methods perform well for certain conditional shifts.

## Method Summary
The GeSS benchmark systematically evaluates GDL models under distribution shifts by first identifying the type of shift in scientific applications through domain knowledge and causal analysis. The evaluation framework tests three levels of OOD information access (No-Info, O-Feature, Par-Label) across 30 different experiment settings using three GDL backbones (EGNN, DGCNN, Point Transformer) with 11 learning algorithms. The benchmark covers 10 distribution shift types across three scientific datasets: Track (particle physics), QMOF (materials science), and DrugOOD-3D (biochemistry). Performance is measured using accuracy for classification tasks and mean absolute error for regression tasks, comparing OOD performance against ID baselines.

## Key Results
- Transfer learning methods show significant advantages under concept shifts, particularly when marginal label distribution changes are large
- Domain adaptation methods perform well when distribution shifts affect features critical for label determination
- No single approach is optimal across all shift types, requiring careful method selection based on application and OOD information availability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: No single approach is optimal for all shift types, requiring careful method selection based on application and OOD information availability
- Mechanism: Different distribution shift types (conditional, covariate, concept) have distinct underlying causal structures that interact differently with various learning algorithms. The effectiveness of each method depends on how well its assumptions match the shift type and OOD information level.
- Core assumption: The causal mechanism behind each shift type remains stable and can be identified through domain knowledge
- Evidence anchors:
  - [abstract]: "the effectiveness of transfer learning under concept shifts and domain adaptation methods for certain conditional shifts"
  - [section]: "no approach can be the best for all types of shifts, and the levels of OOD information may benefit ML models to various extents across different applications"
  - [corpus]: Corpus contains related works on OOD generalization but no direct evidence about the effectiveness of different methods across shift types
- Break condition: If the causal mechanism behind a shift changes dynamically or cannot be identified, method selection becomes unreliable

### Mechanism 2
- Claim: Transfer learning methods show advantages under concept shifts, particularly when there are significant changes in marginal label distribution
- Mechanism: Concept shifts involve changes in the labeling rule P(Y|X), which transfer learning can address by fine-tuning on target domain labels to adapt the model to the new concept
- Core assumption: The feature representations learned from source domain data remain useful for the target domain, and only the decision boundary needs adjustment
- Evidence anchors:
  - [abstract]: "the effectiveness of transfer learning under concept shifts"
  - [section]: "TL methods show advantages under concept shifts, particularly when the shift of the marginal label distribution P(Y) is large"
  - [corpus]: Weak evidence - corpus contains related works on OOD generalization but lacks specific evidence about transfer learning effectiveness under concept shifts
- Break condition: If the feature representations themselves change significantly between domains, not just the labeling rule, transfer learning may fail

### Mechanism 3
- Claim: Domain adaptation methods show advantages when distribution shifts happen to features critical for label determination compared with other features
- Mechanism: Domain adaptation methods learn to align feature distributions between source and target domains, which is particularly effective when the shifted features are causally related to the label
- Core assumption: The shifted features have causal relationship with the label, not just correlation
- Evidence anchors:
  - [abstract]: "domain adaptation methods for certain conditional shifts"
  - [section]: "DA methods show advantages when the distribution shifts happen to the features that are critical for label determination compared with other features"
  - [corpus]: Weak evidence - corpus contains related works on domain adaptation but lacks specific evidence about its effectiveness on features critical for label determination
- Break condition: If shifted features are not causally related to the label or if other features are more important for prediction

## Foundational Learning

- Concept: Causal inference and structural causal models
  - Why needed here: Understanding the causal relationships between variables is crucial for categorizing distribution shifts and selecting appropriate methods
  - Quick check question: Can you explain the difference between P(Y|X) and P(X|Y) and why this distinction matters for categorizing distribution shifts?

- Concept: Out-of-distribution generalization
  - Why needed here: The benchmark focuses on evaluating model performance when test data distribution differs from training data distribution
  - Quick check question: What are the key challenges in training models that generalize well to unseen data distributions?

- Concept: Geometric deep learning fundamentals
  - Why needed here: The benchmark evaluates GDL models specifically, requiring understanding of how GDL handles geometric data structures
  - Quick check question: How do GDL models maintain equivariance and invariance properties when processing geometric data?

## Architecture Onboarding

- Component map: Dataset curation and shift creation -> Algorithm evaluation framework -> Result analysis system
- Critical path: 1) Identify distribution shift type in application 2) Assess OOD information availability 3) Select appropriate method category 4) Implement and evaluate
- Design tradeoffs: Balancing between comprehensive coverage of shift types and practical feasibility of experiments; choosing between more datasets or more algorithms per dataset
- Failure signatures: Poor OOD performance despite good ID performance indicates distribution shift issues; method underperformance suggests mismatch between shift type and algorithm assumptions
- First 3 experiments:
  1. Implement ERM baseline on Pileup shift to establish baseline performance
  2. Test transfer learning on Fidelity shift to verify concept shift effectiveness
  3. Evaluate domain adaptation on Signal shift to test conditional shift handling

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do GDL models that capture higher-order geometric information beyond distances (e.g., angles, torsion) perform under distribution shifts compared to those using only distance information?
- Basis in paper: [explicit] The paper mentions that current backbones use distance information and suggests investigating higher-order geometric information as future work.
- Why unresolved: The study only evaluates backbones using distance information, leaving the impact of higher-order geometric features unexplored.
- What evidence would resolve it: Empirical comparisons of GDL models using distance-only vs. distance-plus-higher-order geometric features under various distribution shifts.

### Open Question 2
- Question: What is the relative importance of each distribution shift type (conditional, covariate, concept) in scientific applications, and how does this vary across domains?
- Basis in paper: [inferred] The paper shows different methods perform better for different shift types but doesn't quantify their prevalence or domain-specific importance.
- Why unresolved: The benchmark covers multiple shift types but doesn't analyze their relative frequency or impact across different scientific domains.
- What evidence would resolve it: A systematic analysis of distribution shift types across a broader range of scientific applications with quantitative importance measures.

### Open Question 3
- Question: How can auxiliary variables be effectively leveraged to improve OOD generalization in GDL models for scientific applications?
- Basis in paper: [explicit] The authors mention this as an interesting future topic, referencing related work that uses auxiliary information for OOD generalization.
- Why unresolved: While the potential is acknowledged, the paper doesn't explore concrete methods for incorporating auxiliary variables into GDL models.
- What evidence would resolve it: Development and evaluation of GDL methods that effectively utilize auxiliary variables for improved OOD generalization on scientific datasets.

## Limitations

- The benchmark relies heavily on domain knowledge to identify shift types, which may not always be available in practice
- Results are based on three specific scientific domains and may not generalize to all scientific applications
- The effectiveness patterns of different methods across shift types lack extensive external validation from the broader literature

## Confidence

- **High confidence**: The framework for categorizing distribution shifts (conditional, covariate, concept) based on their causal mechanisms
- **Medium confidence**: The relative effectiveness of different method categories across shift types, based on empirical results but limited external validation
- **Medium confidence**: The assertion that no single approach is optimal for all shift types, supported by experimental results but requiring broader validation

## Next Checks

1. **Cross-domain validation**: Test the method effectiveness patterns on additional scientific domains beyond particle physics, materials science, and biochemistry to verify generalizability

2. **Causal mechanism verification**: Conduct ablation studies to confirm that the observed method effectiveness directly corresponds to the identified causal mechanisms rather than spurious correlations

3. **OOD information access sensitivity**: Systematically vary the amount and quality of OOD information available to evaluate the robustness of the method selection guidelines across different information scenarios