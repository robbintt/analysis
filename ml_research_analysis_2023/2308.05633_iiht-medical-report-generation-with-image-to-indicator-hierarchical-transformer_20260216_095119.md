---
ver: rpa2
title: 'IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer'
arxiv_id: '2308.05633'
source_url: https://arxiv.org/abs/2308.05633
tags:
- medical
- report
- indicator
- disease
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes IIHT, an image-to-indicator hierarchical transformer
  framework for medical report generation that addresses data imbalance and correlation
  issues in radiology report generation. The method extracts visual features from
  medical images and converts them into disease indicator embeddings, which are then
  expanded into textual sequences and used as input for a transformer-based generator
  to produce final reports.
---

# IIHT: Medical Report Generation with Image-to-Indicator Hierarchical Transformer

## Quick Facts
- arXiv ID: 2308.05633
- Source URL: https://arxiv.org/abs/2308.05633
- Authors: 
- Reference count: 33
- Key outcome: IIHT achieves BLEU-1: 0.513, BLEU-2: 0.375, BLEU-3: 0.297, BLEU-4: 0.245, METEOR: 0.264, ROUGE-L: 0.492 on IU X-Ray dataset

## Executive Summary
This paper proposes IIHT, an image-to-indicator hierarchical transformer framework for medical report generation that addresses data imbalance and correlation issues in radiology report generation. The method extracts visual features from medical images and converts them into disease indicator embeddings, which are then expanded into textual sequences and used as input for a transformer-based generator to produce final reports. The key idea is using disease indicators as a bridge to improve clinical accuracy while maintaining linguistic fluency. Experimental results on the IU X-Ray dataset show that IIHT outperforms state-of-the-art methods across all evaluation metrics.

## Method Summary
IIHT is a three-module framework that converts medical images to reports through disease indicators. First, a classifier extracts image features and predicts disease indicator states (positive, negative, uncertain) using self-attention for interpretability. Second, an indicator expansion module converts these indicator embeddings to text sequences and back using a "data-text-data" strategy to address correlation and length issues. Finally, a transformer-based generator produces the complete medical report using the indicator information, image features, and previous word embeddings. The model is trained with multi-task loss combining classification and generation objectives, optimized using AdamW with five-fold cross-validation on the IU X-Ray dataset.

## Key Results
- IIHT achieves state-of-the-art performance with BLEU-1: 0.513, BLEU-2: 0.375, BLEU-3: 0.297, BLEU-4: 0.245
- METEOR score of 0.264 and ROUGE-L of 0.492 demonstrate strong linguistic fluency and content overlap
- Outperforms baseline methods across all evaluation metrics on the IU X-Ray dataset
- Effectively addresses data imbalance by using disease indicators as a bridge between image and text

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Disease indicator embeddings provide a low-dimensional representation that captures correlations among different diseases, mitigating data imbalance.
- Mechanism: By decomposing high-dimensional image features into distinct low-dimensional embeddings, the method can model domain-specific prior knowledge structures and summarize disease indicator information, reducing the dominance of normal region descriptions.
- Core assumption: Disease indicators extracted from reports can be reliably mapped to image features and their states can be accurately classified.
- Evidence anchors: [abstract] "The key idea is using disease indicators as a bridge to improve clinical accuracy while maintaining linguistic fluency." [section 3.1] "The intuitive advantage of separating high-dimensional image features into distinct low-dimensional embeddings is that it facilitates the exploration of the relationships among disease indicators."
- Break condition: If disease indicators are not accurately extracted or classified, the entire hierarchical structure loses its clinical grounding and the method degrades to a standard image-to-text approach.

### Mechanism 2
- Claim: The "data-text-data" conversion strategy enhances interpretability of short disease indicator sequences, improving generated report reliability.
- Mechanism: Converting indicator embeddings to textual word sequences and back allows the model to learn richer representations by leveraging both structured indicator information and natural language context, addressing length and correlation issues in long report sequences.
- Core assumption: Short disease indicator sequences contain sufficient information to guide generation and can be effectively converted between embedding and text representations.
- Evidence anchors: [abstract] "The disease-related indicators are subsequently utilised as input for the indicator expansion module, incorporating the 'data-text-data' strategy." [section 3.2] "This strategy involves converting the input indicator embedding from its original format into a textual sequential word representation and then converting it back to the original format."
- Break condition: If the conversion between indicator embeddings and text sequences loses critical information, the benefits of this approach disappear and generation quality suffers.

### Mechanism 3
- Claim: Self-attention module decomposes disease indicator embeddings into state-aware representations, improving interpretability and clinical accuracy.
- Mechanism: Each indicator embedding is matched with state embeddings (positive, negative, uncertain) through vector similarity, creating state-aware representations that explicitly encode disease status information for more accurate report generation.
- Core assumption: Disease states can be reliably determined through self-attention and these states significantly improve report quality when incorporated into generation.
- Evidence anchors: [section 3.1] "To improve the interpretability of the disease indicator embeddings, a self-attention module is employed... Each indicator embedding is further decomposed to obtain the disease state such as positive, negative or uncertain." [section 3.1] "The calculated self-attention score αtm is the confidence level of classifying disease t into the state m."
- Break condition: If self-attention fails to accurately classify disease states, the state-aware embeddings become unreliable and may introduce noise into the generation process.

## Foundational Learning

- Concept: Multi-label classification for disease states
  - Why needed here: The method needs to assign one of three states (positive, negative, uncertain) to each disease indicator, which is inherently a multi-label problem.
  - Quick check question: How does the loss function LC handle cases where multiple states could apply to a single disease indicator?

- Concept: Hierarchical modeling in medical report generation
  - Why needed here: The three-module architecture (classifier → indicator expansion → generator) creates a hierarchy that addresses different aspects of the generation problem systematically.
  - Quick check question: What advantages does the hierarchical approach have over a single-stage transformer model for this task?

- Concept: Data imbalance handling in medical datasets
  - Why needed here: Medical datasets typically have far more normal cases than abnormal ones, which can bias generation toward normal descriptions unless specifically addressed.
  - Quick check question: How does using disease indicators as a bridge help mitigate the data imbalance problem compared to direct image-to-text approaches?

## Architecture Onboarding

- Component map: Image features → classifier → indicator expansion → generator → final report
- Critical path: Image features → classifier → indicator expansion → generator → final report
- Design tradeoffs:
  - Using disease indicators adds complexity but improves clinical accuracy; simpler image-to-text approaches may be more robust but less clinically relevant
  - The "data-text-data" strategy requires additional computation and training complexity but addresses data imbalance and correlation issues
  - Self-attention for state decomposition improves interpretability but requires accurate state labeling in training data
- Failure signatures:
  - Poor BLEU/METEOR scores indicate issues with linguistic fluency
  - Generated reports dominated by normal descriptions suggest data imbalance not properly addressed
  - Inconsistent disease indicator states across similar images indicate classifier issues
  - Long generation times may indicate inefficiencies in the indicator expansion module
- First 3 experiments:
  1. Ablation study removing the indicator expansion module to quantify its contribution to performance
  2. Comparison of different visual feature extractors (ResNet vs ViT) with and without disease indicators
  3. Test of the "data-text-data" strategy by comparing direct indicator embedding input vs. converted text sequence input to the generator

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the IIHT framework perform on datasets with different levels of data imbalance compared to other medical report generation methods?
- Basis in paper: [explicit] The paper mentions that data imbalance is a key challenge in medical report generation and proposes the IIHT framework to address this issue.
- Why unresolved: The paper only provides results on the IU X-Ray dataset, which may have a specific level of data imbalance. It is unclear how the framework would perform on datasets with varying levels of imbalance.
- What evidence would resolve it: Evaluating the IIHT framework on multiple medical datasets with different levels of data imbalance and comparing its performance to other methods would provide insights into its effectiveness across different scenarios.

### Open Question 2
- Question: How does the inclusion of additional patient information, such as age, gender, and height, impact the performance of the IIHT framework in medical report generation?
- Basis in paper: [inferred] The paper mentions that incorporating additional patient information could be an interesting future direction to investigate from a multi-modal perspective.
- Why unresolved: The paper does not explore the impact of additional patient information on the performance of the IIHT framework. It is unclear whether including such information would enhance the accuracy and comprehensiveness of the generated reports.
- What evidence would resolve it: Conducting experiments to evaluate the IIHT framework with and without additional patient information and comparing the results would provide insights into the potential benefits of incorporating such information.

### Open Question 3
- Question: How does the IIHT framework handle rare or uncommon diseases in medical report generation?
- Basis in paper: [inferred] The paper focuses on generating medical reports for common diseases and indicators but does not specifically address the handling of rare or uncommon diseases.
- Why unresolved: It is unclear how the IIHT framework would perform when faced with rare or uncommon diseases that may have limited training data available.
- What evidence would resolve it: Evaluating the IIHT framework on datasets that include rare or uncommon diseases and comparing its performance to other methods would provide insights into its ability to handle such cases effectively.

## Limitations
- The method relies heavily on accurate disease indicator extraction, which may not generalize well to different datasets or disease categories
- The "data-text-data" conversion strategy adds complexity and may introduce information loss during the conversion process
- Limited evaluation on a single dataset (IU X-Ray) restricts generalizability claims to other medical imaging domains

## Confidence
- Medium confidence in the core claim that disease indicators improve medical report generation
- Low confidence in the specific mechanisms (particularly the "data-text-data" strategy and self-attention state decomposition) due to lack of ablation studies
- Key limitation: insufficient evidence that improvements are specifically due to the hierarchical disease indicator approach rather than general architectural enhancements

## Next Checks
1. **Ablation study**: Remove the indicator expansion module entirely and compare performance to the full IIHT model to quantify the specific contribution of the "data-text-data" strategy.

2. **Cross-dataset validation**: Test IIHT on multiple medical imaging datasets (e.g., MIMIC-CXR, ChestX-ray14) to assess generalizability beyond the IU X-Ray dataset.

3. **Human evaluation**: Conduct clinician assessment of generated reports focusing on clinical accuracy and diagnostic completeness, beyond automated metrics like BLEU and ROUGE.