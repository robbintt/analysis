---
ver: rpa2
title: Reconstruction Error-based Anomaly Detection with Few Outlying Examples
arxiv_id: '2305.10464'
source_url: https://arxiv.org/abs/2305.10464
tags:
- anomalies
- training
- anomaly
- data
- normal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of semi-supervised anomaly detection,
  where only a few labeled anomalies are available for training. The proposed method,
  AE-SAD, is a novel approach to train Autoencoders that exploits the information
  of labeled anomalies to increase the contrast between the reconstruction error of
  normal and anomalous examples.
---

# Reconstruction Error-based Anomaly Detection with Few Outlying Examples

## Quick Facts
- arXiv ID: 2305.10464
- Source URL: https://arxiv.org/abs/2305.10464
- Reference count: 40
- Key outcome: AE-SAD outperforms state-of-the-art semi-supervised anomaly detection methods, achieving excellent performance even with few labeled anomalies and showing robustness to normal data pollution

## Executive Summary
This paper introduces AE-SAD, a novel autoencoder-based approach for semi-supervised anomaly detection that leverages limited labeled anomalies to enhance the contrast between normal and anomalous data reconstruction errors. The method modifies the standard autoencoder loss function to penalize reconstruction of known anomalies differently, forcing them to reconstruct poorly while maintaining good reconstruction of normal data. Extensive experiments demonstrate AE-SAD's superior performance across multiple datasets, including its ability to detect unseen anomaly types and maintain effectiveness under normal data pollution.

## Method Summary
AE-SAD modifies the standard autoencoder architecture by introducing a custom loss function that treats normal and anomalous data differently during training. The loss function LF(x) = (1-y)·||x-ˆx||² + λ·y·||F(x)-ˆx||² assigns normal data to minimize reconstruction error while anomalies are trained to minimize error relative to a reverse mapping F(x)=1-x. This creates poor reconstruction of anomalies while maintaining good reconstruction of normals. The autoencoder architecture consists of two encoder layers, a 32-dimensional latent space, and two decoder layers. Training uses standard gradient descent with the modified loss, and evaluation uses standard MSE for anomaly scoring.

## Key Results
- AE-SAD outperforms baseline autoencoder and state-of-the-art semi-supervised methods (OC-SVM, A3, Deep-SAD) on both tabular and image datasets
- The method achieves excellent performance with as few as 8 labeled anomalies in the training set
- AE-SAD maintains effectiveness under normal data pollution, correctly identifying mislabeled anomalies as outliers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AE-SAD modifies the loss function to penalize reconstruction of known anomalies differently from normal data, increasing reconstruction error contrast
- Mechanism: The proposed loss function LF(x) = (1-y)·||x-ˆx||² + λ·y·||F(x)-ˆx||² assigns normal data to minimize reconstruction error and anomalies to minimize error relative to a reverse mapping F(x)=1-x. This creates poor reconstruction of anomalies while maintaining good reconstruction of normals
- Core assumption: Anomalies can be made to reconstruct poorly if the model is trained to map them to a reverse image rather than their original form
- Evidence anchors:
  - [abstract] "our strategy exploits a limited number of anomalous examples to increase the contrast between the reconstruction error associated with normal examples and those associated with both known and unknown anomalies"
  - [section] "by means of the here proposed loss, the Autoencoder is able to take advantage of the information about the known anomalies and use it to increase the contrast between the reconstruction error associated with normal examples and those associated with both known and unknown anomalies"
- Break condition: If F(x) produces reconstructions that are too similar to normal data patterns, the contrast enhancement fails and anomaly detection performance degrades

### Mechanism 2
- Claim: AE-SAD maintains good reconstruction of normal data while forcing anomalies to reconstruct poorly, even when anomalies come from different distributions than training anomalies
- Mechanism: The loss function ensures normal data x are mapped to x̂ similar to x, while anomalies are mapped to F(x) which is substantially different from x. This creates a clear separation in reconstruction error space that generalizes to unseen anomaly types
- Core assumption: The autoencoder can learn to distinguish between normal and anomalous patterns even when trained with limited labeled anomalies, and this distinction transfers to unseen anomaly types
- Evidence anchors:
  - [abstract] "AE-SAD is able to obtain excellent performances even with few anomalous examples in the training set"
  - [section] "we can observe that all the anomalous classes, both seen and unseen, take advantage of the AE–SAD strategy"
- Break condition: If the autoencoder overfits to specific anomaly patterns in the training set, it may fail to generalize to truly unseen anomaly types

### Mechanism 3
- Claim: AE-SAD provides robustness to normal data pollution by correctly identifying mislabeled anomalies as outliers
- Mechanism: The modified loss function gives more weight to correctly labeled anomalies through the λ parameter, forcing the model to treat anomalies as fundamentally different from normal data regardless of their labels in the training set
- Core assumption: The autoencoder can learn to identify anomalies based on their reconstruction behavior rather than relying solely on training labels
- Evidence anchors:
  - [abstract] "AE–SAD outperforms the state-of-the-art competitors on both tabular and image datasets"
  - [section] "AE–SAD improves on the baseline AE and performs better also in this setting"
- Break condition: If pollution levels are too high (majority of training data is mislabeled), the autoencoder may learn to treat normal data as anomalous

## Foundational Learning

- Concept: Autoencoder architecture and reconstruction error
  - Why needed here: Understanding how standard autoencoders work and their limitations in anomaly detection is crucial for grasping why AE-SAD's modifications are necessary
  - Quick check question: What happens to reconstruction error when an autoencoder is trained on both normal and anomalous data using standard MSE loss?

- Concept: Loss function modification and its impact on learning
  - Why needed here: AE-SAD's core innovation is a modified loss function that treats normal and anomalous data differently, requiring understanding of how loss functions shape neural network behavior
  - Quick check question: How does changing the loss function to weight different classes differently affect the gradients and learned representations?

- Concept: Semi-supervised learning settings and contamination handling
  - Why needed here: AE-SAD operates in semi-supervised settings with limited labeled anomalies and must handle polluted training data, requiring understanding of these specific learning scenarios
  - Quick check question: What are the key challenges in semi-supervised anomaly detection compared to fully supervised or unsupervised approaches?

## Architecture Onboarding

- Component map:
  - Input normalization to [0,1] range -> Encoder (2 dense layers) -> Latent space (32 dimensions) -> Decoder (2 dense layers) -> Reconstruction with modified loss

- Critical path:
  1. Input normalization to [0,1] range
  2. Forward pass through encoder-decoder
  3. Compute modified loss based on label y
  4. Backpropagation and weight update
  5. Evaluation using standard MSE for anomaly scoring

- Design tradeoffs:
  - λ parameter: Higher values increase anomaly sensitivity but may reduce normal data reconstruction quality
  - F(x) function: Current choice (1-x) works well for images but may need adaptation for other data types
  - Latent space dimension: 32 provides good balance for tested datasets but may need tuning for different data

- Failure signatures:
  - Normal data reconstruction error increases significantly with λ adjustment
  - Anomaly detection performance degrades on unseen anomaly types
  - Training becomes unstable or converges slowly

- First 3 experiments:
  1. Train on MNIST with class 8 as normal and classes 1,3,5,9 as anomalies with s=8 labeled anomalies
  2. Test with unseen anomaly classes (0,2,4,6,7) to evaluate generalization
  3. Add 5% pollution by mislabeling anomalies as normal and test detection performance

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but suggests future work includes exploring AE-SAD with VAEs and GANs, which implies questions about the method's performance with different autoencoder architectures.

## Limitations
- The specific choice of F(x)=1-x appears somewhat arbitrary and may not generalize optimally to all data types beyond images
- Performance gains vary significantly across datasets, suggesting effectiveness depends heavily on dataset characteristics and hyperparameter tuning
- Lack of architectural details (layer sizes, activations, optimizer settings) creates uncertainty about exact reproducibility

## Confidence
- **High**: The core mechanism of modified loss function for anomaly reconstruction is well-supported and theoretically sound
- **Medium**: The generalization to unseen anomaly types is demonstrated but could benefit from more diverse anomaly types
- **Low**: The specific choice of F(x)=1-x and its optimality for different data types lacks justification

## Next Checks
1. Test AE-SAD with alternative F(x) functions (e.g., random noise, Gaussian blur) on image datasets to validate whether the specific choice of F(x)=1-x is optimal or merely sufficient
2. Evaluate AE-SAD on tabular datasets with continuous features to verify the method's effectiveness beyond image data where F(x)=1-x may not be meaningful
3. Conduct ablation studies varying λ across a wider range to identify optimal settings and understand the tradeoff between normal data reconstruction quality and anomaly detection performance