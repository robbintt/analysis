---
ver: rpa2
title: 'LCE: An Augmented Combination of Bagging and Boosting in Python'
arxiv_id: '2308.07250'
source_url: https://arxiv.org/abs/2308.07250
tags:
- learning
- package
- data
- python
- xgboost
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The LCE package introduces a new ensemble method that combines
  Random Forest and XGBoost with a supplementary diversification approach, achieving
  better generalization performance than either method alone. The package supports
  classification and regression tasks, handles missing data by design, and is compatible
  with scikit-learn pipelines and model selection tools.
---

# LCE: An Augmented Combination of Bagging and Boosting in Python

## Quick Facts
- arXiv ID: 2308.07250
- Source URL: https://arxiv.org/abs/2308.07250
- Reference count: 15
- Primary result: LCE achieves best average rank (1.0) vs Random Forest (2.1) and XGBoost (2.0) on 10 datasets

## Executive Summary
LCE is a Python package implementing a novel ensemble method that combines Random Forest and XGBoost with a supplementary diversification approach. The method achieves superior generalization performance by learning different parts of the training data at each decision node through a cascade mechanism. LCE is designed to be compatible with scikit-learn pipelines, handles missing data by design, and includes comprehensive documentation and testing. Evaluation on 10 public datasets demonstrates LCE's effectiveness, winning or tying on 10 out of 20 dataset-method comparisons.

## Method Summary
LCE combines bagging (Random Forest) and boosting (XGBoost) strategies to create an ensemble that learns different parts of the training data at each decision node. The algorithm applies XGBoost as a base learner at each node, adds the output probabilities as new attributes to the dataset, and then uses bagging to create multiple diverse predictors. This cascade mechanism captures both global and local patterns that neither Random Forest nor XGBoost can capture alone. The method supports both classification and regression tasks, handles missing data by design, and is compatible with scikit-learn pipelines and model selection tools.

## Key Results
- LCE achieves best average rank (1.0) compared to Random Forest (2.1) and XGBoost (2.0) across 10 datasets
- LCE wins or ties on 10 out of 20 dataset-method comparisons
- The method handles missing data by design without requiring preprocessing
- LCE follows scikit-learn conventions and achieves 100% code coverage testing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LCE achieves superior generalization by combining bagging and boosting while learning different parts of training data at each decision node
- Core assumption: Different parts of training data contain complementary information discoverable through divide-and-conquer strategy
- Evidence anchors:
  - "LCE combines their strengths and adopts a complementary diversification approach to obtain a better generalizing predictor"
  - "LCE is a method adopting these two diversification approaches. First, (i) LCE combines the two well-known methods that modify the distribution of the original training data with complementary effects on the bias-variance trade-off"
- Break condition: If additional features from boosting outputs don't provide meaningful information for subsequent splits

### Mechanism 2
- Claim: scikit-learn compatibility enables seamless integration into existing workflows
- Core assumption: scikit-learn conventions are sufficient for most machine learning workflows
- Evidence anchors:
  - "Code Quality. To allow interaction with scikit-learn - the current reference framework for traditional machine learning - and ease the maintenance of the code, LCE package adheres to scikit-learn conventions"
  - "Therefore, LCE can interact with scikit-learn pipelines and model selection tools"
- Break condition: If scikit-learn interfaces are insufficient for LCE's requirements

### Mechanism 3
- Claim: Comprehensive documentation and open-source nature reduce adoption barriers
- Core assumption: Comprehensive documentation and open-source licensing are critical for adoption
- Evidence anchors:
  - "Documentation. LCE package is made available with a complete documentation hosted on Read the Docs"
  - "Openness to new developers. LCE is available on GitHub, open source (license Apache 2.0) and compatible with all operating systems"
- Break condition: If documentation is insufficient or contribution process creates friction

## Foundational Learning

- Concept: Ensemble methods and bias-variance tradeoff
  - Why needed: LCE combines bagging (variance reduction) and boosting (bias reduction)
  - Quick check: What is the primary difference between how bagging and boosting reduce model error?

- Concept: Decision tree algorithms and limitations
  - Why needed: LCE builds on tree principles with additional cascade complexity
  - Quick check: What are main limitations of single decision trees that ensembles address?

- Concept: Python package development and testing
  - Why needed: Paper emphasizes 100% code coverage and CI/CD practices
  - Quick check: What are benefits and drawbacks of 100% code coverage for ML packages?

## Architecture Onboarding

- Component map: LCEClassifier/LCERegressor -> BaseEstimator -> scikit-learn components -> numpy/pandas/xgboost/hyperopt
- Critical path: Load data → Create LCE instance → Fit model → Make predictions
- Design tradeoffs: Increased complexity and training time vs better generalization
- Failure signatures: Poor performance if cascade mechanism fails, memory issues with large datasets, integration problems with API changes
- First 3 experiments:
  1. Run Iris dataset example to verify basic functionality
  2. Compare LCE vs Random Forest vs XGBoost on small dataset using cross-validation
  3. Test LCE's missing data handling by introducing NaN values

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but identifies several areas for future work including adding base learner selection as a hyperparameter and further improving the diversification approach.

## Limitations
- No statistical significance testing for performance differences across datasets
- Missing data handling mechanism not detailed or empirically validated
- Software development claims (100% coverage, CI) stated but not independently verified

## Confidence
- Evaluation methodology: Medium (no significance testing)
- Missing data claims: Low (mechanism not detailed)
- Software quality claims: Medium (stated but unverified)

## Next Checks
1. Conduct paired statistical tests (Wilcoxon signed-rank) on 10 datasets to determine if performance improvements are significant
2. Create benchmark dataset with controlled missing values to evaluate LCE's handling compared to imputation methods
3. Implement ablation study removing components (bagging, boosting cascade) to quantify individual contributions to performance