---
ver: rpa2
title: Example-Based Explanations of Random Forest Predictions
arxiv_id: '2311.14581'
source_url: https://arxiv.org/abs/2311.14581
tags:
- examples
- number
- training
- forest
- predictions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of explaining random forest predictions
  by identifying which training examples most influence each prediction. It demonstrates
  that each prediction can be expressed as a weighted sum of training example labels,
  with weights determined by leaf node memberships.
---

# Example-Based Explanations of Random Forest Predictions

## Quick Facts
- arXiv ID: 2311.14581
- Source URL: https://arxiv.org/abs/2311.14581
- Reference count: 16
- Key outcome: Random forest predictions can be expressed as weighted sums of training example labels, with weights determined by leaf node memberships, enabling substantial reduction in explanation complexity while maintaining or improving performance.

## Executive Summary
This paper introduces a method for explaining random forest predictions by identifying which training examples most influence each prediction. The approach demonstrates that predictions can be expressed as weighted sums of training example labels, with weights determined by leaf node memberships. By modifying the prediction procedure to include only top-weighted examples, the method provides exact, example-based explanations without approximating the underlying model.

## Method Summary
The core method involves tracking which training examples fall into the same leaf nodes as test objects across all trees in the random forest. Weights are calculated based on normalized leaf membership frequencies, and predictions can be modified to use only the top-weighted examples either by specifying a fixed number k or a cumulative weight threshold c. This provides exact example-based explanations that maintain or improve predictive performance while significantly reducing the number of examples needed for explanation.

## Key Results
- Prediction explanations can be reduced by 85-90% for regression and 99.8% for classification while maintaining or improving performance
- With MNIST digit classification, accuracy was maintained while reducing explanations from nearly 6000 examples to as few as 10 examples per prediction
- Increasing the number of trees leads to more specific leaf nodes with fewer training examples per leaf, increasing the total number of examples with non-zero weights

## Why This Works (Mechanism)

### Mechanism 1
Random forest predictions can be expressed as weighted sums of training example labels. Each test object falls into specific leaf nodes across all trees, and the weight for each training example is computed as the normalized frequency of its occurrence in those leafs. This mechanism assumes leaf node memberships across the forest fully capture the contribution of each training example to the prediction.

### Mechanism 2
Reducing the number of training examples used in predictions can maintain or improve predictive performance. By selecting only the top-weighted training examples, the prediction procedure can filter out noisy or redundant examples while preserving the core predictive signal. This assumes the most heavily weighted examples capture essential information needed for accurate prediction.

### Mechanism 3
Dataset properties and random forest hyperparameters affect the number of training examples with non-zero weights. Increasing the number of trees leads to more specific leaf nodes with fewer training examples per leaf, increasing the total number of examples with non-zero weights. Increasing minimum leaf sample size has the opposite effect by forcing more examples into the same leafs.

## Foundational Learning

- Concept: Leaf node membership and weight calculation in random forests
  - Why needed here: The entire explanation mechanism depends on understanding how training examples contribute to predictions through their presence in leaf nodes
  - Quick check question: How is the weight for a training example calculated when a test object falls into a leaf node?

- Concept: Morgan fingerprints and molecular feature representation
  - Why needed here: The Lipophilicity dataset uses Morgan fingerprints as features, which are binary vectors representing molecular structures
  - Quick check question: What type of features are used to represent chemical compounds in the Lipophilicity dataset?

- Concept: Binary classification vs multiclass classification in random forests
  - Why needed here: The paper frames the regression problem as both binary and multiclass classification to test the explanation method across different prediction tasks
  - Quick check question: How are regression targets transformed into binary classification labels in the experiments?

## Architecture Onboarding

- Component map: Random forest model -> Weight calculation module -> Top-weighted example selection -> Modified prediction procedure
- Critical path: 1) Train random forest with standard hyperparameters 2) For each test object, record which training examples fall into the same leaf nodes 3) Calculate weights based on normalized leaf membership frequencies 4) Sort examples by weight and select top-k or cumulative threshold 5) Compute prediction using only selected examples 6) Evaluate performance impact compared to standard predictions
- Design tradeoffs: Number of trees vs explanation complexity (more trees improve accuracy but increase explanation complexity), minimum leaf sample size vs example count (smaller leaf sizes reduce examples but may reduce accuracy), feature dimensionality vs example count (higher dimensionality can reduce examples by creating more specific leaf nodes)
- Failure signatures: Performance degradation when reducing examples beyond a threshold, unexpectedly high number of examples with non-zero weights despite hyperparameter tuning, inconsistent behavior across different datasets or prediction tasks
- First 3 experiments: 1) Implement weight calculation and verify that predictions match standard random forest predictions when using all examples 2) Test the top-k selection algorithm on a small dataset to ensure correct example selection and weight normalization 3) Evaluate the cumulative weight threshold method on a regression task to find the optimal threshold that maintains performance while reducing examples

## Open Questions the Paper Calls Out

### Open Question 1
How does the dimensionality of the feature space affect the effective number of training examples used in random forest predictions? The paper observes that increasing the number of features leads to a decreased number of training examples used in predictions for regression and multiclass classification tasks, but this relationship may vary across different types of data and model configurations.

### Open Question 2
What is the impact of the minimum leaf sample size on the interpretability and predictive performance of random forests? The paper finds that increasing the minimum leaf sample size deteriorates both predictive performance and the number of examples needed to explain predictions, but optimal settings for different types of tasks remain unexplored.

### Open Question 3
How can example-based explanations be effectively combined with other explanation techniques, such as feature scores or rule sets? The paper mentions the potential for combining example-based explanations with other techniques but does not explore this in detail or investigate how these combined explanations might improve user understanding.

## Limitations

- The weight calculation mechanism assumes all training examples present in leaf nodes contribute meaningfully to predictions, potentially overlooking the impact of bootstrap sampling where some examples are excluded from certain trees
- Performance improvements observed may be specific to the datasets tested (Lipophilicity and MNIST) and may not generalize across all problem domains
- The computational overhead of tracking leaf memberships and calculating weights for each prediction could offset the benefits of reduced explanation complexity

## Confidence

**High Confidence**: The core mathematical framework for expressing predictions as weighted sums of training examples is well-established and verifiable. The algorithms for top-k and cumulative weight threshold selection are clearly defined and implementable.

**Medium Confidence**: The empirical claims about performance improvements with reduced examples are based on specific datasets and may not generalize to all domains. The relationship between random forest hyperparameters and explanation complexity is demonstrated but could vary with different implementations.

**Low Confidence**: The claim that this approach provides "exact" explanations without approximating the underlying model is somewhat questionable, as the explanation mechanism itself introduces a new layer of approximation through weight calculation and example selection.

## Next Checks

1. Cross-dataset validation: Test the explanation method on diverse datasets beyond chemical compounds and images to verify generalizability of performance claims.

2. Computational overhead measurement: Quantify the runtime and memory overhead of tracking leaf memberships and calculating weights compared to standard random forest predictions.

3. Bootstrap sampling impact: Investigate how out-of-bag examples affect weight distributions and whether the explanation mechanism can distinguish between examples that were actually used in training versus those excluded by bootstrap sampling.