---
ver: rpa2
title: 'MalFake: A Multimodal Fake News Identification for Malayalam using Recurrent
  Neural Networks and VGG-16'
arxiv_id: '2310.18263'
source_url: https://arxiv.org/abs/2310.18263
tags:
- news
- fake
- multimodal
- detection
- malayalam
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes MalFake, a multimodal deep learning framework
  for detecting fake news in Malayalam. It combines text (using LSTM with pre-trained
  Word2Vec embeddings) and image features (using VGG-16) to classify news articles
  as real or fake.
---

# MalFake: A Multimodal Fake News Identification for Malayalam using Recurrent Neural Networks and VGG-16

## Quick Facts
- arXiv ID: 2310.18263
- Source URL: https://arxiv.org/abs/2310.18263
- Reference count: 6
- Primary result: Proposed multimodal deep learning framework for Malayalam fake news detection combining text (LSTM with Word2Vec) and image (VGG-16) features

## Executive Summary
This paper introduces MalFake, a novel multimodal deep learning framework for detecting fake news in Malayalam. The system combines text features extracted using LSTM with pre-trained Word2Vec embeddings and image features extracted using VGG-16, then fuses these modalities before classification. The model was trained and tested on a dataset of 1,852 Malayalam news items (926 fake, 926 real). Results show the multimodal approach achieves precision of 0.70 for real news and 0.64 for fake news, with an overall accuracy of 0.67, outperforming single-modality approaches and representing the first application of multimodal deep learning for Malayalam fake news detection.

## Method Summary
MalFake combines text and image modalities for fake news detection in Malayalam. Text headlines are processed through an LSTM model using pre-trained Word2Vec embeddings to capture linguistic patterns. Images are processed through a VGG-16 model to extract visual features. The outputs from both models are concatenated and passed through dense layers for final classification as real or fake news. The dataset contains 1,852 Malayalam news items with balanced classes (926 fake, 926 real), including headlines, URLs, and associated images.

## Key Results
- Achieved precision of 0.70 for real news classification and 0.64 for fake news classification
- Overall accuracy of 0.67 on the 1,852-sample Malayalam dataset
- First multimodal deep learning approach for Malayalam fake news detection
- Outperforms single-modality approaches by leveraging complementary text and image information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multimodal fusion improves fake news detection accuracy by leveraging complementary information from text and image modalities.
- Mechanism: The model concatenates LSTM-extracted text features and VGG-16 extracted image features before classification, allowing the network to learn joint representations that capture both linguistic and visual cues of fake news.
- Core assumption: Text and image modalities contain complementary signals that, when combined, provide better discriminative power than either modality alone.
- Evidence anchors:
  - [abstract]: "Models trained with more than one modality typically outperform models taught with only one modality."
  - [section]: "This combination of NLP and deep learning techniques allows a more comprehensive assessment of the presented information."
  - [corpus]: Weak evidence - no direct citations to multimodal fusion studies in the corpus, though related papers exist.
- Break condition: If either modality provides noisy or contradictory signals, fusion could degrade performance rather than improve it.

### Mechanism 2
- Claim: Pre-trained embeddings provide linguistic knowledge that helps the model recognize fake news patterns in Malayalam.
- Mechanism: Word2Vec embeddings trained on Malayalam text provide semantic understanding that helps the LSTM identify linguistic patterns associated with fake news.
- Core assumption: Pre-trained embeddings capture meaningful semantic relationships in Malayalam that are relevant to fake news detection.
- Evidence anchors:
  - [section]: "We train our LSTM model with pre-trained word embeddings in our Multimodal Fake News Detection project, giving it a solid linguistic base."
  - [section]: "These word vectors play a crucial role in enhancing the understanding of textual content and improving the accuracy of our fake news detection system."
  - [corpus]: Weak evidence - no specific corpus evidence for Malayalam Word2Vec effectiveness.
- Break condition: If the pre-trained embeddings don't capture domain-specific fake news patterns, they may not help and could introduce noise.

### Mechanism 3
- Claim: Transfer learning from VGG-16 provides effective image feature extraction without requiring extensive image data.
- Mechanism: Using a pre-trained VGG-16 model allows the system to extract meaningful visual features from news images without training a convolutional network from scratch.
- Core assumption: Visual patterns in news images (like manipulated content or suspicious imagery) are consistent enough across domains to be captured by a pre-trained model.
- Evidence anchors:
  - [section]: "We use the VGG16 transfer learning model to extract useful image characteristics to make use of this."
  - [section]: "This model can recognize various visual patterns and features because it was pre-trained on a sizable image dataset."
  - [corpus]: Weak evidence - no direct corpus evidence for VGG-16 effectiveness on news images specifically.
- Break condition: If news images have very different characteristics than ImageNet images, transfer learning may not be effective.

## Foundational Learning

- Concept: Recurrent Neural Networks (LSTM)
  - Why needed here: LSTMs can capture sequential dependencies in text, which is crucial for understanding the context and flow of news articles that may contain deceptive patterns.
  - Quick check question: What problem do LSTMs solve that traditional feedforward networks cannot handle effectively in text processing?

- Concept: Transfer Learning
  - Why needed here: Transfer learning allows the model to leverage knowledge from pre-trained models (VGG-16) without requiring large amounts of labeled data for image feature extraction.
  - Quick check question: Why is transfer learning particularly valuable for low-resource languages like Malayalam?

- Concept: Multimodal Fusion
  - Why needed here: Combining text and image features allows the model to capture complementary information that neither modality alone might detect, improving overall detection accuracy.
  - Quick check question: What are the potential risks of multimodal fusion when one modality contains contradictory information?

## Architecture Onboarding

- Component map:
  Text preprocessing pipeline → LSTM text model → Text features
  Image preprocessing pipeline → VGG-16 model → Image features
  Concatenation layer → Dense layers → Classification output
  Dataset loader with 1,852 Malayalam news items (926 fake, 926 real)

- Critical path:
  Text preprocessing → LSTM feature extraction → Image preprocessing → VGG-16 feature extraction → Feature concatenation → Classification → Output

- Design tradeoffs:
  - Using pre-trained models vs. training from scratch (faster training but potentially less domain-specific)
  - Concatenation vs. attention-based fusion (simpler but may miss complex interactions)
  - Fixed sequence length vs. dynamic padding (computational efficiency vs. information preservation)

- Failure signatures:
  - High accuracy on training but low on validation suggests overfitting
  - Text-only or image-only models outperform the multimodal model suggests poor feature fusion
  - Consistently misclassifying certain types of news suggests bias in training data

- First 3 experiments:
  1. Train text-only LSTM model to establish baseline performance
  2. Train image-only VGG-16 model to establish baseline performance
  3. Train multimodal model with different fusion strategies (concatenation, addition, attention) to compare effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the MalFake model compare to state-of-the-art models for fake news detection in other languages?
- Basis in paper: [explicit] The authors mention that the MalFake model achieves a precision of 0.70 for real news and 0.64 for fake news, with an overall accuracy of 0.67. However, they do not compare these results to models developed for other languages.
- Why unresolved: The authors do not provide a direct comparison of the MalFake model's performance to models developed for other languages, making it difficult to assess its relative effectiveness.
- What evidence would resolve it: A comprehensive comparison of the MalFake model's performance to state-of-the-art models for fake news detection in other languages, using the same evaluation metrics and datasets, would provide a clearer understanding of its relative effectiveness.

### Open Question 2
- Question: How does the inclusion of additional modalities, such as audio or video, affect the performance of the MalFake model?
- Basis in paper: [inferred] The authors mention that the MalFake model combines text and image features, but they do not explore the potential benefits of incorporating additional modalities like audio or video.
- Why unresolved: The authors do not investigate the impact of including additional modalities on the model's performance, leaving the potential benefits of a more comprehensive multimodal approach unexplored.
- What evidence would resolve it: Experimenting with the inclusion of audio or video features in the MalFake model and comparing its performance to the original model would provide insights into the potential benefits of a more comprehensive multimodal approach.

### Open Question 3
- Question: How does the MalFake model perform on fake news detection in other low-resource languages?
- Basis in paper: [explicit] The authors state that the MalFake model is designed for fake news detection in Malayalam, a low-resource language. However, they do not explore its potential applicability to other low-resource languages.
- Why unresolved: The authors do not investigate the generalizability of the MalFake model to other low-resource languages, leaving its potential applicability to other linguistic contexts unexplored.
- What evidence would resolve it: Evaluating the MalFake model's performance on fake news detection in other low-resource languages, using appropriate datasets and evaluation metrics, would provide insights into its generalizability and potential applicability to other linguistic contexts.

## Limitations
- Dataset size limitation: The 1,852-sample dataset may limit the model's ability to generalize to diverse fake news patterns
- Implementation transparency: Missing details about specific pre-trained Word2Vec model and exact classification layer architecture make exact replication challenging
- First-to-field claim: The claim of being the "first" multimodal approach for Malayalam fake news detection cannot be independently verified due to limited publication records

## Confidence
- **High Confidence**: The overall approach of multimodal fusion for fake news detection is well-established in the literature, and the reported performance metrics (precision 0.70/0.64, accuracy 0.67) are plausible for a single-modality baseline.
- **Medium Confidence**: The specific architecture combining LSTM with pre-trained embeddings and VGG-16 transfer learning is reasonable, but the effectiveness depends heavily on implementation details not fully specified.
- **Low Confidence**: The claim of being the "first" multimodal approach for Malayalam fake news detection cannot be independently verified due to limited publication records in this specific domain.

## Next Checks
1. **Dataset Validation**: Verify the class distribution and content balance of the 1,852 samples to ensure the reported metrics aren't inflated by dataset bias or easy-to-classify examples.
2. **Baseline Comparison**: Implement and compare against text-only and image-only baselines to confirm the multimodal approach provides meaningful improvement over single-modality approaches.
3. **Generalization Testing**: Test the model on a separate, unseen dataset of Malayalam fake news to evaluate whether the reported performance metrics hold across different news sources and topics.