---
ver: rpa2
title: 'Boolformer: Symbolic Regression of Logic Functions with Transformers'
arxiv_id: '2309.12207'
source_url: https://arxiv.org/abs/2309.12207
tags:
- boolean
- head
- which
- functions
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents Boolformer, a Transformer-based model for
  end-to-end symbolic regression of Boolean functions. The core idea is to frame the
  task as sequence prediction: the model is trained to map truth tables to Boolean
  formulas expressed in terms of AND, OR, and NOT gates.'
---

# Boolformer: Symbolic Regression of Logic Functions with Transformers

## Quick Facts
- arXiv ID: 2309.12207
- Source URL: https://arxiv.org/abs/2309.12207
- Reference count: 40
- Primary result: Transformer-based model achieves symbolic regression of Boolean functions, outperforming genetic algorithms while providing interpretable formulas

## Executive Summary
Boolformer is a Transformer-based model that performs symbolic regression of Boolean functions by treating the problem as sequence prediction from truth tables to logical formulas. The model generates compact expressions using AND, OR, and NOT gates, demonstrating strong performance on both synthetic and real-world binary classification tasks. When applied to gene regulatory network inference, Boolformer achieves competitive results with state-of-the-art genetic algorithms but operates orders of magnitude faster. The approach shows particular promise for interpretable machine learning, producing formulas that are significantly more compact than random forest models.

## Method Summary
The model treats symbolic regression as a sequence-to-sequence task where truth tables serve as input and Boolean formulas as output. A Transformer architecture maps input pairs (x, y) ∈ {0, 1}^D+1 to predicted formulas. The model is trained on synthetically generated Boolean functions created using random unary-binary trees with AND, OR, and NOT gates. Training uses cross-entropy loss with the Adam optimizer, and beam search is employed for inference. The approach handles noisy and incomplete data by learning to identify relevant variables and filter out noise, with the model trained on varying noise levels to improve robustness.

## Key Results
- Successfully predicts compact formulas for complex unseen functions (D≥7) where memorization is impossible
- Handles noisy and incomplete observations with excellent ability to identify function support and discard noise
- Achieves competitive performance on gene regulatory network inference, outperforming genetic algorithms while being significantly faster
- Provides interpretable alternative to black-box models on real-world binary classification datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Boolformer achieves symbolic regression by framing the problem as sequence prediction of Boolean formulas from truth tables.
- Mechanism: The model takes a truth table as input (represented as a sequence of input-output pairs) and predicts the corresponding Boolean formula as output. This leverages the Transformer's strength in sequence-to-sequence tasks.
- Core assumption: The problem of symbolic regression can be effectively reformulated as a sequence prediction task where the input is the truth table and the output is the formula.
- Evidence anchors: [abstract] "First, we show that it can predict compact formulas for complex functions not seen during training, given their full truth table." [section] "Each training example is a synthetically generated function whose truth table is the input and whose formula is the target."

### Mechanism 2
- Claim: The Boolformer can handle noisy and incomplete data by learning to identify relevant variables and filter out noise.
- Mechanism: During training, the model is exposed to varying levels of noise (bit flipping, irrelevant variables, partial observability). This forces the model to learn robust representations that can distinguish signal from noise.
- Core assumption: The model can learn to identify the support of the function (which variables are relevant) even in the presence of noise and irrelevant variables.
- Evidence anchors: [abstract] "Then, we demonstrate that even with incomplete or noisy observations, Boolformer is still able to find good approximate expressions." [section] "Performance improves as the number of input points N increases, and degrades as the amount of random flipping and the number of inactive variables increase. but the influence of the two latter parameters is rather mild."

### Mechanism 3
- Claim: The Boolformer provides interpretable results by generating compact Boolean formulas.
- Mechanism: The model is trained to predict compact formulas using AND, OR, and NOT gates. This inherently produces interpretable results compared to black-box models like neural networks.
- Core assumption: The model's architecture and training objective bias it towards generating compact formulas, which are inherently more interpretable than complex interpolators.
- Evidence anchors: [abstract] "We evaluate Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods." [section] "Since the Boolean formula it outputs only contains a few dozen nodes at most, whereas the trees of random forest use up to several hundreds."

## Foundational Learning

- Concept: Boolean algebra and logical operators (AND, OR, NOT)
  - Why needed here: The model operates on Boolean functions and generates formulas using these operators.
  - Quick check question: Can you express the XOR function using only AND, OR, and NOT operators?

- Concept: Truth tables and their representation
  - Why needed here: The model takes truth tables as input and generates formulas based on them.
  - Quick check question: How would you represent the truth table for a 2-input AND gate as a sequence of input-output pairs?

- Concept: Sequence-to-sequence modeling with Transformers
  - Why needed here: The model uses a Transformer architecture to map sequences (truth tables) to sequences (formulas).
  - Quick check question: What is the role of positional encodings in a Transformer, and why might they be removed in this model?

## Architecture Onboarding

- Component map: Embedder → Transformer → Output layer
- Critical path: Embedder → Transformer → Output layer
- Design tradeoffs:
  - Quadratic complexity of Transformers vs. embedding approach to handle variable input dimensions
  - Beam search vs. greedy decoding for formula generation
  - Simplification of formulas vs. preserving all possible solutions
- Failure signatures:
  - Model generates overly complex or incorrect formulas
  - Model fails to generalize to unseen functions
  - Model is sensitive to noise and irrelevant variables
- First 3 experiments:
  1. Train the model on a simple dataset (e.g., 2-input AND, OR, NOT) and evaluate its ability to generate correct formulas
  2. Test the model's robustness to noise by adding bit flipping to the input data and observing the impact on formula generation
  3. Evaluate the model's ability to handle incomplete data by providing partial truth tables and measuring the accuracy of the generated formulas

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the model's performance scale with the number of variables in the truth table, and what is the theoretical limit for its scalability?
- Basis in paper: [explicit] The paper mentions that due to the quadratic cost of self-attention, the number of input points is limited to a thousand during training, which limits the model's performance on high-dimensional functions and large datasets.
- Why unresolved: The paper does not provide a detailed analysis of how the model's performance scales with the number of variables in the truth table, nor does it discuss the theoretical limits of its scalability.
- What evidence would resolve it: Experimental results showing the model's performance on truth tables with varying numbers of variables, and a theoretical analysis of the model's scalability limits.

### Open Question 2
- Question: How does the inclusion of the XOR gate in the generated Boolean functions affect the model's performance and the complexity of the predicted formulas?
- Basis in paper: [inferred] The paper mentions that the logical functions which the model is trained on do not include the XOR gate explicitly, limiting both the compactness of the formulas it predicts and its ability to express complex formulas such as parity functions.
- Why unresolved: The paper does not explore the impact of including the XOR gate in the generated Boolean functions on the model's performance and the complexity of the predicted formulas.
- What evidence would resolve it: Experimental results comparing the model's performance and the complexity of the predicted formulas with and without the inclusion of the XOR gate in the generated Boolean functions.

### Open Question 3
- Question: How does the model's performance on real-world datasets compare to other interpretable machine learning methods, such as decision trees or rule-based models?
- Basis in paper: [explicit] The paper mentions that the model's F1 score is slightly below that of a random forest of 100 trees but slightly above that of the random forest with a single tree, and that the model provides an interpretable alternative to classic machine learning methods on tabular data.
- Why unresolved: The paper does not provide a detailed comparison of the model's performance on real-world datasets with other interpretable machine learning methods, such as decision trees or rule-based models.
- What evidence would resolve it: Experimental results comparing the model's performance on real-world datasets with other interpretable machine learning methods, such as decision trees or rule-based models.

## Limitations

- Quadratic complexity of self-attention limits scalability to high-dimensional functions and large datasets
- Synthetic function generation may not capture the complexity of real-world Boolean functions
- Simplification step using boolean.py is only briefly described and its impact on performance is unclear

## Confidence

- **High Confidence**: The model's ability to generate correct formulas for unseen functions given full truth tables (D≥7 functions)
- **Medium Confidence**: The model's performance on noisy and incomplete data
- **Low Confidence**: The claim of interpretability through compact formulas

## Next Checks

1. **Real-world noise validation**: Test the model on datasets with naturally occurring noise patterns (e.g., gene expression data with batch effects) rather than synthetic bit-flipping to verify robustness claims.

2. **Formula interpretability analysis**: Conduct a user study with domain experts to assess whether the generated Boolean formulas provide actionable insights beyond standard black-box models, particularly for the gene regulatory network inference task.

3. **Scalability stress test**: Systematically evaluate model performance on functions with D>10 inputs to quantify the practical limits of the self-attention mechanism and validate whether the proposed solutions (linear attention, input subsampling) maintain accuracy while improving efficiency.