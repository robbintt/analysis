---
ver: rpa2
title: Few-shot Anomaly Detection in Text with Deviation Learning
arxiv_id: '2308.11780'
source_url: https://arxiv.org/abs/2308.11780
tags:
- anomaly
- detection
- data
- learning
- scores
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes FATE, a few-shot anomaly detection framework
  for text that uses a limited number of labeled anomalies. It employs a multi-head
  self-attention layer to learn anomaly scores end-to-end, optimizing them directly
  using deviation learning.
---

# Few-shot Anomaly Detection in Text with Deviation Learning

## Quick Facts
- arXiv ID: 2308.11780
- Source URL: https://arxiv.org/abs/2308.11780
- Reference count: 39
- Key outcome: FATE achieves 3.85-7.8 percentage points higher AUROC than state-of-the-art baselines while requiring only 10-20 labeled anomalies

## Executive Summary
FATE introduces a novel few-shot anomaly detection framework for text that leverages deviation learning with multi-head self-attention. The method learns multiple orthogonal anomaly scores end-to-end, optimizing them to push normal samples toward a Gaussian reference distribution while forcing anomalies to deviate significantly. By requiring only 10-20 labeled anomalies, FATE addresses the critical challenge of limited labeled data in anomaly detection tasks.

## Method Summary
FATE employs a BERT-based sentence encoder followed by a multi-head self-attention (MHSA) layer that generates multiple orthogonal anomaly score vectors. These scores are aggregated using a top-K multiple instance learning (MIL) approach, where the K highest-scoring instances are averaged to produce a final anomaly score. The model is trained using deviation learning with a Gaussian prior, optimizing a contrastive loss that pushes normal samples toward the reference mean while forcing anomalies to deviate. The framework also includes an orthogonality constraint to ensure distinct attention heads capture different aspects of anomalousness.

## Key Results
- Achieves 3.85-7.8 percentage points higher AUROC than best baseline methods on three benchmark datasets
- Requires only 10 labeled anomalies to achieve strong performance, demonstrating exceptional sample efficiency
- Maintains robust performance even with 15% data contamination, showing resilience to noise

## Why This Works (Mechanism)

### Mechanism 1
Multi-head self-attention enables the model to learn multiple distinct anomaly scores that capture different aspects of anomalousness in text. The MHSA layer transforms input embeddings into multiple attention heads, each producing a distinct score vector. These orthogonal score vectors represent different semantic contexts of anomalousness, allowing the model to capture diverse anomaly patterns. The core assumption is that different anomaly patterns in text can be effectively captured by separate attention heads that focus on different semantic contexts.

### Mechanism 2
Deviation learning with Z-scores provides an effective way to distinguish anomalies from normal samples by pushing scores toward a reference distribution. Normal samples are pushed to have scores close to the mean of a reference Gaussian distribution, while anomalous samples are forced to deviate significantly from this reference in the upper tail. The core assumption is that a Gaussian distribution can effectively model the distribution of normal anomaly scores, making Z-scores a valid metric for deviation.

### Mechanism 3
Multiple instance learning (MIL) with top-K scoring effectively aggregates multiple anomaly scores into a single representative score for each text instance. Each text is represented as a set of K highest-scoring instances from the MHSA layer outputs, and the final anomaly score is the average of these top K scores. The core assumption is that the most anomalous aspects of a text are captured by the top-scoring instances from the MHSA layer.

## Foundational Learning

- Concept: Deviation learning with Z-scores
  - Why needed here: It provides a principled way to contrast normal and anomalous samples using statistical deviation from a reference distribution
  - Quick check question: How does the Z-score formula in Equation 6 ensure that normal samples cluster around the reference mean while anomalies are pushed away?

- Concept: Multi-head self-attention
  - Why needed here: It allows the model to capture multiple semantic contexts of anomalousness simultaneously through different attention heads
  - Quick check question: Why does Equation 1 apply softmax to each column of the attention matrix rather than the entire matrix?

- Concept: Multiple instance learning (MIL)
  - Why needed here: It enables aggregation of multiple anomaly scores into a single representative score for each text instance
  - Quick check question: What is the purpose of selecting the top-K instances in Equation 4 rather than averaging all instances?

## Architecture Onboarding

- Component map: Text → Sentence Encoder → MHSA → Top-K MIL → Anomaly Score → Deviation Loss
- Critical path: Text → Sentence Encoder → MHSA → Top-K MIL → Anomaly Score → Deviation Loss
- Design tradeoffs:
  - MHSA vs direct scoring: MHSA provides multiple perspectives but adds complexity
  - Gaussian vs other distributions: Gaussian is simple and interpretable but may not fit all data
  - Top-K vs all instances: Top-K focuses on most anomalous aspects but may miss subtle patterns
- Failure signatures:
  - High orthogonality loss: Attention heads are not learning distinct patterns
  - Low deviation loss: Model is not effectively separating normal and anomalous scores
  - Performance plateau with more anomalies: Model may not generalize to unseen anomaly types
- First 3 experiments:
  1. Vary K in top-K MIL (1% to 20%) and measure impact on AUROC
  2. Test different prior distributions (Gaussian vs uniform vs empirical) for reference scores
  3. Compare MHSA vs direct scoring from sentence encoder on a small dataset

## Open Questions the Paper Calls Out

### Open Question 1
How does FATE's performance degrade when dealing with entirely unseen anomaly classes during testing? The paper mentions that FATE's performance is affected when there are no representative samples from one of the outlier classes in the training set, highlighting a limitation in managing previously unseen classes. The paper does not provide detailed analysis or experiments specifically focused on unseen anomaly classes, leaving the extent of performance degradation unclear. Conducting experiments where FATE is tested on datasets containing entirely new anomaly classes not present during training would provide insights into its robustness and generalization capabilities.

### Open Question 2
Can FATE's interpretability be enhanced to provide more detailed explanations for its anomaly detection decisions? The paper mentions that interpretability is a future work goal, indicating that current interpretability features are limited. The paper does not explore methods to improve or quantify the interpretability of FATE's decision-making process. Developing and implementing techniques to visualize or explain the contributions of different features or attention heads in FATE's decision-making process would enhance its interpretability.

### Open Question 3
How does FATE's performance compare to other few-shot learning methods in anomaly detection beyond text? The paper focuses on FATE's performance in text anomaly detection but does not compare it to few-shot learning methods in other domains like images or graphs. The paper does not explore the applicability or performance of FATE in non-textual domains, limiting understanding of its versatility. Testing FATE on datasets from other domains, such as image or graph anomaly detection, and comparing its performance to established few-shot learning methods would provide insights into its generalizability.

## Limitations
- Reliance on Gaussian prior for normal scores may not capture complex score distributions in real-world scenarios
- Fixed hyperparameters (m=5 heads, K=10% top scores, ra=150) were not extensively validated across diverse anomaly types
- Few-shot setup assumes labeled anomalies are representative of true anomaly distribution, which may not hold in practice

## Confidence

**High Confidence**: The core mechanism of using multi-head self-attention to generate multiple anomaly scores is well-supported by the architecture description and ablation studies. The deviation learning framework with Z-scores is clearly defined and mathematically sound.

**Medium Confidence**: The effectiveness of the top-K MIL aggregation and the specific choice of Gaussian prior are supported by experiments but lack extensive sensitivity analysis. The orthogonality constraint's contribution to performance is mentioned but not thoroughly validated.

**Low Confidence**: The claim that FATE "requires only 10-20 labeled anomalies" is based on limited experiments (only 10 labeled anomalies used in main results). The robustness to 15% contamination is tested on only two datasets, limiting generalizability.

## Next Checks

1. **Prior Distribution Sensitivity**: Test FATE with alternative prior distributions (uniform, empirical, heavy-tailed) on all three benchmark datasets to assess whether Gaussian assumptions are critical to performance.

2. **Head Number and K Value Optimization**: Systematically vary the number of attention heads (m=3,5,10) and top-K percentage (5%, 10%, 20%) to identify optimal configurations and understand their impact on different anomaly types.

3. **Cross-Domain Transfer**: Evaluate FATE on datasets from different domains (e.g., medical records, code repositories, social media) to test generalization beyond news and text classification domains, particularly focusing on whether the few-shot capability holds for diverse anomaly patterns.