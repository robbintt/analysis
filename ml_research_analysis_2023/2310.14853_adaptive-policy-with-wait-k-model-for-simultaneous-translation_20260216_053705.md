---
ver: rpa2
title: Adaptive Policy with Wait-$k$ Model for Simultaneous Translation
arxiv_id: '2310.14853'
source_url: https://arxiv.org/abs/2310.14853
tags:
- uni00000013
- uni00000011
- uni0000001c
- uni00000014
- uni0000001b
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DaP-SiMT, a divergence-based adaptive policy
  for simultaneous machine translation. The key idea is to make read/write decisions
  by estimating the divergence between translation distributions with partial and
  full source context.
---

# Adaptive Policy with Wait-$k$ Model for Simultaneous Translation

## Quick Facts
- arXiv ID: 2310.14853
- Source URL: https://arxiv.org/abs/2310.14853
- Authors: 
- Reference count: 40
- Key outcome: DaP-SiMT introduces a divergence-based adaptive policy that improves accuracy-latency trade-off in simultaneous translation by estimating divergence between partial and full source context distributions.

## Executive Summary
This paper presents DaP-SiMT, a divergence-based adaptive policy for simultaneous machine translation that dynamically makes read/write decisions by estimating the divergence between translation distributions with partial and full source context. The approach extends a frozen multi-path wait-k model with a lightweight policy network, making it memory and computation efficient. Experimental results across multiple benchmarks demonstrate that DaP-SiMT offers an improved accuracy-latency trade-off compared to strong baselines, outperforming both fixed wait-k and existing adaptive policies like ITST.

## Method Summary
DaP-SiMT uses a multi-path wait-k translation model (frozen during training) combined with a lightweight policy network that predicts divergence between partial and full source context distributions. The policy is trained using divergence supervision computed from parallel data, where divergence measures the difference between translation distributions generated from partial versus full source context. At inference, the policy compares predicted divergence to a threshold to decide whether to read more source tokens or write a target token, with the threshold controlling the latency-accuracy trade-off.

## Key Results
- DaP-SiMT achieves improved BLEU scores at lower average lagging compared to fixed wait-k policies across multiple language pairs
- The method outperforms adaptive policies like ITST while maintaining computational efficiency through a frozen translation model
- NLL vs. AL curves demonstrate that DaP-SiMT provides better average translation quality at each latency point compared to baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The divergence-based policy improves over fixed wait-k because it dynamically measures translation uncertainty from partial context.
- Mechanism: At each step, the policy computes divergence between the translation distribution given current partial source (ppart) and that given full source (pfull). If divergence is low, the partial context suffices for accurate translation; otherwise, more source tokens are needed.
- Core assumption: Low divergence between ppart and pfull correlates with minimal translation quality loss when using partial context.
- Evidence anchors:
  - [abstract] "makes read/write decisions for any translation model based on the potential divergence in translation distributions resulting from future information."
  - [section 4.2] "we want to quantify the divergence D(ppart, pfull) between two distributions, one computed given partial source input and another given full source"
- Break condition: If the translation model itself is highly sensitive to context truncation, low divergence may not predict good translation quality.

### Mechanism 2
- Claim: Multi-path wait-k models can be adapted for simultaneous translation without joint policy-training because any adaptive path decomposes into subpaths from various wait-k paths.
- Mechanism: A multi-path wait-k model is pre-trained on random k values, enabling it to translate any prefix-to-prefix pair. The divergence-based policy then selects which subpath to use dynamically at inference.
- Core assumption: The multi-path wait-k model generalizes well across different k values, making it a suitable translation backbone for any adaptive path.
- Evidence anchors:
  - [abstract] "Our motivation stems from the observation that a standalone multi-path wait-k model performs competitively with adaptive policies utilized in state-of-the-art SiMT approaches."
  - [section 4.1] "any adaptive read/write path can be composed of subpaths of various wait-k paths. Given that a multi-path wait-k model is trained to perform prefix-to-prefix translation for different k values, we argue that such a model can also achieve competitive performance when used with an adaptive read/write policy."
- Break condition: If the translation quality degrades significantly on certain k values, the multi-path model may not generalize enough for effective adaptive translation.

### Mechanism 3
- Claim: Using divergence supervision from parallel data eliminates the need for manual annotation and enables effective policy learning.
- Mechanism: For each parallel sentence pair, divergence is computed for all prefix-to-prefix pairs using either an offline model or the multi-path wait-k model. These values serve as ground-truth supervision for training the lightweight policy network.
- Core assumption: Divergence computed on parallel data is a valid proxy for the divergence that would be observed during streaming translation.
- Evidence anchors:
  - [abstract] "We propose a novel method to construct read/write supervision signals from a parallel training corpus based on statistical divergence."
  - [section 4.2] "we treat the divergence measures computed from parallel sentences as ground-truth values, and train a single adaptive read/write policy model to predict the ground-truth values from the partial source and target pair"
- Break condition: If the source-target alignment in training data does not reflect realistic streaming conditions, divergence supervision may be misleading.

## Foundational Learning

- Concept: Divergence measures between probability distributions (Euclidean, KL, cosine).
  - Why needed here: These quantify how much translation predictions change when additional source context is added, guiding read/write decisions.
  - Quick check question: If ppart and pfull are identical distributions, what should the divergence value be?

- Concept: Prefix-to-prefix translation and wait-k policy mechanics.
  - Why needed here: The multi-path wait-k model is trained to translate any source prefix to any target prefix, enabling flexible adaptive paths.
  - Quick check question: In a wait-3 policy, how many source tokens are read before the first write?

- Concept: Transformer encoder-decoder architecture and parameter freezing.
  - Why needed here: The policy model adds a lightweight decoder layer on top of a frozen multi-path wait-k model, minimizing computational overhead.
  - Quick check question: If the underlying translation model is frozen, which parameters are updated during policy training?

## Architecture Onboarding

- Component map:
  Multi-path wait-k translation model (frozen parameters) -> Additional transformer decoder layer (policy network) -> Regression head (predicts divergence scores) -> Divergence threshold (controls latency vs. accuracy)

- Critical path:
  1. Input partial source and target prefix
  2. Multi-path wait-k encoder processes source
  3. Additional decoder layer computes policy features
  4. Regression head predicts divergence
  5. Compare predicted divergence to threshold
  6. Decide read or write action

- Design tradeoffs:
  - Freezing translation model reduces training complexity but limits adaptation
  - Lightweight policy network minimizes overhead but may underfit complex divergence patterns
  - Divergence threshold is simple but not directly linked to latency metrics

- Failure signatures:
  - Excessive reads: divergence predictions too conservative (threshold too low)
  - Excessive writes: divergence predictions too optimistic (threshold too high)
  - Poor BLEU: divergence supervision not representative of streaming conditions

- First 3 experiments:
  1. Ablation: Replace divergence-based policy with fixed wait-k and measure BLEU vs. AL trade-off
  2. Sensitivity: Vary divergence threshold and plot resulting latency distribution
  3. Supervision source: Compare divergence computed from offline model vs. multi-path wait-k model as ground truth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal way to model divergence supervision signals to minimize the gap between predicted and ground truth divergence values?
- Basis in paper: [explicit] The paper notes that using ground truth divergence values significantly outperforms predicted values, suggesting potential for improvement in modeling divergence supervision signals.
- Why unresolved: The paper only briefly mentions the potential for improvement without exploring specific methods or architectures to better model these signals.
- What evidence would resolve it: Experiments comparing different divergence modeling approaches (e.g., different neural architectures, loss functions, or training strategies) that demonstrate improved alignment between predicted and ground truth divergence values.

### Open Question 2
- Question: How can we effectively determine the optimal threshold λ that controls latency without requiring extensive manual tuning?
- Basis in paper: [explicit] The paper mentions that λ controls latency but doesn't have a direct one-to-one relationship with it, requiring careful consideration.
- Why unresolved: The paper doesn't provide a systematic method for threshold selection and only shows sensitivity analysis without addressing how to choose the best threshold.
- What evidence would resolve it: A method or algorithm that can automatically determine the optimal λ based on desired latency targets or other criteria, validated across multiple language pairs and datasets.

### Open Question 3
- Question: What architectural modifications to the policy network could improve performance across different language pairs, particularly for those with significant word order variations?
- Basis in paper: [inferred] The paper observes that the maximum continuous read constraint has varying impacts on different language pairs, suggesting architectural differences might help address language-specific challenges.
- Why unresolved: The paper only explores a limited set of architectural variations (0, 1, or 3 extra decoder layers) and doesn't investigate language-specific adaptations.
- What evidence would resolve it: Comparative experiments showing performance improvements when using language-specific policy network architectures or when incorporating language-specific features into a universal policy model.

## Limitations
- The multi-path generalization claim relies on external citation without direct ablation in this paper
- Divergence supervision validity from parallel data is assumed but not empirically verified against streaming conditions
- Key architectural details and hyperparameter settings are underspecified, making exact reproduction challenging

## Confidence
- Mechanism 1 (Divergence-based decisions): High confidence
- Mechanism 2 (Multi-path model generalization): Medium confidence
- Mechanism 3 (Divergence supervision construction): Medium confidence

## Next Checks
1. **Ablation Study on Multi-Path Generalization**: Train separate wait-k models for different k values (e.g., k=1, k=5, k=10) and compare their performance when used with the divergence policy versus the multi-path model. This would directly test whether the multi-path model truly generalizes across k values as claimed.

2. **Correlation Analysis of Divergence Supervision**: Compute the correlation between divergence values measured on parallel data versus those observed during actual streaming inference. This would validate whether the supervision signals accurately represent streaming conditions.

3. **Policy Architecture Sensitivity**: Perform sensitivity analysis by varying the policy network architecture (e.g., number of layers, hidden dimensions) while keeping the divergence-based approach constant. This would determine whether the lightweight design is sufficient or if more capacity is needed for accurate divergence prediction.