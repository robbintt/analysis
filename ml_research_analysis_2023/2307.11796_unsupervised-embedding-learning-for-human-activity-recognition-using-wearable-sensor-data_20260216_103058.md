---
ver: rpa2
title: Unsupervised Embedding Learning for Human Activity Recognition Using Wearable
  Sensor Data
arxiv_id: '2307.11796'
source_url: https://arxiv.org/abs/2307.11796
tags:
- data
- activity
- loss
- features
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents an unsupervised embedding learning approach
  for human activity recognition using wearable sensor data. The core idea is to project
  activity data into a clustering-friendly embedding space based on two key properties:
  temporal coherence and locality preservation.'
---

# Unsupervised Embedding Learning for Human Activity Recognition Using Wearable Sensor Data

## Quick Facts
- arXiv ID: 2307.11796
- Source URL: https://arxiv.org/abs/2307.11796
- Reference count: 4
- Primary result: Achieved clustering accuracy scores of 85.43%, 68.12%, and 74.01% on PAMAP2, REALDISP, and SBHAR datasets respectively using k-means clustering on learned embeddings

## Executive Summary
This paper presents an unsupervised embedding learning approach for human activity recognition using wearable sensor data. The core innovation lies in projecting activity data into a clustering-friendly embedding space by leveraging two key properties: temporal coherence and locality preservation. The approach uses an autoencoder framework enhanced with task-oriented loss functions to capture essential activity features while disregarding irrelevant details like personal variations and fine-grained temporal changes. Experiments on three benchmark datasets demonstrate that the proposed method significantly improves clustering performance compared to traditional unsupervised techniques, achieving state-of-the-art results without requiring labeled training data.

## Method Summary
The approach uses a three-component autoencoder framework with joint loss function comprising reconstruction loss (Φae), temporal coherence loss (Φtc), and locality preservation loss (Φlp). Temporal coherence loss encourages temporally close samples to be similar in the embedding space, leveraging the slowly changing nature of human activities. Locality preservation loss removes irrelevant personal or individual details by forcing the model to decode samples using representations of nearby data points. The method segments raw sensor data using sliding windows, extracts statistical features (mean, variance, std, median, max, min, iqr), and trains the autoencoder with the combined loss function. After learning embeddings, k-means clustering is applied to group similar activities.

## Key Results
- Achieved clustering accuracy of 85.43% on PAMAP2 dataset with 12 activity classes
- Achieved clustering accuracy of 68.12% on REALDISP dataset with 33 activity classes
- Achieved clustering accuracy of 74.01% on SBHAR dataset with 6 basic activities plus transitions
- Outperformed baselines including PCA + k-means and vanilla autoencoder + k-means on all three datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Temporal coherence loss enables the model to learn activity features while ignoring irrelevant temporal details
- Mechanism: The temporal coherence loss forces temporally close data samples to be similar to one another by comparing their representations. This leverages the natural property that human activities change slowly over time, with the same activity type being maintained over longer periods. By minimizing the difference between nearby samples in the embedding space, the model learns to extract the essential, activity-relevant features while ignoring the fine-grained temporal variations that are not important for distinguishing activity types.
- Core assumption: Human activities have a temporally stationary component (the activity type) that persists over time, while only a temporally varying component (body pose details) changes frequently.
- Evidence anchors: [abstract] "Based on this nature of the human activity, the temporal coherence loss forces temporally close data samples to be similar to one another, and ignore the difference in the temporal varying component." [section] "Intuitively, a human activity can be decomposed into two components, a temporally varying component and a temporally stationary component... Based on this nature of the human activity, the temporal coherence loss forces temporally close data samples to be similar to one another, and ignore the difference in the temporal varying component."
- Break condition: The temporal coherence assumption breaks down when a person switches between different activities frequently, as temporally adjacent samples may represent different activity types.

### Mechanism 2
- Claim: Locality preservation loss removes irrelevant personal or individual details from the learned representations
- Mechanism: The locality preservation loss forces the model to decode a data sample using the learned representation of its nearby data samples in the handcrafted feature space. This is based on the observation that different persons can perform the same type of activity in different ways, but these personal differences should not hinder the identification of the activity type. By preserving the high-level features that are commonly present across multiple nearby data samples, the model learns to disregard individual or personal features that are not essential for activity recognition.
- Core assumption: The features that are commonly present across multiple data samples represent the essential features of an activity, while individual or personal features that are unique to single samples are not necessary for activity recognition.
- Evidence anchors: [abstract] "Based on this property, another local neighborhood based objective function, which aims at removing irrelevant personal or individual details in the data, is used to guide the learning of the model." [section] "Locality preservation is inspired by the observation that different persons perform the same type of activity in different fashions, but different fashions don't hinder other people to identify the activity type... The locality preserving loss then aims to preserve the high level feature characteristics that are generally present in the local neighborhood."
- Break condition: The locality preservation assumption may break down when the local neighborhood contains data samples from different activity types, leading the model to learn a mixture of features that are not specific to a single activity.

### Mechanism 3
- Claim: The combination of temporal coherence and locality preservation losses, along with the reconstruction loss, enables the model to learn a clustering-friendly embedding space
- Mechanism: The temporal coherence loss captures the slowly changing nature of human activities, while the locality preservation loss removes irrelevant personal details. The reconstruction loss ensures that the learned representations retain sufficient information for reconstructing the original input. By combining these three losses, the model learns to encode the essential features of activities while disregarding irrelevant details, resulting in a representation space that is more suitable for clustering similar activities together.
- Core assumption: The combination of temporal coherence, locality preservation, and reconstruction losses can guide the model to learn a representation space that is both informative and discriminative for activity clustering.
- Evidence anchors: [abstract] "Specifically, our approach attempts to leverage two types of relationships: the temporal coherence of time series data, and locality preservation in the feature space... Using this, subsequent clustering algorithms can benefit from the embeddings, forming behavior clusters that represent the distinct activities performed by a person." [section] "The joint loss function is the sum of the temporal coherence loss and the locality preserving loss... While Φtc and Φlp preserve more task relevant information in the representation, the Φae component is also necessary in the learning process because without the reconstruction loss Φae, the risk of learning trivial solutions or worse representations will increase."
- Break condition: The effectiveness of the combined loss function may break down if the balance between the different loss terms is not properly tuned, or if the assumptions underlying the individual losses do not hold for the given dataset.

## Foundational Learning

- Concept: Autoencoders
  - Why needed here: The autoencoder framework serves as the foundation for the proposed approach, providing a way to learn a compressed representation of the input data that can be used for subsequent clustering tasks.
  - Quick check question: What are the two main components of an autoencoder, and what is the purpose of each component?

- Concept: Unsupervised learning
  - Why needed here: The approach aims to recognize human activities without relying on labeled data, which is often scarce and expensive to obtain. Unsupervised learning techniques, such as the proposed embedding learning approach, can leverage the abundant unlabeled sensor data to learn meaningful representations for activity recognition.
  - Quick check question: What is the main difference between supervised and unsupervised learning, and why is unsupervised learning particularly useful for human activity recognition using wearable sensor data?

- Concept: Clustering algorithms
  - Why needed here: After learning the embedding representations, a clustering algorithm (in this case, k-means) is applied to group similar activities together based on their learned representations. Understanding the basics of clustering algorithms and their performance metrics (e.g., ACC, ARI, NMI) is essential for evaluating the effectiveness of the proposed approach.
  - Quick check question: What is the purpose of clustering algorithms, and what are some common metrics used to evaluate their performance?

## Architecture Onboarding

- Component map: Input layer -> Encoder -> Temporal coherence loss -> Locality preservation loss -> Decoder -> Reconstruction loss
- Critical path:
  1. Segment the raw sensor data using a sliding window approach
  2. Extract statistical features from the segmented data
  3. Feed the extracted features into the autoencoder framework
  4. Train the autoencoder using the combined loss function (temporal coherence, locality preservation, and reconstruction losses)
  5. Use the learned encoder to project new data samples into the embedding space
  6. Apply a clustering algorithm (e.g., k-means) to group similar activities together in the embedding space
- Design tradeoffs:
  - The choice of the sliding window size for data segmentation can impact the temporal coherence assumption and the granularity of the learned representations
  - The balance between the temporal coherence, locality preservation, and reconstruction losses can affect the quality and discriminative power of the learned embeddings
  - The architecture of the autoencoder (e.g., number of layers, number of neurons per layer) can influence the model's capacity to learn complex representations and its susceptibility to overfitting
- Failure signatures:
  - If the temporal coherence assumption does not hold (e.g., frequent activity switches), the learned embeddings may not effectively capture the activity types
  - If the locality preservation assumption is violated (e.g., local neighborhoods contain samples from different activities), the learned embeddings may mix features from different activities
  - If the reconstruction loss is too dominant, the model may learn to preserve too much task-irrelevant information, leading to suboptimal clustering performance
- First 3 experiments:
  1. Verify the basic functionality of the autoencoder by training it on a simple dataset (e.g., MNIST) and checking the reconstruction quality
  2. Implement the temporal coherence loss and evaluate its impact on the learned embeddings by visualizing the similarity between temporally close samples in the embedding space
  3. Implement the locality preservation loss and assess its effect on the learned embeddings by examining the presence of personal or individual features in the representations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed approach perform on datasets with a larger number of activity classes or more complex activities?
- Basis in paper: [inferred] The paper evaluates the approach on three benchmark datasets with varying numbers of activity classes (12 for PAMAP2, 33 for REALDISP, and 6 for SBHAR), but does not explore performance on datasets with a significantly larger number of classes or more complex activities.
- Why unresolved: The paper does not provide results on datasets with a larger number of activity classes or more complex activities, leaving the scalability and effectiveness of the approach in such scenarios unexplored.
- What evidence would resolve it: Conducting experiments on datasets with a larger number of activity classes or more complex activities, such as those used in daily living activity recognition or sports performance analysis, would provide insights into the approach's scalability and robustness.

### Open Question 2
- Question: How does the approach handle activity transitions and gradual changes in activity types?
- Basis in paper: [explicit] The paper mentions that during activity transitions, the temporal coherence assumption may not hold, leading to inaccuracies in the model. However, it does not provide a detailed analysis of how the approach handles these transitions or gradual changes in activity types.
- Why unresolved: The paper does not provide a detailed analysis of the approach's performance during activity transitions or gradual changes in activity types, leaving the effectiveness of the approach in these scenarios unexplored.
- What evidence would resolve it: Conducting experiments that focus on activity transitions and gradual changes in activity types, such as those found in daily living or sports performance analysis, would provide insights into the approach's ability to handle these scenarios effectively.

### Open Question 3
- Question: How does the approach perform on datasets with imbalanced activity classes or varying activity durations?
- Basis in paper: [inferred] The paper does not provide information on the class distribution or activity duration in the datasets used, nor does it discuss how the approach handles imbalanced classes or varying activity durations.
- Why unresolved: The paper does not provide information on the class distribution or activity duration in the datasets used, nor does it discuss how the approach handles imbalanced classes or varying activity durations, leaving the robustness of the approach in these scenarios unexplored.
- What evidence would resolve it: Conducting experiments on datasets with imbalanced activity classes or varying activity durations, such as those found in real-world applications, would provide insights into the approach's robustness and effectiveness in handling these challenges.

## Limitations

- The paper does not specify the exact values of the hyperparameters α and β that balance the temporal coherence and locality preservation losses, making reproducibility difficult.
- The effectiveness of the approach may depend heavily on the proper tuning of hyperparameters, which is not addressed in detail.
- The paper does not provide a detailed analysis of how the approach handles activity transitions or gradual changes in activity types, which are common in real-world scenarios.

## Confidence

- **High Confidence**: The core autoencoder framework and loss function formulation are well-specified and theoretically sound. The three benchmark datasets and evaluation metrics (ACC, ARI, NMI) are clearly defined.
- **Medium Confidence**: The clustering performance improvements (85.43% for PAMAP2, 68.12% for REALDISP, 74.01% for SBHAR) are reported with five-fold cross-validation, but without access to exact implementation details and hyperparameter values, independent verification is challenging.
- **Low Confidence**: Claims about the superiority of temporal coherence and locality preservation mechanisms are supported by ablation studies showing improved performance, but the specific contributions of each loss term cannot be fully assessed without hyperparameter transparency.

## Next Checks

1. **Hyperparameter Sensitivity Analysis**: Conduct systematic experiments varying α and β values across a grid (e.g., 0.1 to 0.9 in increments of 0.2) for each dataset to identify optimal settings and assess robustness. Compare performance across different hyperparameter configurations.

2. **Subject-Independent Evaluation Protocol**: Implement a true subject-independent train/test split where subjects in test data were not seen during training. Evaluate whether the model maintains performance when generalizing to unseen users, which is critical for real-world deployment.

3. **Ablation Study with Modern Baselines**: Extend the ablation studies to include comparisons with DEC, VAE-based clustering, and contrastive learning approaches. This would better establish the relative contribution of the proposed temporal coherence and locality preservation mechanisms compared to other unsupervised representation learning techniques.