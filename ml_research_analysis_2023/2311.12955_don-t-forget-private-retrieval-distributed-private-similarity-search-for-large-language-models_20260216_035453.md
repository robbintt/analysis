---
ver: rpa2
title: 'Don''t forget private retrieval: distributed private similarity search for
  large language models'
arxiv_id: '2311.12955'
source_url: https://arxiv.org/abs/2311.12955
tags:
- database
- retrieval
- query
- data
- private
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PRAG introduces the first secure, distributed neural information
  retrieval approach for large language models, enabling private search over secret-shared
  databases using multi-party computation. The method achieves sublinear communication
  complexity by implementing an MPC-friendly inverted file index for approximate nearest
  neighbor search, maintaining 99% accuracy on real data.
---

# Don't forget private retrieval: distributed private similarity search for large language models

## Quick Facts
- arXiv ID: 2311.12955
- Source URL: https://arxiv.org/abs/2311.12955
- Reference count: 17
- The approach achieves 99% accuracy on real data while enabling private search over secret-shared databases using multi-party computation

## Executive Summary
This paper introduces PRAG, the first secure distributed neural information retrieval approach for large language models that enables private search over secret-shared databases using multi-party computation (MPC). The system achieves sublinear communication complexity by implementing an MPC-friendly inverted file index for approximate nearest neighbor search while maintaining 99% accuracy on real data. The method provides both fully private search and a partially private variant that trades some privacy for significant speed improvements.

## Method Summary
The approach uses Shamir secret sharing to distribute database content across multiple servers, with each server holding only shares of the data. During query time, the client secret-shares their query vector and sends shares to all servers. The servers then perform MPC operations to compute distances (dot product, cosine similarity, L2 norm) and use an inverted file index (IVF) with k-means clustering to partition the database into √N clusters. The system searches only the nprobe closest clusters, achieving sublinear complexity. For exact retrieval, a tree-based reduction protocol computes top-k results in O(k log²N) rounds. The system can return actual document content through oblivious retrieval, preventing servers from learning query-database relationships.

## Key Results
- Maintains 97.5-98.6% retrieval accuracy across database sizes up to 5×10^5
- Achieves sublinear communication complexity through IVF-based approximate search
- No single server observes query vectors or database content during operation
- Provides both fully private and partially private variants with significant speed tradeoffs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Shamir secret sharing over prime fields ensures no single server can reconstruct query vectors or database content
- Mechanism: Data split into shares where reconstruction requires threshold number of shares
- Core assumption: Honest majority setting with at most t < nservers/2 corrupt servers
- Evidence anchors: Abstract states "ensuring no server observes a client's query or can see the database content"; section describes "at most t < nservers/2 of the servers are corrupt"
- Break condition: If more than t servers collude, they can reconstruct original data

### Mechanism 2
- Claim: MPC-friendly inverted file index enables sublinear communication complexity
- Mechanism: Database clustered into √N clusters, only nprobe closest clusters searched during query
- Core assumption: Choice of nc = α√N and appropriate nprobe maintains recall while reducing communication
- Evidence anchors: Abstract mentions "fast document search over distributed and private data in sublinear communication complexity"; section explains "choose the number of clusters to be nc = α√N"
- Break condition: If nprobe approaches nc, complexity becomes O(N) defeating sublinear advantage

### Mechanism 3
- Claim: Oblivious database retrieval allows extraction of document tokens without revealing access patterns
- Mechanism: One-hot vectors and private information retrieval return actual content rather than indices
- Core assumption: Database structure allows oblivious access without revealing patterns
- Evidence anchors: Abstract states "data for use in LLMs can be accessed and used without needing to centralize or forgo privacy"; section describes "return the original tokens from a secret shared database directly in MPC"
- Break condition: If retrieval patterns or database structure leak information about accessed documents

## Foundational Learning

- Concept: Shamir Secret Sharing
  - Why needed here: Provides foundation for distributing database across multiple servers without single server having complete information
  - Quick check question: How many shares are needed to reconstruct a secret shared with threshold t?

- Concept: Multi-Party Computation (MPC)
  - Why needed here: Enables computation on secret-shared data without revealing underlying values
  - Quick check question: What is the difference between linear and non-linear operations in MPC regarding communication complexity?

- Concept: Inverted File Index (IVF) for Approximate Nearest Neighbors
  - Why needed here: Reduces search complexity from linear to sublinear by clustering database and searching relevant clusters
  - Quick check question: How does choice of nprobe affect both accuracy and search time in IVF?

## Architecture Onboarding

- Component map:
  Client -> Secret-sharing module -> Servers (hold shares) -> Distance calculation module -> IVF index -> Exact top-k module -> Oblivious retrieval module -> Document content

- Critical path:
  1. Client secret-shares query vector and sends to servers
  2. Servers compute distances using MPC-friendly operations
  3. Servers perform IVF-based search to identify relevant clusters
  4. Servers retrieve candidate documents through oblivious access
  5. Servers compute exact top-k among candidates
  6. Servers return document content to client

- Design tradeoffs:
  - Exact vs approximate search: Exact provides higher accuracy but O(N) complexity vs sublinear for approximate
  - Number of servers: More servers increase robustness but add coordination overhead
  - Privacy vs speed: Leaky variant sacrifices some privacy for significant speed gains
  - Choice of nprobe: Higher values increase accuracy but also communication/computation costs

- Failure signatures:
  - Accuracy degradation: May indicate numerical precision issues in MPC or suboptimal IVF parameters
  - Communication bottlenecks: Could signal need for optimization in sum-of-products protocol
  - Timing discrepancies: May reveal information through side channels if not properly masked

- First 3 experiments:
  1. Test secret sharing and reconstruction with synthetic data to verify basic MPC functionality
  2. Benchmark distance calculations (dot product, cosine, euclidean) with varying vector sizes
  3. Validate IVF clustering and search accuracy with synthetic embeddings before moving to real data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does choice of embedding dimension size impact communication and computational complexity for dimensions beyond 8192?
- Basis in paper: Paper benchmarks across embedding sizes 256 to 8192, suggesting interest in scalability
- Why unresolved: No analysis for dimensions larger than 8192
- What evidence would resolve it: Performance results for dimensions significantly larger than 8192

### Open Question 2
- Question: Can partially private IVF variant maintain speed advantage while further reducing query information leakage?
- Basis in paper: Paper introduces 'leaky' version allowing partial privacy under budget with speed improvements
- Why unresolved: Trade-off limits not explored
- What evidence would resolve it: Experiments comparing performance and privacy under various privacy budget configurations

### Open Question 3
- Question: How does MPC-based IVF performance compare to non-MPC IVF for very large databases (10^7+)?
- Basis in paper: Paper evaluates up to 5×10^5 database size and discusses sublinear complexity
- Why unresolved: No data for databases significantly larger than 5×10^5
- What evidence would resolve it: Comparative results on databases with sizes in order of 10^7 or larger

## Limitations
- Numerical precision requirements for MPC operations may introduce accuracy degradation not fully characterized
- System assumes honest majority setting which may not hold in all deployment scenarios
- Communication complexity analysis assumes optimal parameter choices without sensitivity analysis

## Confidence
- High Confidence: Theoretical foundation of Shamir secret sharing and general approach of combining IVF with MPC
- Medium Confidence: Numerical precision analysis and practical communication complexity in real deployments
- Medium Confidence: Claimed 99% accuracy maintenance across database sizes up to 5×10^5

## Next Checks
1. **Numerical Precision Validation**: Implement MPC protocols with varying fixed-point precision parameters and field sizes, then measure accuracy degradation systematically. Compare MPC results against plaintext calculations across multiple datasets.

2. **Parameter Sensitivity Analysis**: Conduct experiments varying nc and nprobe to quantify tradeoff between accuracy and communication complexity. Identify optimal parameter ranges for different database sizes and query workloads.

3. **Robustness Testing Under Malicious Behavior**: Simulate scenarios with malicious servers attempting to infer information through timing or communication patterns. Test system resistance to active attacks and evaluate need for additional MPC techniques.