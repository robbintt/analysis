---
ver: rpa2
title: 'PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation'
arxiv_id: '2310.14192'
source_url: https://arxiv.org/abs/2310.14192
tags:
- examples
- data
- promptmix
- class
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PromptMix, a two-step prompting-based method
  for generating high-quality data in few-shot text classification setups. The method
  first instructs an LLM to generate borderline examples by mixing information from
  multiple classes, then uses an LLM as a classifier to relabel the generated examples
  and improve label accuracy.
---

# PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation

## Quick Facts
- arXiv ID: 2310.14192
- Source URL: https://arxiv.org/abs/2310.14192
- Reference count: 18
- 2-shot PromptMix achieves 80.1% accuracy on Banking77, outperforming strong 5-shot baselines

## Executive Summary
PromptMix is a two-step prompting-based method for generating high-quality data in few-shot text classification setups. The method first instructs an LLM to generate borderline examples by mixing information from multiple classes, then uses an LLM as a classifier to relabel the generated examples and improve label accuracy. Experiments show that PromptMix significantly outperforms multiple 5-shot data augmentation baselines on four text classification datasets in 2-shot and zero-shot settings.

## Method Summary
PromptMix generates augmented data through a two-step process: (1) Using GPT3.5-turbo with Mixup-inspired prompts to create borderline examples that blend information from multiple classes, and (2) Relabeling these generated examples using GPT3.5-turbo as a classifier to correct mislabeled instances. The method is designed for few-shot learning scenarios (2-shot and zero-shot) and aims to transfer knowledge from massive LLMs to smaller classifiers through high-quality augmented data.

## Key Results
- 2-shot PromptMix achieves 80.1% accuracy on Banking77, outperforming strong 5-shot baselines like USE, CONVERT, and CPFT
- Relabeling step is crucial, with an average improvement of 10.1% across datasets
- Effectively transfers knowledge from GPT3.5-turbo (175B parameters) into much smaller models like DistilBERT and BERT
- Zero-shot PromptMix achieves 61.8% accuracy on Subjectivity dataset

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PromptMix's two-step approach generates high-quality augmented data by creating borderline examples and then correcting mislabeled instances.
- Mechanism: Step 1 uses Mixup to blend two classes in varying proportions, creating ambiguous examples. Step 2 uses GPT3.5-turbo as a classifier to relabel these examples, improving label accuracy.
- Core assumption: LLMs can follow instructions to generate mixed-class examples and accurately classify them in a few-shot setting.
- Evidence anchors: [abstract] "generate challenging text augmentations near class boundaries... then uses an LLM as a classifier to relabel the generated examples"; [section 3.1] "instruct GPT3.5-turbo... to generate n example utterances that are a mix of two classes"; [section 3.2] "use an LLM as a classifier to assign new labels to the generated examples"

### Mechanism 2
- Claim: Generating borderline examples near class boundaries improves knowledge distillation from large to small models.
- Mechanism: Borderline examples expose the small model to ambiguous cases that require nuanced decision boundaries, forcing it to learn richer representations from the teacher model.
- Core assumption: Training on difficult examples near class boundaries leads to better generalization than training only on clear examples.
- Evidence anchors: [abstract] "generating and, crucially, relabeling borderline examples facilitates the transfer of knowledge of a massive LLM like GPT3.5-turbo into smaller and cheaper classifiers"; [section 6.2] "PromptMix achieves almost similar performance as NN+GPT3.5... GPT3.5-turbo with 175B parameters is ~2600× larger than DistilBERT base"; [section 4] Table 1 shows Mixup generates sentences containing information from both majority and minority classes

### Mechanism 3
- Claim: Using multiple class descriptions and examples in prompts improves LLM generation quality compared to single-class prompts.
- Mechanism: Providing broader context about multiple classes helps the LLM understand class relationships and generate more diverse examples that respect inter-class boundaries.
- Core assumption: LLMs can effectively use contextual information from multiple classes to generate better examples for any specific class.
- Evidence anchors: [section 6.4] "simply adding a class description to the prompt leads to decent performance gains... using multiple class descriptions in a prompt is either better or equivalent to using a single class with its description and examples"; [section 3.1] "randomly select a group of t(= 4) 2 classes... For each class in c, we combine the description and k examples in the prompt"

## Foundational Learning

- Concept: Mixup interpolation in feature space
  - Why needed here: PromptMix uses Mixup conceptually but in natural language generation rather than feature interpolation
  - Quick check question: What is the key difference between Mixup in computer vision (pixel interpolation) and PromptMix's approach (text generation)?

- Concept: Knowledge distillation from teacher to student models
  - Why needed here: The paper explicitly frames PromptMix as a knowledge distillation technique from GPT3.5-turbo to smaller models
  - Quick check question: How does PromptMix differ from traditional knowledge distillation methods that use soft labels from the teacher model?

- Concept: Few-shot learning and prompt engineering
  - Why needed here: The entire method operates in extreme few-shot settings (2-shot, zero-shot) using carefully crafted prompts
  - Quick check question: What are the key differences between zero-shot, one-shot, and few-shot learning scenarios?

## Architecture Onboarding

- Component map: Class selection → Prompt construction → LLM generation → Mixup parameter sampling → Generated examples → SBERT embedding → Nearest-class selection → LLM classification → Label correction → Model training → Evaluation
- Critical path: Prompt construction → LLM generation → Relabeling → Model training → Evaluation
- Design tradeoffs:
  - Generation quality vs. cost: More examples improve results but increase GPT3.5-turbo API costs
  - Relabeling accuracy vs. computational overhead: Using SBERT + LLM relabeling is more accurate but slower than heuristic approaches
  - Mixup parameter selection: Wider α range creates more diverse examples but increases relabeling workload
- Failure signatures:
  - High relabeling percentage (>50%) suggests Mixup parameters are too aggressive
  - Low baseline accuracy with high augmentation accuracy indicates data scarcity issues
  - Large gap between A1 and A2 indicates relabeling step is crucial for quality
- First 3 experiments:
  1. Baseline comparison: Run 2-shot training without augmentation to establish minimum performance
  2. Single-step validation: Generate examples with Mixup but skip relabeling to measure generation quality
  3. Ablation study: Test with and without Mixup parameter sampling to verify its impact on example diversity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of α values (degree of mixing) in PromptMix affect the quality and diversity of generated examples, and is there an optimal distribution for α?
- Basis in paper: [explicit] The paper mentions using α = round(10(x + 1))/20 ∀ x ∼ β(5, 2) and states this distribution restricts the range to (0.5, 1.0] with a peak near 1.0.
- Why unresolved: The paper does not explore alternative distributions for α or conduct sensitivity analysis on the choice of α distribution.
- What evidence would resolve it: Experiments comparing PromptMix performance using different α distributions (e.g., uniform, normal, other beta distributions) would show how α choice impacts generated example quality and diversity.

### Open Question 2
- Question: Can the relabeling step in PromptMix be further improved by incorporating human feedback or using a more sophisticated model than GPT3.5-turbo as the classifier?
- Basis in paper: [explicit] The paper mentions that the relabeling step is highly effective but relies completely on GPT's pseudolabels and does not address potential out-of-scope/out-of-domain (OOS/OOD) generations.
- Why unresolved: The paper does not explore alternative relabeling strategies or human-in-the-loop approaches to improve label accuracy.
- What evidence would resolve it: Experiments comparing PromptMix performance with and without human feedback during relabeling, or using a more sophisticated model (e.g., GPT-4) as the classifier, would show the impact of improved relabeling on generated data quality.

### Open Question 3
- Question: How does the performance of PromptMix scale with the number of classes in the dataset, and are there any limitations or challenges when dealing with extremely large-scale classification tasks?
- Basis in paper: [inferred] The paper mentions that some datasets can have hundreds of classes, which would not fit in the context size of the LLM, and that the initial fine-tuning step becomes a bottleneck for large-scale tasks.
- Why unresolved: The paper does not conduct experiments on datasets with a very large number of classes or discuss the limitations and challenges of scaling PromptMix to such tasks.
- What evidence would resolve it: Experiments evaluating PromptMix on datasets with hundreds of classes, or theoretical analysis of the limitations and challenges of scaling PromptMix to large-scale classification tasks, would provide insights into the method's scalability.

## Limitations

- High computational cost due to reliance on GPT3.5-turbo for both generation and relabeling steps
- Manually written class descriptions require human expertise and may not generalize across domains
- Performance on datasets with many classes (hundreds) is untested and may face context window limitations
- Zero-shot performance on Banking77 is notably weak (25.6%), suggesting fundamental limitations when no seed examples are available

## Confidence

**High Confidence**: The core mechanism of using Mixup parameters to generate borderline examples and the effectiveness of the relabeling step in improving accuracy

**Medium Confidence**: The claim that generating borderline examples improves knowledge distillation from large to small models

**Low Confidence**: The claim about multiple-class prompts improving generation quality compared to single-class prompts

## Next Checks

1. **Cost-Performance Tradeoff Analysis**: Run the same experiments using GPT3.5-turbo API with cost tracking to quantify the economic feasibility of PromptMix compared to traditional few-shot methods, including both generation and relabeling costs per example.

2. **Generalization to Unseen Domains**: Test PromptMix on datasets from completely different domains (e.g., medical text, legal documents, or multilingual datasets) to evaluate whether the manually written class descriptions and prompt engineering strategies transfer effectively.

3. **Relabeling Step Ablation**: Conduct a controlled experiment where generated examples are evaluated without relabeling (using original Mixup labels) versus with relabeling, measuring both accuracy and the percentage of examples requiring relabeling to quantify the overhead-benefit tradeoff.