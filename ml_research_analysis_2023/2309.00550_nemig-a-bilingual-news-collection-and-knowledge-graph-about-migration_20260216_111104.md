---
ver: rpa2
title: NeMig -- A Bilingual News Collection and Knowledge Graph about Migration
arxiv_id: '2309.00550'
source_url: https://arxiv.org/abs/2309.00550
tags:
- news
- political
- user
- knowledge
- entities
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: NeMig is a bilingual news collection and knowledge graph on the
  topic of migration, comprising over 7K German and 10K English news articles. The
  dataset is annotated with sentiment polarization, political leaning of media outlets,
  subtopics, and named entities linked to Wikidata.
---

# NeMig -- A Bilingual News Collection and Knowledge Graph about Migration

## Quick Facts
- arXiv ID: 2309.00550
- Source URL: https://arxiv.org/abs/2309.00550
- Reference count: 40
- Primary result: A bilingual (German/English) news dataset with 7K+ German and 10K+ English articles, annotated with sentiment, political leaning, subtopics, and Wikidata-linked entities

## Executive Summary
NeMig is a comprehensive dataset designed to enable research into the multidimensional effects of algorithmic news curation, particularly around migration topics. It combines a large corpus of German and English news articles with rich metadata including sentiment polarization, political leaning of media outlets, subtopics, and named entities linked to Wikidata. The dataset goes beyond traditional click-based feedback by collecting user socio-demographic and political information alongside explicit click behavior, enabling analysis of recommendation effects beyond simple accuracy metrics.

## Method Summary
The NeMig dataset was constructed through a multi-stage pipeline involving news crawling from various media outlets, manual and automated annotation for sentiment, political leaning, and subtopics, named entity recognition and linking to Wikidata, and knowledge graph construction enriched with up to two-hop Wikidata neighbors. User data was collected through the Watson platform, capturing explicit click feedback alongside demographics and political attitudes. The dataset supports multiple neural news recommender models (NRMS, NAML, MINS, CAUM, DKN, TANR, SentiDebias) trained with specific hyperparameters (Adam optimizer, learning rate 1e-5, batch size 4, 10 epochs) and evaluated using both traditional recommendation metrics (AUC, MRR, nDCG) and aspect-based diversity/personalization measures.

## Key Results
- Successfully constructed a bilingual news corpus of over 17,000 articles with comprehensive metadata annotations
- Developed domain-specific knowledge graphs enriched with Wikidata connections for semantic entity relationships
- Collected user data including socio-demographic and political information beyond click feedback
- Demonstrated dataset utility through experiments on news recommender benchmarking and bias analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bilingual news data with rich metadata (sentiment, political leaning, subtopics, entities) enables analysis of recommendation effects beyond accuracy.
- Mechanism: Combining textual features with structured knowledge (Wikidata entities, political orientation, sentiment labels) creates a rich feature space that exposes algorithmic biases and filter bubble formation.
- Core assumption: Sentiment and political leaning are meaningful signals for understanding polarization effects in recommendations.
- Evidence anchors: [abstract] and [section] annotations described; [corpus] lacks quantitative support for claim.

### Mechanism 2
- Claim: Knowledge graph construction with Wikidata enrichment enables modeling of knowledge-level connections between news articles.
- Mechanism: By linking named entities to Wikidata and expanding with k-hop neighbors, the KG captures semantic relationships that cannot be derived from text alone, improving recommendation quality and diversity.
- Core assumption: Wikidata provides relevant and accurate context for news entities that improves downstream recommendation performance.
- Evidence anchors: [abstract] and [section] describe KG construction; [corpus] lacks explicit performance metrics.

### Mechanism 3
- Claim: Collecting user socio-demographic and political information beyond click feedback enables study of multidimensional recommender effects.
- Mechanism: Rich user profiles (demographics, political attitudes, empathy, media usage) allow correlation between algorithmic recommendations and political polarization, filter bubble effects, and user behavior patterns.
- Core assumption: User political and demographic data is reliably collected and representative for the study population.
- Evidence anchors: [abstract] and [section] describe user data collection; [corpus] provides sample questions but no statistical validation.

## Foundational Learning

- Concept: Named Entity Recognition and Linking
  - Why needed here: Entities extracted from news text must be disambiguated and linked to external knowledge bases (Wikidata) to construct meaningful knowledge graphs.
  - Quick check question: How do you distinguish between a person named "Washington" as a location versus as a person in the text?

- Concept: Knowledge Graph Embeddings
  - Why needed here: KG embeddings are used to represent news and entities in a continuous space for recommendation models like DKN.
  - Quick check question: What is the difference between TransE and TransD embedding models, and when would you prefer one over the other?

- Concept: Aspect-based Diversity and Personalization Metrics
  - Why needed here: To evaluate whether recommendations are diverse in terms of sentiment, politics, and topics, and personalized to user history.
  - Quick check question: How does normalized entropy measure diversity, and what does a value close to 1 indicate?

## Architecture Onboarding

- Component map: News crawler → annotation pipeline (sentiment, subtopic, NER, linking) → KG construction (base + Wikidata enrichment) → user study → recommendation benchmarking
- Critical path: Data collection → annotation → KG construction → user data integration → model training and evaluation
- Design tradeoffs: Rich metadata vs. annotation cost; KG size vs. noise; user privacy vs. research utility
- Failure signatures: Low entity linking accuracy → poor KG quality; sparse user feedback → unreliable personalization metrics; imbalanced political coverage → biased bias analysis
- First 3 experiments:
  1. Run NER and entity linking on a small sample; verify Wikidata match rate and entity type consistency.
  2. Build base KG (no Wikidata enrichment) and test TransD embeddings for a subset of news.
  3. Train a simple NRMS model on the full dataset; check if AUC exceeds baseline (e.g., random).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do sentiment polarization and political leaning of news articles influence the effectiveness of news recommender systems in multilingual contexts?
- Basis in paper: [explicit] The paper discusses the annotation of sentiment polarization and political leanings of media outlets as critical features for analyzing algorithmic news curation effects.
- Why unresolved: The paper demonstrates the utility of these annotations but does not provide empirical results on their direct influence on recommender system performance across different languages.
- What evidence would resolve it: Comparative studies of recommender system performance with and without sentiment and political annotations in multilingual datasets.

### Open Question 2
- Question: To what extent do knowledge graph embeddings enriched with Wikidata neighbors improve news recommendation accuracy in low-data scenarios?
- Basis in paper: [explicit] The paper investigates the impact of different knowledge graph variants on the quality of entity embeddings and their effect on recommendation performance.
- Why unresolved: While the paper finds that adding 1-hop neighbors is beneficial, it does not explore the optimal extent of knowledge graph enrichment or its impact on other recommendation tasks.
- What evidence would resolve it: Systematic experiments varying the number of Wikidata hops and measuring their impact on diverse recommendation tasks.

### Open Question 3
- Question: How do aspect-based diversity and personalization metrics correlate with user satisfaction and engagement in news recommendation systems?
- Basis in paper: [inferred] The paper introduces aspect-based diversity and personalization metrics but does not explore their correlation with user satisfaction or engagement.
- Why unresolved: The study focuses on technical performance metrics and does not include user studies or engagement data to validate the relevance of these metrics.
- What evidence would resolve it: User studies measuring satisfaction and engagement with recommendations generated using aspect-based diversity and personalization metrics.

## Limitations

- Knowledge graph enrichment depends heavily on Wikidata's coverage and accuracy for migration-related entities, which may be incomplete or noisy.
- User data comes from a single platform (Watson) and may not represent broader populations.
- Political leaning annotations could introduce systematic bias based on annotator perspectives.

## Confidence

- Dataset utility for content recommendation: Medium
- Dataset utility for bias analysis: Low-Medium
- Entity linking quality: Medium
- Political leaning annotation reliability: Medium
- User data representativeness: Low-Medium

## Next Checks

1. Entity Linking Quality Assessment: Sample 100 randomly selected named entities and manually verify their Wikidata links and types to quantify linking accuracy and relevance to migration topics.

2. Political Leaning Annotation Validation: Have three independent annotators classify 50 randomly selected articles' political orientation and compute inter-annotator agreement (Krippendorff's alpha) to establish reliability.

3. Knowledge Graph Relevance Filtering: Measure the topical distance between Wikidata neighbors and their source news articles using embedding similarity; filter out neighbors with similarity below a threshold (e.g., 0.3 cosine) to reduce noise in KG embeddings.