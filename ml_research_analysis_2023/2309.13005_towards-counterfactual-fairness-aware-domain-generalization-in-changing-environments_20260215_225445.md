---
ver: rpa2
title: Towards Counterfactual Fairness-aware Domain Generalization in Changing Environments
arxiv_id: '2309.13005'
source_url: https://arxiv.org/abs/2309.13005
tags:
- fairness
- domain
- causal
- domains
- sensitive
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of achieving counterfactual
  fairness in machine learning models across evolving domains. The authors propose
  a novel framework called Counterfactual Fairness-Aware Domain Generalization with
  Sequential Autoencoder (CDSAE), which disentangles environmental information and
  sensitive attributes from classification features.
---

# Towards Counterfactual Fairness-aware Domain Generalization in Changing Environments

## Quick Facts
- arXiv ID: 2309.13005
- Source URL: https://arxiv.org/abs/2309.13005
- Reference count: 8
- One-line primary result: CDSAE achieves counterfactual fairness across evolving domains by disentangling sensitive attributes from environmental information using a sequential autoencoder framework.

## Executive Summary
This paper addresses the challenge of achieving counterfactual fairness in machine learning models across evolving domains. The authors propose a novel framework called Counterfactual Fairness-Aware Domain Generalization with Sequential Autoencoder (CDSAE), which disentangles environmental information and sensitive attributes from classification features. The method partitions exogenous variables into four latent components and employs fairness regularization. Experiments on synthetic and real-world datasets demonstrate that CDSAE outperforms existing methods in terms of accuracy while preserving fairness.

## Method Summary
CDSAE uses a sequential autoencoder architecture with four latent variable components: semantic information caused by sensitive attributes, semantic information not caused by sensitive attributes, environmental information caused by sensitive attributes, and environmental information not caused by sensitive attributes. The framework employs variational inference with an ELBO that includes reconstruction terms, KL-divergence penalties, and a counterfactual fairness regularization term. Only the two semantic latent variables are used for classification, while environmental variables are excluded from the decision path. The method is trained on sequentially evolving domains using both static and dynamic inference networks.

## Key Results
- On Fair-circle dataset, CDSAE achieves accuracy of 0.8870 and total effect of 0.1225
- CDSAE outperforms baseline methods including VAE-based approaches on multiple datasets
- The method successfully maintains fairness across sequential domains while preserving predictive performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CDSAE achieves counterfactual fairness by explicitly disentangling sensitive-attribute-caused semantic features from environment-caused ones.
- Mechanism: The framework partitions exogenous variables into four latent components: semantic info caused by sensitive attributes, semantic info not caused by sensitive attributes, environmental info caused by sensitive attributes, and environmental info not caused by sensitive attributes. Only the two "semantic" latent variables are used for classification.
- Core assumption: The distribution of semantic information remains invariant across all domains, whereas the distribution of environmental information varies with environmental changes.
- Evidence anchors: [abstract] "This approach effectively separates environmental information and sensitive attributes from the embedded representation of classification features"; [section] "By incorporating fairness regularization, we exclusively employ semantic information for classification purposes."
- Break condition: If semantic features themselves correlate with sensitive attributes in a way that isn't fully captured by the causal graph, or if environmental factors are not truly separable from semantic ones.

### Mechanism 2
- Claim: The ELBO formulation enforces that the learned latent variables capture domain-invariant semantic information while still allowing reconstruction of both semantic and environmental features.
- Mechanism: The Evidence Lower Bound includes terms for reconstructing both Xs and Xns, while KL-divergences enforce that us and uns follow standard normal priors and uv1, uv2 follow Markovian dynamics.
- Core assumption: Variational inference with the specified ELBO can successfully disentangle the four latent components in practice.
- Evidence anchors: [section] "Empirical validation on synthetic and real-world datasets substantiates the effectiveness of our approach"; [section] "We theoretically analyze the Evidence Lower Bound (ELBO) that should be considered within evolving environments."
- Break condition: If the inference network fails to disentangle the four latent variables properly, the semantic variables may still contain environmental information.

### Mechanism 3
- Claim: The counterfactual fairness loss directly penalizes dependence between predicted outcomes and sensitive attributes by comparing predictions under different counterfactual values of A.
- Mechanism: The fairness regularization term measures the squared difference between p(y|a, us, uns) and p(y|¬a, us, uns) across all domains.
- Core assumption: The latent semantic variables us and uns are sufficient to represent all information relevant to the prediction task.
- Evidence anchors: [section] "The essence of counterfactual fairness lies in minimizing the impact of A on the predicted value ˆY"; [section] "To earnestly achieve fairness in classification, it is imperative to augment the objective function with a fairness regularization term."
- Break condition: If us and uns don't fully capture all predictive information, the classifier may still depend on A indirectly through the latent representation.

## Foundational Learning

- Concept: Variational Autoencoder (VAE) framework
  - Why needed here: CDSAE extends the VAE framework to handle multiple sequential domains with fairness constraints, using variational inference to learn the four-way latent variable decomposition.
  - Quick check question: How does the ELBO in a standard VAE differ from the ELBO in CDSAE, and why are the additional terms necessary?

- Concept: Causal inference and do-calculus
  - Why needed here: The framework is built on causal reasoning, using structural causal models to formalize how sensitive attributes, environmental factors, and semantic content interact, and to define counterfactual fairness.
  - Quick check question: What is the difference between "total effect" and "counterfactual effect" in the context of fairness evaluation?

- Concept: Domain generalization under distribution shift
  - Why needed here: The method must generalize across sequentially evolving domains while maintaining fairness, requiring techniques that learn domain-invariant representations.
  - Quick check question: Why is it insufficient to simply train a fair model on source domains without considering how the data distribution evolves over time?

## Architecture Onboarding

- Component map: Static feature extractors (Es, Ens) → Dynamic inference networks (Ev1, Ev2) → Prior networks (F v1, F v2) → Decoders (Ds, Dns) → Discriminator (D) → Classifier (C)

- Critical path: Inference → Disentanglement → Classification
  1. Encode data through Es/Ens/Ev1/Ev2 to obtain us, uns, uv1, uv2
  2. Apply fairness regularization and disentanglement loss
  3. Classify using C(us, uns, at)
  4. Backpropagate through entire network to update all parameters

- Design tradeoffs: The four-way decomposition increases model complexity but provides stronger fairness guarantees. Using LSTMs for environmental priors adds temporal modeling capability but requires more training data and computational resources.

- Failure signatures: 
  - High KL divergence between q(us, at, uns) and q(us)q(at, uns) indicates poor disentanglement
  - Large counterfactual effect values indicate remaining fairness violations
  - Performance degradation across sequential domains suggests the environmental modeling is insufficient

- First 3 experiments:
  1. Train on Fair-circle dataset with varying degrees of domain shift; measure accuracy and total effect across all domains
  2. Ablation study: Remove fairness regularization and observe increase in counterfactual effect
  3. Compare performance on Adult dataset when partitioning domains by age vs. random partitioning to test sensitivity to domain definition

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed method perform in environments with more than two sensitive attributes, and how does the complexity of disentangling multiple sensitive attributes scale?
- Basis in paper: [inferred] The paper treats every attribute A as a binary variable and does not discuss scenarios with multiple or non-binary sensitive attributes.
- Why unresolved: The paper focuses on binary sensitive attributes and does not explore the generalization of the method to more complex scenarios involving multiple sensitive attributes.
- What evidence would resolve it: Experiments comparing the performance of CDSAE with multiple binary or non-binary sensitive attributes to baseline methods, along with an analysis of computational complexity as the number of sensitive attributes increases.

### Open Question 2
- Question: What is the impact of different correlation levels between sensitive attributes and class labels on the effectiveness of CDSAE?
- Basis in paper: [inferred] The paper mentions that the correlation between sensitive attributes and class labels is controlled by a parameter (ϕ), but does not thoroughly investigate how different levels of correlation affect the model's performance.
- Why unresolved: The paper does not provide a comprehensive analysis of the model's performance across a range of correlation levels, leaving uncertainty about its robustness in varying real-world scenarios.
- What evidence would resolve it: A systematic study varying the correlation parameter (ϕ) and measuring the impact on CDSAE's accuracy and fairness metrics, compared to baseline methods across different correlation levels.

### Open Question 3
- Question: How does CDSAE's performance compare to other fairness-aware domain generalization methods that do not rely on causal inference?
- Basis in paper: [explicit] The paper compares CDSAE to VAE-based methods and mentions that it outperforms existing exogenous variable disentanglement methods, but does not directly compare to other fairness-aware DG methods that use different approaches.
- Why unresolved: The comparison is limited to VAE-based methods, and a broader comparison with other fairness-aware DG methods would provide a more comprehensive understanding of CDSAE's relative performance.
- What evidence would resolve it: Experimental results comparing CDSAE to other fairness-aware DG methods, such as those using adversarial training or other fairness regularization techniques, across multiple datasets and metrics.

## Limitations
- The four-way latent variable decomposition significantly increases model complexity without sufficient empirical validation that the inference network successfully learns this decomposition.
- The method requires sequential domain data, which may not be available in many real-world scenarios where data arrives in non-sequential or non-stationary ways.
- The Fair-circle dataset, while useful for controlled experiments, may not capture the full complexity of real-world fairness challenges involving multiple interacting factors.

## Confidence
- High Confidence: The core mechanism of using counterfactual fairness regularization to achieve fairness in domain generalization is well-established and theoretically sound.
- Medium Confidence: The specific four-way latent variable decomposition and its effectiveness in achieving counterfactual fairness across evolving domains needs more empirical validation.
- Medium Confidence: The sequential autoencoder architecture with LSTM-based priors is plausible but requires more detailed analysis of training stability and convergence.

## Next Checks
1. Conduct ablation studies removing individual components (fairness regularization, disentanglement loss, sequential modeling) to quantify their contribution to final performance.
2. Test model robustness to varying degrees of domain shift and different domain partitioning strategies on the Adult dataset to assess sensitivity to domain definition.
3. Perform statistical analysis comparing counterfactual effects across domains to verify that the model maintains fairness guarantees as environments evolve.