---
ver: rpa2
title: A Challenge in Reweighting Data with Bilevel Optimization
arxiv_id: '2310.17386'
source_url: https://arxiv.org/abs/2310.17386
tags:
- weights
- bilevel
- where
- algorithm
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the problem of data reweighting, where the goal
  is to learn a weight for each data point in the training set such that the model
  trained with these weights generalizes well to a test set with a different distribution.
  The authors formalize this as a bilevel optimization problem and analyze the dynamics
  of the warm-started bilevel optimization algorithm.
---

# A Challenge in Reweighting Data with Bilevel Optimization

## Quick Facts
- **arXiv ID**: 2310.17386
- **Source URL**: https://arxiv.org/abs/2310.17386
- **Reference count**: 40
- **Primary result**: Warm-started bilevel optimization for data reweighting leads to sparse weights when the outer learning rate is much larger than the inner learning rate, hindering generalization.

## Executive Summary
This paper studies data reweighting using bilevel optimization, where sample weights are learned to minimize test loss. The authors analyze warm-started bilevel optimization algorithms and show that when parameters are updated much slower than weights, the algorithm converges to extremely sparse weight solutions. This sparsity occurs because weight updates follow a mirror descent flow with low-rank hypergradient fields, making it difficult to satisfy stability conditions without sparse solutions. The theoretical findings are supported by experiments on a toy regression problem and a real-world hyper data-cleaning task.

## Method Summary
The method involves warm-started bilevel optimization where sample weights w and model parameters θ are updated simultaneously. Weights are optimized over the simplex using mirror descent with entropy regularization, while parameters are updated via gradient descent on the weighted training loss. The algorithm computes hypergradients to guide weight updates. The analysis uses ODE formulations to study the dynamics, showing that when the outer learning rate greatly exceeds the inner learning rate, weights converge to sparse solutions with at most p non-zero entries (where p is the parameter dimension).

## Key Results
- Warm-started bilevel optimization with high outer learning rates leads to sparse weight solutions
- Sparse weights result in poor generalization since the model is effectively trained on few samples
- The sparsity arises from the low-rank structure of hypergradient fields in mirror descent dynamics
- When parameters update faster than weights, the algorithm recovers exact bilevel behavior

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Warm-started bilevel optimization with simultaneous updates leads to sparse weights due to faster weight dynamics compared to parameters.
- **Mechanism**: When outer learning rate η ≫ inner learning rate ρ, weights evolve much faster than parameters. The mirror descent flow on the simplex with hypergradient field (parameterized by p-dimensional parameters) converges to sparse solutions with at most p non-zero weights due to low-rank structure making stability conditions difficult to satisfy.
- **Core assumption**: Weight dynamics are much faster than parameter dynamics (β ≫ α), and mirror descent flow converges to stationary point.
- **Evidence anchors**: Abstract mentions sparse weights; section 3.2 shows convergence to sparse solutions; related papers discuss bilevel optimization but not specifically this sparsity issue.
- **Break condition**: Increasing inner learning rate ρ to be comparable to η, or changing problem structure to have higher-dimensional parameter space or different gradient structure.

### Mechanism 2
- **Claim**: In regime where parameters update much faster than weights (α ≫ β), warm-started bilevel method recovers exact bilevel approach.
- **Mechanism**: When inner learning rate ≫ outer learning rate, parameters rapidly track minimizer θ*(w) for current weights w. Weight dynamics follow true gradient of outer function h, recovering exact bilevel optimization behavior.
- **Core assumption**: Parameters updated much faster than weights (α ≫ β), and inner problem is strongly convex.
- **Evidence anchors**: Section 3.1 states parameters track θ*(w) when α ≫ β; section 3 mentions recovery of non-warm-started bilevel approach; related papers discuss bilevel optimization but not tracking behavior in fast-parameter regime.
- **Break condition**: If inner problem not strongly convex or inner learning rate not sufficiently large, parameters may not track θ*(w) accurately.

### Mechanism 3
- **Claim**: Sparsity of weights leads to suboptimal generalization because model trained on only few samples.
- **Mechanism**: Sparse weights mean only small subset of training samples contribute to parameter updates, leading to overfitting on selected samples and poor generalization to test set, especially if selected samples don't represent full distribution.
- **Core assumption**: Test set has different distribution from training set, and sparse weights don't adequately capture relevant information from full dataset.
- **Evidence anchors**: Abstract mentions sparse weights hinder generalization; section 2.4 shows toy experiment with sparse weights and higher estimation error; section 4.2 shows hyper data-cleaning experiment with sparse weights and suboptimal validation accuracy.
- **Break condition**: If training and test distributions similar, or if sparse weights select most informative samples, generalization gap may be less severe.

## Foundational Learning

- **Concept: Bilevel Optimization**
  - Why needed here: Data reweighting problem formalized as bilevel optimization where weights w optimize to minimize test loss F(θ*(w)), and θ*(w) is minimizer of weighted training loss G(θ, w).
  - Quick check question: In a bilevel optimization problem, what is the relationship between upper-level variable (weights) and lower-level variable (parameters)?

- **Concept: Mirror Descent on the Simplex**
  - Why needed here: Weights constrained to simplex, mirror descent used to optimize over simplex. Understanding dynamics crucial for analyzing sparsity of solutions.
  - Quick check question: What is update rule for mirror descent on simplex, and how does it differ from standard gradient descent?

- **Concept: Dynamical Systems and ODEs**
  - Why needed here: Warm-started bilevel algorithm analyzed as discretization of ODE, allowing use of dynamical systems theory to study convergence and stability.
  - Quick check question: How does continuous-time ODE formulation of iterative algorithm help in understanding its behavior and convergence properties?

## Architecture Onboarding

- **Component map**: Training set X with n samples and weights w -> Model parameters θ -> Loss functions ℓ(θ; x) for training and ℓ'(θ; x') for testing -> Inner optimization (gradient descent) to find θ*(w) -> Outer optimization (mirror descent) to update weights w -> Hypergradient computation Ψ(θ, w)

- **Critical path**: 1. Initialize weights w and parameters θ; 2. For each iteration: a) Compute hypergradient Ψ(θ, w); b) Update parameters θ using gradient descent on weighted training loss; c) Update weights w using mirror descent on simplex with hypergradient; 3. Repeat until convergence or maximum iterations reached

- **Design tradeoffs**: Inner learning rate ρ vs outer learning rate η balancing speed of parameter updates and weight updates to avoid sparsity while maintaining convergence; choice of inner optimization algorithm impacting computational cost and convergence properties; regularization on inner problem ensuring strong convexity and unique solutions for θ*(w); implementation of hypergradient computation with approximations and scalability considerations

- **Failure signatures**: Sparse weights (only few training samples have non-zero weights) indicating potential overfitting and poor generalization; slow convergence if outer learning rate too small and weights don't adapt quickly enough to changing parameters; oscillations or divergence if learning rates not well-tuned and algorithm fails to converge or exhibits unstable behavior

- **First 3 experiments**: 1. Toy regression problem with two clusters: Implement warm-started bilevel algorithm on 2D regression problem with two clusters where test set contains samples from one cluster; analyze sparsity of learned weights and generalization performance; 2. MNIST data cleaning: Apply warm-started bilevel algorithm to classification task on MNIST dataset with corrupted training labels; vary outer learning rate and observe sparsity of learned weights and validation accuracy; 3. Ablation study on learning rates: Fix inner learning rate and vary outer learning rate; measure sparsity of learned weights, convergence speed, and final generalization performance; identify optimal range of learning rates balancing sparsity and performance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: Under what conditions does warm-started bilevel optimization algorithm for data reweighting converge to sparse solution, and what is relationship between convergence speed and sparsity of resulting weights?
- **Basis in paper**: [explicit] Paper states warm starting with mirror descent leads to sparse weights and provides theoretical analysis showing weights become sparse when outer learning rate too high
- **Why unresolved**: Paper provides theoretical analysis and experiments showing weights become sparse, but doesn't provide complete characterization of conditions under which this happens or relationship between convergence speed and sparsity
- **What evidence would resolve it**: More detailed theoretical analysis characterizing conditions under which algorithm converges to sparse solution, and set of experiments systematically varying learning rates and hyperparameters to study impact on convergence speed and sparsity

### Open Question 2
- **Question**: How does choice of inner learning rate and outer learning rate affect performance of warm-started bilevel optimization algorithm for data reweighting?
- **Basis in paper**: [explicit] Paper states small outer learning rate should be used which might lead to slow convergence and provides experiments showing range of learning rates where algorithm converges quickly to good solution is very narrow
- **Why unresolved**: Paper provides some insights into impact of learning rates, but doesn't provide comprehensive analysis of how choice of learning rates affects algorithm performance
- **What evidence would resolve it**: Systematic study of impact of inner and outer learning rates on performance of algorithm including convergence speed, accuracy, and sparsity of resulting weights

### Open Question 3
- **Question**: Are there alternative algorithms or modifications to warm-started bilevel optimization algorithm that can mitigate sparsity issue and improve performance of data reweighting?
- **Basis in paper**: [explicit] Paper mentions several works try to fix issues by proposing bilevel algorithms that don't have to form Hessian or invert system and that are stochastic
- **Why unresolved**: Paper focuses on analysis of warm-started bilevel optimization algorithm, but doesn't explore alternative algorithms or modifications that could potentially mitigate sparsity issue
- **What evidence would resolve it**: Comparison of performance of warm-started bilevel optimization algorithm with alternative algorithms or modifications including their convergence speed, accuracy, and sparsity of resulting weights

## Limitations

- Theoretical analysis assumes strongly convex inner problems, which may not generalize to non-convex settings common in deep learning
- Sparsity result relies heavily on low-rank structure of hypergradients and mirror descent dynamics, which may be affected by problem-specific factors like regularization or initialization
- Experimental validation limited to toy problem and one real-world case study, lacking broader empirical evidence

## Confidence

- **High**: The ODE-based analysis connecting learning rate ratios to algorithm behavior
- **Medium**: The sparsity result for mirror descent on the simplex with hypergradients
- **Medium**: The experimental demonstration of sparsity issues in toy and real-world settings

## Next Checks

1. **Non-convex extension**: Test warm-started bilevel algorithm on non-convex problem (e.g., neural network training) to verify if sparsity still emerges with high outer learning rates

2. **Regularizer ablation**: Compare different regularization schemes on simplex (e.g., ℓ2 vs entropy) to determine if sparsity can be mitigated while maintaining computational efficiency

3. **High-dimensional scaling**: Evaluate algorithm in settings where parameter dimension p is much larger than sample size n, testing theoretical bound on sparsity (at most p non-zero weights)