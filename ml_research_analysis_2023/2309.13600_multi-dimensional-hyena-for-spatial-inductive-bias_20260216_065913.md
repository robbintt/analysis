---
ver: rpa2
title: Multi-Dimensional Hyena for Spatial Inductive Bias
arxiv_id: '2309.13600'
source_url: https://arxiv.org/abs/2309.13600
tags:
- hyena
- layer
- layers
- arxiv
- attention
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Hyena N-D, a multi-dimensional extension
  of the Hyena layer that can be used as a drop-in replacement for self-attention
  in Vision Transformers (ViTs). Hyena N-D employs implicit global convolution filters
  that are constructed via feed-forward networks operating on positional encodings,
  and incorporates spatial locality through window functions.
---

# Multi-Dimensional Hyena for Spatial Inductive Bias

## Quick Facts
- arXiv ID: 2309.13600
- Source URL: https://arxiv.org/abs/2309.13600
- Authors: [Authors not specified in source]
- Reference count: 21
- This paper introduces Hyena N-D, a multi-dimensional extension of the Hyena layer that can be used as a drop-in replacement for self-attention in Vision Transformers (ViTs).

## Executive Summary
This paper introduces Hyena N-D, a multi-dimensional extension of the Hyena layer that can be used as a drop-in replacement for self-attention in Vision Transformers (ViTs). Hyena N-D employs implicit global convolution filters that are constructed via feed-forward networks operating on positional encodings, and incorporates spatial locality through window functions. The authors theoretically analyze the expressiveness and inductive bias of Hyena N-D, showing it can express high-rank kernels and has an inductive bias towards low-rank tensors. Empirically, they demonstrate that Hyena N-D outperforms attention on various ViT architectures across multiple datasets, especially in the small data regime. They also propose hybrid models that combine Hyena N-D with attention, further improving performance.

## Method Summary
Hyena N-D extends the Hyena layer to multiple dimensions by constructing implicit global convolution filters through feed-forward networks operating on positional encodings. These filters are combined with window functions that encode spatial locality (e.g., exp(-α(i+j)) + γ for symmetric 2D locality). The layer maintains sub-quadratic complexity through efficient FFT-based convolution while incorporating spatial inductive bias that benefits performance particularly in small data regimes. The authors also introduce a multi-directional extension to address the causal nature of the original Hyena layer, which is unnatural for computer vision tasks.

## Key Results
- Hyena N-D outperforms standard attention in ViTs across CIFAR-100, Tiny-ImageNet, and CelebA datasets, especially in small data regimes
- The multi-directional extension improves results by ~1-1.5% by allowing information flow in all spatial directions
- Hybrid models combining Hyena N-D with attention further improve performance over either component alone
- Hyena N-D maintains sub-quadratic complexity while capturing global context through implicit convolution filters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Hyena N-D layer introduces spatial inductive bias into ViTs through implicit global convolution filters that incorporate two-dimensional locality.
- Mechanism: The layer constructs N-D implicit filters by applying feed-forward networks on positional encodings and combines them with window functions that encode spatial locality (e.g., exp(-α(i+j)) + γ for symmetric 2D locality). This replaces the permutation-invariant self-attention with a spatial-aware convolution-like operation.
- Core assumption: The implicit global convolution filters can effectively capture spatial relationships in images while maintaining the flexibility to handle varying image sizes and aspect ratios.
- Evidence anchors:
  - [abstract] "Hyena N-D employs implicit global convolution filters that are constructed via feed-forward networks operating on positional encodings, and incorporates spatial locality through window functions."
  - [section 3] "The Hyena N-D layer is composed of three main components: (i) implicit global filters (ii) a data control mechanism in the form of gating (element-wise multiplications), and (iii) a short filter implemented by a 1-D convolutional layer."
  - [corpus] Weak evidence - related works focus on 2-D SSM and convolution-injector methods but don't directly address Hyena N-D's mechanism.
- Break condition: If the window function parameters (α, β, γ) are not properly learned or if the positional encoding is insufficient to distinguish spatial positions, the spatial inductive bias may not be effectively captured.

### Mechanism 2
- Claim: The Hyena N-D layer achieves sub-quadratic complexity in sequence length while maintaining global context.
- Mechanism: By using implicit global convolution filters constructed through feed-forward networks on positional encodings, the layer avoids the O(L²) complexity of self-attention. The convolution can be efficiently computed using FFT, resulting in O(L log L) complexity for each dimension.
- Core assumption: The feed-forward network can parameterize the implicit filters effectively without requiring explicit storage of all pairwise interactions.
- Evidence anchors:
  - [abstract] "The authors theoretically analyze the expressiveness and inductive bias of Hyena N-D, showing it can express high-rank kernels and has an inductive bias towards low-rank tensors."
  - [section 5.1] "Under the assumption that the hidden FFN dimension is smaller than the number of channels (M ≤ C), the time and space complexity of creating implicit filters in Hyena 1-D, Hyena N-D and Hyena N-D product are LCM."
  - [corpus] Weak evidence - while related works discuss efficiency, they don't directly analyze Hyena N-D's complexity advantage.
- Break condition: If the feed-forward network becomes too large (M approaches C) or if the sequence length becomes extremely large, the complexity advantage may diminish.

### Mechanism 3
- Claim: The multi-directional extension of Hyena N-D improves performance by allowing information flow in all spatial directions.
- Mechanism: The layer rotates the input representation before applying the Hyena recurrence in multiple directions (4-directional or 2-directional variants), ensuring that the model can capture dependencies from all spatial orientations rather than just causal directions.
- Core assumption: Images contain information that flows in multiple spatial directions, and restricting the model to causal processing limits its ability to capture these relationships.
- Evidence anchors:
  - [section 4] "Since the Hyena layer is causal, previous data elements will not be affected by subsequent ones. While this property is essential for language modeling, it is very unnatural for computer vision tasks... To address this limitation, we introduce a multi-directional extension to our layer."
  - [section 6.2] "As expected, for both Hyena N-D and Hyena N-D product, the multi-directional approach improves the results by ~1-1.5 %."
  - [corpus] Weak evidence - related works focus on rotational equivariance but don't specifically address Hyena N-D's multi-directional approach.
- Break condition: If the rotation operations introduce too much computational overhead or if the model overfits to directional patterns that don't generalize.

## Foundational Learning

- Concept: Implicit global convolution filters
  - Why needed here: Understanding how the Hyena layer constructs filters implicitly through feed-forward networks on positional encodings, rather than explicit parameterization, is crucial for grasping the model's efficiency and flexibility advantages.
  - Quick check question: How does the Hyena layer's approach to filter construction differ from standard convolution layers, and what are the computational implications of this difference?

- Concept: Tensor rank and expressiveness
  - Why needed here: The paper's theoretical analysis relies on tensor rank as a criterion for expressiveness, showing that Hyena N-D can express high-rank kernels while maintaining an inductive bias toward low-rank tensors.
  - Quick check question: What is the relationship between the hidden dimension of the FFN layer and the maximum tensor rank that can be expressed by the Hyena N-D filters?

- Concept: Spatial inductive bias in vision models
  - Why needed here: Understanding why traditional CNNs perform well on small datasets due to their spatial inductive bias, and how the Hyena N-D layer attempts to incorporate similar bias into a transformer-like architecture, is key to appreciating the paper's contributions.
  - Quick check question: Why do standard ViTs struggle with small datasets, and how does the Hyena N-D layer's approach to spatial inductive bias address this limitation?

## Architecture Onboarding

- Component map:
  Input -> Positional encoding layer -> Window function layer -> Feed-forward network (FFN) -> N-D convolution operation (computed via FFT) -> Element-wise gating mechanism -> Short 2D convolution layer -> Output projection

- Critical path:
  1. Positional encoding of input patches
  2. Construction of N-D implicit filters via FFN
  3. Application of window function to filters
  4. N-D convolution between filters and input
  5. Element-wise gating with input
  6. Short 2D convolution
  7. Output projection

- Design tradeoffs:
  - Window function choice: Symmetric (i+j) vs dimensional (i, j) encoding of locality
  - Multi-directional vs single-directional processing
  - Hyena-only vs hybrid with attention
  - Number of directions in multi-directional extension (2 vs 4)
  - Hidden dimension of FFN (balancing expressiveness and efficiency)

- Failure signatures:
  - Poor performance on small datasets may indicate insufficient spatial inductive bias
  - High memory usage may suggest inefficient FFT implementation or overly large FFN
  - Degraded performance with multi-directional extension may indicate overfitting to directional patterns
  - Inconsistent results across different architectures (ViT, Swin, DeiT) may suggest implementation issues

- First 3 experiments:
  1. Baseline comparison: Replace attention layers in a small ViT with Hyena N-Dproduct on CIFAR-100 to establish performance improvement
  2. Window function ablation: Compare symmetric vs dimensional window functions on CIFAR-100 to validate the choice of dimensional window
  3. Multi-directional ablation: Test 1-directional, 2-directional, and 4-directional variants on CIFAR-100 to quantify the benefit of multi-directional processing

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Hyena N-D layer's performance compare to other state-of-the-art methods on larger datasets and more complex tasks like segmentation and generation?
- Basis in paper: [inferred] The authors mention benchmarking Hyena-ViT on tasks beyond classification and applying the layer to other N-dimensional modalities as future work.
- Why unresolved: The paper only evaluates Hyena N-D on image classification benchmarks, leaving its performance on other tasks and modalities unexplored.
- What evidence would resolve it: Empirical results comparing Hyena N-D to other methods on larger datasets and more complex tasks, as well as its application to other N-dimensional modalities.

### Open Question 2
- Question: What is the optimal configuration of the Hyena N-D layer, including the choice of window function, number of hidden layers, and hidden dimension size?
- Basis in paper: [explicit] The authors conduct ablation studies on window functions and multi-directional methods, but leave the optimal configuration of the Hyena N-D layer as an open question.
- Why unresolved: The paper provides insights into the impact of specific design choices, but does not determine the overall optimal configuration of the Hyena N-D layer.
- What evidence would resolve it: A comprehensive study systematically varying the Hyena N-D layer's configuration and evaluating its impact on performance.

### Open Question 3
- Question: How does the Hyena N-D layer's inductive bias towards low-rank tensors impact its generalization performance on different tasks and datasets?
- Basis in paper: [explicit] The authors theoretically characterize the Hyena N-D layer's inductive bias towards low-rank tensors, but do not explore its empirical impact on generalization.
- Why unresolved: The paper establishes the theoretical inductive bias but does not investigate its practical implications on the layer's performance across different tasks and datasets.
- What evidence would resolve it: Empirical studies comparing the Hyena N-D layer's generalization performance to other methods with different inductive biases on various tasks and datasets.

## Limitations
- The exact parameterization and implementation details of the Hyena N-D layer, particularly the feed-forward network structure for filter construction, remain somewhat unclear
- The computational complexity advantages, while theoretically sound, may not hold in practice due to implementation overhead or memory constraints with very large sequence lengths
- The multi-directional extension's effectiveness may vary significantly depending on the specific dataset and task, as the assumption about bidirectional information flow in images may not always hold

## Confidence

- **High Confidence**: The theoretical analysis of expressiveness and inductive bias, supported by tensor rank arguments and complexity analysis
- **Medium Confidence**: The empirical results showing performance improvements, as they depend on precise implementation details and training setup
- **Low Confidence**: The generalizability of the multi-directional extension across diverse computer vision tasks, as this requires extensive validation beyond the reported experiments

## Next Checks

1. **Implementation Verification**: Reimplement the Hyena N-D layer from scratch and compare its output distribution statistics with those reported in the paper. Verify that the implicit filter construction through FFN produces the expected tensor ranks and that the convolution operations maintain the theoretical complexity bounds.

2. **Ablation on Window Functions**: Conduct a systematic ablation study comparing different window function parameterizations (symmetric vs dimensional, varying α, β, γ) across multiple datasets to determine which configuration provides the most robust spatial inductive bias.

3. **Transfer Learning Analysis**: Test the Hyena N-D layer's performance when pretrained on ImageNet and fine-tuned on smaller datasets like CIFAR-100, comparing against standard ViT transfer learning. This would validate the claimed data efficiency advantage in a realistic setting where pretraining on large datasets is the norm.