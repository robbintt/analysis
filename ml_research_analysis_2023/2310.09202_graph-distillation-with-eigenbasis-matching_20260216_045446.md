---
ver: rpa2
title: Graph Distillation with Eigenbasis Matching
arxiv_id: '2310.09202'
source_url: https://arxiv.org/abs/2310.09202
tags:
- graph
- synthetic
- gnns
- graphs
- condensation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the generalization problem in graph condensation
  methods. Existing methods suffer from poor generalization because GNNs inject spectrum
  bias into synthetic graphs during condensation, causing distribution shifts.
---

# Graph Distillation with Eigenbasis Matching

## Quick Facts
- arXiv ID: 2310.09202
- Source URL: https://arxiv.org/abs/2310.09202
- Reference count: 40
- Key outcome: Proposes GCEM method that matches eigenbasis and node features to generate synthetic graphs without spectrum bias, improving generalization across GNN architectures

## Executive Summary
This paper addresses the generalization problem in graph condensation methods, where existing approaches suffer from poor performance across different GNN architectures due to spectrum bias. The authors propose Graph Condensation with Eigenbasis Matching (GCEM), which aligns the eigenbasis and node features of real and synthetic graphs without explicitly using spectrum information. GCEM constructs synthetic graphs using the real graph's spectrum while employing a discrimination constraint for balance. The method theoretically generates spectral approximations of real graphs and experimentally outperforms state-of-the-art methods on five datasets.

## Method Summary
GCEM addresses spectrum bias in graph condensation by matching eigenbasis rather than adjacency matrices. The method first preprocesses the real graph to select important eigenvectors, then initializes synthetic graph structure and features using a stochastic block model and pre-trained MLP. It iteratively optimizes eigenbasis matching objectives and discrimination constraints to align node features in subspaces defined by real and synthetic eigenbasis. Finally, GCEM reconstructs the synthetic adjacency matrix using the real graph's eigenvalues while preserving the aligned eigenbasis structure.

## Key Results
- Outperforms state-of-the-art graph condensation methods on Cora, Citeseer, Pubmed, arXiv, and Flickr datasets
- Significantly narrows performance gaps across different GNN architectures (GCN, GAT, SGC, JK-Net)
- Demonstrates improved generalization compared to spectrum-based approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GNNs inject spectrum bias into synthetic graphs during condensation, causing distribution shifts that hurt generalization.
- Mechanism: During gradient matching, the condensation GNN preferentially preserves low-frequency spectral components while discarding high-frequency ones, resulting in synthetic graphs with biased spectral distributions compared to real graphs.
- Core assumption: The spectrum bias introduced by GNNs is harmful for generalization across different GNN architectures.
- Evidence anchors:
  - [abstract] "GNNs can affect the spectrum (i.e., eigenvalues) of the real graph, causing spectrum bias in the synthetic graph"
  - [section] "Replacing the one-layer GCN with other graph filters results in different GNNs... This replacement does not affect our analysis but provides different spectrum preferences"

### Mechanism 2
- Claim: Matching eigenbasis instead of adjacency matrix eliminates spectrum bias while preserving essential structural information.
- Mechanism: By aligning node features in the subspaces defined by important eigenvectors of real and synthetic graphs, the method preserves structural similarity without explicitly using spectral information that would introduce GNN-specific bias.
- Core assumption: Eigenbasis alignment is sufficient to preserve essential graph structure without spectrum bias.
- Evidence anchors:
  - [abstract] "GCEM matches the eigenbasis and node features of real and synthetic graphs... thus avoiding bias"
  - [section] "The eigenbasis consists of a set of Laplacian eigenvectors, representing the underlying structures of the corresponding graph"

### Mechanism 3
- Claim: Using the real graph's spectrum to construct the synthetic graph after eigenbasis matching preserves spectral similarity.
- Mechanism: After generating the synthetic eigenbasis through bias-free matching, the method reconstructs the adjacency matrix using the real graph's eigenvalues, ensuring spectral properties are maintained without GNN-induced bias.
- Core assumption: The synthetic and real graphs can share the same spectrum after proper eigenbasis alignment.
- Evidence anchors:
  - [section] "GCEM constructs the synthetic graph by leveraging the spectrum of the real graph, which naturally preserves some global structural properties"
  - [section] "If the eigenbasis of the real and synthetic graphs align well, they can share the same spectrum"

## Foundational Learning

- Concept: Graph Laplacian and its eigenbasis decomposition
  - Why needed here: Understanding how graphs can be represented in spectral domain is crucial for the eigenbasis matching approach
  - Quick check question: What does each eigenvector in the Laplacian's eigenbasis represent about the graph structure?

- Concept: Total variation as a measure of signal smoothness on graphs
  - Why needed here: The paper uses total variation to demonstrate spectrum bias in synthetic graphs generated by different GNNs
  - Quick check question: How does total variation relate to the eigenvalues and eigenvectors of the graph Laplacian?

- Concept: Graph condensation vs traditional graph reduction
  - Why needed here: Understanding the difference between these approaches helps appreciate why eigenbasis matching is novel
  - Quick check question: What is the key difference between preserving model performance versus preserving graph structure?

## Architecture Onboarding

- Component map: Pre-processing -> Initialization -> Eigenbasis matching -> Discrimination constraint -> Graph construction
- Critical path:
  1. Pre-process real graph to select important eigenvectors
  2. Initialize synthetic graph structure and features
  3. Iteratively optimize eigenbasis matching and discrimination objectives
  4. Reconstruct final synthetic adjacency matrix
  5. Evaluate on downstream tasks
- Design tradeoffs:
  - Eigenbasis matching vs direct adjacency optimization: avoids spectrum bias but requires eigenvalue decomposition
  - Number of eigenvectors (K1, K2): balances computational cost with representational capacity
  - Discrimination constraint weight: trades off effectiveness vs generalization
- Failure signatures:
  - Poor performance on spectral GNNs: likely insufficient eigenvector coverage
  - High variance across architectures: eigenbasis matching not properly aligned
  - Slow convergence: learning rate or regularization parameters need tuning
- First 3 experiments:
  1. Ablation study: Remove eigenbasis matching term (Lğ‘’) to confirm its importance for generalization
  2. Hyperparameter sensitivity: Vary K1, K2 to find optimal eigenvector selection
  3. Visualization: Plot total variation evolution during training to verify spectrum preservation claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of eigenbasis (i.e., which eigenvectors to match) affect the performance and generalization of GCEM?
- Basis in paper: [explicit] The paper states that they choose eigenvectors with the ğ¾1 smallest and ğ¾2 largest eigenvalues, where ğ¾1 and ğ¾2 are hyperparameters, and ğ¾1 + ğ¾2 â‰¤ ğ‘›â€². However, the impact of different choices for ğ¾1 and ğ¾2 is not explored.
- Why unresolved: The paper does not provide experimental results or analysis on the sensitivity of GCEM to the choice of ğ¾1 and ğ¾2.
- What evidence would resolve it: Experiments varying ğ¾1 and ğ¾2 and reporting their impact on performance and generalization would resolve this question.

### Open Question 2
- Question: How does the discrimination constraint (Lğ‘‘) affect the performance and generalization of GCEM?
- Basis in paper: [explicit] The paper introduces Lğ‘‘ as a regularization term to improve the discriminative power of the synthetic graph, but the impact of this term is not fully explored.
- Why unresolved: The paper does not provide a detailed analysis of the effect of Lğ‘‘ on the performance and generalization of GCEM.
- What evidence would resolve it: Experiments varying the weight of Lğ‘‘ (ğ›½) and reporting its impact on performance and generalization would resolve this question.

### Open Question 3
- Question: How does GCEM compare to other graph condensation methods that do not rely on spectrum information?
- Basis in paper: [inferred] The paper suggests that GCEM is a spectrum-free graph condensation method, but it does not compare its performance to other spectrum-free methods.
- Why unresolved: The paper does not provide a comparison between GCEM and other spectrum-free graph condensation methods.
- What evidence would resolve it: Experiments comparing GCEM to other spectrum-free graph condensation methods would resolve this question.

## Limitations

- The computational complexity of eigenvalue decomposition for large graphs may limit practical applicability
- The method's performance on heterophilous graphs versus homophilous graphs is not explicitly evaluated
- The core assumption that spectrum bias is universally harmful across diverse graph types and tasks lacks comprehensive validation

## Confidence

- **High Confidence:** The experimental results showing improved performance over baseline methods on the tested datasets. The theoretical framework for eigenbasis matching is well-established in spectral graph theory.
- **Medium Confidence:** The claim that spectrum bias is the primary cause of poor generalization in graph condensation. The proposed solution of eigenbasis matching without spectrum information is promising but requires more rigorous ablation studies.
- **Low Confidence:** The assertion that GCEM completely avoids spectrum bias while maintaining spectral similarity through the reconstruction step. The discrimination constraint's impact on different GNN architectures needs more systematic evaluation.

## Next Checks

1. **Ablation Study Extension:** Conduct a more comprehensive ablation study removing different components (eigenbasis matching, discrimination constraint, spectrum reconstruction) to quantify their individual contributions to performance and generalization.

2. **Scalability Analysis:** Evaluate GCEM on larger graphs (e.g., OGB datasets) to assess computational feasibility and identify bottlenecks in the eigenbasis matching process.

3. **Heterophily Testing:** Systematically test GCEM on graphs with varying levels of heterophily to determine if the method performs consistently across different graph structural properties, particularly for GNNs designed for heterophilous graphs.