---
ver: rpa2
title: 'EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge: Mixed Sequences
  Prediction'
arxiv_id: '2307.12837'
source_url: https://arxiv.org/abs/2307.12837
tags:
- sequence
- action
- domain
- target
- actions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses unsupervised domain adaptation (UDA) in egocentric
  action recognition. The key idea is to mitigate domain shift by mixing action sequences
  from source and target domains using pseudo-labels for the target.
---

# EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge: Mixed Sequences Prediction

## Quick Facts
- arXiv ID: 2307.12837
- Source URL: https://arxiv.org/abs/2307.12837
- Reference count: 13
- Primary result: 2nd place in verb classification, 4th place in noun and action classification on EPIC-Kitchens-100 UDA challenge leaderboard

## Executive Summary
This work addresses unsupervised domain adaptation (UDA) for egocentric action recognition by mitigating domain shift through mixing action sequences from source and target domains. The approach generates modified sequences by replacing actions in source sequences with equivalent target actions sharing the same verb and noun labels, then trains a transformer-based sequence predictor on these mixed sequences. The method achieves strong performance on the EPIC-Kitchens-100 UDA challenge, placing 2nd for verb classification and 4th for noun and action classification.

## Method Summary
The method generates pseudo-labels for target domain samples using a confidence threshold of λ=0.75 on source-trained predictions. It then creates mixed sequences by randomly replacing one or more actions in source sequences with equivalent target actions (same verb/noun labels). A transformer encoder models temporal relationships in these mixed sequences while a domain classifier provides adversarial alignment. During inference, predictions are refined using a language model to filter unlikely sequences and a co-occurrence matrix to eliminate unseen verb-noun pairs from the source domain.

## Key Results
- Achieved 2nd place in verb classification on EPIC-Kitchens-100 UDA challenge
- Ranked 4th in both noun and action classification tasks
- Demonstrated effectiveness of mixed sequence generation for UDA in egocentric action recognition

## Why This Works (Mechanism)

### Mechanism 1
Mixing target domain actions into source sequences helps the model learn domain-agnostic temporal patterns. By randomly replacing actions in source sequences with equivalent target actions, the model is forced to predict central actions using both domains' data, learning invariant temporal relationships. This works under the assumption that the order of actions is similar between source and target domains.

### Mechanism 2
Language model filtering removes unlikely action sequences, improving prediction accuracy. A masked language model trained on source sequences scores generated sequences, and the most probable sequence according to the LM is selected for final prediction. This assumes the language model can capture valid action sequence patterns that exist across domains.

### Mechanism 3
Co-occurrence matrix eliminates unseen verb-noun pairs, refining predictions. During inference, verb-noun pairs not seen in source training data have their probabilities reduced by factor of 0.01. This assumes that actions not present in source data are unlikely to appear in target data.

## Foundational Learning

- **Concept: Unsupervised Domain Adaptation**
  - Why needed here: The task involves adapting a model trained on labeled source data to unlabeled target data with different distribution
  - Quick check question: What is the key difference between supervised and unsupervised domain adaptation?

- **Concept: Temporal sequence modeling**
  - Why needed here: Actions in egocentric videos follow temporal patterns that can be exploited for better recognition across domains
  - Quick check question: How does temporal context help distinguish between similar actions in video sequences?

- **Concept: Pseudo-labeling strategy**
  - Why needed here: Since target data is unlabeled, we need a method to generate labels for target samples to enable the mixing process
  - Quick check question: What confidence threshold is used for accepting pseudo-labels in this approach?

## Architecture Onboarding

- **Component map**: Feature extraction (TBN with RGB, Flow, Audio) → Pseudo-label generator (confidence threshold λ=0.75) → Mixed sequence generator → Transformer encoder → Domain classifier → Language model → Co-occurrence matrix

- **Critical path**: Feature extraction → Pseudo-labeling → Mixed sequence generation → Transformer encoding → Domain adversarial training → Language model refinement → Co-occurrence filtering

- **Design tradeoffs**: 
  - Single vs multiple replacements: Replacing 1 action gives best action accuracy, more replacements only help individual categories
  - Sequence length: Length 5 provides optimal balance between context and computational cost
  - Confidence threshold: Higher thresholds reduce noisy pseudo-labels but may limit target data usage

- **Failure signatures**:
  - Low pseudo-label confidence: Target domain too different from source
  - Language model consistently filters all sequences: LM overfits to source patterns
  - Co-occurrence filtering hurts performance: Target contains novel actions

- **First 3 experiments**:
  1. Test baseline performance without any domain adaptation components
  2. Evaluate pseudo-labeling quality by checking confidence distribution on target data
  3. Measure impact of different sequence lengths (1, 3, 5, 9) on validation set

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of the proposed method scale with larger domain gaps or more diverse target domains? The paper evaluates the method on EPIC-Kitchens-100 UDA challenge but doesn't explore performance on increasingly dissimilar domains. This remains unresolved because the experiments are limited to a single dataset without systematically varying domain dissimilarity. Testing on multiple datasets with controlled domain shifts would resolve this question.

### Open Question 2
What is the impact of different pseudo-label confidence thresholds (λ) on the final performance, and is there an optimal value that generalizes across datasets? The paper uses λ = 0.75 but only mentions it's based on confidence threshold without exploring sensitivity or optimal selection. This remains unresolved because only one threshold value is tested without ablation studies on different thresholds. Systematic experiments with varying λ values would resolve this question.

### Open Question 3
How does the method perform when target domain sequences have significantly different temporal patterns compared to the source domain? The method assumes similar temporal order between domains but doesn't test scenarios where this assumption breaks down. This remains unresolved because the paper doesn't create adversarial scenarios or test on domains with fundamentally different action sequences. Experiments with target domains where action sequences are intentionally reordered would resolve this question.

## Limitations
- The assumption that action temporal order is similar across domains is asserted but not empirically validated
- Minimal details provided about language model implementation, training procedure, or validation
- Co-occurrence matrix filtering may limit performance if target domain contains genuinely novel actions

## Confidence
- **Mixed Sequence Approach Effectiveness**: Medium Confidence - Challenge leaderboard results show effectiveness, but component contributions not isolated
- **Temporal Invariance Learning**: Low Confidence - No direct evidence showing what temporal features the model learns
- **Language Model Refinement Benefit**: Low Confidence - No quantitative comparison showing performance with and without this component

## Next Checks
1. Conduct detailed analysis of pseudo-label confidence distribution on target domain, plotting confidence scores across different action categories to identify systematic misclassifications
2. Perform ablation study varying number of action replacements (0, 1, 2, 3+) to quantify benefit of mixing versus other components
3. Extract and compare action transition probabilities and sequence patterns between source and target domains, calculating KL divergence to empirically validate temporal similarity assumption