---
ver: rpa2
title: 'Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific
  Semantic Textual Similarity'
arxiv_id: '2309.06541'
source_url: https://arxiv.org/abs/2309.06541
tags:
- similarity
- chatgpt
- text
- llms
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study investigates the performance of generative large language
  models (LLMs) like ChatGPT on semantic textual similarity (STS) tasks, which have
  been under-explored despite the rise of LLMs in other NLP domains. The authors argue
  that LLMs are well-suited for STS due to their vast world knowledge and ability
  to reason about semantic relationships.
---

# Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity

## Quick Facts
- arXiv ID: 2309.06541
- Source URL: https://arxiv.org/abs/2309.06541
- Reference count: 18
- Key outcome: ChatGPT significantly outperforms encoder baselines on domain-specific STS tasks by leveraging world knowledge and improved prompting strategies

## Executive Summary
This study investigates the potential of generative large language models (LLMs) for semantic textual similarity (STS) tasks, which have been under-explored despite the rise of LLMs in other NLP domains. The authors propose a new STS prompting strategy that maps similarity scores to a [0-1] scale, significantly improving LLM performance compared to existing [0-5] scales. They evaluate ChatGPT and Llama2 on standard STS benchmarks and three new domain-specific STS challenge sets in Health, Politics, and Sports. Results show ChatGPT achieves state-of-the-art performance on standard benchmarks and outperforms encoder baselines by an average of 22.3% on domain-specific tasks.

## Method Summary
The study evaluates generative LLMs using zero-shot, few-shot, and chain-of-thought prompting strategies on both standard STS benchmarks (STS12-16, STS-B, SICK-R) and newly created domain-specific challenge sets. The authors propose mapping similarity scores from the original [0-5] scale to [0-1], which significantly improves LLM performance. They compare results against supervised encoder models (RoBERTa-base/large fine-tuned on STS-B) and unsupervised models (SBERT, SimCSE, GenSE+) using Spearman correlation as the evaluation metric.

## Key Results
- ChatGPT achieves state-of-the-art results on STS13 and STS15, with competitive performance on other standard datasets
- On domain-specific challenge sets, ChatGPT outperforms best encoder baselines by 22.3% average improvement
- Llama2 performs poorly in zero-shot settings but improves significantly with few-shot prompting
- The [0-1] scale mapping consistently improves LLM performance compared to [0-5] scales

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs are better at STS than encoders because they have broader world knowledge from pre-training.
- **Mechanism:** LLMs can leverage knowledge learned during pre-training to handle domain-specific STS tasks without needing domain-specific labeled data, while encoders rely on task-specific training.
- **Core assumption:** The world knowledge present in LLM pre-training data is sufficient to handle the domain-specific STS tasks without additional fine-tuning.
- **Evidence anchors:** [abstract] "LLMs do not rely on human-labeled data, allowing them to be exposed to a broad range of world knowledge." [section] "Success on STS-Sports requires a model to know Lebron James plays for the Los Angeles Lakers."
- **Break condition:** If the STS task requires knowledge not present in pre-training data or if the knowledge is outdated.

### Mechanism 2
- **Claim:** LLMs perform better on STS when similarity scores are mapped to [0-1] instead of [0-5].
- **Mechanism:** The [0-1] scale aligns better with the natural language percentages LLMs encounter during pre-training, making it easier for them to reason about similarity.
- **Core assumption:** LLMs have been exposed to more percentage-based similarity expressions during pre-training than Likert scale expressions.
- **Evidence anchors:** [abstract] "We find that mapping the original [0-5] similarity scale used in STS benchmarks to be between [0-1] significantly improves LLM performance." [section] "We find it to be intuitive that LLMs have an easier time understanding