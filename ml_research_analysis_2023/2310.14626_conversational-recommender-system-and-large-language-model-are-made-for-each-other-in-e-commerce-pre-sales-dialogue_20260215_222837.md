---
ver: rpa2
title: Conversational Recommender System and Large Language Model Are Made for Each
  Other in E-commerce Pre-sales Dialogue
arxiv_id: '2310.14626'
source_url: https://arxiv.org/abs/2310.14626
tags:
- user
- pre-sales
- dialogue
- llms
- needs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores the collaboration between large language models
  (LLMs) and conversational recommender systems (CRSs) in E-commerce pre-sales dialogues.
  Two collaboration methods are proposed: CRS assisting LLM and LLM assisting CRS.'
---

# Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue

## Quick Facts
- arXiv ID: 2310.14626
- Source URL: https://arxiv.org/abs/2310.14626
- Reference count: 19
- This paper explores collaboration between large language models (LLMs) and conversational recommender systems (CRSs) in E-commerce pre-sales dialogues, showing effectiveness across three tasks.

## Executive Summary
This paper investigates how large language models (LLMs) and conversational recommender systems (CRSs) can effectively collaborate in E-commerce pre-sales dialogues. The authors propose two collaboration methods: CRS assisting LLM and LLM assisting CRS, and evaluate them on four tasks including dialogue understanding, user needs elicitation, recommendation, and dialogue generation. Experiments on a real-world dataset demonstrate that these collaborations significantly improve performance across all tasks, with LLMs excelling at understanding user needs and CRSs providing domain-specific recommendation capabilities.

## Method Summary
The study evaluates two collaboration methods between LLMs and CRSs on E-commerce pre-sales dialogues. The first method (CLLM-BCRS) integrates CRS predictions into LLM inputs to improve dialogue understanding and generation. The second method (ALLM-CCRS) incorporates LLM predictions into CRS prompts and representations to enhance recommendation accuracy. The experiments use two CRS architectures (UniMIND with BART and CPT encoders) and two LLMs (ChatGLM-6B and Chinese-Alpaca-7B) on the U-NEED dataset containing 7,698 annotated pre-sales dialogues across five product categories.

## Key Results
- LLM assisting CRS (CLLM-BCRS) substantially outperforms baseline CRS methods on dialogue understanding tasks across all categories
- CRS assisting LLM (ALLM-CCRS) achieves 6.9%, 3.8%, and 4.9% improvements on Accuracy, Hit@5, and MRR@5 respectively compared to baseline CRS methods
- The collaborative approaches show consistent performance improvements across all five product categories (Beauty, Phones, Fashion, Shoes, Electronics)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM assisting CRS improves dialogue understanding by leveraging the LLM's superior semantic understanding capabilities
- Mechanism: The LLM processes dialogue context and extracts fine-grained semantic frames, which are incorporated into the CRS prompt to enhance user needs understanding
- Core assumption: LLM's pre-trained language understanding generalizes well to domain-specific E-commerce dialogues after fine-tuning
- Evidence anchors:
  - LLMs generate responses that mimic pre-sales dialogues after fine-tuning but lack domain-specific knowledge
  - ChatGLM substantially outperforms classical baseline methods and CRSs on all metrics in all categories

### Mechanism 2
- Claim: CRS assisting LLM improves recommendation accuracy by providing product embeddings that capture implicit relationships
- Mechanism: CRS learns user representations and computes product recommendation scores, which LLM uses as additional context when generating responses
- Core assumption: CRS's learned product embeddings contain meaningful information about product-user relationships that LLM can leverage
- Evidence anchors:
  - LLMs lack information about candidate products, making them unsuitable for domain-specific recommendations
  - ALLM-CCRS achieves significant improvements on Accuracy, Hit@5, and MRR@5 metrics

### Mechanism 3
- Claim: Combination provides complementary strengths - LLM for understanding user needs and CRS for domain-specific recommendations
- Mechanism: LLM handles open-domain understanding and generation while CRS focuses on domain-specific recommendation using learned representations
- Core assumption: LLM and CRS have orthogonal strengths that complement each other effectively
- Evidence anchors:
  - Strengths of LLM and CRS in E-commerce pre-sales dialogues are complementary
  - CLLM-BCRS outperforms baseline CRS on all metrics for all categories

## Foundational Learning

- Concept: Pre-sales dialogue understanding
  - Why needed here: Fundamental task that both LLMs and CRSs need to perform well for effective collaboration
  - Quick check question: How would you extract attributes and values from a user utterance like "I need a warm thermal underwear that's durable and affordable"?

- Concept: User needs elicitation
  - Why needed here: Determines which attributes to ask about to better understand user needs, crucial for making good recommendations
  - Quick check question: Given user needs {("Functional requirement", "Warmest"), ("Category", "Thermal underwear")}, what attributes would you select to elicit more information?

- Concept: User representation learning
  - Why needed here: CRSs rely on learned user representations to make recommendations, which need to capture user preferences effectively
  - Quick check question: How would you represent a user's preferences based on their dialogue history and behavior?

## Architecture Onboarding

- Component map: User utterance → LLM understanding → CRS user representation → Recommendation generation → Response generation
- Critical path: User utterance → LLM understanding → CRS user representation → Recommendation generation → Response generation
- Design tradeoffs:
  - Fine-tuning LLMs on domain-specific data vs. using them zero-shot
  - Using BART vs. CPT encoders in CRS for different performance characteristics
  - Incorporating LLM recommendations directly vs. using them as additional context
- Failure signatures:
  - Degradation in dialogue understanding when LLM-CRS collaboration is used
  - Poor recommendation quality when CRS-LLM collaboration is used
  - Increased response latency due to additional processing steps
- First 3 experiments:
  1. Compare LLM performance on dialogue understanding with and without CRS integration
  2. Compare CRS recommendation accuracy with and without LLM-provided product embeddings
  3. Evaluate end-to-end performance on all four tasks for different LLM-CRS combinations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do collaborative approaches perform when using LLMs with significantly different parameter sizes?
- Basis in paper: The paper mentions findings may only apply to LLMs around 7B parameters and exploring larger models would require more resources
- Why unresolved: Only experiments with 7B parameter models due to resource constraints
- What evidence would resolve it: Experiments comparing collaborative approaches using LLMs of varying parameter sizes on same dataset and tasks

### Open Question 2
- Question: What is the impact of using different CRS architectures in collaborative approaches?
- Basis in paper: The paper uses BART and CPT-based CRSs and suggests exploring CRSs designed for persuasive recommendation generation
- Why unresolved: Only tests collaborations with BART and CPT-based CRSs
- What evidence would resolve it: Experiments testing collaborative approaches with various CRS architectures including persuasive recommendation generators

### Open Question 3
- Question: How does effectiveness vary across different product categories and domains beyond the five tested?
- Basis in paper: The paper analyzes five categories but acknowledges potential for category-specific effectiveness variations
- Why unresolved: Only tests across five specific categories
- What evidence would resolve it: Experiments applying collaborative approaches across wider range of product categories and domains

## Limitations
- Computational costs of collaboration methods and scalability with larger product catalogs not addressed
- Evaluation focuses primarily on quantitative metrics without extensive qualitative analysis of dialogue quality
- Study only examines two specific CRS architectures and two LLMs, limiting generalizability

## Confidence
- **High**: LLM semantic understanding enhancing CRS dialogue understanding is well-supported by experimental results showing CLLM-BCRS outperforming baseline CRS methods
- **Medium**: CRS product embeddings meaningfully improving LLM recommendations is supported by performance metrics but lacks detailed analysis of valuable information
- **Medium**: Complementary strengths between LLM and CRS is reasonable given task division but would benefit from more explicit evidence of minimal functional overlap

## Next Checks
1. Conduct ablation studies to quantify individual contributions of LLM semantic understanding versus CRS domain knowledge in CLLM-BCRS method
2. Test collaboration methods with different CRS architectures and larger, more diverse E-commerce datasets to assess scalability and generalizability
3. Perform user studies to evaluate quality and helpfulness of generated dialogues beyond automated metrics, focusing on naturalness and practical utility for pre-sales scenarios