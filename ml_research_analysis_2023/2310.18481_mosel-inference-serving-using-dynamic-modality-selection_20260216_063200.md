---
ver: rpa2
title: 'MOSEL: Inference Serving Using Dynamic Modality Selection'
arxiv_id: '2310.18481'
source_url: https://arxiv.org/abs/2310.18481
tags:
- accuracy
- modality
- latency
- inference
- jobs
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of serving predictions from
  large ML models under strict latency and cost constraints. It introduces MOSEL,
  an inference serving system that dynamically selects input modalities for multi-modal
  models to meet user-defined performance and accuracy requirements.
---

# MOSEL: Inference Serving Using Dynamic Modality Selection

## Quick Facts
- arXiv ID: 2310.18481
- Source URL: https://arxiv.org/abs/2310.18481
- Reference count: 40
- Key outcome: MOSEL improves system throughput by 3.6× with accuracy guarantee and reduces job completion times by 11× compared to modality-agnostic approaches

## Executive Summary
MOSEL addresses the challenge of serving predictions from large ML models under strict latency and cost constraints by introducing dynamic modality selection for multi-modal inference. The system employs an offline profiling stage to precompute latency and accuracy data for different modality combinations, followed by an online optimization stage that dynamically assigns modality selection strategies to jobs in a queue. This approach enables MOSEL to handle dynamic workloads while preventing deadline violations by adjusting modality choices for queued jobs. Evaluations on representative multi-modal models demonstrate significant improvements in system throughput and job completion times while maintaining accuracy guarantees.

## Method Summary
MOSEL uses a two-stage approach: offline profiling followed by online optimization. The offline stage measures latency and accuracy for all modality combinations across different batch sizes, then generates an optimal strategy matrix using nonlinear integer programming (GEKKO). The online stage monitors incoming jobs and system state, dynamically assigning modality strategies to meet accuracy requirements while minimizing latency. When new jobs risk missing deadlines, MOSEL can reassign strategies to earlier jobs, potentially sacrificing their accuracy to free resources for subsequent requests. The system is designed to handle multi-modal models with combinations of text, image, audio, and video inputs.

## Key Results
- Improves system throughput by 3.6× with accuracy guarantee
- Reduces job completion times by 11× compared to modality-agnostic approaches
- Maintains accuracy requirements while dynamically adjusting to workload changes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MOSEL improves throughput by dynamically selecting the most cost-effective modalities for each inference request
- Mechanism: The system precomputes latency and accuracy profiles for all modality combinations, then uses an offline-generated strategy matrix to select modalities that meet accuracy requirements while minimizing latency
- Core assumption: Different modalities contribute unequally to accuracy while having different computational costs, creating exploitable tradeoffs
- Evidence anchors:
  - [abstract]: "improves system throughput by 3.6× with an accuracy guarantee"
  - [section]: "some modalities (e.g., the audio modality in the Textless Vision-Language Transformer (TVLT) model [65]) contribute significantly to prediction accuracy while not being the major contributor to resource use"
  - [corpus]: Weak evidence - corpus papers focus on LLM serving and MoE architectures, not multimodal input selection

### Mechanism 2
- Claim: MOSEL prevents deadline violations by dynamically adjusting modality selection for queued jobs
- Mechanism: When new jobs risk missing deadlines, MOSEL reassigns modality strategies to earlier jobs, potentially sacrificing their accuracy to free resources and maintain system responsiveness
- Core assumption: System load is dynamic enough that early jobs can be adjusted without catastrophic accuracy loss to benefit later jobs
- Evidence anchors:
  - [abstract]: "reduces job completion times by 11× compared to modality-agnostic approaches"
  - [section]: "When job 2 selects a modality that yields the lowest accuracy for one of its requests, the leftover system resource could aid job 3"
  - [corpus]: Weak evidence - corpus focuses on MoE routing and batch optimization, not deadline-aware modality adjustment

### Mechanism 3
- Claim: MOSEL's two-stage approach (offline profiling + online optimization) enables efficient real-time modality selection
- Mechanism: Offline profiling creates a strategy matrix mapping job sizes and accuracy requirements to optimal modality combinations. Online optimization then quickly selects from precomputed strategies rather than solving optimization problems from scratch
- Core assumption: The relationship between job characteristics and optimal modality selection remains stable enough to precompute effectively
- Evidence anchors:
  - [section]: "Running the NILP entirely online may increase the risk of deadline violations due to the solver's overhead"
  - [section]: "We use GEKKO to generate the offline modality selection strategies"
  - [corpus]: No direct evidence - corpus papers don't discuss offline profiling for modality selection

## Foundational Learning

- Concept: Multi-modal learning fusion strategies (early vs late fusion)
  - Why needed here: Understanding how different modalities are combined is crucial for predicting how dropping modalities affects accuracy
  - Quick check question: What's the key difference between early and late fusion in multi-modal models?

- Concept: Integer Non-Linear Programming (INLP)
  - Why needed here: MOSEL uses INLP formulations for both offline strategy generation and online optimization
  - Quick check question: Why can't MOSEL use simpler linear programming for modality selection?

- Concept: Model quantization and its interaction with modality selection
  - Why needed here: The paper shows MOSEL can be combined with quantization techniques for additional performance gains
  - Quick check question: How might quantization affect the latency-accuracy tradeoffs that MOSEL exploits?

## Architecture Onboarding

- Component map: Profiler -> Offline optimizer -> Online monitor -> Online optimizer -> Worker
- Critical path: Job arrival → Monitor queues job → Worker executes with assigned modalities → Monitor updates system metrics
- Design tradeoffs:
  - Precomputation vs flexibility: More precomputed strategies = faster online decisions but less adaptability to changing patterns
  - Accuracy vs throughput: Aggressive modality dropping improves throughput but may violate accuracy requirements
  - Optimization overhead vs deadline guarantees: More sophisticated optimization = better outcomes but risks missing deadlines
- Failure signatures:
  - Increasing SLO violations despite MOSEL activation
  - Profiler showing unexpected latency spikes for certain modality combinations
  - Online optimizer failing to find feasible solutions for queued jobs
- First 3 experiments:
  1. Run profiler on a simple bimodal model (audio+video) with varying batch sizes, verify strategy matrix generation
  2. Simulate job queue with mixed accuracy requirements, verify MOSEL adjusts strategies to prevent deadline violations
  3. Introduce synthetic latency spikes in profiler data, verify MOSEL degrades gracefully without complete failure

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does MOSEL's modality selection perform on other multi-modal models beyond those evaluated (TVLT, ViLT, TBN, AVHuBERT, MMSA)?
- Basis in paper: [explicit] The paper mentions that MOSEL was evaluated on "representative multi-modal models" but doesn't specify if the results would generalize to other architectures or modalities
- Why unresolved: The evaluation only covers a specific subset of models with different fusion strategies, leaving uncertainty about performance on other model types or modalities
- What evidence would resolve it: Empirical testing of MOSEL on a broader range of multi-modal models with different architectures, fusion strategies, and modality combinations

### Open Question 2
- Question: What is the impact of model compression techniques (pruning, quantization) on the effectiveness of MOSEL's modality selection?
- Basis in paper: [inferred] The paper briefly mentions that MOSEL is compatible with quantization but doesn't provide detailed analysis of how compression affects modality selection benefits
- Why unresolved: While compatibility is mentioned, the interaction between model compression and modality selection effectiveness is not thoroughly explored
- What evidence would resolve it: Systematic evaluation of MOSEL with various combinations of compression techniques and different levels of compression

### Open Question 3
- Question: How does MOSEL's performance scale with the number of modalities and the complexity of modality combinations?
- Basis in paper: [explicit] The paper discusses that the search space grows exponentially with the number of modalities and mentions that for 20 requests with 3 modalities there are 231 possible strategies
- Why unresolved: While the complexity is acknowledged, the paper doesn't provide analysis of how performance degrades or scales with increasing modality count or combination complexity
- What evidence would resolve it: Empirical testing of MOSEL with varying numbers of modalities and complex modality combinations, measuring performance impact and scalability limits

## Limitations
- Performance claims rely heavily on the accuracy of offline profiling and stability of modality-accuracy relationships
- Limited discussion of how frequently profiling needs updating as model characteristics change
- Evaluation focuses on specific multi-modal models without extensive validation across different architectures or domains

## Confidence

High confidence in Mechanism 1 (throughput improvement via cost-effective modality selection) - The paper provides clear evidence that different modalities have unequal accuracy contributions and computational costs, creating exploitable tradeoffs. The 3.6× throughput improvement claim is well-supported by evaluation results.

Medium confidence in Mechanism 2 (deadline violation prevention through dynamic adjustment) - While the paper describes the mechanism clearly, the evaluation could benefit from more detailed analysis of edge cases where deadline adjustment fails or causes cascading accuracy degradation across multiple jobs.

Medium confidence in Mechanism 3 (two-stage approach efficiency) - The theoretical argument for offline profiling + online optimization is sound, but the paper doesn't quantify the overhead of strategy matrix generation or explore the impact of strategy staleness on system performance.

## Next Checks

1. **Stability Test**: Implement a continuous profiling system that tracks accuracy-latency relationships over time, then measure how often MOSEL's strategy matrix needs updating to maintain performance guarantees. This would validate the assumption that modality-accuracy relationships remain stable enough for effective precomputation.

2. **Extreme Load Test**: Design a workload scenario where accuracy requirements are uniformly high across all jobs (e.g., 95%+ accuracy for every request). Measure whether MOSEL can still prevent deadline violations without degrading into a modality-agnostic approach, testing the limits of the dynamic adjustment mechanism.

3. **Cross-Model Generalization**: Apply MOSEL to a multi-modal model with fundamentally different architecture (e.g., a MoE-based model or one using early fusion rather than late fusion). Measure whether the same profiling-based optimization approach works effectively, or if architecture-specific modifications are needed.