---
ver: rpa2
title: 'Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023'
arxiv_id: '2309.15554'
source_url: https://arxiv.org/abs/2309.15554
tags:
- translation
- pages
- simultaneous
- speech
- subtitling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper describes FBK\u2019s submission to the IWSLT 2023 simultaneous\
  \ translation and automatic subtitling tracks. The core idea is to use direct end-to-end\
  \ architectures without modifications for simultaneous translation and with fine-tuning\
  \ for subtitling."
---

# Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023

## Quick Facts
- arXiv ID: 2309.15554
- Source URL: https://arxiv.org/abs/2309.15554
- Reference count: 31
- Primary result: FBK's submission to IWSLT 2023 simultaneous translation and automatic subtitling tracks using direct end-to-end models, achieving up to 3.5 BLEU gain in SimulST and 3.7 SubER improvement in English-German subtitling.

## Executive Summary
This paper describes FBK's submission to the IWSLT 2023 simultaneous translation and automatic subtitling tracks. The core approach uses direct end-to-end speech translation models without modifications for simultaneous translation and with fine-tuning for subtitling. For simultaneous translation, an offline-trained Conformer model is applied with an adaptive policy (ALIGN ATT) to control latency. For subtitling, the model is adapted to produce well-formed subtitles and timestamps. Results show the system achieves lower latency and higher quality compared to previous winners, with significant improvements in both translation quality and subtitle segmentation.

## Method Summary
The method employs direct end-to-end speech translation models using Conformer architecture with CTC loss. For simultaneous translation, the offline-trained model is applied with ALIGN ATT adaptive policy to control latency based on cross-attention scores. For subtitling, the model is fine-tuned on subtitle-like translations to produce well-formed subtitles and timestamps. The system uses Fairseq-ST implementation with SpecAugment, label smoothing, and various data preprocessing techniques including punctuation restoration and segmentation using SHAS.

## Key Results
- Simultaneous translation: 3.5 BLEU gain compared to 2021-2022 top systems
- Automatic subtitling: 3.7 SubER improvement (en-de) and 1.7 SubER improvement (en-es) over existing direct system solutions
- Lower computational-aware latency achieved through ALIGN ATT policy
- Better subtitle segmentation quality with standard encoder-decoder architecture vs Triangle architecture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Direct end-to-end speech translation models can be used for simultaneous translation without re-training, leveraging adaptive policies to control latency.
- Mechanism: The offline-trained model generates partial hypotheses incrementally while processing input audio, and the policy (e.g., ALIGN ATT) decides when to emit translated words based on attention alignments between source and target tokens.
- Core assumption: The cross-attention scores between encoder and decoder reliably indicate when sufficient source context has been processed for translating each target token.
- Evidence anchors:
  - [abstract] "Our English-German SimulST system shows a reduced computational-aware latency compared to the one achieved by the top-ranked systems in the 2021 and 2022 rounds of the task, with gains of up to 3.5 BLEU."
  - [section] "Since our objective is to avoid any modifications to the offline-trained model, we pointed our attention to the latter, more conservative category [of adaptive policies]."
  - [corpus] Weak evidence - no direct mention of adaptive policy success in neighbor papers, but related works on SimulST exist.
- Break condition: If attention alignments do not correlate with translation quality or latency requirements, the policy will fail to balance quality and speed effectively.

### Mechanism 2
- Claim: Fine-tuning the direct ST model on subtitle-like translations improves automatic subtitling performance.
- Mechanism: The model learns to produce well-formed subtitles and timestamps by adapting to the constraints of subtitle segmentation and synchronization with audiovisual content.
- Core assumption: The direct ST architecture can be adapted to handle subtitle-specific constraints (e.g., character limits, reading speed) without losing translation quality.
- Evidence anchors:
  - [abstract] "Our automatic subtitling system outperforms the only existing solution based on a direct system by 3.7 and 1.7 SubER in English-German and English-Spanish respectively."
  - [section] "we adapted a direct ST model to produce well-formed subtitles and exploiting the same architecture to produce the timestamps needed for their synchronization with audiovisual contents."
  - [corpus] Weak evidence - neighbor papers focus on subtitling but do not detail direct model adaptation for subtitling tasks.
- Break condition: If the model cannot learn to balance subtitle constraints with translation quality, the fine-tuning will degrade performance.

### Mechanism 3
- Claim: Using the Triangle architecture with separate decoders for transcripts and translations improves subtitle segmentation quality.
- Mechanism: The model attends to both the source audio and the predicted transcript to generate translations, allowing better alignment between caption and subtitle content.
- Core assumption: Consistency between captions and subtitles is important for good subtitle segmentation, and attending to both improves this consistency.
- Evidence anchors:
  - [section] "Therefore, in our submission, based on the findings of the aforementioned work, we inspected the use of both a classic single encoder-single decoder architectures, as in (Papi et al., 2023a), and of the Triangle architecture for automatic subtitling."
  - [section] "the standard architectures perform better on all the considered metrics... there is a huge gap in the quality of the segmentation into subtitles, with the standard model improving by 3.3 and 4.7 Sigma the scores obtained by the Triangle respectively on en-de and en-es."
  - [corpus] No direct evidence in neighbor papers; this is a novel finding from the current work.
- Break condition: If the predicted captions do not provide useful information for subtitle generation, the Triangle architecture will not improve segmentation quality.

## Foundational Learning

- Concept: Cross-attention scores and their interpretation
  - Why needed here: The adaptive policies (e.g., ALIGN ATT) rely on cross-attention scores to decide when to emit translated words.
  - Quick check question: What do high cross-attention scores between a source frame and a target word indicate about the translation process?

- Concept: Subtitle constraints and evaluation metrics
  - Why needed here: The automatic subtitling task requires producing subtitles that conform to character limits and reading speed constraints, evaluated using metrics like SubER and Sigma.
  - Quick check question: How do character per line (CPL) and characters per second (CPS) constraints affect the subtitle generation process?

- Concept: Speech recognition and translation model architectures
  - Why needed here: Understanding the Conformer-based architecture and its components (encoder, decoder, attention mechanisms) is crucial for implementing and modifying the direct ST models.
  - Quick check question: What are the key differences between the Conformer architecture and traditional Transformer architectures, and how do they impact speech translation performance?

## Architecture Onboarding

- Component map: Audio input -> Feature extraction -> Encoder processing -> Cross-attention with decoder states -> Decoder generates partial hypotheses -> Adaptive policy decides word emission -> Fine-tuning on subtitle data

- Critical path:
  1. Audio input → Feature extraction → Encoder processing
  2. Encoder outputs → Cross-attention with decoder states
  3. Decoder generates partial hypotheses based on attention scores
  4. Adaptive policy decides when to emit translated words
  5. Fine-tuning on subtitle-like data for subtitling task

- Design tradeoffs:
  - Model size (encoder layers) vs. computational efficiency and latency
  - Fixed vs. adaptive policies for simultaneous translation
  - Standard vs. Triangle architectures for subtitling
  - CTC compression for faster inference vs. potential loss in translation quality

- Failure signatures:
  - High latency or poor translation quality in simultaneous translation
  - Subtitles not conforming to character limits or reading speed constraints
  - Poor alignment between source audio and generated subtitles
  - Inconsistent performance across different domains (e.g., TED talks vs. TV series)

- First 3 experiments:
  1. Implement and compare the three adaptive policies (LA, EDATT, ALIGN ATT) on a small SimulST dataset to assess their impact on latency and translation quality.
  2. Fine-tune the direct ST model on subtitle-like translations and evaluate its performance on a held-out subtitling dataset using SubER and Sigma metrics.
  3. Compare the standard encoder-decoder architecture with the Triangle architecture on the subtitling task to determine which performs better in terms of subtitle segmentation quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice between the EDATT and ALIGN ATT policies affect the quality-latency trade-off in simultaneous speech translation under different computational constraints?
- Basis in paper: [explicit] The paper compares EDATT and ALIGN ATT policies in terms of their ability to reach different latency ranges, both ideally and computationally aware, with EDATT limited to a narrower latency range compared to ALIGN ATT.
- Why unresolved: The paper does not provide a detailed analysis of how each policy performs under varying computational constraints or different latency requirements, leaving the optimal choice for specific scenarios unclear.
- What evidence would resolve it: Empirical results showing the performance of EDATT and ALIGN ATT under different computational constraints and latency requirements, including a detailed comparison of their quality-latency trade-offs in various scenarios.

### Open Question 2
- Question: Why does the Triangle architecture underperform compared to the standard encoder-decoder architecture in automatic subtitling tasks?
- Basis in paper: [explicit] The paper reports that the Triangle architecture performs worse than the standard encoder-decoder architecture in terms of subtitle segmentation quality and overall subtitle quality (SubER) for both English-German and English-Spanish language pairs.
- Why unresolved: The paper does not provide a detailed analysis of the reasons behind the Triangle architecture's underperformance, leaving the underlying causes unclear.
- What evidence would resolve it: A detailed analysis of the architectural differences between the Triangle and standard encoder-decoder models, including their impact on subtitle segmentation and overall quality, and potential modifications to improve the Triangle architecture's performance.

### Open Question 3
- Question: How does the inclusion of prosody information affect the quality of automatic subtitling in direct speech translation models?
- Basis in paper: [explicit] The paper mentions that cascaded architectures cannot access prosody information, which has been shown to be important for subtitle segmentation, and that direct ST models are better at subtitle segmentation compared to cascade ones.
- Why unresolved: The paper does not investigate the specific impact of prosody information on subtitle quality in direct ST models, leaving the potential benefits of incorporating prosody unclear.
- What evidence would resolve it: Experimental results comparing the performance of direct ST models with and without prosody information, including metrics for subtitle segmentation quality and overall subtitle quality, to quantify the impact of prosody on automatic subtitling.

## Limitations

- Limited experimental validation with minimal ablation studies and lack of detailed hyperparameter tuning analysis
- Generalizability concerns due to evaluation only on MuST-C v2 and MuST-Cinema datasets
- No cross-domain evaluation on diverse real-world datasets beyond speech translation benchmarks

## Confidence

**High Confidence**: Direct end-to-end models can be adapted for both simultaneous translation and subtitling tasks without major architectural modifications.

**Medium Confidence**: Specific performance improvements (3.5 BLEU gain, 3.7 SubER improvement) due to lack of detailed ablation studies and hyperparameter tuning information.

**Low Confidence**: Superiority of ALIGN ATT policy over other adaptive policies due to limited comparison scope and lack of statistical significance testing.

## Next Checks

1. **Adaptive Policy Parameter Sensitivity Analysis**: Conduct systematic grid search over ALIGN ATT policy parameters (α, λ, f) on held-out validation set to determine optimal configuration and assess robustness of latency-quality trade-off.

2. **Architecture Ablation Study for Subtitling**: Implement and evaluate additional subtitling architectures beyond standard encoder-decoder and Triangle models to determine whether performance differences are due to specific architectural choices or underlying model capacity.

3. **Cross-Domain Evaluation**: Test adapted models on diverse real-world datasets including live broadcast data, movies with different genres, and spontaneous speech from various domains to assess generalizability and identify potential failure modes.