---
ver: rpa2
title: Autoregressive Language Models For Estimating the Entropy of Epic EHR Audit
  Logs
arxiv_id: '2311.06401'
source_url: https://arxiv.org/abs/2311.06401
tags:
- audit
- logs
- language
- entropy
- workflow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of measuring the complexity of
  clinical workflow using Electronic Health Record (EHR) audit logs, which are granular
  event streams capturing clinician activities. Traditional methods for analyzing
  these logs are limited to time- or frequency-based aggregations, failing to capture
  the full complexity of EHR sessions.
---

# Autoregressive Language Models For Estimating the Entropy of Epic EHR Audit Logs

## Quick Facts
- arXiv ID: 2311.06401
- Source URL: https://arxiv.org/abs/2311.06401
- Authors: 
- Reference count: 12
- LLaMA models achieved average perplexity of ~3.17 on METRIC NAME feature

## Executive Summary
This study proposes using autoregressive transformer-based language models to estimate the entropy or disorderedness of clinical workflow sequences in Electronic Health Record (EHR) audit logs. Traditional methods for analyzing EHR logs are limited to time- or frequency-based aggregations, failing to capture the full complexity of EHR sessions. The researchers trained and evaluated several models, including GPT-2, RWKV, and LLaMA, on a dataset of audit logs from ICU clinicians. They demonstrate that cross-entropy calculated from these models can serve as a proxy for workflow complexity, with LLaMA models performing best at capturing the complexity of EHR interactions.

## Method Summary
The researchers collected EHR audit logs from ICU clinicians at Barnes-Jewish Hospital, containing METRIC NAME (action descriptions), ACCESS TIME (timestamps), and PAT ID (patient identifiers). They preprocessed the data by sorting by ACCESS INSTANT, converting ACCESS TIME to time-deltas, splitting into shifts and sessions, quantizing time-deltas into logarithmic bins, and tokenizing all fields. Multiple autoregressive transformer models (GPT-2, RWKV, LLaMA) were trained on the tokenized sequences to predict the next action. Models were evaluated using next-action prediction accuracy, ROUGE-1 scores, and per-feature perplexity, with cross-entropy used as a proxy for workflow complexity.

## Key Results
- LLaMA models achieved the lowest perplexity (~3.17) for METRIC NAME feature prediction
- Cross-entropy measurements correlated with expected workflow complexity patterns
- Quantized time-deltas and PAT ID fields enabled effective finite-vocabulary modeling
- Models successfully captured EHR interaction patterns beyond simple frequency analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Autoregressive language models can estimate workflow complexity by modeling the probability of next action sequences in EHR audit logs.
- Mechanism: The model learns P(x_i | x_i-k...x_i-1) and uses cross-entropy as a proxy for entropy of the workflow. Lower probability action sequences (more disorder) yield higher cross-entropy.
- Core assumption: EHR action sequences have a learnable probability distribution and the model can approximate it well enough for meaningful entropy estimation.
- Evidence anchors:
  - [abstract] "The results showed that LLaMA models performed best, with an average perplexity of around 3.17 for the METRIC NAME feature, indicating the models' ability to capture the complexity of EHR interactions."
  - [section] "Using raw EHR audit log data, cross-entropy calculated for each EHR-based action can be used as proxy of representing complexity of clinical workflow."
- Break condition: If the sequence distribution is too chaotic or non-stationary for the model to learn, cross-entropy will not meaningfully reflect workflow complexity.

### Mechanism 2
- Claim: Quantizing continuous fields (time deltas, PAT ID) enables finite vocabulary modeling while preserving sequence structure.
- Mechanism: Time deltas are binned logarithmically into 5 intervals, PAT ID is mapped to finite identifiers per shift, allowing the model to learn token-level probabilities instead of raw continuous values.
- Core assumption: The chosen quantization scheme preserves enough information to capture meaningful temporal and identity patterns without excessive loss.
- Evidence anchors:
  - [section] "Time-deltas are then quantized into a series of logarithmically-spaced bins of 5 intervals ranging from 0 to 240 seconds."
  - [section] "To ensure that the field vocab for the PAT ID is finite, we limit the patient count to 128 per shift."
- Break condition: Over-quantization collapses distinct events into the same token, losing granularity; under-quantization leads to an intractably large vocabulary.

### Mechanism 3
- Claim: Using cross-entropy as a relative measure of workflow complexity works because it monotonically decreases as the model improves its approximation of the true probability distribution.
- Mechanism: Cross-entropy is an upper bound for true entropy; as the language model learns the underlying distribution, the calculated cross-entropy better approximates the actual disorder in the action sequences.
- Core assumption: The language model's approximation quality correlates with its ability to capture workflow complexity, even if the absolute cross-entropy values are not interpretable on their own.
- Evidence anchors:
  - [section] "Cross-entropy has the useful property that it is an upper-bound for true entropy, and decreases monotonically as Ë†P improves."
  - [section] "We expect higher entropy states to have higher action sequence complexity, as action sequences that deviate from commonly-used sequences represent greater disorder within the workflow."
- Break condition: If the model overfits to training data or fails to generalize, the cross-entropy may reflect model bias rather than true workflow disorder.

## Foundational Learning

- Concept: Probability theory and information entropy
  - Why needed here: The core metric for workflow complexity is cross-entropy, which is derived from Shannon entropy and requires understanding of probabilistic modeling.
  - Quick check question: What does it mean if a sequence has high cross-entropy according to the language model?

- Concept: Transformer architecture and autoregressive modeling
  - Why needed here: The study evaluates multiple transformer-based architectures (GPT-2, RWKV, LLaMA) that learn to predict the next token in a sequence.
  - Quick check question: How does an autoregressive model differ from a bidirectional model in terms of training objective?

- Concept: Tokenization and quantization of structured data
  - Why needed here: EHR audit logs contain both categorical (METRIC NAME) and continuous (ACCESS TIME) fields that must be converted to discrete tokens for language modeling.
  - Quick check question: Why is logarithmic binning chosen for ACCESS TIME instead of uniform binning?

## Architecture Onboarding

- Component map:
  Data preprocessing -> Tokenization -> Model training -> Cross-entropy calculation -> Complexity analysis
  Key components: Audit log dataset, preprocessing pipeline (sorting, time-delta conversion, quantization), tokenizer, transformer models, evaluation metrics (accuracy, ROUGE, perplexity)

- Critical path:
  1. Load and sort audit logs by ACCESS INSTANT
  2. Convert ACCESS TIME to time-deltas and quantize
  3. Tokenize METRIC NAME, PAT ID, ACCESS TIME fields
  4. Split into sessions and chunks for model input
  5. Train transformer models on preprocessed sequences
  6. Evaluate using next-action accuracy, ROUGE scores, and perplexity
  7. Calculate cross-entropy for workflow complexity analysis

- Design tradeoffs:
  - Quantization granularity vs. model capacity: More bins improve fidelity but increase vocabulary size and training difficulty
  - Sequence length vs. context capture: Longer sequences allow better modeling but increase computational cost
  - Model size vs. performance: Larger models may overfit on limited data; smaller models may underfit complex patterns

- Failure signatures:
  - High training loss that plateaus early: Model cannot learn the sequence distribution
  - Very high perplexity on test data: Model overfits to training distribution
  - Cross-entropy not correlating with manual complexity assessment: Model captures irrelevant patterns or misses key workflow signals

- First 3 experiments:
  1. Compare quantized vs. raw continuous time deltas as input features to assess information loss
  2. Vary the number of quantization bins for ACCESS TIME and measure impact on perplexity
  3. Train models on subsets of clinician specialties to test generalizability and identify specialty-specific workflow patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can cross-entropy reliably quantify clinical workflow complexity across different clinician specialties and roles?
- Basis in paper: [explicit] The authors state their models were trained on ICU clinicians only and acknowledge limitations in generalizability to other specialties
- Why unresolved: The study only evaluated models on ICU clinicians, and the authors explicitly note that different specialties may have different workflows not captured in the training data
- What evidence would resolve it: Testing the models on audit logs from multiple clinical specialties and comparing cross-entropy values with expert assessments of workflow complexity

### Open Question 2
- Question: How do individual clinician differences in EHR interaction styles affect cross-entropy measurements?
- Basis in paper: [explicit] The authors mention they treat each session independently assuming similar workflows but acknowledge "potential individual differences in EHR interaction styles are not considered"
- Why unresolved: The study uses a population-level approach without examining intra-clinician variability or individual behavioral patterns
- What evidence would resolve it: Analyzing cross-entropy measurements at both individual and group levels, and correlating with known individual workflow patterns

### Open Question 3
- Question: What is the optimal quantization strategy for ACCESS TIME and PAT ID fields to maximize model performance?
- Basis in paper: [explicit] The authors note that "the number of bins is effectively limited by the imbalanced number of examples" and requires "significant manual tuning"
- Why unresolved: The study used a specific quantization approach but acknowledges this as a major limitation without exploring alternative strategies
- What evidence would resolve it: Systematic evaluation of different quantization schemes and their impact on model performance metrics

## Limitations
- Limited to single hospital system (Barnes-Jewish Hospital) with ICU clinicians only
- Cross-entropy relationship to clinical workflow complexity lacks empirical validation
- Significant information reduction through logarithmic binning of time deltas
- Population-level analysis ignores individual clinician workflow variations

## Confidence
- High confidence: The technical implementation of transformer training and evaluation methodology is sound and well-documented.
- Medium confidence: The relationship between cross-entropy and workflow complexity is theoretically justified but lacks empirical validation.
- Low confidence: The generalizability of findings to other clinical settings, specialties, or EHR systems is uncertain given the single-source dataset.

## Next Checks
1. **Clinical validation**: Compare cross-entropy estimates with manual complexity assessments from clinical experts across multiple institutions to establish ground-truth correlation.
2. **Temporal sensitivity analysis**: Evaluate model performance with different quantization schemes for ACCESS TIME (varying number of bins, alternative binning strategies) to quantify information loss impact.
3. **Generalizability test**: Train and evaluate models on EHR audit logs from different clinical specialties and hospital systems to assess robustness across diverse workflow patterns.