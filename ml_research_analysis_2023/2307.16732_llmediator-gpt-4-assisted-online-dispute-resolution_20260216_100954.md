---
ver: rpa2
title: 'LLMediator: GPT-4 Assisted Online Dispute Resolution'
arxiv_id: '2307.16732'
source_url: https://arxiv.org/abs/2307.16732
tags:
- message
- parties
- mediator
- messages
- system
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LLMediator is an experimental platform using GPT-4 to support online
  dispute resolution. It reformulates inflammatory user messages to be more neutral,
  suggests draft mediator interventions, and can autonomously intervene in negotiations.
---

# LLMediator: GPT-4 Assisted Online Dispute Resolution

## Quick Facts
- arXiv ID: 2307.16732
- Source URL: https://arxiv.org/abs/2307.16732
- Authors: 
- Reference count: 40
- Primary result: LLMediator is an experimental GPT-4-powered platform for online dispute resolution that reformulates inflammatory messages and suggests mediator interventions.

## Executive Summary
LLMediator is an experimental platform using GPT-4 to support online dispute resolution by reformulating inflammatory user messages, drafting mediator responses, and autonomously intervening in negotiations. The system aims to increase access to justice for low-intensity legal disputes by leveraging LLMs to guide discussions toward amicable settlements. Initial qualitative evaluations show promising results, with the model demonstrating strong emergent capabilities in mediation tasks. The approach is framed as augmented intelligence to reduce risks, with human review before messages are sent.

## Method Summary
The LLMediator platform integrates GPT-4 API to reformulate inflammatory messages into neutral tones, suggest draft mediator interventions, and autonomously respond to discussions when triggered. The system processes user messages, detects inflammatory content, and uses GPT-4 to generate neutral alternatives while preserving semantic content. Mediator suggestions are drafted based on conversation context and previous messages. Autonomous intervention is triggered by specific events like inactivity or inflammatory messages, though this feature requires human oversight due to potential risks.

## Key Results
- GPT-4 successfully reformulates inflammatory messages while preserving semantic content
- The model demonstrates strong contextual understanding and provides relevant, appropriate responses
- Autonomous intervention capability shows promise but requires careful study before deployment
- Initial qualitative evaluations demonstrate potential for LLMs to support ODR and facilitate settlements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can reformulate inflammatory messages into more neutral tones while preserving semantic content.
- Mechanism: The model detects inflammatory language and rewrites it with equivalent meaning but less confrontational wording.
- Core assumption: The LLM has learned from its training data patterns of how to rephrase emotional language neutrally.
- Evidence anchors: [abstract] "LLMediator aims to improve the efficacy of such processes by leveraging GPT-4 to reformulate user messages, draft mediator responses, and potentially autonomously engage in the discussions." [section] "The model seems to be capable of understanding a wide variety of contexts, and providing a relevant and appropriate responses, clearly taking into account the provided instructions and user messages."

### Mechanism 2
- Claim: GPT-4 can draft mediator interventions that are contextually relevant and actionable.
- Mechanism: The model reads previous messages, identifies points of contention, and generates a suggested intervention with guidance for resolution.
- Core assumption: The LLM has internalized knowledge of mediation techniques through its training data.
- Evidence anchors: [abstract] "We present and discuss several features of LLMediator and conduct initial qualitative evaluations, demonstrating the potential for LLMs to support ODR and facilitate amicable settlements." [section] "The responses we examined do this by dynamically adapting to the conversation between the parties, e.g., by calming the discussion, trying to establish key facts, or even suggesting possible compromises that the parties may consider."

### Mechanism 3
- Claim: GPT-4 can autonomously intervene in negotiations when triggered by specific events.
- Mechanism: The system monitors conversation state and sends AI-generated messages directly to parties.
- Core assumption: The LLM can generate appropriate interventions without human review in controlled scenarios.
- Evidence anchors: [abstract] "Finally, LLMediator offers an experimental feature to autonomously respond to the discussion by the parties." [section] "The LLMediator autonomously generated a message and sent it to the parties, suggesting a few possible options to encourage a settlement."

## Foundational Learning

- Concept: Understanding of large language model capabilities and limitations
  - Why needed here: To know what GPT-4 can and cannot do, and when human oversight is required
  - Quick check question: What are the key differences between GPT-3 and GPT-4 that make the latter suitable for mediation tasks?

- Concept: Basics of online dispute resolution (ODR) processes
  - Why needed here: To understand the context in which LLMediator operates and what mediators typically do
  - Quick check question: What are the main stages of an ODR process and how do they differ from traditional court proceedings?

- Concept: Prompt engineering techniques for LLMs
  - Why needed here: To craft effective prompts that elicit the desired behavior from GPT-4
  - Quick check question: How would you modify a prompt to get GPT-4 to focus on specific aspects of a dispute?

## Architecture Onboarding

- Component map: User interface -> GPT-4 API integration -> Message detection logic -> Reformulation module -> Intervention suggestion module -> Autonomous intervention trigger
- Critical path: User sends message → Detection logic identifies need for intervention → GPT-4 API called → Response processed and displayed to user
- Design tradeoffs: Accuracy vs. speed in message detection, cost of GPT-4 API calls vs. system capability, autonomy vs. human oversight
- Failure signatures: Inappropriate reformulations, irrelevant mediator suggestions, autonomous interventions that escalate conflict
- First 3 experiments:
  1. Test message reformulation on a set of inflammatory and neutral messages to measure accuracy
  2. Evaluate mediator intervention suggestions by having mediators rate their usefulness
  3. Run a simulation of autonomous intervention to identify potential failure modes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is GPT-4 at autonomously intervening in negotiations compared to human mediators in terms of settlement rates and user satisfaction?
- Basis in paper: [explicit] The paper discusses the experimental feature of autonomous LLM intervention but notes substantial risks and the need for careful study before deployment.
- Why unresolved: The authors explicitly state that considerable studies would have to be performed before deploying autonomous LLM mediators, and they only present this as an experimental feature rather than evaluating its effectiveness.
- What evidence would resolve it: Controlled studies comparing settlement rates, user satisfaction, and fairness outcomes between GPT-4 autonomous mediation, human mediation, and no mediation conditions across various dispute types.

### Open Question 2
- Question: What is the optimal balance between system autonomy and human oversight in LLM-assisted ODR to maximize settlement rates while minimizing risks of bias or inaccurate information?
- Basis in paper: [explicit] The paper emphasizes using LLMs as "augmented intelligence" with human review, discussing different approaches (F1, F2, F3) with varying levels of autonomy.
- Why unresolved: The authors present multiple implementation approaches but don't empirically test which balance of autonomy and oversight produces the best outcomes.
- What evidence would resolve it: Comparative studies testing different levels of LLM autonomy (fully human-reviewed, semi-autonomous with prompts, fully autonomous) across various dispute contexts measuring settlement rates, user trust, and error rates.

### Open Question 3
- Question: How does the use of LLM-assisted reformulation of inflammatory messages affect the quality and fairness of negotiated settlements compared to standard ODR platforms without this feature?
- Basis in paper: [explicit] The paper presents the reformulation feature as potentially helpful for maintaining constructive tone but notes it's an experimental approach requiring further study.
- Why unresolved: While the paper provides examples of reformulation, it doesn't present empirical data on whether this actually improves settlement outcomes or introduces new problems.
- What evidence would resolve it: Randomized controlled trials comparing settlement rates, agreement quality, and participant satisfaction between platforms with and without LLM reformulation features, with analysis of whether reformulations accurately preserve original intent.

## Limitations
- No systematic evaluation of message reformulation accuracy or mediator intervention quality
- Limited testing of autonomous intervention scenarios and potential failure modes
- No empirical validation of the system's impact on dispute resolution outcomes
- Potential bias in GPT-4 responses that could affect mediation fairness

## Confidence

- Medium: GPT-4's ability to reformulate inflammatory messages and draft mediator interventions
- Low: Autonomous intervention capability and overall system effectiveness in real disputes
- Medium: Potential to increase access to justice through ODR enhancement

## Next Checks
1. Conduct controlled experiments comparing GPT-4 interventions against human mediators on standardized dispute scenarios
2. Measure message reformulation accuracy by having parties rate whether neutral versions preserve original meaning
3. Implement A/B testing of autonomous vs. human-reviewed interventions to quantify risk vs. benefit tradeoffs