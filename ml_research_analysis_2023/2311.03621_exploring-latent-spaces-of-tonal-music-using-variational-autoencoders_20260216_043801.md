---
ver: rpa2
title: Exploring Latent Spaces of Tonal Music using Variational Autoencoders
arxiv_id: '2311.03621'
source_url: https://arxiv.org/abs/2311.03621
tags:
- pitch
- music
- encoding
- latent
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper compares different symbolic music encodings in their
  ability to train Variational Autoencoders (VAEs) that produce latent spaces capturing
  tonal relations. Six encodings are evaluated: Piano roll, MIDI, ABC, Tonnetz, and
  two Fourier-based methods (DFT of pitch and pitch class distributions).'
---

# Exploring Latent Spaces of Tonal Music using Variational Autoencoders

## Quick Facts
- arXiv ID: 2311.03621
- Source URL: https://arxiv.org/abs/2311.03621
- Reference count: 18
- Primary result: Pitch DFT VAEs capture tonal relationships best; ABC encodings achieve best reconstruction

## Executive Summary
This study systematically compares six symbolic music encodings for training Variational Autoencoders (VAEs) on Bach chorales, focusing on their ability to produce latent spaces that capture tonal relationships. The encodings evaluated include Piano roll, MIDI, ABC, Tonnetz, and two Fourier-based methods (DFT of pitch and pitch class distributions). The research demonstrates a clear trade-off between reconstruction fidelity and tonal understanding, with ABC encoding excelling at preserving original musical structures while Pitch DFT encoding best captures cognitive tonal distances between keys.

## Method Summary
The study implements a multi-encoding framework where 371 Bach chorales are processed through six different symbolic representations, each augmented by 12 key transpositions. A standardized VAE architecture (two LSTM layers with 1024 units, 256-dimensional latent space) is trained on each encoding using appropriate loss functions (categorical/binary cross-entropy or MSE). Model performance is evaluated through reconstruction metrics (accuracy, MSE, KL-divergence) and alignment with cognitive tonal distances using clustering metrics (Davis-Bouldin score, Dunn index) and circular correlation analysis.

## Key Results
- ABC encoding achieves the highest reconstruction accuracy across all tested encodings
- Pitch DFT latent spaces show strongest alignment with cognitive tonal distances between musical keys
- Longer musical pieces (over 114 slices) demonstrate better tonal space alignment than shorter pieces
- VAEs trained on Pitch DFT capture the tonal hierarchy and fuzzy cluster relationships between keys

## Why This Works (Mechanism)

### Mechanism 1
The Pitch DFT encoding captures tonal hierarchies better because the DFT's phase information encodes shared tones between keys. Fourier decomposition separates pitch distributions into magnitude (interval content) and phase (shared-tone alignment). When two keys share many tones, their phase vectors become similar, making them cluster together in latent space. Core assumption: Phase information in DFT correlates with cognitive tonal distances between keys. Break condition: If phase information does not correlate with tonal similarity.

### Mechanism 2
ABC notation achieves best reconstruction because it preserves vertical harmonic structure better than other encodings. ABC notation represents chords as text strings with explicit pitch and duration information, maintaining the original harmonic relationships that get lost in piano roll or Tonnetz representations. Core assumption: Vertical harmonic structure is critical for accurate reconstruction of tonal music. Break condition: If horizontal melodic structure proves more important than vertical harmony for reconstruction.

### Mechanism 3
The VAE with 256-dimensional latent space preserves sufficient information while reducing dimensionality for effective tonal analysis. The VAE learns to compress musical information into 256 dimensions, which is small enough to reveal tonal relationships but large enough to retain reconstruction capability. Core assumption: 256 dimensions provides an optimal balance between compression and information retention for tonal music analysis. Break condition: If different latent sizes perform significantly better for specific encodings or tasks.

## Foundational Learning

- **Discrete Fourier Transform (DFT) and its properties**: Understanding how DFT decomposes pitch distributions into magnitude and phase components that capture interval content and shared tones. Quick check: What musical information is encoded in the magnitude versus phase components of a DFT applied to pitch distributions?

- **Variational Autoencoders (VAEs) and latent space learning**: Understanding how VAEs learn compressed representations and the role of reconstruction loss and KL-divergence in shaping latent spaces. Quick check: How does the KL-divergence term in VAE loss function influence the structure of the learned latent space?

- **Tonal hierarchy and cognitive pitch space theory**: Understanding how musical keys and their relationships are perceived cognitively, including concepts like the circle of fifths and common-tone relationships. Quick check: Why do neighboring keys on the circle of fifths share more common tones than distant keys?

## Architecture Onboarding

- **Component map**: Encoding extraction → Augmentation → One-hot encoding → VAE training → Latent space extraction → Clustering analysis
- **Critical path**: Encoding → Augmentation → One-hot encoding → VAE training → Latent space extraction → Clustering analysis
- **Design tradeoffs**: Higher dimensional latent space could improve reconstruction but obscure tonal relationships; simpler encodings like ABC preserve structure but may lose some information; DFT encodings capture tonal relationships but are computationally expensive
- **Failure signatures**: Poor reconstruction accuracy indicates encoding-loss mismatch; scattered key clusters indicate failure to capture tonal relationships; high KL-divergence indicates poor latent space regularization
- **First 3 experiments**:
  1. Train VAE with ABC encoding on Bach chorales and verify >80% reconstruction accuracy
  2. Generate latent space for Pitch DFT encoding and check if major keys cluster together
  3. Compare circular correlation coefficients between Pitch DFT and MIDI-like encodings to confirm tonal alignment differences

## Open Questions the Paper Calls Out

- **Cross-musical-system validation**: How do VAE latent spaces trained on modal or microtonal music compare to those trained on tonal music in terms of capturing pitch relationships and tonal hierarchies? The study focuses exclusively on tonal music and doesn't investigate other musical systems.

- **Encoding optimization trade-offs**: What is the optimal encoding for preserving musical structure versus capturing tonal relationships in generative music models? The paper identifies ABC as best for reconstruction and Pitch DFT as best for tonal alignment but doesn't explore hybrid approaches.

- **Piece length effects**: How does the length of musical pieces affect the quality of VAE latent spaces in capturing tonal relationships? The authors observe longer pieces show better tonal alignment but don't investigate underlying reasons for this phenomenon.

## Limitations

- Analysis confined to Bach chorales in Western tonal tradition, limiting generalizability to other musical styles
- Fixed 256-dimensional latent space may be sub-optimal for some representations
- Cognitive tonal distance alignment relies on circular correlation, which may not fully capture complex tonal relationships

## Confidence

- **High**: Reconstruction performance comparisons across encodings
- **Medium**: Tonal alignment claims due to indirect nature of circular correlation validation  
- **Medium-Low**: Generalization to other musical repertoires or encoding schemes not tested

## Next Checks

1. **Cross-genre validation**: Test the same encodings and VAE architecture on Baroque keyboard works, Romantic art songs, and non-Western tonal music to assess generalizability of the Pitch DFT and ABC findings.

2. **Latent dimensionality sweep**: Systematically vary latent space dimensions (128, 256, 512, 1024) for each encoding to identify optimal compression ratios that balance reconstruction accuracy with tonal space preservation.

3. **Alternative tonal metrics**: Validate tonal alignment findings using additional cognitive distance measures beyond circular correlation, including voice-leading distances and tonal tension models, to strengthen the evidence for Pitch DFT's superior tonal representation.