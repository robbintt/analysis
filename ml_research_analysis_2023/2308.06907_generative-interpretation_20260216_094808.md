---
ver: rpa2
title: Generative Interpretation
arxiv_id: '2308.06907'
source_url: https://arxiv.org/abs/2308.06907
tags:
- interpretation
- contract
- https
- parties
- available
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This article introduces generative interpretation, a method for
  using large language models (LLMs) to estimate contractual meaning. The authors
  demonstrate through case studies that LLMs can ascertain ordinary meaning, quantify
  ambiguity, fill gaps in agreements, and assess extrinsic evidence.
---

# Generative Interpretation

## Quick Facts
- arXiv ID: 2308.06907
- Source URL: https://arxiv.org/abs/2308.06907
- Reference count: 0
- One-line primary result: Generative interpretation uses LLMs to estimate contractual meaning more cheaply and accessibly than traditional methods

## Executive Summary
This article introduces generative interpretation, a method using large language models to estimate contractual meaning. The authors demonstrate through case studies that LLMs can ascertain ordinary meaning, quantify ambiguity, fill gaps in agreements, and assess extrinsic evidence. Unlike traditional methods relying on dictionaries and canons, generative interpretation offers a more accessible, transparent, and efficient approach. The authors argue this method can serve as a middle ground between textualism and contextualism, providing courts with a practical tool for predicting parties' intent while addressing concerns about access to justice and interpretation costs.

## Method Summary
The method uses LLMs to analyze contract text by transforming words into high-dimensional vectors and applying attention mechanisms to capture contextual usage patterns. The approach involves computing cosine distances between word embeddings and contextual clauses, running multiple prompts at different temperatures to generate probability distributions, and incorporating extrinsic evidence alongside contract text. The method is validated through case studies using actual contract texts from legal disputes, with results evaluated across multiple models and prompt variations.

## Key Results
- LLMs can ascertain ordinary meaning and quantify ambiguity in contracts more cheaply than traditional methods
- The method can fill gaps in agreements and assess extrinsic evidence like phone conversations and industry customs
- Generative interpretation has potential to shift legal interpretation from textualism to contextualism by making contextual evidence cheaper and more objective

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can predict contractual meaning more cheaply and accessibly than traditional methods like dictionaries and canons.
- Mechanism: By transforming words into high-dimensional vectors and using attention mechanisms, LLMs capture contextual usage patterns from vast training data to infer likely meaning.
- Core assumption: The training corpus reflects common usage patterns relevant to the contract context.
- Evidence anchors:
  - [abstract] "Unlike traditional methods relying on dictionaries and canons, generative interpretation offers a more accessible, transparent, and efficient approach."
  - [section] "Dictionaries, encyclopedias, or corpus linguistics can do that. What makes large language models powerful is the vastness of the data they incorporate; what makes them unique is that they wield an internal mechanism known as 'attention' which allows them to attend to context."
- Break condition: If the training data does not represent the relevant linguistic community or time period, predictions may be inaccurate.

### Mechanism 2
- Claim: LLMs can quantify ambiguity and fill gaps in contracts more objectively than human judges.
- Mechanism: By running multiple prompts at different temperatures, LLMs generate probability distributions over possible interpretations, revealing spectrum of likely meanings.
- Core assumption: Probability outputs from the model correlate with likelihood of parties' intended meaning.
- Evidence anchors:
  - [abstract] "The authors demonstrate through case studies that LLMs can ascertain ordinary meaning, quantify ambiguity, fill gaps in agreements..."
  - [section] "Generative interpretation does not answer the question of whether language is reasonably susceptible to a meaning, it instead helps us visualize a broad spectrum of meaning and quantify how likely a particular result is."
- Break condition: If the model's probability outputs are not calibrated to real-world likelihood, the quantification will mislead.

### Mechanism 3
- Claim: Generative interpretation can shift the default from textualism to contextualism by making contextual evidence cheaper and more objective.
- Mechanism: LLMs can incorporate and weigh extrinsic evidence (like phone conversations, industry customs) alongside contract text, producing more accurate predictions without the bias and cost of human testimony.
- Core assumption: Parties prefer courts to consider more evidence when it's cheap and unbiased.
- Evidence anchors:
  - [abstract] "Using LLMs permits courts to estimate what the parties intended cheaply and accurately, and as such generative interpretation unsettles the current interpretative stalemate."
  - [section] "Generative interpretation allows both predictability and constraint, while also offering better linguistic accuracy. And it corrals litigation costs."
- Break condition: If parties do not value accuracy over certainty when cost is low, the default shift may not occur.

## Foundational Learning

- Embedding vectors
  - Why needed here: To understand how LLMs represent and compare word meanings numerically.
  - Quick check question: How do embeddings differ from simple one-hot encodings of words?
- Attention mechanisms
  - Why needed here: To grasp how LLMs use context to adjust word meanings dynamically.
  - Quick check question: What role does the attention score play in determining a word's embedding?
- Temperature scaling
  - Why needed here: To understand how LLM outputs vary with randomness and how to interpret probability distributions.
  - Quick check question: How does increasing temperature affect the diversity of LLM responses?

## Architecture Onboarding

- Component map: Input: Contract text, extrinsic evidence, query prompt -> Processing: Embedding generation, attention-based context adjustment, probability prediction -> Output: Ranked interpretations with confidence scores -> Evaluation: Cross-validation across models and prompts
- Critical path: Query → Prompt engineering → Model inference → Result interpretation → Legal reasoning integration
- Design tradeoffs: Model accuracy vs. hallucination risk, context window size vs. processing time, temperature settings vs. result stability
- Failure signatures: Hallucinations (made-up facts), leading prompts (biased results), majoritarian bias (minority meanings suppressed)
- First 3 experiments:
  1. Replicate a simple case (e.g., Famiglio) with multiple models and prompts to validate basic functionality.
  2. Test ambiguity quantification by comparing probability distributions across different temperature settings.
  3. Evaluate extrinsic evidence weighting by adding hypothetical phone conversations or industry customs to a contract and observing changes in model outputs.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific criteria should judges use to determine when generative interpretation is appropriate versus traditional textualist or contextualist methods?
- Basis in paper: [explicit] The paper discusses when courts might prefer contextual evaluation of meaning and notes that parties could contract for specific interpretative methods
- Why unresolved: The paper suggests generative interpretation could become a majoritarian default but doesn't provide clear guidelines for when courts should use it versus other methods
- What evidence would resolve it: Empirical studies comparing outcomes and costs of generative interpretation versus traditional methods across different types of contracts and contexts

### Open Question 2
- Question: How can courts ensure that generative interpretation does not systematically disadvantage minority linguistic communities or non-majoritarian interpretations?
- Basis in paper: [explicit] The paper discusses how majoritarian interpretations may suppress important perspectives and suggests querying models about distinct communities' linguistic conventions
- Why unresolved: While the paper identifies this concern, it doesn't provide concrete solutions for how courts would implement this in practice
- What evidence would resolve it: Comparative studies of generative interpretation outputs across different demographic groups and proposed mechanisms for incorporating diverse linguistic perspectives

### Open Question 3
- Question: What are the long-term effects of widespread generative interpretation adoption on contract drafting practices and the role of formal contracts?
- Basis in paper: [explicit] The conclusion suggests generative AI might make formal contracts obsolete if terms are determinable from parties' goals
- Why unresolved: The paper presents this as a possibility but doesn't explore how parties might actually respond to this technology over time
- What evidence would resolve it: Longitudinal studies of contracting practices before and after generative interpretation adoption, and experiments testing whether parties would rely more on goal-setting versus formal contracts

## Limitations
- The correlation between LLM probability outputs and actual parties' intended meaning has not been empirically validated through controlled studies with real contracting parties
- The method's performance across different legal domains and contract types remains untested, particularly for specialized technical or cross-border agreements
- Potential bias in training data - such as underrepresentation of certain dialects, cultures, or legal traditions - could systematically skew interpretation results

## Confidence
- High Confidence: The technical feasibility of using embeddings and attention mechanisms to capture contextual meaning, and the general cost advantages of LLM-based approaches over traditional methods
- Medium Confidence: The claim that generative interpretation can quantify ambiguity through probability distributions, as this requires calibration studies not yet reported
- Low Confidence: The assertion that parties would universally prefer contextualism when contextual evidence becomes cheap and objective, as this involves complex behavioral predictions about legal preferences

## Next Checks
1. Conduct a calibration study where actual contracting parties interpret sample contracts, then compare their choices to LLM-generated probability distributions to assess correlation
2. Apply generative interpretation to contracts from at least three distinct legal domains (e.g., commercial, employment, IP licensing) to identify performance variations and domain-specific limitations
3. Analyze the training data composition for over/under-representation of specific demographic groups, industries, or legal traditions, and test whether this correlates with systematic interpretation biases in the model outputs