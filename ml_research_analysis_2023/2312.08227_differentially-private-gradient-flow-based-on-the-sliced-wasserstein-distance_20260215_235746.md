---
ver: rpa2
title: Differentially Private Gradient Flow based on the Sliced Wasserstein Distance
arxiv_id: '2312.08227'
source_url: https://arxiv.org/abs/2312.08227
tags:
- flow
- private
- gradient
- differentially
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel method for differentially private
  generative modeling using gradient flows in the space of probability measures. The
  key idea is to discretize the gradient flow of a Gaussian-smoothed sliced Wasserstein
  distance and incorporate Gaussian noise to ensure differential privacy.
---

# Differentially Private Gradient Flow based on the Sliced Wasserstein Distance

## Quick Facts
- **arXiv ID**: 2312.08227
- **Source URL**: https://arxiv.org/abs/2312.08227
- **Reference count**: 40
- **Primary result**: Achieves FID scores of 71 and 117 for ε=10 and ε=5 respectively on MNIST, outperforming generator-based DPSWgen baseline (FID 149 and 199).

## Executive Summary
This paper introduces a novel method for differentially private generative modeling using gradient flows in the space of probability measures. The key idea is to discretize the gradient flow of a Gaussian-smoothed sliced Wasserstein distance and incorporate Gaussian noise to ensure differential privacy. The method leverages a particle scheme to simulate the discretized flow, where drift terms are computed using the differentially private sliced Wasserstein distance. Experiments on MNIST and FashionMNIST datasets demonstrate that the proposed method outperforms generator-based models trained with the same DP metric, achieving lower FID scores at low privacy budgets.

## Method Summary
The method discretizes a gradient flow of a Gaussian-smoothed sliced Wasserstein distance, incorporating Gaussian noise to ensure differential privacy. A particle scheme simulates the discretized flow, with drift terms computed using the differentially private sliced Wasserstein distance. The approach leverages an autoencoder for dimensionality reduction and uses a stochastic differential equation to evolve particles toward the target distribution while maintaining privacy guarantees.

## Key Results
- Achieves FID scores of 71 and 117 for ε=10 and ε=5 respectively on MNIST
- Outperforms DPSWgen baseline (FID 149 and 199 for same privacy budgets)
- Demonstrates higher-fidelity data generation at low privacy budgets compared to generator-based DP approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method uses a gradient flow of a Gaussian-smoothed sliced Wasserstein distance to ensure differential privacy.
- Mechanism: The flow evolves a distribution of particles according to a stochastic differential equation (SDE) with a drift term derived from the private sliced Wasserstein distance. The Gaussian smoothing in the distance computation acts as a Gaussian mechanism, providing differential privacy.
- Core assumption: The smoothing parameter σ is large enough to satisfy the privacy budget constraints while maintaining sufficient fidelity in the generated samples.

### Mechanism 2
- Claim: The particle scheme approximates the continuous-time gradient flow, enabling scalable computation.
- Mechanism: A finite number of particles evolve according to the discretized SDE, with the drift term estimated using Monte Carlo integration over random projections. The empirical distribution of particles approximates the target distribution.
- Core assumption: The number of particles N is sufficiently large to ensure the empirical distribution closely approximates the true distribution, and the number of projections Nθ is large enough for accurate estimation of the drift term.

### Mechanism 3
- Claim: The method provides a rigorous differential privacy guarantee by carefully tracking the privacy budget across iterations.
- Mechanism: The Gaussian mechanism is applied to the projection of the data onto random directions, with the sensitivity bounded using results from Rakotomamonjy & Ralaivola (2021). The privacy budget is tracked using the Gaussian moments accountant method.
- Core assumption: The sensitivity bound from Lemma 1 holds with high probability, and the moments accountant accurately tracks the cumulative privacy loss.

## Foundational Learning

- **Differential privacy**: Ensures privacy of training data while generating synthetic samples. Quick check: What is the difference between ε-DP and (ε, δ)-DP, and when would you use each?
- **Optimal transport and Wasserstein distance**: The method uses sliced Wasserstein distance as a metric for comparing probability distributions. Quick check: How does sliced Wasserstein distance differ from standard Wasserstein distance, and what are the computational advantages?
- **Gradient flows in probability measures**: Defines the gradient flow of the private sliced Wasserstein distance to evolve particle distributions. Quick check: What is the relationship between gradient flows and the Fokker-Planck equation?

## Architecture Onboarding

- **Component map**: Autoencoder -> Particle system -> Gaussian mechanism -> Privacy accountant
- **Critical path**: 
  1. Preprocess data using autoencoder
  2. Initialize particle system with samples from initial distribution
  3. For each iteration: compute drift terms using private sliced Wasserstein distance, update particle positions according to SDE, track privacy budget
  4. Generate samples from final particle distribution
- **Design tradeoffs**: 
  - Number of particles (N) vs. computational cost
  - Number of projections (Nθ) vs. privacy budget
  - Smoothing parameter (σ) vs. sample fidelity
- **Failure signatures**: 
  - Overly smoothed samples indicate σ is too large
  - Quick privacy budget exhaustion indicates Nθ is too large or σ is too small
  - Failure to capture target distribution indicates N is too small
- **First 3 experiments**:
  1. Reproduce toy problem from Figure 1 to visualize particle flow behavior with different σ values
  2. Evaluate method on MNIST with varying privacy budgets (ε = ∞, 10, 5) and compare FID scores to baseline methods
  3. Investigate impact of number of particles (N) and projections (Nθ) on sample quality and privacy budget consumption

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of the number of projections Nθ impact the trade-off between privacy guarantee and generative quality?
- Basis: The paper mentions privacy parameter ε degrades linearly with Nθ in the Gaussian mechanism
- Why unresolved: While providing theoretical bounds, the paper doesn't empirically investigate how different Nθ values affect sample quality and achieved privacy
- Evidence needed: Systematic experiments varying Nθ with reported FID scores and achieved ε values

### Open Question 2
- Question: Can the approach be extended to more complex data distributions beyond simple Gaussian mixtures?
- Basis: Toy problem uses 5 Gaussian mixtures, relatively simple compared to real-world data
- Why unresolved: Paper focuses on MNIST, FashionMNIST, and CelebA but doesn't explore handling complex multi-modal distributions
- Evidence needed: Experiments on diverse datasets with complex multi-modal distributions

### Open Question 3
- Question: How sensitive is the approach to the choice of regularization parameter λ?
- Basis: λ > 0 is mentioned as a constant in the continuity equation but not investigated
- Why unresolved: Fixed λ = 0.001 in toy problem without exploring impact on generated samples or convergence
- Evidence needed: Sensitivity analysis varying λ with corresponding FID scores and convergence behavior

## Limitations
- Limited to small-scale datasets (MNIST, FashionMNIST) without validation on more complex data distributions
- No comparison with non-private SWflow baselines to isolate DP cost from other architectural choices
- Relationship between particle count N, projection count Nθ, and sample quality not systematically explored

## Confidence

- **High confidence**: Theoretical framework connecting Gaussian smoothing to differential privacy via SDE drift term
- **Medium confidence**: Empirical results showing improved FID scores over DPSWgen baseline at low privacy budgets
- **Medium confidence**: Claim that method is "promising" for private generative modeling

## Next Checks

1. Reproduce main experimental results on MNIST with ε=10 and ε=5, comparing both DPSWflow-r and DPSWgen baselines under identical conditions
2. Implement non-private SWflow baseline to quantify performance gap attributable to differential privacy constraints
3. Systematically vary N and Nθ to analyze trade-off between particle/projection count, sample quality, and privacy budget consumption