---
ver: rpa2
title: 'PDPK: A Framework to Synthesise Process Data and Corresponding Procedural
  Knowledge for Manufacturing'
arxiv_id: '2308.08371'
source_url: https://arxiv.org/abs/2308.08371
tags:
- knowledge
- process
- data
- procedural
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents PDPK, a framework for generating synthetic
  datasets that combine process data with procedural knowledge representations for
  manufacturing domains. The framework simulates production and parametrization processes,
  creating knowledge graphs that encode causal relationships between parameters and
  quality characteristics.
---

# PDPK: A Framework to Synthesise Process Data and Corresponding Procedural Knowledge for Manufacturing

## Quick Facts
- arXiv ID: 2308.08371
- Source URL: https://arxiv.org/abs/2308.08371
- Reference count: 40
- Key outcome: Framework generates synthetic datasets combining process data with procedural knowledge graphs for manufacturing, showing BoxE and RDF2Vec embeddings perform consistently on link prediction tasks.

## Executive Summary
This paper introduces PDPK, a framework for generating synthetic datasets that combine process data with procedural knowledge representations for manufacturing domains. The framework simulates production and parametrization processes, creating knowledge graphs that encode causal relationships between parameters and quality characteristics. The synthetic data generation is highly configurable and modular, allowing adaptation to various manufacturing scenarios. The authors evaluate established knowledge graph embedding methods on the generated benchmark dataset, showing that BoxE and RDF2Vec achieve the most consistent results for link prediction and subgraph aggregation tasks.

## Method Summary
The framework simulates manufacturing processes by generating configurable causal dependencies between process parameters and quality characteristics, then iteratively adjusts parameters to optimize quality. This creates synthetic production and parametrization data, which is transformed into RDF knowledge graphs using representation patterns that encode indirections and ternary relations. The framework includes a data splitter for creating train/test splits while maintaining knowledge graph consistency. Multiple knowledge graph embedding methods (TransE, ComplEx, RotatE, BoxE, RDF2Vec) are evaluated on both synthetic and real FDM datasets using standard metrics like hits@k and AMRI for link prediction tasks.

## Key Results
- BoxE and RDF2Vec embedding methods achieve the most consistent results across both synthetic and real FDM datasets
- Synthetic datasets generated by PDPK exhibit characteristics similar to real-world procedural knowledge graphs despite being significantly smaller
- The framework successfully captures essential properties of procedural knowledge in manufacturing contexts, validating its approach to synthetic data generation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic datasets can approximate real-world procedural knowledge graph characteristics.
- Mechanism: The framework generates synthetic production processes with configurable causal dependencies between parameters and quality characteristics, then extracts procedural knowledge as RDF knowledge graphs. The knowledge graph generation uses representation patterns that encode indirections and ternary relations present in real procedural knowledge.
- Core assumption: Real procedural knowledge exhibits specific structural properties (e.g., ternary relations, asymmetry, literals) that can be modeled through configurable parameter spaces and underlying causal functions.
- Evidence anchors:
  - [abstract] "the framework simulates production and parametrization processes, creating knowledge graphs that encode causal relationships between parameters and quality characteristics"
  - [section] "Building on this, [10] presented the notion of modelling patterns, in the following called representations, for procedural knowledge graphs capable of representing different levels of detail"
- Break condition: If the synthetic generation cannot reproduce the indirections and asymmetric relations found in real procedural knowledge graphs, or if the knowledge graph properties (closeness centrality, degree distributions) diverge significantly from real-world examples.

### Mechanism 2
- Claim: Embedding methods trained on synthetic procedural knowledge generalize to real-world datasets.
- Mechanism: The framework creates synthetic datasets with procedural knowledge representations, then evaluates established knowledge graph embedding methods (TransE, ComplEx, RotatE, BoxE, RDF2Vec) on both synthetic and real FDM datasets. Consistent performance across datasets indicates the synthetic data captures essential procedural knowledge properties.
- Core assumption: Embedding methods that work well on factual knowledge can capture procedural knowledge semantics when applied to appropriately structured knowledge graphs.
- Evidence anchors:
  - [abstract] "The authors evaluate established knowledge graph embedding methods on the generated benchmark dataset, showing that BoxE and RDF2Vec achieve the most consistent results"
  - [section] "To evaluate the link prediction performance, we rely on established evaluation metrics, i.e. hits@k and adjusted (arithmetic) mean rank index(AMRI)"
- Break condition: If embedding performance on synthetic data does not correlate with performance on real-world datasets, indicating the synthetic data fails to capture essential procedural knowledge characteristics.

### Mechanism 3
- Claim: Configurable framework parameters enable adaptation to different manufacturing scenarios.
- Mechanism: The framework exposes parameters for the number of process parameters, quality characteristics, causal dependency percentages, and exploration vs exploitation behavior. These allow generation of datasets matching specific manufacturing contexts.
- Core assumption: Manufacturing processes across different domains share common structural properties that can be parameterized, allowing a single framework to generate diverse yet realistic datasets.
- Evidence anchors:
  - [abstract] "The synthetic data generation is highly configurable and modular, allowing adaptation to various manufacturing scenarios"
  - [section] "To arrive at benchmark data, however, we propose a parametrization that is inspired by observations of manufacturing processes in both FDM as well as plastic extrusion"
- Break condition: If the framework cannot generate datasets matching the characteristics of a new manufacturing domain despite parameter adjustments, indicating the model assumptions don't capture that domain's specific knowledge structure.

## Foundational Learning

- Concept: Resource Description Framework (RDF) and knowledge graph representations
  - Why needed here: The framework generates procedural knowledge as RDF-compliant knowledge graphs, and the evaluation relies on understanding these representations
  - Quick check question: What are the key components of an RDF triple and how do they differ from standard graph edges?

- Concept: Knowledge graph embedding methods (TransE, ComplEx, RotatE, BoxE, RDF2Vec)
  - Why needed here: The evaluation compares multiple embedding methods on the generated datasets to establish baseline performance
  - Quick check question: How do translational embeddings (TransE) differ from complex embeddings (ComplEx) in their approach to modeling relations?

- Concept: Link prediction evaluation metrics (hits@k, AMRI)
  - Why needed here: The paper evaluates embedding methods using these standard metrics to assess their ability to predict missing triples
  - Quick check question: What does an AMRI score of 0 indicate about an embedding method's performance compared to random guessing?

## Architecture Onboarding

- Component map:
  - Production Process Generator: Simulates manufacturing with configurable causal dependencies
  - Parametrization Process Generator: Models iterative parameter adjustment to optimize quality
  - Knowledge Graph Generator: Extracts procedural knowledge from simulated processes using representation patterns
  - Data Splitter: Creates train/test splits while maintaining knowledge graph consistency
  - Configuration Module: Controls all generation parameters and random seeds

- Critical path: Parameter configuration → Production process simulation → Parametrization process simulation → Knowledge graph generation → Train/test split → Evaluation

- Design tradeoffs: The framework prioritizes configurability and modularity over simulation accuracy, sacrificing detailed physical modeling for broader applicability across manufacturing domains.

- Failure signatures: Inconsistent knowledge graph properties across runs (indicates random seed issues), embedding performance significantly worse than random (indicates generation problems), train/test split leakage (indicates improper data separation).

- First 3 experiments:
  1. Generate a minimal dataset with 2 parameters and 2 quality characteristics, verify knowledge graph creation and basic embedding evaluation
  2. Adjust the (P×Q)c parameter to 50% and observe changes in knowledge graph density and embedding performance
  3. Compare embedding results between the default configuration and a configuration with only exploitative behavior in parametrization processes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the inclusion of mixed representations and additional factual knowledge in knowledge graphs affect the performance of embedding methods compared to graphs containing only one representation?
- Basis in paper: [explicit] The authors suggest investigating knowledge graphs containing mixed representations and additional factual knowledge as a future research direction.
- Why unresolved: This has not been empirically tested in the current study, which focuses on single representation types.
- What evidence would resolve it: Empirical comparison of embedding method performance on knowledge graphs with mixed representations versus single representations, showing quantitative differences in metrics like link prediction accuracy.

### Open Question 2
- Question: Can PDPK be extended to simulate production processes with sufficient detail to allow models trained on synthetic data to be applied in real-world manufacturing scenarios?
- Basis in paper: [explicit] The authors propose investigating whether PDPK can simulate production processes to sufficient detail for real-world application as future work.
- Why unresolved: The current framework focuses on generating synthetic datasets but has not been validated for transferring learned models to actual manufacturing environments.
- What evidence would resolve it: Demonstration of successful model deployment and performance on real manufacturing data after training on PDPK-generated synthetic data, with quantitative comparisons to baseline approaches.

### Open Question 3
- Question: How would the introduction of uncertainty into the knowledge graphs affect the requirements for embedding methods and their performance?
- Basis in paper: [explicit] The authors suggest extending the dataset to include uncertainty and evaluating specific embedding methods designed for uncertain knowledge graphs as future work.
- Why unresolved: The current evaluation uses deterministic knowledge graphs, and the impact of uncertainty on embedding method performance has not been studied.
- What evidence would resolve it: Comparative analysis of embedding method performance on uncertain versus certain knowledge graphs, including metrics for handling uncertainty and maintaining accuracy.

## Limitations

- The framework's assumptions about causal dependencies and parameter interactions may not capture all nuances of actual industrial processes
- The small size of the real FDM dataset limits generalizability claims when comparing synthetic and real data performance
- The framework prioritizes configurability over simulation accuracy, potentially missing domain-specific manufacturing process details

## Confidence

- **High Confidence**: The framework successfully generates synthetic procedural knowledge graphs with configurable characteristics, and the knowledge graph embedding evaluation methodology is sound and reproducible.
- **Medium Confidence**: The comparison between synthetic and real FDM datasets demonstrates reasonable performance correlation, though the small size of the real dataset limits generalizability claims.
- **Low Confidence**: The framework's ability to capture all essential characteristics of real-world procedural knowledge across diverse manufacturing domains, particularly for processes with complex, non-linear parameter relationships.

## Next Checks

1. **Cross-Domain Validation**: Apply the framework to generate datasets for a different manufacturing domain (e.g., semiconductor manufacturing) and evaluate embedding performance compared to domain experts' expectations.

2. **Parameter Sensitivity Analysis**: Systematically vary key configuration parameters (P×Q percentages, exploration vs exploitation ratios) to identify which parameters most significantly impact embedding performance and knowledge graph characteristics.

3. **Embedding Method Comparison**: Test additional domain-specific embedding methods designed for temporal or sequential data to determine if they outperform general knowledge graph embeddings on procedural knowledge tasks.