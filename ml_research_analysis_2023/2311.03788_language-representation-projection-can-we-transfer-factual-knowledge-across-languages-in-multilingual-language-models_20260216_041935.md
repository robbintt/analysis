---
ver: rpa2
title: 'Language Representation Projection: Can We Transfer Factual Knowledge across
  Languages in Multilingual Language Models?'
arxiv_id: '2311.03788'
source_url: https://arxiv.org/abs/2311.03788
tags:
- language
- knowledge
- factual
- languages
- lrp2
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the challenge of multilingual factual knowledge
  transfer in pretrained language models, where a significant performance gap exists
  between high-resource and low-resource languages. The authors propose Language Representation
  Projection (LRP2), a parameter-free framework that explicitly transfers factual
  knowledge from English to non-English languages by aligning their representation
  spaces.
---

# Language Representation Projection: Can We Transfer Factual Knowledge across Languages in Multilingual Language Models?

## Quick Facts
- arXiv ID: 2311.03788
- Source URL: https://arxiv.org/abs/2311.03788
- Reference count: 21
- This paper proposes a parameter-free framework called Language Representation Projection (LRP2) that improves multilingual factual knowledge transfer in pretrained language models.

## Executive Summary
This paper addresses the challenge of multilingual factual knowledge transfer in pretrained language models, where high-resource languages like English significantly outperform low-resource languages. The authors propose Language Representation Projection (LRP2), a parameter-free framework that explicitly transfers factual knowledge from English to non-English languages by aligning their representation spaces. LRP2 uses two modules - LIRP (converts non-English representations to English-like) and LSRP (reverts English-like back to non-English) - to enable non-English languages to access and retrieve factual knowledge encoded in English representations. Experiments on mLAMA demonstrate significant improvements in factual knowledge retrieval accuracy across diverse non-English languages.

## Method Summary
LRP2 is a parameter-free framework that improves cross-lingual factual knowledge transfer by projecting non-English representations into English-like spaces and back. The method uses two modules: LIRP (Language-Independent Representation Projection) converts non-English representations to English-like equivalents by subtracting the language vector, while LSRP (Language-Specific Representation Projection) reverts English-like representations back to the corresponding non-English language by adding the language vector. The optimal insertion points for these modules vary across languages and are systematically evaluated. The approach leverages the hypothesis that aligning representation spaces across languages enables non-English languages to access English-encoded factual knowledge through the English-like representations.

## Key Results
- LRP2 significantly improves factual knowledge retrieval accuracy across diverse non-English languages on mLAMA
- The framework enhances alignment of representation spaces between English and non-English languages
- LRP2 increases overlap of knowledge neurons across languages, enabling non-English languages to acquire transferred factual knowledge
- Different languages require varying optimal layer configurations for LIRP and LSRP insertion

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual alignment of representation spaces enables factual knowledge transfer across languages.
- Mechanism: By projecting non-English representations into English-like representations (via LIRP) and then back into the corresponding non-English language (via LSRP), the model can access English-encoded knowledge through the English-like representations and output answers in the target language.
- Core assumption: The representation spaces of two languages can be transferred through a Euclidean distance mapping by subtracting and adding language vectors.
- Evidence anchors:
  - [abstract]: "LRP2 incorporates two parameter-free Language-Independent Representation Projection modules (LIRP) that converts non-English representations into English-like equivalents, and a Language-Specific Representation Projection (LSRP) that reverts English-like representations back into representations of the corresponding non-English language."
  - [section 3]: "By performing this projection, the representations of non-English language l are mapped into the English space and subsequently fed to the succeeding layers."
  - [corpus]: Weak evidence - corpus neighbors discuss cross-lingual transfer but don't directly address representation space alignment.

### Mechanism 2
- Claim: LRP2 enhances the overlap of knowledge neurons across languages.
- Mechanism: By aligning representation spaces through LIRP and LSRP, non-English languages can activate knowledge neurons similar to those activated in English, thereby acquiring transferred factual knowledge.
- Core assumption: Knowledge neurons expressing specific factual knowledge exist in multilingual pretrained Transformers and can be shared across languages.
- Evidence anchors:
  - [section 5.2]: "LRP2 increases the overlap rate of knowledge neurons between Chinese and English. This improvement indicates that LRP2 facilitates the alignment of English and non-English representation spaces and enhances the activation of knowledge neurons in non-English languages, making them more similar to those in English."
  - [corpus]: Moderate evidence - corpus includes papers on tracing multilingual factual knowledge acquisition and representation sharing in LLMs.

### Mechanism 3
- Claim: Different non-English languages require varying degrees of representation space alignment for optimal knowledge transfer.
- Mechanism: The effectiveness of LRP2 depends on the specific layer configurations for inserting LIRP and LSRP modules, which vary across languages based on their representation space characteristics.
- Core assumption: The optimal layer settings for LIRP and LSRP insertion differ across languages due to variations in representation space learning.
- Evidence anchors:
  - [section 4.2]: "We observe that different languages exhibit distinct requirements for representation space alignment to achieve optimal transferability."
  - [appendix B.2]: "Different Languages Necessitate Varying Optimal Layer Settings - Figure 3 presents the change of cross-lingual transferability for five languages as the number of layers between LIRP and LSRP varies."
  - [corpus]: Weak evidence - corpus neighbors don't specifically address optimal layer configurations for different languages.

## Foundational Learning

- Concept: Representation space alignment in multilingual models
  - Why needed here: LRP2 relies on aligning representation spaces across languages to enable knowledge transfer. Understanding how multilingual models represent different languages is crucial for implementing LIRP and LSRP.
  - Quick check question: How does subtracting a language vector from representations help in aligning representation spaces across languages?

- Concept: Knowledge neurons in pretrained Transformers
  - Why needed here: LRP2's effectiveness is partly explained by enhanced overlap of knowledge neurons across languages. Understanding knowledge neurons is key to analyzing LRP2's working mechanism.
  - Quick check question: How are knowledge neurons identified in multilingual pretrained models, and what does their overlap rate signify?

- Concept: Cross-lingual transfer learning techniques
  - Why needed here: LRP2 is a form of cross-lingual transfer, and understanding existing techniques helps in appreciating its novelty and potential limitations.
  - Quick check question: What are the main categories of cross-lingual transfer learning approaches, and how does LRP2 differ from them?

## Architecture Onboarding

- Component map: Input non-English query -> LIRP projects to English-like space -> English-like representations access English knowledge -> LSRP projects back to non-English -> Output answer in non-English language

- Critical path:
  1. Input non-English query
  2. LIRP projects representations to English-like space
  3. English-like representations access English-encoded knowledge
  4. LSRP projects back to non-English language
  5. Output answer in non-English language

- Design tradeoffs:
  - Parameter-free approach vs. learned projection matrices
  - Simplicity of Euclidean distance mapping vs. more complex semantic transfer methods
  - Generalizability across languages vs. language-specific optimizations

- Failure signatures:
  - Decreased performance when LIRP and LSRP are inserted at certain layers
  - Inconsistent improvements across different languages or factual relations
  - Over-alignment of representation spaces leading to loss of language-specific information

- First 3 experiments:
  1. Implement LIRP and LSRP as additional layers in a multilingual model and test on a small multilingual factual knowledge probing dataset
  2. Systematically vary the insertion layers for LIRP and LSRP to find optimal configurations for different languages
  3. Analyze the overlap of knowledge neurons before and after applying LRP2 to verify the alignment effect

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific architectural modifications beyond simple projection layers could further enhance cross-lingual knowledge transfer in multilingual models?
- Basis in paper: [inferred] The paper shows that simple parameter-free projection modules (LRP2) improve knowledge transfer, but notes these are coarse mappings that may lose semantic information.
- Why unresolved: The authors acknowledge their approach is relatively simple and hypothesize that more sophisticated alignment methods could yield better results, but do not explore alternatives.
- What evidence would resolve it: Comparative experiments testing different architectural approaches (e.g., attention-based alignment, adversarial training, or neural machine translation-inspired methods) against LRP2 on the same benchmarks.

### Open Question 2
- Question: How does the effectiveness of LRP2 scale with model size and architecture (e.g., comparing BERT vs. GPT-style models vs. encoder-decoder models)?
- Basis in paper: [explicit] The authors note they were limited to small models due to compute constraints and plan to investigate LRP2 on larger language models when more compute resources are available.
- Why unresolved: The paper only tests LRP2 on mBERT and BLOOM (small versions), leaving open questions about its effectiveness on larger or architecturally different models.
- What evidence would resolve it: Systematic experiments applying LRP2 to various model sizes and architectures (e.g., BERT-large, GPT-3, mT5) measuring knowledge transfer improvements across the same multilingual benchmarks.

### Open Question 3
- Question: What is the relationship between the degree of language similarity and the optimal layer configuration for LIRP/LSRP insertion?
- Basis in paper: [explicit] The paper observes that different languages require different optimal layer configurations and that some languages are highly sensitive to layer placement, but does not systematically analyze why.
- Why unresolved: While the paper identifies that optimal layer placement varies by language, it does not investigate whether this variation correlates with linguistic properties (e.g., typological similarity, script overlap, or phylogenetic distance from English).
- What evidence would resolve it: Correlation analysis between optimal layer configurations and linguistic distance metrics (e.g., syntactic similarity, vocabulary overlap, or phylogenetic relationships) across the tested languages.

## Limitations
- The effectiveness of LIRP and LSRP depends heavily on the choice of layer configurations, which may not generalize well across different model architectures.
- The assumption that Euclidean distance mapping can effectively align cross-lingual representation spaces lacks rigorous theoretical justification.
- The paper doesn't address potential information loss during the projection process, particularly for languages with significantly different grammatical structures from English.

## Confidence
- Medium confidence in representation space alignment mechanism based on empirical evidence but limited theoretical justification
- Medium confidence in knowledge neuron overlap findings supported by experimental results
- Low confidence in generalizability of optimal layer configurations across model architectures

## Next Checks
1. **Layer Configuration Robustness**: Systematically test LIRP/LSRP insertion points across different multilingual model architectures (e.g., XLM-R, mT5) to verify if optimal layer configurations transfer across models.

2. **Knowledge Quality Assessment**: Compare the factual accuracy and completeness of knowledge retrieved through LRP2 against native English knowledge and knowledge retrieved through other cross-lingual transfer methods.

3. **Information Preservation Analysis**: Quantify information loss during the LIRPâ†’LSRP projection cycle by measuring semantic similarity between original and projected representations across multiple languages.