---
ver: rpa2
title: Universal Detection of Backdoor Attacks via Density-based Clustering and Centroids
  Analysis
arxiv_id: '2301.04554'
source_url: https://arxiv.org/abs/2301.04554
tags:
- samples
- poisoned
- class
- cca-ud
- benign
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes a universal defence method against backdoor\
  \ attacks, called CCA-UD, which can detect the presence of poisoned data in the\
  \ training dataset regardless of the attack approach, the size and shape of the\
  \ triggering pattern, and the percentage of poisoned samples. CCA-UD works by clustering\
  \ the samples of each class in the training set using density-based clustering,\
  \ then applying a novel strategy to detect the presence of poisoned clusters based\
  \ on the misclassi\uFB01cation behaviour of the features of a representative example\
  \ of the analysed cluster."
---

# Universal Detection of Backdoor Attacks via Density-based Clustering and Centroids Analysis

## Quick Facts
- arXiv ID: 2301.04554
- Source URL: https://arxiv.org/abs/2301.04554
- Reference count: 40
- Universal defense method detects poisoned data regardless of attack approach, trigger shape, or poisoning percentage

## Executive Summary
This paper proposes CCA-UD, a universal defense method against backdoor attacks that can detect poisoned data in training datasets regardless of the attack approach, trigger shape, or poisoning percentage. The method uses density-based clustering (DBSCAN) to identify clusters of poisoned and benign samples, then applies a novel centroid analysis strategy to detect poisoned clusters based on misclassification behavior. Experimental results show CCA-UD outperforms state-of-the-art techniques across various classification tasks, network architectures, and attack types.

## Method Summary
CCA-UD works by clustering training samples using DBSCAN, then analyzing cluster centroids to detect poisoned data. For each cluster, the centroid deviation from the class centroid is computed and tested by adding it to features of benign samples from other classes. If this addition causes misclassification toward the cluster's class, the cluster is flagged as poisoned. The method is attack-agnostic, working against both clean-label and corrupted-label attacks, and robust to varying poisoning ratios.

## Key Results
- CCA-UD achieves high true positive rates (TPR) and low false positive rates (FPR) across multiple datasets and attack types
- The method outperforms state-of-the-art techniques in all tested scenarios
- CCA-UD demonstrates robustness to varying poisoning ratios and different trigger shapes
- Experimental results show effectiveness on MNIST, Fashion-MNIST, and GTSRB datasets with various attack methods

## Why This Works (Mechanism)

### Mechanism 1
CCA-UD detects poisoned clusters by computing cluster centroids and checking whether the centroid deviation vector induces misclassifications when added to features of benign samples from other classes. For a poisoned cluster, the centroid contains trigger features in addition to target class features. Subtracting the class centroid isolates trigger features, which when added to benign samples cause misclassification toward the target class.

### Mechanism 2
CCA-UD is attack-agnostic because it exploits the general property that backdoor triggers create a shortcut to the target class, regardless of label corruption. In clean-label attacks, poisoned samples contain triggers but correct labels. In corrupted-label attacks, samples have wrong labels but triggers are present. In both cases, centroid deviation contains trigger features that cause misclassification when added to benign samples.

### Mechanism 3
CCA-UD is robust to various poisoning ratios because DBSCAN can identify poisoned and benign samples regardless of cluster size imbalance. DBSCAN automatically determines cluster numbers based on density, grouping poisoned samples even when they are fewer than benign samples. This contrasts with K-means, which requires fixed cluster numbers and struggles with unbalanced sizes.

## Foundational Learning

### Concept: Density-based clustering (DBSCAN)
- Why needed here: DBSCAN automatically identifies clusters of poisoned and benign samples based on feature density without requiring fixed cluster numbers, crucial for handling varying poisoning ratios and unbalanced cluster sizes
- Quick check question: What are the two main parameters of DBSCAN, and how do they affect clustering?

### Concept: Feature space representation and dimensionality reduction
- Why needed here: CCA-UD works in the feature space where poisoned and benign samples may have different distributions. Dimensionality reduction via UMAP reduces computational complexity and avoids the curse of dimensionality
- Quick check question: Why is dimensionality reduction beneficial for clustering in high-dimensional feature spaces?

### Concept: Centroid analysis and deviation vectors
- Why needed here: The centroid represents average features of cluster members. Computing deviation from class centroid isolates trigger features, which when added to benign samples cause misclassification toward the target class
- Quick check question: How does the deviation vector βk_i help in detecting poisoned clusters?

## Architecture Onboarding

### Component map:
Trained model Fα -> Feature extraction fα_1(x) -> Dimensionality reduction UMAP -> DBSCAN clustering -> Outlier detection -> Centroid analysis -> Misclassification check -> Output Pi and Bi sets

### Critical path:
1. Feature extraction and dimensionality reduction
2. DBSCAN clustering and outlier detection
3. Centroid analysis and deviation vector computation
4. Misclassification check and cluster labeling

### Design tradeoffs:
- Choice of d' (reduced dimension): Lower d' reduces computational complexity but may lose important information
- Choice of DBSCAN parameters (minPts, ϵ): Affects clustering quality and sensitivity to noise
- Choice of threshold θ: Balances true positive and false positive rates

### Failure signatures:
- High false positive rate: Cluster centroids may not accurately represent average features of their members
- Low true positive rate: Trigger features may be distributed across multiple clusters or not prominent enough
- Sensitivity to hyperparameters: Performance may degrade if d', minPts, ϵ, or θ are not set appropriately

### First 3 experiments:
1. Verify feature extraction and dimensionality reduction: Check that feature representations are computed correctly and UMAP reduces dimension as expected
2. Test DBSCAN clustering: Verify that DBSCAN identifies correct number of clusters and separates poisoned and benign samples
3. Evaluate centroid analysis: Check that deviation vectors are computed correctly and induce misclassifications for poisoned clusters

## Open Questions the Paper Calls Out

### Open Question 1
How does CCA-UD performance scale with significantly larger and more complex datasets beyond MNIST, Fashion-MNIST, and GTSRB? The paper notes experiments were conducted on benchmark datasets but does not explore scalability to larger or more complex datasets with higher dimensionality, more classes, or complex feature distributions.

### Open Question 2
What is the impact of different trigger types (e.g., 3D patterns, audio triggers) on CCA-UD effectiveness? The paper evaluates CCA-UD against 2D image triggers but does not explore other trigger modalities or more complex patterns, despite claiming universality.

### Open Question 3
How does CCA-UD perform against backdoor attacks that target multiple classes simultaneously? While the paper suggests multiple triggers would cluster separately, there is no empirical validation of CCA-UD's effectiveness against multi-class backdoor attacks.

## Limitations

- Performance may degrade with subtle triggers that do not create distinct clusters in feature space
- Computational overhead of feature extraction and dimensionality reduction may limit scalability
- Sensitivity to hyperparameter choices (d', minPts, epsilon, θ) without clear guidance on optimal settings
- Limited evaluation to controlled benchmark settings without extensive real-world validation

## Confidence

**Medium Confidence**: Attack-agnostic nature and robustness to varying poisoning ratios - theoretically sound but requiring extensive empirical validation across diverse attack scenarios

**Medium Confidence**: Effectiveness of DBSCAN clustering in separating poisoned and benign samples - assumes poisoned samples form distinct clusters which may not always be true

**Low Confidence**: Generalizability to real-world scenarios with complex triggers, diverse datasets, and large-scale models - experiments focus on controlled benchmark settings

## Next Checks

1. **Parameter Sensitivity Analysis**: Systematically evaluate impact of hyperparameters (d', minPts, epsilon, θ) on detection performance across different datasets and attack types to identify optimal settings and robustness boundaries

2. **Real-world Trigger Evaluation**: Test CCA-UD on datasets with naturally occurring patterns resembling backdoor triggers (e.g., watermarks, logos) to assess false positive rates in practical scenarios

3. **Scalability Assessment**: Measure computational overhead of feature extraction and UMAP dimensionality reduction on large-scale datasets and complex models to determine practical applicability limits