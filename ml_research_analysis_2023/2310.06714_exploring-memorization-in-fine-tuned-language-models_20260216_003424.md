---
ver: rpa2
title: Exploring Memorization in Fine-tuned Language Models
arxiv_id: '2310.06714'
source_url: https://arxiv.org/abs/2310.06714
tags:
- memorization
- tasks
- fine-tuning
- attention
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper conducts a comprehensive analysis of memorization in
  fine-tuned language models across diverse tasks. It finds that fine-tuned models
  exhibit task-specific memorization disparities, with high-memorization tasks like
  summarization and dialogue showing uniform, sparse attention distributions, while
  low-memorization tasks like classification and QA have concentrated attention.
---

# Exploring Memorization in Fine-tuned Language Models

## Quick Facts
- arXiv ID: 2310.06714
- Source URL: https://arxiv.org/abs/2310.06714
- Authors: 
- Reference count: 12
- Memorization in fine-tuned language models varies significantly across tasks, with summarization showing highest memorization rates

## Executive Summary
This paper conducts a comprehensive analysis of memorization in fine-tuned language models across diverse tasks. The authors find that fine-tuned models exhibit task-specific memorization disparities, with high-memorization tasks like summarization and dialogue showing uniform, sparse attention distributions, while low-memorization tasks like classification and QA have concentrated attention. They introduce a Corrective Attention Dispersion metric to quantify attention dispersion, finding it correlates with memorization rates. The paper also demonstrates that multi-task fine-tuning can mitigate memorization in high-memorization tasks compared to single-task fine-tuning.

## Method Summary
The paper employs an automatic plagiarism detection pipeline to evaluate memorization in fine-tuned language models. It uses Elasticsearch for searching similar texts and PAN2014 plagiarism detection for identifying memorized cases. The authors fine-tune models on various tasks (summarization, dialogue, QA, translation, sentiment analysis) using T5-base architecture and specific datasets like Multi-News, HealthcareMagic, and IMDB. They analyze attention score distributions and calculate Corrective Attention Dispersion (CAD) scores to understand memorization patterns across tasks.

## Key Results
- Fine-tuned models show task-specific memorization disparities, with summarization and dialogue exhibiting highest memorization rates
- High-memorization tasks demonstrate uniform, sparse attention distributions while low-memorization tasks show concentrated attention
- Multi-task fine-tuning significantly reduces memorization in high-memorization tasks compared to single-task fine-tuning (29.6‰ vs 110.3‰)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Memorization during fine-tuning is task-dependent due to varying information density requirements
- Mechanism: Tasks requiring comprehensive understanding of input (like summarization) force models to encode more information, increasing memorization risk
- Core assumption: Different tasks require different amounts of input information for successful completion
- Evidence anchors:
  - [abstract] "memorization presents a strong disparity among different fine-tuning tasks"
  - [section 4.2] "the memorization behavior might be closely related to the information needed to fulfill certain language tasks"
  - [corpus] Weak - related papers focus on mitigation strategies but don't explain task disparity mechanism

### Mechanism 2
- Claim: Attention score distribution patterns correlate with memorization levels
- Mechanism: Dense attention distributions (uniform scores) indicate comprehensive information processing, while concentrated distributions suggest selective feature extraction
- Core assumption: Attention patterns reflect how much input information the model needs to process
- Evidence anchors:
  - [section 5.1] "high memorization tasks demonstrate uniform, sparse attention distributions"
  - [section 5.2] "we propose Corrective Attention Dispersion (CAD) to quantify the dispersion degree of the attention score"
  - [corpus] Weak - corpus papers don't discuss attention-memorization correlation

### Mechanism 3
- Claim: Multi-task fine-tuning reduces memorization by distributing learning across multiple objectives
- Mechanism: Learning multiple tasks prevents over-memorization of any single dataset by requiring the model to generalize across diverse objectives
- Core assumption: Exposure to diverse tasks forces models to extract more generalizable patterns rather than memorizing specific data
- Evidence anchors:
  - [section 6] "multi-task fine-tuning can alleviate memorization compared to single-task fine-tuning"
  - [section 6] "memorization ratio of the multi-task fine-tuned FLAN-T5 (29.6‰) is substantially lower than that of T5-base (110.3‰)"
  - [corpus] Moderate - related papers mention mitigation but don't explain the mechanism

## Foundational Learning

- Concept: Sparse coding theory
  - Why needed here: Provides mathematical framework for understanding how models encode information
  - Quick check question: If data Z comes from combinations of hidden features X, how does this relate to memorization?

- Concept: Transformer attention mechanisms
  - Why needed here: Central to understanding how models process and potentially memorize input information
  - Quick check question: What does uniform attention distribution across input tokens indicate about information processing?

- Concept: Memorization detection techniques
  - Why needed here: Enables quantitative measurement of memorization across different tasks and models
  - Quick check question: How does the plagiarism detection pipeline distinguish between verbatim and paraphrased memorization?

## Architecture Onboarding

- Component map: Fine-tuning pipeline → Memorization detection → Attention analysis → Multi-task comparison
- Critical path: Data preparation → Model fine-tuning → Memorization evaluation → Attention visualization → CAD calculation
- Design tradeoffs: Single-task vs multi-task fine-tuning, task selection impact on memorization
- Failure signatures: Inconsistent memorization patterns across similar tasks, unexpected attention distributions
- First 3 experiments:
  1. Replicate single-task fine-tuning results on T5-base across summarization, classification, and QA
  2. Implement attention score heatmap visualization for fine-tuned models
  3. Calculate CAD scores and correlate with memorization ratios across tasks

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the amount of memorization differ between fine-tuning on private versus public datasets, and what are the implications for privacy?
- Basis in paper: [explicit] The paper discusses that fine-tuning often involves domain-specific, private, or valuable data, and that leakage of such fine-tuning data can seriously violate user privacy or intellectual property rights.
- Why unresolved: The paper does not provide specific experiments or data comparing memorization rates between private and public datasets during fine-tuning.
- What evidence would resolve it: Experiments fine-tuning models on datasets with known privacy levels (private vs public) and measuring the resulting memorization rates and types.

### Open Question 2
- Question: How do different attention mechanisms beyond encoder-decoder attention (e.g., self-attention) correlate with memorization rates?
- Basis in paper: [inferred] The paper focuses on decoder-encoder attention as an indicator of memorization, but does not explore other attention mechanisms.
- Why unresolved: The paper only examines one type of attention and does not investigate whether other attention mechanisms show similar correlations with memorization.
- What evidence would resolve it: Analysis of memorization rates and attention patterns across different attention mechanisms (self-attention, cross-attention, etc.) within the same model architectures.

### Open Question 3
- Question: What is the long-term impact of multi-task fine-tuning on memorization compared to single-task fine-tuning across model lifetimes?
- Basis in paper: [explicit] The paper shows that multi-task fine-tuning can mitigate memorization in high-memorization tasks compared to single-task fine-tuning, but does not examine long-term effects.
- Why unresolved: The paper only presents a snapshot comparison and does not track memorization changes over time as models are used and updated.
- What evidence would resolve it: Longitudinal studies tracking memorization rates in models under single-task vs multi-task fine-tuning as they are deployed and updated over extended periods.

## Limitations

- Weak corpus evidence supporting the core mechanism that attention score distributions correlate with memorization levels
- Plagiarism detection pipeline may introduce false positives/negatives that could skew memorization measurements
- Multi-task fine-tuning results lack ablation studies to isolate which aspects drive memorization reduction

## Confidence

High confidence: Task-specific memorization disparities are well-supported by direct experimental evidence; methodology for calculating memorization ratios and CAD scores is clearly specified.

Medium confidence: Correlation between attention dispersion and memorization appears consistent within experiments but lacks external validation; multi-task fine-tuning results show clear patterns but mechanism isn't fully explained.

Low confidence: Foundational assumption about task information requirements lacks empirical support beyond paper's own observations; relationship between attention patterns and memorization processing isn't established in broader literature.

## Next Checks

1. Implement manual validation of plagiarism detection results by having independent annotators review a sample of detected memorized cases across different tasks to establish precision and recall rates.

2. Conduct ablation studies on multi-task fine-tuning by varying the number and types of tasks to isolate which factors most strongly influence memorization reduction.

3. Design controlled experiments comparing attention distributions across tasks with identical input lengths but different output requirements to test whether information density requirements drive memorization patterns.