---
ver: rpa2
title: 'Successor Heads: Recurring, Interpretable Attention Heads In The Wild'
arxiv_id: '2312.09230'
source_url: https://arxiv.org/abs/2312.09230
tags:
- successor
- tokens
- figure
- heads
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Successor heads are interpretable attention heads that increment
  tokens in ordinal sequences like numbers, months, and days. We find that these heads
  occur across language models of many different scales and architectures.
---

# Successor Heads: Recurring, Interpretable Attention Heads In The Wild

## Quick Facts
- arXiv ID: 2312.09230
- Source URL: https://arxiv.org/abs/2312.09230
- Reference count: 40
- Successor heads are interpretable attention heads that increment tokens in ordinal sequences like numbers, months, and days.

## Executive Summary
This paper identifies "successor heads" - attention heads in language models that increment tokens in ordinal sequences such as numbers, months, and days. The authors find these heads across language models of varying scales (31M to 12B parameters) and architectures. Through mechanistic interpretability techniques including sparse autoencoders and vector arithmetic, they demonstrate that these heads act on shared numeric representations decomposed into abstract "mod-10 features" that encode token positions in ordinal sequences. The paper also reveals that successor heads exhibit polysemanticity, performing acronym completion in addition to their primary succession function.

## Method Summary
The paper identifies successor heads by computing succession scores based on the effective OV circuit, which measures how well attention heads predict successor tokens in ordinal sequences. The authors train sparse autoencoders on MLP0 representations to isolate mod-10 features and verify their causal importance through ablation experiments. They use linear probes to analyze the compositional structure of numeric representations and demonstrate that vector arithmetic with mod-10 features can steer successor head behavior. The analysis spans multiple models including GPT-2, Pythia, and Llama-2 across different parameter scales.

## Key Results
- Successor heads are found across language models ranging from 31 million to 12 billion parameters, spanning multiple architectures.
- Sparse autoencoders reveal abstract "mod-10 features" that encode token positions in ordinal sequences and are causally important for incrementation.
- Vector arithmetic with mod-10 features can manipulate successor head behavior, demonstrating compositional structure in numeric representations.
- Successor heads exhibit polysemanticity, performing both token incrementation and acronym completion tasks.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Successor heads implement abstract numeric representations that increment ordinal sequence tokens through compositional MLP0 representations.
- **Mechanism:** MLP0 encodes token positions using shared index features and domain features, which successor heads use to increment tokens.
- **Core assumption:** Ordinal sequence tokens share a common numeric subspace independent of specific domain.
- **Evidence:** Successor heads found across models; MLP0 representations show compositional structure.
- **Break condition:** MLP0 lacks shared index/domain feature decomposition or successor heads cannot generalize across ordinal tasks.

### Mechanism 2
- **Claim:** Sparse autoencoders isolate "mod-10 features" that encode token positions modulo 10 and are causally important for incrementation.
- **Mechanism:** SAEs decompose MLP0 representations into sparse features revealing mod-10 structure that enables correct token incrementation.
- **Core assumption:** SAEs can reliably identify causally important features for successor head behavior.
- **Evidence:** SAE analysis shows periodic mod-10 feature activations; ablation experiments confirm causal importance.
- **Break condition:** SAEs fail to isolate important features or features don't generalize across ordinal tasks.

### Mechanism 3
- **Claim:** Vector arithmetic with mod-10 features can steer successor head behavior across different ordinal sequence tasks.
- **Mechanism:** Adding/subtracting mod-10 features from token representations shifts predicted successor tokens by desired amounts modulo 10.
- **Core assumption:** Mod-10 features are transferable and compositional across ordinal sequence tasks.
- **Evidence:** Vector arithmetic experiments successfully manipulate successor head outputs.
- **Break condition:** Vector arithmetic fails to steer behavior or only works for specific ordinal tasks.

## Foundational Learning

- **Concept:** Transformer architecture and attention mechanisms
  - **Why needed:** Understanding attention heads and residual streams is crucial for interpreting successor head behavior.
  - **Quick check:** How does an attention head's OV matrix affect the residual stream and subsequent token predictions?

- **Concept:** Mechanistic interpretability and sparse autoencoders
  - **Why needed:** The paper relies on SAEs to decompose and understand internal model representations.
  - **Quick check:** What is the purpose of the sparsity regularization term in the sparse autoencoder loss function?

- **Concept:** Vector arithmetic in latent spaces
  - **Why needed:** The paper demonstrates that vector arithmetic with mod-10 features can manipulate successor head behavior.
  - **Quick check:** How does adding a feature vector to a token representation affect the model's prediction?

## Architecture Onboarding

- **Component map:** Token embedding → MLP0 → Attention heads (successor head) → Residual stream → Unembedding → Output logits

- **Critical path:** Token embedding → MLP0 → Attention heads (successor head) → Residual stream → Unembedding → Output logits

- **Design tradeoffs:** Using MLP0 vs other layers for successor behavior; training SAEs on numeric vs ordinal tokens; focusing on mod-10 vs other modular structures

- **Failure signatures:** Successor heads not forming across models; MLP0 lacking shared feature decomposition; SAEs failing to isolate important features; vector arithmetic not steering behavior

- **First 3 experiments:**
  1. Compute successor scores for attention heads in target model to identify potential successor heads
  2. Train SAE on MLP0 representations of numeric tokens and analyze resulting features for mod-10 structure
  3. Perform vector arithmetic experiments by adding/subtracting mod-10 features to/from token representations

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** Do successor heads exhibit universal behavior across all transformer architectures, or are they specific to certain model families?
- **Basis:** Successor heads found in models from 31M to 12B parameters across GPT and related architectures
- **Why unresolved:** Limited validation across diverse architectures beyond GPT family
- **What evidence would resolve it:** Testing successor heads in BERT, T5, encoder-decoder models, and non-Transformer architectures

### Open Question 2
- **Question:** How do successor heads handle tokens at boundaries of ordinal sequences (e.g., Sunday to Monday, December to January)?
- **Basis:** Paper acknowledges cyclical successors but doesn't analyze boundary case handling
- **Why unresolved:** No detailed analysis of how successor heads manage end-to-beginning transitions
- **What evidence would resolve it:** Analyzing successor head behavior on boundary tokens and cyclical transitions

### Open Question 3
- **Question:** Are mod-10 features a universal property of numeric representations in language models, or specific to studied tasks and models?
- **Basis:** Paper identifies mod-10 features in successor heads but doesn't explore other numeric representations
- **Why unresolved:** Limited investigation beyond specific successor head tasks and models
- **What evidence would resolve it:** Extending mod-10 feature analysis to other numeric representations and tasks

## Limitations

- Limited validation across diverse transformer architectures beyond GPT family
- Potential overfitting to specific SAE methodology for feature decomposition
- Insufficient testing of successor head behavior on out-of-distribution ordinal sequences

## Confidence

- **Existence of successor heads:** High confidence - Robust empirical evidence across multiple models
- **Compositionality of numeric representations:** Medium confidence - Compelling but limited-scope evidence
- **Causal importance of mod-10 features:** Medium confidence - Ablative experiments show importance but limited contexts
- **Cross-model universality:** Low confidence - Sample size too small for strong universality claims

## Next Checks

1. **Cross-architecture validation:** Test successor head identification and behavior in BERT, T5, and encoder-decoder models to verify universality across different model families

2. **Alternative feature decomposition:** Replicate SAE analysis using activation patching and causal tracing to verify mod-10 features are robust to methodology

3. **Out-of-distribution testing:** Evaluate successor head behavior on custom ordinal sequences and non-standard calendars to test compositional structure and abstract feature representations