---
ver: rpa2
title: Scale-aware Test-time Click Adaptation for Pulmonary Nodule and Mass Segmentation
arxiv_id: '2307.15645'
source_url: https://arxiv.org/abs/2307.15645
tags:
- segmentation
- nodule
- click
- nodules
- test-time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper tackles the challenge of robust segmentation performance
  for pulmonary nodules and masses of various sizes in lung cancer screening, noting
  that large lesions are particularly difficult due to imbalanced scale distributions
  in datasets. The proposed solution is a Scale-aware Test-time Click Adaptation (SaTTCA)
  method that leverages easily obtainable lesion clicks during testing to adjust network
  normalization parameters, improving segmentation of large lesions.
---

# Scale-aware Test-time Click Adaptation for Pulmonary Nodule and Mass Segmentation

## Quick Facts
- arXiv ID: 2307.15645
- Source URL: https://arxiv.org/abs/2307.15645
- Reference count: 27
- Primary result: Test-time click adaptation improves large lesion segmentation recall by 1.71-2.96% and Dice by 1.71-2.96% over baselines.

## Executive Summary
This paper addresses the challenge of segmenting pulmonary nodules and masses across a wide range of sizes, with particular difficulty for large lesions due to scale imbalances in training data. The authors propose Scale-aware Test-time Click Adaptation (SaTTCA), a method that leverages easily obtainable lesion center clicks during testing to adapt network normalization parameters, improving segmentation of large lesions. The method combines a multi-scale input encoder with test-time adaptation using ellipsoid masks derived from lesion clicks, demonstrating significant performance gains across three datasets while being compatible with both CNN and Transformer backbones.

## Method Summary
The method uses a multi-scale input encoder that processes CT images at three resolutions (64×96×96, 32×48×48, 16×24×24) through separate convolution paths, then concatenates and downsamples features before feeding them to CNN or Transformer backbones. During testing, lesion center clicks are used to generate ellipsoid masks whose size is determined by a scale-aware mapping function based on the predicted bounding box. These masks supervise test-time adaptation of normalization layer parameters through an entropy-minimized loss combining click loss, Dice loss, and entropy loss, running for 10 epochs per sample.

## Key Results
- SaTTCA increases recall for large nodules/masses by 1.71% (in-house), 2.59% (LNDb), and 2.96% (LIDC) compared to baselines
- Dice scores improve by 1.71% (in-house), 2.59% (LNDb), and 2.96% (LIDC) for large lesions
- The method works with both CNN (nnUNet) and Transformer (TransBTS) backbones
- Outperforms existing click-based methods while adding only ~1 second inference overhead per sample

## Why This Works (Mechanism)

### Mechanism 1
Test-time adaptation using lesion center clicks allows the network to recalibrate normalization parameters for the current image without requiring retraining. During testing, the click is used to generate an ellipsoid mask whose size is proportional to the bounding box of the network's predicted lesion. This mask is then used to supervise parameter updates in normalization layers via an entropy-minimized loss (click loss + Dice loss + entropy loss). The core assumption is that the ellipsoid mask approximates the true lesion region well enough to guide meaningful normalization parameter updates at test time.

### Mechanism 2
Multi-scale input encoder improves segmentation across a wide range of lesion sizes by explicitly exposing the network to different resolutions of the same lesion. Input images are resized to 64×96×96, 32×48×48, and 16×24×24, processed through separate convolution paths, then concatenated and downsampled to a common scale before feeding into CNN or transformer blocks. The core assumption is that different lesion scales have distinct optimal feature extraction scales, and combining multi-scale features will better represent the full size spectrum.

### Mechanism 3
Scale-aware ellipsoid generation based on predicted bounding box size enables more targeted adaptation for lesions of different scales. The ellipsoid axes are derived from the bounding box using a mapping function that is quadratic for small/medium lesions (7-40mm) and linear for larger lesions (>40mm), ensuring the adaptation mask matches the lesion size more accurately. The core assumption is that the relationship between bounding box size and optimal ellipsoid mask size is approximately quadratic for medium lesions and linear for large ones.

## Foundational Learning

- **Normalization layers and learnable parameters**: These layers (e.g., BatchNorm, InstanceNorm) have scale and shift parameters that are learned during training. Here they're adapted at test-time to better fit the current image's statistics. Quick check: What are the two learnable parameters in a typical normalization layer, and how are they updated during training?

- **Test-time adaptation and entropy minimization**: TTA allows networks to adapt to test data without retraining. Entropy minimization encourages confident predictions consistent with the ellipsoid mask. Quick check: Why would minimizing entropy help during test-time adaptation when using a supervision mask?

- **Multi-scale feature extraction**: Processing the same image at different resolutions helps capture features at scales appropriate for different lesion sizes. Quick check: How does processing the same image at different resolutions help segmentation of lesions spanning a wide size range?

## Architecture Onboarding

- **Component map**: Input preprocessing → Multi-scale encoder (3 parallel CNN paths) → Feature concatenation → Backbone (CNN/Transformer) → Decoder → Output segmentation. Test-time adaptation module: Takes click, generates ellipsoid mask, computes loss, updates normalization parameters for 10 epochs.

- **Critical path**: Click → ellipsoid mask generation → test-time loss computation → normalization parameter update → segmentation refinement.

- **Design tradeoffs**: Multi-scale inputs improve size robustness but increase computation and memory. Test-time adaptation improves large lesion recall but adds ~1 second inference overhead. Ellipsoid mapping function is dataset-specific; poor choices can harm performance.

- **Failure signatures**: If clicks are consistently off-center, adaptation will mislead the network. If dataset has extreme scale imbalance not seen during ellipsoid parameter tuning, SaTTCA may over- or under-adapt. If backbone has poor initial lesion detection, bounding box estimation fails and ellipsoid generation becomes meaningless.

- **First 3 experiments**: 1) Baseline: Train and test without SaTTCA to establish recall/DSC across scales. 2) Ablation: Apply TTCA (fixed-radius ellipsoid) vs. SaTTCA (scale-aware ellipsoid) to quantify improvement from adaptive masking. 3) Backbone comparison: Run SaTTCA with nnUNet and TransBTS to confirm method is backbone-agnostic.

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of SaTTCA scale with the number of test-time adaptation epochs? Is there an optimal number of epochs beyond which performance plateaus or degrades? The paper only reports results for a fixed number of 10 epochs. Experiments varying the number of test-time adaptation epochs and plotting performance metrics against epochs would clarify the optimal number and potential overfitting.

### Open Question 2
Can the scale-aware test-time click adaptation be extended to other types of medical lesions beyond pulmonary nodules and masses, such as liver lesions or brain tumors? The method relies on lesion clicks and scale information, which are applicable to various medical imaging tasks. Applying SaTTCA to other medical segmentation tasks and comparing performance against baselines would demonstrate generalizability.

### Open Question 3
How sensitive is the performance of SaTTCA to the choice of hyperparameters in the mapping function R(d), particularly the quadratic and linear transition points (7mm and 40mm thresholds)? The paper uses fixed thresholds without exploring their impact on performance or providing sensitivity analysis. Systematic experiments varying the threshold values and measuring the resulting performance changes would reveal the sensitivity and potential optimal ranges for these hyperparameters.

### Open Question 4
How does the multi-scale input encoder compare to other multi-scale strategies, such as feature pyramid networks or atrous spatial pyramid pooling, in terms of performance and computational efficiency? The paper only compares its multi-scale encoder to the baseline without comparing it to other established multi-scale architectures. Implementing and comparing the proposed multi-scale encoder against other multi-scale architectures on the same datasets would provide a comprehensive evaluation of its effectiveness.

## Limitations

- The ellipsoid mask generation function and its parameter tuning are empirically derived but not fully validated across diverse datasets, potentially limiting generalization.
- The method assumes lesion center clicks are easily obtainable and accurate, which may not hold in all clinical workflows or for lesions with complex shapes.
- Multi-scale encoder increases computational cost without explicit quantification of memory overhead or latency impact beyond the stated ~1 second inference overhead.

## Confidence

- **High**: The core mechanism of test-time adaptation using lesion clicks to adjust normalization parameters is well-grounded and demonstrated across multiple datasets (LIDC, LNDb, in-house).
- **Medium**: The scale-aware ellipsoid mapping function (quadratic for 7-40mm, linear for >40mm) is empirically chosen but lacks theoretical justification or cross-dataset validation.
- **Low**: The exact derivation of click loss weighting parameters (σ=0.5, γ=1) is unclear, and their sensitivity to dataset characteristics is not explored.

## Next Checks

1. **Ablation Study**: Compare SaTTCA with fixed-radius ellipsoid adaptation (TTCA) to isolate the contribution of scale-aware mask generation and quantify improvement from adaptive masking.

2. **Cross-Dataset Robustness**: Apply SaTTCA to a dataset with different scale distributions (e.g., predominantly small nodules) to test ellipsoid mapping generalization and identify potential overfitting to specific size distributions.

3. **Click Accuracy Sensitivity**: Evaluate performance degradation when clicks are systematically offset from lesion centers to quantify reliance on click precision and identify acceptable tolerance ranges for clinical deployment.