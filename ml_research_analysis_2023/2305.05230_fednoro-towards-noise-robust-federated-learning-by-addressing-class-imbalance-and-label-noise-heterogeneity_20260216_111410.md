---
ver: rpa2
title: 'FedNoRo: Towards Noise-Robust Federated Learning by Addressing Class Imbalance
  and Label Noise Heterogeneity'
arxiv_id: '2305.05230'
source_url: https://arxiv.org/abs/2305.05230
tags:
- noisy
- clients
- learning
- noise
- label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses federated learning under class imbalance and
  heterogeneous label noise. It proposes a two-stage framework FedNoRo that first
  detects noisy clients using per-class loss and GMM, then employs knowledge distillation
  and distance-aware aggregation for noise-robust model updating.
---

# FedNoRo: Towards Noise-Robust Federated Learning by Addressing Class Imbalance and Label Noise Heterogeneity

## Quick Facts
- arXiv ID: 2305.05230
- Source URL: https://arxiv.org/abs/2305.05230
- Reference count: 16
- Primary result: Proposed FedNoRo framework achieves 70.69% and 66.00% balanced accuracy on ICH and ISIC2019 datasets, outperforming state-of-the-art methods under various noise rates.

## Executive Summary
This paper addresses the critical challenge of federated learning under both class imbalance and heterogeneous label noise. The proposed FedNoRo framework operates in two stages: first detecting noisy clients using per-class loss indicators combined with Gaussian Mixture Models, then performing noise-robust training through knowledge distillation and distance-aware aggregation. Experiments on medical imaging datasets demonstrate significant improvements over existing federated learning methods when dealing with noisy labels.

## Method Summary
FedNoRo is a two-stage framework for noise-robust federated learning. In the first stage, after an initial warm-up training phase, clients are identified as clean or noisy using per-class loss values and Gaussian Mixture Model clustering. In the second stage, clean clients use cross-entropy loss with logit adjustment while noisy clients use knowledge distillation with the global model's predictions as soft targets. A distance-aware aggregation function weights client updates based on their proximity to the nearest clean client's model. The framework employs ResNet-18 as the backbone architecture and is evaluated on intracranial hemorrhage (ICH) and ISIC2019 skin disease datasets.

## Key Results
- FedNoRo achieves 70.69% balanced accuracy on ICH dataset, outperforming baselines by 3-5% across various noise rates
- On ISIC2019 dataset, FedNoRo achieves 66.00% balanced accuracy, demonstrating 4-6% improvement over state-of-the-art methods
- The framework shows consistent performance gains across different noise rates (10%-40%) and maintains effectiveness under varying levels of class imbalance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Per-class loss indicators enable effective noisy client detection by reducing the impact of class imbalance and heterogeneity.
- Mechanism: Instead of using a global average loss for each client, the framework calculates the average loss for each class separately. This allows cleaner intra-class comparisons and helps distinguish noisy clients as outliers based on per-class loss values.
- Core assumption: Intra-class samples are more IID even under class imbalance, while inter-class comparisons are skewed by imbalanced data distributions.
- Evidence anchors:
  - [abstract]: "per-class loss indicators followed by Gaussian Mixture Model are deployed for noisy client identification"
  - [section 4.1]: "the average loss values of all classes on each client denoted as li = (l1 i, l2 i, ..., lC i )T ∈ RC are used for identification"
  - [corpus]: Weak evidence - related papers focus on noisy client detection but don't specifically address per-class loss indicators.

### Mechanism 2
- Claim: Knowledge distillation with soft labels helps noisy clients learn better representations without overfitting to noisy labels.
- Mechanism: For noisy clients, the framework uses knowledge distillation where the global model's predictions (soft labels) are used as targets. This allows the local model to learn from the global model's more stable predictions rather than relying solely on potentially incorrect hard labels.
- Core assumption: The global model, even if imperfect, provides more reliable supervision than the noisy local labels.
- Evidence anchors:
  - [abstract]: "knowledge distillation and a distance-aware aggregation function are jointly adopted for noise-robust federated model updating"
  - [section 4.2]: "a knowledge distillation (KD) [Hinton et al., 2015] based training method is applied" with soft labels dominating as training progresses
  - [corpus]: Moderate evidence - several related papers mention knowledge distillation for noisy label learning, but not specifically in federated settings.

### Mechanism 3
- Claim: Distance-aware aggregation reduces the negative impact of noisy clients on global model updates.
- Mechanism: The framework assigns lower aggregation weights to models that are farther from the nearest clean client model, effectively reducing the influence of potentially corrupted models from noisy clients.
- Core assumption: Noisy clients' models will be farther from clean clients' models due to learning from corrupted data.
- Evidence anchors:
  - [abstract]: "a distance-aware aggregation function are jointly adopted for noise-robust federated model updating"
  - [section 4.2]: "a distance-aware model aggregation function is proposed where a client-wise distance metric is defined as d(i) = min j∈Sc ∥wi−wj∥2"
  - [corpus]: Weak evidence - distance-aware aggregation is mentioned in related works but not specifically for noisy client mitigation.

## Foundational Learning

- Concept: Gaussian Mixture Model for unsupervised clustering
  - Why needed here: Used to separate clients into clean and noisy groups based on their per-class loss vectors without requiring labeled data for validation
  - Quick check question: What assumption does GMM make about the data distribution of clean vs. noisy clients?

- Concept: Knowledge distillation
  - Why needed here: Enables noisy clients to learn from the global model's predictions (soft labels) rather than relying solely on potentially corrupted local labels
  - Quick check question: How does the temperature parameter in softmax affect the uniformity of soft labels in knowledge distillation?

- Concept: Logit adjustment for class imbalance
  - Why needed here: Compensates for biased class priors in local data by adjusting the logits during training, ensuring each class is treated equally regardless of local class distribution
  - Quick check question: How does logit adjustment modify the classification loss to account for class imbalance?

## Architecture Onboarding

- Component map: Warm-up phase -> Per-class loss computation -> GMM clustering -> Stage 2 training with appropriate strategies -> Distance-aware aggregation
- Critical path: Warm-up → Per-class loss computation → GMM clustering → Stage 2 training with appropriate strategies → Distance-aware aggregation
- Design tradeoffs:
  - Per-class vs. global indicators: Per-class indicators are more robust to class imbalance but increase computational overhead
  - Hard vs. soft labels for noisy clients: Soft labels provide smoother learning but may be less precise than hard labels for clean data
  - Distance-based vs. fixed weights for aggregation: Distance-based weights are adaptive but require additional computation per round
- Failure signatures:
  - Poor noisy client detection: High precision but low recall, or vice versa
  - Degraded global model quality: Performance drops despite noise mitigation strategies
  - Communication bottlenecks: Excessive per-class loss computations or distance calculations
- First 3 experiments:
  1. Validate per-class loss effectiveness: Compare noisy client detection performance using per-class vs. global loss indicators on a controlled dataset with known noisy clients
  2. Test knowledge distillation contribution: Run with and without KD on noisy clients while keeping other components constant
  3. Evaluate distance-aware aggregation: Compare standard FedAvg aggregation vs. distance-aware aggregation under varying noise rates

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed heterogeneous instance-dependent noise (H-IDN) model compare to other label noise models in terms of capturing real-world label noise patterns in federated learning?
- Basis in paper: [explicit] The paper introduces H-IDN as a new noise model that considers local data distribution as an additional factor to manipulate label noise, making it more realistic for modeling complicated label noise in multi-source data.
- Why unresolved: While the paper presents the H-IDN model and demonstrates its effectiveness through experiments, a comprehensive comparison with other label noise models in terms of capturing real-world label noise patterns is not provided.
- What evidence would resolve it: Conducting experiments comparing H-IDN with other label noise models on various datasets and scenarios, and analyzing the performance differences in terms of noise detection and model robustness.

### Open Question 2
- Question: How does the proposed FedNoRo framework handle class imbalance in the presence of heterogeneous label noise, and what are the limitations of the current approach?
- Basis in paper: [explicit] The paper addresses class imbalance by using per-class loss indicators and logit adjustment (LA) in the local training phase, and proposes a distance-aware aggregation function to balance the importance of clean and noisy clients. However, the limitations of this approach in handling class imbalance under heterogeneous label noise are not discussed.
- Why unresolved: The paper focuses on demonstrating the effectiveness of FedNoRo in addressing class imbalance and label noise heterogeneity but does not provide a thorough analysis of the limitations and potential improvements of the current approach.
- What evidence would resolve it: Conducting experiments to evaluate the performance of FedNoRo under different levels of class imbalance and label noise heterogeneity, and analyzing the impact of various factors such as the number of clients, data distribution, and noise patterns on the framework's effectiveness.

### Open Question 3
- Question: How does the proposed FedNoRo framework compare to other federated learning methods in terms of communication efficiency and scalability, especially when dealing with large-scale datasets and a large number of clients?
- Basis in paper: [inferred] The paper presents FedNoRo as a two-stage framework that involves noisy client detection and noise-robust training, which may require additional communication rounds and computational resources compared to traditional federated learning methods. However, the communication efficiency and scalability of FedNoRo are not explicitly discussed.
- Why unresolved: While the paper focuses on addressing class imbalance and label noise heterogeneity, the communication efficiency and scalability of the proposed framework are not thoroughly evaluated, which is crucial for practical applications in real-world scenarios.
- What evidence would resolve it: Conducting experiments to compare the communication efficiency and scalability of FedNoRo with other federated learning methods on large-scale datasets and a large number of clients, and analyzing the impact of various factors such as the number of clients, data distribution, and noise patterns on the framework's performance.

## Limitations
- Limited evaluation to medical imaging domains, raising questions about generalizability to other domains
- Reliance on unsupervised GMM clustering which may struggle with complex or overlapping noise patterns
- The distance-aware aggregation assumes noisy clients are systematically farther from clean clients, which may not hold in all scenarios

## Confidence

- **High confidence**: The core framework design combining per-class loss indicators with GMM clustering for noisy client detection
- **Medium confidence**: The effectiveness of knowledge distillation for noisy client training, based on similar approaches in centralized learning
- **Medium confidence**: Distance-aware aggregation performance, though the underlying assumption needs more validation

## Next Checks

1. **Cross-domain validation**: Test FedNoRo on non-medical datasets (e.g., CIFAR, SVHN) to verify generalizability beyond medical imaging

2. **GMM sensitivity analysis**: Systematically evaluate GMM performance under varying noise types, intensities, and client distributions to understand failure modes

3. **Alternative aggregation comparison**: Compare distance-aware aggregation with other robust aggregation methods (trimmed mean, Krum) to isolate its specific contribution to performance gains