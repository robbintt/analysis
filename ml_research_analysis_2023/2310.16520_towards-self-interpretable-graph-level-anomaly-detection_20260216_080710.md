---
ver: rpa2
title: Towards Self-Interpretable Graph-Level Anomaly Detection
arxiv_id: '2310.16520'
source_url: https://arxiv.org/abs/2310.16520
tags:
- graph
- learning
- anomaly
- glad
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel self-interpretable graph-level anomaly
  detection (GLAD) model called SIGNET that can simultaneously predict anomaly scores
  and provide explanations in the form of critical subgraphs. The key idea is to construct
  two distinct graph views (original graph and its dual hypergraph) and apply a multi-view
  subgraph information bottleneck (MSIB) framework to learn bottleneck subgraphs from
  both views in a self-supervised manner.
---

# Towards Self-Interpretable Graph-Level Anomaly Detection

## Quick Facts
- arXiv ID: 2310.16520
- Source URL: https://arxiv.org/abs/2310.16520
- Authors: 
- Reference count: 40
- Key outcome: SIGNET achieves 95.89% AD-AUC and 78.41% EX-AUC on BM-MT dataset, outperforming best baseline by 22.26% and 27.89% respectively

## Executive Summary
This paper introduces SIGNET, a self-interpretable graph-level anomaly detection model that simultaneously predicts anomaly scores and provides explanations in the form of critical subgraphs. The key innovation is a multi-view subgraph information bottleneck framework that learns bottleneck subgraphs from both the original graph and its dual hypergraph in a self-supervised manner. By measuring the mutual information between these bottleneck subgraphs, SIGNET can detect anomalies while providing interpretable explanations. Extensive experiments on 16 datasets demonstrate superior performance compared to state-of-the-art baselines.

## Method Summary
SIGNET constructs two distinct graph views (original graph and dual hypergraph) and applies a multi-view subgraph information bottleneck framework to learn bottleneck subgraphs from both views. The abnormality of a graph is measured by the mutual information between these bottleneck subgraphs, while the bottleneck subgraphs themselves serve as explanations. The model uses a single extractor to maintain consistency across views, and employs Info-NCE for mutual information estimation. This approach enables simultaneous anomaly detection and explanation generation without requiring ground-truth explanations.

## Key Results
- SIGNET achieves 95.89% AD-AUC and 78.41% EX-AUC on BM-MT dataset
- Outperforms best baseline by 22.26% and 27.89% on BM-MT
- Demonstrates superior performance across all 16 benchmark datasets
- Successfully provides self-interpretable explanations via bottleneck subgraphs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-view mutual information between bottleneck subgraphs provides a reliable measure of graph abnormality
- Mechanism: Anomalous graphs exhibit lower cross-view agreement (mutual information) compared to normal graphs because their substructures don't align well across views
- Core assumption: Anomalous graphs have substructures that violate matching patterns between original and dual hypergraph views
- Evidence anchors:
  - [abstract]: "the abnormality of a graph is then measured by the mutual information between the bottleneck subgraphs"
  - [section 3.4]: "the negative of MI can indicate the abnormality of testing data"
  - [corpus]: No direct evidence found about this specific mechanism in related papers
- Break condition: If normal graphs also exhibit low cross-view MI due to structural complexity, the abnormality measurement would become unreliable

### Mechanism 2
- Claim: Dual hypergraph transformation provides complementary structural information that enhances anomaly detection
- Mechanism: DHT converts edges to nodes and nodes to hyperedges, creating a view that emphasizes edge-level relationships. This complementary perspective helps capture both node-level and edge-level anomaly patterns that might be missed by examining only the original graph
- Core assumption: Edge-level information contains complementary discriminative signals for anomaly detection
- Evidence anchors:
  - [section 3.2]: "The dual hypergraph pays more attention to the edge-level information, encouraging the model to capture not only node-level but also edge-level anomaly patterns"
  - [section 3.2]: "dual hypergraph has significantly distinct contents from the original view"
  - [corpus]: Weak evidence - related papers focus on reconstruction-based methods rather than dual hypergraph approaches
- Break condition: If edge-level information doesn't contain meaningful discriminative signals for the specific dataset, the dual view adds noise rather than value

### Mechanism 3
- Claim: Single extractor design with node-to-edge lifting maintains consistency between bottleneck subgraphs across views
- Mechanism: Instead of using separate extractors for original graph and dual hypergraph, a single extractor processes the original graph and probabilities are lifted to edge level for dual hypergraph processing. This ensures consistent bottleneck subgraphs across views, improving both abnormality measurement and explanation quality
- Core assumption: Consistent bottleneck subgraphs across views are more informative than independently extracted ones
- Evidence anchors:
  - [section 3.3]: "we use a single extractor to generate bottleneck subgraphs for two views"
  - [section 3.3]: "the generated bottleneck subgraphs in two views can be highly correlated"
  - [section 4.4]: "the two-extractor version still underperforms the original SIGNET with one extractor"
- Break condition: If the node-to-edge lifting process introduces significant information loss, the consistency benefit might be outweighed by reduced discriminative power

## Foundational Learning

- Concept: Information Bottleneck Principle
  - Why needed here: Provides theoretical foundation for learning compressed representations that retain only information relevant to abnormality detection
  - Quick check question: How does the information bottleneck principle balance between compression and predictive power in unsupervised settings?

- Concept: Mutual Information Estimation
  - Why needed here: Essential for measuring cross-view agreement between bottleneck subgraphs without ground truth labels
  - Quick check question: Why is Info-NCE preferred over other MI estimators for this application?

- Concept: Graph Neural Networks and Hypergraph Neural Networks
  - Why needed here: Required to process both original graph and dual hypergraph views to extract meaningful subgraph representations
  - Quick check question: What architectural differences between GNN and HGNN are critical for processing their respective graph types?

## Architecture Onboarding

- Component map: Input graph → Dual hypergraph transformation → Single bottleneck subgraph extractor → GNN/HGNN encoders → Info-NCE MI estimation → Anomaly scoring and explanation
- Critical path: DHT → Subgraph extraction → MI estimation → Anomaly detection
- Design tradeoffs: Dual views provide complementary information but increase computational cost; single extractor ensures consistency but may limit specialization
- Failure signatures: Low cross-view MI on both normal and anomalous graphs (model too compressed); high cross-view MI on anomalous graphs (model too permissive)
- First 3 experiments:
  1. Compare MI values between normal and anomalous graphs on synthetic datasets with known motifs
  2. Ablation study removing dual hypergraph view to measure performance impact
  3. Test different MI estimators (JS, DV, Info-NCE) on a small dataset to verify robustness claims

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the dual hypergraph view construction compare to other perturbation-based view construction methods in terms of stability and effectiveness for anomaly detection in graph-structured data?
- Basis in paper: [explicit] The paper discusses the limitations of perturbation-based view constructions and highlights the advantages of the dual hypergraph-based view construction.
- Why unresolved: The paper mentions the limitations of perturbation-based methods but does not provide a direct comparison with other perturbation-based methods.
- What evidence would resolve it: Empirical comparison of dual hypergraph-based view construction with other perturbation-based methods on benchmark datasets.

### Open Question 2
- Question: How does the performance of SIGNET vary with different choices of GNN and HGNN encoders?
- Basis in paper: [explicit] The paper mentions using GIN and Hyper-Conv as GNN and HGNN encoders, respectively, but does not explore other options.
- Why unresolved: The paper does not investigate the impact of different encoder choices on the performance of SIGNET.
- What evidence would resolve it: Experiments comparing the performance of SIGNET with different GNN and HGNN encoder combinations.

### Open Question 3
- Question: How does the self-interpretability of SIGNET compare to post-hoc explainers in terms of providing meaningful explanations for anomaly detection results?
- Basis in paper: [explicit] The paper mentions the importance of self-interpretability and compares the performance of SIGNET with post-hoc explainers.
- Why unresolved: The paper does not provide a detailed comparison of the quality and reliability of explanations generated by SIGNET and post-hoc explainers.
- What evidence would resolve it: User studies or qualitative analysis of the explanations generated by SIGNET and post-hoc explainers.

## Limitations

- Computational overhead from dual hypergraph transformation may limit scalability to large graphs
- Performance highly dependent on hyperparameter tuning, particularly embedding dimensionality and MI estimation parameters
- Evaluation metrics don't directly measure practical interpretability for end-users

## Confidence

- **High confidence**: The theoretical framework of using cross-view MI for anomaly detection is well-grounded in information theory
- **Medium confidence**: Benchmark performance claims are supported by extensive experiments across 16 datasets
- **Low confidence**: Scalability claims are not empirically validated beyond the benchmark datasets

## Next Checks

1. **Scalability Test**: Evaluate SIGNET's performance on larger graphs (e.g., >1000 nodes) to verify computational efficiency claims and identify potential bottlenecks
2. **Cross-dataset Transfer**: Test whether bottleneck subgraphs learned on one dataset can effectively explain anomalies in structurally similar but different datasets
3. **User Study**: Conduct qualitative user study where domain experts assess the practical interpretability and usefulness of SIGNET's explanations in a real-world anomaly detection scenario