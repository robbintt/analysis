---
ver: rpa2
title: 'WeatherDepth: Curriculum Contrastive Learning for Self-Supervised Depth Estimation
  under Adverse Weather Conditions'
arxiv_id: '2310.05556'
source_url: https://arxiv.org/abs/2310.05556
tags:
- weather
- depth
- weatherdepth
- estimation
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: WeatherDepth addresses depth estimation under adverse weather conditions
  using a self-supervised curriculum contrastive learning approach. It introduces
  three progressive curricula from clear to increasingly adverse weather (sunny, relative
  adverse, adverse), and integrates contrastive learning across stages to prevent
  forgetting.
---

# WeatherDepth: Curriculum Contrastive Learning for Self-Supervised Depth Estimation under Adverse Weather Conditions

## Quick Facts
- arXiv ID: 2310.05556
- Source URL: https://arxiv.org/abs/2310.05556
- Reference count: 34
- Primary result: Achieves state-of-the-art performance on depth estimation under adverse weather conditions

## Executive Summary
WeatherDepth addresses the challenge of depth estimation under adverse weather conditions (rain, snow, fog) using a self-supervised curriculum contrastive learning approach. The method introduces three progressive curricula that gradually adapt models from clear to increasingly adverse weather conditions, while contrastive learning across stages prevents catastrophic forgetting. An adaptive scheduler automatically determines optimal switching points between curricula. The WeatherKITTI dataset with synthetic weather variations is proposed for training and evaluation. WeatherDepth demonstrates significant performance improvements, reducing absolute relative error by up to 40% compared to the best previous method on synthetic weather datasets, and showing strong performance on real weather scenes from DrivingStereo and CADC datasets.

## Method Summary
WeatherDepth employs a curriculum contrastive learning framework that progressively adapts depth estimation models from clear to adverse weather conditions. The method consists of three training stages: sunny scenes, relative adverse weather (light rain/snow), and fully adverse conditions (heavy rain, fog-like rain, dense snow). At each stage, contrastive learning is applied between different weather augmentations of the same scene to maintain depth consistency and prevent forgetting of previously learned features. An adaptive curriculum scheduler monitors self-supervised loss convergence to automatically determine when to switch between curricula, reducing manual intervention. The WeatherKITTI dataset is synthetically generated using GAN and PBR techniques to provide controlled weather variations for training and evaluation.

## Key Results
- Reduces absolute relative error by up to 40% on WeatherKITTI synthetic dataset compared to best previous method
- Achieves state-of-the-art performance on both synthetic and real weather datasets
- Demonstrates strong generalization to real rain, snow, and fog scenes from DrivingStereo and CADC datasets
- Shows significant improvements over baseline models including MonoViT, PlaneDepth, and WaveletMonodepth

## Why This Works (Mechanism)

### Mechanism 1: Progressive Curriculum Learning
- Claim: Progressive curriculum learning enables gradual adaptation to adverse weather by starting from clear scenes and incrementally introducing weather complexity.
- Mechanism: Three-stage training from sunny → relative adverse → adverse weather conditions allows the model to first learn robust depth cues in clean data, then adapt to partial weather effects, and finally handle full adverse conditions.
- Core assumption: Depth cues learned in clear conditions can be incrementally transferred and refined for increasingly complex weather scenarios.
- Evidence anchors: [abstract] "progressive curriculum learning scheme with three simple-to-complex curricula", [section III-B] "We define our first curriculum as sunny scenes..."
- Break condition: If the domain gap between consecutive curricula is too large, the model cannot transfer learned features effectively.

### Mechanism 2: Contrastive Learning for Consistency
- Claim: Contrastive learning between different weather augmentations prevents catastrophic forgetting by enforcing depth consistency across weather conditions.
- Mechanism: Depth predictions from clear, relative adverse, and adverse versions of the same scene are contrasted to create a depth consistency constraint that maintains knowledge from previous stages.
- Core assumption: Different weather augmentations of the same scene share identical depth structure, so their predictions should be consistent.
- Evidence anchors: [abstract] "to prevent the model from forgetting previous curricula, we integrate contrastive learning into different curricula", [section III-C] "we can contrast the depth results from different curriculum stages"
- Break condition: If the contrastive weight is not properly scheduled, the model may overfit to weather variations or fail to maintain consistency.

### Mechanism 3: Adaptive Curriculum Scheduling
- Claim: Adaptive curriculum scheduling automatically determines optimal switching points between curricula based on loss convergence.
- Mechanism: The scheduler monitors the change in self-supervised loss and switches curricula when improvement plateaus, reducing manual intervention.
- Core assumption: Loss convergence patterns can reliably indicate when the model has sufficiently learned the current curriculum level.
- Evidence anchors: [abstract] "we designed an adaptive curriculum scheduler to automatically search for the best timing for course switching", [section III-D] "we check whether the network has fitted well in the current stage based on the change of self-supervised loss"
- Break condition: If the threshold for switching is set too low or high, the model may switch prematurely or remain stuck in suboptimal curricula.

## Foundational Learning

- Concept: Self-supervised depth estimation using photometric consistency
  - Why needed here: WeatherDepth builds on self-supervised depth estimation frameworks, so understanding the photometric consistency loss is essential
  - Quick check question: How does the photometric reconstruction loss work when weather particles violate the consistency assumption?

- Concept: Curriculum learning and catastrophic forgetting
  - Why needed here: The paper explicitly addresses forgetting through curriculum design, so understanding this ML concept is critical
  - Quick check question: What happens to a model's performance on previous tasks when trained sequentially on new tasks without any mitigation?

- Concept: Contrastive learning and consistency regularization
  - Why needed here: Contrastive learning is the key mechanism for preventing forgetting across curricula
  - Quick check question: How does contrastive learning between different augmentations of the same image help maintain consistency in the learned representations?

## Architecture Onboarding

- Component map: Base depth model (MonoViT/PlaneDepth/WaveletMonodepth) → Weather augmentation → Curriculum selector (sunny → relative adverse → adverse) → Depth estimation → Contrastive loss computation → Backward pass → Adaptive scheduler monitoring

- Critical path: Input → Weather augmentation → Curriculum selection → Depth estimation → Contrastive loss computation → Backward pass → Scheduler monitoring

- Design tradeoffs:
  - Progressive curricula vs. mixed training: Progressive approaches show better performance but require careful scheduling
  - Contrastive weight scheduling: Too high causes instability, too low causes forgetting
  - Weather realism vs. training efficiency: More realistic weather requires more complex rendering but improves real-world performance

- Failure signatures:
  - Training instability when contrastive weight increases too rapidly
  - Performance degradation on clear scenes when contrastive learning is absent
  - Poor adaptation to real weather when synthetic augmentation doesn't match real conditions

- First 3 experiments:
  1. Baseline ablation: Train without curriculum progression (mixed weather training) to quantify the benefit of progressive learning
  2. Contrastive ablation: Train with curriculum progression but without contrastive learning to measure forgetting effects
  3. Scheduler sensitivity: Test different patience values and thresholds in the adaptive scheduler to find optimal switching points

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the WeatherDepth model's performance vary when trained on real-world weather datasets (e.g., from different geographic regions) versus synthetic weather datasets?
- Basis in paper: [inferred] The paper discusses the effectiveness of WeatherDepth on synthetic and real weather datasets, but does not explore variations across different geographic regions.
- Why unresolved: The paper does not provide experiments or discussions on geographic variations in weather data.
- What evidence would resolve it: Comparative experiments on real-world weather datasets from different geographic regions would clarify the model's adaptability to diverse weather conditions.

### Open Question 2
- Question: What are the long-term effects of using WeatherDepth in autonomous driving systems, particularly in terms of safety and reliability under varying weather conditions?
- Basis in paper: [inferred] The paper mentions potential applications in autonomous driving but does not address long-term effects or safety concerns.
- Why unresolved: The paper focuses on performance metrics and does not explore real-world deployment implications.
- What evidence would resolve it: Long-term studies and safety assessments in autonomous driving scenarios would provide insights into the model's reliability and safety.

### Open Question 3
- Question: How does the integration of contrastive learning in WeatherDepth affect its computational efficiency compared to other methods that do not use contrastive learning?
- Basis in paper: [explicit] The paper discusses the integration of contrastive learning to prevent forgetting and improve performance, but does not provide a detailed comparison of computational efficiency.
- Why unresolved: While the paper mentions efficiency, it lacks a direct comparison with methods lacking contrastive learning.
- What evidence would resolve it: Detailed computational benchmarks comparing WeatherDepth with and without contrastive learning would clarify its efficiency impact.

## Limitations

- WeatherKITTI dataset is synthetically generated and may not fully capture the complexity of real-world adverse weather conditions
- Performance gains on real datasets are promising but evaluated on limited sample sizes
- Adaptive scheduler's effectiveness depends on proper threshold tuning that was not fully disclosed
- Computational overhead of contrastive learning across multiple weather augmentations increases training time significantly

## Confidence

- **High confidence**: The core curriculum learning approach (progressive adaptation from clear to adverse conditions) and the quantitative performance improvements on benchmark datasets
- **Medium confidence**: The specific contrastive learning mechanism's contribution to preventing forgetting, as the ablation study could be more comprehensive
- **Medium confidence**: The generalizability of WeatherKITTI synthetic data to real-world adverse weather scenarios

## Next Checks

1. **Real-world deployment test**: Evaluate WeatherDepth on diverse real-world adverse weather datasets beyond the three mentioned (e.g., autonomous driving datasets with varied weather conditions) to assess generalization

2. **Ablation study completeness**: Conduct a more comprehensive ablation study removing individual components (curriculum learning, contrastive learning, adaptive scheduler) to quantify each contribution precisely

3. **Computational efficiency analysis**: Measure and report the training time and memory overhead introduced by the contrastive learning components compared to standard self-supervised depth estimation methods