---
ver: rpa2
title: 'Interpretable Deep Learning for Forecasting Online Advertising Costs: Insights
  from the Competitive Bidding Landscape'
arxiv_id: '2302.05762'
source_url: https://arxiv.org/abs/2302.05762
tags:
- time
- data
- advertisers
- series
- forecasting
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study evaluates multiple time-series forecasting models, including
  statistical, machine learning, and deep learning approaches, to predict daily cost-per-click
  (CPC) in online advertising. It demonstrates that incorporating multivariate features
  from competitors' CPC patterns, identified via time-series clustering, significantly
  improves forecasting accuracy.
---

# Interpretable Deep Learning for Forecasting Online Advertising Costs: Insights from the Competitive Bidding Landscape

## Quick Facts
- arXiv ID: 2302.05762
- Source URL: https://arxiv.org/abs/2302.05762
- Reference count: 9
- The Temporal Fusion Transformer (TFT) with distance-based clustering achieves best performance for CPC forecasting, with MAE of 0.201 and SMAPE of 0.177 at 14 days ahead.

## Executive Summary
This study evaluates time-series forecasting models for daily cost-per-click (CPC) in online advertising, demonstrating that incorporating multivariate features from competitors' CPC patterns significantly improves forecasting accuracy. The approach uses time-series clustering to identify relevant competitor data as covariates, with the Temporal Fusion Transformer (TFT) model achieving superior performance across multiple forecasting horizons. The methodology proves robust during market shifts like the COVID-19 pandemic and provides interpretable insights into budget effects and competitive dynamics. The framework offers a scalable solution for strategic budget planning in online advertising.

## Method Summary
The study preprocesses daily CPC data from 249,000 German advertisers, extracting temporal features and budget information. Four models are evaluated: SARIMA, XGBoost, LSTM, and Temporal Fusion Transformer (TFT), both in univariate and multivariate configurations. Time-series clustering identifies competitor CPC patterns as covariates using three approaches: distance-based (DTW), extracted-features-based, and category-based. Models are trained on historical data and evaluated across 14, 30, and 60-day forecasting horizons using MAE and SMAPE metrics.

## Key Results
- TFT with distance-based clustering achieves MAE of 0.201 and SMAPE of 0.177 at 14 days ahead
- Same model achieves MAE of 0.232 and SMAPE of 0.196 at 60 days ahead
- Multivariate models with competitor covariates consistently outperform univariate approaches across all horizons
- Approach demonstrates robustness during COVID-19 market shifts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distance-based clustering captures non-linear competitive dynamics that extracted-feature clustering misses
- Mechanism: Dynamic Time Warping aligns time-series with similar patterns even if they are temporally shifted or scaled differently, creating more relevant covariate groups
- Core assumption: Competitive CPC patterns across advertisers exhibit temporal alignment rather than just statistical similarity
- Evidence anchors: [abstract] "TFT model that uses the covariates obtained from distance-based clustering achieves the best performance"; [section] "DTW allows for the alignment of two smoothed advertiser time series, where similar patterns are shifted in time and occur in different scales"
- Break condition: If competitive dynamics are purely contemporaneous with no temporal shifts, Euclidean distance might suffice

### Mechanism 2
- Claim: Deep learning models with variable selection can identify relevant covariates from large competitor pools better than traditional methods
- Mechanism: Temporal Fusion Transformer's variable selection networks filter thousands of potential competitor CPC series down to those most predictive for each target advertiser
- Core assumption: The most relevant competitors for CPC prediction are not always from the same industry category
- Evidence anchors: [abstract] "incorporating multivariate models, enriched with covariates derived from competitors' CPC patterns through time-series clustering, significantly improves forecasting accuracy"; [section] "The TFT model that uses the covariates obtained from distance-based clustering achieves the best performance"
- Break condition: If all relevant competitors could be identified through industry categories alone, simpler models might suffice

### Mechanism 3
- Claim: Including competitive landscape information helps models maintain accuracy during market shocks
- Mechanism: Models trained on multiple advertisers learn the relationships between budget changes, competitive bidding, and CPC outcomes, allowing them to adapt when one advertiser's patterns shift dramatically
- Core assumption: Competitive bidding dynamics create correlated CPC responses across advertisers during market events
- Evidence anchors: [abstract] "Our method proves robust during major market shifts, such as the COVID-19 pandemic, consistently outperforming models that rely solely on individual advertisers' data"; [section] "Our proposed model learns more reliably and performs better when trained on long data series that include drastic changes in past target variable development"
- Break condition: If market shocks affect all advertisers independently without competitive correlation

## Foundational Learning

- Concept: Time series clustering with DTW
  - Why needed here: To identify relevant competitor groups beyond simple industry categorization
  - Quick check question: How does DTW handle time series of different lengths or with temporal shifts compared to Euclidean distance?

- Concept: Multivariate time series forecasting
  - Why needed here: To incorporate competitive dynamics and budget effects on CPC prediction
  - Quick check question: What are the key differences between univariate and multivariate forecasting approaches in terms of feature engineering requirements?

- Concept: Transformer attention mechanisms
  - Why needed here: To provide interpretability and capture long-term temporal dependencies in CPC patterns
  - Quick check question: How does multi-head attention in TFT differ from standard self-attention in language models?

## Architecture Onboarding

- Component map: Data preprocessing pipeline -> Feature engineering -> Clustering module -> Model training framework -> Evaluation system -> Interpretability tools

- Critical path: Data preprocessing → Clustering → Feature composition → Model training → Evaluation → Interpretability analysis

- Design tradeoffs:
  - Complexity vs interpretability: TFT provides both accuracy and interpretability but is more complex than XGBoost
  - Granularity vs stability: Daily data captures more patterns but increases noise compared to weekly aggregation
  - Cluster size vs relevance: More clusters might capture finer competitive dynamics but reduce sample size per cluster

- Failure signatures:
  - Poor clustering assignment: Check if cluster compositions make business sense by examining category distributions
  - Overfitting to noise: Monitor validation performance across horizons, especially for deep learning models
  - Missing temporal patterns: Verify seasonal decomposition of residuals for unexplained periodic components

- First 3 experiments:
  1. Compare DTW vs Euclidean distance clustering on a small subset to validate alignment benefits
  2. Test univariate vs multivariate TFT performance on a single advertiser to confirm competitive feature value
  3. Run ablation study removing budget features to quantify their impact on long-horizon forecasting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed approach be extended to predict other key performance metrics in online advertising, such as revenue, number of transactions, or cost-per-acquisition (CPA)?
- Basis in paper: [explicit] The authors suggest that predicting revenue, number of transactions, CPA, or return on ad spend (ROAS) would be valuable for online marketing teams and that these metrics are inherently intertwined with market and competitor behaviors, implying the techniques could be applicable.
- Why unresolved: The paper focuses specifically on cost-per-click (CPC) prediction. While the authors mention the potential for extending the approach to other metrics, they do not provide any concrete analysis or results for these alternative metrics. The effectiveness and necessary modifications for different metrics remain untested.
- What evidence would resolve it: Empirical results demonstrating the performance of the proposed approach (including the TFT model and clustering methods) when applied to predict revenue, transactions, CPA, or ROAS, compared to baseline models, would resolve this question.

### Open Question 2
- Question: How does the performance of the TFT model compare to Graph Neural Networks (GNNs) when modeling the competitive landscape of online advertising?
- Basis in paper: [explicit] The authors mention that GNNs, which use static or temporal dynamic graph representations, seem well-suited for modeling the competitive landscape of online advertising. They suggest comparing the performance of GNNs to their proposed TFT approach.
- Why unresolved: The paper does not include any experiments or comparisons with GNN-based models. The relative strengths and weaknesses of TFT versus GNN for this specific application are unknown.
- What evidence would resolve it: Direct empirical comparison of TFT and GNN models on the same dataset, using the same evaluation metrics (e.g., MAE, SMAPE) and forecasting horizons, would resolve this question.

### Open Question 3
- Question: To what extent do advertisers in the same cluster share common keywords, and how does this keyword overlap influence the effectiveness of the clustering-based forecasting approach?
- Basis in paper: [explicit] The authors note that further research on the actual keyword level is necessary to explore the advertising connections across industries. They also mention the possibility of generating a graph structure based on keyword data, where nodes are advertisers and edge weights represent shared keywords.
- Why unresolved: The paper analyzes clustering based on CPC time series but does not investigate the underlying keyword data. The relationship between keyword overlap and cluster formation, or its impact on forecasting accuracy, is not explored.
- What evidence would resolve it: Analysis of keyword data for advertisers within the same clusters, quantifying the average keyword overlap, and assessing whether clusters with higher keyword overlap lead to better forecasting performance, would resolve this question.

## Limitations
- Proprietary data from a major advertising platform limits external validation
- Clustering methodology lacks statistical significance testing between model variants
- COVID-19 robustness claims based on single-event observation rather than systematic stress-testing

## Confidence
- High confidence: Core finding that multivariate models with competitive covariates outperform univariate approaches
- Medium confidence: Distance-based clustering superiority claims
- Medium confidence: Interpretability insights

## Next Checks
1. Cross-platform validation: Test the methodology on publicly available advertising datasets to verify generalizability
2. Statistical significance testing: Conduct paired t-tests or bootstrap analysis to confirm performance improvements are significant
3. Dynamic cluster stability: Evaluate how cluster assignments evolve over time and whether models can adapt without complete retraining