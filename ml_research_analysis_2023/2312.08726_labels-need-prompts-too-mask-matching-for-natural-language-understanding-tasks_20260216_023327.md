---
ver: rpa2
title: 'Labels Need Prompts Too: Mask Matching for Natural Language Understanding
  Tasks'
arxiv_id: '2312.08726'
source_url: https://arxiv.org/abs/2312.08726
tags:
- mask
- matching
- label
- tasks
- semantic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel natural language understanding (NLU)
  paradigm called Mask Matching that incorporates prompting methodology into both
  the input and label sides. Specifically, it equips an input with a prompt and its
  label with another, and then makes predictions by matching their mask representations.
---

# Labels Need Prompts Too: Mask Matching for Natural Language Understanding Tasks

## Quick Facts
- arXiv ID: 2312.08726
- Source URL: https://arxiv.org/abs/2312.08726
- Reference count: 7
- Primary result: Mask Matching significantly outperforms fine-tuning and prompt-tuning, setting state-of-the-art performances on several NLU datasets.

## Executive Summary
This paper introduces Mask Matching, a novel NLU paradigm that extends prompting methodology to both input and label sides. By equipping inputs and labels with respective prompts and matching their mask representations, the method achieves state-of-the-art performance across 8 NLU tasks with 14 datasets. Mask Matching is particularly effective for tasks with large label counts and informative label names, avoiding the need for manual verbalizer design.

## Method Summary
Mask Matching incorporates prompting into both input and label representations. The input text is passed through an input-prompt containing a [MASK] token, while each label name is processed through a corresponding label-prompt. The [MASK] representations from both sides are extracted and compared via dot product similarity. Classification is performed by computing cross-entropy loss between the input's [MASK] representation and all label [MASK] representations. This approach avoids manual verbalizer design and leverages the semantic richness of label names through contextualization.

## Key Results
- Mask Matching significantly outperforms fine-tuning and conventional prompt-tuning baselines.
- Sets state-of-the-art performances on multiple datasets across 8 NLU tasks.
- Particularly effective for tasks with large label counts and informative label names.
- Demonstrates robustness to prompt template variations while maintaining strong performance.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using a prompt on the label side generates contextualized label representations that capture semantic richness beyond fixed embeddings.
- Mechanism: The label-prompt concatenates the label name with "is [MASK]" and passes it through the PLM. The [MASK] representation is compared to the input-prompt's [MASK] representation via dot product.
- Core assumption: The [MASK] representation in a prompt-conditioned PLM captures semantic meaning of the surrounding context better than static label embeddings.
- Evidence anchors: [abstract] states incorporating prompting methodology into label side for first time using mask representations; [section 3.2] describes label-prompt as "PL = is [MASK]" and explains computing loss between MI and ML over all predefined labels.
- Break condition: If the PLM does not properly condition on the prompt or if label names are too generic, the mask representation may not capture meaningful semantics.

### Mechanism 2
- Claim: The dual-prompt setup provides a symmetric semantic space enabling direct matching without needing a verbalizer or label embedding layer.
- Mechanism: Both input and label are passed through the same PLM with their respective prompts, generating [MASK] tokens in the same embedding space for direct comparison.
- Core assumption: The PLM's [MASK] representations from input-prompt and label-prompt are in a shared semantic space suitable for direct comparison.
- Evidence anchors: [section 3.3] explains utilizing mask within input-prompt as input representation and corresponding [MASK]s from label-prompts as label embeddings; [abstract] says makes predictions by matching their mask representations.
- Break condition: If [MASK] representations are not comparable across different prompt contexts, or if prompt templates do not properly align semantic spaces, matching will be ineffective.

### Mechanism 3
- Claim: Incorporating label names directly into the prompt avoids manual verbalizer design and allows the model to learn richer label semantics from context.
- Mechanism: Instead of mapping labels to arbitrary words, the model sees actual label name in the prompt, which is then contextualized by the PLM to produce semantic representation.
- Core assumption: Label names are semantically informative and can be better utilized when placed in a prompt context rather than mapped to arbitrary label words.
- Evidence anchors: [abstract] states incorporating prompting methodology into label side for first time and mentions avoiding verbalizer engineering; [section 5.1] shows improvements on datasets with "informative label names".
- Break condition: If label names are uninformative or ambiguous, the prompt may not yield useful representations.

## Foundational Learning

- Concept: Prompt-based fine-tuning in PLMs
  - Why needed here: Understanding how [MASK] tokens are used in prompts and how the PLM generates representations conditioned on context is essential to grasp why Mask Matching works.
  - Quick check question: In a prompt like "It is [MASK]", what does the [MASK] token represent and how is it used for classification?

- Concept: Semantic matching and label representation
  - Why needed here: Comparing Mask Matching to semantic matching baselines requires understanding how label representations are typically generated and why those may be suboptimal.
  - Quick check question: What is the difference between using a [MASK] representation from a prompt and using max-pooling over label name tokens for label representation?

- Concept: Cross-entropy loss with multiple label representations
  - Why needed here: Mask Matching computes cross-entropy between the input's [MASK] and multiple label [MASK]s; understanding this setup is key to implementing and debugging the method.
  - Quick check question: How does the loss function in Mask Matching differ from standard classification loss when using a classification head?

## Architecture Onboarding

- Component map: Input text → input-prompt (with [MASK]) → PLM → input representation (MI); Label name → label-prompt (with [MASK]) → PLM → label representations (ML1...MLn); Compute dot product between MI and each ML, apply softmax, compute cross-entropy with ground truth.
- Critical path: Text encoding through input-prompt → [MASK] representation extraction → Label encoding through label-prompt → [MASK] representation extraction → Matching via dot product → Loss computation.
- Design tradeoffs: Using prompts avoids manual verbalizer but requires careful template design; using the same PLM for both sides simplifies but may limit flexibility; multiple label prompts increase memory but improve representation quality.
- Failure signatures: If prompts are poorly designed, [MASK] representations may be uninformative; if label names are too generic, matching may not work; if the PLM is not properly fine-tuned, representations may not align.
- First 3 experiments:
  1. Implement a simple sentiment analysis with a basic input-prompt and label-prompt, verify that [MASK] representations are being generated and matched correctly.
  2. Compare Mask Matching to fine-tuning on a small dataset to confirm performance improvement and understand sensitivity to label names.
  3. Test different label-prompt templates (e.g., "Label is [MASK]" vs "Label means [MASK]") to see impact on performance and validate robustness to template choice.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Mask Matching's performance compare when using multiple mask tokens in both input and label prompts?
- Basis in paper: [explicit] The paper mentions that some works use multiple mask tokens and achieve favorable performances, but Mask Matching only uses one mask token in each prompt.
- Why unresolved: The paper does not experiment with using multiple mask tokens in Mask Matching, leaving the potential performance gains unexplored.
- What evidence would resolve it: Conducting experiments with Mask Matching using multiple mask tokens in both input and label prompts, and comparing the results with the single-mask-token version.

### Open Question 2
- Question: Can Mask Matching be effectively adapted for sentence-pair tasks like natural language inference and paraphrase?
- Basis in paper: [explicit] The paper acknowledges that Mask Matching does not gain remarkable improvements when dealing with sentence-pair tasks and suggests designing a new framework for these tasks.
- Why unresolved: The paper does not provide a concrete solution or experimental results for adapting Mask Matching to sentence-pair tasks.
- What evidence would resolve it: Developing and testing a new framework for sentence-pair tasks using Mask Matching, and comparing its performance with existing methods.

### Open Question 3
- Question: How can label names be automatically extended with relevant information in Mask Matching?
- Basis in paper: [explicit] The paper discusses the potential of enriching label names but notes that manually identifying synonyms is time-consuming and challenging without domain knowledge.
- Why unresolved: The paper does not provide a method for automatically extending label names in Mask Matching.
- What evidence would resolve it: Proposing and implementing an automatic method for extending label names in Mask Matching, and evaluating its impact on performance.

## Limitations

- The method's effectiveness heavily depends on label informativeness, with unclear operational definition of what constitutes "informative" label names.
- Scalability concerns exist for tasks with extremely large label sets, where computing dot products between input and all label representations could become computationally prohibitive.
- The paper does not rigorously validate whether the [MASK] representation is essential or if other contextualized embeddings would suffice.

## Confidence

- **High Confidence**: The method's general architecture (input-prompt + label-prompt → [MASK] matching) is clearly described and reproducible. The experimental setup, including datasets and evaluation metrics, is well-specified.
- **Medium Confidence**: The claim that Mask Matching outperforms fine-tuning and prompt-tuning is supported by experiments, but the magnitude of improvement and its consistency across tasks warrant further scrutiny.
- **Low Confidence**: The assertion that label informativeness is critical for success is based on limited evidence and lacks a clear operational definition.

## Next Checks

1. **Ablation on Label Representation Methods**: Compare Mask Matching's [MASK]-based label representation against alternatives such as mean-pooling over label name tokens, max-pooling, or using the [CLS] token to clarify whether the [MASK] mechanism is essential.

2. **Scalability Test with Large Label Sets**: Evaluate Mask Matching on a task with hundreds or thousands of labels (e.g., fine-grained entity typing) to measure computational overhead and verify whether the method remains effective or degrades due to quadratic scaling of label comparisons.

3. **Label Informativeness Quantification**: Design an experiment where label names are systematically made more or less informative (e.g., by abbreviating, paraphrasing, or replacing with synonyms) and measure the impact on Mask Matching performance to provide empirical grounding for the informativeness claim.