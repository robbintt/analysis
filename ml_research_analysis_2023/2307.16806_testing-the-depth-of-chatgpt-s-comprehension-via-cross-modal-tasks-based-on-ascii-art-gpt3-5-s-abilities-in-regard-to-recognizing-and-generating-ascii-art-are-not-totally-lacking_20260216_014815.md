---
ver: rpa2
title: 'Testing the Depth of ChatGPT''s Comprehension via Cross-Modal Tasks Based
  on ASCII-Art: GPT3.5''s Abilities in Regard to Recognizing and Generating ASCII-Art
  Are Not Totally Lacking'
arxiv_id: '2307.16806'
source_url: https://arxiv.org/abs/2307.16806
tags:
- ascii-art
- image
- which
- reference
- chatgpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores GPT-3.5's ability to process and generate ASCII
  art, focusing on visual tasks like image recognition and manipulation without relying
  on text-based descriptions. The author conducts experiments using randomly generated
  ASCII art diagrams and human-drawn ASCII art of animals and machines, testing GPT-3.5's
  performance in tasks like translation, rotation, noise tolerance, and scale changes.
---

# Testing the Depth of ChatGPT's Comprehension via Cross-Modal Tasks Based on ASCII-Art: GPT3.5's Abilities in Regard to Recognizing and Generating ASCII-Art Are Not Totally Lacking

## Quick Facts
- **arXiv ID**: 2307.16806
- **Source URL**: https://arxiv.org/abs/2307.16806
- **Reference count**: 40
- **Primary result**: GPT-3.5 demonstrates non-trivial visual reasoning on ASCII art, achieving accuracy above random guessing on recognition and generation tasks.

## Executive Summary
This paper investigates GPT-3.5's ability to process and generate ASCII art for visual tasks without relying on text-based descriptions. Through experiments involving randomly generated ASCII art diagrams and human-drawn ASCII art of animals and machines, the study tests the model's performance on tasks like translation, rotation, noise tolerance, and scale changes. Results indicate that GPT-3.5 can perform these tasks better than random guessing, though with room for improvement. The paper concludes that while not perfect, GPT-3.5 shows meaningful visual understanding of ASCII art, suggesting potential for further development in this area.

## Method Summary
The study employs Chain-of-Thought prompting with GPT-3.5-turbo (temperature 0) to test ASCII art recognition and generation. Experiments use randomly generated ASCII art diagrams (24x24 canvas, Poisson-distributed box sizes) and human-drawn ASCII art from the ASCII Art Archive. Tasks include multiple-choice recognition tests after transformations (translation, rotation, noise, scale changes) and generation tasks where the model must output ASCII art based on given transformations. Performance is measured against random guessing and edit-distance baselines.

## Key Results
- GPT-3.5 achieved 90.5% accuracy on translation tasks, significantly above random guessing
- Rotation task performance was 34-35% accurate, showing limitations in spatial reasoning
- Generation tasks produced outputs with meaningful structural similarity but often with imperfections
- Performance exceeded edit-distance baselines across all tested tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3.5 can perform non-trivial visual reasoning on ASCII-art by mapping character patterns to semantic object categories without explicit text labels.
- Mechanism: The model leverages its pretraining on natural language corpora that include ASCII-art to learn latent visual-semantic mappings, enabling it to infer object identity and spatial relationships from character arrangements.
- Core assumption: ASCII-art of structured diagrams frequently co-occurs with descriptive text in training data, allowing the model to form cross-modal associations.
- Evidence anchors: [abstract] Tests GPT-3.5's "aptitude for visual tasks" where inputs are ASCII-art "without overt distillation into a lingual summary."

### Mechanism 2
- Claim: GPT-3.5 uses spatial reasoning heuristics learned from text to interpret ASCII-art transformations like translation, rotation, and scaling.
- Mechanism: The model applies learned algebraic reasoning about spatial relations even without explicit geometry training.
- Core assumption: Natural language training data contains abundant spatial metaphors and procedural descriptions that can be generalized to symbolic spatial manipulation.
- Evidence anchors: [abstract] Experiments include "various transforms typical in visual settings" such as translation, rotation, and scale changes.

### Mechanism 3
- Claim: GPT-3.5's generation ability on ASCII-art stems from memorized templates and compositional rules rather than pixel-level image synthesis.
- Mechanism: The model recalls ASCII-art patterns from training and applies compositional logic to generate transformed outputs.
- Core assumption: ASCII-art appears in structured contexts in training data, allowing the model to learn reusable visual grammar.
- Evidence anchors: [abstract] Generation experiments test the model's ability to "transform reference images" and output ASCII-art.

## Foundational Learning

- Concept: Cross-modal representation learning
  - Why needed here: GPT-3.5 must connect symbolic character patterns to semantic meanings without explicit visual modality training.
  - Quick check question: Can you describe how ASCII-art might appear in natural language training data and why that helps the model?

- Concept: Spatial reasoning via algebraic metaphors
  - Why needed here: The model uses learned linguistic spatial concepts to manipulate ASCII-art without geometry engines.
  - Quick check question: How would you explain "rotate 90° clockwise" to someone using only text, and why would that help GPT-3.5?

- Concept: Template-based compositional generation
  - Why needed here: ASCII-art generation relies on recalling and recombining learned visual templates rather than novel synthesis.
  - Quick check question: What are the basic building blocks of ASCII-art boxes, and how might the model reuse them?

## Architecture Onboarding

- Component map: Prompt -> CoT warm-up -> ASCII-art input -> Multiple-choice or generation task -> Output parsing
- Critical path: Input preprocessing (ASCII-art formatting) -> Prompt engineering (CoT) -> Model inference -> Result extraction (parsing) -> Evaluation
- Design tradeoffs: Larger ASCII-art -> more context tokens used; simpler prompts -> less guidance but more authentic test of capability
- Failure signatures: Random guessing on recognition tasks; output without ASCII-art characters; incomplete or incorrect transformations
- First 3 experiments:
  1. Verbatim copy test: Provide ASCII-art, ask model to return it unchanged; verify exact match.
  2. Translation test: Shift ASCII-art and ask model to identify correct translation among choices.
  3. Rotation test: Rotate ASCII-art 90° and ask model to identify correct rotation among choices.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can GPT-3.5 generate novel ASCII art depictions of objects, beyond just modifying existing images?
- Basis in paper: [explicit] The paper discusses GPT-3.5's ability to generate ASCII art based on given transformations, finding that it can produce reasonable outputs but often with imperfections.
- Why unresolved: The paper does not explore GPT-3.5's ability to generate entirely new ASCII art from scratch.
- What evidence would resolve it: Testing GPT-3.5's ability to generate ASCII art depictions of objects it has not seen before, and evaluating the quality and accuracy of the generated art.

### Open Question 2
- Question: How does GPT-3.5's performance on ASCII art tasks compare to other language models or image recognition systems?
- Basis in paper: [inferred] The paper compares GPT-3.5's performance on ASCII art tasks to random guessing and string edit-distance, but does not compare it to other language models or image recognition systems.
- Why unresolved: The paper does not provide a benchmark against other models or systems.
- What evidence would resolve it: Conducting experiments comparing GPT-3.5's performance on ASCII art tasks to other language models or image recognition systems.

### Open Question 3
- Question: Can GPT-3.5 learn to recognize and generate more complex ASCII art structures, such as nested boxes or irregular shapes?
- Basis in paper: [explicit] The paper discusses GPT-3.5's ability to recognize and generate ASCII art diagrams with boxes, but does not explore more complex structures.
- Why unresolved: The paper focuses on simpler ASCII art structures and does not investigate GPT-3.5's ability to handle more complex ones.
- What evidence would resolve it: Designing experiments that test GPT-3.5's ability to recognize and generate more complex ASCII art structures, and evaluating its performance.

## Limitations

- Performance on rotation tasks (34-35% accuracy) suggests fundamental limits in spatial reasoning capabilities
- Evaluation methodology may overestimate capabilities due to prompt engineering and Chain-of-Thought approaches
- Reliance on constrained ASCII art corpus (primarily structured diagrams and common objects) limits generalizability

## Confidence

- **High confidence**: GPT-3.5 demonstrates non-random performance on ASCII art recognition and generation tasks, exceeding baseline edit-distance measures
- **Medium confidence**: The model's abilities stem from cross-modal representation learning rather than text-based pattern matching, though this remains partially speculative
- **Low confidence**: Claims about template-based compositional generation being the primary mechanism, as this is inferred from output patterns rather than directly tested

## Next Checks

1. **Ablation study on prompt engineering**: Test the same tasks without Chain-of-Thought prompting to determine if performance degrades significantly, isolating the effect of guided reasoning versus inherent capability.

2. **Cross-architecture comparison**: Evaluate GPT-4 (or another model without extensive ASCII art in training) on the same tasks to determine if performance differences suggest true visual understanding versus memorization.

3. **Novel composition test**: Generate ASCII art transformations that combine elements in ways unlikely to appear in training data (e.g., abstract geometric patterns) to test whether the model can generalize beyond memorized templates.