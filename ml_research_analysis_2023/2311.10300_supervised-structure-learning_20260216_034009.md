---
ver: rpa2
title: Supervised structure learning
arxiv_id: '2311.10300'
source_url: https://arxiv.org/abs/2311.10300
tags:
- learning
- states
- structure
- likelihood
- free
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for structure learning in discrete
  generative models using Bayesian model selection under active inference. The core
  idea is to grow models by evaluating posterior probabilities of parent versus augmented
  models, using variational free energy and mutual information as priors.
---

# Supervised structure learning

## Quick Facts
- arXiv ID: 2311.10300
- Source URL: https://arxiv.org/abs/2311.10300
- Reference count: 40
- One-line primary result: A method for structure learning in discrete generative models using Bayesian model selection under active inference

## Executive Summary
This paper presents a method for structure learning in discrete generative models using Bayesian model selection under active inference. The core idea is to grow models by evaluating posterior probabilities of parent versus augmented models, using variational free energy and mutual information as priors. This enables discovery of latent factorial structure and dynamics from ordered data streams. Applied to MNIST digit classification, the method learned approximately 50 styles per digit class and achieved ~96% classification accuracy. For a sprite-based visual disentanglement task, the model discovered three factors (two for object location and one for object class) and learned their dynamics through self-supervised exploration. Applied to the Tower of Hanoi problem, the method discovered the problem's structure and learned to solve it efficiently.

## Method Summary
The method uses discrete state-space generative models with Dirichlet priors, performing Bayesian model selection through comparison of variational free energy and expected free energy. Structure learning proceeds by iteratively adding latent states, paths, or factors when data suggests unseen generative processes. Variational message passing enables exact inference, while Dirichlet updates allow one-shot learning of new exemplars. Active inference drives exploration to complete likelihood mappings when uncertainty remains. The approach is demonstrated on MNIST classification, visual disentanglement, and Tower of Hanoi problem solving.

## Key Results
- Achieved ~96% classification accuracy on MNIST with learned style factors
- Discovered latent factorial structure (location and object class) in visual disentanglement task
- Learned Tower of Hanoi dynamics and solved problem instances efficiently
- Demonstrated structure learning through self-supervised exploration driven by expected free energy minimization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bayesian model selection under active inference enables the system to grow generative models by evaluating posterior probabilities of parent versus augmented models.
- Mechanism: When a new observation arrives, the system computes the variational free energy for both the existing model and a proposed augmented model (with additional latent states, paths, or factors). The expected free energy, which reduces to a constrained mutual information, acts as a prior favoring models that maximize information gain. The model with the highest posterior probability (combining likelihood and prior) is selected.
- Core assumption: The new data is either generated by previously unseen latent states or by previously encountered ones, and the ordering of data respects the temporal structure of the underlying generative process.
- Evidence anchors:
  - [abstract] "This paper presents a method for structure learning in discrete generative models using Bayesian model selection under active inference."
  - [section 3] "The difference in expected free energy reflects the information gain in selecting one model over the other, following (3)."
- Break condition: If the data ordering is corrupted or random, the model will not learn the correct dynamics because the transition tensors cannot be properly inferred.

### Mechanism 2
- Claim: Discrete state-space models enable exact inference and learning via tensor operations without backpropagation.
- Mechanism: The generative model uses categorical distributions over discrete states, with Dirichlet priors over parameters. Inference proceeds via variational message passing, which converges quickly due to the discrete nature. Learning updates Dirichlet counts based on inferred latent states, allowing one-shot assimilation of new exemplars.
- Core assumption: The state and outcome spaces can be adequately represented as discrete categories, and the likelihood tensor can be learned from sufficient exemplars.
- Evidence anchors:
  - [section 2] "The variational message passing scheme becomes remarkably simple and corresponds to a fixed-point iteration scheme."
  - [section 4] "For the simple case of recognising static patterns, the generative model is a tensor mapping from latent states to outcomes."
- Break condition: If the state space is too large or continuous nature of the data is critical, the discrete representation may lose essential information or become intractable.

### Mechanism 3
- Claim: Active inference drives exploration to resolve uncertainty in model parameters when the likelihood mapping is incomplete.
- Mechanism: After structure learning, the agent has precise beliefs about state transitions but gaps in the likelihood tensor. By selecting actions that minimize expected free energy, the agent prioritizes novelty (expected information gain about parameters) and visits unexplored state-outcome combinations, thereby completing the likelihood mapping.
- Core assumption: The agent can control certain paths (actions) and has prior preferences that guide exploration toward informative regions of the state space.
- Evidence anchors:
  - [section 5] "To evince self-supervised learning... we simply allowed the agent to select actions on the basis of expected free energy that, initially, is dominated by the novelty or expected information gain pertaining to the likelihood parameters."
  - [section 5] "The agent now has the right structure and has discovered that there are three factors... However, the agent is far from having learned its generative model."
- Break condition: If the action space is too limited or the prior preferences are misaligned, the agent may not explore sufficiently to fill in the likelihood tensor.

## Foundational Learning

- Concept: Variational Free Energy as Evidence Lower Bound
  - Why needed here: It provides a tractable bound on model evidence that can be optimized during inference and learning, enabling the system to compare models and update beliefs.
  - Quick check question: Why is minimizing variational free energy equivalent to maximizing model evidence?

- Concept: Dirichlet Distributions for Parameter Uncertainty
  - Why needed here: Dirichlet distributions encode uncertainty over categorical parameters (e.g., likelihood mappings), allowing Bayesian updates as new data is observed and enabling model selection via Bayesian model reduction.
  - Quick check question: How do Dirichlet parameters accumulate counts of co-occurrences between latent states and outcomes?

- Concept: Active Inference and Expected Free Energy
  - Why needed here: Expected free energy extends variational free energy to future outcomes, balancing exploration (information gain) and exploitation (achieving preferred outcomes), which drives both model selection and active learning.
  - Quick check question: How does expected free energy decompose into risk and ambiguity components?

## Architecture Onboarding

- Component map: Generative model -> Inference engine -> Learning module -> Selection module -> Action selector

- Critical path:
  1. Receive observation.
  2. Infer latent states via variational message passing.
  3. Update Dirichlet parameters based on inferred states and observation.
  4. Evaluate parent vs. augmented model using free energy and expected free energy.
  5. Select best model and update structure if needed.
  6. If exploration needed, select actions to minimize expected free energy.

- Design tradeoffs:
  - Discrete vs. continuous state spaces: Discrete enables exact inference but may require high-dimensional tensors; continuous allows compact representations but needs differentiability and backpropagation.
  - Factorisation depth: More factors enable richer structure but increase computational complexity of message passing.
  - Prior strength: Strong priors speed convergence but may bias learning; weak priors allow flexibility but require more data.

- Failure signatures:
  - Model stops growing despite new data: Likely issue with free energy threshold or prior over models.
  - Inference fails to converge: Check tensor dimensions, message passing equations, or Dirichlet concentration parameters.
  - Poor classification accuracy: Insufficient training exemplars, overly sparse Dirichlet priors, or incorrect factorisation.

- First 3 experiments:
  1. Implement MNIST digit classification with minimal model (one style per digit) and verify structure learning adds styles as new exemplars arrive.
  2. Test dSprites-like object location learning, ensuring the model discovers horizontal and vertical factors and learns transitions via active exploration.
  3. Apply to Tower of Hanoi, verifying the model learns all allowable arrangements and transitions, then solves instances via planning.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the order of data presentation affect structure learning performance and what is the optimal curriculum for different types of generative models?
- Basis in paper: [explicit] The paper discusses how the order of data presentation (curriculum learning) is crucial for structure learning, particularly for learning dynamics and disentangling factors in discrete state-space models.
- Why unresolved: The paper provides examples of effective curricula for specific tasks (e.g., MNIST, dSprites, Tower of Hanoi) but does not explore the general principles or optimal strategies for designing curricula across diverse generative models and learning scenarios.
- What evidence would resolve it: Systematic experiments comparing different curriculum designs on a range of generative models and tasks, quantifying the impact on structure learning performance, and identifying common principles or heuristics for optimal curriculum design.

### Open Question 2
- Question: How can the active inference framework be extended to continuous state-space models, and what are the implications for expected free energy calculations over continuous trajectories?
- Basis in paper: [explicit] The paper acknowledges the potential advantages of continuous state-space models and mentions the challenge of extending the active inference framework to continuous domains, particularly for evaluating expected free energy over continuous trajectories.
- Why unresolved: The paper does not provide a concrete solution for extending active inference to continuous state-space models, and the mathematical challenges of computing expected free energy over continuous trajectories remain unaddressed.
- What evidence would resolve it: Development of a rigorous mathematical framework for active inference in continuous state-space models, including methods for approximating or computing expected free energy over continuous trajectories, and empirical validation of the approach on continuous control tasks or other relevant domains.

### Open Question 3
- Question: How does the performance of the proposed discrete state-space model approach compare to state-of-the-art machine learning methods on various tasks, and what are the trade-offs between the two approaches?
- Basis in paper: [explicit] The paper mentions that the classification accuracy achieved on MNIST is unremarkable compared to state-of-the-art methods, but does not provide a comprehensive comparison across different tasks and model architectures.
- Why unresolved: The paper focuses on the unique aspects of the discrete state-space model approach (e.g., structure learning, disentanglement) but does not thoroughly investigate its performance relative to other methods or explore the trade-offs in terms of accuracy, computational efficiency, interpretability, and other relevant metrics.
- What evidence would resolve it: Extensive empirical comparisons of the discrete state-space model approach with state-of-the-art methods (e.g., deep learning, Bayesian nonparametric models) on a variety of tasks (e.g., image classification, reinforcement learning, generative modeling), quantifying performance, computational requirements, and other relevant factors to identify the strengths and limitations of each approach.

## Limitations
- Computational intractability of tensor operations for large state spaces limits scalability to complex, high-dimensional data
- Discrete state-space representation may lose critical information when continuous features are important
- Dependence on sufficient exemplars for accurate Dirichlet updates and proper data ordering for learning correct dynamics

## Confidence
- Core claims regarding Bayesian model selection for structure learning under active inference: High confidence
- Scalability to complex, high-dimensional real-world data: Low confidence
- Claim that this approach mirrors biological learning mechanisms: Medium confidence

## Next Checks
1. Apply the method to MNIST with 100+ styles per digit and measure inference time and memory requirements to assess practical limits.

2. Implement a hybrid approach using discrete latent factors with continuous observation likelihoods (e.g., Gaussian mixtures) and compare performance to the purely discrete version on a real-world dataset.

3. Compare the learned structure and dynamics from the Tower of Hanoi experiment against human problem-solving trajectories to evaluate the claim of biological correspondence.