---
ver: rpa2
title: Natural Language Decomposition and Interpretation of Complex Utterances
arxiv_id: '2305.08677'
source_url: https://arxiv.org/abs/2305.08677
tags:
- utterances
- utterance
- complex
- program
- step
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces DECOMP, an approach for parsing complex natural
  language utterances into executable programs by decomposing them into a sequence
  of simpler steps. DECOMP leverages a large language model to break down complex
  commands into natural language steps that resemble elementary utterances, which
  are then parsed into program fragments using an existing NL-to-program model.
---

# Natural Language Decomposition and Interpretation of Complex Utterances

## Quick Facts
- arXiv ID: 2305.08677
- Source URL: https://arxiv.org/abs/2305.08677
- Reference count: 21
- The paper introduces DECOMP, an approach for parsing complex natural language utterances into executable programs by decomposing them into a sequence of simpler steps.

## Executive Summary
This paper introduces DECOMP, a novel approach for parsing complex natural language utterances into executable programs by decomposing them into a sequence of simpler steps. The method leverages a large language model to break down complex commands into natural language steps that resemble elementary utterances, which are then parsed into program fragments using an existing NL-to-program model. To evaluate this approach, the authors introduce DeCU, a new benchmark dataset containing both elementary and complex utterances for calendar and email management. Experiments on DeCU show that DECOMP outperforms direct few-shot prompting methods, achieving 35% correctness on complex utterances compared to 26% for the baseline.

## Method Summary
DECOMP maps a complex command to a sequence of interpretable lower-level natural language steps that resemble elementary utterances. Each step is then parsed independently using an existing NL-to-program model trained on elementary data. The approach uses in-context learning with dynamically selected examples from the elementary dataset, retrieved using BM25 similarity. The decomposition and program generation steps are interleaved, with later portions conditioned on earlier program fragments. This enables the system to handle structurally novel user requests without requiring large amounts of complex labeled data.

## Key Results
- DECOMP achieves 35% correctness on complex utterances compared to 26% for direct few-shot prompting baseline
- On elementary utterances, DECOMP achieves 61% correctness compared to 62% for baseline
- 51% of DECOMP predictions contain hallucinated functions or arguments, indicating room for improvement in parser control

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Decomposing complex utterances into simpler natural language steps enables the use of existing elementary parsers without retraining.
- **Mechanism**: The LLM breaks down a complex utterance into steps that resemble elementary utterances. Each step is then parsed independently using an existing NL-to-program model trained on elementary data.
- **Core assumption**: The elementary NL-to-program parser can handle the decomposed steps if they resemble elementary utterances.
- **Evidence anchors**: [abstract], [section 4.1]

### Mechanism 2
- **Claim**: In-context learning with dynamically selected examples from elementary data improves parsing accuracy for each step.
- **Mechanism**: For each decomposed step, the parser retrieves up to M most similar elementary examples using BM25 similarity and includes them in the prompt for the LLM.
- **Core assumption**: The similarity-based retrieval finds relevant examples that help the LLM generate correct program fragments.
- **Evidence anchors**: [section 4.2], [section 5.3]

### Mechanism 3
- **Claim**: Combining parametric knowledge (pre-training) with non-parametric knowledge (in-context examples) enables generalization to structurally novel user requests.
- **Mechanism**: The LLM uses its pre-trained knowledge of plans and reasoning plus the in-context examples to generate appropriate decompositions for requests it hasn't seen before.
- **Core assumption**: The pre-trained LLM has learned general patterns of task decomposition that transfer to the specific domain.
- **Evidence anchors**: [abstract], [section 4.1]

## Foundational Learning

- **Concept**: Few-shot in-context learning with LLMs
  - Why needed here: The approach relies on demonstrating decomposition patterns through examples in the prompt rather than fine-tuning the model.
  - Quick check question: What happens if you reduce the number of decomposition examples (K) from 10 to 2 in the prompt?

- **Concept**: Semantic parsing from natural language to executable programs
  - Why needed here: The core task is converting user utterances into programs that can be executed by the system's APIs.
  - Quick check question: How does the system handle references to previously generated program fragments (e.g., s1, s2 variables)?

- **Concept**: Retrieval-augmented generation with similarity search
  - Why needed here: The parser needs relevant examples from the elementary dataset to generate correct programs for each step.
  - Quick check question: What similarity metric is used to select examples from the elementary dataset, and why was it chosen?

## Architecture Onboarding

- **Component map**: User utterance → LLM decomposition → NL steps → Example retrieval (BM25) → LLM parsing → Program fragments → Assembled program
- **Critical path**: Complex utterance → Decomposition generation → Step-by-step parsing with example retrieval → Program assembly → Execution
- **Design tradeoffs**:
  - Using in-context learning vs. fine-tuning: Faster development but limited by context window size
  - Number of examples (K vs M): More examples improve accuracy but reduce context window for other components
  - Elementary vs. complex examples in prompts: Elementary examples help parser but complex examples help decomposition
- **Failure signatures**:
  - Low well-formed rate (52%): Parser generates syntactically invalid programs
  - High hallucination rate (51%): Parser invents non-existent functions or arguments
  - Partial intent capture: Generated program addresses only part of the user request
- **First 3 experiments**:
  1. Test with reduced number of decomposition examples (K=2) to see impact on parsing accuracy
  2. Test with random elementary examples instead of BM25-selected ones to validate retrieval importance
  3. Test with a simpler parser (text-davinci-001 instead of text-davinci-003) to establish baseline for LLM choice

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would DECOMP perform on domains with more complex program structures or APIs?
- Basis in paper: [inferred] The paper focuses on calendar and email management domains with relatively simple program structures.
- Why unresolved: The paper only evaluates DECOMP on DeCU dataset which focuses on calendar and email management.
- What evidence would resolve it: Testing DECOMP on domains with more complex APIs and program structures would provide evidence of its generalizability.

### Open Question 2
- Question: Can the quality of NL decomposition be further improved to reduce errors in the final program?
- Basis in paper: [explicit] The authors report that 51% of errors in DECOMP outputs are due to "Hallucination/Not found error" and 6% are "Partial User Intent" errors.
- Why unresolved: While the authors demonstrate that DECOMP outperforms the baseline, there is still room for improvement in the quality of NL decomposition.
- What evidence would resolve it: Developing methods to improve the quality of NL decomposition would provide evidence of their effectiveness.

### Open Question 3
- Question: How can the parser be constrained to only use allowed functions and reduce syntax/type errors?
- Basis in paper: [explicit] The authors note that roughly half of the predictions from DECOMP and DIRECT-PRED are not well-formed.
- Why unresolved: While the authors acknowledge the issue of syntax and type errors, they do not explore methods to constrain the parser to only use allowed functions.
- What evidence would resolve it: Implementing methods to constrain the parser to only use allowed functions would provide evidence of their effectiveness.

## Limitations

- The 35% correctness rate on complex utterances, while outperforming the baseline, remains relatively low and suggests the approach has not yet solved the fundamental challenge.
- The approach relies heavily on a hand-designed domain library with 33 types and over 200 functions, representing substantial engineering effort that may not generalize well.
- 51% of predictions contain hallucinated functions or arguments, indicating the LLM's generation process is not well-controlled.

## Confidence

**High Confidence**: The decomposition mechanism and basic evaluation methodology are well-established.
**Medium Confidence**: The in-context learning effectiveness shows promise but the 52% well-formed rate suggests significant room for improvement.
**Low Confidence**: The generalization claims are the weakest, given the relatively low correctness rates and heavy dependence on the domain library.

## Next Checks

1. **Ablation Study on Retrieval Component**: Remove the BM25-based example selection and replace with random elementary examples to quantify the specific contribution of the retrieval-augmented approach versus other factors like decomposition quality.

2. **Cross-Domain Generalization Test**: Apply DECOMP to a completely different domain (e.g., smart home commands) with minimal domain library modifications to assess whether the decomposition approach generalizes beyond calendar/email contexts.

3. **Scaling Analysis of Example Counts**: Systematically vary both the number of decomposition examples (K) and the number of elementary examples per step (M) to identify optimal configurations and understand the marginal value of additional context versus context window constraints.