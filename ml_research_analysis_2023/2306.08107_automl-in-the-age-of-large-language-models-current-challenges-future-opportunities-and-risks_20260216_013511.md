---
ver: rpa2
title: 'AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities
  and Risks'
arxiv_id: '2306.08107'
source_url: https://arxiv.org/abs/2306.08107
tags:
- automl
- learning
- llms
- language
- proceedings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores the potential of integrating Automated Machine
  Learning (AutoML) and Large Language Models (LLMs) to push the boundaries of both
  fields. The authors identify five main challenges in applying AutoML to LLMs: the
  high computational cost of pre-training, the complexity of optimizing across multiple
  stages of the LLM lifecycle, the difficulty in determining optimal neural architectures,
  the multitude of performance indicators, and the combination of different learning
  paradigms.'
---

# AutoML in the Age of Large Language Models: Current Challenges, Future Opportunities and Risks

## Quick Facts
- arXiv ID: 2306.08107
- Source URL: https://arxiv.org/abs/2306.08107
- Reference count: 12
- Primary result: Explores integration of AutoML and LLMs, identifying five main challenges and opportunities for mutual enhancement

## Executive Summary
This paper examines the intersection of Automated Machine Learning (AutoML) and Large Language Models (LLMs), highlighting both the challenges and opportunities that arise from their integration. The authors identify five key challenges in applying AutoML to LLMs: computational costs, multi-stage optimization complexity, neural architecture determination, multiple performance indicators, and combined learning paradigms. They also explore how LLMs can enhance AutoML through improved human-machine interaction, system configuration, and as components within AutoML pipelines. The paper concludes by discussing potential risks including evaluation challenges, false facts from hallucinations, trust issues, and resource consumption concerns.

## Method Summary
The paper takes a survey-based approach, reviewing existing literature on both AutoML and LLMs to identify challenges, opportunities, and risks at their intersection. Rather than presenting a specific experimental method, the authors synthesize findings from various studies to construct a comprehensive framework for understanding how these two fields can benefit from each other. The analysis covers the full lifecycle of LLMs from pre-training through inference, examining how AutoML techniques can be applied at each stage and how LLMs can serve as meta-learners or interface components for AutoML systems.

## Key Results
- AutoML faces significant computational challenges when applied to LLMs due to expensive pre-training and fine-tuning processes
- LLMs can serve as meta-learned performance estimators, replacing traditional neural performance predictors in AutoML pipelines
- The integration creates opportunities for natural language interfaces that can configure AutoML systems through conversational interaction
- Multiple risks exist including evaluation bias from data snooping, LLM hallucinations leading to false facts, and substantial resource consumption requirements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can serve as a meta-learned performance estimator in AutoML, replacing traditional neural performance predictors
- Mechanism: LLMs leverage their vast knowledge encoded from unstructured data to predict the performance of machine learning pipelines without explicit training on task-specific data
- Core assumption: The knowledge distilled in LLMs from their training corpus includes patterns about machine learning pipeline performance
- Evidence anchors:
  - [abstract] "LLMs offer a great opportunity to serve as a special form of meta-learned replacement based on knowledge extracted from large amount of unstructured data"
  - [section 3.3] "Once again, LLMs offer a great opportunity to serve as a special form of meta-learned replacement based on knowledge extracted from large amount of unstructured data, which is not accessible to standard meta-learned approaches"
- Break condition: If the LLM's knowledge doesn't generalize well to specific AutoML tasks or domains, predictions will be unreliable

### Mechanism 2
- Claim: LLMs can significantly improve human-machine interaction in AutoML by providing natural language interfaces
- Mechanism: The advanced NLP capabilities of LLMs enable conversational interfaces that can extract user requirements and configure AutoML systems accordingly
- Core assumption: Users can effectively communicate their ML needs through natural language dialogue
- Evidence anchors:
  - [abstract] "LLMs have the potential to alleviate this situation by allowing for significantly more powerful chatbots and better textual interaction with a user"
  - [section 3.1.1] "These can iteratively extract the requirements of a user across a conversation and, in the background, configure an AutoML system correspondingly"
- Break condition: If prompt engineering becomes a barrier to entry, defeating the democratization goal

### Mechanism 3
- Claim: LLMs can replace multiple AutoML sub-components, creating end-to-end automated systems
- Mechanism: LLMs can function as solution candidate selectors, architecture generators, and even full pipeline designers through iterative prompting
- Core assumption: LLMs can accurately evaluate and generate ML pipelines through contextual prompting
- Evidence anchors:
  - [section 3.3] "GPT-NAS (C. Yu et al., 2023) leverages a GPT model to predict (parts) of a neural architecture" and "GENIUS (Zheng et al., 2023) even goes a step further and replaces the whole architecture suggestion step with GPT-4"
  - [section 3.3] "Similarly, S. Zhang, Gong, et al. (2023) and L. Zhang et al. (2023) suggest AutoML-GPT and MLCopilot, respectively, which fully work as an zero-shot AutoML tool on their own"
- Break condition: If LLM-generated solutions consistently underperform compared to traditional AutoML methods

## Foundational Learning

- Concept: Multi-fidelity optimization
  - Why needed here: LLMs are computationally expensive to train, making traditional full-evaluation approaches infeasible
  - Quick check question: How does multi-fidelity optimization help reduce computational costs in LLM hyperparameter tuning?

- Concept: Neural Architecture Search (NAS)
  - Why needed here: Finding optimal architectures for LLMs is challenging and current NAS methods haven't produced groundbreaking architectures
  - Quick check question: What are the key limitations of current NAS approaches when applied to transformer-based models?

- Concept: Reinforcement Learning from Human Feedback (RLHF)
  - Why needed here: Alignment fine-tuning for LLMs uses RLHF, which poses unique challenges for AutoML systems
  - Quick check question: How does the non-stationary nature of RLHF data collection affect AutoML optimization?

## Architecture Onboarding

- Component map: User input → LLM configuration → AutoML execution → LLM evaluation/reporting
- Critical path: User input → LLM configuration → AutoML execution → LLM evaluation/reporting
- Design tradeoffs: Accuracy vs. computational cost of LLM queries, generalization vs. specialization of LLM knowledge, user control vs. automation
- Failure signatures: Incorrect AutoML configurations, unreliable performance predictions, excessive resource consumption
- First 3 experiments:
  1. Implement LLM as a performance predictor for simple classification tasks and compare against traditional meta-learners
  2. Create a conversational interface for AutoML configuration and measure user satisfaction vs. traditional configuration methods
  3. Replace the solution candidate selection component in an existing AutoML tool with an LLM-based approach and measure performance impact

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs effectively replace human experts in configuring AutoML systems, particularly in setting up search spaces and determining runtime?
- Basis in paper: [explicit] The paper discusses how LLMs could provide configurations for AutoML systems, including setting up search spaces and determining runtime.
- Why unresolved: The effectiveness of LLMs in replacing human experts for these tasks is not yet proven and requires further research and experimentation.
- What evidence would resolve it: Comparative studies between LLM-configured AutoML systems and those configured by human experts, measuring performance and efficiency.

### Open Question 2
- Question: How can we ensure the evaluation of AutoML approaches using LLMs is free from data snooping bias?
- Basis in paper: [explicit] The paper highlights the risk of data snooping when using publicly available data to evaluate AutoML approaches configured via LLMs.
- Why unresolved: Current methods to detect and remove prior knowledge of LLMs about datasets are not fully reliable, making unbiased evaluation challenging.
- What evidence would resolve it: Development of robust protocols for detecting and removing prior knowledge from LLMs, and successful application of these protocols in unbiased evaluations.

### Open Question 3
- Question: What are the potential risks of integrating LLMs into AutoML systems, and how can they be mitigated?
- Basis in paper: [explicit] The paper discusses several risks, including false facts from LLM hallucinations, trust issues, and resource consumption.
- Why unresolved: The full extent of these risks and effective mitigation strategies are not yet fully understood and require further investigation.
- What evidence would resolve it: Case studies and experiments demonstrating the impact of these risks in real-world scenarios, and the effectiveness of proposed mitigation strategies.

## Limitations

- Computational expense of LLM pre-training and fine-tuning makes standard AutoML approaches prohibitively expensive
- Risk of data snooping when using publicly available datasets for evaluation, as LLMs may have already been trained on this data
- Non-stationary nature of LLM data and combination of different learning paradigms create unique challenges for traditional AutoML methods

## Confidence

**High Confidence:**
- The computational challenges of applying AutoML to LLMs are well-documented and represent a fundamental barrier
- LLMs can serve as meta-learned performance estimators based on their knowledge extraction from unstructured data
- The need for multi-objective optimization across different stages of the LLM lifecycle is a real and significant challenge

**Medium Confidence:**
- LLMs can significantly improve human-machine interaction in AutoML through natural language interfaces
- LLMs can replace multiple AutoML sub-components to create end-to-end automated systems
- The risks associated with LLM integration (hallucinations, evaluation challenges, resource consumption) are substantial

**Low Confidence:**
- The specific mechanisms by which LLMs will overcome current AutoML limitations are still largely theoretical
- The extent to which LLMs can generalize their knowledge to specific AutoML tasks remains unproven
- The practical feasibility of implementing LLM-based AutoML systems at scale is uncertain

## Next Checks

1. Implement a comparative study of LLM-based performance prediction versus traditional meta-learners on a standardized AutoML benchmark, measuring both accuracy and computational overhead.

2. Conduct a user study comparing natural language AutoML configuration through LLMs versus traditional configuration interfaces, measuring task completion time, user satisfaction, and configuration accuracy.

3. Build a prototype that replaces the solution candidate selection component in an existing AutoML tool with an LLM-based approach, then evaluate the impact on solution quality, search efficiency, and resource consumption across multiple problem domains.