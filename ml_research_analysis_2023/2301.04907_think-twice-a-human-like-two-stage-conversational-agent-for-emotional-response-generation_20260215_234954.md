---
ver: rpa2
title: 'Think Twice: A Human-like Two-stage Conversational Agent for Emotional Response
  Generation'
arxiv_id: '2301.04907'
source_url: https://arxiv.org/abs/2301.04907
tags:
- emotion
- dialogue
- response
- emotional
- linguistics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of generating emotionally appropriate
  dialogue responses while maintaining semantic relevance, a challenge in current
  end-to-end emotional dialogue approaches due to the mutual restriction between emotion
  and semantics, and the lack of large-scale emotion-annotated dialogue corpora. The
  proposed method, inspired by human "think twice" behavior in dialogue, introduces
  a two-stage conversational agent.
---

# Think Twice: A Human-like Two-stage Conversational Agent for Emotional Response Generation

## Quick Facts
- arXiv ID: 2301.04907
- Source URL: https://arxiv.org/abs/2301.04907
- Reference count: 40
- Key outcome: Two-stage conversational agent achieves Acc scores of 57.36% and 65.42% on DailyDialog and EmpatheticDialogues datasets respectively while maintaining semantic quality

## Executive Summary
This paper addresses the challenge of generating emotionally appropriate dialogue responses while maintaining semantic relevance, a problem that current end-to-end emotional dialogue approaches struggle with due to the mutual restriction between emotion and semantics. The proposed solution is inspired by human "think twice" behavior in dialogue and implements a two-stage conversational agent that first generates a semantically coherent prototype response, then refines it with emotional modifications using rewriting and adding strategies. Experimental results show the approach outperforms comparison models in emotion generation while maintaining semantic performance, and effectively reduces the need for large-scale emotion-annotated dialogue corpora.

## Method Summary
The proposed two-stage conversational agent consists of a prototype response generator (DialoGPT-based) that produces semantically coherent responses from non-emotion-annotated dialogue data, and a controllable emotion refiner that modifies these responses based on detected contextual emotions. The refiner employs two human-inspired strategies: rewriting (replacing emotional words) and adding (appending extra sentences). The approach uses the empathy hypothesis to determine appropriate emotional responses and reduces the need for emotion-annotated dialogue corpora by training components on non-dialogue emotion data. A GLEU-based selector chooses between refined responses to balance emotional strength with semantic preservation.

## Key Results
- Achieves Acc scores of 57.36% and 65.42% on DailyDialog and EmpatheticDialogues datasets respectively
- Maintains semantic quality with BLEU-4 scores of 0.67 and 0.39 on the respective datasets
- Outperforms comparison models in both automatic and human evaluations across emotion generation and semantic maintenance metrics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Two-stage generation separates semantic coherence from emotional refinement, preventing mutual interference between emotion and semantics.
- Mechanism: The first stage generates a semantically coherent prototype using a pre-trained dialogue model, while the second stage applies a controllable emotion refiner that modifies the prototype based on detected contextual emotions without affecting the core semantics.
- Core assumption: Emotional refinement can be effectively decoupled from semantic generation without losing overall coherence.
- Evidence anchors: [abstract] "The proposed method effectively alleviates two problems of existing emotional dialogue approaches, i.e., weakening the emotion effect during the complex learning process and restricting the semantic generation to meet the emotion demand." [section] "However, current end-to-end emotional dialogue models still face several challenges. Firstly, in deep neural networks, the input emotion signals are often weakened through the complex learning process. Secondly, in the joint generation model, the design to enhance emotions often restricts the semantic performance of generated responses (e.g., safe responses)."

### Mechanism 2
- Claim: Empathy hypothesis-based emotion detection enables context-aware emotional refinement that mimics human empathetic response patterns.
- Mechanism: Dialogue emotion detector analyzes the entire dialogue context to determine the predominant emotional state, which is then used to guide the emotion refiner in adjusting the prototype response to match the speaker's emotional tone.
- Core assumption: Empathetic responses tend to align with the emotional state of the dialogue context.
- Evidence anchors: [abstract] "According to the empathy hypothesis, the type of generated emotion is consistent with the contextual emotional state." [section] "According to the empathy hypothesis, during emotional dialogues between two individuals, the listener usually tends to respond in a way that recognizes the speaker's feelings."

### Mechanism 3
- Claim: Human-inspired rewriting and adding strategies provide effective emotional refinement without requiring parallel emotion-annotated dialogue corpora.
- Mechanism: The rewrite module replaces emotional words/phrases in the prototype to match target emotions, while the add module appends extra sentences with the desired emotional tone, both leveraging pre-trained models trained on non-dialogue emotion corpora.
- Core assumption: Emotional expression can be effectively modified through targeted word replacement and sentence addition rather than complete reconstruction.
- Evidence anchors: [abstract] "The proposed two-stage conversational agent reduces the demand for the sizeable emotion-annotated dialogue corpus." [section] "The training of the prototype response generator in the first stage only requires general dialogue corpora without emotion annotation, and the controllable emotion dialogue refiner is trained on non-dialogue and non-parallel emotion-annotated corpora."

## Foundational Learning

- Concept: Transformer-based pre-training and fine-tuning
  - Why needed here: The prototype generator relies on DialoGPT, a Transformer-based model, and the emotion refiner uses Transformer architecture for both rewrite and add modules.
  - Quick check question: How does the attention mechanism in Transformer help capture long-range dependencies in dialogue context?

- Concept: Graph Convolutional Networks for dialogue emotion detection
  - Why needed here: The emotion detector uses DialogueGCN to model the emotional influence between utterances in a dialogue, which is crucial for determining appropriate response emotions.
  - Quick check question: How does the edge weight calculation in DialogueGCN capture the emotional influence between different utterances?

- Concept: Style transfer and controllable text generation
  - Why needed here: The rewrite and add modules implement controllable text generation to modify emotional style without changing semantic content, similar to techniques used in style transfer research.
  - Quick check question: What is the difference between attribute-conditioned generation and style transfer in natural language processing?

## Architecture Onboarding

- Component map: Context → Prototype Generator → Emotion Detector → Refiner (Rewrite/Add) → Selector → Final Response

- Critical path: The dialogue context flows through the prototype generator to create an initial response, then the emotion detector analyzes the context to determine appropriate emotional tone, which guides the refiner modules to modify the prototype, with the selector choosing the final output based on GLEU scoring.

- Design tradeoffs: Using pre-trained models reduces training data requirements but may introduce domain bias; two-stage approach adds complexity but enables better emotion-semantic separation; Selector based on GLEU favors semantic preservation over emotional strength.

- Failure signatures: Prototype generator producing generic responses indicates need for better fine-tuning; emotion detector misclassifying emotions suggests inadequate training data or model architecture issues; rewrite/add modules producing incoherent text indicates problems with the controlled generation approach.

- First 3 experiments: 1) Test prototype generator alone on DailyDialog test set to establish baseline semantic performance; 2) Evaluate emotion detector accuracy on validation set to verify empathy hypothesis implementation; 3) Compare rewrite vs add module performance on a small sample to determine which strategy works better for different emotion types.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the two-stage approach affect long-term dialogue coherence and emotional consistency across multiple turns?
- Basis in paper: [explicit] The paper evaluates the model on single-turn responses but does not address multi-turn dialogue scenarios or long-term emotional consistency
- Why unresolved: The current evaluation focuses on isolated responses without examining how the emotional modifications propagate through extended conversations
- What evidence would resolve it: Comparative studies on multi-turn dialogues measuring emotional drift and semantic coherence over multiple exchanges

### Open Question 2
- Question: What is the optimal balance between rewriting and adding strategies for different types of emotional expressions?
- Basis in paper: [inferred] The paper mentions both strategies but doesn't systematically analyze when each approach is most effective or how to determine the optimal mix
- Why unresolved: The Selector mechanism uses GLEU score but doesn't explore whether different emotion types or intensity levels might require different strategy weights
- What evidence would resolve it: Ablation studies varying the rewrite/add ratio across different emotion categories and intensity levels

### Open Question 3
- Question: How would the approach scale to more nuanced or mixed emotional states beyond binary positive/negative classification?
- Basis in paper: [explicit] The paper reduces emotions to binary categories and mentions 32 emotions in EmpatheticDialogues but only uses binary classification
- Why unresolved: The paper doesn't explore whether the two-stage approach would work with multi-dimensional emotion representations or complex emotional states
- What evidence would resolve it: Experiments using multi-dimensional emotion embeddings or fine-grained emotion categories to test scalability of the approach

### Open Question 4
- Question: What are the limitations of the empathy hypothesis in contexts where emotional mimicry might be inappropriate or counterproductive?
- Basis in paper: [explicit] The paper explicitly adopts the empathy hypothesis but doesn't explore situations where emotional matching might be suboptimal
- Why unresolved: The paper assumes emotional consistency with context is always beneficial without examining edge cases or cultural differences in emotional expression
- What evidence would resolve it: Analysis of dialogue contexts where emotional divergence from the context leads to better outcomes or user satisfaction

## Limitations
- The approach's performance on more diverse, open-domain conversations beyond DailyDialog and EmpatheticDialogues remains unclear
- The GLEU-based selector may systematically favor semantic preservation over emotional intensity, potentially limiting the approach's ability to generate strongly emotional responses when needed
- The effectiveness of the emotion refiner modules heavily depends on the quality of the emotion detector, which is not thoroughly evaluated independently

## Confidence
- **High Confidence**: The core claim that separating semantic generation from emotional refinement can prevent mutual interference is well-supported by both theoretical reasoning and experimental results showing improved Acc and BLEU-4 scores.
- **Medium Confidence**: The assertion that this approach reduces the need for large-scale emotion-annotated dialogue corpora is plausible but requires further validation, as the emotion refiner still requires substantial emotion-annotated data for training.
- **Low Confidence**: The claim about human-like "think twice" behavior being accurately modeled by this two-stage process is more metaphorical than empirically validated, lacking direct comparisons to actual human response patterns.

## Next Checks
1. **Independent Emotion Detector Evaluation**: Evaluate the dialogue emotion detector's accuracy on a held-out validation set before integrating it with the refiner to establish baseline performance and identify potential failure modes.
2. **Cross-Dataset Generalization Test**: Test the model on an additional emotional dialogue dataset not seen during training to assess whether the two-stage approach generalizes beyond DailyDialog and EmpatheticDialogues.
3. **Ablation Study on Selector Strategy**: Compare GLEU-based selection against alternative strategies (e.g., emotion intensity maximization or hybrid approaches) to determine if the current selector might be overly conservative in emotional refinement.