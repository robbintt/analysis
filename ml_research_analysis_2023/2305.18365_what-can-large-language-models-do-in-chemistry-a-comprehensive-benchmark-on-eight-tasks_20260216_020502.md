---
ver: rpa2
title: What can Large Language Models do in chemistry? A comprehensive benchmark on
  eight tasks
arxiv_id: '2305.18365'
source_url: https://arxiv.org/abs/2305.18365
tags:
- tasks
- prediction
- chemistry
- molecule
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates large language models (LLMs) like GPT-4, GPT-3.5,
  and Davinci-003 on eight practical chemistry tasks, including name prediction, property
  prediction, yield prediction, reaction prediction, retrosynthesis, text-based molecule
  design, and molecule captioning. The authors carefully designed prompts and utilized
  in-context learning with demonstration examples.
---

# What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks

## Quick Facts
- arXiv ID: 2305.18365
- Source URL: https://arxiv.org/abs/2305.18365
- Reference count: 40
- Primary result: GPT-4 outperforms other models on chemistry tasks, with strong capabilities in text-related explanation tasks but struggles with precise understanding of molecular SMILES representation.

## Executive Summary
This paper comprehensively evaluates large language models (GPT-4, GPT-3.5, and Davinci-003) on eight practical chemistry tasks using carefully designed prompts and in-context learning. The authors find that GPT-4 demonstrates superior performance across most tasks, particularly excelling at text-based explanations like molecule captioning. However, the models show significant limitations when dealing with molecular SMILES representations, especially for reaction prediction and retrosynthesis tasks. The study highlights both the potential and current limitations of LLMs in chemistry applications.

## Method Summary
The authors evaluate five LLMs across eight chemistry tasks using both zero-shot and few-shot in-context learning settings. They carefully select demonstration examples and perform grid search on validation sets to optimize prompts. Datasets from multiple sources (BBBP, Tox21, PubChem, USPTO, ChEBI) are used across different tasks. Performance is measured using task-specific metrics including accuracy, F1 score, BLEU, ROUGE, and chemical validity checks. Five repeated evaluations are conducted for each task to ensure reliability.

## Key Results
- GPT-4 outperforms GPT-3.5 and Davinci-003 across most chemistry tasks
- GPT models show strong capabilities in text-related explanation tasks like molecule captioning
- GPT models struggle with tasks requiring precise understanding of molecular SMILES representation
- In-context learning significantly improves performance compared to zero-shot prompting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 outperforms other models due to its superior ability to understand and generate text-based explanations in chemistry tasks.
- Mechanism: GPT-4's enhanced language understanding allows it to perform better on tasks like molecule captioning and text-based molecule design, where textual explanation is key.
- Core assumption: GPT-4 has a better grasp of natural language and can generate more accurate and relevant text-based outputs.
- Evidence anchors:
  - [abstract] "GPT models exhibit strong capabilities in text-related explanation tasks such as molecule captioning"
  - [section] "GPT-4 outperforms the other two models among the three evaluated"
- Break condition: If the task requires precise understanding of molecular SMILES representation, GPT-4's advantage diminishes.

### Mechanism 2
- Claim: GPT models struggle with tasks requiring precise understanding of molecular SMILES representation.
- Mechanism: The complexity of SMILES strings and the lack of inherent understanding of molecular structures by GPT models lead to inaccuracies in tasks like reaction prediction and retrosynthesis.
- Core assumption: GPT models treat SMILES strings as sequences of characters without understanding their molecular significance.
- Evidence anchors:
  - [abstract] "GPT models exhibit less competitive performance in tasks demanding precise understanding of molecular SMILES representation, such as reaction prediction and retrosynthesis"
  - [section] "A significant limitation of LLMs is their lack of understanding of molecular representations in SMILES strings"
- Break condition: If GPT models are provided with tools or additional context to interpret SMILES strings, their performance may improve.

### Mechanism 3
- Claim: In-context learning (ICL) improves GPT model performance by providing relevant examples.
- Mechanism: ICL allows GPT models to learn from demonstration examples, enhancing their ability to perform specific tasks.
- Core assumption: The quality and relevance of ICL examples directly impact the model's performance.
- Evidence anchors:
  - [abstract] "Five LLMs... are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstration examples"
  - [section] "In-context learning (ICL) achieves a significantly better performance than zero-shot prompting"
- Break condition: If the ICL examples are not relevant or of high quality, the performance gain may be minimal.

## Foundational Learning

- Concept: Molecular representations (SMILES, IUPAC names, molecular formulas)
  - Why needed here: Understanding different molecular representations is crucial for evaluating GPT models' ability to handle chemistry tasks.
  - Quick check question: What are the differences between SMILES, IUPAC names, and molecular formulas?

- Concept: In-context learning (ICL)
  - Why needed here: ICL is a key method used in the paper to evaluate GPT models' performance in chemistry tasks.
  - Quick check question: How does ICL differ from zero-shot prompting in terms of GPT model performance?

- Concept: Evaluation metrics for chemistry tasks
  - Why needed here: Different tasks require different metrics to assess model performance accurately.
  - Quick check question: What are the appropriate evaluation metrics for tasks like molecule captioning and reaction prediction?

## Architecture Onboarding

- Component map: GPT models (GPT-4, GPT-3.5, Davinci-003) -> Chemistry tasks (name prediction, property prediction, yield prediction, reaction prediction, retrosynthesis, text-based molecule design, molecule captioning, reagents selection) -> Datasets (BBBP, Tox21, PubChem, USPTO, ChEBI) -> Evaluation metrics (accuracy, F1 score, BLEU, ROUGE, etc.) -> ICL strategies (random sampling, scaffold similarity)

- Critical path:
  1. Define chemistry tasks and select datasets.
  2. Design prompts and ICL examples.
  3. Evaluate GPT models using zero-shot and ICL settings.
  4. Analyze results and compare with baselines.

- Design tradeoffs:
  - Zero-shot vs. ICL: Zero-shot is faster but less accurate; ICL is slower but more effective.
  - Random vs. scaffold sampling: Random is simpler but scaffold similarity may provide better examples.

- Failure signatures:
  - Poor performance on SMILES-related tasks indicates a lack of understanding of molecular structures.
  - Low accuracy in property prediction suggests issues with the model's ability to interpret chemical properties.

- First 3 experiments:
  1. Evaluate GPT-4 on name prediction tasks to assess its understanding of molecular representations.
  2. Test GPT models on property prediction tasks to compare their performance with classical ML models.
  3. Analyze the impact of ICL strategies on reaction prediction tasks to determine the best approach for example selection.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can GPT models be effectively fine-tuned on chemistry-specific datasets to improve their performance on tasks like reaction prediction and retrosynthesis?
- Basis in paper: [inferred] The paper notes that GPT models underperform compared to baselines in tasks requiring deep understanding of SMILES strings, suggesting a need for improved model training approaches.
- Why unresolved: The study only evaluated few-shot in-context learning and zero-shot prompting, not full fine-tuning on chemistry datasets.
- What evidence would resolve it: Comparing the performance of fine-tuned GPT models against current baselines on reaction prediction and retrosynthesis tasks.

### Open Question 2
- Question: What specific modifications to GPT architecture or tokenization could improve understanding of molecular SMILES representations?
- Basis in paper: [explicit] The paper identifies limitations in GPT's understanding of SMILES strings, particularly regarding implicit hydrogen atoms and multiple valid representations for the same molecule.
- Why unresolved: The study did not experiment with architectural modifications or alternative tokenization methods for chemistry-specific tasks.
- What evidence would resolve it: Testing modified GPT architectures or specialized tokenization schemes on chemistry tasks and comparing performance to standard GPT models.

### Open Question 3
- Question: How can chemistry-specific evaluation metrics be developed to better assess GPT models' performance on molecule generation and captioning tasks?
- Basis in paper: [explicit] The paper notes that traditional NLP metrics like BLEU and exact match don't fully capture the quality of chemistry-related outputs, particularly for molecular design tasks.
- Why unresolved: Current evaluation relies on NLP metrics that may not align with chemistry-specific requirements for exact matching and chemical validity.
- What evidence would resolve it: Development and validation of new metrics that incorporate chemical validity, novelty, and functional requirements alongside traditional NLP measures.

## Limitations

- The study only evaluates a limited set of LLMs (GPT-4, GPT-3.5, Davinci-003) without exploring other specialized chemistry models
- Performance limitations on SMILES-based tasks remain unexplained - unclear whether due to tokenization, training data bias, or fundamental architectural constraints
- The paper lacks quantitative measures of hallucination frequency and severity across tasks

## Confidence

**High Confidence:** GPT-4 outperforms GPT-3.5 and Davinci-003 across most tasks
**Medium Confidence:** GPT models struggle with SMILES-based tasks, but underlying mechanisms remain speculative
**Medium Confidence:** In-context learning effectiveness is demonstrated, but optimal demonstration selection strategy shows only marginal differences

## Next Checks

1. Conduct systematic hallucination analysis across all tasks to quantify frequency and severity of chemically invalid outputs
2. Perform controlled experiments varying SMILES tokenization strategies to isolate whether performance gaps stem from tokenization or architectural limitations
3. Evaluate GPT models against dedicated chemistry models (graph neural networks, traditional QSAR models) to establish whether LLMs provide genuine advantages beyond existing approaches