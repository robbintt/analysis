---
ver: rpa2
title: Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot Translation
arxiv_id: '2309.16599'
source_url: https://arxiv.org/abs/2309.16599
tags:
- translation
- language
- training
- https
- online
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the off-target problem in zero-shot neural
  machine translation, where language IDs fail to effectively guide the model, leading
  to the generation of non-target language words. The authors identify that the root
  cause lies in the gap between the training and inference processes, specifically
  the exposure bias issue.
---

# Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot Translation

## Quick Facts
- arXiv ID: 2309.16599
- Source URL: https://arxiv.org/abs/2309.16599
- Reference count: 40
- Improves zero-shot translation by 9.1 BLEU score while reducing off-target ratio by 48.0%

## Executive Summary
This paper addresses the off-target problem in zero-shot neural machine translation, where language IDs fail to guide models effectively, causing generation of non-target language words. The authors identify exposure bias between training and inference as the root cause, where decoder inputs shift from ground-truth during training to model-generated outputs during inference. Through analysis of contextual word representations, they discover that language ID effectiveness depends on alignment between language ID and decoder input. To address this, they propose unlikelihood tuning on negative samples (language- and ID-mismatched samples) during training, enabling language IDs to discriminate between on- and off-target tokens. The UNIONS method achieves significant improvements across 40 zero-shot translation directions.

## Method Summary
The method involves pretraining a multilingual NMT model, then fine-tuning it with a combined objective: maximizing likelihood on supervised translation data while minimizing likelihood (unlikelihood) on negative samples. Negative samples are constructed by replacing target language IDs with random off-target language IDs. The final model is selected based on contextual word representation (CWR) separation degree in zero-shot off-target settings. This approach teaches language IDs to recognize and avoid off-target tokens during generation.

## Key Results
- Reduces off-target ratio by 48.0% on average across 40 zero-shot translation directions
- Improves translation quality by 9.1 BLEU score in zero-shot settings
- Maintains or improves supervised translation performance while enhancing zero-shot capabilities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Language IDs lose navigation ability when decoder input is off-target
- Mechanism: Contextual word representations (CWRs) from mismatched ID+input pairs become chaotically distributed, while matched pairs remain well-separated
- Core assumption: The model's representation space preserves language distinctions when training and inference conditions align
- Evidence anchors:
  - CWRs of different languages are well-separated when the language ID and decoder input match (on-target setting), but become chaotic when they mismatch (off-target setting)
  - The CWRs of different languages are effectively distributed in separate regions when the sentence and ID are matched (ON setting), and if the sentence and ID are unmatched (OFF setting), the CWRs of different languages are chaotically distributed
- Break condition: If CWR separation is not the primary mechanism for language navigation, or if other factors dominate the off-target problem

### Mechanism 2
- Claim: Minimizing probability of negative (off-target) samples teaches language IDs to discriminate between on/off-target tokens
- Mechanism: Unlikelihood tuning on negative samples forces the model to assign lower probability to wrong-language outputs
- Core assumption: The model can learn to distinguish between correct and incorrect language outputs through explicit negative sampling
- Evidence anchors:
  - We employ unlikelihood tuning on the negative (OFF) samples to minimize their probability such that the language IDs can discriminate between the on- and off-target tokens
  - We optimize the unlikelihood objective on these negative samples to minimize their probability and simultaneously optimize the MNMT objective on the (positive) translation samples
- Break condition: If the model cannot effectively learn from negative samples, or if negative sampling introduces instability

### Mechanism 3
- Claim: Exposure bias between training and inference creates the off-target problem
- Mechanism: During training, decoder input is ground-truth (on-target), but during inference, it's model-generated (potentially off-target), creating a distribution shift
- Core assumption: The gap between training and inference conditions is the root cause of the navigation failure
- Evidence anchors:
  - During training, the decoder input is the ground-truth target language words, but during inference, it is the model's own generated words, which may be off-target
  - We show that the gap between the MNMT training and ZST inference processes is a crucial cause of the terrible off-target problem
- Break condition: If other factors (e.g., spurious correlations, missing ingredients) are more significant than exposure bias

## Foundational Learning

- Concept: Contextual Word Representations (CWRs)
  - Why needed here: Understanding how language IDs navigate translation through representation space separation
  - Quick check question: How do CWRs change when language ID and decoder input are mismatched vs. matched?

- Concept: Unlikelihood Training
  - Why needed here: The core technique for teaching the model to avoid wrong-language outputs
  - Quick check question: How does unlikelihood training differ from standard maximum likelihood training in practice?

- Concept: Exposure Bias
  - Why needed here: Explains why the off-target problem occurs in the first place
  - Quick check question: What's the key difference between training and inference conditions that creates exposure bias?

## Architecture Onboarding

- Component map:
  Encoder -> Decoder -> Language ID + Negative Sample Generator -> Combined Likelihood + Unlikelihood Loss

- Critical path:
  1. Load pretrained MNMT model
  2. Generate negative samples by replacing target ID with random other language ID
  3. Train with combined likelihood (positive samples) and unlikelihood (negative samples) objectives
  4. Select final model based on CWR separation degree

- Design tradeoffs:
  - Using random negative samples vs. more sophisticated negative sampling strategies
  - Balancing likelihood and unlikelihood loss weights
  - Computational cost of CWR separation degree calculation for model selection

- Failure signatures:
  - No improvement in OTR scores after tuning
  - Decreased supervised translation performance
  - Unstable training dynamics with unlikelihood loss

- First 3 experiments:
  1. Verify CWR visualization shows separation in on-target vs. chaos in off-target settings
  2. Test unlikelihood tuning with different negative sample ratios (10%, 50%, 100%)
  3. Compare model selection using CWR separation vs. validation loss on supervised directions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of UNIONS vary across different language families and what are the underlying mechanisms?
- Basis in paper: The paper mentions that UNIONS is more effective for target languages similar to English and discusses the influence of language similarity on performance.
- Why unresolved: The paper does not provide a detailed analysis of the effectiveness of UNIONS across different language families or the underlying mechanisms that contribute to this variation.
- What evidence would resolve it: Conducting experiments with a diverse set of language families and analyzing the performance of UNIONS across these families would provide insights into its effectiveness and the underlying mechanisms.

### Open Question 2
- Question: How does the model selection strategy based on CWR separation degree impact the final performance of UNIONS?
- Basis in paper: The paper mentions that the final model is selected based on the CWR separation degree in the zero-shot off-target setting.
- Why unresolved: The paper does not provide a detailed analysis of how the model selection strategy impacts the final performance of UNIONS or compare it with other model selection strategies.
- What evidence would resolve it: Conducting experiments with different model selection strategies and comparing their impact on the final performance of UNIONS would provide insights into the effectiveness of the proposed model selection strategy.

### Open Question 3
- Question: How does the performance of UNIONS vary with different sizes of training data and model architectures?
- Basis in paper: The paper mentions that UNIONS is evaluated on different benchmarks with varying sizes of training data and model architectures.
- Why unresolved: The paper does not provide a detailed analysis of how the performance of UNIONS varies with different sizes of training data and model architectures or identify the optimal settings for different scenarios.
- What evidence would resolve it: Conducting experiments with different sizes of training data and model architectures and analyzing the performance of UNIONS would provide insights into its scalability and the optimal settings for different scenarios.

## Limitations
- The paper lacks ablation studies to confirm whether CWR separation is the causal mechanism rather than a correlation
- Evaluation focuses primarily on zero-shot performance without comprehensive analysis of potential negative transfer to supervised translation directions
- The analysis doesn't systematically explore alternative causes beyond exposure bias, such as spurious correlations in pretraining data

## Confidence

**Low** - The central claim about CWR separation as the mechanism for language navigation lacks direct experimental validation. While the authors present visualizations suggesting CWRs are well-separated in on-target settings and chaotic in off-target settings, there's no ablation study showing whether improving CWR separation actually causes better off-target performance. The relationship could be correlational rather than causal.

**Medium** - The unlikelihood tuning method shows promising results, but the paper doesn't adequately address potential negative transfer to supervised translation directions. The evaluation focuses primarily on zero-shot performance, leaving open the question of whether the method might degrade performance on high-resource language pairs.

**Medium** - The paper claims exposure bias as the root cause, but doesn't systematically compare against other potential causes like spurious correlations in pretraining data or architectural limitations. The analysis could be missing other important factors contributing to the off-target problem.

## Next Checks

1. **Ablation Study on CWR Separation**: Create a control experiment where CWRs are explicitly regularized to be well-separated during training, but without the unlikelihood tuning component. If this produces similar off-target improvements, it would suggest CWR separation is the primary mechanism rather than the unlikelihood approach itself.

2. **Supervised Translation Impact Analysis**: Conduct a comprehensive evaluation of the UNIONS method on all supervised translation directions in the multilingual dataset, not just the zero-shot ones. This would reveal whether there are hidden costs to the approach that weren't captured in the current evaluation.

3. **Alternative Negative Sampling Strategies**: Test whether the improvements are specific to the random negative sampling approach or whether more sophisticated negative sampling (e.g., hard negatives, curriculum-based sampling) would yield better or different results. This would help determine if the method is robust to sampling strategy choices.