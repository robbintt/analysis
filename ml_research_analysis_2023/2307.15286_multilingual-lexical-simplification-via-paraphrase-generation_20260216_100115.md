---
ver: rpa2
title: Multilingual Lexical Simplification via Paraphrase Generation
arxiv_id: '2307.15286'
source_url: https://arxiv.org/abs/2307.15286
tags:
- word
- methods
- complex
- multilingual
- languages
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a multilingual lexical simplification method
  using paraphrase generation. The method leverages a multilingual neural machine
  translation system (NLLB) to generate paraphrases, treating it as a zero-shot translation
  task within the multilingual NMT.
---

# Multilingual Lexical Simplification via Paraphrase Generation

## Quick Facts
- arXiv ID: 2307.15286
- Source URL: https://arxiv.org/abs/2307.15286
- Reference count: 40
- Primary result: Introduces multilingual lexical simplification using NLLB-based paraphrase generation, achieving state-of-the-art performance across English, Spanish, and Portuguese

## Executive Summary
This paper presents a novel approach to multilingual lexical simplification that leverages a multilingual neural machine translation system (NLLB) for paraphrase generation. By treating paraphrase generation as a zero-shot translation task where input and output languages match, the method generates lexical variations of complex words while preserving sentence meaning. The approach addresses key limitations of existing methods by focusing specifically on lexical variations and using a decoding strategy that incorporates contextual information through a lookahead heuristic.

## Method Summary
The method uses NLLB as a paraphraser by configuring it for zero-shot translation where input and output languages are identical. A novel decoding strategy forces the decoder to begin with the prefix of the complex word, then re-scores candidates using a lookahead heuristic that incorporates suffix word probabilities. Generated substitutes are ranked using a weighted combination of prediction probability, word frequency, and semantic similarity between the complex word and candidate. The approach is evaluated on the TSAR-2022 benchmark across English, Spanish, and Portuguese.

## Key Results
- Significantly outperforms BERT-based methods and zero-shot GPT3-based approaches on multilingual lexical simplification
- Demonstrates strong performance across English, Spanish, and Portuguese
- Shows that NLLB-based paraphrase generation effectively addresses the lexical simplification task while preserving sentence meaning
- Validates the effectiveness of the prefix-based decoding strategy with lookahead heuristic

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Using multilingual NMT as a paraphraser enables zero-shot generation of substitutes across multiple languages without needing separate pretrained models.
- Mechanism: By configuring the output language to match the input language, the NMT system generates paraphrases directly, which are then filtered to extract lexical variations of the complex word.
- Core assumption: Paraphrases preserve the sentence meaning while providing diverse word choices, and the NMT model can be repurposed for paraphrase generation.
- Evidence anchors:
  - [abstract]: "We regard paraphrasing as a zero-shot translation task within multilingual neural machine translation that supports hundreds of languages."
  - [section 1]: "By configuring the output language to correspond with the input language, multilingual NMT can generate paraphrases directly, overcoming the first limitation."
  - [corpus]: Weak evidence; only one related paper directly addresses paraphrase generation for lexical substitution.
- Break condition: If the NMT model does not preserve sentence meaning in paraphrases, the generated substitutes may not be valid replacements.

### Mechanism 2
- Claim: The decoding strategy that starts with the prefix of the complex word and uses a lookahead heuristic ensures the generated substitutes are contextually appropriate.
- Mechanism: The decoder is forced to begin with the prefix of the complex word, generating a probability distribution for the word's position, then re-scoring candidates by incorporating the likelihood of generating the suffix words.
- Core assumption: The NMT model's probability distribution accurately reflects the contextual fit of the candidate word with the rest of the sentence.
- Evidence anchors:
  - [section 2]: "After feeding the sentence x into the encoder of Multilingual NMT, we force the decoder to begin with prefix x<c of complex word, and decode succeeding token distribution pθ(yc|y<c = x<c, x)."
  - [section 2]: "Inspired by Lu[19], we incorporate an extended estimate for the original suffix into our scoring function, replacing Equation (1) with: Yc = arg topK {log pθ(yc|y<c, x) + log pθ(y>c|y<c, yc, x)}"
  - [corpus]: Weak evidence; no direct corpus evidence for the effectiveness of this specific decoding strategy.
- Break condition: If the lookahead heuristic does not improve the contextual fit, the generated substitutes may be semantically coherent but not contextually appropriate.

### Mechanism 3
- Claim: Ranking substitutes using frequency, embedding similarity, and prediction probability selects the most appropriate simpler word.
- Mechanism: The final score for each substitute is calculated as a weighted sum of the three features: prediction probability, word frequency, and semantic similarity between the complex word and the candidate.
- Core assumption: Higher frequency words are simpler, and embedding similarity reflects semantic closeness.
- Evidence anchors:
  - [section 2]: "Word frequency feature calculated by large corpus is often used to measure the complexity of the substitutes."
  - [section 2]: "We give one simple ranking method that uses three features with different weights to rank the generated substitutes: (1) prediction feature using Equation (2), (2) Word Frequency, and (3) semantic similarity (cosine similarity between the word embedding vector of the complex word and the candidate)."
  - [corpus]: Weak evidence; no direct corpus evidence for the effectiveness of this specific ranking method.
- Break condition: If the weighting of features is not optimal, the ranking may not select the simplest and most appropriate substitute.

## Foundational Learning

- Concept: Neural Machine Translation (NMT) and its encoder-decoder framework
  - Why needed here: Understanding how NMT models work is crucial for repurposing them as paraphrasers.
  - Quick check question: How does the encoder-decoder framework in NMT models facilitate paraphrase generation?

- Concept: Zero-shot learning in NMT
  - Why needed here: The method relies on the ability of NMT to translate between languages without direct parallel data.
  - Quick check question: What enables zero-shot translation in multilingual NMT models?

- Concept: Word embeddings and semantic similarity
  - Why needed here: The ranking of substitutes depends on the semantic similarity between the complex word and the candidates.
  - Quick check question: How is semantic similarity between words typically measured using word embeddings?

## Architecture Onboarding

- Component map:
  Input sentence with complex word -> NLLB multilingual NMT encoder -> Decoder with prefix constraint -> Lookahead heuristic re-scoring -> Ranking module (frequency, embedding similarity, prediction probability) -> Output ranked substitutes

- Critical path:
  1. Input sentence and complex word
  2. NMT encoder processes the sentence
  3. Decoder generates candidates starting with the prefix of the complex word
  4. Lookahead heuristic re-scores candidates
  5. Ranking module selects the top substitutes
  6. Output the ranked list

- Design tradeoffs:
  - Using NMT as paraphraser vs. dedicated paraphrase models: NMT supports more languages but may not be optimized for paraphrase quality
  - Ranking with multiple features vs. simpler methods: More features may improve accuracy but increase complexity
  - Zero-shot approach vs. few-shot or supervised methods: Zero-shot is more scalable but may be less accurate

- Failure signatures:
  - Generated substitutes are semantically coherent but not contextually appropriate: Issue with decoding strategy or lookahead heuristic
  - Generated substitutes do not preserve the sentence meaning: Issue with the NMT paraphraser or the ranking method
  - Method does not scale well to low-resource languages: Issue with the NMT model's performance on those languages

- First 3 experiments:
  1. Evaluate the paraphrasing quality of the NMT model on a held-out test set
  2. Test the decoding strategy with and without the lookahead heuristic to measure its impact on contextual appropriateness
  3. Experiment with different weights for the ranking features to find the optimal combination for selecting the simplest and most appropriate substitute

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the multilingual lexical simplification method vary with different sizes of the multilingual NMT model (0.6B, 1.3B, 3.3B, 55.3B)?
- Basis in paper: [explicit] The paper discusses the impact of model size on performance and compares the results of different model sizes.
- Why unresolved: The paper only compares the performance of the first three models due to hardware limitations, leaving the impact of the largest model (55.3B) unexplored.
- What evidence would resolve it: Conducting experiments with the 55.3B model and comparing its performance with the smaller models would provide insights into the impact of model size on multilingual lexical simplification.

### Open Question 2
- Question: What is the optimal length of the estimated suffix in the decoding strategy for generating substitutes of the complex word?
- Basis in paper: [explicit] The paper discusses the effect of the estimated suffix length on the performance of the decoding strategy and mentions that estimating two or three suffix words produces optimal results.
- Why unresolved: The paper does not provide a definitive answer on the optimal length of the estimated suffix, leaving room for further investigation.
- What evidence would resolve it: Conducting experiments with different lengths of the estimated suffix and comparing their impact on the performance of the decoding strategy would help determine the optimal length.

### Open Question 3
- Question: How does the proposed multilingual lexical simplification method perform on low-resource languages?
- Basis in paper: [explicit] The paper mentions that the proposed method is advantageous for low-resource languages but does not provide specific results or comparisons for such languages.
- Why unresolved: The paper does not provide empirical evidence or detailed analysis of the method's performance on low-resource languages.
- What evidence would resolve it: Conducting experiments on low-resource languages and comparing the performance of the proposed method with other approaches would provide insights into its effectiveness in such scenarios.

## Limitations
- The optimal weights for ranking features are not explicitly specified, requiring additional tuning for different languages
- The method's effectiveness on truly low-resource languages remains untested despite theoretical advantages
- Hardware limitations prevented testing with the largest NLLB model (55.3B), leaving questions about scaling benefits unanswered

## Confidence

- High Confidence: The core mechanism of using multilingual NMT as a paraphraser is well-established in the literature and the paper provides clear theoretical justification
- Medium Confidence: The effectiveness of the novel decoding strategy and the lookahead heuristic is supported by the paper's results but lacks extensive ablation studies or comparison with alternative decoding approaches
- Low Confidence: The optimal weights for the ranking features are not specified, and their impact on the final performance is not thoroughly analyzed

## Next Checks

1. Reproduce Results: Implement the method and evaluate its performance on the TSAR-2022 benchmark to verify the claimed improvements over BERT-based and zero-shot GPT3-based methods
2. Ablation Study: Conduct an ablation study to assess the individual contributions of the decoding strategy, lookahead heuristic, and ranking features to the overall performance
3. Cross-Lingual Generalization: Test the method on a wider range of languages, including low-resource languages, to validate its multilingual scalability and identify potential limitations