---
ver: rpa2
title: Collaborative Large Language Model for Recommender Systems
arxiv_id: '2311.01343'
source_url: https://arxiv.org/abs/2311.01343
tags:
- item
- user
- cllm4rec
- language
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLLM4Rec bridges the semantic gap between natural language and
  recommendation tasks by extending pretrained LLM vocabularies with user/item ID
  tokens and employing a novel soft+hard prompting strategy for effective language
  modeling on recommendation-specific corpora. The method introduces mutual regularization
  to capture recommendation-oriented information from user/item content and uses a
  recommendation-oriented finetuning strategy with multinomial likelihood to generate
  multiple item recommendations efficiently.
---

# Collaborative Large Language Model for Recommender Systems

## Quick Facts
- arXiv ID: 2311.01343
- Source URL: https://arxiv.org/abs/2311.01343
- Reference count: 40
- Primary result: CLLM4Rec achieves up to 0.1656 Recall@20 and 0.1118 NDCG@100 on Amazon Beauty dataset, outperforming state-of-the-art ID-based and LLM-based recommenders

## Executive Summary
CLLM4Rec introduces a novel approach to bridge the semantic gap between natural language and recommendation tasks by extending pretrained LLM vocabularies with user/item ID tokens and employing a soft+hard prompting strategy. The method incorporates mutual regularization to capture recommendation-oriented information from user/item content and uses recommendation-oriented finetuning with multinomial likelihood for efficient multi-item recommendations. Experiments demonstrate significant performance improvements over existing ID-based and LLM-based recommender systems across multiple public and industrial datasets.

## Method Summary
CLLM4Rec extends pretrained LLM vocabularies with user/item ID tokens, implements a soft+hard prompting strategy for language modeling on recommendation-specific corpora, and introduces mutual regularization between collaborative and content LLMs. The method uses a recommendation-oriented finetuning strategy with multinomial likelihood to generate multiple item recommendations efficiently. The approach involves transforming user-item interactions and textual features into documents of token sequences, pretraining collaborative and content LLMs with mutual regularization, and fine-tuning with masked prompts for recommendation generation.

## Key Results
- Achieves up to 0.1656 Recall@20 and 0.1118 NDCG@100 on Amazon Beauty dataset
- Significantly outperforms state-of-the-art ID-based and LLM-based recommender systems
- Soft+hard prompting strategy and mutual regularization effectively learn user/item token embeddings
- Recommendation-oriented finetuning enables efficient multi-item recommendations without hallucination

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Extending LLM vocabulary with user/item ID tokens enables faithful modeling of collaborative and content semantics while avoiding spurious correlations from tokenization of numeric IDs.
- Mechanism: By introducing dedicated "<user_i>" and "<item_j>" tokens that are not broken down into atomic components, the model can learn continuous embeddings for users and items that are aligned with the vocab space. This allows the LLM to reason about user preferences and item properties directly rather than through brittle ID-based correlations.
- Core assumption: The pretrained LLM's ability to encode knowledge and reasoning can be preserved when expanding the vocabulary with new tokens, provided the embeddings are learned through appropriate language modeling tasks.
- Evidence anchors:
  - [abstract] "extend the vocabulary of pretrained LLMs with user/item ID tokens to faithfully model user/item collaborative and content semantics"
  - [section 3.2] "We use bracket notations "<user_>" and "<item_>" to denote the newly-introduced token for the th user and the th item"
  - [corpus] Weak - corpus neighbors don't directly discuss vocabulary extension for ID tokens
- Break condition: If the pretrained LLM backbone cannot effectively incorporate new token embeddings without catastrophic forgetting of its original knowledge, or if the vocabulary expansion creates instability in the attention mechanism.

### Mechanism 2
- Claim: Soft+hard prompting decomposes documents into heterogeneous context tokens and homogeneous main text, enabling stable and effective language modeling on recommendation-specific corpora.
- Mechanism: Each document is split into a prompt containing user/item (soft) and vocab (hard) tokens providing context, and a main text of homogeneous item or vocab tokens. This allows the prediction head to focus exclusively on collaborative or content information during language modeling, enhancing stability and effectiveness.
- Core assumption: The order of items in interaction history is not critical for recommendation, allowing the prompt to capture context while the main text provides the sequential target.
- Evidence anchors:
  - [abstract] "a novel soft+hard prompting strategy is proposed to effectively learn user/item collaborative/content token embeddings via language modeling on RS-specific corpora"
  - [section 3.3.2] "we propose a novel soft+hard prompting strategy to facilitate language modeling on RS-specific corpora with heterogeneous user/item/vocab tokens"
  - [corpus] Weak - corpus neighbors discuss generative recommenders but not specifically soft+hard prompting
- Break condition: If the heterogeneous tokens in the prompt cannot effectively trigger the pretrained LLM's reasoning ability, or if the homogeneous main text structure is not maintained during generation.

### Mechanism 3
- Claim: Mutual regularization connects collaborative and content LLMs to capture recommendation-oriented information while preventing overfitting on sparse interactions.
- Mechanism: The content LLM guides the collaborative LLM to learn from user/item textual features, while the collaborative LLM provides side information to improve content modeling. This is implemented through conditional Gaussian priors that regularize the content and collaborative token embeddings to be similar.
- Core assumption: User/item textual features contain information relevant to recommendations, but require guidance from collaborative signals to filter out noise and focus on recommendation-oriented content.
- Evidence anchors:
  - [abstract] "a novel mutual regularization strategy is introduced to encourage CLLM4Rec to capture recommendation-oriented information from noisy user/item content"
  - [section 3.3.3] "we propose the mutually-regularized pretraining for CLLM4Rec, where collaborative LLM can guide content LLM to capture recommendation-oriented information"
  - [corpus] Weak - corpus neighbors don't explicitly discuss mutual regularization between collaborative and content models
- Break condition: If the mutual regularization strength is poorly tuned, leading to either insufficient content guidance (too weak) or loss of collaborative information (too strong), or if the textual features are too noisy to provide useful regularization signals.

## Foundational Learning

- Concept: Large Language Model pretraining and fine-tuning
  - Why needed here: CLLM4Rec builds upon a pretrained LLM backbone, requiring understanding of how LLMs learn knowledge through language modeling and how this knowledge can be adapted to new tasks through fine-tuning.
  - Quick check question: What is the key difference between encoder-only, encoder-decoder, and decoder-only LLMs, and why does CLLM4Rec focus on decoder-only models?

- Concept: Collaborative filtering and content-based recommendation
  - Why needed here: CLLM4Rec integrates both collaborative filtering (learning from user-item interactions) and content-based methods (learning from user/item features), requiring understanding of how these paradigms capture different aspects of recommendation signals.
  - Quick check question: How do traditional ID-based recommenders represent users and items, and what are the limitations of this approach compared to CLLM4Rec's token-based representation?

- Concept: Prompt engineering and context-based generation
  - Why needed here: The soft+hard prompting strategy relies on carefully designed prompts to trigger the LLM's reasoning ability, and the recommendation-oriented fine-tuning uses masked prompts to adapt the model to recommendation tasks.
  - Quick check question: What is the purpose of the "hard" vocab tokens in the prompt, and how do they differ from the "soft" user/item tokens in guiding the generation process?

## Architecture Onboarding

- Component map: Pretrained LLM backbone -> User/item ID tokens and collaborative embeddings -> User/item content embeddings -> Collaborative LLM with item prediction head -> Content LLM with vocab prediction head -> RecLLM with multinomial likelihood head
- Critical path: Extend vocabulary -> Pretrain with mutual regularization -> Fine-tune with masked prompts -> Generate recommendations
- Design tradeoffs:
  - Vocabulary expansion vs. maintaining pretrained knowledge stability
  - Soft+hard prompting complexity vs. improved language modeling stability
  - Mutual regularization strength vs. learning recommendation-oriented content
  - Computational cost of fine-tuning vs. efficiency of multinomial prediction
- Failure signatures:
  - Catastrophic forgetting of pretrained knowledge (vocabulary expansion issues)
  - Unstable training or poor convergence (prompt design or mutual regularization problems)
  - Overfitting on sparse interactions (insufficient regularization or content guidance)
  - Inefficient recommendations (improper fine-tuning or multinomial prediction issues)
- First 3 experiments:
  1. Test vocabulary extension by checking if user/item embeddings can be learned without degrading vocab token representations
  2. Validate soft+hard prompting by comparing language modeling performance on heterogeneous vs. homogeneous token sequences
  3. Tune mutual regularization strength by observing the balance between collaborative and content learning effectiveness on a validation set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of mutual regularization strength (位c) on the performance of CLLM4Rec across different datasets and recommendation tasks?
- Basis in paper: [explicit] The paper mentions that the mutual regularization strength 位c controls the balance between collaborative and content information, and discusses its influence on performance through sensitivity analysis.
- Why unresolved: While the paper provides sensitivity analysis results for 位c, it only tests a limited range of values (0.01 to 100) and does not explore the full spectrum of possible values. Additionally, the optimal value of 位c may vary depending on the dataset characteristics and the specific recommendation task.
- What evidence would resolve it: Conducting experiments with a wider range of 位c values, including very small and very large values, on various datasets and recommendation tasks would provide a more comprehensive understanding of its impact on CLLM4Rec's performance.

### Open Question 2
- Question: How does the choice of LLM backbone (e.g., GPT, T5, LLaMA) affect the performance and efficiency of CLLM4Rec?
- Basis in paper: [explicit] The paper mentions that CLLM4Rec is implemented with GPT-2 and T5 backbones, and observes that the T5 backbone performs worse than the GPT-2 backbone.
- Why unresolved: The paper only tests two LLM backbones and does not explore other popular options like LLaMA. The reasons for the inferior performance of T5 are not fully investigated, and it is unclear whether other LLM backbones would perform better or worse.
- What evidence would resolve it: Conducting experiments with different LLM backbones, including LLaMA, and analyzing their performance and efficiency on various datasets and recommendation tasks would provide insights into the impact of LLM choice on CLLM4Rec.

### Open Question 3
- Question: How can CLLM4Rec be adapted to handle cold-start users and items effectively?
- Basis in paper: [inferred] The paper focuses on the recommendation task for users and items with sufficient historical interactions and content features. However, it does not explicitly address the cold-start problem, where new users or items have limited or no historical data.
- Why unresolved: The effectiveness of CLLM4Rec for cold-start scenarios is not evaluated or discussed in the paper. It is unclear how the model would handle the lack of historical data and whether it can still provide accurate recommendations for new users and items.
- What evidence would resolve it: Conducting experiments on datasets with a significant proportion of cold-start users and items, and evaluating the performance of CLLM4Rec in these scenarios, would provide insights into its ability to handle the cold-start problem. Additionally, exploring techniques like meta-learning or few-shot learning to adapt CLLM4Rec for cold-start scenarios could be investigated.

## Limitations
- The effectiveness of vocabulary extension depends on the pretrained LLM's ability to incorporate new token embeddings without catastrophic forgetting of its original knowledge
- The soft+hard prompting strategy assumes item order in interaction history is not critical, which may not hold for all recommendation scenarios
- The mutual regularization mechanism's success depends heavily on proper tuning of regularization strength, which may be dataset-dependent

## Confidence

*Mechanism 1 (Vocabulary Extension)*: Medium confidence. While the conceptual framework is sound, there is limited empirical evidence in the paper about how well the pretrained LLM backbone preserves its original knowledge capabilities after vocabulary expansion. The success of this approach critically depends on proper embedding initialization and training procedures.

*Mechanism 2 (Soft+Hard Prompting)*: Low confidence. The paper describes the decomposition strategy but provides limited validation of whether heterogeneous tokens in prompts can effectively trigger LLM reasoning ability. The assumption that item order in interaction history is not critical needs empirical verification across different recommendation datasets.

*Mechanism 3 (Mutual Regularization)*: Medium confidence. The theoretical foundation is reasonable, but the effectiveness of mutual regularization depends heavily on proper tuning of regularization strength. The paper doesn't provide comprehensive ablation studies showing how different regularization strengths affect recommendation performance.

## Next Checks

1. **Vocabulary Stability Test**: Run controlled experiments comparing the performance of CLLM4Rec on standard language modeling tasks (e.g., next token prediction on general text corpora) before and after vocabulary extension with user/item tokens. This would validate whether the pretrained knowledge is preserved or whether catastrophic forgetting occurs.

2. **Prompt Effectiveness Analysis**: Conduct ablation studies systematically varying the proportion of soft vs. hard tokens in prompts and measuring the impact on recommendation quality. Additionally, test whether maintaining homogeneous main text structure is critical by introducing controlled heterogeneity and observing performance degradation.

3. **Regularization Strength Sensitivity**: Perform comprehensive grid search experiments varying the mutual regularization strength 位c across multiple orders of magnitude, measuring both recommendation performance and content learning effectiveness. This would identify optimal regularization settings and reveal whether the current choice is robust or dataset-dependent.