---
ver: rpa2
title: 1D-Convolutional transformer for Parkinson disease diagnosis from gait
arxiv_id: '2311.03177'
source_url: https://arxiv.org/abs/2311.03177
tags:
- disease
- parkinson
- gait
- severity
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This study proposes a hybrid ConvNet-Transformer architecture\
  \ for Parkinson\u2019s disease (PD) diagnosis and severity staging from gait signals.\
  \ The model combines convolutional neural networks to extract local features from\
  \ vertical ground reaction force (VGRF) signals and transformers to capture long-term\
  \ spatio-temporal dependencies."
---

# 1D-Convolutional transformer for Parkinson disease diagnosis from gait

## Quick Facts
- arXiv ID: 2311.03177
- Source URL: https://arxiv.org/abs/2311.03177
- Reference count: 36
- Key outcome: Hybrid ConvNet-Transformer achieves 88% accuracy in PD stage classification from gait signals

## Executive Summary
This study proposes a hybrid ConvNet-Transformer architecture for Parkinson's disease (PD) diagnosis and severity staging from gait signals. The model combines convolutional neural networks to extract local features from vertical ground reaction force (VGRF) signals and transformers to capture long-term spatio-temporal dependencies. Experimental results on the Physionet gait dataset show the proposed approach achieves 88% accuracy in PD stage classification, outperforming existing methods. The hybrid architecture demonstrates superior performance compared to using either CNNs or transformers alone, validating the effectiveness of combining both architectures for analyzing 1D physiological signals.

## Method Summary
The proposed hybrid ConvNet-Transformer architecture processes 18-channel VGRF signals from the Physionet gait dataset. The model segments signals into 100-timestep windows with 50% overlap and processes them through 18 parallel 1D-ConvNets with two blocks (8→16→16 filters), followed by temporal and spatial Transformer encoders. The temporal Transformer captures temporal relationships across sensors, while the spatial Transformer models spatial dependencies. A classifier with two fully connected layers produces 4-class PD severity predictions, with final patient-level classification determined through majority voting over segments. The model is trained for 30 epochs using the Nadam optimizer with dropout regularization.

## Key Results
- 88% accuracy in classifying PD severity across four stages (Healthy, H&Y stage 2, 2.5, 3)
- Superior performance compared to single-model baselines (ConvNet-only or Transformer-only)
- Effective handling of spatio-temporal dependencies in 1D gait signals through hybrid architecture

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The hybrid ConvNet-Transformer captures both local temporal features and long-range dependencies in gait signals, improving classification accuracy over single architectures.
- Mechanism: The ConvNet extracts local patterns from individual foot sensors via 1D convolutions, while the Transformer aligns these local features across sensors to model spatial and temporal relationships. The concatenation of these processed features provides richer discriminative information.
- Core assumption: Local features extracted independently by ConvNets and global relationships modeled by Transformers are complementary for classifying PD severity.
- Evidence anchors:
  - [abstract]: "the former is able to extract relevant local features from Vertical Ground Reaction Force (VGRF) signal, while the latter allows to capture long-term spatio-temporal dependencies in data"
  - [section]: "Our Hybrid ConvNet-Transformer comprises two main components, to capture both local and global features from signal. The ConvNet captures local patterns, while the Transformer captures long-term dependencies and temporal relationships."
  - [corpus]: Weak. Corpus contains related hybrid approaches but does not explicitly compare ConvNet+Transformer performance to single-model baselines.
- Break condition: If ConvNet features are redundant with Transformer self-attention or if sensor independence assumption is violated (e.g., strong inter-sensor coupling not captured), hybrid gains diminish.

### Mechanism 2
- Claim: Segmenting gait signals and using majority voting over segments improves patient-level classification robustness.
- Mechanism: Dividing a walk into fixed-length overlapping segments allows the model to capture variability within a single patient's gait and reduces overfitting to a single long sequence. Majority voting aggregates segment predictions to reduce noise.
- Core assumption: PD severity is consistent across a patient's walk, so segment-level predictions are indicative of overall severity.
- Evidence anchors:
  - [section]: "The final patient classification is decided according to the majority classification of all the segments of the patient's walk."
  - [section]: "The number of elements is chosen so that enough information is stored in each segment."
  - [corpus]: Weak. No corpus neighbor explicitly discusses segment-based voting for gait-based PD classification.
- Break condition: If gait variability within a patient's walk is high due to medication timing, fatigue, or freezing episodes, majority voting may misrepresent true severity.

### Mechanism 3
- Claim: Using fixed positional encodings for both temporal and spatial transformers is appropriate because gait data segments are of fixed length and sensor positions are known.
- Mechanism: Fixed positional encodings provide the transformer layers with explicit information about the order of time steps and relative sensor positions, enabling the model to learn meaningful temporal and spatial patterns.
- Core assumption: The gait data is collected in a consistent, fixed-length format with known sensor positions, making fixed positional encodings sufficient.
- Evidence anchors:
  - [section]: "To capture temporal dependencies, we used a fixed positional encoding with a constant step according to the appropriate segment length."
  - [section]: "The spatial transformer encoder is made of Bst = 1 block. The corresponding input is composed of 18 outputs of 10 elements from the S = 18 parallel temporal transformers that have been dimensionally reduced."
  - [corpus]: Weak. Corpus does not mention positional encoding strategies in gait analysis.
- Break condition: If gait data varies in length or sensor layout is not consistent across recordings, fixed positional encodings become ineffective or misleading.

## Foundational Learning

- Concept: Vertical Ground Reaction Force (VGRF) signals
  - Why needed here: The input data for PD severity classification are VGRF signals, which represent the force exerted by the ground on the feet during walking.
  - Quick check question: What does a VGRF signal represent in gait analysis, and how is it typically measured?

- Concept: Hoehn and Yahr (H&Y) scale
  - Why needed here: The model classifies PD patients into stages based on the H&Y scale, which is a clinical tool for assessing PD severity.
  - Quick check question: What are the stages of the H&Y scale, and what distinguishes each stage in terms of motor symptoms?

- Concept: 1D Convolutional Neural Networks
  - Why needed here: The ConvNet part of the hybrid architecture uses 1D convolutions to extract local temporal features from the VGRF signals.
  - Quick check question: How do 1D convolutions differ from 2D convolutions, and what types of features are they suited to extract from time-series data?

## Architecture Onboarding

- Component map: Input (18 VGRF signals) → ConvNet Block → Temporal Transformer → Spatial Transformer → Classifier → Majority Voting
- Critical path: ConvNet Block → Temporal Transformer → Spatial Transformer → Classifier → Majority Voting
- Design tradeoffs:
  - Parallel ConvNet streams allow independent processing of heterogeneous sensor signals but increase parameter count
  - Fixed positional encodings simplify implementation but assume consistent sensor layout and segment length
  - Majority voting over segments reduces sensitivity to noise but assumes consistent severity within a walk
- Failure signatures:
  - Low training accuracy but high validation accuracy → Overfitting in ConvNet layers or insufficient regularization
  - High training accuracy but low validation accuracy → Overfitting in Transformer layers or excessive model complexity
  - Poor minority class performance (H&Y stage 3) → Class imbalance or insufficient representation in training data
  - Degraded performance with variable segment lengths → Positional encoding assumptions violated
- First 3 experiments:
  1. Replace ConvNet with raw signal input to the temporal transformer to test if ConvNet feature extraction is necessary
  2. Remove majority voting and classify using the first segment only to evaluate segment independence assumption
  3. Train a ConvNet-only baseline (no transformer) to quantify contribution of long-range dependency modeling

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided text.

## Limitations
- The hybrid architecture assumes complementary information between ConvNet features and Transformer relationships, which may not hold if features are redundant
- Fixed positional encodings rely on consistent gait data format and may fail with variable segment lengths or sensor layouts
- Class imbalance affects minority class (H&Y stage 3) performance, with the model performing less accurately on this underrepresented stage

## Confidence
- High confidence: The hybrid architecture's superior performance over single models for PD classification
- Medium confidence: The mechanism of combining local feature extraction with long-range dependency modeling
- Medium confidence: The effectiveness of majority voting for patient-level classification robustness

## Next Checks
1. Test the necessity of ConvNet feature extraction by replacing it with raw signal input to the temporal transformer
2. Evaluate the segment independence assumption by classifying using the first segment only without majority voting
3. Quantify the contribution of long-range dependency modeling by training a ConvNet-only baseline without transformer components