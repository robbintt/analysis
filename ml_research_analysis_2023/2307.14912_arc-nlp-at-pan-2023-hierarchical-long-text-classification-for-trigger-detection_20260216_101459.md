---
ver: rpa2
title: 'ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger Detection'
arxiv_id: '2307.14912'
source_url: https://arxiv.org/abs/2307.14912
tags:
- trigger
- detection
- classification
- document
- multi-label
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of detecting triggering content
  in fanfiction documents to ensure the safety and well-being of online communities.
  The authors propose a hierarchical model using recurrence over Transformer-based
  language models to identify multiple triggering labels in long text documents.
---

# ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger Detection

## Quick Facts
- arXiv ID: 2307.14912
- Source URL: https://arxiv.org/abs/2307.14912
- Reference count: 18
- Primary result: Hierarchical recurrence over Transformer embeddings achieves F1-macro of 0.372 and F1-micro of 0.736 on validation set for fanfiction trigger detection

## Executive Summary
This paper addresses the challenge of detecting triggering content in fanfiction documents by proposing a hierarchical model that uses recurrence over Transformer-based language models. The approach segments long documents into 200-word chunks with 50-word overlap, fine-tunes RoBERTa on these segments, and uses LSTM networks to model sequential relationships between segment embeddings for multi-label classification across 32 trigger categories. The method successfully handles class imbalance through weighted loss functions and achieves state-of-the-art performance on the PAN CLEF 2023 Trigger Detection task, ranking first in multi-label F1-macro score and second in F1-micro score on the test set.

## Method Summary
The proposed approach first preprocesses fanfiction documents by removing HTML tags, URLs, stop words, and lowercasing the text. Documents are then split into 200-word segments with 50-word overlap between consecutive segments to preserve contextual continuity. A fine-tuned RoBERTa-base model processes each segment to extract CLS token embeddings, which are then fed into individual LSTM networks (with 100 hidden units) for each of the 32 trigger labels. The model addresses severe class imbalance by applying positive class weights during training for underrepresented trigger categories, particularly those ranging from kidnapping (class 15) to animal-cruelty (class 32).

## Key Results
- Achieves F1-macro score of 0.372 and F1-micro score of 0.736 on validation set
- Ranks first in multi-label F1-macro score and second in F1-micro score on PAN CLEF 2023 test set
- Successfully handles class imbalance with weighted loss function for rare trigger labels

## Why This Works (Mechanism)

### Mechanism 1
Segmenting long fanfiction documents into 200-word chunks with 50-word overlap preserves contextual continuity while enabling Transformer models to process long sequences effectively. By splitting documents into smaller segments and maintaining overlap between consecutive segments, the model ensures that important context is not lost at segment boundaries. This allows the fine-tuned RoBERTa model to process each segment individually while the overlap region helps capture cross-segment dependencies.

### Mechanism 2
Using hierarchical recurrence over Transformer embeddings allows the model to capture long-range dependencies across document segments. After extracting CLS token embeddings from each segment using the fine-tuned RoBERTa model, these embeddings are fed into an LSTM network that can model sequential relationships across segments. This hierarchical approach combines the local pattern recognition of Transformers with the sequential modeling capabilities of LSTMs.

### Mechanism 3
Addressing class imbalance through weighted loss function improves detection of rare trigger labels. The model assigns higher weights to underrepresented classes during training, effectively increasing their contribution to the loss function. This helps the model learn patterns for rare trigger labels that would otherwise be overwhelmed by the frequent classes.

## Foundational Learning

- Concept: Multi-label classification
  - Why needed here: The task requires assigning multiple trigger labels to each document simultaneously, unlike single-label classification where only one category is assigned.
  - Quick check question: How does multi-label classification differ from multi-class classification, and why is this distinction important for trigger detection?

- Concept: Hierarchical modeling
  - Why needed here: The approach combines Transformer models for local pattern recognition with LSTM models for sequential relationships, creating a two-level architecture that can handle both local and global document features.
  - Quick check question: What are the advantages of using a hierarchical approach versus a single flat model for long document classification?

- Concept: Class imbalance handling
  - Why needed here: The trigger labels show extreme imbalance (e.g., pornographic content appears in 77.52% of documents while animal-cruelty appears in only 0.05%), requiring special techniques to ensure the model learns to detect rare triggers.
  - Quick check question: What are the different methods for handling class imbalance, and when would you choose weighted loss versus oversampling or undersampling?

## Architecture Onboarding

- Component map:
  Input -> Preprocessing -> Segmentation (200 words, 50-word overlap) -> Tokenization (RoBERTa) -> Feature Extraction (CLS embeddings) -> LSTM modeling (100 hidden units) -> Binary classification (32 labels) -> Label aggregation

- Critical path:
  Segmentation → Tokenization → Feature Extraction → LSTM modeling → Binary classification → Label aggregation

- Design tradeoffs:
  - Segment length vs. computational efficiency: Shorter segments are faster to process but may lose context
  - Overlap size vs. redundancy: Larger overlap captures more context but increases computational cost
  - LSTM hidden size vs. model capacity: Larger hidden states can capture more complex patterns but risk overfitting

- Failure signatures:
  - High precision but low recall on rare classes: Indicates insufficient weight adjustment for minority classes
  - Degraded performance on long documents: Suggests segment length or overlap is inadequate
  - Inconsistent predictions across similar documents: May indicate overfitting or insufficient training data

- First 3 experiments:
  1. Baseline: Train RoBERTa-Segment (without LSTM) to isolate the impact of hierarchical recurrence
  2. Overlap sensitivity: Test different overlap sizes (25, 50, 75 words) to find optimal context preservation
  3. Class weighting ablation: Train models with different weight configurations to understand the impact of imbalance handling

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed hierarchical recurrence over Transformer-based language models approach compare to other long document classification methods in terms of performance and computational efficiency? The paper only compares the proposed method to a few baseline methods and does not explore other potential approaches or discuss computational efficiency.

### Open Question 2
How does the performance of the proposed method vary across different types of triggering content in Fanfiction? The paper mentions that the dataset contains 32 distinct trigger labels, but it does not provide a detailed analysis of the model's performance for each trigger class.

### Open Question 3
How does the proposed method handle the class imbalance problem in the dataset, and what impact does it have on the overall performance? The paper mentions that the trigger classes are greatly imbalanced and that they solve this problem by changing the weights of the underrepresented classes during back-propagation updates.

## Limitations
- The black-box nature of Transformer-based approaches limits interpretability of trigger detection decisions
- Fixed segmentation strategy (200 words with 50-word overlap) may not optimally preserve context for all trigger types
- Evaluation on a single dataset (AO3 fanfiction) raises questions about generalizability to other domains
- Weighted loss for class imbalance may introduce bias toward minority classes at the expense of overall precision

## Confidence
**High Confidence Claims:**
- The hierarchical recurrence over Transformer embeddings effectively captures document-level patterns for trigger detection
- Class imbalance significantly impacts performance on rare trigger labels
- The 50-word overlap between segments provides sufficient context preservation

**Medium Confidence Claims:**
- The specific segmentation strategy (200 words with 50-word overlap) is optimal for this task
- The chosen LSTM architecture with 100 hidden units is sufficient for modeling segment relationships
- The positive class weighting approach is the best method for handling the observed imbalance

**Low Confidence Claims:**
- The model's generalizability to other fanfiction platforms or trigger types
- The relative importance of each architectural component (segmentation, recurrence, class weighting)
- The robustness of predictions across different document lengths and writing styles

## Next Checks
1. **Ablation Study on Architectural Components**: Systematically remove or modify each key component (segmentation, LSTM recurrence, class weighting) to quantify their individual contributions to the final performance.

2. **Cross-Domain Generalization Test**: Apply the trained model to fanfiction datasets from different platforms or communities to assess whether the learned trigger detection patterns transfer effectively.

3. **Context Preservation Analysis**: Conduct controlled experiments varying the segment overlap size (e.g., 25, 50, 75, 100 words) and measuring the impact on trigger detection performance, particularly for triggers that typically appear near segment boundaries.