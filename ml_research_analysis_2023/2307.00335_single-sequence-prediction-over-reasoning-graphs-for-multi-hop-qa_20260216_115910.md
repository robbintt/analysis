---
ver: rpa2
title: Single Sequence Prediction over Reasoning Graphs for Multi-hop QA
arxiv_id: '2307.00335'
source_url: https://arxiv.org/abs/2307.00335
tags:
- reasoning
- answer
- uni0000001c
- uni00000013
- uni00000048
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SEQGRAPH, a method for multi-hop question
  answering that integrates a graph structure over context passages to reduce disconnected
  reasoning and improve interpretability. The approach constructs a local entity-passage
  graph using Wikipedia hyperlinks, encodes it with a graph neural network, and fuses
  the structured representations into the language model to guide generation of a
  reasoning path and final answer.
---

# Single Sequence Prediction over Reasoning Graphs for Multi-hop QA

## Quick Facts
- arXiv ID: 2307.00335
- Source URL: https://arxiv.org/abs/2307.00335
- Authors: 
- Reference count: 11
- This paper introduces SEQGRAPH, a method for multi-hop QA that integrates a graph structure over context passages to reduce disconnected reasoning and improve interpretability, achieving state-of-the-art performance on Musique with a 17-point improvement in answer F1.

## Executive Summary
SEQGRAPH is a method for multi-hop question answering that integrates a graph neural network (GNN) with a language model to improve reasoning faithfulness and interpretability. The approach constructs a local entity-passage graph using Wikipedia hyperlinks, encodes it with a GNN, and fuses the structured representations into the language model to guide generation of a reasoning path and final answer. Experiments on HotpotQA and Musique show that SEQGRAPH significantly improves answer and support exact-match/F1 scores over baseline generative models, reduces disconnected reasoning as measured by DIRE score, and achieves state-of-the-art performance on Musique with a 17-point improvement in answer F1. The method adds only up to 4% more parameters and maintains strong performance while improving reasoning faithfulness.

## Method Summary
SEQGRAPH combines a transformer encoder-decoder model (T5) with a graph neural network to encode structural relationships between entities and passages. The method first constructs a local entity-passage graph from Wikipedia hyperlinks in the context passages, where nodes represent entities and passages and edges represent hyperlink connections. The T5 encoder processes the input sequences and provides intermediate representations from the first L layers, which are used to initialize node embeddings for a graph neural network. The GNN encodes the graph structure into node representations, which are then fused with the T5 representations via element-wise addition. The fused representations are passed to the remaining layers of the T5 encoder and then to the decoder, which generates a reasoning path with special tokens ([title], [facts], [answer]) followed by the final answer. The model is trained end-to-end using cross-entropy loss on both the reasoning path and answer predictions.

## Key Results
- SEQGRAPH achieves 49.3 EM and 66.8 F1 on HotpotQA distractor test, outperforming baseline generative models
- SEQGRAPH achieves 70.3 EM and 76.7 F1 on Musique Answerable test, a 17-point improvement in answer F1 over previous state-of-the-art
- SEQGRAPH reduces disconnected reasoning as measured by DIRE score, indicating more faithful reasoning paths

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph neural network representations bias the model toward connected reasoning paths by providing structural context between passages.
- Mechanism: The GNN encodes a local entity-passage graph constructed from Wikipedia hyperlinks, creating node embeddings that capture structural relationships between entities and passages. These embeddings are fused with the language model's text representations to guide the decoder toward selecting connected facts rather than disconnected ones.
- Core assumption: The structural relationships encoded in the entity-passage graph (based on Wikipedia hyperlinks) reflect the true reasoning dependencies needed to answer multi-hop questions.
- Evidence anchors:
  - [abstract]: "We use a graph neural network to encode this graph structure and fuse the resulting representations into the entity representations of the model."
  - [section 3.2]: "The structured representations are fused to bias the generative model toward predicting a faithful, connected reasoning path which improves answer predictions."
  - [corpus]: Weak - related papers focus on retrieval and ranking improvements but don't directly validate the GNN fusion mechanism described here.
- Break condition: If the Wikipedia hyperlink structure doesn't align with the actual reasoning path needed, or if the GNN fails to propagate meaningful information between connected nodes.

### Mechanism 2
- Claim: Shallow text representations from the first L transformer layers are effective initializers for the GNN because they capture local context before deep semantic fusion.
- Mechanism: The method extracts representations from the Lth layer of the T5 encoder, which contain shallow contextualized information about entity spans and passage titles. These are used as initial node embeddings for the GNN, preserving local context while allowing the GNN to add structural information.
- Core assumption: Shallow representations (L layers) retain sufficient local context for entities and passages without being overwhelmed by global semantic information that might obscure structural relationships.
- Evidence anchors:
  - [section 3.2]: "we first encode Si through the first L layers to obtain the intermediate hidden representations ZL_i in Eq. (2), which capture the shallow contextualized information of the input sequence."
  - [section 3.2]: "We utilize these shallow representations to initialize the node embeddings for a graph neural network."
  - [corpus]: Weak - no direct evidence in related works about optimal layer selection for GNN initialization.
- Break condition: If L is too small (insufficient context) or too large (overly fused semantics), the GNN initialization becomes ineffective.

### Mechanism 3
- Claim: Simple addition fusion preserves both the language model's semantic understanding and the GNN's structural information without introducing complex learned combinations.
- Mechanism: The method uses element-wise addition to combine the GNN's structured node representations (ZG_i) with the language model's contextualized text representations (ZL_i), creating a fused representation that benefits from both sources of information.
- Core assumption: Addition is sufficient to combine heterogeneous representations (textual semantics and structural relationships) without losing information from either source.
- Evidence anchors:
  - [section 3.2]: "Finally, we fuse the contextualized text representations ZL_i from the text encoder and the structured node representations ZG_i by an aggregation operator âŠ•, and pass them to the remaining layers of the text encoder to obtained the fused representations Si for each input sequence Si: In this work, the aggregation operator used is a simple addition."
  - [corpus]: Weak - related works discuss fusion techniques but don't validate simple addition specifically for this GNN-text fusion context.
- Break condition: If addition causes catastrophic interference between the two representation types, or if learned combinations would be significantly more effective.

## Foundational Learning

- Concept: Graph Neural Networks and message passing
  - Why needed here: The GNN is the core mechanism for encoding structural relationships between entities and passages into vector representations that can be fused with text embeddings.
  - Quick check question: Can you explain how a GAT layer updates node representations using attention over neighbor nodes, and why this is appropriate for the entity-passage graph structure?

- Concept: Transformer encoder-decoder architecture and layer-wise representations
  - Why needed here: Understanding how to extract intermediate representations from specific transformer layers is crucial for initializing the GNN and fusing representations.
  - Quick check question: What is the difference between representations from early vs. late transformer layers, and why would shallow layers be chosen for GNN initialization in this context?

- Concept: Multi-hop reasoning and disconnected reasoning
  - Why needed here: The problem being solved requires understanding how models can incorrectly "hop" between passages without proper reasoning chains, and how structural information can prevent this.
  - Quick check question: Can you describe what constitutes disconnected reasoning in multi-hop QA and how it manifests in predicted reasoning paths?

## Architecture Onboarding

- Component map: Text Encoder (T5) -> Graph Neural Network -> Fusion Module -> Decoder (T5)
- Critical path: Graph Construction -> Text Encoding (L layers) -> GNN Encoding -> Fusion -> Text Encoding (M-L layers) -> Decoding
- Design tradeoffs:
  - GNN vs. no GNN: Adds parameter overhead (~4%) but improves reasoning faithfulness
  - Shallow vs. deep text representations for GNN initialization: Balances local context preservation with semantic richness
  - Simple addition vs. learned fusion: Simplicity and parameter efficiency vs. potentially better performance with learned combinations
- Failure signatures:
  - Low improvement in DIRE score despite high answer F1: Model may still be using disconnected reasoning shortcuts
  - Degradation in answer performance when adding GNN: GNN fusion may be introducing noise or incorrect structural information
  - GNN parameter sensitivity: Performance varies significantly with different GNN architectures or hyperparameters
- First 3 experiments:
  1. Baseline comparison: Run FID and PATH-FID baselines on HotpotQA distractor setting to establish performance floor
  2. Ablation study: Test SEQGRAPH with and without GNN (replace with identity) to measure impact of structural encoding
  3. Layer analysis: Vary L (number of text encoder layers used for GNN initialization) to find optimal balance between local context and semantic information

## Open Questions the Paper Calls Out

- Can the reasoning path output length be optimized for complex multi-hop questions without sacrificing interpretability?
- Can entity linking be integrated directly into the model to eliminate the need for external entity linkers?
- How does the performance of SEQGRAPH scale with increasing numbers of hops beyond what was tested?
- What alternative aggregation mechanisms beyond simple addition could improve the fusion of text and graph representations?

## Limitations

- The method relies on Wikipedia hyperlink structure, which may not capture all relevant reasoning dependencies for multi-hop questions
- The approach adds computational overhead through the GNN component, though limited to 4% additional parameters
- The performance on questions requiring more than 4 hops shows degradation, indicating potential scalability limits

## Confidence

**High confidence** in the empirical results showing performance improvements on HotpotQA and Musique datasets. The answer EM/F1 and support EM/F1 metrics are well-established in the literature, and the reported improvements are substantial and statistically significant.

**Medium confidence** in the mechanism claims about why the GNN fusion improves reasoning faithfulness. While the DIRE score provides supporting evidence for reduced disconnected reasoning, the paper doesn't conduct ablation studies that would definitively prove the GNN is the causal factor rather than other aspects of the architecture.

**Low confidence** in the generalizability claims beyond the two tested datasets. The paper doesn't provide evidence about performance on other multi-hop QA datasets or in zero-shot/cross-domain settings, and the reliance on Wikipedia hyperlink structure may limit applicability to other knowledge sources.

## Next Checks

1. **Ablation study on GNN component**: Implement SEQGRAPH without the GNN (using identity instead of GNN outputs) and measure changes in answer EM/F1, support EM/F1, and DIRE score. This would isolate the contribution of the structural encoding from other architectural differences.

2. **Graph structure validation**: Conduct an analysis comparing Wikipedia hyperlink connections to human-annotated reasoning paths on a subset of questions. Calculate precision/recall of the graph structure in capturing true reasoning dependencies to validate the core assumption about hyperlink relevance.

3. **Layer sensitivity analysis**: Systematically vary the number of encoder layers L used for GNN initialization (e.g., L=2, 4, 6, 8) and measure impact on performance metrics. This would test the hypothesis about optimal balance between shallow context preservation and semantic richness.