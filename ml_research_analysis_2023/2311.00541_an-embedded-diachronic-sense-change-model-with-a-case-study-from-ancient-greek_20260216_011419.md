---
ver: rpa2
title: An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek
arxiv_id: '2311.00541'
source_url: https://arxiv.org/abs/2311.00541
tags:
- sense
- edisc
- word
- disc
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces EDiSC, an embedded version of the Diachronic
  Sense Change (DiSC) model, for modeling diachronic lexical semantic change. EDiSC
  extends DiSC by incorporating word embeddings, representing context words and target-word
  senses as vectors in a shared embedding space.
---

# An Embedded Diachronic Sense Change Model with a Case Study from Ancient Greek

## Quick Facts
- arXiv ID: 2311.00541
- Source URL: https://arxiv.org/abs/2311.00541
- Reference count: 15
- Primary result: EDiSC outperforms DiSC, GASC, and SCAN models in predictive accuracy and uncertainty quantification for diachronic sense change modeling

## Executive Summary
This paper introduces EDiSC, an embedded version of the Diachronic Sense Change (DiSC) model, for modeling diachronic lexical semantic change. EDiSC extends DiSC by incorporating word embeddings, representing context words and target-word senses as vectors in a shared embedding space. This approach allows EDiSC to leverage semantic information from the wider text corpus, improving predictive accuracy and uncertainty quantification compared to DiSC. Experiments on ancient Greek and English data show that EDiSC outperforms baseline models in terms of Brier scores and provides more precise credible intervals for sense-prevalence estimates.

## Method Summary
EDiSC extends the DiSC model by incorporating word embeddings, representing context words and target-word senses as vectors in a shared embedding space. The model is fitted using Markov Chain Monte Carlo (MCMC) methods, specifically Hamiltonian Monte Carlo (HMC) and No-U-Turn sampler (NUTS). Experiments are conducted on the Diorisis Ancient Greek Corpus with three target words ("kosmos", "mus", and "harmonia"), each having three true senses. The data consists of snippets of 14 lemmatized context words around the target word, with genre and time period annotations.

## Key Results
- EDiSC outperforms DiSC, GASC, and SCAN models in terms of Brier scores, which measure predictive accuracy.
- EDiSC provides more precise credible intervals for sense-prevalence estimates, improving uncertainty quantification.
- EDiSC demonstrates better sampling efficiency and scalability with MCMC methods compared to DiSC.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EDiSC improves predictive accuracy by leveraging semantic information from the full text corpus through word embeddings.
- Mechanism: By representing context words as vectors in an embedding space, EDiSC captures semantic relationships that are not apparent from local context alone, leading to more accurate sense distributions.
- Core assumption: Word embeddings learned from the full corpus encode semantic relationships that are relevant for distinguishing word senses in the target text.
- Evidence anchors:
  - [abstract]: "EDiSC extends DiSC by incorporating word embeddings, representing context words and target-word senses as vectors in a shared embedding space. This approach allows EDiSC to leverage semantic information from the wider text corpus, improving predictive accuracy..."
  - [section]: "embeddings exploit the wider text corpora to capture useful semantic information about the context words, which is otherwise lost if we focus only on the context of a given target word. This feature of EDiSC leads to improved predictive accuracy..."
  - [corpus]: Weak - no direct corpus evidence of improved accuracy, only model comparison results.
- Break condition: If the embedding space fails to capture the relevant semantic distinctions for the specific corpus, or if the embedding dimension is too low to represent the semantic nuances.

### Mechanism 2
- Claim: EDiSC provides better uncertainty quantification through more precise credible intervals for sense-prevalence estimates.
- Mechanism: The embedding structure imposes a more constrained and lower-dimensional parameter space, which leads to more stable posterior distributions and tighter credible intervals.
- Core assumption: The embedding structure regularizes the model, reducing posterior multimodality and leading to more concentrated credible sets.
- Evidence anchors:
  - [abstract]: "EDiSC also provides more precise credible intervals for sense-prevalence estimates..."
  - [section]: "Quantification of uncertainty in sense-change estimates is an under-explored area within the field, yet important when working with small and sparse datasets... EDiSC offers improved predictive accuracy, ground-truth recovery and uncertainty quantification..."
  - [corpus]: Weak - no direct corpus evidence of credible interval precision, only model comparison results.
- Break condition: If the embedding space is too restrictive and fails to capture the true sense distributions, leading to biased estimates and underconfident intervals.

### Mechanism 3
- Claim: EDiSC offers better sampling efficiency and scalability with MCMC methods compared to DiSC.
- Mechanism: The lower-dimensional embedding space (M dimensions) compared to the full vocabulary size (V dimensions) reduces the computational complexity of MCMC sampling, especially for large vocabularies.
- Core assumption: The reduction in parameter space dimension from V to M leads to faster mixing and convergence of MCMC chains.
- Evidence anchors:
  - [abstract]: "...better sampling efficiency and scalability properties with MCMC methods..."
  - [section]: "The dimension of the embedding space is lower than the vocabulary size, and is typically held constant even against an increasing vocabulary size. This results in more efficient Monte Carlo sampling and scalability properties..."
  - [corpus]: Weak - no direct corpus evidence of sampling efficiency, only model comparison results.
- Break condition: If the embedding dimension M is chosen too high, negating the computational benefits, or if the embedding space introduces computational bottlenecks (e.g., matrix operations).

## Foundational Learning

- Concept: Word embeddings and their properties
  - Why needed here: Understanding how word embeddings capture semantic relationships is crucial for grasping how EDiSC improves upon DiSC.
  - Quick check question: How do traditional word embeddings like GloVe differ from contextualised embeddings like BERT in terms of their ability to capture word senses?

- Concept: Bayesian inference and MCMC sampling
  - Why needed here: EDiSC uses MCMC methods to sample from the posterior distribution of model parameters, and understanding these methods is essential for interpreting the results.
  - Quick check question: What are the key differences between Metropolis-Adjusted Langevin Algorithm (MALA) and Hamiltonian Monte Carlo (HMC) in terms of their efficiency and convergence properties?

- Concept: Model selection and evaluation metrics
  - Why needed here: Choosing the appropriate number of model senses (K) and embedding dimension (M) is critical for EDiSC's performance, and understanding evaluation metrics like Brier scores and WAIC is necessary for model comparison.
  - Quick check question: How does the Widely Applicable Information Criterion (WAIC) differ from the Akaike Information Criterion (AIC) in terms of its suitability for Bayesian model selection?

## Architecture Onboarding

- Component map: Data preprocessing -> Embedding learning -> Model specification -> MCMC sampling -> Model evaluation -> Visualization

- Critical path:
  1. Preprocess the data and learn embeddings
  2. Specify the EDiSC model with chosen K and M
  3. Implement MCMC sampling and check convergence
  4. Evaluate model performance using Brier scores and WAIC
  5. Compare results to ground truth (if available) and interpret findings

- Design tradeoffs:
  - Embedding dimension (M): Higher M captures more semantic nuances but increases computational cost and risk of overfitting
  - Number of model senses (K): Higher K provides finer-grained sense distinctions but may lead to overlapping senses and reduced interpretability
  - MCMC sampler: MALA is simpler to implement but may mix slower than HMC or NUTS; NUTS automates tuning but may be more sensitive to hyperparameters

- Failure signatures:
  - Non-convergence of MCMC chains: May indicate multimodal posteriors, poor initialization, or inappropriate sampler settings
  - Poor predictive performance (high Brier scores): May suggest misspecified model, inadequate embeddings, or insufficient data
  - Uninterpretable sense distributions: May indicate overlapping senses, insufficient K, or poor quality embeddings

- First 3 experiments:
  1. Fit EDiSC with K=2 and M=100 on the "bank" dataset and compare Brier scores to DiSC
  2. Vary the embedding dimension M (50, 100, 200, 300) for the "kosmos" dataset and select the best M using WAIC
  3. Assess MCMC convergence for EDiSC with different samplers (MALA, HMC, NUTS) and tune hyperparameters for optimal performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the EDiSC model framework be expanded to accommodate contextualised word embeddings?
- Basis in paper: [inferred] The authors acknowledge that EDiSC uses traditional word embeddings with one vector representation per word and note that contextualised embeddings would not be straightforward to integrate into their framework, suggesting this as an interesting avenue for future research.
- Why unresolved: The current EDiSC framework is built around the assumption of a single, static word embedding per word, which is incompatible with the dynamic nature of contextualised embeddings that vary based on context.
- What evidence would resolve it: A concrete proposal or implementation of an extended EDiSC model that successfully integrates contextualised word embeddings, along with empirical results demonstrating improved performance on diachronic sense change tasks.

### Open Question 2
- Question: How would EDiSC perform compared to other methods on shared tasks or when used in conjunction with other NLP methods?
- Basis in paper: [inferred] The authors mention that their models can be generalised for wider purposes such as WSD or sense change-point detection, and express interest in comparing their models against other methods on shared tasks or in conjunction with other NLP methods.
- Why unresolved: The paper focuses on comparing EDiSC against DiSC, GASC, and SCAN models, and does not include comparisons with a broader range of methods from the NLP literature that might be used for similar tasks.
- What evidence would resolve it: Results from applying EDiSC to benchmark datasets or shared tasks in WSD or semantic change detection, and comparing its performance to other state-of-the-art methods.

### Open Question 3
- Question: How does the choice of embedding dimension M affect the performance of EDiSC, and is there an optimal way to determine M for a given dataset?
- Basis in paper: [explicit] The authors discuss the choice of M as an important modelling decision, noting that there is no universally optimal method and that it requires judgement based on the specific corpus and task. They experiment with different values of M and use WAIC to guide their choice.
- Why unresolved: While the authors provide guidelines for choosing M and demonstrate its impact on performance through experiments, they do not provide a definitive method for determining the optimal M for any given dataset.
- What evidence would resolve it: A comprehensive study that systematically varies M across a wide range of datasets and tasks, identifying patterns or rules for selecting M that consistently lead to optimal performance.

## Limitations

- The reliance on pre-trained word embeddings may limit the model's ability to capture corpus-specific semantic nuances, particularly for ancient Greek texts with domain-specific vocabulary and historical context.
- The model's scalability with increasing vocabulary size is claimed to be improved, but this is primarily based on theoretical arguments rather than extensive empirical validation across diverse corpora and vocabulary sizes.
- The choice of hyperparameters (embedding dimension M, number of senses K) significantly impacts model performance, but the paper does not provide a systematic investigation of the sensitivity of results to these choices.

## Confidence

- **High Confidence**: The overall methodology of extending DiSC with word embeddings is sound and well-motivated. The experimental setup and evaluation metrics are appropriate for the task.
- **Medium Confidence**: The claims of improved predictive accuracy and uncertainty quantification compared to baseline models are supported by the experimental results, but the absolute performance gains may be modest in some cases.
- **Low Confidence**: The claims regarding sampling efficiency and scalability with MCMC methods are primarily theoretical and lack extensive empirical validation.

## Next Checks

1. **Embedding Ablation Study**: Systematically evaluate the impact of embedding quality on model performance by comparing EDiSC with different embedding models (e.g., GloVe, BERT, domain-specific embeddings) and varying embedding dimensions.

2. **Vocabulary Size Scalability**: Conduct experiments on corpora with varying vocabulary sizes to empirically assess the claimed scalability improvements of EDiSC compared to DiSC.

3. **Hyperparameter Sensitivity Analysis**: Perform a systematic sensitivity analysis of EDiSC's performance to the choice of embedding dimension M and number of senses K, using techniques like grid search or Bayesian optimization.