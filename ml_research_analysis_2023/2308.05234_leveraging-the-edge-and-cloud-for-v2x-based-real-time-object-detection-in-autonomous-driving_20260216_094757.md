---
ver: rpa2
title: Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous
  Driving
arxiv_id: '2308.05234'
source_url: https://arxiv.org/abs/2308.05234
tags:
- compression
- detection
- quality
- cloud
- edge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of real-time object detection
  in autonomous driving by exploring the trade-off between detection quality and latency.
  Due to computational and power constraints in vehicles, larger object detection
  models cannot be run locally in real-time.
---

# Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving

## Quick Facts
- arXiv ID: 2308.05234
- Source URL: https://arxiv.org/abs/2308.05234
- Reference count: 40
- Key outcome: Cloud-based object detection with JPEG-H compression achieves 85% mAP with 74.5ms end-to-end latency, outperforming local embedded processing while meeting real-time constraints.

## Executive Summary
This work explores the trade-off between object detection quality and latency in autonomous driving by offloading computation to edge and cloud platforms via C-V2X communication. Due to computational and power constraints in vehicles, larger object detection models cannot be run locally in real-time. The authors propose using YOLOv5 models of varying sizes on different platforms, with input compression to reduce transmission latency. Results demonstrate that models with adequate compression can be run in real-time on the cloud while outperforming local detection performance, with the cloud platform consistently achieving better mean average precision and end-to-end latency trade-offs across all compression techniques.

## Method Summary
The study creates a synthetic dataset using CARLA simulator with 10,000 frames annotated for three object classes (vehicles, pedestrians, traffic lights). YOLOv5 object detection models of varying sizes are trained on this dataset and evaluated on local (NVIDIA Jetson Xavier NX), edge (laptop with GTX 1650), and cloud (HPC node with Tesla V100) platforms. Input frames are compressed using JPEG and H.265 techniques before transmission via simulated 5G C-V2X network using Simu5G framework. The evaluation measures mean average precision (mAP) and end-to-end latency including compression, transmission, decompression, and inference. Target is 20Hz operation (50ms total delay).

## Key Results
- Cloud platform with JPEG-H compression achieves best mAP of 85% with 74.5ms end-to-end latency
- Edge platform performance is consistently inferior to cloud across all compression techniques
- Local small model achieves 64% mAP with 19.5ms latency but significantly lower detection quality
- Compression reduces transmission size sufficiently to enable real-time remote inference when C-V2X is available

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Offloading heavy object detection models to cloud reduces end-to-end latency while improving detection quality.
- Mechanism: Large YOLOv5 models (76M parameters) provide better mean average precision (mAP) than smaller models but are too slow to run locally on embedded hardware. By compressing input frames with JPEG or H.265 and offloading inference to cloud platforms with high-performance GPUs, the system achieves both higher mAP and real-time processing rates.
- Core assumption: Network latency and computational savings from cloud offloading outweigh local processing costs and compression overhead.
- Evidence anchors:
  - [abstract] "models with adequate compression can be run in real-time on the cloud while outperforming local detection performance"
  - [section] "the cloud platform consistently outperformed the edge platform in terms of mAP and end-to-end latency trade-off"
- Break condition: If network latency exceeds computational savings from using a larger model, or if compression quality degrades mAP below local performance levels.

### Mechanism 2
- Claim: JPEG and H.265 compression reduce data transmission size sufficiently to enable real-time remote inference.
- Mechanism: By compressing high-resolution camera frames before transmission, the system significantly reduces the amount of data that needs to be sent over the network. This reduction in data size directly translates to lower transmission latency, making it feasible to send large frames to remote platforms for processing without violating real-time constraints.
- Core assumption: Compression techniques preserve sufficient image quality for accurate object detection, and compression/decompression overhead is negligible compared to transmission latency.
- Evidence anchors:
  - [section] "compression can drastically reduce the size of the frame to be transmitted, allowing real-time remote object detection when C-V2X is available"
  - [section] "compression and decompression have a negligible impact on the overall delay"
- Break condition: If compression artifacts severely degrade detection performance (e.g., mAP drops below 10% with very low quality settings), or if processing overhead of compression/decompression becomes non-negligible.

### Mechanism 3
- Claim: Synthetic dataset generation using CARLA enables training of object detection models without requiring large real-world datasets.
- Mechanism: The CARLA simulator is used to generate a synthetic dataset of 10,000 frames with ground truth bounding boxes for three object classes (vehicles, pedestrians, traffic lights). This dataset is then used to train YOLOv5 models, allowing for controlled experimentation and evaluation of different offloading strategies without the need for extensive real-world data collection.
- Core assumption: Synthetic data generated by CARLA accurately represents real-world scenarios and can produce models that generalize well to actual driving conditions.
- Evidence anchors:
  - [section] "We create a synthetic dataset to train an object detection model and evaluate the proposed offloading strategies"
  - [section] "We run the simulation to collect ten thousand camera frames, taken at 1Hz from the front of the ego-vehicle"
- Break condition: If models trained on synthetic data perform significantly worse on real-world data, or if synthetic dataset fails to capture important variations in real driving scenarios.

## Foundational Learning

- Concept: Object detection and mean average precision (mAP)
  - Why needed here: Understanding how object detection models are evaluated and compared is crucial for interpreting results of different offloading strategies.
  - Quick check question: What is the difference between precision, recall, and mAP in the context of object detection?

- Concept: 5G C-V2X communication and network simulation
  - Why needed here: Knowledge of how C-V2X communication works and how network latency is simulated is essential for understanding experimental setup and results.
  - Quick check question: How does the use of Simu5G framework help in evaluating the end-to-end delay of different offloading strategies?

- Concept: YOLO architecture and model variants
  - Why needed here: Understanding different sizes and capabilities of YOLOv5 models is important for grasping why certain models are chosen for local vs. cloud deployment.
  - Quick check question: Why are larger YOLOv5 models (e.g., with 76M parameters) not suitable for real-time operation on embedded hardware, despite their better performance?

## Architecture Onboarding

- Component map: Camera frame -> Compression -> Network transmission -> Decompression -> Model inference -> Results transmission
- Critical path: Camera frame → Compression → Network transmission → Decompression → Model inference → Results transmission
- Design tradeoffs:
  - Model size vs. inference speed: Larger models provide better mAP but are slower
  - Compression quality vs. detection performance: Higher compression reduces latency but may degrade mAP
  - Local vs. remote processing: Local is faster but limited by hardware constraints; remote offers better performance but introduces network latency
- Failure signatures:
  - High end-to-end latency: Check network simulation parameters and compression settings
  - Low mAP: Investigate compression quality and model architecture choices
  - System instability: Verify network simulation setup and hardware configurations
- First 3 experiments:
  1. Compare end-to-end latency of local small model vs. edge/cloud models with no compression
  2. Evaluate impact of different JPEG compression qualities on mAP and latency for edge vs. cloud scenarios
  3. Test effect of H.265 compression with varying CRF values on detection quality and end-to-end delay

## Open Questions the Paper Calls Out
- The paper acknowledges that current experiments use a static setup, which is a limitation as it doesn't accurately reflect real-world scenarios where mobility is common. They mention that future work will focus on examining the influence of mobility on network latency.

## Limitations
- Performance advantage of cloud over edge platforms is demonstrated only on synthetic data from CARLA, with no validation on real-world driving scenarios
- Network simulation uses fixed parameters without sensitivity analysis to variations in real-world C-V2X conditions like signal fading, interference, or congestion
- Compression impact is tested only on YOLOv5 models; effectiveness with other architectures or sensor modalities (LiDAR, radar) remains unknown

## Confidence
- High confidence: Local platform latency and mAP measurements (19.5ms, 64% mAP) are directly measured and reproducible
- Medium confidence: Cloud platform superiority (85% mAP, 74.5ms) is demonstrated but only under controlled synthetic conditions and specific network parameters
- Low confidence: Generalization of findings to real-world deployments, other object detection models, or different compression algorithms without further validation

## Next Checks
1. Validate synthetic dataset results on real-world autonomous driving footage from public datasets (e.g., nuScenes, KITTI) to assess cross-domain performance
2. Conduct sensitivity analysis by varying Simu5G network parameters (latency, bandwidth, packet loss) to identify breaking points for cloud/edge offloading
3. Test alternative compression schemes (e.g., JPEG 2000, WebP) and object detection architectures (e.g., EfficientDet, SSD) to evaluate robustness of proposed trade-off strategy