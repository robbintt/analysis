---
ver: rpa2
title: 'Eureka-Moments in Transformers: Multi-Step Tasks Reveal Softmax Induced Optimization
  Problems'
arxiv_id: '2310.12956'
source_url: https://arxiv.org/abs/2310.12956
tags:
- task
- attention
- learning
- training
- indicator
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper identifies a problem in transformers where they struggle
  to learn multi-step tasks, particularly the intermediate steps. This issue, called
  Eureka-moments, occurs when the training loss plateaus for hundreds of epochs before
  suddenly improving.
---

# Eureka-Moments in Transformers: Multi-Step Tasks Reveal Softmax Induced Optimization Problems

## Quick Facts
- **arXiv ID**: 2310.12956
- **Source URL**: https://arxiv.org/abs/2310.12956
- **Authors**: [Not specified in input]
- **Reference count**: 40
- **Key outcome**: Transformers struggle to learn multi-step tasks, particularly intermediate steps, due to Softmax-induced gradient vanishing in self-attention blocks, which can be mitigated by NormSoftmax and Heat Treatment interventions.

## Executive Summary
This paper identifies a fundamental optimization problem in transformers called "Eureka-moments," where transformers exhibit prolonged training plateaus before suddenly improving on multi-step tasks. The authors trace this issue to the Softmax function in self-attention blocks, which causes vanishing gradients for key and query weight matrices when attention distributions are uniform. They propose two interventions - NormSoftmax and Heat Treatment - that increase attention entropy to maintain useful gradients, leading to faster convergence and higher accuracy on synthetic multi-step tasks. The findings suggest implications for language modeling and in-context learning beyond the synthetic setting.

## Method Summary
The authors create synthetic two-step tasks to study transformer learning behavior in a controlled setting. They train vanilla ViT models and observe the Eureka-moment phenomenon, then apply their proposed solutions (NormSoftmax and Heat Treatment) to compare performance. The interventions modify the attention mechanism by either normalizing dot products or gradually increasing temperature to maintain useful gradients. They measure Eureka-ratio (proportion of runs with Eureka-moments), accuracy after breakthrough, and average epoch of occurrence across different datasets and model architectures.

## Key Results
- NormSoftmax and Heat Treatment reduce training steps required for Eureka-moments and increase the Eureka-ratio
- Both interventions lead to faster convergence, higher accuracy, and greater robustness to hyperparameters
- The problems observed in synthetic tasks transfer to improvements in language modeling and in-context learning
- Transformers initially learn a shortcut by ignoring indicators and learning only the prior p(z), requiring long training or interventions to unlearn this behavior

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Softmax function in self-attention blocks causes small gradients for key (K) and query (Q) weight matrices when attention is uniformly distributed.
- Mechanism: When attention scores are uniform, the Jacobian of Softmax produces near-zero entries, resulting in vanishing gradients for WK and WQ while WV gradients remain large.
- Core assumption: The attention distribution becomes too uniform before the model learns to solve the intermediate task.
- Evidence anchors:
  - [abstract] "trace the problem back to the Softmax function in the self-attention block of transformers and show ways to alleviate the problem"
  - [section] "Softmax attention can cause vanishing gradients... since all entries of the Jacobian of the Softmax will become close to 0"
  - [corpus] Weak evidence for direct softmax gradient analysis; no direct citations found
- Break condition: When attention entropy collapses (very peaky) instead of being uniform.

### Mechanism 2
- Claim: NormSoftmax and temperature scheduling interventions increase attention entropy in a controlled way, enabling larger gradients for WK and WQ.
- Mechanism: By normalizing the dot product or gradually increasing temperature, the Softmax produces more varied attention scores, preventing gradient collapse.
- Core assumption: Increasing attention entropy early in training helps the model learn to attend to relevant features (indicators) for the intermediate task.
- Evidence anchors:
  - [abstract] "We found that ways to improve on the synthetic multi-step tasks can be used to improve the training of language modeling and ICL"
  - [section] "Both HT and NormSoftmax reduce the training steps required for Eureka-moments to occur and increase the Eureka-ratio"
  - [corpus] Weak evidence; related works focus on softmax alternatives but not specifically for multi-step tasks
- Break condition: If temperature is set too high too early, attention may become too uniform and lose discriminative power.

### Mechanism 3
- Claim: The transformer initially learns a prior p(z) ignoring evidence, and only through long training or interventions does it unlearn this and pay attention to indicators.
- Mechanism: Without intermediate supervision, the transformer defaults to always picking the more likely target, as shown in experiments with changed target probabilities.
- Core assumption: The model can shortcut by learning p(z) without solving task 1, and this is the initial optimization path.
- Evidence anchors:
  - [abstract] "transformers can get stuck during optimization for two-stage tasks"
  - [section] "We observe that transformers can learn these tasks suddenly and unexpectedly but usually take a long time to do so"
  - [corpus] No direct evidence; this is inferred from experimental observations
- Break condition: When interventions force the model to attend to indicators early, breaking the p(z) shortcut.

## Foundational Learning

- Concept: Softmax function and its Jacobian properties
  - Why needed here: Understanding why uniform attention causes vanishing gradients requires knowing how Softmax gradients behave
  - Quick check question: What happens to the Jacobian of Softmax when all input values are equal?

- Concept: Attention entropy and its relationship to gradient magnitude
  - Why needed here: The interventions work by controlling attention entropy to maintain useful gradients
  - Quick check question: How does increasing temperature in Softmax affect the entropy of the output distribution?

- Concept: Multi-step reasoning and implicit task decomposition
  - Why needed here: The core problem is the transformer's inability to learn intermediate sub-tasks without explicit supervision
  - Quick check question: In a two-step task where task 1 determines which data to use for task 2, what must the model learn to succeed?

## Architecture Onboarding

- Component map:
  Input tokens → Patch embeddings → Transformer blocks (Multi-Head Attention + Feed Forward) → CLS token → Classification head

- Critical path:
  1. Attend to indicators in early layers to solve task 1
  2. Use this information to attend to correct target for task 2
  3. Backpropagate gradients through attention weights to learn both tasks

- Design tradeoffs:
  - Temperature vs. attention specificity: Higher temperature increases entropy but may reduce discriminative power
  - Model depth vs. learning difficulty: Shallower models sometimes learn easier, but may lack capacity for complex tasks

- Failure signatures:
  - Training and validation loss plateau for hundreds of epochs
  - Attention maps show uniform distribution or focus only on targets, ignoring indicators
  - Gradients for WK and WQ are orders of magnitude smaller than WV

- First 3 experiments:
  1. Train baseline ViT on synthetic two-step task and observe Eureka-moments
  2. Apply NormSoftmax and compare Eureka-ratio and training speed
  3. Visualize attention maps and gradient norms to confirm the mechanism

## Open Questions the Paper Calls Out
The paper doesn't explicitly call out open questions, but based on the analysis, several questions remain:

### Open Question 1
- Question: Can the Eureka-moment phenomenon be directly observed and measured in real-world, non-synthetic datasets beyond the RoBERTa example provided?
- Basis in paper: [inferred] The paper mentions RoBERTa pretraining as an example where NormSoftmax leads to earlier Eureka-moments, suggesting transferability to real datasets. However, the paper primarily relies on synthetic data to study the phenomenon in detail.
- Why unresolved: The paper only provides one example of Eureka-moments in a real dataset (RoBERTa). More extensive analysis and quantification of Eureka-moments in diverse real-world tasks and models are needed to confirm the generalizability of the findings.
- What evidence would resolve it: Systematic analysis of Eureka-moments in a wide range of real-world datasets and models, including but not limited to language models, vision tasks, and reinforcement learning scenarios. This would involve tracking training curves, identifying plateaus and sudden improvements, and correlating them with the model's ability to solve multi-step tasks.

### Open Question 2
- Question: What is the precise mechanism by which the Softmax function in the self-attention block causes small gradients for the key and value weight matrices, and how does this specifically hinder learning of intermediate tasks?
- Basis in paper: [explicit] The paper identifies the Softmax function as the root cause of small gradients for WK and WQ, but the exact mechanism and its impact on intermediate task learning are not fully elucidated. The paper provides some evidence through gradient analysis and attention maps, but a more comprehensive theoretical understanding is lacking.
- Why unresolved: While the paper demonstrates the correlation between Softmax, small gradients, and Eureka-moments, it does not provide a complete theoretical explanation of the underlying mechanism. The paper mentions that local uniform attention causes small gradients, but the precise relationship between attention entropy, gradient magnitudes, and the learning of intermediate tasks needs further investigation.
- What evidence would resolve it: Detailed mathematical analysis of the gradient flow through the Softmax function in the self-attention block, considering different attention distributions and their impact on the gradients of WK and WQ. This could involve analyzing the Jacobian of the Softmax function, studying the relationship between attention entropy and gradient magnitudes, and developing theoretical models to explain how small gradients hinder the learning of intermediate tasks.

### Open Question 3
- Question: Are there other architectural modifications or training strategies beyond NormSoftmax and Heat Treatment that can effectively mitigate the Eureka-moment problem and improve the learning of multi-step tasks in transformers?
- Basis in paper: [inferred] The paper proposes NormSoftmax and Heat Treatment as solutions to the Eureka-moment problem, but it acknowledges that other factors like weight decay and gradient scaling were less effective. This suggests that there might be other approaches to address the issue.
- Why unresolved: The paper only explores a limited set of solutions to the Eureka-moment problem. There might be other architectural modifications, training strategies, or optimization techniques that could be more effective in mitigating the issue and improving the learning of multi-step tasks.
- What evidence would resolve it: Extensive experimentation with various architectural modifications (e.g., different attention mechanisms, normalization techniques, or residual connections) and training strategies (e.g., different learning rate schedules, regularization techniques, or curriculum learning approaches) to identify novel solutions that effectively address the Eureka-moment problem and improve the learning of multi-step tasks in transformers.

## Limitations
- The core mechanism relies heavily on the claim that Softmax-induced gradient vanishing is the primary cause of Eureka-moments, but direct empirical validation of this gradient vanishing mechanism is not provided
- The analysis could benefit from more rigorous mathematical proofs connecting Softmax Jacobian properties to the observed phenomena, particularly in multi-head attention settings where gradient flow is more complex
- Limited ablation studies on the proposed interventions make it difficult to isolate which components are most critical for the improvements

## Confidence
- High confidence: The existence of Eureka-moments as a training phenomenon (observed plateau-then-sudden-improvement pattern is well-documented)
- Medium confidence: The attribution of Eureka-moments primarily to Softmax-induced gradient vanishing (plausible but not definitively proven)
- Medium confidence: The effectiveness of NormSoftmax and Heat Treatment interventions (supported by experiments but with limited ablation studies)
- Low confidence: The claim that this mechanism explains language model and ICL training improvements (only briefly mentioned without detailed analysis)

## Next Checks
1. **Direct gradient measurement**: Instrument the training process to measure and visualize the actual gradient magnitudes of WK, WQ, and WV matrices throughout training, particularly during the plateau phase, to confirm the predicted vanishing gradient pattern.

2. **Controlled entropy experiments**: Systematically vary attention entropy through temperature scheduling while measuring both gradient magnitudes and task performance to establish the causal relationship between entropy, gradients, and learning progress.

3. **Multi-head attention analysis**: Extend the gradient analysis to multi-head attention settings, examining whether the gradient vanishing occurs uniformly across heads or if some heads maintain useful gradients while others collapse.