---
ver: rpa2
title: Counterfactual Augmentation for Multimodal Learning Under Presentation Bias
arxiv_id: '2305.14083'
source_url: https://arxiv.org/abs/2305.14083
tags:
- counterfactual
- bias
- data
- augmentation
- presentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes counterfactual augmentation to address presentation
  bias, a feedback loop issue in machine learning systems where model recommendations
  influence user behavior and distort training labels. The authors introduce a causal
  framework where presentation bias arises from the relationship between model recommendations
  and user interactions, then propose generating counterfactual labels to break this
  link.
---

# Counterfactual Augmentation for Multimodal Learning Under Presentation Bias

## Quick Facts
- **arXiv ID**: 2305.14083
- **Source URL**: https://arxiv.org/abs/2305.14083
- **Reference count**: 20
- **Primary result**: Counterfactual augmentation consistently outperforms uncorrected models and existing bias-correction methods across binary classification, multi-class classification, and regression tasks, with the largest improvements in minority class performance.

## Executive Summary
This paper addresses presentation bias in multimodal machine learning systems, where model recommendations create a feedback loop that distorts training labels. The authors propose a causal framework where recommendations influence which user interactions are observed, creating selection bias in the label distribution. They introduce counterfactual augmentation as a solution, using a multimodal counterfactual GAN to generate realistic labels for unobserved data points. Experiments on synthetic and real-world multimodal datasets (Airbnb listings and clothing reviews) demonstrate that this approach consistently outperforms uncorrected models and existing bias-correction methods, particularly improving performance on minority classes.

## Method Summary
The method uses a multimodal counterfactual GAN to generate synthetic labels for data points where user interactions weren't observed due to presentation bias. The GAN architecture includes separate discriminators for each recommendation condition (R=0 and R=1) to ensure proper distribution matching. The generated counterfactual labels are combined with observed labels to create a bias-corrected training dataset. This approach breaks the causal link between recommendations and observed labels, approximating the true label distribution P(Y) rather than the biased P(Y|A=1).

## Key Results
- Counterfactual augmentation consistently outperforms uncorrected models across all tested tasks and datasets
- The largest performance improvements occur in minority class predictions, with substantial gains in macro and minority class F1 scores
- Generated counterfactuals closely match true counterfactuals, particularly for binary classification tasks
- The method achieves 11.2% improvement in minority class F1 for binary classification on the synthetic Airbnb dataset
- For multi-class classification on real Airbnb data, counterfactual augmentation achieves 8.4% higher F1 on minority classes compared to uncorrected models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Presentation bias creates a feedback loop where model recommendations influence which user interactions are observed, distorting the label distribution.
- Mechanism: The causal path R0 → A → Y creates a selection bias where P(Y|A=1) ≠ P(Y). Labels are more likely to be observed when recommendations are positive (R0=1), creating an overrepresentation of positive feedback.
- Core assumption: The relationship between recommendations and observed interactions follows the stated causal structure and probabilities.
- Evidence anchors:
  - [abstract] "feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels"
  - [section 2] "users are much more likely to interact with recommended items, such that P(A=1|R0=1) >> P(A=1|R0=0)"
- Break condition: If user behavior becomes independent of recommendations or if the probability of interaction given recommendation approaches uniform distribution.

### Mechanism 2
- Claim: Counterfactual augmentation corrects presentation bias by generating synthetic labels for unobserved data points, breaking the R0 → A → Y causal link.
- Mechanism: By generating counterfactual labels Y_A=1 for cases where A=0, the method creates a balanced dataset that approximates the true label distribution P(Y) rather than the biased P(Y|A=1).
- Core assumption: The generated counterfactual labels accurately approximate what labels would have been observed under unbiased conditions.
- Evidence anchors:
  - [abstract] "we propose generating counterfactual labels to break this link"
  - [section 3.1] "we can break the causal link behind presentation bias with a counterfactual question: how would users have reacted had they interacted with all items"
- Break condition: If the counterfactual generation model fails to produce realistic labels or systematically biases the generated labels.

### Mechanism 3
- Claim: The multimodal counterfactual GAN generates realistic counterfactual labels by learning the relationship between features and labels across different recommendation conditions.
- Mechanism: The GAN architecture with separate discriminators for each recommendation condition (R=0 and R=1) learns to generate labels that match the true distribution within each condition, avoiding the collapse to the R=1 distribution.
- Core assumption: The discriminator constraint properly enforces separate distributions for each recommendation condition.
- Evidence anchors:
  - [section 3.2] "we address this problem by defining two separate discriminators—one for each recommendation condition"
  - [section 5.2] "For the easier binary classification task, the distribution of generated counterfactuals closely reflects that of the true counterfactuals"
- Break condition: If the discriminators fail to enforce separate distributions or if the generator learns to produce biased outputs.

## Foundational Learning

- Concept: Causal inference and counterfactual reasoning
  - Why needed here: The entire approach relies on understanding how interventions (recommendations) affect outcomes (observed labels) and what would have happened under alternative scenarios.
  - Quick check question: If a user always interacts with recommended items, what is the relationship between P(Y|R=1) and P(Y)?

- Concept: Selection bias and its correction methods
  - Why needed here: Presentation bias is a form of selection bias, and understanding standard correction methods (like inverse propensity weighting) provides context for why counterfactual augmentation is needed.
  - Quick check question: How does inverse propensity weighting attempt to correct selection bias, and why might it be insufficient for presentation bias?

- Concept: Generative adversarial networks and multimodal learning
  - Why needed here: The method uses a GAN architecture that can handle both text and image features, requiring understanding of both GAN training dynamics and multimodal feature integration.
  - Quick check question: What is the role of the discriminator in a GAN, and how does having separate discriminators for different conditions affect training?

## Architecture Onboarding

- Component map: Multimodal counterfactual GAN → Counterfactual label generation → Bias-corrected dataset → Task model training
- Critical path: Data preparation → GAN training → Counterfactual generation → Dataset augmentation → Task model training
- Design tradeoffs: 
  - Single vs. separate discriminators (chosen: separate for better distribution matching)
  - Sequential vs. parallel fine-tuning (chosen: sequential for stability)
  - Generator capacity vs. training efficiency (chosen: balanced approach)
- Failure signatures:
  - Poor counterfactual quality: Generated labels don't match true counterfactual distributions
  - Training instability: GAN loss oscillates or diverges
  - Bias amplification: Counterfactuals reinforce existing biases instead of correcting them
- First 3 experiments:
  1. Train counterfactual GAN on synthetic data with known ground truth to verify counterfactual generation quality
  2. Apply counterfactual augmentation to binary classification task and measure minority class F1 improvement
  3. Compare counterfactual augmentation vs. IPW on same task to validate performance gains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does counterfactual augmentation perform in data settings with high noise or sparse features?
- Basis in paper: [inferred] The paper hypothesizes that poor-quality counterfactuals may be produced if "the feature data is very noisy or sparse, making it difficult to learn counterfactuals."
- Why unresolved: The experiments only evaluated on relatively clean multimodal datasets (Airbnb and Clothing) with both tabular and rich features.
- What evidence would resolve it: Testing counterfactual augmentation on datasets with varying levels of noise and sparsity, measuring the quality of generated counterfactuals and downstream performance.

### Open Question 2
- Question: What is the optimal architecture for the multimodal counterfactual GAN across different task types?
- Basis in paper: [explicit] The paper states "Although our multimodal counterfactual GAN generates high-quality counterfactuals for the tasks and data settings that we evaluate, we do not know if this will be the case across every task and data setting. A different counterfactual estimation method may be required depending on the particular problem."
- Why unresolved: The paper used a single GAN architecture across all experiments but acknowledges this may not generalize.
- What evidence would resolve it: Systematic comparison of different GAN architectures and counterfactual generation methods across diverse task types and data modalities.

### Open Question 3
- Question: How does the performance of counterfactual augmentation scale with dataset size?
- Basis in paper: [inferred] The paper does not address scalability, though it mentions "the environmental impact of large language and image models" suggesting computational considerations.
- Why unresolved: All experiments were conducted on datasets with tens of thousands of samples, with no analysis of performance degradation or improvement as dataset size increases.
- What evidence would resolve it: Experiments measuring performance across multiple orders of magnitude of dataset sizes, analyzing both accuracy and computational efficiency.

### Open Question 4
- Question: Can counterfactual augmentation effectively correct biases beyond presentation bias, such as social biases?
- Basis in paper: [explicit] The authors state "We believe that counterfactual augmentation may be helpful not only in correcting presentation bias but also in reducing social biases in data" and "counterfactual augmentation can be used to correct any type of bias for which the causal mechanism is known."
- Why unresolved: The experiments only focused on presentation bias in recommendation systems.
- What evidence would resolve it: Application of counterfactual augmentation to datasets with known social biases (e.g., gender or racial bias) with evaluation of bias reduction metrics alongside performance metrics.

### Open Question 5
- Question: What is the relationship between the degree of label imbalance and the effectiveness of counterfactual augmentation?
- Basis in paper: [explicit] The paper notes that "due to the imbalance in the distribution of Y, macro and minority class F1 score are the best measures of performance" and that "the biggest improvements resulting from counterfactual augmentation are in the minority classes."
- Why unresolved: While the paper observes better performance on minority classes, it doesn't systematically vary the degree of imbalance to understand the relationship.
- What evidence would resolve it: Controlled experiments with synthetic datasets varying the degree of label imbalance, measuring performance changes across different levels of imbalance.

## Limitations
- Counterfactual generation quality varies across tasks, with better performance on binary classification than multi-class tasks
- The approach requires training an additional GAN model, increasing computational overhead
- The method's effectiveness depends on having sufficient observed data to learn the relationship between features and labels

## Confidence
- **High Confidence**: The existence of presentation bias as a real problem in recommender systems, the basic causal framework for understanding this bias, and the overall empirical improvement from counterfactual augmentation across all tested tasks and datasets.
- **Medium Confidence**: The specific mechanism by which separate discriminators improve counterfactual quality, the exact contribution of each architectural component to performance gains, and the generalizability of results to other multimodal domains.
- **Low Confidence**: The optimal threshold for label binarization (only specified as "approximately 0.25 to 0.75"), the sensitivity of results to specific hyperparameter choices, and the method's performance on domains with different feature distributions or label characteristics.

## Next Checks
1. **Ablation Study on Discriminator Design**: Compare counterfactual quality and downstream task performance between single discriminator, separate discriminators, and alternative multi-condition discriminator architectures to quantify the specific contribution of the separate discriminator design.

2. **Sensitivity Analysis to Presentation Bias Level**: Systematically vary the degree of label dropping (e.g., different dropping probabilities) and measure how counterfactual augmentation performance scales with increasing bias levels to understand method robustness.

3. **Cross-Domain Generalization Test**: Apply the method to a different multimodal domain (e.g., movie recommendations with plot descriptions and posters) to evaluate whether the performance improvements generalize beyond the tested Airbnb and clothing domains.