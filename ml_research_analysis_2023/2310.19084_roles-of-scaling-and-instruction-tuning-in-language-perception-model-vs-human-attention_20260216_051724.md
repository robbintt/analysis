---
ver: rpa2
title: 'Roles of Scaling and Instruction Tuning in Language Perception: Model vs.
  Human Attention'
arxiv_id: '2310.19084'
source_url: https://arxiv.org/abs/2310.19084
tags:
- human
- attention
- language
- resemblance
- instruction
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the effects of scaling and instruction tuning
  on language perception in large language models (LLMs) by comparing self-attention
  patterns to human reading attention. The analysis shows that scaling significantly
  improves human resemblance and reduces trivial pattern reliance, while instruction
  tuning does not enhance human resemblance but increases sensitivity to instructions.
---

# Roles of Scaling and Instruction Tuning in Language Perception: Model vs. Human Attention

## Quick Facts
- arXiv ID: 2310.19084
- Source URL: https://arxiv.org/abs/2310.19084
- Reference count: 23
- Primary result: Scaling enhances human resemblance in LLM attention patterns while instruction tuning increases instruction sensitivity but reduces human resemblance

## Executive Summary
This study investigates how scaling and instruction tuning affect language perception in large language models by comparing their self-attention patterns to human reading attention (saccades). The analysis reveals that scaling significantly improves the alignment between model attention and human reading patterns while reducing reliance on trivial attention patterns. Instruction tuning, while enhancing instruction-following capabilities, actually reduces human resemblance in attention patterns. Notably, current LLMs consistently resemble non-native English speakers more than native speakers, suggesting limitations in their language perception capabilities.

## Method Summary
The study compares self-attention patterns from LLaMA family models (7B, 13B, 30B, 65B) and their instruction-tuned variants (Alpaca, Vicuna) against human reading attention data from 108 participants reading 5 STEM articles. Attention patterns are collected through sentence-by-sentence next-token prediction, then reshaped to word-level matrices for comparison with human saccade data. The analysis uses Jensen-Shannon divergence to measure general attention changes, linear regression for human resemblance quantification, and regression scores for trivial pattern reliance analysis.

## Key Results
- Scaling significantly enhances human resemblance and reduces trivial pattern reliance, especially in deeper layers
- Instruction tuning increases instruction sensitivity but reduces human resemblance
- All models consistently resemble non-native English speakers more than native speakers
- Scaling effects are more pronounced than instruction tuning effects on language perception quality

## Why This Works (Mechanism)

### Mechanism 1
Scaling increases human resemblance by enhancing contextualized attention patterns. As model size increases, attention patterns become less dependent on trivial patterns (like attending to first word or previous word) and more aligned with human saccade patterns.

### Mechanism 2
Instruction tuning increases sensitivity to instructions while reducing human resemblance. Instruction tuning adapts attention patterns to instruction-following tasks, but this adaptation comes at the cost of reduced alignment with general human reading patterns.

### Mechanism 3
LLMs naturally resemble non-native speakers more than native speakers in attention patterns. The training data and optimization process create attention patterns that align better with the more rigid, pattern-following behavior of non-native speakers.

## Foundational Learning

- **Jensen-Shannon divergence**: Used to quantify how scaling and instruction tuning affect general attention distribution. *Quick check*: How does JS divergence differ from KL divergence and why is it preferred for comparing attention distributions?

- **Linear regression for human resemblance**: The core method for quantifying how well model attention matches human saccade patterns. *Quick check*: Why use linear regression rather than correlation to measure human resemblance, and what does the R² score represent in this context?

- **Trivial pattern reliance**: Used to distinguish between adaptive attention patterns and rigid, context-free attention behaviors. *Quick check*: What are the three trivial patterns analyzed and why do they represent non-contextualized attention?

## Architecture Onboarding

- **Component map**: Input preprocessing (SentencePiece tokenization) -> Model execution (next-token prediction with attention collection) -> Analysis pipeline (JS divergence, linear regression, trivial pattern analysis) -> Reference data (human saccade matrices)

- **Critical path**: Model attention collection → reshaping to word-level → comparison with human saccade via linear regression → aggregation and analysis

- **Design tradeoffs**: Using raw attention scores vs. more interpretable attention metrics (like ALTI or Attention Flow) - raw scores preserve original computation but may be less interpretable

- **Failure signatures**: High JS divergence without corresponding change in human resemblance suggests attention changes that don't improve language perception; high trivial pattern reliance indicates rigid attention patterns

- **First 3 experiments**:
  1. Verify JS divergence reference values by comparing two identical model versions
  2. Test human resemblance calculation by correlating model attention with shuffled human data (should yield near-zero)
  3. Validate trivial pattern reliance by confirming that trivial patterns show high reliance on themselves (positive control)

## Open Questions the Paper Calls Out

- **Open Question 1**: Does scaling affect the human resemblance of LLMs trained on languages other than English? The study only uses English data and does not test models trained on other languages.

- **Open Question 2**: What is the underlying cause of the higher human resemblance of LLMs to non-native English speakers (L2) compared to native speakers (L1)? The study partially explains the difference by trivial pattern reliance but does not provide a comprehensive explanation for the underlying cause.

- **Open Question 3**: How do instruction tuning and scaling interact to affect the language perception abilities of LLMs? The study does not explore the interaction between instruction tuning and scaling in detail or provide insights into how these factors jointly influence language perception.

## Limitations

- Findings are based on analysis of 5 STEM articles read by 108 participants, limiting generalizability to broader language domains
- Linear regression assumes linear relationships between model attention and human saccade patterns, potentially missing non-linear relationships
- Only LLaMA family models were analyzed, limiting applicability to other model architectures

## Confidence

- **High confidence**: The finding that scaling reduces trivial pattern reliance and increases JS divergence between model versions
- **Medium confidence**: The claim that instruction tuning reduces human resemblance while increasing instruction sensitivity
- **Low confidence**: The assertion that all current LLMs consistently resemble non-native speakers more than native speakers

## Next Checks

- Replicate the human resemblance analysis using non-linear correlation measures (e.g., mutual information or rank correlation) to verify that linear regression captures the true relationship
- Test the scaling effect on a larger and more diverse corpus to determine if improvements generalize beyond STEM content
- Conduct ablation studies on instruction tuning by varying instruction types and dataset compositions to isolate which aspects contribute to reduced human resemblance