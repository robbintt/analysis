---
ver: rpa2
title: 'ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following
  the Metaphor Identification Procedure'
arxiv_id: '2309.03103'
source_url: https://arxiv.org/abs/2309.03103
tags:
- word
- metaphor
- sense
- basic
- datasets
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces ContrastWSD, a RoBERTa-based model for metaphor
  detection that follows the Metaphor Identification Procedure (MIP) by extracting
  and contrasting the contextual meaning with the basic meaning of a target word.
  The method integrates a Word Sense Disambiguation (WSD) model to obtain word senses
  and leverages dictionary definitions for the basic meaning.
---

# ContrastWSD: Enhancing Metaphor Detection with Word Sense Disambiguation Following the Metaphor Identification Procedure

## Quick Facts
- arXiv ID: 2309.03103
- Source URL: https://arxiv.org/abs/2309.03103
- Reference count: 6
- Key outcome: ContrastWSD achieves up to 10.32% improvement in F1-score for novel metaphors and 6.41% for conventional metaphors compared to prior state-of-the-art models

## Executive Summary
This paper introduces ContrastWSD, a RoBERTa-based model for metaphor detection that follows the Metaphor Identification Procedure (MIP) by explicitly contrasting contextual and basic word meanings. The model integrates a Word Sense Disambiguation (WSD) model to extract contextual definitions from WordNet and retrieves basic definitions from Wiktionary. Evaluation on benchmark datasets shows significant improvements over strong baselines, demonstrating the effectiveness of explicitly aligning with MIP steps through definition contrast rather than implicit inference methods.

## Method Summary
ContrastWSD is a RoBERTa-based model that follows the Metaphor Identification Procedure (MIP) by explicitly contrasting contextual and basic word meanings. The model uses a WSD model to extract the contextual definition of the target word from WordNet, then retrieves the basic definition from Wiktionary. Three RoBERTa encoders process the sentence, contextual definition, and basic definition separately. The model measures semantic similarity between these definitions using cosine similarity and includes helper layers to learn relationships between target word embeddings and definition embeddings. The model is trained for 3 epochs with a learning rate of 3e-5 and evaluated using precision, recall, and F1-score on benchmark datasets.

## Key Results
- Achieved up to 10.32% improvement in F1-score for detecting novel metaphors compared to prior state-of-the-art models
- Demonstrated 6.41% improvement in F1-score for detecting conventional metaphors
- Showed statistically significant improvements across multiple benchmark datasets (VUA-18, VUA-20, VUA-verb, VUA-MPD-All, VUA-MPD-Conv)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model enhances metaphor detection by explicitly contrasting contextual word sense definitions with basic word sense definitions, which aligns with the Metaphor Identification Procedure (MIP) steps 3-5.
- Mechanism: The model uses a WSD model to extract the contextual definition of the target word from WordNet, then retrieves the basic definition from Wiktionary. These two definitions are encoded separately and their semantic similarity is measured using cosine similarity. The contrast between these definitions helps determine metaphoricity.
- Core assumption: The contextual definition extracted by the WSD model accurately represents the word's meaning in the given sentence, and the basic definition from Wiktionary truly represents the word's basic sense as defined by MIP.
- Evidence anchors:
  - [abstract] "By utilizing the word senses derived from a WSD model, our model enhances the metaphor detection process and outperforms other methods that rely solely on contextual embeddings or integrate only the basic definitions"
  - [section] "To align with MIP, we augmented the existing datasets... Firstly, we employed a BERT WSD model fine-tuned on a sequence-pair ranking task (Yap et al., 2020) to extract the word sense contextual definition of the target word from WordNet"
  - [corpus] Weak - corpus contains related papers on WSD and metaphor detection but no direct evidence about this specific mechanism's effectiveness
- Break condition: If the WSD model fails to accurately identify the contextual sense, or if the basic definition from Wiktionary does not represent the true basic meaning of the word, the contrast will be meaningless and metaphor detection will fail.

### Mechanism 2
- Claim: The model leverages helper layers that learn relationships between the target word's contextual embedding and its embeddings adjacent to both contextual and basic definitions, which helps when WSD fails.
- Mechanism: Two helper layers are introduced that learn the relationship between the target word's contextual embedding (et) and the target word embeddings adjacent to its contextual definition (etc) and basic definition (etb). These layers help the model when the WSD model fails to distinguish between word sense and basic definition.
- Core assumption: The target word embeddings adjacent to definitions contain useful information about the relationship between the word and its meanings, even when WSD fails.
- Evidence anchors:
  - [section] "We have also introduced two additional helper layers to our model. The first layer learns the relationship between the target word's contextual embedding et and the target word embedding adjacent to the word's sense etc, while the second layer learns the relationship between the target word's contextual embedding et and the target word embedding adjacent to the word's basic definition etb"
  - [section] "We believe that these helper layers will assist the MIP layer when the WSD model fails to distinguish between the word sense and the basic definition, particularly in the case of detecting novel metaphors that lack multiple definitions in the dictionary"
  - [corpus] Weak - no direct evidence in corpus about helper layers effectiveness
- Break condition: If the helper layers cannot learn meaningful relationships between the target word and its definitions, or if the WSD model fails frequently, the model's performance will degrade significantly.

### Mechanism 3
- Claim: The model's architecture follows the MIP procedure more closely than previous approaches by explicitly encoding and contrasting definitions rather than relying on implicit inference.
- Mechanism: Unlike previous models that use contextual embeddings to implicitly infer word sense or assume out-of-context embeddings represent basic meaning, ContrastWSD explicitly retrieves and contrasts contextual and basic definitions. This explicit contrast better aligns with MIP steps 3-5.
- Core assumption: Explicit encoding and contrasting of definitions is more effective for metaphor detection than implicit inference methods used in previous models.
- Evidence anchors:
  - [section] "We argue that this model still lacks full alignment with MIP since it implicitly contrasts the basic definition with the word sense. To achieve a more explicit alignment with MIP, we propose a different approach"
  - [section] "The explicit contrast between the basic and word sense definitions corresponds better to steps 3 to 5 outlined in the flowchart of the MIP procedure"
  - [corpus] Moderate - corpus contains related work on metaphor detection but no direct comparison of explicit vs implicit methods
- Break condition: If the explicit contrast does not provide more discriminative information than implicit methods, or if the additional complexity introduces noise, the model may not outperform simpler approaches.

## Foundational Learning

- Concept: Word Sense Disambiguation (WSD)
  - Why needed here: The model relies on WSD to extract the contextual definition of the target word from WordNet, which is then contrasted with the basic definition to determine metaphoricity
  - Quick check question: What is the difference between a word's contextual meaning and its basic meaning in the context of metaphor detection?

- Concept: The Metaphor Identification Procedure (MIP)
  - Why needed here: The model's architecture is designed to follow MIP steps 3-5 by explicitly contrasting contextual and basic meanings, so understanding MIP is crucial for understanding why the model works
  - Quick check question: According to MIP, what determines whether a lexical unit is used metaphorically?

- Concept: Cosine similarity for semantic comparison
  - Why needed here: The model uses cosine similarity to measure the semantic gap between contextual and basic definitions, with larger gaps indicating higher likelihood of metaphor
  - Quick check question: How does cosine similarity between two embeddings relate to their semantic similarity?

## Architecture Onboarding

- Component map:
  Input layer -> Three RoBERTa encoders (sentence, contextual definition, basic definition) -> Target embedding, local context embedding, POS embedding -> MIP layer with cosine similarity -> Two helper layers -> Classification layer

- Critical path:
  1. Input sentence with target word marked
  2. WSD model extracts contextual definition from WordNet
  3. Basic definition retrieved from Wiktionary
  4. Three RoBERTa encoders process sentence, contextual definition, and basic definition
  5. MIP layer combines contextual and basic definition embeddings with cosine similarity
  6. Helper layers learn relationships between target word and definition embeddings
  7. All components concatenated and passed to classification layer
  8. Binary prediction output (metaphorical or literal)

- Design tradeoffs:
  - Using WSD adds complexity but provides more accurate contextual definitions than implicit inference
  - Retrieving definitions from external sources (WordNet, Wiktionary) adds dependency but aligns better with MIP
  - Three separate RoBERTa encoders increase computational cost but allow specialized processing of different input types
  - Helper layers add parameters but improve robustness when WSD fails

- Failure signatures:
  - High loss on validation set: Could indicate issues with WSD model, definition retrieval, or model architecture
  - Poor performance on novel metaphors: May indicate helper layers are not learning effectively or WSD model struggles with novel senses
  - No improvement over baseline models: Could indicate that explicit contrast is not more effective than implicit methods, or that the additional complexity introduces noise

- First 3 experiments:
  1. Test the WSD model independently on a held-out dataset to verify it accurately extracts contextual definitions
  2. Compare model performance with and without helper layers to quantify their contribution
  3. Test model on datasets with varying proportions of novel vs conventional metaphors to identify performance differences

## Open Questions the Paper Calls Out
No open questions were explicitly called out in the paper.

## Limitations
- The model's performance heavily depends on the accuracy of the external WSD model and the availability of word senses in WordNet, with significant degradation when WSD fails
- Reliance on external resources like Wiktionary and WordNet introduces potential inconsistencies and coverage gaps that limit model effectiveness
- No ablation study quantifies the specific contribution of helper layers to overall model performance, making their necessity unclear

## Confidence
**High Confidence** - The claim that ContrastWSD outperforms baseline models is supported by statistically significant improvements across multiple benchmark datasets, with F1-score improvements up to 10.32% for novel metaphors and 6.41% for conventional metaphors.

**Medium Confidence** - The claim that the explicit contrast between contextual and basic definitions better aligns with MIP steps 3-5 is theoretically sound but lacks direct empirical comparison with implicit methods to demonstrate superiority beyond numerical performance gains.

**Low Confidence** - The assertion that helper layers significantly improve performance when WSD fails is not directly validated in the paper. While the authors argue for their necessity, no ablation study quantifies their specific contribution to model performance.

## Next Checks
1. Conduct an ablation study to measure the individual contributions of the WSD model accuracy and helper layers to overall model performance, isolating their effects on both novel and conventional metaphor detection.

2. Test the model's robustness across different WSD model variants and WordNet versions to assess sensitivity to external resource changes and identify potential failure modes.

3. Compare explicit contrast approach with alternative implicit methods (e.g., using out-of-context embeddings as basic meaning) on the same datasets to directly validate the claimed advantage of explicit MIP alignment.