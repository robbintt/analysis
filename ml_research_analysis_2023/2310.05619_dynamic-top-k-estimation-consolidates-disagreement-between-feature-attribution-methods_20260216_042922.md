---
ver: rpa2
title: Dynamic Top-k Estimation Consolidates Disagreement between Feature Attribution
  Methods
arxiv_id: '2310.05619'
source_url: https://arxiv.org/abs/2310.05619
tags:
- methods
- attribution
- agreement
- human
- dynamic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the problem of feature attribution methods
  in NLP that disagree on which tokens to highlight as important for model predictions.
  The authors propose a dynamic top-k estimation method that determines the number
  of salient tokens for each method and instance based on local attribution peaks,
  rather than using a fixed k value.
---

# Dynamic Top-k Estimation Consolidates Disagreement between Feature Attribution Methods

## Quick Facts
- arXiv ID: 2310.05619
- Source URL: https://arxiv.org/abs/2310.05619
- Reference count: 8
- Key outcome: Dynamic top-k estimation improves agreement between feature attribution methods by focusing on relative attribution differences rather than absolute values

## Executive Summary
Feature attribution methods in NLP often disagree on which tokens to highlight as important for model predictions. This study proposes a dynamic top-k estimation method that determines the number of salient tokens for each method and instance based on local attribution peaks, rather than using a fixed k value. Experiments on an NLI task show that dynamic k improves agreement between methods, particularly for Integrated Gradient and GradientXInput, and yields a level of plausibility comparable to human preferences for k=4.

## Method Summary
The study uses a fine-tuned DistilBERT model on the e-SNLI dataset for NLI tasks. Six feature attribution methods (Vanilla Gradient, Integrated Gradient, Partition SHAP, LIME, Vanilla GradientXInput, and Integrated GradientXInput) are applied to calculate token-wise attribution scores. The dynamic k estimation method detects local attribution peaks in each method-instance pair's attribution profile, inspired by event detection in time series. Agreement@k metrics measure token relevance across methods, comparing fixed k versus dynamic k approaches.

## Key Results
- Dynamic k improves agreement between feature attribution methods compared to fixed k approaches
- The improvement is particularly significant for Integrated Gradient and GradientXInput methods
- Dynamic k values vary across methods and instances, with Integrated Gradient averaging 7.3±2.6 and Partition SHAP averaging 4.5±1.7
- Human preferences for k=4 align with the plausibility achieved by dynamic k estimation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dynamic top-k estimation improves agreement by focusing on relative attribution differences rather than absolute values
- Mechanism: The method detects local peaks in attribution profiles, allowing each method-instance pair to have its own k value
- Core assumption: Local attribution peaks represent truly salient features that are method-invariant
- Evidence anchors: [abstract] "Our approach is dynamic across sentences, method-agnostic, and deals with sentence length bias"

### Mechanism 2
- Claim: Dynamic k consolidation reduces disagreement between Integrated Gradient and GradientXInput specifically
- Mechanism: These gradient-based methods have distributed attribution profiles with multiple local maxima
- Core assumption: Integrated Gradient and GradientXInput produce more complex attribution profiles requiring flexible k values
- Evidence anchors: [abstract] "Their advantage over other methods disappears with dynamic ks which mainly improve Integrated Gradient and GradientXInput"

### Mechanism 3
- Claim: Dynamic k mitigates sentence length bias in feature attribution evaluation
- Mechanism: By determining k based on local attribution patterns rather than fixed values or fractions of sentence length
- Core assumption: Sentence length bias exists when k is determined by sentence length fractions or fixed values
- Evidence anchors: [abstract] "Our approach is dynamic across sentences, method-agnostic, and deals with sentence length bias"

## Foundational Learning

- Concept: Local maxima detection in time series
  - Why needed here: The dynamic k estimation relies on detecting attribution peaks in token sequences, similar to event detection in time series data
  - Quick check question: What defines a local maximum in a sequence of attribution scores, and how does it differ from a global maximum?

- Concept: Feature attribution methods in NLP
  - Why needed here: Understanding how different attribution methods produce attribution scores is crucial for interpreting the dynamic k approach
  - Quick check question: How do Vanilla Gradient, Integrated Gradient, LIME, and SHAP differ in their computation of token attribution scores?

- Concept: Agreement metrics in interpretability
  - Why needed here: The paper introduces a new agreement@k metric that measures token relevance across multiple methods
  - Quick check question: How does the proposed agreement@k metric differ from traditional MAP@k, and why is it more suitable for comparing multiple attribution methods?

## Architecture Onboarding

- Component map: Fine-tuned DistilBERT model -> Ferret package attribution calculations -> Peak detection algorithm -> Agreement@k calculator -> Output metrics
- Critical path: 1) Load fine-tuned model and attribution package, 2) Calculate attribution scores for all 6 methods, 3) Apply peak detection to determine dynamic k, 4) Compute agreement@k for all method pairs, 5) Compare fixed vs. dynamic k results
- Design tradeoffs: Peak detection sensitivity vs. noise detection, method-agnostic approach vs. method-specific optimization, computational cost vs. agreement improvement
- Failure signatures: Agreement scores unchanged between fixed and dynamic k, extremely consistent dynamic k values across methods, agreement improvement only for specific method pairs
- First 3 experiments: 1) Run peak detection on synthetic attribution profiles with known peaks, 2) Compare dynamic k values across methods on same instances, 3) Test agreement@k with dynamic k on subset using 2-3 methods

## Open Questions the Paper Calls Out
1. How does the dynamic top-k estimation method perform when applied to other natural language processing tasks beyond NLI?
2. What are the implications of using dynamic k for span-level visualizations, and how does it affect interpretability?
3. How does the choice of attribution methods influence the effectiveness of dynamic k, and are there specific methods that benefit more from this approach?

## Limitations
- The study focuses exclusively on a single NLI task using DistilBERT, limiting generalizability
- The dynamic k estimation method lacks detailed specification of implementation parameters
- The claim that local attribution peaks represent salient features is not directly validated against human perception

## Confidence
- High confidence: Dynamic k improves agreement between feature attribution methods
- High confidence: Dynamic k particularly benefits Integrated Gradient and GradientXInput methods
- Medium confidence: Dynamic k captures truly salient features through local attribution peaks
- Medium confidence: Dynamic k mitigates sentence length bias in evaluation

## Next Checks
1. Apply dynamic k approach to at least two additional NLP tasks (sentiment analysis and question answering) using different model architectures
2. Conduct ablation study varying peak detection sensitivity and threshold parameters
3. Perform human evaluation where annotators assess whether tokens selected by dynamic k correspond to their perception of important features