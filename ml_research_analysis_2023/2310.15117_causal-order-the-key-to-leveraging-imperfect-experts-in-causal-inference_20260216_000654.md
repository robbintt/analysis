---
ver: rpa2
title: 'Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference'
arxiv_id: '2310.15117'
source_url: https://arxiv.org/abs/2310.15117
tags:
- causal
- answer
- graph
- node
- nodes
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Causal inference typically requires a full causal graph, but this
  paper shows that causal order alone is sufficient for estimating causal effects
  via backdoor adjustment. To obtain this order, the authors propose a triplet-based
  LLM prompting strategy that asks the model to consider three variables at once,
  avoiding cycles that plague pairwise methods.
---

# Causal Order: The Key to Leveraging Imperfect Experts in Causal Inference

## Quick Facts
- arXiv ID: 2310.15117
- Source URL: https://arxiv.org/abs/2310.15117
- Reference count: 26
- Primary result: LLM-generated causal orders enable accurate causal effect estimation without full graph discovery

## Executive Summary
This paper addresses the challenge of leveraging expert knowledge in causal inference by showing that causal order alone suffices for estimating causal effects via backdoor adjustment. The authors propose a novel triplet-based LLM prompting strategy that outperforms pairwise methods by avoiding cycles and producing more accurate causal orders. By combining LLM-generated orders with existing discovery algorithms, they significantly improve topological accuracy while reducing reliance on full causal graph inference. The approach enables smaller LLMs to match or exceed GPT-4's performance in causal order prediction.

## Method Summary
The method generates causal orders by querying LLMs with triplet prompts that ask about three variables at once, avoiding cycles that plague pairwise approaches. For each triplet, the LLM outputs a 3-node DAG, which are aggregated via majority voting to form pairwise orientations. Ties are resolved using GPT-4 with chain-of-thought prompting. The resulting causal order is then integrated with constraint-based (PC) or score-based (CaMML) discovery algorithms as a prior constraint, improving their topological accuracy while maintaining valid backdoor adjustment sets.

## Key Results
- Triplet prompting produces more accurate causal orders than pairwise methods, avoiding cycles entirely
- Small LLMs (Phi-3, Llama-3 8B) match or exceed GPT-4's performance with triplet prompting
- Combining LLM orders with PC and CaMML algorithms significantly improves Dtop (topological divergence)
- Causal order alone suffices for backdoor adjustment when no latent confounding exists

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal order alone is sufficient for estimating causal effects via backdoor adjustment
- Mechanism: The backdoor adjustment formula requires blocking all non-causal paths between treatment and outcome, achievable by adjusting for variables preceding the treatment in causal order
- Core assumption: No latent confounding exists (all confounders are observed)
- Evidence anchors:
  - [abstract]: "causal order alone suffices for estimating causal effects via backdoor adjustment"
  - [section 4.1]: "Given a DAG G, a set of variables Z satisfies back-door criterion relative to a pair of treatment and target variables (Xi, Xj) if no variable in Z is a descendant of Xi; and Z blocks every path between Xi and Xj that contains an arrow into Xi."
- Break condition: If there are unobserved confounders, the causal order approach fails since it cannot identify the necessary adjustment set

### Mechanism 2
- Claim: Triplet-based prompting avoids cycles that plague pairwise methods
- Mechanism: By asking LLMs to consider three variables at once, the triplet prompt creates constraints that prevent contradictory edge orientations
- Core assumption: LLMs can consistently orient small triplets without cycles
- Evidence anchors:
  - [abstract]: "we propose the triplet method, a novel querying strategy that introduces an auxiliary variable for every variable pair and instructs the LLM to avoid cycles within this triplet"
  - [section 5.2]: "triplet-based prompt that asks LLM to consider three variables at once, compared to the pairwise prompts employed in past work"
  - [section 7.2]: "the triplet prompt provides the most robust causal order predictions" with "no cycles" for medium-size graphs
- Break condition: If LLMs cannot consistently orient triplets, the voting mechanism may produce incorrect results

### Mechanism 3
- Claim: Combining LLM output with existing discovery algorithms improves accuracy
- Mechanism: LLM-provided causal order serves as a constraint that guides constraint-based or score-based algorithms, reducing their search space and improving topological order accuracy
- Core assumption: LLM output, while imperfect, contains useful directional information
- Evidence anchors:
  - [abstract]: "algorithms that combine LLM-generated causal orders with existing discovery methods, significantly improving their accuracy"
  - [section 6]: "algorithms for combining LLM-outputted causal order with existing causal discovery paradigms"
  - [section 7.3]: "adding LLM to existing algorithms improves Dtop or keeps it constant" with "significant reductions in Dtop"
- Break condition: If LLM output is systematically wrong, it could mislead the discovery algorithms

## Foundational Learning

- Concept: Backdoor criterion and adjustment sets
  - Why needed here: The entire paper builds on the backdoor criterion being the mechanism for causal effect estimation from observational data
  - Quick check question: Given a treatment X, outcome Y, and confounders Z, what conditions must Z satisfy to be a valid adjustment set according to the backdoor criterion?

- Concept: Topological order and DAGs
  - Why needed here: Causal order is defined as a topological ordering, and the paper proves that this ordering alone suffices for effect estimation
  - Quick check question: In a DAG with edges A→B and B→C, what are the valid topological orderings?

- Concept: Large language model prompting strategies
  - Why needed here: The paper compares different prompting approaches (pairwise, iterative, triplet) to elicit causal knowledge from LLMs
  - Quick check question: What is the key difference between asking an LLM about pairwise relationships versus triplet relationships?

## Architecture Onboarding

- Component map:
  Input Variables -> LLM Triplet Module -> Aggregation Layer -> Integration Module -> Output Causal Order and Effects

- Critical path:
  1. Generate all variable triplets
  2. Query LLM for each triplet's causal subgraph
  3. Aggregate pairwise orientations via majority voting
  4. Resolve ties using GPT-4 with chain-of-thought
  5. Apply order to guide discovery algorithm
  6. Compute causal effects using backdoor adjustment

- Design tradeoffs:
  - Triplet prompting vs pairwise: More accurate but requires 3x more LLM queries
  - Voting vs deterministic rules: More robust but introduces stochasticity
  - LLM integration vs standalone: Better accuracy but more complex pipeline

- Failure signatures:
  - Cycles in output: Indicates triplet prompting failed or voting was inconsistent
  - High number of isolated nodes: LLM uncertain about specific variables' positions
  - Worsening of discovery algorithm: LLM order is misleading the algorithm

- First 3 experiments:
  1. Run triplet prompting on a simple 5-node graph (e.g., Earthquake) and verify no cycles
  2. Compare pairwise vs triplet prompting on the same graph, measuring cycle occurrence
  3. Integrate LLM order with PC algorithm on a small dataset and measure Dtop improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would the proposed triplet-based LLM prompting strategy perform on much larger causal graphs with hundreds of nodes?
- Basis in paper: [inferred] The paper demonstrates effectiveness on graphs with up to 22 nodes, but scalability to larger graphs is not explored
- Why unresolved: The computational complexity of generating all possible triplets grows rapidly with graph size, potentially making the method infeasible for very large graphs
- What evidence would resolve it: Experiments on benchmark graphs with 50-200 nodes comparing the triplet method's accuracy, runtime, and memory usage against other methods

### Open Question 2
- Question: What are the specific failure modes of LLMs when inferring causal order, and how can these be detected and corrected?
- Basis in paper: [explicit] The authors acknowledge that LLMs can exhibit unknown failure modes and discuss combining LLM outputs with existing discovery algorithms for robustness
- Why unresolved: The paper does not systematically characterize LLM failure modes or propose methods to detect them beyond the voting ensemble approach
- What evidence would resolve it: A comprehensive analysis of LLM outputs across diverse datasets identifying common errors, followed by development and validation of detection/correction mechanisms

### Open Question 3
- Question: How sensitive are the causal effect estimates to errors in the LLM-provided causal order, and what is the optimal tradeoff between order accuracy and computational efficiency?
- Basis in paper: [explicit] The authors show that Dtop correlates with effect estimation error but do not quantify the sensitivity or explore efficiency tradeoffs
- Why unresolved: While the paper establishes that causal order is sufficient for effect estimation, it does not characterize how much order errors degrade effect estimates or how this relates to computational costs
- What evidence would resolve it: Empirical studies varying the allowed topological divergence and measuring corresponding effect estimation errors and computational resources across multiple datasets

## Limitations

- The approach assumes no latent confounding, which would invalidate the causal order sufficiency claim
- Empirical validation is limited to benchmark causal graphs rather than real-world applications with unknown causal structures
- Performance improvements on relatively small graphs (up to 37 nodes) may not scale to larger, more complex causal structures

## Confidence

**High Confidence Claims:**
- Causal order alone suffices for backdoor adjustment when no latent confounding exists
- Triplet prompting reduces cycle formation compared to pairwise methods
- Combining LLM-generated orders with PC and CaMML algorithms improves topological accuracy

**Medium Confidence Claims:**
- Small LLMs can match or exceed GPT-4's performance with triplet prompting
- The voting ensemble effectively resolves conflicting triplet outputs
- The approach generalizes across multiple real-world benchmark graphs

**Low Confidence Claims:**
- Performance on graphs with latent confounding
- Scalability to very large causal graphs (>100 nodes)
- Robustness across diverse domains beyond the tested benchmarks

## Next Checks

1. **Latent Confounding Test**: Evaluate the approach on simulated graphs with known latent confounders to quantify performance degradation when the backdoor criterion assumptions are violated

2. **Scaling Experiment**: Apply the triplet prompting and integration methodology to larger benchmark graphs (100+ nodes) to assess computational feasibility and accuracy retention at scale

3. **Domain Transfer Validation**: Test the approach on causal inference problems from domains not represented in the current benchmark datasets (e.g., genomics, economics, or social network analysis) to evaluate generalizability