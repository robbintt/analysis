---
ver: rpa2
title: Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics
arxiv_id: '2309.16109'
source_url: https://arxiv.org/abs/2309.16109
tags:
- dynamics
- learning
- lemma
- which
- where
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies non-contrastive self-supervised learning, where
  a network learns representations using only positive views of data, without negative
  examples. While non-contrastive learning is effective, it lacks the repulsive force
  from negative examples that contrastive learning uses.
---

# Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics

## Quick Facts
- arXiv ID: 2309.16109
- Source URL: https://arxiv.org/abs/2309.16109
- Reference count: 40
- Primary result: Feature normalization (cosine loss) stabilizes non-contrastive learning dynamics by preventing representation collapse even under strong regularization

## Executive Summary
This paper analyzes why non-contrastive self-supervised learning methods succeed without negative examples. The key finding is that feature normalization, implemented through cosine loss, fundamentally changes the learning dynamics by inducing sixth-order eigenmode dynamics instead of third-order dynamics seen with L2 loss. This mathematical difference enables regime shifts that prevent representation collapse even under strong regularization, explaining the empirical success of methods like BYOL and SimSiam.

## Method Summary
The authors study non-contrastive learning dynamics using synthetic Gaussian data with a two-layer linear network (encoder Φ and projection head W) trained via gradient flow. They derive eigenmode dynamics by simultaneously diagonalizing the feature matrix F and projection head W, analyzing stability of equilibrium points. The key innovation is extending previous L2 loss analysis to cosine loss with feature normalization, revealing sixth-order dynamics that exhibit regime shifts preventing collapse. Numerical simulations validate the theoretical predictions under high-dimensional limits.

## Key Results
- Feature normalization induces sixth-order eigenmode dynamics vs third-order for L2 loss
- Cosine loss dynamics exhibit regime shifts from Collapse to Stable regimes as eigenmodes shrink
- Strong regularization initially causes collapse but enables recovery through regime shifts
- Simultaneous diagonalizability of F and W enables tractable analysis of individual eigenmodes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feature normalization (cosine loss) stabilizes non-contrastive learning dynamics by preventing representation collapse even under strong regularization.
- Mechanism: The cosine loss involves normalizing feature vectors before similarity computation. In the high-dimensional limit, this normalization concentrates feature norms, leading to sixth-order eigenmode dynamics that dynamically generate stable equilibria even when only collapsed solutions exist initially.
- Core assumption: The thermodynamical limit (d, h → ∞) holds so that feature norms concentrate around constants, allowing closed-form analysis of the dynamics.
- Evidence anchors:
  - [abstract]: "we extend the previous theory based on the L2 loss by considering the cosine loss, which involves feature normalization"
  - [section]: "Under the setup of synthetic data, we derive the learning dynamics of encoder parameters... We show that the cosine loss induces sixth-order dynamics"
  - [corpus]: "Weak evidence - corpus contains related papers on collapse prevention but none specifically analyze the sixth-order dynamics mechanism described here"
- Break condition: If the thermodynamical limit assumption fails (dimensions are too small), feature norm concentration breaks down and the analysis no longer applies.

### Mechanism 2
- Claim: The cosine loss dynamics undergo regime shifts from Collapse to Stable regimes as eigenmodes shrink, unlike L2 loss dynamics.
- Mechanism: When regularization is strong, the dynamics initially fall into the Collapse regime with only unstable equilibria. However, as eigenmodes approach zero, the parameter norms NΦ and NΨ shrink, causing a regime shift to the Stable regime where non-trivial stable equilibria emerge.
- Core assumption: Norms remain stable during training (Assumption 5) or at least undergo controlled shrinkage that enables regime shifts.
- Evidence anchors:
  - [section]: "Notably, Eq. (8) is a sixth-order non-linear ODE... From Fig. 2, we can classify the dynamics into three regimes (Collapse, Acute, Stable)"
  - [section]: "Importantly, this cosine loss dynamics stabilizes and would not collapse to zero regardless of the regularization strength ρ, which is in stark contrast to the L2 loss dynamics"
  - [corpus]: "Weak evidence - corpus mentions collapse prevention but doesn't detail the regime shift mechanism"
- Break condition: If eigenmodes don't shrink sufficiently or shrink too rapidly, the system may not transition properly between regimes.

### Mechanism 3
- Claim: Simultaneous diagonalizability of projection head W and feature matrix F enables tractable eigenmode analysis.
- Mechanism: The dynamics maintain commutativity between W and F (L(t) → 0), allowing both matrices to be simultaneously diagonalized. This decomposition reveals how individual eigenmodes evolve independently under the sixth-order dynamics.
- Core assumption: The commutator ∥[F, W]∥F remains small during training (Assumption 6 holds approximately).
- Evidence anchors:
  - [section]: "Let U be the common eigenvectors of F and W... By extending the discussion of [TCG21, Appendix B.1], we can show that U would not change over time"
  - [section]: "We verify the validity of the assumption in Section 5.4, where we see that the commutator remains to be nearly zero"
  - [corpus]: "No direct evidence - corpus doesn't discuss commutativity requirements for eigenmode analysis"
- Break condition: If the commutator grows large during training, simultaneous diagonalization breaks and the eigenmode decomposition becomes invalid.

## Foundational Learning

- Concept: High-dimensional concentration of measure
  - Why needed here: The analysis relies on feature norms concentrating in high dimensions to simplify the dynamics equations
  - Quick check question: If feature dimensions are small (h=64, d=512), would the concentration assumptions still hold reasonably?

- Concept: Dynamical systems stability analysis
  - Why needed here: Understanding when equilibrium points are stable/unstable determines whether representations collapse
  - Quick check question: How does the order of the ODE (third vs sixth) affect the number and stability of equilibrium points?

- Concept: Eigenvalue decomposition and simultaneous diagonalization
  - Why needed here: The analysis requires decomposing the dynamics into independent eigenmodes
  - Quick check question: What conditions must hold for two matrices to be simultaneously diagonalizable?

## Architecture Onboarding

- Component map: Data augmentation -> Encoder (Φ) -> Normalization -> Projection head (W) -> Loss -> Gradient update
- Critical path: Input → Augmentation → Encoder → Normalization → Loss → Gradient update
- Design tradeoffs:
  - Feature normalization vs L2 loss: Adds computational cost but enables regime shifts
  - Regularization strength: Too strong causes initial collapse but regime shifts can recover
  - Dimension choice: Must be large enough for concentration but practical for computation
- Failure signatures:
  - Representations collapsing to zero (collapse regime)
  - Eigenmodes not shifting between regimes properly
  - Commutator growing large (breaking diagonalization assumption)
- First 3 experiments:
  1. Test regime shifts by varying regularization strength (ρ) and observing eigenmode behavior
  2. Verify concentration of feature norms empirically in high dimensions
  3. Check commutativity preservation during training by monitoring ∥[F, W]∥F

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the sixth-order eigenmode dynamics to deviations from Assumptions 1-6?
- Basis in paper: [explicit] The authors note that Assumptions 1-6 simplify subsequent analyses but are tested empirically in Section 5.4
- Why unresolved: The theoretical analysis relies on these assumptions to derive the simplified eigenmode dynamics. Real-world non-contrastive learning may not perfectly satisfy these conditions.
- What evidence would resolve it: Numerical experiments varying initialization, projection head architecture, and feature normalization methods while tracking eigenmode evolution and stability.

### Open Question 2
- Question: Can the theoretical framework be extended to analyze other non-contrastive learning methods beyond BYOL/SimSiam?
- Basis in paper: [inferred] The authors focus on BYOL/SimSiam with cosine loss, but mention other non-contrastive methods like Barlow Twins, VICReg, and SwAV in the related work
- Why unresolved: The specific dynamics depend on the loss function and architecture. Different methods may exhibit different stability properties and equilibrium structures.
- What evidence would resolve it: Derive eigenmode dynamics for alternative non-contrastive methods and compare stability regions and equilibrium properties to those found for BYOL/SimSiam.

### Open Question 3
- Question: What are the implications of the cosine loss dynamics for downstream task performance?
- Basis in paper: [explicit] The authors note that understanding non-contrastive dynamics is a step toward analyzing downstream tasks, but refrain from addressing this directly
- Why unresolved: The paper focuses on theoretical stability of the learning dynamics rather than practical performance. The connection between stable dynamics and useful representations is not established.
- What evidence would resolve it: Empirical studies correlating eigenmode stability and regime transitions with linear probing accuracy, fine-tuning performance, and representation quality metrics across datasets and architectures.

## Limitations
- High-dimensional limit analysis may not hold for practical network sizes
- Simultaneous diagonalizability assumption (Assumption 6) only approximately satisfied in practice
- Regime shift mechanism depends on controlled shrinkage of eigenmodes requiring specific initialization scales

## Confidence
- Feature normalization prevents collapse (Medium): Supported by theoretical analysis but requires empirical validation on real data
- Regime shift mechanism (Medium): Theoretically derived but sensitive to initialization and hyperparameters
- Sixth-order dynamics vs third-order (High): Mathematical derivation is clear and internally consistent

## Next Checks
1. Test the regime shift empirically by varying regularization strength on real datasets (CIFAR-10, ImageNet) and measuring representation quality
2. Verify concentration of feature norms empirically across different dimensionalities (h, d values) to assess when the high-dimensional limit approximation breaks down
3. Monitor the commutator norm ∥[F, W]∥F during training to quantify how well the simultaneous diagonalization assumption holds in practice