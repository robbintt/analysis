---
ver: rpa2
title: 'LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers'
arxiv_id: '2305.18396'
source_url: https://arxiv.org/abs/2305.18396
tags:
- inference
- private
- uni00000013
- uni00000011
- softmax
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to improve privacy-preserving inference
  for transformer-based language models by replacing computationally expensive operators
  with more privacy-computing friendly approximations. The approach identifies GELU,
  softmax, and layer normalization as bottlenecks and substitutes them with ReLU-based
  alternatives while retaining model accuracy through fine-tuning.
---

# LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers

## Quick Facts
- arXiv ID: 2305.18396
- Source URL: https://arxiv.org/abs/2305.18396
- Authors: 
- Reference count: 40
- This paper proposes a method to improve privacy-preserving inference for transformer-based language models by replacing computationally expensive operators with more privacy-computing friendly approximations.

## Executive Summary
This paper addresses the computational and communication bottlenecks in privacy-preserving transformer inference by identifying GELU, softmax, and layer normalization as the primary expensive operations. The authors propose replacing these with ReLU-based approximations and simplified normalization while retaining model accuracy through fine-tuning. The resulting framework achieves a 5× speedup and 80% reduction in communication overhead compared to prior work, while maintaining nearly identical accuracy on BERT-Tiny.

## Method Summary
The paper builds a private inference system supporting FC layers, ReLU, GELU, softmax, and layer normalization to identify performance bottlenecks. The method substitutes expensive operators with privacy-computing friendly alternatives: ReLU for GELU, modified softmax, and affine transformation for layer normalization. Models are fine-tuned layer by layer from last block to first using a bound control mechanism to prevent overflow while maintaining accuracy. The approach leverages homomorphic encryption (BFV scheme) and secure multiparty computation (additive secret-sharing) primitives for private inference.

## Key Results
- Achieves 5× speedup compared to Iron baseline
- Reduces communication overhead by 80%
- Maintains nearly identical accuracy to original models after fine-tuning
- GELU can be replaced with ReLU with minimal accuracy loss
- Layer normalization can be simplified to affine transformation without standard deviation division

## Why This Works (Mechanism)

### Mechanism 1
- Replacing GELU and softmax with ReLU-based alternatives reduces cryptographic overhead significantly while maintaining accuracy.
- GELU requires tanh evaluations and multiple multiplications, softmax requires exp and division; ReLU and simple ReLU-based softmax approximations eliminate these expensive operations.
- Core assumption: The model can adapt to these approximations through fine-tuning without losing significant performance.
- Evidence: GELU is the most expensive operator in private inference pipeline; can be simply replaced with ReLU with nearly no accuracy drop.

### Mechanism 2
- Layer normalization can be simplified to only centralization and affine transformation without standard deviation division.
- The affine transformation γ and β can capture the scaling effect of standard deviation, eliminating expensive reciprocal and square root operations.
- Core assumption: The model can learn appropriate scaling through the affine parameters during fine-tuning.
- Evidence: The expensive part of layer normalization is the division operation of standard deviation.

### Mechanism 3
- Sequential layer-by-layer substitution with bound control prevents overflow and maintains accuracy.
- Gradual substitution starting from the last layer with decreasing bounds prevents hidden state explosion that causes overflow in fixed-point representation.
- Core assumption: Early layers are more critical for accuracy, so preserving them while substituting later layers maintains overall performance.
- Evidence: Earlier LN layers are more important; design workflow to gradually substitute operators layer by layer from last block to first.

## Foundational Learning

- Concept: Homomorphic Encryption (HE) and Secure Multiparty Computation (MPC)
  - Why needed here: These cryptographic primitives enable private inference where neither party learns the other's data
  - Quick check question: What are the main operations supported by HE and what limitations does it have for neural networks?

- Concept: Transformer architecture components (attention, GELU, softmax, layer norm)
  - Why needed here: Understanding which components are computationally expensive for private inference
  - Quick check question: Which transformer components require the most cryptographic operations in private inference?

- Concept: Fixed-point arithmetic and overflow handling
  - Why needed here: Essential for implementing the bound control mechanism during fine-tuning
  - Quick check question: How does fixed-point representation affect the range of values that can be represented without overflow?

## Architecture Onboarding

- Component map:
  - Input preprocessing → Secret sharing → Matrix multiplication (HE) → Non-linear operations (MPC) → Output reconstruction
  - Key modules: Matrix multiplication protocol, ReLU/softmax substitution, Layer norm simplification, Bound control

- Critical path: Matrix multiplication → Non-linear operations → Output generation
  - Matrix multiplication dominates computation time, non-linear operations dominate communication

- Design tradeoffs:
  - Accuracy vs privacy efficiency: More aggressive substitutions improve efficiency but may reduce accuracy
  - Communication vs computation: HE reduces communication but increases computation; MPC reduces computation but increases communication

- Failure signatures:
  - Overflow errors: Hidden states exceed fixed-point bounds
  - Accuracy degradation: Substitutions too aggressive for fine-tuning to compensate
  - Communication bottlenecks: Insufficient bandwidth for MPC operations

- First 3 experiments:
  1. Replace GELU with ReLU in BERT-Tiny on MRPC dataset, measure accuracy drop and runtime improvement
  2. Implement simplified softmax with ReLU approximation, compare against original softmax in terms of accuracy and communication cost
  3. Test layer-by-layer substitution strategy with bound control, identify the point where accuracy degradation becomes unacceptable

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the fundamental reason that replacing the first few LayerNorm layers causes accuracy collapse while replacing later ones does not?
- Basis in paper: Explicit observation that "earlier LN layers are more important" and "the first few layers are essential to capture the overall features of the input sentences"
- Why unresolved: The paper conjectures about feature capture but doesn't empirically test what specific role these early LayerNorms play or what architectural changes could preserve their function when replaced
- What evidence would resolve it: Ablation studies isolating early vs late LayerNorm contributions, or architectural modifications that preserve early LayerNorm functionality while maintaining privacy-computing friendliness

### Open Question 2
- Question: Could the accuracy improvements observed when replacing GELU with ReLU be replicated in other transformer architectures or training regimes?
- Basis in paper: Explicit observation that "using ReLU instead of GELU sometimes results in better accuracy than the original models"
- Why unresolved: The paper only tests this on fine-tuned models and doesn't explore whether this phenomenon extends to other architectures, training objectives, or training from scratch scenarios
- What evidence would resolve it: Systematic experiments across different transformer architectures, training objectives, and training paradigms comparing GELU vs ReLU performance

### Open Question 3
- Question: How does the bound control mechanism's effectiveness scale with model size and depth?
- Basis in paper: Explicit description of bound control mechanism with decreasing bounds across substitutions, but no systematic analysis of its effectiveness across different model scales
- Why unresolved: The paper uses fixed bounds for different model sizes but doesn't explore how these bounds should scale with model depth, embedding dimension, or sequence length
- What evidence would resolve it: Empirical studies measuring overflow rates and accuracy impacts across various model sizes with systematically varied bound parameters

## Limitations
- Experimental validation limited to BERT-Tiny on single MRPC dataset
- Unclear whether 5× speedup and 80% communication reduction scale to larger models
- Missing specific implementation details for GPU-accelerated BFV cryptosystem
- Fine-tuning procedure details not fully specified

## Confidence
**High Confidence** (4 claims):
- GELU and softmax are computationally expensive operators in private inference contexts
- Privacy-computing friendly approximations can reduce cryptographic overhead
- Layer normalization can be simplified to affine transformation without standard deviation division
- Sequential layer-by-layer substitution strategy with bound control prevents overflow

**Medium Confidence** (2 claims):
- 5× speedup and 80% communication reduction claims based on specific implementation details
- Nearly identical accuracy maintenance requires careful tuning of bound control mechanism

## Next Checks
1. Scale-up Validation: Test operator substitution approach on BERT-Base with multiple datasets to verify performance improvements scale beyond BERT-Tiny and MRPC.

2. Robustness Testing: Evaluate model performance with different random seeds and varying bound control parameters to assess stability of fine-tuning adaptation.

3. Cross-Architecture Generalization: Apply same operator substitution strategy to GPT-style transformers to determine approach generalizes beyond BERT-style architectures.