---
ver: rpa2
title: Interactive Distillation of Large Single-Topic Corpora of Scientific Papers
arxiv_id: '2309.10772'
source_url: https://arxiv.org/abs/2309.10772
tags:
- papers
- dataset
- core
- topic
- documents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces BUNIE, a novel interactive machine learning
  tool for expanding and refining highly specific datasets of scientific literature.
  BUNIE uses a citation network traversal approach combined with human-in-the-loop
  pruning to constructively build targeted corpora.
---

# Interactive Distillation of Large Single-Topic Corpora of Scientific Papers

## Quick Facts
- **arXiv ID:** 2309.10772
- **Source URL:** https://arxiv.org/abs/2309.10772
- **Reference count:** 32
- **Key outcome:** BUNIE achieves dataset expansion from 6-63 to 79-453 papers while increasing compactness scores from 0.823 to 0.861 through citation network traversal and human-in-the-loop pruning.

## Executive Summary
This paper introduces BUNIE, a novel interactive machine learning tool for expanding and refining highly specific datasets of scientific literature. BUNIE uses a citation network traversal approach combined with human-in-the-loop pruning to constructively build targeted corpora. Key techniques include SciNCL transformer-based document embeddings, UMAP dimensionality reduction for visualization, and SeNMFk topic modeling. The tool was applied to two domains - tensor decomposition and audio processing - achieving significant dataset expansion while maintaining topic coherence, with compactness scores increasing from 0.823 to 0.861 after pruning. BUNIE offers an effective solution for literature review and dataset curation at scale.

## Method Summary
BUNIE starts with a small core corpus of scientific papers and iteratively expands it through citation network traversal. At each hop, it generates SciNCL embeddings for all papers and uses UMAP to create a 2D visualization for human-in-the-loop pruning. Papers are removed if they're deemed off-topic through manual selection or automatic methods including hypersphere pruning (based on core paper embedding distances) and SeNMFk topic modeling. The process repeats until the dataset reaches the desired size while maintaining high topic coherence measured by compactness scores.

## Key Results
- Dataset expansion from 6-63 papers to 79-453 papers across two domains (tensor decomposition and audio processing)
- Compactness score improvements from 0.823 to 0.861 after iterative pruning
- Successful maintenance of topic coherence during significant dataset growth
- Effective human-in-the-loop pruning combined with automatic methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Citation network traversal with document embeddings enables scalable topic-specific dataset expansion.
- Mechanism: Starting from a small core corpus, BUNIE iteratively traverses the citation network, expanding the dataset while maintaining relevance through embedding-based similarity checks.
- Core assumption: Citation networks contain relevant papers for the core topic and that document embeddings accurately capture topical similarity.
- Evidence anchors:
  - [abstract]: "Given a small initial 'core' corpus of papers, we build a citation network of documents. At each step of the citation network, we generate text embeddings and visualize the embeddings through dimensionality reduction."
  - [section]: "With the core established, the user can grow the dataset by making a 'hop' within the citation network. The citation network represents a directed graph formed by publications and their respective citations."
  - [corpus]: Weak evidence - corpus shows related work on literature review tools but doesn't directly support citation network effectiveness.
- Break condition: Citation networks become sparse or disconnected from core topic, or embeddings fail to capture semantic similarity.

### Mechanism 2
- Claim: Human-in-the-loop pruning using UMAP visualization and bag-of-words wordclouds enables effective manual curation of large datasets.
- Mechanism: UMAP reduces 768-dimensional SciNCL embeddings to 2D for visualization, allowing users to identify and remove off-topic papers through interactive selection.
- Core assumption: UMAP preserves enough structural information for humans to identify relevant clusters, and bag-of-words wordclouds provide sufficient topical context.
- Evidence anchors:
  - [abstract]: "Papers are kept in the dataset if they are 'similar' to the core or are otherwise pruned through human-in-the-loop selection."
  - [section]: "To simplify this task, we employ SciNCL to transform the aggregated titles and abstracts of the dataset into 768-dimensional embeddings. These high-dimensional embeddings are reduced to a two-dimensional projection using UMAP."
  - [corpus]: Weak evidence - corpus mentions visualization tools but doesn't validate UMAP+bag-of-words approach specifically.
- Break condition: UMAP projection fails to preserve topical structure or wordclouds become uninformative at scale.

### Mechanism 3
- Claim: Topic modeling with SeNMFk and hypersphere pruning maintains dataset coherence during expansion.
- Mechanism: SeNMFk decomposes the corpus into topics, preserving only documents matching core paper topics, while hypersphere pruning removes documents too distant from core embeddings in high-dimensional space.
- Core assumption: SeNMFk can identify and preserve relevant topics, and hypersphere distance correlates with topical relevance.
- Evidence anchors:
  - [abstract]: "Additional insight into the papers is gained through sub-topic modeling using SeNMFk topic modeling."
  - [section]: "To further ensure topic cohesion, we perform topic modeling on the pruned dataset... We utilize Semantic non-negative matrix factorization with automatic model selection (SeNMFk) for topic modeling."
  - [corpus]: Weak evidence - corpus mentions topic modeling tools but doesn't validate SeNMFk specifically.
- Break condition: SeNMFk fails to correctly identify core topics or hypersphere distance metric becomes ineffective.

## Foundational Learning

- Concept: Citation network traversal and graph algorithms
  - Why needed here: BUNIE's core expansion mechanism relies on systematically traversing citation networks to find related papers.
  - Quick check question: How would you implement a breadth-first search of a citation network starting from a core paper set?

- Concept: Document embeddings and similarity metrics
  - Why needed here: BUNIE uses SciNCL embeddings and cosine similarity to assess paper relevance during pruning.
  - Quick check question: How would you calculate cosine similarity between two document embeddings and interpret the result?

- Concept: Topic modeling and non-negative matrix factorization
  - Why needed here: SeNMFk is used to decompose the corpus into topics and identify relevant papers for the core topic.
  - Quick check question: How does SeNMFk differ from standard NMF, and why might it be better for scientific literature?

## Architecture Onboarding

- Component map: GUI (UMAP visualization + wordclouds) → SciNCL embedding generator → UMAP reducer → Pruning modules (HITL, hypersphere, SeNMFk) → Corpus storage
- Critical path: Core paper input → Citation network expansion → Embedding generation → UMAP visualization → HITL pruning → Automatic pruning → Topic modeling → Final dataset output
- Design tradeoffs: HITL pruning provides accuracy but doesn't scale; automatic pruning scales but may miss nuanced relevance; SeNMFk ensures coherence but may be computationally expensive.
- Failure signatures: Dataset grows too large (pruning ineffective); dataset becomes too small (over-pruning); topics become incoherent (SeNMFk failure); UMAP visualization becomes cluttered.
- First 3 experiments:
  1. Start with a small core (6-10 papers) in a well-defined topic, perform 2-3 hops, and manually verify pruned output relevance.
  2. Test hypersphere pruning parameters by varying ρ and measuring compactness score changes.
  3. Compare SeNMFk vs standard NMF on a sample dataset and measure topic coherence.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design an autonomous system that dynamically adapts topic extraction and refinement based on continuous feedback on the topic's state?
- Basis in paper: [explicit] The authors mention promising future work in seeding an initial topic specification and iterating autonomously, filtering out documents and recalculating topic estimates to achieve topic distillation based on reinforcement learning.
- Why unresolved: Current BUNIE requires manual intervention at each pruning step, and there is no existing implementation of an autonomous feedback-driven system for topic refinement.
- What evidence would resolve it: A working prototype demonstrating autonomous topic refinement with measurable improvements in topic coherence over multiple iterations would provide evidence.

### Open Question 2
- Question: How can we develop methods to create a 'synthetic' core paper that serves as a foundation for automated topic alignment?
- Basis in paper: [explicit] The authors suggest exploring methods of creating a 'synthetic' core paper as part of future work.
- Why unresolved: Creating a synthetic core paper that accurately represents the topic without human input is a complex challenge in natural language generation and topic modeling.
- What evidence would resolve it: A method that successfully generates synthetic core papers which, when used in BUNIE, produce comparable or improved results to manually selected cores would provide evidence.

### Open Question 3
- Question: How can graph neural networks be utilized to better understand the relationship between citations and improve insights into the structure and interconnections of scientific literature?
- Basis in paper: [explicit] The authors suggest exploring the utilization of graph neural networks for understanding the relationship between citations as part of future work.
- Why unresolved: While citation networks are used in BUNIE, the full potential of graph neural networks in capturing complex citation patterns and their implications for topic modeling remains unexplored.
- What evidence would resolve it: A study comparing BUNIE with and without graph neural network integration, showing improved topic coherence or more meaningful dataset expansion, would provide evidence.

## Limitations

- Lack of detailed hyperparameter specifications for SciNCL, UMAP, and SeNMFk components
- Evaluation relies solely on compactness scores without external validation of dataset quality
- Human-in-the-loop pruning effectiveness depends heavily on user expertise and may not scale well

## Confidence

- **High confidence:** The core citation network traversal mechanism is well-established and the basic framework is sound
- **Medium confidence:** The combination of pruning methods is plausible but effectiveness depends on implementation details not fully specified
- **Low confidence:** The specific claims about compactness score improvements require more rigorous validation with multiple datasets and comparison to alternatives

## Next Checks

1. Implement a controlled experiment comparing BUNIE's expansion and pruning to a simple baseline (e.g., random sampling or keyword filtering) on the same core datasets
2. Conduct user studies with domain experts to evaluate whether manually pruned datasets actually contain more relevant papers than automatically pruned ones
3. Test the tool's robustness by applying it to datasets with known ground truth (e.g., curated review articles) and measuring precision/recall of recovered relevant papers