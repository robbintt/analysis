---
ver: rpa2
title: Improving Speech Inversion Through Self-Supervised Embeddings and Enhanced
  Tract Variables
arxiv_id: '2309.09220'
source_url: https://arxiv.org/abs/2309.09220
tags:
- speech
- hubert
- input
- data
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates two methods for improving acoustic-to-articulatory
  speech inversion: using self-supervised speech embeddings (HuBERT) as input features,
  and employing an improved geometric transformation model to extract more accurate
  tract variables from articulatory data. The proposed geometric transformation better
  captures the relationship between articulatory movements and acoustic output, while
  HuBERT embeddings provide richer input representations compared to conventional
  MFCCs.'
---

# Improving Speech Inversion Through Self-Supervised Embeddings and Enhanced Tract Variables

## Quick Facts
- arXiv ID: 2309.09220
- Source URL: https://arxiv.org/abs/2309.09220
- Reference count: 0
- Primary result: 6.9% improvement in Pearson correlation (PPMC) from 0.7452 to 0.8141 for tract variable estimation

## Executive Summary
This paper investigates two complementary approaches to improve acoustic-to-articulatory speech inversion: using self-supervised speech embeddings (HuBERT) as input features, and employing an improved geometric transformation model to extract more accurate tract variables from articulatory data. The study demonstrates that combining these approaches yields a 6.9% improvement in Pearson product-moment correlation scores for tract variable estimation. By leveraging HuBERT's richer speech representations and a more accurate geometric transformation that better captures constriction-based articulatory features, the proposed system achieves state-of-the-art performance in predicting articulatory tract variables from speech audio.

## Method Summary
The method combines improved input representations with enhanced output transformations for speech inversion. Input features use HuBERT self-supervised embeddings (1024-dimensional, 50 Hz) extracted from 16 kHz audio, replacing conventional MFCCs. The output transformation employs a novel geometric model that maps raw articulator positions to constriction-based tract variables (Tongue Body Constriction Degree, Tongue Tip Constriction Degree, etc.) by fitting tongue body circles and measuring distances to an extended palatal trace. A Bidirectional Gated Recurrent Unit (BiGRNN) architecture is trained on the X-ray Microbeam dataset, with speaker-independent splits (36/5/5 for train/val/test). The system is optimized using ADAM with early stopping on validation loss.

## Key Results
- PPMC scores improved from 0.7452 to 0.8141, representing a 6.9% increase
- HuBERT embeddings outperform MFCCs as input features for speech inversion
- The novel geometric transformation produces more acoustically relevant tract variables
- Combined approach yields better performance than either improvement alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HuBERT self-supervised embeddings improve speech inversion performance by providing richer input features that better capture articulatory information than conventional MFCCs.
- Mechanism: HuBERT embeddings are learned through a self-supervised masking task that requires the model to predict masked regions of speech using context from both directions. This creates representations that encode fine-grained phonetic and articulatory structure without requiring labeled articulatory data during pre-training.
- Core assumption: The masked prediction objective in HuBERT training inherently captures articulatory-relevant information that transfers to the speech inversion task.
- Evidence anchors: [abstract] "utilizing speech representations acquired via self-supervised learning (SSL) models, such as HuBERT compared to conventional acoustic features" [section 4.1] "Based on the previous work in [13] for using SSL features for the SI task with EMA data, we explored the idea of using HuBERT SSL features [14] as the input acoustic representation to train our best performing Bidirectional Gated Recurrent Unit (BiGRNN) SI architecture."
- Break condition: If HuBERT embeddings do not contain sufficient articulatory-relevant structure (e.g., if masking strategy fails to preserve positional or constriction-related cues), then fine-tuning will not improve inversion performance.

### Mechanism 2
- Claim: The improved geometric transformation produces tract variables that are more closely related to acoustic output, thereby improving inversion accuracy.
- Mechanism: The transformation maps raw articulator positions to constriction-based variables (e.g., Tongue Body Constriction Degree) that directly relate to acoustic effects. By modeling the tongue body as a fitted circle and measuring distances to an extended palatal trace, the transformation captures constriction location and degree in a speaker-normalized way.
- Core assumption: Acoustic output depends more on constriction location and degree than on absolute articulator positions, so TVs derived from constrictions will correlate better with acoustics.
- Evidence anchors: [abstract] "incorporation of novel tract variables (TVs) through an improved geometric transformation model" [section 3.1.2] "TBCD is measured as the minimum Euclidean distance between the tongue body circle and the extended palatal trace"
- Break condition: If the geometric model fails to accurately capture constriction relationships (e.g., due to inaccurate circle fitting or palate trace definition), TVs will not correlate better with acoustics and inversion performance will not improve.

### Mechanism 3
- Claim: Combining improved input features and improved output representations yields multiplicative gains in inversion accuracy beyond either alone.
- Mechanism: Better input features (HuBERT) provide more discriminative speech representations, while better output representations (novel TVs) provide a more acoustically relevant target space. Training a model on this combination allows the network to learn a more effective mapping from speech to articulatory constriction parameters.
- Core assumption: The improvements from input and output enhancements are complementary and not redundant; they capture different aspects of the speech-articulatory relationship.
- Evidence anchors: [abstract] "By combining these two approaches, we improve the Pearson product moment correlation (PPMC) scores which evaluate the accuracy of TV estimation of the SI system from 0.7452 to 0.8141, a 6.9% increase." [section 5.2] "Overall, by combining better input and output representations, along with including more data, we were able to improve the PPMC score by from 0.7452 to 0.8141, a 6.9% improvement."
- Break condition: If either the input or output improvements are ineffective, the combined gain will not exceed the better single improvement; if they are redundant, no multiplicative gain occurs.

## Foundational Learning

- Concept: Self-supervised learning and masked prediction objectives
  - Why needed here: Understanding how HuBERT learns representations without labels is key to knowing whether its embeddings will contain articulatory-relevant information transferable to inversion.
  - Quick check question: What does the masked prediction task in HuBERT optimize for, and why might that be relevant to articulatory inference?

- Concept: Geometric transformations and tract variables
  - Why needed here: The paper relies on transforming raw articulator coordinates into TVs that are more closely related to acoustics; knowing how this works is essential to evaluate the proposed transformation.
  - Quick check question: How do constriction-based TVs differ from raw coordinate representations, and why are they expected to correlate better with acoustic output?

- Concept: Correlation metrics and model evaluation
  - Why needed here: The paper uses Pearson Product Moment Correlation (PPMC) to measure inversion accuracy; understanding what this metric captures is necessary to interpret results.
  - Quick check question: What does a PPMC of 0.8141 between predicted and ground-truth TVs indicate about the model's performance?

## Architecture Onboarding

- Component map: Raw audio -> HuBERT embeddings (1024-dim, 50 Hz) -> BiGRNN encoder -> 6 tract variables (LA, LP, TBCL, TBCD, TTCL, TTCD) -> PPMC evaluation
- Critical path: 1. Extract HuBERT embeddings from raw audio 2. Feed embeddings into BiGRNN encoder 3. Predict 6 TVs from encoder output 4. Compute PPMC against ground truth for evaluation
- Design tradeoffs: HuBERT vs MFCC: HuBERT provides richer, pre-trained representations but requires more compute to extract; MFCCs are simple and fast but less expressive. Geometric transformation complexity: More accurate TV definitions improve correlation but increase computational cost and potential for numerical instability in circle fitting. Dataset size: Using reconstructed files increases training data but may introduce label noise.
- Failure signatures: Low PPMC across all TVs: Likely issue with either input features not containing articulatory info or output transformation not capturing acoustics. High PPMC for some TVs, low for others: Indicates specific TVs may be poorly defined or the model struggles with certain constriction types. Overfitting (train PPMC >> val PPMC): Model memorizing training speakers rather than learning generalizable articulatory patterns.
- First 3 experiments: 1. Train baseline BiGRNN with MFCCs and original TV transformation; verify PPMC â‰ˆ 0.745. 2. Replace MFCCs with HuBERT embeddings but keep original TV transformation; check for PPMC improvement. 3. Replace TV transformation with proposed geometric model but keep MFCCs; verify improvement over baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does extending the tongue body circle beyond T4 affect the accuracy of Tongue Body Constriction Location (TBCL) estimation?
- Basis in paper: [explicit] The authors acknowledge that their current model lags behind the transformation proposed in [16] for TBCL and suggest that not extending the tongue body circle beyond T4 might be a reason for this discrepancy.
- Why unresolved: The authors did not implement this extension in their current model, leaving the potential improvement unexplored.
- What evidence would resolve it: Implementing the extended tongue body circle and evaluating the resulting TBCL estimation accuracy and PPMC scores would provide evidence.

### Open Question 2
- Question: What is the impact of using different SSL models (e.g., wav2vec2, tera) compared to HuBERT on the performance of acoustic-to-articulatory speech inversion?
- Basis in paper: [explicit] The authors reference previous work that found HuBERT to be the best among SSL models for SI tasks, but they do not directly compare other SSL models in their study.
- Why unresolved: The authors chose to focus on HuBERT based on prior research and did not explore the performance of other SSL models in their experiments.
- What evidence would resolve it: Conducting experiments using different SSL models as input features and comparing their performance with HuBERT in terms of PPMC scores would provide evidence.

### Open Question 3
- Question: How does the size of the training dataset affect the performance of SI models when using HuBERT features compared to MFCC features?
- Basis in paper: [inferred] The authors mention that improving input representations was more effective than increasing training data size, but they do not provide a detailed analysis of the relationship between dataset size and feature type.
- Why unresolved: The authors did not systematically vary the size of the training dataset or directly compare the effects of dataset size on HuBERT and MFCC features.
- What evidence would resolve it: Training SI models with varying sizes of training datasets using both HuBERT and MFCC features and comparing their performance would provide evidence.

## Limitations

- Geometric transformation details underspecified: The exact implementation of the novel geometric transformation, particularly for TBCL and TTCL, lacks complete definition of the extended palatal trace.
- HuBERT feature extraction pipeline unclear: The preprocessing and normalization steps for extracting HuBERT features are not fully described.
- No ablation experiments: The study lacks controlled experiments to isolate the individual contributions of input features versus output transformations.

## Confidence

- HuBERT embeddings improve inversion accuracy: Medium
- Novel geometric transformation produces more acoustically relevant TVs: Medium
- Combined approach yields multiplicative gains: Low

## Next Checks

1. Implement ablation study comparing: (a) baseline MFCC + original transformation, (b) HuBERT + original transformation, (c) MFCC + new transformation, (d) HuBERT + new transformation, to quantify individual contribution of each improvement.

2. Verify geometric transformation implementation by checking intermediate TV values against the paper's definitions and ensuring numerical stability of circle fitting procedures.

3. Replicate results using standard speaker-independent train/validation/test splits (36/5/5 speakers) and confirm that learning rate and batch size optimization yields the reported performance gains.