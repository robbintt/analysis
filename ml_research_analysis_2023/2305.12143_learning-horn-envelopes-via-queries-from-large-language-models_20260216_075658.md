---
ver: rpa2
title: Learning Horn Envelopes via Queries from Large Language Models
arxiv_id: '2305.12143'
source_url: https://arxiv.org/abs/2305.12143
tags:
- horn
- then
- algorithm
- learning
- negative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem of extracting interpretable rules
  from neural networks, particularly pre-trained language models, to uncover hidden
  biases. The authors adapt Angluin''s classical algorithm for learning Horn theories
  to this setting, but must overcome three key obstacles: (1) simulating equivalence
  queries using random sampling, (2) converting neural network inputs/outputs to propositional
  logic, and (3) handling non-Horn targets by learning the Horn envelope.'
---

# Learning Horn Envelopes via Queries from Large Language Models

## Quick Facts
- arXiv ID: 2305.12143
- Source URL: https://arxiv.org/abs/2305.12143
- Reference count: 40
- Key outcome: Algorithm learns Horn envelopes from neural networks via queries, revealing gender biases in BERT/RoBERTa

## Executive Summary
This paper addresses the challenge of extracting interpretable rules from neural networks, specifically pre-trained language models, to uncover hidden biases. The authors adapt Angluin's classical algorithm for learning Horn theories to this setting, overcoming three key obstacles: simulating equivalence queries with random sampling, converting neural network inputs/outputs to propositional logic, and handling non-Horn targets by learning their Horn envelopes. The proposed algorithm learns the tightest Horn approximation of an arbitrary Boolean function defined by a neural network and proves termination in exponential time (worst case) or polynomial time if the target has polynomially many non-Horn examples. Experiments on BERT and RoBERTa successfully extract interpretable rules revealing gender biases in occupation associations.

## Method Summary
The method adapts Angluin's exact learning algorithm for Horn formulas to work with neural network oracles. It maintains two sets: E- (Horn negative examples) and Enh (non-Horn negative examples). When a negative counterexample is encountered, it's either added to E- or used to refine an existing example. The algorithm constructs Horn clauses from E- and non-Horn clauses from Enh, ensuring termination. For language models, interpretations are converted to natural language expressions using a lookup table, then queried and converted back to the algorithm's format. The approach is validated on BERT and RoBERTa using 100-200 equivalence queries to extract rules revealing gender biases in occupation associations.

## Key Results
- Successfully extracts interpretable rules revealing gender biases (e.g., "women are not mathematicians, diplomats, bankers")
- Algorithm terminates in exponential time (worst case) and polynomial time if non-Horn examples are polynomially bounded
- Proves the algorithm is at least as hard as learning CNFs
- Demonstrates practical extraction of rules from BERT and RoBERTa models

## Why This Works (Mechanism)

### Mechanism 1
The algorithm learns Horn envelopes by maintaining E- (Horn negative examples) and Enh (non-Horn negative examples) sets. When encountering negative counterexamples, it adds them to E- or refines existing examples, constructing Horn clauses from E- and non-Horn clauses from Enh. This ensures termination by systematically covering all possible counterexamples.

Core assumption: The target Boolean function can be approximated by its Horn envelope, and neural network behavior can be queried to simulate membership and equivalence queries.

Evidence anchors:
- [abstract]: "We propose a new algorithm that aims at extracting the 'tightest Horn approximation' of the target theory"
- [section]: "We propose an adaptation of Angluin's algorithm for Horn formulas to deal with non-Horn oracles"

Break condition: If neural network behavior changes during learning or Horn envelope is too large (exponential in V), algorithm may not terminate in polynomial time.

### Mechanism 2
The algorithm converts interpretations to natural language expressions using a lookup table, queries language models, and converts classifications back to algorithm format. This enables using language models as oracles for membership and equivalence queries.

Core assumption: Language model behavior can be queried to simulate membership and equivalence queries, and conversion between representations is accurate.

Evidence anchors:
- [abstract]: "Experiments on BERT and RoBERTa language models extract rules revealing gender biases"
- [section]: "We convert interpretations into expressions in natural language and then the classification of the model back into the format expected by the algorithm"

Break condition: If language model behavior changes during learning or conversion is inaccurate, extracted rules may be unreliable.

### Mechanism 3
The algorithm learns Horn envelopes in polynomial time when non-Horn examples are polynomially bounded by using a modified Angluin algorithm that tracks positive examples to exclude non-Horn negative examples with weakest possible non-Horn clauses.

Core assumption: Number of non-Horn examples is polynomially bounded by |env(φ)| and |V|, where env(φ) is the Horn envelope of target formula φ.

Evidence anchors:
- [abstract]: "guaranteed to terminate in exponential time (in the worst case) and in polynomial time if the target has polynomially many non-Horn examples"
- [section]: "We prove that this algorithm is guaranteed to terminate in exponential time and in polynomial time in the size of the most concise Horn envelope of the target formula and the number of variables if the number of non-Horn examples is polynomial"

Break condition: If non-Horn examples are exponential in |env(φ)| and |V|, algorithm may not terminate in polynomial time.

## Foundational Learning

- **Propositional logic and Horn formulas**: The algorithm operates on propositional formulas, specifically Horn formulas, to learn the Horn envelope of a target formula.
  - Why needed here: Core mathematical framework for the learning algorithm
  - Quick check question: Can you explain the difference between a Horn formula and a general propositional formula?

- **Exact learning with membership and equivalence queries**: The algorithm uses membership and equivalence queries to learn the Horn envelope of a target formula defined by a neural network.
  - Why needed here: Fundamental learning framework for extracting interpretable rules
  - Quick check question: How do membership and equivalence queries differ in the context of exact learning?

- **Language model probing and bias extraction**: The algorithm uses pre-trained language models as oracles to extract interpretable rules revealing biases.
  - Why needed here: Enables practical application to real-world bias detection
  - Quick check question: How can pre-trained language models be used to probe for biases in a given dataset?

## Architecture Onboarding

- **Component map**: Neural network (oracle) -> Algorithm (Horn envelope learner) -> Conversion module (interpretations ↔ natural language) -> Lookup table (attributes → expressions)

- **Critical path**: 
  1. Initialize algorithm with empty E- and Enh sets
  2. Pose equivalence queries to neural network using random sampling
  3. Convert counterexamples to natural language expressions and query language model
  4. Update E- and Enh sets based on classification
  5. Construct Horn and non-Horn clauses from E- and Enh sets
  6. Repeat until termination

- **Design tradeoffs**: 
  - Runtime vs. quality of extracted rules: More equivalence queries improve rule quality but increase runtime
  - Accuracy of conversion vs. complexity: More accurate conversion between representations may increase complexity

- **Failure signatures**:
  - Non-termination: Algorithm may not terminate if non-Horn examples are exponential in |env(φ)| and |V|
  - Inaccurate rules: Extracted rules may be inaccurate if language model behavior changes or conversion is inaccurate

- **First 3 experiments**:
  1. Test algorithm on simple Boolean function with known Horn envelope
  2. Test on pre-trained language model with known bias (occupation-based gender bias)
  3. Test on more complex Boolean function or language model with multiple biases

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the algorithm terminate in polynomial time when the target formula is non-Horn but has only a polynomial number of non-Horn examples?
- Basis in paper: [explicit] The paper states the algorithm terminates in polynomial time if the target has polynomially many non-Horn examples (Theorem 8, Corollary 18).
- Why unresolved: The paper provides theoretical guarantee but doesn't empirically validate this claim for different non-Horn formulas and numbers of non-Horn examples.
- What evidence would resolve it: Empirical studies showing algorithm's runtime for various non-Horn formulas with different numbers of non-Horn examples, demonstrating polynomial growth as non-Horn examples increase.

### Open Question 2
- Question: How does the choice of template sentence affect the extracted rules and their biases?
- Basis in paper: [explicit] The paper uses a template sentence in experiments but doesn't explore impact of different templates on extracted rules.
- Why unresolved: Paper focuses on single template sentence, limiting generalizability. Different templates might capture different bias aspects or yield different rule sets.
- What evidence would resolve it: Experiments using various template sentences to probe language models and compare extracted rules and biases across templates.

### Open Question 3
- Question: Can the algorithm be extended to handle more complex biases beyond binary gender?
- Basis in paper: [explicit] The paper focuses on binary gender biases but acknowledges this limitation.
- Why unresolved: Paper doesn't explore adapting algorithm for non-binary gender identities or other complex biases like intersectional biases.
- What evidence would resolve it: Modifications to algorithm and experiments demonstrating effectiveness for non-binary gender identities or intersectional biases.

### Open Question 4
- Question: How does the number of equivalence queries affect the quality and reliability of extracted rules?
- Basis in paper: [explicit] The paper shows increasing equivalence queries improves rule quality but also increases runtime.
- Why unresolved: Paper doesn't provide clear threshold for queries needed for reliable rules or explore runtime vs quality tradeoff in detail.
- What evidence would resolve it: Experiments varying equivalence queries and analyzing impact on rule quality, reliability, and runtime to determine optimal balance.

## Limitations

- Sampling-based equivalence queries introduce uncertainty about whether true Horn envelope has been learned, with no rigorous bounds on sampling error provided
- Conversion between propositional interpretations and natural language expressions lacks detail on validation, potentially introducing systematic errors
- Limited empirical validation with only 60 occupations and 100-200 queries, raising questions about scalability to larger bias detection tasks
- Extracted rules evaluated through qualitative inspection rather than quantitative validation against ground truth bias patterns

## Confidence

- **High confidence** in theoretical framework: Adaptation of Angluin's algorithm and termination bounds appear mathematically sound
- **Medium confidence** in experimental results: Methodology is clear but limited scope and lack of quantitative validation reduce practical utility confidence
- **Low confidence** in scalability claims: No empirical evidence for polynomial-time convergence beyond small-scale experiments

## Next Checks

1. **Scalability experiment**: Run algorithm on larger set of occupations (500+) and measure how query requirements and runtime scale to validate polynomial-time claims in practice.

2. **Ground truth comparison**: Create synthetic language models with known bias patterns and use as oracles, comparing extracted Horn envelopes against known ground truth to measure accuracy quantitatively.

3. **Sampling error analysis**: Systematically vary number of samples in equivalence queries and measure impact on stability and accuracy of extracted rules to quantify computational cost vs reliability tradeoff.