---
ver: rpa2
title: How Good Are LLMs at Out-of-Distribution Detection?
arxiv_id: '2308.10261'
source_url: https://arxiv.org/abs/2308.10261
tags:
- detection
- llms
- fine-tuning
- language
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the out-of-distribution (OOD) detection
  capabilities of large language models (LLMs) like LLaMA. The authors evaluate commonly
  used OOD detectors on LLaMA models ranging from 7B to 65B parameters, both in zero-shot
  and fine-tuning scenarios.
---

# How Good Are LLMs at Out-of-Distribution Detection?

## Quick Facts
- arXiv ID: 2308.10261
- Source URL: https://arxiv.org/abs/2308.10261
- Reference count: 17
- Key outcome: Generative fine-tuning improves OOD detection robustness compared to discriminative fine-tuning, and cosine distance works exceptionally well due to LLM embedding isotropy

## Executive Summary
This paper evaluates out-of-distribution detection capabilities of LLaMA models (7B-65B parameters) using commonly used OOD detectors. The authors reformulate sentence classification as a generative task to align with LLMs' autoregressive pre-training. Key findings include that generative fine-tuning mitigates ID overfitting, LLMs excel at far-OOD detection without fine-tuning, and cosine distance outperforms other detectors due to the isotropic nature of LLM embeddings. The 65B model uniquely performs well on near-OOD detection without fine-tuning.

## Method Summary
The authors evaluate LLaMA models (7B, 13B, 30B, 65B) on out-of-distribution detection tasks using SST-2, 20NG, and CLINC150 as in-distribution datasets. They compare zero-shot performance against fine-tuned models using both generative and discriminative approaches. OOD detectors include Mahalanobis distance, cosine distance, MSP, and energy score. Fine-tuning uses parameter-efficient LoRA with AdamW optimizer, and early stopping is applied based on validation performance. The paper reformulates classification as a generative task by having LLMs predict masked words related to class labels.

## Key Results
- Generative fine-tuning improves OOD detection robustness compared to discriminative fine-tuning by mitigating ID overfitting
- Cosine distance outperforms other OOD detectors, attributed to the isotropic embedding space of LLMs
- The 65B LLaMA model achieves satisfactory near-OOD detection performance without fine-tuning, while smaller models require fine-tuning

## Why This Works (Mechanism)

### Mechanism 1
Generative fine-tuning improves OOD detection robustness compared to discriminative fine-tuning by mitigating ID overfitting. The generative training objective maintains separation between ID and OOD distributions while training on ID data, preserving the effectiveness of distance-based OOD detectors. Core assumption: The generative training objective naturally preserves embedding space structure that allows OOD detection methods to work effectively.

### Mechanism 2
LLMs have isotropic embedding spaces that make cosine distance effective for OOD detection. The isotropic nature means points are uniformly distributed in embedding space, making cosine similarity a reliable measure of distance between samples. Core assumption: The pre-training objective of LLMs (autoregressive prediction) creates embeddings with uniform distribution rather than concentration in narrow cones.

### Mechanism 3
LLMs scale well for near-OOD detection, with 65B models showing dramatic performance improvement. Larger models have better representation capacity to distinguish subtle differences between near-OOD and ID samples. Core assumption: Model capacity directly correlates with ability to separate semantically similar classes.

## Foundational Learning

- **Out-of-Distribution Detection**: The entire paper evaluates how well LLMs can distinguish between ID and OOD data. Quick check: What's the difference between far-OOD and near-OOD detection?
- **Pre-trained Language Models vs Large Language Models**: The paper contrasts smaller BERT-style models with larger decoder-based LLMs. Quick check: What's the key architectural difference between encoder-based and decoder-based Transformers?
- **Fine-tuning Paradigms (Discriminative vs Generative)**: The paper compares how different fine-tuning approaches affect OOD detection performance. Quick check: How does generative fine-tuning differ from standard classification fine-tuning?

## Architecture Onboarding

- **Component map**: LLM backbone → Sentence representation layer → OOD detector (cosine/Maha/Energy/MSP) → Confidence score
- **Critical path**: Pre-training → (optional) Fine-tuning → OOD detection evaluation
- **Design tradeoffs**: Larger models perform better but require more resources; generative fine-tuning preserves OOD detection but may sacrifice some ID accuracy
- **Failure signatures**: Poor OOD performance when ID and OOD distributions overlap; cosine distance fails when embeddings are anisotropic
- **First 3 experiments**:
  1. Evaluate zero-shot OOD detection with different LLAMA sizes on far-OOD tasks
  2. Compare generative vs discriminative fine-tuning on near-OOD detection performance
  3. Test cosine distance effectiveness with different few-shot training scenarios

## Open Questions the Paper Calls Out

1. How does the isotropy of LLM embeddings compare quantitatively to smaller transformer models like BERT across multiple benchmark datasets?
2. What is the impact of different pre-training objectives (autoregressive vs. masked language modeling) on the isotropy of learned representations?
3. How does the effectiveness of cosine distance as an OOD detector vary across different types of semantic shifts (e.g., topic drift, style change, domain adaptation)?

## Limitations
- The paper lacks theoretical grounding for why generative fine-tuning preserves embedding space structure better than discriminative fine-tuning
- The isotropic embedding space claim is speculative without direct evidence through visualization or quantitative measures
- The 65B model performance may not be practically significant due to deployment constraints

## Confidence
- **High confidence**: Zero-shot far-OOD detection performance across LLMs, cosine distance outperforming other detectors, fine-tuning degrading OOD detection
- **Medium confidence**: Generative fine-tuning mitigating ID overfitting, isotropic embedding space claim, 65B model's near-OOD superiority
- **Low confidence**: Theoretical mechanisms explaining why generative fine-tuning works better and why LLM embeddings are isotropic

## Next Checks
1. Generate embeddings for randomly sampled sentences from the training corpus and compute average cosine similarity between all pairs to verify isotropy claims
2. Compare generative fine-tuning against discriminative fine-tuning while controlling for other variables in an ablation study
3. Evaluate near-OOD detection performance systematically across more model sizes to verify scaling relationships