---
ver: rpa2
title: 'Encoded Summarization: Summarizing Documents into Continuous Vector Space
  for Legal Case Retrieval'
arxiv_id: '2309.08187'
source_url: https://arxiv.org/abs/2309.08187
tags:
- summary
- case
- document
- lexical
- legal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach to legal case retrieval
  by summarizing documents into continuous vector space. The authors propose an encoded
  summarization method that utilizes deep neural networks to score phrases within
  documents based on their contextual importance.
---

# Encoded Summarization: Summarizing Documents into Continuous Vector Space for Legal Case Retrieval

## Quick Facts
- arXiv ID: 2309.08187
- Source URL: https://arxiv.org/abs/2309.08187
- Authors: 
- Reference count: 9
- Key outcome: F1 scores of 65.6% and 57.6% on COLIEE 2018 and 2019 datasets

## Executive Summary
This paper introduces a novel approach to legal case retrieval by summarizing documents into continuous vector space. The authors propose an encoded summarization method that utilizes deep neural networks to score phrases within documents based on their contextual importance. This approach allows for more effective representation of legal case documents compared to traditional lexical matching methods. The system combines both lexical features and latent features generated through the encoded summarization process.

## Method Summary
The method uses a phrase scoring framework with deep neural networks to identify contextually important phrases in legal case documents. Convolutional neural networks encode local contexts of phrases at multiple levels (word, sentence, document), with max-pooling aggregating features. Document vectors are composed by weighting multi-level contextual features using phrase scores, analogous to summarization in vector space. The system combines these latent features with lexical features (n-grams, skip-grams, LCS) and uses a learning-to-rank model (Linear-SVM) to identify relevant legal cases.

## Key Results
- F1 score of 65.6% on COLIEE 2018 dataset
- F1 score of 57.6% on COLIEE 2019 dataset
- Demonstrated that lexical features and latent features generated with neural networks complement each other
- Showed encoded summarization creates more effective document representations than traditional lexical matching

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Phrase scoring framework extracts contextually important phrases by leveraging multi-level contextual features (word, sentence, document).
- Mechanism: Convolutional neural networks encode local contexts of phrases, and max-pooling operations aggregate features at sentence and document levels. The final scoring uses a multilayer perceptron to combine these features.
- Core assumption: The contextual similarity property of word embeddings (words with similar contexts have similar meanings) holds for legal case documents.
- Evidence anchors:
  - [section] The paper states: "We adapt convolutional neural networks (CNNs)...to encode each local context into latent feature space. Specifically, document phrase features are captured by applying convolutional operations with window size 2k + 1 covering the word, k left and k right neighbors."
  - [abstract] The abstract mentions: "Our phrase scoring framework utilizing deep neural networks to score phrases within documents based on their contextual importance."
- Break condition: If legal case documents contain phrases where contextual similarity breaks down (e.g., highly specialized legal jargon that doesn't follow general semantic patterns), the CNN-based scoring would fail.

### Mechanism 2
- Claim: Combining lexical features with latent features (from encoded summarization) improves retrieval performance by capturing complementary information.
- Mechanism: Lexical features provide surface-level matching (n-grams, skip-grams, LCS), while latent features capture semantic similarity through vector space representations. The combination leverages both exact matching and meaning-based matching.
- Core assumption: Legal case retrieval benefits from both lexical and semantic similarity measures, as they capture different aspects of document relevance.
- Evidence anchors:
  - [abstract] The paper states: "Our experiments show that lexical features and latent features generated with neural networks complement each other to improve the retrieval system performance."
  - [section] The paper notes: "The lexical similarity and semantic similarity differ from each other and can potentially complement each other as well."
- Break condition: If legal cases have minimal lexical overlap but high semantic similarity (or vice versa), the combination might not improve performance if one feature type dominates.

### Mechanism 3
- Claim: Encoded summarization creates document vectors that selectively weight important content based on phrase scores, improving retrieval by focusing on key information.
- Mechanism: The phrase scoring model assigns scores to document phrases, and the document vector is composed by weighting multi-level contextual features (phrase, sentence, document) by these scores. This is analogous to summarization but in vector space.
- Core assumption: Important phrases identified by the scoring model are also the most relevant for legal case retrieval, and weighting by these scores improves the quality of document representations.
- Evidence anchors:
  - [section] The paper describes: "The composition weights the document contents based on their scores obtained from the phrase scoring framework. Important contents should have high contribution or affection to the final document vector."
  - [abstract] The abstract states: "This approach allows for more effective representation of legal case documents compared to traditional lexical matching methods."
- Break condition: If the phrase scoring model incorrectly identifies important phrases (e.g., common but irrelevant phrases get high scores), the weighted document vectors would be misleading for retrieval.

## Foundational Learning

- Concept: Understanding of convolutional neural networks for text modeling
  - Why needed here: The phrase scoring framework uses CNNs to encode local contextual features of phrases
  - Quick check question: How do CNNs with varying window sizes capture different levels of phrase context?

- Concept: Knowledge of vector space representations and composition methods
  - Why needed here: The paper employs various methods (word embeddings, doc2vec, encoded summarization) to represent documents in continuous vector space
  - Quick check question: What are the differences between max pooling, average pooling, and hierarchical pooling for composing document vectors from word embeddings?

- Concept: Familiarity with legal document structure and terminology
  - Why needed here: The system processes legal case documents with specific structures (summaries, paragraphs, catchphrases) that require domain understanding
  - Quick check question: What are the typical components of a legal case document, and how do they differ from general text documents?

## Architecture Onboarding

- Component map: Phrase Scoring Model -> Document Vector Composition -> Lexical Feature Extraction -> Latent Feature Generation -> Relevance Modeling -> Learning to Rank
- Critical path: Phrase scoring → Document vector composition → Feature combination → Learning to rank → Candidate selection
- Design tradeoffs:
  - Using CNNs vs. other architectures for phrase scoring: CNNs are effective for capturing local contexts but may miss long-range dependencies
  - Weighting by phrase scores vs. uniform weighting: Improves focus on important content but depends on scoring accuracy
  - Combining lexical and latent features: Captures complementary information but increases feature dimensionality
- Failure signatures:
  - Low performance with encoded summarization alone: Indicates phrase scoring model not capturing relevant information
  - No improvement from feature combination: Suggests lexical and latent features are capturing similar information
  - High scores for irrelevant cases: Points to issues with the learning to rank model or feature combination
- First 3 experiments:
  1. Evaluate phrase scoring model on a held-out summarization task to assess its ability to identify important phrases
  2. Compare document vector composition methods (max pooling, average pooling, hierarchical pooling) to determine the most effective approach
  3. Test different combinations of lexical and latent features to find the optimal feature set for retrieval performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the encoded summarization model be improved to better capture non-summary legal points that are relevant to the main points of a case?
- Basis in paper: [inferred] The paper mentions that the encoded summarization weights case content based on the summary, potentially capturing related legal points. However, it acknowledges that some non-supporting but highly similar cases may still be retrieved.
- Why unresolved: The paper does not provide specific methods or experiments to address this limitation.
- What evidence would resolve it: Experiments showing improved performance on a dataset with diverse legal points, or ablation studies demonstrating the effectiveness of additional techniques to capture non-summary legal points.

### Open Question 2
- Question: How can the phrase scoring model be adapted to work effectively on datasets from different jurisdictions or legal systems?
- Basis in paper: [inferred] The phrase scoring model is trained on COLIEE 2018 dataset and directly applied to COLIEE 2019 dataset without re-training. The paper mentions that the model's performance may be affected by differences in summary phenomena between datasets.
- Why unresolved: The paper does not explore the model's performance on datasets from different legal systems or provide methods for adapting the model to new domains.
- What evidence would resolve it: Experiments comparing the model's performance on datasets from different jurisdictions, or studies on transfer learning techniques to adapt the model to new legal domains.

### Open Question 3
- Question: How can the lexical matching approach be enhanced by incorporating statistical information about term frequency and inverse document frequency?
- Basis in paper: [explicit] The paper mentions that lexical matching has not yet considered statistical information of terms in the corpus, which can be modeled by term frequency-inverse document frequency.
- Why unresolved: The paper does not provide experiments or analysis on the potential benefits of incorporating this statistical information.
- What evidence would resolve it: Experiments comparing the performance of lexical matching with and without term frequency-inverse document frequency information, or studies on the impact of different weighting schemes on retrieval performance.

## Limitations
- Phrase scoring framework architecture details are not fully specified, particularly CNN filter configurations and MLP layer sizes
- Training methodology for phrase scoring model is incomplete with unspecified hyperparameters for optimization
- Limited ablation studies on contribution of different vector composition methods
- Performance metrics reported only on COLIEE datasets without external validation on other legal case corpora

## Confidence
- **High Confidence**: The core mechanism of combining lexical and latent features for legal case retrieval is well-supported by experimental results showing F1 scores of 65.6% and 57.6% on COLIEE 2018 and 2019 datasets
- **Medium Confidence**: The claim that encoded summarization improves retrieval by focusing on contextually important phrases, though the paper provides limited evidence on the accuracy of the phrase scoring model itself
- **Low Confidence**: The generalizability of the approach to other legal domains or languages beyond Japanese legal cases

## Next Checks
1. Implement ablation studies to quantify the contribution of encoded summarization versus traditional lexical matching and other vector composition methods
2. Test the phrase scoring model's ability to identify important phrases through an independent summarization evaluation task on held-out legal case data
3. Validate the approach on additional legal case corpora from different jurisdictions to assess cross-domain performance and robustness