---
ver: rpa2
title: Minimax Forward and Backward Learning of Evolving Tasks with Performance Guarantees
arxiv_id: '2310.15974'
source_url: https://arxiv.org/abs/2310.15974
tags:
- tasks
- learning
- forward
- task
- backward
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Incremental Minimax Risk Classifiers (IMRCs)
  to address the problem of incrementally learning evolving classification tasks over
  time. Unlike existing methods designed for tasks with time-independent similarities
  or only the last task, IMRCs exploit both forward and backward learning by recursively
  obtaining uncertainty sets using information from all tasks.
---

# Minimax Forward and Backward Learning of Evolving Tasks with Performance Guarantees

## Quick Facts
- arXiv ID: 2310.15974
- Source URL: https://arxiv.org/abs/2310.15974
- Reference count: 40
- This paper introduces Incremental Minimax Risk Classifiers (IMRCs) to address the problem of incrementally learning evolving classification tasks over time.

## Executive Summary
This paper addresses the problem of incrementally learning evolving classification tasks over time. The proposed method, Incremental Minimax Risk Classifiers (IMRCs), exploits both forward and backward learning by recursively obtaining uncertainty sets using information from all tasks. The key idea is to use recursions based on Kalman filtering and smoothing to obtain mean and MSE vectors for each task, accounting for the evolving nature of the tasks. Theoretical analysis characterizes the increase in effective sample size (ESS) provided by IMRCs in terms of the tasks' expected quadratic change and the number of tasks. Experiments on multiple datasets demonstrate significant performance improvement, especially for reduced sample sizes, compared to state-of-the-art techniques.

## Method Summary
The proposed Incremental Minimax Risk Classifiers (IMRCs) use forward and backward learning to incrementally learn evolving classification tasks. Forward learning employs Kalman filter recursions to update mean vectors using new task samples and preceding task estimates. Backward learning applies fixed-lag smoothing recursions to propagate information from new tasks back to earlier tasks. This recursive structure maintains optimal linear estimators with minimum MSE under the evolving task assumption. The method determines classification rules minimizing worst-case error probabilities over uncertainty sets that shrink with accumulated task information.

## Key Results
- IMRCs achieve 13% classification error on Yearbook dataset with 10 samples per task, compared to 18% for best baseline method
- The method increases effective sample size (ESS) by leveraging information across tasks, with gains proportional to the number of tasks and inversely proportional to expected quadratic change
- Experiments demonstrate significant performance improvement over state-of-the-art techniques on 12 public datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The recursive Kalman filtering and smoothing equations allow IMRCs to maintain optimal linear estimators of evolving task distributions with minimal MSE.
- Mechanism: At each step k, forward learning uses Kalman filter recursions to update the mean vector τ⇀k using the new task's sample average τk and the preceding task's forward estimate τ⇀k-1. Backward learning applies fixed-lag smoothing recursions to propagate information from the new task back to earlier tasks, yielding τ⇋k for all tasks. This recursive structure ensures unbiased estimates with minimum MSE under the evolving task assumption.
- Core assumption: The change between consecutive tasks (wj = τ∞j - τ∞j-1) is independent and zero-mean, enabling Kalman recursions to be valid.
- Evidence anchors:
  - [section]: "The mean vectors evolve over time steps through the linear dynamical system τ∞j = τ∞j-1 + wj where vectors wj for j ∈ {2,3,…,k} are independent and zero-mean because pj - pj-1 are independent and zero-mean."
  - [abstract]: "IMRCs exploit both forward and backward learning by recursively obtaining uncertainty sets using information from all tasks."
- Break condition: If the independence or zero-mean assumptions on task changes are violated, the recursive estimators become biased or suboptimal.

### Mechanism 2
- Claim: Forward and backward learning increase the effective sample size (ESS) of each task by leveraging information across tasks.
- Mechanism: The recursions in (6) and (10) combine the current task's sample information with estimates from preceding or succeeding tasks, weighted by their MSE vectors and expected quadratic changes. This effectively pools evidence across tasks, increasing the ESS beyond the nominal sample size n. Theorems 2 and 4 show that ESS grows with the number of tasks and inversely with the expected quadratic change d².
- Core assumption: The expected quadratic change d² between consecutive tasks is small enough that information pooling is beneficial (i.e., d² < 1/j² for substantial gains).
- Evidence anchors:
  - [section]: "The value n⇀j in (8) is the ESS of the proposed IMRC method with forward learning since the bound in (8) coincides with that of single-task learning in (5) if the sample size for the j-th task is n⇀j."
  - [section]: "Theorem 2 characterizes the increase in ESS provided by forward learning in terms of the tasks' expected quadratic change and the number of tasks."
- Break condition: If d² is large (drastic task changes), the weighting favors single-task information, nullifying ESS gains.

### Mechanism 3
- Claim: The minimax risk bound in Theorem 3 ensures robust classification by minimizing worst-case error over uncertainty sets that shrink with accumulated task information.
- Mechanism: Uncertainty sets U⇋k j are defined using the forward and backward mean vectors τ⇋k j and MSE vectors s⇋k j. The bound R(U⇋k j) ≤ R∞j + M(κ+1)√2log(2m/δ)/√n⇋k j guarantees that classification error is controlled even when the true distribution is unknown, with the bound tightening as ESS increases.
- Core assumption: The feature mapping Φ(x,y) is bounded (||Φ||∞ ≤ M) and sub-Gaussian with parameter κ, ensuring concentration inequalities hold.
- Evidence anchors:
  - [abstract]: "IMRCs determine classification rules minimizing worst-case error probabilities over uncertainty sets that can contain the sequence of evolving underlying distributions."
  - [section]: "Theorem 3 shows that the methods proposed can increase ESS of each task by leveraging information from all the tasks."
- Break condition: If feature mappings violate boundedness or sub-Gaussianity, the concentration bounds fail, breaking the risk guarantee.

## Foundational Learning

- Concept: Kalman filtering and smoothing for linear dynamical systems
  - Why needed here: The evolving task assumption models task distributions as a linear dynamical system, where Kalman recursions provide optimal estimators of the evolving state (mean vectors) with minimum MSE.
  - Quick check question: What are the state transition and observation equations for the task distribution evolution, and how do they map to the Kalman filter recursions in (6)?

- Concept: Sub-Gaussian concentration inequalities
  - Why needed here: The risk bounds in Theorems 1-3 rely on Chernoff bounds for sub-Gaussian random variables to control the deviation of estimated mean vectors from true means.
  - Quick check question: Given that Φ(x,y) is bounded by M, what is the sub-Gaussian parameter σ(Φ(i)j) in terms of M and n?

- Concept: Minimax risk classification with uncertainty sets
  - Why needed here: IMRCs minimize worst-case 0-1 loss over uncertainty sets U, providing robust classification even when the true task distribution is unknown, which is critical for evolving tasks with limited samples.
  - Quick check question: How does the uncertainty set U in (1) shrink as more tasks are observed, and what is the effect on the minimax risk R(U)?

## Architecture Onboarding

- Component map:
  - Data pipeline: Sequential arrival of sample sets D1, D2, ..., Dk from evolving tasks
  - Estimator module: Implements Kalman filter recursions (6) for forward learning and fixed-lag smoothing recursions (10) for backward learning
  - Uncertainty set module: Constructs sets U⇋k j from mean vectors τ⇋k j and MSE vectors s⇋k j
  - Classifier module: Solves the convex optimization (3) to obtain classification parameters µj
  - Performance module: Computes classification error and running time for comparison

- Critical path:
  1. Receive new task sample set Dk
  2. Compute sample average τk and MSE sk
  3. Update forward mean vector τ⇀k and MSE s⇀k using (6)
  4. For j = k-1, k-2, ..., k-b: update backward mean vector τ↽k j+1 using (6) in retrodiction, then forward-backward mean vector τ⇋k j using (10)
  5. Solve (3) to obtain µj for each task j
  6. Evaluate classification error on test set

- Design tradeoffs:
  - Number of backward steps b: More backward steps increase ESS but also increase computational and memory complexity linearly
  - Window size W for estimating d²j: Larger W provides more stable estimates but may lag behind rapid task changes
  - Feature representation: Rich features (e.g., last layer of ResNet18) improve classification but increase computational cost of solving (3)

- Failure signatures:
  - Degraded performance: If d²j is underestimated, the ESS gains are overestimated, leading to overconfidence and higher error
  - High variance in estimates: If the sample size n is too small, the MSE vectors sj become large, reducing the effectiveness of information pooling
  - Slow adaptation: If the step size in the subgradient method (22) is too small, the classifier parameters µj converge slowly, hurting real-time performance

- First 3 experiments:
  1. Verify the Kalman filter recursions: Implement (6) and check that τ⇀k is an unbiased estimator of τ∞k with minimum MSE for a synthetic linear dynamical system
  2. Test ESS gains: Run IMRC with forward learning on a dataset with small d² (e.g., Yearbook) and compare the classification error to single-task learning, confirming the error reduction scales with the number of tasks
  3. Validate risk bounds: Compute the empirical classification error and the theoretical bound from Theorem 3 for a range of sample sizes n and number of tasks k, ensuring the bound is valid and tightens with increasing ESS

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions.

## Limitations
- The theoretical guarantees rely heavily on the evolving task assumption (zero-mean, independent changes between consecutive tasks)
- The sub-Gaussian parameter κ is estimated from data, which introduces potential variability in the risk bounds
- Computational complexity of backward learning scales linearly with the number of backward steps b

## Confidence

High confidence in the mechanism of Kalman filtering for forward learning, as this is well-established theory. Medium confidence in the forward-backward smoothing approach, as the recursions are sound but the practical benefits over forward-only learning need more extensive validation across diverse task evolutions. Medium confidence in the minimax risk bounds, as they depend on estimated parameters (κ, d²) that may vary across datasets.

## Next Checks

1. **Assumption Sensitivity Analysis**: Systematically vary the correlation structure between consecutive tasks (deviating from zero-mean, independent changes) and measure degradation in classification performance and ESS gains.

2. **Sub-Gaussian Parameter Stability**: Across all 12 datasets, track the estimated κ values and their impact on the gap between theoretical risk bounds and empirical classification error.

3. **Backward Learning Threshold**: Empirically determine the minimum number of backward steps b required to achieve most of the ESS gains, establishing a practical guideline for the tradeoff between performance and computational cost.