---
ver: rpa2
title: Hierarchical Multi-Task Learning Framework for Session-based Recommendations
arxiv_id: '2309.06533'
source_url: https://arxiv.org/abs/2309.06533
tags:
- prediction
- hiersrec
- learning
- category
- item
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: HierSRec introduces a hierarchical multi-task learning framework
  for session-based recommendation, employing a metadata-aware Transformer to encode
  sessions and using category prediction as an auxiliary task to enhance next-item
  prediction accuracy. The model generates high-quality candidate items for scalable
  inference by leveraging predicted categories, achieving significant performance
  improvements over existing session-based recommenders.
---

# Hierarchical Multi-Task Learning Framework for Session-based Recommendations

## Quick Facts
- **arXiv ID**: 2309.06533
- **Source URL**: https://arxiv.org/abs/2309.06533
- **Reference count**: 40
- **Primary result**: Achieves 25.8% improvement in MRR@20 and uses only 4% of total items as candidates for scalable inference

## Executive Summary
HierSRec introduces a hierarchical multi-task learning framework for session-based recommendation that leverages category prediction as an auxiliary task to enhance next-item prediction accuracy. The model employs a metadata-aware Transformer to encode session sequences, incorporating item IDs, categories, and textual metadata (titles, descriptions) into the representation. By predicting categories first and using these predictions to generate compact candidate sets (e.g., 4% of total items), HierSRec achieves significant performance improvements over existing methods while enabling scalable inference. The approach demonstrates superior accuracy on two large-scale e-commerce datasets while maintaining computational efficiency through intelligent candidate generation.

## Method Summary
HierSRec encodes sessions using a metadata-aware Transformer that combines item ID embeddings, category embeddings, and metadata embeddings (titles, descriptions). The model employs hierarchical multi-task learning where next-category prediction serves as an auxiliary task, with its outputs feeding into the main next-item prediction task. During inference, the model predicts top-K categories for each session and generates candidate items by aggregating items from these predicted categories, dramatically reducing the search space. The model is trained using combined loss functions for both tasks with the Adam optimizer, achieving improved accuracy while maintaining computational efficiency through compact candidate generation.

## Key Results
- Improves MRR@20 by up to 25.8% compared to existing session-based recommenders
- Achieves comparable accuracy to full-item evaluation using only 4% of total items as candidates
- Demonstrates effectiveness on two large-scale e-commerce datasets (THD and Diginetica)
- Maintains strong performance across varying candidate sizes while significantly reducing computational overhead

## Why This Works (Mechanism)

### Mechanism 1
- Claim: HierSRec improves next-item prediction accuracy by incorporating category prediction as an auxiliary task, providing richer input features to the main task.
- Mechanism: The hierarchical multi-task learning structure feeds outputs from next-category prediction (auxiliary task) as additional input features to the next-item prediction (main task), effectively augmenting the session representation with categorical context.
- Core assumption: Category information captures meaningful semantic groupings that correlate with item co-occurrence patterns in sessions.
- Evidence anchors:
  - [abstract] "employing a metadata-aware Transformer to encode sessions and using category prediction as an auxiliary task to enhance next-item prediction accuracy"
  - [section] "HierSRec performs next-category prediction (i.e., auxiliary task) with the session encoding. Next, HierSRec conducts next-item prediction (i.e., main task) with the category prediction result and session encoding"

### Mechanism 2
- Claim: HierSRec enables scalable inference by generating compact candidate item sets (e.g., 4% of total items) using category predictions, maintaining comparable accuracy to full-item evaluation.
- Mechanism: During test time, the model predicts top-K categories for each session, then constructs candidate sets by aggregating items from these predicted categories, dramatically reducing the search space while preserving relevant items.
- Core assumption: The ground-truth next item in a session is highly likely to belong to one of the top-K predicted categories.
- Evidence anchors:
  - [abstract] "HierSRec creates a compact set of candidate items (e.g., 4% of total items) per test example using the category prediction"
  - [section] "HierSRec can create a small candidate set (e.g., 4% of total items) consisting of key items that are highly related to the ground-truth next item in a session"

### Mechanism 3
- Claim: The metadata-aware Transformer encoder captures richer session representations by incorporating item metadata (IDs, categories, titles, descriptions) alongside item sequences.
- Mechanism: Item embeddings are constructed by concatenating item ID embeddings, item category embeddings, and metadata embeddings (titles, descriptions), then passed through a Transformer encoder to produce context-aware session representations.
- Core assumption: Item metadata provides complementary information that enhances the semantic understanding of session dynamics beyond just item IDs.
- Evidence anchors:
  - [section] "HierSRec encodes a given session with a metadata-aware Transformer and performs next-category prediction (i.e., auxiliary task) with the session encoding"
  - [section] "Given an observed item ð‘–ð‘ð‘œð‘  , âˆ€ð‘ð‘œð‘ , 1 â‰¤ ð‘ð‘œð‘  â‰¤ ð‘˜ in the current session S, its embedding is constructed as follows... ð¸ð‘–ð‘ð‘œð‘  = ð‘‡ð‘Ÿð‘Žð‘›ð‘ ð¸ð‘›ð‘ (ð‘ð‘œð‘›ð‘ð‘Žð‘¡ (ð¸ I ð‘–ð‘ð‘œð‘  , ð¸ C ð‘–ð‘ð‘œð‘  , ð¸M ð‘–ð‘ð‘œð‘  ))"

## Foundational Learning

- Concept: Multi-task learning and parameter sharing
  - Why needed here: Understanding how sharing representations between related tasks (next-item and next-category prediction) prevents overfitting and improves generalization
  - Quick check question: What is the key difference between single-task learning and multi-task learning in terms of model parameters and training objectives?

- Concept: Hierarchical task relationships and feature propagation
  - Why needed here: Understanding how outputs from lower-level tasks (category prediction) serve as input features for higher-level tasks (item prediction) creates a knowledge flow that enhances the main prediction task
  - Quick check question: In HierSRec's architecture, which task serves as the auxiliary task and which serves as the main task, and how are they connected?

- Concept: Candidate generation strategies for large-scale recommendation
  - Why needed here: Understanding why random candidate sampling can lead to inconsistent evaluation metrics and how category-based candidate generation provides more accurate proxy evaluations
  - Quick check question: What is the primary disadvantage of using randomly sampled candidates for evaluating session-based recommenders compared to using all items?

## Architecture Onboarding

- Component map:
  - Metadata-aware Transformer Encoder -> Category Prediction Module -> Category Embeddings Projection -> Item Prediction Module -> Candidate Generation

- Critical path:
  1. Session encoding through metadata-aware Transformer
  2. Next-category prediction from session encoding
  3. Category prediction embeddings projection
  4. Next-item prediction using combined session and category information
  5. Candidate generation using category predictions

- Design tradeoffs:
  - Complexity vs. accuracy: Adding metadata and hierarchical structure improves accuracy but increases model complexity and training time
  - Candidate quality vs. coverage: Using category-based candidates reduces evaluation time but may miss relevant items if category predictions are inaccurate
  - Metadata dependency: Performance relies on availability and quality of item metadata, which may not be consistent across all datasets

- Failure signatures:
  - Degraded performance on datasets with poor category-label quality or unavailable metadata
  - Overfitting when training data is limited relative to the model's parameter count
  - Inconsistent evaluation results when category prediction accuracy drops significantly

- First 3 experiments:
  1. Ablation study: Remove hierarchical structure (treat as single-task learning) to quantify the contribution of multi-task learning
  2. Ablation study: Remove metadata from the Transformer encoder to assess the impact of metadata-aware encoding
  3. Scalability test: Compare accuracy and inference time using full-item evaluation vs. category-based candidate generation with varying candidate sizes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HierSRec change when using different types of metadata (e.g., titles, descriptions, images) in the Transformer encoder?
- Basis in paper: [explicit] The paper mentions using item ID, category information, and metadata such as titles and descriptions to generate item representations. It states that the metadata-aware Transformer shows the best empirical performance.
- Why unresolved: The paper does not provide an ablation study on the impact of different metadata types on performance.
- What evidence would resolve it: Experiments comparing HierSRec's performance with different combinations of metadata inputs (e.g., ID only, ID + category, ID + category + title, etc.) would show the relative importance of each metadata type.

### Open Question 2
- Question: Can HierSRec be effectively extended to handle cold-start items or sessions with very few interactions?
- Basis in paper: [inferred] The conclusion mentions extending HierSRec to predict next items accurately in sessions with cold-start items or only a few items by employing their metadata.
- Why unresolved: The paper does not explore or validate this extension, focusing instead on sessions with sufficient interactions.
- What evidence would resolve it: Experiments testing HierSRec on datasets with a high proportion of cold-start items or short sessions, comparing its performance to baseline methods, would demonstrate its effectiveness in these scenarios.

### Open Question 3
- Question: How does the performance of HierSRec vary with different hierarchical structures between prediction tasks?
- Basis in paper: [explicit] The paper mentions that HierSRec uses a hierarchical MTL framework with category prediction as an auxiliary task feeding into item prediction. It suggests that more complex hierarchical structures could be explored in future work.
- Why unresolved: The paper only implements a two-level hierarchy (category â†’ item) and does not experiment with other hierarchical structures (e.g., multi-level categories, or incorporating other metadata types hierarchically).
- What evidence would resolve it: Experiments comparing HierSRec with different hierarchical task structures (e.g., adding more auxiliary tasks like interaction type prediction in a hierarchical manner) would show the impact of task hierarchy complexity on performance.

## Limitations
- Heavy reliance on high-quality item metadata, which may not be available across all domains
- Potential performance degradation when category prediction accuracy falls below critical thresholds
- Unclear scalability to datasets with millions of distinct categories or items

## Confidence
- Category prediction as auxiliary task: **High confidence** - explicitly supported by architectural descriptions and performance metrics
- Category-based candidate generation scalability: **Medium confidence** - limited discussion of computational overhead and dependency on category prediction accuracy
- Metadata-aware Transformer contribution: **Medium confidence** - lacks ablation studies isolating metadata impact

## Next Checks
1. Conduct ablation study removing the hierarchical structure to quantify multi-task learning benefits versus single-task training
2. Test candidate generation performance across varying category prediction accuracy levels (90%, 80%, 70%) to establish robustness thresholds
3. Evaluate metadata impact by comparing performance with and without title/description embeddings on a metadata-sparse dataset