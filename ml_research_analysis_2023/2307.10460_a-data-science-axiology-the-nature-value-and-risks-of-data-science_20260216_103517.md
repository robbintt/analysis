---
ver: rpa2
title: 'A data science axiology: the nature, value, and risks of data science'
arxiv_id: '2307.10460'
source_url: https://arxiv.org/abs/2307.10460
tags:
- science
- data
- human
- problem
- knowledge
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents an axiology of data science, exploring its
  purpose, nature, importance, risks, and value for problem solving. The key outcome
  is a comprehensive analysis of data science as a fundamentally new research paradigm
  that can address problems of scope, scale, and complexity beyond human understanding.
---

# A data science axiology: the nature, value, and risks of data science

## Quick Facts
- arXiv ID: 2307.10460
- Source URL: https://arxiv.org/abs/2307.10460
- Reference count: 40
- Primary result: Data science is a fundamentally new research paradigm that can address problems of scope, scale, and complexity beyond human understanding.

## Executive Summary
This paper presents a comprehensive axiology of data science, establishing it as a distinct research paradigm that differs fundamentally from traditional science. The analysis reveals that data science's unique capability to discover patterns beyond human reasoning creates unprecedented opportunities for knowledge discovery while introducing significant risks due to its inscrutability. The paper argues that data science will surpass science as a knowledge discovery paradigm, but this power comes with challenges in verification, ethical use, and risk management that remain largely unresolved.

## Method Summary
The paper employs philosophical and conceptual analysis to explore data science as a research paradigm. Drawing on existing literature across multiple domains, it develops a data science reference framework and examines the field's purpose, nature, importance, risks, and value. The analysis distinguishes data science from science, identifies its key characteristics (inherent risks, exploratory nature, indirect approach, and inscrutability), and explores both its transformative potential and the challenges it presents for verification and ethical deployment.

## Key Results
- Data science can address problems of scope, scale, and complexity beyond human understanding, making it a fundamentally new research paradigm
- The inscrutability of AI-based data science methods creates significant risks that cannot be fully managed through traditional verification approaches
- Data science is changing our world in profound ways, with impacts extending far beyond knowledge discovery into new ways of understanding phenomena

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data science surpasses science as a research paradigm because it can address problems of scope, scale, and complexity beyond human understanding.
- Mechanism: By leveraging computational analysis of large datasets, data science bypasses human conceptual and cognitive limitations that restrict scientific inquiry to N variables (typically <10) and Cartesian disciplinary boundaries.
- Core assumption: The inscrutability of AI-based methods is acceptable because the benefits of discovering patterns beyond human reasoning outweigh the inability to explain how discoveries were made.
- Evidence anchors:
  - [abstract] "data science is a research paradigm with an unfathomed scope, scale, complexity, and power for knowledge discovery that is not otherwise possible and can be beyond human reasoning"
  - [section] "Data science can address problems of scope, scale, and complexity beyond human understanding, hence its unfathomed scope, scale, and power will surpass science as a knowledge discovery paradigm"
  - [corpus] Weak evidence - corpus papers focus on AI applications but don't explicitly compare data science vs science paradigms

### Mechanism 2
- Claim: Data science accelerates discovery by orders of magnitude compared to traditional scientific methods.
- Mechanism: Computational methods can process massive datasets and run thousands of experiments in parallel, while traditional science is limited by human time and resource constraints for physical experiments.
- Core assumption: Larger datasets and more parameters lead to better models, following the inverse power law relationship between resources and model performance.
- Evidence anchors:
  - [section] "Moderna's spikevax COVID-19 vaccine that was designed in 48 hours using an existing ML-based mRNA vaccine development platform. Prior to the ML-based solution, drug design based on protein folding took a PhD-level team six to ten years"
  - [section] "China's Wu Dao 2.0 transformer model has 1.75T parameters. The BaGuaLu model has 174T"
  - [corpus] Moderate evidence - corpus papers discuss synthetic data and AI applications but don't quantify acceleration rates

### Mechanism 3
- Claim: Data science's inscrutability creates unfathomed risks that cannot be fully managed through traditional verification methods.
- Mechanism: AI-based methods produce probabilistic, correlational results without causal explanations, making it impossible to verify correctness or estimate risks in critical applications.
- Core assumption: The inability to prove completeness or correctness of data science results is inherent to the paradigm and cannot be overcome through technical means.
- Evidence anchors:
  - [section] "Data science results are probabilistic, correlational, possibly fragile or specific to the analysis method or dataset, cannot be proven complete or correct, and lack explanations and interpretations"
  - [section] "The extent of such risks can be estimated by the nature of the application, e.g., recommending a movie versus a medical treatment"
  - [corpus] Strong evidence - corpus paper "The Need for Verification in AI-Driven Scientific Discovery" directly addresses verification challenges

## Foundational Learning

- Concept: Axiology (theory of value)
  - Why needed here: The paper is fundamentally about establishing the value, purpose, risks, and nature of data science as a research paradigm
  - Quick check question: What distinguishes axiology from ontology and epistemology in the context of data science?

- Concept: Research paradigm distinction
  - Why needed here: Understanding how data science differs from science is central to the paper's argument about its unique capabilities and risks
  - Quick check question: How does the scope of data science (any phenomena with adequate data) compare to the scope of science (observable, measurable phenomena)?

- Concept: Inscrutability and interpretability
  - Why needed here: The paper emphasizes that data science methods are largely inscrutable, creating both opportunities and risks
  - Quick check question: Why is the inscrutability of data science methods considered both a strength (discovering beyond human reasoning) and a weakness (unmanaged risks)?

## Architecture Onboarding

- Component map: Axiology (purpose, value, risks) -> Ontology (informal definitions) -> Epistemology (reasoning) -> Methodology (method and workflow) -> Methods (computational methods and results) -> Technology (engineering)
- Critical path: From problem formulation to data acquisition, model training, result interpretation, and domain problem solution
- Design tradeoffs: Between computational power and inscrutability, between scope/scale and interpretability, between acceleration and risk management
- Failure signatures: Erroneous results in critical applications, ethical violations in deployed systems, inability to verify or explain model decisions
- First 3 experiments:
  1. Implement a simple data science pipeline on a well-understood dataset to experience the indirect problem-solving nature
  2. Compare scientific vs data science approaches on the same problem to understand paradigm differences
  3. Experiment with different model sizes and datasets to observe the inverse power law relationship

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can data science truly surpass science as a knowledge discovery paradigm given its inherent inscrutability and lack of provable theories?
- Basis in paper: [explicit] The paper states that data science's "unfathomed scope, scale, and power will surpass science as a knowledge discovery paradigm" but also acknowledges its inscrutability and lack of theories to understand and manage its properties.
- Why unresolved: This question touches on fundamental debates about the nature of knowledge discovery and the role of human reasoning versus computational analysis. The inscrutability of AI-based data science methods means we may never fully understand how they work or prove their properties like accuracy and reliability.
- What evidence would resolve it: Empirical studies comparing the scope, scale, and complexity of problems solved by data science versus science, along with attempts to develop theories explaining how data science methods work and can be trusted.

### Open Question 2
- Question: What are the practical limits of data science's applicability given the no free lunch conjecture and the difficulty of obtaining truly representative datasets?
- Basis in paper: [explicit] The paper discusses the "no free lunch conjecture" suggesting there's no optimal algorithm for any specific analysis of a specific dataset, and notes the challenge of acquiring datasets that truly represent phenomena.
- Why unresolved: While data science has shown remarkable success in many domains, its limitations due to the no free lunch conjecture and dataset representativeness are not fully understood. The paper suggests these issues may be inherent to data science.
- What evidence would resolve it: Empirical studies testing the limits of data science performance across different domains and dataset types, along with theoretical work on the relationship between dataset representativeness and analytical power.

### Open Question 3
- Question: How can the risks of data science applications be adequately evaluated and bounded, especially for life-critical and societal-critical applications?
- Basis in paper: [explicit] The paper states that "it is difficult to evaluate or bound the risks of data science applications" and discusses the challenges of ensuring safe, ethical use given data science's inscrutability.
- Why unresolved: The paper highlights the inherent risks of data science but doesn't provide concrete solutions for evaluating and managing these risks, especially in high-stakes domains. This remains a significant challenge as data science is increasingly applied to critical areas.
- What evidence would resolve it: Development and testing of risk evaluation frameworks specifically for data science applications, along with case studies of successful risk management in high-stakes domains.

## Limitations

- The paper's claims about data science surpassing science rest on the assumption that inscrutability is an acceptable tradeoff for computational power, but this philosophical position is debatable and not empirically validated.
- The assertion that data science can address problems "beyond human understanding" lacks concrete examples of discoveries that were genuinely impossible through traditional scientific methods.
- The inverse power law relationship between resources and model performance may not generalize across all data science applications.

## Confidence

- **High confidence**: Data science has unfathomed scope, scale, and power for knowledge discovery that surpasses traditional scientific methods in certain domains (supported by concrete examples like Moderna's vaccine development).
- **Medium confidence**: The inscrutability of AI-based methods creates significant risks that cannot be fully managed through traditional verification methods (supported by corpus evidence on verification challenges).
- **Low confidence**: Data science is fundamentally changing our world in ways that will take us "into new ways of understanding the world" (this claim is philosophical and lacks empirical validation).

## Next Checks

1. Identify specific scientific discoveries that were genuinely impossible through traditional methods but achieved through data science approaches, and evaluate whether these represent true paradigm shifts or incremental improvements.
2. Test the inverse power law relationship across multiple data science applications by systematically varying dataset sizes, model parameters, and computational resources to determine where diminishing returns occur.
3. Design a comparative study of problem-solving approaches using both scientific and data science paradigms on the same well-defined problems to quantify differences in scope, scale, and complexity that each can address.