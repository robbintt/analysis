---
ver: rpa2
title: Asking More Informative Questions for Grounded Retrieval
arxiv_id: '2311.08584'
source_url: https://arxiv.org/abs/2311.08584
tags:
- questions
- question
- image
- images
- open-ended
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of asking informative questions
  in a grounded multi-turn image identification task. The authors propose a method
  that formulates open-ended questions and incorporates presupposition handling to
  improve question selection and belief updates.
---

# Asking More Informative Questions for Grounded Retrieval

## Quick Facts
- arXiv ID: 2311.08584
- Source URL: https://arxiv.org/abs/2311.08584
- Reference count: 19
- Primary result: 14% accuracy improvement and 48% efficiency gain in multi-turn image identification

## Executive Summary
This paper addresses the challenge of asking informative questions in a grounded multi-turn image identification task. The authors propose a method that formulates open-ended questions and incorporates presupposition handling to improve question selection and belief updates. Their approach involves a two-stage process: first filtering out irrelevant images based on presuppositions, then updating beliefs only on relevant images. Through self-play and human evaluations, they demonstrate that their method significantly outperforms previous state-of-the-art approaches.

## Method Summary
The proposed method formulates open-ended questions and incorporates presupposition handling to improve question selection and belief updates in a grounded multi-turn image identification task. It involves a two-stage process: first filtering out irrelevant images based on presuppositions using existence simulation, then updating beliefs only on relevant images. The approach uses off-the-shelf VQA models without training and evaluates performance through self-play and human evaluations on the MS-COCO dataset.

## Key Results
- 14% accuracy improvement over past state-of-the-art approaches
- 48% more efficient games in human evaluations
- Open-ended questions significantly outperform polar yes/no questions in terms of game length
- Presupposition handling mechanism prevents confidence updates on irrelevant images

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Presupposition handling significantly improves question informativeness by filtering irrelevant images before belief updates.
- Mechanism: The two-stage process first identifies which images are relevant to a question using existence simulation, then updates beliefs only on those relevant images. This prevents confidence updates on irrelevant images that would occur due to presupposition errors.
- Core assumption: VQA models' confidence scores on decomposed yes/no questions accurately indicate image relevance to the original wh- question.
- Evidence anchors:
  - [abstract]: "Our method first filters out images which are irrelevant to a given question, then updates its beliefs about which image the user intends."
  - [section]: "We compute P(Relevance(q, i)) as follows: (1) We convert wh- question q into a set of polar yes/no questions... Using our VQA model, we implicitly ask each of these yes/no questions and take the mean across questions"
- Break condition: If the presupposition filtering step fails to identify irrelevant images, the system will update beliefs based on irrelevant image information, leading to accuracy degradation.

### Mechanism 2
- Claim: Open-ended questions provide substantially more information than yes/no questions in image identification tasks.
- Mechanism: Open-ended questions like "What type of food are the people eating?" can eliminate multiple candidate images in a single turn by identifying specific attributes, whereas yes/no questions can only eliminate one attribute at a time.
- Core assumption: The VQA model can accurately answer open-ended questions about visual content, and the question selection process can identify questions that maximize expected information gain.
- Evidence anchors:
  - [abstract]: "asking informative open-ended questions, increasing accuracy over the past state-of-the-art by 14%, while resulting in 48% more efficient games"
  - [section]: "Both open-ended methods perform much better than the polar yes/no questions in terms of game length, which demonstrates that open-ended questions indeed fetch more information for the model"
- Break condition: If the VQA model cannot accurately answer open-ended questions, or if the question selection fails to identify truly informative questions, the advantage of open-ended questions disappears.

### Mechanism 3
- Claim: The null response option enables the model to handle unanswerable questions without making incorrect belief updates.
- Mechanism: When the responder chooses "No Answer," the model interprets this as indicating the question's subject doesn't exist in the target image, allowing it to upweight images without that subject and downweight those with it.
- Core assumption: The "No Answer" response is used consistently and accurately by the responder to indicate irrelevance.
- Evidence anchors:
  - [abstract]: "Our setting allows two types of responses, either the standard response or a null response (i.e., responding with 'No Answer')."
  - [section]: "Because 'No Answer' is not in the vocabulary for our VQA model, we instead design a proxy method to calculate P(rnull | i, q)"
- Break condition: If the "No Answer" response is ambiguous or inconsistently applied, the model cannot reliably update beliefs based on this information.

## Foundational Learning

- Concept: Expected Information Gain (EIG)
  - Why needed here: The core metric for selecting the most informative question to ask in each turn of the game.
  - Quick check question: Can you derive the formula for EIG from first principles of information theory?

- Concept: Bayesian belief updating
  - Why needed here: The model maintains and updates a probability distribution over which image is the target based on question-answer pairs.
  - Quick check question: How would you update your belief distribution after receiving the answer "Yes" to the question "Is there a dog in the image?"

- Concept: Presupposition and presupposition failure
  - Why needed here: Understanding why open-ended questions can fail when they assume the existence of entities not present in the target image.
  - Quick check question: What is the presupposition error in the question "What is the dog eating?" when there is no dog in the target image?

## Architecture Onboarding

- Component map: VQA model → Question generator → Existence simulator → Response simulator → Belief updater → Question selector
- Critical path: Image → Captions → Questions → Relevance check → Response simulation → Information gain calculation → Question selection → Ask → Response → Belief update → Repeat
- Design tradeoffs: Open-ended questions provide more information but require presupposition handling; yes/no questions are simpler but less informative
- Failure signatures: Accuracy drops when presupposition handling fails; game length increases when question selection fails to identify informative questions
- First 3 experiments:
  1. Test presupposition filtering accuracy: Feed known irrelevant questions and verify the system correctly identifies and excludes those images
  2. Compare open-ended vs yes/no question performance on a small image set with known ground truth
  3. Validate belief update correctness: Manually verify that belief distributions update correctly after each question-answer pair

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the two-stage process for handling presuppositions compare to other methods of addressing presupposition errors in VQA models?
- Basis in paper: [explicit] The paper introduces a two-stage process to handle presupposition errors, first filtering out irrelevant images and then updating beliefs.
- Why unresolved: The paper does not compare this method to other potential approaches for handling presupposition errors in VQA models.
- What evidence would resolve it: Experimental results comparing the two-stage process to alternative methods for handling presupposition errors in VQA models.

### Open Question 2
- Question: What is the impact of using different types of questions (e.g., "how many", "what color") on the performance of the model in the image identification task?
- Basis in paper: [inferred] The paper mentions that certain types of questions are not used because they cannot be easily inferred from visual information, suggesting that the type of question could impact performance.
- Why unresolved: The paper does not explore the impact of different types of questions on the model's performance.
- What evidence would resolve it: Experimental results comparing the performance of the model when using different types of questions.

### Open Question 3
- Question: How does the performance of the model scale with the number of images in the dataset, and what is the theoretical limit of the model's scalability?
- Basis in paper: [explicit] The paper mentions that the model's performance was tested with 100 images, but does not discuss the theoretical limits of scalability.
- Why unresolved: The paper does not explore the scalability limits of the model or how its performance changes with a larger number of images.
- What evidence would resolve it: Experimental results showing the model's performance with varying numbers of images, and theoretical analysis of the model's scalability limits.

## Limitations
- Weak empirical validation with limited human evaluations
- Sparse corpus evidence for presupposition handling mechanisms
- High implementation sensitivity to VQA model performance

## Confidence
- High confidence: The fundamental premise that open-ended questions can be more informative than yes/no questions in image retrieval tasks
- Medium confidence: The specific two-stage presupposition handling mechanism and its implementation details
- Low confidence: The claimed performance improvements, particularly the 48% efficiency gain, due to limited human evaluation evidence

## Next Checks
1. **Presupposition filtering accuracy test**: Create a controlled dataset where 50% of candidate questions contain presuppositions that fail in the target image. Measure the system's ability to correctly identify and exclude irrelevant images before belief updates.

2. **Cross-model robustness evaluation**: Replace the ViLT-VQA model with alternative VQA architectures (e.g., BLIP-2, LLaVA) and measure performance degradation. This tests whether improvements stem from the question selection algorithm or VQA model quality.

3. **Human evaluation expansion**: Conduct human trials with at least 100 games comparing the proposed method against baseline approaches, measuring both accuracy and game length metrics to validate the claimed efficiency improvements.