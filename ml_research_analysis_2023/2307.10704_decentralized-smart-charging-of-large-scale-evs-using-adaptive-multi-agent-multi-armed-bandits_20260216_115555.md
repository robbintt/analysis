---
ver: rpa2
title: Decentralized Smart Charging of Large-Scale EVs using Adaptive Multi-Agent
  Multi-Armed Bandits
arxiv_id: '2307.10704'
source_url: https://arxiv.org/abs/2307.10704
tags:
- agent
- charging
- system
- each
- amas
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a decentralized smart charging system for large-scale
  electric vehicles (EVs) using an adaptive multi-agent system (AMAS) combined with
  multi-armed bandit (MAB) learning. The system aims to mitigate issues like electrical
  current congestion and voltage limit violations caused by peak load demands, while
  considering fairness among different players and handling uncertainties in the system.
---

# Decentralized Smart Charging of Large-Scale EVs using Adaptive Multi-Agent Multi-Armed Bandits

## Quick Facts
- arXiv ID: 2307.10704
- Source URL: https://arxiv.org/abs/2307.10704
- Reference count: 15
- Primary result: Decentralized AMAS with MAB learning reduces charging costs and ensures fairness in large-scale EV networks

## Executive Summary
This paper presents a decentralized smart charging system for large-scale electric vehicles (EVs) using an adaptive multi-agent system (AMAS) combined with multi-armed bandit (MAB) learning. The system addresses electrical current congestion and voltage limit violations caused by peak load demands while ensuring fairness among different players. Each EV agent makes binary charge/no-charge decisions based on local criticality values received from neighboring line and bus agents, without requiring global system knowledge. The approach is fully decentralized, scalable, real-time, model-free, and ensures data privacy.

## Method Summary
The method implements a fully decentralized approach where EV agents use linear Thompson Sampling to learn optimal charging schedules while considering local grid constraints. Each EV agent perceives only its immediate neighborhood and makes binary decisions to charge or not charge based on received neighborhood criticalities. The system uses a communication tree structure where line and bus agents monitor current congestion and voltage violations, forwarding the most critical requests upward. The MAB framework treats each time instant as a base arm, with EV agents selecting super arms (charge/no-charge decisions) to minimize electricity costs while satisfying state-of-charge and grid constraints.

## Key Results
- Proposed AMAS reduces system cost compared to basic charging strategy with near-optimal results
- Achieves fairness index values of 0.994 (small-scale) and 0.993 (large-scale) studies
- Successfully scales to 10,175 households with EVs while maintaining performance
- Ensures no constraint violations (current congestion or voltage limits) through adaptive learning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decentralized EV agents can make binary charge/no-charge decisions using local criticality comparisons without needing global system knowledge.
- Mechanism: Each agent perceives only its immediate neighborhood (physical lines, buses, and nearby EVs) and forwards the most critical request upward in the communication tree. The EV agent then selects charging instants by optimizing against this local criticality signal, avoiding both line congestion and voltage violations.
- Core assumption: Criticality values are well-calibrated to represent actual system stress (0 = safe, ±1 = constraint violation) and the communication topology matches the physical grid topology.
- Evidence anchors:
  - [abstract] "fully decentralized approach, where each EV agent makes binary decisions to charge or not charge based on its objective and the received neighborhood criticalities"
  - [section] "Each agent perceives only a small part of its immediate environment (neighboring agents)"
- Break condition: If line or bus criticalities are delayed or inaccurate, the EV agent's reward signal will be noisy, leading to suboptimal charging schedules and potential constraint violations.

### Mechanism 2
- Claim: Multi-armed bandit (MAB) learning allows EV agents to optimize charging costs under uncertainty without an oracle.
- Mechanism: The EV agent treats each time instant as a base arm and uses linear Thompson Sampling to learn the parameter vector θ linking time slots to electricity cost. The binary decision per instant is equivalent to selecting a "super arm" (subset of base arms) that minimizes cost while satisfying SoC and grid constraints.
- Core assumption: The relationship between cost and time is approximately linear in the parameter space and can be learned online with sufficient exploration-exploitation balance.
- Evidence anchors:
  - [section] "each day d consists of m equally spaced instants (base arms), linked to the instantaneous electricity cost c(i)"
  - [section] "Each EV agent uses linear Thompson Sampling to learn this parameter [θ]"
- Break condition: If the cost signal is highly non-linear or if PV production patterns are too volatile, linear Thompson Sampling may fail to converge, leading to persistent suboptimal super-arm selection.

### Mechanism 3
- Claim: Uniform sampling of EVs for cooperative actions ensures fairness and prevents systematic bias.
- Mechanism: When a line or bus agent identifies itself as critical, it forwards a criticality pair (Cr_f, [X]_f) to its neighbors, where [X]_f is a uniformly sampled subset of all EVs in the network. This ensures that no single EV or group of EVs is always selected for load-shifting, spreading the cost burden evenly.
- Core assumption: Uniform sampling is computationally cheap and representative enough of the whole EV population to maintain fairness across diverse usage patterns.
- Evidence anchors:
  - [section] "This uniform sampling helps in maintaining fairness among all EV agents"
  - [section] "fairness index value of 0.994 for the small-scale study and 0.993 for the large-scale study"
- Break condition: If the sampling is too coarse (too few EVs per request), the cooperative action may be ineffective; if too fine, communication overhead could negate the benefits of decentralization.

## Foundational Learning

- Concept: Multi-Armed Bandit (MAB) Theory
  - Why needed here: EV agents must learn the cost structure of the grid without an oracle, and MAB provides a principled way to balance exploration (trying new charge times) and exploitation (using known cheap slots).
  - Quick check question: What is the difference between a "base arm" and a "super arm" in combinatorial MAB, and why does the linear structure matter?

- Concept: Adaptive Multi-Agent Systems (AMAS)
  - Why needed here: The system needs to coordinate many autonomous EVs without a central controller, and AMAS provides the rules for local cooperation and self-organization that achieve global objectives.
  - Quick check question: How does the "minimize the maximum of own and neighbors' criticalities" rule prevent cascading failures in the grid?

- Concept: Electrical Distribution Constraints
  - Why needed here: The EV agents' decisions directly impact line current and bus voltage; understanding these constraints is essential for designing valid criticality metrics and reward functions.
  - Quick check question: What happens to a distribution feeder's voltage profile when multiple EVs charge simultaneously at maximum power?

## Architecture Onboarding

- Component map:
  - EV agents (binary decision makers) -> Line agents (current congestion monitors) -> Bus agents (voltage violation monitors) -> Physical grid topology
  - PV sensor network (provides real-time energy production) <-> Communication protocol (criticality + sampled EV set pairs)

- Critical path:
  1. EV connects → bus agent perceives SoC, arrival/departure
  2. EV agent enters main loop: perception → decision → action
  3. At each instant: EV agent receives criticality requests from neighbors
  4. EV agent uses MAB to choose charge/no-charge → updates reward
  5. Agents forward most critical request up the tree

- Design tradeoffs:
  - Uniform sampling vs. targeted selection: fairness vs. immediate congestion relief
  - Linear Thompson Sampling vs. nonlinear methods: computational scalability vs. modeling accuracy
  - Decentralized vs. hierarchical: robustness and privacy vs. potential coordination efficiency

- Failure signatures:
  - Voltage or current constraint violations → line/bus agent criticality not reaching EVs quickly
  - Poor convergence of EV agent cost optimization → MAB exploration rate too low or cost signal too noisy
  - Unfair cost distribution → sampling bias or unequal EV agent perception

- First 3 experiments:
  1. Simulate single EV agent with synthetic cost signal to validate MAB convergence and super-arm selection.
  2. Add line/bus agents with static criticality to verify EV agents respond appropriately to congestion/voltage signals.
  3. Deploy full small-scale topology with synchronized PV generation to confirm end-to-end constraint satisfaction and fairness metrics.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the AMAS system perform when EV agents do not have perfect information about their own battery state-of-charge (SoC) and instead rely on estimations or delayed readings?
- Basis in paper: [explicit] The paper assumes perfect knowledge of EV SoC and other parameters in the experiments, but does not explore the impact of sensor inaccuracies or communication delays.
- Why unresolved: The experimental setup assumes ideal conditions with perfect sensor data and communication, which may not reflect real-world scenarios where EV agents have imperfect or delayed information.
- What evidence would resolve it: Experiments comparing AMAS performance with and without sensor noise or communication delays would quantify the robustness of the system to information imperfections.

### Open Question 2
- Question: What is the impact of incorporating PV forecast data as contextual information in the MAB learning algorithm on the convergence time and overall system performance?
- Basis in paper: [explicit] The authors suggest that the impact of using PV forecasts as contextual data in the MAB algorithm can be studied in the future.
- Why unresolved: The current implementation uses Thompson Sampling without contextual information, potentially missing opportunities to improve learning efficiency by leveraging PV forecasts.
- What evidence would resolve it: Comparative experiments measuring convergence time and system cost with and without contextual PV forecasts would demonstrate the benefits of incorporating such information.

### Open Question 3
- Question: How does the AMAS system scale when the number of EVs exceeds the tested 10,175 households, particularly in terms of communication overhead and convergence time?
- Basis in paper: [inferred] While the paper tests a large-scale network with 10,175 households, it does not explore scaling beyond this point or analyze communication complexity as the network grows.
- Why unresolved: The experimental results show successful scaling to 10,175 EVs, but do not address potential bottlenecks or performance degradation when scaling to even larger networks.
- What evidence would resolve it: Stress tests with progressively larger networks, measuring communication overhead, convergence time, and system performance metrics, would reveal the practical limits of AMAS scalability.

## Limitations

- The linear Thompson Sampling approach may fail to converge under highly non-linear or volatile electricity cost signals and PV production patterns
- Uniform sampling of EVs for cooperative actions could introduce communication overhead that scales poorly with network size
- The criticality metrics depend on accurate real-time grid monitoring; delays or inaccuracies in line/bus agent feedback could propagate suboptimal decisions to EV agents

## Confidence

- **High**: The overall system architecture and agent-based coordination mechanism are well-defined and consistent with AMAS theory.
- **Medium**: The MAB-based learning framework is valid, but its convergence and optimality depend on the linearity assumption and exploration-exploitation balance.
- **Medium**: The fairness index results (0.994 and 0.993) are promising, but the sampling mechanism's robustness to diverse EV usage patterns is not fully explored.

## Next Checks

1. **Convergence under non-linear cost signals**: Simulate the EV agents with highly non-linear or volatile electricity cost and PV production profiles to test the robustness of linear Thompson Sampling.

2. **Criticality propagation delay**: Introduce artificial delays or noise in line/bus agent criticality values and observe the impact on EV agent decisions and constraint violations.

3. **Sampling bias analysis**: Vary the size and distribution of the uniformly sampled EV set [X]_f and measure the effect on fairness and cooperative load-shifting effectiveness.