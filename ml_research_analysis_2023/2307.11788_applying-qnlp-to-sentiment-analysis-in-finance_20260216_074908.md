---
ver: rpa2
title: Applying QNLP to sentiment analysis in finance
arxiv_id: '2307.11788'
source_url: https://arxiv.org/abs/2307.11788
tags:
- discocat
- quantum
- data
- qlstm
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper investigates the applicability of two quantum NLP methods\u2014\
  DisCoCat and QLSTM\u2014for sentiment analysis in finance. The authors generate\
  \ synthetic datasets using ChatGPT to ensure grammatical structure and realistic\
  \ complexity, addressing the lack of suitable real-world data for current quantum\
  \ circuit simulators."
---

# Applying QNLP to sentiment analysis in finance

## Quick Facts
- arXiv ID: 2307.11788
- Source URL: https://arxiv.org/abs/2307.11788
- Reference count: 32
- QLSTM trains faster than DisCoCat while achieving comparable accuracy to classical LSTM

## Executive Summary
This paper investigates two quantum NLP methods—DisCoCat and QLSTM—for sentiment analysis in finance, using synthetic datasets generated with ChatGPT to address the lack of suitable real-world data. The authors implement both methods alongside a classical LSTM baseline, finding that QLSTM trains substantially faster than DisCoCat while achieving validation accuracies above 80% within 20 epochs on simpler datasets. DisCoCat struggles with training progress due to high computational demands, particularly with CPU-based circuit simulation, making it impractical under current hardware constraints. The study concludes that QLSTM is more practical for QNLP tasks in finance, though future GPU support may improve DisCoCat performance.

## Method Summary
The authors generate synthetic financial sentiment datasets using ChatGPT prompts, creating sentences with maximum five words discussing financial topics with explicit sentiment labels. They implement three approaches: DisCoCat using pregroup parsing via BobCatParser to construct quantum circuits, QLSTM modifying PennyLane's LSTM cell with quantum ansatz layers, and a classical LSTM baseline with ReLU activations and trainable embeddings. All models are trained using binary cross-entropy loss, with QLSTM and classical LSTM evaluated on both low and moderate complexity datasets, while DisCoCat is limited to the simpler dataset due to computational constraints. Performance is measured through validation accuracy and training convergence curves.

## Key Results
- QLSTM achieves validation accuracies above 80% within 20 epochs on low complexity financial datasets
- DisCoCat requires ~82 hours for training on CPU, significantly slower than QLSTM's ~10 hours for the same dataset
- Classical LSTM baseline performs comparably to QLSTM on moderate complexity datasets, validating quantum approaches

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: QLSTM trains faster than DisCoCat for sentiment analysis on synthetic finance datasets.
- **Mechanism**: QLSTM uses recurrent cell structures with quantum-enhanced gates that allow incremental learning over time steps, while DisCoCat requires full sentence parsing and quantum circuit generation upfront, creating higher computational overhead per training iteration.
- **Core assumption**: The synthetic datasets generated with ChatGPT preserve grammatical structure needed for DisCoCat but are small enough to fit in memory for both approaches.
- **Evidence anchors**:
  - [abstract] "QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results"
  - [section] "QLSTM reaches validation accuracies above 80% within 20 epochs, whereas DisCoCat struggles with training progress due to high computational demands"
  - [corpus] Weak evidence; no direct comparison of runtime between QLSTM and DisCoCat found in related papers
- **Break condition**: If synthetic datasets become too large or complex, DisCoCat's pre-group parsing overhead may dominate, eroding the speed advantage.

### Mechanism 2
- **Claim**: Synthetic data generation via ChatGPT enables controlled grammatical structure for DisCoCat.
- **Mechanism**: ChatGPT is prompted to produce sentences with explicit sentiment labels and financial context, ensuring that each sentence can be parsed into pregroup expressions required by DisCoCat's categorical framework.
- **Core assumption**: The ChatGPT-generated sentences retain sufficient grammatical correctness for the CCG parser used in DisCoCat.
- **Evidence anchors**:
  - [section] "Generate sentences with a maximum length of five words discussing financial topics... At the end of each sentence, mention its respective label"
  - [section] "An overview of the generated datasets is displayed in Tab. I" showing vocabulary size and word count
  - [corpus] No corpus evidence found for effectiveness of ChatGPT-based synthetic data in DisCoCat; assumption based on methodology description
- **Break condition**: If the synthetic data lacks sufficient linguistic diversity or complexity, DisCoCat may fail to generalize to real-world finance text.

### Mechanism 3
- **Claim**: DisCoCat requires classical post-selection, increasing runtime especially with more qubits.
- **Mechanism**: After executing the quantum circuit for a sentence, measurement outcomes must match a target state to extract meaning; this probabilistic filtering multiplies the number of required circuit executions.
- **Core assumption**: The dimensionality of the word embedding space (number of qubits per wire) scales with sentence complexity.
- **Evidence anchors**:
  - [section] "to extract the meaning of the sentence |s⟩, wires 1 and 3 have to be measured in the |0⟩⊗|N | state... can contribute to a potentially immense increase in overall runtime"
  - [section] "only the low complexity data was used, as the hardware requirements were substantially higher"
  - [corpus] No direct corpus evidence; statement inferred from paper description of DisCoCat's computational demands
- **Break condition**: If hardware supports efficient post-selection or if sentence complexity is reduced, runtime penalty may become negligible.

## Foundational Learning

- **Concept**: Quantum circuit simulation vs. classical LSTM training
  - **Why needed here**: The paper compares training times and convergence behavior between quantum and classical models; understanding simulation bottlenecks is critical for interpreting results.
  - **Quick check question**: Why does QLSTM training take ~10 hours while DisCoCat takes ~82 hours for the same dataset?

- **Concept**: Pregroup grammar and CCG parsing
  - **Why needed here**: DisCoCat relies on converting sentences into pregroup expressions; without this understanding, one cannot grasp why synthetic data generation was necessary.
  - **Quick check question**: What is the difference between a noun type `n` and a verb type `nr · s · nl` in pregroup grammar?

- **Concept**: Word embedding dimensionality and qubit mapping
  - **Why needed here**: The choice of embedding size directly affects the number of qubits and thus simulation time; crucial for scaling experiments.
  - **Quick check question**: How does increasing the word embedding dimension from 5 to 10 affect the number of qubits required in DisCoCat?

## Architecture Onboarding

- **Component map**:
  - Data generation: ChatGPT prompts → labeled synthetic sentences
  - Classical baseline: Embedding layer → LSTM → Dense → Dropout
  - QLSTM: One-hot yt → QNN layers with ansatz → Quantum measurement
  - DisCoCat: CCG parser → pregroup expression → DisCoCat diagram → quantum circuit → post-selection

- **Critical path**: For QLSTM, the bottleneck is ansatz layer count and qubit count; for DisCoCat, it's pregroup parsing accuracy and post-selection overhead.

- **Design tradeoffs**:
  - More ansatz layers → better expressivity but higher barren plateau risk
  - Larger embedding dimension → richer semantics but exponential increase in qubits
  - Binary vs. multi-class classification → simpler quantum circuits but less informative results

- **Failure signatures**:
  - QLSTM: Stagnant loss curves after initial epochs suggest barren plateaus
  - DisCoCat: Random guessing accuracy indicates parsing or post-selection issues
  - Both: Long wall-clock times with minimal accuracy gain indicate hardware simulation limits

- **First 3 experiments**:
  1. Run QLSTM with 1 ansatz layer on low complexity data; verify >80% accuracy within 20 epochs.
  2. Parse a small subset of synthetic sentences with CCG parser; confirm valid pregroup expressions.
  3. Simulate DisCoCat circuit for a single sentence with 1-qubit output; measure post-selection success rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of DisCoCat compare to QLSTM when GPU-based circuit simulation becomes available?
- Basis in paper: [explicit] The authors note that DisCoCat's CPU-based simulation bottleneck prevented comprehensive evaluation, and speculate that GPU support could significantly improve performance.
- Why unresolved: Current software implementations only support CPU-based simulation for DisCoCat, while QLSTM implementations have GPU support. The authors observed that QLSTM outperformed DisCoCat in their CPU-based comparison but caution against generalizing these results.
- What evidence would resolve it: Comparative studies of DisCoCat and QLSTM performance using GPU-based circuit simulation for both methods, with identical datasets and hyperparameters.

### Open Question 2
- Question: What is the optimal number of ansatz layers for QLSTM to balance training time and accuracy for different dataset complexities?
- Basis in paper: [explicit] The authors observed that training time for QLSTM increased substantially with more ansatz layers, creating a time/quality trade-off, but did not fully explore this relationship.
- Why unresolved: The authors only performed basic hyperparameter tuning and noted the correlation between ansatz layers and training time without conducting an exhaustive search to find optimal configurations for different dataset complexities.
- What evidence would resolve it: Systematic hyperparameter studies varying ansatz layers across multiple dataset complexities, measuring both training time and accuracy to identify optimal layer counts.

### Open Question 3
- Question: How would more complex pregroup parsers affect DisCoCat performance on realistic financial sentiment analysis tasks?
- Basis in paper: [explicit] The authors used a CCG parser as a substitute for the unavailable stable pregroup parser, which may have limited DisCoCat's performance on their generated datasets.
- Why unresolved: The paper acknowledges the limitation of using CCG parsers instead of true pregroup parsers and suggests this may have contributed to DisCoCat's poor performance, but did not evaluate alternative parsing approaches.
- What evidence would resolve it: Comparative studies using different pregroup parsing methods on the same financial sentiment analysis datasets, measuring how parsing accuracy affects overall DisCoCat performance.

## Limitations
- Study relies entirely on synthetic datasets generated via ChatGPT, which may not capture real-world financial text complexity
- CPU-based simulation severely limits DisCoCat's practicality and prevents comprehensive evaluation
- Small vocabulary sizes (160-230 words) and short sentence lengths (max 5 words) may not represent practical deployment scenarios

## Confidence
- QLSTM training speed advantage: High - Directly measured and reported with clear training curves
- DisCoCat computational bottleneck: Medium - Inferred from runtime observations and literature, but not systematically benchmarked
- Synthetic data adequacy for DisCoCat: Low - No validation against real financial text or comparison with alternative synthetic generation methods

## Next Checks
1. Test DisCoCat on GPU hardware to quantify performance improvement and validate the CPU bottleneck hypothesis
2. Evaluate both quantum methods on real-world financial sentiment datasets to assess synthetic data generalization
3. Conduct ablation studies varying embedding dimensions and ansatz depths to identify optimal configurations for each method