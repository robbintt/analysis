---
ver: rpa2
title: A multimodal deep learning architecture for smoking detection with a small
  data approach
arxiv_id: '2309.10561'
source_url: https://arxiv.org/abs/2309.10561
tags:
- smoking
- image
- images
- data
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of detecting smoking content
  in multimedia (text and images) with limited training data, which is particularly
  relevant for identifying covert tobacco advertisements. The authors propose a multimodal
  deep learning architecture that leverages pre-trained models for both image and
  text processing, combined with human reinforcement and ensemble methods.
---

# A multimodal deep learning architecture for smoking detection with a small data approach

## Quick Facts
- arXiv ID: 2309.10561
- Source URL: https://arxiv.org/abs/2309.10561
- Reference count: 40
- Primary result: Achieved 74% image accuracy and 98% text accuracy for smoking detection with limited training data

## Executive Summary
This paper addresses the challenge of detecting smoking content in multimedia with limited training data, particularly for identifying covert tobacco advertisements. The authors propose a multimodal deep learning architecture that combines pre-trained models for both image and text processing, enhanced with human reinforcement and ensemble methods. The system demonstrates that effective smoking detection is feasible even with scarce data and in low-resource languages like Hungarian, achieving strong performance through careful model selection and data augmentation techniques.

## Method Summary
The proposed architecture processes video and text inputs through a multimodal pipeline. For video, frames are extracted and passed through CLIP-ViT-B-32 for semantic filtering based on cosine similarity to the "smoking" concept, then classified using fine-tuned EfficientNet B5. For text, Hungarian smoking-related terms are processed using XLM-RoBERTa fine-tuned on synthetic data generated via ChatGPT. The system employs an ensemble approach combining multimodal filtering and classification, with human reinforcement for continuous improvement. Key design choices include using 224x224 resolution frames, synthetic data generation for low-resource languages, and transfer learning to compensate for limited training data.

## Key Results
- Image classification accuracy: 74% achieved using multimodal filtering + EfficientNet ensemble
- Text classification accuracy: 98% achieved using XLM-RoBERTa fine-tuned on Hungarian smoking terms
- F1-scores: 96% (validation) and 91% (test) for text model
- System demonstrates feasibility of smoking detection with scarce data in low-resource languages

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CLIP multimodal filtering effectively narrows the search space for smoking content in video frames by comparing cosine similarities between image embeddings and the "smoking" term embedding.
- Mechanism: CLIP's ViT encoder transforms both images and the target term into 512-dimensional embeddings. Cosine similarity scores indicate semantic alignment; frames with high similarity are retained for further classification.
- Core assumption: Semantic proximity in embedding space correlates with actual visual smoking content.
- Evidence anchors:
  - [abstract] "The system allows expert intervention for continuous improvement and demonstrates the feasibility of detecting smoking content even with scarce data..."
  - [section] "We use the CLIP-ViT-B-32 model as a filter. After filtering, to achieve more accurate results, we recommend using the pre-trained EfficientNet B5 model..."
  - [corpus] Weak evidence; no neighbor papers directly discuss CLIP-based filtering for smoking content.
- Break condition: If embedding space alignment does not reflect true visual content, cosine similarity thresholds will misclassify frames.

### Mechanism 2
- Claim: Ensemble of multimodal-filtered images with fine-tuned EfficientNet improves detection accuracy beyond either model alone.
- Mechanism: Multimodal filtering reduces false positives by semantic relevance; EfficientNet provides high-precision visual classification on the filtered subset. Ensemble boosting combines complementary strengths.
- Core assumption: The two models' errors are sufficiently uncorrelated to benefit from ensemble combination.
- Evidence anchors:
  - [section] "We found that the predictions of the two constructions were sufficiently diverse to connect them using the boosting ensemble [44] solution."
  - [corpus] Weak evidence; no neighbor papers directly discuss ensemble boosting for smoking detection.
- Break condition: If both models share systematic biases, ensemble will not improve accuracy.

### Mechanism 3
- Claim: Fine-tuning XLM-RoBERTa on smoking-related Hungarian text data yields high accuracy despite low-resource language constraints.
- Mechanism: Pre-trained multilingual XLM-RoBERTa is adapted to smoking terminology using synthetic Hungarian data generated via ChatGPT and prompt engineering.
- Core assumption: Synthetic data preserves linguistic patterns needed for accurate smoking term detection.
- Evidence anchors:
  - [section] "The XLM-RoBERTa model achieved the best performance on the validation dataset with an F1-score of 96% and 98% accuracy."
  - [corpus] Weak evidence; no neighbor papers discuss fine-tuning XLM-RoBERTa for smoking term detection in Hungarian.
- Break condition: If synthetic data generation introduces noise or distributional shift, model performance will degrade.

## Foundational Learning

- Concept: Cosine similarity in high-dimensional embedding space
  - Why needed here: Determines which frames pass multimodal filtering based on semantic relevance to smoking.
  - Quick check question: What does a cosine similarity of 1 indicate about two vectors?

- Concept: Transfer learning and fine-tuning
  - Why needed here: Enables high performance on limited smoking datasets by adapting pre-trained models.
  - Quick check question: Why is fine-tuning preferred over training from scratch when data is scarce?

- Concept: Named entity recognition (NER) for domain-specific terms
  - Why needed here: Identifies smoking-related expressions in Hungarian text for detection.
  - Quick check question: What is the difference between NER and simple keyword matching?

## Architecture Onboarding

- Component map: Video/Text input → Frame extractor → CLIP multimodal filter → EfficientNet classifier → Text NER pipeline (XLM-RoBERTa) → Human reinforcement feedback loop → Storage
- Critical path: Video → CLIP filter → EfficientNet → Ensemble → Output
- Design tradeoffs:
  - Resolution vs. speed: 224x224 frames balance accuracy and processing time
  - Synthetic vs. real data: Synthetic Hungarian data speeds training but may introduce noise
- Failure signatures:
  - Low cosine similarity scores across all frames → CLIP model not capturing smoking semantics
  - Consistent false positives in EfficientNet → Need more diverse training images
  - High text NER errors → Synthetic data distribution mismatch
- First 3 experiments:
  1. Run CLIP filtering on a known smoking video; plot cosine similarity distribution to verify thresholding logic
  2. Fine-tune EfficientNet on the augmented smoker/non-smoker dataset; measure baseline accuracy
  3. Generate synthetic Hungarian smoking text with ChatGPT; fine-tune XLM-RoBERTa and validate on small annotated test set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed system perform on other languages beyond Hungarian, and what modifications would be needed to adapt it to other low-resource languages?
- Basis in paper: [inferred] The paper specifically focuses on Hungarian and mentions that XLM-RoBERTa supports multiple languages, suggesting potential for multilingual adaptation.
- Why unresolved: The paper only tests the system on Hungarian language data and doesn't provide any experiments or analysis for other languages.
- What evidence would resolve it: Experiments testing the system on multiple languages with varying levels of available training data, along with documentation of any necessary model adjustments or retraining requirements.

### Open Question 2
- Question: What is the long-term effectiveness of the human reinforcement component in continuously improving the system's accuracy?
- Basis in paper: [explicit] The paper mentions human reinforcement as a way to improve the system over time but doesn't provide any data on its actual impact.
- Why unresolved: The paper proposes human reinforcement as a mechanism but doesn't show any results from its implementation or measure how much it improves system performance over time.
- What evidence would resolve it: Longitudinal studies tracking system accuracy before and after human reinforcement interventions, including metrics on how quickly errors are corrected and how the system adapts to new types of smoking-related content.

### Open Question 3
- Question: How would the system's performance change if object detection capabilities were added to identify smoking paraphernalia and behaviors more precisely?
- Basis in paper: [explicit] The paper explicitly suggests this as a future enhancement in the conclusions section.
- Why unresolved: The authors acknowledge this as a potential improvement but don't provide any experimental results or estimates of the performance gain.
- What evidence would resolve it: Comparative experiments measuring accuracy with and without object detection, including analysis of how much more precise the system becomes at identifying different types of smoking-related content and false positive reduction.

## Limitations
- Relatively low image classification accuracy (74%) compared to text accuracy (98%)
- Use of synthetic Hungarian data introduces uncertainty about linguistic authenticity and potential distribution mismatch
- System performance on real-world, diverse video content beyond controlled datasets remains unclear

## Confidence
- **High Confidence**: Text processing with XLM-RoBERTa (98% accuracy is well-documented and reproducible)
- **Medium Confidence**: Overall multimodal architecture design and implementation approach
- **Low Confidence**: Specific effectiveness of CLIP-based multimodal filtering and ensemble combination methodology

## Next Checks
1. Conduct ablation studies to quantify individual contributions of CLIP filtering, EfficientNet classification, and ensemble methods to overall performance
2. Test the system on diverse, real-world smoking video content with varying lighting, angles, and contexts to assess robustness
3. Validate synthetic Hungarian text data quality by comparing model performance using both synthetic and human-annotated training sets