---
ver: rpa2
title: LLM-enhanced Self-training for Cross-domain Constituency Parsing
arxiv_id: '2311.02660'
source_url: https://arxiv.org/abs/2311.02660
tags:
- domain
- self-training
- parsing
- target
- constituency
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an LLM-enhanced self-training method for
  cross-domain constituency parsing, addressing the challenge of limited and low-quality
  raw corpora in traditional self-training. The proposed approach integrates large
  language models (LLMs) into the iterative self-training process, using grammar rules
  to guide LLM-generated raw corpora and employing a combined grammar-rule-based and
  confidence-based selection criterion for pseudo-data.
---

# LLM-enhanced Self-training for Cross-domain Constituency Parsing

## Quick Facts
- **arXiv ID**: 2311.02660
- **Source URL**: https://arxiv.org/abs/2311.02660
- **Reference count**: 16
- **Key outcome**: LLM-enhanced self-training improves cross-domain constituency parsing with average F1 gains of 0.88 (bert-base-uncased) and 0.99 (bert-large-uncased).

## Executive Summary
This paper addresses the challenge of cross-domain constituency parsing by introducing an LLM-enhanced self-training method. Traditional self-training suffers from limited and low-quality raw corpora, which this approach mitigates by integrating large language models (LLMs) into the iterative training process. By using grammar rules to guide LLM-generated sentences and employing a combined grammar-rule-based and confidence-based selection criterion, the method achieves significant improvements over traditional approaches across five target domains.

## Method Summary
The proposed LLM-enhanced self-training method integrates LLMs into the iterative self-training process for cross-domain constituency parsing. Grammar rules are extracted from source-domain parse trees and used to guide LLMs in generating target-domain sentences. These sentences are then parsed by the model, and high-quality pseudo-data is selected using a combined grammar-rule-based and confidence-based criterion. The process is repeated iteratively, progressively adapting the parser to the target domain.

## Key Results
- Significant F1 score improvements: 0.88 for bert-base-uncased and 0.99 for bert-large-uncased on average across five target domains.
- The combined grammar-rule-based and confidence-based selection criterion yields the highest performance.
- Open-source LLMs (e.g., falcon-40b-instruct) achieve comparable performance to closed-source models like ChatGPT.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Grammar-rule-based guidance improves LLM-generated sentence quality for constituency parsing.
- Mechanism: By constraining the LLM with grammar rules extracted from source-domain parse trees, the generated sentences are structurally aligned with the parsing task, reducing semantic drift and improving syntactic relevance.
- Core assumption: Grammar rules effectively encode syntactic constraints that guide meaningful sentence generation relevant to the parsing domain.
- Evidence anchors: [abstract] "we employ grammar rules as instructions for LLMs to generate target domain sentences"; [section 3.4] "LLMs generate sentences that closely resemble the target domain using grammar rules"; [corpus] Weak evidence: No direct evaluation of generated sentence quality; relies on downstream parsing performance.
- Break condition: If grammar rules do not align well with the target domain, generated sentences may still be irrelevant or noisy.

### Mechanism 2
- Claim: Combining grammar-rule-based and confidence-based selection yields the best pseudo-data quality.
- Mechanism: Grammar-rule-based selection ensures structural alignment with source domain, while confidence-based selection filters out unreliable parses, jointly ensuring both relevance and reliability.
- Core assumption: The joint criterion can balance structural fidelity and parsing confidence, leading to better adaptation.
- Evidence anchors: [abstract] "the combination of grammar rules and confidence criteria for pseudo-data selection yields the highest performance"; [section 3.4] "GRsConf-based criteria select high-confidence instances among candidates with high scores on the grammar rule"; [corpus] Moderate evidence: Performance gains reported, but no ablation showing individual contribution of each criterion.
- Break condition: If either criterion is too restrictive, it may reduce the diversity or quantity of pseudo-data, hurting adaptation.

### Mechanism 3
- Claim: Iterative LLM-enhanced self-training gradually adapts the parser to the target domain.
- Mechanism: In each iteration, LLM generates raw sentences, the parser is trained on updated data, and selection criteria refine the pseudo-treebank, progressively reducing domain mismatch.
- Core assumption: Each iteration moves the data distribution closer to the target domain without catastrophic forgetting.
- Evidence anchors: [section 3.3] "updated grammar rules and selected pseudo data progressively move closer to the target domain"; [section 5.2] "the distance between the selected pseudo-data and the source domain increases, while the distance to the target domain gradually decreases"; [corpus] Moderate evidence: Observed trend in domain distances; no long-term stability analysis beyond 4 iterations.
- Break condition: If iterations continue beyond convergence, performance may degrade due to overfitting or noise accumulation.

## Foundational Learning

- Concept: Constituency parsing
  - Why needed here: The entire method is designed to improve constituency parsing performance across domains.
  - Quick check question: What is the difference between constituency and dependency parsing in terms of output structure?
- Concept: Self-training
  - Why needed here: The method relies on iterative pseudo-labeling and model retraining to adapt to the target domain.
  - Quick check question: In self-training, how do you typically decide which pseudo-labels to keep for retraining?
- Concept: Large language models (LLMs)
  - Why needed here: LLMs are used to generate domain-relevant raw text guided by grammar rules.
  - Quick check question: What are common challenges when using LLMs for structured output tasks like parsing?

## Architecture Onboarding

- Component map:
  - Source domain treebank → Grammar rule extractor → LLM prompt generator → LLM → Raw sentence corpus
  - Raw corpus → Parser trainer (Berkeley Neural Parser) → Parser → Parsed trees → Selection module (Token/Conf/GRs/GRsConf) → Pseudo-treebank
  - Pseudo-treebank → Updated source treebank → Next iteration
- Critical path: Source treebank → Grammar rule extraction → LLM generation → Parser training → Tree selection → Target parser
- Design tradeoffs:
  - Using LLM vs. real raw corpus: LLM provides control but may lack domain authenticity; real corpus is more natural but less controllable.
  - Grammar-rule vs. confidence-only selection: Grammar rules ensure structural relevance but may exclude useful data; confidence alone is safer but less targeted.
- Failure signatures:
  - Performance plateaus or degrades after iterations: Likely overfitting or noise accumulation.
  - Grammar rules too restrictive: Parser fails to generalize to target domain.
  - Confidence scores unreliable: Poor pseudo-data selection despite high confidence.
- First 3 experiments:
  1. Test LLM generation with grammar rules on a small subset and evaluate sentence syntactic relevance.
  2. Compare each selection criterion (Token, Conf, GRs, GRsConf) individually on a validation set.
  3. Run a 2-iteration self-training loop with GRsConf selection and measure F1 gain over baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the number of grammar rules extracted from the treebank affect the quality and diversity of sentences generated by LLMs?
- Basis in paper: [explicit] The paper states that there is a direct correlation between the number of grammar rules and the length of LLM generated sentences, and mentions adjusting the value of N based on sentence length distribution.
- Why unresolved: The paper only briefly mentions this relationship and doesn't explore the optimal number of grammar rules for generating high-quality, diverse sentences.
- What evidence would resolve it: A systematic study varying the number of grammar rules and evaluating the resulting sentence quality and diversity would provide insights into the optimal number for effective LLM-enhanced self-training.

### Open Question 2
- Question: How does the choice of target domain sentences used as style references impact the performance of LLM-enhanced self-training?
- Basis in paper: [explicit] The paper mentions using a small set of domain-specific sentences as style references and explores the impact of varying the number of target domain sentences.
- Why unresolved: The paper only explores the impact of the number of target domain sentences, not the specific characteristics of these sentences (e.g., their length, complexity, or topic distribution) that might influence the LLM's ability to generate appropriate sentences.
- What evidence would resolve it: Experiments comparing the performance of LLM-enhanced self-training using different sets of target domain sentences with varying characteristics would shed light on the importance of selecting appropriate style references.

### Open Question 3
- Question: How does the performance of LLM-enhanced self-training compare to other domain adaptation methods for constituency parsing, such as adversarial training or meta-learning approaches?
- Basis in paper: [inferred] The paper focuses on comparing LLM-enhanced self-training to vanilla self-training and direct model transfer, but doesn't explore other domain adaptation methods.
- Why unresolved: The paper doesn't provide a comprehensive comparison with other state-of-the-art domain adaptation techniques, making it difficult to assess the relative effectiveness of LLM-enhanced self-training.
- What evidence would resolve it: Conducting experiments comparing LLM-enhanced self-training to other domain adaptation methods on the same datasets and evaluation metrics would provide a clearer picture of its strengths and weaknesses relative to other approaches.

## Limitations
- No direct evaluation of LLM-generated sentence quality; improvements are inferred from downstream parsing performance.
- Lack of ablation studies to quantify individual contributions of grammar-rule-based and confidence-based selection criteria.
- No long-term stability analysis beyond 4 iterations, raising concerns about potential degradation from noise accumulation or overfitting.

## Confidence

- **High confidence**: The experimental methodology and reported F1 score improvements are sound and reproducible. The comparative analysis against vanilla self-training and direct model transfer provides clear evidence of the method's effectiveness.
- **Medium confidence**: The mechanisms by which grammar rules and confidence criteria improve adaptation are plausible but not definitively proven. The absence of ablation studies and direct quality assessment of LLM-generated sentences introduces uncertainty about the exact sources of improvement.
- **Low confidence**: Claims about the superiority of combined GRsConf selection over individual criteria lack empirical support through ablation studies. The stability and scalability of the iterative process beyond the tested iterations remain unverified.

## Next Checks
1. Conduct an ablation study comparing Token, Conf, GRs, and GRsConf selection criteria individually to quantify their respective contributions to performance gains.
2. Implement a direct evaluation of LLM-generated sentence quality using syntactic metrics (e.g., parse tree accuracy on a held-out sample) to validate the effectiveness of grammar-rule guidance.
3. Extend the iterative self-training process to 8-10 iterations with monitoring of F1 scores and domain distance metrics to assess long-term stability and identify potential degradation points.