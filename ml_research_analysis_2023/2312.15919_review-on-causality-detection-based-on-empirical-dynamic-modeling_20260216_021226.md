---
ver: rpa2
title: Review on Causality Detection Based on Empirical Dynamic Modeling
arxiv_id: '2312.15919'
source_url: https://arxiv.org/abs/2312.15919
tags:
- causal
- time
- series
- correlation
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a comprehensive review of causal detection
  methods based on Empirical Dynamic Modeling (EDM), focusing on the Convergent Cross
  Mapping (CCM) algorithm. It addresses the limitations of traditional correlation-based
  analyses in nonlinear dynamic systems, which can lead to spurious correlations or
  miss true causal relationships.
---

# Review on Causality Detection Based on Empirical Dynamic Modeling

## Quick Facts
- arXiv ID: 2312.15919
- Source URL: https://arxiv.org/abs/2312.15919
- Reference count: 40
- One-line primary result: Comprehensive review of Empirical Dynamic Modeling (EDM) methods for causal detection, focusing on Convergent Cross Mapping (CCM) algorithm.

## Executive Summary
This paper provides a comprehensive review of causal detection methods based on Empirical Dynamic Modeling (EDM), focusing on the Convergent Cross Mapping (CCM) algorithm. It addresses the limitations of traditional correlation-based analyses in nonlinear dynamic systems, which can lead to spurious correlations or miss true causal relationships. The paper introduces the foundational concepts of EDM, including Takens' Embedding Theorem, the Simplex Projection algorithm, and the CCM algorithm. It also discusses various improvements and applications of EDM in fields such as ecology, finance, meteorology, and medicine. The key outcome is that EDM offers a model-free, data-driven approach to detect causal relationships in complex dynamic systems, overcoming the limitations of correlation-based methods.

## Method Summary
The CCM method detects causality by measuring whether information from variable X can be recovered from the reconstructed attractor manifold of variable Y. It uses time-delayed embedding to reconstruct Y's manifold, then tests whether it can predict X's historical values. High prediction skill (ρ) that converges as data length increases indicates causality. The Simplex Projection algorithm estimates the optimal embedding dimension E and serves as the core prediction engine within CCM, identifying E+1 nearest neighbors in the attractor manifold for weighted averaging predictions.

## Key Results
- CCM offers a model-free, data-driven approach to detect causal relationships in complex dynamic systems
- Convergence of prediction skill (ρ) with increasing time series length is a necessary condition for causality
- EDM methods overcome limitations of correlation-based methods and Granger causality in nonlinear systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Convergent Cross Mapping (CCM) detects causality by measuring whether information from variable X can be recovered from the reconstructed attractor manifold of variable Y.
- Mechanism: If X causes Y, the underlying attractor manifold of Y contains implicit information about X. CCM uses time-delayed embedding to reconstruct Y's manifold, then tests whether it can predict X's historical values. High prediction skill (ρ) that converges as data length increases indicates causality.
- Core assumption: Causality implies information transfer; the attractor manifold preserves this information even under nonlinear coupling.
- Evidence anchors:
  - [abstract] "It posits that if variable X causes variable Y (X ⇒ Y), then the information about X is inherent in Y and can be extracted from Y's data."
  - [section] "CCM assesses the strength of the causal relationship in the X ⇒ Y direction (i.e., X causing Y) based on the extent to which variable Y can be reliably inferred from variable X."
- Break condition: If the system is driven by common external factors or strong unidirectional forcing causes synchronization, CCM may produce false bidirectional signals.

### Mechanism 2
- Claim: Simplex Projection algorithm estimates the optimal embedding dimension E and serves as the core prediction engine within CCM.
- Mechanism: For each state point in the reconstruction, E+1 nearest neighbors are identified in the attractor manifold. Predictions are made by weighted averaging of neighbors' future states. Prediction skill (ρ) is maximized at the correct embedding dimension.
- Core assumption: Local neighborhoods in reconstructed state space preserve dynamical relationships.
- Evidence anchors:
  - [section] "The Simplex Projection Algorithm, based on the reconstruction of the phase space from historical time-series data, is a method employed for short-term forecasting of chaotic dynamical systems."
  - [section] "By varying the value of E, different levels of predictive performance can be computed, with the optimal embedding dimension E corresponding to the highest predictive accuracy."
- Break condition: When noise dominates or data is sparse, nearest-neighbor prediction skill degrades and E estimation becomes unreliable.

### Mechanism 3
- Claim: Convergence of prediction skill (ρ) with increasing time series length L is a necessary condition for causality.
- Mechanism: As more data is used to reconstruct the attractor manifold, density increases, making local neighborhoods more representative. For causal variables, prediction skill improves and converges toward a stable value; for non-causal pairs, it remains low or does not converge.
- Core assumption: Causality implies persistent dynamical coupling that becomes more evident with more data.
- Evidence anchors:
  - [section] "When a causal relationship exists, as the length of the variable's time series L increases, this prediction skill gradually increases and converges toward a stable value."
  - [section] "Convergence is a necessary condition for the presence of causality and a key attribute distinguishing causality from correlation."
- Break condition: If the system is non-stationary or coupling strength changes over time, convergence may fail even if causality exists.

## Foundational Learning

- Takens' Embedding Theorem
  - Why needed here: Enables reconstruction of high-dimensional attractor manifold from a single scalar time series, which is essential for CCM to work without requiring all system variables.
  - Quick check question: What mathematical property guarantees that the reconstructed attractor is topologically equivalent to the original manifold?

- Convergent Cross Mapping (CCM)
  - Why needed here: Provides a model-free, data-driven method to detect nonlinear causality that avoids pitfalls of correlation-based or Granger causality methods.
  - Quick check question: How does CCM distinguish between spurious correlation and true causal influence?

- Nearest Neighbor Prediction (Simplex Projection)
  - Why needed here: Forms the prediction engine that quantifies how well one variable's attractor manifold can recover information about another variable.
  - Quick check question: Why is the number of neighbors chosen as E+1 rather than E?

## Architecture Onboarding

- Component map:
  - Time series ingestion → Time delay embedding → Attractor manifold reconstruction → Nearest neighbor search → Prediction skill calculation → Convergence analysis
  - Supporting modules: Parameter selection (τ, E), cross-validation, noise handling

- Critical path:
  1. Load paired time series X and Y
  2. Choose embedding parameters (τ=1 default, E via simplex projection)
  3. Reconstruct Y's attractor manifold M_y
  4. For each point in M_y, find E+1 nearest neighbors
  5. Predict X's value at corresponding time using weighted neighbor values
  6. Compute correlation (ρ) between predicted and actual X
  7. Repeat for increasing L and assess convergence

- Design tradeoffs:
  - Longer time series improve convergence but increase computation
  - Higher E captures more complexity but risks overfitting with limited data
  - Noise filtering improves robustness but may remove weak causal signals

- Failure signatures:
  - Non-convergence despite suspected causality → check for non-stationarity or strong unidirectional forcing
  - High ρ in both directions → check for synchronization or common driver
  - Low ρ in both directions → insufficient data length or noise dominance

- First 3 experiments:
  1. Test CCM on the logistic map coupled system from section 2.2 to verify bidirectional causality detection
  2. Apply CCM to ecological predator-prey time series with known coupling to validate convergence behavior
  3. Introduce increasing levels of noise to a deterministic system and measure degradation in prediction skill and convergence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the CCM method be effectively extended to handle systems with a large number of variables without losing predictive accuracy?
- Basis in paper: [explicit] The paper mentions that the method is more applicable in systems with fewer variables and that traditional state space reconstruction theories struggle with more variables over long-term processes.
- Why unresolved: The complexity and evolution of dynamic systems with more variables pose challenges for modeling stability and capturing underlying patterns in time series data.
- What evidence would resolve it: Empirical studies demonstrating successful application of CCM in high-dimensional systems with comparable predictive accuracy to low-dimensional systems.

### Open Question 2
- Question: How can the CCM method be improved to handle irregular or sparse sampling in time series data without compromising causal detection performance?
- Basis in paper: [explicit] The paper notes that irregular data collection and sampling are common in fields like ecology, medicine, and atmospheric sciences, and that the method's performance deteriorates with significant data gaps or irregular sampling.
- Why unresolved: State space reconstruction theory assumes evenly distributed sample points over time, which is often not the case in real-world applications.
- What evidence would resolve it: Development and validation of enhanced CCM algorithms that effectively reconstruct state spaces and maintain causal detection accuracy with irregular or sparse data.

### Open Question 3
- Question: What systematic approach can be developed to distinguish between direct and indirect causal relationships in complex systems using CCM?
- Basis in paper: [explicit] The paper mentions that while some methods can distinguish between direct and indirect causality, they require substantial data and are constrained by multiple factors, resulting in suboptimal practical outcomes.
- Why unresolved: Existing methods for distinguishing direct and indirect causality are data-intensive and not systematically comprehensive.
- What evidence would resolve it: A new methodological framework that reliably differentiates direct from indirect causality with minimal data requirements and demonstrates robust performance across diverse complex systems.

## Limitations
- The review does not adequately address scenarios where CCM may fail, such as strong unidirectional forcing causing synchronization or non-stationary coupling strength.
- Limited attention to alternative EDM approaches (S-map, nonlinear forecasting) that might be more appropriate for certain system types.
- Empirical validation examples are primarily synthetic or from well-studied domains, limiting generalizability claims to novel application areas.

## Confidence

- Core mechanism (convergence indicates causality): High
- Specific parameter recommendations (τ=1, optimal E via Simplex): Medium
- Effectiveness in high-dimensional systems: Low

## Next Checks

1. Test CCM on a system with known unidirectional forcing to quantify false bidirectional detection rates and evaluate ECCM's effectiveness.

2. Apply the method to short, noisy time series from a known causal system to determine minimum data requirements and robustness thresholds.

3. Compare CCM performance against Granger causality and transfer entropy on identical datasets to benchmark detection accuracy and computational efficiency.