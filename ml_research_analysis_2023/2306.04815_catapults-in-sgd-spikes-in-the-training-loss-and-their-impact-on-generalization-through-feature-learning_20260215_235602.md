---
ver: rpa2
title: 'Catapults in SGD: spikes in the training loss and their impact on generalization
  through feature learning'
arxiv_id: '2306.04815'
source_url: https://arxiv.org/abs/2306.04815
tags:
- loss
- training
- catapults
- learning
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the phenomenon of spikes in training loss
  during neural network optimization with stochastic gradient descent (SGD). The authors
  provide evidence that these spikes, known as "catapults", are optimization dynamics
  that occur in the top eigenspace of the tangent kernel.
---

# Catapults in SGD: spikes in the training loss and their impact on generalization through feature learning

## Quick Facts
- arXiv ID: 2306.04815
- Source URL: https://arxiv.org/abs/2306.04815
- Reference count: 40
- Primary result: SGD training spikes (catapults) improve generalization by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor.

## Executive Summary
This paper investigates the phenomenon of spikes in training loss during neural network optimization with stochastic gradient descent (SGD). The authors provide evidence that these spikes, known as "catapults", are optimization dynamics that occur in the top eigenspace of the tangent kernel. They show that catapults can be generated multiple times by increasing the learning rate during gradient descent (GD) and that they lead to improved generalization by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor. The authors also demonstrate that smaller batch sizes in SGD induce more catapults, thereby improving AGOP alignment and test performance. The results suggest that catapults are an important mechanism for feature learning and generalization in deep neural networks.

## Method Summary
The paper investigates catapults through a combination of theoretical analysis and empirical experiments. The method involves training neural networks on various datasets (CIFAR-10, SVHN, CelebA) and synthetic polynomial regression tasks using SGD with varying batch sizes and learning rates. The authors analyze the tangent kernel eigenspaces, compute AGOP at different training stages, and measure the alignment between AGOP and the true predictor's AGOP. The training procedure includes monitoring loss spikes, eigenvalue changes, and AGOP alignment to identify catapult events and their impact on generalization.

## Key Results
- Spikes in training loss correspond to catapult dynamics occurring in the top eigenspace of the tangent kernel
- Smaller batch sizes in SGD lead to more catapults, which improve generalization through increased AGOP alignment
- Catapults improve generalization by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Spikes in training loss correspond to catapult dynamics occurring in the top eigenspace of the tangent kernel.
- Mechanism: The catapult phenomenon occurs when the learning rate exceeds a critical value, causing the loss to increase in certain eigendirections of the tangent kernel. The spikes are localized to the top eigenspace, allowing the loss to recover quickly afterward.
- Core assumption: Wide neural networks can be approximated by their linearization, and the catapult dynamics are governed by the spectral properties of the tangent kernel.
- Evidence anchors:
  - [abstract] "We provide evidence that the spikes in the training loss of SGD are 'catapults', an optimization phenomenon originally observed in GD with large learning rates"
  - [section] "we project the residual to the top eigenspace of the tangent kernel and show that spikes in the total loss function correspond to the spikes in the components of the loss in this low-dimensional subspace"
  - [corpus] Weak evidence - no direct mention of catapults or tangent kernel in corpus papers.

### Mechanism 2
- Claim: Smaller batch sizes in SGD lead to more catapults, which improve generalization through increased AGOP alignment.
- Mechanism: Smaller batch sizes increase the variance in the eigenvalues of the tangent kernel across batches. This variance causes the critical learning rate to oscillate around the fixed learning rate more frequently, resulting in more catapult events.
- Core assumption: The critical learning rate for each batch fluctuates due to batch sampling, and these fluctuations cause more catapult events with smaller batch sizes.
- Evidence anchors:
  - [abstract] "Furthermore, we demonstrate that a smaller batch size in SGD induces a larger number of catapults, thereby improving AGOP alignment and test performance"
  - [section] "as small batch size leads to higher variance in the eigenvalues of the tangent kernel for any given batch, small batch size results in an increased number of catapults"
  - [corpus] Weak evidence - no direct mention of batch size effects on catapults or AGOP alignment in corpus papers.

### Mechanism 3
- Claim: Catapults improve generalization by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor.
- Mechanism: Catapults cause the network to explore regions of parameter space that lead to better feature learning, as measured by AGOP alignment. This improved feature learning translates to better generalization performance.
- Core assumption: AGOP alignment is a valid proxy for feature learning and generalization capability.
- Evidence anchors:
  - [abstract] "we posit an explanation for how catapults lead to better generalization by demonstrating that catapults promote feature learning by increasing alignment with the Average Gradient Outer Product (AGOP) of the true predictor"
  - [section] "we show that catapults improve the generalization performance by alignment between the AGOP of the trained network with that of the true AGOP"
  - [corpus] Weak evidence - no direct mention of AGOP or its role in generalization in corpus papers.

## Foundational Learning

- Concept: Neural Tangent Kernel (NTK)
  - Why needed here: The NTK is central to understanding the catapult dynamics, as the spikes occur in its top eigenspace.
  - Quick check question: How does the NTK change during a catapult event, and why does this lead to a spike in the loss?

- Concept: Eigenvalue decomposition and spectral analysis
  - Why needed here: The catapult phenomenon is analyzed by decomposing the tangent kernel into its eigenspaces and observing the behavior of the loss in each subspace.
  - Quick check question: What happens to the loss in the top eigenspace versus the remaining eigenspaces during a catapult event?

- Concept: Average Gradient Outer Product (AGOP)
  - Why needed here: AGOP alignment is used as a measure of feature learning and generalization, and catapults are shown to improve AGOP alignment.
  - Quick check question: How is AGOP computed, and why does its alignment with the true AGOP correlate with generalization performance?

## Architecture Onboarding

- Component map: Data preprocessing -> Model definition and initialization -> Training loop with SGD and learning rate scheduling -> Loss computation and backpropagation -> Eigenvalue decomposition of the tangent kernel -> AGOP computation and alignment measurement -> Visualization and analysis tools

- Critical path:
  1. Load and preprocess data
  2. Initialize model with NTK parameterization
  3. Compute tangent kernel and its eigendecomposition
  4. Train model with SGD, monitoring loss and eigenvalues
  5. Identify catapult events by analyzing loss spikes and eigenvalue changes
  6. Compute AGOP at various training stages
  7. Measure AGOP alignment and its correlation with generalization

- Design tradeoffs:
  - Wider networks provide better linearization approximations but increase computational cost
  - Smaller batch sizes lead to more catapults but also more noisy gradients
  - Computing full eigendecomposition of the tangent kernel is expensive for large datasets

- Failure signatures:
  - Loss spikes that do not recover (indicates divergence rather than catapult)
  - No significant changes in the tangent kernel's eigenvalues (suggests learning rate is too small)
  - Poor correlation between AGOP alignment and generalization (suggests AGOP is not a reliable measure)

- First 3 experiments:
  1. Train a simple fully connected network on a synthetic low-rank polynomial regression task with SGD, varying the batch size and learning rate. Monitor the loss spikes and eigenvalue changes to identify catapult events.
  2. Compute the AGOP at initialization and after each catapult event. Measure the alignment with the true AGOP and its correlation with generalization performance.
  3. Repeat experiment 1 with different network architectures (e.g., CNN, ResNet) and datasets (e.g., CIFAR-10, SVHN) to verify the robustness of the catapult phenomenon and its impact on generalization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do catapult dynamics affect the generalization performance of neural networks with non-standard architectures, such as transformers or recurrent neural networks?
- Basis in paper: The paper demonstrates catapult dynamics in various network architectures, including Wide ResNet and ViT, but does not explore their effects on generalization in these specific architectures.
- Why unresolved: The study primarily focuses on fully connected and convolutional networks, leaving a gap in understanding how catapults influence generalization in other architectures.
- What evidence would resolve it: Experiments showing the impact of catapults on generalization across different architectures, including transformers and recurrent networks, would provide insights into their broader applicability.

### Open Question 2
- Question: What is the role of catapults in the optimization dynamics of neural networks trained with adaptive learning rate methods, such as Adam or RMSprop?
- Basis in paper: The paper explores the relationship between catapults and generalization in standard SGD, but does not investigate their role in adaptive learning rate methods.
- Why unresolved: The study focuses on SGD dynamics and does not extend its analysis to adaptive methods, which are widely used in practice.
- What evidence would resolve it: Experiments demonstrating the presence and impact of catapults in networks trained with adaptive learning rate methods would clarify their role in these optimization algorithms.

### Open Question 3
- Question: How do catapults influence the feature learning process in neural networks with different activation functions, such as sigmoid or tanh?
- Basis in paper: The paper discusses the role of catapults in feature learning through AGOP alignment, but does not explore their effects with various activation functions.
- Why unresolved: The study primarily uses ReLU activation functions and does not investigate how catapults might affect feature learning with other activation functions.
- What evidence would resolve it: Experiments showing the impact of catapults on feature learning with different activation functions would provide insights into their influence on network behavior.

### Open Question 4
- Question: Can the occurrence of catapults be predicted or controlled during the training process to enhance generalization performance?
- Basis in paper: The paper demonstrates the occurrence of catapults and their positive impact on generalization, but does not provide methods for predicting or controlling them.
- Why unresolved: The study identifies catapults as a beneficial phenomenon but does not explore strategies to predict or control their occurrence.
- What evidence would resolve it: Development of predictive models or control mechanisms for catapults, along with experimental validation of their impact on generalization, would address this question.

## Limitations
- The linearization approximation may not hold for narrow networks or certain architectures, limiting the generalizability of the findings.
- The relationship between AGOP alignment and generalization is assumed but not rigorously proven across diverse tasks and architectures.
- The critical learning rate for catapult dynamics may not be stable with very small batch sizes, potentially leading to unstable training.

## Confidence

- **High confidence** in empirical observations of loss spikes and their spectral localization in tangent kernel eigenspaces
- **Medium confidence** in the mechanism linking learning rate to catapult dynamics via critical thresholds
- **Low confidence** in the AGOP-alignment-generalization pathway as a universal explanation

## Next Checks

1. Test whether catapults occur in non-NTK-parameterized networks on CIFAR-10 with batch sizes 16-128, verifying if spectral analysis still reveals catapult dynamics in the top eigenspace

2. Design a control experiment where AGOP is explicitly manipulated (e.g., through feature regularization) without changing learning rate, to isolate whether AGOP alignment causally drives generalization improvements

3. Implement a modified SGD with dynamic learning rate adjustment that targets the critical threshold more precisely, to test if more frequent catapults systematically improve generalization across architectures