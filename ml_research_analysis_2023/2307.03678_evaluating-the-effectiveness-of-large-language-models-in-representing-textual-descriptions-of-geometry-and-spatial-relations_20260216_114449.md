---
ver: rpa2
title: Evaluating the Effectiveness of Large Language Models in Representing Textual
  Descriptions of Geometry and Spatial Relations
arxiv_id: '2307.03678'
source_url: https://arxiv.org/abs/2307.03678
tags:
- spatial
- llms
- relations
- geometry
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates the effectiveness of large language models
  (LLMs) in representing geometries and spatial relations from textual descriptions.
  The authors use GPT-2 and BERT to encode geometries in WKT format and assess their
  embeddings on six downstream tasks, including geometry type classification, area
  and centroid computation, spatial predicate prediction, distance measurement, and
  location prediction.
---

# Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations

## Quick Facts
- arXiv ID: 2307.03678
- Source URL: https://arxiv.org/abs/2307.03678
- Authors: 
- Reference count: 19
- Primary result: LLMs can preserve geometry types with up to 73% accuracy on spatial relations, but struggle with numeric estimation and spatial retrieval

## Executive Summary
This paper evaluates how well large language models (LLMs) like GPT-2 and BERT can encode geometries represented in Well-Known Text (WKT) format and perform downstream geospatial tasks. The study tests embeddings on six tasks: geometry type classification, area and centroid computation, spatial predicate prediction, distance measurement, and location prediction. Results show LLMs successfully preserve geometry types (100% accuracy) and capture some spatial relations (up to 73% accuracy), but face challenges in estimating numeric values like area and distance due to information loss during tokenization and averaging of embeddings. The research highlights the need for improved encoding methods and integration of domain knowledge to support GeoAI applications using foundation models.

## Method Summary
The study uses real-world geospatial datasets from OpenStreetMap (road networks, POIs) and Microsoft Building Footprints for Madison, WI, sampling 12,000 geometries (Point, LineString, Polygon) with computed attributes and spatial relations. WKT representations are encoded using GPT-2 and BERT, with token embeddings averaged to create geometry representations. These embeddings are then fed into simple MLP classifiers/regressors for six downstream tasks. The models are trained on 80% of the data, validated on 5%, and tested on 15%, with performance measured using accuracy, MAPE, RMSE, and precision@5 metrics.

## Key Results
- LLMs achieve 100% accuracy on geometry type classification due to reliable tokenization of geometry keywords
- Spatial predicate prediction reaches 71-73% accuracy, improving when geometry type is explicitly included
- Numeric tasks (area, distance, centroid) show poor performance (MAPE 41.9-44.1% for polygons) due to loss of magnitude information during embedding aggregation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM embeddings can preserve geometry types because the textual WKT representations are tokenized in ways that preserve lexical markers for geometry type (e.g., "POINT", "LINESTRING").
- Mechanism: During tokenization, words like "POINT" or "LINESTRING" are likely treated as distinct tokens, so their presence in the embedding space is retained.
- Core assumption: The tokenizer reliably separates geometry type keywords from coordinate data and that these tokens maintain their semantic meaning through the embedding process.
- Evidence anchors:
  - [abstract] "The results show that LLMs can preserve geometry types and capture some spatial relations with up to 73% accuracy."
  - [section] "The 100% accuracy achieved on both the validation and the test dataset of T1 is expected as the geometry type are words that often occur in text documents."
  - [corpus] Weak evidence; no corpus neighbor explicitly discusses tokenization or geometry type preservation.
- Break condition: If the tokenizer conflates geometry type keywords with numeric coordinate tokens, or if the model's attention mechanism degrades keyword semantics during averaging embeddings.

### Mechanism 2
- Claim: Spatial predicates can be predicted when geometry type is included because embeddings capture the joint distribution of geometry type + spatial relation.
- Mechanism: The concatenated embedding [Enc(gi); Enc(gj)] encodes geometry types and coordinates, and spatial relation predicates are partially predictable from these features due to learned correlations in the training data.
- Core assumption: The embedding space preserves discriminative features for both geometry types and spatial relations; and that MLP classifier can linearly separate predicate classes given these features.
- Evidence anchors:
  - [abstract] "The results show that LLMs can preserve geometry types and capture some spatial relations with up to 73% accuracy."
  - [section] "One interesting finding is that the spatial predicate can be better predicted when combined with the geometry type, with accuracy increased from 62%~68% to 71%~73%."
  - [corpus] No direct corpus evidence; neighbor papers focus on LLMs for general spatial reasoning but not specific predicate classification.
- Break condition: If geometry type tokens are not reliably tokenized or if predicate geometry type co-occurrence patterns are too sparse for effective learning.

### Mechanism 3
- Claim: LLM embeddings can encode spatial relations but fail at numeric estimation due to averaging embeddings collapsing magnitude information.
- Mechanism: Spatial relations are categorical and preserved in embeddings, but numeric values (area, distance) require fine-grained magnitude information that is lost when averaging token embeddings or fragmented during tokenization.
- Core assumption: Averaging embeddings destroys coordinate magnitude information needed for regression; tokenization breaks continuity of coordinate sequences.
- Evidence anchors:
  - [abstract] "However, challenges remain in estimating numeric values (e.g., area, distance) and retrieving spatially related objects."
  - [section] "significant errors... are observed in area and centroid computations... suggesting a potential loss of information when averaging the token embeddings or fragmentation of coordinates during tokenization."
  - [corpus] No direct corpus evidence; neighbor papers focus on general LLM effectiveness but not specifically on numeric regression failures.
- Break condition: If alternative aggregation methods (e.g., max-pooling, attention-weighted sum) or coordinate preprocessing preserve magnitude; or if fine-tuning embeddings on numeric tasks improves performance.

## Foundational Learning

- Concept: Geometry encoding in GIS
  - Why needed here: Understanding WKT format and how GIS represents geometries is essential for preprocessing data and interpreting embedding results.
  - Quick check question: What is the WKT representation of a polygon with vertices (0,0), (1,0), (1,1), (0,1)?

- Concept: Spatial relations and predicates
  - Why needed here: The evaluation tasks rely on understanding DE-9IM, OGC predicates, and how spatial predicates map to geometry pairs.
  - Quick check question: Which predicate describes a geometry completely inside another geometry?

- Concept: Tokenization and embeddings
  - Why needed here: Knowing how LLMs tokenize text and generate embeddings is crucial for interpreting why numeric values are lost and why geometry types are preserved.
  - Quick check question: Why does averaging token embeddings risk losing coordinate magnitude information?

## Architecture Onboarding

- Component map: GeoPandas data extraction -> GPT-2/BERT encoding -> MLP classifier/regressor -> Evaluation metrics
- Critical path:
  1. Load and preprocess geospatial data → extract WKT → compute ground-truth attributes
  2. Encode WKT with LLM → aggregate embeddings (average)
  3. Train MLP on downstream tasks → evaluate performance
- Design tradeoffs:
  - Using simple MLP vs. more complex architectures (less flexibility but easier to isolate LLM embedding effectiveness)
  - Averaging embeddings vs. other aggregation (simplicity vs. preserving information)
  - Concatenation vs. interaction layers for predicate prediction (model capacity vs. training complexity)
- Failure signatures:
  - Perfect geometry type accuracy but poor numeric regression → tokenization preserves keywords but loses magnitude
  - Predicate accuracy improves with geometry type → embeddings encode geometry type implicitly but not explicitly
  - Poor retrieval precision → embeddings encode relations but not fine-grained spatial context
- First 3 experiments:
  1. Verify geometry type preservation by encoding random WKT strings and checking if geometry type tokens are preserved in embeddings.
  2. Test numeric regression with alternative aggregation (max-pooling, attention-weighted sum) to see if magnitude loss is due to averaging.
  3. Evaluate predicate prediction without geometry type to quantify implicit geometry type encoding in embeddings.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we improve the accuracy of numeric estimations (area, distance) from LLM embeddings of geometries?
- Basis in paper: [explicit] The paper explicitly states that "challenges remain in estimating numeric values and retrieving spatially related objects due to the loss of magnitude during tokenization" and shows poor performance in area computation (MAPE 41.9-44.1% for polygons) and distance measurement tasks.
- Why unresolved: The averaging approach for token embeddings loses important geometric information, and simply modifying notation or using chain-of-thought prompting may not be sufficient to capture the full complexity of geospatial data.
- What evidence would resolve it: Development and evaluation of new encoding methods that preserve magnitude information, such as attention mechanisms that weigh different parts of the geometry text differently, or hybrid approaches that combine LLM embeddings with traditional geometric calculations.

### Open Question 2
- Question: Can LLM embeddings be enhanced to support direct geometric manipulations and spatial reasoning without requiring additional classifiers/regressors?
- Basis in paper: [explicit] The paper shows that "even though the LLMs can encode the spatial relations and geometries in a consistent way, generating embeddings using an average approach alone is insufficient to support spatial reasoning and conduct geometric manipulations directly."
- Why unresolved: Current LLM architectures and tokenization methods are designed for natural language understanding rather than geometric computation, creating a fundamental mismatch between the input format and the required output operations.
- What evidence would resolve it: Demonstration of a modified LLM architecture or fine-tuning approach that can directly perform spatial operations (e.g., determining if one polygon contains another, computing intersections) using only the embeddings without additional machine learning layers.

### Open Question 3
- Question: What is the optimal way to represent complex geometries in text format for LLM processing while preserving all necessary spatial information?
- Basis in paper: [inferred] The paper uses WKT format with a sliding window approach due to token length limitations, but notes that "the centroids computed from the high-dimensional embeddings often fall outside the study area," suggesting information loss during encoding.
- Why unresolved: The WKT format, while standardized, may not be optimal for LLM processing as it requires linearizing inherently multidimensional data, and the sliding window approach fragments spatial relationships.
- What evidence would resolve it: Comparative evaluation of alternative text representations (such as coordinate sequences, normalized coordinates, or symbolic representations) against downstream task performance to identify the most effective encoding strategy for different types of geometries and spatial operations.

## Limitations
- The averaging approach for token embeddings systematically destroys magnitude information needed for numeric tasks
- The study uses a specific geographic dataset (Madison, WI) which may limit generalizability
- Simple MLP architectures may underrepresent the true potential of LLM embeddings for complex spatial reasoning

## Confidence

- Geometry type preservation: High confidence
- Spatial predicate prediction: Medium confidence
- Numeric value estimation: Low confidence

## Next Checks

1. **Tokenization analysis**: Extract and analyze the exact token sequences generated by GPT-2 and BERT for diverse WKT geometries, particularly focusing on how numeric coordinates and geometry type keywords are tokenized. Verify that geometry type tokens are consistently separated from coordinate tokens and that numeric tokens preserve their magnitude information.

2. **Alternative aggregation methods**: Re-run the numeric regression tasks (area, distance, centroid) using alternative embedding aggregation methods: max-pooling, attention-weighted sum, and concatenation with coordinate position embeddings. Compare performance to determine if averaging is the primary cause of magnitude loss.

3. **Cross-dataset generalization**: Evaluate the same LLM embeddings on geometry datasets from different geographic regions (different cities, countries, or synthetic distributions) to determine if the 73% accuracy ceiling is dataset-specific or reflects general LLM limitations in spatial reasoning.