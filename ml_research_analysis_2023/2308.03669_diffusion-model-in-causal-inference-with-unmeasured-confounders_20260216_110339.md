---
ver: rpa2
title: Diffusion Model in Causal Inference with Unmeasured Confounders
arxiv_id: '2308.03669'
source_url: https://arxiv.org/abs/2308.03669
tags:
- nodes
- causal
- where
- node
- bdcm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper extends the Diffusion-based Causal Model (DCM) to handle
  unmeasured confounders by introducing Backdoor Criterion-based DCM (BDCM). The core
  idea is to include variables that satisfy the backdoor criterion in the diffusion
  model's decoding process, allowing the model to account for unobserved confounders.
---

# Diffusion Model in Causal Inference with Unmeasured Confounders

## Quick Facts
- **arXiv ID**: 2308.03669
- **Source URL**: https://arxiv.org/abs/2308.03669
- **Reference count**: 0
- **Key outcome**: Backdoor Criterion-based Diffusion Causal Model (BDCM) achieves lower Maximum Mean Discrepancy (MMD) scores than standard DCM when handling unmeasured confounders, demonstrating more accurate counterfactual distribution estimation.

## Executive Summary
This paper extends the Diffusion-based Causal Model (DCM) to handle unmeasured confounders by introducing Backdoor Criterion-based DCM (BDCM). The key innovation is incorporating variables that satisfy the backdoor criterion into the diffusion model's decoding process, allowing the model to account for unobserved confounding effects. The approach is validated on synthetic experiments with two causal models, showing that BDCM produces more accurate counterfactual distributions than DCM, as measured by lower MMD scores. This work addresses a critical limitation of existing diffusion-based causal inference methods that assume causal sufficiency.

## Method Summary
The paper proposes BDCM, which extends DCM by replacing parent node conditioning with backdoor criterion variable conditioning in the diffusion model's decoder. For each node in the causal graph, the method identifies variables that satisfy the backdoor criterion (blocking all paths from cause to outcome) and uses these variables as conditioning inputs during the denoising process. The approach involves: (1) generating synthetic data from structural causal models with unobserved confounders, (2) training denoising diffusion models conditioned on backdoor variables rather than parent nodes, and (3) sampling from the target counterfactual distribution to evaluate performance using Maximum Mean Discrepancy (MMD) against ground truth distributions.

## Key Results
- BDCM achieves lower MMD scores (e.g., 1.24 ± 0.744) compared to DCM (e.g., 1.79 ± 1.54) in experiments with unmeasured confounders
- The method produces more accurate counterfactual distributions by incorporating backdoor criterion variables in the diffusion decoding process
- BDCM successfully handles causal inference tasks where DCM fails due to unmeasured confounding

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Including backdoor variables in the diffusion decoder compensates for unmeasured confounders
- Mechanism: The diffusion model learns to generate samples conditioned on backdoor variables that block paths from cause to outcome, effectively adjusting for unobserved confounding effects
- Core assumption: The selected backdoor variables satisfy the backdoor criterion and block all backdoor paths between cause and outcome
- Evidence anchors:
  - [abstract] "BDCM, whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders"
  - [section] "we include the nodes which meet the backdoor criterion XBi and the corresponding exogenous nodes Zi and also include the intervened node Xj if it is the child of the intervened node"
  - [corpus] Weak - no direct evidence in corpus about backdoor criterion application in diffusion models
- Break condition: If no valid backdoor variables exist or if the backdoor criterion is incorrectly identified, the model cannot compensate for unmeasured confounding

### Mechanism 2
- Claim: DCM's causal sufficiency assumption is relaxed through backdoor variable inclusion
- Mechanism: By replacing parent node conditioning with backdoor variable conditioning, the model can handle cases where direct parents of the outcome are unobserved but sufficient adjustment variables exist
- Core assumption: The data-generating process satisfies the backdoor criterion with observed variables
- Evidence anchors:
  - [abstract] "To overcome the limitation of DCM, we extend it and propose a new algorithm to be able to estimate the ATE even under the existence of the unmeasured confounders by including the nodes that satisfy the backdoor criterion"
  - [section] "As the parent nodes of the outcome node always satisfy the backdoor criterion under Assumption 6, including the nodes that meet the backdoor criterion instead of the parent nodes in the decoder of BDCM is the generalized algorithm of DCM"
  - [corpus] Moderate - corpus contains related work on proxy variables for unmeasured confounders but not specifically on backdoor criterion in diffusion models
- Break condition: When the causal structure prevents satisfying the backdoor criterion with observed variables, the method fails

### Mechanism 3
- Claim: The diffusion model can learn the noise schedule conditioned on backdoor variables
- Mechanism: The neural network ϵθ learns to predict the noise level at each timestep based on backdoor variables, allowing proper denoising even when parent nodes are unobserved
- Core assumption: The neural network architecture can effectively capture the relationship between backdoor variables and the target distribution
- Evidence anchors:
  - [abstract] "we can sample from the target distribution ν(Xj | do(Xi = xi)) more accurately than existing state-of-the-art algorithms under the following causal sufficiency"
  - [section] "we also construct the neural network that captures how much noise ϵ we should add according to the time t and the already sampled values of the parent nodes bXPai"
  - [corpus] Weak - corpus lacks evidence about diffusion models conditioned on backdoor variables specifically
- Break condition: If the neural network cannot learn the complex mapping from backdoor variables to the target distribution, performance degrades

## Foundational Learning

- Concept: Directed Acyclic Graphs (DAGs) and causal relationships
  - Why needed here: The entire approach relies on understanding causal structure and identifying valid adjustment sets
  - Quick check question: Can you identify all backdoor paths between two nodes in a given DAG?
- Concept: Do-calculus and causal intervention
  - Why needed here: The target distribution ν(Xj | do(Xi = xi)) requires understanding of causal interventions
  - Quick check question: How does the do-operator differ from conditioning in probability?
- Concept: Diffusion models and denoising processes
  - Why needed here: The core algorithm uses diffusion models for sampling from target distributions
  - Quick check question: What is the relationship between the forward and reverse diffusion processes?

## Architecture Onboarding

- Component map: DAG structure identification -> Backdoor criterion evaluation -> Diffusion model training with backdoor conditioning -> Sampling procedure -> Evaluation metrics (MMD)
- Critical path: DAG → Backdoor identification → Neural network training → Sampling → Evaluation
- Design tradeoffs: Between computational cost of finding backdoor variables and accuracy gains; between model complexity and generalization ability
- Failure signatures: High MMD scores indicating poor approximation of target distribution; failure to identify valid backdoor variables; neural network training instability
- First 3 experiments:
  1. Implement DCM on a simple SCM with no unmeasured confounders to establish baseline performance
  2. Add a single unmeasured confounder and verify DCM performance degrades as expected
  3. Implement BDCM with backdoor variable inclusion and compare MMD scores against DCM baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the convergence guarantee of BDCM be formally derived?
- Basis in paper: [inferred] from "one of the intriguing topics would be to derive the convergence guarantee of BDCM"
- Why unresolved: The authors mention it as future work without providing theoretical analysis or proof
- What evidence would resolve it: Mathematical proof showing convergence properties of BDCM under various conditions, including different DAG structures and sample sizes

### Open Question 2
- Question: How does BDCM perform on real-world datasets with unmeasured confounders compared to synthetic data?
- Basis in paper: [inferred] from "Implementing the comprehensive algorithm of BDCM in Python would also be interesting"
- Why unresolved: The paper only demonstrates performance on synthetic data with controlled settings
- What evidence would resolve it: Empirical evaluation on real-world datasets with known causal structures, comparing BDCM to existing methods

### Open Question 3
- Question: Can BDCM be generalized using the Front-door criterion for cases where backdoor criterion is insufficient?
- Basis in paper: [explicit] from "it would be intriguing to generalize BDCM using the Front-door criterion"
- Why unresolved: The authors propose this as future work without implementing or testing it
- What evidence would resolve it: Development and evaluation of a Front-door criterion-based extension of BDCM, showing its effectiveness in cases where backdoor criterion cannot be applied

## Limitations

- The approach fundamentally depends on the existence of valid backdoor criterion variables, which may not always be available in real-world causal structures
- The method's effectiveness is constrained by the assumption that observed variables can fully block all backdoor paths between cause and outcome
- The paper only evaluates on synthetic data with known DAG structures, limiting generalizability to scenarios with unknown or partially known causal relationships

## Confidence

- **High Confidence**: The theoretical foundation of using backdoor criterion for causal adjustment is well-established in the causal inference literature
- **Medium Confidence**: The integration of backdoor criterion with diffusion models represents a novel approach, but empirical validation is limited to synthetic experiments
- **Low Confidence**: The scalability of the method to high-dimensional causal graphs and its robustness to incorrect backdoor criterion identification remain unclear

## Next Checks

1. Test BDCM on real-world datasets with known causal structures to assess practical applicability beyond synthetic scenarios
2. Evaluate the method's performance when backdoor criterion variables are imperfectly identified or when multiple valid adjustment sets exist
3. Analyze computational complexity scaling with DAG size and number of backdoor variables to determine practical limitations