---
ver: rpa2
title: DADO -- Low-Cost Query Strategies for Deep Active Design Optimization
arxiv_id: '2307.04536'
source_url: https://arxiv.org/abs/2307.04536
tags:
- design
- candidates
- selection
- size
- strategies
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work applies deep active learning to design optimization to
  reduce the number of computationally expensive numerical simulations. The authors
  present two selection strategies, L2-Select and L2-Reject, for self-optimization
  to reduce the computational cost in multi-objective design optimization problems.
---

# DADO -- Low-Cost Query Strategies for Deep Active Design Optimization

## Quick Facts
- arXiv ID: 2307.04536
- Source URL: https://arxiv.org/abs/2307.04536
- Reference count: 20
- Primary result: Deep active learning selection strategies (L2-Select and L2-Reject) significantly reduce expensive simulations in multi-objective design optimization while maintaining solution quality.

## Executive Summary
This paper introduces DADO (Deep Active Design Optimization), a method that applies deep active learning to reduce computationally expensive numerical simulations in design optimization. The authors propose two selection strategies, L2-Select and L2-Reject, which use L2-norms of predicted objective values to identify promising design candidates. These model-agnostic strategies offer significant improvements over random sampling without requiring uncertainty estimation. Evaluated on a large fluid dynamics dataset, the methods demonstrate effectiveness in accelerating design optimization while introducing new evaluation metrics better suited for ranking-based assessment.

## Method Summary
DADO employs a meta-model (MLP) to predict design performance and iteratively selects candidates for expensive simulation using L2-based strategies. Starting with a small annotated dataset, the system trains the meta-model and uses L2-Select (choosing candidates with smallest L2-norm) or L2-Reject (rejecting candidates with largest L2-norm) to identify the most promising designs for simulation. The process iterates, updating the training set with new annotations. The method prioritizes ranking accuracy over precise value prediction, introducing metrics like SROCC, mean rank, and intersection to evaluate performance.

## Key Results
- L2-Select and L2-Reject strategies provide significant improvements over random sampling in multi-objective design optimization
- New evaluation metrics (SROCC, mean rank, intersection) better capture the effectiveness of selection strategies than traditional MSE
- The process develops increasing self-awareness over iterations, improving its ability to select optimal design candidates
- Method is easily transferable to other self-optimization problems and circumvents the need for uncertainty estimation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: L2-norm based selection strategies reduce computational cost by focusing training on promising design candidates
- Mechanism: Both strategies compute the L2-norm of predicted objective values for candidate designs. L2-Select selects candidates with smallest norm, while L2-Reject rejects candidates with largest norm, biasing training toward regions likely containing optimal solutions
- Core assumption: L2-norm effectively captures proximity to optimal solutions in multi-objective design space
- Evidence anchors: Abstract states strategies "offer significant improvements over random sampling" and are "model-agnostic"; section describes L2-Select and L2-Reject as "simple but efficient selection strategies"
- Break condition: L2-norm assumption fails if optimal solution region doesn't correspond to small L2-norm values in target space

### Mechanism 2
- Claim: Deep active learning reduces expensive simulations by iteratively selecting informative design candidates
- Mechanism: System starts with small annotated designs, trains meta-model to predict performance, and uses selection strategies to choose which candidates to simulate next, reducing total simulations needed
- Core assumption: Meta-model's predictions can effectively identify promising candidates with fewer simulations than random selection
- Evidence anchors: Abstract states method "reduce[s] the number of computationally expensive numerical simulations"; section describes objective to "maximize performance with as few requests to the expert model as possible"
- Break condition: Meta-model's predictions become too inaccurate to identify promising candidates, requiring more random exploration

### Mechanism 3
- Claim: Introduced metrics (SROCC, MR, Intersection) better evaluate DADO performance than traditional MSE
- Mechanism: These metrics assess how well model ranks promising candidates rather than predicting exact values. SROCC measures correlation between predicted and true rankings, MR measures average rank of selected candidates, and Intersection measures overlap between selected and truly optimal candidates
- Core assumption: For design optimization, correct ranking of candidates is more important than precise value prediction
- Evidence anchors: Section states "We prioritize SROCC, MR, and intersections metrics over classic MSE for DADO, as accurate ranking of designs is more crucial than precise estimations of target values"
- Break condition: If precise value prediction becomes necessary for downstream optimization tasks

## Foundational Learning

- Concept: Active Learning
  - Why needed here: DADO relies on iteratively selecting most informative samples for annotation, which is core principle of active learning applied to design optimization
  - Quick check question: How does active learning differ from passive learning in terms of sample selection strategy?

- Concept: Multi-objective Optimization
  - Why needed here: Paper optimizes for both pressure loss and cooling capacity simultaneously, requiring understanding of Pareto optimality and trade-offs
  - Quick check question: What is the difference between a Pareto optimal solution and a single-objective optimal solution?

- Concept: Deep Neural Networks for Regression
  - Why needed here: Meta-model uses MLP to predict continuous objective values from design parameters, requiring understanding of regression architectures and loss functions
  - Quick check question: Why might dropout layers be beneficial in the meta-model architecture?

## Architecture Onboarding

- Component map: Expert Model (oracle simulation) -> Meta Model (MLP predictor) -> Selector (L2-Select/L2-Reject) -> Data Pool (candidate designs) -> Training Loop (iterative update)
- Critical path: Data Pool → Meta Model → Selector → Expert Model → Updated Training Set → Meta Model
- Design tradeoffs: Simple L2-norm selection vs. more complex uncertainty-based methods; model-agnostic selection vs. model-specific approaches
- Failure signatures: Random selection outperforming proposed strategies in MSE; high reconstruction error in VAE extension; poor convergence in early iterations
- First 3 experiments:
  1. Compare L2-Select vs. random selection on small synthetic dataset to verify ranking improvement
  2. Test L2-Reject on dataset where optimal solutions cluster at distribution edges
  3. Evaluate all three metrics (SROCC, MR, Intersection) on same experiment to understand relationships

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop selection strategies for DADO that are more robust to differently scaled target values?
- Basis in paper: [explicit] Authors suggest replacing circular selection with ellipsoid to improve robustness to differently scaled target values
- Why unresolved: Paper does not provide concrete method or experimental results for ellipsoid-based selection strategy
- What evidence would resolve it: Experimental results comparing current L2-norm based strategies with ellipsoid-based selection on datasets with differently scaled target values

### Open Question 2
- Question: How can we extend proposed selection strategies to handle higher-dimensional multi-objective optimization problems?
- Basis in paper: [explicit] Authors state extension to higher dimensional multi-objective optimization should be straightforward
- Why unresolved: Paper provides no details on extension or experimental results validating effectiveness
- What evidence would resolve it: Experimental results demonstrating performance of extended strategies on problems with more than two objectives

### Open Question 3
- Question: How can we achieve good balance between reconstruction and disentanglement in latent space when incorporating generative model into DADO process?
- Basis in paper: [explicit] Authors mention challenges achieving suitable trade-off between well-separable latent space and reconstruction error when incorporating VAE
- Why unresolved: Paper does not provide concrete solution or experimental results addressing trade-off
- What evidence would resolve it: Experimental results demonstrating performance with VAE achieving good balance between reconstruction and disentanglement

## Limitations

- Effectiveness depends on assumption that optimal designs cluster where predicted objectives have small L2-norms, which may not hold for all design spaces
- Dataset represents specific fluid dynamics domain; transferability to other engineering problems requires further validation
- Paper does not address computational complexity of selection strategies relative to uncertainty-based methods

## Confidence

- High confidence: Core mechanism of using L2-norm for candidate selection and overall active learning framework (95)
- Medium confidence: Effectiveness of L2-Select and L2-Reject compared to random sampling (85), superiority of proposed metrics over MSE (80)
- Low confidence: Transferability to other design optimization domains (60), scalability to higher-dimensional design spaces (65)

## Next Checks

1. **Domain Transferability Test**: Apply L2-Select and L2-Reject to different design optimization problem (e.g., structural optimization or chemical process design) with distinct characteristics from fluid dynamics to validate generalizability

2. **Convergence Analysis**: Track distribution of selected candidates throughout optimization process to verify strategies maintain effectiveness as search approaches optimal regions and identify potential saturation points

3. **Uncertainty Comparison**: Implement baseline uncertainty-based selection strategy (e.g., BALD or variation ratios) on same dataset and compare both computational cost and optimization performance to establish practical advantages of L2-norm approach