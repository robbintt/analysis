---
ver: rpa2
title: 'Think Before You Duel: Understanding Complexities of Preference Learning under
  Constrained Resources'
arxiv_id: '2312.17229'
source_url: https://arxiv.org/abs/2312.17229
tags:
- uni00000013
- preference
- dueling
- regret
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles constrained dueling bandits, where an agent
  must maximize cumulative reward while respecting budget constraints on resource
  consumption. Unlike standard bandits, the agent observes only relative feedback
  between pairs of arms, making the problem harder.
---

# Think Before You Duel: Understanding Complexities of Preference Learning under Constrained Resources

## Quick Facts
- arXiv ID: 2312.17229
- Source URL: https://arxiv.org/abs/2312.17229
- Reference count: 40
- Key outcome: Proposes EXP3-based algorithm achieving regret of Õ(OPT(b)/B · K^(1/3) · T^(2/3)) for constrained dueling bandits under sufficient budget assumptions

## Executive Summary
This paper addresses the constrained dueling bandit problem where an agent must maximize cumulative reward while respecting budget constraints on resource consumption. Unlike standard bandits, the agent observes only relative feedback between pairs of arms, making the problem harder. The authors show that without assumptions, regret is Ω(T), but under sufficient budget assumptions, they propose an EXP3-based algorithm that incorporates consumption constraints through dual optimization. The method uses dual optimization to balance reward and resource usage, achieving sub-linear regret bounds. Empirical results on synthetic and real-world car preference data demonstrate superior performance compared to unconstrained dueling bandit baselines, especially when high-reward arms also have high resource costs.

## Method Summary
The paper proposes a constrained dueling bandit algorithm based on the EXP3 framework that incorporates resource consumption through dual optimization. The algorithm maintains separate distributions for sampling arms and uses shifted Borda scores as unbiased estimators of true Borda scores. It solves a constrained optimization problem via the Lagrangian formulation, balancing reward maximization against resource constraints. The algorithm updates arm distributions using exponential weights on estimated cumulative Lagrangian values. Under sufficient budget assumptions (B = O(max{K/ϵ²min, T³/⁴})), the method achieves regret of Õ(OPT(b)/B · K^(1/3) · T^(2/3)).

## Key Results
- Proves Ω(T) regret lower bound for constrained dueling bandits without additional assumptions
- Achieves Õ(OPT(b)/B · K^(1/3) · T^(2/3)) regret bound under sufficient budget assumptions
- Outperforms unconstrained dueling bandit baselines (D-EXP3 and D-TS) in synthetic and real-world car preference experiments
- Demonstrates superior performance when high-reward arms have high resource costs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The algorithm maintains dual distributions for each arm choice to separately track consumption and reward optimization.
- Mechanism: By maintaining separate distributions qx and qy, the algorithm can estimate the shifted Borda scores and consumption vectors for each arm independently, allowing it to trade off reward maximization against resource constraints via the Lagrangian formulation.
- Core assumption: The consumption vectors are independent of the preference feedback, and the shifted Borda score is an unbiased estimator of the true Borda score.
- Evidence anchors:
  - [abstract] "The method uses dual optimization to balance reward and resource usage"
  - [section] "we maintain two distributions qx t and qy t to sample the arms xt and yt at time t"
- Break condition: If the consumption vectors are correlated with the preference feedback, the unbiased estimation assumption fails, and the algorithm's regret bounds no longer hold.

### Mechanism 2
- Claim: The algorithm uses exponential weighting on the estimated cumulative Lagrangian values to update the arm distributions.
- Mechanism: The algorithm computes unbiased estimates of the shifted Borda scores and consumption vectors, then uses these to update the arm distributions via exponential weights on the estimated cumulative Lagrangian values, balancing reward and consumption.
- Core assumption: The estimates of the shifted Borda scores and consumption vectors are unbiased, and the exponential weights update converges to the optimal solution.
- Evidence anchors:
  - [abstract] "EXP3 based dueling algorithm that also considers the associated consumptions"
  - [section] "Next we update the arm distributions qx t and qy t using exponential weights on the estimated cumulative lagrangians"
- Break condition: If the estimates of the shifted Borda scores or consumption vectors are biased, the exponential weights update may converge to a suboptimal solution, and the algorithm's regret bounds no longer hold.

### Mechanism 3
- Claim: The algorithm uses a shifted Borda score to make the optimization problem more tractable.
- Mechanism: The algorithm replaces the original Borda score with a shifted Borda score, which is an unbiased estimator of the true Borda score. This allows the algorithm to optimize the shifted Borda score instead of the original Borda score, making the optimization problem more tractable.
- Core assumption: The shifted Borda score is an unbiased estimator of the true Borda score, and the optimal solution to the optimization problem with the shifted Borda score is close to the optimal solution to the original problem.
- Evidence anchors:
  - [abstract] "We replace the Borda score b(x) in (LP − Borda) by the shifted Borda score ˜b(x)"
  - [section] "We replace the Borda score b(x) in (LP − Borda) by the shifted Borda score ˜b(x)"
- Break condition: If the shifted Borda score is not an unbiased estimator of the true Borda score, or if the optimal solution to the optimization problem with the shifted Borda score is far from the optimal solution to the original problem, the algorithm's regret bounds no longer hold.

## Foundational Learning

- Concept: Lagrangian duality
  - Why needed here: The algorithm uses Lagrangian duality to balance the reward maximization objective with the resource consumption constraints.
  - Quick check question: What is the relationship between the primal and dual optimization problems in Lagrangian duality?

- Concept: EXP3 algorithm
  - Why needed here: The algorithm is based on the EXP3 algorithm, which is a well-known algorithm for solving multi-armed bandit problems.
  - Quick check question: What is the key idea behind the EXP3 algorithm, and how does it differ from other multi-armed bandit algorithms?

- Concept: Regret analysis
  - Why needed here: The algorithm's performance is analyzed in terms of regret, which measures the difference between the cumulative reward of the algorithm and the optimal policy.
  - Quick check question: What is the definition of regret in the context of multi-armed bandit problems, and how is it typically analyzed?

## Architecture Onboarding

- Component map: Sampling component -> Estimation component -> Update component -> Sampling component (cyclic)
- Critical path: At each time step: sample arms from qx and qy -> observe preference feedback and consumption vectors -> estimate shifted Borda scores and consumption vectors -> update arm distributions using exponential weights on cumulative Lagrangian values
- Design tradeoffs: The algorithm trades off exploration and exploitation by using exponential weights on the estimated cumulative Lagrangian values. The algorithm also trades off the accuracy of the estimates against the computational complexity of the algorithm.
- Failure signatures: The algorithm may fail if the estimates of the shifted Borda scores or consumption vectors are biased, or if the exponential weights update converges to a suboptimal solution. The algorithm may also fail if the resource constraints are too tight, making it impossible to find a feasible solution.
- First 3 experiments:
  1. Run the algorithm on a synthetic dataset with K=6 arms and the specified preference matrix, Borda scores, and consumption vectors for the three test cases
  2. Run the algorithm on a synthetic dataset with a larger number of arms and a more complex preference matrix, and compare the algorithm's performance to a baseline algorithm that does not consider resource constraints
  3. Run the algorithm on a real-world dataset, such as the car preference dataset, and compare the algorithm's performance to a baseline algorithm that does not consider resource constraints

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the Ω(T) lower bound be improved for the Condorcet Constrained-DB problem under additional assumptions on the preference matrix structure?
- Basis in paper: [explicit] The paper shows that the Ω(T) regret bound exists even when P satisfies total ordering (TO) but not when P satisfies strong stochastic transitivity (SST), suggesting potential improvements under specific structural assumptions.
- Why unresolved: The authors demonstrate that without further assumptions, the Ω(T) regret is unavoidable. However, they do not explore whether additional structural properties beyond SST could further reduce this lower bound.
- What evidence would resolve it: Constructing new lower bound examples that exploit or circumvent different structural properties of preference matrices beyond TO and SST, or proving tighter bounds under new assumptions.

### Open Question 2
- Question: How does the performance of Constrained D-EXP3 compare to a constrained version of Dueling Thompson Sampling (D-TS)?
- Basis in paper: [explicit] The experimental section notes that D-TS outperforms both Constrained D-EXP3 and D-EXP3 in the unconstrained case, suggesting potential benefits of developing a constrained D-TS algorithm.
- Why unresolved: The authors only compare their algorithm against D-EXP3 and do not implement or test a constrained version of D-TS, leaving a gap in understanding the relative performance of different approaches under constraints.
- What evidence would resolve it: Implementing and evaluating a constrained version of D-TS against Constrained D-EXP3 on the same datasets, comparing cumulative rewards and resource utilization.

### Open Question 3
- Question: Can the regret bound for the Borda Constrained-DB problem be improved under assumptions on the available budget B?
- Basis in paper: [explicit] The paper assumes B = O(max{K/ϵ²min, T³/⁴}) to achieve sub-linear regret, but does not explore whether tighter bounds are possible under stronger budget assumptions.
- Why unresolved: While the authors establish a regret bound under certain budget conditions, they do not investigate the full spectrum of possible budget constraints or whether the dependence on B in the regret bound can be reduced.
- What evidence would resolve it: Deriving tighter regret bounds by exploring different budget regimes (e.g., B = o(T) vs. B = Ω(T)) and analyzing how the regret scales with B under these conditions.

## Limitations

- The algorithm's performance critically depends on the assumption that consumption vectors are independent of preference feedback, which may not hold in real-world scenarios where high-reward options often consume more resources.
- The regret bound's dependence on K^(1/3) suggests the algorithm scales poorly with the number of arms, limiting its applicability to large-scale problems.
- The paper assumes known consumption vectors and budget constraints, but in practice these may be uncertain or need to be learned online.

## Confidence

- **High confidence**: The core mechanism of using dual optimization with EXP3 framework is well-established and correctly implemented. The shifted Borda score approach for making the optimization tractable is sound.
- **Medium confidence**: The regret bound derivation relies on specific assumptions about the problem structure that may not generalize well. The empirical results show promising performance but are limited to synthetic and one real-world dataset.
- **Low confidence**: The algorithm's behavior under tight budget constraints and its scalability to large action spaces remain unclear from the current analysis.

## Next Checks

1. Test algorithm sensitivity to correlation between consumption vectors and preference feedback by introducing controlled dependencies in synthetic data
2. Evaluate performance on larger-scale problems (K > 20 arms) to assess scalability and verify the K^(1/3) dependence in practice
3. Implement and compare against an online learning variant that estimates consumption vectors rather than assuming they are known