---
ver: rpa2
title: 'PBES: PCA Based Exemplar Sampling Algorithm for Continual Learning'
arxiv_id: '2312.09352'
source_url: https://arxiv.org/abs/2312.09352
tags:
- data
- class
- learning
- number
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a PCA-based exemplar sampling algorithm (PBES)
  for continual learning. The main idea is to select exemplars that best represent
  the data distribution using PCA and median sampling, which is more robust to outliers
  compared to existing methods like herding.
---

# PBES: PCA Based Exemplar Sampling Algorithm for Continual Learning

## Quick Facts
- arXiv ID: 2312.09352
- Source URL: https://arxiv.org/abs/2312.09352
- Reference count: 24
- Primary result: PCA-based exemplar sampling algorithm (PBES) outperforms state-of-the-art methods in class-incremental learning with improved robustness to outliers

## Executive Summary
This paper introduces PBES, a PCA-based exemplar sampling algorithm for class-incremental learning that addresses the challenge of selecting representative exemplars while being robust to outliers. The method combines PCA-based median sampling with KeepAugment for data augmentation to handle class imbalance. Experimental results on Sports100, Tiny ImageNet, and CIFAR100 datasets demonstrate superior performance compared to methods like Rainbow Memory, GDUMB, and iCaRL in terms of F1 score, geometric mean, and accuracy.

## Method Summary
The method uses PCA-based median sampling (PBES) to select exemplars that are robust to outliers by projecting data onto principal components and selecting median points along these directions. KeepAugment is integrated to balance class distributions by generating synthetic samples for underrepresented classes. The training combines cross-entropy loss for the balanced data stream with knowledge distillation loss for preserving old knowledge from exemplar memory. The algorithm operates in a class-incremental learning setting where new classes arrive sequentially.

## Key Results
- PBES achieves better F1 score, geometric mean, and accuracy than Rainbow Memory, GDUMB, and iCaRL on Sports100, Tiny ImageNet, and CIFAR100
- The combined loss function (cross-entropy + knowledge distillation) effectively mitigates catastrophic forgetting
- KeepAugment successfully balances class distributions in imbalanced datasets
- Ablation studies confirm the effectiveness of each component

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PCA-based median sampling selects exemplars robust to outliers and better representing data distribution
- Mechanism: Projects data onto principal components (maximum variance directions), then selects median points along these directions, ensuring extreme outliers don't dominate selection
- Core assumption: Principal components capture most important data variation, and medians along these directions yield representative, outlier-resistant subsets
- Evidence anchors: [abstract] "This approach avoids the pitfalls due to outliers in the data"; [section] "We propose a novel sampling algorithm that performs better than state-of-the-art methods in CL"
- Break condition: If data distribution is heavily skewed or principal components don't align with relevant data structure

### Mechanism 2
- Claim: KeepAugment creates balanced training sets from imbalanced datasets, improving model performance on rare classes
- Mechanism: Identifies most frequent class, generates synthetic samples for underrepresented classes using selective cut augmentation to balance class distribution
- Core assumption: Augmentation method preserves class-specific information without introducing significant artifacts
- Evidence anchors: [section] "The KeepAugment [9] algorithm is used to supplement each new incoming class, creating a balanced data stream"
- Break condition: If augmentation generates samples too dissimilar from original class distribution

### Mechanism 3
- Claim: Combined loss function (cross-entropy + knowledge distillation) mitigates catastrophic forgetting while learning new classes
- Mechanism: Cross-entropy applied to balanced data stream, distillation loss applied to exemplars from previous tasks, ensuring model learns new classes without forgetting old ones
- Core assumption: Teacher model outputs for old classes remain reliable targets for distillation
- Evidence anchors: [section] "We have that, Di M = Di ∪Ii ∪ DE... Therefore, the cross-entropy loss for training task ti is formulated as..."
- Break condition: If teacher model outputs become unreliable due to significant data distribution drift

## Foundational Learning

- Concept: Principal Component Analysis (PCA)
  - Why needed here: PCA identifies directions of maximum variance for median sampling to select exemplars
  - Quick check question: What is the main purpose of PCA in exemplar selection, and how does it differ from using class means as in herding?

- Concept: Data Augmentation (KeepAugment)
  - Why needed here: KeepAugment balances class distribution within each task by generating synthetic samples for underrepresented classes
  - Quick check question: How does KeepAugment differ from other data augmentation techniques, and why is it particularly suited for handling class imbalance in continual learning?

- Concept: Knowledge Distillation
  - Why needed here: Knowledge distillation preserves model's knowledge of old classes while learning new ones by minimizing difference between teacher and student model outputs
  - Quick check question: In continual learning, why is knowledge distillation important, and how does it complement cross-entropy loss?

## Architecture Onboarding

- Component map:
  Data Augmentation (KeepAugment) -> PCA-based Median Sampling (PBES) -> Neural Network Model (Combined Loss) -> Classifier -> Representative Memory

- Critical path:
  1. For each task, balance class distribution using KeepAugment
  2. Select exemplars using PBES (PCA-based median sampling)
  3. Train model on balanced data stream using combined loss
  4. Store exemplars in representative memory for future tasks

- Design tradeoffs:
  - PBES vs. Herding: PBES is more robust to outliers but may be computationally more expensive
  - KeepAugment vs. Other Augmentations: KeepAugment preserves class-specific information but may introduce artifacts if not carefully tuned
  - Combined Loss vs. Single Loss: Combined loss mitigates catastrophic forgetting but requires careful balancing of components

- Failure signatures:
  - If PBES fails: Model may overfit to outliers or fail to generalize well to new data
  - If KeepAugment fails: Model may struggle with rare classes or overfit to synthetic samples
  - If combined loss fails: Model may experience catastrophic forgetting or fail to learn new classes effectively

- First 3 experiments:
  1. Implement PBES and compare exemplar selection with herding on CIFAR-10
  2. Integrate KeepAugment and evaluate balancing effectiveness on Sports100
  3. Combine PBES, KeepAugment, and dual loss function, evaluate performance on CIFAR-100 with incremental class learning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PBES perform when number of exemplars per class is significantly smaller than total data points in that class?
- Basis in paper: [explicit] Algorithm selects m exemplars from class with n data points, where m ≤ n
- Why unresolved: Paper doesn't provide specific performance metrics for different m/n ratios
- What evidence would resolve it: Experimental results showing performance for various m/n ratios

### Open Question 2
- Question: What is the impact of using different numbers of principal components in PBES on final performance?
- Basis in paper: [explicit] Algorithm uses p principal components, where p is calculated as ⌈m/2⌉ or ⌈m/2⌉ + 1
- Why unresolved: Paper doesn't explore effect of varying principal component numbers on performance
- What evidence would resolve it: Experiments comparing performance with different principal component counts

### Open Question 3
- Question: How does PBES compare to other exemplar selection methods in terms of computational efficiency?
- Basis in paper: [inferred] Paper claims PBES is simple to implement but doesn't provide direct computational comparison
- Why unresolved: Paper doesn't include computational complexity analysis or runtime comparison
- What evidence would resolve it: Detailed computational complexity analysis and comparison with other methods

## Limitations
- Limited reproducibility due to incomplete algorithmic specifications
- Lack of comparison with recent continual learning methods beyond three baselines
- No analysis of computational overhead introduced by PCA-based sampling
- Potential overfitting to specific datasets tested

## Confidence
Medium: The methodology is well-specified but several key implementation details remain unclear. The PBES algorithm's exact computational steps are not fully described, and KeepAugment parameters lack specificity. While ablation studies demonstrate component effectiveness, comparative claims rely heavily on results from a single paper without external validation.

## Next Checks
1. Implement PBES on CIFAR-10 to verify exemplar selection quality against herding baseline
2. Test KeepAugment's balancing effectiveness on an artificially imbalanced subset of CIFAR-100
3. Reproduce the combined loss function training regime and evaluate catastrophic forgetting on a sequential task benchmark