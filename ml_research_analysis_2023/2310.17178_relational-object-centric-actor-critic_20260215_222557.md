---
ver: rpa2
title: Relational Object-Centric Actor-Critic
arxiv_id: '2310.17178'
source_url: https://arxiv.org/abs/2310.17178
tags:
- object
- learning
- object-centric
- objects
- goca
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel object-centric reinforcement learning
  algorithm (GOCA) that combines actor-critic and model-based approaches. The key
  idea is to use a pre-trained object-centric feature extractor (SLATE) and a GNN-based
  world model to predict the next state and reward.
---

# Relational Object-Centric Actor-Critic

## Quick Facts
- **arXiv ID**: 2310.17178
- **Source URL**: https://arxiv.org/abs/2310.17178
- **Reference count**: 8
- **Primary result**: Proposes GOCA, an object-centric RL algorithm combining actor-critic and model-based approaches, outperforming state-of-the-art baselines in 3D robotic and 2D compositional environments.

## Executive Summary
This paper introduces GOCA, a novel object-centric reinforcement learning algorithm that combines actor-critic and model-based approaches. The key innovation is using a pre-trained object-centric feature extractor (SLATE) with a GNN-based world model to predict next states and rewards. The method is evaluated in 3D robotic and 2D environments with compositional structure, showing superior performance compared to state-of-the-art model-free and model-based baselines, particularly in more challenging scenarios with many objects.

## Method Summary
GOCA integrates a pre-trained SLATE object-centric encoder with a GNN-based world model and actor-critic framework. The SLATE model decomposes raw pixel observations into K object slots, which feed into GNN transition, reward, state-value, and actor models. The world model predicts next state and reward, which are used in a Bellman backup to estimate Q-values. The method uses SAC/SACD objectives for training, with the world model and policy learned jointly. GOCA is evaluated on Object Reaching, Navigation, and Pushing tasks in both 3D and 2D environments.

## Key Results
- GOCA outperforms state-of-the-art model-free (OCRL) and model-based (DreamerV3) baselines in Object Reaching and Navigation tasks
- In more challenging scenarios with many objects, GOCA shows significantly better performance than baselines
- Ablation study demonstrates the importance of pre-trained SLATE encoder and object-centric world model for GOCA's performance
- GOCA achieves faster learning or higher metrics than baselines in all tasks except Pushing7x7

## Why This Works (Mechanism)

### Mechanism 1
- Pre-trained SLATE encoder provides object-centric representations that align with environment's compositional structure, improving model-based predictions through its slot-attention and transformer architecture that decomposes raw pixels into permutation-invariant object slots.

### Mechanism 2
- GNN-based transition and reward models leverage relational structure between objects through message-passing over a fully connected graph, explicitly modeling interactions between all object pairs conditioned on actions.

### Mechanism 3
- Integrating GNN world model into critic via Bellman backup enables model-based value estimation without executing policy in real environment, allowing multi-step planning and faster credit assignment.

## Foundational Learning

- **Object-centric representation learning**: Decomposes raw observations into object slots to reduce state space and focus learning on relevant entities. Quick check: What is the difference between monolithic and object-centric encoders in terms of permutation invariance?

- **Graph neural networks for relational reasoning**: Explicitly models pairwise interactions between objects through message-passing. Quick check: How are actions incorporated into both node and edge models in the transition model?

- **Soft Actor-Critic with discrete/continuous action spaces**: Handles both continuous (Object Reaching) and discrete (Navigation) action spaces. Quick check: What is the key difference between discrete SAC policy objective and continuous SAC policy objective?

## Architecture Onboarding

- **Component map**: SLATE encoder → object slots (K dim) → GNN world model (edgeT/nodeT, edgeR/nodeR) → transition ∆z, reward R → GNN state-value model (edgeV/nodeV) → V(zt) → GNN actor model (edgeactor/nodeactor) → π(zt) → Critic: Q(zt, at) = R(zt, at) + γV(zt + ∆z)

- **Critical path**: 1) Pre-train SLATE on random trajectories, 2) Initialize GOCA with SLATE and random GNN weights, 3) Sample real transitions and train world model and SAC/SACD objectives, 4) Use Q from world model for policy updates, 5) Repeat until convergence

- **Design tradeoffs**: Fixed K slots vs. variable objects (simpler but fragile), fully connected GNN vs. sparse graph (captures all interactions but scales poorly), deterministic world model vs. stochastic (easier to train but cannot model uncertainty)

- **Failure signatures**: World model predictions drift over time causing unreliable value estimates, object slots lose semantic meaning causing noisy GNN input, target entropy mis-specification causing exploration problems

- **First 3 experiments**: 1) Train GOCA on Navigation5x5 with K=4 slots and verify SLATE extracts 4 objects, 2) Compare Q-values from real vs. model-based backup on fixed dataset to measure world model accuracy, 3) Run ablation replacing GNN with MLP pooling of SLATE embeddings

## Open Questions the Paper Calls Out

### Open Question 1
- How does GOCA's performance scale with the number of objects beyond tested cases? The paper notes better performance with many objects but doesn't explore scalability limits or performance degradation thresholds.

### Open Question 2
- How sensitive is GOCA's performance to the quality of the pre-trained SLATE model? The paper uses pre-trained SLATE but doesn't explore how variations in feature extractor quality affect GOCA's performance.

### Open Question 3
- How does GOCA compare to other object-centric MBRL algorithms not based on SAC? The paper compares to SAC-based and model-free baselines but doesn't compare to object-centric MBRL algorithms using different RL frameworks like TD3 or PPO.

## Limitations

- The fixed number of object slots (K) may limit scalability to environments with dynamic or unknown numbers of objects
- Exact GNN architectural details and training hyperparameters are underspecified, potentially affecting reproducibility
- The deterministic world model may accumulate errors over long horizons in stochastic environments

## Confidence

- **High Confidence**: Integration of SLATE with GNN-based world models is feasible and outperforms monolithic baselines in structured environments
- **Medium Confidence**: GNN's message-passing structure improves relational reasoning, but exact contribution of pairwise interactions is unclear
- **Low Confidence**: Claims about generalization to highly dynamic environments with unknown numbers of objects are not directly tested

## Next Checks

1. Run diagnostic comparing GNN-predicted Q-values against real Q-values on fixed validation set after each training epoch to track model error accumulation over multi-step rollouts.

2. Test GOCA with varying numbers of SLATE slots (K=4, K=8, K=12) on Object Reaching and Navigation tasks to measure performance sensitivity and visualize slot consistency.

3. Replace GNN-based transition and reward models with simple MLP pooling of SLATE slots to isolate contribution of relational reasoning through comparison of learning curves and final performance.