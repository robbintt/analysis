---
ver: rpa2
title: 'Towards Better Chain-of-Thought Prompting Strategies: A Survey'
arxiv_id: '2310.04959'
source_url: https://arxiv.org/abs/2310.04959
tags:
- reasoning
- prompting
- language
- corr
- wang
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a systematic and comprehensive analysis of
  Chain-of-Thought (CoT) prompting for large language models (LLMs). The paper identifies
  four key factors that significantly impact CoT prompting performance: task types,
  prompts design, extension strategies, and models.'
---

# Towards Better Chain-of-Thought Prompting Strategies: A Survey

## Quick Facts
- arXiv ID: 2310.04959
- Source URL: https://arxiv.org/abs/2310.04959
- Reference count: 28
- One-line primary result: Systematic analysis of four key factors affecting Chain-of-Thought (CoT) prompting performance in large language models

## Executive Summary
This survey provides a comprehensive analysis of Chain-of-Thought (CoT) prompting for large language models (LLMs), identifying four key factors that significantly impact performance: task types, prompts design, extension strategies, and models. The paper offers detailed guidance on effectively utilizing CoT prompting across different applications and discusses current challenges and future research directions. By covering various CoT-related strategies including ensemble methods, sub-problems division, external assistance, and rationalization techniques, this work serves as a valuable reference for researchers and practitioners in natural language processing.

## Method Summary
The survey employs a systematic methodology to analyze 28 referenced papers on Chain-of-Thought prompting, focusing on four key factors: task types (close domain reasoning, open domain reasoning, code generation), prompts design (demonstrations and textual instructions), extension strategies (ensemble, sub-problems division, external assistance, rationalization), and models (size and training corpus). The analysis formalizes the CoT prompting pipeline and provides guidance on how to effectively utilize this technique across different applications, while also identifying current challenges and future research directions.

## Key Results
- Identifies four critical factors affecting CoT prompting performance: task types, prompts design, extension strategies, and models
- Provides detailed guidance on demonstration selection and design for effective CoT prompting
- Discusses ensemble methods, sub-problem division, external assistance, and rationalization as extension strategies
- Highlights current challenges including faithfulness, generality, and lack of theoretical analysis

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Chain-of-Thought prompting works because it transforms complex reasoning into a sequence of simpler, tractable sub-steps that language models can process more reliably.
- Mechanism: The CoT approach breaks down a multi-step reasoning problem into intermediate steps, each involving a smaller cognitive leap. This decomposition aligns with the way humans reason step-by-step, enabling models to access learned knowledge incrementally rather than needing to solve the entire problem in one pass.
- Core assumption: The language model has learned the necessary reasoning patterns during pre-training and can access them when prompted with intermediate steps.
- Evidence anchors:
  - [abstract]: "CoT prompts are special designed input sequences to instruct the model to generate coherent series of intermediate reasoning steps."
  - [section 3]: "This prompt-ting strategy tries to incorporate intermediate steps to guide a progressive reasoning, achieving surprising improvement on many reasoning benchmarks."
  - [corpus]: Weak - corpus does not provide direct evidence for this mechanism, though related work suggests intermediate reasoning helps with task decomposition.
- Break condition: If the model lacks the necessary knowledge or reasoning patterns in its training data, the intermediate steps cannot be generated correctly, leading to chain failure.

### Mechanism 2
- Claim: CoT prompting enhances model performance by providing relevant reasoning context that guides the model's knowledge retrieval and application.
- Mechanism: Demonstrations in CoT prompts serve as examples that provide the model with relevant context, including both bridging objects (critical reasoning elements) and language templates (connecting knowledge). This context helps the model retrieve and apply appropriate knowledge to the current problem.
- Core assumption: The model can effectively match demonstration patterns to the query problem and transfer the demonstrated reasoning process.
- Evidence anchors:
  - [section 5.1.2]: "Bridging objects provide the reasoning materials and lead to logical language templates, while language templates provide the essential knowledge and help to better organize bridging objects."
  - [section 5.1.1]: "Relevant demonstration problems could provide similar knowledge and reasoning pattern for the query, which make LLM easier to imitate."
  - [corpus]: Weak - corpus mentions relevance and diversity but doesn't directly address the knowledge retrieval mechanism.
- Break condition: If demonstrations are too dissimilar or too similar to the query, the model may either fail to find relevant patterns or overfit to specific examples.

### Mechanism 3
- Claim: Ensemble strategies improve CoT performance by integrating diverse reasoning processes and correcting individual errors.
- Mechanism: By generating multiple reasoning chains (either through different prompts or sampling), ensemble methods can combine the strengths of different approaches while mitigating the weaknesses of individual chains. This diversity helps capture different aspects of the problem and reduces the impact of errors in any single reasoning path.
- Core assumption: Different reasoning chains will capture complementary information about the problem, and the ensemble can effectively integrate these perspectives.
- Evidence anchors:
  - [section 6.1]: "Wang et al. (2022e) point out ensemble methods can even bring performance increment on tasks where vanilla CoT fails."
  - [section 6.1]: "This method construct diverse CoT prompts by repeating sampling different demonstrations from exemplars set."
  - [corpus]: Weak - corpus doesn't provide direct evidence for ensemble effectiveness in CoT context.
- Break condition: If all generated chains are similarly flawed or if the ensemble integration method is poorly designed, the ensemble may not provide improvement.

## Foundational Learning

- Concept: Prompt engineering and demonstration design
  - Why needed here: The effectiveness of CoT prompting heavily depends on how demonstrations are selected and presented to the model.
  - Quick check question: What factors should be considered when selecting demonstrations for a CoT prompt?

- Concept: Reasoning task decomposition
  - Why needed here: Understanding how to break down complex problems into simpler sub-problems is crucial for effective CoT prompting.
  - Quick check question: How can you determine whether a problem would benefit from sub-problem division in CoT prompting?

- Concept: Model capability assessment
  - Why needed here: The success of CoT prompting depends on matching the task complexity to the model's capabilities.
  - Quick check question: What model characteristics should be evaluated before applying CoT prompting to a task?

## Architecture Onboarding

- Component map: Task Identification -> Prompt Design (Demonstrations + Textual Instructions) -> Extension Strategy (Optional) -> Language Model -> Answer Generation
- Critical path: Task → Prompt Design → Extension Strategy (optional) → Model → Answer Generation
- Design tradeoffs: More complex demonstrations improve context but increase computational cost; ensemble methods improve robustness but add inference overhead; external assistance can enhance capability but introduces dependency on external tools.
- Failure signatures: Hallucination in small models, incorrect intermediate steps leading to wrong answers, over-reliance on demonstrations causing poor generalization, ensemble methods introducing noise instead of improvement.
- First 3 experiments:
  1. Test CoT prompting on a simple arithmetic reasoning task with 2-3 demonstrations to verify basic functionality.
  2. Compare zero-shot CoT (with textual instructions only) vs few-shot CoT on the same task to understand the impact of demonstrations.
  3. Apply sub-problem division to a complex reasoning task and compare performance with vanilla CoT.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we ensure the faithfulness of Chain-of-Thought (CoT) rationales generated by large language models (LLMs)?
- Basis in paper: [explicit] The paper discusses the challenge of faithfulness in CoT prompting, noting that current methods generate rationales together with final answers, which cannot guarantee the answer is directly acquired from the rationales. It also mentions the need for a truly faithful step-by-step reasoning process on LLMs.
- Why unresolved: The paper states that existing methods cannot ensure faithfulness in how rationales are generated from the query problem. It also mentions the need for more research in this area to achieve truly interpretable and transparent prompting strategies.
- What evidence would resolve it: Evidence of a method that can generate rationales separately from answers and ensure the answer is directly derived from the rationales would help resolve this question. Additionally, research demonstrating improved faithfulness in CoT reasoning would contribute to answering this question.

### Open Question 2
- Question: How can we improve the generality of CoT-assisted LLMs in handling problems that require a great amount of external knowledge or deeper understanding of language?
- Basis in paper: [explicit] The paper discusses the challenge of generality in CoT prompting, noting that current methods struggle with tasks requiring substantial external knowledge or deeper language understanding. It mentions the need for better methods to instruct LLMs to recognize and utilize learned knowledge.
- Why unresolved: The paper states that current CoT methods are limited in handling tasks that require external knowledge or deeper language understanding. It suggests that further research is needed to improve the generality of CoT-assisted LLMs in these areas.
- What evidence would resolve it: Evidence of a method that can effectively integrate external knowledge or enhance language understanding in CoT-assisted LLMs would help resolve this question. Additionally, research demonstrating improved performance on tasks requiring external knowledge or deeper language understanding would contribute to answering this question.

### Open Question 3
- Question: How can we develop a comprehensive theoretical analysis of CoT prompting to explain its working mechanism?
- Basis in paper: [explicit] The paper discusses the lack of theoretical analysis on CoT prompting and highlights the need for a better understanding of its working mechanism. It mentions that existing explanations focus on in-context learning but do not specifically address the complexities of CoT prompts.
- Why unresolved: The paper states that current explanations of CoT prompting are primarily empirical and do not provide a comprehensive theoretical analysis. It suggests that further research is needed to clarify the working mechanism of CoT prompting.
- What evidence would resolve it: Evidence of a theoretical framework that can explain the working mechanism of CoT prompting and address the complexities introduced by step-by-step reasoning chains would help resolve this question. Additionally, research demonstrating improved understanding and prediction of CoT prompting performance based on theoretical analysis would contribute to answering this question.

## Limitations
- Analysis based on 28 referenced papers may not capture the full landscape of CoT research
- Proposed mechanisms for CoT effectiveness are primarily theoretical with limited direct empirical validation
- The survey methodology and categorization approach lack detailed specification

## Confidence
- High confidence: The identification of task types, prompts design, extension strategies, and models as key factors affecting CoT performance
- Medium confidence: The effectiveness of ensemble methods and sub-problem division strategies, as these rely on cited studies with varying degrees of experimental rigor
- Low confidence: The proposed mechanisms explaining why CoT works, particularly the knowledge retrieval and reasoning context theories, which lack direct experimental support in the corpus

## Next Checks
1. Conduct controlled experiments comparing CoT performance across the identified task types (close domain reasoning, open domain reasoning, code generation) to verify the task-dependency claims
2. Systematically test the impact of demonstration factors (complexity, relevance, diversity) on CoT effectiveness using standardized benchmarks
3. Validate the ensemble strategy claims by implementing and testing multiple ensemble approaches across different reasoning tasks to confirm their effectiveness and identify optimal configurations