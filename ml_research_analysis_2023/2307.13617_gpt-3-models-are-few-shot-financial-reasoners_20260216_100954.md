---
ver: rpa2
title: GPT-3 Models are Few-Shot Financial Reasoners
arxiv_id: '2307.13617'
source_url: https://arxiv.org/abs/2307.13617
tags:
- financial
- question
- language
- gpt-3
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates how well large language models like GPT-3
  can perform financial question answering without fine-tuning. The authors find that
  while GPT-3 can generate directionally correct answers in some cases, its performance
  is limited when it must retrieve relevant passages and perform multi-step calculations
  on its own.
---

# GPT-3 Models are Few-Shot Financial Reasoners

## Quick Facts
- arXiv ID: 2307.13617
- Source URL: https://arxiv.org/abs/2307.13617
- Reference count: 33
- Key outcome: GPT-3 can generate directionally correct financial answers without fine-tuning, but specialized retrieval and calculation components are essential for near SOTA accuracy

## Executive Summary
This paper investigates GPT-3's capability to perform financial question answering using few-shot prompting without fine-tuning. The authors find that while GPT-3 can produce directionally correct answers in many cases, its performance significantly degrades as question complexity increases. By separating retrieval and calculation tasks into specialized components, the authors achieve near state-of-the-art accuracy on the FinQA dataset. The study demonstrates that precise reasoning and complex information in financial documents require tailored retrieval and calculation modules to achieve strong performance.

## Method Summary
The authors evaluate GPT-3's financial QA capabilities using the FinQA dataset (7,228 examples after filtering) and compare end-to-end prompting with decomposed approaches. They implement a BERT-base retriever for extracting relevant passages and a computational tree calculator for executing multi-step financial formulas. The experiments use GPT-3 DaVinci with few-shot examples (8-shot for retrieval/reasoning, 1-shot for end-to-end) and evaluate execution accuracy across different configurations: full passage context, retrieved passages only, and retrieved passages with external calculator.

## Key Results
- GPT-3's execution accuracy drops from 20% (simple questions) to 5% (complex multi-step questions) without specialized components
- Separating retrieval and calculation improves execution accuracy from 5% to 20% compared to end-to-end prompting
- Near SOTA accuracy achieved when using GPT-3 for program generation combined with external calculator execution
- GPT-3 consistently provides answers with correct sign, unit, and scale even when exact values are incorrect

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** GPT-3's few-shot prompting can generate directionally correct financial answers even without fine-tuning.
- **Mechanism:** The model leverages its pre-trained knowledge of numerical reasoning and financial terminology to infer plausible answers from minimal examples.
- **Core assumption:** GPT-3's training corpus included sufficient financial and mathematical content for it to form a latent understanding of financial question-answering tasks.
- **Evidence anchors:**
  - [abstract] states GPT-3 achieves "near SOTA accuracy without any fine-tuning."
  - [section] reports GPT-3 gave answers with "correct sign, unit, and scale" in end-to-end experiments.
  - [corpus] shows no strong supporting evidence; corpus signals are weak for financial QA-specific performance.
- **Break condition:** If financial reasoning requires domain-specific knowledge not present in pre-training, or if questions involve novel financial instruments not covered in the training corpus.

### Mechanism 2
- **Claim:** Separating retrieval and calculation tasks from GPT-3's reasoning improves performance.
- **Mechanism:** By handling retrieval externally, GPT-3 can focus its attention on generating programs and answers without being overwhelmed by context length or irrelevant information.
- **Core assumption:** The model's performance bottleneck is not reasoning ability but the ability to efficiently process large financial documents.
- **Evidence anchors:**
  - [abstract] indicates that "a separate retrieval model and logic engine continue to be essential components."
  - [section] shows execution accuracy jumped from 5% (full passage) to 20% (retrieved passages) when retrieval was handled externally.
  - [corpus] provides no direct evidence but related papers suggest retrieval enhancement is a common approach.
- **Break condition:** If the retriever component becomes a bottleneck or if the financial documents are small enough for GPT-3 to handle directly.

### Mechanism 3
- **Claim:** GPT-3's accuracy decreases linearly with question step complexity, but can handle multi-step problems when external calculation is provided.
- **Mechanism:** The model can generate correct programs for complex questions but struggles with execution, suggesting its strength is in pattern recognition rather than logical computation.
- **Core assumption:** GPT-3 captures statistical patterns in financial formulas but not the underlying mathematical logic required for precise calculations.
- **Evidence anchors:**
  - [section] reports "GPT-3's accuracy decreased as the complexity of the question increased" and "program execution is difficult for the model."
  - [section] shows near SOTA performance when an external calculator was added to handle execution.
  - [corpus] contains no direct evidence but the pattern aligns with general findings about LLMs and logical reasoning.
- **Break condition:** If the model is fine-tuned specifically on financial calculation tasks or if the questions become too complex for even the external calculator to handle.

## Foundational Learning

- **Concept:** Retrieval-augmented generation
  - **Why needed here:** Financial documents contain too much information for GPT-3 to process directly, requiring efficient retrieval of relevant passages.
  - **Quick check question:** What is the main advantage of using a retriever component before generating answers?

- **Concept:** Few-shot learning
  - **Why needed here:** The model must learn financial reasoning patterns from minimal examples without fine-tuning.
  - **Quick check question:** How does few-shot learning differ from traditional fine-tuning approaches?

- **Concept:** Program generation for numerical reasoning
  - **Why needed here:** Financial questions require multi-step calculations that must be broken down into executable programs.
  - **Quick check question:** Why is program generation important for financial question answering?

## Architecture Onboarding

- **Component map:** Retriever (BERT-base) -> GPT-3 (program generation) -> Calculator (execution) -> Answer validation

- **Critical path:** Retrieve relevant passages → Generate program → Execute program → Validate answer

- **Design tradeoffs:**
  - Token limitations vs. context completeness
  - Retriever accuracy vs. computational efficiency
  - GPT-3 temperature settings vs. answer consistency

- **Failure signatures:**
  - Incorrect retrieval leading to irrelevant programs
  - GPT-3 generating invalid programs with syntax errors
  - Calculator failing to parse complex financial formulas

- **First 3 experiments:**
  1. End-to-end GPT-3 prompting with full financial report context
  2. GPT-3 prompting with externally retrieved passages only
  3. GPT-3 program generation with external calculator execution

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GPT-3 performance on Financial QA scale with model size compared to specialized retrievers and calculators?
- Basis in paper: [inferred] The paper found that GPT-3's performance decreased with increased step complexity, and that specialized components were essential for state-of-the-art results.
- Why unresolved: The paper only tested GPT-3 DaVinci (175B parameters) and did not compare performance across different model sizes or directly compare to smaller specialized models.
- What evidence would resolve it: Experiments testing GPT-3 models of different sizes (e.g. Curie, Babbage, Ada) on the same Financial QA tasks, compared to performance of specialized retrievers and calculators of various sizes.

### Open Question 2
- Question: Can GPT-3 be fine-tuned on financial data to improve its performance on Financial QA tasks?
- Basis in paper: [explicit] The authors mention "Future work possibilities include running experiments with different hyperparameters and fine-tune language models to explore the limits of numerical inference within Financial QA."
- Why unresolved: The paper only used few-shot prompting with GPT-3 and did not explore fine-tuning on financial data.
- What evidence would resolve it: Experiments fine-tuning GPT-3 on financial data (e.g. FinTabNet) and comparing performance to few-shot prompting and state-of-the-art methods.

### Open Question 3
- Question: How well does GPT-3 generalize to financial domains beyond earnings reports?
- Basis in paper: [inferred] The paper tested GPT-3 on Financial QA using earnings reports from the FinQA dataset, but did not explore performance on other financial domains.
- Why unresolved: The paper's experiments were limited to earnings reports, so it's unclear how well GPT-3 would perform on other financial domains (e.g. financial news, SEC filings, analyst reports).
- What evidence would resolve it: Experiments testing GPT-3 on Financial QA tasks using data from diverse financial domains beyond earnings reports.

## Limitations

- Data filtering criteria are unspecified, potentially introducing selection bias
- Only GPT-3 DaVinci was evaluated, limiting generalizability to other model sizes
- No comparison with fine-tuned baselines to validate near SOTA claims

## Confidence

**High Confidence:** GPT-3 can generate directionally correct financial answers; accuracy decreases with question complexity

**Medium Confidence:** Separating retrieval and calculation improves performance; near SOTA accuracy achievable without fine-tuning

**Low Confidence:** Exact prompt templates and data filtering criteria are unspecified; results may not generalize to other financial domains

## Next Checks

1. Replicate the full pipeline with exact data filtering and prompt templates to verify reported execution accuracy of 20% for retrieved passages

2. Test robustness across financial domains (technology, healthcare, retail) to determine if performance holds across varied financial reporting styles

3. Compare against fine-tuned baselines (BERT for retrieval, specialized calculator) to establish competitiveness with traditional fine-tuned systems