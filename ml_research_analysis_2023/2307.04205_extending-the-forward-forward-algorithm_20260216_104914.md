---
ver: rpa2
title: Extending the Forward Forward Algorithm
arxiv_id: '2307.04205'
source_url: https://arxiv.org/abs/2307.04205
tags:
- forward
- algorithm
- network
- threshold
- layer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors replicated Hinton's Forward Forward algorithm on MNIST,
  achieving 1.37% test error comparable to backprop. They extended the method to sentiment
  analysis on IMDb reviews, obtaining 84.86% accuracy.
---

# Extending the Forward Forward Algorithm

## Quick Facts
- arXiv ID: 2307.04205
- Source URL: https://arxiv.org/abs/2307.04205
- Authors: 
- Reference count: 13
- Key outcome: Replicated Hinton's Forward Forward algorithm achieving 1.37% MNIST test error and 84.86% IMDb accuracy, introduced pyramidal threshold tuning with up to 8% error reduction, showed ReLU outperforms bounded activations, and revealed FF weights are 10-20x larger than backprop weights.

## Executive Summary
This paper extends Geoffrey Hinton's Forward Forward algorithm beyond its initial vision application, demonstrating its viability on both MNIST image classification (1.37% test error) and sentiment analysis of IMDb reviews (84.86% accuracy). The authors introduce a pyramidal threshold tuning strategy that significantly improves performance by having larger thresholds in deeper layers, reflecting their role in higher-level feature recognition. They also systematically compare activation functions, finding that ReLU works best while bounded activations like tanh and sigmoid fail to train effectively. The study reveals that Forward Forward networks develop weights 10-20x larger than backpropagation-trained networks, suggesting fundamental differences in how the algorithm learns.

## Method Summary
The authors implement Hinton's Forward Forward algorithm using a 4-layer fully connected network with 2000 neurons per layer, trained with the Adam optimizer (learning rate 0.01) and ReLU activation. The algorithm trains each layer independently to maximize activation for positive samples while minimizing it for negative samples, using a threshold hyperparameter to define the objective. For MNIST, they embed labels within images and generate random negative samples. They introduce a pyramidal threshold tuning strategy where thresholds increase monotonically across layers (k=0.3-0.5), and extend the method to sentiment analysis on IMDb reviews using Word2Vec embeddings with one-hot concatenated labels. Inference uses either a 1-layer classification network or label-maximization.

## Key Results
- Forward Forward achieves 1.37% test error on MNIST, comparable to backpropagation performance
- Pyramidal threshold tuning strategy shows up to 8% error reduction compared to uniform thresholds
- ReLU activation outperforms bounded activations (tanh, sigmoid), which fail to train effectively
- Forward Forward weights are 10-20x larger than backpropagation-trained weights
- Sentiment analysis on IMDb achieves 84.86% accuracy with 6 epochs of training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Forward Forward works by training each layer independently to maximize activation for positive samples while minimizing it for negative samples, eliminating the need for backpropagation.
- Mechanism: Each layer has its own loss function that compares the sum of squared activations to a threshold. The layer learns to push activations above the threshold for positive data and below for negative data through a second forward pass with randomly labeled "negative" data.
- Core assumption: The layer-wise independence with appropriate threshold tuning can achieve comparable performance to end-to-end backpropagation.
- Evidence anchors:
  - [abstract] "The Forward Forward algorithm, proposed by Geoffrey Hinton in November 2022, is a novel method for training neural networks as an alternative to backpropagation."
  - [section 4.1] "The goal of the loss function is maximise the layer activation for positive data while minimising the layer activation for negative data. More concretly, the training loss for each layer is the difference between the sum of neuron activations to positive/negative inputs and a threshold hyper-parameter value."
  - [corpus] Weak evidence - related papers discuss Forward Forward but don't directly validate this specific mechanism claim.
- Break condition: If threshold tuning fails or if inter-layer dependencies are too strong for independent layer training to work effectively.

### Mechanism 2
- Claim: The pyramidal threshold strategy improves performance by having larger thresholds in deeper layers, allowing more expressive activation ranges where needed.
- Mechanism: Early layers have smaller thresholds for feature extraction while deeper layers have larger thresholds to capture more complex patterns. This creates a pyramid-shaped threshold progression across layers.
- Core assumption: Deeper layers benefit more from higher activation ranges, and this structured approach captures hierarchical feature learning better than uniform thresholds.
- Evidence anchors:
  - [abstract] "Our pyramidal approach shows that a good thresholding strategy causes a difference of upto 8% in test error."
  - [section 5.2] "We found that the monotonically increasing the threshold across layers performs distinctly better than other approaches. We hypothesize that larger threshold values in later layers improves performance as the later layers are responsible for higher level feature recognition while the lower layers tend to behave as feature extractors."
  - [corpus] No direct evidence in related papers about pyramidal threshold strategies.
- Break condition: If the hierarchical assumption about layer functions doesn't hold for certain architectures or datasets.

### Mechanism 3
- Claim: The algorithm's biological plausibility stems from using only forward passes, avoiding the biologically implausible backward error propagation.
- Mechanism: By training each layer independently with only forward computations and random negative samples, the algorithm mimics how biological neurons might learn without requiring error signals to travel backward through synapses.
- Core assumption: Biological learning can be approximated by layer-wise independent training with local objectives rather than global error backpropagation.
- Evidence anchors:
  - [abstract] "First, it provides a more plausible model of learning in the human brain"
  - [section 1] "First, backpropagation is biologically implausible. There is no convincing evidence that the cortex of the brain explicitly propagates error derivatives or stores neural activities for use in a subsequent backward pass"
  - [corpus] Weak evidence - related papers discuss biological plausibility but don't validate the specific mechanism.
- Break condition: If experiments show that biological plausibility doesn't translate to practical performance advantages.

## Foundational Learning

- Concept: Forward vs Backward Pass Distinction
  - Why needed here: Understanding that Forward Forward eliminates the backward pass entirely is crucial for grasping why it's biologically plausible and how it differs from standard training.
  - Quick check question: What is the key computational difference between Forward Forward and standard backpropagation in terms of data flow through the network?

- Concept: Loss Threshold Hyperparameter
  - Why needed here: The threshold is central to how each layer learns its objective and requires careful tuning for optimal performance.
  - Quick check question: How does changing the loss threshold affect a layer's behavior toward positive versus negative samples?

- Concept: Negative Data Generation
  - Why needed here: Forward Forward requires artificially generated negative samples with incorrect labels, which is a key difference from standard supervised learning.
  - Quick check question: How are negative samples created in the Forward Forward algorithm and why are they necessary?

## Architecture Onboarding

- Component map: Input → 4-layer fully connected network (2000 neurons each) → Layer-wise loss functions with thresholds → Adam optimizer → 1-layer classification network for inference OR label-maximization inference
- Critical path: Input → Forward pass through all layers → Compute layer activations → Compare to thresholds → Update weights using Adam → Repeat for negative samples → Aggregate losses
- Design tradeoffs: No backpropagation enables biological plausibility and hardware efficiency but requires careful threshold tuning and may converge slower than backpropagation.
- Failure signatures: Poor performance with inappropriate threshold values, failure to train with bounded activations like tanh/sigmoid, very large weight magnitudes compared to backpropagation-trained networks.
- First 3 experiments:
  1. Replicate MNIST baseline with standard threshold = number of neurons per layer
  2. Test pyramidal threshold strategy with monotonically increasing thresholds
  3. Compare ReLU vs bounded activations (tanh, sigmoid) performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal threshold scheduling strategy for the Forward Forward algorithm across different network depths and layer sizes?
- Basis in paper: [explicit] The paper mentions that pyramidal threshold tuning showed up to 8% error reduction and that monotonically increasing thresholds across layers performed better than other approaches, but the optimal scheduling strategy remains unclear.
- Why unresolved: While the paper demonstrates that threshold tuning matters significantly, it only explores a limited range of scheduling strategies and does not systematically investigate the relationship between threshold values, layer depth, and layer size.
- What evidence would resolve it: Systematic ablation studies varying threshold schedules across different network architectures, layer depths, and sizes to identify optimal threshold progression patterns.

### Open Question 2
- Question: Why do bounded activation functions (tanh, sigmoid) fail to train effectively in the Forward Forward algorithm?
- Basis in paper: [explicit] The paper observes that bounded activations do not train at all for certain thresholds and perform worse than unbounded activations like ReLU, even after hyperparameter tuning.
- Why unresolved: The paper only provides a hypothesis about bounded activations requiring "incredibly high weight values" but does not experimentally verify this or explore alternative explanations.
- What evidence would resolve it: Detailed analysis of weight distributions and activation patterns for bounded vs unbounded activations across different threshold values, along with experiments testing alternative normalization or scaling strategies.

### Open Question 3
- Question: Why do Forward Forward networks develop weights that are 10-20x larger than backpropagation networks?
- Basis in paper: [explicit] The paper observes that FF weights are significantly larger than backprop weights and notes this disparity may be attributed to the objective function encouraging highly positive/negative activations.
- Why unresolved: While the paper identifies this phenomenon, it does not investigate the underlying mechanisms or explore whether this large weight magnitude is necessary for the algorithm to function or merely a side effect.
- What evidence would resolve it: Experiments testing whether weight decay or normalization techniques can reduce weight magnitude without harming performance, and analysis of the relationship between weight magnitude and activation patterns.

## Limitations

- The loss function formulation remains underspecified beyond basic threshold comparison, making exact reproduction challenging
- Comparison to backpropagation uses different network architectures (fully connected vs CNN), limiting direct performance comparisons
- Claims about biological plausibility lack experimental validation and theoretical justification

## Confidence

- **High confidence**: The basic Forward Forward algorithm implementation and its performance on MNIST (1.37% error)
- **Medium confidence**: The pyramidal threshold strategy's effectiveness (up to 8% improvement) and ReLU activation superiority
- **Low confidence**: Claims about biological plausibility and implications for neural architecture design

## Next Checks

1. **Threshold sensitivity analysis**: Systematically vary threshold parameters across a wider range (k=0.1 to 0.9) to establish robust performance bounds and identify optimal scheduling strategies.

2. **Cross-architecture validation**: Test Forward Forward on CNN architectures for MNIST and compare performance to backpropagation-trained CNNs using identical architectures to establish fair baseline comparisons.

3. **Generalization assessment**: Evaluate model performance on out-of-distribution MNIST samples and corrupted images to understand how the large weight magnitudes affect robustness compared to backpropagation-trained networks.