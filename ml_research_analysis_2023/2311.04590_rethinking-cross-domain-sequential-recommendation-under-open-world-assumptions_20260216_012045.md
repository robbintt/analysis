---
ver: rpa2
title: Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions
arxiv_id: '2311.04590'
source_url: https://arxiv.org/abs/2311.04590
tags:
- users
- recommendation
- cdsr
- sequential
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the limitations of cross-domain sequential
  recommendation (CDSR) methods that assume closed-world scenarios with fully overlapping
  users. The authors propose an Adaptive Multi-Interest Debiasing (AMID) framework
  to handle open-world environments with partial user overlap and data distribution
  shifts.
---

# Rethinking Cross-Domain Sequential Recommendation under Open-World Assumptions

## Quick Facts
- arXiv ID: 2311.04590
- Source URL: https://arxiv.org/abs/2311.04590
- Authors: 
- Reference count: 40
- Key outcome: AMID framework outperforms state-of-the-art CDSR methods in open-world environments with partial user overlap

## Executive Summary
This paper addresses the limitations of cross-domain sequential recommendation methods that assume closed-world scenarios with fully overlapping users. The authors propose an Adaptive Multi-Interest Debiasing (AMID) framework that handles open-world environments with partial user overlap and data distribution shifts. AMID consists of a Multi-Interest Information Module (MIM) for propagating cross-domain information among both overlapping and non-overlapping users, and a Doubly Robust Estimator (DRE) to mitigate selection bias. The framework can be integrated with most single-domain sequential recommendation models and demonstrates superior performance in both offline experiments and online A/B tests.

## Method Summary
The AMID framework addresses open-world CDSR challenges through two main components: MIM constructs interest groups that include both overlapping and non-overlapping users by computing pairwise similarity between user sequences across domains, then propagates cross-domain messages within these groups. DRE reduces estimation bias by combining error imputation with propensity scoring through an alternating training process. The framework first trains imputation and propensity models on observed data, then fine-tunes the prediction model on the full dataset using learned propensity weights. This joint learning approach enables the framework to effectively transfer knowledge across domains while mitigating selection bias inherent in open-world scenarios.

## Key Results
- AMID outperforms state-of-the-art CDSR and debiasing methods on Amazon and large-scale financial datasets
- Online A/B tests on Alipay demonstrate improved exposure, click-through rate, and conversion rate compared to existing solutions
- The framework shows consistent improvement across varying degrees of user overlap (25% and 75% overlap ratios)

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: MIM improves cross-domain knowledge transfer by constructing interest groups that include both overlapping and non-overlapping users
- **Mechanism**: Computes pairwise similarity between user sequences across domains using learned transformation matrices, then propagates cross-domain messages within the same group
- **Core assumption**: User sequence similarity across domains correlates with shared interests that can be transferred
- **Evidence anchors**: Abstract states MIM establishes interest groups for both overlapping and non-overlapping users; section 4.1 describes cross-domain information transfer
- **Break condition**: If user sequence similarity doesn't correlate with transferable interests, or threshold-based grouping creates poor relationships

### Mechanism 2
- **Claim**: DRE reduces estimation bias by combining error imputation with propensity scoring
- **Mechanism**: Combines prediction error imputation model with propensity model to create unbiased estimator that remains accurate when one component is imperfect
- **Core assumption**: Both imputation errors and propensity scores can be learned from observed data
- **Evidence anchors**: Abstract mentions DRE mitigates selection bias; section 4.3 proposes doubly robust estimator generalizing traditional DR estimator
- **Break condition**: If either imputation or propensity model fails to learn accurate estimates from observed data

### Mechanism 3
- **Claim**: Joint learning with alternating optimization reduces both bias and variance
- **Mechanism**: Alternates between training imputation and propensity models on observed data, then fine-tuning prediction model on full dataset
- **Core assumption**: Observed data contains sufficient signal to learn accurate models
- **Evidence anchors**: Section 4.4 describes alternating training for joint learning; abstract reports AMID outperforms state-of-the-art methods
- **Break condition**: If alternating optimization fails to converge or second step overfits to biased observed data

## Foundational Learning

- **Concept**: Cross-domain sequential recommendation fundamentals
  - Why needed here: Understanding how sequential patterns in one domain inform another domain is essential for grasping MIM's group-based propagation approach
  - Quick check question: What distinguishes CDSR from traditional cross-domain recommendation, and why does this distinction matter for the proposed approach?

- **Concept**: Selection bias and inverse propensity scoring
  - Why needed here: DRE mechanism relies on understanding how selection bias affects training data and how propensity scores correct for this bias
  - Quick check question: How does selection bias manifest in recommendation systems, and why is it particularly problematic in open-world CDSR scenarios?

- **Concept**: Doubly robust estimation theory
  - Why needed here: Theoretical foundation for why combining imputation and propensity models provides bias reduction is crucial for understanding DRE's design
  - Quick check question: What conditions must hold for a doubly robust estimator to provide unbiased estimates, and how does this apply to cross-domain sequential setting?

## Architecture Onboarding

- **Component map**: User sequences → MIM grouping → cross-domain message aggregation → SDSR backbone encoding → DRE joint training → debiased predictions

- **Critical path**: User sequence → MIM grouping → cross-domain message aggregation → SDSR backbone encoding → DRE joint training → debiased predictions

- **Design tradeoffs**:
  - MIM vs. direct transfer: MIM avoids reliance on overlapping users but adds computational overhead for similarity computation
  - DRE vs. IPS only: DRE provides lower variance but requires training additional models
  - Joint learning complexity: Alternating optimization improves robustness but complicates training

- **Failure signatures**:
  - Poor performance on non-overlapping users indicates MIM grouping issues
  - High variance in estimates suggests DRE propensity model problems
  - Training instability may indicate joint learning hyperparameter issues

- **First 3 experiments**:
  1. Test MIM with varying thresholds on synthetic data with known group structures
  2. Validate DRE bias reduction on simulated selection bias scenarios
  3. Evaluate joint learning convergence on partially overlapping user datasets

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions in the provided content.

## Limitations
- Time complexity of constructing groups for |Z| domains is O(|Z|²), which becomes time-consuming as the number of domains increases
- Performance under extreme partial overlap scenarios (beyond 25% and 75% overlap ratios) is not explored
- Cold-start problem for new users with no historical interactions in any domain is not addressed

## Confidence
- **High confidence**: MIM's ability to propagate cross-domain information to non-overlapping users
- **Medium confidence**: DRE's bias reduction capability
- **Low confidence**: Framework's performance under extreme partial overlap scenarios

## Next Checks
1. Conduct sensitivity analysis for MIM threshold k across multiple values (0.5-0.9) to establish optimal range and robustness
2. Test DRE performance under controlled synthetic selection bias scenarios where ground truth bias magnitude is known
3. Evaluate AMID's performance on datasets with more extreme partial overlap ratios (5%, 90%) to stress-test open-world assumptions