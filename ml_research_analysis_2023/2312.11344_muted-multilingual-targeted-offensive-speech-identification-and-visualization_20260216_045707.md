---
ver: rpa2
title: 'Muted: Multilingual Targeted Offensive Speech Identification and Visualization'
arxiv_id: '2312.11344'
source_url: https://arxiv.org/abs/2312.11344
tags:
- offensive
- target
- language
- attention
- spans
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We present MUTED, a system to identify multilingual hate, abuse,
  and profanity (HAP) by visualizing offensive arguments and their targets using attention
  heatmaps. MUTED can leverage any transformer-based HAP classifier to identify toxic
  spans without further fine-tuning, and uses spaCy to identify specific targets and
  arguments.
---

# Muted: Multilingual Targeted Offensive Speech Identification and Visualization

## Quick Facts
- arXiv ID: 2312.11344
- Source URL: https://arxiv.org/abs/2312.11344
- Reference count: 12
- Primary result: F1 scores of 0.50 (English) and 0.44 (German) for identifying both targets and arguments in offensive content

## Executive Summary
MUTED is a system for identifying multilingual hate, abuse, and profanity (HAP) by visualizing offensive arguments and their targets using attention heatmaps. The system leverages transformer-based HAP classifiers to identify toxic spans without fine-tuning, then uses spaCy's dependency parser to identify specific targets and arguments. The authors present model performance on English and German datasets and provide a visualization tool for multilingual inputs. The approach aims to make offensive content identification more interpretable by showing which words contribute most to the classification decision and how targets and arguments are identified.

## Method Summary
MUTED uses attention heatmaps from transformer-based classifiers to identify toxic spans in text, then applies spaCy's dependency parser to determine the target (subject) and argument (object) of offensive content. The system can work with any transformer-based HAP classifier out-of-the-box without requiring additional fine-tuning. The Piccolo-HAP classifier, a 4-layer XLM-Roberta model with 153M parameters, is presented as the primary implementation, trained on 1.7 million sentences across 6 languages. The approach extracts attention weights from the CLS token of the last transformer layer, applies a threshold to identify offensive spans, and uses spaCy's subj and obj labels to map the relationships.

## Key Results
- MUTED achieves F1 scores of 0.50 for English and 0.44 for German in identifying both targets and arguments of offensive content
- The Piccolo-HAP model outperforms all other German Huggingface models and also the multi-lingual model with the exception of the target-only score
- The system can visualize multilingual inputs and provides interpretability through attention heatmaps and dependency parsing visualizations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transformer attention mechanisms can identify toxic spans without additional fine-tuning
- Core assumption: High attention weights on specific tokens indicate their importance in offensive content classification
- Evidence: The system extracts attention outputs from the last transformer layer, computes average attention across all heads, and uses a threshold to identify tokens with highest attention scores
- Break condition: If CLS token attention doesn't correlate with toxic content or model architecture differs significantly from standard transformers

### Mechanism 2
- Claim: spaCy dependency parser can identify target and argument of offensive spans
- Core assumption: Syntactic relationships between offensive words and other sentence elements reliably indicate target and argument structure
- Evidence: Uses subj and obj labels from spaCy dependency parser to identify TARGET (subject) and ARGUMENT (object) of offense
- Break condition: If spaCy parser fails to correctly identify syntactic relationships or target/argument structure doesn't follow standard patterns

### Mechanism 3
- Claim: Piccolo-HAP's multilingual capability and small size enable efficient offensive language identification
- Core assumption: Smaller multilingual transformer models can perform as well as larger monolingual models
- Evidence: 4-layer XLM-Roberta model (153M parameters) trained on 1.7 million sentences across 6 languages outperforms other models
- Break condition: If performance degrades significantly on languages with less training data or small size limits ability to capture complex patterns

## Foundational Learning

- Concept: Transformer attention mechanisms
  - Why needed here: Understanding how self-attention works in transformers to identify important tokens for classification decisions
  - Quick check question: How does multi-head attention in transformers work, and why would CLS token's attention be relevant for identifying important input tokens?

- Concept: Dependency parsing and syntactic relationships
  - Why needed here: Using spaCy's dependency parser to identify subject-object relationships indicating targets and arguments
  - Quick check question: What are key dependency labels (like subj and obj) used in spaCy, and how do they help identify grammatical relationships in sentences?

- Concept: Multilingual NLP model training
  - Why needed here: Piccolo-HAP model is trained on multiple languages, requiring understanding of cross-lingual training data handling
  - Quick check question: What are key considerations when training multilingual transformer models, particularly regarding data balance across languages?

## Architecture Onboarding

- Component map: Input text -> Transformer classifier -> Attention extraction module -> Thresholding component -> spaCy dependency parser -> Visualization module -> Frontend interface

- Critical path:
  1. User inputs text
  2. Text processed by transformer classifier
  3. Attention weights extracted and processed to identify offensive spans
  4. spaCy dependency parser analyzes spans to identify target and argument
  5. Visualizations generated and displayed to user

- Design tradeoffs:
  - Attention from CLS token vs. aggregating attention from argument tokens for target identification
  - Fixed vs. adaptive attention thresholds for span identification
  - Multilingual vs. monolingual model performance trade-offs
  - Model size vs. inference speed considerations (Piccolo-HAP vs. larger models)

- Failure signatures:
  - Incorrect span identification due to attention weights not correlating with offensive content
  - Misidentification of target/argument due to spaCy parser errors or unusual sentence structures
  - Poor performance on languages with less training data
  - Visualization errors or delays in frontend interface

- First 3 experiments:
  1. Test attention-based span identification on known offensive sentences to verify high-attention tokens correspond to offensive content
  2. Evaluate spaCy dependency parser's ability to correctly identify target-argument pairs in diverse offensive sentences
  3. Compare Piccolo-HAP performance with larger monolingual model on balanced offensive sentences across supported languages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the model effectively identify targets containing typos or misspellings?
- Basis in paper: Authors note the model struggles with targets containing typos, such as "yal" instead of "y'all"
- Why unresolved: Paper doesn't provide detailed analysis of how model handles typos or propose improvement solutions
- What evidence would resolve it: Study testing model performance on dataset with intentionally misspelled targets compared to correctly spelled targets

### Open Question 2
- Question: Can the model be improved by using attention of argument to identify target instead of CLS vector?
- Basis in paper: Authors suggest more robust approach is to find words most heavily attended to by tokens in offensive span (argument) instead of CLS vector
- Why unresolved: Paper doesn't implement or test this alternative approach
- What evidence would resolve it: Experiment comparing current approach (CLS vector attention) with proposed approach (argument token attention)

### Open Question 3
- Question: How can system be extended to provide warnings and hide offensive content to users?
- Basis in paper: Authors mention wanting to extend demo to provide warnings and hide offensive content in future
- Why unresolved: Paper doesn't provide details on implementation or effectiveness evaluation
- What evidence would resolve it: Prototype or user study evaluating effectiveness of warning and hiding features

## Limitations

- Performance variability across languages beyond English and German, with limited data on other supported languages
- Reliance on attention mechanisms whose correlation with semantic importance isn't explicitly validated
- Heavy dependence on spaCy dependency parser accuracy, with no detailed error analysis for complex sentence structures

## Confidence

- High confidence: Core architecture and methodology clearly described, following established NLP practices
- Medium confidence: Reported performance metrics based on established datasets, but modest F1 scores and limited ablation studies reduce absolute effectiveness confidence
- Low confidence: Claims about robustness to multilingual inputs beyond English and German not adequately supported

## Next Checks

1. Test MUTED on balanced offensive sentences across all six supported languages to measure performance consistency and identify underperforming languages

2. Compare attention-based toxic span identification against alternative approaches (gradient-based methods, model-specific token importance scoring) to quantify reliability and advantages

3. Conduct detailed error analysis on diverse offensive sentences, categorizing spaCy parser failure modes and their impact on target/argument identification, focusing on edge cases and non-standard language use