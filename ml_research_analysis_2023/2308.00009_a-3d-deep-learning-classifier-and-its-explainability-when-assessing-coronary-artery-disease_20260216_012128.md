---
ver: rpa2
title: A 3D deep learning classifier and its explainability when assessing coronary
  artery disease
arxiv_id: '2308.00009'
source_url: https://arxiv.org/abs/2308.00009
tags:
- coronary
- classification
- learning
- deep
- segmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents a 3D deep learning approach for coronary artery
  disease (CAD) classification using computed tomography coronary angiography (CTCA)
  images. The proposed 3D Resnet-50 model directly classifies normal subjects and
  CAD patients without requiring centerline extraction or multi-planar reconstruction.
---

# A 3D deep learning classifier and its explainability when assessing coronary artery disease

## Quick Facts
- arXiv ID: 2308.00009
- Source URL: https://arxiv.org/abs/2308.00009
- Reference count: 39
- This study presents a 3D deep learning approach for coronary artery disease (CAD) classification using computed tomography coronary angiography (CTCA) images.

## Executive Summary
This study presents a 3D deep learning approach for coronary artery disease (CAD) classification using computed tomography coronary angiography (CTCA) images. The proposed 3D Resnet-50 model directly classifies normal subjects and CAD patients without requiring centerline extraction or multi-planar reconstruction. The method achieves a test accuracy of 71.43%, outperforming a 2D Resnet-50 model by 23.65%. The model demonstrates excellent precision (1.00) and fair recall (0.43) on the test set. Additionally, the study explores explainability through Grad-CAM visualization and proposes linking 3D classification to 2D two-class semantic segmentation for improved explainability and accurate abnormality localization.

## Method Summary
The method uses a 3D Resnet-50 architecture trained on CTCA images from 88 subjects (44 normal, 44 CAD patients). Images are preprocessed to 128x128 resolution with 256 slices per case. The model is trained using focal loss and Adam optimizer with early stopping after 10 epochs without improvement. Classification performance is evaluated using accuracy, recall, precision, and F1-score. Explainability is provided through Grad-CAM visualization, and a 2D U-Net segmentation model is used to produce pixel-level masks of aorta and coronary arteries for improved explainability.

## Key Results
- 3D Resnet-50 achieves test accuracy of 71.43%, outperforming 2D Resnet-50 by 23.65%
- Model demonstrates excellent precision (1.00) but fair recall (0.43) on test set
- Grad-CAM explainability reveals model decision regions, though not always localized to coronary arteries
- Linking 3D classification to 2D semantic segmentation provides exact abnormality localization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: 3D Resnet-50 learns spatial-temporal features across coronary artery slices, improving classification accuracy over 2D models.
- Mechanism: 3D convolutions aggregate volumetric context across adjacent slices, enabling the model to capture vessel morphology and plaque distribution in 3D space rather than per-slice features.
- Core assumption: CAD diagnosis benefits from inter-slice anatomical continuity rather than isolated slice classification.
- Evidence anchors:
  - [abstract]: "Our proposed method outperforms a 2D Resnet-50 model by 23.65%."
  - [section]: "The 3D Resnet-50 network is the extension of the 2D Resnet-50 network. It uses 1x1x1 convolutions for bottleneck block. It has the ability to learn features across several images while the 2D Resnet-50 learns the features within a single image only."

### Mechanism 2
- Claim: Grad-CAM explainability reveals the model's decision regions, though not always localized to the coronary arteries themselves.
- Mechanism: Gradient-weighted class activation mapping backpropagates through the network to highlight regions contributing to classification, producing heatmaps for each convolutional layer.
- Core assumption: The heatmaps can be interpreted by clinicians to understand what the model "sees" as diagnostic features.
- Evidence anchors:
  - [abstract]: "Explainability is also provided by using a Grad-GAM."
  - [section]: "The Grad-CAM produces a heat map and highlights the regions in the image which are important for the classification."

### Mechanism 3
- Claim: Linking 3D classification to 2D semantic segmentation improves explainability and provides exact abnormality localization.
- Mechanism: The segmentation model produces pixel-level masks of aorta and coronary arteries, which can be overlaid with classification decisions to show exactly where abnormalities occur.
- Core assumption: Combining coarse patient-level classification with fine-grained segmentation provides both diagnostic accuracy and clinical interpretability.
- Evidence anchors:
  - [abstract]: "Furthermore, we link the 3D CAD classification to a 2D two-class semantic segmentation for improved explainability and accurate abnormality localisation."
  - [section]: "It confirms that the deep learning model focused on the aorta and coronary arteries for the segmentation task."

## Foundational Learning

- Concept: 3D Convolutional Neural Networks
  - Why needed here: CAD manifests in volumetric coronary anatomy that requires spatial context across slices for accurate detection.
  - Quick check question: What is the primary difference between 2D and 3D convolutions in how they process medical image data?

- Concept: Explainable AI and Grad-CAM
  - Why needed here: Clinicians need to understand model decisions to trust and validate CAD diagnoses in clinical settings.
  - Quick check question: How does Grad-CAM generate heatmaps from a trained classification model?

- Concept: Semantic Segmentation for Medical Images
  - Why needed here: Pixel-level masks of coronary anatomy provide exact localization of abnormalities that complement patient-level classification.
  - Quick check question: What is the difference between semantic segmentation and classification in the context of medical image analysis?

## Architecture Onboarding

- Component map:
  - Input pipeline: CTCA image preprocessing (intensity normalization, resizing to 128x128, resampling to 256 slices)
  - 3D Resnet-50 classifier: Patient-level CAD vs normal classification
  - Grad-CAM explainer: Heatmap generation for classification decisions
  - 2D U-Net segmentation: Pixel-level aorta and coronary artery masks
  - Seg-Grad-CAM: Explainability for segmentation decisions

- Critical path:
  1. Preprocess CTCA images to standard format
  2. Run 3D Resnet-50 classification
  3. Generate Grad-CAM heatmaps for explainability
  4. Run 2D U-Net segmentation
  5. Generate Seg-Grad-CAM for segmentation explainability
  6. Combine classification and segmentation results for final diagnosis

- Design tradeoffs:
  - 3D vs 2D: 3D provides better accuracy but requires more GPU memory and training data
  - Heatmap granularity: Last convolution layer provides broader context, middle layer may be more focused
  - Segmentation vs classification: Segmentation provides exact localization but requires pixel-level annotations

- Failure signatures:
  - Poor classification accuracy: Likely indicates overfitting, insufficient training data, or incorrect preprocessing
  - Heatmaps not focused on coronary regions: May indicate the model is learning non-relevant features
  - Segmentation mask misalignment: Could indicate preprocessing errors or domain shift between training and test data

- First 3 experiments:
  1. Train 2D Resnet-50 on single slices and compare accuracy to 3D model to quantify the benefit of volumetric context
  2. Visualize Grad-CAM heatmaps from different convolution layers to determine which provides most clinically relevant explainability
  3. Evaluate segmentation model performance using Dice Similarity Coefficient and visualize failure cases to identify preprocessing issues

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the incorporation of prior knowledge (such as centerline extraction or aorta and coronary arteries masks) into the 3D CAD classification model affect classification accuracy and explainability compared to the current approach?
- Basis in paper: [explicit] The paper suggests incorporating prior information (informed cues) to improve the explainability and accuracy of the 3D CAD classification model.
- Why unresolved: The study did not implement the incorporation of prior knowledge into the 3D CAD classification model, leaving its potential impact on accuracy and explainability untested.
- What evidence would resolve it: Comparative studies between the current 3D CAD classification model and a model that incorporates prior knowledge, evaluating both classification accuracy and explainability.

### Open Question 2
- Question: Can the proposed 2D two-class semantic segmentation approach be extended to 3D multi-class segmentation (e.g., aorta and coronary arteries, stable plaques, and unstable plaques) to improve classification accuracy and explainability with exact abnormality localization?
- Basis in paper: [explicit] The paper discusses the potential extension of the 2D two-class semantic segmentation to 3D multi-class segmentation for improved classification accuracy and explainability.
- Why unresolved: The study did not implement or evaluate the 3D multi-class segmentation approach, leaving its potential benefits untested.
- What evidence would resolve it: Implementation and evaluation of the 3D multi-class segmentation approach, comparing its classification accuracy and explainability to the current methods.

### Open Question 3
- Question: What is the impact of using balanced versus unbalanced datasets on the classification accuracy and generalizability of the deep learning models for CAD detection?
- Basis in paper: [explicit] The paper mentions that the previous study produced better classification accuracy due to unbalanced datasets, while the current study used balanced datasets to produce unbiased results.
- Why unresolved: The study does not provide a direct comparison between the effects of balanced and unbalanced datasets on model performance and generalizability.
- What evidence would resolve it: Comparative studies using both balanced and unbalanced datasets, evaluating the classification accuracy and generalizability of the deep learning models.

## Limitations
- Small dataset size (88 subjects) raises concerns about model generalizability and potential overfitting
- Test accuracy of 71.43% combined with fair recall (0.43) suggests potential issues with false negatives in medical diagnosis
- Grad-CAM explainability lacks rigorous validation showing highlighted regions correspond to clinically relevant coronary anatomy

## Confidence
- Medium confidence: The 3D Resnet-50 architecture and its advantage over 2D models is reasonably well-supported by the reported performance improvement of 23.65%. However, the small sample size and lack of external validation limit strong confidence claims.
- Low confidence: The explainability claims through Grad-CAM are weakly supported. The paper mentions the technique but provides limited evidence that the heatmaps actually highlight clinically relevant features, and there is no clinician validation of the explainability component.
- Medium confidence: The segmentation-to-classification linkage approach is conceptually sound and supported by the methodology description, but the actual performance metrics and clinical validation are not provided.

## Next Checks
1. External validation: Test the trained 3D Resnet-50 model on an independent dataset from a different institution or scanner manufacturer to assess generalizability and confirm the 71.43% accuracy is not due to overfitting on the specific dataset.

2. Clinician validation of explainability: Have experienced cardiologists review the Grad-CAM heatmaps alongside the classification results to determine if the highlighted regions correspond to actual coronary artery pathology and if the explanations improve clinical trust in the model.

3. Ablation study of architectural components: Systematically remove the 3D components, Grad-CAM, and segmentation linkage to quantify the individual contribution of each component to overall performance, helping to identify which innovations provide the most value.