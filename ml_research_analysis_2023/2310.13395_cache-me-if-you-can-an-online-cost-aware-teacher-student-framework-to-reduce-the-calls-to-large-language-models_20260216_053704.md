---
ver: rpa2
title: 'Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce
  the Calls to Large Language Models'
arxiv_id: '2310.13395'
source_url: https://arxiv.org/abs/2310.13395
tags:
- teacher
- student
- instances
- incoming
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: OCaTS reduces LLM API costs by caching responses and training a
  local model. It uses reliability criteria (entropy, distance to cached instances)
  to decide when to trust the student vs.
---

# Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models

## Quick Facts
- arXiv ID: 2310.13395
- Source URL: https://arxiv.org/abs/2310.13395
- Reference count: 25
- Reduces LLM API costs by 67% while maintaining accuracy with <0.4% loss using GPT-4 + k-NN

## Executive Summary
OCaTS introduces a framework that reduces costly calls to large language models by caching responses and training a local student model. The framework uses reliability criteria (entropy and distance metrics) to determine when to trust the student model versus calling the expensive teacher LLM. With GPT-4 and k-NN, calls drop to one-third of total while maintaining near-original accuracy. The approach generalizes across different teacher/student model combinations and tasks, offering a practical solution for cost reduction in LLM-based applications.

## Method Summary
The framework consists of three components: a teacher (typically a resource-intensive LLM), a student (a cost-effective local model), and a cache storing processed instances. When an incoming instance arrives, the student model attempts classification first. If its output meets reliability criteria based on entropy and distance to cached examples, the cached response is used; otherwise, the teacher LLM is called and its response is cached. The framework introduces discounted accuracy as a metric that penalizes teacher calls, enabling optimization of the tradeoff between cost and performance. Reliability thresholds are tuned via Bayesian optimization on development sets for different cost-sensitivity levels (λ values).

## Key Results
- Reduces teacher calls to 1/3 of total with <0.4% accuracy loss using GPT-4 + k-NN
- Similar results achieved with GPT-3.5 + MLP on sentiment analysis task
- Framework generalizes across different model combinations and tasks
- Discounted accuracy effectively quantifies cost-performance tradeoffs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework reduces LLM API calls by caching responses and training a local model
- Mechanism: When an incoming instance is processed, the student model attempts to classify it first. If the student's output is deemed reliable based on entropy and distance criteria, the cached response is used; otherwise, the teacher LLM is called and its response is cached for future use
- Core assumption: Similar customer inputs occur frequently enough to justify caching and student training
- Evidence anchors:
  - [abstract] "We propose a framework that allows reducing the calls to LLMs by caching previous LLM responses and using them to train a local inexpensive model"
  - [section] "OCaTS consists of three main components: a teacher, typically a resource-intensive model offering premium results; a student, a cost-effective model that is typically much smaller and simpler than the teacher; a cache, a repository of incoming instances that have already been processed by the teacher"
- Break condition: If customer inputs become too diverse or infrequent, the cache becomes ineffective and student accuracy drops below the reliability threshold

### Mechanism 2
- Claim: Discounted accuracy quantifies the tradeoff between performance and cost
- Mechanism: The framework introduces a discounted evaluation measure that subtracts a cost penalty (λ · ρ) from the standard accuracy, where ρ is the proportion of instances requiring teacher calls
- Core assumption: SMEs can quantify the relative importance of accuracy vs. cost in terms of a single parameter λ
- Evidence anchors:
  - [abstract] "The framework includes criteria for deciding when to trust the local model or call the LLM, and a methodology to tune the criteria and measure the tradeoff between performance and cost"
  - [section] "We introduce a discounted variant ˆϕ of any common evaluation measure ϕ... where N is the number of incoming instances that have been processed... M is the number of calls made to the teacher... λ is a scalar specifying how intensively the measure should be discounted"
- Break condition: If the relationship between cost and accuracy degradation is non-linear or varies across different ranges of ρ, the constant λ assumption breaks down

### Mechanism 3
- Claim: The reliability criteria ensure student responses are trustworthy before bypassing the teacher
- Mechanism: Two criteria are used: (1) the entropy of the student's probability distribution must be below a threshold, and (2) the cosine distance between the incoming instance and cached instances must be below another threshold
- Core assumption: Low entropy and small distance to cached instances indicate high confidence in the student's classification
- Evidence anchors:
  - [section] "The second criterion requires Hw to be less than a threshold tH... Intuitively, it requires the neighbors to agree on the label of the incoming instance"
  - [section] "The first condition is that the cosine distance between the (MPNet-based) vector representation of the incoming message and the weighted centroid vector c of the k nearest neighbors should be less than a threshold tc"
- Break condition: If the student model's confidence is poorly calibrated or the embedding space doesn't preserve semantic similarity well, these criteria may fail to identify unreliable predictions

## Foundational Learning

- Concept: Distance-weighted k-NN classification
  - Why needed here: The student model uses distance-weighted k-NN to classify incoming instances based on similarity to cached examples
  - Quick check question: How does the weight of each neighbor get calculated in distance-weighted k-NN?

- Concept: Entropy as a measure of prediction confidence
  - Why needed here: Entropy of the student's probability distribution is used as one criterion to assess whether the prediction is reliable enough to trust
  - Quick check question: What does a high entropy value indicate about the student's confidence in its prediction?

- Concept: In-context learning with LLMs
  - Why needed here: The teacher LLM uses few-shot in-context learning to classify instances, requiring careful prompt construction with demonstrators
  - Quick check question: What components are typically included in a prompt for few-shot in-context learning?

## Architecture Onboarding

- Component map:
  - Incoming instance -> Student prediction -> Reliability check -> (Pass: use student response / Fail: call teacher) -> (Teacher called: cache response)

- Critical path: Incoming instance → Student prediction → Reliability check → (Pass: use student response / Fail: call teacher) → (Teacher called: cache response)

- Design tradeoffs:
  - Student model complexity vs. accuracy: Simpler models are cheaper but less accurate
  - Cache size vs. storage costs: Larger caches improve student performance but require more storage
  - Threshold tuning vs. reliability: Tighter thresholds reduce errors but increase teacher calls

- Failure signatures:
  - High teacher call rate: Student reliability criteria too strict or student model too weak
  - Low accuracy: Student model not trained adequately or reliability criteria not properly tuned
  - Cache not growing: Incoming instances too diverse or teacher responses not being cached properly

- First 3 experiments:
  1. Test the student model on cached instances to establish baseline accuracy
  2. Run a small stream of incoming instances with relaxed reliability thresholds to observe teacher call patterns
  3. Tune the reliability thresholds using a development set to optimize the discounted accuracy metric

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would different student model architectures beyond k-NN and MLP perform in the OCaTS framework?
- Basis in paper: [explicit] The paper states "We leave other instantiations of OCaTS (other teachers, students, tasks, representations) for future work."
- Why unresolved: The experiments only tested k-NN and MLP classifiers, leaving performance of other architectures unexplored.
- What evidence would resolve it: Experiments comparing OCaTS performance with student models like transformers, decision trees, or ensemble methods on the same tasks and datasets.

### Open Question 2
- Question: How do varying exchange rates λ across different accuracy ranges affect the tradeoff between cost savings and performance?
- Basis in paper: [explicit] The paper notes "We implicitly assume that the exchange rate λ is constant for all the values of δ and ρ" but acknowledges this may not be realistic.
- Why unresolved: The current discounted accuracy measure uses a fixed λ, which may not reflect real-world cost-accuracy relationships.
- What evidence would resolve it: Experiments testing variable λ values based on accuracy ranges or implementing adaptive λ policies that adjust based on cache state.

### Open Question 3
- Question: How would incorporating student model costs and other financial metrics into the discounted evaluation measures affect OCaTS performance?
- Basis in paper: [explicit] The paper mentions "A more detailed analysis would also incorporate the student cost and other financial metrics possibly with different weights; OCaTS can be easily extended in that direction."
- Why unresolved: Current experiments only consider LLM call costs, not the computational costs of running the student model.
- What evidence would resolve it: Comparative experiments measuring total cost (LLM calls + student inference) and its impact on optimal threshold tuning and λ selection.

## Limitations
- Framework performance degrades when incoming queries diverge significantly from cached examples
- Fixed threshold assumption may not reflect real-world cost-accuracy relationships across different ranges
- Long-term performance in production with evolving data distributions remains unexplored

## Confidence
**High confidence**: The core framework architecture and basic mechanism of caching teacher responses to train a student model is well-established and the experimental results show consistent improvements in cost reduction while maintaining accuracy. The mathematical formulation of discounted accuracy is straightforward and verifiable.

**Medium confidence**: The specific reliability criteria (entropy and distance thresholds) work as described, but their effectiveness may vary significantly across different domains and data distributions. The assumption that distance-weighted k-NN classification is sufficient for the student model may not generalize to all task types.

**Low confidence**: The long-term performance of the framework in production environments with evolving data distributions is unclear. The framework's behavior under extreme conditions (e.g., cache saturation, concept drift, or adversarial inputs) has not been thoroughly explored.

## Next Checks
1. **Distribution Shift Test**: Evaluate the framework's performance when the distribution of incoming instances gradually shifts away from the cached examples. Measure how quickly the student model's accuracy degrades and how the framework responds to this drift.

2. **Cache Efficiency Analysis**: Conduct a detailed analysis of cache hit rates and the relationship between cache size and student model performance. Identify the point of diminishing returns where adding more cached instances provides minimal improvement.

3. **Adversarial Robustness Evaluation**: Test the framework's reliability when faced with adversarial inputs designed to trigger false positives in the reliability criteria, potentially causing unnecessary teacher calls or, conversely, bypassing the teacher when student predictions are unreliable.