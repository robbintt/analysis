---
ver: rpa2
title: Open-World Lifelong Graph Learning
arxiv_id: '2310.12565'
source_url: https://arxiv.org/abs/2310.12565
tags:
- graph
- detection
- learning
- datasets
- homophily
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of lifelong graph learning in
  open-world settings, where a model must handle new tasks and potentially unknown
  classes. The authors propose combining existing out-of-distribution (OOD) detection
  methods with graph structure information to identify new classes in evolving graphs.
---

# Open-World Lifelong Graph Learning

## Quick Facts
- arXiv ID: 2310.12565
- Source URL: https://arxiv.org/abs/2310.12565
- Reference count: 40
- Key outcome: Combines OOD detection with graph structure for lifelong learning on evolving graphs

## Executive Summary
This paper addresses lifelong graph learning in open-world settings where models must handle new tasks and potentially unknown classes. The authors propose GOOD, a meta-method that propagates OOD scores through graph neighborhoods based on homophily, and Open-WRF, a weakly-supervised threshold determination method that reduces sensitivity to OOD detection thresholds. Experiments on six benchmark datasets with four GNN models and three OOD detectors show that GOOD consistently improves OOD detection performance, especially on homophilic graphs, while Open-WRF demonstrates robustness to threshold selection.

## Method Summary
The method combines existing OOD detection approaches with graph structure information to identify new classes in evolving graphs. GOOD aggregates OOD scores from neighboring vertices using a weighted average, leveraging the homophily assumption that connected vertices share class membership. Open-WRF implements a weakly supervised linear classifier on raw OOD scores, using pseudo-labels based on domain knowledge to determine robust thresholds. The approach is compatible with arbitrary GNNs and OOD detectors, making it versatile for real-world applications.

## Key Results
- GOOD consistently improves OOD detection performance on homophilic graphs across all tested datasets
- Open-WRF method demonstrates robustness to threshold selection with reduced sensitivity to hyperparameter q
- The aggregation and threshold methods work with arbitrary GNNs (GCN, GAT, GraphSAGE, Graph-MLP) and OOD detectors (ODIN, IsoMax+, gDOC)

## Why This Works (Mechanism)

### Mechanism 1
GOOD improves OOD detection by propagating OOD scores through graph neighborhoods based on homophily. The method aggregates scores from neighboring vertices and combines them with the vertex's own score using a weighted average. The assumption is that vertices with edges are more likely to share the same class, so neighbors' OOD scores provide valuable context. This breaks down on heterophilic graphs where connected vertices are less likely to belong to the same class.

### Mechanism 2
Open-WRF provides robust threshold determination by using weakly-supervised learning on pseudo-labeled data. The method uses a domain-interpretable hyperparameter q to create pseudo-labels for OOD detection (top q% as OOD, rest as ID), then trains a simple classifier on these labels to determine robust thresholds. This approach decreases sensitivity to threshold selection but requires reasonable estimation of q based on domain knowledge about expected new class ratios.

### Mechanism 3
GOOD's neighborhood aggregation parameter αOOD can be optimized to balance individual and neighbor information for improved OOD detection. The hyperparameter controls the trade-off between using a vertex's own OOD score versus aggregated neighbor scores. Optimal values typically range from 0.2 to 0.6, balancing local and neighborhood information. Extreme values either ignore neighborhood information entirely or completely rely on neighbors, potentially missing important individual signals.

## Foundational Learning

- **Graph Neural Networks and message passing**: Why needed - The entire approach builds on GNN representations and leverages graph structure for OOD detection. Quick check - How does a GCN update vertex representations using neighbor information?
- **Out-of-Distribution detection principles**: Why needed - The method combines existing OOD detection approaches with graph structure, requiring understanding of both. Quick check - What's the difference between post-hoc and a-priori OOD detection methods?
- **Homophily in graphs**: Why needed - GOOD's effectiveness depends on the assumption that connected vertices share similar properties. Quick check - How would you measure homophily in a graph, and what values indicate high versus low homophily?

## Architecture Onboarding

- **Component map**: Base GNN model (GCN, GAT, GraphSAGE, or Graph-MLP) -> OOD detector (ODIN, IsoMax+, gDOC) -> GOOD meta-method for neighborhood aggregation -> Open-WRF threshold determination module -> Dataset loader and preprocessing pipeline
- **Critical path**: 1) Train base GNN model on training data 2) Apply OOD detector to get initial scores 3) Apply GOOD to aggregate scores with neighborhood information 4) Apply Open-WRF to determine robust thresholds 5) Evaluate OOD detection performance
- **Design tradeoffs**: GOOD vs. direct OOD detection (GOOD leverages graph structure but requires homophily; direct methods work on any data but miss structural information); Open-WRF vs. fixed thresholds (Open-WRF is more robust but requires additional training; fixed thresholds are simpler but less adaptive); Neighborhood size in GOOD (larger neighborhoods provide more context but increase computation and may dilute signals)
- **Failure signatures**: Low AUROC scores despite good base GNN performance (likely homophily assumption violated or αOOD poorly tuned); Open-WRF performs worse than fixed threshold (q poorly estimated or OOD scores poorly calibrated); GOOD degrades performance (may indicate heterophilic graph structure or improper αOOD value)
- **First 3 experiments**: 1) Apply ODIN directly to Cora dataset and measure baseline AUROC 2) Apply GOOD with ODIN on Cora and compare AUROC improvement 3) Apply Open-WRF with GOOD+ODIN on Cora and compare threshold robustness to fixed threshold approach

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several areas remain unexplored based on the methodology and results presented.

## Limitations
- GOOD's effectiveness is fundamentally constrained by graph homophily assumptions, breaking down on heterophilic graphs like dblp-hard
- Open-WRF requires domain knowledge for the q parameter, which may not be readily available in all applications
- Both methods introduce additional hyperparameters (αOOD for GOOD, q for Open-WRF) that require tuning for optimal performance

## Confidence

- **High Confidence**: The core mechanism of combining OOD scores with graph neighborhood information (GOOD) is theoretically sound and supported by empirical results on homophilic datasets
- **Medium Confidence**: The Open-WRF threshold determination method's robustness to hyperparameter selection is demonstrated but may depend heavily on dataset characteristics
- **Medium Confidence**: The claim of consistent improvements across all six datasets is supported but shows significant variation in effect size between homophilic and heterophilic graphs

## Next Checks

1. **Heterophily Stress Test**: Evaluate GOOD on extreme heterophilic graphs to quantify performance degradation when the homophily assumption fails
2. **Hyperparameter Sensitivity Analysis**: Systematically test αOOD values across the full [0,1] range and q values spanning orders of magnitude to map the stability regions
3. **Cross-Dataset Transferability**: Train Open-WRF thresholds on one dataset type (e.g., Cora) and evaluate on different dataset types (e.g., dblp-hard) to assess generalizability of threshold determination