---
ver: rpa2
title: Revisiting and Advancing Adversarial Training Through A Simple Baseline
arxiv_id: '2306.07613'
source_url: https://arxiv.org/abs/2306.07613
tags:
- adversarial
- training
- robust
- accuracy
- simpleat
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SimpleAT, a simple yet effective adversarial
  training method that achieves state-of-the-art results on CIFAR-10, CIFAR-100, and
  SVHN. SimpleAT employs a training protocol that integrates rescaled square loss,
  cyclic learning rates, and erasing-based data augmentation.
---

# Revisiting and Advancing Adversarial Training Through A Simple Baseline

## Quick Facts
- arXiv ID: 2306.07613
- Source URL: https://arxiv.org/abs/2306.07613
- Reference count: 9
- Primary result: SimpleAT achieves 52.3% adversarial accuracy on CIFAR-10 and 55.95% on CIFAR-100 against AutoAttack

## Executive Summary
This paper introduces SimpleAT, a simple yet effective adversarial training method that achieves state-of-the-art results on CIFAR-10, CIFAR-100, and SVHN. SimpleAT employs a training protocol that integrates rescaled square loss, cyclic learning rates, and erasing-based data augmentation. The key insights are: (1) using square loss instead of cross-entropy loss improves robustness; (2) cyclic learning rates reduce robust overfitting; and (3) rescaled square loss achieves a favorable balance between adversarial and natural accuracy. SimpleAT consistently outperforms existing methods, achieving 52.3% adversarial accuracy on CIFAR-10 and 55.95% on CIFAR-100 against AutoAttack. The authors also show that SimpleAT reduces the variance in model predictions, which is a primary contributor to robust overfitting.

## Method Summary
SimpleAT is an adversarial training protocol that combines three key techniques: rescaled square loss (RSL), cyclic learning rates, and erasing-based data augmentation (IDBH). RSL minimizes both the L2-norm of logit features and classification error, preventing overconfidence while maintaining high accuracy on clean data. Cyclic learning rates smooth training dynamics and prevent convergence to sharp minima susceptible to adversarial perturbations. IDBH augmentation further reduces variance in predictions and improves robustness. The method uses SGD with momentum (0.9), weight decay (5e-4), and is evaluated on CIFAR-10/100, SVHN, and Tiny-ImageNet.

## Key Results
- SimpleAT achieves 52.3% adversarial accuracy on CIFAR-10 against AutoAttack
- SimpleAT achieves 55.95% adversarial accuracy on CIFAR-100 against AutoAttack
- SimpleAT reduces variance in model predictions, mitigating robust overfitting

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Using square loss instead of cross-entropy loss reduces robust overfitting by lowering model variance.
- **Mechanism:** Square loss inherently penalizes large logit values, which prevents the model from becoming overconfident on adversarial examples. This reduces the variance in predictions and stabilizes training.
- **Core assumption:** Lower variance in model predictions correlates with reduced robust overfitting.
- **Evidence anchors:**
  - [abstract] "SimpleAT exhibits good performance in the presence of various image corruptions... SimpleAT is capable of reducing the variance in model predictions, which is considered the primary contributor to robust overfitting."
  - [section] "Our findings demonstrate that all of these simple techniques are capable of reducing the variance of model predictions, which is regarded as the primary contributor to robust overfitting."
  - [corpus] Weak: The corpus neighbors do not directly address variance reduction or square loss, so this anchor is not supported.
- **Break condition:** If the variance in predictions does not correlate with overfitting, or if overconfidence is not the root cause of robust overfitting.

### Mechanism 2
- **Claim:** Cyclic learning rates mitigate robust overfitting by smoothing the training dynamics and preventing the model from converging too quickly to a fragile solution.
- **Mechanism:** The one-cycle learning rate schedule allows the model to explore the parameter space more thoroughly, avoiding sharp minima that are susceptible to adversarial perturbations. This leads to smoother loss curves and better generalization.
- **Core assumption:** Smooth training dynamics and avoidance of sharp minima improve robustness.
- **Evidence anchors:**
  - [abstract] "One cyclic learning rate is a good scheduler, which can effectively reduce the risk of robust overfitting."
  - [section] "We find that combing cyclic learning rates with either erasing-based data augmentations or square loss can reduce robust overfitting while achieving comparable performance."
  - [corpus] Weak: The corpus neighbors do not provide evidence for the effectiveness of cyclic learning rates in mitigating robust overfitting.
- **Break condition:** If cyclic learning rates do not prevent convergence to sharp minima or if they fail to smooth training dynamics.

### Mechanism 3
- **Claim:** Rescaled square loss achieves a favorable balance between adversarial and natural accuracy by adaptively constraining logit features.
- **Mechanism:** The rescaled square loss (RSL) minimizes both the L2-norm of the logit features and the classification error, which prevents overconfidence and maintains high accuracy on clean data while improving robustness.
- **Core assumption:** Constraining logit features improves the trade-off between accuracy and robustness.
- **Evidence anchors:**
  - [abstract] "Employing rescaled square loss during model training can yield a favorable balance between adversarial and natural accuracy."
  - [section] "We argue that the primary distinction from CEL lies within the first item and the effect of RSL is due to its adaptive constraint on the L2-norm of logit features."
  - [corpus] Weak: The corpus neighbors do not discuss the specific impact of rescaled square loss on the accuracy-robustness trade-off.
- **Break condition:** If constraining logit features does not improve the trade-off or if it degrades performance on clean data.

## Foundational Learning

- **Concept:** Adversarial training and its formulation as a min-max optimization problem.
  - **Why needed here:** Understanding the basic adversarial training setup is essential to grasp how SimpleAT modifies the training protocol.
  - **Quick check question:** What is the difference between PGD-AT and FGSM-AT in terms of how they generate adversarial examples?

- **Concept:** Bias-variance decomposition in the context of adversarial training.
  - **Why needed here:** The paper uses bias-variance decomposition to explain why SimpleAT reduces robust overfitting, so understanding this concept is crucial.
  - **Quick check question:** How does reducing variance in model predictions help mitigate robust overfitting?

- **Concept:** Logit penalty methods and their role in preventing overconfidence.
  - **Why needed here:** SimpleAT is compared to logit penalty methods, and understanding these methods helps explain why RSL is effective.
  - **Quick check question:** What is the difference between logit penalty and logit normalization in terms of how they constrain logit features?

## Architecture Onboarding

- **Component map:** Loss function: Cross-entropy loss (CEL) → Square loss (OSL) → Rescaled square loss (RSL) → Learning rate schedule: Piecewise decay → One-cycle learning rate → Data augmentation: Standard augmentation → Erasing-based augmentation (IDBH) → Model architecture: ResNet-18 (primary), WideResNet (secondary) → Adversarial attack generation: PGD-attack (10-step) for PGD-AT, NFGSM-attack for FGSM-AT

- **Critical path:**
  1. Replace CEL with RSL to reduce overconfidence and variance.
  2. Implement one-cycle learning rate to smooth training dynamics.
  3. Use IDBH data augmentation to further reduce variance and improve robustness.
  4. Evaluate performance on CIFAR-10/100, SVHN, and Tiny-ImageNet.
  5. Compare results against state-of-the-art methods and analyze bias-variance decomposition.

- **Design tradeoffs:**
  - Using RSL may slightly reduce natural accuracy compared to CEL, but it significantly improves robustness.
  - One-cycle learning rate may require more epochs to converge, but it prevents robust overfitting.
  - IDBH data augmentation improves robustness but may increase training time.

- **Failure signatures:**
  - If the model still suffers from robust overfitting, check if the learning rate schedule is correctly implemented.
  - If the natural accuracy drops significantly, verify that the RSL parameters (k and M) are properly tuned.
  - If the model is not robust against strong attacks, ensure that the adversarial examples are generated correctly during training.

- **First 3 experiments:**
  1. Replace CEL with OSL and observe the impact on robust overfitting and accuracy.
  2. Implement one-cycle learning rate and compare the training dynamics and final performance with piecewise decay.
  3. Add IDBH data augmentation and evaluate its effect on both natural and adversarial accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does SimpleAT perform on larger and more diverse datasets beyond CIFAR and SVHN, such as ImageNet?
- Basis in paper: [inferred] The paper focuses on CIFAR-10, CIFAR-100, and SVHN, with some mention of Tiny-ImageNet. It suggests that SimpleAT's effectiveness on larger datasets is untested.
- Why unresolved: The paper does not provide empirical evidence for SimpleAT's performance on larger, more complex datasets like ImageNet.
- What evidence would resolve it: Experiments demonstrating SimpleAT's performance on ImageNet or similar large-scale datasets, comparing it to state-of-the-art methods.

### Open Question 2
- Question: What is the theoretical foundation for why cyclic learning rates and square loss specifically improve adversarial robustness and reduce overfitting?
- Basis in paper: [explicit] The paper mentions that cyclic learning rates and square loss contribute to robustness, but does not provide a deep theoretical explanation.
- Why unresolved: While empirical results show benefits, the paper lacks a comprehensive theoretical analysis of the underlying mechanisms.
- What evidence would resolve it: A theoretical framework or proof explaining how cyclic learning rates and square loss interact with adversarial training dynamics to improve robustness.

### Open Question 3
- Question: What is the impact of SimpleAT on model calibration and confidence estimates, especially under adversarial attacks?
- Basis in paper: [explicit] The paper mentions that SimpleAT reduces variance in model predictions, which is linked to robust overfitting, but does not delve into calibration specifics.
- Why unresolved: While variance reduction is noted, the paper does not provide a detailed analysis of how SimpleAT affects model calibration and confidence under adversarial conditions.
- What evidence would resolve it: Empirical studies measuring calibration metrics (e.g., Expected Calibration Error) and confidence distributions under various attack scenarios for models trained with SimpleAT.

## Limitations
- The effectiveness of cyclic learning rates in preventing robust overfitting needs further validation across different architectures and datasets
- The rescaling parameter M in RSL is set to 1 empirically without theoretical justification for this specific value
- The variance reduction claims rely heavily on bias-variance decomposition, but the paper doesn't fully establish that variance reduction is the primary mechanism behind improved robustness

## Confidence

- **High confidence**: SimpleAT's empirical performance improvements over baselines on CIFAR-10/100 and SVHN
- **Medium confidence**: The variance reduction mechanism as the primary driver of robust overfitting mitigation
- **Medium confidence**: The effectiveness of RSL in balancing accuracy and robustness

## Next Checks
1. Test SimpleAT with different M values (e.g., 0.5, 2) in the rescaled square loss to determine optimal scaling and validate if M=1 is truly optimal
2. Apply SimpleAT to a more diverse set of architectures (e.g., EfficientNet, ConvNext) and datasets (e.g., ImageNet) to verify generalizability
3. Conduct ablation studies removing cyclic learning rates while keeping RSL and IDBH to isolate their individual contributions to robustness improvements