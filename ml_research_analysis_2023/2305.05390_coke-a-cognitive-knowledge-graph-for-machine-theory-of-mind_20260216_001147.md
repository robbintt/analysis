---
ver: rpa2
title: 'COKE: A Cognitive Knowledge Graph for Machine Theory of Mind'
arxiv_id: '2305.05390'
source_url: https://arxiv.org/abs/2305.05390
tags:
- cognitive
- situation
- coke
- thought
- generation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces COKE, the first cognitive knowledge graph
  for machine theory of mind (ToM). COKE instantiates ToM as 45k+ manually verified
  cognitive chains, each containing five node types: situation, clue, thought, action,
  and emotion, labeled with positive or negative polarity.'
---

# COKE: A Cognitive Knowledge Graph for Machine Theory of Mind

## Quick Facts
- arXiv ID: 2305.05390
- Source URL: https://arxiv.org/abs/2305.05390
- Reference count: 12
- Primary result: Introduces COKE, a cognitive knowledge graph with 45k+ manually verified cognitive chains, and COKE+, a T5-based model for machine theory of mind reasoning.

## Executive Summary
This paper introduces COKE, the first cognitive knowledge graph for machine theory of mind (ToM), instantiated as 45k+ manually verified cognitive chains linking situations, clues, thoughts, actions, and emotions. To extend ToM to unseen scenarios, the authors train COKE+, a T5-based controllable generation model, on COKE data to predict cognitive chains in four tasks: clue, thought, action, and emotion generation. Automatic and human evaluations show that COKE+ significantly outperforms T5-base and InstructGPT on all tasks, demonstrating strong ToM ability and validating the quality of COKE. The work enables AI systems to infer human mental states and behavioral/affective responses in social contexts.

## Method Summary
The authors construct COKE by prompting InstructGPT to generate raw cognitive chains (situation, clue, thought, action, emotion) from 400 ATOMIC events expanded to 2000 situations, then manually filtering and revising the outputs with 8 trained annotators to obtain 45k+ cognitive chains. They split 1200 situations into 1080 train/120 validation sets. COKE+ is built by finetuning T5-base (220M params) on the decomposed four tasks (clue, thought, action, emotion generation) using special tokens for polarity control. The model is evaluated on the validation set using BLEU scores for generation tasks and accuracy for emotion classification, plus human evaluation on a 3-point Likert scale.

## Key Results
- COKE+ significantly outperforms T5-base and InstructGPT on all four cognitive generation tasks (clue, thought, action, emotion) in automatic BLEU evaluation.
- COKE+ achieves strong emotion classification accuracy, demonstrating effective polarity control.
- Human evaluation confirms that cognitive chains generated by COKE+ are more acceptable and cognitively plausible than baseline models.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: COKE enables AI systems to perform Theory of Mind reasoning by providing a structured graph of human cognitive chains.
- Mechanism: The graph encodes social situations as nodes linked through causal cognitive chains (situation→clue→thought→action/emotion), allowing models to infer mental states and behavioral/affective responses.
- Core assumption: Human mental processes can be formalized as deterministic sequences of cognitive nodes that are learnable by AI systems.
- Evidence anchors:
  - [abstract] "COKE formalizes ToM as a collection of 45k+ manually verified cognitive chains"
  - [section 2.3] "We instantiate ToM with a total of 45,369 cognitive chains in COKE"
  - [corpus] Weak - no direct corpus evidence linking graph structure to model performance
- Break condition: If human cognitive processes are too context-dependent or probabilistic to be captured in fixed chains, the graph would fail to generalize.

### Mechanism 2
- Claim: COKE+ extends ToM reasoning to unseen situations by finetuning a language model on the structured COKE data.
- Mechanism: Decomposing cognitive chains into four generation tasks (clue, thought, action, emotion) allows T5 to learn task-specific mappings and controllable generation via special tokens.
- Core assumption: Language models can internalize structured cognitive patterns when trained on decomposed, labeled data.
- Evidence anchors:
  - [section 3.2] "COKE+ is built as a standard encoder-decoder architecture and initialized with the pre-trained language model T5-base"
  - [section 4.2] "COKE+ exhibits a huge performance boost for cognitive generation tasks of ToM"
  - [corpus] Weak - no evidence of how task decomposition specifically aids learning
- Break condition: If the generation tasks are too interdependent or the controllable tokens are ineffective, the model may fail to produce coherent chains.

### Mechanism 3
- Claim: Human evaluation confirms that COKE+ generates more acceptable cognitive chains than baseline models.
- Mechanism: By sampling cognitive chains for validation situations and scoring them on a Likert scale, the model's output quality is measured against human judgment.
- Core assumption: Human perception of cognitive plausibility correlates with model performance.
- Evidence anchors:
  - [section 4.3] "The results in Table 4 demonstrate that the cognitive chains generated by COKE+ are more acceptable to humans"
  - [section 4.2] "COKE+, which is designed as a controllable generative model for multiple cognitive tasks, can effectively internalize the ToM ability"
  - [corpus] Weak - no external validation of human evaluation criteria
- Break condition: If human raters are inconsistent or biased, the evaluation may not reflect true model capability.

## Foundational Learning

- Concept: Theory of Mind (ToM)
  - Why needed here: ToM is the target cognitive ability being modeled; understanding its definition and mechanisms is essential for interpreting COKE's purpose.
  - Quick check question: What are the five node types in a COKE cognitive chain and what does each represent?
- Concept: Knowledge graph construction
  - Why needed here: COKE is instantiated as a structured graph; knowing how nodes, edges, and chains are defined is key to understanding its architecture.
  - Quick check question: How are the polarity (positive/negative) of cognitive chains determined in COKE?
- Concept: Controllable text generation
  - Why needed here: COKE+ uses special tokens to guide generation; understanding how controllable generation works is necessary to grasp the model's design.
  - Quick check question: What role do special tokens like [NegClue] play in COKE+ generation?

## Architecture Onboarding

- Component map:
  - InstructGPT -> Raw cognitive chain generation
  - Human annotators -> Data curation and revision
  - COKE -> Structured cognitive knowledge graph
  - T5-base -> Backbone model for COKE+
  - COKE+ -> Controllable generative model for cognitive chain prediction

- Critical path:
  1. Prompt InstructGPT to generate raw nodes (situations, clues, thoughts, actions, emotions)
  2. Human annotators select and revise data into COKE
  3. Decompose COKE into four generation tasks
  4. Finetune T5-base (COKE+) on decomposed data
  5. Evaluate on unseen situations via automatic and human metrics

- Design tradeoffs:
  - Using InstructGPT for data collection speeds up process but risks low-quality outputs, mitigated by human revision.
  - Decomposing into four tasks simplifies training but may lose inter-task dependencies.
  - Restricting emotions to six categories simplifies classification but limits expressiveness.

- Failure signatures:
  - Poor BLEU scores indicate generation quality issues.
  - Low human evaluation scores suggest outputs are not cognitively plausible.
  - High retention rate in data collection suggests good initial quality; low rate signals need for better prompts or annotator training.

- First 3 experiments:
  1. Train COKE+ on full COKE without task decomposition and compare BLEU scores.
  2. Replace T5-base with a larger model (e.g., T5-large) and measure performance gains.
  3. Evaluate COKE+ on a held-out set of situations from underrepresented topics to test generalization.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of COKE+ compare when using larger backbone models like GPT-3 or GPT-4 instead of T5-base?
- Basis in paper: [inferred] The paper mentions that COKE+ is built on T5-base and acknowledges that adopting larger backbone models could contribute to a more powerful inference model, but does not explore this.
- Why unresolved: The paper only experiments with T5-base and does not investigate the impact of using larger language models as the backbone for COKE+.
- What evidence would resolve it: Conducting experiments with COKE+ using larger language models like GPT-3 or GPT-4 and comparing their performance to T5-base.

### Open Question 2
- Question: How well does COKE+ generalize to out-of-domain situations that are significantly different from the social topics covered in COKE?
- Basis in paper: [inferred] The paper acknowledges that COKE has a relatively small data scale and cannot cover all situations in deployment, which may lead to unreliable predictions in out-of-domain situations.
- Why unresolved: The paper does not evaluate COKE+ on out-of-domain situations or provide insights into its performance in such scenarios.
- What evidence would resolve it: Testing COKE+ on a diverse set of out-of-domain situations and analyzing its performance and generalization capabilities.

### Open Question 3
- Question: How does the quality and diversity of the cognitive chains generated by COKE+ compare to those generated by human experts in various social contexts?
- Basis in paper: [inferred] The paper conducts human evaluation on the cognitive chains generated by COKE+, but does not compare them to chains generated by human experts.
- Why unresolved: The paper does not provide a direct comparison between the cognitive chains generated by COKE+ and those generated by human experts, leaving the question of relative quality and diversity unanswered.
- What evidence would resolve it: Conducting a study where human experts generate cognitive chains for the same set of situations and comparing the quality and diversity of the chains generated by COKE+ and the human experts.

## Limitations
- The manual construction of COKE relies on the quality and representativeness of the 45k+ cognitive chains, with no analysis of diversity or potential annotation biases.
- The controllable generation approach using special tokens is innovative but lacks ablation studies to confirm their necessity or effectiveness.
- The evaluation setup, while combining automatic and human metrics, does not include external validation on truly held-out scenarios or comparison with domain experts beyond the initial annotation phase.

## Confidence

- **High confidence**: The methodology for constructing COKE (manual annotation of InstructGPT outputs) is clearly described and reproducible. The decomposition of cognitive chains into four generation tasks is explicitly defined and implemented.

- **Medium confidence**: The reported performance improvements of COKE+ over T5-base and InstructGPT are based on provided metrics, but the evaluation lacks depth in terms of error analysis, cross-dataset validation, or comparison with alternative model architectures.

- **Low confidence**: The generalizability of COKE to truly unseen or diverse social scenarios is not thoroughly tested. The human evaluation, while mentioned, lacks detail on rater training, inter-rater reliability, or potential cultural/contextual biases in the cognitive chains.

## Next Checks

1. **Error Analysis and Bias Audit**: Conduct a detailed error analysis of COKE+ outputs to identify systematic failures (e.g., overgeneralization, cultural bias). Audit the COKE graph for diversity in situations, emotions, and cognitive patterns to ensure broad coverage.

2. **External Generalization Test**: Evaluate COKE+ on a held-out set of situations from underrepresented topics or from a different cultural context to assess true generalization beyond the training distribution.

3. **Ablation Study on Controllable Generation**: Remove the polarity tokens and retrain COKE+ to measure the impact on generation quality and task performance, confirming whether the controllable generation mechanism is essential.