---
ver: rpa2
title: 'Crowdotic: A Privacy-Preserving Hospital Waiting Room Crowd Density Estimation
  with Non-speech Audio'
arxiv_id: '2309.10280'
source_url: https://arxiv.org/abs/2309.10280
tags:
- audio
- occupancy
- privacy
- non-speech
- speech
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Crowdotic, a privacy-preserving system for
  estimating crowd density in hospital waiting rooms using non-speech audio. The system
  employs a transformer-based model trained on non-speech audio captured via a microphone
  array, with speech detection performed on-device to ensure privacy.
---

# Crowdotic: A Privacy-Preserving Hospital Waiting Room Crowd Density Estimation with Non-speech Audio

## Quick Facts
- arXiv ID: 2309.10280
- Source URL: https://arxiv.org/abs/2309.10280
- Reference count: 40
- One-line primary result: Non-speech audio achieves 0.74 correlation and 2.18 MAE for occupancy estimation while preserving privacy

## Executive Summary
This paper introduces Crowdotic, a system for estimating crowd density in hospital waiting rooms using non-speech audio captured through a microphone array. The approach employs a transformer-based model trained on non-speech audio embeddings, with on-device speech detection to ensure privacy. Over a three-month deployment in a university hospital waiting room, the system achieved superior performance compared to thermal camera-based methods, with a correlation coefficient of 0.74 and mean average error of 2.18 for minute-level occupancy estimation.

## Method Summary
Crowdotic uses a microphone array to capture audio in waiting rooms, processes it through an on-device speech detection CNN to filter out speech-containing segments, then generates embeddings using TRILL or VGGish models. A transformer encoder processes 60-second sequences of non-speech audio embeddings to predict occupancy. The system implements differential privacy through Laplace noise injection with configurable epsilon values to balance privacy and accuracy.

## Key Results
- Achieved correlation coefficient of 0.74 and MAE of 2.18 for minute-level occupancy estimation
- Outperformed thermal camera-based methods, especially for shorter time windows
- Maintained good performance even with strong privacy guarantees (epsilon values as low as 1)

## Why This Works (Mechanism)

### Mechanism 1
Non-speech audio contains sufficient acoustic signatures to reliably estimate occupancy. The transformer-based model learns temporal patterns from 60-second sequences of non-speech audio embeddings, correlating these patterns with crowd density. The core assumption is that non-speech sounds generated by human presence are consistent enough across similar environments to be predictive of occupancy.

### Mechanism 2
On-device speech detection ensures privacy by excluding speech-containing audio before storage. A CNN-based speech detection model processes each audio snippet in real-time, discarding segments with speech probability > 0.5. The core assumption is that the speech detection model achieves high accuracy in distinguishing speech from non-speech content.

### Mechanism 3
Differential privacy via Laplace mechanism adds noise to embeddings to protect against linkage attacks. For each second of audio, embeddings are clipped and perturbed with Laplace noise before transmission to backend. The core assumption is that the clipping parameter C and epsilon (ε) values provide sufficient privacy guarantees without degrading model performance.

## Foundational Learning

- **Transformer models and attention mechanisms**: Needed to process variable-length audio sequences and capture temporal dependencies between non-speech audio segments. Quick check: How does multi-head self-attention help the model learn different acoustic patterns simultaneously?

- **Differential privacy and Laplace mechanism**: Needed to provide mathematical guarantees that individual privacy is preserved when sharing occupancy data. Quick check: How does the sensitivity parameter C affect the amount of noise added for a given epsilon?

- **Speech detection and audio preprocessing**: Needed to ensure only non-speech content is used for analysis, maintaining privacy while preserving occupancy signals. Quick check: What audio features (spectrogram, MFCC) are most effective for distinguishing speech from non-speech?

## Architecture Onboarding

- **Component map**: Microphone array → Speech detection CNN → Non-speech audio buffer (60 sec) → TRILL/VGGish embedding CNN → Transformer encoder (4 layers, 8 heads) → Linear layer → Occupancy prediction

- **Critical path**: Audio capture → Speech detection → Embedding generation → Transformer processing → Occupancy output

- **Design tradeoffs**: Privacy (speech exclusion) vs. data completeness; model complexity (transformer) vs. on-device feasibility; noise injection (differential privacy) vs. prediction accuracy

- **Failure signatures**: High MAE or low correlation coefficient; excessive speech snippets passing through detection; transformer overfitting to training environment

- **First 3 experiments**:
  1. Validate speech detection accuracy on held-out audio with both speech and non-speech content
  2. Test transformer model performance with varying sequence lengths (30s, 60s, 90s)
  3. Measure occupancy estimation accuracy under different Laplace noise levels (ε = 5, 2, 1, 0.5)

## Open Questions the Paper Calls Out

### Open Question 1
What is the effect of different room acoustics and environmental conditions on the accuracy of non-speech audio-based occupancy estimation? The current study was conducted in a single hospital waiting room environment, which may have specific acoustic characteristics and occupancy patterns that do not generalize to other settings.

### Open Question 2
How does the proposed non-speech audio approach compare to other privacy-preserving sensing modalities in terms of accuracy and robustness? While the paper demonstrates superiority over some modalities, it does not directly compare the non-speech audio approach to other emerging privacy-preserving techniques like RF-based or multimodal fusion methods.

### Open Question 3
What is the optimal balance between differential privacy guarantees and system accuracy for non-speech audio-based occupancy estimation? The paper provides results for different epsilon values but does not analyze the relationship between privacy guarantees and system utility or identify an optimal privacy-accuracy balance.

## Limitations

- Tested only in a single hospital waiting room environment, limiting generalizability to other settings
- Speech detection model performance metrics are not fully specified in the corpus
- Does not address potential failure modes like equipment failure, extreme acoustic environments, or adversarial attacks

## Confidence

- Non-speech audio feasibility: Medium confidence
- Speech detection mechanism: Low confidence (lacks specific performance metrics)
- Differential privacy implementation: Medium confidence (mathematical soundness but limited empirical validation)

## Next Checks

1. Test the on-device speech detection model on a diverse dataset with varying accents, background noise levels, and speech patterns to quantify false positive/negative rates.

2. Deploy the system in at least two additional waiting room environments (different sizes, acoustic properties, and noise sources) to validate generalizability.

3. Systematically test the system across a broader range of epsilon values (ε = 10, 5, 2, 1, 0.5, 0.1) and evaluate the tradeoff between privacy guarantees and prediction utility.