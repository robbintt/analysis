---
ver: rpa2
title: Image and Data Mining in Reticular Chemistry Using GPT-4V
arxiv_id: '2312.05468'
source_url: https://arxiv.org/abs/2312.05468
tags:
- image
- gpt-4v
- data
- page
- nitrogen
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study demonstrated GPT-4V's ability to automatically analyze
  and extract data from scientific literature in reticular chemistry. A dataset of
  346 articles was converted into 6,240 page images and analyzed using carefully designed
  prompts.
---

# Image and Data Mining in Reticular Chemistry Using GPT-4V

## Quick Facts
- arXiv ID: 2312.05468
- Source URL: https://arxiv.org/abs/2312.05468
- Reference count: 35
- Primary result: GPT-4V achieved >93% accuracy and recall in identifying key characterization plots and extracted porosity parameters from over 200 compounds in reticular chemistry literature.

## Executive Summary
This study demonstrates GPT-4V's capability to automatically analyze and extract data from scientific literature in reticular chemistry. By converting 346 articles into 6,240 page images and applying carefully designed prompts, the model accurately identified key characterization plots (nitrogen isotherms, PXRD patterns, TGA curves) with accuracy and recall above 93%. The approach also enabled extraction of critical parameters from nitrogen isotherms with high precision, facilitating comparison of experimental and theoretical porosity values across compounds. This methodology shows significant potential for accelerating digital database creation in reticular chemistry and could be generalized to other scientific fields.

## Method Summary
The study employed a systematic approach where 346 scholarly articles were converted into 6,240 page images using Python scripts. GPT-4V was then used to analyze these images through carefully crafted prompts designed to classify figures into six categories and extract specific data from nitrogen isotherms. The methodology involved prompt engineering to guide the model in identifying figure types and extracting quantitative parameters like BET surface area, Langmuir surface area, and pore volume. Results were validated against ground truth data through expert review, demonstrating the model's capability for automated scientific literature analysis.

## Key Results
- GPT-4V achieved accuracy and recall above 93% in identifying key characterization plots
- Successfully extracted critical parameters from nitrogen isotherms with high precision
- Enabled comparison of experimental and theoretical porosity values for over 200 compounds
- Identified 3,537 pages lacking target plots, streamlining literature review processes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4V can accurately identify and categorize scientific plot types using natural language prompts without specialized coding or vision expertise.
- Mechanism: The model leverages pre-trained multimodal understanding to process page images alongside carefully crafted prompts, recognizing visual elements and textual context to classify plots.
- Core assumption: GPT-4V's vision capabilities can interpret scientific figures across varied formatting without task-specific fine-tuning.
- Evidence anchors: [abstract] "accuracy and recall above 93%"; [section] "These novel capabilities allow researchers from diverse backgrounds..."
- Break condition: Classification accuracy may drop below acceptable thresholds if figure styles deviate significantly from training data.

### Mechanism 2
- Claim: GPT-4V can extract quantitative and qualitative data from nitrogen isotherm plots with high precision by combining visual analysis with OCR-like text recognition.
- Mechanism: The model processes isotherm images, identifies axes, legends, and textual annotations, using this information to extract descriptors like figure numbers, compound names, and porosity values.
- Core assumption: The model's image processing pipeline can reliably parse both visual and textual elements in scientific figures.
- Evidence anchors: [abstract] "proficiency in extracting critical information"; [section] "remarkable ability to extract these details by analyzing the isotherm..."
- Break condition: Extraction accuracy may degrade if figures lack clear labels, use non-standard units, or have overlapping text.

### Mechanism 3
- Claim: GPT-4V enables rapid creation of digital databases by automating literature analysis, reducing manual review needs.
- Mechanism: Processing large volumes of literature images with prompts, the model identifies relevant pages, extracts data, and flags pages without target plots.
- Core assumption: Automation can scale efficiently without sacrificing accuracy, and the prompt-driven approach generalizes across different paper layouts.
- Evidence anchors: [abstract] "potential of AI in accelerating scientific discovery"; [section] "strategy to be applied in the future to help human researchers streamline the review process..."
- Break condition: Automation efficiency may plateau if prompt design becomes too complex or literature diversity exceeds generalization ability.

## Foundational Learning

- Concept: Multimodal understanding in large language models
  - Why needed here: GPT-4V's ability to interpret both text and images is central to analyzing scientific figures.
  - Quick check question: Can you explain how multimodal models like GPT-4V differ from traditional text-only models in processing scientific content?

- Concept: Prompt engineering for structured outputs
  - Why needed here: Carefully designed prompts guide GPT-4V in categorizing and extracting data consistently.
  - Quick check question: What are the key principles of prompt engineering that ensure accurate and reproducible model responses?

- Concept: Optical character recognition (OCR) integration
  - Why needed here: Extracting textual information from figures (e.g., axis labels, compound names) is critical for accurate data mining.
  - Quick check question: How does OCR enhance the ability of vision models to interpret scientific plots?

## Architecture Onboarding

- Component map: PDF → PNG images → Prompt generation → GPT-4V API/web interface → Response parsing → Data storage → Validation
- Critical path: Image conversion → Prompt execution → Data extraction → Quality check
- Design tradeoffs: Web interface offers ease of use but slower throughput; API enables automation but requires more setup and token management.
- Failure signatures: High misclassification rates, missing or incorrect data extraction, slow processing times, API rate limiting.
- First 3 experiments:
  1. Test GPT-4V on a small set of manually labeled scientific figures to measure classification accuracy.
  2. Validate data extraction accuracy by comparing GPT-4V outputs with ground truth for nitrogen isotherm parameters.
  3. Benchmark throughput and cost differences between web interface and API-based processing.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the accuracy of GPT-4V's classification be improved for the "other gas sorption isotherm" category?
- Basis in paper: [explicit] The paper notes that this category has lower precision due to its broad scope and occasional mislabeling of IR and NMR spectra as such.
- Why unresolved: The current prompt does not adequately instruct GPT-4V to distinguish between different types of gas sorption isotherms and other spectral data.
- What evidence would resolve it: Developing more specific prompts that clearly define characteristics of each gas sorption isotherm type and differentiate them from other spectral data would provide evidence of improved accuracy.

### Open Question 2
- Question: Can the integration of DSPy further enhance GPT-4V's performance in scientific data mining tasks?
- Basis in paper: [explicit] The paper mentions that DSPy could potentially improve the effectiveness of instructions given to GPT-4V by automating the instruction process.
- Why unresolved: The paper does not provide empirical evidence of DSPy's impact on GPT-4V's performance.
- What evidence would resolve it: Conducting experiments comparing GPT-4V's performance with and without DSPy integration on the same dataset would provide evidence of its impact.

### Open Question 3
- Question: How can the discrepancies between theoretical and experimental porosity values be minimized in the future?
- Basis in paper: [explicit] The paper observes discrepancies between theoretical and experimental porosity values, even when using experimentally determined structures.
- Why unresolved: The underlying causes of these discrepancies, such as structural collapse during activation or inaccessible pore environments, are not fully understood or addressed.
- What evidence would resolve it: Further research into factors contributing to these discrepancies, such as detailed structural analysis and comparison of activation conditions, would provide evidence for minimizing them.

## Limitations

- Performance uncertainty on non-standard figure formats, poor image quality, or unconventional labeling conventions
- Prompt engineering approach relies on subjective design choices that may not generalize across different scientific domains
- Focus on six plot categories relevant to reticular chemistry leaves uncertainty about performance with other scientific visualization types

## Confidence

**High Confidence (85-95%)**
- GPT-4V's ability to classify nitrogen isotherms, PXRD patterns, and TGA curves with accuracy above 93% within the tested dataset
- The model's capacity to extract specific parameters (BET surface area, Langmuir surface area, pore volume) from nitrogen isotherms
- The potential for accelerating digital database creation through automated literature analysis

**Medium Confidence (65-85%)**
- Generalization of the methodology to other scientific fields beyond reticular chemistry
- Performance consistency across diverse figure styles and publication formats
- Long-term cost-effectiveness of the approach at scale

**Low Confidence (35-65%)**
- Exact reproducibility without access to the complete prompt formulations and ground truth datasets
- Performance on figures with non-standard layouts or poor quality
- Comparison of web interface versus API performance characteristics

## Next Checks

1. **Cross-Domain Validation**: Test GPT-4V's classification and extraction capabilities on scientific figures from unrelated fields (e.g., biochemistry, materials science, environmental science) to assess generalization limits and identify domain-specific prompt adaptations needed.

2. **Quality Robustness Testing**: Systematically degrade image quality through controlled experiments (compression, noise addition, resolution reduction) to determine the minimum quality threshold for maintaining >90% accuracy in both classification and parameter extraction.

3. **Comparative Benchmark Analysis**: Implement parallel processing pipelines using both the web interface and API versions of GPT-4V to measure differences in throughput, cost per page, and accuracy consistency, particularly for large-scale database creation projects.