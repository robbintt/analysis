---
ver: rpa2
title: 'The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections
  through Federated Learning'
arxiv_id: '2310.00141'
source_url: https://arxiv.org/abs/2310.00141
tags:
- training
- words
- examples
- federated
- targeted
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of outdated ASR models trained
  on static datasets that fail to capture evolving language and new terms. The authors
  propose using federated learning to continually update models with user corrections
  from edge devices.
---

# The Gift of Feedback: Improving ASR Model Quality by Learning from User Corrections through Federated Learning

## Quick Facts
- arXiv ID: 2310.00141
- Source URL: https://arxiv.org/abs/2310.00141
- Reference count: 0
- Key outcome: Federated learning improves ASR model quality on fresh and long-tail terms while preventing catastrophic forgetting

## Executive Summary
This paper addresses the challenge of outdated ASR models trained on static datasets that fail to capture evolving language and new terms. The authors propose using federated learning to continually update models with user corrections from edge devices. By filtering training examples to those containing likely misrecognized "fresh" terms and applying techniques like weight averaging and mixing federated with centralized training, the approach demonstrates improvements in recognizing fresh and long-tail words while maintaining overall model quality. The method is also effective for improving recognition of contact names.

## Method Summary
The approach uses federated learning to train an ASR model on user edits from edge devices, focusing on examples containing fresh terms likely to be misrecognized. The model fine-tunes only the decoder portion of a Conformer-based streaming transducer, applying static checkpoint averaging to prevent catastrophic forgetting. Training mixes federated rounds with centralized updates on the original distribution, using probabilistic sampling and client loss weighting to improve long-tail word learning. MWER loss is modified for on-device training efficiency.

## Key Results
- Significant WER improvements on targeted fresh/long-tail word test sets while maintaining overall model quality
- Effective mitigation of catastrophic forgetting through static checkpoint averaging
- Positive results for improving recognition of contact names using name-specific word lists
- Decoder-only fine-tuning (40M parameters) provides substantial memory savings while maintaining most quality improvements

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Filtering training examples to those containing fresh words identified as likely misrecognitions improves model quality on targeted terms.
- Mechanism: The model maintains a list of fresh words not in the original training corpus. When users make corrections containing these words, only those examples are retained for training, focusing learning on true misrecognitions.
- Core assumption: User edits containing fresh words are more likely to be corrections of model errors rather than general text revisions.
- Evidence anchors: The paper explores techniques to target fresh terms the model has not previously encountered and proposes filtering training examples containing terms the model is likely to misrecognize.

### Mechanism 2
- Claim: Static checkpoint averaging prevents catastrophic forgetting by maintaining connection to original model parameters.
- Mechanism: After each federated round, model weights are averaged with initial pre-trained checkpoint weights using a scaling factor, creating a weighted combination that preserves original knowledge while incorporating new learning.
- Core assumption: The initial pre-trained model contains valuable knowledge that should be preserved during fine-tuning.
- Evidence anchors: The authors compare techniques for mitigating catastrophic forgetting in FL, including variants of weight averaging algorithms, and modify weights by averaging with initial pre-trained checkpoint weights.

### Mechanism 3
- Claim: Mixing centralized and federated training maintains overall model quality while improving targeted term recognition.
- Mechanism: Server-side centralized training runs in parallel with federated rounds, with both contributing updates to the central model during aggregation, ensuring the model continues learning from the original distribution.
- Core assumption: The original training distribution remains relevant and should be maintained alongside new learning.
- Evidence anchors: The paper re-introduces data from the original distribution by mixing centralized training with federated rounds, performing centralized training on the same server datasets used to train the initial pre-trained checkpoint.

## Foundational Learning

- Concept: Federated Learning
  - Why needed here: Enables learning from user corrections without accessing raw user data, preserving privacy while allowing continuous model improvement
  - Quick check question: How does federated learning differ from traditional centralized training in terms of data flow and privacy guarantees?

- Concept: Catastrophic Forgetting
  - Why needed here: Fine-tuning on new data can cause the model to lose performance on the original distribution, requiring mitigation techniques
  - Quick check question: What happens to model performance on the original distribution when fine-tuning occurs without any forgetting mitigation?

- Concept: Long-tail Distribution
  - Why needed here: Fresh terms are inherently rare in training data, requiring specialized techniques to learn effectively from sparse examples
  - Quick check question: Why are traditional sampling techniques insufficient for learning from long-tail distributions in this context?

## Architecture Onboarding

- Component map: Speech audio -> ASR inference -> user edits -> federated round with wordlist filtering -> local training on filtered examples -> gradient aggregation -> model update -> evaluation on targeted and overall testsets
- Critical path: User speech → ASR inference → user edits → federated round with wordlist filtering → local training on filtered examples → gradient aggregation → model update → evaluation on targeted and overall testsets
- Design tradeoffs: Training only the decoder portion (40M parameters out of 150M total) provides significant memory savings for on-device training while maintaining most quality improvements, but may limit learning compared to full model training.
- Failure signatures: Rapid WER degradation when training on all user edits indicates many edits are revisions rather than corrections; failure to improve targeted terms despite training suggests filtering criteria are too restrictive.
- First 3 experiments:
  1. Train on all examples with user edits vs. filtered examples to demonstrate the necessity of wordlist filtering
  2. Compare static vs. dynamic checkpoint averaging to evaluate forgetting mitigation effectiveness
  3. Test probabilistic sampling vs. client loss weighting to determine optimal long-tail learning approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we automatically generate a high-quality list of "fresh" terms that the ASR model is likely to misrecognize, without manual curation?
- Basis in paper: The authors mention that in the long term, this step should be automated, e.g., by aggregating over user corrections across devices through Federated Analytics, but they used a manually-curated list of 241 words in their experiments.
- Why unresolved: The paper only demonstrates the approach using a manually-curated word list, and does not explore or evaluate automated methods for generating this list.
- What evidence would resolve it: Experiments comparing the performance of the proposed approach using manually-curated vs. automatically-generated word lists, with metrics like improvement in WER on targeted test sets and overall model quality.

### Open Question 2
- Question: How does the performance of the proposed approach scale with the size and diversity of the training data, particularly for rare and long-tail words?
- Basis in paper: The paper mentions that the fresh terms are long-tail words and training examples are sparse, and proposes techniques like probabilistic sampling and client loss weighting to address this. However, the experiments only evaluate the approach on a limited set of words.
- Why unresolved: The paper does not explore how the performance of the proposed approach changes with varying amounts and diversity of training data, particularly for extremely rare words.
- What evidence would resolve it: Experiments varying the size and diversity of the training data, and measuring the improvement in WER on targeted test sets for different frequency bands of words.

### Open Question 3
- Question: Can the proposed approach be extended to handle other types of model updates, such as adapting to new accents or dialects, or incorporating new language features?
- Basis in paper: The paper demonstrates the approach for learning fresh terms and improving recognition of contact names, but does not explore other types of model updates.
- Why unresolved: The paper only evaluates the approach for a specific use case (learning fresh terms), and does not investigate its applicability to other types of model updates.
- What evidence would resolve it: Experiments applying the proposed approach to adapt the ASR model to new accents, dialects, or language features, and measuring the improvement in WER on targeted test sets.

## Limitations
- Reliance on user edits containing fresh words being legitimate corrections rather than general text revisions
- Effectiveness depends on quality of fresh word list construction, which could miss important terms or include irrelevant ones
- Focus on decoder-only fine-tuning may limit model's ability to learn fundamental representations compared to full model training
- Evaluation primarily on English data with specific domain characteristics; generalization to other languages or domains unclear
- Computational overhead of maintaining both federated and centralized training streams may be prohibitive for some deployment scenarios

## Confidence
- High confidence: The federated learning framework and basic training methodology are well-established and the experimental results are clearly presented with appropriate controls
- Medium confidence: The effectiveness of specific mechanisms like static checkpoint averaging and mixing centralized/federated training, as these rely on assumptions about catastrophic forgetting and distribution shifts that weren't extensively validated
- Low confidence: The generalizability of results to other languages, domains, and the long-term effectiveness of the approach as language continues to evolve

## Next Checks
1. Cross-lingual validation: Test the federated learning approach on non-English ASR models to verify effectiveness across different languages and linguistic structures
2. Long-term stability analysis: Run extended federated training over multiple months to assess whether the model maintains improvements on fresh terms without degrading overall quality
3. User behavior validation: Conduct user studies to verify that edits containing fresh words are predominantly corrections rather than general text revisions, and analyze the false positive rate of the filtering mechanism