---
ver: rpa2
title: Enhancing Interpretability using Human Similarity Judgements to Prune Word
  Embeddings
arxiv_id: '2310.10262'
source_url: https://arxiv.org/abs/2310.10262
tags:
- features
- words
- pruned
- word
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a supervised pruning method for word embeddings
  that identifies domain-specific feature subsets which better predict human similarity
  judgments than full embeddings. For 8 semantic domains (sports, professions, etc.),
  the method retains only 20-40% of original features while improving correlation
  with human judgments.
---

# Enhancing Interpretability using Human Similarity Judgements to Prune Word Embeddings

## Quick Facts
- arXiv ID: 2310.10262
- Source URL: https://arxiv.org/abs/2310.10262
- Reference count: 4
- This paper presents a supervised pruning method for word embeddings that identifies domain-specific feature subsets which better predict human similarity judgments than full embeddings.

## Executive Summary
This paper introduces a supervised pruning method for word embeddings that identifies domain-specific feature subsets to better predict human similarity judgments. For 8 semantic domains (sports, professions, etc.), the method retains only 20-40% of original features while improving correlation with human judgments. The pruned sets capture different semantic dimensions across domains: profession features best predict cognitive/social dimensions, while fruit/vegetable features best predict taste. The approach provides a transparent way to align AI semantic representations with human knowledge.

## Method Summary
The method uses sequential feature selection to prune GloVe embeddings based on their ability to predict human similarity judgments from the Richie and Bhatia (2020) dataset across 8 semantic domains. The pruning algorithm iteratively removes features that contribute least to matching human similarity matrices. After pruning, PCA identifies principal components representing latent dimensions, and PMI correlation analysis finds vocabulary words whose co-occurrence patterns align with these components. Finally, PLSR probing tasks use the pruned features to predict semantic dimensions from the Binder et al. (2016) dataset.

## Key Results
- Pruned embeddings retain only 20-40% of original features while improving Spearman correlation with human similarity judgments
- Different domains capture distinct semantic dimensions: professions predict cognitive/social features, fruits/vegetables predict taste
- PCA interpretation reveals interpretable dimensions (e.g., sports as gender-inclusive/international)
- PLSR predictions using pruned features successfully capture semantic dimensions across 65 annotations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Supervised pruning improves prediction of human similarity judgments by identifying domain-specific feature subsets that capture human-relevant semantic dimensions.
- Mechanism: The pruning algorithm iteratively removes features that contribute least to matching human similarity matrices, retaining only those that preserve the most salient dimensions for each semantic domain.
- Core assumption: Human similarity judgments reflect underlying semantic dimensions that can be captured by identifying the most relevant subset of word embedding features for each domain.
- Evidence anchors:
  - [abstract]: "This paper presents a supervised pruning method for word embeddings that identifies domain-specific feature subsets which better predict human similarity judgments than full embeddings."
  - [section]: "For 8 semantic domains (sports, professions, etc.), the method retains only 20-40% of original features while improving correlation with human judgments."
  - [corpus]: Weak evidence - corpus contains related work on word similarity and interpretability but doesn't directly confirm the pruning mechanism's effectiveness.
- Break condition: If human similarity judgments don't align with any subset of features in the embedding space, or if the pruning algorithm fails to identify meaningful feature subsets.

### Mechanism 2
- Claim: Pruned feature sets reveal interpretable human-relevant dimensions through principal component analysis and PMI correlation analysis.
- Mechanism: After pruning, PCA identifies principal components representing latent dimensions, and PMI correlation analysis finds vocabulary words whose co-occurrence patterns align with these components, revealing interpretable semantic dimensions.
- Core assumption: The first principal component of pruned embeddings captures the most salient semantic dimension for each domain, and PMI correlations with this component reveal interpretable dimensions.
- Evidence anchors:
  - [abstract]: "The pruned sets capture different semantic dimensions across domains: profession features best predict cognitive/social dimensions, while fruit/vegetable features best predict taste."
  - [section]: "This analysis reveals that humans differentiate e.g. sports based on how gender-inclusive and international they are."
  - [corpus]: Weak evidence - corpus mentions related interpretability work but doesn't directly validate the PCA/PMI correlation approach.
- Break condition: If the first principal component doesn't capture meaningful semantic dimensions, or if PMI correlations don't align with interpretable semantic patterns.

### Mechanism 3
- Claim: Pruned feature sets encode domain-specific semantics that can be probed to predict human-rated semantic features across different dimensions.
- Mechanism: Using pruned feature sets as variables in a probing task (PLSR) successfully predicts values along 65 semantically annotated dimensions, revealing which domains' pruned features best capture which semantic areas.
- Core assumption: Pruned feature sets retain the semantic information most relevant to human judgments in each domain, making them effective predictors for corresponding semantic dimensions.
- Evidence anchors:
  - [abstract]: "The features retained for professions are best at predicting cognitive, emotional and social dimensions, whereas features retained for fruits or vegetables best predict the gustation (taste) dimension."
  - [section]: "These results suggest that the identified dimensions contained in the pruned sets reflect information that is central to the way people compare objects in these categories."
  - [corpus]: Weak evidence - corpus contains related probing work but doesn't directly validate the domain-specific semantic prediction claims.
- Break condition: If pruned features don't capture domain-relevant semantics, or if PLSR predictions don't align with human-rated semantic features.

## Foundational Learning

- Concept: Word embeddings and semantic similarity
  - Why needed here: Understanding how word embeddings represent semantic relationships is crucial for interpreting how pruning affects similarity judgments.
  - Quick check question: How do cosine similarity and Pearson correlation differ in measuring word embedding similarity?

- Concept: Principal Component Analysis (PCA)
  - Why needed here: PCA is used to identify latent semantic dimensions in pruned embeddings and interpret their meaning.
  - Quick check question: What does the first principal component of a PCA represent in terms of variance explained?

- Concept: Pointwise Mutual Information (PMI)
  - Why needed here: PMI is used to identify vocabulary words whose co-occurrence patterns align with principal component scores, revealing interpretable dimensions.
  - Quick check question: How does PMI measure the association between two words compared to raw co-occurrence frequency?

## Architecture Onboarding

- Component map: Human similarity judgments and GloVe embeddings -> Supervised pruning algorithm -> PCA and PMI correlation analysis -> PLSR probing task -> Pruned feature sets and interpretable dimensions

- Critical path:
  1. Load human similarity judgments and GloVe embeddings
  2. Apply supervised pruning algorithm to identify domain-specific feature subsets
  3. Perform PCA on pruned embeddings to identify principal components
  4. Compute PMI correlations to interpret semantic dimensions
  5. Use PLSR to probe pruned features for predicting semantic features

- Design tradeoffs:
  - Computational efficiency vs. semantic accuracy: More features retained increases accuracy but reduces interpretability
  - Domain specificity vs. generalizability: Domain-specific pruning improves domain accuracy but may reduce cross-domain applicability
  - Interpretability vs. complexity: Simple pruning methods are more interpretable but may miss complex semantic relationships

- Failure signatures:
  - Pruning fails to improve similarity prediction: Indicates pruning algorithm not identifying relevant features
  - PCA components not interpretable: Suggests semantic dimensions not captured by principal components
  - PLSR predictions poor: Indicates pruned features not encoding relevant semantic information

- First 3 experiments:
  1. Run pruning algorithm on single domain (e.g., sports) and verify improvement in similarity prediction
  2. Perform PCA on pruned sports embeddings and interpret first principal component through PMI analysis
  3. Use pruned sports features in PLSR to predict semantic features and compare to full embedding performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the supervised pruning method generalize to contextual embeddings (like BERT) or only non-contextual embeddings (like GloVe)?
- Basis in paper: [explicit] The authors state "understanding how this methodology could be applied to contextualized embeddings remains to be explored."
- Why unresolved: The paper only tests the pruning method on GloVe embeddings, and contextual embeddings have different structural properties that might affect the pruning approach.
- What evidence would resolve it: Testing the pruning algorithm on BERT or other contextual embeddings and comparing the feature retention rates and HSJ prediction improvements to the GloVe results.

### Open Question 2
- Question: How does the pruning methodology perform when applied to different similarity datasets beyond the Richie and Bhatia (2020) dataset?
- Basis in paper: [explicit] The authors note "one important question that remains to be answered is how the results would generalize if the type of embedding and/or the similarity dataset were different."
- Why unresolved: The study is limited to a single HSJ dataset, and similarity judgments can vary based on cultural context and participant demographics.
- What evidence would resolve it: Applying the pruning method to other established HSJ datasets (e.g., MEN, SimLex-999) and comparing the feature retention patterns and prediction accuracy.

### Open Question 3
- Question: What is the relationship between the pruned feature sets and the specific word combinations in each category, and how might different word sets produce different semantic dimensions?
- Basis in paper: [explicit] The authors state "the dimensions highlighted by supervised pruning may be related to the set of words being compared, to the extent that the similarity ratings are impacted by contrast-relation in the specific category set."
- Why unresolved: The study uses fixed word sets for each category, and similarity judgments are influenced by contrast effects within the set, meaning different word combinations could yield different semantic dimensions.
- What evidence would resolve it: Creating multiple word sets for the same category (e.g., different sports combinations) and testing whether the pruned feature sets and identified dimensions change significantly across word set variations.

## Limitations
- The pruning method's generalizability beyond the 8 semantic domains tested remains uncertain
- The computational efficiency of the sequential feature selection algorithm is not explicitly evaluated
- The broader implications for AI transparency and alignment with human knowledge are not demonstrated with real-world impact

## Confidence

- **High Confidence**: The core claim that pruned embeddings (20-40% feature retention) improve correlation with human similarity judgments compared to full embeddings. This is directly supported by the leave-one-out cross-validation results.
- **Medium Confidence**: The interpretability claims regarding PCA and PMI analysis revealing human-relevant dimensions. While the method is described clearly, the subjective nature of "interpretability" makes this harder to quantify objectively.
- **Low Confidence**: The broader implications for AI transparency and alignment with human knowledge. The paper presents a promising approach but doesn't demonstrate real-world impact on downstream AI systems.

## Next Checks
1. **Cross-domain validation**: Apply the pruning method to 2-3 additional semantic domains not covered in the original study (e.g., emotions, tools, or animals) to test generalizability.
2. **Computational scaling analysis**: Measure the runtime complexity of the pruning algorithm as a function of embedding dimensionality and domain size to assess practical scalability.
3. **Downstream task evaluation**: Test whether the pruned embeddings maintain performance on standard NLP benchmarks (e.g., word analogy, sentiment analysis) compared to full embeddings, to verify that semantic information isn't lost in pruning.