---
ver: rpa2
title: 'Generative Models: What Do They Know? Do They Know Things? Let''s Find Out!'
arxiv_id: '2311.17137'
source_url: https://arxiv.org/abs/2311.17137
tags:
- image
- scene
- diffusion
- intrinsics
- generative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper explores whether generative models inherently encode\
  \ scene intrinsics like surface normals, depth, albedo, and shading. The authors\
  \ introduce INTRINSIC LORA (I-LORA), a method that uses Low-Rank Adaptation (LoRA)\
  \ to extract these intrinsics from various generative models\u2014diffusion models,\
  \ GANs, and autoregressive models\u2014by modulating key feature maps with minimal\
  \ additional parameters (less than 0.6% of the original model)."
---

# Generative Models: What Do They Know? Do They Know Things? Let's Find Out!

## Quick Facts
- arXiv ID: 2311.17137
- Source URL: https://arxiv.org/abs/2311.17137
- Reference count: 40
- Key outcome: The paper introduces INTRINSIC LORA (I-LORA), a method that uses Low-Rank Adaptation to extract scene intrinsics (surface normals, depth, albedo, shading) from generative models with minimal parameters and labeled data.

## Executive Summary
This paper explores whether generative models inherently encode scene intrinsics and introduces INTRINSIC LORA (I-LORA) to extract these properties using LoRA adaptation. The method works across different generative architectures (diffusion, GANs, autoregressive) by modulating key feature maps with minimal additional parameters. Experiments show that as few as 250 labeled images are sufficient for high-quality intrinsic extraction, with performance improving alongside the generative model's image quality.

## Method Summary
The authors propose using Low-Rank Adaptation (LoRA) to extract scene intrinsics from pretrained generative models. LoRA modules are inserted at key locations in different model architectures - attention layers for diffusion models, affine layers for StyleGAN, and convolutional attention layers for VQGAN. These adapters learn to modulate features to produce intrinsic outputs while preserving the original generation capability. The method requires minimal labeled data (250-1000 images) and uses pseudo-ground truth from specialized models for training.

## Key Results
- I-LORA successfully extracts surface normals, depth, albedo, and shading from various generative models using less than 0.6% additional parameters
- As few as 250 labeled images are sufficient for high-quality intrinsic extraction, outperforming state-of-the-art supervised methods on some tasks
- The quality of extracted intrinsics correlates with the generative model's image quality, with diffusion models achieving the best results
- The method works across diverse domains (face, general scene, art) and model types (VQGAN, StyleGAN-v2, StyleGAN-XL, Stable Diffusion)

## Why This Works (Mechanism)

### Mechanism 1
LoRA modulates key feature maps to enable scene intrinsic extraction without modifying the original generative model's decoder. The LoRA adapter learns low-rank matrices that modulate specific feature maps (attention layers in diffusion models, affine layers in GANs, convolutional attention layers in VQGAN). This modulation adjusts the feature representations to align with scene intrinsic targets while preserving the original generation capability.

### Mechanism 2
Scene intrinsics are implicitly learned during generative pretraining, and LoRA extraction reveals these latent representations. The generative model learns rich scene representations during pretraining to produce realistic images. LoRA acts as a minimal adapter that extracts these latent intrinsic representations without requiring full model retraining.

### Mechanism 3
Minimal labeled data requirement is possible because the generative model provides strong priors for scene intrinsics. The pretrained generative model already encodes scene priors, so the LoRA adapter only needs to learn how to extract these representations rather than learning intrinsics from scratch.

## Foundational Learning

- **Concept**: Low-Rank Adaptation (LoRA)
  - **Why needed here**: LoRA enables efficient adaptation of large generative models with minimal additional parameters, making it feasible to extract scene intrinsics without full model retraining.
  - **Quick check question**: What is the typical rank used in LoRA for vision tasks, and how does it affect parameter count relative to the base model?

- **Concept**: Scene intrinsics representation
  - **Why needed here**: Understanding that surface normals, depth, albedo, and shading can be represented as image-like outputs with up to three channels is crucial for applying LoRA effectively.
  - **Quick check question**: How do surface normals, depth, albedo, and shading differ in their channel representations and value ranges?

- **Concept**: Pretrained generative model feature extraction
  - **Why needed here**: The method relies on extracting features from pretrained generative models, so understanding how these models encode scene information is essential.
  - **Quick check question**: What are the key architectural differences between diffusion models, GANs, and autoregressive models that affect how they encode scene information?

## Architecture Onboarding

- **Component map**: Pretrained generative model -> LoRA adapter modules -> Intrinsic output -> Comparison with pseudo-ground truth
- **Critical path**: Pretrained generative model → LoRA feature modulation → Intrinsic output → Comparison with pseudo-ground truth
- **Design tradeoffs**: 
  - Using LoRA vs full fine-tuning: LoRA preserves original generation capability but may limit extraction quality
  - Single-step vs multi-step diffusion: Single-step is simpler but multi-step can improve quality at the cost of complexity
  - Rank selection: Higher rank improves quality but increases parameters (rank 8 achieves good balance)
- **Failure signatures**:
  - Color shifts in extracted intrinsics (indicates distribution mismatch)
  - Misalignment between input image and extracted intrinsics (indicates diffusion step issues)
  - Poor quality on complex scenes (indicates model capacity limitations)
- **First 3 experiments**:
  1. Extract surface normals from StyleGAN-v2 FFHQ model using rank-8 LoRA with 250 labeled examples, measure mean angular error
  2. Compare single-step vs multi-step diffusion for Stable Diffusion 1.5, measure alignment and color shift artifacts
  3. Test different LoRA ranks (2, 4, 8, 16) on same model to find optimal parameter-efficiency tradeoff

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but the following questions emerge from the analysis:

### Open Question 1
What is the exact mechanism by which LoRA adaptation allows generative models to extract scene intrinsics, and how does this relate to the underlying learned representations of the model?

### Open Question 2
How do the quality of the extracted scene intrinsics correlate with the quality of the generated images, and what are the underlying factors that contribute to this correlation?

### Open Question 3
How can the proposed method be extended to extract additional scene intrinsics beyond the four studied in the paper (normals, depth, albedo, and shading)?

### Open Question 4
How does the proposed method compare to other approaches for extracting scene intrinsics from generative models, such as fine-tuning or linear probing?

## Limitations
- The method's performance on highly diverse or complex scenes beyond the tested datasets is unclear
- The exact LoRA configuration (rank selection, initialization) may require extensive hyperparameter tuning for optimal results
- The pseudo-ground truth quality and domain alignment significantly impact results but are not thoroughly analyzed

## Confidence
- **High confidence**: The LoRA framework works as a general adapter for different generative architectures
- **Medium confidence**: The minimal labeled data requirement (250 images) generalizes across domains and intrinsic types
- **Low confidence**: Claims about outperforming state-of-the-art supervised methods on albedo and shading tasks without more rigorous benchmarking

## Next Checks
1. **Domain Generalization Test**: Evaluate the method on entirely different datasets (e.g., indoor scenes, artistic images) to verify the claimed cross-domain applicability
2. **Pseudo-Ground Truth Sensitivity**: Systematically vary the quality and domain of pseudo-ground truth generation to quantify its impact on final intrinsic extraction quality
3. **Robustness Analysis**: Test the method's performance on challenging scenes with complex lighting, occlusions, and texture variations to identify failure modes and limitations