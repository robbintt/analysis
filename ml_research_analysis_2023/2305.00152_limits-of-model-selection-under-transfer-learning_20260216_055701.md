---
ver: rpa2
title: Limits of Model Selection under Transfer Learning
arxiv_id: '2305.00152'
source_url: https://arxiv.org/abs/2305.00152
tags:
- risk
- then
- target
- c1np
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the limits of model selection in transfer learning
  settings where data from both a source and target distribution are available. The
  authors show that the standard adaptive rates achievable without distributional
  knowledge can be arbitrarily slower than oracle rates achievable with knowledge
  of transfer distances.
---

# Limits of Model Selection under Transfer Learning

## Quick Facts
- arXiv ID: 2305.00152
- Source URL: https://arxiv.org/abs/2305.00152
- Reference count: 40
- Primary result: Adaptive model selection rates can be arbitrarily slower than oracle rates in transfer learning when transfer distances vary across hypothesis classes

## Executive Summary
This paper establishes fundamental limits on model selection in transfer learning settings where both source and target data are available. The authors show that without knowledge of how well each hypothesis class transfers from source to target, adaptive procedures cannot achieve the optimal rates that would be possible with this information. The key insight is that model selection must balance not just estimation vs approximation errors, but also the unknown transfer distance between source and target distributions induced by each class. They provide matching upper and lower bounds for both fixed classes and hierarchical model selection, demonstrating that the achievable rate depends critically on both the source excess risk and a transfer exponent parameter.

## Method Summary
The paper develops two main algorithms for adaptive model selection under transfer learning. Algorithm 1 uses an intersection of empirical confidence balls to find the largest hypothesis class where source and target data agree on the minimal set. Algorithm 2 then selects a hypothesis from this intersection set using held-out target data to balance source transfer benefit against target empirical performance. The theoretical analysis establishes tight lower bounds showing that these adaptive procedures cannot match oracle rates achievable with knowledge of which class best transfers. The methodology relies on recent notions of transfer distance that combine source excess risk with a transfer exponent, and provides a complete characterization of the achievable rates for both fixed classes and hierarchical model selection.

## Key Results
- Adaptive rates achievable without distributional knowledge can be arbitrarily slower than oracle rates when transfer distances vary across classes
- For fixed hypothesis classes, the achievable rate is characterized by EQ(ĥ) ≲ min{(d/nP)^(1/2ρ) + EQ(h*P), (d/nQ)^(1/2)}
- Standard complexity regularization (SRM) cannot achieve optimal adaptive rates in transfer learning without distributional knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adaptive model selection rates can be arbitrarily slower than oracle rates in transfer learning when the transfer distance varies with hypothesis class.
- Mechanism: The paper establishes lower bounds showing that without knowledge of transfer distances, any adaptive procedure must incur a penalty proportional to the worst-case transfer distance encountered, even if better distances exist for other classes.
- Core assumption: The hierarchy of hypothesis classes {Hi} contains classes with varying transfer distances (ρi, EQ(h*P,i)) that are a priori unknown.
- Evidence anchors:
  - [abstract] "adaptive rates, i.e., those achievable with no distributional information, can be arbitrarily slower than oracle rates, i.e., when given knowledge on distances"
  - [section] "The next result, relying on a second Algorithm 2, states that a better rate is achievable with some distributional knowledge"
  - [corpus] Weak corpus evidence; no direct matches to transfer distance mechanisms found
- Break condition: If transfer distances were known or could be estimated reliably without additional data, the gap between adaptive and oracle rates could be eliminated.

### Mechanism 2
- Claim: The transfer exponent ρ and source excess risk EQ(h*P) jointly determine the achievable transfer learning rate for a fixed hypothesis class.
- Mechanism: The paper shows that the adaptive rate EQ(ĥ) ≲ min{(d/nP)^(1/2ρ) + EQ(h*P), (d/nQ)^(1/2)} captures both the benefit of source data (through ρ) and the initial gap (through EQ(h*P)).
- Core assumption: The Bernstein class condition holds for both source and target distributions with known parameters βP and βQ.
- Evidence anchors:
  - [abstract] "adaptive rate on a fixed choice H, admits matching lower-bounds over any parameter value"
  - [section] "For a fixed classH, we adopt a recent notion of distanceP →Q from [Hanneke and Kpotufe, 2019] comprised of two components: (1) the excess riskEQ(h*P) of a risk minimizerh*P underP , and (2) atransfer-exponent ρ"
  - [corpus] No relevant corpus evidence found
- Break condition: If the Bernstein condition does not hold or if the transfer exponent ρ cannot be bounded away from 1, the rate characterization breaks down.

### Mechanism 3
- Claim: Standard complexity regularization (SRM) cannot achieve the optimal adaptive rate in transfer learning without distributional knowledge.
- Mechanism: The paper proves that SRM, which trades off estimation and approximation errors, fails to account for the transfer distance and thus cannot automatically balance the additional tradeoff parameter introduced by transfer learning.
- Core assumption: The hierarchy {Hi} admits a global risk minimizer h*P that is unknown to the learner.
- Evidence anchors:
  - [abstract] "we emphasize that in contrast, popular SRM approaches yield no clear such guarantee: supposenQ = 0, SRM can only guarantee lowP -risk, but no specific choice of model class"
  - [section] "SRM, a.k.a. complexity regularization approaches are prevalent in the literature and in practice, it is unclear whether such approaches can adaptively achieve the above rate of φ♯(i*P)"
  - [corpus] No corpus evidence related to SRM limitations in transfer learning
- Break condition: If the model hierarchy is constrained such that all classes have similar transfer properties, SRM might perform adequately.

## Foundational Learning

- Concept: Transfer exponent and its relationship to effective sample size
  - Why needed here: The transfer exponent ρ quantifies how well source data informs the target task, directly affecting the achievable rate
  - Quick check question: If ρ = 1, what does this imply about the relationship between source and target distributions?

- Concept: Bernstein class condition and fast rates
  - Why needed here: The Bernstein condition with parameter β determines whether fast rates (n^-1) versus slow rates (n^(-1/2)) are achievable
  - Quick check question: How does the value of β affect the exponent in the sample complexity term (d/n)^(1/(2-β))?

- Concept: Model selection tradeoffs beyond estimation-approximation
  - Why needed here: In transfer learning, model selection must additionally balance the unknown transfer distance, creating a three-way tradeoff
  - Quick check question: What additional term must be considered in model selection when source data is available beyond the standard estimation-approximation tradeoff?

## Architecture Onboarding

- Component map:
  - Data processing: Source samples (nP), Target samples (nQ), Hold-out target samples (nQ')
  - Algorithm 1: Adaptive Trade-off - computes intersection of empirical confidence balls
  - Algorithm 2: Tradeoff on Q - selects hypothesis based on held-out performance
  - Oracle procedure: Requires knowledge of arg mini φ♯(i) to achieve optimal rate
  - Lower bound construction: Randomized distributions to establish impossibility results

- Critical path:
  1. Compute empirical minimal sets for each hypothesis class using source and target data
  2. Find largest index ˆiP where intersection of source confidence balls is non-empty
  3. Compute intersection of target confidence balls starting from ˆiP
  4. Run Algorithm 2 on the intersection set with held-out target data
  5. Return hypothesis that balances source transfer benefit and target empirical performance

- Design tradeoffs:
  - Using held-out data for final selection vs. using all data for estimation
  - Computational cost of maintaining intersections across all hypothesis classes
  - Choice of confidence level δ affecting both statistical and computational complexity

- Failure signatures:
  - Algorithm 1 returns empty intersection → model hierarchy too restrictive or insufficient data
  - Final hypothesis performs poorly on held-out data → transfer distance larger than expected
  - Runtime grows exponentially with number of classes → need to implement class pruning

- First 3 experiments:
  1. Implement Algorithms 1 and 2 on synthetic data with known transfer distances to verify φ♯(i*P) rate
  2. Compare performance against standard SRM baseline when transfer distances vary across classes
  3. Test lower bound construction by attempting to achieve oracle rate without transfer distance knowledge

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what conditions on the hierarchy of hypothesis classes can adaptive procedures achieve oracle rates that are better than the source risk minimizer's rate?
- Basis in paper: [explicit] The paper states that oracle rates are unachievable adaptively without further structural conditions on the hierarchy, but does not specify what these conditions are.
- Why unresolved: The paper provides examples showing the gap between adaptive and oracle rates but does not characterize when the gap can be closed.
- What evidence would resolve it: A characterization of hierarchy structures (e.g., smoothness conditions, transfer monotonicity) that allow adaptive procedures to match oracle rates.

### Open Question 2
- Question: How does the transfer exponent ρ vary with the choice of hypothesis class in realistic transfer learning scenarios beyond simple neural networks?
- Basis in paper: [inferred] The paper gives examples with neural networks showing that ρ can increase or decrease with model complexity, but these are limited to 1D cases.
- Why unresolved: The paper only provides two specific 1D neural network examples, which may not generalize to higher dimensions or different model families.
- What evidence would resolve it: Empirical studies or theoretical bounds on how ρ scales with model complexity and architecture for common model families (e.g., CNNs, transformers).

### Open Question 3
- Question: What are the lower bounds for adaptive rates when the source excess risk EQ(h*_P) > 0?
- Basis in paper: [explicit] The paper states that the lower bound construction of [Hanneke and Kpotufe, 2019] only holds for EQ(h*_P) = 0, and extends it to the general case.
- Why unresolved: While the paper establishes upper bounds for the general case, it does not provide matching lower bounds.
- What evidence would resolve it: A lower bound construction showing that the adaptive rate cannot be improved beyond a certain threshold even when EQ(h*_P) > 0.

### Open Question 4
- Question: Can improper learning procedures achieve better rates than proper ones in model selection under transfer learning?
- Basis in paper: [explicit] The paper shows that proper learners can achieve rates up to φ♯(i*_P), but does not compare to improper learners.
- Why unresolved: The paper focuses on proper learning procedures and does not investigate whether allowing improper learning could close the gap to oracle rates.
- What evidence would resolve it: A lower bound showing that no improper learner can achieve better rates than the proper upper bound, or an upper bound showing improper learners can exceed the proper rate.

### Open Question 5
- Question: How does the Bernstein class condition parameter β affect the achievable rates in model selection under transfer learning?
- Basis in paper: [explicit] The paper includes β in the rate expressions but does not analyze its impact on the adaptive-oracle gap.
- Why unresolved: The paper provides general upper and lower bounds that include β but does not explore how different β values affect the hardness of adaptation.
- What evidence would resolve it: A detailed analysis showing how the adaptive-oracle gap scales with β, or examples where different β values lead to qualitatively different behavior.

## Limitations

- The paper lacks empirical validation of the claimed gap between adaptive and oracle rates, with lower bound constructions being abstract rather than practically demonstrated
- The theoretical framework assumes known parameters like transfer exponents and Bernstein conditions, which may not be available in practice
- The analysis is limited to specific hypothesis classes (neural networks in 1D) and doesn't generalize to common model families used in real-world transfer learning

## Confidence

- **High confidence**: The mathematical characterization of adaptive rates as EQ(ĥ) ≲ min{(d/nP)^(1/2ρ) + EQ(h*P), (d/nQ)^(1/2)} and the oracle rate φ♯(i*) = min{(d/nP)^(1/2ρ(i)) + EQ(h*P), (d/nQ)^(1/2)}
- **Medium confidence**: The claim that adaptive rates can be arbitrarily slower than oracle rates, and that SRM cannot achieve optimal transfer learning rates
- **Low confidence**: Practical implications of the transfer distance lower bounds and their real-world significance

## Next Checks

1. **Empirical verification of rate gaps**: Implement Algorithms 1 and 2 on synthetic data with varying transfer distances to empirically measure the gap between adaptive and oracle rates, particularly focusing on scenarios where ρ varies significantly across hypothesis classes.

2. **SRM comparison**: Compare the performance of the proposed adaptive algorithm against standard SRM approaches on real-world transfer learning tasks to verify whether SRM indeed fails to achieve optimal rates when transfer distances vary.

3. **Transfer exponent estimation**: Develop methods to estimate the transfer exponent ρ from data, as this parameter is critical for the theoretical guarantees but appears to require prior knowledge in the current formulation.