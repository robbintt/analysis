---
ver: rpa2
title: 'ESGReveal: An LLM-based approach for extracting structured data from ESG reports'
arxiv_id: '2312.17264'
source_url: https://arxiv.org/abs/2312.17264
tags:
- data
- module
- reports
- disclosure
- esgreveal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: ESGReveal is a method using Large Language Models (LLMs) enhanced
  with Retrieval Augmented Generation (RAG) techniques to extract structured data
  from ESG reports. The ESGReveal system includes an ESG metadata module for targeted
  queries, a preprocessing module for assembling databases, and an LLM agent for data
  extraction.
---

# ESGReveal: An LLM-based approach for extracting structured data from ESG reports

## Quick Facts
- arXiv ID: 2312.17264
- Source URL: https://arxiv.org/abs/2312.17264
- Reference count: 4
- Primary result: Achieved 76.9% accuracy in data extraction and 83.7% in disclosure analysis using GPT-4, outperforming baseline models

## Executive Summary
ESGReveal is an innovative method that combines Large Language Models with Retrieval Augmented Generation techniques to extract structured data from corporate ESG reports. The system addresses the challenge of processing unstructured ESG data by implementing a three-module architecture: ESG metadata for targeted queries, preprocessing for database assembly, and an LLM agent for data extraction. Tested on 166 companies across 12 industries listed on the Hong Kong Stock Exchange in 2022, ESGReveal demonstrated superior performance in both data extraction and disclosure analysis tasks.

## Method Summary
ESGReveal employs a three-module approach to extract structured ESG data from corporate reports. The ESG metadata module defines ESG indicators and provides domain knowledge extensions, while the report preprocessing module uses layout analysis tools (LayoutLMv3, GeoLayoutLM) to parse document structure and build multi-type knowledge bases. The LLM agent module retrieves relevant content through vector similarity search and generates structured outputs using GPT-4. The system processes 2249 ESG reports through a RAG framework that combines enhanced document preprocessing with domain-specific knowledge integration.

## Key Results
- GPT-4 achieved 76.9% accuracy in data extraction and 83.7% in disclosure analysis
- Environmental data disclosure was 69.5% while social data disclosure was 57.2% across analyzed companies
- Outperformed baseline models with significant improvements in both data extraction and disclosure analysis tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ESGReveal achieves higher accuracy by combining enhanced document preprocessing with domain-specific knowledge integration in a RAG framework.
- Mechanism: The system first applies layout analysis (using LayoutLMv3 and GeoLayoutLM) to parse ESG report structure, then builds multi-type knowledge bases (textual, outline, and table contents) with vector embeddings. When queries are processed, the RAG framework retrieves relevant content from these knowledge bases and augments LLM prompts with ESG metadata including domain knowledge from experts.
- Core assumption: Accurate document structure parsing and targeted knowledge retrieval significantly improve LLM's ability to extract ESG indicators compared to raw text processing.
- Evidence anchors:
  - [abstract] "Utilizing ESGReveal unearthed significant findings... GPT-4 achieving accuracy rates of 76.9% in data extraction and 83.7% in disclosure analysis, outperforming baseline models."
  - [section] "These results underscore the effectiveness of report preprocessing and LLM agent modules proposed in this study."
  - [corpus] Weak evidence - related papers focus on similar RAG-based approaches but don't provide direct comparative accuracy data for this specific architecture.
- Break condition: If document layout analysis fails to accurately identify table structures or if the vector similarity search retrieves irrelevant content, the accuracy advantage would diminish significantly.

### Mechanism 2
- Claim: Domain-specific ESG metadata framework improves LLM performance by providing structured query templates and indicator definitions.
- Mechanism: The ESG metadata module structures ESG indicators as <Aspect, KPI, Topic, Quantity> entities and provides Extensions with domain knowledge and search terms. This structured approach guides the LLM to extract specific numerical values rather than just identifying disclosure presence.
- Core assumption: LLMs require explicit domain knowledge and structured query formats to accurately extract specific ESG metrics from unstructured reports.
- Evidence anchors:
  - [section] "The ESG metadata module, rooted in LLM technology, enables the conversion of various ESG reporting standards into structured data extraction commands."
  - [section] "These results amply demonstrate the potent potential and practical application value of ESGReveal in ESG analysis tasks."
  - [corpus] Moderate evidence - papers like "Advanced Unstructured Data Processing for ESG Reports" discuss similar metadata approaches but lack specific performance comparisons.
- Break condition: If the metadata framework doesn't cover emerging ESG indicators or if companies use non-standard reporting formats, the system's accuracy would degrade.

### Mechanism 3
- Claim: The ablation study demonstrates that both enhanced RAG preprocessing and ESG domain knowledge contribute incrementally to performance improvements.
- Mechanism: By comparing baseline RAG performance with enhanced versions (enhanced preprocessing + ESG metadata), the study quantifies the contribution of each component. GPT-4 improved from 57.8% to 83.7% in disclosure analysis through these enhancements.
- Core assumption: Systematic ablation testing can isolate the contribution of individual components to overall system performance.
- Evidence anchors:
  - [section] "GPT-4 saw notable improvements in performance for both types of tasks, achieving 81.2% (+23.4%) for disclosure analysis and 74.0% (+21.8%) for data extraction."
  - [section] "With the introduction of <Knowledge> of ESG metadata module, both GPT-4 and GPT-3.5 achieved varying degrees of improvement."
  - [corpus] Strong evidence - the ablation study design is explicitly described with quantitative results showing incremental improvements.
- Break condition: If the baseline RAG implementation is already highly optimized or if the enhancements don't generalize to other LLM architectures, the incremental gains might not be replicable.

## Foundational Learning

- Concept: Vector similarity search and semantic matching
  - Why needed here: The system uses cosine similarity and semantic similarity (coROM model) to retrieve relevant content from knowledge bases. Understanding these concepts is crucial for grasping how the RAG framework works.
  - Quick check question: How does cosine similarity differ from semantic similarity, and why would both be used in this ESG extraction system?

- Concept: Prompt engineering with in-context learning
  - Why needed here: The LLM agent module constructs prompts that include preset information, reference content, expert knowledge, and formatted questions. Understanding prompt engineering is essential for optimizing LLM performance.
  - Quick check question: What are the key components of an effective prompt for structured data extraction from ESG reports?

- Concept: Document layout analysis and table structure recognition
  - Why needed here: The preprocessing module uses computer vision tools to extract document structure and reconstruct table formats. Understanding these techniques is important for comprehending how unstructured ESG reports are converted to structured data.
  - Quick check question: How do layout analysis models like LayoutLMv3 identify different document components (headers, paragraphs, tables) in ESG reports?

## Architecture Onboarding

- Component map: ESG Metadata Module -> Report Preprocessing Module -> LLM Agent Module -> Knowledge Bases (textual, outline, table contents)

- Critical path: ESG report → Preprocessing (layout analysis → table reconstruction → knowledge base construction) → Retrieval (query vectorization → similarity search → semantic re-ranking) → LLM Prompt Generation → Structured Data Extraction

- Design tradeoffs:
  - Accuracy vs. computational cost: More sophisticated preprocessing and retrieval methods improve accuracy but increase processing time
  - Domain specificity vs. generalization: Highly specialized ESG metadata improves performance for ESG tasks but limits applicability to other domains
  - Manual annotation vs. automation: Requires manual annotation for accuracy metrics but enables automated extraction at scale

- Failure signatures:
  - Low accuracy in table data extraction: Likely indicates issues with table structure recognition algorithms
  - Poor performance on specific industries: May suggest insufficient domain knowledge for those sectors
  - Degradation with multilingual reports: Could indicate limitations in the current vector embedding models

- First 3 experiments:
  1. Baseline RAG performance test: Run the system without enhanced preprocessing or ESG metadata to establish baseline accuracy metrics
  2. Component isolation test: Disable either the preprocessing enhancement or ESG metadata to quantify each component's contribution
  3. Industry-specific performance test: Analyze accuracy differences across the 12 industries to identify sectors needing additional domain knowledge

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the ESGReveal system be enhanced to process and extract data from pictorial information in ESG reports, such as charts and graphs, to provide a more comprehensive analysis?
- Basis in paper: [explicit] The paper mentions that current iterations of ESGReveal do not process pictorial information, a functionality intended for future enhancement.
- Why unresolved: The current ESGReveal system is limited to text and tabular data extraction and does not include capabilities for interpreting and extracting data from images or pictorial representations within ESG reports.
- What evidence would resolve it: Development and implementation of image processing capabilities within ESGReveal, followed by testing and validation to ensure accurate extraction of data from pictorial information in ESG reports.

### Open Question 2
- Question: How does the performance of ESGReveal vary when applied to ESG reports from different industries, and what specific challenges or limitations arise in certain sectors?
- Basis in paper: [explicit] The study analyzed 166 companies across 12 industries, revealing varying levels of ESG disclosure and data extraction accuracy.
- Why unresolved: The paper provides an overview of performance across industries but does not delve into detailed comparative analysis or identify specific challenges unique to certain sectors.
- What evidence would resolve it: A detailed comparative analysis of ESGReveal's performance across different industries, highlighting sector-specific challenges and proposing tailored solutions to address them.

### Open Question 3
- Question: What are the potential improvements in ESG data extraction accuracy and disclosure analysis by incorporating multilingual capabilities into ESGReveal, considering the global nature of ESG reporting?
- Basis in paper: [inferred] The paper does not address the multilingual capabilities of ESGReveal, which could be crucial for analyzing ESG reports from non-English speaking regions.
- Why unresolved: The current ESGReveal system's language capabilities are not specified, and there is no discussion on how it handles reports in languages other than English.
- What evidence would resolve it: Implementation of multilingual support in ESGReveal, followed by testing its effectiveness on ESG reports in various languages to assess improvements in data extraction and analysis accuracy.

## Limitations
- Performance claims rely heavily on Hong Kong Stock Exchange dataset, limiting generalizability to other markets
- ESG metadata framework appears manually constructed, raising scalability concerns as reporting standards evolve
- Evaluation focuses on accuracy metrics without addressing computational efficiency or deployment costs

## Confidence

**High Confidence:** The overall system architecture and methodology description is detailed and reproducible, with clear explanations of the RAG framework and preprocessing steps.

**Medium Confidence:** The accuracy metrics (76.9% for data extraction, 83.7% for disclosure analysis) are specific but rely on manual annotation that isn't fully detailed in the paper.

**Low Confidence:** The generalizability of results to other ESG reporting frameworks (GRI, SASB, TCFD) and geographic markets beyond Hong Kong remains uncertain.

## Next Checks

1. **Cross-market validation test:** Apply ESGReveal to ESG reports from companies listed on different stock exchanges (e.g., NYSE, LSE) to assess performance consistency across reporting standards and geographic regions.

2. **Component dependency analysis:** Conduct a more granular ablation study by systematically disabling individual preprocessing steps (layout analysis, table extraction) to quantify their marginal contributions to overall accuracy.

3. **Longitudinal performance tracking:** Evaluate the system's accuracy over multiple reporting years (2020-2023) to identify whether performance degrades as ESG reporting formats evolve and new indicators emerge.