---
ver: rpa2
title: 'U-CREAT: Unsupervised Case Retrieval using Events extrAcTion'
arxiv_id: '2307.05260'
source_url: https://arxiv.org/abs/2307.05260
tags:
- bm25
- legal
- events
- retrieval
- case
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new dataset for the task of prior case
  retrieval (PCR) in the legal domain, focusing on the Indian legal system. The proposed
  method, U-CREAT, leverages event extraction to improve retrieval performance.
---

# U-CREAT: Unsupervised Case Retrieval using Events extrAcTion

## Quick Facts
- arXiv ID: 2307.05260
- Source URL: https://arxiv.org/abs/2307.05260
- Reference count: 16
- U-CREAT significantly outperforms BM25 baselines on both Indian and Canadian legal systems with faster inference times

## Executive Summary
This paper introduces U-CREAT, an unsupervised method for Prior Case Retrieval (PCR) in legal domains that leverages event extraction to improve retrieval performance. The method extracts predicate-argument tuples from legal documents and uses them to compute relevance scores, achieving state-of-the-art results on both a newly created IL-PCR dataset for the Indian legal system and an existing COLIEE benchmark. Experiments demonstrate that event-based representations filter noise from lengthy legal documents, generalize across different legal systems, and achieve faster inference times compared to traditional word-based methods.

## Method Summary
U-CREAT extracts events (predicate-argument tuples) from legal documents using dependency parsing, then creates document representations based on these events. The method applies BM25 variants to different representations including atomic events, non-atomic events, and events filtered documents. Retrieval performance is evaluated using micro-averaged F1 score at optimal top-K retrieved documents, comparing against baselines like standard BM25 and transformer-based approaches. The approach is fully unsupervised and demonstrates cross-system generalization between Indian and Canadian legal corpora.

## Key Results
- U-CREAT achieves F1 scores of 0.4703 on IL-PCR test set, outperforming BM25 baseline (0.3392)
- Cross-system generalization: U-CREAT outperforms existing approaches on COLIEE-21 benchmark
- Inference speed: Event-based BM25 with trigrams runs 50% faster than word-based BM25

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Event extraction filters out non-relevant information from long legal documents, improving retrieval performance
- Mechanism: By extracting predicate-argument tuples (events) from legal documents, the method creates a concise representation focusing on key actions and participants, reducing noise from irrelevant sections
- Core assumption: Events capture the most relevant factual and precedent information needed for prior case retrieval
- Evidence anchors: [abstract] "events obtained via a dependency parser play an essential role in providing a short summary of long judgment documents, hence reducing the noise"; [section 4.1] "Events play an important role in establishing the relationship between a case and a cited (precedent) case"
- Break condition: If events extracted are not representative of the document's relevance (e.g., events from boilerplate sections or procedural details), the filtering would remove relevant information instead of noise

### Mechanism 2
- Claim: Event-based representations generalize across different legal systems without tuning
- Mechanism: The method uses syntactic dependency parsing to extract events, which are language-agnostic structural features, allowing the same approach to work on both Indian and Canadian legal systems
- Core assumption: The structural patterns of events in legal documents are similar enough across legal systems for this method to transfer
- Evidence anchors: [abstract] "Our proposed system is generic, we show that it generalizes across two different legal systems (Indian and Canadian)"; [section 5.2] "The proposed event-based approaches outperform the existing approaches by a significant margin highlighting the effectiveness of events in legal document retrieval"
- Break condition: If legal systems have fundamentally different event structures or if the dependency parser performs significantly worse on one system, the generalization would fail

### Mechanism 3
- Claim: Event-based methods achieve faster inference times than word-based BM25 methods
- Mechanism: By representing documents as sets of events rather than words, the method reduces computational complexity as event-based BM25 with trigrams performs similarly to word-based BM25 but with fewer terms to process
- Core assumption: The number of events in a document is significantly smaller than the number of words, leading to faster computation
- Evidence anchors: [section 5.3] "Events BM25 (trigram) model has a much faster inference time of 15.2 minutes, which is approximately 50% faster than the Word BM25 (unigram) model"; [section 5.3] "Event Filtered Docs BM25 (quadgram) model also has a relatively fast inference time of 24.42 minutes, which is about 10% faster than the Word BM25 (unigram) model"
- Break condition: If event extraction is computationally expensive or if the number of events approaches the number of words, the speed advantage would disappear

## Foundational Learning

- Concept: Dependency parsing and event extraction
  - Why needed here: The method relies on extracting predicate-argument tuples to represent documents, which requires understanding syntactic relationships between words
  - Quick check question: Can you explain the difference between a subject, object, and indirect object in dependency parsing?

- Concept: Information retrieval metrics (Precision, Recall, F1)
  - Why needed here: The evaluation uses micro-averaged F1 score to compare retrieval performance across different methods
  - Quick check question: How would you calculate F1 score given precision and recall values?

- Concept: Transformer models and fine-tuning strategies
  - Why needed here: The method compares against transformer-based approaches and uses fine-tuning strategies like SimCSE for sentence embeddings
  - Quick check question: What is the difference between masked language modeling and contrastive learning in transformer fine-tuning?

## Architecture Onboarding

- Component map: Input documents -> Dependency parser -> Event extraction -> Document representation (atomic/non-atomic/events filtered) -> BM25 scoring -> Ranked output

- Critical path:
  1. Parse documents with dependency parser
  2. Extract events (predicate-argument tuples)
  3. Create document representations based on events
  4. Compute BM25 scores using event-based representations
  5. Rank candidates by relevance score

- Design tradeoffs:
  - Event granularity: Atomic events preserve event structure but may miss word-level similarities; non-atomic events capture more details but lose event boundaries
  - Document preprocessing: Removing citation sentences may reduce noise but could remove relevant context
  - Model complexity: Simpler event representations are faster but may miss nuanced relationships

- Failure signatures:
  - Poor performance: Events extracted are not representative of document relevance
  - Slow inference: Event extraction is computationally expensive or generates too many events
  - Generalization failure: Events don't capture relevant information in a different legal system

- First 3 experiments:
  1. Compare F1 scores of atomic vs non-atomic event representations on a small subset
  2. Measure event extraction time vs document length to verify speed advantage
  3. Test cross-system performance by training on Indian data and evaluating on Canadian data

## Open Questions the Paper Calls Out

- Question: How can we further improve the performance of event-based methods for Prior Case Retrieval by incorporating additional legal information such as statutes and laws?
- Basis in paper: [inferred] The paper mentions that event-based methods partially address the limitations of PCR, where relevance may sometimes differ from lexical/semantic similarity. It suggests incorporating more legal information like statutes and laws to improve performance.
- Why unresolved: The paper does not explore the use of statutes and laws in event-based methods, and it remains unclear how their inclusion would impact the retrieval performance.
- What evidence would resolve it: Experiments comparing event-based methods with and without the inclusion of statutes and laws, along with an analysis of the impact on retrieval performance, would provide insights into the effectiveness of incorporating additional legal information.

- Question: Can event-based methods be combined with supervised techniques like contrastive learning to develop more efficient models for Prior Case Retrieval?
- Basis in paper: [inferred] The paper mentions the potential of combining event-based methods with supervised techniques such as contrastive learning to improve the task of PCR. However, it does not provide any experiments or analysis to support this claim.
- Why unresolved: The paper does not explore the combination of event-based methods with supervised techniques like contrastive learning, leaving the effectiveness of such an approach unknown.
- What evidence would resolve it: Experiments comparing event-based methods with and without the incorporation of supervised techniques like contrastive learning, along with an analysis of the impact on retrieval performance, would provide insights into the potential benefits of combining these approaches.

- Question: How does the proposed event-based framework generalize over other legal corpora, and what factors influence its performance in different legal systems?
- Basis in paper: [explicit] The paper mentions that the proposed event-based framework generalizes well across different legal systems (Indian and Canadian systems) without any law/demography-specific tuning of models. However, it does not provide an in-depth analysis of the factors influencing its performance in different legal systems.
- Why unresolved: The paper does not explore the factors that influence the performance of the event-based framework in different legal systems, leaving the understanding of its generalizability limited.
- What evidence would resolve it: Experiments evaluating the performance of the event-based framework on a diverse set of legal corpora from different legal systems, along with an analysis of the factors influencing its performance, would provide insights into its generalizability and the factors that impact its effectiveness.

## Limitations
- Performance on adversarial cases where events don't capture key legal concepts remains untested
- Scalability to larger legal systems or non-English languages is unexplored
- Paper doesn't address potential bias introduced by event filtering that might systematically exclude certain types of relevant cases

## Confidence
- Cross-system generalization claim: Medium confidence (demonstrated on only two legal systems with limited diversity)
- Event-based retrieval superiority: High confidence (consistent F1 improvements across multiple metrics on IL-PCR)
- Speed advantage claim: Low confidence (only relative timing comparisons without absolute benchmarks or detailed computational analysis)

## Next Checks
1. Create test cases where the most relevant prior case doesn't share obvious events with the query to verify the method doesn't miss cases based solely on event overlap
2. Test the method on a multilingual legal corpus to validate whether event extraction truly generalizes across languages or if it's specifically tuned to English dependency structures
3. Systematically remove different types of events (procedural vs substantive) to identify which event categories contribute most to retrieval performance and whether certain event types introduce noise