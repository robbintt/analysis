---
ver: rpa2
title: 'ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving'
arxiv_id: '2309.17452'
source_url: https://arxiv.org/abs/2309.17452
tags:
- reasoning
- sqrt
- language
- math
- tora
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces TORA, a tool-integrated reasoning agent for
  mathematical problem solving. TORA combines natural language reasoning with program-based
  tool use to solve challenging mathematical problems.
---

# ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving

## Quick Facts
- arXiv ID: 2309.17452
- Source URL: https://arxiv.org/abs/2309.17452
- Reference count: 40
- Primary result: TORA-7B achieves 44.6% accuracy on MATH dataset, surpassing best open-source model WizardMath-70B by 22% absolute

## Executive Summary
TORA introduces a novel tool-integrated reasoning agent that combines natural language reasoning with program-based tool use for mathematical problem solving. The method interleaves natural language rationales with program-based tool execution, leveraging the complementary strengths of both modalities. Through output space shaping and fine-tuning on curated tool-use trajectories, TORA achieves state-of-the-art performance on mathematical reasoning tasks, with the 34B variant being the first open-source model to exceed 50% accuracy on the competition-level MATH dataset.

## Method Summary
TORA trains models to interleave natural language rationales with program-based tool use for mathematical problem solving. The approach involves collecting interactive tool-use trajectories on mathematical datasets using GPT-4, applying imitation learning on the annotations, and implementing output space shaping to refine reasoning behavior. The method uses both LLaMA-2 and CodeLLaMA as base models, with CodeLLaMA showing particular advantage for program-based tool use. The output space shaping technique samples diverse tool-use trajectories, keeps valid ones, corrects invalid ones with a teacher model, and retrains on this expanded dataset to improve reasoning performance.

## Key Results
- TORA models achieve 13%-19% absolute improvements over open-source models across all scales on 10 mathematical reasoning datasets
- TORA-7B reaches 44.6% accuracy on MATH, surpassing WizardMath-70B by 22% absolute
- TORA-CODE-34B is the first open-source model to exceed 50% accuracy on MATH, competitive with GPT-4's program-based solving

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Interleaving natural language rationales with program-based tool use significantly improves mathematical reasoning performance
- Mechanism: Natural language excels at semantic analysis, planning, and abstract reasoning while programs excel at precise computation, symbolic manipulation, and algorithmic processing
- Core assumption: The reasoning process can be effectively decomposed into steps where natural language is more appropriate for analysis and planning, and programs are more appropriate for precise computation and symbolic manipulation
- Evidence anchors: [abstract] "TORA series solve challenging mathematical problems by leveraging both natural language reasoning and program-based tool use"; [section] "Natural language is suitable for semantic analysis, planning, and abstract reasoning... programs excel in rigorous operations"

### Mechanism 2
- Claim: Output space shaping improves reasoning performance by encouraging diverse valid trajectories and reducing improper tool-use behavior
- Mechanism: Instead of relying solely on imitation learning from curated trajectories, TORA samples diverse tool-use trajectories, keeps valid ones, corrects invalid ones with a teacher model, and retrains on this expanded dataset
- Core assumption: Many incorrect trajectories have plausible reasoning steps that can be corrected, and exposing the model to diverse valid trajectories improves its ability to explore plausible reasoning paths during testing
- Evidence anchors: [section] "Output space shaping significantly boosts reasoning performance, allowing open-source models to attain an accuracy exceeding 50% on the competition-level MATH dataset"

### Mechanism 3
- Claim: Using CodeLLaMA as the base model significantly benefits program-based tool use compared to LLaMA-2
- Mechanism: CodeLLaMA is trained on code data, making it more adept at generating and executing programs
- Core assumption: Pre-training on code data provides the model with better understanding of programming concepts, syntax, and execution patterns, which is crucial for effective tool integration
- Evidence anchors: [section] "The accuracy of TORA-CODE is about 5% higher than TORA of the same size, demonstrating that continued training on code data significantly benefits program-based tool use"

## Foundational Learning

- Concept: Tool-integrated reasoning format
  - Why needed here: This is the core innovation of TORA - the interleaved format of natural language rationales and program-based tool use
  - Quick check question: What are the two key components of the TORA reasoning format, and when is each component most appropriate to use?

- Concept: Output space shaping
  - Why needed here: This technique is crucial for improving TORA's performance beyond what's possible with simple imitation learning
  - Quick check question: What are the two main strategies used in output space shaping, and how do they complement each other?

- Concept: Tool execution and feedback integration
  - Why needed here: TORA's effectiveness depends on properly integrating tool execution outputs back into the reasoning process
  - Quick check question: How does TORA handle tool execution outputs, and what mechanisms exist for correcting errors that arise during tool use?

## Architecture Onboarding

- Component map: Input processor -> Natural language generator -> Program generator -> Tool executor -> Output processor -> Training pipeline
- Critical path: Problem → Rationale → Program → Tool Execution → Output → Next Rationale → Answer
- Design tradeoffs:
  - Granularity of tool use: More frequent tool use provides precision but increases complexity
  - Teacher model selection: Larger models provide better corrections but are more expensive
  - Sampling strategy: More samples increase diversity but also computational cost
  - Stopping criteria: Earlier stopping reduces computation but may miss better solutions
- Failure signatures:
  - Tool execution timeouts indicate overly complex programs or insufficient computational resources
  - Incorrect tool outputs suggest programming errors or inappropriate tool selection
  - Stuck in loops indicates poor stopping criteria or inadequate error handling
  - Poor generalization suggests insufficient diversity in training trajectories
- First 3 experiments:
  1. Implement basic TORA format with single tool use per problem and compare to pure natural language or pure program approaches
  2. Test output space shaping with different numbers of sampled trajectories and evaluate impact on performance
  3. Compare LLaMA-2 and CodeLLaMA as base models to quantify the benefit of code pre-training for tool integration

## Open Questions the Paper Calls Out

- How can we effectively incorporate visual modalities and image interactions to improve geometric reasoning capabilities in TORA?
- What are the most effective strategies for handling complex symbolic reasoning over algebraic expressions and conditions in problems like Intermediate Algebra and Precalculus?
- How can we further improve the diversity and quality of tool-use trajectories in TORA's training data?
- How can we effectively scale TORA to larger and more diverse mathematical domains beyond the current focus on arithmetic, algebra, geometry, and number theory?

## Limitations

- TORA is limited to mathematical problems that can be formalized through equations and algorithms, making it unsuitable for geometric problems requiring spatial understanding or visual modalities
- Complex symbolic reasoning over algebraic expressions and conditions remains challenging, with the system prone to timeout exceptions or incorrect solutions
- Performance on out-of-distribution datasets suggests potential overfitting to training data patterns

## Confidence

**High Confidence Claims:**
- TORA models significantly outperform open-source models on the tested mathematical reasoning datasets
- The interleaving of natural language and program-based tool use represents a valid approach for mathematical problem solving
- CodeLLaMA provides better performance than LLaMA-2 for tool-integrated reasoning tasks

**Medium Confidence Claims:**
- The 13%-19% average improvement across all scales represents a meaningful advance in mathematical reasoning
- Output space shaping is the primary driver of TORA's competitive performance with GPT-4
- The first open-source model exceeding 50% accuracy on MATH represents a significant milestone

**Low Confidence Claims:**
- The specific mechanism by which interleaving improves reasoning beyond what either modality achieves alone
- The generalizability of TORA's approach to non-mathematical reasoning tasks
- The long-term stability and scalability of the output space shaping technique

## Next Checks

1. **Generalization Test**: Evaluate TORA on a broader set of mathematical problems including geometric reasoning and visual math problems to quantify the stated limitations regarding spatial understanding and visual modalities.

2. **Ablation Study**: Systematically remove components of the TORA system (natural language reasoning, program-based tools, output space shaping) to quantify the individual contribution of each mechanism to overall performance.

3. **Cross-Domain Transfer**: Test TORA on non-mathematical reasoning tasks that could benefit from tool integration (e.g., scientific reasoning, logical puzzles) to assess whether the interleaving approach generalizes beyond mathematical domains.