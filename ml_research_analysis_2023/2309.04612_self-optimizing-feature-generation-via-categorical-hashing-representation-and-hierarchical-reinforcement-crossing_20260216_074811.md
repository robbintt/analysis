---
ver: rpa2
title: Self-optimizing Feature Generation via Categorical Hashing Representation and
  Hierarchical Reinforcement Crossing
arxiv_id: '2309.04612'
source_url: https://arxiv.org/abs/2309.04612
tags:
- feature
- generation
- features
- reinforcement
- crossing
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper presents a principled framework for self-optimizing
  feature generation using hierarchical reinforcement crossing and categorical hashing
  representation. The method addresses three key challenges in feature generation:
  meaningful generation by learning feature-feature interactions through reinforcement
  agents, robustness against outlier feature values through discretization, and efficiency
  by reducing search space through hierarchical control.'
---

# Self-optimizing Feature Generation via Categorical Hashing Representation and Hierarchical Reinforcement Crossing

## Quick Facts
- arXiv ID: 2309.04612
- Source URL: https://arxiv.org/abs/2309.04612
- Authors: 
- Reference count: 36
- Key outcome: Proposed method achieves accuracy improvements of up to 5.4% over baselines on four datasets using hierarchical reinforcement crossing and categorical hashing representation

## Executive Summary
This paper introduces a principled framework for self-optimizing feature generation that addresses three key challenges: meaningful feature generation through learning feature-feature interactions, robustness against outliers via discretization, and efficiency through hierarchical control. The method employs a three-step approach (discretization, hashing, and summarization) to create fixed-length state representations from dynamically-varying feature spaces, and uses two reinforcement agents (meta controller and controller) to iteratively generate meaningful features. Experiments demonstrate superior performance across logistic regression, decision tree, and random forest classifiers, with the method converging quickly in just 6-8 episodes.

## Method Summary
The framework converts continuous features to categorical bins, maps categorical features to a smaller fixed set of integers using hashing, and extracts fixed-length state representations through descriptive statistics. A hierarchical reinforcement learning approach uses a meta-controller DQN to select meta features and a controller DQN to select features for crossing. The agents are trained alternately on memory batches with a reward function combining accuracy, feature relevance, and redundancy. The method is evaluated on four datasets with varying numbers of samples and features, using classification accuracy, precision, recall, and F-measure as metrics.

## Key Results
- Achieves accuracy improvements of up to 5.4% on some datasets compared to state-of-the-art baselines
- Converges quickly in just 6-8 episodes, making it efficient for real-world applications
- Demonstrates superior performance across logistic regression, decision tree, and random forest classifiers
- Effectively handles dynamically-varying feature spaces through fixed-length state representation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Discretization converts continuous features into categorical bins, preventing outlier propagation during feature crossing.
- **Mechanism**: By binning continuous values, extreme values are grouped with similar neighbors, reducing their disproportionate influence when crossed with other features. This ensures generated features are not dominated by anomalies.
- **Core assumption**: The distribution of feature values within each bin is sufficiently homogeneous to preserve the underlying data pattern.
- **Evidence anchors**:
  - [abstract]: "discretization of feature values before generation is useful because categorical feature crossing can robustilize FG to fight against outlier numeric or continuous feature values"
  - [section]: "Binning smooths a continuous data value by consulting its neighborhood, transforms the value into a discrete category, and ensures that data in the same bin is similar and data in different bins are more distinguishable."
- **Break condition**: If the binning threshold is too coarse, it may lose meaningful distinctions between values; if too fine, outliers may still have undue influence.

### Mechanism 2
- **Claim**: Feature hashing reduces dimensionality while preserving feature space patterns, enabling efficient state representation extraction.
- **Mechanism**: A hash function maps categorical feature values to a smaller fixed set of integers, preventing dimensionality explosion that would occur with one-hot encoding. This allows for fast computation of descriptive statistics over the hashed feature table.
- **Core assumption**: The hash function distributes feature values uniformly across the target space, minimizing collisions that could distort feature space patterns.
- **Evidence anchors**:
  - [abstract]: "feature hashing can reduce the size of the data table, and help to complete the next step of descriptive summarization in a short time"
  - [section]: "Since a hashing function can map all categorical data into a smaller fixed set, the use of hashing can greatly reduce the number of categories and prevent dimensional explosion."
- **Break condition**: Excessive hash collisions could merge distinct feature values, losing important information for feature generation.

### Mechanism 3
- **Claim**: Hierarchical reinforcement learning balances exploration and exploitation by using meta-controller and controller agents to select features for crossing.
- **Mechanism**: The meta-controller selects a "meta feature" based on the current state, then the controller selects a feature to cross with the meta feature. This hierarchical structure allows for temporal abstraction and long-term reward optimization, avoiding local optima that greedy methods might get stuck in.
- **Core assumption**: The feature selection process can be modeled as a Markov Decision Process where the current state contains sufficient information to make optimal decisions about future feature crossings.
- **Evidence anchors**:
  - [abstract]: "hierarchical reinforcement crossing of meta feature and crossed feature to generate meaningful dimensions in the crossing step"
  - [section]: "The hierarchical agent design includes a meta controller agent and a controller agent to sense feature-feature interaction to select a meta feature and a crossed feature that are the most appropriate for crossing new meaningful dimensions."
- **Break condition**: If the state representation fails to capture relevant information about feature interactions, the agents may make suboptimal selections.

## Foundational Learning

- **Concept**: Reinforcement Learning (RL) - learning through interaction with an environment to maximize cumulative reward
  - **Why needed here**: Feature generation is framed as an optimization problem where the "reward" is improved model performance. RL allows the system to learn which feature combinations are most valuable without exhaustive enumeration.
  - **Quick check question**: What distinguishes RL from supervised learning in the context of feature generation?

- **Concept**: Feature Hashing - mapping high-dimensional categorical data to a lower-dimensional space using hash functions
  - **Why needed here**: One-hot encoding categorical features would create an exponentially growing feature space. Hashing provides a computationally efficient alternative that maintains feature space patterns.
  - **Quick check question**: How does feature hashing differ from one-hot encoding in terms of dimensionality and computational complexity?

- **Concept**: Mutual Information - a measure of the mutual dependence between two random variables
  - **Why needed here**: Used to quantify feature-feature redundancy and feature-label relevance, which are incorporated into the reward function to guide the reinforcement learning agents toward generating diverse and predictive features.
  - **Quick check question**: How does mutual information differ from correlation as a measure of feature relationship?

## Architecture Onboarding

- **Component map**: Discretization module -> Hashing module -> Descriptive statistics module -> State Representation -> Meta-controller DQN -> Controller DQN -> Feature Crossing -> Reward Calculation -> Memory Update -> Network Training

- **Critical path**: Discretization → Hashing → Descriptive Statistics → State Representation → Meta-controller Action → Controller Action → Feature Crossing → Reward Calculation → Memory Update → Network Training

- **Design tradeoffs**:
  - Binning granularity vs. outlier robustness
  - Hash table size vs. collision probability
  - State representation complexity vs. computational efficiency
  - Exploration rate in RL vs. convergence speed

- **Failure signatures**:
  - Poor performance despite many iterations: likely issue with state representation or reward function
  - Extremely slow convergence: may indicate insufficient exploration or inappropriate hyperparameters
  - Generated features showing high redundancy: potential issue with mutual information calculation or reward weighting

- **First 3 experiments**:
  1. **Sanity check**: Run on a simple dataset (e.g., iris) with known feature interactions to verify the pipeline produces meaningful cross-features
  2. **Ablation study**: Compare performance with and without discretization to quantify outlier robustness
  3. **Hyperparameter sensitivity**: Test different hash table sizes and binning thresholds to find optimal settings for a given dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed hierarchical reinforcement crossing framework handle feature interaction detection in high-dimensional sparse datasets where mutual information becomes less reliable?
- Basis in paper: [explicit] The paper mentions using mutual information for feature-label relevance and feature-feature redundancy, but acknowledges this becomes challenging in sparse datasets.
- Why unresolved: The paper demonstrates effectiveness on datasets with 9-120 features but doesn't explore extremely high-dimensional scenarios (1000+ features) or explicitly address sparsity challenges.
- What evidence would resolve it: Experiments showing performance degradation on increasingly sparse high-dimensional datasets, or alternative interaction detection mechanisms for sparse data.

### Open Question 2
- Question: What is the impact of discretization granularity on the final model performance, and is there an optimal binning strategy that works across different domains?
- Basis in paper: [explicit] The paper mentions using hierarchical bottom-up clustering and X²-distribution for automated binning, but doesn't explore the sensitivity of this parameter.
- Why unresolved: The paper uses a specific discretization approach but doesn't systematically study how different binning strategies or granularity levels affect performance across various datasets.
- What evidence would resolve it: Comprehensive experiments varying discretization parameters and measuring their impact on downstream task performance across diverse datasets.

### Open Question 3
- Question: How does the framework scale with dataset size, particularly regarding memory requirements for the DQN training process?
- Basis in paper: [inferred] The paper mentions setting memory to 40 for each DQN and using batch size of 20, but doesn't explore scalability beyond the tested datasets.
- Why unresolved: The paper focuses on moderate-sized datasets (30K-120K samples) without discussing computational complexity or memory requirements for much larger datasets (millions of samples).
- What evidence would resolve it: Performance and memory usage measurements on progressively larger datasets, including time and resource requirements for training convergence.

### Open Question 4
- Question: Can the hierarchical reinforcement crossing approach be effectively extended to regression tasks, or are there fundamental limitations that prevent this adaptation?
- Basis in paper: [explicit] The paper mentions that "in the regression task, this method will lose data accuracy when discretizing continuous variables" and only tested on classification tasks.
- Why unresolved: The paper acknowledges potential limitations for regression but doesn't explore whether modifications could overcome these limitations or identify fundamental barriers.
- What evidence would resolve it: Experiments testing modified versions of the framework on regression tasks, or theoretical analysis identifying specific challenges that cannot be overcome.

## Limitations
- The method requires discretization of continuous variables, which may lose important information in regression tasks
- The framework's effectiveness on extremely high-dimensional or sparse datasets has not been established
- The sensitivity to discretization granularity and hashing parameters across different domains remains unexplored

## Confidence
**High confidence**: The hierarchical reinforcement learning framework and its basic implementation are well-specified and reproducible. The three-step categorical hashing representation (discretization, hashing, summarization) is clearly described with sufficient detail for implementation.

**Medium confidence**: The empirical results showing performance improvements over baselines are convincing for the tested datasets, but the generalization to other domains and the sensitivity to hyperparameters are not fully established.

**Low confidence**: The theoretical claims about why the method works (e.g., specific mechanisms by which discretization prevents outlier propagation) lack rigorous mathematical justification or extensive empirical validation across diverse datasets.

## Next Checks
1. **Hyperparameter sensitivity analysis**: Systematically vary discretization binning thresholds, hash table sizes, and reward function weights across multiple datasets to identify robust configurations and quantify performance variance.

2. **Collision impact study**: Measure hash collision rates and their correlation with performance degradation by comparing against alternative hashing schemes or direct one-hot encoding on smaller datasets where computational cost is manageable.

3. **Generalization test**: Apply the method to datasets from different domains (e.g., text, image features, time series) to evaluate whether the hierarchical reinforcement crossing approach maintains its effectiveness when feature distributions and interaction patterns differ significantly from the tested tabular datasets.