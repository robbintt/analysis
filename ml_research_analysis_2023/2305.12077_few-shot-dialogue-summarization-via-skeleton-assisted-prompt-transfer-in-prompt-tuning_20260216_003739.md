---
ver: rpa2
title: Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer in Prompt
  Tuning
arxiv_id: '2305.12077'
source_url: https://arxiv.org/abs/2305.12077
tags:
- dialogue
- prompt
- transfer
- task
- summarization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of few-shot dialogue summarization,
  where labeled samples are limited due to high annotation costs. The proposed method,
  Skeleton-Assisted Prompt Transfer (SAPT), leverages dialogue state tracking as a
  source task to improve cross-task knowledge transfer in prompt tuning.
---

# Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer in Prompt Tuning

## Quick Facts
- arXiv ID: 2305.12077
- Source URL: https://arxiv.org/abs/2305.12077
- Authors: 
- Reference count: 28
- Key outcome: SAPT improves few-shot dialogue summarization with up to 9.8 ROUGE points improvement on TODS UM dataset

## Executive Summary
This paper addresses the challenge of few-shot dialogue summarization where labeled samples are limited due to high annotation costs. The authors propose Skeleton-Assisted Prompt Transfer (SAPT), a method that leverages dialogue state tracking as a source task to improve cross-task knowledge transfer in prompt tuning. SAPT uses skeleton generation as extra supervision, extracted via perturbation-based probes, to connect the distinct source and target tasks and preserve model capability during prompt transfer. Experiments on two dialogue summarization benchmarks demonstrate significant performance improvements over existing baselines.

## Method Summary
SAPT leverages dialogue state tracking (DST) as a source task for cross-task knowledge transfer to dialogue summarization. The method consists of three key steps: first, soft prompts are trained on the DST task; second, skeletons are extracted from the model using perturbation-based probes; third, these skeletons serve as extra supervision during prompt transfer to the target task. The skeleton generation acts as an intermediate task-specific medium that shares semantic overlap with both source and target tasks, facilitating knowledge transfer. By training on skeletons extracted with perturbation-based probes, SAPT also preserves model capability during the transfer process.

## Key Results
- SAPT achieves significant performance improvements on few-shot dialogue summarization tasks
- On TODS UM dataset, SAPT improves ROUGE scores by up to 9.8 points compared to baseline methods
- On SPN ET dataset, SAPT improves ROUGE scores by up to 8.5 points
- SAPT [DST+SUMM] variant consistently outperforms other variants, indicating the importance of combined supervision

## Why This Works (Mechanism)

### Mechanism 1
Skeleton-Assisted Prompt Transfer improves cross-task knowledge transfer by using skeleton generation as an intermediate task-specific medium between DST and dialogue summarization. By incorporating skeleton generation as extra supervision, SAPT creates an intermediate task that shares more semantic overlap with both source and target tasks, facilitating better knowledge transfer. The core assumption is that skeleton generation captures dialogue-state-related information relevant to both tasks. Evidence shows SAPT outperforms baselines, though the literature suggests moderate relevance in cross-task transfer methods.

### Mechanism 2
SAPT preserves model capability during prompt transfer by training on skeletons extracted with perturbation-based probes. The skeletons embody model sensitivity to dialogue-state information, which represents model capability. Training on these skeletons helps maintain the model's dialogue-state processing ability during transfer. The core assumption is that perturbation-based probe sensitivity correlates with model capability, though this connection lacks direct empirical validation.

### Mechanism 3
SAPT's effectiveness depends on the specific order of supervision incorporation and supervision sources used. Different variants (DST, SUMM, DST+SUMM) perform differently, indicating that the combination and order of source/target task supervision with skeleton generation matters for optimal transfer. The work shows that DST+SUMM achieves the highest ROUGE scores, suggesting that both source task preservation and target task guidance are important.

## Foundational Learning

- Concept: Few-shot learning
  - Why needed here: The paper addresses the problem where labeled samples for dialogue summarization are limited, requiring techniques that can learn effectively from few examples
  - Quick check question: What is the difference between few-shot learning and zero-shot learning in the context of NLP tasks?

- Concept: Prompt tuning and prompt transfer
  - Why needed here: SAPT builds on prompt tuning as a parameter-efficient transfer learning technique, using soft prompts that are transferred from source to target tasks
  - Quick check question: How does prompt tuning differ from traditional fine-tuning of language models?

- Concept: Dialogue state tracking (DST)
  - Why needed here: DST serves as the source task in SAPT, providing the knowledge that needs to be transferred to the dialogue summarization task
  - Quick check question: Why is DST considered easier to annotate than dialogue summarization, making it a good source task for transfer?

## Architecture Onboarding

- Component map: BART-large backbone -> soft prompt embeddings (φ) -> perturbation-based probe module -> skeleton extraction -> combined supervision prompt tuning
- Critical path: Source task (DST) prompt tuning → perturbation-based skeleton extraction → combined supervision prompt tuning → target task (dialogue summarization) prompt tuning
- Design tradeoffs: Parameter efficiency vs. performance (prompt tuning vs. full fine-tuning), intermediate task complexity vs. transfer effectiveness, perturbation sensitivity vs. noise in skeleton extraction
- Failure signatures: Poor ROUGE scores indicating ineffective transfer, significant performance drop when skeleton supervision is removed, failure to improve over baseline prompt transfer
- First 3 experiments:
  1. Test SAPT with different skeleton types (random vs. perturbation-based) to verify the importance of the extraction method
  2. Evaluate different decoding orders (prepend vs. append skeletons) to understand the impact of supervision ordering
  3. Test SAPT variants with and without source/target task supervision to isolate the contribution of skeleton generation

## Open Questions the Paper Calls Out
- The paper acknowledges that summaries generated by SAPT might contain information unmentioned in the dialogue, raising concerns about hallucination and faithfulness of generated summaries.

## Limitations
- The paper lacks empirical validation for core mechanisms, with no ablation studies showing what happens when skeleton supervision is removed
- The assumption that perturbation-based probe sensitivity directly correlates with model capability is not empirically validated
- The work does not explore alternative skeleton extraction methods beyond perturbation-based probes and random selection

## Confidence
- High Confidence: Experimental results showing SAPT outperforms baseline methods on both TODS UM and SPN ET datasets
- Medium Confidence: Claims about cross-task knowledge transfer benefits from DST to dialogue summarization
- Low Confidence: Claims that training on perturbation-based probe-extracted skeletons preserves model capability during prompt transfer

## Next Checks
1. Conduct ablation studies removing skeleton generation supervision to quantify its exact contribution to performance improvements, and compare SAPT with and without perturbation-based probe extraction versus random skeleton extraction
2. Design experiments that directly test whether perturbation-based probe sensitivity correlates with model capability by measuring performance on dialogue state tracking tasks before and after prompt transfer
3. Systematically test different combinations and orderings of supervision sources (DST only, SUMM only, DST→SUMM, SUMM→DST, DST+SUMM) with and without skeleton generation