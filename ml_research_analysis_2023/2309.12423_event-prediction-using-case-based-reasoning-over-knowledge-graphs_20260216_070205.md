---
ver: rpa2
title: Event Prediction using Case-Based Reasoning over Knowledge Graphs
arxiv_id: '2309.12423'
source_url: https://arxiv.org/abs/2309.12423
tags:
- event
- prediction
- entity
- relation
- effect
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a case-based reasoning approach, EvCBR, for
  event prediction in knowledge graphs. The problem is framed as 2-hop link prediction,
  where given a cause event, we predict properties about its effect event.
---

# Event Prediction using Case-Based Reasoning over Knowledge Graphs

## Quick Facts
- arXiv ID: 2309.12423
- Source URL: https://arxiv.org/abs/2309.12423
- Reference count: 40
- Key outcome: EvCBR outperforms or is competitive with baselines on event prediction in knowledge graphs

## Executive Summary
This paper proposes EvCBR, a case-based reasoning approach for event prediction in knowledge graphs. The model frames event prediction as a 2-hop link prediction problem, where given a cause event, it predicts properties of its effect event. EvCBR uses statistical measures to identify similar cause-effect cases in the KG and applies path-based reasoning to make predictions about unseen effect events. The model requires no training and can handle new events and changes in the KG. Experiments on a novel Wikidata-based event dataset and FB15k-237 show that EvCBR outperforms or is competitive with baselines including embedding-based, GNN-based, and rule-based link prediction models.

## Method Summary
EvCBR performs inductive link prediction for unseen entities by leveraging similarity between known cause-effect cases in the KG. The model computes entity similarity based on shared outgoing connections and subclass hierarchies, then uses this similarity to retrieve cases of past events that are similar to the query. Paths from these cases are sampled and scored to predict properties of the unseen effect event. The model optionally refines predictions by applying the prediction method in reverse to validate predictions. This approach allows EvCBR to adapt to new entities and changed relationships without any model updates.

## Key Results
- EvCBR achieves good results in predicting event properties and retrieving similar cases
- The model shows promise for event prediction applications, outperforming or being competitive with embedding-based, GNN-based, and rule-based link prediction models
- EvCBR's case-based reasoning approach is well-suited for KGs that frequently change, as it does not require retraining

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EvCBR performs inductive link prediction for unseen entities by leveraging similarity between known cause-effect cases in the KG.
- Mechanism: The model computes entity similarity based on shared outgoing connections and subclass hierarchies, then uses this similarity to retrieve cases of past events that are similar to the query. Paths from these cases are sampled and scored to predict properties of the unseen effect event.
- Core assumption: Similar cause-effect events in the KG will share similar properties and follow similar paths through the KG.
- Evidence anchors:
  - [abstract] "EvCBR uses statistical measures to identify similar events and performs path-based predictions, requiring no training step."
  - [section 4.1.1] "Our goal in this step is to acquire a very rough sense of similarity between individual entities, which will be utilized in our subsequent steps."
  - [corpus] Found 25 related papers, average neighbor FMR=0.512, indicating moderate relatedness of the corpus to the paper's topic.

### Mechanism 2
- Claim: EvCBR's score refinement step improves prediction accuracy by applying the prediction method in reverse to validate predictions.
- Mechanism: After making initial predictions about the unseen effect event, EvCBR temporarily treats the predicted triple as present in the KG and samples paths from the effect event to predict properties of the known cause event. The accuracy of these reverse predictions is used to refine the scores of the original predictions.
- Core assumption: If a predicted entity for the effect event is correct, paths from that entity should accurately predict properties of the cause event.
- Evidence anchors:
  - [section 4.4] "The key intuition behind this step is that if we have chosen the correct entity ð‘§ for the prediction triple (ð‘’, ð‘’ð‘Ÿ, ?ð‘§), we would expect that applying our prediction methods starting from the event ð‘’ to predict properties of ð‘ should yield good results."
  - [corpus] The corpus includes related work on case-based reasoning and rule-based systems, suggesting this refinement approach is novel and worth testing.

### Mechanism 3
- Claim: EvCBR's case-based reasoning approach is well-suited for KGs that frequently change, as it does not require retraining.
- Mechanism: Unlike embedding-based models that must be retrained as the KG changes, EvCBR relies on case retrieval and path sampling at prediction time. This allows it to adapt to new entities and changed relationships without any model updates.
- Core assumption: The similarity measures and path scoring methods used by EvCBR are robust to changes in the KG structure and content.
- Evidence anchors:
  - [abstract] "The model requires no training and can handle new events and changes in the KG."
  - [section 1] "Additionally, even for models that are capable of this task, some KGs (such as Wikidata) constantly undergo updates and changes, which can negatively affect a model's performance as its training data becomes outdated."
  - [corpus] The corpus includes related work on knowledge graph completion and reasoning, but no specific mention of handling changes in KGs, indicating this may be a novel contribution of EvCBR.

## Foundational Learning

- Concept: Knowledge graphs and link prediction
  - Why needed here: The paper proposes a method for performing link prediction over knowledge graphs to predict properties of unseen events. Understanding the structure of KGs and the link prediction task is essential to grasp the problem setup and the proposed solution.
  - Quick check question: What is the difference between standard link prediction and inductive link prediction, and why is the latter more challenging?

- Concept: Case-based reasoning
  - Why needed here: EvCBR is a case-based reasoning approach that leverages past cases of similar events to make predictions about new events. Understanding the principles of case-based reasoning is key to understanding how the model works and why it is effective.
  - Quick check question: What are the main steps in a case-based reasoning process, and how does EvCBR implement each of these steps?

- Concept: Entity similarity measures
  - Why needed here: EvCBR uses a specific entity similarity measure based on shared outgoing connections and subclass hierarchies. Understanding this measure and how it differs from other similarity measures is important for understanding how the model identifies similar cases.
  - Quick check question: How does EvCBR's entity similarity measure differ from simple Jaccard similarity or cosine similarity, and why is this difference important for the task?

## Architecture Onboarding

- Component map: Query event -> Case retrieval -> Path enumeration and scoring -> Prediction -> (Optional) Refinement
- Critical path: Case retrieval -> Path enumeration and scoring -> Prediction -> (Optional) Refinement
- Design tradeoffs:
  - Similarity measure: EvCBR uses a simple similarity measure based on shared outgoing connections and subclass hierarchies. More complex measures could potentially capture more nuanced similarities but may be more computationally expensive.
  - Number of cases and paths: The model retrieves a fixed number of cases and samples a fixed number of paths from each case. Tuning these hyperparameters can trade off between accuracy and efficiency.
  - Refinement step: The optional refinement step can improve accuracy but adds computational overhead. It may not always be necessary or beneficial.
- Failure signatures:
  - Low similarity scores: If the entity similarity measure fails to find any cases that are sufficiently similar to the query, the model will not have enough cases to base its predictions on.
  - Poor path sampling: If the path sampling fails to find paths that accurately predict the effect's properties, the scored paths will not lead to good predictions.
  - Inaccurate refinement: If the refinement step fails to validate the predictions or introduces errors, the final predictions may be worse than the initial ones.
- First 3 experiments:
  1. Test case retrieval: Given a set of query events, measure the similarity scores and retrieved cases for each query. Check if the retrieved cases are indeed similar to the queries based on human judgment.
  2. Test path scoring: Given a set of retrieved cases and paths, measure the path scores and compare them to the actual accuracy of the paths in predicting the effect's properties. Check if higher scores correspond to higher accuracy.
  3. Test end-to-end predictions: Given a set of query events, measure the final predictions and compare them to the ground truth. Check if the predictions are accurate and if the refinement step improves accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does EvCBR's performance scale when applied to KGs with significantly more complex causal relationships and larger numbers of events?
- Basis in paper: [inferred] The paper mentions EvCBR's effectiveness on a novel Wikidata-based event dataset and FB15k-237, but does not explore performance on larger, more complex KGs with deeper causal chains.
- Why unresolved: The current evaluation is limited to relatively simple 2-hop predictions and smaller datasets, leaving uncertainty about scalability.
- What evidence would resolve it: Experiments on KGs with multi-hop causal relationships, larger numbers of events, and more complex event hierarchies.

### Open Question 2
- Question: How does EvCBR handle situations where similar cause-effect event pairs are sparse or missing in the KG, leading to poor case retrieval?
- Basis in paper: [explicit] The paper notes that one failure pattern was when no particularly similar event pairs were present in the KG, due to Wikidata's variable coverage.
- Why unresolved: The paper acknowledges this limitation but does not propose solutions or explore the impact of sparse data on EvCBR's performance.
- What evidence would resolve it: Experiments testing EvCBR's performance on KGs with varying levels of event coverage and similarity, along with proposed methods to handle sparse data.

### Open Question 3
- Question: Can EvCBR's case-based reasoning approach be extended to handle temporal aspects of events, such as predicting the timing of effects or identifying causal chains over time?
- Basis in paper: [inferred] The paper focuses on predicting properties of events based on causal relationships, but does not explore temporal aspects or causal chains.
- Why unresolved: The current formulation treats events as static entities, ignoring the potential for temporal dependencies and causal chains that evolve over time.
- What evidence would resolve it: Modifications to EvCBR to incorporate temporal information, such as timestamps or event durations, and experiments on datasets with temporal event data.

## Limitations

- Handling of temporal aspects: The paper acknowledges that event prediction in KGs requires handling temporal aspects and dynamic changes, but the proposed EvCBR model does not explicitly address time-aware reasoning. The model treats events as static nodes without temporal ordering or time-aware path sampling.
- Generalization to unseen event types: While the model claims to handle new events without retraining, the experiments focus on predicting properties of events that already exist in the training set. The paper does not provide evidence for predicting entirely novel event types that have no similar cases in the KG.
- Performance on sparse data: The paper notes that EvCBR's performance can degrade when similar cause-effect event pairs are sparse or missing in the KG, but does not propose solutions or explore the impact of sparse data on the model's performance.

## Confidence

- EvCBR's performance advantage: High
- Handling of temporal aspects: Low
- Generalization to unseen event types: Medium

## Next Checks

1. **Temporal robustness test**: Evaluate EvCBR on a temporal knowledge graph dataset where events have time-stamps, measuring performance degradation as events become temporally distant from the training data.

2. **Extreme sparsity analysis**: Test the model on KGs with varying densities (from dense to extremely sparse) to determine the minimum number of similar cases required for reliable predictions.

3. **Ablation on similarity metrics**: Compare EvCBR's entity similarity measure against alternative similarity metrics (Jaccard, cosine, knowledge graph embeddings) to quantify the contribution of the proposed similarity approach to overall performance.