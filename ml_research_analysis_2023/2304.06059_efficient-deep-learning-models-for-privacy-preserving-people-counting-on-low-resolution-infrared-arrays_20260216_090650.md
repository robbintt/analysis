---
ver: rpa2
title: Efficient Deep Learning Models for Privacy-preserving People Counting on Low-resolution
  Infrared Arrays
arxiv_id: '2304.06059'
source_url: https://arxiv.org/abs/2304.06059
tags:
- people
- counting
- ieee
- which
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores efficient deep learning architectures for privacy-preserving
  people counting using low-resolution infrared sensors. The authors evaluate six
  different model types, including single-frame and multi-frame CNNs, LSTM, and TCN-based
  architectures, on a novel dataset collected from a commercial 8x8 IR array.
---

# Efficient Deep Learning Models for Privacy-preserving People Counting on Low-resolution Infrared Arrays

## Quick Facts
- arXiv ID: 2304.06059
- Source URL: https://arxiv.org/abs/2304.06059
- Reference count: 40
- This paper identifies Pareto-optimal deep learning models for 8x8 IR array people counting, achieving 55.70-82.70% balanced accuracy with 0.41-9.28kB memory footprint on commercial microcontrollers.

## Executive Summary
This paper addresses the challenge of privacy-preserving people counting using low-resolution infrared (IR) sensors by exploring efficient deep learning architectures. The authors evaluate six different model types—including single-frame and multi-frame CNNs, LSTM, and TCN-based architectures—on a novel dataset collected from a commercial 8x8 IR array. Through extensive architectural exploration and Pareto optimization, they identify models that achieve significant accuracy improvements (up to 39.9%) over deterministic baselines while meeting strict computational constraints for deployment on ultra-low-power IoT edge devices.

## Method Summary
The authors collected the LINAIGE dataset with 25,110 IR frames (8x8 pixels) from a ceiling-mounted Panasonic Grid-EYE sensor at 10 FPS, labeled with people counts (0-3). They implemented six deep learning model families using Keras/TensorFlow 2.0 and performed 4-fold cross-validation with session-based splits. The training protocol included ADAM optimization, categorical cross-entropy loss with class weighting, and quantization-aware training to 8-bit integers. Models were converted to TensorFlow Lite and deployed using the X-CUBE-AI toolchain on STM32L4A6ZG MCU, measuring model size, latency, and energy consumption.

## Key Results
- Deep learning models significantly outperform deterministic baselines (up to +39.9% accuracy) while being 3.53x faster and more energy efficient
- Best models achieve 55.70-82.70% balanced accuracy with 0.41-9.28kB memory footprint and 1.10-7.74ms inference time on commercial MCU
- Multi-frame architectures with temporal context consistently improve accuracy by capturing movement patterns
- Quantization-aware training successfully recovers accuracy loss from 8-bit quantization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Deep learning models outperform deterministic baselines in both accuracy and efficiency for low-resolution IR array people counting
- Mechanism: Data-driven models learn complex spatial and temporal patterns in IR frames that deterministic methods cannot capture, enabling better distinction between people and background objects while optimizing for the target hardware
- Core assumption: The dataset contains sufficient variability and labeled examples for models to learn discriminative features
- Evidence anchors:
  - [abstract] "Our models are significantly more accurate than a previous deterministic method (up to +39.9%), while being up to 3.53x faster and more energy efficient"
  - [section] "All Pareto-optimal models outperform the deterministic approach of [25], showing the benefit of data-driven methods for this task"
- Break condition: Insufficient labeled training data, poor generalization to unseen environments, or hardware constraints that prevent model deployment

### Mechanism 2
- Claim: Multi-frame architectures with temporal context improve accuracy by capturing movement patterns
- Mechanism: Processing sequences of IR frames allows the model to distinguish between static objects and moving people, and to separate closely-spaced individuals based on their movement trajectories
- Core assumption: Human movement patterns are sufficiently consistent across sessions to be learned from training data
- Evidence anchors:
  - [section] "the first and simplest mechanism that we considered to process multiple IR frames consists in feeding them to a CNN as different input channels" and "Considering a sliding window of IR frames as input can reveal information on people movement"
  - [section] "The rationale is that considering a sliding window of IR frames as input can reveal information on people movement, which in turn can improve the prediction accuracy in complex cases"
- Break condition: Very short observation windows, stationary scenes, or non-standard movement patterns not present in training data

### Mechanism 3
- Claim: Quantization-aware training recovers accuracy loss while enabling efficient MCU deployment
- Mechanism: 8-bit quantization reduces model size and computational complexity, while quantization-aware training simulates quantization during training to adjust weights and prevent accuracy degradation
- Core assumption: The quantization process preserves the essential information in the model weights and activations
- Evidence anchors:
  - [section] "After this initial floating point training, we quantize the parameters, inputs, outputs, and intermediate activations of the resulting models to 8-bit integers"
  - [section] "We then apply quantization-aware training (QAT) to recover the accuracy drop due to quantization as much as possible"
- Break condition: Excessive quantization leading to information loss, or lack of QAT support for certain model components (e.g., LSTM cells)

## Foundational Learning

- Concept: Cross-validation with session-based splits
  - Why needed here: Prevents data leakage between training and testing, ensures model generalizes to different environments and conditions
  - Quick check question: What would happen if we used random frame sampling instead of session-based splits?

- Concept: Pareto optimization in architecture search
  - Why needed here: Balances competing objectives (accuracy vs. model size vs. operations) to find optimal solutions for constrained hardware
  - Quick check question: How does changing the cost metric (parameters vs. MACs) affect the Pareto-optimal solutions?

- Concept: Model quantization and deployment constraints
  - Why needed here: Enables real-time inference on resource-constrained MCUs while maintaining acceptable accuracy
  - Quick check question: What are the trade-offs between 8-bit quantization and floating-point inference for different model types?

## Architecture Onboarding

- Component map:
  - Input preprocessing: 8x8 IR frames, sliding window formation, tensor stacking
  - Model architectures: Single-frame CNN, multi-channel CNN, majority voting CNN, concatenated CNN, CNN-LSTM, CNN-TCN
  - Training pipeline: Cross-validation, class-weighted loss, quantization-aware training
  - Deployment toolchain: TensorFlow Lite conversion, X-CUBE-AI optimization for STM32L4A6ZG

- Critical path:
  1. Data collection and labeling
  2. Cross-validation setup with session-based splits
  3. Architecture exploration across model families
  4. Pareto optimization and model selection
  5. Quantization and deployment preparation
  6. MCU deployment and performance measurement

- Design tradeoffs:
  - Accuracy vs. complexity: Simpler models (single-frame CNN) vs. complex models (CNN-LSTM/TCN)
  - Temporal vs. spatial processing: Multi-frame architectures vs. single-frame
  - Memory vs. operations: Model size constraints vs. computational requirements
  - Precision vs. efficiency: Floating-point vs. quantized implementations

- Failure signatures:
  - Overfitting: High training accuracy but low validation accuracy
  - Underfitting: Consistently low accuracy across all metrics
  - Deployment failure: Model size exceeds MCU memory, latency exceeds real-time requirements
  - Accuracy degradation: Significant performance drop after quantization

- First 3 experiments:
  1. Baseline comparison: Implement and test the deterministic algorithm [25] on the LINAIGE dataset to establish reference performance
  2. Single-frame CNN exploration: Train various single-frame CNN architectures with different layer configurations to identify optimal basic architecture
  3. Multi-frame impact assessment: Compare single-frame vs. multi-frame architectures with window sizes W=3,5,7 to quantify the benefit of temporal context

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of these models scale with higher resolution IR arrays (e.g., 32x24 or 80x60) compared to the 8x8 resolution studied?
- Basis in paper: [explicit] The paper compares their 8x8 models to state-of-the-art approaches using higher resolution arrays (32x24, 80x60) in Table V, noting that their models achieve comparable accuracy with much lower complexity, but doesn't explore how their models would perform on higher resolution data directly.
- Why unresolved: The authors only tested their models on the 8x8 resolution dataset and used downsampling for comparison. They don't explore training and testing their architectures directly on higher resolution data to understand the performance trade-offs.
- What evidence would resolve it: Direct experiments training and testing their DL models on higher resolution IR array datasets (32x24, 80x60) to compare accuracy, latency, and energy consumption against both their 8x8 models and existing state-of-the-art approaches.

### Open Question 2
- Question: How do the performance characteristics change when deploying these models on different MCU architectures (e.g., Cortex-M0+ vs Cortex-M4)?
- Basis in paper: [explicit] The paper only evaluates deployment on STM32L4A6ZG (Cortex-M4) and mentions that quantized LSTM cells aren't supported by TFMOT, implying architecture-specific limitations.
- Why unresolved: The authors only report results for a single MCU architecture. Different MCU cores have varying computational capabilities, memory hierarchies, and instruction sets that could significantly impact the actual performance of these models.
- What evidence would resolve it: Deployment and benchmarking of the same DL models across multiple MCU architectures with different core types (Cortex-M0+, M3, M4, M7) to measure variations in latency, energy consumption, and memory usage.

### Open Question 3
- Question: What is the impact of varying the training data distribution (e.g., different environments, lighting conditions, or temperature ranges) on model generalization and performance?
- Basis in paper: [explicit] The authors note their dataset includes different environments (offices, laboratories, corridors) and room temperatures, and they use a leave-one-session-out CV strategy to test generalization, but they don't systematically explore how different data distributions affect performance.
- Why unresolved: While the paper shows good generalization across different sessions, it doesn't investigate how changes in environmental conditions or sensor placement affect model robustness, or whether additional data augmentation or domain adaptation techniques could improve performance.
- What evidence would resolve it: Systematic experiments varying the training data distribution by environment type, temperature range, or sensor placement, and measuring the resulting performance changes across different test conditions.

## Limitations

- Dataset Generalization: The LINAIGE dataset was collected in a single controlled environment (205x135 cm testbed), limiting generalizability to diverse real-world settings
- Hardware Constraints: Results may vary significantly with different MCU architectures; only STM32L4A6ZG was evaluated
- Deterministic Baseline: Exact implementation details of the referenced method [25] are not publicly available, requiring approximation

## Confidence

- **High Confidence**: Model accuracy improvements over deterministic baseline (39.9% increase), Pareto-optimal solutions for specific MCU constraints, quantization-aware training effectiveness
- **Medium Confidence**: Generalization across different environments, temporal context benefits, deployment metrics on target hardware
- **Low Confidence**: Performance in real-world uncontrolled environments, scalability to larger sensor arrays, comparison with alternative privacy-preserving sensing modalities

## Next Checks

1. **Cross-Environment Validation**: Test selected Pareto-optimal models on data from multiple different environments (varying room sizes, ceiling heights, and background objects) to assess generalization capabilities.

2. **Energy-Latency Trade-off Analysis**: Systematically vary MCU clock frequency and voltage to quantify the relationship between operating conditions and inference latency/energy consumption for the deployed models.

3. **Baseline Implementation Verification**: Implement multiple variations of the deterministic baseline method [25] to establish the robustness of the claimed accuracy improvements and identify the critical algorithmic differences.