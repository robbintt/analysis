---
ver: rpa2
title: Combining Behaviors with the Successor Features Keyboard
arxiv_id: '2310.15940'
source_url: https://arxiv.org/abs/2310.15940
tags:
- tasks
- task
- transfer
- learning
- csfa
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the Successor Features Keyboard (SFK), a
  method for transferring behavioral knowledge across tasks in complex 3D environments.
  SFK leverages discovered representations of state-features (cumulants) and task
  encodings to adaptively combine known behaviors using Successor Features and Generalized
  Policy Improvement.
---

# Combining Behaviors with the Successor Features Keyboard

## Quick Facts
- arXiv ID: 2310.15940
- Source URL: https://arxiv.org/abs/2310.15940
- Reference count: 40
- Primary result: SFK achieves better jump-start performance compared to baselines like Multitask RL and Distral, requiring 100-200 million fewer samples for longer task combinations.

## Executive Summary
This paper introduces the Successor Features Keyboard (SFK), a method for transferring behavioral knowledge across tasks in complex 3D environments. SFK leverages discovered representations of state-features (cumulants) and task encodings to adaptively combine known behaviors using Successor Features and Generalized Policy Improvement. The authors propose the Categorical Successor Feature Approximator (CSFA), a novel learning algorithm that estimates successor features while jointly discovering cumulants and task encodings. Experiments in the Playroom environment demonstrate that CSFA discovers representations compatible with successor features and generalized policy improvement, enabling transfer to combinations of long-horizon tasks with sparse rewards.

## Method Summary
The method consists of two phases: pretraining and transfer. In pretraining, CSFA learns successor features over discovered cumulants and task encodings. CSFA addresses the challenge of estimating bootstrapped returns over non-stationary targets by modeling successor features with a probability mass function over discretized values. During transfer, SFK uses the pretrained CSFA to compute successor features for training task encodings and learns a policy that generates linear combinations of these encodings. The policy uses Generalized Policy Improvement to select actions based on the combined successor features.

## Key Results
- CSFA discovers representations compatible with successor features and generalized policy improvement in the Playroom environment
- SFK achieves better jump-start performance compared to Multitask RL and Distral baselines
- SFK requires 100-200 million fewer samples for longer task combinations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CSFA enables joint learning of cumulants, task encodings, and successor features by modeling the successor feature as a probability mass function over discretized values.
- Mechanism: CSFA represents successor features as distributions over bins using categorical cross-entropy loss against a two-hot target encoding the true value.
- Core assumption: True successor feature values can be well-approximated by discretizing the value space into bins.
- Evidence anchors: [abstract] and [section 4.1] descriptions of CSFA's categorical representation approach.

### Mechanism 2
- Claim: Sharing the SF-approximator across tasks while jointly learning cumulants and task encodings enables transfer with dynamic queries in SFK.
- Mechanism: SFK computes successor features for training task encodings and learns a policy that generates linear combinations for transfer tasks.
- Core assumption: Learned task encodings are spread out enough in embedding space to allow meaningful linear combinations.
- Evidence anchors: [abstract] and [section 4.2] descriptions of SFK's transfer approach.

### Mechanism 3
- Claim: Bounding task encoding norms and stopping gradients from Q-learning prevents instability and dimensional collapse.
- Mechanism: Task encodings are constrained to a unit sphere and gradients from Q-learning don't flow back to the task encoder.
- Core assumption: These constraints mitigate instability and dimensional collapse in joint learning.
- Evidence anchors: [section 4.1] observations about dimensional collapse and instability.

## Foundational Learning

- Concept: Successor Features (SFs)
  - Why needed here: SFs represent behaviors in terms of expected cumulative discounted features, enabling transfer via GPI.
  - Quick check question: How does the successor feature of a policy relate to the expected cumulative discounted cumulant?

- Concept: Generalized Policy Improvement (GPI)
  - Why needed here: GPI selects the best action from policies for new tasks by re-evaluating their successor features.
  - Quick check question: What is the mathematical form of the policy selected by GPI given a set of successor features and a task encoding?

- Concept: Categorical Distribution and Cross-Entropy Loss
  - Why needed here: CSFA uses categorical distribution to represent successor features and learns via cross-entropy loss against two-hot targets.
  - Quick check question: How does a two-hot encoding represent a scalar value in a discretized space?

## Architecture Onboarding

- Component map: Observation encoder (ResNet) -> State function (LSTM) -> Cumulant function (MLP ResNet) -> SF-approximator (MLP with categorical output) + Task encoder (LSTM + projection)
- Critical path:
  1. Pretraining: Learn cumulants, task encodings, and SFs with CSFA using full architecture
  2. Transfer: Freeze CSFA, learn new state function and task encoder, learn policy that generates linear combinations of task encodings, use GPI for action selection
- Design tradeoffs:
  - Categorical vs. scalar SF representation: Categorical is more robust but may require more parameters
  - Sharing SF-approximator across tasks vs. separate: Sharing enables transfer but may make learning harder
  - Bounding ||w|| vs. not: Bounding prevents instability but may limit expressiveness
- Failure signatures:
  - Poor GPI performance on training tasks: Indicates cumulants or task encodings are not learned correctly
  - Dimensional collapse of task encodings: Indicates gradients from Q-learning are causing collapse
  - Large SF TD errors: Indicates instability in SF estimation
- First 3 experiments:
  1. Train CSFA on simple "Find" tasks and evaluate GPI performance on training tasks
  2. Train CSFA on full curriculum and evaluate GPI performance on training tasks
  3. Train SFK for transfer to task combinations and compare jumpstart performance against MTRL and Distral

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would SFK and CSFA perform if task encoding space were not concentrated and task encodings were more diverse?
- Basis in paper: [inferred] The paper mentions task encodings are fairly concentrated and suggests contrastive learning could spread them.
- Why unresolved: Paper doesn't test with more diverse task encodings, only suggests potential improvement.
- What evidence would resolve it: Experiments comparing performance with concentrated vs. diverse task encodings using contrastive learning.

### Open Question 2
- Question: What is the upper limit on number of training tasks SFK and CSFA can handle effectively?
- Basis in paper: [explicit] Paper states it didn't study upper limit but notes significant increase in complexity from prior work.
- Why unresolved: Paper doesn't experiment with scaling up training tasks to find the upper limit.
- What evidence would resolve it: Experiments scaling up training tasks and measuring performance to identify degradation point.

### Open Question 3
- Question: How would SFK and CSFA perform if agent had to hold an object for longer period of time?
- Basis in paper: [explicit] Paper mentions challenge of holding objects over prolonged periods.
- Why unresolved: Paper doesn't experiment with tasks requiring longer object holding.
- What evidence would resolve it: Experiments with tasks requiring increasingly longer object holding and measuring method performance.

## Limitations
- Reliance on discretization for successor feature representation may limit precision in continuous value spaces
- Assumes cumulant and task encoding discovery is reliable enough for GPI to work effectively
- Performance improvements are environment-specific and may not generalize to all domains

## Confidence
- **High confidence**: The categorical successor feature approximation method and implementation details are well-specified and reproducible
- **Medium confidence**: Transfer performance improvements over baselines, though results are environment-specific
- **Medium confidence**: Architectural constraints effectively prevent instability, based on observed experimental behavior

## Next Checks
1. **Ablation study on discretization granularity**: Test CSFA performance across different bin resolutions to quantify precision trade-off
2. **Transfer robustness test**: Evaluate SFK performance on transfer tasks with novel combinations not seen during pretraining
3. **Comparison with scalar successor features**: Implement scalar estimation variant to benchmark against categorical approach