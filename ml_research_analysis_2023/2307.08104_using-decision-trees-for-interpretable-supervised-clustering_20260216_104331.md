---
ver: rpa2
title: Using Decision Trees for Interpretable Supervised Clustering
arxiv_id: '2307.08104'
source_url: https://arxiv.org/abs/2307.08104
tags:
- decision
- data
- tree
- node
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to find interpretable clusters of
  class-uniform data using decision tree classifiers. The key idea is to train a decision
  tree on labelled data, rank its nodes by a combination of precision and recall (F-measure),
  and select the node with the highest score as a cluster.
---

# Using Decision Trees for Interpretable Supervised Clustering

## Quick Facts
- arXiv ID: 2307.08104
- Source URL: https://arxiv.org/abs/2307.08104
- Reference count: 27
- Primary result: Decision trees can find interpretable clusters in labeled data by iteratively training and selecting high-quality nodes based on F-measure scores

## Executive Summary
This paper introduces an iterative method that uses decision tree classifiers to extract interpretable clusters from labeled datasets. The approach trains decision trees on the full dataset, ranks nodes by F-measure scores combining precision and recall, selects the highest-scoring node as a cluster, removes its data, and repeats the process. The method was validated on synthetic and real datasets, successfully identifying artificially created high-density groups and showing varying stability levels across different datasets.

## Method Summary
The method iteratively trains decision tree classifiers on labeled datasets, computing Fβ scores for each node to identify the best cluster. After selecting the highest-scoring node as a cluster, its data is removed and the process repeats on the remaining data. Symbolic features are preprocessed by sorting values by frequency of occurrence in the target class, improving split quality. Cluster stability is assessed through bagging, measuring Jaccard similarity between clusters extracted from bootstrap samples and the original dataset.

## Key Results
- Successfully identified artificially created high-density groups in synthetic Adult dataset
- Titanic dataset clusters showed high stability (90-98% score)
- Adult dataset clusters exhibited low stability (20-25% score)
- Symbolic data sorting improved clustering performance compared to baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decision trees can locate interpretable clusters in labelled data by iteratively training and selecting high-quality nodes based on F-measure.
- Mechanism: The method trains a decision tree on the full dataset, computes Fβ scores for each node, selects the node with the highest score, removes its data, and repeats the process. This iterative retraining enables finding high-density clusters not visible in a single tree.
- Core assumption: High-density class-uniform regions in labelled data correspond to nodes with high F-measure scores in a decision tree.
- Evidence anchors:
  - [abstract] "We propose an iterative method to extract high-density clusters with the help of decision-tree-based classifiers"
  - [section 3.3] "Listing 2 Cluster extraction algorithm" describes the retraining and node selection loop
  - [corpus] Weak - no direct corpus evidence for iterative retraining strategy
- Break condition: The process breaks when no nodes remain with positive F-measure scores, indicating no further class-uniform clusters can be extracted.

### Mechanism 2
- Claim: Symbolic data preprocessing through frequency-based sorting improves decision tree split quality for interpretable clustering.
- Mechanism: Symbolic features are sorted by frequency of occurrence in the target class, creating an ordinal mapping that enables more meaningful splits using less-than-or-equal-to conditions rather than equality checks.
- Core assumption: Ordering symbolic values by class frequency creates more interpretable and higher-quality splits than arbitrary or lexicographic ordering.
- Evidence anchors:
  - [section 3.2] "Hence, it is preferable to map symbolic data to the set of ordinals... in such a way that there exists a pivot p such that the column split producing sets {x ≤ p} and {x > p} minimizes the impurity metric"
  - [section 4] "Figure 3 shows the effect of symbolic data sorting on supervised cluster extraction"
  - [corpus] Missing - no corpus evidence for symbolic ordering strategy
- Break condition: Break condition occurs when symbolic features have too many unique values that cannot be meaningfully binned or ordered for interpretable clustering.

### Mechanism 3
- Claim: Bagging-based stability assessment reveals whether extracted clusters will generalize to unseen data.
- Mechanism: Multiple bootstrap samples are drawn from the dataset, clusters are extracted from each sample, and pairwise Jaccard similarity measures the overlap between original and sample clusters to compute stability scores.
- Core assumption: Clusters that remain stable across bootstrap samples are more likely to represent genuine patterns rather than dataset-specific artifacts.
- Evidence anchors:
  - [section 5] "We generate N samples from the original dataset... compute extracted cluster stability score as follows"
  - [section 5] "Using this method, we estimated that the main cluster extracted from the Titanic dataset exhibits stability score around 90-98%"
  - [corpus] Missing - no corpus evidence for bagging-based stability assessment
- Break condition: Break condition occurs when stability scores are consistently low (e.g., <50%), indicating clusters are not robust and may not generalize.

## Foundational Learning

- Concept: Decision tree CART algorithm with Gini impurity
  - Why needed here: The method relies on decision tree splits to identify class-uniform regions, requiring understanding of how trees partition data
  - Quick check question: What impurity metric does the standard CART algorithm optimize when selecting splits?

- Concept: Precision-recall tradeoff and F-measure
  - Why needed here: Node ranking depends on balancing precision and recall using Fβ scores to select the most meaningful clusters
  - Quick check question: How does changing β in Fβ affect the tradeoff between precision and recall in node selection?

- Concept: Symbolic data preprocessing and ordinal encoding
  - Why needed here: The method requires transforming symbolic features to enable meaningful splits in decision trees
  - Quick check question: Why is it problematic to use equality-based splits for nominal symbolic data with many unique values?

## Architecture Onboarding

- Component map: Data preprocessing → Decision tree training → Node scoring → Cluster extraction → Data removal → Repeat → Stability assessment

- Critical path: Data preprocessing → Decision tree training → Node scoring → Cluster extraction → Data removal → Repeat → Stability assessment

- Design tradeoffs:
  - Shallow trees vs deep trees: Shallow trees are more interpretable but may miss complex patterns; deep trees can capture more detail but become harder to interpret
  - Fβ parameter selection: Lower β favors precision (purer clusters) while higher β favors recall (larger clusters)
  - Preprocessing intensity: Aggressive binning speeds up training but may lose information; minimal preprocessing preserves detail but increases computational cost

- Failure signatures:
  - Very low stability scores across bootstrap samples
  - Extracted clusters with extremely small sample sizes
  - Decision paths requiring conditions on sets with many values (e.g., "x ∈ {large set}")
  - Decision trees that cannot find any splits with positive impurity reduction

- First 3 experiments:
  1. Run the pipeline on the Titanic dataset without symbolic ordering to observe baseline cluster quality and stability
  2. Apply symbolic ordering by frequency and compare cluster quality metrics and interpretability
  3. Vary the β parameter in Fβ scoring to find the optimal tradeoff for the target application domain

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of Fβ parameter affect the quality and interpretability of the extracted clusters?
- Basis in paper: [explicit] The paper discusses using Fβ to rank nodes by a combination of precision and recall, but does not explore how different β values impact the clusters found.
- Why unresolved: The paper only demonstrates the use of Fβ with specific values (e.g., F0.5 and F0.33) but does not systematically analyze the impact of varying β on cluster quality or interpretability.
- What evidence would resolve it: Systematic experiments varying β across a range of values, measuring cluster quality metrics (precision, recall, F1) and interpretability scores (e.g., number of rules, complexity) for each value.

### Open Question 2
- Question: How does the proposed method perform on real-world datasets with complex, non-linear relationships between features?
- Basis in paper: [inferred] The paper validates the method on a synthetic Adult dataset with artificially created groups, but does not test it on real-world datasets with more complex patterns.
- Why unresolved: Real-world datasets often contain complex, non-linear relationships that may not be easily captured by decision trees, and the synthetic dataset may not fully represent these complexities.
- What evidence would resolve it: Application of the method to diverse real-world datasets with known ground truth clusters or expert-labeled groups, evaluating both clustering accuracy and interpretability.

### Open Question 3
- Question: How can the method be extended to handle multi-label classification problems where instances can belong to multiple classes simultaneously?
- Basis in paper: [inferred] The paper focuses on binary classification problems, but does not address how the method could be adapted for multi-label scenarios.
- Why unresolved: The current node selection and ranking approach is designed for binary classification, and extending it to multi-label cases would require new strategies for identifying and ranking clusters that may contain instances from multiple classes.
- What evidence would resolve it: Development and evaluation of a modified version of the method that can handle multi-label classification, demonstrating its effectiveness on datasets with multiple labels per instance.

## Limitations
- The method's effectiveness on datasets with complex symbolic features remains unclear, as validation is limited to Adult and Titanic examples
- Stability assessment reveals concerning low stability (20-25%) for Adult dataset clusters, suggesting potential generalizability limitations
- Exact implementation details for symbolic binning methods, particularly similarity-based grouping using Jaro-Winkler distance, are not fully specified

## Confidence
- **High Confidence**: The core iterative decision tree retraining mechanism and Fβ node selection strategy are well-documented and theoretically sound
- **Medium Confidence**: The symbolic data preprocessing approach shows promise but lacks comprehensive validation across diverse datasets with varying symbolic feature complexities
- **Low Confidence**: The stability assessment methodology, while conceptually sound, shows concerning results for the Adult dataset that warrant deeper investigation into whether this reflects dataset characteristics or methodological limitations

## Next Checks
1. Reproduce stability analysis on additional datasets: Apply the method to UCI datasets with varying proportions of symbolic features (e.g., Mushroom, Chess) to determine if the low stability observed in Adult is dataset-specific or indicates broader limitations

2. Test alternative symbolic preprocessing strategies: Implement and compare the frequency-based ordering with alternative approaches such as entropy-based ordering or domain-driven ordering to assess robustness of the symbolic preprocessing component

3. Vary the β parameter systematically: Conduct experiments across a range of β values (e.g., β=0.1, 0.33, 1, 3) on multiple datasets to empirically determine optimal settings for different data distributions and clustering objectives