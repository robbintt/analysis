---
ver: rpa2
title: Generative AI
arxiv_id: '2309.07930'
source_url: https://arxiv.org/abs/2309.07930
tags:
- generative
- systems
- such
- information
- research
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides a comprehensive conceptualization of generative
  AI as an entity in socio-technical systems, covering models, systems, and applications
  across text, image, and audio modalities. It introduces limitations of current generative
  AI, including incorrect outputs, bias, copyright violation, and environmental concerns.
---

# Generative AI

## Quick Facts
- arXiv ID: 2309.07930
- Source URL: https://arxiv.org/abs/2309.07930
- Reference count: 22
- Key outcome: Comprehensive conceptualization of generative AI as socio-technical entity across models, systems, and applications

## Executive Summary
This paper provides a structured framework for understanding generative AI as a socio-technical system, organizing capabilities across model-, system-, and application-level perspectives while addressing text, image, and audio modalities. The authors identify key limitations including incorrect outputs, bias, copyright violations, and environmental concerns, then propose a research agenda for the Business & Information Systems Engineering community. The framework aims to guide both technical development and organizational decision-making while highlighting critical areas for future investigation.

## Method Summary
This conceptual paper synthesizes existing generative AI technologies, frameworks, and research to create a unified taxonomy of the field. The authors systematically categorize generative AI across three hierarchical levels (models, systems, applications) and multiple data modalities, then identify limitations and propose future research directions. The methodology involves reviewing current state-of-the-art technologies, analyzing their capabilities and constraints, and mapping these findings to implications for business and information systems research.

## Key Results
- Provides unified taxonomy of generative AI across model-, system-, and application-level perspectives
- Identifies four major limitations: incorrect outputs, bias, copyright violation, and environmental concerns
- Proposes research agenda for BISE community across seven departments
- Demonstrates socio-technical integration connecting technical capabilities to organizational implications

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Hierarchical taxonomy enables cross-modal understanding of generative AI capabilities
- Mechanism: Three-level framework (model, system, application) across text, image, and audio modalities allows systematic mapping of capabilities and limitations
- Core assumption: Clear boundaries exist between model capabilities, system integration, and real-world applications
- Evidence anchors: [abstract] "conceptualization of generative AI as an entity in socio-technical systems" with examples across levels; [section] "Figure 1 shows a systematization... across selected data modalities"

### Mechanism 2
- Claim: Socio-technical perspective connects technical capabilities to organizational decision-making
- Mechanism: Explicit integration of human factors, trust, and organizational processes with technical capabilities
- Core assumption: Technical capabilities alone insufficient without human and organizational context
- Evidence anchors: [abstract] "focus on generative AI in the context of information systems"; [section] "interaction between humans and AI... collective intelligence begins to shift"

### Mechanism 3
- Claim: Balanced limitations section prevents over-optimistic adoption while highlighting research opportunities
- Mechanism: Systematic identification of incorrect outputs, bias, copyright, and environmental concerns creates realistic foundation
- Core assumption: Awareness of limitations necessary for responsible development and deployment
- Evidence anchors: [abstract] "introduce limitations... including incorrect outputs, bias, copyright violation, and environmental concerns"; [section] "four salient boundaries... important limitations in real-world applications"

## Foundational Learning

- Concept: Generative vs. discriminative modeling
  - Why needed here: Framework rests on understanding generative AI creates new content rather than classifying existing data
  - Quick check question: What is the key difference between how generative and discriminative models handle the joint probability distribution P(X,Y)?

- Concept: Deep learning architectures (transformers, diffusion models, GANs)
  - Why needed here: Paper extensively references specific architectures fundamental to current capabilities
  - Quick check question: Which architecture uses an adversarial training process between generator and discriminator networks?

- Concept: Prompt engineering and fine-tuning concepts
  - Why needed here: Paper discusses customization of generative AI systems and user interaction
  - Quick check question: What is the difference between zero-shot learning and few-shot learning in large language models?

## Architecture Onboarding

- Component map: Foundation model layer (transformer, diffusion, GAN architectures) → System integration layer (scalability, deployment, usability) → Application layer (specific business use cases)
- Critical path: Select appropriate foundation model → Integrate into system with proper interfaces → Deploy to solve specific business problem while addressing limitations
- Design tradeoffs: Model size vs. environmental impact, closed-source vs. open-source, general-purpose vs. specialized
- Failure signatures: Incorrect outputs (hallucination), biased outputs (systematic representation issues), copyright violations (output resembling protected content), environmental concerns (excessive computational resource consumption)
- First 3 experiments:
  1. Test pre-trained text-to-image model on domain-specific prompts to evaluate hallucination rates and bias patterns
  2. Implement retrieval-augmented system to address knowledge cutoff limitations
  3. Measure carbon footprint of different model sizes for same task to establish environmental efficiency baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can generative AI systems be designed to ensure reliable and correct outputs while maintaining user trust?
- Basis in paper: [explicit] Discusses incorrect outputs as major limitation where models generate probable responses rather than necessarily correct ones
- Why unresolved: Current approaches like explanations and references are still probabilistic and subject to errors; black-box nature hinders further tuning
- What evidence would resolve it: Empirical studies on effectiveness of explanations/references in decision-making, algorithmic solutions for detecting hallucinations

### Open Question 2
- Question: What are the economic implications of generative AI on labor markets, and how can these be quantified and addressed?
- Basis in paper: [explicit] Discusses potential GDP growth and job displacement but notes need for rigorous causal evidence
- Why unresolved: Velocity of AI research and complexity of labor markets make isolating effects challenging
- What evidence would resolve it: Longitudinal studies tracking adoption and impact on specific industries and job roles

### Open Question 3
- Question: How can generative AI be leveraged to support creativity and innovation in design science research while ensuring appropriate learning and reflection?
- Basis in paper: [explicit] Suggests incorporating generative AI in design thinking methodologies while emphasizing need for better reflection of design activities
- Why unresolved: Potential for automation raises questions about role of human creativity and importance of reflection in design process
- What evidence would resolve it: Case studies comparing effectiveness of design projects with/without AI assistance, qualitative analyses of impact on design process

## Limitations

- Taxonomy may become outdated as new model architectures emerge that don't fit current modality categories
- Socio-technical integration claims rely heavily on theoretical frameworks that may not capture evolving human-AI interaction patterns
- Specific predictions about business process transformation and timeline for addressing limitations remain speculative

## Confidence

- High Confidence: Hierarchical taxonomy structure and core limitations identification are well-supported by current evidence
- Medium Confidence: Socio-technical integration claims and research agenda across BISE departments are reasonable but depend on future developments
- Low Confidence: Specific predictions about business transformation and timeline for addressing limitations are highly uncertain

## Next Checks

1. Test framework's extensibility by applying it to emerging generative AI technologies (video generation, 3D models) not covered in original conceptualization
2. Implement systematic monitoring system to track how identified limitations evolve over time, particularly hallucination rates and bias patterns
3. Conduct case studies across multiple BISE departments to evaluate how well proposed research agenda translates into actual research priorities