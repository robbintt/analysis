---
ver: rpa2
title: 'ETDPC: A Multimodality Framework for Classifying Pages in Electronic Theses
  and Dissertations'
arxiv_id: '2311.04262'
source_url: https://arxiv.org/abs/2311.04262
tags:
- pages
- etds
- categories
- training
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces ETDPC, a novel framework for classifying pages
  in Electronic Theses and Dissertations (ETDs). ETDs are long scholarly documents
  with unique features, making existing document classification frameworks unsuitable.
---

# ETDPC: A Multimodality Framework for Classifying Pages in Electronic Theses and Dissertations

## Quick Facts
- arXiv ID: 2311.04262
- Source URL: https://arxiv.org/abs/2311.04262
- Reference count: 28
- ETDPC achieves F1 scores of 0.84-0.96 for 9 out of 13 ETD page categories

## Executive Summary
ETDPC introduces a novel framework for classifying pages in Electronic Theses and Dissertations (ETDs), addressing the limitations of existing document classification models on these unique scholarly documents. The framework employs a two-stream multimodal model with cross-attention, combining visual and textual features to classify ETD pages into 13 categories. To handle imbalanced labeled samples, the authors use data augmentation for minority categories and implement a hierarchical classifier. ETDPC demonstrates superior performance over state-of-the-art models, achieving F1 scores ranging from 0.84 to 0.96 for 9 categories, while also showing data efficiency and customizability for non-English ETDs.

## Method Summary
ETDPC uses a two-stream multimodal model with cross-attention, combining visual features extracted by ResNet50v2 and textual features from BERT with Talking-Heads Attention. The framework employs early fusion of projected embeddings and cross-attention output, followed by a softmax layer for 13-class classification. To address class imbalance, a hierarchical classification strategy is used, first separating chapters from non-chapters, then classifying the more balanced non-chapter set. Data augmentation techniques including paraphrasing and image-based transformations are applied to minority categories.

## Key Results
- ETDPC achieves F1 scores of 0.84-0.96 for 9 out of 13 ETD page categories
- The framework outperforms state-of-the-art models including BERT, ResNet50v2, and their combinations
- ETDPC demonstrates data efficiency and customizability for non-English ETDs

## Why This Works (Mechanism)

### Mechanism 1
The cross-attention layer enables the model to focus on the most important pixels of an image that relate to their corresponding textual parts, improving classification accuracy for ETDs. Cross-attention combines asymmetrically two separate embedding sequences from visual and textual modalities, allowing the model to learn to attend to specific image regions based on relevant textual information and vice versa. This assumes that visual and textual features contain complementary information that, when properly aligned through attention, enhances classification performance. Evidence includes the explicit design choice of using cross-attention and the superior performance compared to single-modality approaches. Break condition: If cross-attention fails to properly align visual and textual features, the model may perform worse than single-modality approaches.

### Mechanism 2
The hierarchical classification strategy effectively mitigates the data imbalance problem by first separating chapters from non-chapters, then classifying the more balanced non-chapter set. This assumes that data imbalance is primarily driven by the dominance of chapter pages, and separating this class first creates more balanced subsequent classification tasks. Evidence includes the implementation of a two-level classifier and the improved performance on minority categories. Break condition: If the chapter/non-chapter separation is not sufficiently accurate, errors will propagate to the second stage, degrading overall performance.

### Mechanism 3
The combination of BERT with Talking-Heads Attention outperforms standard BERT on the ETD classification task by better capturing long-range dependencies in the text. This assumes that ETD text contains complex linguistic structures and domain-specific terminology that benefit from the enhanced attention mechanism of Talking-Heads. Evidence includes the general performance improvements reported for Talking-Heads models on other tasks, though direct comparison on ETDs is not provided. Break condition: If the ETD text does not benefit from the additional complexity of Talking-Heads Attention, standard BERT might perform equally well or better.

## Foundational Learning

- **Multimodal learning and cross-modal attention mechanisms**: ETDs contain both visual layout information and textual content that must be jointly processed for accurate classification. Quick check: How does cross-attention differ from simple feature concatenation in multimodal models?

- **Data augmentation techniques for imbalanced datasets**: The ETD500 dataset has significant class imbalance, with some categories having very few samples. Quick check: What are the advantages and disadvantages of using paraphrasing versus image-based transformations for data augmentation?

- **Hierarchical classification strategies**: The two-level classifier approach addresses the class imbalance by first separating the dominant class (chapters) from others. Quick check: In what scenarios might a hierarchical classifier perform worse than a flat multi-class classifier?

## Architecture Onboarding

- **Component map**: ETD page images (PNG) → ResNet50v2 → projection → cross-attention ← projection ← BERT with Talking-Heads ← OCR text → Softmax

- **Critical path**: Image → ResNet50v2 → projection → cross-attention ← projection ← BERT with Talking-Heads ← OCR text → Softmax

- **Design tradeoffs**:
  - Multimodal vs. single modality: Multimodal achieves better performance but requires more computational resources and data
  - Early fusion vs. late fusion: Early fusion allows cross-attention to work on unified feature spaces but may lose some modality-specific information
  - Hierarchical vs. flat classification: Hierarchical improves performance on imbalanced data but adds complexity and potential error propagation

- **Failure signatures**:
  - Low accuracy on minority classes despite data augmentation: May indicate augmentation techniques are not producing realistic samples
  - Similar performance between visual-only and multimodal models: Could suggest poor cross-attention alignment or redundant information
  - Degraded performance when using pre-trained weights: May indicate domain mismatch between pre-training data and ETDs

- **First 3 experiments**:
  1. Replace BERT with Talking-Heads with standard BERT to verify the claimed performance improvement
  2. Train visual-only and text-only baselines to establish the value added by the multimodal approach
  3. Test the model on a held-out test set from a different institution to evaluate generalizability

## Open Questions the Paper Calls Out

- How does the performance of ETDPC change when applied to born-digital ETDs compared to scanned ETDs? The paper mentions that for born-digital ETDs, it is "straightforward to convert them to images" but does not provide empirical results comparing performance on born-digital versus scanned documents.

- What is the optimal data augmentation strategy for the minority categories to maximize model performance? The paper uses paraphrasing and image-based transformations for data augmentation but notes that performance improvements plateau for some categories and suggests adding more training data for others.

- How does ETDPC's performance compare to human annotators in classifying ETD pages, particularly for minority categories? The paper reports high F1 scores for ETDPC but does not compare its performance to human annotators, especially for challenging categories like ListofFigures and ListofTables.

## Limitations

- The paper lacks direct comparisons between Talking-Heads BERT and standard BERT on the ETD classification task, relying instead on general performance claims from the original Talking-Heads paper
- The effectiveness of the hierarchical classification strategy versus alternative imbalance mitigation approaches is not empirically validated
- The cross-attention mechanism's contribution is inferred rather than isolated through ablation studies

## Confidence

- **High confidence**: The overall framework design and its superior performance compared to state-of-the-art models (BERT, ResNet50v2, and their combinations)
- **Medium confidence**: The specific benefits of Talking-Heads Attention and hierarchical classification strategy
- **Low confidence**: The exact contribution of the cross-attention mechanism relative to simpler fusion approaches

## Next Checks

1. Conduct an ablation study to isolate the contribution of cross-attention by comparing against late fusion and feature concatenation approaches
2. Evaluate the model on ETD datasets from different institutions to assess generalizability beyond the ETD500 corpus
3. Compare the hierarchical classification approach against alternative imbalance mitigation techniques (class weighting, oversampling) on the same dataset