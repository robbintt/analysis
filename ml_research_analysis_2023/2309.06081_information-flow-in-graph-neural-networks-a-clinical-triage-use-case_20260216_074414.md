---
ver: rpa2
title: 'Information Flow in Graph Neural Networks: A Clinical Triage Use Case'
arxiv_id: '2309.06081'
source_url: https://arxiv.org/abs/2309.06081
tags:
- nodes
- embeddings
- connectivity
- data
- patient
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates how the flow of embedding information within
  Graph Neural Networks (GNNs) affects link prediction performance in Knowledge Graphs
  (KGs). A mathematical model is proposed that decouples GNN connectivity from the
  underlying graph data structure.
---

# Information Flow in Graph Neural Networks: A Clinical Triage Use Case

## Quick Facts
- **arXiv ID**: 2309.06081
- **Source URL**: https://arxiv.org/abs/2309.06081
- **Reference count**: 22
- **Primary result**: GNN connectivity that only allows embedding information to flow from observation and condition nodes to encounter nodes achieves 88% accuracy for care action prediction in clinical triage

## Executive Summary
This paper investigates how the flow of embedding information within Graph Neural Networks affects link prediction performance in Knowledge Graphs, using a clinical triage use case with synthetic healthcare data. The authors propose a mathematical model that decouples GNN connectivity from the underlying graph data structure, allowing task-specific embedding flow design. Experiments demonstrate that incorporating domain knowledge into the GNN connectivity leads to better performance than using the same connectivity as the KG or allowing unconstrained embedding propagation. The results also show that negative edges play a crucial role in achieving good predictions, and that using too many GNN layers can degrade performance due to over-smoothing.

## Method Summary
The paper evaluates link prediction in a clinical triage setting using Graph Neural Networks on a synthetic healthcare dataset generated from Synthea. The approach constructs a Knowledge Graph with patients, encounters, medical conditions, observations, and care actions, then trains a GNN model with RGCNConv layers, DistMult scoring function, and logistic regression loss. The key innovation is decoupling GNN connectivity from KG structure through communication masks that control how embeddings propagate. Four different connectivity patterns are tested, with the optimal pattern allowing information flow only from observation and condition nodes to encounter nodes. The model is trained for 1000 epochs using the Adam optimizer with variable learning rate.

## Key Results
- C3 connectivity (allowing embedding flow from observations and conditions to encounters) achieves 88% accuracy for care action prediction, outperforming other connectivities
- Negative edges in the KG are crucial for link prediction performance
- Using more than 3 GNN layers degrades performance due to over-smoothing
- Bespoke GNN connectivity designed with domain knowledge significantly outperforms connectivity matching the KG structure

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Decoupling GNN connectivity from KG connectivity allows task-specific embedding flow
- **Mechanism**: The mathematical model enables designing connectivity patterns that match the specific link prediction task, independent of the actual graph structure
- **Core assumption**: Optimal embedding flow for learning may differ from the actual graph structure
- **Evidence**: Abstract states the model decouples GNN connectivity from graph data; Section II.C explains designing GNN connectivity is use-case dependent
- **Break condition**: If optimal embedding flow matches KG structure, decoupling adds no benefit

### Mechanism 2
- **Claim**: Negative edges provide crucial negative samples for link prediction
- **Mechanism**: Negative edges act as counterexamples during training, helping the model distinguish between true and false connections
- **Core assumption**: Link prediction is fundamentally binary classification requiring negative samples
- **Evidence**: Section IV-C3 shows not using negative edges considerably drops performance; Section IV-B1 describes adding negative links between encounters and non-matching care actions
- **Break condition**: If task has balanced positive/negative samples or uses loss functions not requiring explicit negative examples

### Mechanism 3
- **Claim**: Too many GNN layers cause over-smoothing, degrading performance
- **Mechanism**: As layers increase, node embeddings become increasingly similar to neighbors', eventually converging across the graph
- **Core assumption**: Over-smoothing phenomenon applies to this clinical triage use case
- **Evidence**: Section IV-C2 shows adding more layers decreases performance, contrasting with deep CNNs; attributes behavior to over-smoothing
- **Break condition**: If graph has properties preventing over-smoothing or if skip connections mitigate the effect

## Foundational Learning

- **Concept: Knowledge Graph structure and multi-relational data**
  - Why needed: The paper operates entirely within KG framework where nodes have types, edges have relations, and the goal is link prediction
  - Quick check: What are the three types of links mentioned (positive, negative, unknown) and what does each represent?

- **Concept: Graph Neural Network message passing**
  - Why needed: Understanding how embeddings propagate through the graph is central to investigating different GNN connectivities
  - Quick check: In the toy example (Fig. 2), how is the patient embedding computed from the medical conditions?

- **Concept: Optimization and loss functions for link prediction**
  - Why needed: The paper casts link prediction as optimization problem where embeddings and relation weights are learned to minimize loss
  - Quick check: What is the relationship between the score function f(ei, Wr, ej) and the label y_ij in the optimization problem?

## Architecture Onboarding

- **Component map**: Data preparation → PyG KG construction → GNN model definition → Training loop → Link prediction
- **Critical path**: The communication mask that controls GNN connectivity is the critical component affecting all downstream performance
- **Design tradeoffs**: Bespoke GNN connectivity vs. KG connectivity - bespoke performs better but requires domain knowledge
- **Failure signatures**: Poor performance with C1/C2 connectivities (not allowing observation/condition nodes to influence encounters), degradation with too many layers, significant drop without negative edges
- **First 3 experiments**:
  1. Compare C1, C2, C3, C4 connectivities to establish baseline performance differences
  2. Vary embedding size and layer count to find optimal architecture parameters
  3. Remove negative edges to confirm their importance in the KG

## Open Questions the Paper Calls Out
- How can the learning of domain knowledge for GNN connectivity be automated?
- What is the optimal number of GNN layers for different types of knowledge graphs and tasks?
- How does the performance of the proposed approach scale with larger and more complex knowledge graphs?

## Limitations
- Results are demonstrated on a single clinical triage use case with synthetic healthcare data, limiting generalizability to other domains
- The mathematical model for decoupling GNN connectivity is described but not rigorously proven optimal for arbitrary tasks
- The optimal number of GNN layers is determined empirically but not theoretically justified

## Confidence
- **High Confidence**: C3 connectivity outperforming other connectivities in this specific clinical triage task; importance of negative edges
- **Medium Confidence**: Over-smoothing causing performance degradation with deeper layers (consistent with literature but lacks direct evidence)
- **Low Confidence**: General claim that decoupling GNN connectivity from KG structure is beneficial across all link prediction tasks (only demonstrated for one use case)

## Next Checks
1. Apply the same connectivity comparison (C1-C4) to a different link prediction task (e.g., recommendation systems, social network analysis) to test generalizability
2. Measure embedding similarity between layers during training to directly confirm the over-smoothing hypothesis and plot how node embedding variance changes with layer depth
3. Repeat the negative edge removal experiment using margin-based ranking loss to determine if the importance of negative edges is loss-function dependent