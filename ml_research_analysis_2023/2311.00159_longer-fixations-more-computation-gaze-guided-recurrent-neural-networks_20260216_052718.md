---
ver: rpa2
title: 'Longer Fixations, More Computation: Gaze-Guided Recurrent Neural Networks'
arxiv_id: '2311.00159'
source_url: https://arxiv.org/abs/2311.00159
tags:
- fixation
- duration
- data
- human
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using eye fixation duration data to guide recurrent
  neural networks in processing text, making their computational behavior more similar
  to human reading patterns. The authors design fixation-guided parallel (FGP) RNN
  architectures that allocate more computational resources to words with longer fixation
  durations.
---

# Longer Fixations, More Computation: Gaze-Guided Recurrent Neural Networks

## Quick Facts
- arXiv ID: 2311.00159
- Source URL: https://arxiv.org/abs/2311.00159
- Reference count: 24
- Primary result: FGP RNN achieves 70.5 perplexity on WikiText-2 vs 76.0 for vanilla LSTM

## Executive Summary
This paper proposes fixation-guided parallel (FGP) RNN architectures that allocate computational resources based on eye fixation durations. The model uses parallel RNN components that activate selectively depending on fixation length, allowing more processing for words requiring deeper cognitive engagement. Experiments show FGP models outperform vanilla RNNs on language modeling and sentiment analysis tasks. Notably, the adaptive fixation prediction model learns to generate fixation patterns that, while resembling human eye movements, are actually better suited for guiding language models than human fixations themselves.

## Method Summary
The authors design FGP and FGL RNN architectures that use fixation duration data to control computational allocation. For language modeling, they train on WikiText-2 with weight tying and dropout, using Adam optimizer (lr=0.001) for 50 epochs. The adaptive fixation prediction model is trained alongside using multi-task learning on eye-tracking corpora (Dundee, GECO, ZuCo1, ZuCo2). Fixation durations are normalized to discrete values [1,12] and mapped to parallel component activation via sigmoid gating. For sentiment analysis, they use the Eye-tracking and Sentiment Analysis-II dataset with similar architecture.

## Key Results
- FGP LSTM achieves 70.5 perplexity on WikiText-2 vs 76.0 for vanilla LSTM
- Adaptive fixation prediction model learns fixation patterns resembling human eye movements without explicit training
- FGP models outperform baselines on sentiment analysis accuracy
- Model-predicted fixations are often more suitable than human fixations for guiding language models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FGP architecture allocates more computational resources to words with longer fixation durations, improving language modeling performance.
- Mechanism: Multiple parallel RNN components selectively update based on fixation duration, dedicating more processing power to important words.
- Core assumption: Longer fixation durations indicate higher cognitive processing needs, and distributing resources accordingly improves performance.
- Evidence anchors: FGP models achieve considerably better performance than baseline; longer fixations trigger more hidden state updates.
- Break condition: If fixation duration doesn't correlate with word importance or parallel structure introduces excessive overhead.

### Mechanism 2
- Claim: Adaptive fixation prediction model learns task-specific fixation patterns superior to human fixations.
- Mechanism: Trained end-to-end with FGP model, allowing discovery of optimal fixation patterns for language modeling.
- Core assumption: Optimal fixation pattern for language modeling differs from human reading patterns, and learned models can discover these differences.
- Evidence anchors: Model-predicted fixations resemble human eye movements but are more suitable for guiding language models; differences explained by task requirements.
- Break condition: If adaptive FP model fails to learn meaningful patterns or human fixations prove superior.

### Mechanism 3
- Claim: Parallel structure provides computational efficiency while maintaining or improving performance.
- Mechanism: Parallel architecture with selective activation processes sequences more efficiently than sequential RNNs.
- Core assumption: Parallel architecture with controlled activation offers computational benefits over sequential processing.
- Evidence anchors: FGP models achieve comparable results while only partially activating RNN layers; good performance attributed to parallel structure.
- Break condition: If parallel structure introduces significant overhead without performance benefits.

## Foundational Learning

- Concept: Eye-tracking data and fixation patterns
  - Why needed here: Model relies on fixation duration data to guide computational allocation
  - Quick check question: What's the difference between first fixation duration and total reading time in eye-tracking data?

- Concept: Recurrent neural network architectures and limitations
  - Why needed here: Paper builds upon RNNs to create more sophisticated models
  - Quick check question: How does the vanishing gradient problem affect traditional RNNs?

- Concept: Multi-task learning and adaptive model training
  - Why needed here: Adaptive FP model trained alongside main task using multi-task learning
  - Quick check question: What are benefits and challenges of multi-task learning in neural networks?

## Architecture Onboarding

- Component map: Word embeddings -> Fixation Prediction Model -> FGP/FGL layers -> Output layer (fully connected)

- Critical path:
  1. Word embeddings are processed
  2. Fixation durations are predicted or provided
  3. FGP/FGL layers selectively activate components based on fixation durations
  4. Outputs are combined and processed through task-specific layers

- Design tradeoffs:
  - Parallel vs. sequential processing: Parallel offers efficiency but may introduce complexity
  - Fixed vs. adaptive fixation prediction: Fixed is simpler but may not optimize for specific tasks
  - Number of components: More components allow finer control but increase computational cost

- Failure signatures:
  - Poor performance on language modeling tasks
  - Inability to learn meaningful fixation patterns
  - Excessive computational overhead without performance gains

- First 3 experiments:
  1. Implement basic FGP RNN with fixed fixation durations and compare to vanilla RNN
  2. Add adaptive fixation prediction and evaluate performance improvements
  3. Test different numbers of components in FGP architecture to find optimal configuration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would fixation-guided models perform on larger-scale language modeling datasets like WikiText-103 compared to WikiText-2?
- Basis in paper: Authors note limited compute budget prevents evaluation on larger datasets
- Why unresolved: No experimental results on larger datasets provided
- What evidence would resolve it: Running experiments on WikiText-103 and comparing performance to vanilla models

### Open Question 2
- Question: What is the optimal activation function for fixation prediction model instead of Sigmoid?
- Basis in paper: Paper mentions Sigmoid may not be best choice due to vanishing gradients
- Why unresolved: No experiments with alternative activation functions conducted
- What evidence would resolve it: Experimenting with ReLU, tanh, or other activations and evaluating impact

### Open Question 3
- Question: How do fixation-guided models perform on other NLP tasks beyond language modeling and sentiment analysis?
- Basis in paper: Authors suggest considering differences between generative modeling and human comprehension
- Why unresolved: Only evaluated on language modeling and sentiment analysis
- What evidence would resolve it: Conducting experiments on machine translation, question answering, or summarization tasks

## Limitations
- Computational efficiency claims lack runtime and memory usage comparisons
- Limited evaluation to WikiText-2 dataset without testing on larger corpora
- Analysis of human vs. model fixation differences based on indirect evidence

## Confidence
- Performance improvements: High confidence (clear quantitative metrics with significant differences)
- Computational efficiency: Low confidence (no runtime or resource usage comparisons)
- Adaptive fixation learning: Medium confidence (performance gains shown but mechanisms not fully explained)
- Human vs. model fixations: Medium confidence (interesting observations but limited direct evidence)

## Next Checks
1. Measure and compare training time, inference speed, and memory usage between FGP and vanilla RNNs across multiple hardware configurations
2. Test adaptive fixation prediction model on eye-tracking corpora not used during training to assess generalization
3. Conduct systematic ablation study disabling different FGP components to quantify individual contributions to performance improvements