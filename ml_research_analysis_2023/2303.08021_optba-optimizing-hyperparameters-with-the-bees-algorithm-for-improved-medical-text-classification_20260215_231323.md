---
ver: rpa2
title: 'OptBA: Optimizing Hyperparameters with the Bees Algorithm for Improved Medical
  Text Classification'
arxiv_id: '2303.08021'
source_url: https://arxiv.org/abs/2303.08021
tags:
- bees
- lstm
- dataset
- arabic
- algorithm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of hyperparameter optimization
  for deep learning models applied to medical text classification. The authors propose
  OptBA, a novel mechanism that leverages the Bees Algorithm, a recent swarm intelligence
  algorithm, to automatically fine-tune hyperparameters.
---

# OptBA: Optimizing Hyperparameters with the Bees Algorithm for Improved Medical Text Classification

## Quick Facts
- arXiv ID: 2303.08021
- Source URL: https://arxiv.org/abs/2303.08021
- Reference count: 18
- English dataset accuracy: 99.63% using LSTM + OptBA

## Executive Summary
This paper addresses the challenge of hyperparameter optimization for deep learning models in medical text classification. The authors propose OptBA, a novel mechanism that leverages the Bees Algorithm to automatically fine-tune hyperparameters, specifically for LSTM networks. Experiments on English and Arabic datasets demonstrate significant accuracy improvements, with OptBA achieving 99.63% accuracy on the English dataset compared to baseline LSTM performance.

## Method Summary
The approach combines text preprocessing (tokenization, stop-word removal, lemmatization), word embeddings for English text, and the Bees Algorithm for hyperparameter optimization. For English data, LSTM models are tuned with OptBA to optimize epochs and unit counts. For Arabic data, AraBERT is used with data augmentation to handle small sample sizes. The Bees Algorithm iteratively searches the hyperparameter space, using validation accuracy as the fitness function to guide the search process.

## Key Results
- Achieved 99.63% accuracy on English medical text classification using LSTM with OptBA
- Improved baseline LSTM accuracy by approximately 1.45% through hyperparameter optimization
- Arabic dataset performance reached 88% accuracy using AraBERT with data augmentation
- OptBA successfully optimized LSTM hyperparameters from baseline (64 units, 20 epochs) to optimal (17 units, 47 epochs)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Bees Algorithm improves LSTM performance by fine-tuning both epoch count and number of LSTM units through iterative local and global search.
- Mechanism: OptBA uses a population of bees, each encoding a hyperparameter configuration (epochs, units). Local search explores neighborhoods around elite bees; global search introduces diversity via random sampling. Fitness is measured by LSTM validation accuracy.
- Core assumption: Small hyperparameter adjustments in the neighborhood of elite solutions yield improvements without destabilizing model convergence.
- Evidence anchors:
  - [abstract] "Experiments included two different datasets: English and Arabic... The highest accuracy achieved is 99.63% on the English dataset using LSTM along with the Bees Algorithm"
  - [section] "Each parameter is generated randomly using the Uniform distribution function... The evaluation function in the proposed method is the neural network in Section 3.4, and the evaluation value is the obtained accuracy on the validation set"
  - [corpus] Weak evidence; no neighboring papers explicitly validate BA for LSTM hyperparameter tuning in medical text classification.
- Break condition: If the validation accuracy plateaus or degrades during local search iterations, the algorithm should revert to a prior elite bee or trigger global search to escape local optima.

### Mechanism 2
- Claim: Data augmentation expands the Arabic dataset from 150 to 423 samples, enabling AraBERT to learn a richer representation and achieve 88% accuracy.
- Mechanism: nlpaug generates synthetic variations of existing text samples (e.g., synonym replacement, word insertion). The augmented dataset becomes balanced, allowing AraBERT to generalize better on small, imbalanced data.
- Core assumption: The augmented samples are semantically consistent with original ones and do not introduce noise that would mislead the model.
- Evidence anchors:
  - [section] "text augmentation is applied to enhance the deep learning model performance and reduce the probability of overﬁtting... the size of the data increased to 2829 and 342 data samples in both English and Arabic datasets, respectively"
  - [corpus] No direct neighboring evidence; this is a common NLP technique but not validated here specifically for AraBERT on Arabic medical data.
- Break condition: If cross-validation accuracy drops significantly after augmentation, revert to the original dataset or adjust augmentation intensity.

### Mechanism 3
- Claim: LSTM with 64 units and 20 epochs is a strong baseline; OptBA improves it to 17 units and 47 epochs, yielding a 1.45% accuracy gain.
- Mechanism: The baseline model is first trained to establish performance. OptBA then searches the hyperparameter space defined by epoch ∈ [low, high] and units ∈ [low, high], optimizing validation accuracy.
- Core assumption: The LSTM architecture with default parameters is not optimal; there exists a better combination within the explored ranges.
- Evidence anchors:
  - [section] "the Bees Algorithm is applied to ﬁnd the optimal values of the number of epochs... and the number of units in LSTM network to enhance the obtained accuracy... the resulting accuracy value"
  - [corpus] Weak; no neighboring papers provide direct comparison of BA-tuned LSTM on medical text classification.
- Break condition: If the optimal hyperparameters found by BA do not outperform the baseline after 3 independent runs, the approach may not be effective for this domain.

## Foundational Learning

- Concept: Swarm intelligence algorithms (e.g., Bees Algorithm)
  - Why needed here: Provides a meta-heuristic for efficient hyperparameter search, reducing manual tuning effort.
  - Quick check question: How does the Bees Algorithm balance exploration and exploitation compared to random search?

- Concept: Text preprocessing pipeline (tokenization, stop-word removal, lemmatization)
  - Why needed here: Converts raw medical text into a format suitable for numerical embedding and model ingestion.
  - Quick check question: What is the effect of removing stop words on medical terminology that may be common but informative?

- Concept: Cross-validation for small datasets
  - Why needed here: Ensures model robustness when the dataset is limited (e.g., Arabic data with 150 samples).
  - Quick check question: Why might 5-fold cross-validation be preferred over 10-fold when sample size is small?

## Architecture Onboarding

- Component map:
  Data preprocessing → Word embeddings → LSTM model → Bees Algorithm hyperparameter search → Evaluation metrics (Precision, Recall, F1, Accuracy)
  Separate pipeline for English (LSTM + OptBA) and Arabic (AraBERT)

- Critical path:
  1. Load and augment data
  2. Preprocess and embed text
  3. Train baseline LSTM
  4. Run OptBA to find optimal hyperparameters
  5. Evaluate on test set
  6. Repeat for Arabic with AraBERT

- Design tradeoffs:
  - OptBA vs. random search: BA may converge faster but requires careful neighborhood sizing; random search is simpler but may miss fine-tuned regions.
  - Data augmentation: Improves generalization but risks introducing label noise if synthetic samples are unrealistic.
  - LSTM units vs. epochs: More units increase capacity but risk overfitting; more epochs improve training but risk overfitting if early stopping is not used.

- Failure signatures:
  - OptBA produces hyperparameters that yield worse accuracy than baseline → check neighborhood size and elite selection criteria.
  - High variance in cross-validation scores → check data augmentation quality and class balance.
  - Training curves plateau early → increase epochs or adjust learning rate.

- First 3 experiments:
  1. Train baseline LSTM with default hyperparameters (64 units, 20 epochs) and record validation accuracy.
  2. Run OptBA with a small population (n=5) and minimal iterations to verify search mechanics.
  3. Apply data augmentation to Arabic dataset and retrain AraBERT, comparing before/after cross-validation accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal number of epochs for the LSTM model on the English dataset, and does it plateau beyond a certain point?
- Basis in paper: [explicit] The paper shows that accuracy improves with epochs up to 20, but ablation studies explore up to 40 epochs.
- Why unresolved: While the paper shows that accuracy improves up to 20 epochs, it does not definitively state the optimal number of epochs. The ablation studies suggest that there is no significant improvement beyond 20 epochs, but this needs further investigation.
- What evidence would resolve it: Additional experiments with more epochs, potentially beyond 40, to determine if accuracy plateaus or continues to improve.

### Open Question 2
- Question: How does the Bees Algorithm perform on other deep learning architectures beyond LSTM, such as Convolutional Neural Networks (CNN) or Transformer models?
- Basis in paper: [inferred] The paper focuses on applying the Bees Algorithm to LSTM for medical text classification, but does not explore its performance on other architectures.
- Why unresolved: The paper does not provide evidence of the Bees Algorithm's effectiveness on other deep learning architectures, which limits its generalizability.
- What evidence would resolve it: Experiments applying the Bees Algorithm to other deep learning architectures on the same or similar datasets to compare performance.

### Open Question 3
- Question: What is the impact of different word embedding techniques, such as Word2Vec or GloVe, on the performance of the LSTM model with the Bees Algorithm?
- Basis in paper: [inferred] The paper uses word embeddings of size 32, but does not explore the impact of different embedding techniques.
- Why unresolved: The paper does not provide evidence of the impact of different word embedding techniques on the performance of the LSTM model with the Bees Algorithm.
- What evidence would resolve it: Experiments using different word embedding techniques, such as Word2Vec or GloVe, with the same LSTM model and Bees Algorithm to compare performance.

## Limitations

- Limited validation of Arabic dataset augmentation strategy and potential label noise introduction
- Lack of comparison with established hyperparameter optimization methods (Bayesian optimization, random search)
- No detailed specification of Bees Algorithm implementation parameters (neighborhood size, stopping criteria)

## Confidence

- Bees Algorithm hyperparameter optimization: Medium confidence - novel approach but lacks direct comparison with established methods
- Arabic dataset augmentation: Low confidence - limited dataset size and lack of cross-validation details
- Overall accuracy claims: Medium confidence - based on single dataset, may not generalize to other medical text classification tasks

## Next Checks

1. Implement the Bees Algorithm with varying neighborhood sizes and compare convergence behavior against random search baseline.
2. Conduct ablation studies on data augmentation by training with and without synthetic samples, measuring the impact on Arabic dataset performance.
3. Perform 5-fold cross-validation on both English and Arabic datasets to establish model robustness and reduce overfitting concerns.