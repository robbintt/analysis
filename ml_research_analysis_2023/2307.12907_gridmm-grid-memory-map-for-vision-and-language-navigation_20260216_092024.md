---
ver: rpa2
title: 'GridMM: Grid Memory Map for Vision-and-Language Navigation'
arxiv_id: '2307.12907'
source_url: https://arxiv.org/abs/2307.12907
tags:
- navigation
- grid
- features
- gridmm
- environments
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a Grid Memory Map (GridMM) to structure the
  visited environment for vision-and-language navigation (VLN). GridMM uses a dynamically
  growing grid map to represent the global space-time relations of the environment,
  and an instruction relevance aggregation method to capture fine-grained visual clues.
---

# GridMM: Grid Memory Map for Vision-and-Language Navigation

## Quick Facts
- arXiv ID: 2307.12907
- Source URL: https://arxiv.org/abs/2307.12907
- Authors: [Authors not specified]
- Reference count: 40
- Primary result: Proposes Grid Memory Map (GridMM) that achieves state-of-the-art performance on vision-and-language navigation benchmarks

## Executive Summary
GridMM introduces a novel approach to vision-and-language navigation by constructing a dynamically growing grid memory map that captures global space-time relations of the environment. The method projects fine-grained visual features into a unified top-down egocentric grid and employs instruction relevance aggregation to filter and combine visual information. Experiments demonstrate superior performance across multiple datasets including REVERIE, R2R, SOON, and R2R-CE, with comprehensive analyses comparing effectiveness against other mapping approaches.

## Method Summary
GridMM addresses vision-and-language navigation by creating a top-down egocentric grid memory map that dynamically grows as the agent explores. The approach extracts visual features using CLIP-ViT-B/32 for grid regions and ViT-B/16 for panoramic views, then transforms absolute coordinates to relative egocentric coordinates for efficient spatial representation. Instruction relevance aggregation filters visual features based on their importance to navigation instructions via cross-attention mechanisms. The method is trained with pre-training tasks (MLM, MVM, SAP, HER) followed by fine-tuning using Dagger training on Matterport3D simulator.

## Key Results
- Achieves state-of-the-art performance on REVERIE, R2R, SOON, and R2R-CE datasets
- Demonstrates superior navigation error and success rate metrics compared to previous methods
- Provides comprehensive analysis showing effectiveness of GridMM versus alternative mapping approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GridMM provides superior spatial representation through egocentric coordinate transformation
- Mechanism: Transforms absolute coordinates to relative egocentric coordinates, placing agent at map center for efficient alignment
- Core assumption: Egocentric transformation preserves spatial relationships while simplifying action planning
- Evidence anchors:
  - [abstract] "historical observations are projected into a unified grid map in a top-down view"
  - [section] "we propose a new mapping method to construct the top-down egocentric and dynamically growing map"
- Break condition: Frequent heading changes may diminish egocentric alignment advantage

### Mechanism 2
- Claim: Instruction relevance aggregation captures critical visual clues
- Mechanism: Uses cross-attention between grid features and instruction tokens, followed by row-wise max-pooling
- Core assumption: Not all visual features are equally important; instruction-relevant features should dominate
- Evidence anchors:
  - [abstract] "we further propose an instruction relevance aggregation method to capture fine-grained visual clues"
  - [section] "a large number of grid features within each cell region are not all needed by the agent"
- Break condition: Ambiguous instructions may lead to discarding useful visual information

### Mechanism 3
- Claim: Dynamic grid resizing balances representation capacity and efficiency
- Mechanism: Grid side length increases with exploration distance to fit visited regions
- Core assumption: Visited environment extent can be bounded by agent trajectory
- Evidence anchors:
  - [section] "build a grid map in an egocentric view by projecting all features"
  - [section] "size of the GridMM increases with the expansion of the visited environment"
- Break condition: Sudden large expansions may cause resizing lag

## Foundational Learning

- Concept: Coordinate transformation between absolute and relative frames
  - Why needed here: Converts global coordinates to agent-centric view for efficient planning
  - Quick check question: What mathematical operation converts absolute coordinate (x,y) to relative coordinates when agent is at (X,Y) facing angle Θ?

- Concept: Cross-modal attention for relevance scoring
  - Why needed here: Evaluates visual feature importance for navigation instruction
  - Quick check question: How does relevance matrix A in Equation (6) relate grid features to instruction tokens?

- Concept: Dynamic memory management with caching
  - Why needed here: Handles growing grid features efficiently without recomputing
  - Quick check question: Why does caching previous relevance computations reduce computational cost?

## Architecture Onboarding

- Component map: CLIP-ViT-B/32 -> Grid feature extraction -> Coordinate transformation -> Instruction relevance aggregation -> Map feature creation -> Cross-modal transformer -> Action prediction
- Critical path: Visual observation → Grid feature extraction → Coordinate transformation → Instruction relevance aggregation → Map feature creation → Cross-modal reasoning → Action prediction
- Design tradeoffs:
  - Grid scale vs. computational cost: Larger grids capture more detail but increase computation quadratically
  - Cache granularity vs. memory usage: Fine-grained caching saves computation but requires more memory
  - Instruction relevance vs. completeness: Aggressive filtering improves efficiency but may miss useful information
- Failure signatures:
  - Grid features not appearing in expected cells → Coordinate transformation error
  - Poor navigation performance despite correct map construction → Instruction relevance aggregation failure
  - Memory overflow during long trajectories → Dynamic memory management issue
- First 3 experiments:
  1. Verify coordinate transformation by plotting projected features against ground truth positions
  2. Test instruction relevance aggregation by visualizing attention weights on sample grid features
  3. Benchmark computational cost with and without caching at different trajectory lengths

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does GridMM handle multi-floor environments, and what modifications would be needed to extend its current approach?
- Basis in paper: [explicit] "how to handle multi-floor environments remains open" in conclusion section
- Why unresolved: Current GridMM designed for single-floor environments without addressing vertical transitions
- What evidence would resolve it: Experiments on multi-floor datasets or architectural modifications for vertical transitions

### Open Question 2
- Question: How does choice of CLIP-ViT-B/32 for grid features impact GridMM's performance compared to other vision models?
- Basis in paper: [explicit] "we adopt the pre-trained CLIP-ViT-B/32 [44] to extract grid features Gt on all datasets"
- Why unresolved: No ablation study comparing CLIP-ViT-B/32 with other vision models for grid feature extraction
- What evidence would resolve it: Ablation study comparing GridMM performance using different vision models

### Open Question 3
- Question: What is the optimal scale for Grid Memory Map considering performance and computational cost trade-off?
- Basis in paper: [explicit] "we evaluate the scale of our GridMM" showing scale increases improve performance but computational cost
- Why unresolved: No comprehensive analysis of optimal scale balancing performance and computational cost
- What evidence would resolve it: Detailed analysis of relationship between scale, performance, and computational cost with cost-benefit analysis

## Limitations

- Computational overhead of dynamic grid system not thoroughly analyzed
- Method requires depth information, limiting applicability in environments with unreliable depth sensing
- Scalability to larger or outdoor environments remains untested

## Confidence

- High confidence in effectiveness of egocentric coordinate transformation (supported by strong quantitative results across multiple datasets)
- Medium confidence in instruction relevance aggregation contribution (results show improvement but ablation studies are limited)
- Medium confidence in overall architectural design (effective but computational efficiency concerns not fully addressed)

## Next Checks

1. Test GridMM in environments with noisy or missing depth information to assess robustness to sensor limitations
2. Conduct ablation studies specifically isolating contribution of instruction relevance aggregation versus coordinate transformation
3. Benchmark computational overhead against baseline methods across trajectories of varying lengths to quantify efficiency trade-offs