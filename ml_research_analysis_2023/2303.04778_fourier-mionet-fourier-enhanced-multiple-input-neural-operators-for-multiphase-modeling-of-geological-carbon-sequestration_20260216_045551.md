---
ver: rpa2
title: 'Fourier-MIONet: Fourier-enhanced multiple-input neural operators for multiphase
  modeling of geological carbon sequestration'
arxiv_id: '2303.04778'
source_url: https://arxiv.org/abs/2303.04778
tags:
- time
- fourier-mionet
- u-fno
- training
- neural
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We propose Fourier-MIONet, a Fourier-enhanced multiple-input neural
  operator for the modeling of multiphase flow in porous media, with applications
  to geological carbon sequestration. Fourier-MIONet combines the multiple-input deep
  neural operator (MIONet) framework with the Fourier neural operator (FNO), enabling
  efficient and accurate predictions of CO2 saturation and pressure buildup over time.
---

# Fourier-MIONet: Fourier-enhanced multiple-input neural operators for multiphase modeling of geological carbon sequestration

## Quick Facts
- arXiv ID: 2303.04778
- Source URL: https://arxiv.org/abs/2303.04778
- Reference count: 40
- Key outcome: Achieves 90% fewer parameters than U-FNO while maintaining similar accuracy for CO2 saturation and pressure prediction in geological carbon sequestration

## Executive Summary
Fourier-MIONet introduces a novel neural operator architecture that combines multiple-input operators with Fourier-based convolutions for efficient modeling of multiphase flow in porous media. The method treats time as a separate input rather than expanding it across spatial dimensions, enabling training with as few as six time snapshots while maintaining generalizability. By leveraging 2D FFT instead of 3D FFT and reducing parameter count, the model achieves significant computational efficiency gains without sacrificing prediction accuracy.

## Method Summary
Fourier-MIONet builds on the MIONet framework by incorporating Fourier layers from the U-FNO architecture. The model uses branch networks to encode field inputs (permeability, porosity) and scalar inputs (injection rate, temperature), while time is handled separately by a trunk network. Merge operations (point-wise summation and multiplication) combine these representations before passing through a U-FNO decoder with 2D FFT. The model is trained using lp-loss on a dataset of 4500 training cases and 500 test cases, each with 24 time snapshots spanning 30 years of geological carbon sequestration simulation.

## Key Results
- Achieves similar prediction accuracy to U-FNO with 90% fewer trainable parameters
- Reduces training time by approximately 3.5 times while requiring less CPU (<15%) and GPU (<35%) memory
- Can be trained with as few as six time snapshots and generalize to predict solutions for 30 years
- Maintains excellent accuracy (R2 scores >0.99 for both CO2 saturation and pressure predictions)

## Why This Works (Mechanism)

### Mechanism 1
Fourier-MIONet achieves similar prediction accuracy to U-FNO while reducing trainable parameters by 90% by treating time as a separate trunk input rather than expanding it across spatial dimensions. This works because PDE solutions are continuous over time, allowing the model to learn a continuous mapping from time to solution fields without requiring full temporal-channel expansion.

### Mechanism 2
The model can be trained with as few as six time snapshots and generalize to unseen times because it enforces temporal continuity through its architecture. By using time as the trunk input, the model learns to interpolate and extrapolate solution fields across time, leveraging the physical principle that PDE solutions vary continuously over time.

### Mechanism 3
Fourier-MIONet significantly reduces computational cost by using 2D FFT instead of 3D FFT, reducing parameter count, and allowing flexible batchtime selection. The separation of spatial and temporal processing optimizes memory usage and computation speed while maintaining sufficient information for accurate prediction.

## Foundational Learning

- **Neural Operators (DeepONet, FNO)**: Understanding the difference between learning operators vs functions, and why Fourier methods accelerate convolutions. Quick check: What is the key difference between DeepONet and FNO in terms of computational efficiency?
- **Multiphase flow in porous media**: The physical problem being modeled requires understanding of governing equations and input/output fields. Quick check: What are the two main output fields being predicted in this geological carbon sequestration problem?
- **Fourier transforms and FFT for PDE solutions**: FNO's efficiency comes from computing convolutions in Fourier space rather than physical space. Quick check: Why does FNO use Fourier transforms instead of traditional convolutional layers?

## Architecture Onboarding

- **Component map**: Field inputs → Branch nets → Merge → Trunk (time) → Merge → FNO decoder → Output fields
- **Critical path**: Branch networks process permeability, porosity, and scalar parameters; trunk network processes time; merge operations combine representations; U-FNO decoder with 2D FFT produces final outputs
- **Design tradeoffs**: 2D vs 3D FFT (memory vs accuracy), time as separate input vs full temporal channels, parameter reduction vs model capacity
- **Failure signatures**: Poor accuracy at unseen times, high memory usage despite parameter reduction, training instability or convergence issues
- **First 3 experiments**: 
  1. Train with batchtime=24 (full time) to verify baseline accuracy matches U-FNO
  2. Reduce batchtime to 8 and measure accuracy/memory tradeoff
  3. Train with only 6 time snapshots to test generalization capability

## Open Questions the Paper Calls Out

### Open Question 1
How does Fourier-MIONet's performance scale when applied to 4D geological carbon sequestration problems with complex, non-radially symmetric heterogeneities? The paper acknowledges this importance but lacks empirical results or performance metrics.

### Open Question 2
What is the impact of different merge operations (e.g., point-wise summation vs. point-wise multiplication) on the accuracy and efficiency of Fourier-MIONet? The paper only tests one type and mentions alternatives as potential future study areas.

### Open Question 3
How does the choice of nonuniform sampling strategies affect the generalizability and accuracy of Fourier-MIONet when trained on sparse time snapshots? The paper tests several cases but doesn't explore the full range of possible strategies or their trade-offs.

## Limitations

- Time generalization capability has not been benchmarked against alternative approaches for sparse time data
- The model's performance on problems with strong temporal-spatial coupling remains untested
- No systematic comparison of different merge operations or their impact on model performance
- Limited validation on geological formations beyond the specific dataset used

## Confidence

- Computational efficiency claims (90% fewer parameters, 3.5x faster): Medium
- Prediction accuracy parity with U-FNO: High
- Time generalization from 6 snapshots: Low
- Memory reduction claims (CPU <15%, GPU <35%): Medium

## Next Checks

1. Benchmark against alternative time-generalization methods to compare Fourier-MIONet's sparse time data extrapolation capability against recurrent neural operators or physics-informed neural networks.

2. Stress-test the 2D FFT assumption by systematically evaluating performance degradation with increased temporal resolution or strong time-space coupling to determine the limits of the spatial decomposition approach.

3. Cross-validate on independent datasets by applying Fourier-MIONet to multiphase flow problems from different geological formations or with different physical parameters to verify robustness beyond the specific dataset used.