---
ver: rpa2
title: Construction of Paired Knowledge Graph-Text Datasets Informed by Cyclic Evaluation
arxiv_id: '2309.11669'
source_url: https://arxiv.org/abs/2309.11669
tags:
- triples
- datasets
- text
- dataset
- evaluation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using cyclic generation to assess the quality
  of Knowledge Graph (KG)-text datasets, where models are trained to generate text
  from KG (forward) and KG from text (reverse), and then reconstruct the original
  source. The authors verify that noisier datasets lead to more hallucination, and
  show that manually created WebNLG is superior to automatically constructed datasets
  like TeKGen and T-REx in terms of cyclic evaluation.
---

# Construction of Paired Knowledge Graph-Text Datasets Informed by Cyclic Evaluation

## Quick Facts
- arXiv ID: 2309.11669
- Source URL: https://arxiv.org/abs/2309.11669
- Reference count: 19
- Key outcome: Proposes cyclic generation evaluation for KG-text datasets, introduces LAGRANGE dataset, shows noisy datasets lead to more hallucination

## Executive Summary
This paper introduces cyclic evaluation as a method to assess the quality of Knowledge Graph-text datasets by training models to generate text from KG (forward) and KG from text (reverse), then measuring their ability to reconstruct the original source. The authors demonstrate that noisier datasets lead to more hallucination and show that manually created WebNLG is superior to automatically constructed datasets like TeKGen and T-REx in cyclic evaluation. They introduce LAGRANGE, a new dataset constructed using heuristics to improve KG-text equivalence, and demonstrate its superiority over existing datasets.

## Method Summary
The method trains T5 transformer models for forward (KG-to-text) and reverse (text-to-KG) generation, then evaluates cyclic reconstruction quality using BLEU, ROUGE, precision, recall, and F1 metrics. The LAGRANGE dataset is constructed by aligning Wikidata triples with Wikipedia sentences using string matching, incorporating second-hop neighbors, applying semantic entailment filtering, and augmenting KG triples using T2G models.

## Key Results
- Noisier datasets lead to more hallucination in cyclic generation tasks
- WebNLG outperforms automatically constructed datasets (TeKGen, T-REx) in cyclic evaluation
- LAGRANGE dataset shows superior performance across multiple metrics
- LLM-generated synthetic datasets perform well on cyclic text generation but less so on KG generation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Cyclic evaluation provides a better proxy for dataset quality than unidirectional evaluation.
- **Mechanism**: By training models in both directions (KG→text and text→KG) and measuring their ability to reconstruct the original input, cyclic evaluation indirectly assesses the equivalence between KG and text pairs in the dataset.
- **Core assumption**: The quality of cyclic reconstruction correlates with the inherent alignment quality of the dataset.
- **Evidence anchors**:
  - [abstract] "We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset."
  - [section 3] "In cyclic evaluations (see Figure 1), we compute a GTG score... which compares a cyclically generated set of triples... against the original set... Similarly we compute a TGT evaluation... which compares a cyclically generated sentence... against the original T."
- **Break condition**: If the model architecture is too weak to learn meaningful representations, cyclic evaluation scores may reflect model capacity rather than dataset quality.

### Mechanism 2
- **Claim**: Noisy datasets lead to more hallucination in generated text and KG.
- **Mechanism**: When the conditioning data (KG or text) contains information not present in the target (text or KG), models learn to hallucinate to compensate for the mismatch. Cyclic evaluation captures this by measuring how well the model can reconstruct the original input after two passes through the model.
- **Core assumption**: The level of noise in the dataset directly affects the model's tendency to hallucinate during generation.
- **Evidence anchors**:
  - [abstract] "we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination."
  - [section 4] "We can control the level of misalignment by controlling the probability with which triples are modified7. We observe that as additional noise is introduced, the forward and reverse models trained on these noisy datasets become less accurate in both precision and recall."
- **Break condition**: If the model is over-regularized or trained with strong adversarial objectives, it might suppress hallucination regardless of dataset noise.

### Mechanism 3
- **Claim**: LAGRANGE improves dataset alignment by incorporating second-hop neighbors and semantic filtering.
- **Mechanism**: By including second-hop neighbors in the KG triples and filtering out triples that are not semantically entailed by the text, LAGRANGE ensures better coverage and relevance of the KG to the text. This improves the alignment quality and reduces hallucination in models trained on the dataset.
- **Core assumption**: Second-hop neighbors provide additional context that is relevant to the sentence, and semantic filtering removes irrelevant triples.
- **Evidence anchors**:
  - [section 4.1.2] "A significant number of sentences contain additional information in them that does not relate to the subject entity, but to other entities in the sentence. In order to ensure a good coverage of the information present in the sentence, we also matched second-hop KG triples..."
  - [section 4.1.3] "To fix this, we use an entailment model to remove aligned KG triples that were not entailed by the text."
  - [table 6] "As observed, all the proposed techniques consistently resulted in improvements across almost all metrics for both TGT and GTG evaluations, affirming their effectiveness."
- **Break condition**: If the entailment model is not accurate or the second-hop neighbors are not relevant, the filtering and augmentation steps may not improve alignment quality.

## Foundational Learning

- **Concept**: Knowledge Graph (KG) and Text alignment
  - **Why needed here**: The paper focuses on creating and evaluating datasets that pair KGs with text. Understanding how KGs and text can be aligned is crucial for assessing the quality of these datasets.
  - **Quick check question**: What are the key challenges in aligning KGs and text, and how do different datasets (WebNLG, TeKGen, T-REx) address these challenges?

- **Concept**: Sequence-to-sequence (seq2seq) modeling
  - **Why needed here**: The paper uses seq2seq models to train forward and reverse models for generating text from KG and vice versa. Understanding how seq2seq models work is essential for understanding the cyclic evaluation approach.
  - **Quick check question**: How do seq2seq models handle the generation of text from structured KG data, and what are the common challenges in this task?

- **Concept**: Cyclic evaluation and back-translation
  - **Why needed here**: The paper proposes cyclic evaluation as a method to assess dataset quality, which is similar to back-translation in machine translation. Understanding the principles of cyclic evaluation and back-translation is important for grasping the paper's methodology.
  - **Quick check question**: How does cyclic evaluation differ from traditional evaluation methods, and what are the advantages of using cyclic evaluation for assessing KG-text datasets?

## Architecture Onboarding

- **Component map**: Wikidata triples → String matching → Semantic entailment filtering → Second-hop neighbor inclusion → LAGRANGE dataset → T5 seq2seq models → Cyclic evaluation

- **Critical path**:
  1. Construct initial KG-text alignment using string matching and second-hop neighbors
  2. Filter out low-quality matches using semantic entailment
  3. Augment KG triples using T2G model
  4. Train seq2seq models on the dataset
  5. Perform cyclic evaluation to assess dataset quality
  6. Compare cyclic evaluation results across different datasets

- **Design tradeoffs**:
  - **Dataset size vs. quality**: Larger datasets like TeKGen may have more examples but lower alignment quality compared to smaller, manually created datasets like WebNLG
  - **Second-hop coverage vs. relevance**: Including second-hop neighbors increases coverage but may introduce irrelevant information if not filtered properly
  - **Semantic filtering vs. completeness**: Strict semantic filtering improves alignment but may remove some valid triples

- **Failure signatures**:
  - **Poor cyclic evaluation scores**: Indicates low alignment quality or model capacity issues
  - **High hallucination in generated text**: Suggests noise or misalignment in the dataset
  - **Low precision/recall in KG reconstruction**: Implies missing or incorrect KG triples in the dataset

- **First 3 experiments**:
  1. **Noise injection experiment**: Introduce varying levels of noise into WebNLG and measure the impact on cyclic evaluation scores
  2. **Ablation study of LAGRANGE construction**: Remove each heuristic (second-hop, semantic filtering, length filtering) and measure the impact on cyclic evaluation
  3. **Comparison of LLM-generated datasets**: Generate KG-text pairs using different LLMs and compare their cyclic evaluation scores to assess alignment quality

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How do the synthetic datasets generated by LLMs perform on cyclic generation tasks compared to human-created or automatically constructed datasets?
- **Basis in paper**: The authors constructed synthetic datasets using ChatGPT and Guanaco-33B, and evaluated their performance on cyclic generation tasks. They found that these datasets performed well on cyclic text generation but less so on KG generation.
- **Why unresolved**: While the authors observed this trend, they did not provide a detailed analysis of the specific reasons behind the performance difference between text and KG generation in synthetic datasets.
- **What evidence would resolve it**: Further investigation into the characteristics of the generated text and KG, such as the diversity of predicates and entities, the consistency of ontology, and the level of detail in the generated content, could help explain the observed performance difference.

### Open Question 2
- **Question**: How does the choice of evaluation metrics (BLEU, ROUGE, precision, recall, F1) impact the assessment of dataset quality in cyclic generation tasks?
- **Basis in paper**: The authors used various evaluation metrics to assess the performance of cyclic generation tasks, including BLEU, ROUGE, precision, recall, and F1 scores. They observed that different metrics might have varying levels of resolution in detecting the effects of errors made in unidirectional generations on the reconstruction of the original source.
- **Why unresolved**: The authors did not provide a comprehensive analysis of the strengths and limitations of each evaluation metric in the context of cyclic generation tasks.
- **What evidence would resolve it**: A detailed comparison of the evaluation metrics, including their sensitivity to different types of errors and their ability to capture the overall quality of the generated content, would help determine the most appropriate metrics for assessing dataset quality in cyclic generation tasks.

### Open Question 3
- **Question**: How does the level of noise in KG-T datasets affect the performance of forward and reverse models in cyclic generation tasks?
- **Basis in paper**: The authors conducted experiments to test the effect of noise on the performance of forward and reverse models in cyclic generation tasks. They found that as more noise was introduced into the datasets, the quality of the generated content deteriorated.
- **Why unresolved**: While the authors demonstrated the negative impact of noise on cyclic generation performance, they did not explore the specific mechanisms through which noise affects the models' ability to generate accurate and coherent content.
- **What evidence would resolve it**: Further investigation into the relationship between noise levels and model performance, including the identification of specific types of noise that have the most significant impact, could help develop strategies to mitigate the effects of noise on cyclic generation tasks.

## Limitations

- The paper doesn't fully address whether poor cyclic scores are due to dataset quality or model limitations
- The effectiveness of cyclic evaluation for real-world downstream task performance remains unproven
- The fundamental limitations of LLM-generated datasets for KG generation are noted but not deeply explored

## Confidence

- **High confidence**: The basic premise that cyclic evaluation can serve as a proxy for dataset quality alignment, supported by controlled experiments with noise injection
- **Medium confidence**: The effectiveness of LAGRANGE's specific heuristics (second-hop neighbors, semantic filtering) in improving cyclic evaluation scores
- **Low confidence**: The generalizability of cyclic evaluation scores to real-world downstream task performance, and the fundamental limitations of LLM-generated datasets for KG generation

## Next Checks

1. **Downstream task validation**: Train models on WebNLG, TeKGen, T-REx, LAGRANGE, and LLM-generated datasets, then evaluate their performance on a standard KG-text generation benchmark to verify that cyclic evaluation scores correlate with task performance

2. **Model capacity ablation**: Repeat the cyclic evaluation experiments using models of varying capacities (T5-small, T5-base, T5-large) to determine whether cyclic scores reflect dataset quality or are confounded by model limitations

3. **Real-world noise analysis**: Instead of synthetic noise injection, analyze the correlation between cyclic evaluation scores and naturally occurring noise patterns in automatically constructed datasets, such as entity linking errors or relation extraction mistakes