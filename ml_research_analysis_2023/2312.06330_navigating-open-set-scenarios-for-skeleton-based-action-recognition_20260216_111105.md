---
ver: rpa2
title: Navigating Open Set Scenarios for Skeleton-based Action Recognition
arxiv_id: '2312.06330'
source_url: https://arxiv.org/abs/2312.06330
tags:
- open-set
- recognition
- o-auroc
- os-sar
- action
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles open-set skeleton-based action recognition,
  where models must recognize known actions and reject unknown ones using only skeletal
  data. The authors propose CrossMax, a multimodal approach that leverages joint,
  bone, and velocity streams with a novel cross-modality mean max discrepancy suppression
  mechanism during training and a cross-modality distance-based logits refinement
  method during testing.
---

# Navigating Open Set Scenarios for Skeleton-based Action Recognition

## Quick Facts
- arXiv ID: 2312.06330
- Source URL: https://arxiv.org/abs/2312.06330
- Reference count: 29
- Primary result: Proposes CrossMax, achieving 90.62% O-AUROC on NTU60 cross-subject evaluation

## Executive Summary
This paper addresses the challenge of open-set skeleton-based action recognition, where models must distinguish between known action classes and unknown/unseen classes using only skeletal data. The authors propose CrossMax, a multimodal approach that leverages joint, bone, and velocity streams with a novel cross-modality mean max discrepancy suppression mechanism during training and a cross-modality distance-based logits refinement method during testing. The method achieves state-of-the-art performance across multiple datasets and backbones, consistently outperforming existing open-set recognition methods with significant improvements in open-set metrics.

## Method Summary
CrossMax tackles open-set skeleton-based action recognition through a multimodal architecture operating on joint, bone, and velocity representations of skeleton data. The method employs a cross-modality mean max discrepancy (CrossMMD) loss during training to align latent spaces across the three modalities, followed by a test-time refinement using channel-normalized Euclidean distance (CNE-distance) to improve open-set confidence estimation. The approach uses an ensemble of three backbones (CTRGCN, HDGCN, Hyperformer) and introduces a novel logits refinement mechanism that combines averaged logits with distance-based confidence scores to balance classification accuracy with open-set detection.

## Key Results
- Achieves 90.62% O-AUROC on NTU60 cross-subject evaluation, significantly surpassing the best baseline (84.13% O-AUROC)
- Consistently outperforms existing open-set recognition methods across multiple datasets including NTU120 and ToyotaSmartHome
- Demonstrates improved robustness under Gaussian noise disturbance and random occlusion compared to baselines
- Shows generalizability across different backbone architectures including CTRGCN, HDGCN, and Hyperformer

## Why This Works (Mechanism)

### Mechanism 1
CrossMMD during training improves alignment of latent spaces across skeleton modalities (joints, bones, velocities) by computing intra- and inter-source differences using Gaussian kernels over concatenated embeddings. This encourages similar distributions across modalities in RKHS, allowing distribution-wise information exchange and reducing modality disparities. The core assumption is that Gaussian kernel-based MMD can effectively quantify and minimize distribution mismatch across heterogeneous skeleton streams.

### Mechanism 2
Channel-Normalized Euclidean distance (CNE-distance) provides better disentanglement between in- and out-of-distribution samples than SoftMax scores by computing L2-normalized Euclidean distance to nearest training embedding in each modality, then averaging. This produces Gaussian-like probability distributions and improves open-set recognition reliability. The core assumption is that Euclidean distance in normalized embedding space correlates well with semantic similarity and can serve as robust open-set confidence measure.

### Mechanism 3
Cross-modality distance-based logits refinement combines averaged logits with CNE-distances to preserve close-set accuracy while improving open-set detection by identifying the position of max logit, then refining salient logit using distance-weighted exponential transformation while scaling non-salient logits by squared distance. This balances classification accuracy with open-set confidence. The core assumption is that distance information can be meaningfully integrated into logits to distinguish in- and out-of-distribution samples without sacrificing classification performance.

## Foundational Learning

- Concept: Open-set recognition
  - Why needed here: The task requires distinguishing known actions from unknown ones, unlike closed-set classification where all test classes are seen during training
  - Quick check question: In open-set recognition, what should the model output for an action category never seen during training?

- Concept: Skeleton-based action representation
  - Why needed here: The method operates on skeletal data (joints, bones, velocities) rather than raw video or images, requiring specialized feature extraction
  - Quick check question: How are bone vectors computed from joint positions in skeleton data?

- Concept: Multi-modal fusion with cross-modal alignment
  - Why needed here: Different skeleton modalities capture complementary information; aligning them improves robustness and discriminative power
  - Quick check question: Why might joint positions alone be insufficient for action recognition compared to using bones and velocities as well?

## Architecture Onboarding

- Component map: Feature extraction backbones (CTRGCN, HDGCN, Hyperformer) -> Three parallel streams: joints, bones, velocities -> CrossMMD loss module (training) -> CNE-distance computation module (testing) -> Logits refinement module (testing) -> SoftMax classifier (both)

- Critical path: 1. Extract features from all three modalities using backbone 2. Apply CrossMMD loss to align latent spaces during training 3. At inference: compute CNE-distance for each modality 4. Average logits and apply distance-based refinement 5. Pass refined logits through SoftMax for final prediction

- Design tradeoffs: Memory vs. performance: using three backbones triples memory usage but improves cross-backbone generalizability; Training complexity vs. test simplicity: CrossMMD adds training complexity but simplifies test-time confidence estimation; Distance-based refinement vs. pure SoftMax: refinement improves open-set performance but adds hyperparameter sensitivity

- Failure signatures: Poor open-set performance despite good closed-set accuracy: likely insufficient disentanglement between in- and out-of-distribution samples; Unstable results across random splits: likely insufficient modality alignment or distance calibration; Degraded performance on noisy/occluded data: likely sensitivity to feature quality or embedding structure

- First 3 experiments: 1. Compare CrossMMD vs. no CrossMMD on a single backbone/dataset to verify latent space alignment benefits 2. Evaluate CNE-distance vs. SoftMax alone to confirm improved open-set confidence estimation 3. Test logits refinement with and without CNE-distance to validate the combination's effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
How does the CrossMMD mechanism specifically affect the alignment of latent spaces across different modalities (joints, bones, velocities) in terms of quantitative improvements in open-set recognition performance? While the paper mentions the CrossMMD mechanism and its role in aligning latent spaces, it does not provide detailed quantitative analysis or ablation studies specifically isolating the impact of CrossMMD on the alignment of different modalities.

### Open Question 2
What are the specific characteristics of the out-of-distribution samples that lead to the observed overconfidence in SoftMax-normalized probability estimates, and how does the CNE-distance mechanism address these characteristics? The paper identifies that SoftMax-based probability prediction suffers from bad disentanglement between in- and out-of-distribution samples, leading to overconfidence, but does not provide a detailed analysis of the specific characteristics of these samples.

### Open Question 3
How does the CrossMax methodology perform under varying levels of noise and occlusion in the skeleton data, and what are the specific degradation patterns observed in open-set recognition performance? While the paper presents performance under noise and occlusion, it does not provide a detailed analysis of the specific degradation patterns or how CrossMax's performance varies across different noise levels and occlusion ratios.

## Limitations
- The effectiveness of CrossMMD relies heavily on the assumption that Gaussian kernel-based distribution alignment can meaningfully bridge heterogeneous skeleton modalities, but direct validation on skeleton data is absent
- The CNE-distance assumption that nearest-neighbor distance in normalized embedding space correlates with semantic novelty is reasonable but unproven for skeleton data
- The logits refinement mechanism adds complexity with distance-based transformations that may be sensitive to hyperparameter tuning, and exact implementation details are sparse

## Confidence

- High confidence in the overall experimental methodology and evaluation framework
- Medium confidence in the cross-modality alignment approach (CrossMMD)
- Low confidence in the specific implementation details of the distance-based refinement mechanism

## Next Checks
1. Implement CrossMMD loss in isolation and compare latent space alignment via t-SNE visualizations against baseline without alignment
2. Validate CNE-distance distributions by checking if distances from known vs. unknown classes form separable distributions in validation sets
3. Conduct ablation study removing logits refinement while keeping CNE-distance to quantify refinement's specific contribution to performance gains