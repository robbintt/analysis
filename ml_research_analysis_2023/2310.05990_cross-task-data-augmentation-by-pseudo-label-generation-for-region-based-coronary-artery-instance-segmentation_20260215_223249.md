---
ver: rpa2
title: Cross-Task Data Augmentation by Pseudo-label Generation for Region Based Coronary
  Artery Instance Segmentation
arxiv_id: '2310.05990'
source_url: https://arxiv.org/abs/2310.05990
tags:
- segmentation
- coronary
- artery
- dataset
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of coronary artery segmentation
  in angiographic images, a crucial task for diagnosing Coronary Artery Diseases (CADs).
  Limited data availability and difficulty in curating datasets hinder model performance.
---

# Cross-Task Data Augmentation by Pseudo-label Generation for Region Based Coronary Artery Instance Segmentation

## Quick Facts
- arXiv ID: 2310.05990
- Source URL: https://arxiv.org/abs/2310.05990
- Reference count: 40
- This study introduces pseudo-label augmentation from a stenosis detection dataset to improve coronary artery segmentation performance, achieving F1 score of 0.35 on test set.

## Executive Summary
This study addresses the challenge of coronary artery segmentation in angiographic images, a crucial task for diagnosing Coronary Artery Diseases (CADs). Limited data availability and difficulty in curating datasets hinder model performance. To overcome this, the authors introduce a novel data augmentation technique using pseudo-labels generated from a separate related dataset. They employ the YOLO-v8 model as a baseline and augment it with pseudo-labels generated on stenosis images. The model is trained with an ensemble of five models from near the end of training phases. The proposed method achieves an F1 score of 0.35 on the test set, outperforming baseline models like ConvNeXt and ConvNeXtV2. The study demonstrates the effectiveness of pseudo-label augmentation in improving coronary artery segmentation performance.

## Method Summary
The method uses YOLO-v8 with CSP53Darknet backbone, trained for 120 epochs with AdamW optimizer. Pseudo-labels are generated from stenosis images using a YOLO-v8 model trained on the original dataset with weak augmentations. Predictions with confidence score ≥0.5 are considered valid annotations. The final model is an ensemble of five models from near the end of training phases. Input images undergo preprocessing with Unsharp Mask filter followed by CLAHE. The combined dataset (original + pseudo-labels) is used for training with specified loss weights (Lb=7.5, Lc=0.5, Ls=0.468, Lf=2.0) and augmentations including HSV, flip, translate, and scale operations.

## Key Results
- Achieved F1 score of 0.35 on test set, outperforming ConvNeXt and ConvNeXtV2 baselines
- Pseudo-label augmentation improved performance by incorporating diverse task-relevant data from stenosis detection dataset
- Ensemble averaging of five models from later training epochs improved robustness compared to single best model

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pseudo-label augmentation improves generalization by incorporating diverse task-relevant data from a separate stenosis detection dataset
- Mechanism: The model is trained on a combined dataset containing both original segmentation labels and pseudo-labels generated from stenosis images. These pseudo-labels are predictions from a YOLO-v8 model trained on the original dataset with weak augmentations, providing additional diverse training examples
- Core assumption: Pseudo-labels generated with sufficient confidence (≥0.5) are accurate enough to serve as reliable training signals for the target segmentation task
- Evidence anchors:
  - [abstract]: "we introduce the use of pseudo-labels generated on a dataset of separate related task to diversify and improve model performance"
  - [section 4.1]: "The pseudolables are generated using a model trained earlier on the actual dataset with weak train time augmentations. Predictions with confidence score 0.5 or greater were considered valid annotations"
  - [corpus]: Weak - the corpus doesn't contain direct evidence about pseudo-label quality thresholds or confidence calibration
- Break condition: Pseudo-labels contain too many errors, leading to model confusion or learning incorrect patterns

### Mechanism 2
- Claim: Ensemble averaging of multiple models from later training epochs improves robustness and generalization compared to using a single best model
- Mechanism: Five models from near the end of training (120 epochs) are averaged to create the final model, reducing variance and improving stability in predictions
- Core assumption: Models at similar stages of training capture complementary information that can be beneficial when combined
- Evidence anchors:
  - [section 4.4]: "Another important improvement in our model was achieved when instead of single best model we used an average of five models exported from near the end of the training phases"
  - [section 4.4]: "The averaged model achieved better performance on F1 Score when compared to the best model from previous training"
  - [corpus]: Weak - no corpus evidence about ensemble averaging in medical image segmentation
- Break condition: Models being averaged are too similar, providing no complementary information

### Mechanism 3
- Claim: Image enhancement preprocessing (Unsharp Mask + CLAHE) improves model performance by enhancing vessel-background contrast in angiographic images
- Mechanism: Preprocessing pipeline applied to both original and pseudo-label datasets improves feature extraction quality for the YOLO-v8 backbone
- Core assumption: The quality improvement from preprocessing translates to better learned representations in the feature extractor
- Evidence anchors:
  - [section 4.1]: "The new combined dataset, including the validation set, underwent preprocessing using a series of image enhancement techniques. These techniques included the application of an Unsharp Mask filter followed by Contrast Limited Adaptive Histogram Equalization (CLAHE)"
  - [section 4.3]: "For images with good contrast between vessel and background almost all of the baseline models perform well in detection as well as segmentation. However, when the contrast deters baseline models make erratic predictions"
  - [corpus]: Weak - corpus doesn't discuss specific preprocessing techniques for coronary artery segmentation
- Break condition: Preprocessing introduces artifacts that confuse the model or removes important diagnostic information

## Foundational Learning

- Concept: Pseudo-label generation and confidence thresholding
  - Why needed here: The method relies on generating high-quality pseudo-labels from a stenosis detection model to augment the limited coronary artery segmentation dataset
  - Quick check question: What confidence threshold was used to filter pseudo-labels, and why was this threshold chosen?

- Concept: Ensemble model averaging
  - Why needed here: The approach uses an ensemble of five models from later training epochs rather than a single best model to improve generalization
  - Quick check question: How many models were averaged in the ensemble, and at what stage of training were they selected?

- Concept: Loss function composition in instance segmentation
  - Why needed here: The YOLO-v8 model uses a composite loss function with specific gain coefficients for different loss components
  - Quick check question: What are the four components of the loss function, and what gain coefficients were assigned to each?

## Architecture Onboarding

- Component map: Input → Preprocessing (Unsharp Mask + CLAHE) → YOLO-v8 CSP53Darknet backbone → C2f neck module → Head (bounding boxes, objectness scores, class probabilities, segmentation masks) → Output
- Critical path: Data preprocessing → Backbone feature extraction → Neck feature aggregation → Head prediction generation
- Design tradeoffs: YOLO-v8 with C2f module chosen over traditional neck architecture for better feature aggregation; ensemble averaging adds computational overhead but improves generalization
- Failure signatures:
  - Poor F1 scores with high variance across classes suggests pseudo-label quality issues
  - Model overfitting to original dataset indicates insufficient diversity in augmentation
  - Convergence problems may indicate incorrect loss function gain coefficients
- First 3 experiments:
  1. Train baseline YOLO-v8 on original dataset only (no pseudo-labels) to establish performance baseline
  2. Generate pseudo-labels with different confidence thresholds (0.3, 0.5, 0.7) to find optimal quality filter
  3. Compare single best model vs. ensemble averaging from last 5 epochs to validate robustness improvement

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do pseudo-labels generated from a separate dataset affect model performance when the target dataset has significant class imbalance?
- Basis in paper: [explicit] The authors note that "the imbalanced nature of problem meant that the results weren't translated very well to the test set" and that "the performance of most of these models hence was skewed based on classes as well."
- Why unresolved: While the paper mentions class imbalance issues, it does not explore strategies to mitigate these effects when using pseudo-labels from different datasets
- What evidence would resolve it: Results from experiments testing different class balancing techniques (e.g., oversampling, class weighting) combined with pseudo-label augmentation

### Open Question 2
- Question: How does the quality of pseudo-labels impact the performance of the downstream segmentation model?
- Basis in paper: [explicit] The authors generate pseudo-labels using a model trained on the actual dataset with weak augmentations and use predictions with confidence score 0.5 or greater as valid annotations
- Why unresolved: The paper does not investigate the relationship between pseudo-label quality (e.g., confidence thresholds, model architecture used for generation) and segmentation performance
- What evidence would resolve it: Experiments varying pseudo-label quality metrics and their corresponding impact on segmentation F1 scores

### Open Question 3
- Question: Can the proposed pseudo-label augmentation technique generalize to other medical imaging tasks beyond coronary artery segmentation?
- Basis in paper: [inferred] The authors demonstrate the effectiveness of pseudo-label augmentation for coronary artery segmentation but do not explore its applicability to other tasks
- Why unresolved: The paper focuses solely on coronary artery segmentation and does not provide evidence for the technique's generalizability
- What evidence would resolve it: Experiments applying the pseudo-label augmentation technique to other medical imaging tasks and comparing performance to baseline methods

## Limitations
- The ARCADE dataset used contains only 1,200 images with 25 anatomical classes, which may limit model robustness to diverse angiographic presentations
- The pseudo-label generation process relies on a stenosis detection model trained on separate data, but the study doesn't provide detailed validation of pseudo-label quality or confidence calibration
- The ensemble averaging approach uses five models from near training completion without justification for this specific number or explanation of the averaging methodology

## Confidence

**High Confidence:** The experimental methodology for combining original and pseudo-label datasets, along with the reported F1 score of 0.35, appears reproducible based on the specified YOLO-v8 configuration and training parameters

**Medium Confidence:** The effectiveness of pseudo-label augmentation depends heavily on the quality of stenosis detection model predictions, but the study lacks detailed analysis of pseudo-label error rates or confidence calibration curves

**Low Confidence:** The ensemble averaging approach shows improvement over single-model baselines, but the selection criteria for which epochs to average and the specific averaging methodology remain underspecified

## Next Checks

1. **Pseudo-label Quality Analysis:** Generate confidence calibration curves for pseudo-labels at different threshold levels (0.3, 0.5, 0.7) to quantify the trade-off between quantity and quality of augmented data

2. **Ablation Study on Ensemble Size:** Systematically test ensemble averaging with different numbers of models (3, 5, 7) selected from various training stages to optimize the balance between diversity and performance

3. **Cross-dataset Generalization Test:** Evaluate the trained model on external coronary angiography datasets to assess whether pseudo-label augmentation improves generalization beyond the ARCADE dataset domain