---
ver: rpa2
title: Survey on Computer Vision Techniques for Internet-of-Things Devices
arxiv_id: '2308.02553'
source_url: https://arxiv.org/abs/2308.02553
tags:
- techniques
- dnns
- accuracy
- operations
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey paper reviews recent advances in low-power and energy-efficient
  deep neural network (DNN) implementations for deployment on Internet-of-Things (IoT)
  devices. The authors survey techniques for both convolutional and transformer DNNs,
  categorizing them into neural network compression, network architecture search and
  design, and compiler and graph optimizations.
---

# Survey on Computer Vision Techniques for Internet-of-Things Devices

## Quick Facts
- arXiv ID: 2308.02553
- Source URL: https://arxiv.org/abs/2308.02553
- Reference count: 37
- Primary result: Review of techniques to optimize DNNs for energy-efficient deployment on IoT devices

## Executive Summary
This survey paper reviews recent advances in low-power and energy-efficient deep neural network (DNN) implementations for deployment on Internet-of-Things (IoT) devices. The authors survey techniques for both convolutional and transformer DNNs, categorizing them into neural network compression, network architecture search and design, and compiler and graph optimizations. They find that these techniques can significantly reduce the memory requirements, number of arithmetic operations, or both, making DNNs more deployable on resource-constrained IoT devices. The paper provides a comparison of different techniques, highlights their advantages and disadvantages, and proposes new evaluation metrics for future research in this area.

## Method Summary
The survey analyzes existing literature on low-power computer vision techniques for IoT devices, focusing on quantization, pruning, layer decomposition, architecture search, and compiler optimizations. It evaluates these techniques based on their impact on accuracy, energy consumption, memory requirements, and number of parameters and operations. The survey compares various DNN models including convolutional and transformer architectures using the ImageNet-2012 dataset as a reference.

## Key Results
- Quantization, pruning, and layer decomposition techniques can significantly reduce DNN complexity for IoT deployment
- Neural architecture search and compiler optimizations provide additional opportunities for efficiency gains
- New evaluation metrics are proposed to better assess the trade-offs between accuracy and efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Quantization reduces the number of memory operations by mapping 32-bit floating-point values to lower precision formats such as 16-bit floating point or 8-bit integer.
- Mechanism: Lower precision values require fewer bits to represent, reducing memory bandwidth and storage needs during DNN inference.
- Core assumption: The hardware supports low-precision arithmetic operations and the quantized model maintains sufficient accuracy.
- Evidence anchors:
  - [abstract] "These techniques either reduce the memory requirements, the number of arithmetic operations, or both."
  - [section II.A] "Quantization techniques are methods to map 32-bit floating point values to lower precision formats such as 16-bit floating point or 8-bit integer."
  - [corpus] Weak evidence; neighbor papers discuss low-power optimization but not quantization specifically.
- Break condition: If the hardware does not support low-precision arithmetic or if accuracy degradation is unacceptable.

### Mechanism 2
- Claim: Pruning removes redundant weights and biases from DNNs, reducing model size and computational requirements.
- Mechanism: By eliminating unimportant parameters, pruning decreases the number of operations and memory accesses needed for inference.
- Core assumption: DNNs are over-parameterized and can maintain accuracy with fewer weights.
- Evidence anchors:
  - [abstract] "These techniques either reduce the memory requirements, the number of arithmetic operations, or both."
  - [section II.B] "DNN Pruning is a technique that can reduce the size of DNNs by removing some of these redundant weights and biases."
  - [corpus] Weak evidence; neighbor papers do not discuss pruning.
- Break condition: If pruning removes too many important parameters, leading to significant accuracy loss.

### Mechanism 3
- Claim: Layer decomposition breaks down large weight matrices into smaller low-rank matrices, reducing memory requirements and operations.
- Mechanism: Decomposing tensors into low-rank components decreases the peak memory needed and the number of computations.
- Core assumption: Large matrices can be effectively decomposed without significant accuracy loss.
- Evidence anchors:
  - [abstract] "These techniques either reduce the memory requirements, the number of arithmetic operations, or both."
  - [section II.C] "Large matrices can be decomposed into smaller low-rank matrices. These low-rank matrices reduce the peak memory requirements of the DNN."
  - [corpus] Weak evidence; neighbor papers do not discuss layer decomposition.
- Break condition: If decomposition techniques result in unacceptable accuracy losses or if the computational savings do not outweigh the decomposition overhead.

## Foundational Learning

- Concept: Deep Neural Networks (DNNs) are composed of layers with billions of parameters, making them computationally expensive.
  - Why needed here: Understanding the structure and scale of DNNs is essential to grasp why optimizations are necessary for IoT deployment.
  - Quick check question: Why do DNNs require significant computational resources?

- Concept: IoT devices are characterized by low-cost hardware and limited battery lives, necessitating energy-efficient DNN implementations.
  - Why needed here: Recognizing the constraints of IoT devices explains the need for low-power techniques in the survey.
  - Quick check question: What are the typical constraints of IoT devices that impact DNN deployment?

- Concept: Quantization, pruning, and layer decomposition are key techniques to reduce DNN complexity.
  - Why needed here: These techniques directly address the challenges of deploying DNNs on resource-constrained devices.
  - Quick check question: What are the three main categories of techniques discussed for optimizing DNNs?

## Architecture Onboarding

- Component map: Neural Network Compression -> Architecture Search and Design -> Compiler and Graph Optimizations
- Critical path: The critical path for deploying DNNs on IoT devices involves applying techniques from each category to balance accuracy and efficiency
- Design tradeoffs: There is a tradeoff between model accuracy and computational efficiency; more aggressive optimizations may reduce accuracy
- Failure signatures: Common failure modes include significant accuracy loss, increased training complexity, and incompatibility with hardware
- First 3 experiments:
  1. Implement quantization on a pre-trained DNN and measure accuracy and energy consumption
  2. Apply pruning to reduce model size and evaluate the impact on performance and resource usage
  3. Experiment with layer decomposition techniques and analyze the balance between efficiency gains and accuracy losses

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the fundamental reasons why some tensor decomposition techniques (e.g., SVD) perform worse than others (e.g., Tucker-2, CPD) in terms of computer vision accuracy when applied to pre-trained DNNs?
- Basis in paper: [explicit] The paper mentions that SVD often leads to lower computer vision accuracy than Tucker-2 or CPD, but the reasons for this difference are not explored.
- Why unresolved: While the performance difference is observed, the underlying mathematical or empirical reasons for why certain decomposition techniques are more effective than others in maintaining accuracy are not explained in the surveyed literature.
- What evidence would resolve it: Comparative studies analyzing the properties of different decomposition techniques (e.g., their ability to capture relevant features, their sensitivity to noise, or their impact on gradient flow during fine-tuning) and their correlation with final accuracy would help understand the reasons behind the performance differences.

### Open Question 2
- Question: How can we develop neural architecture search (NAS) algorithms that can discover DNN architectures containing building blocks different from existing human-designed DNNs?
- Basis in paper: [explicit] The paper states that existing NAS solutions only try different combinations of well-known "architectural blocks" and breaking this dependency may allow us to build new architectures.
- Why unresolved: Current NAS algorithms are limited to searching within a predefined search space of existing architectural components. Exploring novel building blocks that are not human-designed is a significant challenge that requires new approaches to architecture representation and search.
- What evidence would resolve it: Development and evaluation of NAS algorithms that can generate and evaluate novel architectural components (e.g., new types of layers, connections, or operations) beyond the current search space would demonstrate progress in this area.

### Open Question 3
- Question: What are the optimal combinations of different low-power DNN optimization techniques (e.g., quantization, pruning, architecture search) that can achieve the best accuracy-efficiency trade-off for specific IoT devices and computer vision tasks?
- Basis in paper: [inferred] The paper mentions that more fine-grained control over the accuracy vs efficiency tradeoff may be possible by combining different types of techniques, but most combinations have not yet been explored exhaustively.
- Why unresolved: While individual techniques have been studied, the synergistic effects and optimal combinations of multiple techniques are not well understood. The effectiveness of combinations may vary depending on the specific hardware, task, and accuracy requirements.
- What evidence would resolve it: Systematic studies evaluating the performance of different combinations of techniques across a range of IoT devices, computer vision tasks, and accuracy-efficiency targets would help identify optimal combinations and provide guidelines for their application.

## Limitations
- Significant accuracy loss may occur when applying aggressive optimization techniques
- Hardware support for low-precision arithmetic operations is necessary for quantized DNNs
- Computational overhead of decomposition methods may offset efficiency gains

## Confidence
- High: The core claim that quantization, pruning, and layer decomposition can reduce DNN complexity is well-supported by the literature
- Medium: The effectiveness of these techniques in maintaining accuracy while reducing computational requirements may vary depending on the specific implementation and hardware constraints
- Low: The survey does not provide extensive empirical evidence or quantitative comparisons of the different optimization techniques

## Next Checks
1. Conduct a comprehensive empirical study comparing the effectiveness of various optimization techniques (quantization, pruning, layer decomposition) on a diverse set of DNN architectures and IoT hardware platforms
2. Investigate the impact of hardware support for low-precision arithmetic operations on the performance and accuracy of quantized DNNs in real-world IoT applications
3. Explore the potential of hybrid optimization approaches that combine multiple techniques (e.g., quantization + pruning + layer decomposition) to achieve better accuracy-efficiency tradeoffs