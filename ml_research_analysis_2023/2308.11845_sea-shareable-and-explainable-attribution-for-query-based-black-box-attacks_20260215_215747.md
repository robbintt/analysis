---
ver: rpa2
title: 'SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks'
arxiv_id: '2308.11845'
source_url: https://arxiv.org/abs/2308.11845
tags:
- attack
- attacks
- adversarial
- trace
- black-box
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: SEA introduces a forensic system for black-box ML attacks that
  analyzes query traces to attribute attacks to known sources. It models attack behavior
  as Hidden Markov Models to enable explainable, data-efficient attribution.
---

# SEA: Shareable and Explainable Attribution for Query-based Black-box Attacks

## Quick Facts
- **arXiv ID**: 2308.11845
- **Source URL**: https://arxiv.org/abs/2308.11845
- **Reference count**: 40
- **Primary result**: Achieves 90+% Top-1 and 95+% Top-3 accuracy in attributing black-box adversarial attacks using HMM-based modeling

## Executive Summary
SEA introduces a forensic system for attributing query-based black-box adversarial attacks on ML models. The system analyzes query traces to identify known attack sources, providing both attribution and per-query explanations of attack behavior. By modeling attacks as Hidden Markov Models and extracting attack traces through correlation-based clustering, SEA achieves high accuracy while enabling shareable attack fingerprints. The system discovers implementation bugs in attack libraries and maintains effectiveness even under adaptive evasion strategies.

## Method Summary
SEA models black-box attack behavior as Hidden Markov Models where internal procedures are hidden states and queries are observations. The system extracts attack traces from history queries using DBSCAN clustering based on correlation with the final adversarial example. It then attributes traces to known attacks using the forward algorithm to compute likelihood under each attack's HMM, and explains behavior through Viterbi decoding of the procedure sequence. Fingerprints are generated from transition matrices and shared between forensic systems, enabling data-efficient attribution without requiring access to attack model distributions.

## Key Results
- Achieves >90% Top-1 and >95% Top-3 accuracy in recognizing known attacks across multiple datasets and model architectures
- Maintains effectiveness against adaptive attacks using evasion strategies
- Discovers implementation bugs in attack libraries through explainable attribution process
- Provides per-query explanations that distinguish between noise procedures and pattern procedures

## Why This Works (Mechanism)

### Mechanism 1
HMMs model black-box attack behavior as stochastic processes where internal procedures are hidden states and queries are observations. The forward algorithm computes likelihood of observed traces under each attack's HMM. Core assumption: attack behavior follows Markovian properties where each query depends only on previous query and current internal procedure. Break condition: if attack behavior becomes non-Markovian or exhibits long-range dependencies.

### Mechanism 2
DBSCAN clustering with correlation threshold identifies attack trace from history queries. SEA clusters queries based on correlation with final adversarial example, treating correlated queries as attack trace. Core assumption: attack queries are more correlated with final adversarial example than random queries. Break condition: if adaptive attacks send uncorrelated dummy queries or if benign queries happen to be highly correlated.

### Mechanism 3
Fingerprint matching via cosine similarity enables sharing and attribution without model distribution. Each attack's fingerprint is its transition matrix, and new traces are attributed by matching fingerprint similarity to average fingerprint of each attack. Core assumption: transition matrices of same attack type are more similar than different attack types. Break condition: if different attacks converge to similar transition matrices or if same attack exhibits highly variable behavior.

## Foundational Learning

- **Concept**: Hidden Markov Models
  - Why needed here: Provides theoretical framework for modeling black-box attacks as stochastic processes with hidden internal procedures
  - Quick check question: What are the three key components of an HMM and how do they relate to black-box attack modeling?

- **Concept**: Spectral analysis of image transformations
  - Why needed here: Enables detection of patterns in per-query changes through power spectral density analysis
  - Quick check question: How does binarizing power spectral density help distinguish between noise procedures and pattern procedures?

- **Concept**: Template matching with Pearson correlation
  - Why needed here: Provides similarity metric for comparing per-query changes to procedure templates
  - Quick check question: Why use absolute value of Pearson correlation coefficient for template matching in this context?

## Architecture Onboarding

- **Component map**: Trace Extractor -> Attribution Engine -> Explanation Engine -> Fingerprint Database -> Attack Database -> Procedure Database
- **Critical path**: Trace extraction → HMM attribution → Fingerprint matching → Explanation generation
- **Design tradeoffs**: Storage vs performance (down-scaling images reduces storage cost but impacts accuracy), Precision vs recall (higher correlation threshold improves precision but may miss attack queries), Automation vs accuracy (semi-automated procedure discovery requires manual validation but ensures quality)
- **Failure signatures**: Low extraction precision (correlation threshold too low, benign queries being included), Poor attribution accuracy (insufficient fingerprints per attack or attack variants too similar), Incomplete trace extraction (adaptive attacks using dummy queries or transformations)
- **First 3 experiments**: 1) Test trace extraction with different correlation thresholds on HSJ attack to find optimal precision-recall tradeoff, 2) Compare attribution accuracy using single fingerprint vs multiple fingerprints for SignOPT attack, 3) Evaluate performance degradation when down-scaling ImageNet queries to 64x64 resolution

## Open Questions the Paper Calls Out

- **Open Question 1**: How can SEA be extended to handle multi-modal attacks that combine multiple adversarial techniques simultaneously?
- **Open Question 2**: What are the optimal thresholds and parameters for SEA's trace extraction algorithm across different threat models and deployment scenarios?
- **Open Question 3**: How does SEA perform when attackers target different stages of the ML pipeline beyond image classification?

## Limitations

- The HMM-based modeling assumes Markovian properties that may not hold for adaptive or state-dependent attacks
- Performance metrics are measured on controlled attacks from standard libraries rather than real-world scenarios
- The system assumes complete access to query history, which may not be available in all deployment scenarios
- Procedure database initialization requires domain expertise that may not transfer across different model architectures

## Confidence

- **High Confidence**: HMM-based attribution mechanism is theoretically sound and empirically validated
- **Medium Confidence**: Explainability features provide meaningful insights but depend on procedure database completeness
- **Low Confidence**: Data-efficient fingerprinting claims may not generalize to attacks with high behavioral variance

## Next Checks

1. **Robustness to Noise**: Test SEA's performance when attack queries are mixed with 10-20% random noise queries to evaluate trace extraction robustness
2. **Cross-Dataset Generalization**: Evaluate attribution accuracy when training on ImageNet queries but testing on CIFAR10 or CelebA to assess domain transfer capabilities
3. **Adaptive Attack Resilience**: Implement a white-box adaptive attacker that deliberately modifies query patterns to evade SEA's attribution mechanisms, measuring performance degradation