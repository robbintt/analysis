---
ver: rpa2
title: 'PharmacyGPT: The AI Pharmacist'
arxiv_id: '2307.10432'
source_url: https://arxiv.org/abs/2307.10432
tags:
- arxiv
- patient
- llms
- language
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PharmacyGPT applies large language models like ChatGPT and GPT-4
  to clinical pharmacy tasks using real ICU patient data from UNC Hospital. It introduces
  dynamic prompting with in-context learning and an iterative optimization algorithm
  for LLM adaptation without retraining.
---

# PharmacyGPT: The AI Pharmacist

## Quick Facts
- arXiv ID: 2307.10432
- Source URL: https://arxiv.org/abs/2307.10432
- Reference count: 40
- Primary result: GPT-4 with dynamic context achieved highest accuracy in ICU outcome prediction, though precision and recall were limited by data imbalance

## Executive Summary
PharmacyGPT applies large language models like ChatGPT and GPT-4 to clinical pharmacy tasks using real ICU patient data from UNC Hospital. The system introduces dynamic prompting with in-context learning and an iterative optimization algorithm for LLM adaptation without retraining. It clusters patients into interpretable groups aligned with ICD-10 codes, predicts outcomes like mortality and APACHE II scores, and generates medication plans. GPT-4 with dynamic context achieved the highest accuracy in outcome prediction, though precision and recall were limited by data imbalance. Expert pharmacists evaluated the AI-generated medication plans for clinical reasonableness. The work highlights LLM strengths and limitations in pharmacy, emphasizes the need for human oversight, and suggests future directions including multimodal models, better datasets, and specialized evaluation metrics.

## Method Summary
The system uses dynamic prompting with in-context learning to adapt LLMs to pharmacy tasks without fine-tuning. Patient data from UNC Hospital ICU (5000 patients) is processed through GPT-3 to generate embeddings, which are then clustered using hierarchical clustering to create interpretable groups aligned with ICD-10 codes. GPT-4 with dynamic context and similar sample selection is used for outcome prediction (mortality, APACHE II scores). An iterative optimization algorithm refines LLM outputs through automatic evaluation and prompt composition. Expert pharmacists evaluate the clinical reasonableness of AI-generated medication plans.

## Key Results
- GPT-4 with dynamic context achieved the highest accuracy in outcome prediction among tested models
- Patient clustering produced groups closely aligned with ICD-10 code categories and deemed interpretable by clinical experts
- Expert pharmacists evaluated AI-generated medication plans for clinical reasonableness, highlighting the need for human oversight

## Why This Works (Mechanism)

### Mechanism 1
Dynamic prompting with in-context learning improves LLM performance in specialized domains without fine-tuning. The system constructs dynamic contexts by selecting semantically similar examples from existing data and including them in the prompt. This allows the LLM to adapt to the pharmacy domain by learning from relevant contextual information.

### Mechanism 2
Iterative optimization algorithm refines LLM outputs through automatic evaluation and prompt composition. After each LLM output generation, the system evaluates the result against reference outputs, then modifies the input prompt based on the evaluation score. This creates a feedback loop that gradually improves the model's responses without retraining.

### Mechanism 3
Clustering patients using LLM embeddings creates interpretable groups that align with clinical categories. Patient information is transformed into high-dimensional embeddings using GPT-3, then hierarchical clustering is applied to group similar patients. The resulting clusters are interpretable because they align with ICD-10 code categories.

## Foundational Learning

- Concept: In-context learning
  - Why needed here: The system relies on providing relevant examples within prompts to adapt LLMs to pharmacy tasks without fine-tuning
  - Quick check question: What is the key difference between in-context learning and traditional fine-tuning, and why is this distinction important for the PharmacyGPT approach?

- Concept: Hierarchical clustering
  - Why needed here: Patient clustering is performed using hierarchical clustering on LLM-generated embeddings to create interpretable groups
  - Quick check question: How does hierarchical clustering differ from other clustering methods like k-means, and what advantages does it offer for creating interpretable patient groups?

- Concept: Evaluation metrics for imbalanced datasets
  - Why needed here: The study deals with imbalanced mortality prediction data (9:1 ratio of alive to deceased patients), requiring appropriate evaluation metrics beyond accuracy
  - Quick check question: Why might accuracy be misleading as an evaluation metric for imbalanced classification problems, and what alternative metrics would be more appropriate?

## Architecture Onboarding

- Component map: Data preprocessing -> Embedding generation (GPT-3) -> Dynamic prompt construction -> LLM inference (ChatGPT/GPT-4) -> Iterative optimization loop -> Clustering module -> Evaluation components
- Critical path: Data preprocessing → embedding generation → dynamic prompt construction → LLM inference → evaluation → prompt refinement
- Design tradeoffs: The system trades computational efficiency for flexibility by using LLMs without fine-tuning. This avoids the cost and complexity of model retraining but may limit performance compared to specialized models. The iterative optimization adds computational overhead but enables adaptation without additional training data.
- Failure signatures: Common failure modes include poor clustering quality (indicative of ineffective embeddings or clustering parameters), low evaluation scores in iterative optimization (suggesting evaluation function issues or ineffective prompt modifications), and inconsistent medication plan generation (pointing to prompt construction or LLM limitations).
- First 3 experiments:
  1. Validate embedding quality by checking if semantically similar patients produce similar embeddings and if clusters align with known clinical categories
  2. Test iterative optimization convergence by running with different evaluation thresholds and monitoring prompt refinement effectiveness
  3. Evaluate medication plan generation by comparing GPT-4 outputs with expert pharmacist assessments across diverse patient cases

## Open Questions the Paper Calls Out

### Open Question 1
How does dynamic prompting with in-context learning compare to fine-tuning for domain adaptation of large language models in clinical pharmacy? The paper states that dynamic prompting and iterative optimization were used instead of retraining or fine-tuning, and suggests future work could compare these approaches.

### Open Question 2
What evaluation metrics beyond n-gram similarity would better assess AI-generated medication plans for clinical safety and effectiveness? The paper states that "evaluation metrics extend beyond traditional n-gram-based metrics" and that expert pharmacists will "devise evaluation metrics" for this task.

### Open Question 3
How would multimodal foundation models improve medication planning compared to text-only large language models? The paper discusses the potential of multimodal models that can process text, images, and structured data for pharmacy applications.

## Limitations
- Data imbalance in mortality prediction (9:1 ratio of alive to deceased patients) constrained precision and recall metrics
- Specific implementation details of the iterative optimization algorithm remain underspecified
- Generalizability is limited by the single-institution dataset from UNC Hospital

## Confidence

- **High Confidence**: The core claim that LLMs can generate clinically reasonable medication plans and perform outcome prediction in pharmacy contexts is well-supported by expert pharmacist evaluations and comparative model performance data.
- **Medium Confidence**: The effectiveness of dynamic prompting with in-context learning is demonstrated, though the specific mechanisms and threshold values require further clarification.
- **Low Confidence**: The scalability and generalizability of the clustering approach across different healthcare systems and patient demographics remains unproven.

## Next Checks
1. Cross-Institutional Validation: Test the system on ICU datasets from multiple hospitals to assess generalizability and identify potential biases in the UNC Hospital data.
2. Data Augmentation Impact: Evaluate whether synthetic minority oversampling or other imbalance mitigation techniques improve mortality prediction precision and recall.
3. Human-AI Collaboration Assessment: Conduct controlled trials comparing pharmacist performance with and without PharmacyGPT assistance to quantify actual clinical impact and workflow integration benefits.