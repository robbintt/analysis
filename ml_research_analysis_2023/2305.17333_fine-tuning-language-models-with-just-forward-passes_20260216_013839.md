---
ver: rpa2
title: Fine-Tuning Language Models with Just Forward Passes
arxiv_id: '2305.17333'
source_url: https://arxiv.org/abs/2305.17333
tags:
- mezo
- gradient
- learning
- memory
- experiments
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces MeZO, a memory-efficient zeroth-order optimizer
  that adapts the classical ZO-SGD method to fine-tune large language models using
  only forward passes. The key innovation is an in-place implementation that reduces
  memory consumption to the same level as inference, enabling fine-tuning of models
  up to 30B parameters on a single A100 GPU, compared to 2.7B parameters with standard
  backpropagation.
---

# Fine-Tuning Language Models with Just Forward Passes

## Quick Facts
- arXiv ID: 2305.17333
- Source URL: https://arxiv.org/abs/2305.17333
- Authors: Anonymous
- Reference count: 40
- Primary result: Achieves comparable fine-tuning performance to backpropagation with up to 12× memory reduction using only forward passes

## Executive Summary
This paper introduces MeZO, a memory-efficient zeroth-order optimizer that enables fine-tuning large language models using only forward passes. The key innovation is an in-place implementation that reduces memory consumption to the same level as inference, making it possible to fine-tune models up to 30B parameters on a single A100 GPU. MeZO achieves comparable performance to backpropagation-based fine-tuning on 7 out of 11 tasks tested, while also being compatible with parameter-efficient techniques and capable of optimizing non-differentiable objectives like accuracy and F1 score.

## Method Summary
MeZO adapts the classical ZO-SGD method using Simultaneous Perturbation Stochastic Approximation (SPSA) to estimate gradients from just two forward passes per optimization step. The in-place implementation regenerates perturbation vectors on-demand using random number generator seeds, avoiding the need to store full perturbation vectors in memory. This allows MeZO to have a memory footprint equivalent to inference while achieving convergence rates that depend on the local effective rank of the loss landscape rather than the number of parameters, explaining its effectiveness on large models.

## Key Results
- Achieves comparable performance to backpropagation on 7/11 tasks tested
- Reduces memory usage by up to 12× compared to standard fine-tuning
- Cuts GPU-hours by up to 2× while maintaining similar task performance
- Successfully optimizes non-differentiable objectives like accuracy and F1 score
- Scales to 30B parameter models on single GPU, compared to 2.7B with backpropagation

## Why This Works (Mechanism)

### Mechanism 1
- Memory-efficient zeroth-order optimization can achieve comparable performance to backpropagation despite using only forward passes
- Uses SPSA to estimate gradients from two forward passes with in-place implementation ensuring memory footprint matches inference
- Depends on pre-trained models having favorable loss landscapes where optimization speed depends on local effective rank rather than parameter count

### Mechanism 2
- In-place perturbation strategy reduces memory overhead from 2× to effectively 1× compared to naive ZO methods
- Reuses random number generator seeds to regenerate perturbation vector entries on-demand during four perturbation steps
- Requires perturbation vector z to be deterministically regenerable without affecting gradient estimate statistical properties

### Mechanism 3
- Can optimize non-differentiable objectives like accuracy and F1 score effectively
- Zeroth-order approach estimates gradients from loss differences, working regardless of differentiability
- Requires discrete objective to be sufficiently smooth when evaluated on mini-batches

## Foundational Learning

- **Zeroth-order optimization and SPSA gradient estimation**: Core mathematical foundation for gradient estimation without backpropagation. *Quick check: How does SPSA estimate gradients using only two function evaluations, and what is the role of the perturbation vector z?*

- **Local effective rank and Hessian structure**: Explains why large models can be optimized efficiently despite theoretical lower bounds. *Quick check: What is the relationship between the local effective rank of the Hessian and the convergence rate of zeroth-order methods?*

- **Memory-efficient in-place computation patterns**: Critical for achieving claimed memory reduction. *Quick check: How does the in-place perturbation strategy avoid storing the full perturbation vector while maintaining statistical properties?*

## Architecture Onboarding

- **Component map**: Forward pass engine -> Perturbation generator -> Loss calculator -> Parameter updater -> Memory manager

- **Critical path**: 
  1. Sample batch and seed
  2. Perturb parameters (forward pass)
  3. Calculate loss (forward pass)
  4. Reset and re-perturb (forward pass)
  5. Calculate second loss (forward pass)
  6. Compute gradient estimate
  7. Update parameters
  8. Repeat

- **Design tradeoffs**: 
  - Memory vs compute: In-place implementation saves memory but requires recomputation of random numbers
  - Step count vs memory: More steps needed than backpropagation but with much lower memory per step
  - Parameter count vs speed: Tuning fewer parameters doesn't significantly accelerate convergence

- **Failure signatures**:
  - Memory usage still high: Check if perturbation vectors are being stored instead of regenerated
  - Poor convergence: Verify perturbation scale is appropriate and loss landscape has low effective rank
  - Unstable training: Check if batch size is too small for reliable gradient estimates

- **First 3 experiments**:
  1. Memory profiling: Compare peak GPU memory usage of MeZO vs backpropagation on same model/task
  2. Convergence comparison: Run both methods for fixed compute budget and compare final performance
  3. Non-differentiable objective test: Try optimizing accuracy/F1 on classification task and compare to cross-entropy baseline

## Open Questions the Paper Calls Out

### Open Question 1
- How does MeZO performance scale with model size beyond 66B parameters?
- The paper projects results for 175B parameter models without actual testing
- Empirical results on models larger than 66B parameters would resolve this

### Open Question 2
- Impact of combining MeZO with other memory-efficient techniques like FlashAttention and quantization
- Paper mentions these methods but states "We leave investigating how MeZO works with these methods to future work"
- Experiments comparing MeZO alone versus MeZO combined with other memory-saving methods would resolve this

### Open Question 3
- Performance on non-differentiable objectives beyond accuracy and F1 score
- Paper shows preliminary experiments but states "Although minimizing cross entropy results in stronger performance, these preliminary findings highlight the promising potential..."
- Comprehensive experiments optimizing various non-differentiable objectives would resolve this

### Open Question 4
- Optimal schedule for the number of noise samples (n) in n-SPSA during training
- Paper mentions n=1 is most efficient in cursory experiments but doesn't provide systematic analysis
- Systematic experiments comparing different n-schedules would resolve this

## Limitations

- Effectiveness critically depends on pre-trained model's loss landscape having low effective rank, which is assumed but not universally verified
- Theoretical analysis relies on idealized assumptions about gradient smoothness and bounded Hessians that may not hold in practice
- In-place implementation's performance claims assume random perturbation regeneration doesn't introduce statistical bias

## Confidence

**High Confidence**: Memory efficiency claims (12× reduction) and compatibility with parameter-efficient tuning methods
**Medium Confidence**: Performance claims of achieving "comparable" results to backpropagation on 7/11 tasks
**Low Confidence**: Claims about effectively optimizing non-differentiable objectives based on limited experimental evidence

## Next Checks

1. **Landscape Analysis Validation**: Systematically measure the local effective rank of the loss landscape across different model scales and tasks

2. **Perturbation Bias Test**: Design experiments to detect potential statistical bias introduced by the in-place perturbation regeneration strategy

3. **Non-differentiable Objective Robustness**: Test MeZO's performance on a wider range of non-differentiable objectives with varying degrees of discontinuity