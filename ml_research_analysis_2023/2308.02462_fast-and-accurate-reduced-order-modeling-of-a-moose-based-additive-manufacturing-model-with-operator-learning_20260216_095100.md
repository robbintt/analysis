---
ver: rpa2
title: Fast and Accurate Reduced-Order Modeling of a MOOSE-based Additive Manufacturing
  Model with Operator Learning
arxiv_id: '2308.02462'
source_url: https://arxiv.org/abs/2308.02462
tags:
- deeponet
- roms
- qois
- time
- bead
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work addresses the computational challenge of simulating\
  \ time-dependent thermal and mechanical behaviors in additive manufacturing (AM)\
  \ processes by developing fast, accurate reduced-order models (ROMs). The study\
  \ employs operator learning (OL) techniques\u2014specifically Fourier Neural Operator\
  \ (FNO) and Deep Operator Network (DeepONet)\u2014to learn mappings from input parameters\
  \ (e.g., laser power, scanning speed, radius, efficiency, and scaling factor) to\
  \ output quantities of interest (QoIs) such as maximum bead volume and melt pool\
  \ temperature."
---

# Fast and Accurate Reduced-Order Modeling of a MOOSE-based Additive Manufacturing Model with Operator Learning

## Quick Facts
- arXiv ID: 2308.02462
- Source URL: https://arxiv.org/abs/2308.02462
- Reference count: 34
- Primary result: Operator learning methods (FNO, DeepONet) outperform DNNs in accuracy and generalizability for time-dependent thermal QoIs in AM processes

## Executive Summary
This work addresses the computational challenge of simulating time-dependent thermal and mechanical behaviors in additive manufacturing (AM) processes by developing fast, accurate reduced-order models (ROMs). The study employs operator learning (OL) techniques—specifically Fourier Neural Operator (FNO) and Deep Operator Network (DeepONet)—to learn mappings from input parameters (e.g., laser power, scanning speed, radius, efficiency, and scaling factor) to output quantities of interest (QoIs) such as maximum bead volume and melt pool temperature. Unlike conventional deep neural networks (DNNs), these OL methods can handle time-dependent QoIs without dimensionality reduction. Results show that OL methods outperform DNNs in accuracy and generalizability, with FNO achieving smaller mean prediction errors and DeepONet offering faster training times. All ROMs were significantly faster than the original high-fidelity MOOSE model while maintaining high accuracy, making them suitable for multi-query tasks in AM process control and optimization.

## Method Summary
The method involves generating 500 Latin hypercube samples of five process parameters (laser power, scanning speed, laser effective radius, laser efficiency coefficient, scaling factor) and running a MOOSE-based AM model to collect time-dependent bead volume and melt pool temperature data for 200 time steps per sample. After removing 18 non-melting samples, the data is standardized and split into 80% training, 10% validation, and 10% test sets. Fourier Neural Operator (FNO) and Deep Operator Network (DeepONet) architectures are implemented with modifications for time-dependent outputs, trained on the training set, and evaluated on the test set using RMSE and R² metrics.

## Key Results
- FNO and DeepONet achieved RMSE values 50-250% lower than DNN for scalar QoIs
- FNO generally had smaller mean prediction errors while DeepONet trained faster
- ROMs reduced computational time from 17.3 days to seconds for 1000 parameter samples
- All OL-based ROMs maintained high accuracy while enabling rapid global sensitivity analysis

## Why This Works (Mechanism)

### Mechanism 1
- FNO and DeepONet learn mappings between infinite-dimensional function spaces rather than individual PDE solutions, enabling generalization across varying process parameters without retraining
- Both methods treat laser heat source parameters as continuous inputs and directly learn the operator mapping to solution functions
- Core assumption: Input-output relationship for thermal PDEs is sufficiently smooth and low-rank in function space
- Evidence: OL methods outperformed DNN in accuracy and generalizability for scalar model responses

### Mechanism 2
- OL methods predict time-dependent QoIs without dimensionality reduction by treating time as part of input space
- Modified FNO and DeepONet accept time as input through repeated parameter vectors or explicit time vectors in trunk net
- Core assumption: Temporal evolution is governed by the same operator learned from input parameters
- Evidence: Both methods simulated time series data without dimensionality reduction techniques required by DNN

### Mechanism 3
- Fast ROMs enable global sensitivity analysis by reducing computational cost from days to seconds
- Trained OL-based ROMs approximate MOOSE model with RMSE errors of 10^-3 to 10^-2
- Core assumption: ROM error is small enough that sensitivity indices from ROM closely approximate full model
- Evidence: Using ROMs reduced runtime from 17.3 days to seconds for 1000 samples in sensitivity analysis

## Foundational Learning

- Concept: Operator learning as generalization of function approximation
  - Why needed: Conventional DNNs learn from finite datasets tied to specific PDE instances; OL methods learn mappings between infinite-dimensional function spaces, crucial for handling varying laser parameters without retraining
  - Quick check: What is the key difference between learning a solution instance vs. learning an operator in the context of PDEs?

- Concept: Fourier integral kernels and spectral methods
  - Why needed: FNO uses Fourier transforms in integral kernel to efficiently capture global spatial dependencies and periodic boundary conditions in thermal problem
  - Quick check: How does Fourier basis help in approximating integral operator kernel for PDEs?

- Concept: Two-network architecture in DeepONet
  - Why needed: DeepONet encodes input function into branch net and evaluation points into trunk net; their dot product yields operator output, enabling flexible handling of spatially/temporally varying outputs
  - Quick check: Why does DeepONet use two separate networks (branch and trunk) instead of single network?

## Architecture Onboarding

- Component map: Latin hypercube sampling -> MOOSE simulations -> QoI extraction -> Standardization -> Train/val/test split -> FNO/DeepONet training -> RMSE/R² evaluation -> Sensitivity analysis
- Critical path: 1) Generate 500 parameter samples and run MOOSE model 2) Preprocess data and split sets 3) Train OL models with hyperparameter tuning 4) Validate and test accuracy 5) Deploy ROM for rapid QoI prediction and SA
- Design tradeoffs: FNO vs DeepONet (lower mean RMSE vs faster training), model complexity vs generalization (risk of overfitting), training data size vs accuracy (computational cost)
- Failure signatures: High RMSE or large relative error outliers, oscillatory FNO predictions from insufficient Fourier modes, large Sobol index discrepancies between ROM and full model
- First 3 experiments: 1) Train minimal FNO (2 Fourier layers, 5 modes) on small subset to check overfitting 2) Vary Fourier modes from 1-20 and plot RMSE vs modes 3) Compare training/validation losses for FNO and DeepONet on same data split

## Open Questions the Paper Calls Out
1. How do FNO and DeepONet models perform when trained on time-dependent input parameters rather than constant ones?
2. What is the impact of increasing the number of time steps on accuracy and computational efficiency of FNO and DeepONet models?
3. How do FNO and DeepONet models perform when applied to other types of AM processes or materials beyond DED?

## Limitations
- Assumes thermal behavior can be well-approximated by smooth operators in function space, which may break down for extreme parameter combinations
- ROM error bounds for sensitivity analysis are not quantified - small errors could compound across thousands of samples
- Training dataset (500 samples) may not fully capture parameter space, potentially limiting generalizability

## Confidence
- High confidence: Relative performance comparison between OL methods and DNNs (FNO and DeepONet outperforming DNN)
- Medium confidence: Absolute accuracy claims (RMSE values and R² scores) due to limited transparency in hyperparameters and validation procedures
- Medium confidence: Runtime speedup claims, dependent on specific hardware and implementation details not fully disclosed

## Next Checks
1. Quantify how ROM errors propagate through global sensitivity analysis by comparing Sobol indices from ROM predictions vs. a smaller set of full MOOSE simulations
2. Test ROM predictions on parameter combinations outside training domain (e.g., extreme laser powers) to assess extrapolation capability
3. Perform k-fold cross-validation (k=5 or 10) instead of single train/val/test split to ensure results aren't dependent on specific data partitioning