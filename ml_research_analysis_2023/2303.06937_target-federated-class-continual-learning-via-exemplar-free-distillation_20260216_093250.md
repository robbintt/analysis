---
ver: rpa2
title: 'TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation'
arxiv_id: '2303.06937'
source_url: https://arxiv.org/abs/2303.06937
tags:
- data
- tasks
- learning
- forgetting
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes TARGET, a novel method for federated class-continual
  learning (FCCL) that addresses catastrophic forgetting without requiring additional
  datasets or storing private data. TARGET leverages global information at both the
  model and data levels.
---

# TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation

## Quick Facts
- arXiv ID: 2303.06937
- Source URL: https://arxiv.org/abs/2303.06937
- Reference count: 40
- Key outcome: Achieves 36.31% accuracy on CIFAR-100, outperforming baselines by ~6%

## Executive Summary
TARGET addresses catastrophic forgetting in federated class-continual learning without requiring stored exemplars or additional datasets. It uses a dual-level approach: knowledge distillation from a global model to transfer knowledge of old tasks, and synthetic data generation to simulate the global data distribution. Experiments on CIFAR-100 and Tiny-ImageNet show significant improvements over existing methods, achieving 36.31% accuracy on CIFAR-100 compared to 30.43% for the best baseline. The method effectively balances preserving privacy with maintaining performance across sequential learning tasks.

## Method Summary
TARGET operates in a federated learning setting where new classes are dynamically added across tasks. The server trains a global model and uses it to generate synthetic data that simulates the global data distribution. Knowledge distillation transfers knowledge from the previously trained global model to the current task. Clients train on their real data for the current task combined with synthetic data from previous tasks, updating the global model without storing any private data. The method specifically addresses non-IID data distributions where label skew exacerbates catastrophic forgetting.

## Key Results
- Achieves 36.31% accuracy on CIFAR-100, ~6% higher than best baseline
- Synthetic data (2k samples) achieves performance comparable to storing 1k real training data
- Effectively mitigates catastrophic forgetting while preserving data privacy in federated settings

## Why This Works (Mechanism)

### Mechanism 1
Non-IID data distribution among clients exacerbates catastrophic forgetting in federated class-continual learning. Skewed label distributions cause clients to have limited exposure to previous classes, making it harder to maintain performance on old tasks when new tasks arrive. Core assumption: The degree of data heterogeneity correlates with the severity of forgetting. Evidence: Figure 1 illustrates the impact of catastrophic forgetting under IID and different levels of non-IID data partitions. Break condition: If data becomes IID or if clients receive balanced class distributions across tasks.

### Mechanism 2
Knowledge distillation from the previously trained global model transfers knowledge of old tasks to the current task at the model level. The global model trained on previous tasks acts as a teacher, providing soft targets that regularize the current model to maintain old task performance while learning new classes. Core assumption: The global model captures representative knowledge of all previously seen classes that can be transferred. Evidence: Inspired by LwF, knowledge is leveraged from the previously trained global model to the current task via Knowledge Distillation (KD). Break condition: If the global model's knowledge becomes stale or if catastrophic forgetting occurs before distillation can occur.

### Mechanism 3
Synthetic data generation simulates the global distribution of data on each client, providing exemplar-free rehearsal data for previous tasks. A generator creates synthetic samples that mimic the distribution of previously seen classes by optimizing against the global model's predictions and batch normalization statistics. Core assumption: Synthetic data generated from the global model distribution can effectively represent previous task data without accessing real private data. Evidence: A generator is trained to produce synthetic data to simulate the global distribution of data on each client at the data level. Break condition: If the generator fails to capture the true data distribution or if synthetic data quality degrades over tasks.

## Foundational Learning

- Concept: Knowledge Distillation
  - Why needed here: Transfers knowledge from the global teacher model to local student models to prevent forgetting of old tasks
  - Quick check question: How does knowledge distillation help maintain performance on previous classes when training on new classes?

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: The generator creates synthetic data that mimics the global data distribution without requiring stored exemplars
  - Quick check question: What losses ensure the generator creates realistic samples that the global model can classify correctly?

- Concept: Federated Learning
  - Why needed here: The method operates in a distributed setting where clients cannot share raw data but can collaborate through model updates
  - Quick check question: How does the server aggregate client updates while maintaining data privacy?

## Architecture Onboarding

- Component map:
  Server (Global model, Generator, Student model, Synthetic data buffer) <- Updates from -> Clients (Local model, Real data for current task, Received synthetic data)

- Critical path:
  1. Server receives client updates for current task
  2. Server generates synthetic data using global model
  3. Server sends synthetic data to clients
  4. Clients train on real + synthetic data with knowledge distillation
  5. Clients send updated models to server

- Design tradeoffs:
  - Synthetic data size vs. memory/communication cost
  - Generator training iterations vs. server computation load
  - Knowledge distillation weight (α) vs. balancing old/new task performance

- Failure signatures:
  - Synthetic data looks unrealistic or produces poor classification
  - Performance degrades significantly on old tasks despite distillation
  - Communication bottlenecks due to large synthetic data transfers

- First 3 experiments:
  1. Run with only knowledge distillation (no synthetic data) to establish baseline
  2. Generate synthetic data and measure quality by classification accuracy on synthetic samples
  3. Compare performance with different synthetic data sizes (2k, 4k, 8k samples)

## Open Questions the Paper Calls Out

### Open Question 1
How can the effectiveness of synthetic data be improved to match or surpass that of real data in federated class-incremental learning? Basis: The paper acknowledges that synthetic data generated by TARGET achieves similar performance to storing 1k real training data by storing 2k synthetic data, but still cannot outperform storing 2k real training data. Why unresolved: The paper identifies this as a challenge but does not provide a solution for effectively using fewer synthetic data with more valuable knowledge from previous tasks. What evidence would resolve it: Experimental results showing that synthetic data can achieve equal or better performance than real data when using the same amount of data.

### Open Question 2
What is the optimal balance between backward and forward transfer in federated class-incremental learning, and how can it be achieved? Basis: The paper discusses the trade-off between maintaining high accuracy on old tasks (backwards transfer) and achieving high accuracy on new tasks (forward transfer), and shows that different values of α can affect this balance. Why unresolved: The paper demonstrates the trade-off but does not provide a definitive method for determining the optimal balance for different scenarios. What evidence would resolve it: A systematic study showing how different α values affect performance across various datasets and task configurations.

### Open Question 3
How can the computational cost of generating synthetic data be reduced while maintaining its effectiveness in federated class-incremental learning? Basis: The paper mentions that generating excessive synthetic data can lead to increased memory and communication costs, and that determining an appropriate amount of synthetic data is critical for effectiveness and efficiency. Why unresolved: The paper acknowledges the trade-off between data volume and performance but does not provide a method for optimizing this trade-off. What evidence would resolve it: An analysis showing the relationship between synthetic data volume, computational cost, and model performance.

## Limitations
- Method's performance on larger, more diverse datasets beyond CIFAR-100 and Tiny-ImageNet has not been demonstrated
- Computational overhead of server-side synthetic data generation could limit scalability
- Specific Glow-based generator architecture details and hyperparameter settings remain unclear

## Confidence
- High confidence in the core mechanism of using knowledge distillation to prevent forgetting
- Medium confidence in the effectiveness of synthetic data generation for maintaining previous task knowledge
- Low confidence in the scalability and performance on larger, more complex datasets

## Next Checks
1. Implement a detailed evaluation of the synthetic data quality by computing KL divergence between teacher and student model outputs on both real and synthetic data across multiple tasks.

2. Measure the actual communication costs (bandwidth and latency) when transmitting synthetic data versus model parameters alone, comparing with traditional federated learning approaches.

3. Test TARGET on larger datasets (e.g., ImageNet-1K) with increased client numbers and task sequences to evaluate performance degradation and computational feasibility.