---
ver: rpa2
title: Diagnosing Alzheimer's Disease using Early-Late Multimodal Data Fusion with
  Jacobian Maps
arxiv_id: '2310.16936'
source_url: https://arxiv.org/abs/2310.16936
tags:
- data
- fusion
- brain
- images
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors proposed an Early-Late Fusion (ELF) framework for multi-stage
  classification of Alzheimer's Disease using multimodal MRI and CT data. To tackle
  missing modalities and small dataset issues, they introduced a preprocessing pipeline
  including bias correction, brain extraction, multi-stage registration with per-subject
  adaptation, and Jacobian map transformation.
---

# Diagnosing Alzheimer's Disease using Early-Late Multimodal Data Fusion with Jacobian Maps

## Quick Facts
- arXiv ID: 2310.16936
- Source URL: https://arxiv.org/abs/2310.16936
- Reference count: 30
- Four-stage AD classification accuracy: 97.19%

## Executive Summary
This paper introduces an Early-Late Fusion (ELF) framework for multi-stage classification of Alzheimer's Disease using multimodal MRI and CT data. The approach addresses missing modalities and small dataset challenges through a comprehensive preprocessing pipeline that includes bias correction, brain extraction, multi-stage registration with per-subject adaptation, and Jacobian map transformation. By combining early-fused Jacobian features with modality-specific Random Forest models and hot-deck imputation for missing data, the method achieves state-of-the-art performance in classifying AD into four stages (normal, MCI, mild AD, severe AD) on the OASIS-3 dataset.

## Method Summary
The proposed ELF framework processes multimodal MRI and CT data through a preprocessing pipeline that includes bias correction, brain extraction, multi-stage registration with per-subject adaptation, and Jacobian domain transformation. The framework combines a lightweight 3D CNN operating on early-fused Jacobian features with Random Forest models for individual modalities, using hot-deck imputation based on kurtosis and skewness to handle missing data. The final prediction averages probability outputs from the CNN and RF models, achieving robust classification across the four AD stages.

## Key Results
- Achieved 97.19% accuracy in four-stage AD classification (normal, MCI, mild AD, severe AD)
- Outperformed prior approaches on the OASIS-3 dataset
- Successfully handled missing modalities through hot-deck imputation based on kurtosis and skewness

## Why This Works (Mechanism)

### Mechanism 1
Jacobian domain transformation amplifies subtle brain volume changes by encoding local deformation information at the voxel level. The preprocessing pipeline applies DIR to align MRI images to MNI152, then computes the Jacobian determinant for each voxel. The Jacobian value |J(x)| < 1 indicates volume compression, > 1 indicates expansion, and = 1 indicates no change. This scalar field captures local morphometric variations that are otherwise imperceptible in raw intensity images. Core assumption: Local volume changes are meaningful biomarkers for AD progression across multiple stages.

### Mechanism 2
Early-late fusion balances feature-level complementarity with modality-specific modeling, avoiding redundancy while handling missing data. Jacobian maps from all available modalities are depth-wise concatenated (early fusion) and fed into a lightweight 3D CNN. Simultaneously, each modality passes through its own ResNet + RF branch (late fusion). The final prediction is an average of the three models' probability outputs. This architecture allows the CNN to learn joint cross-modal features while RF models preserve modality-specific discriminative patterns. Core assumption: Early fusion captures cross-modal interactions without losing modality-specific discriminative cues that RF models can exploit.

### Mechanism 3
Hot-deck imputation based on kurtosis and skewness preserves distributional characteristics of missing modalities. For a subject missing a modality, the algorithm finds a donor subject with the same AD class label and the most similar kurtosis/skewness in the available modality. The donor's missing modality values replace the target's missing values. This preserves both class-conditional distributions and individual subject similarity. Core assumption: Subjects with similar statistical shape descriptors (kurtosis/skewness) in one modality are likely to have similar distributions in another modality, conditional on disease stage.

## Foundational Learning

- Concept: Jacobian determinant computation and interpretation
  - Why needed here: The Jacobian map is the core transformed feature space; understanding its geometric meaning is essential to diagnose why volume-based biomarkers may or may not be effective.
  - Quick check question: What does a Jacobian value of 0.8 signify about local brain volume relative to the template?

- Concept: Multimodal fusion strategies (early, late, joint)
  - Why needed here: The ELF framework explicitly leverages both early and late fusion; engineers must understand trade-offs to tune architecture and diagnose fusion-related failures.
  - Quick check question: How does early fusion differ from late fusion in terms of data dependency and missing modality handling?

- Concept: Hot-deck imputation mechanics and assumptions
  - Why needed here: HDI is a non-parametric imputation method used here; engineers must grasp its assumptions to assess when it may fail.
  - Quick check question: Why is matching both class label and statistical descriptors (kurtosis/skewness) important in this HDI scheme?

## Architecture Onboarding

- Component map: Preprocessing (Bias correction -> BET -> Multi-stage registration -> Jacobian computation) -> Early fusion (depth-wise concat) -> 3D CNN (conv layers + BN + dropout -> FC + softmax) -> RF branches (ResNet + RF per modality) -> HDI (kurtosis/skewness matching) -> Ensemble prediction (probability averaging)

- Critical path: Registration → Jacobian → Early fusion → CNN → RF branches → HDI → Ensemble prediction

- Design tradeoffs:
  - Lightweight CNN vs deeper architecture: balances small dataset constraints vs expressive power
  - ResNet pretraining vs training from scratch: avoids overfitting but may limit modality-specific adaptation
  - HDI vs mean/mode imputation: preserves distributional properties but relies on sufficient donor availability

- Failure signatures:
  - Registration errors → Jacobian maps dominated by noise → CNN confusion across classes
  - Poor early fusion → CNN underperforms RF branches → Ensemble degrades
  - HDI donor scarcity → Imputed modalities inconsistent → RF overfitting

- First 3 experiments:
  1. Train CNN only on early-fused Jacobian maps (no RF, no HDI) → assess cross-modal learning baseline
  2. Train RF per modality with HDI on missing data → assess modality-specific contribution
  3. Full ELF ensemble → compare against step 1 and 2 to quantify fusion gain

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed Early-Late Fusion (ELF) approach perform when extended to more heterogeneous modalities beyond MRI and CT, such as EEG and MEG data? The authors mention that the ELF framework can be easily extended to more heterogeneous modalities like EEG and MEG, but do not provide experimental results for these extensions.

### Open Question 2
What is the impact of using different deep feature extractors (e.g., other than ResNet) in the ELF framework for handling single-modal data? The authors use a pretrained ResNet as a deep feature extractor for single-modal data before applying Random Forest models, but do not explore the impact of using other feature extractors.

### Open Question 3
How does the ELF approach handle the trade-off between model complexity and interpretability, especially when dealing with multiple modalities? The authors propose a combination of deep learning models (CNN) and shallow models (Random Forest) in the ELF framework, but do not discuss the interpretability of the model or the trade-offs involved.

## Limitations
- The OASIS-3 dataset, while large for AD studies, still presents challenges with multimodal data availability and class imbalance across the four-stage classification
- The hot-deck imputation strategy assumes that subjects with similar statistical distributions in available modalities will have similar missing modality values
- The lightweight 3D CNN architecture may not capture complex nonlinear relationships that deeper architectures could potentially learn

## Confidence

**High Confidence**: The Jacobian domain transformation mechanism is well-established in neuroimaging literature, and the mathematical foundation is sound. The preprocessing pipeline with registration and bias correction is standard practice.

**Medium Confidence**: The early-late fusion architecture shows promise, but the specific contribution of each component (early vs late fusion, CNN vs RF models) to the final performance is not clearly isolated through ablation studies.

**Low Confidence**: The hot-deck imputation approach, while innovative for this application, lacks extensive validation. The assumption that kurtosis and skewness matching ensures modality similarity may not hold across all subjects.

## Next Checks

1. **Ablation Study**: Systematically disable each component (early fusion, late fusion branches, HDI) to quantify individual contributions to the 97.19% accuracy.

2. **Registration Quality Validation**: Perform visual and quantitative assessment of Jacobian map quality across subjects to verify that local volume changes are being captured accurately rather than registration artifacts.

3. **Donor Pool Sufficiency Analysis**: Evaluate the distribution of available donors for HDI across different classes and missing patterns to ensure statistical matching is reliable and not based on coincidental matches.