---
ver: rpa2
title: 'InstanT: Semi-supervised Learning with Instance-dependent Thresholds'
arxiv_id: '2310.18910'
source_url: https://arxiv.org/abs/2310.18910
tags:
- learning
- label
- instant
- will
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces InstanT, a semi-supervised learning method
  that assigns instance-dependent thresholds for pseudo-label selection. Unlike existing
  approaches using uniform or class-dependent thresholds, InstanT estimates a unique
  threshold for each unlabeled instance based on its instance-level ambiguity and
  instance-dependent error rates of pseudo-labels.
---

# InstanT: Semi-supervised Learning with Instance-dependent Thresholds

## Quick Facts
- arXiv ID: 2310.18910
- Source URL: https://arxiv.org/abs/2310.18910
- Reference count: 40
- Key outcome: InstanT achieves state-of-the-art performance across multiple benchmark datasets, especially in scenarios with extremely limited labeled data

## Executive Summary
InstanT introduces a novel approach to semi-supervised learning that assigns instance-dependent thresholds for pseudo-label selection. Unlike existing methods that use uniform or class-dependent thresholds, InstanT estimates a unique threshold for each unlabeled instance based on its instance-level ambiguity and instance-dependent error rates of pseudo-labels. This approach reduces the inclusion of mislabeled instances by adjusting the confidence cutoff based on the estimated noise level of each instance.

The method provides a bounded probabilistic guarantee for the correctness of assigned pseudo-labels, with the probability lower-bound increasing asymptotically as training progresses. Experimental results demonstrate significant improvements over existing state-of-the-art methods across multiple benchmark datasets, particularly in scenarios with extremely limited labeled data.

## Method Summary
InstanT is a semi-supervised learning method that improves pseudo-label selection by using instance-dependent thresholds. The method estimates instance-level ambiguity and instance-dependent error rates to compute a unique threshold for each unlabeled instance. It employs transition matrix estimation to model label noise, distribution alignment to prevent class imbalance issues, and loss correction to recover clean class posteriors. The method is tested on CIFAR-10, CIFAR-100, and STL-10 datasets with varying numbers of labeled samples per class.

## Key Results
- InstanT achieves state-of-the-art performance across multiple benchmark datasets
- The method shows significant improvements especially in scenarios with extremely limited labeled data (1-4 labels per class)
- Instance-dependent thresholds provide a bounded probabilistic guarantee for pseudo-label correctness that increases as training progresses

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Instance-dependent thresholds reduce inclusion of mislabeled instances by adjusting the confidence cutoff based on the estimated noise level of each instance.
- Mechanism: For each unlabeled instance, InstanT estimates a transition matrix that models how likely the true label is to be transformed into the predicted pseudo-label. The threshold for including an instance is set higher when the instance is more likely to be mislabeled, using the formula from Theorem 1.
- Core assumption: The transition matrix T(x) can be accurately estimated from labeled data, and the clean class posterior can be recovered via importance reweighting or loss correction.
- Evidence anchors:
  - [abstract] "devise a novel instance-dependent threshold function for all unlabeled instances by utilizing their instance-level ambiguity and the instance-dependent error rates of pseudo-labels"
  - [section] "We want to quantify and reduce such error by estimating an instance-dependent confidence threshold function based on the potential label noise level and instance ambiguity"
  - [corpus] Weak evidence - no corpus papers directly discuss instance-dependent threshold estimation.
- Break condition: If the transition matrix cannot be accurately estimated (e.g., with extremely limited labeled data), the thresholds become unreliable and the method degrades to uniform thresholding.

### Mechanism 2
- Claim: The probabilistic guarantee from Theorem 1 ensures that instances passing the threshold have a bounded probability of being correctly labeled, which increases as training progresses.
- Mechanism: Theorem 1 shows that P(k = h*(xu), ˆP( ˆY = k|X = xu) ≥ τ(xu)) > 1 - C[O(ϵθ)]^α, where ϵθ is the estimation error between noisy class posteriors. As the model improves, ϵθ decreases, increasing the lower bound probability.
- Core assumption: The estimated noisy class posterior satisfies the Tsybakov Margin Condition and the estimation error is bounded by δ0 min_i Ti,i(xu).
- Evidence anchors:
  - [abstract] "we demonstrate that our instance-dependent threshold function provides a bounded probabilistic guarantee for the correctness of the pseudo-labels it assigns"
  - [section] "we can establish a lower-bound probability for the predictions to be correct through similar derivations"
  - [corpus] Weak evidence - no corpus papers discuss probabilistic guarantees for pseudo-label correctness.
- Break condition: If the Tsybakov Margin Condition is violated or the estimation error grows beyond the threshold, the probabilistic guarantee fails.

### Mechanism 3
- Claim: Distribution alignment compensates for class imbalance in pseudo-label predictions, preventing the model from ignoring minority classes.
- Mechanism: DA estimates the prior of pseudo-labels P( ˆY) during training and sets a clean class prior ˆP(Y), usually uniform. It scales predictions by Norm( ˆP( ˆY = j|X = xu)P(Y = j)/P( ˆY = j)) to balance the class distribution.
- Core assumption: The true class prior P(Y) is uniform or known, and the pseudo-label distribution P( ˆY) can be accurately estimated during training.
- Evidence anchors:
  - [section] "Distribution Alignment (DA) is used to modulate the prediction so that the poorly predicted class will not be overlooked completely"
  - [section] "This is achieved by estimating the prior of the pseudo-label P( ˆY) during training, and setting a clean class prior ˆP(Y)"
  - [corpus] Weak evidence - corpus papers discuss imbalance but not DA specifically for SSL.
- Break condition: If the class prior is highly non-uniform and unknown, or if P( ˆY) cannot be accurately estimated, DA may introduce bias.

## Foundational Learning

- Concept: Semi-supervised learning and pseudo-labeling
  - Why needed here: InstanT builds on pseudo-labeling, where a model trained on labeled data assigns pseudo-labels to unlabeled instances based on confidence thresholds.
  - Quick check question: What is the main challenge in pseudo-labeling that InstanT aims to address?

- Concept: Instance-dependent label noise
  - Why needed here: The paper assumes label noise is instance-dependent, meaning the probability of a label being corrupted depends on the instance's features, not just its class.
  - Quick check question: How does instance-dependent noise differ from class-dependent noise in terms of modeling and estimation?

- Concept: Tsybakov Margin Condition
  - Why needed here: This condition is assumed to hold for the estimated noisy class posterior, which is crucial for deriving the probabilistic guarantee in Theorem 1.
  - Quick check question: What does the Tsybakov Margin Condition imply about the separability of the data?

## Architecture Onboarding

- Component map:
  - Classifier ˆfθ -> Main model trained with labeled and pseudo-labeled data
  - Transition matrix estimator ˆfθ' -> Estimates T(x) from labeled data
  - Instance-dependent threshold function τ(xu) -> Computes thresholds for each unlabeled instance
  - Distribution alignment module -> Balances class predictions
  - Loss correction module -> Applies forward correction to approximate clean class posterior

- Critical path:
  1. Train transition matrix estimator on labeled data using Equation 7
  2. During inference, compute instance-dependent thresholds using Equation 5
  3. Apply thresholds to filter pseudo-labels before adding to training set
  4. Train main classifier with consistency regularization and loss correction

- Design tradeoffs:
  - Instance-dependent vs uniform thresholds: Higher flexibility but increased complexity
  - Transition matrix estimation: More accurate noise modeling but requires labeled data
  - Distribution alignment: Prevents class imbalance but may introduce bias if priors are wrong

- Failure signatures:
  - Poor performance with extremely limited labeled data (transition matrix estimation fails)
  - Degradation to uniform thresholding behavior
  - Class imbalance issues if distribution alignment is disabled

- First 3 experiments:
  1. Compare InstanT with uniform threshold baseline on CIFAR-10 with 10 labels
  2. Test InstanT with different transition matrix estimation methods (e.g., importance reweighting vs loss correction)
  3. Evaluate the impact of distribution alignment on class-balanced vs imbalanced datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical guarantee for instance-dependent thresholds when the transition matrix T(x) is not fully identifiable due to insufficient labeled samples per class?
- Basis in paper: [explicit] The paper states that three informative noisy labels per class are sufficient for T(x) identification, but does not address the theoretical guarantee when this condition is not met.
- Why unresolved: The paper focuses on the case where T(x) is identifiable and does not explore the implications of partial or no identifiability on the theoretical guarantees of the instance-dependent thresholds.
- What evidence would resolve it: Empirical or theoretical analysis showing the performance of InstanT when the number of labeled samples per class is less than three, and how the instance-dependent thresholds behave in this scenario.

### Open Question 2
- Question: How does the performance of InstanT compare to other SSL methods when the instance-dependent label noise is not the dominant source of error in the model's predictions?
- Basis in paper: [inferred] The paper assumes that instance-dependent label noise is a significant factor in SSL, but does not investigate the performance of InstanT in scenarios where other sources of error, such as model misspecification or class imbalance, are more prominent.
- Why unresolved: The paper's theoretical analysis and experiments are centered around the instance-dependent label noise scenario, leaving the performance of InstanT in other error scenarios unexplored.
- What evidence would resolve it: Comparative experiments between InstanT and other SSL methods in settings where the primary source of error is not instance-dependent label noise, such as class imbalance or model misspecification.

### Open Question 3
- Question: Can the instance-dependent threshold function τ(xu) be further improved by incorporating additional instance-level information beyond the transition matrix and prediction confidence?
- Basis in paper: [inferred] The paper proposes τ(xu) based on the transition matrix and prediction confidence, but does not explore the potential benefits of incorporating other instance-level features, such as the local density of the data or the presence of outliers.
- Why unresolved: The paper's focus is on the transition matrix and prediction confidence, leaving the exploration of additional instance-level features for improving τ(xu) as an open question.
- What evidence would resolve it: Experimental results comparing the performance of InstanT with τ(xu) based on different sets of instance-level features, and an analysis of how these features impact the effectiveness of the instance-dependent thresholds.

## Limitations
- The effectiveness of transition matrix estimation heavily depends on the availability of sufficient labeled data
- The Tsybakov Margin Condition assumption may not hold in practice for complex datasets
- Computational overhead of instance-dependent threshold computation may become prohibitive for large-scale applications

## Confidence
- High confidence in the theoretical framework and proof of probabilistic guarantees (Theorem 1)
- Medium confidence in the practical effectiveness across all tested scenarios, particularly with extreme label scarcity
- Medium confidence in the claimed state-of-the-art performance, as some comparisons use slightly different architectures or hyperparameters

## Next Checks
1. Conduct ablation studies to isolate the contribution of each component (transition matrix estimation, distribution alignment, loss correction) to InstanT's performance
2. Test InstanT on additional real-world datasets with known label noise characteristics to validate the instance-dependent noise assumption
3. Measure and report the computational overhead of instance-dependent threshold computation compared to uniform thresholding baselines across different dataset sizes