---
ver: rpa2
title: Causal Entropy and Information Gain for Measuring Causal Control
arxiv_id: '2309.07703'
source_url: https://arxiv.org/abs/2309.07703
tags:
- causal
- information
- entropy
- variable
- gain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces causal entropy and causal information gain,
  new information-theoretic measures designed to evaluate the causal importance of
  features with respect to an outcome variable. The authors define these measures
  to quantify how much control a feature provides over an outcome, extending traditional
  entropy and mutual information to interventional settings.
---

# Causal Entropy and Information Gain for Measuring Causal Control

## Quick Facts
- arXiv ID: 2309.07703
- Source URL: https://arxiv.org/abs/2309.07703
- Reference count: 25
- One-line primary result: Introduces causal entropy and causal information gain as new information-theoretic measures for evaluating causal importance of features

## Executive Summary
This paper introduces causal entropy and causal information gain, new information-theoretic measures designed to evaluate the causal importance of features with respect to an outcome variable. The authors define these measures to quantify how much control a feature provides over an outcome, extending traditional entropy and mutual information to interventional settings. They prove that causal information gain is non-zero if and only if the feature has a causal effect on the outcome, while standard mutual information can be misleading due to statistical dependencies. The paper lays the theoretical foundation for methods that accurately assess causal feature importance, with potential applications in interpretable machine learning and scientific exploration.

## Method Summary
The method introduces causal entropy and causal information gain as extensions of traditional information-theoretic measures to interventional settings. Causal entropy measures the entropy of an outcome variable after intervening on a feature, while causal information gain quantifies the reduction in entropy achieved by such interventions. These measures are defined within the framework of structural causal models (SCMs) and require specification of an intervention protocol. The key insight is that these causal measures can distinguish between statistical dependencies and true causal effects, addressing limitations of standard mutual information in causal inference.

## Key Results
- Causal information gain is non-zero if and only if a feature has a causal effect on the outcome
- Causal entropy equals prior entropy if and only if there is no total causal effect
- Causal information gain is asymmetric, correctly reflecting directional nature of causal relationships
- Running example demonstrates correct identification of causally important features versus spurious correlations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal information gain correctly identifies features with causal influence by measuring how much entropy of the outcome decreases after intervention, rather than just conditioning
- Mechanism: The paper defines causal information gain as the expected reduction in entropy of the outcome variable Y when intervening on feature X, using an intervention protocol X'. This directly captures the causal effect by modeling the interventional distribution rather than the observational one
- Core assumption: The structural causal model (SCM) is known or can be estimated, and interventions can be modeled through atomic interventions (do-calculus)
- Evidence anchors:
  - [abstract] "causal information gain is non-zero if and only if the feature has a causal effect on the outcome"
  - [section] "causal information gain Ic(Y | do(X ∼ X ′)) of Y for X given the intervention protocol X ′ is the difference between the entropy of Y w.r.t. its prior and the causal entropy of Y given the intervention protocol X ′"
  - [corpus] Weak evidence - corpus papers mention causal entropy but don't provide direct evidence for this specific mechanism
- Break condition: If the SCM is misspecified or if the intervention protocol doesn't match the true distribution of interventions, the causal information gain may not correctly identify causal features

### Mechanism 2
- Claim: Causal entropy equals the prior entropy of Y if and only if X has no causal effect on Y, making it a diagnostic tool for causal relationships
- Mechanism: The paper shows that if there is no total causal effect of X on Y, then the causal entropy Hc(Y | do(X ∼ X ′)) equals H(Y) for any intervention protocol. This provides a theoretical foundation for using causal entropy as a test for causal influence
- Core assumption: The system can be modeled as an SCM with well-defined structural assignments and noise distributions
- Evidence anchors:
  - [abstract] "causal versions of entropy and mutual information, termed causal entropy and causal information gain, which are designed to assess how much control a feature provides over the outcome variable"
  - [section] "Proposition 1. If there is no total effect of X on Y, then Hc(Y | do(X ∼ X ′)) = H(Y) for any intervention protocol X ′ for X"
  - [corpus] No direct evidence in corpus for this specific mechanism
- Break condition: If the entropy function is non-injective (different distributions can have the same entropy), then Hc(Y | do(X ∼ X ′)) = H(Y) might occur even when X has a causal effect on Y

### Mechanism 3
- Claim: Causal information gain is not symmetric, unlike mutual information, which correctly reflects the directional nature of causal relationships
- Mechanism: The paper establishes that causal information gain measures the reduction in uncertainty about Y when intervening on X, but not vice versa, which aligns with the asymmetric nature of causation (X can cause Y without Y causing X)
- Core assumption: The causal structure is acyclic (DAG), ensuring that causal relationships are directional
- Evidence anchors:
  - [abstract] "causal versions of entropy and mutual information, termed causal entropy and causal information gain, which are designed to assess how much control a feature provides over the outcome variable"
  - [section] "A few properties of causal information gain can be immediately gleaned from its definition. First, in contrast with mutual information, causal information gain is not symmetric"
  - [corpus] Weak evidence - corpus papers discuss causal relationships but don't provide direct evidence for this specific mechanism
- Break condition: If there are feedback loops or cyclic causal relationships in the system, the asymmetry assumption breaks down

## Foundational Learning

- Concept: Structural Causal Models (SCMs)
  - Why needed here: The entire framework of causal entropy and causal information gain is built on the assumption that the system can be represented as an SCM with known structural assignments and noise distributions
  - Quick check question: Can you explain the difference between endogenous and exogenous variables in an SCM and why this distinction matters for causal inference?

- Concept: Do-calculus and interventions
  - Why needed here: Causal entropy and causal information gain measure changes in entropy under interventions, not just conditioning, which requires understanding the do-calculus framework and how atomic interventions modify SCMs
  - Quick check question: How does an atomic intervention do(X = x) modify the structural assignment of variable X in an SCM?

- Concept: Entropy and mutual information
  - Why needed here: The paper extends these traditional information-theoretic quantities to the causal context, so understanding their standard definitions and properties is essential for grasping the causal generalizations
  - Quick check question: What is the relationship between mutual information and entropy reduction, and how does this relationship inform the definition of causal information gain?

## Architecture Onboarding

- Component map: SCM specification and manipulation -> Intervention protocol definition -> Entropy calculation -> Causal information gain computation
- Critical path: The critical path for computing causal information gain involves: (1) Specifying the SCM, (2) Defining the intervention protocol X', (3) Computing the interventional distribution pdo(X=x) for each possible intervention value, (4) Calculating the entropy of Y under each interventional distribution, (5) Computing the expected entropy under the intervention protocol, and (6) Subtracting this from the prior entropy of Y
- Design tradeoffs: The choice of intervention protocol X' is crucial - a uniform distribution may not reflect realistic intervention scenarios, while a domain-specific distribution requires additional knowledge. The computational cost increases with the number of possible intervention values and the complexity of the SCM
- Failure signatures: If causal information gain is zero for all features, it could indicate either that no features have causal effects or that the SCM is misspecified. If causal information gain values are similar across features with known different causal strengths, the intervention protocol may be poorly chosen or the SCM may be incomplete
- First 3 experiments:
  1. Implement the running example from the paper (ice cream sales scenario) to verify that causal information gain correctly identifies advertising (X2) as having causal control over sales (Y) while the number of people wearing shorts (X1) does not
  2. Create a simple SCM with known causal structure and verify that causal information gain is non-zero only for features with causal effects on the outcome
  3. Compare causal information gain with standard mutual information on datasets where some features are confounders, verifying that causal information gain correctly ignores non-causal statistical dependencies

## Open Questions the Paper Calls Out

- What are the necessary and sufficient conditions for causal entropy and causal information gain to satisfy properties analogous to the chain rule and data processing inequality for standard entropy and mutual information?
- How do different choices of intervention protocol distributions affect the values and interpretation of causal entropy and causal information gain?
- What are efficient estimation methods for causal entropy and causal information gain that can handle high-dimensional data and complex real-world datasets, particularly in observational settings?

## Limitations
- Requires complete structural causal model as input, which is rarely available in real-world scenarios
- Assumes acyclic causal structures, limiting applicability to systems with feedback loops
- Does not address computational complexity or scalability to high-dimensional data

## Confidence
- Theoretical foundation (High): The mathematical derivations and proofs are rigorous and internally consistent
- Practical applicability (Medium): While the framework is sound, real-world implementation challenges are not fully addressed
- Empirical validation (Low): The paper relies on a single running example without broader empirical testing across diverse scenarios

## Next Checks
1. **SCM Specification Challenge**: Test the method on synthetic datasets where the true SCM is known, systematically varying the quality of SCM specification to quantify how misspecification affects causal information gain accuracy
2. **Intervention Protocol Sensitivity**: Evaluate how different intervention protocols (uniform, domain-specific, sparse) affect the ranking of features by causal information gain to determine the robustness of the method to protocol choice
3. **Comparison with Causal Discovery Methods**: Apply the method to benchmark datasets used in causal discovery literature and compare feature rankings with established causal inference techniques to validate practical utility