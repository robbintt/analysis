---
ver: rpa2
title: How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation
arxiv_id: '2312.07424'
source_url: https://arxiv.org/abs/2312.07424
tags:
- gpt-4v
- image
- format
- answer
- llava
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates the robustness of GPT-4V(ision) to distribution
  shifts across diverse domains, including natural, medical, and molecular images.
  We evaluate its zero-shot generalization capabilities and compare it with models
  like CLIP and LLaVA.
---

# How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation

## Quick Facts
- arXiv ID: 2312.07424
- Source URL: https://arxiv.org/abs/2312.07424
- Reference count: 14
- Primary result: GPT-4V shows strong adaptability to natural images but struggles with specialized domains like medicine and chemistry

## Executive Summary
This study investigates GPT-4V's robustness to distribution shifts across diverse domains, evaluating its zero-shot generalization capabilities on 13 datasets spanning natural, medical, and molecular images. The research compares GPT-4V's performance against CLIP and LLaVA, revealing strong performance on natural imagery but significant limitations in specialized domains. Through controlled data perturbations and in-context learning strategies, the study demonstrates GPT-4V's potential for domain bridging while highlighting critical limitations in tasks with non-semantic labels and the need for domain-specific fine-tuning.

## Method Summary
The study evaluates GPT-4V's zero-shot performance across 13 datasets using structured prompts that include confidence scores and reasoning. Researchers implemented controlled data perturbations through Gaussian noise and ControlNet style transfer, then tested in-context learning effectiveness by providing source domain examples to guide target domain classification. Performance was compared against CLIP and LLaVA baselines using classification accuracy as the primary metric.

## Key Results
- GPT-4V achieves 88.9% accuracy on Office-Home and 68.0% on DomainNet for natural images, significantly outperforming CLIP
- The model struggles with specialized domains, showing limited effectiveness on medical (Camelyon17, HAM10000) and chemical (DrugOOD_Assay, DrugOOD_Scaffold) datasets
- In-context learning improves performance by 3.7-16.67% across four datasets, demonstrating potential for distribution shift adaptation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4V exhibits strong zero-shot generalization for natural images but weaker performance in specialized domains.
- Mechanism: Zero-shot performance is tied to the presence of domain-specific data in GPT-4V's pre-training corpus. Natural images are likely well-represented, while medical and molecular domains are underrepresented.
- Core assumption: GPT-4V's pre-training dataset contains a large proportion of natural imagery but limited domain-specific data for medicine and chemistry.
- Evidence anchors:
  - [abstract] "Our findings reveal that GPT-4V demonstrates strong adaptability in natural images but struggles with specialized domains like medicine and chemistry."
  - [section 3.1.2] "GPT-4V’s high accuracy rates in Office-Home (0.889) and DomainNet (0.680) suggest a robust understanding and adaptability to diverse natural visuals... However, its proficiency waned in more specialized fields like medicine and chemistry."
- Break condition: If GPT-4V's pre-training corpus is revealed to include substantial medical/molecular data, this mechanism would fail.

### Mechanism 2
- Claim: GPT-4V's performance degrades predictably under controlled data perturbations, reflecting distributional shift sensitivity.
- Mechanism: Gaussian noise and style transfer (ControlNet) induce perturbations that fall outside GPT-4V's learned data distribution, revealing the model's generalization limits.
- Core assumption: The perturbations are sufficiently different from any domain seen during training to cause performance drops.
- Evidence anchors:
  - [section 4.1.1] "GPT-4V significantly surpasses CLIP’s performance (0.238 vs 0.161 in Fmow and 0.459 vs 0.214 in Terra_incognita)..."
  - [section 4.2.1] "In Office-Home_unseen, GPT-4V showcases remarkable generalization capabilities... Its impressive accuracy rate of 75.5% in Office-Home_unseen..."
- Break condition: If perturbations are within the training distribution, performance should not degrade.

### Mechanism 3
- Claim: In-context learning can partially bridge distribution shifts without fine-tuning.
- Mechanism: By conditioning on representative examples from a source domain, GPT-4V can adapt its inference process to handle target domain images without updating parameters.
- Core assumption: GPT-4V's attention and transformer architecture allow dynamic adaptation via context alone.
- Evidence anchors:
  - [section 5.2] "This approach demonstrates consistent performance enhancements across four distinct datasets... improvements of 3.7%, 8.4%, 2.4%, and 16.67%..."
  - [section 5.3] "GPT-4V effectively discerns between the regular, uniform tissue patterns... and applies this discernment to precisely classify the test image from hospital_3."
- Break condition: If in-context examples are too few or irrelevant, the model will not adapt.

## Foundational Learning

- Concept: Distribution shift and out-of-distribution generalization
  - Why needed here: The entire paper is about evaluating how GPT-4V performs when test data differs from training data.
  - Quick check question: What is the difference between covariate shift and label shift in the context of distribution shift?

- Concept: Zero-shot learning and few-shot in-context learning
  - Why needed here: GPT-4V's evaluation relies heavily on zero-shot performance and the effectiveness of in-context learning as an adaptation method.
  - Quick check question: How does in-context learning differ from traditional fine-tuning in terms of parameter updates?

- Concept: Multimodal model architectures (vision-language transformers)
  - Why needed here: GPT-4V is a multimodal foundation model; understanding its architecture is key to interpreting its performance.
  - Quick check question: What are the typical components of a vision-language transformer, and how do they interact?

## Architecture Onboarding

- Component map: Image encoder -> Text encoder -> Cross-attention fusion -> Decoder
- Critical path:
  1. Encode image → Extract visual features
  2. Encode prompt → Generate textual embeddings
  3. Cross-attention fusion → Joint multimodal representation
  4. Decoder → Generate answer, confidence, and reasoning
- Design tradeoffs:
  - Token limit constraints affect how much context can be used for in-context learning
  - Multimodal alignment quality impacts zero-shot performance across domains
  - Scale vs. efficiency: GPT-4V's large size allows broad generalization but limits fine-tuning
- Failure signatures:
  - Poor performance on specialized domains suggests lack of domain-specific pre-training data
  - Incorrect classifications with high confidence indicate overconfident but unreliable predictions
  - Failure on non-semantic labels suggests limitations in abstract reasoning for symbolic tasks
- First 3 experiments:
  1. Evaluate GPT-4V zero-shot accuracy on natural image datasets (e.g., PACS, VLCS) and compare to CLIP/LLaVA
  2. Apply Gaussian noise to natural images and measure robustness degradation relative to baselines
  3. Test in-context learning on medical images by providing two source examples and one target test image

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can GPT-4V's performance in specialized domains like medicine and chemistry be significantly improved?
- Basis in paper: [explicit] The paper states that GPT-4V's proficiency waned in more specialized fields like medicine and chemistry, signaling potential areas for enhancement.
- Why unresolved: The study identifies the need for domain-specific fine-tuning but does not explore specific methods or datasets that could be used for this purpose.
- What evidence would resolve it: Experiments demonstrating improved performance in medical and chemical domains after fine-tuning GPT-4V with domain-specific datasets.

### Open Question 2
- Question: What is the optimal strategy for selecting in-context examples to maximize GPT-4V's adaptability to distribution shifts?
- Basis in paper: [explicit] The paper suggests that a more deliberate selection of in-context examples could potentially lead to even greater improvements in model performance.
- Why unresolved: The study uses a random selection of in-context examples and acknowledges the potential for improvement but does not investigate optimal selection strategies.
- What evidence would resolve it: Comparative experiments showing the impact of different in-context example selection strategies on GPT-4V's performance across various distribution shift scenarios.

### Open Question 3
- Question: How does GPT-4V's performance compare to specialized models in domains where it currently underperforms?
- Basis in paper: [inferred] The paper highlights GPT-4V's limitations in specialized domains and suggests the need for further research, implying a comparison with specialized models could be insightful.
- Why unresolved: The study focuses on comparing GPT-4V with general models like CLIP and LLaVA but does not explore its performance relative to specialized models in domains like medicine and chemistry.
- What evidence would resolve it: Head-to-head comparisons of GPT-4V's performance against specialized models in medical and chemical domains, demonstrating relative strengths and weaknesses.

## Limitations

- The study's evaluation may be biased by using CLIP failure cases for augmentation, potentially inflating GPT-4V's relative performance
- GPT-4V demonstrates fundamental limitations with non-semantic labels, suggesting architectural constraints in symbolic reasoning tasks
- The effectiveness of in-context learning remains unclear, with the study showing only modest improvements without establishing systematic understanding of when and why this approach works

## Confidence

- High confidence: GPT-4V demonstrates strong zero-shot generalization on natural images but weaker performance on specialized domains (medical/chemistry)
- Medium confidence: In-context learning provides consistent but modest improvements across different datasets
- Low confidence: The claim that GPT-4V can bridge distribution shifts through in-context learning alone, particularly for complex domain adaptation tasks

## Next Checks

1. Conduct ablation studies on in-context learning effectiveness by varying the number of examples (1, 2, 4, 8) and measuring performance decay to establish the optimal context size
2. Test GPT-4V on additional non-semantic label datasets (e.g., abstract pattern classification) to better understand the scope of its limitations with symbolic reasoning tasks
3. Evaluate whether fine-tuning GPT-4V on domain-specific data from the target distribution can achieve performance levels comparable to specialized models like Meditron-70B or MoLeR-GPT, establishing whether in-context learning can truly replace fine-tuning