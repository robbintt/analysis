---
ver: rpa2
title: 'AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition
  and Linking'
arxiv_id: '2309.06175'
source_url: https://arxiv.org/abs/2309.06175
tags:
- entity
- candidate
- entities
- knowledge
- base
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the Entity Recognition and Linking Challenge
  at NLPCC 2015, focusing on extracting named entity mentions from short search queries
  and linking them to entities in a Chinese knowledge base. The approach involves
  expanding the knowledge base, using external knowledge to identify candidate entities,
  and employing Support Vector Regression and Multiple Additive Regression Tree as
  scoring functions to filter results.
---

# AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition and Linking

## Quick Facts
- arXiv ID: 2309.06175
- Source URL: https://arxiv.org/abs/2309.06175
- Reference count: 24
- F1 score of 0.535 achieved on NLPCC 2015 Entity Recognition and Linking Challenge

## Executive Summary
This paper presents AKEM, a method for Entity Recognition and Linking in Chinese search queries. The approach expands the knowledge base to improve recall, uses external search to identify candidate entities, and employs SVR and MART models to filter results. Rule-based refinement further enhances precision. The method achieves an F1 score of 0.535, demonstrating its effectiveness in addressing the challenges of entity recognition and linking in Chinese search queries.

## Method Summary
AKEM addresses the Entity Recognition and Linking Challenge by first expanding the knowledge base through various methods, including processing English entities, removing brackets, establishing a place directory, and extending entity names via regular expressions. For each query, the system performs Chinese word segmentation, searches each mention using Baidu, and matches search results with entities in the extended knowledge base. Features are extracted for each mention-candidate entity pair, and SVR and MART models are trained to score and filter candidates. Finally, rule-based filtering is applied to refine the results and improve precision.

## Key Results
- Achieves an F1 score of 0.535 on the NLPCC 2015 Entity Recognition and Linking Challenge.
- Demonstrates effectiveness in extracting named entity mentions from short Chinese search queries and linking them to entities in a Chinese knowledge base.
- Shows that the approach is computationally efficient while maintaining competitive performance.

## Why This Works (Mechanism)

### Mechanism 1
- Expanding the knowledge base improves recall by enabling the system to match more candidate entities.
- The approach extends the knowledge base by processing English entities, removing brackets, establishing a place directory, and extending entity names via regular expressions.
- More entity variations in the knowledge base lead to higher recall during matching.

### Mechanism 2
- Using SVR and MART scoring functions effectively filters noisy candidate entities, improving precision.
- The system trains SVR and MART models on a labeled training set, extracting features such as similarity between query and object description, mention characteristics, substring relationships, and word embedding similarities.
- Statistical learning models learn to distinguish correct from incorrect entity links based on extracted features.

### Mechanism 3
- Rule-based filtering further refines results by removing obvious noise and resolving ambiguities.
- Rules include removing English strings split into multiple entities, filtering out single Chinese character candidates, and selecting the mention most similar to the candidate when multiple mentions link to one entity.
- Simple deterministic rules catch errors that statistical models miss, especially for edge cases.

## Foundational Learning

- **Chinese word segmentation and named entity recognition (NER)**
  - Why needed: The task involves extracting named entity mentions from short Chinese search queries, which requires accurate segmentation and NER to identify candidate mentions.
  - Quick check: How does word segmentation impact the identification of candidate entities in Chinese queries?

- **Entity linking and disambiguation**
  - Why needed: After recognizing mentions, the system must link them to the correct entities in the knowledge base, handling ambiguity and multiple candidate entities.
  - Quick check: What challenges arise when linking mentions to entities in the presence of ambiguity or multiple candidates?

- **Support Vector Regression (SVR) and Multiple Additive Regression Trees (MART)**
  - Why needed: These statistical models are used to score and filter candidate entities based on extracted features, improving precision by removing noisy entities.
  - Quick check: How do SVR and MART models differ in their approach to ranking candidate entities?

## Architecture Onboarding

- **Component map**: Knowledge Base Expansion -> Candidate Entity Search -> Feature Extraction -> Statistical Filtering (SVR-MART) -> Rule-based Filtering -> Output
- **Critical path**:
  1. Expand knowledge base to improve recall.
  2. Segment query and search for candidate entities.
  3. Extract features for each mention-candidate entity pair.
  4. Apply SVR-MART scoring to filter candidates.
  5. Apply rule-based filtering to refine results.
  6. Output final linked entities.
- **Design tradeoffs**:
  - Recall vs. Precision: Expanding the knowledge base and searching broadly improves recall but may introduce noise, requiring more aggressive filtering to maintain precision.
  - Statistical vs. Rule-based Filtering: Statistical models can learn complex patterns but may miss edge cases; rules are deterministic but may not generalize well to all cases.
  - Computational Efficiency: The method is designed to be computationally efficient, but complex feature extraction or large knowledge bases may impact performance.
- **Failure signatures**:
  - Low recall: Insufficient knowledge base expansion or candidate search may miss correct entities.
  - Low precision: Inadequate filtering (statistical or rule-based) may allow too many incorrect entities through.
  - Performance issues: Complex feature extraction or large-scale processing may slow down the system.
- **First 3 experiments**:
  1. Test knowledge base expansion: Apply the expansion methods to a sample KB and verify that more entity variations are recognized during matching.
  2. Test candidate search: Use a small set of queries to ensure the search engine is finding relevant candidate entities and that the recall improves.
  3. Test SVR-MART filtering: Train the models on a labeled dataset and evaluate their ability to distinguish correct from incorrect entity links using precision and recall metrics.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the performance of AKEM change when using different search engines for candidate entity retrieval, beyond Baidu?
- **Basis in paper**: [explicit] The paper mentions using the Baidu search engine to find candidate entities, but doesn't explore other search engines.
- **Why unresolved**: The paper only evaluates the method with Baidu, so there's no comparative data on the impact of using different search engines.
- **What evidence would resolve it**: Conducting experiments using multiple search engines (e.g., Google, Bing) and comparing the recall and precision results would provide insights into the impact of search engine choice on AKEM's performance.

### Open Question 2
- **Question**: How would the inclusion of more advanced NLP techniques for Chinese word segmentation and named entity recognition affect AKEM's performance?
- **Basis in paper**: [inferred] The paper acknowledges that basic NLP tasks like Chinese word segmentation and named entity recognition significantly influence the outcome of recognizing candidate entities.
- **Why unresolved**: The paper uses standard methods for these tasks but doesn't explore the potential benefits of more advanced or specialized techniques.
- **What evidence would resolve it**: Implementing and testing AKEM with state-of-the-art Chinese NLP models for word segmentation and named entity recognition, then comparing the results with the current performance, would demonstrate the impact of these techniques.

### Open Question 3
- **Question**: What is the impact of using different thresholds (α) and values for k in the statistical-based filtering on AKEM's overall performance?
- **Basis in paper**: [explicit] The paper sets α = 0.3 and k = 3 for filtering but doesn't explore how varying these parameters affects the results.
- **Why unresolved**: The paper uses fixed values for these parameters without exploring a range of values or their impact on performance.
- **What evidence would resolve it**: Conducting experiments with various combinations of α and k values and analyzing the changes in precision, recall, and F1 scores would provide insights into the optimal parameter settings for AKEM.

## Limitations

- The reported F1 score of 0.535, while competitive, represents a moderate performance level that leaves significant room for improvement.
- The approach relies heavily on Baidu search engine results, introducing dependency on external search quality and potential access limitations.
- The knowledge base expansion methods may not capture all relevant entity variations, particularly for less common or emerging entities.
- The rule-based filtering, while simple and interpretable, may not generalize well to diverse query patterns and could introduce systematic biases.

## Confidence

- **High Confidence**: The core methodology of knowledge base expansion, candidate entity search, and ensemble scoring is well-documented and reproducible.
- **Medium Confidence**: The specific feature engineering choices and hyperparameter settings for the SVR and MART models are not fully detailed, which may affect reproducibility.
- **Low Confidence**: The absolute performance metrics are difficult to contextualize without access to the original evaluation dataset and comparison with contemporary methods.

## Next Checks

1. **Knowledge Base Expansion Validation**: Apply the described expansion methods to a sample Chinese knowledge base and verify that the expanded entities are correctly matched during candidate search. Measure the increase in recall compared to the original knowledge base.

2. **Candidate Entity Search Validation**: Use a small set of Chinese queries to test the Baidu search engine integration and candidate entity matching. Evaluate the precision and recall of the candidate search step to ensure it is finding relevant entities.

3. **SVR-MART Model Validation**: Train the SVR and MART models on the provided 159 labeled queries and evaluate their performance on a held-out test set. Compare the models' ability to distinguish correct from incorrect entity links using precision and recall metrics.