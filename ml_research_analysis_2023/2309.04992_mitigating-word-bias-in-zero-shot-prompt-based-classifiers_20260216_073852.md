---
ver: rpa2
title: Mitigating Word Bias in Zero-shot Prompt-based Classifiers
arxiv_id: '2309.04992'
source_url: https://arxiv.org/abs/2309.04992
tags:
- language
- prompt
- class
- word
- prior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses inherent class bias in prompt-based classifiers,
  where label word probabilities are influenced by distributional statistics of words
  rather than task relevance. To mitigate this, the authors propose re-weighting probabilities
  to ensure a uniform prior over classes using unlabeled data.
---

# Mitigating Word Bias in Zero-shot Prompt-based Classifiers

## Quick Facts
- arXiv ID: 2309.04992
- Source URL: https://arxiv.org/abs/2309.04992
- Reference count: 21
- The paper proposes re-weighting probabilities to ensure a uniform prior over classes using unlabeled data, significantly reducing sensitivity to prompt and label word choice.

## Executive Summary
This paper addresses the inherent class bias in prompt-based classifiers, where label word probabilities are influenced by distributional statistics of words rather than task relevance. The authors propose a simple unsupervised solution of re-weighting probabilities using unlabeled data to search for weight parameters that ensure a uniform prior over classes. They also draw a theoretical connection between class priors and language model word priors, motivating a zero-resource normalization approach. Experiments on sentiment classification, natural language inference, and paraphrase detection tasks show that the unsupervised prior-matching method significantly reduces sensitivity to prompt and label word choice, achieving performance close to oracle upper-bounds.

## Method Summary
The method involves re-weighting the probabilities of prompt-based classifiers to have a uniform prior over classes. Given an input text and a set of class words, the classifier reformats the input text with a task instruction and selects class words associated with each output class. The output probabilities are computed using a language model, and weight parameters are applied to re-weight these probabilities. The weights are found by using unlabeled data to ensure a uniform prior over classes. This approach does not require labeled task data, preserving the zero-shot benefits of prompt-based classifiers.

## Key Results
- Prior-matching increased accuracy from 78.8% to 90.9% on the Rotten Tomatoes dataset across all prompts and label words.
- The unsupervised prior-matching method correlates strongly with oracle upper-bound performance, illustrating that accounting for marginal bias is almost equivalent to maximizing accuracy.
- The method shows large consistent performance gains for prompt settings over a range of NLP tasks, including sentiment classification, natural language inference, and paraphrase detection.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The classifier's output probabilities are influenced by distributional statistics of words (word biases), not task relevance.
- Mechanism: Large language models model Pθ(w|x), and for classification, class probabilities are set proportional to the probability of associated class words. This leads to inherent class bias when label words have high LM prior but low task relevance.
- Core assumption: The prompt-based classifier's probabilities are determined by Pθ(wk|p(x)) / Σwi Pθ(wi|p(x)).
- Evidence anchors:
  - [abstract]: "This discrepancy can be partly attributed to word biases, where the classifier may be biased towards classes."
  - [section 2]: "Given an input sequence x ∈ X , large language models (LLMs) model Pθ(w|x), the output probability distribution over all possible sequences w ∈ X . For a classication task T , a prompt-based classifier 1) reformats the input text x to prompt p ∈ X by including the task instruction, and 2) selects class words{wi}1:K which are associated to each output class {yi}1:K."

### Mechanism 2
- Claim: Re-weighting probabilities to have a uniform prior over classes mitigates the word bias.
- Mechanism: By finding weight parameters α = {αi}1:K that scale the probabilities, the classifier becomes unbiased such that the class prior matches the true prior P(yk).
- Core assumption: There exists a set of weights that can adjust the classifier's output probabilities to match the true class distribution.
- Evidence anchors:
  - [abstract]: "To account for this bias, one could use a labelled dataset to find optimal class decision thresholds. This, however, requires labelled task data, which may limit the zero-shot benefits of prompt-based classifiers. We propose a simple unsupervised solution of re-weighting probabilities, where we use unlabelled data to search for weight parameters that ensure a uniform prior over classes."
  - [section 2]: "¯α = argmin α X ∀yk | ˆPθ(yk|Q, α) − P (yk)| (7) A deterministic solution that exactly matches the distributions exists, which can be found with a search with 1 degree of freedom (that can be accounted for by setting α1 = 1 )."

### Mechanism 3
- Claim: The optimal weights for maximizing accuracy are highly correlated with the weights found by matching class priors.
- Mechanism: The unsupervised prior-matching method finds weights that ensure a uniform class prior, which correlates strongly with the oracle weights that maximize accuracy.
- Core assumption: The weights that make the classifier unbiased (match the true class prior) are close to the weights that maximize accuracy.
- Evidence anchors:
  - [abstract]: "We show that matching class priors correlates strongly with the oracle upper bound performance and demonstrate large consistent performance gains for prompt settings over a range of NLP tasks."
  - [section 2]: "Figure 4 shows a scatter plot of the weights found by the optimal threshold search α∗ (equation 4), with those found from the unsupervised prior matching method ¯α (equation 7) and the zero-resource word prior approximation (equation 9). We see a clear linear relationship between optimal and prior-match, illustrating that accounting for the marginal bias is almost equivalent with maximising accuracy, however, achieved in an unsupervised fashion."

## Foundational Learning

- Concept: Prompt-based classifiers reformulate input text with a task instruction and select class words associated with each output class.
  - Why needed here: Understanding how prompt-based classifiers work is crucial to grasp why word biases occur and how re-weighting can mitigate them.
  - Quick check question: How does a prompt-based classifier assign class probabilities given an input text and a set of class words?

- Concept: Large language models model the probability distribution over all possible sequences given an input.
  - Why needed here: The mechanism of prompt-based classifiers relies on the output probabilities of LLMs, which are influenced by word distributional statistics.
  - Quick check question: What does Pθ(w|x) represent in the context of large language models?

- Concept: The concept of class priors and how they relate to the true distribution of classes in the data.
  - Why needed here: The paper proposes re-weighting probabilities to match the true class prior, which requires understanding what class priors are and why they matter.
  - Quick check question: Why is it important for a classifier to have class priors that match the true distribution of classes in the data?

## Architecture Onboarding

- Component map:
  Input text x -> Prompt p (includes task instruction) -> Class words {wi}1:K -> Language model Pθ(w|x) -> Weight parameters α = {αi}1:K -> Output class probabilities ˆPθ(yk|x, Q, α)

- Critical path:
  1. Reformats input text with prompt
  2. Selects class words
  3. Computes output probabilities using language model
  4. Applies weight parameters to re-weight probabilities
  5. Normalizes to get final class probabilities
  6. Predicts class with highest probability

- Design tradeoffs:
  - Using labelled data to find optimal weights vs. unsupervised re-weighting
  - Computational cost of searching for optimal weights vs. simplicity of prior-matching
  - Sensitivity to prompt and label word choice vs. robustness after re-weighting

- Failure signatures:
  - Large variance in accuracy across different prompts and label words (before re-weighting)
  - Poor performance on certain tasks even after re-weighting
  - Weights found by prior-matching not correlating well with optimal weights

- First 3 experiments:
  1. Evaluate baseline performance of prompt-based classifier without re-weighting on sentiment classification tasks.
  2. Apply prior-matching re-weighting and compare performance to baseline.
  3. Compare performance of prior-matching to oracle upper-bound (optimal weights found using labelled data).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of prior-matching and null-input methods vary across different language models and tasks?
- Basis in paper: [explicit] The paper mentions that prior-matching and null-input methods show large consistent gains across various NLP tasks, but it also notes that for paraphrase detection using Llama-2-chat 7B, the performance boost is moderate and there is a larger discrepancy with optimal weights.
- Why unresolved: The paper does not provide a comprehensive analysis of how these methods perform across a wide range of language models and tasks. The experiments are limited to a few models and tasks.
- What evidence would resolve it: Conducting experiments with a broader range of language models and tasks, including more diverse datasets and model architectures, would provide a clearer understanding of the generalizability and limitations of these methods.

### Open Question 2
- Question: What is the impact of different prompt templates and label words on the performance of prompt-based classifiers?
- Basis in paper: [explicit] The paper discusses the sensitivity of prompt-based classifiers to the choice of prompt templates and label words, and how this can lead to significant performance differences.
- Why unresolved: While the paper demonstrates the impact of prompt and label word choice, it does not explore the full spectrum of possible prompts and label words or their combinations in depth.
- What evidence would resolve it: A systematic study varying prompt templates and label words across different tasks and datasets would help identify which combinations are most effective and why.

### Open Question 3
- Question: How do the proposed methods perform in zero-shot scenarios where no unlabelled data is available?
- Basis in paper: [inferred] The paper introduces a zero-resource approximation method (null-input) that does not require unlabelled data, but it does not extensively evaluate its performance in true zero-shot scenarios.
- Why unresolved: The effectiveness of the null-input method in scenarios without any unlabelled data remains untested, as the experiments primarily use unlabelled data for prior-matching.
- What evidence would resolve it: Testing the null-input method in scenarios where no unlabelled data is available, and comparing its performance to other zero-shot approaches, would clarify its utility and limitations in such settings.

## Limitations

- The method assumes a uniform class prior is optimal, which may not hold for all tasks where class imbalance is inherent to the problem structure.
- The correlation between prior-matching weights and optimal accuracy-maximizing weights, while demonstrated, may not generalize to all language models or prompt types.
- The zero-resource word prior approximation relies on the assumption that word probabilities from unsupervised data adequately represent task-relevant word distributions.

## Confidence

- High: The existence of word bias in prompt-based classifiers and the need for mitigation approaches
- Medium: The effectiveness of prior-matching re-weighting in reducing sensitivity to prompt and label word choice
- Medium: The theoretical connection between class priors and language model word priors

## Next Checks

1. Test the zero-resource word prior approximation on a broader range of language models (beyond FlanT5) to verify generalization.
2. Evaluate performance when the true class prior is non-uniform to assess method robustness.
3. Conduct ablation studies varying the amount of unlabeled data to determine sensitivity to data quantity/quality.