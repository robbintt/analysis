---
ver: rpa2
title: Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head
arxiv_id: '2309.13377'
source_url: https://arxiv.org/abs/2309.13377
tags:
- support
- training
- which
- learning
- invariant
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a nonparametric approach for learning invariant
  representations using a Nadaraya-Watson (NW) head. The NW head makes predictions
  by comparing query representations to a support set of labeled data.
---

# Learning Invariant Representations with a Nonparametric Nadaraya-Watson Head

## Quick Facts
- arXiv ID: 2309.13377
- Source URL: https://arxiv.org/abs/2309.13377
- Authors: 
- Reference count: 40
- Key outcome: Proposes a nonparametric NW head for invariant representation learning, demonstrating competitive performance on Camelyon-17, ISIC, and FMoW datasets without requiring invariance hyperparameter tuning.

## Executive Summary
This paper introduces a novel nonparametric approach for learning invariant representations using a Nadaraya-Watson (NW) head. The method makes predictions by comparing query representations to a support set of labeled data, with the key innovation being the manipulation of this support set to encourage invariant feature learning. By restricting the support set to a single environment during training, the model learns features that are robust to environment-specific variations. The approach is validated on three challenging domain generalization tasks and shows competitive performance compared to state-of-the-art parametric baselines, with the added benefit of interpretability through nearest neighbor explanations.

## Method Summary
The proposed method employs a nonparametric Nadaraya-Watson head that makes predictions by comparing learned query representations to elements in a support set. The core innovation lies in manipulating the support set to encode causal assumptions about the data-generating process. Specifically, the support set can be conditioned on a single environment or balanced across classes to encourage learning of environment-invariant features. The method is trained using cross-entropy loss with a hyperparameter λ controlling the trade-off between standard classification and invariance-promoting objectives. The approach is implemented using standard neural network architectures (DenseNet-121, ResNet-50) with PyTorch, and evaluated using multiple inference modes including random sampling, full support, clustering-based selection, and ensemble methods.

## Key Results
- The proposed NW approach achieves superior results on Camelyon-17 and ISIC datasets compared to state-of-the-art parametric baselines
- The method performs comparably to baselines on FMoW while requiring no invariance hyperparameter tuning
- The nonparametric nature provides interpretability benefits through nearest neighbor explanations in feature space
- Single-environment support conditioning successfully encourages learning of invariant features across different domain generalization tasks

## Why This Works (Mechanism)

### Mechanism 1
Restricting the support set to a single environment encourages the model to learn invariant features that do not depend on environment-specific variations. By conditioning the support set on a single environment during training, the model is prevented from using environment-specific features to make predictions. This forces the model to rely only on environment-invariant "content" features, aligning with the causal assumption that Y is independent of E given ZC.

### Mechanism 2
Balancing classes across environments removes the direct dependence E → Y, effectively performing an intervention on Y. By ensuring the support set has balanced class representation across environments, the model cannot exploit environment-specific label priors. This aligns with the intervened causal graph where Y is independent of E.

### Mechanism 3
The NW head's nonparametric nature allows flexible comparison to real datapoints, enabling causal assumptions to be encoded through support set manipulation. Unlike parametric models that learn fixed decision boundaries, the NW head makes predictions by comparing query representations to labeled support points. By manipulating which points are in the support, different causal assumptions can be encoded without changing the model architecture.

## Foundational Learning

- **Concept: Causal graphs and d-separation**
  - Why needed here: The method relies on causal assumptions about the data-generating process, specifically that Y ⊥ ⊥ E | ZC and Y ̸⊥ ⊥ E | ZS. Understanding these independence relationships is crucial for designing the support set manipulation strategy.
  - Quick check question: Given a causal graph where E → X ← Y and E → Y, what independence relationship would d-separation tell us about Y and E when conditioning on X?

- **Concept: Nonparametric methods and kernel methods**
  - Why needed here: The NW head is a nonparametric approach that makes predictions based on weighted comparisons to support points. Understanding how nonparametric methods differ from parametric approaches is essential for grasping why support set manipulation is possible.
  - Quick check question: How does a nonparametric method like the NW head differ from a parametric classifier in terms of model flexibility and assumptions about the data?

- **Concept: Domain generalization and invariant learning**
  - Why needed here: The goal is to learn representations that generalize across unseen environments. Understanding the challenges of domain shift and common approaches (like IRM) provides context for why this nonparametric approach is valuable.
  - Quick check question: What is the key challenge in domain generalization, and how do methods like IRM attempt to address it?

## Architecture Onboarding

- **Component map**: Feature extractor φ -> Support set S -> Similarity function s(·, ·) -> NW head -> Loss function L
- **Critical path**: 1) Sample query and support mini-batches 2) Pass through feature extractor φ 3) Compute pairwise similarities 4) Calculate NW predictions 5) Compute loss and backpropagate
- **Design tradeoffs**: Computational cost (quadratic scaling with support size vs. linear scaling for parametric models), flexibility (can encode complex causal assumptions vs. limited to architectural constraints), interpretability (provides nearest neighbor explanations vs. black-box predictions), hyperparameter tuning (no invariance hyperparameter vs. requires tuning λ)
- **Failure signatures**: Poor performance when content-style disentanglement assumption fails, high variance across runs especially for nearest-neighbor inference modes, computational bottlenecks with large support sets, failure to generalize when test environments have different label distributions
- **First 3 experiments**: 1) Implement basic NW head with random support set on rotated MNIST 2) Add support set balancing on dataset with environment-label correlations 3) Implement single-environment support conditioning on multi-environment dataset

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of similarity function in the NW head affect the quality of invariant representations learned? The paper mentions using negative Euclidean distance but notes that prior works have explored learnable kernels. This remains unresolved as the paper doesn't compare different similarity functions.

### Open Question 2
What is the theoretical relationship between the number of environments used during training and the generalization performance on unseen environments? The paper uses multiple environments during training but doesn't analyze how varying this number impacts performance on new domains.

### Open Question 3
How does the NW approach compare to other non-parametric methods for domain generalization, such as prototype-based methods? The paper focuses on NW head but doesn't benchmark against other non-parametric approaches like prototypical networks or nearest neighbors.

## Limitations

- The content-style disentanglement assumption (g(X) = (gC(X), gS(X))) is fundamental yet not empirically validated
- The computational cost of the nonparametric approach (O(n²) scaling) is not thoroughly analyzed
- The "Full" inference mode is noted as impractical despite being used in main results

## Confidence

- **High confidence**: Basic NW head implementation and support set manipulation framework
- **Medium confidence**: Causal assumptions and their encoding through support set manipulation (rely on unproven disentanglement assumptions)
- **Low confidence**: Computational efficiency claims and practical scalability, particularly for "Full" inference mode

## Next Checks

1. **Disentanglement validation**: Run experiments to empirically verify whether the feature extractor φ actually learns content and style features that satisfy the assumed independence relationships (Y ⊥ ⊥ E | ZC and Y ̸⊥ ⊥ E | ZS)
2. **Runtime benchmarking**: Measure training and inference times across different support set sizes and inference modes to quantify the computational overhead and verify the claimed efficiency benefits
3. **Ablation on support set size**: Systematically vary the support set size to determine the minimum effective size for each dataset and inference mode, establishing practical scalability limits