---
ver: rpa2
title: End-to-End Breast Cancer Radiotherapy Planning via LMMs with Consistency Embedding
arxiv_id: '2311.15876'
source_url: https://arxiv.org/abs/2311.15876
tags:
- clinical
- segmentation
- arxiv
- radiation
- plan
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces RO-LLaMA, a generalist large language model
  (LLM) tailored for radiation oncology. RO-LLaMA performs multiple clinical tasks
  including clinical report summarization, radiation treatment plan suggestion, and
  plan-guided 3D target volume segmentation.
---

# End-to-End Breast Cancer Radiotherapy Planning via LMMs with Consistency Embedding

## Quick Facts
- arXiv ID: 2311.15876
- Source URL: https://arxiv.org/abs/2311.15876
- Reference count: 40
- Key outcome: RO-LLaMA with CEFTune and CESEG achieves superior performance across clinical tasks in radiation oncology compared to baseline methods

## Executive Summary
This work introduces RO-LLaMA, a generalist large language model (LLM) tailored for radiation oncology. RO-LLaMA performs multiple clinical tasks including clinical report summarization, radiation treatment plan suggestion, and plan-guided 3D target volume segmentation. To improve robustness against noisy intermediate generations, the authors propose Consistency Embedding Fine-Tuning (CEFTune) and Consistency Embedding Segmentation (CESEG), which enforce consistency between predictions from noisy and clean inputs. Multi-center experiments demonstrate that RO-LLaMA with CEFTune and CESEG achieves superior performance across tasks compared to baseline methods, with significant improvements in both internal and external validation settings.

## Method Summary
The authors developed RO-LLaMA by fine-tuning LLaMA-2-7B-Chat on clinical reports, treatment plans, and CT scans for breast cancer radiotherapy. They introduced Consistency Embedding Fine-Tuning (CEFTune) for text tasks and Consistency Embedding Segmentation (CESEG) for segmentation tasks. These techniques use noise injection and consistency regularization to improve robustness against noisy intermediate generations. The framework includes three models: RO-LLaMA-S for report summarization, RO-LLaMA-P for treatment plan suggestion, and RO-LLaMA-SEG++ for 3D target volume segmentation. The models were trained on data from Yonsei Cancer Center and evaluated on both internal and external validation sets.

## Key Results
- RO-LLaMA-S with CEFTune achieved 54.1 ROUGE-1, 24.9 ROUGE-2, and 49.5 ROUGE-L scores on external validation, outperforming baseline methods
- RO-LLaMA-P with CEFTune achieved 41.9 ROUGE-1, 18.6 ROUGE-2, and 39.3 ROUGE-L scores, with clinical experts rating the generated plans as clinically acceptable
- RO-LLaMA-SEG++ with CESEG achieved 77.7 Dice coefficient, 88.0 IoU, and 2.1 HD-95 on external validation, showing superior segmentation performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Consistency Embedding Fine-Tuning (CEFTune) improves robustness by enforcing consistency between predictions from noisy and clean inputs
- Mechanism: During fine-tuning, random noise is injected into embeddings to simulate noisy intermediate generations. A consistency loss term encourages the model's predictions for noisy and clean inputs to be similar, preventing error accumulation in sequential tasks
- Core assumption: Maintaining consistency between noisy and clean input predictions improves model robustness without sacrificing performance on clean inputs
- Evidence anchors:
  - [abstract] "To improve robustness against noisy intermediate generations, the authors propose Consistency Embedding Fine-Tuning (CEFTune) and Consistency Embedding Segmentation (CESEG), which enforce consistency between predictions from noisy and clean inputs."
  - [section 3.1] "To bolster the model's capability in handling both noisy and clean inputs, we incorporate a regularization loss to encourage consistency as follows: LCEFTune(θ) = LNEFTune(θ) + λR(θ, θ−)"

### Mechanism 2
- Claim: Consistency Embedding Segmentation (CESEG) extends the consistency concept to multi-modal segmentation tasks
- Mechanism: For segmentation tasks, text prompts are prepended to treatment plans and noisy embeddings are generated. The model is regularized to maintain consistency between noisy and clean text embeddings when generating segmentation masks
- Core assumption: Enforcing consistency between noisy and clean text embeddings improves segmentation performance when the text input is itself a noisy generation from a previous step
- Evidence anchors:
  - [abstract] "We further extend this concept to LMM-driven segmentation framework, leading to a novel Consistency Embedding Segmentation (CESEG) techniques."
  - [section 3.2] "Apart from the original concept of CEFTune, we modified the consistency regularization module for the multi-modal segmentation task, which combines CEFTune and the text prompt tuning."

### Mechanism 3
- Claim: The generalist LLM approach with task-specific fine-tuning achieves superior performance compared to baseline methods
- Mechanism: RO-LLaMA is fine-tuned on diverse tasks (report summarization, plan suggestion, segmentation) using instruction fine-tuning and noise consistency techniques. This enables end-to-end handling of the clinical workflow
- Core assumption: Fine-tuning a large language model on multiple related clinical tasks with noise consistency improves performance compared to single-task models
- Evidence anchors:
  - [abstract] "Experimental results including multi-centre validation confirm that our RO-LMM with CEFTune and CESEG results in promising performance for multiple clinical tasks with generalization capabilities."
  - [section 4.5] Tables showing RO-LLaMA outperforms baseline methods across multiple tasks and validation sets

## Foundational Learning

- Concept: Noise injection and consistency regularization in deep learning
  - Why needed here: To handle noisy intermediate generations in sequential clinical tasks and improve model robustness
  - Quick check question: How does the consistency loss term in CEFTune differ from standard noise injection approaches like NEFTune?

- Concept: Instruction fine-tuning for large language models
  - Why needed here: To adapt a general LLM (LLaMA2) to specific clinical tasks in radiation oncology
  - Quick check question: What are the key differences between the fine-tuning approaches for RO-LLaMA-S vs RO-LLaMA-P?

- Concept: Multi-modal learning with language-driven segmentation
  - Why needed here: To incorporate treatment plan information into 3D target volume segmentation
  - Quick check question: How does the text prompt tuning in RO-LLaMA-SEG differ from standard text-conditioned segmentation approaches?

## Architecture Onboarding

- Component map:
  - LLM backbone (LLaMA2) fine-tuned for three tasks: RO-LLaMA-S (summary), RO-LLaMA-P (plan), RO-LLaMA-SEG (segmentation)
  - Noise injection module for simulating noisy intermediate generations
  - Consistency regularization module enforcing similarity between noisy and clean input predictions
  - 3D U-Net for image segmentation with text conditioning
  - Text prompt tuning for incorporating treatment plan information

- Critical path:
  1. Fine-tune LLM on report summarization with NEFTune/CEFTune
  2. Fine-tune LLM on treatment plan suggestion with NEFTune/CEFTune
  3. Fine-tune segmentation network with LLM-generated treatment plans
  4. Apply CESEG to improve segmentation robustness

- Design tradeoffs:
  - Task-specific vs generalist approach: Specialized models might outperform on individual tasks but lack end-to-end workflow capability
  - Noise intensity: Too little noise may not improve robustness; too much may degrade clean input performance
  - Consistency loss weight: Poorly tuned weights can harm either noisy or clean input performance

- Failure signatures:
  - Performance degradation on clean inputs indicates overly aggressive noise or consistency regularization
  - Inconsistent outputs between noisy and clean inputs suggests insufficient consistency regularization
  - Poor segmentation results indicate issues with text conditioning or multi-modal alignment

- First 3 experiments:
  1. Compare CEFTune vs NEFTune performance on clean and noisy inputs for report summarization
  2. Evaluate impact of different noise intensity levels on treatment plan suggestion performance
  3. Test segmentation performance with and without CESEG using generated vs ground truth treatment plans

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RO-LLaMA with CEFTune and CESEG generalize to other cancer types beyond breast cancer?
- Basis in paper: [inferred] The paper mentions that the dataset is currently confined to patients with their initial diagnoses of breast cancer, and the authors suggest expanding the scope to cover diverse patient scenarios.
- Why unresolved: The study focuses exclusively on breast cancer, and the authors do not provide any experimental results or discussion on how the model would perform with other cancer types.
- What evidence would resolve it: Conducting experiments with RO-LLaMA on datasets from other cancer types, such as lung or prostate cancer, and comparing the performance to baseline models and human experts would provide evidence of the model's generalizability.

### Open Question 2
- Question: How does the robustness of RO-LLaMA with CEFTune and CESEG hold up under adversarial attacks or intentional noise injection in real-world clinical settings?
- Basis in paper: [explicit] The paper introduces CEFTune and CESEG to improve the model's robustness against noisy inputs, but it does not discuss potential adversarial attacks or intentional noise injection in real-world clinical settings.
- Why unresolved: The study focuses on the model's performance under normal conditions and does not explore its resilience against adversarial attacks or intentional noise injection.
- What evidence would resolve it: Conducting experiments where RO-LLaMA is exposed to adversarial attacks or intentional noise injection, and evaluating its performance and robustness in these scenarios would provide evidence of its resilience in real-world clinical settings.

### Open Question 3
- Question: How does the performance of RO-LLaMA with CEFTune and CESEG compare to human experts in terms of accuracy, efficiency, and clinical decision-making in radiation oncology?
- Basis in paper: [inferred] The paper demonstrates that RO-LLaMA outperforms baseline methods in various tasks, but it does not provide a direct comparison with human experts in terms of accuracy, efficiency, and clinical decision-making.
- Why unresolved: The study focuses on the model's performance compared to baseline methods and does not include a comparison with human experts.
- What evidence would resolve it: Conducting a study where RO-LLaMA and human experts perform the same tasks in radiation oncology, and comparing their accuracy, efficiency, and clinical decision-making would provide evidence of the model's performance relative to human experts.

## Limitations

- The generalizability of CEFTune and CESEG techniques beyond breast cancer radiotherapy remains uncertain, as the approach was only tested on breast cancer cases
- The clinical evaluation methodology has limitations, with expert assessments based on "reasonable clinical relevance" rather than comprehensive clinical validation or comparison to actual treatment decisions
- The exact implementation details of CEFTune and CESEG techniques are not fully described, including the specific noise injection parameters and consistency loss weights

## Confidence

- High Confidence: The technical implementation of noise injection and consistency regularization mechanisms (CEFTune) is well-specified and grounded in established deep learning principles
- Medium Confidence: The multi-task learning approach and generalist model design are theoretically sound, but the relative performance gains compared to specialized models need more extensive validation
- Medium Confidence: The segmentation framework (CESEG) builds logically on CEFTune, but the specific text conditioning approach for medical image segmentation lacks detailed implementation specifications

## Next Checks

1. Cross-cancer validation: Test RO-LLaMA on head-and-neck or prostate cancer cases to evaluate generalizability beyond breast cancer. Compare performance metrics against domain-specific models to quantify the generalist vs specialist tradeoff.

2. Clinical decision correlation: Conduct a retrospective study comparing RO-LLaMA-generated treatment plans against actual clinical decisions across a larger patient cohort. Calculate agreement rates and identify systematic differences in target volume delineation.

3. Ablation study on noise parameters: Systematically vary noise injection intensity and consistency loss weights across the three tasks to identify optimal configurations. Measure the impact on both noisy and clean input performance to establish robustness bounds.