---
ver: rpa2
title: Towards Self-Assembling Artificial Neural Networks through Neural Developmental
  Programs
arxiv_id: '2307.08197'
source_url: https://arxiv.org/abs/2307.08197
tags:
- neural
- network
- networks
- nodes
- growth
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes neural developmental programs (NDPs) as a way
  to grow neural networks through local communication between neurons. The NDP approach
  treats each neuron as an autonomous agent, deciding whether to replicate and how
  to set connection weights based on local information from neighbors.
---

# Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs

## Quick Facts
- arXiv ID: 2307.08197
- Source URL: https://arxiv.org/abs/2307.08197
- Reference count: 7
- Primary result: Neural developmental programs can grow neural networks through local communication, achieving reasonable performance on simple tasks but lacking state-of-the-art results

## Executive Summary
This paper introduces Neural Developmental Programs (NDPs) as a method for growing neural networks through local communication between neurons. Each neuron acts as an autonomous agent that decides whether to replicate and how to set connection weights based on local information from neighbors. The approach treats network growth as a developmental process, similar to biological neural development, where the same program (NDP) controls growth across all neurons. The authors demonstrate this concept on tasks including XOR classification, CartPole and LunarLander reinforcement learning, and MNIST classification, while also exploring topological properties like small-worldness.

## Method Summary
The method uses NDPs that grow networks through iterative local communication between neurons. Each neuron maintains an embedding state that gets updated through graph neural network operations (graph convolutions). Based on these embeddings, MLPs decide whether neurons should replicate and how to assign connection weights. The approach has two optimization variants: evolutionary using CMA-ES and gradient-based using backpropagation. Growth proceeds through discrete steps where neurons can replicate, creating new nodes that inherit connection patterns, with the process guided by the NDP parameters optimized for task performance.

## Key Results
- Successfully grows networks for XOR classification, CartPole, and LunarLander tasks
- NDPs can learn to create networks with desired topological properties like small-worldness
- Evolutionary optimization outperforms gradient-based for MNIST, while gradient-based works better for reinforcement learning tasks
- Network performance can deteriorate with excessive growth steps, suggesting overfitting

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Local communication between neurons enables self-organization of network topology.
- Mechanism: Each neuron acts as an autonomous agent that receives local state information from its neighbors through message passing, then decides whether to replicate and how to set connection weights based solely on this local information.
- Core assumption: The local state vectors (embeddings) contain sufficient information for each neuron to make globally coherent decisions about network growth.
- Evidence anchors:
  - [abstract] "The growth process is guided by another neural network, which we call a Neural Developmental Program (NDP) and which operates through local communication alone."
  - [section] "The NDP takes as input information from the connected neurons in the policy network and decides if a neuron should replicate and how each connection in the network should set its weight."
  - [corpus] No direct supporting evidence found in related papers; this is a novel approach not well-covered in the corpus.
- Break condition: If local information becomes insufficient to maintain network coherence as size increases, or if message passing introduces significant delays that disrupt real-time decision making.

### Mechanism 2
- Claim: Graph neural networks can serve as developmental programs that encode growth rules.
- Mechanism: The NDP uses graph convolutional operations to aggregate neighbor information and update node embeddings, then uses MLPs to decide replication and weight assignment based on these embeddings.
- Core assumption: The learned embedding space can capture meaningful patterns that distinguish when and how to grow the network.
- Evidence anchors:
  - [section] "The N DP architecture consists of a Multilayer Perceptron (MLP) —acting as a Graph Cellular Automata (GNCA)— which updates the node embeddings after each message-passing step during the developmental phase."
  - [section] "Similarly to how most cells in biological organisms contain the same program in the form of DNA, each node's growth and the synaptic weights are controlled by a copy of the same N DP"
  - [corpus] Weak evidence - related work on HyperNCA and cellular automata exists but doesn't directly support this specific graph neural network approach.
- Break condition: If the graph convolutions cannot effectively capture the necessary structural information, or if the MLP heads cannot learn meaningful growth policies from the embedding space.

### Mechanism 3
- Claim: Evolutionary and gradient-based optimization can discover effective developmental programs.
- Mechanism: The NDP parameters can be optimized through either evolutionary strategies (like CMA-ES) or gradient descent, allowing discovery of growth rules that produce task-performing networks.
- Core assumption: The search space of NDP parameterizations is rich enough to contain solutions that can grow effective networks for various tasks.
- Evidence anchors:
  - [section] "The N DP's neural networks can be trained with any black-box optimization algorithm to satisfy any objective function. In this paper, we demonstrate how the approach allows to grow neural networks capable of solving reinforcement learning and classification tasks"
  - [section] "While indirect genome-to-phenotype encodings such as CPPN-based approaches... have had great success, they often purposely abstracted away development"
  - [corpus] No direct supporting evidence in corpus; related work on HyperNEAT and Hypernetworks exists but uses different mechanisms.
- Break condition: If the optimization landscape is too rugged or contains many local optima, preventing discovery of effective growth rules.

## Foundational Learning

- Concept: Graph neural networks and message passing
  - Why needed here: The NDP operates on graph-structured data where each neuron is a node, requiring understanding of how to propagate and aggregate information across the network topology.
  - Quick check question: Can you explain how a single graph convolution step updates node embeddings based on their neighbors?

- Concept: Reinforcement learning and policy networks
  - Why needed here: The grown networks serve as policy networks for RL tasks, requiring understanding of how neural networks can map observations to actions.
  - Quick check question: What's the difference between the actor and critic components in PPO, and how might each be represented in the grown network?

- Concept: Evolutionary algorithms and black-box optimization
  - Why needed here: The evolutionary version of NDP requires understanding of population-based search methods that don't require gradient information.
  - Quick check question: How does CMA-ES adapt its search distribution during optimization, and why is this useful for neural architecture search?

## Architecture Onboarding

- Component map: Node state vectors -> Graph convolution layer -> Replication MLP -> New node creation -> Edge weight assignment MLP -> Network evaluation -> NDP parameter update

- Critical path: Node embedding update → Replication decision → New node creation → Edge weight assignment → Network evaluation → NDP parameter update

- Design tradeoffs:
  - Embedding dimension vs. parameter efficiency: Higher dimensions capture more information but increase computational cost
  - Number of growth steps vs. network complexity: More steps allow larger networks but may lead to overfitting
  - Evolutionary vs. gradient-based optimization: Evolutionary methods are more flexible but sample-inefficient; gradient methods are faster but require differentiability

- Failure signatures:
  - NDP learns to always replicate or never replicate, creating degenerate networks
  - Network grows but fails to connect input/output nodes properly
  - Gradient-based version fails to converge due to non-differentiable operations
  - Performance degrades as network grows larger, suggesting overfitting

- First 3 experiments:
  1. Implement XOR gate growth from single node to verify basic replication mechanism works
  2. Grow a simple feedforward network for CartPole with fixed number of growth steps
  3. Compare evolutionary vs. gradient-based optimization on LunarLander with varying growth step limits

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between the number of developmental steps and the resulting network size for achieving the best task performance?
- Basis in paper: [explicit] The paper mentions that "after a certain number of growth steps, the grown network's performance can deteriorate" and that "growing larger policy networks than necessary for the tasks can have detrimental effects."
- Why unresolved: The paper does not provide a clear method for determining the optimal number of growth steps or network size for a given task. It only suggests that this is an important area for future work.
- What evidence would resolve it: Experiments systematically varying the number of growth steps and measuring task performance to identify the optimal point where additional growth no longer improves performance.

### Open Question 2
- Question: How does incorporating activity-dependent growth affect the performance and adaptability of neural developmental programs?
- Basis in paper: [explicit] The authors state that the current NDP version "does not include any activity-dependent growth" and mention that "biologically nervous systems often rely on both activity and activity-independent growth."
- Why unresolved: The paper only explores growth based on local information and does not investigate how incorporating activity-dependent mechanisms might improve the system's ability to adapt to its environment.
- What evidence would resolve it: Implementing and testing NDPs with activity-dependent growth mechanisms in various environments and comparing their performance to the current approach.

### Open Question 3
- Question: Can neural developmental programs be extended to more complex domains beyond the simple control and classification tasks explored in this paper?
- Basis in paper: [explicit] The authors state that "many future work directions remain to be explored" and that they will "extend the approach to more complex domains."
- Why unresolved: The paper only demonstrates the feasibility of NDPs on relatively simple tasks like XOR classification, CartPole, LunarLander, and MNIST. It does not show how well the approach scales to more challenging problems.
- What evidence would resolve it: Applying NDPs to complex domains such as large-scale reinforcement learning tasks, natural language processing, or computer vision problems and evaluating their performance relative to state-of-the-art methods.

## Limitations
- Performance lags behind established methods (evolutionary NDP scores 131 on CartPole vs. PPO baseline of 500+)
- Limited empirical validation of topological properties and biological plausibility claims
- Minimal baseline comparisons, particularly for MNIST experiments

## Confidence
- **High confidence**: The basic mechanism of local communication between neurons for network growth is well-specified and implementable
- **Medium confidence**: The feasibility of growing networks for simple tasks (XOR, CartPole) is demonstrated, though performance is suboptimal
- **Low confidence**: Claims about topological properties (small-worldness) and biological plausibility lack rigorous validation

## Next Checks
1. **Performance benchmarking**: Implement and compare against established methods (PPO for RL tasks, standard MLP training for MNIST) with proper hyperparameter tuning to establish baseline performance levels.

2. **Scalability testing**: Evaluate NDP growth on progressively larger networks and more complex tasks to identify breaking points where local communication becomes insufficient for coherent network development.

3. **Ablation studies**: Systematically remove components (graph convolutions, replication MLP, weight prediction) to quantify their individual contributions to successful network growth and identify critical dependencies.