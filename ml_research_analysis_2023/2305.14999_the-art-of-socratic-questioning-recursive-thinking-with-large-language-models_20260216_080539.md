---
ver: rpa2
title: 'The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models'
arxiv_id: '2305.14999'
source_url: https://arxiv.org/abs/2305.14999
tags:
- question
- answer
- image
- visual
- questioning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents SOCRATIC QUESTIONING, a novel algorithm that
  mimics the human recursive thinking process for complex reasoning tasks. Unlike
  chain-of-thought prompting, which generates intermediate steps in a single pass,
  SOCRATIC QUESTIONING recursively breaks down a problem into simpler sub-problems
  and aggregates their solutions to resolve the original problem.
---

# The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models

## Quick Facts
- arXiv ID: 2305.14999
- Source URL: https://arxiv.org/abs/2305.14999
- Reference count: 34
- Key outcome: SOCRATIC QUESTIONING algorithm significantly outperforms chain-of-thought and tree-of-thought prompting methods on zero-shot visual question answering tasks

## Executive Summary
This paper introduces SOCRATIC QUESTIONING, a novel algorithm that mimics human recursive thinking for complex reasoning tasks. Unlike traditional chain-of-thought prompting that generates intermediate steps in a single pass, this method recursively breaks down problems into simpler sub-problems, solves them independently, and aggregates the solutions. The approach uses a self-questioning module to proactively raise and answer questions related to the target problem, simulating critical thinking. Evaluated on three public visual question answering datasets, SOCRATIC QUESTIONING demonstrates significant improvements over state-of-the-art prompting methods, with qualitative analysis showing intermediate reasoning steps that resemble human recursive thinking processes.

## Method Summary
SOCRATIC QUESTIONING implements a recursive divide-and-conquer algorithm that decomposes complex visual reasoning tasks into simpler sub-problems. The method employs a SELF-QUESTIONING module that generates factual and visual questions to acquire additional context, answers them using external knowledge sources and visual models, and aggregates the solutions. The framework combines multimodal reasoning (using BLIP-2 for image understanding and GPT-3 for reasoning) with external knowledge retrieval. Unlike chain-of-thought's greedy single-pass approach, this method explicitly navigates the thinking space through recursive decomposition, allowing for error correction and more robust reasoning. The algorithm operates by raising sub-questions, answering them, and using the collected information to resolve the original problem through iterative refinement.

## Key Results
- SOCRATIC QUESTIONING significantly outperforms chain-of-thought and tree-of-thought prompting on VQA-V2, OK-VQA, and AOK-VQA datasets
- The method achieves higher accuracy on knowledge-demanding tasks requiring external reasoning capabilities
- Qualitative analysis shows intermediate reasoning steps that resemble human recursive thinking processes

## Why This Works (Mechanism)

### Mechanism 1: Recursive decomposition improves reasoning by allowing models to correct early errors
The SOCRATIC QUESTIONING framework breaks down complex problems into simpler sub-problems, solves them recursively, and aggregates the solutions. This contrasts with Chain-of-Thought's greedy, single-pass approach where errors accumulate. The method explicitly navigates the thinking space, stimulating effective recursive thinking and demonstrating more robustness towards errors in the thinking process.

### Mechanism 2: Self-questioning drives targeted information gathering for visual reasoning
The SELF-QUESTIONING module proactively generates factual and visual questions to acquire additional context needed to answer the main question. This targets specific information gaps rather than relying on generic image captions, allowing the model to seek potentially helpful hints and perform recursive reasoning on the collected information before predicting the final answer.

### Mechanism 3: Combining multimodal reasoning with external knowledge improves answer accuracy
The method combines visual perception (BLIP-2 for image captioning) with language-based reasoning and knowledge retrieval (GPT-3). This multimodal approach is particularly effective for visual questions that require both image understanding and external knowledge, outperforming single-modality approaches on datasets requiring more outside knowledge and reasoning capability.

## Foundational Learning

- **Concept: Recursive problem decomposition**
  - Why needed here: Allows the model to break complex problems into manageable sub-problems and solve them independently
  - Quick check question: Can you explain how the divide-and-conquer approach differs from a sequential chain-of-thought process?

- **Concept: Self-questioning for information gathering**
  - Why needed here: Enables the model to proactively identify and acquire missing information rather than relying on pre-existing knowledge
  - Quick check question: What types of questions should the SELF-QUESTIONING module generate to be most effective?

- **Concept: Multimodal reasoning combining vision and language**
  - Why needed here: Visual questions often require both image understanding and external knowledge that language models can provide
  - Quick check question: How does the MR module transform visual information into a format that language models can process?

## Architecture Onboarding

- **Component map**: Question → SELF-QUESTIONING → MR/FQG/VQG → Answer/Hints → Recursive call or final answer
- **Critical path**: The main flow goes from the original question through the self-questioning module, which generates sub-questions answered by factual and visual question modules, then combines this information through multimodal reasoning to produce either a final answer or hints for the next recursion level
- **Design tradeoffs**: Tradeoff between depth of recursion (more detailed reasoning) versus computational cost and potential for error propagation
- **Failure signatures**: Failure to generate useful sub-questions, inability to answer sub-questions correctly, or incorrect aggregation of sub-solutions
- **First 3 experiments**:
  1. Test SELF-QUESTIONING module independently with a simple visual question to verify it can generate relevant sub-questions
  2. Test MR module with a question that requires both image understanding and external knowledge
  3. Run a complete SOCRATIC QUESTIONING instance on a simple visual question and verify the recursive reasoning process works as expected

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SOCRATIC QUESTIONING scale with the depth and turn parameters?
- Basis in paper: The paper mentions using depth and turn parameters in the SOCRATIC QUESTIONING algorithm but does not provide a detailed analysis of their impact on performance
- Why unresolved: The paper does not provide an ablation study or sensitivity analysis on these parameters, leaving their optimal values and impact on performance unclear
- What evidence would resolve it: An ablation study varying depth and turn parameters while measuring performance on the benchmark datasets would clarify their impact

### Open Question 2
- Question: How does SOCRATIC QUESTIONING perform on tasks beyond visual question answering, such as text-only reasoning or multimodal tasks with more complex inputs?
- Basis in paper: The paper focuses on visual question answering as a case study but does not explore other task types or more complex multimodal inputs
- Why unresolved: The method's generalizability to other tasks and input modalities is not explored, limiting understanding of its broader applicability
- What evidence would resolve it: Applying SOCRATIC QUESTIONING to diverse tasks (e.g., text reasoning, video understanding) and multimodal inputs would demonstrate its versatility

### Open Question 3
- Question: How does the choice of visual perception model (e.g., BLIP-2) affect the performance of SOCRATIC QUESTIONING?
- Basis in paper: The paper uses BLIP-2 as the visual perception model but does not compare it with other models or analyze its impact on performance
- Why unresolved: The performance contribution of the visual perception model is not isolated, making it unclear how critical this choice is to the overall method
- What evidence would resolve it: Comparing SOCRATIC QUESTIONING with different visual models (e.g., CLIP, Flamingo) would quantify the impact of this component on performance

## Limitations

- Performance improvements are measured against strong baselines using only accuracy metrics without ablation studies to isolate individual component contributions
- The effectiveness of the SELF-QUESTIONING module relies heavily on quality of generated sub-questions, but limited evidence shows these questions meaningfully improve reasoning versus simply increasing token count
- The recursive aggregation mechanism's claimed robustness to errors is not systematically validated through controlled experiments with intentionally corrupted intermediate steps

## Confidence

**High confidence**: The architectural framework and general methodology of recursive decomposition are clearly described and logically sound. The paper provides sufficient detail to understand how SOCRATIC QUESTIONING differs from existing prompting methods and why recursive thinking could be beneficial for complex reasoning tasks.

**Medium confidence**: The quantitative results showing performance improvements over baselines are credible given the rigorous dataset filtering to prevent data leakage. However, the lack of statistical significance testing and comparison to additional prompting strategies (like ReAct or Reflexion) limits confidence in the magnitude of improvements.

**Low confidence**: The qualitative analysis claiming that intermediate reasoning steps "resemble the human recursive thinking process" is subjective and not systematically evaluated. Without human evaluation studies or detailed examples showing clear superiority over baseline methods, this claim remains weakly supported.

## Next Checks

1. **Ablation study validation**: Remove the SELF-QUESTIONING module and run SOCRATIC QUESTIONING with only the MR module to quantify the specific contribution of recursive sub-questioning versus direct multimodal reasoning.

2. **Error propagation analysis**: Systematically introduce errors at different recursion depths and measure how these errors affect final answer accuracy compared to baseline methods, directly testing the claimed robustness advantage.

3. **Human evaluation study**: Recruit human annotators to rate the quality and relevance of intermediate reasoning steps generated by SOCRATIC QUESTIONING versus Chain-of-Thought, measuring whether the recursive steps demonstrate more sophisticated reasoning patterns.