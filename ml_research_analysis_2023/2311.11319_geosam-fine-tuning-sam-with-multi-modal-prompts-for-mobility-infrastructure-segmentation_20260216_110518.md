---
ver: rpa2
title: 'GeoSAM: Fine-tuning SAM with Multi-Modal Prompts for Mobility Infrastructure
  Segmentation'
arxiv_id: '2311.11319'
source_url: https://arxiv.org/abs/2311.11319
tags:
- segmentation
- prompts
- arxiv
- image
- geographical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "GeoSAM introduces a fine-tuning approach for the Segment Anything\
  \ Model (SAM) to enhance mobility infrastructure segmentation in geographical images,\
  \ such as roads, sidewalks, and crosswalks. The method combines sparse prompts from\
  \ a pre-trained CNN and dense prompts generated by zero-shot SAM, improving SAM\u2019\
  s ability to handle the narrow features and similar textures of these objects."
---

# GeoSAM: Fine-tuning SAM with Multi-Modal Prompts for Mobility Infrastructure Segmentation

## Quick Facts
- arXiv ID: 2311.11319
- Source URL: https://arxiv.org/abs/2311.11319
- Reference count: 40
- One-line primary result: GeoSAM fine-tunes SAM with multi-modal prompts for improved mobility infrastructure segmentation, achieving at least 5% improvement in mean IoU.

## Executive Summary
GeoSAM introduces a fine-tuning approach for the Segment Anything Model (SAM) to enhance mobility infrastructure segmentation in geographical images, such as roads, sidewalks, and crosswalks. The method combines sparse prompts from a pre-trained CNN and dense prompts generated by zero-shot SAM, improving SAM’s ability to handle the narrow features and similar textures of these objects. GeoSAM outperforms existing approaches, achieving at least a 5% improvement in mean IoU for segmenting mobility infrastructure in both familiar and unseen regions. The approach demonstrates a significant leap in leveraging foundation models for geographical image segmentation tasks.

## Method Summary
GeoSAM fine-tunes SAM using Parameter Efficient Fine-Tuning (PEFT) techniques with both sparse prompts (generated from a pre-trained CNN encoder) and dense prompts (generated by zero-shot SAM). The sparse prompts provide precise location context for thin structures, while dense prompts add semantic context. The fine-tuning process uses Dice Focal Loss and keeps the encoder parameters frozen while updating the decoder parameters. Post-processing with morphological operations refines the segmentation maps for practical use.

## Key Results
- GeoSAM outperforms existing approaches in mobility infrastructure segmentation, achieving at least a 5% improvement in mean IoU.
- The method demonstrates strong performance in both familiar and unseen geographical regions.
- GeoSAM effectively segments narrow features like roads and sidewalks, which are challenging for traditional segmentation models.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning SAM with both sparse and dense prompts improves segmentation of narrow geographical objects.
- Mechanism: Sparse prompts from a pre-trained CNN provide precise location context for thin structures, while dense prompts from zero-shot SAM add semantic context. Together, they guide SAM's mask decoder to focus on both spatial structure and object boundaries.
- Core assumption: SAM's original zero-shot performance fails on narrow, texture-similar objects, but can be improved with task-specific contextual prompts.
- Evidence anchors:
  - [abstract] "GeoSAM integrates point prompts from a pre-trained task-specific model as primary visual guidance, and text prompts generated by a large language model as secondary semantic guidance"
  - [section] "sparse prompts generated by a domain-specific CNN encoder and complement them with dense prompts produced by zero-shot SAM"
  - [corpus] Weak/no direct evidence in neighbors; inferred from abstract claim.
- Break condition: If the CNN encoder cannot reliably detect the narrow object boundaries, sparse prompts will be inaccurate, reducing fine-tuning effectiveness.

### Mechanism 2
- Claim: Parameter-efficient fine-tuning (PEFT) of SAM's decoder retains the strong visual backbone while adapting only the mask decoder for the new domain.
- Mechanism: Freezing the image and prompt encoders preserves the learned feature representations from natural images, while fine-tuning the lightweight decoder adapts it to the geographical image context using the combined sparse and dense prompts.
- Core assumption: The visual features learned on natural images transfer sufficiently to geographical images when guided by domain-specific prompts.
- Evidence anchors:
  - [section] "we didn't make any modifications to the model's parameters before this point, following the PEFT strategy"
  - [section] "we keep the parameters of the encoder part (both image and prompt encoder) frozen and only update the gradients of the decoder"
  - [corpus] No direct evidence; inferred from PEFT discussion in abstract and section.
- Break condition: If the domain gap is too large, even PEFT on the decoder may not overcome the mismatch in visual features.

### Mechanism 3
- Claim: Post-processing with morphological operations refines segmentation maps for practical use by connecting fragmented paths and removing isolated noise.
- Mechanism: Erosion removes isolated small regions that likely represent false positives, and dilation connects broken segments of paths, improving the usability of the output for infrastructure mapping.
- Core assumption: The initial segmentation maps contain fragmented paths and isolated noise pixels that can be corrected with simple morphological operations.
- Evidence anchors:
  - [section] "techniques such as morphological erosion and dilation [44] are utilized to enhance performance"
  - [section] "We employ an erosion technique to eliminate such isolated regions. Additionally, when the segmentation map displays abrupt interruptions or gaps in connected paths, it indicates failure in accurately segmenting the entire path. Therefore, we utilize dilation to address these issues"
  - [corpus] No direct evidence; inferred from postprocessing discussion in section.
- Break condition: If the initial segmentation is too noisy or fragmented, morphological operations may oversmooth or distort the true object boundaries.

## Foundational Learning

- Concept: Vision foundation models and transfer learning
  - Why needed here: Understanding how SAM was pre-trained on natural images and how its parameters can be adapted (via PEFT) to a new domain (geographical images) is crucial for grasping why GeoSAM works.
  - Quick check question: What is the main advantage of using PEFT over full fine-tuning when adapting a large vision foundation model?

- Concept: Semantic segmentation and evaluation metrics
  - Why needed here: The task is binary segmentation of infrastructure, and performance is measured using IoU. Knowing how segmentation models work and how IoU is calculated is essential for interpreting results.
  - Quick check question: How is the Intersection over Union (IoU) metric calculated for a binary segmentation task?

- Concept: Multi-modal prompting and prompt engineering
  - Why needed here: GeoSAM uses both sparse (point) prompts from a CNN and dense (mask) prompts from zero-shot SAM. Understanding how different types of prompts guide the segmentation model is key to understanding the architecture.
  - Quick check question: What is the difference between sparse and dense prompts in the context of SAM, and how do they each contribute to segmentation?

## Architecture Onboarding

- Component map: Geographical image → CNN Encoder → Sparse prompts → SAM Zero-shot (with CNN features) → Dense prompts → SAM Fine-tuned Decoder → Post-processing → Output

- Critical path: Geographical image → CNN Encoder → Sparse prompts → SAM Zero-shot (with CNN features) → Dense prompts → SAM Fine-tuned Decoder → Post-processing → Output

- Design tradeoffs:
  - Using a pre-trained CNN limits the approach to domains where such a model exists, but enables automated prompt generation without human intervention.
  - PEFT reduces computational cost and memory usage compared to full fine-tuning, but may limit adaptation if the domain gap is large.
  - Morphological post-processing improves usability but may introduce artifacts if overapplied.

- Failure signatures:
  - Poor IoU scores: Indicates the fine-tuned decoder is not learning the task effectively, possibly due to inadequate prompts or insufficient fine-tuning.
  - Fragmented segmentation maps: Suggests the model struggles with thin or connected structures, which post-processing may not fully correct.
  - Over-segmentation or under-segmentation: Could indicate issues with the balance of sparse and dense prompts or the loss function.

- First 3 experiments:
  1. Ablation study: Run GeoSAM without sparse prompts, without dense prompts, and without fine-tuning to quantify the contribution of each component.
  2. Hyperparameter tuning: Experiment with different ratios of foreground/background points in sparse prompts and different numbers of iterations for morphological operations.
  3. Generalization test: Apply the fine-tuned GeoSAM model to a completely new geographical region (not seen during training) to assess cross-location performance.

## Open Questions the Paper Calls Out
- Question: How does GeoSAM perform when applied to geographical imagery from regions with significantly different landscapes (e.g., rural vs. urban) compared to the training data?
  - Basis in paper: [explicit] The paper highlights that GeoSAM outperforms existing approaches in both familiar and unseen regions, suggesting potential for broader generalization.
  - Why unresolved: The experiments focus on Washington DC, and the paper does not explore performance across diverse geographical contexts.
  - What evidence would resolve it: Testing GeoSAM on imagery from varied regions with different infrastructure and environmental conditions.

- Question: What is the impact of varying the ratio of sparse prompts (foreground to background points) on GeoSAM’s segmentation accuracy for mobility infrastructure?
  - Basis in paper: [explicit] The paper includes an ablation study on the number of sparse prompts but does not exhaustively test all possible ratios.
  - Why unresolved: The optimal ratio (2:1) was identified empirically, but other configurations may yield different results.
  - What evidence would resolve it: Systematic testing of various ratios and their effect on segmentation performance.

- Question: Can GeoSAM’s architecture be adapted for other types of segmentation tasks beyond mobility infrastructure, such as land cover classification or object detection in geographical imagery?
  - Basis in paper: [inferred] The paper discusses the potential transferability of the GeoSAM pipeline to other geo-locations and tasks.
  - Why unresolved: The experiments are limited to mobility infrastructure segmentation, and the adaptability to other tasks is not demonstrated.
  - What evidence would resolve it: Applying GeoSAM to different segmentation tasks and evaluating its performance.

## Limitations
- The effectiveness of GeoSAM hinges on the quality of the pre-trained CNN encoder for generating sparse prompts. If the CNN cannot reliably detect narrow infrastructure boundaries, the sparse prompts will be inaccurate, limiting the fine-tuning effectiveness.
- The cross-location generalization claim is based on testing in "unseen regions" but lacks detail on how different these regions are from the training data. Without quantifying the domain shift between locations, it's unclear whether the performance gain generalizes to truly novel environments or is due to similar underlying patterns in the test regions.
- The choice of morphological operations for post-processing is heuristic and may introduce artifacts if overapplied, particularly for complex geographical scenes with variable object scales.

## Confidence
- **High Confidence**: The mechanism of using PEFT to adapt SAM's decoder while freezing the encoder is well-established in the literature and aligns with standard transfer learning practices. The improvement in IoU metrics over baseline methods is directly reported and verifiable.
- **Medium Confidence**: The combined use of sparse and dense prompts as a mechanism for improving narrow object segmentation is logically sound and supported by the described architecture. However, the relative contribution of each prompt type is not quantified through ablation studies.
- **Low Confidence**: The claim of "at least 5% improvement in mean IoU" is specific but lacks context on the baseline methods compared and the statistical significance of the improvement. The post-processing step's impact on the final usable output is also not rigorously evaluated.

## Next Checks
1. **Ablation Study on Prompt Types**: Conduct experiments removing sparse prompts, dense prompts, and both, to quantify their individual and combined contributions to segmentation performance. This will validate the core hypothesis of Mechanism 1.

2. **Domain Shift Analysis**: Systematically test GeoSAM on geographical images from regions with significantly different characteristics (e.g., urban vs. rural, different countries) to quantify the cross-location generalization performance and identify failure modes related to domain adaptation.

3. **Post-processing Impact Evaluation**: Compare segmentation metrics and usability (e.g., path connectivity, noise reduction) with and without morphological operations on a held-out validation set. This will assess the practical benefit and potential drawbacks of the heuristic post-processing step.