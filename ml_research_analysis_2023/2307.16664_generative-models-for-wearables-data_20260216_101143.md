---
ver: rpa2
title: Generative models for wearables data
arxiv_id: '2307.16664'
source_url: https://arxiv.org/abs/2307.16664
tags:
- data
- generated
- real
- training
- sequences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses data scarcity in medical research by developing
  a generative model for wearable activity data. The authors propose a multi-task
  self-attention model trained on FitBit data from 10,000 individuals, capturing resting
  heart rate, sleep minutes, and step counts.
---

# Generative models for wearables data

## Quick Facts
- arXiv ID: 2307.16664
- Source URL: https://arxiv.org/abs/2307.16664
- Reference count: 16
- Primary result: Transformer-based generative model produces synthetic wearable activity data with high realism (MAE 1.21 BPM for heart rate) for medical research applications

## Executive Summary
This paper addresses data scarcity in medical research by developing a generative model for wearable activity data. The authors propose a multi-task self-attention model trained on FitBit data from 10,000 individuals, capturing resting heart rate, sleep minutes, and step counts. The model uses transformer-based architecture with causal masking for autoregressive generation, producing synthetic sequences that visually and statistically match genuine activity patterns. Quantitative evaluation shows the model achieves high realism with mean absolute error of 1.21 BPM for heart rate prediction and similarity scores close to real data benchmarks.

## Method Summary
The model processes 21-day sequences of wearable activity data (resting heart rate, sleep minutes, step counts) from FitBit users. Continuous values are discretized into 100 bins and converted to one-hot encodings for softmax output. A transformer decoder-only architecture with 3 layers, 4 attention heads, and 64-dimensional embeddings processes the sequences using causal masking to prevent future information leakage. Multi-task learning is implemented with shake-shake regularization, where losses for each modality are combined using stochastic affine combinations. Generation is performed autoregressively by recursively predicting and appending next-day values with temperature scaling.

## Key Results
- Mean absolute error of 1.21 BPM for heart rate prediction
- Cosine similarity of 0.810 and DTW distance of 29,028 between generated and real data
- Generated sequences visually and statistically match genuine activity patterns
- High realism achieved across all three modalities (heart rate, sleep, steps)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causal masking in the transformer ensures autoregressive generation without future leakage.
- Mechanism: The upper-right triangle of the attention weight matrix is masked so each position can only attend to previous positions or itself, preventing the model from seeing future time steps during training.
- Core assumption: The sequence ordering is preserved and the causal mask is correctly applied to all attention heads.
- Evidence anchors:
  - [abstract] "The model uses transformer-based architecture with causal masking for autoregressive generation."
  - [section] "As this is an auto-regressive task, we ensure future information is not used by causal masking, i.e. confining each position to previous positions or the current position. This is implemented by masking the upper-right triangle of the attention weight-matrix."
  - [corpus] Weak: No direct evidence from neighbors, but causal masking is a standard transformer technique mentioned in general ML literature.
- Break condition: If the causal mask is omitted or incorrectly applied, the model could "cheat" by peeking at future values, breaking autoregressive generation.

### Mechanism 2
- Claim: Joint multi-task learning with shake-shake regularization improves accuracy across all three modalities.
- Mechanism: Separate feed-forward heads produce softmax distributions for heart rate, steps, and sleep; losses are combined using a stochastic affine combination (α vector) so the model learns correlated patterns across tasks simultaneously.
- Core assumption: The three tasks share enough underlying structure to benefit from joint training rather than being learned independently.
- Evidence anchors:
  - [abstract] "The model uses transformer-based architecture with causal masking for autoregressive generation. Quantitative evaluation shows the model achieves high realism: mean absolute error of 1.21 BPM for heart rate prediction..."
  - [section] "The combined loss which we minimize is then defined as Lcombined = Σ αi Li where α is a random vector of unit length and Li are individual losses."
  - [corpus] Weak: No neighbor papers directly discuss shake-shake regularization in multi-task generative models.
- Break condition: If tasks are too unrelated, joint training could confuse the model and degrade performance.

### Mechanism 3
- Claim: Converting continuous labels to 100-bin one-hot softmax distributions allows the model to learn arbitrary distributions without shape assumptions.
- Mechanism: Instead of regressing continuous values directly, each feature is discretized into 100 bins, enabling a softmax output and cross-entropy loss, which is more compatible with neural networks.
- Core assumption: The discretization into 100 bins preserves enough granularity for downstream realism.
- Evidence anchors:
  - [abstract] "The model uses transformer-based architecture with causal masking for autoregressive generation. Quantitative evaluation shows the model achieves high realism: mean absolute error of 1.21 BPM for heart rate prediction..."
  - [section] "Although the labels are continuous values, we convert them to a one-hot encoding of 100 evenly-spaced bins. We do this to model the outputs as a softmax distribution."
  - [corpus] Weak: Neighbors do not mention discretization or softmax approaches for continuous wearables data.
- Break condition: If bins are too coarse, generated values may lose important variation; if too fine, training becomes unstable.

## Foundational Learning

- Concept: Transformer decoder-only architecture
  - Why needed here: Enables autoregressive generation of time-series where each prediction depends on all previous steps.
  - Quick check question: What part of the transformer is omitted to ensure no future information leaks into predictions?

- Concept: Cross-entropy loss with softmax outputs
  - Why needed here: Discretized labels require a probabilistic output distribution; cross-entropy is standard for classification tasks.
  - Quick check question: Why use cross-entropy instead of MSE when labels are converted to one-hot bins?

- Concept: Causal masking in attention
  - Why needed here: Prevents the model from "cheating" by attending to future time steps during training.
  - Quick check question: How is the causal mask implemented in the attention matrix?

## Architecture Onboarding

- Component map: Input embeddings (64-dim) → Positional encodings → Transformer decoder stack (3 layers, 4 heads) → Task-specific heads (3×100 softmax) → Loss (shake-shake + cross-entropy)
- Critical path: Embedding → Transformer → Output heads → Loss calculation → Backpropagation
- Design tradeoffs:
  - Shorter sequences (21 days) vs. diversity of samples vs. long-term trend capture
  - 100-bin discretization vs. granularity vs. training stability
  - Joint multi-task learning vs. task interference
- Failure signatures:
  - If causal masking is broken: generated sequences look unrealistically accurate for future steps
  - If discretization is too coarse: generated values cluster in large jumps, losing nuance
  - If multi-task joint learning fails: one modality's accuracy degrades while others improve
- First 3 experiments:
  1. Train with causal mask removed to confirm autoregressive property is essential
  2. Vary number of bins (e.g., 50, 200) to see effect on realism and training stability
  3. Train separate single-task models vs. joint multi-task to quantify shake-shake benefit

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of this generative model scale with larger datasets and more parameters, and what is the optimal trade-off between model size and data requirements?
- Basis in paper: [inferred] The paper notes that transformers typically excel with enormous amounts of data and more parameters, and mentions that "more training data will allow us to scale up the model size even further with evidence from other domains suggesting that scale and parameter count is a powerful tool for learning richer representations."
- Why unresolved: The current model was trained on a relatively small dataset (2 million days), and the authors suggest that larger datasets and more parameters could potentially improve performance. However, they do not provide specific results or analysis on how scaling affects the model's performance.
- What evidence would resolve it: Experimental results showing the performance of the model when trained on increasingly larger datasets and with varying numbers of parameters, along with an analysis of the trade-offs between model size and data requirements.

### Open Question 2
- Question: Can the model be adapted to generate synthetic wearable data that is conditional on specific characteristics such as age, physical fitness, or medical conditions?
- Basis in paper: [explicit] The authors state that "a slight modification to the architecture and learning process can make the model conditional, in a process similar to text-conditional image generation," and mention that "a researcher designing a study on insomnia should be able to query that ideal interactive generator for 1 000 participants aged 20-66, have BMI 22-30 and half of whom sleep less than 5 hours per night."
- Why unresolved: While the authors propose this as a future research direction, they do not provide any experimental results or analysis on how to implement or evaluate such a conditional generator.
- What evidence would resolve it: Implementation of a conditional version of the model, along with experiments demonstrating its ability to generate synthetic wearable data that accurately represents specific characteristics or conditions.

### Open Question 3
- Question: How can the generated synthetic wearable data be evaluated for privacy preservation and potential information leakage from the training data?
- Basis in paper: [explicit] The authors mention that "recent reports have highlighted the risks involving authorship" and note that "future work should focus on giving provable privacy guarantees on the generated sequences, preventing individual information from the training data to be leaked in the generated sequences."
- Why unresolved: The paper does not provide any specific methods or analysis for evaluating the privacy preservation of the generated data or detecting potential information leakage.
- What evidence would resolve it: Development and application of privacy-preserving techniques, such as differential privacy or membership inference attacks, to evaluate the generated synthetic wearable data for potential information leakage from the training data.

## Limitations

- The evaluation focuses on statistical similarity metrics rather than downstream task performance, leaving unclear whether synthetic datasets would actually improve medical research outcomes
- Shake-shake regularization technique lacks comparison against simpler multi-task baselines to establish its necessity
- Sensitivity to discretization granularity (100 bins) and potential information loss is not explored

## Confidence

- **High confidence**: The transformer architecture with causal masking for autoregressive generation is well-established and correctly implemented based on the description. The 1.21 BPM MAE for heart rate prediction is a specific, measurable claim with clear methodology.
- **Medium confidence**: The multi-task learning framework with shake-shake regularization likely provides benefits, but the exact magnitude and necessity relative to simpler approaches remains uncertain without ablation studies.
- **Low confidence**: The practical utility of generated data for actual medical research applications is unproven - the paper demonstrates statistical similarity but not functional equivalence in downstream analyses.

## Next Checks

1. **Ablation study on discretization granularity**: Systematically vary the number of bins (25, 50, 100, 200) and measure the impact on generation quality, training stability, and downstream task performance to determine optimal discretization strategy.

2. **Multi-task vs. single-task comparison**: Train separate models for each modality (resting heart rate, sleep, steps) and compare against the joint multi-task model using identical architectures and training procedures to quantify the actual benefit of shake-shake regularization.

3. **Downstream task validation**: Use generated datasets in representative medical research workflows (e.g., predictive modeling, population health analysis) and compare results against analyses using real data to verify that statistical similarity translates to functional equivalence.