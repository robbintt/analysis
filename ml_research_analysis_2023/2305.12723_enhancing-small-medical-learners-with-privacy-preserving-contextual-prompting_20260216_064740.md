---
ver: rpa2
title: Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting
arxiv_id: '2305.12723'
source_url: https://arxiv.org/abs/2305.12723
tags:
- medical
- context
- keywords
- question
- candidate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces a method that leverages large language models\
  \ (LLMs) to enhance the performance of small language models (SLMs) in medical tasks\
  \ under privacy restrictions. The method extracts keywords from medical data and\
  \ uses them to prompt LLMs to generate privacy-preserving medical contexts that\
  \ simulate clinicians\u2019 thought processes."
---

# Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting

## Quick Facts
- arXiv ID: 2305.12723
- Source URL: https://arxiv.org/abs/2305.12723
- Reference count: 40
- Key outcome: Method using LLM-generated contexts significantly outperforms standard SLM fine-tuning, achieving up to 22.57% accuracy improvement on medical tasks while preserving privacy

## Executive Summary
This paper introduces a novel approach to enhance small language models (SLMs) for medical tasks while preserving patient privacy. The method extracts keywords from medical data using named entity recognition (NER), then uses these keywords to prompt large language models (LLMs) to generate privacy-preserving medical contexts that simulate clinician thought processes. These contexts serve as additional input to SLMs during training, significantly improving their decision-making capabilities without requiring full access to sensitive patient data.

The approach demonstrates strong performance gains, achieving state-of-the-art results in two medical tasks and showing robust generalizability to out-of-domain settings. By carefully controlling the privacy budget through keyword extraction, the method balances privacy preservation with model performance, addressing a critical challenge in medical AI applications where data privacy is paramount.

## Method Summary
The method extracts keywords from medical data using NER models, then prompts an LLM with these keywords and candidate answers to generate privacy-preserving medical contexts through in-context learning. These contexts are integrated into SLMs during training, augmenting their decision-making capabilities. The approach uses BioLinkBERT and BioMedLM as SLM backbones, fine-tuned with the generated contexts, and evaluated on medical question-answering tasks while maintaining strict privacy controls through keyword-based prompting.

## Key Results
- Achieved up to 22.57% accuracy improvement over standard SLM fine-tuning without context
- Set new state-of-the-art results in two medical tasks under privacy restrictions
- Demonstrated strong generalizability to out-of-domain settings while maintaining privacy preservation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Keywords from medical data can substitute for full patient information while retaining sufficient medical knowledge for LLMs to generate useful contexts
- Mechanism: The LLM is prompted with extracted keywords and candidate answers rather than full medical text, preserving privacy while still providing enough domain-specific information for context generation
- Core assumption: Medical domain knowledge is sufficiently encoded in LLM parameters that keyword prompts can elicit relevant medical contexts
- Evidence anchors:
  - [abstract] "we mitigate patient privacy issues by extracting keywords from medical data and prompting the LLM"
  - [section] "We use existing named-entity recognition (NER) models [24] to extract keywords, thereby mitigating privacy risks"
  - [corpus] Weak - corpus contains related privacy-preserving work but no direct evidence for keyword effectiveness
- Break condition: If keywords fail to capture essential medical concepts, the LLM cannot generate useful contexts, breaking the privacy-performance tradeoff

### Mechanism 2
- Claim: Medical contexts generated by LLMs serve as effective supplementary input for SLMs, enhancing their medical decision-making capabilities
- Mechanism: The SLM is trained with both the original question and LLM-generated contexts, allowing it to leverage medical knowledge without requiring extensive domain-specific training
- Core assumption: SLMs can effectively integrate external medical knowledge from LLM contexts into their decision-making process
- Evidence anchors:
  - [abstract] "This context serves as additional input for SLMs, augmenting their decision-making capabilities"
  - [section] "we utilize BioLinkBert-Base [11], BioLinkBert-Large [11], and BioMedLM [14] as SLM backbones for Fine-Tuning with Context (FTC)"
  - [corpus] Weak - related work exists but no direct evidence that SLM+context outperforms SLM alone
- Break condition: If the SLM cannot effectively process or utilize the LLM-generated contexts, the approach fails to improve performance

### Mechanism 3
- Claim: The privacy budget (ratio of words provided to LLM vs total words) can be minimized while maintaining performance, enabling strong privacy preservation
- Mechanism: By using only keywords instead of full text, the privacy budget is reduced, limiting information exposure while still enabling effective context generation
- Core assumption: A small fraction of keywords contains sufficient information for the LLM to generate useful medical contexts
- Evidence anchors:
  - [section] "We conduct a privacy analysis on MedQA using BioLinkBERT-Base and introduce the privacy budget"
  - [section] "Privacy Budget-Model Performance Trade-off. We analyze the trade-off between privacy budget and model performance"
  - [corpus] Weak - corpus contains privacy-preserving work but no direct evidence for privacy budget effectiveness
- Break condition: If performance drops significantly with reduced privacy budget, the approach fails to balance privacy and utility

## Foundational Learning

- Concept: Named Entity Recognition (NER)
  - Why needed here: NER is used to extract medical keywords from raw text, which are then used to prompt the LLM while preserving privacy
  - Quick check question: What is the primary purpose of using NER in this privacy-preserving approach?

- Concept: In-context learning
  - Why needed here: In-context learning allows the LLM to generate medical contexts based on a few examples of clinician-written contexts, without requiring fine-tuning
  - Quick check question: How does in-context learning enable the LLM to generate medical contexts for new instances?

- Concept: Context augmentation for SLMs
  - Why needed here: The LLM-generated contexts serve as additional input for the SLM during training, enhancing its medical decision-making capabilities
  - Quick check question: What is the role of LLM-generated contexts in the SLM training process?

## Architecture Onboarding

- Component map: Keyword Extractor → LLM (with in-context learning) → Context Generator → SLM (with context augmentation)
- Critical path: Keyword extraction → LLM prompting → Context generation → SLM training → Inference
- Design tradeoffs: Privacy preservation vs. performance, computational cost of LLM inference vs. SLM efficiency, keyword quality vs. context usefulness
- Failure signatures: Poor keyword extraction leading to irrelevant contexts, LLM generating non-medical or incorrect contexts, SLM unable to effectively utilize contexts
- First 3 experiments:
  1. Test keyword extraction quality on a small medical dataset
  2. Verify LLM can generate relevant contexts with keyword prompts and few-shot examples
  3. Evaluate SLM performance with and without LLM-generated contexts on a small task

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy of keyword extraction affect the quality of generated contexts and subsequent SLM performance?
- Basis in paper: [explicit] The paper states "We use existing named-entity recognition (NER) models [24] to extract keywords 5, thereby mitigating privacy risks" but doesn't explore variations in keyword extraction quality
- Why unresolved: The experiments use a fixed NER model for keyword extraction without comparing different extraction methods or evaluating the impact of keyword quality on performance
- What evidence would resolve it: Comparative experiments showing SLM performance using different keyword extraction methods (NER, dictionary-based, manual) or varying levels of keyword completeness/accuracy

### Open Question 2
- Question: What is the optimal size and diversity of the few-shot examples provided to the LLM for context generation?
- Basis in paper: [explicit] The paper states "We utilize the LLM with a set of human-written instances E ={(kp m, Ap m, Cp m, dp m)}M m=1 as demonstrations for in-context learning" but doesn't systematically explore different few-shot configurations
- Why unresolved: The experiments use a fixed number of demonstrations (M=5) without exploring how varying the number, diversity, or quality of examples affects context generation quality and downstream SLM performance
- What evidence would resolve it: Systematic experiments varying the number and diversity of few-shot examples while measuring context quality metrics and resulting SLM accuracy

### Open Question 3
- Question: How does the proposed method perform when applied to non-multiple-choice medical tasks?
- Basis in paper: [explicit] The paper states "While our primary focus is on multiple-choice medical QA, our framework can be adapted to other tasks or domains" but only provides experimental results for multiple-choice settings
- Why unresolved: All experiments focus exclusively on multiple-choice question answering, leaving the generalizability to other medical task formats (e.g., free-text QA, classification, generation) unexplored
- What evidence would resolve it: Experiments applying the privacy-preserving context generation approach to non-multiple-choice medical tasks like clinical note summarization, diagnosis prediction from EHRs, or medical text generation

## Limitations
- Keyword extraction quality uncertainty: The specific NER model used for keyword extraction is not specified, limiting reproducibility and potentially affecting performance
- Privacy attack surface: The privacy analysis focuses on privacy budget but doesn't address potential side-channel leaks or membership inference attacks
- Computational overhead: LLM-generated context generation for each instance may limit practical deployment in resource-constrained settings

## Confidence
- **High Confidence**: The general methodology of using LLM-generated contexts to augment SLM performance is well-supported by experimental results
- **Medium Confidence**: Privacy-preserving claims are supported by privacy budget analysis but lack robustness testing against various privacy attacks
- **Low Confidence**: Exact implementation details critical for reproduction, particularly NER model specification and prompt engineering, are not provided

## Next Checks
1. Test keyword extraction quality on a held-out validation set by measuring precision/recall of medical entity extraction and evaluating how extraction quality correlates with downstream performance

2. Manually evaluate a sample of LLM-generated contexts for medical relevance and accuracy when given keyword prompts versus full text, to quantify the information loss from the privacy-preserving approach

3. Conduct membership inference or attribute inference attacks on the system to assess whether the keyword-based approach truly provides meaningful privacy protection beyond the theoretical privacy budget metric