---
ver: rpa2
title: Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers
arxiv_id: '2310.09925'
source_url: https://arxiv.org/abs/2310.09925
tags:
- speech
- target
- word
- representations
- context
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates context mixing in speech transformers using
  a linguistic phenomenon in French where homophones like "livre" (singular) and "livres"
  (plural) must be disambiguated based on syntactic cues such as determiners. The
  authors adapt context-mixing scoring methods (Attention Norm and Value Zeroing)
  from text models to analyze how encoder-only and encoder-decoder architectures process
  spoken language.
---

# Homophone Disambiguation Reveals Patterns of Context Mixing in Speech Transformers

## Quick Facts
- arXiv ID: 2310.09925
- Source URL: https://arxiv.org/abs/2310.09925
- Reference count: 25
- Key outcome: Context mixing analysis reveals encoder-only models use middle-layer audio cues for homophone disambiguation, while encoder-decoder models delegate this task to the decoder through text prefix attention.

## Executive Summary
This paper investigates how speech transformers process contextual information by analyzing French homophones like "livre" (singular) and "livres" (plural) that must be disambiguated based on syntactic cues. The authors adapt context-mixing methods from text models to analyze attention patterns in both encoder-only and encoder-decoder architectures. Their findings reveal that encoder-only models rely on audio cue representations in middle layers to disambiguate targets, while encoder-decoder models primarily use text tokens from the prefix through decoder self-attention. Probing experiments confirm grammatical number information is encoded differently across architectures.

## Method Summary
The study extracts French utterances with homophony from the Common Voice corpus and aligns audio frames to words using forced alignment. Five off-the-shelf models (Whisper variants and XLSR models) are analyzed using context-mixing metrics including Attention Norm and Value Zeroing to quantify cue contributions across layers. The authors compare trained versus randomly initialized models to assess learned patterns, and conduct probing experiments with logistic regression classifiers to measure grammatical number encoding. Input ablation studies measure confidence drops when cue words are removed from the input.

## Key Results
- Encoder-only models show peak cue contributions in middle layers (notably layers 10, 12, and 15) for homophone disambiguation
- Encoder-decoder models delegate disambiguation to the decoder, which attends to text tokens from the prefix rather than encoded audio cues
- Probing classifiers achieve higher accuracy for grammatical number prediction in decoder representations of encoder-decoder models, while encoder models show this pattern in middle layers
- Input ablation confirms cue words significantly impact model confidence in target predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Context mixing scores reveal how speech models disambiguate homophones by attending to syntactic cues.
- Mechanism: Value Zeroing quantifies the effect of removing a cue word on target word representations, revealing which layers and components use grammatical agreement information.
- Core assumption: Target word disambiguation relies on cue word representations that encode grammatical number information.
- Evidence anchors:
  - [abstract] "Our findings reveal that representations in encoder-only models effectively incorporate these cues to identify the correct transcription, whereas encoders in encoder-decoder models mainly relegate the task of capturing contextual dependencies to decoder modules."
  - [section] "For the trained model, cue contribution scores indicate that cues are prominently integrated into the target audio representations in the middle layers (notably, at layers 10, 12 and 15)."
  - [corpus] "Found 25 related papers (using 8). Average neighbor FMR=0.387, average citations=0.0." - Weak corpus support for this specific mechanism.
- Break condition: If cue words do not encode grammatical number information, or if the model uses alternative disambiguation strategies (e.g., lexical frequency), the mechanism fails.

### Mechanism 2
- Claim: Encoder-decoder models delegate homophone disambiguation to the decoder through self-attention on text tokens.
- Mechanism: The decoder attends to written cue words in the prefix rather than encoded audio representations, capturing grammatical dependencies more directly.
- Core assumption: Text token representations provide an easier path for grammatical agreement than encoded audio cues.
- Evidence anchors:
  - [abstract] "encoders in encoder-decoder models mainly relegate the task of capturing contextual dependencies to decoder modules."
  - [section] "By comparing the cross and within-decoder alignment scores, we find that the representations in the decoder strongly capture the syntactic dependency on the cue word through the self-attention module."
  - [corpus] "Weak corpus support for this specific mechanism."
- Break condition: If the decoder fails to capture syntactic dependencies or if encoder representations are sufficient for disambiguation, the mechanism breaks.

### Mechanism 3
- Claim: Probing classifiers detect grammatical number encoding in model representations.
- Mechanism: Logistic regression classifiers trained on frozen representations predict singular/plural labels, revealing where number information is accessible.
- Core assumption: Representations that encode number information will enable accurate classification by simple models.
- Evidence anchors:
  - [section] "We conduct a probing experiment by extracting target word representations across all layers, and associating each representation with a Singular or Plural label. We then train a Logistic Regression classifier with L2 regularization on these representations to predict target grammatical number."
  - [section] "For XLSR-53 and XLSR-1 display a noticeable spike in the middle layers (notably at layer 10), the same layers for which we observed higher cue contribution scores."
  - [corpus] "Weak corpus support for this specific mechanism."
- Break condition: If number information is not linearly separable in the representations, or if the classifier learns spurious patterns, the mechanism fails.

## Foundational Learning

- Concept: Transformer attention mechanisms
  - Why needed here: Understanding how self-attention and cross-attention modules process and integrate information is crucial for interpreting context mixing scores.
  - Quick check question: How does the scaled dot-product attention formula weight the contribution of each token in the context?

- Concept: Homophony and grammatical agreement
  - Why needed here: The study relies on French homophones that require syntactic cues for disambiguation, making knowledge of number agreement essential.
  - Quick check question: In French, how do determiners and pronouns signal number agreement with nouns and verbs?

- Concept: Context mixing metrics (Attention Norm, Value Zeroing)
  - Why needed here: These methods quantify information flow in transformers, and understanding their differences is key to interpreting the results.
  - Quick check question: What is the key difference between Attention Norm and Value Zeroing in measuring context mixing?

## Architecture Onboarding

- Component map:
  Audio encoder -> Transformer layers -> CTC layer (encoder-only) or Decoder (encoder-decoder) -> Frame-word alignment

- Critical path:
  1. Extract aligned audio-transcription pairs with homophones
  2. Compute context mixing scores (Attention, AN, VZ) across layers
  3. Analyze cue contribution patterns for encoder-only vs encoder-decoder models
  4. Validate findings with probing experiments and input ablation studies

- Design tradeoffs:
  - Encoder-only: Simpler architecture, relies on audio cues in middle layers, may struggle with long-range dependencies
  - Encoder-decoder: More complex, delegates disambiguation to decoder, potentially more robust to ambiguous audio but requires text prefix

- Failure signatures:
  - Uniform cue contribution scores across layers (no pattern)
  - High probing accuracy even for random representations (identity-based prediction)
  - No confidence drop in input ablation (model ignores cue word)

- First 3 experiments:
  1. Run context mixing analysis on a small subset of examples to verify score computation
  2. Visualize attention weights for selected examples to confirm cue-target relationships
  3. Train probing classifiers on a few layers to check if number information is linearly separable

## Open Questions the Paper Calls Out

- How do encoder-decoder speech models handle cases where multiple syntactic cues with conflicting grammatical number information are present in the context?
- How does pre-training objective (self-supervised vs. supervised) influence context mixing patterns in speech transformers?
- At what point during autoregressive generation do encoder-decoder models integrate cue information from the decoder prefix?

## Limitations
- The alignment procedure between audio frames and words is not fully specified, particularly for Whisper models
- Findings are based on a narrow linguistic phenomenon (French homophone disambiguation) that may not generalize to other languages or syntactic structures
- Probing experiments rely on simple logistic regression classifiers that may not capture complex, non-linear patterns

## Confidence
**High Confidence:** The general pattern that encoder-only models incorporate contextual cues in middle layers, while encoder-decoder models delegate this to the decoder, is well-supported by the data.

**Medium Confidence:** The claim that encoder-decoder models rely on text tokens in the prefix for disambiguation is plausible but depends on assumptions about decoder self-attention effectiveness.

**Low Confidence:** The corpus signals indicate weak external validation, with an average neighbor FMR of 0.387 and no citations.

## Next Checks
1. Conduct a manual audit of frame-word alignments for a subset of examples to ensure the alignment procedure is robust, particularly for Whisper models.
2. Test the probing classifier's performance on randomly initialized models to verify that it captures grammatical number rather than word identity.
3. Replicate the analysis on a different language with homophony (e.g., Mandarin or English) to test whether observed patterns hold across linguistic contexts.