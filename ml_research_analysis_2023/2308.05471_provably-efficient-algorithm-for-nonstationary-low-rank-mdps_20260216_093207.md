---
ver: rpa2
title: Provably Efficient Algorithm for Nonstationary Low-Rank MDPs
arxiv_id: '2308.05471'
source_url: https://arxiv.org/abs/2308.05471
tags:
- policy
- follows
- mdps
- then
- lemma
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PORTAL and Ada-PORTAL, the first algorithms
  to tackle nonstationary reinforcement learning under low-rank Markov Decision Processes
  (MDPs), where both transition kernels and rewards vary over time. The key innovation
  is a policy optimization approach that combines off-policy exploration, data-transfer
  model learning from mismatched distributions, and target policy updates with periodic
  restart.
---

# Provably Efficient Algorithm for Nonstationary Low-Rank MDPs

## Quick Facts
- arXiv ID: 2308.05471
- Source URL: https://arxiv.org/abs/2308.05471
- Reference count: 40
- This paper introduces PORTAL and Ada-PORTAL, the first algorithms to tackle nonstationary reinforcement learning under low-rank Markov Decision Processes (MDPs).

## Executive Summary
This paper addresses nonstationary reinforcement learning in low-rank MDPs where transition kernels and rewards vary over time. The authors propose PORTAL, a policy optimization algorithm that combines off-policy exploration, data-transfer model learning from mismatched distributions, and target policy updates with periodic restart. Ada-PORTAL is a parameter-free variant that adaptively tunes hyperparameters without prior knowledge of nonstationarity. Both algorithms achieve arbitrarily small average dynamic suboptimality gap (GapAve) with polynomial sample complexity under mild nonstationarity assumptions.

## Method Summary
The paper proposes two algorithms for nonstationary low-rank MDPs. PORTAL uses off-policy exploration to collect data, then estimates the current MDP model using maximum likelihood estimation (MLE) with history data within a tuned window. It calculates bonuses for uncertainty, estimates value functions, updates policies, and periodically restarts the target policy to handle nonstationarity. Ada-PORTAL extends PORTAL by using a bandit-style EXP3-P algorithm to adaptively select the window size W and restart period τ without prior knowledge of nonstationarity, achieving better performance when nonstationarity is not negligible.

## Key Results
- PORTAL achieves GapAve scaling as Õ((∆P + ∆φ)K^(-1/3)) where ∆P and ∆φ are variation budgets for transitions and representations
- Ada-PORTAL achieves GapAve scaling as Õ((∆P + ∆φ)^(1/2)K^(-1/3)) without requiring prior knowledge of nonstationarity
- Both algorithms outperform black-box approaches like MASTER+PORTAL when nonstationarity is not significantly small
- Sample complexity is polynomial in relevant parameters with arbitrarily small GapAve achievable

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PORTAL's off-policy exploration with mismatched history data is provably efficient under nonstationary low-rank MDPs.
- Mechanism: The algorithm leverages history data collected under different transition kernels, with MLE error bounded by variation budgets plus a diminishing term as sample size increases. This justifies transferring data from mismatched distributions within a tuned window.
- Core assumption: The low-rank decomposition is realizable (Assumption 4.1) and the transition kernels have bounded density (Assumption 4.2).
- Evidence anchors:
  - [abstract] "The key innovation is a policy optimization approach that combines off-policy exploration, data-transfer model learning from mismatched distributions..."
  - [section 4.1] "PORTAL features new components, including off-policy exploration, data-transfer model learning..."
  - [corpus] Weak—no direct citations, but the approach is novel to nonstationary low-rank settings.
- Break condition: If the variation budgets (∆P, ∆φ) become too large relative to sample size, the MLE error bound fails and the exploration policy becomes ineffective.

### Mechanism 2
- Claim: Ada-PORTAL tunes hyperparameters adaptively without prior knowledge of nonstationarity, outperforming black-box methods like MASTER+PORTAL when nonstationarity is not negligible.
- Mechanism: Ada-PORTAL uses a bandit-style EXP3-P algorithm to select window size W and restart period τ from finite sets, adapting to unknown variation budgets. The method maintains regret bounds that depend on the square-root of variation budgets rather than the full variation.
- Core assumption: The variation budgets are bounded and the choice of feasible sets JW and Jτ covers near-optimal values.
- Evidence anchors:
  - [abstract] "Ada-PORTAL adapts hyperparameters without prior knowledge of nonstationarity... Ada-PORTAL performs better than MASTER+PORTAL when nonstationarity is not significantly small, i.e. ∆ ≥ ˜O(1)."
  - [section 5] "We present a parameter-free algorithm called Ada-PORTAL... which does not require prior knowledge on nonstationarity..."
  - [corpus] Weak—no direct citations, but theoretical comparison is explicit in Theorem 5.1.
- Break condition: If the environment changes too rapidly (variation much larger than the window W allows), the adaptive selection cannot react fast enough and performance degrades.

### Mechanism 3
- Claim: The target policy update with periodic restart in PORTAL handles nonstationarity by resetting policies before model estimation degrades.
- Mechanism: Every τ rounds, the algorithm resets target policy and value function estimates, preventing drift from the optimal policy in a changing environment. The restart period is chosen based on variation budgets.
- Core assumption: The optimal policy changes slowly enough that a restart every τ rounds keeps the policy close to optimal.
- Evidence anchors:
  - [section 4.1] "Due to the nonstationarity, the target policy is reset every τ rounds... our choice of τ is applicable to more general model classes."
  - [section 4.3] "The second part (II) captures the approximation error arising in finding the optimal policy via the policy optimization method..."
  - [corpus] Weak—this is a novel extension beyond prior tabular/linear work.
- Break condition: If τ is chosen too large relative to the rate of policy change (∆π), the policy becomes outdated and performance suffers.

## Foundational Learning

- Concept: Low-rank MDP decomposition and realizability.
  - Why needed here: The entire algorithm relies on decomposing transition kernels into representation φ and state-embedding µ functions. Without realizability, MLE and policy updates fail.
  - Quick check question: If φ⋆,k ∉ Φ or µ⋆,k ∉ Ψ, does the MLE guarantee still hold? (Answer: No—the algorithm assumes realizability.)
- Concept: Off-policy vs on-policy exploration trade-offs.
  - Why needed here: On-policy exploration under low-rank MDPs yields poor uncertainty estimates; off-policy exploration with mismatched data is essential for accurate model learning.
  - Quick check question: Why can't we just use the target policy for data collection like in tabular/linear MDPs? (Answer: Bonus terms in low-rank MDPs cannot serve as point-wise uncertainty measures.)
- Concept: Variation budgets and their impact on sample complexity.
  - Why needed here: The bounds on average dynamic suboptimality gap depend critically on how much the environment changes over time (∆P, ∆φ, ∆π).
  - Quick check question: If ∆P = 0 but ∆φ > 0, which part of the algorithm is most affected? (Answer: The representation learning and model estimation steps.)

## Architecture Onboarding

- Component map: Data collection (off-policy exploration) → MLE model estimation → Bonus calculation → Value function estimation → Policy update → Periodic restart. Ada-PORTAL adds a bandit layer on top to select W and τ per block.
- Critical path: MLE estimation → truncated value function calculation → exploration policy selection → target policy update.
- Design tradeoffs: Larger W improves model accuracy but increases stale data risk; smaller τ keeps policy fresh but increases variance; off-policy exploration improves sample efficiency but complicates uncertainty estimation.
- Failure signatures: If variation budgets are underestimated, W too large leads to model error; if τ too large, policy lag increases; if λk,W too small, MLE becomes unstable.
- First 3 experiments:
  1. Run PORTAL with known W, τ on a synthetic low-rank MDP with controlled nonstationarity to verify GapAve decreases as claimed.
  2. Test Ada-PORTAL's bandit selection by comparing chosen (W, τ) to oracle choices in a known environment.
  3. Stress-test by increasing ∆φ while keeping other variations fixed to isolate impact on model estimation error.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the algorithm's performance change when the representation function φ⋆ is unknown and changes over time, as opposed to the special case where φ⋆ is identical across all rounds?
- Basis in paper: [explicit] The paper discusses a special case where the representation φ⋆ stays identical and only the state-embedding function µ⋆,k changes over time. It mentions that this yields efficiency gain compared with changing φ⋆.
- Why unresolved: The paper provides bounds for the general case and the special case, but does not compare their performance in detail or explore the impact of φ⋆ changing over time.
- What evidence would resolve it: Empirical studies comparing the performance of the algorithm under different scenarios of φ⋆ changes would provide insights into the impact of this factor.

### Open Question 2
- Question: What is the impact of nonstationarity on the algorithm's performance when the variation budgets are significantly large, scaling linearly with K?
- Basis in paper: [explicit] The paper mentions that if the nonstationarity is significantly large, for example, scales linearly with K, then for each round, the previous samples cannot help to estimate the current best policy. Thus, the best W and τ are both 1, and the average dynamic suboptimality gap reduces to a constant.
- Why unresolved: The paper provides theoretical bounds for different regimes of nonstationarity but does not explore the practical implications or performance of the algorithm in scenarios with large variation budgets.
- What evidence would resolve it: Empirical studies or simulations showing the algorithm's performance under different scales of nonstationarity would provide insights into its robustness and limitations.

### Open Question 3
- Question: How does the choice of the forgetting rule (window size W) affect the algorithm's performance in nonstationary environments with varying degrees of nonstationarity?
- Basis in paper: [explicit] The paper discusses the choice of window size W based on the variation of the environment and mentions that typically W is tuned carefully based on the variation of the environment.
- Why unresolved: While the paper provides theoretical bounds and discusses the importance of choosing W based on nonstationarity, it does not explore the impact of different forgetting rules or the optimal choice of W in detail.
- What evidence would resolve it: Empirical studies comparing the performance of the algorithm under different forgetting rules or window sizes would provide insights into the optimal choice of W for different scenarios of nonstationarity.

## Limitations
- The theoretical guarantees critically depend on the realizability assumption - if the true low-rank decomposition does not exist within the specified function classes, the algorithm may fail.
- MLE error bounds under nonstationary conditions require variation budgets to be sufficiently small relative to sample size, which may not hold in rapidly changing environments.
- The hyperparameter tuning in Ada-PORTAL assumes bounded variation budgets and that feasible sets contain near-optimal values, which may not be guaranteed in practice.

## Confidence
- **High confidence**: The core algorithmic framework and its theoretical motivation are sound, as evidenced by the detailed mathematical derivations and clear separation of components.
- **Medium confidence**: The theoretical bounds on GapAve and sample complexity appear rigorous, but their practical tightness and behavior under realistic nonstationarity patterns remain unverified without empirical validation.
- **Low confidence**: The performance of Ada-PORTAL's adaptive hyperparameter selection in practice, particularly the effectiveness of the EXP3-P bandit approach for choosing W and τ without prior knowledge of nonstationarity.

## Next Checks
1. **Realizability stress test**: Implement a synthetic low-rank MDP where the true decomposition is known to exist, then systematically relax the realizability assumption by introducing noise or misspecification. Measure how quickly algorithm performance degrades as the gap between assumed and true decompositions grows.

2. **Variation budget sensitivity analysis**: Create environments with controlled variation budgets (∆P, ∆φ, ∆π) and measure the actual GapAve achieved by PORTAL versus the theoretical bounds. Identify the threshold where the assumptions break down and the algorithm's performance deteriorates sharply.

3. **Adaptive hyperparameter effectiveness**: Compare Ada-PORTAL's automatically selected window size W and restart period τ against oracle choices in environments with known nonstationarity patterns. Measure the regret incurred by suboptimal hyperparameter selection and quantify the improvement over MASTER+PORTAL in various nonstationary regimes.