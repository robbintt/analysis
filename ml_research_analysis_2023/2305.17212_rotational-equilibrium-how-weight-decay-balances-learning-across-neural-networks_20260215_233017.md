---
ver: rpa2
title: 'Rotational Equilibrium: How Weight Decay Balances Learning Across Neural Networks'
arxiv_id: '2305.17212'
source_url: https://arxiv.org/abs/2305.17212
tags:
- weight
- learning
- equilibrium
- rate
- update
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work analyzes how weight decay influences the training dynamics
  of deep neural networks through a framework called Spherical Motion Dynamics (SMD).
  The authors show that weight decay causes scale-invariant weights (e.g., after batch
  normalization) to converge to an equilibrium state where their magnitude and angular
  updates stabilize.
---

# Rotational Equilibrium: How Weight Decay Balances Learning Across Neural Networks

## Quick Facts
- arXiv ID: 2305.17212
- Source URL: https://arxiv.org/abs/2305.17212
- Reference count: 40
- Primary result: Weight decay causes scale-invariant weights to converge to equilibrium, balancing learning rates across layers; rotational variants maintain this equilibrium throughout training with improved performance and minimal tuning.

## Executive Summary
This work introduces the concept of rotational equilibrium, showing how weight decay in deep neural networks with normalization layers creates a stable state where scale-invariant weights maintain consistent rotational updates regardless of their position in the network. The authors develop a theoretical framework called Spherical Motion Dynamics (SMD) to analyze this equilibrium and propose rotational variants of popular optimizers (AdamW, SGD with momentum, Lion) that maintain equilibrium throughout training rather than just at convergence. These rotational variants achieve comparable or better performance with reduced hyperparameter tuning requirements, eliminate the need for learning rate warmup, and improve training of poorly normalized networks.

## Method Summary
The method derives Spherical Motion Dynamics (SMD) equilibrium conditions for scale-invariant weights under weight decay, showing that weight decay balances angular updates across layers by creating a stable equilibrium between gradient-induced growth and weight decay-induced shrinkage. The authors propose rotational optimizer variants that project gradients to be orthogonal to weights and scale them to maintain the equilibrium relative update size throughout training. The wrapper applies these rotational updates only to scale-invariant parameters (associated with normalization layers) while leaving scale-sensitive parameters unchanged, introducing minimal additional hyperparameters (decay factor β).

## Key Results
- Rotational variants of AdamW, SGDM, and Lion achieve comparable or better performance than standard optimizers with minimal hyperparameter tuning
- The methods reduce or eliminate the need for learning rate warmup in image classification tasks
- Rotational variants improve training stability and performance on poorly normalized networks (e.g., layer-normalized ResNets)
- The approach introduces only one additional hyperparameter (decay factor β) while maintaining the benefits of the original optimizers

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Weight decay causes scale-invariant weights to converge to a stable equilibrium where weight norm and expected angular updates stabilize.
- **Mechanism:** In scale-invariant layers, gradients are orthogonal to weights and inversely proportional to weight magnitude, while weight decay provides an opposing force proportional to weight magnitude. These forces balance at equilibrium, fixing both the weight norm and the expected rotational update size.
- **Core assumption:** The loss depends on the weights only through normalized activations, making weights scale-invariant.
- **Evidence anchors:**
  - [abstract] "Weight decay can cause the expected magnitude and angular updates of a neuron's weight vector to converge to a steady state we call rotational equilibrium."
  - [section 2.3] "An orthogonal update in the direction of the gradient always increases the weight norm. Conversely, the effect of weight decay on ω is to decrease ∥ω∥."
- **Break condition:** If the loss has direct dependencies on raw weights (not just normalized outputs), scale-invariance breaks and equilibrium no longer forms.

### Mechanism 2
- **Claim:** In equilibrium, all scale-invariant weights rotate at the same average rate regardless of their position in the network or gradient magnitude.
- **Mechanism:** At equilibrium, the relative update size ηr = ηg/∥ω∥⋆ is constant across all scale-invariant weights, ensuring uniform rotation.
- **Core assumption:** The gradient RMS is constant over time and across elements.
- **Evidence anchors:**
  - [abstract] "These states can be highly homogeneous, effectively balancing the average rotation -- a proxy for the effective learning rate -- across different layers and neurons."
  - [section 2.4] "Simplifying, we get the ηg = √E[∥∆gp∥2] and ηr = √E[∥∆gω∥2]/∥ω∥⋆ in Table 1."
- **Break condition:** If different layers have systematically different gradient statistics or normalization setups, rotation rates may diverge.

### Mechanism 3
- **Claim:** Rotational optimizer variants maintain equilibrium throughout training by constraining the average relative update size to the equilibrium value.
- **Mechanism:** The rotational wrapper projects gradient updates to be orthogonal to weights and scales them to maintain the equilibrium relative update size ηr, removing the transient phase where weights must converge to equilibrium.
- **Core assumption:** The equilibrium relative update size ηr derived for AdamW, SGDM, and Lion accurately predicts the optimal rotation rate.
- **Evidence anchors:**
  - [abstract] "We propose rotational variants (RVs) of these optimizers that force the expected angular update size to match the equilibrium value throughout training."
  - [section 3] "Our proposed method is displayed in Algorithm 1, and acts as a wrapper around any given existing optimizer F with a known or desired ηr."
- **Break condition:** If the equilibrium analysis is inaccurate for specific architectures or if the projection introduces instability in non-scale-invariant layers.

## Foundational Learning

- **Concept:** Scale-invariance in neural networks
  - Why needed here: Understanding which weights are affected by rotational equilibrium and how normalization creates scale-invariance is fundamental to the entire analysis.
  - Quick check question: Given a batch-normalized layer with weights W and activations X, what happens to the output if we scale W by a positive constant r?

- **Concept:** Gradient orthogonality and inverse scaling
  - Why needed here: These properties are the foundation of why weight decay and gradients have opposing effects on weight magnitude in scale-invariant layers.
  - Quick check question: For a scale-invariant weight vector ω, what is the relationship between ∥∇ωL(ω)∥ and ∥ω∥?

- **Concept:** Equilibrium analysis in optimization
  - Why needed here: The equilibrium framework provides the theoretical basis for understanding how weight decay balances learning across the network.
  - Quick check question: In the equilibrium condition for scale-invariant weights, what two forces must balance to create a stable weight norm?

## Architecture Onboarding

- **Component map:** Optimizer wrapper -> Standard optimizer (AdamW/SGDM/Lion) + Rotational projection for scale-invariant weights
- **Critical path:** For each training step: 1) Compute gradients for all parameters, 2) For scale-sensitive parameters: apply standard optimizer updates, 3) For scale-invariant parameters: project gradients to be orthogonal, scale by equilibrium relative update size, maintain constant magnitude
- **Design tradeoffs:** The wrapper introduces minimal hyperparameters (decay factor β) but requires additional memory for RMS tracking. The choice between filter-level vs tensor-level scale-invariance affects which layers benefit from rotational updates.
- **Failure signatures:** If rotational updates are applied to non-scale-invariant weights, training may diverge. If the equilibrium analysis is inaccurate, the wrapper may over/under-constrain updates. If β is poorly chosen, update variation may be too high or too low.
- **First 3 experiments:**
  1. Apply rotational wrapper to a simple batch-normalized linear layer on random data to verify equilibrium convergence matches predictions.
  2. Compare standard vs rotational AdamW on CIFAR-10 with ResNet-20 to verify performance parity and reduced warmup needs.
  3. Test layer-normalized ResNet on CIFAR-100 to verify improved training of poorly normalized networks.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the equilibrium states and rotational update dynamics vary for architectures with more complex or non-standard normalization layers (e.g., Group Normalization, Instance Normalization, or custom normalization schemes)?
- Basis in paper: [explicit] The paper mentions that different normalization setups can result in slightly different SMD properties, but primarily focuses on Batch Normalization and Layer Normalization.
- Why unresolved: The paper does not provide experimental evidence or theoretical analysis for architectures with normalization layers other than Batch and Layer Normalization. The behavior of SMD and rotational equilibrium for these other normalization schemes remains unexplored.
- What evidence would resolve it: Experiments training networks with Group Normalization, Instance Normalization, and other custom normalization schemes using rotational optimizers, comparing their equilibrium states and rotational update dynamics to those of Batch and Layer Normalization. Theoretical analysis of how these normalization schemes affect the gradient orthogonality and inverse scaling properties that lead to SMD.

### Open Question 2
- Question: Can the principles of rotational equilibrium and SMD be extended to optimize non-scale-invariant parameters (e.g., biases, gains, or scale-sensitive weights) in a way that balances their learning rates across the network?
- Basis in paper: [explicit] The paper discusses how scale-sensitive parameters can also converge to similar equilibrium states under certain conditions, but primarily focuses on scale-invariant weights. It mentions the potential for extending rotational updates to scale-sensitive parameters.
- Why unresolved: The paper does not provide a comprehensive analysis of how to apply rotational equilibrium principles to scale-sensitive parameters or experimental validation of such an approach. The potential benefits and challenges of this extension are not explored.
- What evidence would resolve it: Theoretical analysis of how to derive equilibrium states and rotational update dynamics for scale-sensitive parameters, considering their different gradient properties compared to scale-invariant weights. Experiments training networks with rotational updates applied to both scale-invariant and scale-sensitive parameters, comparing their performance and learning rate balance to standard optimizers.

### Open Question 3
- Question: How does the introduction of rotational equilibrium and constrained SMD affect the generalization performance of neural networks, particularly in tasks with limited data or high class imbalance?
- Basis in paper: [inferred] The paper primarily focuses on the optimization dynamics and training stability of rotational optimizers, but does not extensively discuss their impact on generalization performance. Generalization is a key concern in machine learning, especially in challenging data scenarios.
- Why unresolved: The paper does not provide experimental evidence or theoretical analysis of how rotational equilibrium and constrained SMD affect the ability of networks to generalize to unseen data. The potential benefits or drawbacks in terms of generalization are not explored.
- What evidence would resolve it: Experiments training networks on tasks with limited data or high class imbalance using rotational optimizers and comparing their generalization performance to standard optimizers. Theoretical analysis of how the balanced learning rates and constrained SMD induced by rotational optimizers may affect the ability of networks to learn generalizable features and avoid overfitting.

## Limitations

- The theoretical analysis relies on simplifying assumptions (constant gradient RMS, uniform rotation across layers) that may not hold in practice
- The method requires correctly identifying scale-invariant vs scale-sensitive parameters, but the exact boundaries are unclear for complex architectures
- The paper primarily tests on ResNet and Transformer architectures, with limited exploration of how rotational variants perform on architectures with different normalization schemes

## Confidence

**High confidence** in empirical results showing rotational variants achieve comparable performance to baselines with reduced warmup needs and improved stability on poorly normalized networks.

**Medium confidence** in equilibrium analysis and predictions, as the simplifying assumptions may not hold in practice and the paper doesn't thoroughly validate whether real networks achieve predicted equilibrium states.

**Low confidence** in generalizability across diverse architectures, as the paper primarily tests on standard ResNet and Transformer architectures without exploring how rotational variants perform on architectures specifically designed to break scale-invariance.

## Next Checks

1. **Equilibrium validation**: Measure the actual weight norm and angular update statistics during training of standard vs rotational optimizers to verify whether equilibrium is achieved and whether the predicted equilibrium values match observed values across different layers and training phases.

2. **Scale-invariance boundary test**: Systematically vary the normalization setup (batch normalization vs layer normalization vs weight standardization) in the same architecture and measure how rotational variant performance changes, to better understand which architectural components are truly scale-invariant.

3. **Architecture generalization**: Test rotational variants on architectures specifically designed to break scale-invariance (e.g., weight-standardized ResNets) to determine whether the method provides benefits beyond normalization layers and whether it can identify and appropriately handle non-scale-invariant parameters.