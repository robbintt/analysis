---
ver: rpa2
title: 'Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for Entity
  Alignment'
arxiv_id: '2307.02075'
source_url: https://arxiv.org/abs/2307.02075
tags:
- entity
- alignment
- pseudo-labeling
- pseudo-labels
- upl-ea
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of confirmation bias in pseudo-labeling-based
  entity alignment across knowledge graphs (KGs). The authors propose a unified framework
  called UPL-EA that explicitly eliminates two types of pseudo-labeling errors: Type
  I (conflicted misalignments) and Type II (one-to-one misalignments).'
---

# Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for Entity Alignment

## Quick Facts
- arXiv ID: 2307.02075
- Source URL: https://arxiv.org/abs/2307.02075
- Reference count: 6
- Key outcome: UPL-EA framework achieves superior performance on entity alignment tasks with limited prior alignment seeds by eliminating confirmation bias through OT-based pseudo-labeling and cross-iteration calibration

## Executive Summary
This paper addresses the problem of confirmation bias in pseudo-labeling-based entity alignment across knowledge graphs (KGs). The authors propose UPL-EA, a unified framework that explicitly eliminates two types of pseudo-labeling errors: Type I (conflicted misalignments) and Type II (one-to-one misalignments). The framework combines Optimal Transport (OT)-based pseudo-labeling with cross-iteration pseudo-label calibration to achieve state-of-the-art performance on benchmark KG datasets.

## Method Summary
UPL-EA is a unified framework for entity alignment that combines two complementary components: (1) Optimal Transport (OT)-based pseudo-labeling, which uses discrete OT modeling to determine entity correspondences and ensure one-to-one alignments at each iteration, and (2) cross-iteration pseudo-label calibration, which reduces pseudo-label selection variability across multiple iterations to minimize one-to-one misalignments. The framework employs a global-local aggregation architecture to produce informative entity embeddings by capturing both relation semantics and local structure.

## Key Results
- UPL-EA significantly outperforms 15 competitive baselines on benchmark KG datasets
- Achieves superior performance with limited prior alignment seeds (30%-70% split)
- Effectively combats confirmation bias through the proposed two-pronged approach

## Why This Works (Mechanism)

### Mechanism 1
OT-based pseudo-labeling eliminates Type I errors by enforcing one-to-one correspondence through optimal transport constraints. The entropy-regularized Sinkhorn algorithm finds a coupling matrix where each row/column sum constraint enforces one-to-one alignment, with a decision threshold guaranteeing no conflicts.

### Mechanism 2
Cross-iteration calibration eliminates Type II errors by reducing pseudo-label selection variability across consecutive iterations. Multiple independent runs generate m sets of pseudo-labels, and the intersection retains only consistently selected pairs, reducing false positives.

### Mechanism 3
Global-local aggregation architecture produces more informative entity embeddings by capturing both relation semantics and local structure. Relation features are computed from all triplets, while GCN with highway gates captures neighborhood structure while preserving original features.

## Foundational Learning

- Concept: Optimal Transport theory and entropy regularization
  - Why needed here: OT provides the mathematical framework for enforcing one-to-one alignments through probability mass transportation with minimal cost
  - Quick check question: How does the entropy regularization term in OT objective prevent degenerate solutions?

- Concept: Semi-supervised learning and confirmation bias
  - Why needed here: Understanding how erroneous pseudo-labels accumulate and bias subsequent model training is crucial for designing the calibration mechanism
  - Quick check question: Why does iterative pseudo-labeling without correction lead to confirmation bias in EA?

- Concept: Graph neural networks and over-smoothing
  - Why needed here: GCN architecture is used for local-level entity aggregation, but over-smoothing must be prevented to maintain discriminative embeddings
  - Quick check question: How does the highway gate strategy mitigate over-smoothing in GCN layers?

## Architecture Onboarding

- Component map: Prior alignment seeds -> EA model training -> OT-based pseudo-labeling -> cross-iteration calibration -> augmented seeds -> repeat
- Critical path: Prior alignment seeds → EA model training → OT-based pseudo-labeling → cross-iteration calibration → augmented seeds → repeat
- Design tradeoffs:
  - OT vs threshold-based pseudo-labeling: OT guarantees one-to-one but is computationally heavier; threshold is faster but produces conflicts
  - Calibration frequency: More frequent calibration (smaller m) reduces error accumulation but increases computational cost
  - Embedding initialization: Pre-trained embeddings (BERT vs GloVe) affect early-stage alignment quality
- Failure signatures:
  - High Type I errors: OT coupling matrix has many entries above threshold, indicating conflicts
  - High Type II errors: Calibration intersection becomes empty or too small, suggesting inconsistent pseudo-label selection
  - Degraded performance: EA model training loss plateaus or increases despite more pseudo-labels
- First 3 experiments:
  1. Verify OT guarantees one-to-one alignment: Generate synthetic entity sets, compute coupling matrix, check that decision threshold produces conflict-free pseudo-labels
  2. Test calibration precision gain: Run multiple independent EA model trainings, compute precision before/after intersection, verify Theorem 2 conditions
  3. Benchmark against baselines: Implement naive pseudo-labeling (threshold-based), measure Type I/II error rates on DBP15K dataset

## Open Questions the Paper Calls Out

### Open Question 1
How does UPL-EA perform compared to other state-of-the-art entity alignment models when no prior alignment seeds are provided? The paper compares performance with limited prior alignment seeds but doesn't provide direct comparison when no prior alignment seeds are provided against models that don't require them.

### Open Question 2
How does UPL-EA handle cases when the number of entities in two knowledge graphs is significantly different? The paper mentions OT assumes same number of elements but doesn't discuss handling significantly different entity counts in real-world scenarios.

### Open Question 3
How does UPL-EA handle cases when knowledge graphs have different schemas or structures? The paper mentions global-local aggregation but doesn't discuss handling different schemas or structures between knowledge graphs.

## Limitations
- Theoretical guarantees depend on ideal conditions that may not hold in early training iterations
- Cross-iteration calibration assumes monotonic improvement in alignment accuracy, which may not always hold
- Computational complexity of entropy-regularized OT scales poorly with large entity sets

## Confidence
- **High confidence**: Mathematical framework of OT-based one-to-one alignment and basic principle of cross-iteration calibration
- **Medium confidence**: Specific application of OT to eliminate Type I errors in EA is novel and empirically validated
- **Low confidence**: Assumption of monotonic accuracy improvement across iterations may not always hold in practice

## Next Checks
1. Analyze convergence behavior of OT coupling matrices across training iterations to verify one-to-one constraints are consistently maintained
2. Conduct ablation studies to quantify individual contributions of OT-based pseudo-labeling versus cross-iteration calibration to performance gains
3. Test framework's robustness to different prior seed ratios beyond the 30%-70% range used in experiments