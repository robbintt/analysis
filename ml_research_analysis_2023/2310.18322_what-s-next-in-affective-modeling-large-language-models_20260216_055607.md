---
ver: rpa2
title: What's Next in Affective Modeling? Large Language Models
arxiv_id: '2310.18322'
source_url: https://arxiv.org/abs/2310.18322
tags:
- gpt-4
- team
- emotion
- theory
- emotional
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We explore the ability of GPT-4 to solve tasks related to emotion
  prediction. GPT-4 performs well across multiple emotion tasks, distinguishing emotion
  theories and generating emotional stories.
---

# What's Next in Affective Modeling? Large Language Models

## Quick Facts
- arXiv ID: 2310.18322
- Source URL: https://arxiv.org/abs/2310.18322
- Reference count: 29
- Key outcome: GPT-4 demonstrates strong performance across multiple emotion tasks including reverse appraisal, emotion prediction, and emotional storytelling, suggesting LLMs could play an important role in affective modeling.

## Executive Summary
This paper explores the capabilities of GPT-4 for affective modeling tasks including emotion prediction, storytelling, and reverse appraisal. The authors demonstrate that GPT-4 can distinguish between different emotion theories, generate emotional stories, and manipulate emotional intensity when prompted to identify key appraisal factors. They also show that GPT-4 can perform reverse appraisal tasks, inferring missing goals, beliefs, or emotions from the other two components. The results suggest that large language models like GPT-4 have learned sophisticated representations of emotional experiences that could inform or improve existing emotion theories.

## Method Summary
The study uses OpenAI's GPT-4 API to evaluate the model's performance on emotion-related tasks through various text prompts. The evaluation includes asking GPT-4 to explain different emotion theories, generate and annotate emotional stories using appraisal theory factors, manipulate emotional intensity in narratives, and perform reverse appraisal by inferring missing components (goal, belief, or emotion) from the other two. The authors manually evaluate GPT-4's responses for accuracy and appropriateness, though specific scoring rubrics are not detailed in the paper.

## Key Results
- GPT-4 can accurately explain and distinguish between basic emotion theory, theory of constructed emotions, and appraisal theory
- By prompting for factor identification, GPT-4 can manipulate the emotional intensity of its own generated stories
- GPT-4 successfully performs reverse appraisal tasks, correctly inferring missing goals, beliefs, or emotions in most cases

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can generate and annotate emotional stories by leveraging learned appraisal dimensions from its training corpus.
- Mechanism: The model internally represents emotional intensity as a weighted combination of factors such as relevance, coping potential, and future expectancy. By prompting it to identify and adjust these factors, it can control the emotional tone of generated narratives.
- Core assumption: The model's training data contains sufficient examples of emotionally annotated narratives to learn a distributed representation of appraisal factors.
- Evidence anchors: [abstract] "We show that by prompting GPT-4 to identify key factors of an emotional experience, it is able to manipulate the emotional intensity of its own stories." [section] "GPT-4 can appropriately annotate the scenario using these factors [from appraisal theory]."
- Break condition: If the prompt does not explicitly request factor identification, the model defaults to generic emotional descriptions without modulating intensity.

### Mechanism 2
- Claim: GPT-4 can perform reverse appraisal by inferring missing goals, beliefs, or emotions from the other two using contextual inference.
- Mechanism: The model treats the three elements (goal, belief, emotion) as nodes in a causal network and uses its learned language model probabilities to infer the missing node given the other two.
- Core assumption: The training corpus includes enough examples of cause-effect chains in narratives to allow the model to infer implicit mental states.
- Evidence anchors: [abstract] "We explore GPT-4's ability on reverse appraisals by asking it to predict either the goal, belief, or emotion of a person using the other two." [section] "GPT-4 got all of them correctly" for football, and "GPT-4 got eight questions wrong" for quidditch, indicating general capability with context sensitivity.
- Break condition: If insufficient contextual cues are provided (e.g., no explicit agent focus), the model may fail to identify the correct inference.

### Mechanism 3
- Claim: GPT-4 can distinguish and explain different emotion theories by retrieving and synthesizing declarative knowledge from its training data.
- Mechanism: The model maps natural language queries to relevant passages in its training corpus and generates concise summaries that reflect key characteristics of each theory.
- Core assumption: The model's training data contains comprehensive coverage of major emotion theories up to its knowledge cutoff.
- Evidence anchors: [abstract] "GPT-4 is able to report key defining characteristics" of contrasting emotion theories. [section] "Each of GPT-4's responses captures well a high-level description of basic emotion theory, theory of constructed emotions, and appraisal theory."
- Break condition: If asked about post-2021 developments in emotion theory, the model cannot provide accurate information.

## Foundational Learning

- Concept: Appraisal theory
  - Why needed here: It provides the theoretical framework for understanding how emotions arise from evaluations of events in terms of relevance, coping potential, etc.
  - Quick check question: What are the five main appraisal factors used by GPT-4 to annotate emotional stories?

- Concept: Reverse engineering appraisal
  - Why needed here: It describes the task of inferring missing mental states (goal, belief, or emotion) from the other two, which is the core evaluation task.
  - Quick check question: In a sports scenario, if a person is happy and believes their team scored, what can you infer about their goal?

- Concept: Large language model prompting strategies
  - Why needed here: Effective prompting is necessary to elicit desired behaviors such as factor identification and emotion intensity manipulation.
  - Quick check question: How does explicitly prompting for factor identification change GPT-4's story generation compared to a generic emotional prompt?

## Architecture Onboarding

- Component map: GPT-4 (decoder-only transformer) -> prompt interface -> evaluation harness -> human evaluation
- Critical path: Prompt → GPT-4 inference → factor extraction/evaluation → human evaluation of correctness and appropriateness
- Design tradeoffs: GPT-4 offers strong general reasoning but lacks transparency in decision-making; manual evaluation is needed for nuanced tasks like emotion intensity
- Failure signatures: Incorrect inferences when context is sparse, sensitivity to prompt phrasing, inability to reference post-2021 knowledge
- First 3 experiments:
  1. Generate a low-intensity joy scenario and then transform it to high intensity by prompting for factor identification.
  2. Provide two of (goal, belief, emotion) and ask GPT-4 to infer the third in a sports context; verify correctness.
  3. Ask GPT-4 to explain three contrasting emotion theories and evaluate the accuracy of each summary.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What underlying representations of emotional events have LLMs learned that could inform or improve existing emotion theories like appraisal theory?
- Basis in paper: [explicit] The authors speculate that LLMs may have learned richer, different appraisal dimensions for representing social and emotional events based on their vast training data
- Why unresolved: The paper demonstrates GPT-4's capabilities but does not investigate the specific representations or mechanisms LLMs use to make emotional predictions
- What evidence would resolve it: Analysis of LLM internal representations when processing emotional content, comparison of LLM predictions with human emotion judgments, identification of novel dimensions or patterns in LLM emotional reasoning

### Open Question 2
- Question: How does the effectiveness of explicit factor prompting (as demonstrated with emotional intensity) compare to other prompt engineering techniques for controlling LLM emotional outputs?
- Basis in paper: [explicit] The authors show that explicitly prompting GPT-4 to identify factors helped it manipulate emotional intensity in stories
- Why unresolved: The paper only tested one approach (explicit factor identification) and did not compare it to alternative prompting strategies
- What evidence would resolve it: Controlled experiments comparing various prompt engineering techniques (chain-of-thought, role-based prompting, iterative refinement) on multiple emotional generation tasks

### Open Question 3
- Question: What are the limitations of LLMs in emotional reasoning compared to specialized computational emotion models?
- Basis in paper: [inferred] The authors note that while LLMs excel at prediction across tasks, they lack transparency in how they arrive at answers, unlike existing computational models
- Why unresolved: The paper demonstrates LLM capabilities but does not systematically identify their failure modes or compare them to traditional emotion models
- What evidence would resolve it: Head-to-head comparisons between LLMs and specialized emotion models on tasks requiring causal reasoning, physiological modeling, or long-term emotional dynamics

## Limitations

- The evaluation relies heavily on manual assessment, introducing subjectivity and potential inconsistency in scoring responses.
- The study focuses on a limited set of emotion theories and appraisal scenarios, which may not fully capture GPT-4's affective modeling abilities or limitations.
- The paper does not provide detailed scoring rubrics or inter-rater reliability measures, making it difficult to assess the robustness of the reported results.

## Confidence

- **High confidence**: GPT-4 can generate and annotate emotional stories by leveraging learned appraisal dimensions from its training corpus.
- **Medium confidence**: GPT-4 can perform reverse appraisal by inferring missing goals, beliefs, or emotions from the other two using contextual inference.
- **Medium confidence**: GPT-4 can distinguish and explain different emotion theories by retrieving and synthesizing declarative knowledge from its training data.

## Next Checks

1. Implement a standardized scoring rubric: Develop and apply a detailed rubric for evaluating GPT-4's emotion-related responses, including criteria for accuracy, appropriateness, and emotional intensity. Conduct inter-rater reliability tests to ensure consistent scoring.

2. Expand the evaluation corpus: Create a more diverse set of emotion theories, appraisal scenarios, and reverse appraisal tasks to comprehensively assess GPT-4's affective modeling capabilities. Include post-2021 developments in emotion theory to test the model's knowledge cutoff.

3. Investigate prompt sensitivity: Systematically vary the phrasing, length, and specificity of prompts used to elicit GPT-4's emotion-related behaviors. Analyze the impact of prompt variations on response quality and identify best practices for eliciting desired affective modeling tasks.