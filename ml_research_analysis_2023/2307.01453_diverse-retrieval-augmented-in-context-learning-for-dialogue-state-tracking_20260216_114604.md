---
ver: rpa2
title: Diverse Retrieval-Augmented In-Context Learning for Dialogue State Tracking
arxiv_id: '2307.01453'
source_url: https://arxiv.org/abs/2307.01453
tags:
- state
- examples
- dialogue
- methods
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces RefPyDST, a retrieval-augmented in-context
  learning approach for dialogue state tracking (DST) that formulates DST as a Python
  programming task. The method advances the state of the art with three key contributions:
  (1) re-framing DST as text-to-Python, explicitly modeling coreference as variable
  reference, (2) retrieving a diverse set of relevant examples using maximum marginal
  relevance, and (3) introducing a re-weighting method during decoding that accounts
  for competing surface forms.'
---

# Diverse Retrieval-Augmented In-Context Learning for Dialogue State Tracking

## Quick Facts
- arXiv ID: 2307.01453
- Source URL: https://arxiv.org/abs/2307.01453
- Reference count: 26
- Achieves state-of-the-art multi-domain joint-goal accuracy on MultiWOZ in both zero and few-shot settings

## Executive Summary
RefPyDST introduces a retrieval-augmented in-context learning approach that reformulates dialogue state tracking (DST) as a Python programming task. The method advances the state of the art by explicitly modeling coreference through variable references, retrieving diverse relevant examples, and re-weighting completions to mitigate surface form competition. Evaluated on MultiWOZ, RefPyDST outperforms both fine-tuned and other in-context learning approaches, achieving 95% of full-shot performance using only 5% of training data on average.

## Method Summary
RefPyDST formulates DST as text-to-Python synthesis where state changes are represented as Python code with explicit variable references. The system retrieves diverse in-context examples using a supervised embedding model and maximum marginal relevance (MMR) decoding, then generates completions using OpenAI Codex with PMIβ-based re-weighting to account for competing surface forms. The approach demonstrates strong data efficiency and improved coreference resolution compared to traditional DST formulations.

## Key Results
- Achieves state-of-the-art multi-domain joint-goal accuracy on MultiWOZ in both zero and few-shot settings
- Reaches 95% of full-shot performance using only 5% of training data on average
- Outperforms previous methods including fine-tuned approaches on MultiWOZ 2.1 and 2.4 benchmarks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Representing DST as Python code enables explicit modeling of coreference via variable references.
- Mechanism: By framing slot value coreference as variable references in Python (e.g., `state.restaurant = find_restaurant(area=state.hotel.area)`), the model can directly leverage the semantics of code to resolve references without additional reasoning.
- Core assumption: The pre-trained code model (OpenAI Codex) understands and correctly executes variable references in Python, treating them as symbolic links to prior values.
- Evidence anchors:
  - [abstract] "explicitly modeling language coreference as variable reference in Python"
  - [section 3.1] "We represent instances of our programming synthesis task with in-context python examples... One of the key benefits of our formulation of the DST task as python is explicit representation of coreference phenomena."

### Mechanism 2
- Claim: Diverse retrieval-augmented in-context learning improves performance by reducing redundancy and increasing label diversity.
- Mechanism: Using a supervised embedding model fine-tuned to approximate state change similarity, the system retrieves a set of examples Ek that are both similar to the current turn and dissimilar to each other via maximum marginal relevance (MMR). This ensures the examples cover a broader portion of the output space.
- Core assumption: The embedding model accurately captures the similarity between state changes, and the MMR-based decoding effectively balances relevance and diversity.
- Evidence anchors:
  - [section 3.2.2] "We propose an adaptation of MMR which uses our learned embedding model emb to produce a diverse set of examples Ek that maximizes similarity to xt and minimizes similarity between examples in Ek."
  - [section 6] "For a given training set size, we see that diverse decoding increases the number of distinct ‘labels’... as well as the entropy H(S|X)."

### Mechanism 3
- Claim: Re-weighting LM completions by their a priori likelihood (PMIβ) mitigates surface form competition.
- Mechanism: During decoding, each generated completion y is re-weighted by the ratio P(y|prompt)/P(y|task examples)^β. This compensates for the fact that many different strings can map to the same state change, and strings more common in the task context are favored.
- Core assumption: The a priori likelihood P(y|task examples) can be reliably estimated without conditioning on the current turn, and the re-weighting improves selection of the correct state change.
- Evidence anchors:
  - [section 3.3.2] "To compensate for this, they propose scoring with Domain Conditional Point-wise Mutual Information... We introduce a new rescoring function, P M Iβ..."
  - [section 6] "We find this improves system performance in both the zero and few-shot settings."

## Foundational Learning

- Concept: Contrastive learning for embedding similarity
  - Why needed here: To train the retriever to embed turns with similar state changes close together, enabling effective retrieval of relevant in-context examples.
  - Quick check question: How does the supervised contrastive loss ensure that turns with similar state changes have high cosine similarity in the embedding space?

- Concept: Maximum marginal relevance (MMR) for diversity
  - Why needed here: To select a set of examples that are individually relevant but collectively diverse, avoiding redundancy in the demonstrated outputs.
  - Quick check question: What is the role of the dissimilarity factor α in the MMR objective, and how does it balance relevance vs. diversity?

- Concept: Pointwise mutual information (PMI) for re-weighting
  - Why needed here: To adjust the likelihood of generated completions by their a priori probability in the task context, mitigating surface form competition.
  - Quick check question: Why does normalizing by P(y|task examples) help when many strings can represent the same state change?

## Architecture Onboarding

- Component map:
  - Embedding retriever: Fine-tuned MPNet model for turn context similarity
  - Diverse example decoder: MMR-based selection using the retriever
  - Prompt generator: Text-to-Python format with system definition and examples
  - LM generator: OpenAI Codex for program synthesis
  - PMIβ scorer: Re-weights completions by a priori likelihood
  - Parser: Converts Python programs to dialogue state changes

- Critical path:
  1. Embed current turn with retriever
  2. Retrieve and decode diverse examples Ek
  3. Construct prompt with system definition and Ek
  4. Generate candidate completions with Codex
  5. Score candidates with PMIβ
  6. Parse best completion to state change
  7. Apply state change to previous state

- Design tradeoffs:
  - Python vs. SQL: Python allows explicit coreference modeling but may be less familiar to some models
  - Diverse vs. top-k retrieval: Diverse retrieval increases label coverage but may reduce immediate relevance
  - PMIβ vs. greedy decoding: PMIβ improves accuracy but adds computational overhead

- Failure signatures:
  - Low diversity in Ek: α too low or retriever poorly trained
  - Incorrect coreference resolution: Python variable references misinterpreted by Codex
  - Poor candidate selection: PMIβ estimation inaccurate or β poorly tuned

- First 3 experiments:
  1. Ablation: Remove Python prompting (use SQL format) to test coreference benefit
  2. Ablation: Use top-k retrieval instead of diverse decoding to test diversity impact
  3. Ablation: Remove PMIβ scoring (use greedy decoding) to test re-weighting benefit

## Open Questions the Paper Calls Out

- Question: How does the performance of RefPyDST scale with larger language models (e.g., GPT-4) compared to Codex?
  - Basis in paper: [inferred] The paper achieves state-of-the-art results using OpenAI Codex, but does not explore larger models like GPT-4.
  - Why unresolved: The paper focuses on Codex and does not provide a comparison with larger models that might have different capabilities for code generation and in-context learning.
  - What evidence would resolve it: Experiments comparing RefPyDST performance using Codex vs. GPT-4 or other larger models would show if scaling up the language model improves results.

- Question: What is the impact of different diversity factors (α) on retrieval performance across various dialogue domains?
  - Basis in paper: [explicit] The paper mentions using different α values (0.2, 0.3, 0.5) for different training set sizes but does not provide a detailed analysis of their impact on individual domains.
  - Why unresolved: The paper provides aggregate results but lacks a domain-specific analysis of how the diversity factor affects retrieval performance in different dialogue contexts.
  - What evidence would resolve it: Domain-specific performance analysis with varying α values would reveal which diversity factor works best for different types of dialogues.

- Question: How does RefPyDST perform on dialogue datasets with more complex coreference resolution compared to MultiWOZ?
  - Basis in paper: [explicit] The paper demonstrates improved coreference resolution on MultiWOZ but does not test on more challenging datasets.
  - Why unresolved: The paper focuses on MultiWOZ and does not explore whether the approach generalizes to datasets with more complex linguistic phenomena.
  - What evidence would resolve it: Testing RefPyDST on dialogue datasets with more intricate coreference patterns would show its robustness and generalization capabilities.

## Limitations

- The system's performance is tightly coupled with OpenAI Codex's ability to interpret Python variable references correctly, making it dependent on the language model's code understanding capabilities
- Performance improvements rely heavily on the quality of the fine-tuned embedding model for retrieval, which may not generalize well to domains with different state structures
- The approach requires careful tuning of multiple hyperparameters (α, β, sampling parameters) that significantly affect performance but may vary across domains

## Confidence

- High confidence: The general effectiveness of retrieval-augmented in-context learning for DST (supported by strong empirical results on MultiWOZ benchmarks)
- Medium confidence: The specific contribution of Python formulation for coreference (mechanism is sound but implementation details affect real-world performance)
- Medium confidence: The PMIβ re-weighting method (the concept is valid but the exact implementation details and optimal β values may vary)

## Next Checks

1. **Coreference Mechanism Validation**: Conduct controlled experiments where coreference chains are deliberately broken in test examples to verify that Python variable references are actually resolving correctly versus the model learning surface patterns.

2. **Ablation on Retrieval Diversity**: Systematically vary the diversity parameter α and measure not just accuracy but also the actual diversity metrics (number of unique slot types, distribution entropy) in the retrieved examples to confirm the MMR objective is working as intended.

3. **PMIβ Sensitivity Analysis**: Perform a grid search over β values and different methods for estimating P(y|task examples) to identify whether the reported improvements are robust to these choices or highly sensitive to specific implementation details.