---
ver: rpa2
title: Domain Knowledge Injection in Bayesian Search for New Materials
arxiv_id: '2311.15162'
source_url: https://arxiv.org/abs/2311.15162
tags:
- optimization
- performance
- function
- knowledge
- acquisition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DKIBO is a Bayesian optimization algorithm that incorporates domain
  knowledge by augmenting the acquisition function with a predictive model trained
  on previously sampled points. The method addresses the limitation of standard Bayesian
  optimization in leveraging structural knowledge of the search space, which can improve
  sampling efficiency in physical science problems like materials design.
---

# Domain Knowledge Injection in Bayesian Search for New Materials

## Quick Facts
- arXiv ID: 2311.15162
- Source URL: https://arxiv.org/abs/2311.15162
- Reference count: 40
- Key outcome: DKIBO outperforms standard Bayesian optimization and other state-of-the-art methods in materials design and black-box optimization tasks by incorporating domain knowledge through predictive model augmentation of the acquisition function.

## Executive Summary
This paper introduces DKIBO, a Bayesian optimization algorithm that addresses the limitation of standard Bayesian optimization in leveraging structural knowledge of the search space. The method augments the acquisition function with a predictive model trained on previously sampled points, allowing it to capture domain-specific structural information and guide exploration towards more promising regions. DKIBO is validated on various tasks including synthetic functions, black-box optimization challenges, robotic swimming simulations, and materials design problems, demonstrating superior performance in terms of simple regret and cumulative mean regret.

## Method Summary
DKIBO augments standard Bayesian optimization by integrating a predictive model (e.g., random forest or linear regression) into the acquisition function as a corrective term. The algorithm trains the predictive model iteratively on previously sampled points and applies an adaptive weighting function that starts from 0 and gradually increases to 1. An early stopping strategy monitors the similarity between consecutive sampling points and drops the predictive model term when the search becomes too localized. The method is designed to improve sampling efficiency in physical science problems like materials design while maintaining the benefits of both Gaussian process and predictive model approaches.

## Key Results
- DKIBO outperforms standard Bayesian optimization and other state-of-the-art methods in materials design task, achieving superior performance in maximizing photocatalytic hydrogen evolution rate
- The method demonstrates improved convergence speed and final solution quality across various benchmark functions and optimization challenges
- DKIBO shows robustness across different acquisition functions (UCB, EI, POI) and hyperparameters, with early stopping strategy preventing local optima entrapment

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Augmenting the acquisition function with a predictive model provides a corrective term that captures domain-specific structural information.
- Mechanism: The DKIBO algorithm trains a predictive model (e.g., random forest or linear regression) iteratively on previously sampled points. This model's predictions are added to the acquisition function as a corrective term, enriching the approximation power of the Gaussian process.
- Core assumption: The predictive model can capture structural information about the optimization space that the Gaussian process alone cannot effectively model.
- Evidence anchors: [abstract], [section], [corpus]

### Mechanism 2
- Claim: The adaptive weighting function prevents the predictive model from dominating early in the optimization process.
- Mechanism: A monotonically increasing weight function (h(i)) is applied to the predictive model term, starting from 0 and gradually increasing to 1 as more samples are collected.
- Core assumption: Initial samples are insufficient to train an accurate predictive model, so the GP should dominate early exploration.
- Evidence anchors: [section], [section], [corpus]

### Mechanism 3
- Claim: The early stopping strategy prevents the predictive model from dominating when it starts to negatively impact performance.
- Mechanism: The algorithm monitors the similarity between consecutive sampling points and drops the predictive model term when the search becomes too localized.
- Core assumption: When the predictive model dominates, the search will converge to very similar points between iterations, indicating potential local optima confinement.
- Evidence anchors: [section], [section], [corpus]

## Foundational Learning

- Concept: Gaussian Processes and their role in Bayesian Optimization
  - Why needed here: DKIBO builds upon standard Bayesian optimization, which uses GPs as surrogate models. Understanding GP properties (kernel choice, posterior prediction, uncertainty quantification) is essential for grasping how DKIBO augments the acquisition function.
  - Quick check question: How does the Matérn kernel with ν=2.5 differ from a squared exponential kernel in terms of smoothness assumptions?

- Concept: Acquisition functions and their exploration-exploitation tradeoff
  - Why needed here: DKIBO modifies the acquisition function by adding a corrective term. Understanding how acquisition functions like UCB, EI, and POI work is crucial for comprehending the augmentation mechanism.
  - Quick check question: In the UCB acquisition function, what effect does increasing the κ parameter have on the exploration-exploitation balance?

- Concept: Random forests and their properties as predictive models
  - Why needed here: The paper uses random forests as one example of a predictive model to augment the acquisition function. Understanding their strengths (handling non-linear relationships, robustness to outliers) and limitations (potential overfitting, interpretability) is important for evaluating DKIBO's approach.
  - Quick check question: How does a random forest's ability to handle non-linear relationships complement the Gaussian process's typically smoother approximations?

## Architecture Onboarding

- Component map: Observation dataset -> GP fitting -> Predictive model training -> Acquisition function augmentation -> New point selection -> Lab measurement/probing -> Update dataset
- Critical path: 1. Initialize with random samples 2. Fit GP and predictive model on current dataset 3. Calculate augmented acquisition function 4. Select next sampling point 5. Measure objective at selected point 6. Update dataset and check early stopping condition 7. Repeat until convergence or max iterations
- Design tradeoffs: Predictive model choice (complexity vs overfitting), early stopping threshold (sensitivity vs robustness), weight function shape (linear vs quadratic)
- Failure signatures: Performance plateaus early (predictive model dominating), oscillations in search path (early stopping triggering too frequently), no improvement over standard BO (predictive model not capturing relevant structure), very slow convergence (weight function increasing too slowly)
- First 3 experiments: 1. Implement DKIBO with UCB acquisition and random forest predictor on Branin function (2D, known structure). Compare simple regret against standard BO. 2. Test DKIBO with different weight function shapes (linear vs quadratic) on Ackley function (2D, many local optima). Analyze impact on convergence speed. 3. Apply DKIBO to a synthetic materials design problem with known linear structure. Compare performance using linear regression vs random forest as predictive models.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the early stopping criterion be optimized to balance the trade-off between preventing local optima and maintaining the benefits of the predictive model throughout the optimization process?
- Basis in paper: [explicit] The paper mentions that the predictive model can dominate the search and lead to local optima, and proposes an early stopping strategy to drop the model when this happens.
- Why unresolved: The current early stopping criterion is based on the proximity of consecutive sampling points, but this may not be the most effective way to detect when the predictive model is hindering performance. There may be more sophisticated methods to determine when to drop the model.
- What evidence would resolve it: Experiments comparing different early stopping criteria on a variety of optimization problems, measuring the impact on convergence speed and final solution quality.

### Open Question 2
- Question: What is the optimal way to select the predictive model for a given problem, and how can this be done automatically without prior knowledge of the problem structure?
- Basis in paper: [explicit] The paper demonstrates that the choice of predictive model (e.g., linear regression vs. random forest) can significantly impact performance, and that the optimal choice depends on the underlying structure of the problem.
- Why unresolved: The paper manually selects different predictive models for different problems based on their known structure. Developing an automated method to select the best predictive model for a given problem is an open challenge.
- What evidence would resolve it: An algorithm that can automatically analyze a problem and select the most appropriate predictive model, validated on a wide range of optimization tasks with varying problem structures.

### Open Question 3
- Question: How can the proposed method be extended to handle high-dimensional optimization problems, where the curse of dimensionality may limit the effectiveness of the predictive model?
- Basis in paper: [inferred] The paper demonstrates the method on problems with up to 16 dimensions, but does not address how it would scale to much higher dimensions. In high dimensions, the predictive model may struggle to capture the relevant structure of the problem.
- Why unresolved: High-dimensional optimization is a fundamental challenge in many fields, and it is unclear how the proposed method would perform in such settings. Developing techniques to make the method more robust to high dimensionality is an open problem.
- What evidence would resolve it: Experiments on high-dimensional optimization problems (e.g., 100+ dimensions) comparing the proposed method to other state-of-the-art approaches, measuring both convergence speed and final solution quality.

## Limitations

- Limited empirical validation on synthetic benchmarks and single materials design problem rather than diverse real-world applications
- Doesn't thoroughly explore sensitivity to different predictive model choices beyond random forests and linear regression
- Claims about robustness across acquisition functions and hyperparameters not fully substantiated through systematic parameter variation

## Confidence

- **High Confidence**: The theoretical framework of augmenting acquisition functions with predictive models is sound and well-grounded in Bayesian optimization literature
- **Medium Confidence**: The empirical results showing DKIBO outperforming standard BO on benchmark functions and the materials design task are promising but based on limited problem diversity
- **Low Confidence**: Claims about DKIBO's robustness across different acquisition functions and hyperparameters are not fully substantiated

## Next Checks

1. Test DKIBO on additional materials design problems with different structural characteristics (e.g., crystal structure prediction, polymer design) to validate generalizability beyond photocatalytic hydrogen evolution
2. Conduct a systematic ablation study varying the predictive model type (e.g., neural networks, gradient boosted trees with different depths) and weighting function shapes to identify optimal configurations for different problem classes
3. Compare DKIBO against emerging hybrid approaches like Symmetry-Aware Bayesian Flow Networks and language model-based optimization assistants to establish its relative performance in the current state-of-the-art landscape