---
ver: rpa2
title: Optimal Algorithms for Online Convex Optimization with Adversarial Constraints
arxiv_id: '2310.18955'
source_url: https://arxiv.org/abs/2310.18955
tags:
- constraint
- convex
- regret
- functions
- problem
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper considers online convex optimization (OCO) with adversarial
  constraints, where on every round, the adversary reveals a convex cost function
  and a convex constraint function after the learner chooses an action. The goal is
  to design an online learning policy that achieves a small regret and cumulative
  constraint violation (CCV) against an adaptive adversary over a horizon of length
  $T$.
---

# Optimal Algorithms for Online Convex Optimization with Adversarial Constraints

## Quick Facts
- arXiv ID: 2310.18955
- Source URL: https://arxiv.org/abs/2310.18955
- Reference count: 27
- Primary result: Achieves O(√T) regret and Õ(√T) cumulative constraint violation without restrictive assumptions; O(log T) regret with strongly convex cost functions

## Executive Summary
This paper addresses online convex optimization (OCO) with adversarial constraints, where both cost and constraint functions are revealed after the learner's action. The authors propose a simple first-order policy that achieves sublinear regret and constraint violation simultaneously without requiring strong assumptions. By combining adaptive OCO policies with Lyapunov optimization techniques from control theory, the algorithm maintains a queue-based system to track constraint violations and constructs surrogate cost functions that encode these violations. The approach yields O(√T) bounds for general convex functions and improves to O(log T) regret when cost functions are strongly convex, while maintaining the same constraint violation bounds.

## Method Summary
The authors develop a meta-policy that reduces the constrained OCO problem to an unconstrained one by constructing surrogate cost functions that incorporate cumulative constraint violations through a queue-based Lyapunov system. The algorithm maintains queues for each constraint, updates them based on observed violations, and creates surrogate cost functions as linear combinations of the original constraints weighted by queue values. These surrogate functions are then passed to a standard OCO subroutine (like OGD). The regret on the surrogate problem is related back to the original problem using Lyapunov potential function arguments. For strongly convex cost functions, the algorithm achieves improved O(log T) regret by using appropriate adaptive step size schedules.

## Key Results
- Achieves O(√T) regret and Õ(√T) cumulative constraint violation simultaneously without restrictive assumptions
- Improves regret to O(log T) when cost functions are strongly convex while maintaining same constraint violation bound
- Extends results to S-feasible benchmarks where constraints are satisfied in aggregate over intervals of length S
- Provides a black-box reduction from constrained to unconstrained OCO using Lyapunov optimization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The meta-policy achieves sublinear regret and constraint violation by transforming the constrained problem into an unconstrained one via surrogate cost functions that encode cumulative constraint violations as coefficients.
- Mechanism: The algorithm maintains a queue Q(t) for cumulative constraint violations. At each round, it constructs a surrogate cost function that is a linear combination of the constraint functions, weighted by the current queue values. This surrogate is then fed to a standard OCO subroutine. The regret on the surrogate problem is related back to the original regret and violation via a Lyapunov potential function argument.
- Core assumption: There exists a feasible action x* such that all constraints are satisfied (Assumption 3), and the OCO subroutine has data-dependent adaptive regret bounds.
- Evidence anchors:
  - [abstract]: "We establish these results by effectively combining adaptive OCO policies as a blackbox with Lyapunov optimization - a classic tool from control theory."
  - [section]: "Our proposed meta-policy uses the surrogate cost functions to decide the actions on every round." (Section 4.3)
  - [corpus]: The related paper "Beyond O(sqrt(T)) Constraint Violation..." also uses Lyapunov methods, suggesting this is a recognized approach.
- Break condition: If the OCO subroutine does not have adaptive regret bounds, or if the constraints are not convex, the mechanism fails.

### Mechanism 2
- Claim: For strongly convex cost functions, the algorithm achieves O(log T) regret and constraint violation by using an OGD subroutine with a specific step size schedule.
- Mechanism: The algorithm uses the strong convexity of the cost functions to improve the regret bound on the surrogate problem, which then translates to improved bounds on the original problem. The key is the use of the adaptive step size schedule from Theorem 1 part 2.
- Core assumption: The cost functions are strongly convex with known strong convexity parameter α.
- Evidence anchors:
  - [abstract]: "Furthermore, in the case of strongly convex cost and convex constraint functions, the regret guarantee can be improved to O(log T) while keeping the CCV bound the same as above."
  - [section]: "Combining (15) with (3) and using the gradient bound (16) for the surrogate functions and the α-strong-convexity of the constraint functions..." (Section 5.2.2)
  - [corpus]: The related paper "Projection-free Algorithms for Online Convex Optimization with Adversarial Constraints" also mentions strong convexity, suggesting this is a relevant extension.
- Break condition: If the cost functions are not strongly convex, or if the strong convexity parameter is not known, the mechanism fails.

### Mechanism 3
- Claim: The algorithm can handle S-feasible benchmarks (where constraints are satisfied in aggregate over intervals of length S) by modifying the regret decomposition.
- Mechanism: Instead of requiring that all constraints are satisfied at every round, the algorithm only requires that the sum of constraints over any interval of length S is non-positive. This is achieved by modifying the regret decomposition to account for the S-feasibility.
- Core assumption: There exists an S-feasible action (Assumption 4), and the constraint functions are bounded.
- Evidence anchors:
  - [abstract]: "We now replace Assumption 3 with the following Assumption 4 ((S-feasibility)). ΩS ≠∅." (Section 6)
  - [section]: "We now only assume that ΩS ≠∅ for some S ∶1 ≤S ≤T . Clearly, Assumption 4 is weaker than Assumption 3 as Ω∗⊆ΩS,∀S ≥1." (Section 6)
  - [corpus]: The related paper "Tight Bounds for Online Convex Optimization with Adversarial Constraints" also considers S-feasible benchmarks, suggesting this is a recognized relaxation.
- Break condition: If the constraints are not bounded, or if S is not known, the mechanism may fail or give looser bounds.

## Foundational Learning

- Concept: Lyapunov optimization
  - Why needed here: To control the cumulative constraint violations by bounding the drift of a potential function.
  - Quick check question: What is the form of the potential function used in this paper, and how is its drift bounded?

- Concept: Online Convex Optimization (OCO)
  - Why needed here: The algorithm reduces the constrained problem to an unconstrained one by using an OCO subroutine.
  - Quick check question: What are the regret bounds achieved by the OGD algorithm for convex and strongly convex functions?

- Concept: S-feasibility
  - Why needed here: To relax the assumption that all constraints are satisfied at every round, allowing for a more general class of problems.
  - Quick check question: How does the regret decomposition change when moving from 1-feasibility to S-feasibility?

## Architecture Onboarding

- Component map:
  - OCS Meta-policy -> OCO subroutine -> Surrogate cost function
  - Queueing process tracks cumulative constraint violations

- Critical path:
  1. Observe current action and constraints
  2. Update queues based on constraint violations
  3. Construct surrogate cost function
  4. Pass surrogate to OCO subroutine
  5. Get next action from OCO subroutine

- Design tradeoffs:
  - Using a standard OCO subroutine makes the algorithm modular but requires the subroutine to have good regret bounds
  - The Lyapunov approach is general but may give looser bounds than problem-specific methods
  - The S-feasibility assumption relaxes the problem but may require more complex regret decompositions

- Failure signatures:
  - If queues grow linearly, the algorithm is not working
  - If regret is not sublinear, the OCO subroutine may not be working
  - If the algorithm fails to converge, the step size schedule may be incorrect

- First 3 experiments:
  1. Implement the OCS meta-policy with a simple OGD subroutine and test on a synthetic problem with known feasible actions
  2. Vary the strong convexity parameter and observe the effect on regret and violation bounds
  3. Test the S-feasible version on a problem where constraints are only satisfied in aggregate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the O(√T) regret bound for the Generalized OCO problem be achieved with the S-feasibility assumption?
- Basis in paper: [inferred] The paper mentions that obtaining an optimal O(√T) regret bound for Algorithm 3 with the S-feasibility assumption is left as an open problem.
- Why unresolved: The authors state that pre-processing by clipping constraints doesn't work with S-feasible benchmarks because positive violations can't be cancelled with strictly feasible violations on different rounds.
- What evidence would resolve it: A proof showing that Algorithm 3 can achieve O(√T) regret with the S-feasibility assumption, or a lower bound demonstrating that this is impossible.

### Open Question 2
- Question: Can the generalized OCO problem be solved with strongly convex constraints while maintaining optimal performance bounds?
- Basis in paper: [explicit] The authors mention investigating the generalized OCO problem with strongly convex constraints as an exciting research direction.
- Why unresolved: The paper focuses on convex constraint functions and does not explore the case of strongly convex constraints.
- What evidence would resolve it: An algorithm that achieves optimal performance bounds (e.g., O(log T) regret and O(√T log T) cumulative constraint violation) for the generalized OCO problem with strongly convex constraints.

### Open Question 3
- Question: Can the regret decomposition technique be extended to bound dynamic regret in online learning problems with adversarial constraints?
- Basis in paper: [inferred] The authors suggest extending their methodologies to bound dynamic regret as an exciting research direction.
- Why unresolved: The paper focuses on static regret and cumulative constraint violation bounds, and does not explore dynamic regret.
- What evidence would resolve it: A proof demonstrating that the regret decomposition technique can be adapted to bound dynamic regret in online learning problems with adversarial constraints, along with corresponding performance bounds.

## Limitations

- The algorithm requires knowledge of or assumptions about the existence of feasible actions (or S-feasible actions)
- Performance depends on the quality of the OCO subroutine and its regret bounds
- The extension to S-feasible benchmarks may give looser bounds and requires more complex regret decompositions
- The mechanism relies on bounded constraint functions, which may not hold in all practical scenarios

## Confidence

- O(√T) regret and constraint violation bounds: **High** confidence as these follow from well-established Lyapunov optimization techniques
- O(log T) regret bound for strongly convex functions: **Medium** confidence due to the complexity of the adaptive step size schedule
- Extension to S-feasible benchmarks: **Medium** confidence as it requires additional technical modifications

## Next Checks

1. Implement the meta-policy with OGD subroutine: Code the OCS meta-policy using Online Gradient Descent as the subroutine, verify the adaptive step size schedules from Theorem 1, and test on synthetic problems with known feasible actions.

2. Test strongly convex case sensitivity: Systematically vary the strong convexity parameter α and measure how the O(log T) regret bound degrades when α becomes small, validating the theoretical predictions.

3. Validate S-feasibility relaxation: Design experiments where constraints are only satisfied in aggregate over intervals of length S, and verify that the algorithm achieves the claimed regret bounds while maintaining constraint satisfaction in the required sense.