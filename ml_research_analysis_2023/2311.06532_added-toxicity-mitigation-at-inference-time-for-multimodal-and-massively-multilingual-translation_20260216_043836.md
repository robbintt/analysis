---
ver: rpa2
title: Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual
  Translation
arxiv_id: '2311.06532'
source_url: https://arxiv.org/abs/2311.06532
tags:
- toxicity
- mintox
- translation
- toxic
- added
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces MinTox, a novel pipeline to identify and mitigate
  added toxicity at inference time for multimodal and massively multilingual translation.
  MinTox uses a multimodal toxicity detection classifier and applies beam filtering
  on detected toxic tokens.
---

# Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual Translation

## Quick Facts
- **arXiv ID**: 2311.06532
- **Source URL**: https://arxiv.org/abs/2311.06532
- **Reference count**: 19
- **Primary result**: MinTox achieves 25-95% added toxicity reduction across modalities and languages while maintaining translation quality

## Executive Summary
This paper introduces MinTox, a novel pipeline for identifying and mitigating added toxicity at inference time in multimodal and massively multilingual translation systems. The approach uses a multimodal toxicity detection classifier and applies beam filtering on detected toxic tokens. Applied to the SEAMLESS M4T system, MinTox achieves significant added toxicity mitigation across domains, modalities, and language directions while maintaining translation quality. The method is computationally simpler than previous approaches like ReSeToX, requiring only word banning and beam search re-evaluation rather than gradient descent steps.

## Method Summary
MinTox is a toxicity mitigation pipeline that works by first generating an unconstrained translation, then detecting added toxicity using a multimodal toxicity classifier. If toxic output is detected and the source is not toxic, the system identifies toxic tokens and bans them during beam search re-evaluation. This beam filtering approach is computationally simpler than gradient-based methods like ReSeToX, which require attention weight adjustments. The method is designed to work at scale across multiple languages and modalities, including speech-to-text translation.

## Key Results
- Achieves 25-95% reduction in added toxicity across different modalities and domains
- Maintains translation quality with minimal BLEU score degradation (up to 2.2 points)
- Improves BLASER 2.0 scores in speech-to-text translation scenarios
- Outperforms baseline methods in toxicity mitigation effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: MinTox reduces added toxicity by detecting unbalanced toxicity and filtering beam search tokens.
- **Mechanism**: Uses toxicity classifier on both source and generated translation; applies beam filtering when output is toxic but input is not.
- **Core assumption**: Toxicity is primarily lexical and detectable with wordlist-based classifiers; beam filtering without re-weighting can sufficiently mitigate toxicity.
- **Evidence anchors**: [abstract] mentions multimodal toxicity detection and beam filtering; [section 2] describes the pipeline; [corpus] lacks direct citations.
- **Break condition**: If toxicity is non-lexical (sarcasm, context-dependent) or beam filtering removes critical tokens causing quality drop.

### Mechanism 2
- **Claim**: BEAM FILTERING is computationally simpler and faster than gradient-based attention reweighting.
- **Mechanism**: Bans detected toxic words and re-runs beam search directly, avoiding gradient descent steps required by ReSeToX.
- **Core assumption**: Banning specific tokens during beam search is sufficient to avoid toxic outputs without re-training or gradient steps.
- **Evidence anchors**: [abstract] compares MinTox to ReSeToX; [section 2] explains the methodological difference; [corpus] only compares to ReSeToX.
- **Break condition**: If toxic token is critical for correct translation, banning it may lead to quality degradation or mistranslation.

### Mechanism 3
- **Claim**: MinTox maintains translation quality while significantly reducing added toxicity.
- **Mechanism**: Filters toxic tokens only when added toxicity is detected, preserving meaning of toxic inputs while removing introduced toxicity.
- **Core assumption**: Most added toxicity comes from mistranslation of rare words, so banning those words during re-search can correct translation.
- **Evidence anchors**: [abstract] reports filtering 25-95% of added toxicity with minimal BLEU drop; [section 4] shows significant ETOX reduction with minimal quality impact; [corpus] lacks citations on rare word correlation.
- **Break condition**: If toxic word is necessary for correct translation and no alternative exists, quality will degrade.

## Foundational Learning

- **Concept**: Beam search and beam filtering in sequence-to-sequence models
  - **Why needed here**: The mitigation method relies on modifying the beam search process to exclude toxic tokens.
  - **Quick check question**: How does beam filtering differ from beam search with a modified scoring function?

- **Concept**: Wordlist-based toxicity detection and its limitations
  - **Why needed here**: The method uses a wordlist-based classifier (ETOX) to identify toxic tokens.
  - **Quick check question**: What are the main limitations of wordlist-based toxicity detection in multilingual settings?

- **Concept**: Translation evaluation metrics (BLEU, BLASER 2.0)
  - **Why needed here**: Quality is assessed using BLEU for text and BLASER 2.0 for speech-to-text outputs.
  - **Quick check question**: Why might BLASER 2.0 be preferred over BLEU for evaluating speech translation outputs?

## Architecture Onboarding

- **Component map**: Source text → Translation model (NLLB-600M or SEAMLESS M4T-LARGE) → Unconstrained beam search → Toxicity classifier (ETOX) → Conditional re-beam search with banned words (BEAM FILTERING) → Output → Toxicity classifier works on both text and ASR transcriptions for speech inputs.

- **Critical path**: 1) Generate initial translation with unconstrained search; 2) Run toxicity classifier on output; 3) If toxic, run classifier on input; 4) If input is not toxic, ban detected toxic words and re-run beam search; 5) Return filtered translation.

- **Design tradeoffs**: Simplicity vs. precision (banning words is simpler than gradient reweighting but may not always produce correct translation); Coverage vs. accuracy (wordlist-based detection is fast but may miss context-dependent toxicity or false positives).

- **Failure signatures**: High false positive rate in toxicity detection leading to unnecessary filtering; False negatives where toxic words are not detected or banned; Quality degradation when banned words are essential for correct translation; No mitigation for toxicity in input or for non-lexical toxicity.

- **First 3 experiments**: 1) Run baseline translation without filtering and measure ETOX to confirm added toxicity exists; 2) Apply MinTox on small sample and manually inspect outputs for false positives/negatives; 3) Compare BLEU and BLASER 2.0 scores before and after MinTox to verify quality preservation.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the beam filtering implementation handle words that are toxic in some contexts but not others, and what are the false positive rates for different languages?
- **Basis in paper**: [explicit] Manual analysis shows cases where words like "simias", "cachondo", and "vegas" were flagged as toxic in non-toxic contexts, particularly in Spanish and Catalan.
- **Why unresolved**: Paper only provides manual analysis for Catalan and Spanish, but system is used across 95-144 languages; no comprehensive evaluation of false positive rates across all languages.
- **What evidence would resolve it**: Systematic analysis of false positives across all languages, including both manual annotation and automated metrics for context-aware toxicity detection.

### Open Question 2
- **Question**: How does the performance of MinTox vary when applied to different model architectures beyond SEAMLESS M4T-LARGE, such as encoder-decoder models with different attention mechanisms?
- **Basis in paper**: [inferred] Paper only evaluates MinTox on SEAMLESS M4T-LARGE, but method is described as model-agnostic; authors mention computational efficiency suggesting it could work with different architectures.
- **Why unresolved**: Paper doesn't test method on different model architectures or compare efficiency gains across architectures.
- **What evidence would resolve it**: Comparative evaluation of MinTox across multiple model architectures (different encoder-decoder designs, transformer variants) measuring both toxicity mitigation and computational efficiency.

### Open Question 3
- **Question**: What is the impact of recurring application of MinTox (running the beam filtering multiple times) on toxicity mitigation and translation quality, particularly for words that appear in different segmentations?
- **Basis in paper**: [explicit] Paper notes that "porqueria" appears 17 times in SEAMLESS M4T output and is replicated even when banned due to different token segmentations, suggesting this could be solved by "applying MinTox recurrently."
- **Why unresolved**: Paper only tests single application of beam filtering and doesn't explore effects of multiple iterations or different tokenization strategies.
- **What evidence would resolve it**: Experiments comparing single vs. multiple applications of MinTox, including analysis of tokenization effects on toxicity mitigation success rates.

## Limitations
- Relies on wordlist-based toxicity detection which has limitations in capturing context-dependent toxicity, sarcasm, and non-lexical harmful content
- Trade-off between toxicity reduction and translation quality not fully explored, with BLEU drops up to 2.2 points reported
- Evaluation lacks human assessment of actual toxicity mitigation quality, especially for nuanced cases
- Limited testing on non-Latin scripts and languages without word segmentation

## Confidence

**High Confidence** (Medium): Core claim that MinTox reduces added toxicity more effectively than baseline methods is supported by quantitative metrics across multiple domains and languages with ETOX reductions of 25-95%.

**Medium Confidence** (Medium): Claim that MinTox maintains translation quality while mitigating toxicity is partially supported by BLEU and BLASER 2.0 scores, but trade-offs and failure modes not fully explored.

**Low Confidence** (Low): Claim that beam filtering is "methodologically simpler" than gradient-based approaches like ReSeToX presented without sufficient comparative analysis of computational costs, implementation complexity, or failure modes.

## Next Checks

1. **Human evaluation of toxicity mitigation quality**: Conduct human annotation studies to evaluate whether MinTox effectively identifies and mitigates nuanced toxicity cases (context-dependent, sarcasm, etc.) beyond simple lexical matches, and assess false positive rates in real-world usage.

2. **Comprehensive quality degradation analysis**: Systematically evaluate translation quality degradation across different types of toxic content, focusing on cases where banned words are semantically important to correct translation, and measure impact on meaning preservation.

3. **Cross-lingual robustness testing**: Evaluate MinTox's performance across full range of 102 languages in SEAMLESS M4T, with special attention to non-Latin scripts, languages with different tokenization schemes, and languages where toxicity detection may be culturally specific.