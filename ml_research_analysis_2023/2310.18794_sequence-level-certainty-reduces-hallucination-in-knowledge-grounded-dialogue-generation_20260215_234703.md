---
ver: rpa2
title: Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue
  Generation
arxiv_id: '2310.18794'
source_url: https://arxiv.org/abs/2310.18794
tags:
- certainty
- semantic
- response
- hallucination
- computational
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of hallucination in knowledge-grounded
  dialogue generation (KGDG) by proposing sequence-level certainty as a common theme.
  The authors categorize sequence-level certainty into two aspects: probabilistic
  certainty and semantic certainty.'
---

# Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation

## Quick Facts
- arXiv ID: 2310.18794
- Source URL: https://arxiv.org/abs/2310.18794
- Reference count: 39
- Key outcome: Higher sequence-level certainty (probabilistic and semantic) correlates with lower hallucination levels in knowledge-grounded dialogue generation, enabling effective hallucination mitigation through Certainty-based Response Ranking (CRR).

## Executive Summary
This paper addresses hallucination in knowledge-grounded dialogue generation (KGDG) by proposing sequence-level certainty as a unifying theme. The authors identify two types of sequence-level certainty: probabilistic certainty (measured by mean log-probability) and semantic certainty (measured by Agreement Score through entailment). Through extensive experiments on 4 models and 3 datasets, they demonstrate that higher levels of both certainty types correlate with lower hallucination levels. Based on this observation, they propose CRR - a decoding-time method that samples multiple response candidates and outputs the one with highest certainty, with P-CRR and S-CRR variants addressing certainty from different perspectives.

## Method Summary
The method involves training KGDG models on knowledge-grounded dialogue datasets, then generating multiple response candidates using nucleus sampling. For each candidate, both probabilistic certainty (arithmetic mean of log-probabilities) and semantic certainty (Agreement Score via entailment-based pairwise NLI scores) are computed. Candidates are ranked by certainty scores and the highest-certainty response is selected. The approach is evaluated on FaithDial, CMU-DoG, and TopicalChat datasets using GPT2-small, GPT2-medium, T5-base, and OpenLlama models, with faithfulness measured by a RoBERTa-Large-based hallucination classifier.

## Key Results
- Both P-CRR and S-CRR achieve significant improvements in faithful response percentages over baseline models on FaithDial test set
- Higher probabilistic and semantic certainty levels are significantly correlated with lower hallucination levels across all tested models and datasets
- S-CRR performance improves with more candidates (5, 10, 20) while maintaining computational efficiency
- The method generalizes across different model architectures and knowledge-grounded dialogue datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Higher sequence-level probabilistic certainty correlates with lower hallucination
- Mechanism: Models assign higher probabilities to sequences that are more faithful to provided knowledge, so ranking by mean log-probability selects less hallucinated responses
- Core assumption: The model's probability distribution over sequences reflects faithfulness to input knowledge
- Evidence anchors:
  - Empirical results reveal that higher levels of both types of certainty in model responses are correlated with lower levels of hallucination
  - Faithful model responses have both significantly higher probabilistic certainty and significantly higher semantic certainty than hallucinated response candidates
- Break condition: If model learns to assign high probabilities to fluent but hallucinated responses, or if knowledge grounding is poor

### Mechanism 2
- Claim: Semantic certainty measured by Agreement Score (AS) is proportional to probabilistic certainty
- Mechanism: AS measures semantic entailment between sampled responses; high AS indicates responses are semantically aligned with high-probability sequences
- Core assumption: When a model generates multiple responses to the same input, high-probability responses will be semantically similar to each other
- Evidence anchors:
  - Theoretical proof and analysis show that semantic certainty is a good estimator of probabilistic certainty
  - The semantic certainty of a model response is a aligning and unbiased estimator of its probabilistic likelihood
- Break condition: If model generates diverse high-probability responses with low semantic similarity, or if entailment model is poor

### Mechanism 3
- Claim: Sampling multiple candidates and ranking by certainty reduces hallucination during decoding
- Mechanism: By generating n candidates and selecting the one with highest certainty, CRR filters out hallucinated responses that tend to have lower certainty scores
- Core assumption: Hallucinated responses consistently have lower certainty scores than faithful responses
- Evidence anchors:
  - Certainty-based Response Ranking (CRR) samples several response candidates, ranks them based on sequence-level certainty, and outputs the response with the highest certainty level
  - Both P-CRR and S-CRR achieve significant improvements in faithful response percentages over the baselines in most settings
- Break condition: If hallucination occurs independently of certainty scores, or if ranking introduces new errors

## Foundational Learning

- Concept: Probabilistic certainty as arithmetic mean log-probability
  - Why needed here: P-CRR directly uses this measure to rank responses
  - Quick check question: How would you compute probabilistic certainty for a 5-token sequence with log-probabilities [-0.5, -0.3, -0.7, -0.2, -0.4]?

- Concept: Semantic entailment and Agreement Score
  - Why needed here: S-CRR uses AS to measure semantic certainty between response candidates
  - Quick check question: If three response candidates have pairwise entailment scores of 0.9, 0.8, and 0.7 with each other, what is the Agreement Score for each?

- Concept: Statistical correlation vs causation
  - Why needed here: The paper shows correlation between certainty and hallucination, but understanding this distinction is crucial for interpreting results
  - Quick check question: Does a significant negative correlation between certainty and hallucination prove that certainty causes lower hallucination?

## Architecture Onboarding

- Component map:
  Base KGDG models (GPT2-small/medium, T5-base, OpenLlama) -> NLI model for computing entailment probabilities -> Hallucination classifier for evaluation -> Sampling mechanism for generating multiple candidates -> Certainty scoring modules (probabilistic and semantic) -> Ranking and selection module

- Critical path:
  1. Input: conversation history + knowledge
  2. Sample n response candidates using nucleus+top-k sampling
  3. Compute certainty scores for each candidate
  4. Rank candidates by certainty
  5. Output highest-certainty response

- Design tradeoffs:
  - Number of candidates: More candidates improve S-CRR but increase computation
  - Sampling temperature: Higher temperature increases diversity but may reduce certainty
  - NLI model quality: Better entailment detection improves S-CRR accuracy
  - Confidence threshold: Could filter low-certainty responses entirely

- Failure signatures:
  - Both P-CRR and S-CRR fail similarly: suggests fundamental issue with certainty measure or hallucination classification
  - P-CRR succeeds but S-CRR fails: suggests NLI model quality or semantic alignment issues
  - S-CRR improves with more candidates but P-CRR doesn't: suggests S-CRR better captures semantic uncertainty

- First 3 experiments:
  1. Validate that both P-CRR and S-CRR improve faithfulness on FaithDial test set with 5 candidates
  2. Test scalability by varying number of candidates (5, 10, 20) and measuring S-CRR improvement
  3. Cross-dataset generalization: evaluate on CMU-DoG and TopicalChat to test robustness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of S-CRR change when applied to models with different training objectives (e.g., summarization vs. dialogue)?
- Basis in paper: The paper demonstrates S-CRR's effectiveness on KGDG models but does not explore its generalizability to other generation tasks or training objectives.
- Why unresolved: The paper focuses solely on KGDG tasks, leaving open whether S-CRR's semantic certainty approach generalizes to other domains where "faithfulness" might be defined differently.
- What evidence would resolve it: Experiments applying S-CRR to models trained on summarization, translation, or other conditional generation tasks, comparing faithfulness metrics across domains.

### Open Question 2
- Question: What is the relationship between sequence-level certainty and human judgments of response quality beyond just hallucination detection?
- Basis in paper: The paper focuses on certainty's correlation with hallucination but does not investigate whether higher certainty also correlates with other quality dimensions like coherence, informativeness, or engagement.
- Why unresolved: While the paper establishes certainty as a proxy for hallucination, it doesn't explore whether certainty might serve as a broader quality signal that captures multiple aspects of response quality.
- What evidence would resolve it: Human evaluation studies comparing responses with varying certainty levels across multiple quality dimensions (e.g., coherence, informativeness, naturalness) rather than just hallucination detection.

### Open Question 3
- Question: How does the performance of P-CRR and S-CRR scale with model size, and is there a point where semantic certainty becomes less reliable than probabilistic certainty?
- Basis in paper: The paper tests 4 models of varying sizes (117M to 3B parameters) but does not analyze how the relative effectiveness of P-CRR vs. S-CRR changes with scale.
- Why unresolved: The theoretical proof that semantic certainty estimates probabilistic certainty may break down at extreme scales where model behavior becomes more complex or probabilistic outputs become less reliable.
- What evidence would resolve it: Experiments with much larger models (e.g., 10B+ parameters) comparing P-CRR and S-CRR performance, along with analysis of whether semantic certainty remains a good estimator of probabilistic certainty at scale.

## Limitations

- Theoretical foundations require validation as the actual proof of semantic certainty as an estimator of probabilistic certainty is not provided in the paper
- Generalization across datasets may be limited as all experiments focus primarily on FaithDial with only brief validation on CMU-DoG and TopicalChat
- S-CRR's effectiveness heavily depends on the quality of the NLI model used for entailment detection, which is not thoroughly analyzed in the paper

## Confidence

**High Confidence**:
- Both probabilistic and semantic certainty are significantly correlated with lower hallucination levels on FaithDial dataset
- P-CRR and S-CRR both improve faithfulness percentages over baseline models when evaluated on FaithDial
- Sampling multiple candidates and ranking by certainty is an effective decoding-time strategy for hallucination mitigation

**Medium Confidence**:
- The theoretical relationship between semantic certainty and probabilistic certainty holds generally across different model architectures
- The correlation between certainty and hallucination generalizes to other knowledge-grounded dialogue datasets (CMU-DoG, TopicalChat)
- S-CRR provides complementary benefits to P-CRR rather than simply duplicating the same effect

**Low Confidence**:
- Semantic certainty is a better estimator of probabilistic certainty than alternative semantic measures
- The optimal number of candidates for S-CRR is universally 5 across all model-dataset combinations
- The certainty-hallucination relationship would hold with different NLI models or entailment detection approaches

## Next Checks

**Validation Check 1**: Conduct ablation studies varying the NLI model architecture and quality to determine the sensitivity of S-CRR performance to entailment detection accuracy. Test with different NLI models (e.g., BERT-based, RoBERTa-based) and measure how changes in entailment accuracy affect hallucination reduction.

**Validation Check 2**: Perform cross-dataset validation with datasets having different characteristics (e.g., Wizard of Wikipedia, CMU-DoG with different knowledge sources) to test whether the certainty-hallucination correlation holds across domains. Include statistical analysis of correlation coefficients across datasets.

**Validation Check 3**: Implement and evaluate an alternative semantic certainty measure based on knowledge grounding rather than response-to-response entailment. Compare this knowledge-grounded semantic certainty against Agreement Score to determine if the correlation with hallucination is specific to the proposed semantic measure or reflects a more general phenomenon.