---
ver: rpa2
title: Probabilistic Modeling for Sequences of Sets in Continuous-Time
arxiv_id: '2312.15045'
source_url: https://arxiv.org/abs/2312.15045
tags:
- queries
- items
- time
- sampling
- sequences
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new framework for modeling sequences of
  sets in continuous time using neural marked temporal point processes. The authors
  develop a general approach compatible with any intensity-based recurrent neural
  point process, allowing flexible modeling of set-valued data.
---

# Probabilistic Modeling for Sequences of Sets in Continuous-Time

## Quick Facts
- arXiv ID: 2312.15045
- Source URL: https://arxiv.org/abs/2312.15045
- Reference count: 40
- Key outcome: Proposed neural marked temporal point process models for set-valued data outperform static baselines on real-world datasets

## Executive Summary
This paper introduces a novel framework for modeling sequences of sets in continuous time using neural marked temporal point processes (MTPPs). The authors develop a general approach compatible with any intensity-based recurrent neural point process, allowing flexible modeling of set-valued data. They propose importance sampling methods for efficiently answering probabilistic queries about item occurrences and orderings within sets. Experiments on four real-world datasets demonstrate significant improvements in predictive log-likelihood compared to static baselines, with orders-of-magnitude efficiency gains for query answering using importance sampling.

## Method Summary
The method extends neural marked temporal point processes to handle set-valued events through two key innovations: a Dynamic Bernoulli model that parameterizes item inclusion probabilities as functions of a hidden state, and an importance sampling framework for efficient query answering. The Dynamic Bernoulli model assumes conditional independence of item occurrences given the hidden state, enabling tractable marginalization over subsets. The importance sampling approach uses a proposal distribution that focuses sampling on relevant events, dramatically reducing variance for queries about item occurrences and orderings. The models are trained using stochastic gradient optimization with a decomposed log-likelihood objective.

## Key Results
- Proposed models achieve significantly higher predictive log-likelihood than static baselines across all four real-world datasets
- Importance sampling provides orders-of-magnitude efficiency improvements over direct sampling for answering probabilistic queries
- Query-based log-likelihood metrics offer useful insights for model selection and evaluation
- Dynamic DPP model shows potential for capturing negative correlations between items but scales poorly with large item sets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Dynamic Bernoulli model enables tractable marginalization over subsets by assuming conditional independence of item occurrences given the hidden state.
- Mechanism: By parameterizing each item's inclusion probability as a function of the hidden state (via a sigmoid of a neural network output), the model can compute the probability of any subset occurring as a product of individual item probabilities. This factorization makes computing queries like "probability that any item in subset A occurs before time t" computationally feasible.
- Core assumption: The presence of each item in a set is conditionally independent given the history.
- Evidence anchors:
  - [abstract]: "Our work aims to take advantage of the structured nature of the sets Xi to more efficiently and effectively model an MTPP for set-valued marks."
  - [section 3.3]: "Specifically, given a hidden state hθ(t), the conditional set distribution of the next set X is parameterized via p(X = x | t, h(t)) := ∏k∈K ρk(t)1(k∈x)(1−ρk(t))1(k∉x)"
  - [corpus]: Weak evidence - no direct mention of this specific mechanism, but related work on neural point processes supports the general approach.
- Break condition: The conditional independence assumption breaks down when there are strong dependencies between item occurrences that cannot be captured by the hidden state alone.

### Mechanism 2
- Claim: Importance sampling significantly improves the efficiency of answering probabilistic queries by using a proposal distribution that zeroes out intensities for irrelevant items.
- Mechanism: By defining a proposal distribution that excludes events containing items not relevant to the query, the variance of the importance sampling estimator is greatly reduced. This is because the proposal distribution naturally focuses sampling effort on the relevant parts of the event space.
- Core assumption: The proposal distribution can be constructed to have the same support as the target distribution for the query of interest.
- Evidence anchors:
  - [abstract]: "To address this, we develop a class of importance sampling methods for querying with set-based sequences and demonstrate orders-of-magnitude improvements in efficiency over direct sampling"
  - [section 4]: "For hitting-time queries we are interested in the probability p(hit(A) ≤ t | H), defined as the probability that one or more items in the set A are observed before a fixed time t (where A and t are hyperparameters of the query)"
  - [corpus]: Moderate evidence - related work on importance sampling for point processes supports the general approach, but specific application to set-valued data is novel.
- Break condition: The efficiency gains break down when the proposal distribution poorly approximates the target distribution, leading to high variance in the importance weights.

### Mechanism 3
- Claim: The decomposition of the log-likelihood into temporal and set components allows for more effective model selection and training.
- Mechanism: By separating the likelihood into a temporal component (LTime) and a set component (LSet), the model can be trained to optimize both aspects simultaneously. This decomposition also allows for evaluating the relative importance of temporal and set modeling in the overall performance.
- Core assumption: The joint likelihood can be decomposed into additive components without loss of generality.
- Evidence anchors:
  - [section 3.1]: "It can be shown that the log-likelihood of a particular sequence H(T ) with N events decomposes into the following form: L(H(T )) = ∑i log p*(xi | ti) + ∑i log λ*(ti) - ∫0T λ*(s)ds"
  - [section 5.3]: "We also report results in Table 2 for the decomposition of the full log-likelihood L into its components LTime and LSet (Eq. (2))."
  - [corpus]: Weak evidence - no direct mention of this specific decomposition, but related work on point process modeling supports the general approach.
- Break condition: The decomposition breaks down when there are strong interactions between temporal and set components that cannot be captured by separate modeling.

## Foundational Learning

- Concept: Temporal point processes and marked temporal point processes
  - Why needed here: The paper builds on these foundations to extend the framework to handle set-valued events.
  - Quick check question: What is the key difference between a standard temporal point process and a marked temporal point process?

- Concept: Importance sampling and Monte Carlo methods
  - Why needed here: These techniques are used to efficiently estimate probabilities of complex events in the model.
  - Quick check question: How does importance sampling reduce the variance of Monte Carlo estimates compared to naive sampling?

- Concept: Determinantal point processes (DPPs)
  - Why needed here: DPPs are used as an alternative approach to modeling the set distribution, allowing for negative correlations between items.
  - Quick check question: What is the key property of DPPs that makes them suitable for modeling sets with negative correlations?

## Architecture Onboarding

- Component map:
  Base recurrent MTPP model (e.g., Neural Hawkes) -> Hidden state computation module -> Set modeling module (Dynamic Bernoulli or Dynamic DPP) -> Query answering module (importance sampling)

- Critical path:
  Compute hidden state from event history -> Use hidden state to compute item inclusion probabilities -> Sample from the set distribution to generate events -> Use importance sampling to answer probabilistic queries

- Design tradeoffs:
  - Dynamic Bernoulli vs. Dynamic DPP for set modeling (simplicity vs. expressiveness)
  - Linear vs. non-linear mappings for item probabilities (computational efficiency vs. flexibility)
  - Hidden state size (model capacity vs. computational cost)

- Failure signatures:
  - Poor performance on queries involving items with strong dependencies not captured by the hidden state
  - High variance in importance sampling estimates due to poor proposal distribution
  - Overfitting to training data when model capacity is too high

- First 3 experiments:
  1. Implement the Dynamic Bernoulli model and evaluate on a simple synthetic dataset with known ground truth.
  2. Compare the efficiency of importance sampling vs. naive sampling on a range of query types.
  3. Evaluate the impact of different hidden state sizes on model performance and computational cost.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed models perform on datasets with significantly more items (e.g., 100+ items) compared to the 4 real-world datasets used in the experiments?
- Basis in paper: [inferred] The paper mentions that the Dynamic DPP model scales poorly as a function of the number of items K and was not scalable for the MOOC dataset with K = 97. However, it does not explore the performance on datasets with even larger numbers of items.
- Why unresolved: The paper only experiments with 4 real-world datasets, which may not fully capture the performance of the proposed models on datasets with significantly more items.
- What evidence would resolve it: Conducting experiments on synthetic or real-world datasets with 100+ items to evaluate the performance of the proposed models, particularly the Dynamic DPP model, and comparing it with other baselines.

### Open Question 2
- Question: How do the proposed models handle temporal dependencies between events that are not captured by the recurrent neural network component?
- Basis in paper: [inferred] The paper mentions that the proposed models use a recurrent neural network to model the temporal component of the log-likelihood. However, it does not explicitly discuss how the models handle temporal dependencies that are not captured by the RNN.
- Why unresolved: The paper does not provide a clear explanation of how the models handle temporal dependencies beyond the RNN component, which could be an important factor in modeling real-world event sequences.
- What evidence would resolve it: Analyzing the learned representations of the RNN component and comparing them with the actual temporal dependencies in the data to assess the effectiveness of the models in capturing these dependencies.

### Open Question 3
- Question: How sensitive are the proposed models to the choice of hyperparameters, such as the hidden state size and learning rate?
- Basis in paper: [explicit] The paper mentions that the learning rate is fixed at 0.001 with no weight decay, and a batch size of 128 is used. However, it does not provide a detailed analysis of the sensitivity of the models to these hyperparameters.
- Why unresolved: The paper does not conduct a thorough hyperparameter sensitivity analysis, which could provide insights into the robustness and generalizability of the proposed models.
- What evidence would resolve it: Conducting a systematic hyperparameter sensitivity analysis by varying the hidden state size, learning rate, and other relevant hyperparameters, and evaluating the impact on the model performance across different datasets.

## Limitations

- The Dynamic Bernoulli model's conditional independence assumption may fail to capture important dependencies between items in real-world data
- The computational complexity analysis focuses on query evaluation but doesn't fully address training costs, particularly for large hidden state sizes
- The Dynamic DPP model scales poorly with the number of items, limiting its applicability to datasets with many unique items

## Confidence

- Dynamic Bernoulli model effectiveness: **Medium**
- Importance sampling efficiency gains: **High**
- Log-likelihood decomposition utility: **High**
- Model's ability to capture real-world dependencies: **Low**

## Next Checks

1. **Stress test conditional independence**: Design synthetic datasets with known item dependencies and evaluate how well the Dynamic Bernoulli model captures these relationships compared to baselines.

2. **Training cost analysis**: Systematically vary hidden state sizes and embedding dimensions across all datasets to quantify the trade-off between model complexity, training time, and predictive performance.

3. **Proposal distribution sensitivity**: Conduct ablation studies on the importance sampling proposal distribution to identify conditions under which the efficiency gains break down, and develop strategies to mitigate high-variance scenarios.