---
ver: rpa2
title: Multi-modal Graph Learning over UMLS Knowledge Graphs
arxiv_id: '2307.04461'
source_url: https://arxiv.org/abs/2307.04461
tags:
- graph
- learning
- mmugl
- umls
- medical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Multi-modal UMLS Graph Learning (MMUGL) introduces a novel approach
  for learning meaningful medical concept representations using graph neural networks
  over knowledge graphs based on the Unified Medical Language System. The method leverages
  multiple modalities including structured EHR data and unstructured clinical reports,
  and incorporates prior medical knowledge to improve performance on downstream predictive
  tasks.
---

# Multi-modal Graph Learning over UMLS Knowledge Graphs

## Quick Facts
- arXiv ID: 2307.04461
- Source URL: https://arxiv.org/abs/2307.04461
- Authors: Multiple authors from German institutions
- Reference count: 40
- Key outcome: MMUGL outperforms existing graph-based approaches in pretraining and downstream tasks using multi-modal UMLS knowledge graphs

## Executive Summary
This paper introduces MMUGL (Multi-Modal UMLS Graph Learning), a novel approach for learning meaningful medical concept representations using graph neural networks over UMLS knowledge graphs. The method integrates structured EHR data with unstructured clinical reports and incorporates prior medical knowledge from UMLS to improve performance on downstream predictive tasks. MMUGL demonstrates superior performance compared to existing graph-based methods while using a simpler pretraining approach, showing the effectiveness of multi-modal medical concept representations grounded in established medical knowledge.

## Method Summary
MMUGL constructs a large-scale UMLS knowledge graph from MIMIC-III clinical concepts and uses it as a shared latent space for multi-modal learning. The method employs a GNN-based concept embedding module, a transformer-based visit encoder, and a predictor module for both pretraining (auto-encoding) and fine-tuning downstream tasks. Clinical concepts are extracted from notes using QuickUMLS and NegEx, then integrated with structured billing codes. The model is pre-trained using reconstruction loss and fine-tuned for specific tasks including heart failure prediction, disease diagnosis, and medication recommendation.

## Key Results
- MMUGL outperforms existing graph-based approaches in both pretraining and downstream tasks
- Incorporating clinical reports improves performance in diagnosis prediction but not medication recommendation
- The method achieves competitive results with prior work trained on much larger datasets
- Ablation studies show benefits of large-scale knowledge graph, shared latent space, and tailored pretraining procedure

## Why This Works (Mechanism)

### Mechanism 1
The multi-modal graph learning approach works because it leverages a unified latent space grounded in a large-scale UMLS knowledge graph, which allows it to bridge the modality gap between structured EHR data and unstructured clinical reports. By extracting a complex graph from the UMLS Metathesaurus and using it as a shared latent space, the model can learn modality-agnostic representations of medical concepts. This shared space enables the model to fuse information from both structured codes and unstructured text, leading to richer and more comprehensive patient representations.

### Mechanism 2
The multi-modal approach improves performance by incorporating prior medical knowledge and considering multiple modalities, which helps to deal with sample scarcity and improves the robustness of the model. By incorporating prior medical knowledge from the UMLS Metathesaurus, the model can learn representations that are grounded in established medical relationships. Considering multiple modalities (structured EHR data and unstructured clinical reports) provides a richer input signal, which can help the model to better understand patient conditions and improve its predictions.

### Mechanism 3
The pretraining approach with a tailored reconstruction loss improves performance by learning more robust and meaningful medical knowledge graph representations, which can then be fine-tuned for downstream tasks. By pretraining the model on a reconstruction task, it learns to encode and decode medical concepts from the knowledge graph. This pretraining helps the model to learn a good initial representation of the medical concepts, which can then be fine-tuned for specific downstream tasks. The tailored reconstruction loss, which focuses on predicting diseases from either diseases or medications, further improves the model's ability to encode disease-specific information.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs)
  - Why needed here: GNNs are used to learn representations of medical concepts from the UMLS knowledge graph. They can effectively capture the relational structure of the graph and learn meaningful embeddings for each node (medical concept).
  - Quick check question: How does a GNN differ from a traditional neural network, and why is it suitable for learning representations from graph-structured data?

- Concept: Multi-modal Learning
  - Why needed here: Multi-modal learning is used to integrate information from structured EHR data (e.g., billing codes) and unstructured clinical reports. This allows the model to learn richer and more comprehensive patient representations.
  - Quick check question: What are the challenges of multi-modal learning, and how can they be addressed?

- Concept: Knowledge Graphs
  - Why needed here: Knowledge graphs provide a structured representation of medical knowledge, which can be used to ground the model's representations in established medical relationships. The UMLS Metathesaurus is used as the knowledge graph in this work.
  - Quick check question: What are the benefits of using a knowledge graph for medical concept representation, and what are the challenges in constructing and using such a graph?

## Architecture Onboarding

- Component map: Concept Embedding Module -> Visit Encoder -> Predictor Module
- Critical path: The critical path is the flow of information from the input (EHR data and clinical reports) through the Concept Embedding Module, Visit Encoder, and Predictor Module to the final output (predictions for downstream tasks)
- Design tradeoffs:
  - Using a large-scale knowledge graph (UMLS) provides rich prior knowledge but increases computational complexity
  - Multi-modal learning improves performance but requires careful integration of different data modalities
  - Pretraining improves downstream performance but requires additional computational resources and careful tuning of the pretraining objective
- Failure signatures:
  - Poor performance on downstream tasks may indicate that the pretraining did not learn meaningful representations or that the model cannot effectively transfer the learned representations
  - Instability during training may indicate that the model is overfitting to the training data or that the learning rate is not properly tuned
  - High computational cost may indicate that the model is too large or that the knowledge graph is too complex
- First 3 experiments:
  1. Train the model with a simple ICD/ATC hierarchy instead of the full UMLS knowledge graph to assess the impact of the knowledge graph complexity
  2. Train the model without pretraining to assess the impact of pretraining on downstream performance
  3. Train the model with only one modality (e.g., structured EHR data) to assess the impact of multi-modal learning

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MMUGL compare to state-of-the-art methods when using clinical reports in tasks other than diagnosis prediction?
- Basis in paper: [inferred] The paper shows that MMUGL with clinical reports improves performance in diagnosis prediction but not in medication recommendation. This suggests that the impact of clinical reports may vary depending on the task.
- Why unresolved: The paper only provides results for two tasks (diagnosis prediction and medication recommendation) with clinical reports. More experiments are needed to determine the general effectiveness of clinical reports across different medical tasks.
- What evidence would resolve it: Conducting experiments with clinical reports on a wider range of medical tasks and comparing the results to state-of-the-art methods would provide a clearer picture of the benefits of using clinical reports.

### Open Question 2
- Question: Can the performance of MMUGL be further improved by incorporating more sophisticated knowledge graph extraction methods?
- Basis in paper: [explicit] The paper acknowledges that the current knowledge graph extraction method is simple and could be improved. It suggests that a more sophisticated extraction paired with an appropriate GNN could handle the increased heterogeneity of different nodes, edges, and their respective features.
- Why unresolved: The paper does not explore alternative knowledge graph extraction methods or their impact on MMUGL's performance.
- What evidence would resolve it: Implementing and comparing different knowledge graph extraction methods and their impact on MMUGL's performance would provide insights into the potential benefits of more sophisticated extraction techniques.

### Open Question 3
- Question: How does the performance of MMUGL vary with different hyperparameter settings?
- Basis in paper: [explicit] The paper presents ablation studies on hyperparameters such as the number of GNN layers, transformer layers, and learning rates. However, it does not exhaustively explore the full hyperparameter space.
- Why unresolved: The paper only tests a limited set of hyperparameter values and does not provide a comprehensive analysis of their impact on performance.
- What evidence would resolve it: Conducting a more extensive hyperparameter search and analyzing the impact of different settings on MMUGL's performance would provide a better understanding of the model's sensitivity to hyperparameters.

## Limitations
- Evaluation primarily focuses on MIMIC-III data, limiting generalizability to other healthcare settings
- UMLS extraction pipeline lacks complete implementation details, particularly regarding specific relations included and clinical concept coverage
- SapBERT initialization process for concept embeddings is mentioned but not fully detailed for the specific UMLS subset used
- Clinical concept extraction using QuickUMLS and NegEx may introduce noise that affects reproducibility

## Confidence

- High Confidence: The core mechanism of using GNNs over UMLS knowledge graphs for medical concept representation is well-established in the literature. The reported performance improvements over baseline methods are supported by the experimental results presented.
- Medium Confidence: The multi-modal integration approach shows promise, but the relative contribution of each modality (structured codes vs. clinical notes) to performance gains is not clearly quantified. The clinical concept extraction pipeline using QuickUMLS and NegEx is standard but introduces potential noise that affects reproducibility.
- Low Confidence: The pretraining procedure's effectiveness beyond this specific dataset is uncertain, as the work doesn't demonstrate transfer to external validation sets or other medical domains.

## Next Checks

1. Reproduce UMLS graph construction using the exact filtering criteria and relation selection described, then verify node coverage against MIMIC-III clinical concepts to ensure the knowledge graph is properly grounded.

2. Isolate modality contributions by systematically ablating each input source (structured codes, clinical notes, UMLS relations) to quantify their individual impact on downstream task performance.

3. Validate clinical concept extraction by sampling extracted concepts from clinical notes and verifying both the extraction accuracy and negation handling, particularly for conditions that directly impact the predictive tasks.