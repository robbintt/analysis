---
ver: rpa2
title: Data-Adaptive Dimensional Analysis for Accurate Interpolation and Extrapolation
  in Computer Experiments
arxiv_id: '2312.10100'
source_url: https://arxiv.org/abs/2312.10100
tags:
- input
- fanov
- inputs
- variables
- dimensionless
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper proposes a data-adaptive implementation of Buckingham\u2019\
  s \u03A0 theorem for Gaussian process surrogate modeling of computer experiments,\
  \ guided by functional analysis of variance (FANOVA) to choose basis quantities.\
  \ The core method selects input variables with the largest contributions to predicted\
  \ output variance as basis quantities to satisfy dimensional analysis constraints,\
  \ then derives dimensionless input and output variables."
---

# Data-Adaptive Dimensional Analysis for Accurate Interpolation and Extrapolation in Computer Experiments

## Quick Facts
- arXiv ID: 2312.10100
- Source URL: https://arxiv.org/abs/2312.10100
- Reference count: 14
- Primary result: Data-adaptive implementation of Buckingham's Π theorem using FANOVA-guided basis selection significantly improves Gaussian process prediction accuracy, achieving normalized RMSE as low as 0.0002% for interpolation and 2% for extrapolation

## Executive Summary
This paper proposes a data-adaptive implementation of Buckingham's Π theorem for Gaussian process surrogate modeling of computer experiments. The method uses functional analysis of variance (FANOVA) to identify input variables with the largest contributions to output variance, then selects these as basis quantities for dimensional analysis transformations. Applied to three test problems, the FANOVA-driven dimensional analysis significantly improves prediction accuracy compared to non-DA or arbitrary DA implementations, particularly for extrapolation tasks.

## Method Summary
The method transforms physical variables into dimensionless combinations using Buckingham's Π theorem, with basis quantities selected via FANOVA analysis of input-output relationships. FANOVA identifies input variables contributing most to output variance, which are then used as basis quantities to satisfy dimensional analysis constraints. This generates dimensionless input and output variables that are modeled using Gaussian processes. The approach aims to make the resulting dimensionless function easier to model while improving extrapolation performance by removing absolute scale dependencies.

## Key Results
- FANOVA-DA achieved normalized RMSE of 0.0002% for interpolation and 2% for extrapolation on test problems
- Significant improvement over non-DA models and arbitrary DA implementations
- Logarithmic transformations of high-range inputs further improved accuracy, especially for borehole problems
- Expanded log-input variants provided additional accuracy gains at increased computational cost

## Why This Works (Mechanism)

### Mechanism 1
Choosing basis quantities via FANOVA variance contribution maximizes prediction accuracy by ensuring remaining variables' variability is minimized when transformed. This makes the dimensionless function easier to model with Gaussian processes. The core assumption is that variables with high FANOVA variance contribution are the "important" physical factors for system behavior.

### Mechanism 2
Dimensionless transformations improve extrapolation by removing absolute scale dependence. DA replaces raw variables with ratios, so predictions depend only on shape, not absolute magnitude. This means behavior in the training domain maps directly to extrapolated domains without "new" regions in input space. The underlying assumption is scale invariance in dimensionless form.

### Mechanism 3
Logarithmic transformations of inputs improve Gaussian process modeling accuracy in high-range variables by compressing large dynamic ranges. This makes the correlation structure more appropriate and stabilizes variance across the input domain. The assumption is that relationships become more linear or additive on the log scale.

## Foundational Learning

- Concept: Buckingham's Π theorem (dimensional analysis)
  - Why needed here: Method relies on transforming physical variables into dimensionless combinations before Gaussian process modeling
  - Quick check question: If a system has 5 variables and 2 fundamental dimensions, how many dimensionless variables result?

- Concept: Functional analysis of variance (FANOVA)
  - Why needed here: FANOVA quantifies each input's contribution to output variance, guiding basis quantity selection
  - Quick check question: In FANOVA, what does a high main-effect percentage imply about an input's importance?

- Concept: Gaussian process surrogate modeling
  - Why needed here: Statistical model used to predict outputs after DA transformation
  - Quick check question: What is the role of the correlation function in a Gaussian process?

## Architecture Onboarding

- Component map: Physical system specification → FANOVA variance analysis → Basis quantity selection → Dimensionless variable construction → Gaussian process model fitting → Prediction on original scale
- Critical path: The chain from FANOVA → basis selection → dimensionless transformation → GP fitting is critical; failure in any step propagates
- Design tradeoffs: More complex DA variable construction (e.g., expanded log-input) improves accuracy but increases correlation function dimensionality and computation time
- Failure signatures: (a) Low or erratic FANOVA percentages across repeats; (b) High test error even with DA; (c) Instability when extrapolating to zero or near-zero dimensionless values
- First 3 experiments:
  1. Run FANOVA on raw input space to identify dominant variables
  2. Construct two DA variants: one with FANOVA-selected basis, one with arbitrary basis; compare GP accuracy
  3. Apply log-transform to high-range inputs and refit; measure change in test error

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several emerge from the analysis:
- Sensitivity to training design choice after DA transformations
- Generalization to categorical or mixed-type inputs
- Performance with unknown or partially known physical models
- Computational trade-offs of expanded log-inputs and higher-order combinations

## Limitations

- General applicability of FANOVA-driven DA across diverse physical systems remains uncertain
- Computational cost of repeated FANOVA analyses for basis selection is not discussed
- Claims about improved extrapolation assume strict scale invariance of underlying physics
- Method does not address handling dimensionless quantities approaching zero during extrapolation

## Confidence

- FANOVA-driven basis selection effectiveness: Medium - Strong results on test cases, but limited generalizability
- DA improving extrapolation: High - Well-supported by theory and empirical results
- Log-transform benefits: High - Clear evidence across multiple test problems

## Next Checks

1. Apply the method to a system with known scale-dependent physics (e.g., turbulence with Reynolds number effects) to test extrapolation limits
2. Systematically vary the number of FANOVA repeats to quantify the relationship between computational cost and prediction stability
3. Compare basis selection using FANOVA versus physical domain knowledge on a system where both approaches are feasible