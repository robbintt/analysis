---
ver: rpa2
title: Training neural operators to preserve invariant measures of chaotic attractors
arxiv_id: '2306.01187'
source_url: https://arxiv.org/abs/2306.01187
tags:
- neural
- rmse
- statistics
- dynamics
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of training neural operators for
  chaotic dynamical systems where traditional MSE-based training fails to capture
  long-term invariant statistical properties due to exponential divergence of trajectories.
  The authors propose two complementary approaches to address this issue.
---

# Training neural operators to preserve invariant measures of chaotic attractors

## Quick Facts
- arXiv ID: 2306.01187
- Source URL: https://arxiv.org/abs/2306.01187
- Reference count: 35
- Primary result: Neural operator training methods that preserve invariant measures of chaotic attractors by combining short-term MSE loss with either Sinkhorn loss or contrastive learning, achieving up to 49.4% error reduction in histogram metrics and 26.7% in energy spectrum errors

## Executive Summary
This paper addresses the fundamental challenge of training neural operators for chaotic dynamical systems where traditional MSE-based training fails to capture long-term invariant statistical properties due to exponential divergence of trajectories. The authors propose two complementary approaches: an optimal transport-based Sinkhorn loss that matches distributions of physics-informed summary statistics, and a contrastive learning framework that automatically discovers relevant invariant statistics without requiring expert knowledge. Both methods are combined with short-term MSE loss to balance immediate accuracy with long-term statistical consistency.

## Method Summary
The paper proposes two methods to train neural operators on chaotic systems while preserving their invariant measures. The first uses Sinkhorn loss to match distributions of expert-chosen summary statistics between model predictions and data, leveraging optimal transport distance to preserve time-invariant properties. The second employs contrastive learning to discover invariant features automatically by treating sequences from the same trajectory as positive pairs and sequences from different trajectories as negative pairs. Both approaches are combined with relative mean squared error (rMSE) for short-term prediction consistency. The methods are evaluated on chaotic Kuramoto-Sivashinsky and Lorenz-96 systems with varying noise levels.

## Key Results
- The Sinkhorn loss approach preserves invariant measures more effectively than MSE-only training, reducing histogram errors by up to 49.4% and energy spectrum errors by 26.7%
- Contrastive learning preserves statistical properties nearly as well as the optimal transport approach without requiring expert knowledge of the system
- Both methods show improved long-term statistical consistency with only ~10% increase in short-term prediction error compared to baseline MSE training
- The physics-informed Sinkhorn approach requires expert knowledge for choosing summary statistics, while contrastive learning automatically discovers relevant features

## Why This Works (Mechanism)

### Mechanism 1
The Sinkhorn loss matches distributions of summary statistics between model predictions and data, preserving invariant measures of chaotic attractors. By using optimal transport distance (Wasserstein distance) between distributions of physics-informed summary statistics, the model learns to preserve time-invariant statistical properties that characterize chaotic attractors. Core assumption: The chosen summary statistics are sufficient to characterize the invariant measure of the chaotic attractor.

### Mechanism 2
Contrastive learning discovers relevant invariant statistics automatically without requiring expert knowledge. The contrastive learning framework trains an encoder to learn time-invariant features by treating sequences from the same trajectory as positive pairs and sequences from different trajectories as negative pairs, naturally preserving statistical properties. Core assumption: Sequences from the same chaotic attractor share common invariant statistics that can be learned through contrastive learning.

### Mechanism 3
Combining short-term MSE loss with long-term invariant statistics loss prevents overfitting to short-term dynamics while ensuring statistical consistency. The hybrid loss function includes both rMSE for short-term prediction consistency and either Sinkhorn or contrastive feature loss for preserving long-term statistical properties, balancing immediate accuracy with long-term behavior. Core assumption: Short-term MSE alone is insufficient for training neural operators on chaotic systems with noise, but combining it with invariant statistics loss addresses this limitation.

## Foundational Learning

- Concept: Chaotic dynamical systems and Lyapunov exponents
  - Why needed here: Understanding why MSE-based training fails requires knowledge of chaos theory and the exponential divergence of trajectories
  - Quick check question: What property of chaotic systems makes long-term MSE-based predictions fundamentally impossible?

- Concept: Invariant measures and ergodic theory
  - Why needed here: The paper's core approach relies on preserving invariant measures rather than trajectories, which requires understanding these mathematical concepts
  - Quick check question: How does an invariant measure characterize the statistical properties of a chaotic attractor?

- Concept: Optimal transport and Wasserstein distance
  - Why needed here: The Sinkhorn loss is based on optimal transport theory, which is essential for understanding the physics-informed approach
  - Quick check question: What advantage does the Wasserstein distance have over traditional statistical distances when comparing distributions?

## Architecture Onboarding

- Component map: Neural operator backbone -> Sinkhorn loss module / Contrastive learning encoder -> Hybrid loss combiner (rMSE + invariant statistics loss) -> Summary statistics calculator (for Sinkhorn approach)

- Critical path:
  1. Generate or load multi-environment training data with varying parameters
  2. Compute summary statistics for Sinkhorn approach or train contrastive encoder
  3. Train neural operator with hybrid loss
  4. Evaluate on both short-term MSE and long-term invariant statistics

- Design tradeoffs:
  - Physics-informed (Sinkhorn) vs. self-supervised (contrastive): Expert knowledge requirement vs. automation
  - Weighting between rMSE and invariant statistics: Short-term accuracy vs. long-term consistency
  - Sequence length for contrastive learning: More information vs. training difficulty

- Failure signatures:
  - Poor short-term predictions despite good long-term statistics: rMSE weight too low
  - Good short-term predictions but poor long-term statistics: Invariant statistics loss weight too low
  - Both metrics poor: Poor choice of summary statistics or contrastive learning architecture

- First 3 experiments:
  1. Train baseline FNO with only rMSE loss on Lorenz-96 system, evaluate both metrics
  2. Add Sinkhorn loss with expert-chosen statistics, tune α and γ hyperparameters
  3. Implement contrastive learning approach, tune temperature τ and sequence length K

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of the proposed methods scale with increasing system dimensionality beyond the tested 1D Kuramoto-Sivashinsky and finite-dimensional Lorenz-96 systems? The paper acknowledges scalability concerns but does not provide empirical evidence for higher dimensions.

### Open Question 2
What is the theoretical relationship between the learned contrastive features and the optimal transport-based summary statistics in terms of capturing invariant measures? The paper empirically compares the two approaches but doesn't analyze whether they are capturing the same or complementary aspects of the invariant measure.

### Open Question 3
How sensitive are the proposed methods to the choice of hyperparameters (α, λ, γ) and what are principled approaches for selecting them? The paper uses ad-hoc grid search and empirical selection criteria without providing theoretical guidance or demonstrating robustness to parameter choices.

### Open Question 4
Can the proposed approaches be extended to handle time-dependent forcing or control parameters while maintaining their effectiveness? The paper explicitly states this as a limitation without proposing modifications or testing on time-dependent systems.

## Limitations

- The Sinkhorn approach requires expert knowledge to select appropriate summary statistics that capture the invariant measure
- Both methods show only ~10% increase in short-term prediction error compared to baseline, suggesting some trade-off between short-term and long-term accuracy
- The approaches are limited to autonomous systems without time-dependent forcing or control parameters

## Confidence

- **High**: The fundamental insight that MSE-based training fails for chaotic systems due to exponential divergence
- **Medium**: The effectiveness of Sinkhorn loss and contrastive learning in preserving invariant measures
- **Low**: The generalizability of these approaches to arbitrary chaotic systems without significant hyperparameter tuning

## Next Checks

1. **Ablation study on hyperparameter sensitivity**: Systematically vary α (Sinkhorn weight), γ (regularization), τ (temperature), and K (sequence length) to quantify their impact on both short-term MSE and long-term invariant measure preservation across multiple chaotic systems.

2. **Cross-system generalization test**: Apply the trained models to a different chaotic system not seen during training (e.g., Lorenz '63) to evaluate how well the learned approaches generalize beyond the training domain.

3. **Statistical power analysis**: Compare the statistical significance of the reported improvements (49.4% and 26.7% error reductions) by computing confidence intervals and performing hypothesis tests to determine if the improvements are robust across different noise realizations and random seeds.