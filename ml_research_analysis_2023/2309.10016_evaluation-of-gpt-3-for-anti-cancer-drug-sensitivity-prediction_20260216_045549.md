---
ver: rpa2
title: Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction
arxiv_id: '2309.10016'
source_url: https://arxiv.org/abs/2309.10016
tags:
- drug
- gpt-3
- cell
- line
- mutation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study explored GPT-3's capability for predicting anti-cancer
  drug sensitivity using structured pharmacogenomics data from five tissue types (LUAD,
  BRCA, COREAD, THCA, LGG). The task was formulated as binary classification of drug-cell
  line pairs as sensitive or resistant based on IC50 values.
---

# Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction

## Quick Facts
- **arXiv ID**: 2309.10016
- **Source URL**: https://arxiv.org/abs/2309.10016
- **Reference count**: 5
- **One-line primary result**: GPT-3's zero-shot prompting outperforms fine-tuning for drug sensitivity prediction across multiple cancer types, with fine-tuning showing 24-29% F1 score gains when incorporating gene mutation and SMILES features.

## Executive Summary
This study explores GPT-3's capability for predicting anti-cancer drug sensitivity using structured pharmacogenomics data from five tissue types (LUAD, BRCA, COREAD, THCA, LGG). The task is formulated as binary classification of drug-cell line pairs as sensitive or resistant based on IC50 values. Zero-shot prompting with task-specific instructions achieved higher overall F1 scores across all tissue types compared to fine-tuning, though performance was biased toward the sensitive class. Fine-tuning experiments on LUAD data showed that gene mutation features alone or combined with drug SMILES representations yielded 24-29% performance gains in F1 score. The best performance was achieved using Drug + Cell line + Smile + Mutation features. The study demonstrates GPT-3's potential for drug sensitivity prediction in precision oncology, with results suggesting that pre-training on biomedical corpora could further improve per-class performance.

## Method Summary
The study used the GDSC2 database containing 288 unique drugs and 186 unique cell lines across five tissue types. The drug response prediction task was framed as binary classification using a fixed IC50 threshold of -2. Structured pharmacogenomics data was converted to natural language prompts using column names and values. Zero-shot prompting involved task-specific instructions prepended to the structured data. Fine-tuning experiments used prompt-completion pairs for 4 epochs on the GPT-3 Ada model, testing different feature combinations including drug name, target, gene mutations, and SMILES representations.

## Key Results
- Zero-shot prompting with task-specific instructions achieved higher overall F1 scores across all tissue types compared to fine-tuning
- Fine-tuning on LUAD data showed 24-29% F1 score improvements when incorporating gene mutation features alone or combined with drug SMILES representations
- The best performance was achieved using Drug + Cell line + Smile + Mutation features
- Performance was biased toward the sensitive class in zero-shot settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3's zero-shot prompting outperforms fine-tuning across all tissue types due to its strong pre-training on diverse textual corpora.
- Mechanism: The model leverages its general language understanding to interpret task-specific instructions and structured pharmacogenomics data without requiring task-specific parameter updates.
- Core assumption: The pre-trained knowledge captures relevant patterns for drug sensitivity prediction across diverse cancer types.
- Evidence anchors:
  - [abstract]: "Zero-shot prompting with task-specific instructions achieved higher overall F1 scores across all tissue types compared to fine-tuning"
  - [section]: "Comparative analysis was performed to demonstrate GPT-3's drug response generalizability in the zero-shot vs fine-tuning settings"
  - [corpus]: Weak evidence - no direct comparison of zero-shot vs fine-tuning performance found in related papers
- Break condition: If the structured data contains domain-specific patterns not captured in pre-training, or if the instruction format is not sufficiently clear for the model to understand the classification task.

### Mechanism 2
- Claim: Integration of gene mutation features and drug SMILES representations significantly improves performance through fine-tuning.
- Mechanism: Fine-tuning allows the model to learn the specific relationships between genomic mutations, chemical structures, and drug response, capturing complex patterns not present in the general pre-training data.
- Core assumption: The relationships between gene mutations, drug chemical structures, and drug response are learnable and predictive.
- Evidence anchors:
  - [section]: "gene mutation features alone and also in combination with the drug's smile representations are more informative of drug response, with 24% and 29% performance gains in F1 respectively"
  - [abstract]: "Fine-tuning experiments on LUAD data showed that gene mutation features alone or combined with drug SMILES representations yielded 24-29% performance gains in F1 score"
  - [corpus]: Weak evidence - no direct mention of SMILES features in related papers, though some mention drug response prediction
- Break condition: If the relationship between mutations and drug response is too complex or non-linear for the model to capture with limited fine-tuning epochs, or if the SMILES representations are not properly encoded for the model.

### Mechanism 3
- Claim: Pre-training GPT-3 on biomedical corpora could improve per-class performance, particularly for the resistant class.
- Mechanism: Domain-specific pre-training would provide the model with relevant biomedical context, improving its ability to distinguish between sensitive and resistant cases rather than being biased toward one class.
- Core assumption: The current bias toward the 'sensitive' class is due to insufficient biomedical domain knowledge in the pre-training data.
- Evidence anchors:
  - [section]: "We believe the per-class performance with zero-shot prompting could potentially be improved through the pre-training of GPT-3 on biomedical corpora"
  - [abstract]: "performance was biased toward the sensitive class" and "The study demonstrates GPT-3's potential for drug sensitivity prediction in precision oncology, with results suggesting that pre-training on biomedical corpora could further improve per-class performance"
  - [corpus]: Weak evidence - no direct mention of biomedical pre-training for improving class balance, though related papers discuss domain adaptation
- Break condition: If the class imbalance is primarily due to data distribution rather than model knowledge, or if the biomedical pre-training does not adequately address the specific patterns distinguishing sensitive vs resistant responses.

## Foundational Learning

- Concept: Structured data to natural language conversion
  - Why needed here: GPT-3 requires natural language input, so structured pharmacogenomics data must be converted to text format using column names and values
  - Quick check question: How would you convert a drug-cell line pair with drug name "paclitaxel", target "tubulin", mutation "TP53", and IC50 response into a natural language prompt?

- Concept: Binary classification formulation
  - Why needed here: The drug response prediction is framed as a binary classification problem (sensitive vs resistant) using a fixed IC50 threshold
  - Quick check question: What threshold value is used to convert continuous IC50 values to binary labels, and what does each label represent?

- Concept: Prompt engineering for task-specific instructions
  - Why needed here: Task-specific instructions guide the model to perform the correct classification task in zero-shot settings
  - Quick check question: What instruction is prepended to the structured data prompt to guide GPT-3's prediction?

## Architecture Onboarding

- Component map: Data preprocessing → Prompt engineering → GPT-3 model (Ada variant) → Output classification → Performance evaluation
- Critical path: Dataset preparation → Zero-shot prompting evaluation → Fine-tuning with different feature combinations → Performance comparison
- Design tradeoffs: Zero-shot requires no training data but may have class imbalance; fine-tuning requires labeled data but can capture complex patterns; adding SMILES and mutation features increases performance but also complexity
- Failure signatures: Poor performance on resistant class indicates bias; inconsistent predictions across tissue types suggest data quality issues; no improvement from fine-tuning suggests feature engineering problems
- First 3 experiments:
  1. Test zero-shot prompting on a small subset of LUAD data with basic drug + cell line features to verify the prompt format works
  2. Implement fine-tuning on LUAD with drug + cell line features only, using 4 epochs, to establish baseline performance
  3. Add gene mutation features to the fine-tuning pipeline and compare performance gains to isolate the contribution of genomic information

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of GPT-3 for drug sensitivity prediction change when pre-trained on biomedical corpora compared to its current performance?
- Basis in paper: [explicit] The authors suggest that pre-training GPT-3 on biomedical corpora could potentially improve per-class performance with zero-shot prompting.
- Why unresolved: The study did not experiment with pre-training GPT-3 on biomedical corpora, so there is no empirical evidence to support this hypothesis.
- What evidence would resolve it: Comparative studies showing the performance of GPT-3 pre-trained on biomedical corpora versus the current model on the same drug sensitivity prediction task.

### Open Question 2
- Question: What is the impact of using more recent versions of GPT-3 or other advanced LLMs on the accuracy of drug sensitivity prediction?
- Basis in paper: [inferred] The study used GPT-3 Ada model, which may not be the most advanced or recent version available. The potential for improvement with newer models is implied by the rapid advancements in LLM technology.
- Why unresolved: The study did not compare the performance of different GPT-3 versions or other LLMs, leaving the impact of using more advanced models untested.
- What evidence would resolve it: Performance comparisons between different GPT-3 versions and other advanced LLMs on the same drug sensitivity prediction task.

### Open Question 3
- Question: How does the inclusion of additional genomic features beyond gene mutations, such as gene expression data or epigenetic markers, affect the performance of GPT-3 in predicting drug sensitivity?
- Basis in paper: [explicit] The study focused on gene mutation features and drug SMILES representations, but did not explore other genomic features.
- Why unresolved: The study did not experiment with additional genomic features, so their impact on model performance remains unknown.
- What evidence would resolve it: Experiments comparing the performance of GPT-3 with different combinations of genomic features, including gene expression data and epigenetic markers, on the drug sensitivity prediction task.

### Open Question 4
- Question: What is the optimal threshold for converting IC50 values to binary labels for drug sensitivity prediction, and how does it affect the model's performance?
- Basis in paper: [explicit] The study used a fixed threshold θ = −2 for converting IC50 values to binary labels, but did not explore the impact of different thresholds.
- Why unresolved: The study did not experiment with different thresholds, so the optimal threshold and its effect on model performance are not known.
- What evidence would resolve it: Comparative analysis of model performance using different IC50 conversion thresholds to determine the optimal threshold for drug sensitivity prediction.

## Limitations

- The zero-shot prompting approach shows significant class imbalance bias toward the sensitive class, suggesting incomplete capture of resistant response patterns
- Fine-tuning experiments were limited to a single tissue type (LUAD), raising questions about generalizability across the other four tissue types
- Specific prompt templates and formatting used for both zero-shot and fine-tuning scenarios are not fully detailed, making exact replication challenging

## Confidence

- **High Confidence**: GPT-3's capability to process structured pharmacogenomics data when converted to natural language format, and the general trend that feature integration improves prediction performance
- **Medium Confidence**: The specific performance gains (24-29% F1 improvement) from adding mutation and SMILES features, as these are based on single-tissue experiments and specific experimental conditions
- **Medium Confidence**: The claim that pre-training on biomedical corpora would improve per-class performance, as this remains a hypothesis without experimental validation

## Next Checks

1. **Class Balance Validation**: Conduct experiments specifically designed to evaluate and improve per-class performance for both sensitive and resistant categories, potentially through class-weighted loss functions or oversampling techniques during fine-tuning
2. **Cross-Tissue Generalization**: Replicate the fine-tuning experiments across all five tissue types (BRCA, COREAD, THCA, LGG) to validate whether the LUAD-specific findings generalize to other cancer types
3. **Prompt Template Optimization**: Systematically test variations in prompt templates and task instructions to determine optimal prompt engineering strategies for both zero-shot and fine-tuning scenarios, including evaluation of different natural language representations of the structured data