---
ver: rpa2
title: 'LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting
  Strategy for Document-Level Event Argument Extraction'
arxiv_id: '2311.06555'
source_url: https://arxiv.org/abs/2311.06555
tags:
- pattern
- prompting
- argument
- heuristics
- event
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a heuristic-driven link-of-analogy (HD-LoA)
  prompting strategy for document-level event argument extraction using large language
  models. The key idea is that LLMs can learn task-specific heuristics from in-context
  demonstrations.
---

# LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction

## Quick Facts
- arXiv ID: 2311.06555
- Source URL: https://arxiv.org/abs/2311.06555
- Reference count: 19
- Primary result: HD-LoA achieves 4.53% and 9.38% F1 score improvements on two document-level EAE datasets

## Executive Summary
This paper proposes a heuristic-driven link-of-analogy (HD-LoA) prompting strategy for document-level event argument extraction using large language models. The core hypothesis is that LLMs can learn task-specific heuristics from in-context demonstrations, and that explicitly providing these heuristics can improve reasoning efficiency. HD-LoA combines heuristic-driven demonstration construction with analogical reasoning to handle unseen event types. Experiments show HD-LoA outperforms existing prompting methods and few-shot supervised learning on two document-level EAE datasets, while also demonstrating adaptability to sentiment analysis and natural language inference tasks.

## Method Summary
HD-LoA prompting consists of two main components: heuristic-driven demonstration construction and link-of-analogy prompting. Instead of providing multiple examples, the method converts task demonstrations into explicit heuristics while retaining minimal examples for format demonstration. The link-of-analogy component enables LLMs to generalize from known event types to unseen ones through analogical reasoning, using a retrieval-mapping-evaluation process to identify relevant heuristics and apply them to target argument roles. The approach is applied through in-context learning without parameter updates.

## Key Results
- HD-LoA achieves 4.53% and 9.38% F1 score improvements over existing prompting methods on RAMS and DocEE EAE datasets
- The approach shows 2.87% and 2.63% accuracy gains on SST-2 sentiment analysis and SNLI natural language inference tasks
- HD-LoA demonstrates better performance on unseen event types through analogical reasoning
- The method reduces context length by condensing examples into compact heuristics

## Why This Works (Mechanism)

### Mechanism 1
LLMs learn task-specific heuristics from in-context demonstrations during inference. When provided with examples, LLMs extract both lower-level patterns (label space, input distribution) and higher-level heuristics that guide task performance. This learning process is analogous to supervised learning and fine-tuning.

### Mechanism 2
Explicitly providing heuristics in demonstrations simplifies the LLM's reasoning process. By replacing implicit heuristic extraction from examples with direct heuristic provision, LLMs can bypass the two-step recognition-and-inference process and go directly to heuristic-based inference.

### Mechanism 3
Link-of-analogy prompting enables LLMs to generalize heuristics from seen to unseen event types. By retrieving relevant heuristics and mapping them onto target argument roles, LLMs can extrapolate knowledge from known to unknown situations through analogical reasoning.

## Foundational Learning

- **In-context learning (ICL)**: Why needed - the entire approach relies on ICL as the primary mechanism for task adaptation without parameter updates; Quick check - What distinguishes ICL from traditional fine-tuning approaches?
- **Chain-of-Thought (CoT) prompting**: Why needed - HD-LoA is positioned as an improvement over CoT, particularly for non-reasoning tasks; Quick check - Why does CoT prompting degrade to single-step reasoning for non-reasoning tasks?
- **Analogical reasoning**: Why needed - the link-of-analogy component depends on the LLM's ability to perform analogical reasoning across different event types; Quick check - What cognitive science findings support the use of analogical reasoning in LLM prompting?

## Architecture Onboarding

- **Component map**: Heuristic-driven demonstration construction -> Link-of-analogy prompting (retrieval, mapping, evaluation) -> Task-specific pattern demonstration -> LLM inference
- **Critical path**: Prompt construction → heuristic selection and mapping → LLM inference → argument extraction evaluation
- **Design tradeoffs**: Fewer examples (better efficiency) vs. sufficient diversity (better coverage); explicit heuristics (simpler reasoning) vs. implicit learning (more natural adaptation)
- **Failure signatures**: Poor performance on unseen event types suggests analogical reasoning failure; inconsistent outputs suggest heuristic mapping issues
- **First 3 experiments**: 1) Test heuristic-driven construction on sentiment analysis with one example and multiple heuristics; 2) Validate analogical reasoning by providing heuristics for one argument role and testing on related unseen roles; 3) Compare full HD-LoA against standard ICL and CoT on a small document-level EAE dataset

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of HD-LoA prompting vary across different domains of event argument extraction beyond the two datasets tested? The paper only evaluates on the cross-domain setting for DocEE, leaving the conventional setting performance unknown.

### Open Question 2
What is the minimum number of examples needed for HD-LoA prompting to achieve optimal performance, and how does this vary across different tasks? The paper uses 1 example for EAE and 2-3 for other tasks but doesn't systematically explore the trade-off.

### Open Question 3
How does the effectiveness of HD-LoA prompting change as the number of event types and argument roles increases beyond what was tested? The paper notes EAE tasks can feature hundreds of distinct types but only evaluates on datasets with limited variety.

## Limitations

- Limited corpus evidence directly validating that LLMs learn task-specific heuristics from demonstrations
- No systematic exploration of optimal example quantity versus performance trade-offs
- Limited testing on scenarios with hundreds of event types and argument roles to validate generalizability

## Confidence

- Heuristic learning from demonstrations: Medium
- Explicit heuristic provision improves reasoning: Medium
- Analogical reasoning enables generalization: Medium-High
- HD-LoA outperforms baselines: High
- Broad adaptability to different tasks: Medium

## Next Checks

1. **Validate heuristic learning mechanism**: Design experiments comparing heuristic extraction from examples versus direct heuristic provision on multiple tasks, measuring reasoning efficiency and output consistency to empirically test if LLMs learn heuristics from demonstrations.

2. **Test analogical reasoning limits**: Systematically vary the semantic distance between seen and unseen argument roles in controlled experiments to identify when analogical mapping breaks down and quantify the transfer capability limits.

3. **Evaluate robustness to prompt variation**: Conduct sensitivity analysis on prompt structure, heuristic specificity, and example selection to determine how robust HD-LoA is to prompt engineering choices and whether performance degrades predictably under perturbation.