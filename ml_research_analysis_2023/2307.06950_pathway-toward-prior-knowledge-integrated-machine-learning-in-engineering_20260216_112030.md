---
ver: rpa2
title: Pathway toward prior knowledge-integrated machine learning in engineering
arxiv_id: '2307.06950'
source_url: https://arxiv.org/abs/2307.06950
tags:
- knowledge
- data
- learning
- domain
- engineering
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes a knowledge-integrated machine learning paradigm
  to bridge first-principles and data-driven approaches in engineering. It systematically
  analyzes information uncertainty sources through knowledge representation and decomposes
  knowledge into a three-tier integration framework.
---

# Pathway toward prior knowledge-integrated machine learning in engineering

## Quick Facts
- arXiv ID: 2307.06950
- Source URL: https://arxiv.org/abs/2307.06950
- Reference count: 8
- One-line primary result: Proposes a three-tier knowledge-integrated machine learning framework to bridge first-principles and data-driven approaches in engineering.

## Executive Summary
This study presents a knowledge-integrated machine learning paradigm designed to address the performance gaps in engineering applications caused by data limitations, model simplifications, and confirmation biases. The approach systematically decomposes prior knowledge and integrates it with machine learning through a three-level ladder framework. By reconciling holist and reductionist perspectives, the method combines symbolic knowledge with connectionist learning methods to reduce epistemic uncertainty and improve model performance across engineering domains.

## Method Summary
The research proposes a systematic pathway for integrating prior knowledge with machine learning through three progressive levels. The framework begins with knowledge-guided data augmentation for interpolation, advances to knowledge-constrained learning rules and objective functions for extrapolation, and culminates in representation learning with second-order knowledge for causal discovery. Knowledge is decomposed into domain, mathematical, and complexity dimensions before integration. The approach addresses aleatory and epistemic uncertainties by constraining ML models with first-principles models encoded as symbolic rules, mathematical transformations, or multi-scale representations.

## Key Results
- Proposes a three-tier ladder for knowledge-ML integration: interpolation via data augmentation, extrapolation through constraints, and representation learning for causal discovery
- Decomposes knowledge into domain, mathematical, and complexity levels to enable targeted integration strategies
- Addresses epistemic uncertainty in engineering predictions by encoding domain knowledge as symbolic constraints in ML architectures
- Reconciles holist and reductionist perspectives by combining symbolic knowledge with connectionist learning methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating first-principles models with ML reduces epistemic uncertainty in engineering predictions.
- Mechanism: Domain knowledge encoded as symbolic rules constrains ML model architecture, learning rules, and objective functions, guiding the model toward physically consistent solutions and reducing structural epistemic uncertainty.
- Core assumption: Symbolic knowledge accurately captures relevant system physics and constraints.
- Evidence anchors:
  - [abstract] "This approach reconciles holist and reductionist perspectives by combining symbolic knowledge with connectionist learning methods."
  - [section] "Rooted in the reductionism mindset, the first-principles simulation driven by domain knowledge is based on the idea that breaking down a complex problem into smaller parts will necessarily result in a complete understanding of the issue."
  - [corpus] Weak evidence; no direct citations in corpus, but the concept aligns with related works on knowledge-integrated frameworks.
- Break condition: If symbolic rules are incomplete, incorrect, or poorly formalized, the integration may introduce bias rather than reduce uncertainty.

### Mechanism 2
- Claim: Decomposing knowledge into domain, mathematical, and complexity levels enables targeted integration with ML.
- Mechanism: Different decomposition strategies (domain, mathematical, complexity) extract complementary information from systems, which can be encoded as features, constraints, or multi-scale representations for ML models.
- Core assumption: Knowledge can be effectively decomposed without losing critical system interdependencies.
- Evidence anchors:
  - [section] "Knowledge-based decomposition: Before we step on the ladder, we must revisit our embodied prior knowledge from the perspective of decomposition. For a machine to learn, it must have a means of representing the knowledge it will acquire."
  - [section] "Essentially, the purpose of knowledge decomposition and data processing is to transfer information into a unified, machine-learnable representation."
  - [corpus] Weak evidence; the corpus does not explicitly address decomposition strategies, but the concept is consistent with multi-scale modeling literature.
- Break condition: If decomposition oversimplifies or fragments critical system relationships, integration effectiveness decreases.

### Mechanism 3
- Claim: Three-tier integration ladder (interpolation, extrapolation, representation) provides a systematic path to knowledge-ML integration.
- Mechanism: Level 1 uses knowledge for data augmentation; Level 2 integrates knowledge into model architecture and learning; Level 3 employs second-order knowledge for causal discovery and self-supervised learning.
- Core assumption: Each level builds upon and is compatible with lower levels, creating a cumulative integration path.
- Evidence anchors:
  - [abstract] "The three-level ladder includes: (1) interpolation via knowledge-guided data augmentation, (2) extrapolation through knowledge-constrained learning rules and objective functions, and (3) representation learning with second-order knowledge for causal discovery and self-supervised learning."
  - [section] "At this level, the most notable feature is that the ML modeling process is not solely data-driven. The reconstruction and integration of knowledge serve as a 'skeleton' that allows the model modification to be more specialized in the corresponding engineering domain."
  - [corpus] Weak evidence; related works exist but do not explicitly describe a three-tier ladder framework.
- Break condition: If higher-level integration is attempted without sufficient lower-level foundation, the system may fail to learn effectively.

## Foundational Learning

- Concept: No Free Lunch (NFL) theorem in optimization
  - Why needed here: Explains why no single algorithm works best across all scenarios, justifying the need for knowledge integration.
  - Quick check question: What does the NFL theorem state about algorithm performance across different problem spaces?

- Concept: Aleatory vs. epistemic uncertainty
  - Why needed here: Distinguishes between inherent randomness and knowledge-based uncertainty, guiding integration strategy.
  - Quick check question: How do aleatory and epistemic uncertainties differ in their origins and potential mitigation?

- Concept: Causal inference and counterfactual reasoning
  - Why needed here: Enables Level 3 integration by allowing models to discover causal relationships rather than mere correlations.
  - Quick check question: What is the difference between correlation and causation, and why is this distinction important for ML in engineering?

## Architecture Onboarding

- Component map:
  - Data preprocessing pipeline (feature engineering, synthetic data generation)
  - Knowledge formalization module (symbolic rules, mathematical transformations)
  - Multi-level integration framework (Levels 1-3)
  - ML model architecture (neural networks, component-based ML)
  - Uncertainty quantification and validation module

- Critical path: Knowledge formalization → Data augmentation → Model integration → Validation and uncertainty quantification

- Design tradeoffs:
  - Granularity of knowledge decomposition vs. system complexity
  - Symbolic constraint strength vs. model flexibility
  - Data augmentation volume vs. computational cost
  - Integration level depth vs. implementation complexity

- Failure signatures:
  - Poor model performance due to overly restrictive constraints
  - Increased uncertainty from incomplete or incorrect knowledge formalization
  - Computational inefficiency from excessive data augmentation
  - Model overfitting when integration level exceeds available knowledge quality

- First 3 experiments:
  1. Implement Level 1 integration: Add physics-based features and synthetic data to a baseline ML model for building energy prediction, compare performance.
  2. Implement Level 2 integration: Modify a neural network with physics-informed loss function for heat transfer simulation, evaluate extrapolation capability.
  3. Implement Level 3 integration: Apply causal discovery algorithms to identify key variables in building performance data, use discovered relationships to constrain ML model training.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific mechanisms enable second-order knowledge to discover causal dependencies in building performance data without introducing new biases?
- Basis in paper: [explicit] Level 3 discussion on causal inference and self-supervised learning
- Why unresolved: The paper identifies causal inference as a key mechanism but does not detail how it prevents the introduction of spurious correlations or biases during unsupervised discovery
- What evidence would resolve it: Empirical studies comparing causal discovery performance with and without domain knowledge priors, demonstrating reduced bias in discovered causal structures

### Open Question 2
- Question: How can the three-tier integration framework be optimally weighted or combined for different engineering domains beyond building engineering?
- Basis in paper: [inferred] The paper proposes a three-level ladder but does not provide a methodology for determining optimal integration strategies across different engineering domains
- Why unresolved: The paper presents the framework conceptually but lacks quantitative methods for determining the appropriate balance between levels for different types of engineering problems
- What evidence would resolve it: Comparative studies across multiple engineering domains showing performance metrics for different integration level combinations

### Open Question 3
- Question: What computational overhead is introduced by integrating knowledge at each level of the proposed framework, and how does this impact real-time engineering applications?
- Basis in paper: [inferred] The paper discusses knowledge integration benefits but does not quantify computational costs or address real-time application constraints
- Why unresolved: The trade-offs between improved accuracy/interpretability and computational efficiency are not explicitly addressed, particularly for time-sensitive engineering decisions
- What evidence would resolve it: Benchmarking studies comparing inference times and resource utilization across different levels of knowledge integration for representative engineering tasks

## Limitations

- Limited empirical validation of the three-tier integration framework in real engineering applications
- Unclear guidance on knowledge formalization quality assessment and failure detection
- Absence of quantitative benchmarks comparing integrated approaches to pure data-driven methods

## Confidence

**High confidence**: The theoretical framework for knowledge decomposition and the three-tier integration ladder is logically coherent and builds on established concepts in machine learning and engineering knowledge representation.

**Medium confidence**: The mechanism by which knowledge integration reduces epistemic uncertainty is well-reasoned but lacks empirical validation across diverse engineering domains.

**Low confidence**: The specific implementation details for Level 3 integration (representation learning with second-order knowledge) remain vague and would require significant additional development for practical deployment.

## Next Checks

1. Implement the three-tier framework on a benchmark engineering dataset (e.g., building energy consumption or heat transfer) and quantify performance improvements against baseline models across all three integration levels.

2. Conduct sensitivity analysis on knowledge formalization quality by systematically degrading the accuracy of encoded domain knowledge and measuring the impact on model performance and uncertainty reduction.

3. Develop a diagnostic framework to detect and characterize different failure modes (overly restrictive constraints, incomplete knowledge, computational inefficiency) during the integration process.