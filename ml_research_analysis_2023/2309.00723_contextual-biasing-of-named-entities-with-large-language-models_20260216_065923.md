---
ver: rpa2
title: Contextual Biasing of Named-Entities with Large Language Models
arxiv_id: '2309.00723'
source_url: https://arxiv.org/abs/2309.00723
tags:
- biasing
- class
- contextual
- list
- token
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of contextual biasing in speech
  recognition, where rare named entities are difficult to recognize. The core method
  idea is to leverage prompts and multi-task training in large language models (LLMs)
  to incorporate contextual information during second-pass rescoring.
---

# Contextual Biasing of Named-Entities with Large Language Models

## Quick Facts
- **arXiv ID**: 2309.00723
- **Source URL**: https://arxiv.org/abs/2309.00723
- **Reference count**: 0
- **Primary result**: Biasing lists and few-shot examples achieve 17.8% and 9.6% relative WER improvement; multi-task training and dynamic prompting achieve 20.0% and 11.3% relative WER improvement

## Executive Summary
This paper proposes using large language models (LLMs) for contextual biasing in speech recognition, specifically targeting rare named entities. The authors introduce three key techniques: prompt-based biasing with entity lists and few-shot examples, multi-task training to predict both entity classes and tokens, and dynamic prompting that filters entities based on predicted classes. Experiments on CMD and SLUE-Voxpopuli datasets show significant Word Error Rate (WER) improvements over first-pass ASR systems, with multi-task training and dynamic prompting achieving up to 20.0% relative improvement.

## Method Summary
The authors leverage LLMs as second-pass rescorers for speech recognition hypotheses, incorporating contextual biasing through carefully designed prompts. They implement multi-task training by adding a class prediction head to the LLM, using Gumbel softmax to handle the non-differentiability of argmax operations. Dynamic prompting selects only relevant entities per token based on predicted classes, reducing sequence length and attention confusion. The approach uses LoRA for efficient fine-tuning and evaluates performance using WER and pseudo log-likelihood metrics across two datasets.

## Key Results
- Biasing lists and few-shot examples achieve 17.8% and 9.6% relative WER improvement
- Multi-task training and dynamic prompting achieve 20.0% and 11.3% relative WER improvement
- Significant improvements demonstrated on both CMD (445k samples) and SLUE-Voxpopuli (5k samples) datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contextual biasing through prompts improves LLM performance on rare named entities.
- Mechanism: Incorporating biasing lists and few-shot examples into prompts steers the model's focus toward relevant contextual information during rescoring.
- Core assumption: LLMs can effectively process and utilize structured prompt inputs to bias predictions toward specified entities.
- Evidence anchors:
  - [abstract]: "We propose to leverage prompts for a LLM without fine tuning during rescoring which incorporate a biasing list and few-shot examples to serve as additional information when calculating the score for the hypothesis."
  - [section]: "Figure 1 demonstrates a simple yet illustrative example of the power of prompting with LLaMA. We can observe that few-shot examples can help improve the quality of the generated words."
  - [corpus]: Weak correlation (FMR=0.53) with related papers; insufficient evidence to confirm general effectiveness of prompt-based biasing across LLMs.
- Break condition: If the prompt exceeds maximum sequence length or if entities are too numerous to fit within prompt constraints.

### Mechanism 2
- Claim: Multi-task training with class prediction improves contextual biasing.
- Mechanism: Adding a class tag head to predict entity classes and using Gumbel softmax for differentiable argmax allows joint training of token and class prediction.
- Core assumption: Predicting entity classes helps the model better attend to relevant entities during token prediction.
- Evidence anchors:
  - [abstract]: "We propose multi-task training of the LLM to predict both the entity class and the next token."
  - [section]: "The embedding will then be added with the embedding from the backbone and used to predict the next token. While the process may seem straightforward, a key challenge arises due to the non-differentiability of the argmax operation used to select the class with the highest probability."
  - [corpus]: Moderate correlation (FMR=0.58) with related work on contextual biasing; evidence suggests multi-task approaches can improve NER performance.
- Break condition: If class prediction becomes unreliable due to class imbalance or if Gumbel softmax introduces too much noise.

### Mechanism 3
- Claim: Dynamic prompting improves efficiency and accuracy by reducing irrelevant entities.
- Mechanism: Selecting only entities from the predicted class for each token reduces sequence length and attention confusion.
- Core assumption: Entity classes are mutually exclusive enough that filtering by predicted class improves performance.
- Evidence anchors:
  - [abstract]: "We propose dynamic prompting, where we select the most likely class using the class tag prediction, and only use entities in this class as contexts for next token prediction."
  - [section]: "This not only reduces the length of the sequence, but also reduces the number of entities the model needs to attend on, and consequently improving the model performance."
  - [corpus]: Weak correlation (FMR=0.55) with related papers; insufficient evidence that dynamic prompting consistently improves results across different datasets.
- Break condition: If class prediction accuracy drops below threshold or if multiple classes are equally likely for a token.

## Foundational Learning

- Concept: Prompt engineering and few-shot learning
  - Why needed here: Understanding how to structure prompts effectively is crucial for leveraging LLMs in contextual biasing.
  - Quick check question: What are the key considerations when designing prompts for LLMs to avoid exceeding maximum sequence length?

- Concept: Multi-task learning and loss function design
  - Why needed here: Combining token prediction with class prediction requires understanding how to balance different loss components.
  - Quick check question: How does the Gumbel softmax trick make the argmax operation differentiable in multi-task learning?

- Concept: Attention mechanisms and sequence length constraints
  - Why needed here: Dynamic prompting relies on understanding how attention works and how sequence length affects model performance.
  - Quick check question: What are the potential issues when an LLM has to attend to a large number of entities in a long sequence?

## Architecture Onboarding

- Component map: Prompt generator -> Multi-task LLM -> Dynamic filter -> Rescorer
- Critical path:
  1. Generate hypothesis from first-pass ASR
  2. Create contextual prompts with biasing lists
  3. Run through multi-task LLM with dynamic filtering
  4. Calculate scores and select best hypothesis
- Design tradeoffs:
  - Longer prompts vs. sequence length limits
  - More entity classes vs. class prediction accuracy
  - Complex multi-task training vs. simpler single-task approaches
- Failure signatures:
  - Poor performance on short utterances with little context
  - Degradation when ground truth entities are missing from biasing lists
  - Attention confusion when too many entities are present
- First 3 experiments:
  1. Test prompt-based biasing with fixed biasing lists on a small dataset
  2. Add few-shot examples to prompts and measure improvement
  3. Implement multi-task training and compare with single-task approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed dynamic prompting method compare to traditional contextual biasing methods in terms of efficiency and accuracy when dealing with very long biasing lists?
- Basis in paper: [explicit] The paper mentions that the proposed dynamic prompting method is designed to improve attention efficiency and reduce input sequence length, but does not provide a direct comparison with traditional methods in terms of efficiency and accuracy.
- Why unresolved: The paper focuses on demonstrating the effectiveness of the proposed method but does not provide a detailed comparison with traditional methods in terms of efficiency and accuracy when dealing with very long biasing lists.
- What evidence would resolve it: A comprehensive study comparing the proposed dynamic prompting method with traditional contextual biasing methods in terms of efficiency and accuracy when dealing with very long biasing lists.

### Open Question 2
- Question: How does the performance of the proposed multi-task training method vary with different entity class distributions in the biasing list?
- Basis in paper: [inferred] The paper mentions that the entity class is highly unbalanced, and a weight is assigned to each class during training. However, it does not explore how the performance varies with different entity class distributions in the biasing list.
- Why unresolved: The paper does not provide a detailed analysis of how the performance of the proposed multi-task training method varies with different entity class distributions in the biasing list.
- What evidence would resolve it: A detailed analysis of the performance of the proposed multi-task training method with different entity class distributions in the biasing list.

### Open Question 3
- Question: How does the proposed method handle out-of-vocabulary (OOV) named entities that are not present in the biasing list?
- Basis in paper: [inferred] The paper focuses on improving the recognition of named entities in the biasing list but does not explicitly address how the proposed method handles OOV named entities that are not present in the biasing list.
- Why unresolved: The paper does not provide a detailed discussion on how the proposed method handles OOV named entities that are not present in the biasing list.
- What evidence would resolve it: A detailed analysis of how the proposed method handles OOV named entities that are not present in the biasing list.

## Limitations
- Limited dataset diversity with experiments conducted primarily on internal CMD dataset and one public SLUE-Voxpopuli dataset
- No comparison with alternative biasing methods like Trie-based decoding or traditional class-based language models
- Missing implementation specifics including training hyperparameters and LoRA configuration details

## Confidence
- **High confidence**: Prompt-based biasing with few-shot examples shows consistent WER improvements across both datasets (9.6% relative improvement)
- **Medium confidence**: Multi-task training claims (20.0% relative improvement) are supported by experimental results but lack comparison with simpler alternatives
- **Medium confidence**: Dynamic prompting benefits (11.3% relative improvement) are demonstrated but may depend heavily on class prediction accuracy

## Next Checks
1. **Cross-dataset generalization test**: Apply the same methodology to a third, diverse dataset (e.g., TED Talks or podcast transcripts) to verify if relative WER improvements hold beyond the two tested datasets
2. **Ablation study on class prediction accuracy**: Measure how WER improvements correlate with entity class prediction accuracy, particularly testing performance when class prediction accuracy drops below 80%
3. **Sequence length impact analysis**: Systematically test how performance scales with increasing number of biasing entities (from 10 to 100+ entities) to determine the practical limits of prompt-based biasing