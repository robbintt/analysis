---
ver: rpa2
title: 'Why Autonomous Vehicles Are Not Ready Yet: A Multi-Disciplinary Review of
  Problems, Attempted Solutions, and Future Directions'
arxiv_id: '2311.09093'
source_url: https://arxiv.org/abs/2311.09093
tags:
- autonomous
- detection
- vehicles
- driving
- vehicle
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper reviews the applications of computer vision in autonomous
  vehicles. It examines the development of autonomous driving systems from major manufacturers,
  common sensors and datasets, and four key computer vision tasks: depth estimation,
  object detection, lane detection, and traffic sign recognition.'
---

# Why Autonomous Vehicles Are Not Ready Yet: A Multi-Disciplinary Review of Problems, Attempted Solutions, and Future Directions

## Quick Facts
- arXiv ID: 2311.09093
- Source URL: https://arxiv.org/abs/2311.09093
- Reference count: 40
- Most current autonomous vehicles operate at level 2 or 3 autonomy, requiring human supervision due to unresolved technical challenges.

## Executive Summary
This paper reviews the state of autonomous vehicle technology, examining why full autonomy remains elusive despite significant advances in computer vision and sensor technology. The analysis reveals that most commercial systems are limited to level 2 (driver assistance) or level 3 (conditional automation) capabilities, falling short of the level 4 and 5 autonomy needed for true driverless operation. Key challenges include adverse weather conditions that degrade sensor performance, processing constraints that limit real-time decision-making, and high costs that prevent widespread adoption. The review identifies four critical computer vision tasks—depth estimation, object detection, lane detection, and traffic sign recognition—as areas requiring further research and development to achieve higher autonomy levels.

## Method Summary
The paper employs a comprehensive literature review methodology, examining autonomous driving systems from major manufacturers, common sensor technologies, benchmark datasets, and four key computer vision tasks. The analysis synthesizes information from academic publications, industry reports, and technical documentation to identify current limitations and future research directions. The review focuses on technological challenges rather than regulatory or social factors, providing a technical perspective on why autonomous vehicles remain imperfect despite significant investment and development efforts.

## Key Results
- Current commercial autonomous vehicles primarily operate at level 2 or 3 autonomy, requiring human supervision
- Sensor performance degrades significantly under adverse weather conditions like sun glare and rain
- Processing constraints prevent real-time analysis of the massive data volume generated by autonomous vehicle sensors
- High costs (approximately $250,000 vs $30,000 for conventional vehicles) limit market adoption

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Autonomous vehicles are not ready because perception systems still fail under adverse conditions like sun glare and poor weather.
- Mechanism: Perception algorithms (camera, LiDAR, radar) degrade when environmental conditions obscure or distort sensor input, leading to unsafe driving decisions.
- Core assumption: Degradation in sensor data quality directly translates to unsafe vehicle behavior.
- Evidence anchors:
  - [abstract] "Challenges include adverse weather conditions, failure detection in complex environments"
  - [section] "Sun glare is a commonly encountered environment hazard... degrades the performance of computer vision algorithms"
  - [corpus] Weak corpus support; only generic AV terms found, no specific adverse-condition data
- Break condition: If perception systems can robustly fuse multi-modal sensor data or operate safely under degraded inputs, this mechanism weakens.

### Mechanism 2
- Claim: Data volume and real-time processing constraints prevent full autonomy.
- Mechanism: Autonomous vehicles generate ~4000 GB/day of sensor data; current computing platforms cannot process this in real-time within the 0.1s safety window.
- Core assumption: Processing latency directly limits vehicle reaction time and safety.
- Evidence anchors:
  - [abstract] "data size and processing speed" listed as challenges
  - [section] "autonomous vehicles produce about 4000 GB of data a day... this requires a significant amount of computing power"
  - [corpus] No corpus support for data volume claims; only generic AV references
- Break condition: If edge computing or lightweight CNNs reduce data load and latency sufficiently, this mechanism weakens.

### Mechanism 3
- Claim: High costs and public unwillingness to pay for autonomous features limit adoption.
- Mechanism: Full autonomy costs ~$250k vs $30k for conventional vehicles; surveys show most consumers unwilling to pay extra.
- Core assumption: Cost premium must be accepted by consumers for market viability.
- Evidence anchors:
  - [abstract] "high costs" listed as challenges
  - [section] "average cost to build a conventional non-luxury vehicle in the US is around $30000, while for a fully autonomous vehicle, the total cost is increased to $250000"
  - [corpus] No corpus support for cost figures; only generic AV references
- Break condition: If cost reductions through economies of scale or alternative business models emerge, this mechanism weakens.

## Foundational Learning

- Concept: Sensor fusion principles
  - Why needed here: Autonomous vehicles rely on multiple sensors; understanding how to combine their data is critical to overcoming individual sensor limitations.
  - Quick check question: If a camera and LiDAR disagree on object distance, which sensor's data should the system trust and why?

- Concept: Real-time deep learning inference
  - Why needed here: Perception tasks must run in <0.1s; engineers need to know how to optimize CNNs for latency.
  - Quick check question: What techniques can reduce inference time without significantly hurting accuracy?

- Concept: Risk assessment in dynamic environments
  - Why needed here: Autonomous vehicles must anticipate hazards from unpredictable actors; understanding uncertainty modeling is key.
  - Quick check question: How would you model the probability that a pedestrian will suddenly cross the road?

## Architecture Onboarding

- Component map: Sensors (cameras, LiDAR, radar, ultrasonic) → Perception Engine (depth estimation, object detection, lane detection, traffic sign recognition) → Decision Module → Actuators. Edge computing layer optional for offloading.
- Critical path: Sensor data acquisition → Perception processing → Decision making → Vehicle control commands.
- Design tradeoffs: Accuracy vs. latency vs. cost; using LiDAR improves accuracy but increases cost and data volume.
- Failure signatures: Sensor dropout (noisy or missing data), perception misclassification, decision timeout, actuator failure.
- First 3 experiments:
  1. Simulate adverse weather (rain/fog) and measure perception accuracy drop; test sensor fusion mitigation.
  2. Benchmark lightweight CNN models on embedded hardware for <0.1s inference time.
  3. Implement a risk assessment module that flags high-uncertainty detections and forces conservative driving behavior.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific combination of sensors and AI technologies would enable level 4 and level 5 autonomous vehicles in diverse real-world conditions?
- Basis in paper: [explicit] The paper notes that level 4 and 5 systems require high-level computer vision tasks like vision-based path planning and visual localization and mapping, but current commercialized systems do not deploy these functions.
- Why unresolved: The paper indicates these tasks are still in academic research and not yet implemented in commercial vehicles, despite being necessary for higher autonomy levels.
- What evidence would resolve it: Demonstration of a commercial autonomous vehicle system that successfully implements vision-based path planning and visual localization/mapping in diverse real-world conditions, achieving level 4 or 5 autonomy.

### Open Question 2
- Question: How can autonomous vehicles effectively handle unpredictable human behaviors and environmental uncertainties in real-time risk assessment?
- Basis in paper: [explicit] The paper identifies risk assessment algorithms as an important future direction, noting that autonomous vehicles are not completely risk-free due to dynamic real-world environments, varying weather conditions, and unpredictable behaviors of pedestrians and cyclists.
- Why unresolved: Current autonomous vehicle systems struggle with real-time processing of complex environmental variables and human behaviors to make safe driving decisions.
- What evidence would resolve it: Development and validation of a risk assessment algorithm that successfully predicts and mitigates potential hazards in diverse real-world driving scenarios, improving safety beyond human driver capabilities.

### Open Question 3
- Question: What are the most effective methods for reducing the cost of autonomous vehicles while maintaining safety and performance standards?
- Basis in paper: [explicit] The paper highlights that autonomous vehicles currently cost approximately $250,000 to build compared to $30,000 for conventional vehicles, while public surveys show most people are unwilling to pay extra for autonomous features.
- Why unresolved: The high cost of sensors (especially LiDAR), computing platforms, and other onboard devices creates a significant price gap that limits market adoption.
- What evidence would resolve it: Successful commercialization of an autonomous vehicle system that achieves level 3 or higher autonomy at a price point competitive with conventional vehicles, with documented cost reduction strategies that maintain safety and performance standards.

## Limitations

- The paper relies heavily on secondary sources and published literature rather than primary empirical data or original experiments.
- Specific technical claims (cost figures, data volume statistics, failure rates) lack direct verification and may be outdated.
- The review does not address regulatory, legal, or social barriers that may be as significant as technical challenges to autonomous vehicle deployment.

## Confidence

- Medium Confidence: Claims about current autonomy levels (L2/L3) and sensor usage are well-supported by industry announcements and product specifications.
- Low Confidence: Specific cost estimates ($250k for full autonomy, 4000 GB/day data generation) lack primary source verification and may be oversimplified.
- Medium Confidence: General challenges like adverse weather impact and processing latency are theoretically sound, though specific failure rates and mitigation effectiveness are not empirically validated.

## Next Checks

1. Obtain primary source data on actual autonomous vehicle production costs and data generation rates from automotive manufacturers or industry reports.
2. Conduct controlled experiments measuring perception system performance degradation under simulated adverse weather conditions (sun glare, rain, fog) across different sensor modalities.
3. Benchmark current lightweight CNN models on embedded automotive platforms to verify whether <0.1s inference times are achievable for real-time perception tasks.