---
ver: rpa2
title: Learning to Sample Better
arxiv_id: '2310.11232'
source_url: https://arxiv.org/abs/2310.11232
tags:
- rbbbd
- where
- sampling
- learning
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: These lecture notes provide an introduction to generative modeling
  methods based on the dynamical transportation of measures, by means of which samples
  from a simple base measure are mapped to samples from a target measure of interest.
  Special emphasis is put on the applications of these methods to Monte-Carlo (MC)
  sampling techniques, such as importance sampling and Markov Chain Monte-Carlo (MCMC)
  schemes.
---

# Learning to Sample Better

## Quick Facts
- arXiv ID: 2310.11232
- Source URL: https://arxiv.org/abs/2310.11232
- Reference count: 37
- These lecture notes provide an introduction to generative modeling methods based on the dynamical transportation of measures, by means of which samples from a simple base measure are mapped to samples from a target measure of interest. Special emphasis is put on the applications of these methods to Monte-Carlo (MC) sampling techniques, such as importance sampling and Markov Chain Monte-Carlo (MCMC) schemes.

## Executive Summary
This work presents a comprehensive framework for learning transport maps that transform samples from a simple base distribution into samples from a complex target distribution. The approach leverages dynamical transportation of measures through time-dependent velocity fields, connecting this mathematical framework to practical Monte Carlo sampling methods. The key innovation lies in learning these transport maps variationally using data generated by Monte Carlo sampling, creating a positive feedback loop where improved maps lead to better sampling.

The methodology bridges theoretical measure transportation with practical computational techniques, offering multiple strategies for learning velocity fields including adjoint-based gradient computation and simulation-free methods like score-based diffusion models and stochastic interpolants. The framework is particularly valuable for Monte Carlo applications where generating high-quality samples from complex distributions is crucial for accurate inference and estimation.

## Method Summary
The core method involves learning a time-dependent velocity field v(t,x) that defines a flow transporting samples from a base distribution to a target distribution. The transport is governed by the continuity equation ∂tρ_t = -∇·(vρ_t), where ρ_t represents the evolving distribution. The velocity field is learned by minimizing a divergence measure between the transported base distribution and the target distribution, with options including reverse KL divergence, forward KL divergence, and χ² divergence. Learning can proceed through adjoint-based methods that solve backward ODEs for gradient computation, or through simulation-free approaches like score-based diffusion models and stochastic interpolants that frame the problem as quadratic regression.

## Key Results
- Transport maps learned via reverse KL divergence can improve Monte Carlo sampling efficiency by reducing variance in importance weights
- Stochastic interpolants provide a simulation-free alternative to adjoint-based methods for learning transport maps
- Map-assisted Metropolis-Hastings chains achieve faster convergence by proposing moves from transported samples rather than direct base samples

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transport maps learned via reverse KL divergence improve Monte Carlo sampling efficiency by reducing variance in importance weights.
- Mechanism: The reverse KL divergence objective pushes the transported measure ρt=1 closer to the target ρ* by minimizing ∫log(ρt=1/ρ*)ρt=1 dx. This creates a feedback loop where learned maps progressively concentrate proposals in high-probability regions of the target.
- Core assumption: The neural network used to parameterize the velocity field is sufficiently expressive to approximate the optimal transport map.
- Break condition: When the target distribution is multimodal and the initial map is poorly initialized, the reverse KL divergence can lead to mode collapse, focusing only on one mode.

### Mechanism 2
- Claim: Stochastic interpolants provide a simulation-free alternative to adjoint-based methods for learning transport maps.
- Mechanism: By defining a stochastic process x_t = α(t)x_b + β(t)x* that interpolates between base and target measures, the velocity field can be learned through quadratic regression without solving ODEs backward in time.
- Core assumption: The stochastic interpolant process can be sampled efficiently from both base and target distributions.
- Break condition: When the base and target measures have very different support or topology, the linear interpolation may not provide sufficient flexibility for accurate transport.

### Mechanism 3
- Claim: Map-assisted Metropolis-Hastings chains achieve faster convergence by proposing moves from transported samples rather than direct base samples.
- Mechanism: Independent proposals generated by pushing base samples through the learned map X_t=1 are accepted with probability min(exp(R(xi, x_b)), 1), where R incorporates both the target and base potentials plus Jacobian corrections.
- Core assumption: The transport map sufficiently approximates the target distribution so that proposal acceptance rates remain reasonable.
- Break condition: If the learned map poorly approximates the target, acceptance rates may drop significantly, degrading performance compared to standard MCMC.

## Foundational Learning

- Concept: Measure transportation theory
  - Why needed here: The entire framework relies on understanding how to move probability measures from a simple base to a complex target using continuous-time flows
  - Quick check question: What is the relationship between the continuity equation ∂tρ_t = -∇·(vρ_t) and the probability flow ODE ˙X_t(x) = v(t,X_t(x))?

- Concept: Kullback-Leibler divergence
  - Why needed here: KL divergence serves as the objective function for learning transport maps, with reverse and forward forms offering different trade-offs
  - Quick check question: Why does the reverse KL divergence lead to mode-seeking behavior while the forward KL leads to mass-covering behavior?

- Concept: Stochastic differential equations
  - Why needed here: Score-based diffusion models and stochastic interpolants rely on SDEs to define the transport between distributions
  - Quick check question: How does the reverse-time SDE dX_Rt = X_Rt dt + 2∇log ρ_T-t(X_Rt)dt + √2dW_t relate to the forward diffusion process?

## Architecture Onboarding

- Component map: Base sampler → Velocity network v_θ(t,x) → ODE solver (forward) → Transported samples → Objective computation → Gradient computation (adjoint or simulation-free) → Parameter update
- Critical path: Base samples → ODE integration (forward) → proposal generation → objective evaluation → gradient computation → parameter update. For MCMC applications, add acceptance/rejection step and chain state management.
- Design tradeoffs: Reverse KL divergence allows training with only base samples but may struggle with multimodal targets; direct KL requires target samples but explores better; SBDM and stochastic interpolants offer simulation-free training but require different sampling strategies. Choice depends on data availability and target complexity.
- Failure signatures: Slow convergence indicates poor initialization or insufficient network capacity; mode collapse suggests reverse KL with multimodal targets; numerical instability in ODE integration suggests need for smaller time steps or better integrators; low acceptance rates in MCMC suggest the transport map needs refinement.
- First 3 experiments:
  1. Implement Algorithm 1 on a 2D Gaussian mixture target using a fully connected network, starting with zero velocity, and visualize the learned transport map and resulting sample quality
  2. Compare reverse vs forward KL training on the same problem, measuring effective sample size and convergence speed
  3. Implement Algorithm 4 for map-assisted MCMC on a challenging multimodal distribution, comparing autocorrelation times with standard HMC

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we improve the exploration capabilities of reverse KL divergence-based methods when the target distribution is multi-modal?
- Basis in paper: The paper mentions that the reverse KL divergence-based variational formulation is limited in its exploration capabilities, particularly when the target is multi-modal.
- Why unresolved: The paper states that if we do not start with an informed guess for the velocity field, it will be hard to perform the optimization and train the velocity so that the pushforward of the base distribution by X t=1 is close to the target.
- What evidence would resolve it: Developing and testing new methods or modifications to the reverse KL divergence-based approach that can effectively handle multi-modal distributions, and comparing their performance to existing methods.

### Open Question 2
- Question: Can we develop more efficient and scalable algorithms for learning the transport map using the direct KL divergence or score-based diffusion models?
- Basis in paper: The paper discusses the challenges of using the adjoint method for computing gradients in the reverse KL divergence-based approach, and mentions the need for simulation-free methods like score-based diffusion models.
- Why unresolved: While the paper introduces these methods, it does not provide a detailed comparison of their efficiency and scalability compared to other approaches.
- What evidence would resolve it: Conducting extensive experiments to compare the computational efficiency and scalability of different methods for learning the transport map, including the direct KL divergence, score-based diffusion models, and stochastic interpolants.

### Open Question 3
- Question: How can we effectively incorporate prior knowledge about the target distribution into the learning process of the transport map?
- Basis in paper: The paper mentions the possibility of using different types of divergence measures (e.g., χ2-divergence) and the flexibility of the stochastic interpolant framework, which could potentially allow for incorporating prior knowledge.
- Why unresolved: The paper does not provide a detailed discussion on how to incorporate prior knowledge into the learning process, and it is unclear how effective these approaches would be in practice.
- What evidence would resolve it: Developing and testing methods that can effectively incorporate prior knowledge about the target distribution into the learning process of the transport map, and evaluating their performance compared to methods that do not use prior knowledge.

## Limitations
- The framework assumes the target measure has sufficient regularity for the transport map to exist and be computable via neural networks, which may fail for highly discontinuous or irregular targets.
- The reverse KL divergence objective can lead to mode collapse in multimodal settings when the initial map is poorly initialized, potentially missing significant probability mass in the target distribution.
- Numerical stability of adjoint-based gradient computation is sensitive to time discretization, particularly for high-dimensional or stiff dynamics.

## Confidence
- **High confidence**: The theoretical foundation connecting transport maps to Monte Carlo sampling (Proposition 8 guarantees invariant measure preservation for map-assisted MCMC).
- **Medium confidence**: The simulation-free learning methods (score-based diffusion models and stochastic interpolants) will work robustly across diverse target distributions.
- **Low confidence**: The reverse KL divergence will consistently outperform direct KL divergence in all practical sampling scenarios, particularly for multimodal targets.

## Next Checks
1. **Mode Coverage Validation**: Test the learned transport maps on a 10-component Gaussian mixture target, measuring the proportion of modes captured by samples from the transported base measure, comparing reverse vs forward KL training.
2. **Numerical Stability Benchmark**: Systematically vary time step sizes in the adjoint method across dimensions d=2,10,50, measuring gradient norm stability and training convergence rates.
3. **MCMC Efficiency Comparison**: Implement map-assisted Metropolis-Hastings on a challenging multimodal posterior, comparing effective sample size per second against standard HMC and NUTS, with acceptance rates tracked throughout.