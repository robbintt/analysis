---
ver: rpa2
title: Provably Cost-Sensitive Adversarial Defense via Randomized Smoothing
arxiv_id: '2310.08732'
source_url: https://arxiv.org/abs/2310.08732
tags:
- cost-sensitive
- robustness
- certified
- accuracy
- overall
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work proposes a novel approach for training and certifying
  cost-sensitive adversarial robustness using randomized smoothing. The key idea is
  to adapt the standard randomized smoothing certification pipeline to produce tighter
  robustness guarantees tailored to any binary cost matrix.
---

# Provably Cost-Sensitive Adversarial Defense via Randomized Smoothing

## Quick Facts
- arXiv ID: 2310.08732
- Source URL: https://arxiv.org/abs/2310.08732
- Reference count: 36
- Key outcome: Novel approach for training and certifying cost-sensitive adversarial robustness using randomized smoothing with tighter robustness guarantees tailored to binary cost matrices

## Executive Summary
This paper proposes a novel approach for training and certifying cost-sensitive adversarial robustness using randomized smoothing. The key innovation is the introduction of cost-sensitive certified radius, which provides tighter robustness guarantees tailored to specific cost matrices compared to standard certified radius. The authors develop a robust training method that improves certified cost-sensitive robustness without compromising model accuracy through fine-grained optimization of the certified radius for different data subgroups. Extensive experiments on benchmark datasets demonstrate the effectiveness of their certification algorithm and training method across various cost-sensitive scenarios.

## Method Summary
The method adapts standard randomized smoothing to produce cost-sensitive robustness certificates. It introduces cost-sensitive certified radius (Rc-s) that considers only misclassification costs by restricting probability calculations to sensitive target classes. The training pipeline uses Gaussian noise injection with margin-based losses and fine-grained thresholding parameters (γ1, γ2) to optimize certified radius for sensitive and non-sensitive examples differently. The framework includes two certification algorithms (R1 and R2) that use Monte Carlo sampling with confidence bounds to compute practical certificates.

## Key Results
- Cost-sensitive certified radius provides tighter bounds than standard certified radius for most cost matrices
- Proposed training method improves certified cost-sensitive robustness without sacrificing overall accuracy
- Fine-grained thresholding via margin-based losses enables better cost-sensitive robustness-accuracy trade-off
- Extensive experiments demonstrate effectiveness across CIFAR-10, Imagenette, and HAM10k datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cost-sensitive certified radius is tighter than standard certified radius for most cost matrices
- Mechanism: Restricts second probability term to sensitive target classes, avoiding unnecessary consideration of all incorrect classes
- Core assumption: Prediction probability of top sensitive class is significantly lower than probability of second-highest overall class
- Evidence anchors: Theorem 3.3 shows cost-sensitive robustness certificate is never inferior to standard certified radius

### Mechanism 2
- Claim: Reweighting method in Cohen-R fails due to indirect optimization of smoothed classifier
- Mechanism: Direct training of base classifier with weighted losses doesn't properly account for Gaussian smoothing transformation
- Core assumption: Relationship between base classifier training and smoothed classifier performance is non-linear
- Evidence anchors: Section 4.1 shows Cohen-R sacrifices overall accuracy when trying to achieve high cost-sensitive robustness

### Mechanism 3
- Claim: Fine-grained thresholding via margin-based losses enables better cost-sensitive robustness-accuracy trade-off
- Mechanism: Different threshold ranges [l, u] for sensitive and non-sensitive examples prioritize improving certified radius for cost-sensitive examples
- Core assumption: Gradient contribution from sensitive examples with negative radius can improve overall certified radius optimization
- Evidence anchors: Section 4.2 demonstrates improved robustness through subpopulation-specific thresholding

## Foundational Learning

- Concept: Randomized smoothing and Gaussian noise injection
  - Why needed here: Converts base classifier into smoothed classifier through Gaussian noise injection
  - Quick check question: What is the purpose of adding Gaussian noise to inputs in randomized smoothing?

- Concept: Binary cost matrices and sensitive seed classes
  - Why needed here: Framework requires understanding which misclassifications incur costs
  - Quick check question: How do you determine if a class is a sensitive seed class given a binary cost matrix?

- Concept: Confidence bounds and Monte Carlo estimation
  - Why needed here: Practical certification requires estimating probabilities from finite samples
  - Quick check question: What statistical method does Algorithm 1 use to compute confidence bounds for certified radius?

## Architecture Onboarding

- Component map: Base classifier fθ → Gaussian noise injection → Smoothed classifier gθ → Cost-sensitive certified radius computation → Training with margin-based losses
- Critical path: Training pipeline: Input data → Noise injection during training → Base classifier optimization → Margin-based loss computation → Parameter updates
- Design tradeoffs: Reweighting vs. fine-grained thresholding - reweighting is simpler but less effective; thresholding is more complex but achieves better robustness-accuracy balance
- Failure signatures: Poor cost-sensitive robustness despite high overall accuracy indicates need for fine-grained optimization; low overall accuracy suggests threshold parameters are too aggressive
- First 3 experiments:
  1. Implement Algorithm 1 with R1 only and verify it produces equivalent results to standard randomized smoothing
  2. Test Cohen-R with varying α values on a small dataset to observe the robustness-accuracy trade-off
  3. Implement the margin-based loss with fixed γ1 and γ2 values to verify improved cost-sensitive performance

## Open Questions the Paper Calls Out

- Question: Can the proposed framework be extended to certify robustness against general perturbations beyond ℓ2-norm?
- Basis in paper: Explicit statement about extending to other ℓp-norms and general metrics beyond ℓp-norm
- Why unresolved: Paper focuses on ℓ2-norm perturbations without exploring other perturbation norms
- What evidence would resolve it: Empirical results showing effectiveness for ℓ∞-norm and ℓ1-norm perturbations

- Question: How does choice of cost matrix impact performance trade-off between cost-sensitive robustness and overall accuracy?
- Basis in paper: Discussion of various cost matrix scenarios without method for automatic optimization
- Why unresolved: Uses predefined cost matrices without addressing automatic determination or optimization
- What evidence would resolve it: Method for learning or optimizing cost matrix based on data distribution and application requirements

- Question: Can cost-sensitive randomized smoothing be combined with other robustness training methods?
- Basis in paper: Does not explore combining with adversarial training or data augmentation techniques
- Why unresolved: Focuses on MACER adaptation without investigating combinations with other methods
- What evidence would resolve it: Empirical results comparing combined approaches to cost-sensitive randomized smoothing alone

## Limitations

- Theoretical guarantees assume infinite samples, which is unrealistic for practical certification algorithms
- Effectiveness of fine-grained thresholding relies on correctly identifying and weighting sensitive subgroups in complex class distributions
- Confidence bounds used in certification algorithms may not capture true worst-case bounds with finite sampling

## Confidence

- High confidence: Cost-sensitive certified radius provides tighter bounds than standard radius (Theorem 3.3 support)
- Medium confidence: Cohen-R fails due to indirect optimization (experimental observations but limited ablation studies)
- Medium confidence: Fine-grained thresholding approach improves robustness (empirical improvements but limited theoretical justification)

## Next Checks

1. Conduct controlled experiments comparing confidence bounds from R1 and R2 against empirical worst-case perturbations on held-out validation set
2. Perform ablation studies on margin-based loss function by varying γ1 and γ2 independently
3. Test certification framework on non-binary cost matrices to verify theoretical extensions and computational complexity