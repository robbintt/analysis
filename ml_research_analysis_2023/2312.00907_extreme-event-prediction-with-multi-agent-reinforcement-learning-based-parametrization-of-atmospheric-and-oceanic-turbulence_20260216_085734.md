---
ver: rpa2
title: Extreme Event Prediction with Multi-agent Reinforcement Learning-based Parametrization
  of Atmospheric and Oceanic Turbulence
arxiv_id: '2312.00907'
source_url: https://arxiv.org/abs/2312.00907
tags:
- closures
- learning
- climate
- these
- turbulence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study addresses the challenge of accurately representing unresolved
  small-scale processes in climate models, particularly in turbulent flows like atmospheric
  and oceanic dynamics. The authors develop a novel approach using Scientific Multi-Agent
  Reinforcement Learning (SMARL) to create closures that capture these subgrid-scale
  (SGS) effects.
---

# Extreme Event Prediction with Multi-agent Reinforcement Learning-based Parametrization of Atmospheric and Oceanic Turbulence

## Quick Facts
- arXiv ID: 2312.00907
- Source URL: https://arxiv.org/abs/2312.00907
- Reference count: 40
- Primary result: SMARL-based closures capture extreme event statistics in turbulent flows using 16-1024× coarser resolution than direct numerical simulations

## Executive Summary
This study addresses the challenge of accurately representing unresolved small-scale processes in climate models, particularly in turbulent flows like atmospheric and oceanic dynamics. The authors develop a novel approach using Scientific Multi-Agent Reinforcement Learning (SMARL) to create closures that capture these subgrid-scale (SGS) effects. Their method trains agents on physically motivated invariants of the flow and a few high-fidelity samples to learn dynamic coefficients for classical SGS closures (Smagorinsky and Leith). The key innovation is using only low-order statistics (enstrophy spectrum) for training, requiring far fewer samples than traditional supervised learning approaches. The resulting SMARL-based closures enable large eddy simulations (LES) with 16-1024× coarser resolution to reproduce statistics from direct numerical simulations (DNS), including extreme events.

## Method Summary
The method uses Scientific Multi-Agent Reinforcement Learning (SMARL) to develop closures for subgrid-scale effects in turbulent flows. Agents are trained on physically motivated invariants of velocity gradients and Hessians, using only 10 high-fidelity DNS snapshots and matching the enstrophy spectrum. The policy learns dynamic coefficients for classical Smagorinsky and Leith closures, with agents uniformly distributed in the domain and bilinearly interpolated to the LES grid. The Korali framework is used for deep-SMARL training with an inverse L2 error reward based on log spectra matching. The approach is tested on 2D quasi-geostrophic turbulence on β-plane with different forcing cases at Re=20000, comparing LES results with DNS across various resolutions.

## Key Results
- SMARL-based closures reproduce enstrophy spectra and kinetic energy spectra at 16-1024× coarser resolution than DNS
- The method significantly outperforms classical physics-based closures in capturing extreme event tails in vorticity probability density functions
- Training with only 10 DNS snapshots and low-order statistics (enstrophy spectrum) is sufficient for learning successful closures
- SMARL captures both forward energy cascade and backscatter, enabling stable LES simulations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SMARL learns stable closures by matching low-order statistics (enstrophy spectrum) rather than exact SGS terms
- Mechanism: By training on invariant statistics instead of pointwise SGS values, the policy avoids overfitting to specific flow realizations and develops generalizable turbulence representations
- Core assumption: The enstrophy spectrum is nearly invariant across different turbulent flow realizations
- Evidence anchors:
  - [abstract]: "policy is trained using only the enstrophy spectrum, which is nearly invariant and can be estimated from a few high-fidelity samples"
  - [section]: "We have computed the spectrum using 10 snapshots from a short DNS run, which is known to be insufficient to learn a successful closer offline in these flows"
- Break condition: If the enstrophy spectrum loses its invariance properties under different flow regimes or if the spectrum becomes multimodal

### Mechanism 2
- Claim: Multi-agent reinforcement learning enables capturing backscattering (anti-dissipation) that physics-based closures miss
- Mechanism: Agents learn spatially-varying coefficients that allow energy to transfer from unresolved to resolved scales, mimicking natural backscatter processes
- Core assumption: Proper reward structure can incentivize learning backscatter behavior
- Evidence anchors:
  - [abstract]: "tails of the probability density functions of vorticity, which represent rare but important extreme weather events"
  - [section]: "the tails of the vorticity PDFs clearly show the advantage of the SMARL-based closures, suggesting that these closures have the right amount of diffusion and backscattering"
- Break condition: If the reward function overly penalizes backscatter or if training instability prevents learning the anti-dissipative behavior

### Mechanism 3
- Claim: Using physically-motivated invariants (velocity gradients and Hessians) as states improves generalization
- Mechanism: Invariant states embed Galilean invariance and flow structure information that enables learning coefficients that work across different flow configurations
- Core assumption: The 5 non-zero local variables from velocity gradients and Hessians contain sufficient information about SGS effects
- Evidence anchors:
  - [section]: "We have found the use of these physically motivated invariants, rather than (¯u, ¯v) or ¯ψ or their derivatives, to be key in learning successful closures"
  - [section]: "As local states, instantaneous invariants λ of filtered velocity gradients [36] and velocity Hessians [28] (5 non-zero local variables) are used"
- Break condition: If the chosen invariants fail to capture essential SGS physics in more complex flow regimes

## Foundational Learning

- Concept: Reinforcement learning reward shaping
  - Why needed here: The reward function (inverse L2 error of log spectra) guides agents to match turbulent statistics without requiring exact SGS term matching
  - Quick check question: What happens to training stability if we switch from L2 error to KL divergence in the reward function?

- Concept: Spectral filtering and LES formulation
  - Why needed here: Understanding how sharp spectral filtering creates the SGS term Π that needs closure modeling
  - Quick check question: How does changing the filter cutoff wavenumber affect the distribution of the SGS term in physical space?

- Concept: Turbulent backscatter and energy cascade
  - Why needed here: The method aims to capture both forward energy cascade (diffusion) and backscatter (energy transfer from small to large scales)
  - Quick check question: How would you modify the reward function to explicitly encourage backscatter detection?

## Architecture Onboarding

- Component map: LES solver -> Korali framework -> SMARL agents -> Reward calculator -> Policy update
- Critical path: State extraction → Policy inference → Action application → LES integration → Reward computation → Policy update
- Design tradeoffs: Using classical closure structure (Smagorinsky/Leith) vs. pure neural network increases interpretability but may limit expressivity
- Failure signatures:
  - Training instability (exploding gradients, NaN rewards)
  - Underfitting (too diffusive, missing extreme events)
  - Overfitting (unstable LES runs, poor generalization)
- First 3 experiments:
  1. Run baseline LES with only classical Smagorinsky closure to establish performance baseline
  2. Test SMARL with simplified reward (mean vorticity error instead of spectrum) to verify reward sensitivity
  3. Run SMARL with fixed, uniform coefficients to verify that spatial variation is essential for capturing backscatter

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the SMARL-based closure perform when applied to three-dimensional turbulence rather than the two-dimensional cases studied in this paper?
- Basis in paper: [explicit] The authors note that their current work focuses on 2D quasi-geostrophic turbulence and mention future work will involve applying the framework to more complex climate models, but do not provide results for 3D turbulence.
- Why unresolved: The paper only demonstrates results for 2D flows, and the transition to 3D introduces additional complexities in SGS modeling that are not addressed.
- What evidence would resolve it: Results from applying the SMARL-based closure to 3D turbulent flows, including comparison of statistics and extreme event capture with DNS and classical closures.

### Open Question 2
- Question: Can the SMARL-based closures maintain stability and accuracy when used in online learning mode for extended periods (e.g., years of climate simulation time) rather than just short-term LES?
- Basis in paper: [inferred] The paper demonstrates short-term LES with SMARL-based closures but does not test long-term climate simulations. The authors mention the need for stable closures in climate modeling.
- Why unresolved: Long-term stability of RL-trained models in climate simulations is a critical but untested aspect, especially given the known challenges with online learning in GCMs.
- What evidence would resolve it: Multi-year climate simulations using SMARL-based closures that demonstrate stable operation and accurate climate statistics over extended periods.

### Open Question 3
- Question: How does the performance of SMARL-based closures vary across different climate regimes (e.g., different mean temperatures or external forcings)?
- Basis in paper: [explicit] The authors mention future work on generalizability and proper scaling of invariants and spectra for changing systems, but do not provide results for different climate regimes.
- Why unresolved: The paper only tests the closures on specific forced 2D turbulence cases, and it's unclear how well they would generalize to different climate conditions.
- What evidence would resolve it: Testing the SMARL-based closures across a range of climate regimes, including different mean states and external forcings, to quantify their robustness and generalizability.

## Limitations
- Method relies on 2D quasi-geostrophic turbulence with specific forcing configurations, limiting generalization to 3D atmospheric flows or ocean dynamics
- Only 10 DNS snapshots used for training may not capture full diversity of turbulent states needed for robust generalization
- Approach inherits limitations of classical Smagorinsky/Leith closure structures, potentially restricting expressivity of learned representations

## Confidence

- **High confidence**: The SMARL framework can stabilize LES simulations and match low-order statistics (enstrophy spectrum) with coarser resolution grids. The computational demonstration that physics-based closures fail to capture extreme event tails is well-supported.
- **Medium confidence**: The claim that invariant-based state representations are essential for learning successful closures, as alternative state choices were not systematically tested. The specific claim about backscatter capture could be stronger with direct quantification of energy transfer between scales.
- **Low confidence**: Generalization claims to other flow regimes (different Re, 3D flows, or more complex boundary conditions) are not yet demonstrated.

## Next Checks

1. **Cross-validation test**: Train SMARL on one flow configuration (e.g., Re=20000 with specific forcing) and evaluate on a different configuration (e.g., Re=40000 or different β values) to quantify generalization limits.
2. **Backscatter quantification**: Implement direct measurement of forward/backward energy transfer in wavenumber space to verify that SMARL captures backscatter more effectively than physics-based closures.
3. **State representation ablation**: Systematically test alternative state representations (velocity fields, vorticity, or different invariant combinations) to confirm that the chosen gradient/hessian invariants are optimal for this task.