---
ver: rpa2
title: Dynamic Knowledge Injection for AIXI Agents
arxiv_id: '2312.16184'
source_url: https://arxiv.org/abs/2312.16184
tags:
- agent
- time
- environment
- where
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces DynamicHedgeAIXI, a reinforcement learning
  agent that addresses the problem of epistemic uncertainty in AIXI approximations
  by dynamically incorporating new environment models received from a human operator.
  The agent uses a variant of the Hedge algorithm to maintain an exact Bayesian mixture
  over a changing set of models, allowing it to adapt to new knowledge in an online
  fashion.
---

# Dynamic Knowledge Injection for AIXI Agents

## Quick Facts
- arXiv ID: 2312.16184
- Source URL: https://arxiv.org/abs/2312.16184
- Authors: 
- Reference count: 20
- Key outcome: DynamicHedgeAIXI maintains exact Bayesian mixtures over dynamically changing models using a Hedge algorithm variant, achieving sub-linear error growth and quick adaptation to new predicates in epidemic control tasks.

## Executive Summary
This paper addresses the challenge of epistemic uncertainty in AIXI approximations by introducing DynamicHedgeAIXI, an agent that dynamically incorporates new environment models received from human operators. The agent uses a variant of the Hedge algorithm to maintain an exact Bayesian mixture over a changing set of models, allowing it to adapt to new knowledge in an online fashion. The approach is validated on epidemic control over contact networks, where DynamicHedgeAIXI outperforms baseline methods like U-Tree and PARSS-DT, demonstrating its ability to quickly adapt to newly introduced informative predicates.

## Method Summary
DynamicHedgeAIXI is a reinforcement learning agent that addresses epistemic uncertainty by dynamically incorporating new environment models received from a human operator. It maintains an exact Bayesian mixture over a changing set of models using a variant of the Hedge algorithm, computing time-adaptive prior weights over specialists (abstract MDPs). When new models become active, they receive initial weights proportional to their relative performance compared to existing models. The agent is evaluated on epidemic control tasks over contact networks, with models updated every 4K steps by dropping the lowest-weighted model and introducing a new one pre-trained on prior steps.

## Key Results
- DynamicHedgeAIXI outperforms baseline methods (U-Tree, PARSS-DT, HedgeAIXI) in epidemic control tasks by quickly adapting to newly introduced informative predicates
- Theoretical analysis shows cumulative squared value error grows at rate O(k log|MT|), where k is the number of switches and |MT| is the number of models seen
- Performance converges to the best available environment sequence when the number of switches grows sub-linearly and total models grow sub-exponentially with time

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DynamicHedgeAIXI maintains an exact Bayesian mixture over a dynamically changing set of environment models.
- Mechanism: Uses a variant of the Hedge algorithm to compute time-adaptive prior weights over specialists (abstract MDPs), allowing new models to be integrated and old models to be removed while preserving exact Bayesian mixture properties.
- Core assumption: The dynamic knowledge injection setting allows specialists to be active for contiguous time periods and the model space is finite at each time step.
- Evidence anchors:
  - [abstract]: "DynamicHedgeAIXI that maintains an exact Bayesian mixture over dynamically changing sets of models via a time-adaptive prior constructed from a variant of the Hedge algorithm."
  - [section]: "DynamicHedgeAIXI computes an exact Bayesian mixture over the available set of models at each time step."
- Break condition: If the number of models grows unboundedly or models can be active for non-contiguous periods, the weight computation and convergence guarantees may fail.

### Mechanism 2
- Claim: DynamicHedgeAIXI adapts quickly to newly introduced informative models by reinitializing their weights based on past performance.
- Mechanism: When a new specialist becomes active, it receives an initial weight proportional to the relative performance of DynamicHedge to each available model before the new model's arrival time.
- Core assumption: The pre-training period (4K steps) ensures new models perform reasonably well upon introduction.
- Evidence anchors:
  - [abstract]: "DynamicHedgeAIXI is able to quickly adapt to new knowledge that improves its performance."
  - [section]: "DynamicHedgeAIXI can also avoid the objective mismatch issue common to other system identification approaches to model-based reinforcement learning."
- Break condition: If new models perform significantly worse than existing models upon introduction, the initial weight may be too low to allow meaningful contribution.

### Mechanism 3
- Claim: DynamicHedgeAIXI's performance converges to the best available environment sequence with sub-linear error growth.
- Mechanism: Theoretical analysis shows cumulative squared value error grows at rate O(k log|MT|) where k is the number of switches and |MT| is the number of models seen.
- Core assumption: The number of switches k grows sub-linearly and total models |MT| grows sub-exponentially with time T.
- Evidence anchors:
  - [section]: "Theorem 3 makes clear that the cumulative error grows at the rate O(k log|MT|)."
  - [section]: "If the number of switches k grows sub-linearly and the total number of models seen by the agent over T steps |MT| grows sub-exponentially in T, then DynamicHedgeAIXI's value will converge quickly."
- Break condition: If the number of switches grows linearly or models grow exponentially, convergence guarantees may not hold.

## Foundational Learning

- Concept: Bayesian mixture models and their convergence properties
  - Why needed here: DynamicHedgeAIXI relies on exact Bayesian mixtures over environment models, and understanding their convergence is crucial for analyzing performance guarantees.
  - Quick check question: What is the key difference between approximate and exact Bayesian mixture models in reinforcement learning?

- Concept: Prediction with expert advice and the Hedge algorithm
  - Why needed here: DynamicHedgeAIXI uses a variant of the Hedge algorithm to maintain weights over specialists, which is the core mechanism for dynamic knowledge integration.
  - Quick check question: How does the Hedge algorithm differ from simple weighted majority voting in expert advice settings?

- Concept: Abstract MDPs and state abstractions
  - Why needed here: Specialists in DynamicHedgeAIXI are abstract MDPs that use state abstractions, which is the framework for incorporating domain knowledge through predicates.
  - Quick check question: What is the relationship between state abstractions and the potential loss of information in reinforcement learning?

## Architecture Onboarding

- Component map: Agent → DynamicHedge weight manager → Specialist models (Φ-BCTW) → MCTS planner → Environment. The weight manager maintains posterior weights over specialists, each specialist maintains its own Bayesian mixture over Φ-PST models.
- Critical path: Environment observation → State abstraction → Specialist predictions → Weight aggregation → Action selection via MCTS → Environment action → Reward.
- Design tradeoffs: Exact Bayesian mixtures provide strong theoretical guarantees but are computationally expensive; using specialists allows modular knowledge integration but requires careful weight management.
- Failure signatures: Slow adaptation indicates poor weight initialization for new models; poor overall performance suggests specialists are too weak to model the environment; instability suggests weight oscillations between specialists.
- First 3 experiments:
  1. Implement DynamicHedge with two specialists (one good, one bad) and verify weight concentration on the good specialist over time.
  2. Test knowledge injection by starting with only the bad specialist, then introducing the good specialist after some steps, and measuring adaptation speed.
  3. Scale to three specialists with varying performance levels and verify DynamicHedge maintains reasonable weights on all while concentrating on the best.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DynamicHedgeAIXI's performance scale with the number of predicate functions available, particularly when the predicates become redundant or noisy?
- Basis in paper: [explicit] The paper mentions that uninformative predicates are included in the model and that the performance of DynamicHedgeAIXI is evaluated with increasing proportions of informative predicates over time.
- Why unresolved: The paper does not provide a detailed analysis of how the agent's performance is affected by the presence of redundant or noisy predicates, or how it scales with a very large number of predicates.
- What evidence would resolve it: A comprehensive experimental study varying the number and quality of predicates, including redundant and noisy ones, to assess the impact on DynamicHedgeAIXI's performance.

### Open Question 2
- Question: Can DynamicHedgeAIXI be extended to handle continuous action and observation spaces, and if so, how would this affect its theoretical guarantees?
- Basis in paper: [inferred] The paper focuses on discrete action and observation spaces, and the theoretical analysis assumes finite sets.
- Why unresolved: The paper does not explore the extension of DynamicHedgeAIXI to continuous spaces, which are common in many real-world applications.
- What evidence would resolve it: A theoretical extension of the regret bounds to continuous spaces, along with empirical validation on continuous control tasks.

### Open Question 3
- Question: How does the performance of DynamicHedgeAIXI compare to model-based RL methods that use a fixed model class but employ advanced exploration strategies?
- Basis in paper: [inferred] The paper compares DynamicHedgeAIXI to decision-tree based methods but does not consider other model-based RL approaches with fixed model classes.
- Why unresolved: The comparison with other model-based RL methods would provide a more comprehensive understanding of DynamicHedgeAIXI's strengths and weaknesses.
- What evidence would resolve it: Empirical comparisons with state-of-the-art model-based RL methods that use fixed model classes but advanced exploration strategies, such as Bayesian optimization or curiosity-driven exploration.

### Open Question 4
- Question: How does DynamicHedgeAIXI's performance change when the human operator provides predicates that are not directly related to the optimal policy, but rather to auxiliary tasks or subgoals?
- Basis in paper: [explicit] The paper mentions that the human operator can provide domain-specific predicates, but does not explore the scenario where predicates are related to auxiliary tasks or subgoals.
- Why unresolved: The paper does not investigate the impact of providing predicates that are not directly related to the optimal policy, which could be a realistic scenario in Human-AI teaming.
- What evidence would resolve it: An experimental study where the human operator provides predicates related to auxiliary tasks or subgoals, and the impact on DynamicHedgeAIXI's performance is measured.

## Limitations
- Performance guarantees depend critically on the number of switches growing sub-linearly and total models growing sub-exponentially, which may not hold in all settings
- Computational complexity of maintaining exact Bayesian mixtures over dynamically changing model sets is not fully characterized, particularly for high-dimensional state spaces
- Empirical validation is limited to a single domain (epidemic control) with specific model introduction patterns, leaving open questions about performance across diverse environments

## Confidence

- **High confidence**: The mechanism by which DynamicHedgeAIXI maintains exact Bayesian mixtures over changing model sets using the Hedge algorithm variant is well-founded theoretically and clearly specified.
- **Medium confidence**: The empirical performance improvements over baselines in epidemic control are well-demonstrated, though limited to a single domain.
- **Medium confidence**: The theoretical convergence guarantees hold under stated assumptions about sub-linear switch growth and sub-exponential model growth, but real-world applicability depends on these conditions being met.

## Next Checks

1. Test DynamicHedgeAIXI with exponentially growing model sets (|MT| grows exponentially with T) to verify whether the sub-exponential growth assumption is critical for convergence.
2. Implement the algorithm with non-contiguous model activation periods to determine if the contiguous activation assumption is necessary for weight computation and convergence.
3. Scale experiments to environments with significantly larger state spaces and more complex predicate combinations to assess computational tractability and whether performance degrades as theory suggests it should.