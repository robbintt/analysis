---
ver: rpa2
title: Auto-Regressive Next-Token Predictors are Universal Learners
arxiv_id: '2309.06979'
source_url: https://arxiv.org/abs/2309.06979
tags:
- linear
- complexity
- learning
- function
- length
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a theoretical framework for studying auto-regressive
  next-token predictors. The key insight is that even simple models like linear next-token
  predictors can approximate any function efficiently computed by a Turing machine
  when trained on chain-of-thought data.
---

# Auto-Regressive Next-Token Predictors are Universal Learners

## Quick Facts
- arXiv ID: 2309.06979
- Source URL: https://arxiv.org/abs/2309.06979
- Reference count: 40
- Simple models like linear next-token predictors can approximate any Turing-computable function when trained on chain-of-thought data

## Executive Summary
This paper introduces a theoretical framework for studying auto-regressive next-token predictors and demonstrates that even simple models like linear predictors can approximate any Turing-computable function when trained on chain-of-thought data. The key insight is that auto-regressive training with chain-of-thought supervision provides access to intermediate computational steps, enabling models to learn complex functions that would be impossible with standard supervised learning. The authors introduce a new complexity measure called length complexity, which captures the number of intermediate tokens required to learn a target function, and show how this can be traded off against other complexity measures like sample and computational complexity.

## Method Summary
The authors study auto-regressive next-token prediction by training simple models including linear networks and small MLPs on two tasks: text generation using the TinyStories dataset and 4-digit multiplication. The models are trained using a next-token prediction objective with masking to ensure autoregressive training. During inference, a sampling function (typically argmax) is applied after each prediction step to introduce non-linearity. The experiments evaluate text quality qualitatively and measure exact match and per-digit accuracy for multiplication tasks, demonstrating that simple architectures can achieve non-trivial performance when trained auto-regressively with appropriate supervision.

## Key Results
- Simple linear and MLP models achieve coherent text generation on TinyStories despite high perplexity
- MLP models achieve non-trivial accuracy on 4-digit multiplication tasks
- Theoretical framework shows tradeoffs between length complexity and other complexity measures
- Auto-regressive training enables simple models to access intermediate computational states

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Auto-regressive training with chain-of-thought supervision enables simple models to approximate any Turing computable function
- Mechanism: By treating each generated token as both input and label, the model gains access to intermediate computational steps, allowing it to learn complex functions that would be impossible with standard supervised learning
- Core assumption: The training data contains sufficient chain-of-thought sequences that demonstrate the intermediate steps needed to solve the target problems
- Evidence anchors: Linear AR functions can compute very complex functions, for example emulating arbitrary Turing machines
- Break condition: If the training data lacks appropriate chain-of-thought sequences showing intermediate computation steps, the model cannot learn the target function

### Mechanism 2
- Claim: Linear auto-regressive predictors can compute non-linear functions through sampling/non-linearity
- Mechanism: The sampling function (argmax) after each auto-regressive step acts as an explicit non-linearity, allowing linear predictors to implement non-linear computations
- Core assumption: The sampling function introduces sufficient non-linearity to enable computation of non-linear functions
- Evidence anchors: Since auto-regressive inference introduces a sampling function after each step, it allows linear next-token predictors to compute non-linear functions
- Break condition: If the sampling function is removed or replaced with a linear operation, the model loses its ability to compute non-linear functions

### Mechanism 3
- Claim: There's a tradeoff between length complexity and computational/sample complexity
- Mechanism: By increasing the length complexity (number of intermediate tokens), you can decrease the computational or sample complexity required to learn a function
- Core assumption: The hypothesis class can be adjusted to balance between length complexity and other complexity measures
- Evidence anchors: We show that using more intermediate tokens, i.e. increasing the length complexity, can reduce time/sample complexity, and vice versa
- Break condition: If the hypothesis class cannot be adjusted or if there's no benefit to increasing length complexity, the tradeoff doesn't provide practical advantages

## Foundational Learning

- Concept: PAC Learnability
  - Why needed here: The paper builds on classical PAC learning theory to establish when auto-regressive learning is possible
  - Quick check question: Can you explain the difference between PAC learnability and the auto-regressive learning framework presented in this paper?

- Concept: Chain-of-Thought (CoT) reasoning
  - Why needed here: CoT is the key technique that enables simple models to perform complex reasoning by providing intermediate supervision
  - Quick check question: How does chain-of-thought differ from standard supervised learning in terms of the information available to the learning algorithm?

- Concept: Length Complexity
  - Why needed here: This new complexity measure captures how many intermediate tokens are required to learn a concept, which is central to understanding the tradeoffs in auto-regressive learning
  - Quick check question: In what way does length complexity complement traditional measures like sample complexity and computational complexity?

## Architecture Onboarding

- Component map:
  - Input embedding layer -> Linear/MLP layers -> Output embedding layer
  - Masking mechanism (during training)
  - Sampling function (during inference)

- Critical path:
  1. Token embedding → Linear/MLP layers → Output embedding
  2. During training: Add masking to prevent looking ahead
  3. During inference: Apply sampling after each prediction step

- Design tradeoffs:
  - Simple vs. complex architectures: Linear models are more theoretically tractable but may require longer sequences
  - Context length vs. model capacity: Longer contexts allow more complex reasoning but increase computational cost
  - Tokenization strategy: Can significantly impact performance on arithmetic tasks

- Failure signatures:
  - Model produces grammatically correct but semantically meaningless text
  - Model fails to maintain logical consistency across longer sequences
  - Model overfits to specific patterns in training data without generalizing

- First 3 experiments:
  1. Train a linear model on TinyStories dataset and evaluate perplexity and sample outputs
  2. Implement the 4-digit multiplication task with an MLP and compare against GPT models
  3. Vary context length and model complexity to study the tradeoff between length complexity and other complexity measures

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the intrinsic complexity measure for hypothesis classes that can be used to derive length complexity bounds, analogous to VC dimension or SQ dimension?
- Basis in paper: The paper states "Discovering an intrinsic complexity measure for hypothesis classes (analogous to VC dimension or SQ dimension) that can be used to derive length complexity bounds is of particular interest."
- Why unresolved: This question remains open as the paper does not provide a specific complexity measure, but rather suggests its potential importance for future research.
- What evidence would resolve it: Developing a new complexity measure specifically tailored to auto-regressive learning and demonstrating its effectiveness in deriving length complexity bounds for various hypothesis classes.

### Open Question 2
- Question: How does the choice of hypothesis class affect the interplay between computational complexity, sample complexity, and length complexity in auto-regressive learning?
- Basis in paper: The paper discusses "the interplay between the choice of the AR hypothesis class and the different measures of complexity that it induces: sample complexity, computational complexity and length complexity."
- Why unresolved: While the paper provides some examples and insights, a comprehensive understanding of this interplay for various hypothesis classes and tasks is still lacking.
- What evidence would resolve it: Conducting extensive experiments and theoretical analysis on different hypothesis classes and tasks to quantify the trade-offs between computational, sample, and length complexity.

### Open Question 3
- Question: Can the length complexity of auto-regressive learning be reduced further for specific problem classes, such as parities or arithmetic tasks?
- Basis in paper: The paper shows that parities can be learned with O(log n) intermediate tokens, and suggests that "by modifying the choice of the hypothesis class we can possibly shorten the required sequence length."
- Why unresolved: While some progress has been made, finding the optimal hypothesis class and tokenization scheme for reducing length complexity in specific problem classes remains an open challenge.
- What evidence would resolve it: Designing novel hypothesis classes or tokenization schemes that significantly reduce the length complexity for specific problem classes, and demonstrating their effectiveness through experiments and theoretical analysis.

## Limitations

- Theoretical framework assumes perfect chain-of-thought supervision which may not be available in real-world training data
- Experiments show gap between theoretical guarantees and practical performance, particularly for linear models on text generation
- Length complexity measure lacks quantitative empirical validation and bounds
- Claims about sampling providing sufficient non-linearity need more rigorous justification

## Confidence

**High Confidence Claims:**
- Auto-regressive training enables models to access intermediate computational states
- Chain-of-thought supervision provides more informative training signals than standard supervised learning
- There exists a theoretical tradeoff between length complexity and other complexity measures

**Medium Confidence Claims:**
- Simple architectures (linear, small MLPs) can achieve non-trivial performance on text and arithmetic tasks
- The sampling function after each auto-regressive step provides sufficient non-linearity for linear models
- Length complexity is a meaningful measure that captures important aspects of learning difficulty

**Low Confidence Claims:**
- Linear models can efficiently approximate any Turing-computable function given sufficient chain-of-thought data
- The theoretical complexity tradeoffs translate to practical advantages in real-world settings
- Auto-regressive training alone, without architectural innovations, accounts for the success of modern LLMs

## Next Checks

1. **Ablation Study on Chain-of-Thought Data**: Systematically remove chain-of-thought sequences from training data to quantify how much performance degrades. This would directly test whether the theoretical benefits depend on having perfect intermediate supervision.

2. **Quantitative Complexity Tradeoff Analysis**: Design controlled experiments that vary length complexity while measuring sample and computational complexity requirements. Plot these relationships to determine if the theoretical tradeoffs manifest empirically with measurable bounds.

3. **Architecture Scaling Study**: Test increasingly complex architectures (linear → small MLP → medium MLP → transformer) on the same tasks while keeping training data and compute constant. This would reveal whether architectural complexity provides advantages beyond what auto-regressive training alone offers.