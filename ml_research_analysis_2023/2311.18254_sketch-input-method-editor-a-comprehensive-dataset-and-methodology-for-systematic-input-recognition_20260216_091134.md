---
ver: rpa2
title: 'Sketch Input Method Editor: A Comprehensive Dataset and Methodology for Systematic
  Input Recognition'
arxiv_id: '2311.18254'
source_url: https://arxiv.org/abs/2311.18254
tags:
- sketch
- recognition
- segmentation
- semantic
- categories
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of creating a Sketch Input Method
  Editor (SketchIME) for professional C4I systems. It introduces a novel dataset comprising
  374 specialized sketch types from a professional C4I system, annotated for both
  recognition and segmentation.
---

# Sketch Input Method Editor: A Comprehensive Dataset and Methodology for Systematic Input Recognition

## Quick Facts
- arXiv ID: 2311.18254
- Source URL: https://arxiv.org/abs/2311.18254
- Reference count: 40
- Creates SketchIME dataset with 374 specialized sketch types from professional C4I system, achieving state-of-the-art performance with 97.01% recognition accuracy and 97.13% segmentation accuracy

## Executive Summary
This paper introduces SketchIME, a novel dataset and methodology for simultaneous sketch recognition and segmentation in professional C4I systems. The dataset comprises 374 specialized sketch types with annotated semantic components, addressing the need for systematic input recognition in professional applications. The proposed SketchRecSeg architecture employs simultaneous recognition and segmentation with multilevel supervision, incorporating few-shot domain adaptation and class-incremental learning to enhance adaptability to new users and extendibility to new categories. The approach achieves state-of-the-art performance on both recognition and segmentation tasks while providing interpretability through semantic component analysis.

## Method Summary
The method employs a two-stream architecture: a CNN-based recognition stream (ResNet18) and a GNN-based segmentation stream with dynamic graph convolution. The key innovation is multilevel supervision where recognition provides supervisory signals to segmentation through CNN feature augmentation, recognition supervision module, and KLD loss. Few-shot domain adaptation uses conditional domain adversarial networks to align feature distributions between source and target domains. Class-incremental learning employs forward-compatible training with virtual prototypes to enable learning new categories without catastrophic forgetting. The system processes SVG stroke data for segmentation and binary images for recognition, achieving simultaneous category identification and semantic component extraction.

## Key Results
- Recognition accuracy up to 97.01% and segmentation accuracy up to 97.13% on SketchIME dataset
- Superior performance compared to existing methods on both SketchIME-SRS and SPG datasets
- Effective few-shot domain adaptation with 1-5 samples per category improving user adaptability
- Successful class-incremental learning maintaining performance while adding new categories and components

## Why This Works (Mechanism)

### Mechanism 1
The simultaneous recognition and segmentation architecture with multilevel supervision enables the model to leverage prior knowledge of semantic components to improve both tasks. The recognition stream provides supervisory signals to the segmentation stream through three mechanisms: CNN feature augmentation (CFA), recognition supervision module (RSM), and Kullback-Leibler divergence (KLD) loss. The CFA injects sketch-level features from ResNet18 into the graph convolution unit. The RSM uses the translation matrix between categories and semantic components to weight the segmentation output. The KLD loss ensures the segmentation probabilities align with the derived semantic component distribution from recognition. Core assumption: The semantic components required to form a category are known a priori and can be represented in a translation matrix. Break condition: If the prior knowledge about semantic components is incomplete or inaccurate, the supervision signals will be noisy and may degrade both recognition and segmentation performance.

### Mechanism 2
Few-shot domain adaptation enables the system to adapt to new users' sketching styles with minimal labeled data. The conditional domain adversarial network (CDAN) aligns the feature distributions between the source domain (few training samples) and target domain (new user data) in both recognition and segmentation streams. The optimization objective minimizes classification loss while maximizing domain confusion through the discriminator. Core assumption: The source domain samples represent typical examples of each category and can serve as a bridge to the target domain. Break condition: If the source domain samples are not representative of the new user's sketching style, the adaptation may fail to align distributions effectively.

### Mechanism 3
Forward compatible training enables the system to incrementally learn new sketch categories and semantic components without catastrophic forgetting. The FACT method assigns virtual prototypes to squeeze embeddings of known classes and reserve capacity for new ones. During incremental learning, the model simultaneously updates classifiers for recognition and segmentation using pseudo-labels derived from virtual classes. Core assumption: The embedding space can be partitioned to accommodate both known and virtual classes without significant interference. Break condition: If the embedding space becomes saturated or the virtual prototypes conflict with known classes, incremental learning performance will degrade.

## Foundational Learning

- **Graph Neural Networks for stroke-level analysis**
  - Why needed here: Sketch segmentation requires understanding relationships between stroke points at fine granularity, which GNNs can capture through dynamic graph convolutions
  - Quick check question: How does the dynamic graph convolution update the edge structure between adjacent points in each stroke?

- **Domain adaptation techniques**
  - Why needed here: Different users have varying sketching styles that create distribution shifts between training and test data, requiring adaptation to maintain performance
  - Quick check question: What is the key difference between standard domain adaptation and few-shot domain adaptation in this context?

- **Class-incremental learning strategies**
  - Why needed here: Professional C4I systems may require adding new symbol types over time, necessitating a method to learn new classes without forgetting old ones
  - Quick check question: How does forward compatible training differ from traditional rehearsal-based incremental learning?

## Architecture Onboarding

- **Component map**: SVG input → Graph convolution → Node feature augmentation (CFA) → Semantic classifier → Point-level segmentation predictions
- **Critical path**: SVG stroke data → Dynamic graph convolution unit → Node features → Recognition supervision module → Semantic component predictions
- **Design tradeoffs**: Two-stream architecture adds complexity but enables mutual supervision; domain adaptation adds training overhead but improves user adaptability; incremental learning adds memory requirements but extends system lifetime
- **Failure signatures**: Recognition accuracy drops significantly for new users (domain shift); segmentation accuracy drops when new semantic components are introduced (catastrophic forgetting)
- **First 3 experiments**:
  1. Test recognition accuracy on SketchIME-SRS dataset without domain adaptation to establish baseline
  2. Apply few-shot domain adaptation with varying numbers of target samples to measure adaptation effectiveness
  3. Perform incremental learning on SketchIME-CIL1 to test extendibility to new categories and components

## Open Questions the Paper Calls Out

### Open Question 1
How does the SketchIME system handle the real-time recognition and recommendation of sketches during online use? The paper mentions that online recognition and recommendation are important for an excellent SketchIME, but it does not provide detailed information on how this is implemented.

### Open Question 2
What are the specific challenges and solutions for handling different stroke orders in sketches for online recognition and personal identification? The paper mentions that different participants may draw the same symbol using different stroke orders, and that unused parts of the collected data contain different stroke orders for online sketch recognition and personal identification.

### Open Question 3
How does the SketchIME system ensure the adaptability and extendibility for new users and new task-specific sketches in real-world applications? The paper mentions that the few-shot domain adaptation and class-incremental learning mechanisms are used to enhance the network's adaptability to new users and extendibility to new task-specific sketches.

## Limitations

- The dataset size, while substantial, is limited to 18 participants which may constrain generalizability to broader sketching populations
- Several implementation details for dynamic graph convolution and the prior knowledge matrix are underspecified, potentially affecting exact reproduction
- The comparison with SPG dataset may be limited due to different task definitions and dataset characteristics

## Confidence

- **High confidence**: The core architecture design and dataset collection methodology are clearly specified and reproducible
- **Medium confidence**: The empirical results on SketchIME dataset are verifiable, though the comparison with SPG dataset may be limited due to different task definitions
- **Low confidence**: Some implementation details for dynamic graph convolution and the prior knowledge matrix are underspecified, potentially affecting exact reproduction

## Next Checks

1. Implement and test the dynamic graph convolution neighborhood update mechanism with the specified Dilated k-NN approach to verify the stroke-level feature aggregation claims
2. Reproduce the few-shot domain adaptation results with varying numbers of target samples (1-5 per category) to quantify the adaptation effectiveness curve
3. Validate the class-incremental learning performance by testing catastrophic forgetting on SketchIME-CIL1 dataset with multiple incremental steps