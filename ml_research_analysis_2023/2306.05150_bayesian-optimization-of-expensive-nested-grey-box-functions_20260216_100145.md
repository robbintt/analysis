---
ver: rpa2
title: Bayesian Optimization of Expensive Nested Grey-Box Functions
arxiv_id: '2306.05150'
source_url: https://arxiv.org/abs/2306.05150
tags:
- optimization
- function
- grey-box
- functions
- black-box
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of optimizing grey-box functions,
  which are composed of both black-box and white-box functions. The authors propose
  a general formulation for grey-box optimization problems and design an optimism-driven
  algorithm to solve them.
---

# Bayesian Optimization of Expensive Nested Grey-Box Functions

## Quick Facts
- arXiv ID: 2306.05150
- Source URL: https://arxiv.org/abs/2306.05150
- Reference count: 30
- Primary result: Algorithm achieves similar regret bounds as standard BO up to constant multiplicative terms depending on Lipschitz constants

## Executive Summary
This paper addresses the challenge of optimizing expensive nested grey-box functions, which combine black-box components (unknown functions) with white-box components (known functions). The authors propose a general formulation and develop an optimism-driven Bayesian optimization algorithm that achieves theoretical regret bounds comparable to standard black-box optimization methods. Their approach leverages the known structure of white-box functions while maintaining uncertainty quantification for black-box components through Gaussian processes. Experimental results demonstrate significant improvements in finding global optima compared to standard black-box optimization approaches.

## Method Summary
The method formulates grey-box optimization as a sequential decision problem where the objective function is composed of both black-box functions (learned via independent Gaussian processes) and white-box functions (used exactly). The algorithm maintains confidence bounds for each black-box function and solves an auxiliary optimization problem that maximizes over lower confidence bounds while enforcing white-box constraints exactly. After each evaluation, the algorithm updates the GP posteriors and repeats the process. The approach extends to constrained optimization and provides regret bounds that depend on the information gain from observations and the Lipschitz continuity of the functions involved.

## Key Results
- Proposes general formulation for nested grey-box optimization problems
- Achieves regret bounds similar to standard black-box BO (up to multiplicative constants)
- Demonstrates significant empirical improvement in convergence speed on synthetic problems
- Extends method to handle constrained optimization scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Grey-box optimization improves convergence by using known white-box functions as exact constraints in the auxiliary problem.
- Mechanism: The algorithm enforces intermediate variables to satisfy white-box relationships exactly while only bounding black-box functions within their posterior confidence intervals. This reduces the search space compared to treating all components as black-box.
- Core assumption: White-box functions are cheap to evaluate and error-free.
- Evidence anchors:
  - [abstract] "optimism-driven algorithm to solve it" and "up to a constant multiplicative term depending on the Lipschitz constants"
  - [section] "zi+1 = φi(si), ∀i ∈ IW" in line 12c of Algorithm 1
- Break condition: If white-box functions have errors or are expensive, the auxiliary problem becomes computationally intractable or misleading.

### Mechanism 2
- Claim: Independent Gaussian processes for each black-box function allow tight confidence bounds and efficient regret analysis.
- Mechanism: By modeling each unknown function separately, the algorithm maintains independent posterior distributions and maximum information gain bounds, enabling decomposition of cumulative regret into per-function terms.
- Core assumption: Black-box functions are independent and can be evaluated separately.
- Evidence anchors:
  - [abstract] "Gaussian processes to learn the unknown black-box functions"
  - [section] "We use the independent Gaussian processes to learn the unknown black-box functions φi, i ∈ I_B"
- Break condition: If black-box functions are correlated or cannot be evaluated separately, the independence assumption fails and regret bounds become invalid.

### Mechanism 3
- Claim: Optimism-driven auxiliary optimization balances exploration and exploitation by maximizing over lower confidence bounds of the composite function.
- Mechanism: The algorithm solves min z_m subject to l_i,t(s_i) ≤ z_{i+1} ≤ u_i,t(s_i) for black-box components, ensuring selected points have high potential value while respecting current uncertainty.
- Core assumption: The auxiliary problem can be solved efficiently and its optimal solution is feasible for the true grey-box function.
- Evidence anchors:
  - [abstract] "optimism-driven algorithm to solve it"
  - [section] "in each step, we solve an optimistic auxiliary problem"
- Break condition: If the auxiliary problem is too expensive to solve or its solution is far from feasible for the true function, the algorithm loses efficiency.

## Foundational Learning

- Concept: Reproducing kernel Hilbert spaces (RKHS)
  - Why needed here: The algorithm assumes black-box functions lie in RKHS with bounded norm, which enables Gaussian process modeling and information gain bounds
  - Quick check question: What does ∥φ_i∥_{k_i} ≤ B_i mean in terms of function smoothness?

- Concept: Gaussian process posterior inference
  - Why needed here: The algorithm maintains posterior mean and covariance for each black-box function to compute confidence intervals used in the auxiliary optimization
  - Quick check question: How do you compute the posterior mean μ_{i,t}(s_i) given observed data?

- Concept: Lipschitz continuity
  - Why needed here: The algorithm uses Lipschitz bounds to relate confidence intervals of intermediate variables to confidence intervals of the final function value
  - Quick check question: Why does Lipschitz continuity allow bounding |φ_i(s_i) - l_{i,t}(s_i)|?

## Architecture Onboarding

- Component map:
  - Black-box function learners: Independent GP models for each φ_i, i ∈ I_B
  - Auxiliary optimizer: Solves constrained optimization with confidence bounds
  - Confidence bound calculator: Computes l_{i,t} and u_{i,t} from GP posteriors
  - Regret tracker: Accumulates per-function regret contributions

- Critical path:
  1. Evaluate black-box functions at selected points
  2. Update GP posteriors
  3. Compute confidence bounds
  4. Solve auxiliary optimization problem
  5. Select next evaluation point

- Design tradeoffs:
  - Independent GPs vs joint modeling: Independence simplifies regret analysis but ignores potential correlations
  - Confidence bound tightness vs computation: Tighter bounds improve efficiency but require more computation
  - Auxiliary problem complexity vs accuracy: More accurate surrogates improve optimization but increase solve time

- Failure signatures:
  - Rapidly growing cumulative regret: May indicate poor GP hyperparameter choices or violated assumptions
  - Auxiliary problem becoming infeasible: May indicate overly conservative confidence bounds or poor initialization
  - Slow convergence: May indicate insufficient exploration or overly tight confidence bounds

- First 3 experiments:
  1. Linear objective with one black-box constraint: Test basic algorithm functionality
  2. Quadratic objective with multiple black-box constraints: Test handling of multiple functions
  3. Real-world grey-box function (e.g., process control): Test scalability and practical performance

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but leaves several important research directions unexplored, particularly regarding scalability to high-dimensional problems and the impact of white-box function complexity on computational efficiency.

## Limitations
- Assumes white-box functions are cheap to evaluate and error-free, which may not hold in practice
- Computational complexity of auxiliary optimization problem may become prohibitive in high dimensions
- Limited experimental validation on real-world grey-box problems

## Confidence
- Theoretical regret bounds: High
- Computational complexity claims: Medium
- Practical performance improvements: Medium

## Next Checks
1. Test algorithm scalability on problems with 10+ input dimensions to verify claimed computational efficiency.
2. Experiment with white-box functions of varying computational cost to quantify the cheap-evaluation assumption.
3. Compare against state-of-the-art black-box optimizers on real-world grey-box problems from engineering or scientific domains.