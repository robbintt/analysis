---
ver: rpa2
title: 'CoRTEx: Contrastive Learning for Representing Terms via Explanations with
  Applications on Constructing Biomedical Knowledge Graphs'
arxiv_id: '2312.08036'
source_url: https://arxiv.org/abs/2312.08036
tags:
- terms
- term
- explanations
- clustering
- biomedical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces CoRTEx, a novel approach for biomedical term
  representation using contrastive learning with explanations from ChatGPT. The method
  enhances term embeddings by aligning them with generated explanations, improving
  clustering accuracy for constructing biomedical knowledge graphs.
---

# CoRTEx: Contrastive Learning for Representing Terms via Explanations with Applications on Constructing Biomedical Knowledge Graphs

## Quick Facts
- arXiv ID: 2312.08036
- Source URL: https://arxiv.org/abs/2312.08036
- Reference count: 39
- Key outcome: CoRTEx achieves F1 scores of 0.647 and 0.579 on biomedical term clustering, outperforming baselines by aligning term embeddings with ChatGPT-generated explanations

## Executive Summary
This paper introduces CoRTEx, a novel approach for biomedical term representation using contrastive learning with explanations from ChatGPT. The method enhances term embeddings by aligning them with generated explanations, improving clustering accuracy for constructing biomedical knowledge graphs. Evaluated on two test sets, CoRTEx achieves F1 scores of 0.647 and 0.579, outperforming baseline models like SapBERT and MedCPT. The model demonstrates strong generalization, effectively clustering terms without explanations and handling out-of-distribution data. Additionally, a ChatGPT-assisted BIRCH algorithm is employed to cluster 35.6 million terms from the BIOS ontology into 22.1 million clusters, showcasing the method's scalability and effectiveness in real-world applications.

## Method Summary
CoRTEx employs contrastive learning to align biomedical terms with their explanations generated by ChatGPT. The method uses a T5-based transformer model (InstructOR) to produce embeddings for both terms and explanations, then trains to maximize similarity between corresponding pairs while distinguishing them from hard negative samples. The model progressively introduces hard negative samples by periodically updating similarity indices in a vector database. For clustering large ontologies, CoRTEx uses a modified BIRCH algorithm that leverages ChatGPT to confirm cluster assignments, reducing the number of queries from O(N²) to O(N) while maintaining accuracy.

## Key Results
- Achieved F1 scores of 0.647 and 0.579 on two test sets, outperforming baseline models
- Successfully clustered 35.6 million terms from BIOS ontology into 22.1 million clusters using ChatGPT-assisted BIRCH algorithm
- Demonstrated strong generalization by effectively clustering terms without explanations and handling out-of-distribution data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Aligning term embeddings with ChatGPT-generated explanations injects domain knowledge into the embeddings, improving clustering performance.
- Mechanism: The model learns to produce similar embeddings for a term and its explanation through contrastive learning, effectively transferring knowledge from the large language model into the smaller term embedding model.
- Core assumption: ChatGPT's explanations contain accurate and relevant biomedical knowledge that can be distilled into the term embeddings.
- Evidence anchors:
  - [abstract] "By aligning terms to their explanations, CoRTEx demonstrates superior accuracy over benchmark models"
  - [section] "Through the aligning process, we inject explanatory knowledge from ChatGPT into term embedding model of a much smaller size"
  - [corpus] Weak evidence - no direct citations of knowledge injection effectiveness
- Break condition: If ChatGPT explanations are inaccurate or contain irrelevant information, the injected knowledge could degrade embedding quality.

### Mechanism 2
- Claim: Using hard negative sampling progressively improves the model's ability to distinguish between similar but distinct terms.
- Mechanism: The model is trained to identify the most challenging negative samples (terms that are semantically close but from different concepts) and learn to differentiate them from positive samples.
- Core assumption: The hardest negative samples provide the most informative learning signal for the model.
- Evidence anchors:
  - [abstract] "We employ contrastive learning, considering term and explanation embeddings simultaneously, and progressively introduce hard negative samples"
  - [section] "Following CODER++, we periodically update the similarity indices of the terms by their latest embeddings in a vector database to efficiently search for hard negative samples"
  - [corpus] Weak evidence - no direct citations of hard negative sampling effectiveness in biomedical domain
- Break condition: If hard negative sampling is too aggressive, it may create confusion and degrade model performance.

### Mechanism 3
- Claim: The ChatGPT-assisted BIRCH algorithm improves clustering efficiency by reducing the number of queries needed to ChatGPT while maintaining accuracy.
- Mechanism: The algorithm uses embedding similarity to find the nearest cluster candidate, then queries ChatGPT only to confirm whether the term belongs to that cluster, reducing the total number of queries from O(N²) to O(N).
- Core assumption: Terms that are close in embedding space are likely to be semantically similar, making the initial clustering based on embeddings reasonably accurate.
- Evidence anchors:
  - [abstract] "a ChatGPT-assisted BIRCH algorithm is designed for efficient clustering of a new ontology"
  - [section] "we leverage ChatGPT and leverage its ability to discern different terms to replace the static threshold"
  - [corpus] Weak evidence - no direct citations of BIRCH algorithm modifications
- Break condition: If embedding similarity does not correlate well with semantic similarity, the BIRCH algorithm may produce incorrect clusters.

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: To train the model to distinguish between positive (synonymous) and negative (non-synonymous) term pairs by learning representations that place similar terms close together in the embedding space.
  - Quick check question: How does contrastive learning differ from traditional supervised classification?

- Concept: Transformer-based language models
  - Why needed here: To serve as the base model for term embeddings and to generate explanations for terms through fine-tuning and prompting.
  - Quick check question: What is the difference between BERT and T5 transformer architectures?

- Concept: Knowledge graph construction
  - Why needed here: To understand the broader context of term clustering as a step in building biomedical knowledge graphs where synonymous terms are grouped into concepts.
  - Quick check question: What is the difference between a knowledge graph and a traditional database?

## Architecture Onboarding

- Component map: Term → Explanation generation → Embedding generation → Contrastive learning → Clustering
- Critical path: Term → Explanation generation → Embedding generation → Contrastive learning → Clustering
- Design tradeoffs:
  - Model size vs. performance: Larger models may capture more complex patterns but require more computational resources
  - Number of ChatGPT queries vs. clustering accuracy: More queries may improve accuracy but increase cost and latency
  - Hard negative sampling frequency vs. training stability: More frequent updates may improve performance but could cause instability
- Failure signatures:
  - Poor clustering performance on terms that were not in the training set
  - Inconsistent results when re-running the clustering algorithm
  - High variance in embedding similarities for semantically similar terms
- First 3 experiments:
  1. Test the quality of ChatGPT explanations by manually evaluating a sample of generated explanations
  2. Evaluate the model's performance on a small test set with known clusters before scaling up
  3. Compare clustering results using different thresholds for ChatGPT queries in the BIRCH algorithm

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the maximum size of biomedical ontologies that CoRTEx can effectively handle without significant degradation in clustering performance?
- Basis in paper: [explicit] The paper mentions clustering 35.6 million terms from BIOS but does not explore the upper limits of scalability or performance degradation at larger scales.
- Why unresolved: The study only demonstrates performance on a single large dataset (35.6 million terms) without systematic scaling experiments or performance analysis at different dataset sizes.
- What evidence would resolve it: Experimental results showing clustering performance metrics (F1 scores, precision, recall) across multiple ontology sizes ranging from thousands to billions of terms, with systematic analysis of computational complexity and performance bottlenecks.

### Open Question 2
- Question: How do different prompt formulations for ChatGPT affect the quality and consistency of generated explanations for biomedical term clustering?
- Basis in paper: [explicit] The authors mention using a specific prompt for generating explanations but acknowledge that ChatGPT's judgments can diverge from UMLS standards, and they refined the prompt manually.
- Why unresolved: The paper does not provide a systematic comparison of different prompt formulations or quantify how prompt variations affect clustering accuracy.
- What evidence would resolve it: Comparative study showing clustering performance using different prompt formulations, with quantitative metrics for explanation quality, consistency with UMLS standards, and resulting clustering accuracy.

### Open Question 3
- Question: Can CoRTEx's performance be further improved by incorporating additional knowledge sources beyond ChatGPT explanations, such as structured biomedical databases or domain-specific ontologies?
- Basis in paper: [inferred] The authors discuss the importance of knowledge injection and mention that CODER incorporated relations from UMLS, but they only use ChatGPT explanations as an additional knowledge source.
- Why unresolved: The study focuses solely on ChatGPT-generated explanations without exploring whether combining multiple knowledge sources could yield better performance.
- What evidence would resolve it: Experimental results comparing CoRTEx performance with and without additional knowledge sources (e.g., UMLS relations, domain ontologies, structured databases), showing whether the combination provides synergistic improvements in clustering accuracy.

## Limitations

- Dependence on ChatGPT's explanation quality - inaccurate or irrelevant explanations could degrade embedding quality
- Limited evaluation on relatively small test sets (221 and 395 samples) that may not represent full biomedical terminology diversity
- Scalability demonstration relies heavily on ChatGPT's performance and cost-effectiveness at scale, introducing uncertainty about practical deployment

## Confidence

**High confidence**: The effectiveness of contrastive learning for aligning term and explanation embeddings is well-established in the broader literature. The improved clustering performance on test sets (F1 scores of 0.647 and 0.579) compared to baseline models is directly measurable and reproducible.

**Medium confidence**: The generalization capability of the model to cluster terms without explanations and handle out-of-distribution data is demonstrated but requires further validation on more diverse datasets. The efficiency claims of the ChatGPT-assisted BIRCH algorithm are supported by the reduction from O(N²) to O(N) queries, but the quality trade-offs are not fully characterized.

**Low confidence**: The scalability demonstration with 35.6 million BIOS terms relies heavily on ChatGPT's performance and cost-effectiveness at scale, which introduces uncertainty about practical deployment feasibility.

## Next Checks

1. **Quality assessment of ChatGPT explanations**: Manually evaluate a stratified sample of 200 generated explanations across different biomedical domains to measure accuracy, completeness, and potential biases that could affect knowledge injection quality.

2. **Stress test on out-of-distribution terms**: Create a test set of 1,000 biomedical terms that were not present in UMLS 2023AA, including emerging concepts and rare terminology, to evaluate the model's true generalization capabilities beyond the reported results.

3. **Cost-benefit analysis of BIRCH algorithm**: Measure the correlation between the number of ChatGPT queries and clustering accuracy on a subset of 100,000 BIOS terms, comparing results against traditional BIRCH with static thresholds to quantify the trade-off between efficiency and quality.