---
ver: rpa2
title: Exploring Large Language Models for Human Mobility Prediction under Public
  Events
arxiv_id: '2311.17351'
source_url: https://arxiv.org/abs/2311.17351
tags:
- event
- events
- data
- mobility
- demand
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes using Large Language Models (LLMs) for human
  mobility prediction under public events. The key idea is to leverage LLMs' ability
  to process textual event descriptions and learn from minimal examples to predict
  travel demand patterns.
---

# Exploring Large Language Models for Human Mobility Prediction under Public Events

## Quick Facts
- arXiv ID: 2311.17351
- Source URL: https://arxiv.org/abs/2311.17351
- Reference count: 4
- Primary result: LLM-MPE outperforms traditional ML models for event-day mobility prediction by leveraging event descriptions

## Executive Summary
This paper introduces LLM-MPE, a framework that uses Large Language Models (LLMs) to predict human mobility patterns during public events. The approach transforms unstructured event descriptions into standardized formats, decomposes historical mobility data into regular and irregular components, and employs chain-of-thought prompting to generate interpretable predictions. Tested on taxi trip data around Barclays Center in New York City, LLM-MPE demonstrates superior performance on event days compared to traditional models while providing transparent reasoning for its predictions. However, challenges remain including hallucination risks, knowledge cutoff limitations, high computational costs, and limited spatial reasoning capabilities.

## Method Summary
LLM-MPE processes event descriptions through LLMs to create standardized event summaries, then decomposes historical mobility data into regular patterns and irregular deviations. Using chain-of-thought prompting, the framework provides LLMs with historical examples and reasoning instructions to predict travel demand patterns. The method was evaluated using NYC taxi trip data from 2013-2015, comparing performance against traditional ML models (LR, GBDT, FNN, RNN) on both event and non-event days, with predictions generated for pickup and dropoff flows around Barclays Center.

## Key Results
- LLM-MPE outperforms traditional models on event days with significantly lower prediction errors
- Textual event data improves prediction accuracy compared to using only event timing and count features
- The chain-of-thought prompting provides interpretable insights into the model's decision-making process
- LLM-MPE achieves competitive performance on non-event days while maintaining interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs outperform traditional models on event days because they can process unstructured textual event descriptions into actionable insights.
- Mechanism: The LLM-MPE framework transforms raw, unstructured event descriptions from online sources into a standardized format using LLM summarization capabilities. This formatted data is then used alongside decomposed mobility features in a chain-of-thought prompting strategy to generate interpretable predictions.
- Core assumption: LLMs' pre-training on web-scale corpora enables them to understand diverse event semantics and categories even from minimal or noisy text.
- Evidence anchors:
  - [abstract]: "LLM-MPE first transforms raw, unstructured event descriptions from online sources into a standardized format... A prompting strategy is designed to direct LLMs in making and rationalizing demand predictions"
  - [section]: "LLMs excel in distilling extensive event details into concise and pertinent summaries due to their ability to generate natural language. Moreover, they are capable of identifying specific terms like the performer's name or show's title, because LLMs are pre-trained based on vast web data"
- Break condition: If event descriptions lack sufficient semantic clues or if the LLM's pre-training data doesn't cover relevant event types, the transformation quality degrades, reducing prediction accuracy.

### Mechanism 2
- Claim: LLMs achieve better performance than deep learning models despite limited training data because they leverage in-context learning from historical examples.
- Mechanism: The prompting strategy provides LLMs with a few historical examples of similar events and their mobility impacts, allowing the model to infer patterns without requiring massive training datasets.
- Core assumption: LLMs can effectively learn from minimal examples when provided with the right context and reasoning instructions.
- Evidence anchors:
  - [abstract]: "LLMs are equipped with a 'few-shot learning' ability, which means they can undertake new tasks with minimal examples or simple instructions"
  - [section]: "LLMs are effective at learning new tasks with very few examples (Brown et al., 2020), indicating their potential capability to infer event-induced travel demand by learning from limited historical events"
- Break condition: If historical examples are too sparse or too dissimilar from the target event, the in-context learning becomes ineffective, leading to poor generalization.

### Mechanism 3
- Claim: The chain-of-thought prompting strategy improves both accuracy and interpretability by forcing the LLM to articulate its reasoning process.
- Mechanism: By instructing the LLM to "think step-by-step before making the prediction," the model breaks down complex reasoning into sequential steps, capturing temporal patterns, event similarities, and causal relationships.
- Core assumption: LLMs can decompose multi-step reasoning tasks when explicitly prompted to do so, and this decomposition leads to better predictions.
- Evidence anchors:
  - [abstract]: "We employ a chain-of-thought prompting strategy to make LLM-MPE detail its decision-making progressively. This offers clarity on the model's predictive reasoning"
  - [section]: "LLMs have demonstrated the ability to tackle complex, multi-step reasoning tasks, such as solving mathematical problems... Moreover, LLMs are effective at learning new tasks with very few examples"
- Break condition: If the reasoning steps become too complex or if the LLM's intermediate reasoning contains errors (hallucinations), the final prediction quality may degrade despite improved interpretability.

## Foundational Learning

- Concept: Text preprocessing and feature engineering for unstructured data
  - Why needed here: Event descriptions come in varied formats and lengths, requiring standardization before they can be used for prediction
  - Quick check question: What are the key differences between raw event descriptions and formatted event summaries in LLM-MPE?

- Concept: Time series decomposition and pattern extraction
  - Why needed here: Separating regular mobility patterns from event-induced deviations allows the model to focus on the specific impact of events
  - Quick check question: How does mobility feature decomposition improve prediction accuracy compared to using raw travel demand values?

- Concept: Prompt engineering and few-shot learning techniques
  - Why needed here: The effectiveness of LLM predictions depends heavily on how well the prompt guides the model's reasoning process
  - Quick check question: What are the key components of the LLM-MPE prompt template, and how do they guide the prediction process?

## Architecture Onboarding

- Component map: Data ingestion → Text processing → Feature decomposition → Prompt construction → LLM prediction → Evaluation
- Critical path: Event data → Text formatting → Feature decomposition → Prompt construction → LLM prediction → Evaluation
- Design tradeoffs:
  - Using LLMs provides better interpretability but introduces latency and cost compared to traditional ML models
  - Chain-of-thought prompting improves reasoning but increases token usage and API calls
  - Focusing on Barclays Center provides controlled experiments but limits generalizability to other venues
- Failure signatures:
  - High prediction errors on event days indicate poor event-text understanding or insufficient historical examples
  - Low interpretability scores suggest the chain-of-thought reasoning is not being properly generated
  - Performance degradation over time may indicate outdated LLM knowledge base
- First 3 experiments:
  1. Compare LLM-MPE predictions with and without formatted event descriptions to quantify the value of text processing
  2. Test different prompt variations (with/without chain-of-thought, different example selections) to optimize performance
  3. Evaluate prediction accuracy on non-event days to ensure the model doesn't overfit to event patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the hallucination problem in LLMs be effectively mitigated when predicting human mobility under public events?
- Basis in paper: The authors explicitly mention that even advanced LLMs like GPT-4 can produce incorrect information, a phenomenon known as "hallucination," which is concerning from an ethical standpoint as these inaccuracies can lead to irresponsible or even harmful recommendations, potentially impacting human safety and well-being.
- Why unresolved: The paper acknowledges the issue but does not provide a concrete solution to mitigate it. It only suggests the need for more stringent AI regulations and guidelines to ensure responsible use.
- What evidence would resolve it: Development and validation of techniques or methods that can detect and correct hallucinations in LLM predictions for human mobility, along with empirical studies demonstrating their effectiveness.

### Open Question 2
- Question: What are the most effective strategies to incorporate spatial relationships between multiple event venues into LLM-based human mobility prediction models?
- Basis in paper: The authors identify the current limitation of LLMs in understanding spatial relationships, especially in scenarios involving multiple event venues. They suggest two potential strategies: articulating spatial relationships in natural language or combining LLMs with domain-specific deep neural networks like graph neural networks (GNNs).
- Why unresolved: The paper does not explore or validate these strategies in the context of human mobility prediction. It remains unclear how well LLMs can comprehend and utilize spatial information when predicting travel demand across multiple venues.
- What evidence would resolve it: Empirical studies comparing the performance of LLM-based models with and without spatial relationship incorporation, using real-world data from multiple event venues.

### Open Question 3
- Question: How can the efficiency of LLM-based human mobility prediction models be improved to handle large-scale data and high-frequency predictions?
- Basis in paper: The authors highlight the inefficiency of LLMs in generating predictions, noting that in their case study, GBDT takes approximately 2.4 seconds to generate predictions for all test samples, while LLM-MPE takes 12.7 seconds to generate predictions for a single test sample. This inefficiency is problematic for large-scale data and high-frequency predictions.
- Why unresolved: The paper does not provide a detailed solution to address this efficiency issue. It only suggests combining LLMs with traditional machine-learning models as a potential approach.
- What evidence would resolve it: Development and validation of hybrid models that combine LLMs with traditional machine-learning models, along with benchmarking studies demonstrating significant improvements in prediction efficiency without compromising accuracy.

## Limitations
- Geographic specificity: Results validated only for Barclays Center in New York City, limiting generalizability
- Temporal constraints: Training data spans only 1.5 years, potentially limiting robustness for rare or evolving event types
- Resource dependency: Heavy reliance on GPT-4 API introduces cost barriers and potential knowledge cutoff issues

## Confidence

**High confidence**: The framework's ability to process event descriptions and decompose mobility patterns is well-supported by the methodology and experimental results

**Medium confidence**: The claim that LLM-MPE outperforms traditional models is supported by quantitative results but requires replication on diverse datasets

**Low confidence**: The assertion that interpretability directly translates to actionable insights for urban planners needs further validation through user studies

## Next Checks

1. **Cross-venue validation**: Test LLM-MPE on a different venue (e.g., Madison Square Garden) to assess generalizability across event types and urban contexts

2. **Cost-performance tradeoff analysis**: Compare prediction accuracy against API costs for different LLM models (GPT-3.5, Claude, open-source alternatives) to identify optimal configurations

3. **Knowledge freshness evaluation**: Measure prediction degradation over time and test with synthetic events beyond the LLM's training cutoff to quantify knowledge limitation impacts