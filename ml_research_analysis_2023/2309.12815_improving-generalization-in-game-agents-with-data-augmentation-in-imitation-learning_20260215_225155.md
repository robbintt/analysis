---
ver: rpa2
title: Improving Generalization in Game Agents with Data Augmentation in Imitation
  Learning
arxiv_id: '2309.12815'
source_url: https://arxiv.org/abs/2309.12815
tags:
- learning
- data
- augmentations
- augmentation
- generalization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigates how data augmentation can improve the generalization
  of imitation learning (IL) agents in video games. It evaluates six augmentation
  techniques (Gaussian noise, uniform noise, scaling, state-mixup, continuous dropout,
  and semantic dropout) across different combinations, up to three augmentations per
  model, using a feature-based state space from a 3D open-world game.
---

# Improving Generalization in Game Agents with Data Augmentation in Imitation Learning

## Quick Facts
- arXiv ID: 2309.12815
- Source URL: https://arxiv.org/abs/2309.12815
- Reference count: 33
- Key outcome: Data augmentation improves IL agent generalization in games by 20-80% across four test environments

## Executive Summary
This study investigates how data augmentation can improve the generalization of imitation learning (IL) agents in video games. The authors evaluate six augmentation techniques (Gaussian noise, uniform noise, scaling, state-mixup, continuous dropout, and semantic dropout) across different combinations, up to three augmentations per model, using a feature-based state space from a 3D open-world game. Models were trained on 78 human demonstrations and tested across four modified environments. Results show that certain augmentation combinations consistently outperformed a non-augmented baseline, with improvements ranging from 20% to 80% in success rate across environments. The most promising augmentations for generalization were scaling, state-mixup, and continuous dropout, while semantic dropout reduced performance.

## Method Summary
The study trains IL agents using behavioral cloning on 78 human demonstrations from a 3D open-world game. Six data augmentation techniques are applied individually and in combinations (up to three augmentations per model). The agent uses a feature-based state space including agent-to-goal vectors, entity information, and a semantic map processed by a transformer encoder and convolutional layers. Models are trained for 300 epochs and evaluated on four modified test environments to assess generalization performance.

## Key Results
- Data augmentation combinations achieved 20-80% higher success rates compared to baseline across test environments
- Scaling, state-mixup, and continuous dropout showed the most consistent generalization improvements
- Semantic dropout (0.50 relative success rate) actually reduced performance compared to baseline
- Augmentation effectiveness varied across environments, suggesting context-dependent benefits

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data augmentation in IL improves generalization by increasing the diversity of the training distribution to better match the real state-action distribution encountered during testing.
- Mechanism: Augmentations such as Gaussian noise, scaling, and state-mixup introduce variations in the input state space that simulate different environmental conditions. This expanded training distribution helps the agent learn more robust policies that generalize to unseen scenarios.
- Core assumption: The augmented states are physically realizable, and the original actions remain valid for the augmented states.
- Evidence anchors:
  - [abstract] "Inspired by the success of data augmentation in supervised learning, we augment the training data so the distribution of states and actions in the dataset better represents the real state-action distribution."
  - [section III.B] "We assume that applying a small transformation to an input state s results in a physically realizable state ŝ, and that the original action a remains a valid action for the state ŝ."
  - [corpus] No direct evidence found in corpus neighbors.
- Break condition: If the augmentations introduce states that are not physically realizable or if the original actions are not valid for the augmented states, the assumption fails and the mechanism breaks down.

### Mechanism 2
- Claim: Combining multiple augmentations is more effective than using single augmentations alone.
- Mechanism: Sequential application of augmentations (e.g., Gaussian noise followed by scaling) creates compounded variations in the state space, leading to a richer and more diverse training dataset. This diversity helps the agent learn to handle a wider range of scenarios.
- Core assumption: The order of augmentations matters and should be optimized to maximize the effect of changing the data.
- Evidence anchors:
  - [section V.A] "We performed the augmentation step three times, resulting in a dataset four times as large as the original data. Augmentations were applied to the data in the order listed in III-B. This ordering was chosen to maximize the effect of changing the data by first performing translations followed by scaling, and to preserve dropout by performing those augmentations last in the composition."
  - [corpus] No direct evidence found in corpus neighbors.
- Break condition: If the order of augmentations does not matter or if certain combinations of augmentations cancel each other out, the mechanism fails.

### Mechanism 3
- Claim: Certain augmentations are more effective than others in improving generalization.
- Mechanism: Scaling, state-mixup, and continuous dropout were identified as the most promising augmentations for improving generalization. Scaling adjusts the magnitude of state features, state-mixup interpolates between consecutive states, and continuous dropout randomly zeroes out continuous-valued elements, all contributing to a more robust learning process.
- Core assumption: The effectiveness of augmentations can be measured by their impact on the agent's performance in unseen environments.
- Evidence anchors:
  - [section V.B] "From this analysis, we found the following average relative success rates: scaling ( 1.27), state mixup ( 1.26), continuous dropout ( 1.26), Gaussian noise (1.25), uniform noise ( 1.02), and semantic dropout ( 0.50)."
  - [corpus] No direct evidence found in corpus neighbors.
- Break condition: If the effectiveness of augmentations is highly sensitive to the specific task or environment, the mechanism may not generalize well to other scenarios.

## Foundational Learning

- Concept: Markov Decision Process (MDP)
  - Why needed here: The IL agent is trained within an MDP framework, where it learns a policy that maps states to actions. Understanding MDPs is crucial for grasping how the agent interacts with the environment and learns from demonstrations.
  - Quick check question: What are the components of an MDP and how do they relate to the IL agent's learning process?

- Concept: Behavioral Cloning (BC)
  - Why needed here: BC is the IL technique used in this study, where the agent learns to mimic expert behavior from demonstrations. Understanding BC is essential for comprehending the training process and the role of data augmentation.
  - Quick check question: How does BC differ from other IL techniques, and what are its advantages and limitations?

- Concept: Data Augmentation
  - Why needed here: Data augmentation is the core technique used to improve generalization. Understanding how augmentations work and their impact on the training data is crucial for implementing and evaluating the method.
  - Quick check question: What are the different types of data augmentations used in this study, and how do they modify the state space?

## Architecture Onboarding

- Component map: State space (feature-based observations) -> Transformer encoder (semantic map processing) -> Convolutional layers (state feature processing) -> Neural network -> Action probabilities
- Critical path: Collect demonstrations -> Apply data augmentations -> Train IL agent using BC -> Evaluate in test environments
- Design tradeoffs: Choice of augmentations and parameters affects performance; more aggressive augmentations may improve generalization but introduce noise that hinders learning
- Failure signatures: Poor generalization performance in test environments, high variance in success rates, sensitivity to training parameters
- First 3 experiments:
  1. Train baseline IL agent without augmentations and evaluate performance in training and test environments
  2. Apply single augmentation (e.g., Gaussian noise) to training data and retrain agent, comparing performance to baseline
  3. Combine two augmentations (e.g., scaling and state-mixup) and evaluate their impact on generalization performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Which specific combination of data augmentations consistently improves generalization across different game environments and tasks?
- Basis in paper: [explicit] The paper identifies that certain augmentation combinations (scaling, state-mixup, continuous dropout) consistently outperform baselines, but notes that the best combinations vary across environments.
- Why unresolved: The study was limited to one specific game environment and task type, leaving open whether these findings generalize to other game genres, observation spaces, or task complexities.
- What evidence would resolve it: Systematic testing across diverse game environments (different genres, observation spaces, and task types) with varying complexity levels to identify universally effective augmentation combinations.

### Open Question 2
- Question: How do hyperparameters for data augmentations affect the generalization performance of imitation learning agents?
- Basis in paper: [explicit] The paper notes that augmentations are sensitive to training parameters and suggests a more thorough study is needed to assess their contribution.
- Why unresolved: The study only tested specific hyperparameter values and combinations, leaving uncertainty about optimal parameter ranges and their interactions.
- What evidence would resolve it: Comprehensive hyperparameter optimization across multiple augmentation techniques, including sensitivity analysis to identify robust parameter ranges that consistently improve generalization.

### Open Question 3
- Question: Can data augmentation techniques improve generalization in imitation learning agents beyond navigation and interaction tasks?
- Basis in paper: [explicit] The paper tested augmentations only on navigation and interaction tasks, suggesting exploration in different tasks would be valuable.
- Why unresolved: The study's limited task scope means it's unclear whether these augmentation techniques would be effective for more complex game AI tasks like strategy, combat, or creative problem-solving.
- What evidence would resolve it: Testing the same augmentation techniques on diverse game AI tasks (strategy games, combat scenarios, creative tasks) to determine their effectiveness across different cognitive domains.

## Limitations
- Results based on single game environment with 78 demonstrations, limiting generalizability
- Effectiveness of augmentations appears highly sensitive to composition and ordering
- Semantic dropout's negative impact indicates not all augmentations are beneficial
- Assumption that augmented states remain physically realizable is not empirically validated

## Confidence
- Confidence in core claim that data augmentation improves generalization: Medium
- Confidence in specific ranking of augmentation effectiveness: Low
- Confidence in generalizability across domains: Low

## Next Checks
1. **Cross-domain validation**: Test the same augmentation techniques on at least two different game environments with varying state spaces to assess generalizability beyond the original domain.

2. **Dataset size sensitivity analysis**: Systematically vary the number of demonstrations (e.g., 20, 50, 78, 150) to determine how augmentation benefits scale with training data size and identify potential diminishing returns.

3. **Physical realizability verification**: Implement a validation step that checks whether augmented states remain within physically plausible ranges for the game environment, and measure the correlation between physical validity and performance improvements.