---
ver: rpa2
title: Navya3DSeg -- Navya 3D Semantic Segmentation Dataset & split generation for
  autonomous vehicles
arxiv_id: '2302.08292'
source_url: https://arxiv.org/abs/2302.08292
tags:
- dataset
- navya3dseg
- label
- split
- labels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Navya3DSeg is a large-scale autonomous driving point cloud dataset
  with 23 labeled sequences from 13 countries, featuring 30 semantic labels for 3D
  segmentation. The dataset includes diverse environments and introduces the CURB
  label, often missing in other datasets.
---

# Navya3DSeg -- Navya 3D Semantic Segmentation Dataset & split generation for autonomous vehicles

## Quick Facts
- arXiv ID: 2302.08292
- Source URL: https://arxiv.org/abs/2302.08292
- Authors: 
- Reference count: 40
- Primary result: Navya3DSeg achieves 62.84% mIoU with Cylinder3D and introduces novel sequential dataset splitting and active learning methods

## Executive Summary
Navya3DSeg is a large-scale autonomous driving point cloud dataset with 23 labeled sequences from 13 countries, featuring 30 semantic labels for 3D segmentation. The dataset includes diverse environments and introduces the CURB label, often missing in other datasets. A novel sequential dataset split method based on iterative multi-label stratification was proposed, improving test set mIoU by 1.2% over SemanticKITTI's baseline. Semantic segmentation benchmarks on SqueezeSegV2, SalsaNext, and Cylinder3D showed Cylinder3D achieved the highest mIoU (62.84%). Cross-dataset experiments demonstrated the benefits of pre-training, with fine-tuning from SemanticKITTI improving Navya3DSeg performance. An active learning framework with a novel distance-based sampling method was also introduced, enabling dataset distillation to 64.8% of the full dataset while maintaining fully supervised performance.

## Method Summary
Navya3DSeg provides a diverse autonomous driving dataset with 23 labeled sequences from 13 countries, using a Hesai Pandar40 LiDAR sensor. The dataset includes 30 semantic labels with a focus on ground-level features like curbs. The paper introduces a sequential dataset split method using iterative multi-label stratification to minimize label distribution shift and intensity drift. Three semantic segmentation architectures (SqueezeSegV2, SalsaNext, Cylinder3D) were evaluated, with Cylinder3D achieving the best performance (62.84% mIoU). An active learning framework with distance-based sampling was proposed for efficient dataset distillation, achieving 64.8% of the dataset size while maintaining performance. Cross-dataset experiments demonstrated the benefits of pre-training on SemanticKITTI for Navya3DSeg.

## Key Results
- Cylinder3D achieves highest mIoU of 62.84% on Navya3DSeg test set
- Novel split method improves test set mIoU by 1.2% over SemanticKITTI baseline
- Active learning framework enables dataset distillation to 64.8% while maintaining fully supervised performance
- Cross-dataset experiments show 2.1% mIoU improvement when fine-tuning from SemanticKITTI

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The Navya3DSeg dataset's diversity in geography, environments, and sensor characteristics improves model generalization for autonomous driving perception.
- **Mechanism**: The dataset aggregates 23 labeled sequences from 13 countries across 3 continents, including urban, rural, industrial, and university environments. This geographic and environmental diversity exposes models to a wider variety of real-world scenarios than single-region datasets like SemanticKITTI. Additionally, the sensor setup (Hesai Pandar40 with 15° downward pitch) captures ground-focused data, which is essential for tasks like curb detection and road segmentation.
- **Core assumption**: Model generalization benefits from exposure to diverse environmental and sensor conditions during training.
- **Evidence anchors**:
  - [abstract]: "Navya3DSeg (Fig. 1) is a high diversity autonomous vehicle dataset built for semantic segmentation task... from 13 countries, 39 cities and 3 continents."
  - [section]: "Navya3DSeg is split into a labeled and an unlabeled part. The labeled part is made of carefully selected 23 sequences from 9 countries... The unlabeled part contains 25 sequences from 8 countries..."
  - [corpus]: Weak evidence. The related papers focus on other datasets and do not provide direct support for Navya3DSeg's diversity claims.
- **Break condition**: If the dataset's diversity does not translate to improved performance on real-world tasks due to imbalanced label distributions or insufficient representation of critical edge cases.

### Mechanism 2
- **Claim**: The proposed iterative multi-label stratified split method improves the quality of train/validation/test splits by minimizing label distribution shift and intensity drift.
- **Mechanism**: The method extends multi-label stratified shuffle split (MSSS) to sequential LiDAR data by grouping consecutive scans into segments (granularity parameter). It then assigns these segments to splits while minimizing label distribution divergence (LD) and intensity drift (IDS) between subsets. This ensures that each subset has a representative distribution of labels and sensor characteristics, leading to more reliable model evaluation.
- **Core assumption**: High-quality dataset splits are crucial for reliable model evaluation and hyperparameter tuning.
- **Evidence anchors**:
  - [section]: "We introduce a simple extension to the Multi-label Stratiﬁed Shufﬂe Split (MSSS)... We propose a novel method for sequential dataset split generation based on iterative multi-label stratiﬁcation, and demonstrated to achieve a +1.2% mIoU improvement over the original split proposed by SemanticKITTI dataset."
  - [section]: "When compared to SemanticKITTI dataset split, the selected split of Navya3DSeg generated by our split module has lower values of intensity distribution shift (IDS) and label distributional shift (LD), as shown in table II."
  - [corpus]: Weak evidence. The related papers do not discuss dataset splitting methods or their impact on model performance.
- **Break condition**: If the granularity parameter is not optimally chosen, leading to either temporal correlation between subsets or imbalanced subset sizes.

### Mechanism 3
- **Claim**: The active learning framework with distance-based sampling enables efficient dataset distillation while maintaining model performance.
- **Mechanism**: The distance-based sampling method selects samples from the unlabeled pool based on their spatial distance from the labeled pool in the ego-pose space. This reduces spatial overlap and redundancy between labeled and unlabeled subsets, ensuring that the distilled dataset contains diverse and informative samples. The method is integrated into a Bayesian active learning loop using MC Dropout for uncertainty estimation.
- **Core assumption**: Efficient dataset distillation is possible by selecting diverse and informative samples based on their spatial distribution.
- **Evidence anchors**:
  - [abstract]: "An active learning (AL) based dataset distillation framework. We introduce a novel heuristic-free sampling method called distance sampling in the context of AL."
  - [section]: "To address these problems, we propose a novel distance-based sampling method which reduces the spatial overlap on the sequences' trajectories between labeled (L) and unlabeled (U) pools, while compressing a dataset."
  - [corpus]: Weak evidence. The related papers do not discuss active learning or dataset distillation methods.
- **Break condition**: If the distance-based sampling method fails to select samples that are informative for the model, leading to degraded performance on the distilled dataset.

## Foundational Learning

- **Concept**: Dataset splitting and stratification techniques.
  - Why needed here: The quality of dataset splits directly impacts model evaluation and hyperparameter tuning. Navya3DSeg introduces a novel stratified splitting method to improve upon existing approaches.
  - Quick check question: How does multi-label stratification differ from random sampling in dataset splitting, and why is it important for datasets with imbalanced label distributions?

- **Concept**: Semantic segmentation metrics and evaluation.
  - Why needed here: Navya3DSeg uses standard semantic segmentation metrics (IoU, Precision-Recall, F1-Scores) to evaluate model performance. Understanding these metrics is crucial for interpreting the benchmark results.
  - Quick check question: What is the difference between mean IoU (mIoU) and frequency-weighted IoU (fwIoU), and when would you use each?

- **Concept**: Active learning and uncertainty estimation.
  - Why needed here: Navya3DSeg introduces an active learning framework with a novel distance-based sampling method for dataset distillation. Understanding active learning principles is essential for grasping this contribution.
  - Quick check question: How does Bayesian active learning with MC Dropout differ from traditional active learning approaches, and what are its advantages?

## Architecture Onboarding

- **Component map**: Data acquisition (Navya MMS with Hesai Pandar40 LiDAR) -> Dataset creation (Navya3DSeg with 30 labels) -> Dataset splitting (Iterative multi-label stratification) -> Semantic segmentation (SqueezeSegV2, SalsaNext, Cylinder3D) -> Active learning (Bayesian with distance sampling) -> Evaluation (mIoU, Precision-Recall, F1-scores)

- **Critical path**: 1) Data acquisition and preprocessing, 2) Dataset splitting and stratification, 3) Model training and evaluation on semantic segmentation benchmarks, 4) Cross-dataset generalization experiments, 5) Active learning dataset distillation

- **Design tradeoffs**:
  - Dataset diversity vs. label imbalance: Navya3DSeg prioritizes diversity but suffers from label imbalance, requiring label mapping for training
  - Sensor characteristics vs. generalization: The downward-oriented LiDAR captures ground-focused data but may limit generalization to other sensor setups
  - Active learning efficiency vs. computational cost: Distance-based sampling reduces redundancy but increases computational complexity compared to random sampling

- **Failure signatures**:
  - Poor model performance on certain labels due to label imbalance or insufficient representation in the training data
  - Overfitting to the training set due to inadequate dataset splitting or hyperparameter tuning
  - Slow active learning convergence due to ineffective sampling strategy or uncertainty estimation

- **First 3 experiments**:
  1. Evaluate the impact of dataset splitting methods on model performance using a simple semantic segmentation architecture (e.g., SqueezeSegV2)
  2. Compare the generalization performance of models trained on Navya3DSeg vs. SemanticKITTI on a common label space
  3. Implement and evaluate the distance-based sampling method within the active learning framework on a subset of Navya3DSeg

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the proposed CURB label in Navya3DSeg improve autonomous vehicle localization and navigation performance compared to datasets without this label?
- **Basis in paper**: [explicit] The paper introduces the CURB label and states it represents 1.379% of Navya3DSeg, noting its usefulness for tasks like lateral localization, lane fitting, and road segmentation.
- **Why unresolved**: The paper mentions the CURB label's potential benefits but does not provide experimental results demonstrating its impact on autonomous driving tasks.
- **What evidence would resolve it**: Experimental results comparing autonomous vehicle performance (e.g., localization accuracy, lane detection) using models trained on Navya3DSeg versus models trained on datasets without the CURB label.

### Open Question 2
- **Question**: What is the optimal granularity level for multi-label stratified sampling in sequential datasets like Navya3DSeg to balance temporal correlation reduction and desired subset ratio adherence?
- **Basis in paper**: [inferred] The paper discusses the effect of granularity on dataset splits, noting that smaller granularity leads to higher temporal correlation and over-fitting, while larger granularity may not meet desired subset ratios.
- **Why unresolved**: The paper does not provide a definitive answer on the optimal granularity level, as it depends on the specific dataset and task.
- **What evidence would resolve it**: Empirical studies comparing model performance using different granularity levels for multi-label stratified sampling on various sequential datasets.

### Open Question 3
- **Question**: How does the proposed distance-based sampling method in active learning compare to other sampling techniques in terms of computational efficiency and performance across different types of datasets?
- **Basis in paper**: [explicit] The paper introduces a novel distance-based sampling method and compares it to random sampling and BALD, showing improved performance in dataset distillation.
- **Why unresolved**: The paper does not provide a comprehensive comparison of the proposed method's computational efficiency or its performance across diverse datasets.
- **What evidence would resolve it**: Benchmarking the distance-based sampling method against other active learning techniques in terms of computation time and model performance on various datasets with different characteristics.

## Limitations
- Weak evidence anchoring in related corpus for diversity claims and active learning contributions
- Label imbalance across 30 semantic classes may affect model performance
- Sensor-specific characteristics (downward-oriented LiDAR) may limit generalization to other sensor setups
- Computational complexity of distance-based sampling method not thoroughly evaluated

## Confidence

- **High**: Dataset creation methodology and benchmark results (62.84% mIoU with Cylinder3D)
- **Medium**: Geographic diversity claims and split method improvements  
- **Low**: Active learning framework effectiveness due to lack of comparative studies

## Next Checks

1. Conduct ablation studies on the iterative multi-label stratification method using synthetic datasets with known distributions
2. Perform cross-sensor generalization tests by training on Navya3DSeg and evaluating on datasets with different LiDAR configurations
3. Implement the distance-based sampling method on a smaller dataset to verify computational efficiency claims and sampling quality