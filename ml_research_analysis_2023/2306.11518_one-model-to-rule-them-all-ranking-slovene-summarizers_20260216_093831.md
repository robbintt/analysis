---
ver: rpa2
title: 'One model to rule them all: ranking Slovene summarizers'
arxiv_id: '2306.11518'
source_url: https://arxiv.org/abs/2306.11518
tags:
- summarization
- text
- slovene
- meta-model
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors developed four Slovene text summarizers (two extractive,
  one abstractive, one hybrid) and a meta-model to automatically select the best one
  for a given input. The meta-model uses a fully connected neural network to predict
  ROUGE scores from Doc2Vec document embeddings.
---

# One model to rule them all: ranking Slovene summarizers

## Quick Facts
- arXiv ID: 2306.11518
- Source URL: https://arxiv.org/abs/2306.11518
- Reference count: 20
- Key outcome: Meta-model achieves MSE of 70.066 in predicting best Slovene summarizer, outperforming baselines and correctly selecting T5 model 595/1000 times

## Executive Summary
This paper presents a meta-model system that automatically selects the best Slovene text summarizer for a given input document. The system combines four different summarization approaches (two extractive, one abstractive, one hybrid) and uses a fully connected neural network to predict which model will achieve the highest ROUGE score for each input. Tested on 93k documents, the meta-model significantly outperforms baseline selection methods and achieves strong ROUGE scores of 20.38/5.85/13.67.

## Method Summary
The system employs a fully connected neural network that analyzes input content through Doc2Vec document embeddings and predicts which of four Slovene summarizers will perform best for a given text. The meta-model is trained on 93,419 examples where each document has been summarized by all four models and ROUGE scores calculated. During inference, the meta-model selects the summarizer with the highest predicted ROUGE score, improving overall summarization quality compared to using any single model.

## Key Results
- Meta-model achieves mean squared error of 70.066 in predicting ROUGE scores, outperforming baseline (84.493) and random forest (74.975) methods
- System correctly recommended T5-based model for 595 of 1000 test samples
- Final system achieves ROUGE-1/2/L scores of 20.38/5.85/13.67
- Demonstrates that intelligent model selection improves performance over individual models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The meta-model successfully predicts which summarization model will perform best for a given input text by learning the relationship between document embeddings and ROUGE scores.
- Mechanism: The fully connected neural network maps Doc2Vec embeddings to predicted ROUGE scores for each summarizer. During inference, it selects the model with the highest predicted score.
- Core assumption: Document embeddings capture sufficient information about text properties (length, genre, complexity) to predict summarization performance differences across models.
- Evidence anchors:
  - [abstract] "The proposed system employs a fully connected neural network that analyzes the input content and predicts which summarizer should score the best in terms of ROUGE score for a given input."
  - [section] "The meta-model consists of a fully connected neural network, trained to predict the ROUGE scores of the summarizers."
  - [corpus] Weak - corpus shows related work on ranking summarizers but no direct evidence of Doc2Vec-to-ROUGE prediction effectiveness.
- Break condition: If document embeddings fail to capture key distinguishing features between texts that affect summarizer performance, or if ROUGE scores don't correlate with human judgment of summary quality.

### Mechanism 2
- Claim: Using multiple diverse summarization approaches and selecting the best one improves overall performance compared to using any single model.
- Mechanism: The system maintains four different summarizers (extractive, abstractive, hybrid) that each handle different text characteristics well. The meta-model routes each input to the most appropriate one.
- Core assumption: No single summarization approach works best for all text types, and combining approaches through intelligent selection outperforms individual models.
- Evidence anchors:
  - [abstract] "However, there is no single model or approach that performs well on every type of text."
  - [section] "We produced four Slovene summarization models with different properties and trained them on different training data."
  - [corpus] Moderate - corpus includes papers on ranking summarizers and assessing personalization, supporting the idea that model selection matters.
- Break condition: If the performance differences between models are minimal, or if the meta-model selection overhead exceeds the benefits of switching between models.

### Mechanism 3
- Claim: Training the meta-model on a large, diverse corpus enables it to generalize across different text types and genres in Slovene.
- Mechanism: The Doc2Vec model is trained on 677,644 Slovene documents spanning news, financial, academic, and translated content, providing rich document representations that capture genre and length variations.
- Core assumption: The training corpus diversity ensures the meta-model learns patterns that generalize to unseen text types.
- Evidence anchors:
  - [section] "We applied the Doc2Vec model for document representation and train it on the Slovene documents presented in Table 1 (without abstracts)."
  - [section] "The four Slovene summarization models deal with different challenges associated with text summarization in a less-resourced language."
  - [corpus] Weak - corpus shows related work but doesn't confirm the effectiveness of the specific training approach on Slovene data.
- Break condition: If the training corpus doesn't adequately represent the distribution of real-world inputs, or if the Doc2Vec representations don't capture task-relevant features.

## Foundational Learning

- Concept: ROUGE metric calculation and interpretation
  - Why needed here: The entire meta-model is trained to predict ROUGE scores, which are the evaluation metric for summarization quality
  - Quick check question: If a summary has 5 overlapping unigrams and the reference has 10 unigrams, what is the ROUGE-1 recall score?

- Concept: Doc2Vec document embedding generation and properties
  - Why needed here: The meta-model uses Doc2Vec embeddings as input features to predict which summarizer will work best
  - Quick check question: What is the dimensionality of the Doc2Vec vectors used in this system, and why was this size chosen?

- Concept: Neural network architecture for regression tasks
  - Why needed here: The meta-model is a fully connected neural network trained to predict continuous ROUGE scores
  - Quick check question: Why might the authors have chosen ReLU activation and mean squared error loss for this regression problem?

## Architecture Onboarding

- Component map:
  - Raw Slovene text -> Doc2Vec embedding (256-dim, lemmatized, window size 5)
  - Meta-model (fully connected neural network, 2 hidden layers of 1024 neurons each, ReLU activation)
  - Four summarizers: Sumbasic (word frequency), Graph-based (LaBSE sentence encoder), T5-article (fine-tuned Slovene T5), Hybrid-long (extractive + abstractive)
  - Output: Selected summarizer generates final summary

- Critical path:
  Doc2Vec embedding -> Meta-model predicts ROUGE scores for all four models -> Select model with highest predicted score -> Generate summary using selected model

- Design tradeoffs:
  - Using Doc2Vec vs. transformer-based embeddings: Faster inference but potentially less rich representations
  - Predicting ROUGE scores vs. directly classifying best model: Provides continuous scores but adds prediction error
  - Training separate summarizers vs. single multi-task model: Better specialization but more complex system

- Failure signatures:
  - Meta-model consistently predicts same summarizer regardless of input variation
  - High variance in performance across different text types
  - Slow inference due to embedding computation or model selection overhead

- First 3 experiments:
  1. Test Doc2Vec embeddings on a held-out set to verify they capture meaningful document similarities
  2. Evaluate each individual summarizer's performance across different text types to understand their strengths/weaknesses
  3. Train meta-model with varying numbers of hidden neurons (e.g., 512, 1024, 2048) to find optimal capacity

## Open Questions the Paper Calls Out

- How would the meta-model perform with other languages besides Slovene, particularly languages with different morphological complexity?
- Would incorporating human evaluation of summary quality improve the meta-model's selection accuracy beyond ROUGE score predictions?
- How would the meta-model perform with more diverse summarization approaches, such as newer large language models or domain-specific models?

## Limitations

- Performance depends heavily on Doc2Vec embeddings capturing sufficient document characteristics for accurate model selection
- System was trained and evaluated only on Slovene texts, raising questions about generalizability to other languages
- Meta-model selection adds computational overhead that must be justified by performance improvements

## Confidence

- High confidence: The basic architecture of using document embeddings to predict model performance is sound
- Medium confidence: The claim that combining diverse summarizers through meta-model selection improves overall performance is supported but needs more context
- Low confidence: The assumption that this approach generalizes well beyond the tested Slovene corpus remains unverified

## Next Checks

1. Conduct ablation studies removing the meta-model to measure performance degradation when using only the T5-based model alone
2. Test the system on an out-of-distribution Slovene corpus with different genres or text characteristics not represented in the training data
3. Compare Doc2Vec embeddings with transformer-based alternatives (like Sentence-BERT) to verify that the simpler embedding approach captures sufficient information for accurate model selection