---
ver: rpa2
title: 'Explainable Authorship Identification in Cultural Heritage Applications: Analysis
  of a New Perspective'
arxiv_id: '2311.02237'
source_url: https://arxiv.org/abs/2311.02237
tags:
- authorship
- features
- feature
- which
- author
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the applicability of existing general-purpose
  eXplainable Artificial Intelligence (XAI) techniques to Authorship Identification
  (AId) tasks, focusing on explanations for scholars working in cultural heritage.
  The authors assess three types of XAI techniques - feature ranking, probing, and
  factuals and counterfactuals selection - on three AId tasks (authorship attribution,
  authorship verification, same-authorship verification) using real AId data.
---

# Explainable Authorship Identification in Cultural Heritage Applications: Analysis of a New Perspective

## Quick Facts
- arXiv ID: 2311.02237
- Source URL: https://arxiv.org/abs/2311.02237
- Reference count: 40
- This paper explores applying XAI techniques to authorship identification tasks in cultural heritage contexts, finding that while these methods provide useful insights, more work is needed to develop tools fully integrated into scholars' workflows.

## Executive Summary
This paper investigates the application of general-purpose eXplainable Artificial Intelligence (XAI) techniques to Authorship Identification (AId) tasks, specifically focusing on cultural heritage applications. The authors evaluate three types of XAI methods‚Äîfeature ranking, probing, and factual/counterfactual selection‚Äîacross three AId tasks using real Medieval Latin datasets. While the study demonstrates the feasibility of applying these XAI techniques to AId problems, it concludes that existing methods provide only limited insight and are largely insufficient for the specific needs of cultural heritage scholars working with authorship analysis.

## Method Summary
The study employs two machine learning models for authorship identification: a linear SVM classifier using TfIdf-weighted character n-grams, and a fine-tuned RoBERTa transformer model. Three XAI techniques are then applied to these models: feature ranking (using SVM coefficients to identify important n-grams), probing (training simple classifiers on model latent representations to detect specific linguistic features), and factual/counterfactual selection (retrieving similar training examples with same/different labels). The evaluation uses Medieval Latin datasets (MedLatinEpi and MedLatinLit) with five authors including Dante Alighieri and Giovanni Boccaccio, examining authorship attribution, authorship verification, and same-authorship verification tasks.

## Key Results
- Feature ranking reveals the most discriminative n-grams but provides limited insight into complex feature interactions
- Probing demonstrates whether transformer models have learned specific linguistic features like POS chains and function words
- Factual and counterfactual selection helps identify similar examples but requires careful interpretation to be useful for scholars
- Current general-purpose XAI methods are largely insufficient for authorship analysis in cultural heritage contexts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Feature ranking reveals the most discriminative n-grams for authorship tasks
- Mechanism: Linear SVM coefficients directly indicate feature importance; high absolute values correspond to strong predictive power
- Core assumption: Feature weights are interpretable and correspond to linguistic significance
- Evidence anchors:
  - [abstract] "we assess the relative merits of three different types of XAI techniques (feature ranking, probing, factuals and counterfactual selection)"
  - [section] "the higher the absolute value of the weight ùë§ ùëñ associated to the ùëñ-th feature, the larger is the contribution of such feature towards the prediction"
- Break condition: If feature weights are not monotonic with importance or if feature interactions dominate predictions

### Mechanism 2
- Claim: Probing reveals whether a transformer model has learned specific linguistic features
- Mechanism: A simple probe trained on the model's latent representation can detect if specific features (like POS chains or function words) are encoded
- Core assumption: If a simple probe can predict feature presence from latent representations, the model has learned that feature
- Evidence anchors:
  - [abstract] "we assess the relative merits of three different types of XAI techniques (feature ranking, probing, factuals and counterfactual selection)"
  - [section] "the underlying assumption is that, if the presence of a feature can be found even with a simple probe, then that feature is encoded by the main model in the latent representation"
- Break condition: If probe accuracy is not significantly above baseline or if probe complexity affects results

### Mechanism 3
- Claim: Factuals and counterfactuals selection helps scholars understand model decision boundaries
- Mechanism: By retrieving similar training examples with same/different labels, users can see what the model considers similar or different
- Core assumption: Distance in latent space corresponds to meaningful similarity for the task
- Evidence anchors:
  - [abstract] "factuals and counterfactuals selection" are one of the three XAI techniques assessed
  - [section] "retrieve the training instances that are most similar to x according to the model"
- Break condition: If retrieved examples don't provide meaningful insight or if distance metrics don't capture task-relevant similarity

## Foundational Learning

- Concept: Linear classifiers and feature weights
  - Why needed here: Understanding how SVM coefficients indicate feature importance is crucial for interpreting feature ranking results
  - Quick check question: If a feature has coefficient +2.0 in a linear SVM, what does this mean for its contribution to positive class predictions?

- Concept: Transformer latent representations and probing
  - Why needed here: Understanding how to probe a model's latent space to detect learned features is essential for the probing methodology
  - Quick check question: What does it mean if a probe achieves high accuracy at predicting POS chain presence from RoBERTa's latent representations?

- Concept: Similarity metrics in high-dimensional spaces
  - Why needed here: Understanding how to compute and interpret similarity between examples is crucial for factual/counterfactual selection
  - Quick check question: Why might Euclidean distance in latent space be appropriate for finding similar examples?

## Architecture Onboarding

- Component map:
  Data preprocessing ‚Üí Feature extraction (TfIdf for SVM, raw text for RoBERTa) ‚Üí Model training (SVM and RoBERTa) ‚Üí XAI technique application (feature ranking, probing, factual/counterfactual selection) ‚Üí Result visualization and interpretation

- Critical path: Data preprocessing ‚Üí Model training ‚Üí XAI application ‚Üí Interpretation
- Design tradeoffs:
  - SVM offers interpretable feature weights but may miss complex patterns
  - RoBERTa captures complex patterns but requires probing for interpretability
  - Feature ranking is computationally cheap but may oversimplify
  - Probing is more informative but computationally expensive

- Failure signatures:
  - SVM feature ranking shows contradictory importance values across examples
  - Probe accuracy not significantly above random baseline
  - Retrieved factual/counterfactual examples don't provide meaningful insight

- First 3 experiments:
  1. Run SVM on small dataset and verify feature weights correspond to known important n-grams
  2. Train simple probe on RoBERTa latent representations and verify it can predict known feature presence
  3. Retrieve factual/counterfactual for a test example and verify they provide meaningful context for the prediction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can we develop more effective XAI techniques specifically tailored for authorship analysis in cultural heritage contexts?
- Basis in paper: [explicit] The authors state that current general-purpose XAI methods are "largely insufficient" for authorship analysis, providing either "limited perspective" or relying too heavily on user input.
- Why unresolved: Existing XAI methods don't adequately address the unique challenges of authorship analysis, including high dimensionality, minor significance of features, and complex feature interactions.
- What evidence would resolve it: Development and testing of new XAI methods specifically designed for authorship analysis that provide more comprehensive and user-friendly explanations.

### Open Question 2
- Question: How can we effectively combine multiple XAI methods to provide more comprehensive explanations for authorship analysis?
- Basis in paper: [explicit] The authors suggest that "employing a combination of these methods" might mitigate the limitations of individual methods, but wouldn't fully resolve the issue.
- Why unresolved: While combining methods may provide more comprehensive explanations, it's unclear how to effectively integrate and present the information from different methods in a way that's useful for cultural heritage scholars.
- What evidence would resolve it: Research on effective ways to combine and present information from multiple XAI methods for authorship analysis, including user studies with cultural heritage scholars.

### Open Question 3
- Question: Can we develop XAI methods that generate concise, natural language explanations for authorship analysis predictions?
- Basis in paper: [inferred] The authors mention that "concise and informative textual explanations" would be a promising direction for future research, as this format is most familiar to cultural heritage scholars.
- Why unresolved: Current XAI methods focus on visual or statistical explanations, which may be difficult for non-experts to interpret. Generating natural language explanations for complex authorship analysis predictions is a challenging task.
- What evidence would resolve it: Development and evaluation of XAI methods that can generate concise, natural language explanations for authorship analysis predictions, including user studies to assess their effectiveness and usability for cultural heritage scholars.

## Limitations
- The evaluation is limited to Medieval Latin texts, which may not generalize to other authorship attribution problems
- Assessment of XAI technique effectiveness relies on qualitative rather than quantitative metrics of explanation quality
- No user studies with cultural heritage scholars to validate the practical utility of the explanations

## Confidence
- **High confidence**: The technical feasibility of applying feature ranking, probing, and factual/counterfactual selection to AId tasks is well-established and demonstrated
- **Medium confidence**: The qualitative assessment that these techniques provide useful insights for cultural heritage scholars, as this relies on subjective interpretation
- **Low confidence**: The claim that these XAI techniques can be "profitably integrated into scholars' workflows" given the limited evaluation scope and lack of user studies

## Next Checks
1. Conduct a user study with cultural heritage scholars to evaluate the practical utility and interpretability of the XAI explanations in real-world research scenarios
2. Apply the same XAI techniques to a diverse set of authorship attribution datasets (different languages, time periods, genres) to assess generalizability
3. Develop quantitative metrics for evaluating explanation quality (e.g., fidelity, stability, sparsity) and compare the three XAI approaches using these metrics