---
ver: rpa2
title: Towards Ordinal Data Science
arxiv_id: '2307.09477'
source_url: https://arxiv.org/abs/2307.09477
tags:
- data
- ordinal
- order
- ordered
- science
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Ordinal Data Science as a new research agenda
  focused on methods for analyzing and extracting knowledge from ordinal data. The
  authors discuss the need for this field, given the prevalence of ordinal data in
  real-world datasets and the limited availability of methods tailored for such data
  compared to numerical data.
---

# Towards Ordinal Data Science

## Quick Facts
- arXiv ID: 2307.09477
- Source URL: https://arxiv.org/abs/2307.09477
- Reference count: 40
- One-line primary result: Proposes Ordinal Data Science as a new research agenda focused on methods for analyzing and extracting knowledge from ordinal data.

## Executive Summary
This paper introduces Ordinal Data Science as a new research field dedicated to developing methods for analyzing ordinal data, which is prevalent in real-world datasets but lacks specialized analytical tools. The authors argue that ordinal data requires fundamentally different approaches than numerical data, as it captures relational structures rather than quantitative measurements. They provide a comprehensive theoretical foundation based on order theory and lattice theory, identifying key research directions including ordinal measurement theory, ordered metric spaces, algebraic constructions, ordinal factor analysis, and visualization techniques.

## Method Summary
The paper proposes a framework for Ordinal Data Science that leverages mathematical structures from order theory and lattice theory to analyze ordinal data. The core approach involves representing ordinal relationships as ordered sets, embedding them into complete lattices via Dedekind-MacNeille completion, and applying various analytical techniques including measurement theory, ordered metric spaces, algebraic decompositions, and visualization methods. The methodology emphasizes the need to preserve relational structure while enabling algebraic operations that reveal hierarchical patterns and dependencies in ordinal data.

## Key Results
- Establishes theoretical foundations for Ordinal Data Science as a new research agenda
- Identifies key subfields including measurement theory, ordered metric spaces, and algebraic constructions
- Highlights the prevalence of ordinal data in real-world applications and the need for specialized methods
- Proposes integration with existing machine learning and knowledge representation techniques

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Ordinal Data Science leverages the structural properties of ordered sets and lattices to provide richer representations than purely numerical methods.
- Mechanism: By replacing real numbers with ordered sets or lattices, the framework preserves the relational structure of ordinal data while enabling algebraic operations like join, meet, and factorization that reveal hierarchical patterns.
- Core assumption: Ordered sets can be embedded into complete lattices (Dedekind-MacNeille completion) without loss of essential relational information.
- Evidence anchors:
  - [abstract] "Our aim is to establish Ordinal Data Science as a fundamentally new research agenda."
  - [section 4.3] "Every ordered set is embeddable into a complete lattice, its Dedekind-MacNeille completion."
  - [corpus] Weak - no direct citations found in the 8 neighboring papers.
- Break condition: If the order dimension is too high, making embeddings computationally intractable, or if real-world data lacks sufficient hierarchical structure to justify lattice-based methods.

### Mechanism 2
- Claim: Ordered metric spaces (om-spaces) allow simultaneous exploitation of ordinal and numerical relationships in heterogeneous data.
- Mechanism: By defining a triple (P, R, d) where P is a set, R an order relation, and d a metric, om-spaces enable measuring the compatibility between order and distance, providing new quality criteria for machine learning tasks.
- Core assumption: Real-world datasets often contain both ordinal and numerical dimensions that should be analyzed jointly rather than separately.
- Evidence anchors:
  - [section 6] "We therefore propose to develop theoretical and practical methods that honor the compatibility (or consistency) of order relations and metrics on a set."
  - [abstract] "Besides cross-fertilization with other cornerstone machine learning and knowledge representation methods..."
  - [corpus] Weak - neighboring papers don't directly address om-spaces, but one mentions "Ordinal classification for interval-valued data."
- Break condition: If the order and metric are fundamentally incompatible, making the om-space representation misleading or computationally prohibitive.

### Mechanism 3
- Claim: Algebraic constructions and decompositions from universal algebra can reduce the complexity of ordered sets and lattices while preserving essential structure.
- Mechanism: By applying congruences, tolerances, and factorization methods, large lattices can be broken into smaller, more manageable components that maintain the hierarchical relationships.
- Core assumption: Real-world lattices often contain large distributive or otherwise structured substructures that can be exploited for decomposition.
- Evidence anchors:
  - [section 7] "In universal algebra [21, 84, 31] it is a well-known fact that every homomorphic image and every subalgebra of a lattice or of a finite complete lattice... is a lattice again."
  - [section 7.1] "Many of these constructions have never been used for larger data analysis tasks."
  - [corpus] Missing - no neighboring papers directly address algebraic decompositions of lattices.
- Break condition: If the required structural conditions for decomposition are not met in real-world data, or if approximations destroy essential information.

## Foundational Learning

- Concept: Ordered sets (partially ordered sets)
  - Why needed here: They form the basic mathematical structure for representing ordinal data and relationships.
  - Quick check question: Can you identify the reflexive, transitive, and antisymmetric properties in a given relation?

- Concept: Lattices and complete lattices
  - Why needed here: Lattices provide algebraic operations (join, meet) that enable more sophisticated analysis of ordinal data than simple ordering.
  - Quick check question: Given two elements in a lattice, can you identify their least upper bound and greatest lower bound?

- Concept: Dedekind-MacNeille completion
  - Why needed here: This allows embedding any ordered set into a complete lattice, enabling the use of richer lattice theory tools.
  - Quick check question: Why is the Dedekind-MacNeille completion always a complete lattice, even when the original ordered set is finite?

## Architecture Onboarding

- Component map:
  Data Ingestion → Ordinal Structure Extraction → Lattice Construction → Analysis Module → Visualization/Exploration
  Analysis Module branches into: Measurement Theory, Ordered Metric Spaces, Algebraic Decompositions, Factor Analysis, Visualization

- Critical path:
  1. Extract ordinal relations from raw data
  2. Compute Dedekind-MacNeille completion to form complete lattice
  3. Apply chosen analysis method (measurement theory, om-space, etc.)
  4. Generate interpretable results through visualization

- Design tradeoffs:
  - Completeness vs. tractability: Complete lattices are theoretically ideal but may be computationally expensive
  - Abstraction vs. interpretability: More sophisticated mathematical structures may be harder for domain experts to understand
  - Generality vs. specialization: Methods that work for all ordinal data may be less powerful than those tailored to specific domains

- Failure signatures:
  - Exponential growth in lattice size indicating computational intractability
  - Low compatibility between order and metric in om-space analysis
  - Decomposition methods failing to find meaningful substructures
  - Visualization becoming unreadable despite algorithmic optimization

- First 3 experiments:
  1. Test Dedekind-MacNeille completion on a small hierarchical dataset and verify that all original relations are preserved
  2. Implement a simple ordered metric space for a dataset with both ordinal rankings and numerical distances, and measure their compatibility
  3. Apply congruence-based clustering to a moderate-sized lattice and evaluate the interpretability of resulting clusters

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the exact conditions under which measurements into non-linear ordinal scales exist, and how unique are they under permissible transformations?
- Basis in paper: [explicit] Section 5.2.1 discusses extending representational measurement theory to non-numerical scales and mentions the representation and uniqueness problems.
- Why unresolved: The paper identifies this as a key research question but does not provide specific theorems or conditions.
- What evidence would resolve it: Mathematical proofs establishing necessary and sufficient conditions for measurements into various types of non-linear ordinal scales, along with analysis of permissible transformations and their impact on uniqueness.

### Open Question 2
- Question: How can algebraic constructions like factorizations and decompositions be made more robust to handle real-world data with noise and imperfections?
- Basis in paper: [explicit] Section 7.1 states that algebraic operations are sensitive to small perturbations and discusses the need for approximations and heuristics.
- Why unresolved: The paper acknowledges this challenge but doesn't propose specific methods for making these constructions more fault-tolerant.
- What evidence would resolve it: Development and validation of new algorithms that can handle imperfect data in algebraic operations, along with measures of structural impurity and their impact on results.

### Open Question 3
- Question: What are the most effective ways to visualize and interactively explore large ordinal datasets, especially when using approximated algebraic decompositions?
- Basis in paper: [explicit] Section 9.2.2 discusses the need for new visualization and interaction paradigms for approximated algebraic constructions.
- Why unresolved: The paper recognizes the challenge but doesn't propose specific solutions for visualizing approximations or their effects.
- What evidence would resolve it: Development of new visualization techniques and interaction paradigms that effectively communicate the structure of ordinal data and the impact of approximations, validated through user studies.

## Limitations
- Theoretical framework lacks extensive empirical validation on real-world datasets
- Computational feasibility of lattice-based approaches for large-scale applications remains uncertain
- Compatibility between order relations and metrics in ordered metric spaces needs further development
- Sensitivity of algebraic constructions to noise and imperfections requires robust solutions

## Confidence

- High confidence: The mathematical foundations (order theory, lattice theory) are well-established and correctly presented.
- Medium confidence: The conceptual framework for Ordinal Data Science as a new research field is sound, but practical implementations are still largely undeveloped.
- Low confidence: Claims about the computational tractability of proposed methods for real-world applications, as these have not been demonstrated empirically.

## Next Checks

1. Implement Dedekind-MacNeille completion on a medium-sized real-world dataset with hierarchical structure and measure the growth rate in lattice size compared to the original ordered set.

2. Develop a prototype ordered metric space analysis pipeline for a dataset containing both ordinal rankings and numerical distances, and empirically evaluate the compatibility metric across different data types.

3. Apply algebraic decomposition methods to a real-world lattice-based dataset and assess whether the resulting components reveal meaningful, interpretable substructures that could inform domain-specific knowledge discovery.