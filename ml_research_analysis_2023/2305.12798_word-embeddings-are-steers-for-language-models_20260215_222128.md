---
ver: rpa2
title: Word Embeddings Are Steers for Language Models
arxiv_id: '2305.12798'
source_url: https://arxiv.org/abs/2305.12798
tags:
- language
- lm-switch
- russia
- generation
- have
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes LM-Switch, a lightweight approach for controlled
  language model generation by applying linear transformations in the word embedding
  space. Inspired by the connection between Hidden Markov Models and language models,
  the method learns a small matrix to adjust embeddings during generation, enabling
  fine-grained control over attributes like sentiment and toxicity.
---

# Word Embeddings Are Steers for Language Models

## Quick Facts
- arXiv ID: 2305.12798
- Source URL: https://arxiv.org/abs/2305.12798
- Reference count: 40
- Primary result: Lightweight approach for controlled language model generation using linear transformations in word embedding space

## Executive Summary
This paper introduces LM-Switch, a lightweight method for controlled language model generation by applying linear transformations in word embedding space. The approach draws theoretical connections between Hidden Markov Models and language models, demonstrating that condition shifts can be achieved through linear transformations of word embeddings. LM-Switch learns a small transformation matrix that enables fine-grained control over attributes like sentiment and toxicity while using less than 1% of the parameters of traditional methods. The method maintains fluency and diversity of generated text and supports both continuous and compositional control, with the added benefit of transferability across different model sizes.

## Method Summary
LM-Switch applies a learnable linear transformation matrix (W) to word embeddings during language model generation, controlled by a scaling factor (epsilon). The method trains this matrix using maximum likelihood on labeled datasets, transforming embeddings via (I + epsilon*W) to steer generation toward desired attributes. The approach is theoretically grounded in connections between HMM condition shifts and linear transformations in embedding space, and practically implemented as a plug-in to existing language models like GPT-2.

## Key Results
- Achieves comparable or superior performance to state-of-the-art baselines for sentiment and toxicity control
- Uses less than 1% of the parameters compared to traditional control methods
- Maintains fluency (measured by perplexity) and diversity (Dist-1/2/3) of generated text
- Enables continuous and compositional control through linearity guarantees
- Supports transferability of learned transformations across different model sizes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear transformations in word embedding space can steer language model generation styles
- Mechanism: Condition shifts in Hidden Markov Models are associated with linear transformations in word embeddings. By inserting a learnable linear factor (epsilon*W) into the word embedding space, LM-Switch controls the model's output generation according to different conditions like sentiment or toxicity.
- Core assumption: The relationship between conditions and word embeddings is linear and can be captured by a small matrix.
- Evidence anchors:
  - [abstract] "we theoretically and empirically revisit output word embeddings and find that their linear transformations are equivalent to steering language model generation styles"
  - [section 3.2] "shifting from one initial condition to another is equivalent to a linear transformation in word embedding space"
  - [corpus] Weak evidence; the corpus papers focus on related but distinct topics like subword models and spoken language models, not directly on linear transformations for style control.

### Mechanism 2
- Claim: LM-Switch maintains linearity guarantees enabling continuous and compositional control
- Mechanism: The paper proves that the switched model's distribution is close to a linear interpolation from the original model to the switched model. This allows for fine-grained adjustment of the switch value and combination of multiple LM-Switches for compositional control.
- Core assumption: The language model's output distribution changes smoothly with the switch value.
- Evidence anchors:
  - [section 3.4] "LM-Switch maintains a linearity guarantee, regardless of the model architecture applied to"
  - [theorem 2 and 3 in section 3.4] "When varying epsilon's value, The switched model's distribution is close to a linear interpolation" and "their switching effects on distributions are approximately linearly combined"
  - [corpus] Weak evidence; the corpus papers do not directly address linearity guarantees in language model control.

### Mechanism 3
- Claim: LM-Switch is transferable between different language models
- Mechanism: By identifying a linear mapping from the target LM's word embeddings to the source LM's word embeddings, the switch matrix can be transferred and applied to the target model.
- Core assumption: There exists a linear mapping between the word embedding spaces of different language models.
- Evidence anchors:
  - [abstract] "The learned LM-Steer serves as a lens in text styles: it reveals that word embeddings are interpretable when associated with language model generations"
  - [section 5.2] "A much desired property of LM-Switch, because of its theoretical soundness, is its transferability to other language models"
  - [corpus] Weak evidence; the corpus papers do not directly address transferability of control mechanisms between language models.

## Foundational Learning

- Concept: Hidden Markov Models (HMMs)
  - Why needed here: The paper uses HMMs as a theoretical foundation to establish the relationship between conditions and word embeddings.
  - Quick check question: Can you explain how the emission probabilities in an HMM relate to the word embeddings in a language model?

- Concept: Linear algebra and matrix transformations
  - Why needed here: The paper relies on linear transformations of word embeddings to control the language model's output. Understanding matrix operations is crucial for implementing and modifying LM-Switch.
  - Quick check question: How would you compute the effect of applying a linear transformation to a word embedding vector?

- Concept: Language model architectures and decoding
  - Why needed here: LM-Switch is a plug-in that modifies the word embeddings during language model generation. Familiarity with LM architectures and decoding processes is necessary to integrate and use LM-Switch effectively.
  - Quick check question: What is the role of word embeddings in the language model's decoding process?

## Architecture Onboarding

- Component map: LM-Switch consists of a learnable linear transformation matrix (W) that is applied to the word embeddings during language model generation. The switch value (epsilon) controls the intensity and polarity of the transformation.
- Critical path: The critical path involves learning the switch matrix W using a dataset of labeled texts, and then applying the learned transformation during language model generation by scaling the word embeddings with (I + epsilon*W).
- Design tradeoffs: The main tradeoff is between the complexity of the transformation matrix W and the control granularity. A larger matrix may provide finer control but also increases the number of parameters to learn. The paper aims for a lightweight solution by keeping W small.
- Failure signatures: If the learned switch matrix does not effectively control the language model's output, or if the transformed word embeddings lead to poor generation quality, it may indicate a failure in the LM-Switch mechanism.
- First 3 experiments:
  1. Train LM-Switch on a sentiment analysis dataset and evaluate its ability to control the sentiment of generated text.
  2. Transfer the learned switch matrix from one language model to another and assess the transferability of the control mechanism.
  3. Experiment with different switch values (epsilon) to find the optimal balance between control and generation quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the theoretical limits of LM-Switch's applicability across different language model architectures and conditioning tasks?
- Basis in paper: [explicit] The paper states LM-Switch is "architecture-agnostic" but acknowledges limitations with complex tasks like "syntactic trees or persuasive techniques that involve logical reasoning"
- Why unresolved: While the paper demonstrates effectiveness on sentiment, toxicity, and political stance control, it doesn't systematically explore the boundaries of what conditioning types LM-Switch can handle
- What evidence would resolve it: A comprehensive evaluation of LM-Switch across diverse conditioning types (e.g., syntactic structure, reasoning-based prompts, abstract concepts) compared to other conditioning methods would establish its theoretical boundaries

### Open Question 2
- Question: How does the choice of switch value (epsilon) interact with different language model sizes and training dataset characteristics?
- Basis in paper: [explicit] The paper uses a fixed switch value (5*epsilon_0) and mentions an ablation study, but doesn't systematically explore how epsilon should scale with model size or dataset properties
- Why unresolved: The paper notes that "using large epsilon" in transferred models causes "increased instability," suggesting the relationship between epsilon and model characteristics is non-trivial
- What evidence would resolve it: A parameter sensitivity analysis varying epsilon across different model sizes (e.g., GPT-2, GPT-2-XL, GPT-J-6B) and dataset sizes would reveal optimal scaling relationships

### Open Question 3
- Question: What is the relationship between LM-Switch's learned transformation matrices and interpretable linguistic or semantic dimensions?
- Basis in paper: [explicit] The paper analyzes interpretability by examining SVD components and finding "indicative words" associated with toxicity
- Why unresolved: The analysis only scratches the surface of interpretability - it shows which words are affected but not why or how these relate to broader linguistic concepts
- What evidence would resolve it: A systematic study correlating learned switch matrices with established linguistic frameworks (e.g., sentiment lexicons, semantic taxonomies, syntactic categories) would reveal interpretable patterns

### Open Question 4
- Question: How does LM-Switch compare to prompting-based methods when controlling for model size and training data availability?
- Basis in paper: [inferred] The paper contrasts LM-Switch with prompting methods but doesn't directly compare their performance under controlled conditions
- Why unresolved: The paper notes that prompting methods "often rely on the quality and availability of large language models" but doesn't empirically test when each approach is preferable
- What evidence would resolve it: Controlled experiments comparing LM-Switch and prompting methods across different model sizes and training data regimes would reveal their relative strengths and weaknesses

## Limitations
- Theoretical scope has primarily been validated in controlled settings and may not generalize to complex real-world language generation scenarios
- Computational overhead during inference may become significant for large-scale deployments or real-time applications
- Effectiveness heavily depends on the quality and representativeness of the labeled training data

## Confidence
- High Confidence: Linear transformations in word embedding space can effectively steer language model generation styles; LM-Switch achieves comparable or superior performance to state-of-the-art baselines; maintains fluency and diversity while enabling attribute control
- Medium Confidence: Enables continuous and compositional control through linearity guarantees; learned switch matrices can be effectively transferred across different model sizes
- Low Confidence: Relationship between conditions and word embeddings is universally linear across all language model architectures; can effectively control complex, multi-dimensional attributes beyond simple binary classifications

## Next Checks
1. **Cross-Domain Generalization Test**: Evaluate LM-Switch's performance on controlled generation tasks across diverse domains (e.g., technical writing, creative fiction, academic prose) to assess its generalizability beyond the tested sentiment and toxicity attributes.

2. **Stress Test for Linearity**: Systematically probe the linearity assumptions by attempting to control multiple, potentially conflicting attributes simultaneously (e.g., positive sentiment with technical language style) and measure deviations from expected linear interpolation.

3. **Resource Efficiency Benchmark**: Conduct a comprehensive analysis of LM-Switch's computational overhead during inference across different hardware configurations and model sizes, comparing it against the claimed <1% parameter efficiency in practical deployment scenarios.