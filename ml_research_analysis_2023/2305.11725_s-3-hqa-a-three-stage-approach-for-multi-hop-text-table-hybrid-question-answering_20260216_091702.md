---
ver: rpa2
title: 'S$^3$HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question
  Answering'
arxiv_id: '2305.11725'
source_url: https://arxiv.org/abs/2305.11725
tags:
- table
- question
- hybrid
- retriever
- multi-hop
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the problem of answering multi-hop questions
  over hybrid factual knowledge from text and table sources (TextTableQA). The proposed
  S3HQA framework consists of three stages: a retriever with refinement training to
  alleviate noisy labeling, a hybrid selector that considers linked relationships
  between heterogeneous data to select relevant knowledge, and a generation-based
  reasoner with row-wise and LLM prompting generators.'
---

# S$^3$HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid Question Answering

## Quick Facts
- arXiv ID: 2305.11725
- Source URL: https://arxiv.org/abs/2305.11725
- Reference count: 12
- Key outcome: S³HQA achieves state-of-the-art performance on the HybridQA leaderboard, outperforming all baseline methods when trained on the full dataset.

## Executive Summary
This paper addresses the challenge of multi-hop question answering over hybrid factual knowledge from text and table sources (TextTableQA). The proposed S³HQA framework introduces a three-stage approach consisting of a retriever with refinement training, a hybrid selector that leverages linked relationships between heterogeneous data, and a generation-based reasoner with special tags for different reasoning operations. The model demonstrates superior performance on the HybridQA benchmark, particularly in handling comparison and counting questions that require operations beyond span extraction.

## Method Summary
S³HQA employs a three-stage architecture: (1) a retriever with two-step refinement training to reduce noise from weakly supervised labels, (2) a hybrid selector that combines table and passage evidence using hyperlink relationships, and (3) a generation-based reasoner with row-wise and LLM prompting generators that handle different question types through special tags like ⟨Count⟩ and ⟨Compare⟩. The framework addresses key challenges in TextTableQA including noisy labeling, heterogeneous data integration, and complex reasoning operations.

## Key Results
- Achieves state-of-the-art performance on the HybridQA leaderboard when trained on full dataset
- Outperforms all baseline methods in multi-hop TextTableQA task
- Shows competitive results in few-shot settings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The two-step refinement training alleviates noisy labeling in the retriever.
- Mechanism: The model first trains on data with unambiguous single-answer labels (D1), then uses that trained model to provide pseudo-labels for the multi-answer data (D2), reducing noise propagation.
- Core assumption: Single-answer instances in D1 are truly unambiguous and can bootstrap the model to handle noisier cases in D2.
- Evidence anchors:
  - [abstract]: "We use a retriever with refinement training to solve the noisy labeling problem."
  - [section 2.3]: "We use a two-step training method, splitting the training data into two parts, so that the noise in the retrieval phase can be alleviated."
- Break condition: If D1 contains any ambiguous instances, the bootstrapping fails and noise persists.

### Mechanism 2
- Claim: Hybrid selector effectively uses table-passage hyperlink relationships for multi-hop reasoning.
- Mechanism: Selector chooses evidence based on question type—single row + linked passage for bridge questions, multiple rows with passage filtering for comparison/count questions—leveraging hyperlink structure.
- Core assumption: Hyperlinks reliably connect relevant passages to the correct rows, enabling multi-hop reasoning.
- Evidence anchors:
  - [abstract]: "a hybrid selector considers the linked relationships between heterogeneous data to select the most relevant factual knowledge."
  - [section 2.3]: "By considering the hybrid data of tables and text, this paper proposes a hybrid selection algorithm that can effectively utilize the heterogeneous information of tables and passages."
- Break condition: If hyperlinks are missing or incorrect, the selector cannot find correct evidence paths.

### Mechanism 3
- Claim: Generation-based reasoner with special tags handles different reasoning operations (comparison, counting).
- Mechanism: Row-wise generator uses ⟨Count⟩ and ⟨Compare⟩ tags derived from question type to guide answer generation, allowing operations beyond span extraction.
- Core assumption: Lexical analysis can reliably identify question types requiring different reasoning operations.
- Evidence anchors:
  - [section 2.4.1]: "We utilize two special tags⟨Count⟩ and ⟨Compare⟩, which indicates the question types."
  - [section 1]: "Previous methods... mainly used an extraction module to obtain answers, which cannot support knowledge reasoning that requires comparison, calculation, and other operations."
- Break condition: If question type classification fails, the generator cannot apply correct reasoning.

## Foundational Learning

- Concept: Weakly supervised learning with noisy labels
  - Why needed here: The dataset uses string matching for pseudo-labels, introducing noise that must be handled.
  - Quick check question: Can the model distinguish between truly relevant and string-matching-only evidence?
- Concept: Multi-hop reasoning with heterogeneous data
  - Why needed here: Questions require combining table cells and linked passages through hyperlinks.
  - Quick check question: Does the model correctly follow hyperlink chains to retrieve all necessary evidence?
- Concept: Generation-based QA vs extractive QA
  - Why needed here: Comparison and counting questions cannot be answered by span extraction alone.
  - Quick check question: Can the model generate answers requiring arithmetic or comparative reasoning?

## Architecture Onboarding

- Component map: Retriever (two-step refinement) → Selector (hybrid, question-type aware) → Reasoner (generation-based with tags)
- Critical path: Retriever must produce high-recall candidates → Selector must pick correct evidence subset → Reasoner must generate correct answer
- Design tradeoffs: Two-step training adds complexity but reduces noise; generation-based approach handles more operations but requires more training data
- Failure signatures: Low recall in retriever → poor evidence selection; incorrect question type classification → wrong reasoning operation
- First 3 experiments:
  1. Evaluate retriever top-1 recall with/without refinement training
  2. Test hybrid selector vs pure row-based selector on bridge vs comparison questions
  3. Compare generation-based reasoner vs extractive reader on counting questions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the refinement training in the retriever stage alleviate the noise in the weakly supervised data?
- Basis in paper: [explicit] "We use a two-step training method, splitting the training data into two parts, so that the noise in the retrieval phase can be alleviated."
- Why unresolved: The paper mentions the two-step training method but does not provide detailed information on how the refinement training specifically addresses the noise issue in the weakly supervised data.
- What evidence would resolve it: A detailed explanation of the refinement training process and its impact on reducing noise in the weakly supervised data.

### Open Question 2
- Question: How does the hybrid selector effectively utilize the heterogeneous information of tables and passages to select the most relevant factual knowledge?
- Basis in paper: [explicit] "The hybrid selector considers the linked relationships between heterogeneous data to select the most relevant factual knowledge."
- Why unresolved: The paper states that the hybrid selector considers the linked relationships between heterogeneous data but does not provide specific details on how it effectively utilizes this information to select the most relevant factual knowledge.
- What evidence would resolve it: A detailed description of the hybrid selector's algorithm and how it leverages the linked relationships between heterogeneous data to select the most relevant factual knowledge.

### Open Question 3
- Question: How does the generation-based reasoner handle different types of reasoning operations, such as comparison and calculation, in multi-hop questions?
- Basis in paper: [explicit] "The generation-based reasoner utilizes a generation-based model for addressing different question types."
- Why unresolved: The paper mentions that the generation-based reasoner handles different types of reasoning operations but does not provide specific details on how it addresses comparison and calculation questions in multi-hop scenarios.
- What evidence would resolve it: A detailed explanation of the generation-based reasoner's approach to handling different types of reasoning operations, particularly comparison and calculation questions in multi-hop scenarios.

## Limitations
- Weakly supervised training reliance may leave residual noise even after refinement training
- Hybrid selector's effectiveness depends on the quality and completeness of hyperlinks between tables and passages
- Question type classification accuracy directly impacts the generation-based reasoner's ability to apply correct reasoning operations

## Confidence
- High Confidence: The three-stage architecture design and its theoretical justification (High)
- Medium Confidence: The effectiveness of two-step refinement training for noise reduction (Medium)
- Medium Confidence: The hybrid selector's utilization of hyperlink relationships (Medium)
- Low Confidence: The generation-based reasoner's handling of complex reasoning operations (Low)

## Next Checks
1. Measure the top-k retrieval accuracy with and without refinement training to quantify how much noisy labeling is actually reduced by the two-step approach.
2. Evaluate model performance on subsets of HybridQA with varying hyperlink quality (complete vs. partial vs. missing hyperlinks) to assess dependency on this assumption.
3. Remove the question type classification step and use only one generator type to measure the performance impact, revealing how critical accurate type identification is for the reasoning component.