---
ver: rpa2
title: 'Tracr: Compiled Transformers as a Laboratory for Interpretability'
arxiv_id: '2301.05062'
source_url: https://arxiv.org/abs/2301.05062
tags:
- attention
- rasp
- compiled
- tokens
- tracr
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Tracr, a compiler that translates human-readable
  programs written in the RASP language into transformer model weights. Tracr provides
  a way to create transformer models with known structure, enabling controlled experiments
  and evaluation of interpretability methods.
---

# Tracr: Compiled Transformers as a Laboratory for Interpretability

## Quick Facts
- arXiv ID: 2301.05062
- Source URL: https://arxiv.org/abs/2301.05062
- Reference count: 37
- One-line primary result: Tracr compiles RASP programs into transformer models with known structure, enabling controlled experiments and evaluation of interpretability methods.

## Executive Summary
Tracr is a compiler that translates human-readable programs written in the RASP language into transformer model weights. This provides a way to create transformer models with known structure, enabling controlled experiments and evaluation of interpretability methods. The authors demonstrate compiling programs for computing token frequencies, sorting, and parenthesis checking. They also propose a gradient descent-based compression procedure to make compiled models more efficient and realistic, allowing the study of superposition in deeper models. Tracr models serve as a testbed for developing and evaluating interpretability tools, providing ground truth explanations for comparison.

## Method Summary
Tracr compiles RASP programs into transformer models through a six-step pipeline: translating RASP programs to computational graphs, annotating nodes with s-op values, mapping s-ops to craft components, allocating components to layers, constructing a craft model, and generating transformer weights. The system enables controlled experiments by creating models where the implemented algorithm is fully known. The authors also introduce a compression procedure that uses gradient descent to learn a projection matrix reducing residual stream dimensionality while maintaining task performance. This allows studying superposition phenomena in deeper architectures and creates more realistic models for interpretability research.

## Key Results
- Successfully compiled transformer models for token frequency counting, sorting, and parenthesis checking tasks from RASP programs
- Demonstrated compression of compiled models from 14 to 6 dimensions without hurting performance, enabling study of superposition
- Showed that Tracr models can serve as evaluation benchmarks for interpretability tools by providing verifiable ground truth algorithms

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Tracr enables controlled experiments by compiling RASP programs into transformer models with known structure.
- **Mechanism**: The compiler translates human-readable RASP code into actual transformer weights, creating models where the implemented algorithm is fully known. This known structure serves as ground truth for evaluating interpretability methods.
- **Core assumption**: The RASP-to-transformer compilation process faithfully preserves the intended algorithm's behavior.
- **Evidence anchors**:
  - [abstract] "Tracr provides a way to create transformer models with known structure, enabling controlled experiments and evaluation of interpretability methods."
  - [section 3.4] "Tracr translates RASP programs to transformer weights in six steps... translating RASP programs to transformer weights."
- **Break condition**: If the compilation process introduces approximations or errors that alter the algorithm's behavior, the ground truth assumption fails.

### Mechanism 2
- **Claim**: Compressed Tracr models can study superposition phenomena in deeper architectures.
- **Mechanism**: The compression procedure uses gradient descent to learn a projection matrix that reduces the residual stream dimensionality while maintaining task performance. This creates models where features are stored in fewer dimensions than they conceptually require.
- **Core assumption**: The compressed model maintains the same computational behavior as the original despite dimensionality reduction.
- **Evidence anchors**:
  - [section 5.2] "By learning an embedding matrix W, we can reduce the residual dimension from D=14 to d=6 without hurting performance."
  - [section 5.3] "the average cosine similarity between the output at each layer of the two models" is used to verify computational consistency.
- **Break condition**: If the compressed model solves tasks using fundamentally different computations than the original, the superposition study loses its validity.

### Mechanism 3
- **Claim**: Tracr models can serve as evaluation benchmarks for interpretability tools by providing verifiable ground truth.
- **Mechanism**: Since Tracr creates models with known algorithms, interpretability methods can be tested by comparing their explanations to the actual implementation. This allows for systematic validation that would be impossible with learned models.
- **Core assumption**: The interpretability tools can meaningfully extract the known algorithm structure from the compiled models.
- **Evidence anchors**:
  - [section 6.1] "Compiled models serve as a natural foundation for testing the faithfulness of an explanation, and provide a way to falsify the explanations given by interpretability techniques."
  - [section 6] "Tracr allows researchers to set up controlled experiments that test specific hypotheses about the computational structure of transformers."
- **Break condition**: If interpretability tools fail to recover known structures in Tracr models, they cannot be trusted on more complex learned models.

## Foundational Learning

- **RASP programming language**
  - Why needed here: Understanding RASP is essential because Tracr compiles RASP programs to transformer weights. Without knowing how RASP represents computations, one cannot understand what Tracr produces.
  - Quick check question: What are the two basic node types in RASP programs and how do they map to transformer components?

- **Transformer architecture basics**
  - Why needed here: Tracr specifically targets transformer models with alternating attention and MLP layers. Understanding this architecture is crucial for interpreting how compiled programs execute.
  - Quick check question: How do multi-headed attention and MLP layers in transformers correspond to RASP's select-aggregate and elementwise operations?

- **Residual stream concept**
  - Why needed here: Tracr's approach relies heavily on the residual stream view of transformers, where information flows through a continuous memory space. This is central to understanding how compiled models work.
  - Quick check question: Why does Tracr embed each s-op in its own orthogonal subspace of the residual stream, and what are the efficiency implications?

## Architecture Onboarding

- **Component map**:
  RASP program -> computational graph -> s-op value annotations -> craft components -> layer allocation -> craft model -> transformer weights

- **Critical path**: The six-step compilation pipeline is the critical path. Each step depends on the previous one, and errors propagate forward. The most error-prone steps are value inference (step 2) and layer allocation (step 4).

- **Design tradeoffs**: Tracr prioritizes correctness and ground truth over efficiency. The orthogonal embedding of each s-op ensures interpretability but creates sparse, inefficient models. The compression procedure attempts to address this but may alter the underlying computation.

- **Failure signatures**: Common failures include incorrect value inference leading to wrong embeddings, suboptimal layer allocation causing unnecessarily deep models, and compression that changes the algorithm rather than just the representation.

- **First 3 experiments**:
  1. Compile and run the frac_prevs program from Figure 2, verify the model correctly computes the fraction of "x" tokens.
  2. Modify the frac_prevs program to handle a different token, compile it, and compare the weight structures to the original.
  3. Apply the compression procedure to the frac_prevs model and analyze how the embedding matrix W stores the original features.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the compression of compiled transformers behave when applied to deeper models with more complex computational structures?
- Basis in paper: [explicit] The paper discusses compressing compiled models using gradient descent-based compression and notes that this allows studying superposition in deeper models.
- Why unresolved: The paper presents preliminary experiments with compression and mentions that the compressed models can learn different computations than the original models. However, it does not fully explore the behavior of compression in deeper models with more complex structures.
- What evidence would resolve it: Conducting experiments with compression on compiled models of varying depths and complexities, and analyzing the resulting compressed models to understand how superposition and other computational phenomena manifest.

### Open Question 2
- Question: How can the expressivity of RASP and Tracr be extended to handle probabilistic computations and non-binary attention patterns?
- Basis in paper: [explicit] The paper acknowledges that RASP is designed for algorithmic tasks with discrete outputs and binary attention patterns, which limits its ability to model probabilistic computations and complex attention patterns found in real transformer models.
- Why unresolved: While the paper suggests potential extensions to RASP and Tracr, it does not provide concrete solutions or experimental results for handling probabilistic computations and non-binary attention patterns.
- What evidence would resolve it: Developing and implementing extensions to RASP and Tracr that support probabilistic computations and non-binary attention patterns, and evaluating their effectiveness in compiling and analyzing more realistic transformer models.

### Open Question 3
- Question: How can the efficiency of Tracr models be improved by using constraint optimization solvers instead of heuristics for layer allocation?
- Basis in paper: [explicit] The paper mentions that Tracr uses heuristics to allocate components to layers in the compiled model, which can result in suboptimal layer allocations. It suggests that using constraint optimization solvers could improve efficiency.
- Why unresolved: The paper does not explore the use of constraint optimization solvers for layer allocation, leaving the potential benefits and challenges of this approach unexplored.
- What evidence would resolve it: Implementing a constraint optimization solver for layer allocation in Tracr and comparing the resulting model efficiency and performance with the current heuristic-based approach.

## Limitations

- The compression procedure may fundamentally alter the computational pathway of compiled models rather than just the representation, making them unreliable for studying superposition
- The compilation pipeline's assumption of semantic equivalence across all six steps remains largely untested, particularly for complex computational patterns
- The narrow scope of tested programs (token counting, sorting, parenthesis checking) may not adequately stress-test the system's capabilities

## Confidence

**High Confidence**: The core mechanism that Tracr can compile simple RASP programs into functional transformer models is well-supported by empirical demonstrations. The authors show working compiled models for multiple tasks with clear performance metrics.

**Medium Confidence**: The claim that compressed Tracr models can serve as valid testbeds for studying superposition phenomena is supported by dimensional reduction experiments, but the deeper claim about maintaining computational equivalence during compression has limited validation. The cosine similarity metric used to verify consistency doesn't capture whether the compressed model uses fundamentally different computational strategies.

**Low Confidence**: The assertion that Tracr models will reliably serve as gold standards for evaluating interpretability tools is premature. While the theoretical framework is sound, the paper provides limited evidence that state-of-the-art interpretability methods can actually recover the known structures from compiled models, especially in compressed variants where superposition is present.

## Next Checks

1. **Cross-validation of compression**: Take a Tracr-compiled model and create multiple compressed versions using different random seeds for the compression procedure. Compare not just task performance but the internal circuit structures using mechanistic interpretability techniques to verify they converge on the same computational pathway.

2. **Stress-testing compilation pipeline**: Design increasingly complex RASP programs that incorporate features like conditional branching, loops, or multi-step reasoning chains. Measure compilation success rates and identify at which step the pipeline breaks down for complex programs.

3. **Interpretability benchmark evaluation**: Apply multiple state-of-the-art mechanistic interpretability tools (circuit analysis, causal tracing, feature visualization) to both uncompressed and compressed Tracr models. Quantify their ability to recover known ground truth structures using metrics beyond qualitative assessment, such as precision/recall of identified circuit components.