---
ver: rpa2
title: 'Between accurate prediction and poor decision making: the AI/ML gap'
arxiv_id: '2310.02029'
source_url: https://arxiv.org/abs/2310.02029
tags:
- utility
- probability
- expected
- estimation
- decision
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper argues that excessive focus on prediction accuracy in
  AI/ML neglects the importance of utility assessment in decision making. It compares
  the sensitivity of expected utility to uncertainty in probability estimation versus
  utility estimation.
---

# Between accurate prediction and poor decision making: the AI/ML gap

## Quick Facts
- arXiv ID: 2310.02029
- Source URL: https://arxiv.org/abs/2310.02029
- Reference count: 12
- One-line primary result: Excessive focus on prediction accuracy in AI/ML neglects the importance of utility assessment in decision making, with utility uncertainty potentially being as or more harmful than probability estimation error.

## Executive Summary
This paper argues that the AI/ML community's excessive focus on prediction accuracy has created a significant gap in decision-making quality. While substantial efforts have been devoted to reducing prediction errors, often with enormous computational costs, the critical aspect of utility assessment has been largely neglected. The authors demonstrate through theoretical analysis and simulations that inaccurate utility assessment can be as or more harmful than poor probability estimation when making decisions under uncertainty.

## Method Summary
The paper employs a theoretical framework for binary decision-making under uncertainty, deriving analytical expressions for expected loss increase due to suboptimal action selection when probability and utility estimates are uncertain. The analysis uses normal distribution assumptions for estimator errors and validates results through Monte Carlo simulations with Beta and Uniform distributions for probability and cost estimators respectively. The approach quantifies how decision sensitivity scales with estimation uncertainty in both probability and utility terms.

## Key Results
- Utility estimation error can be as harmful as or more harmful than probability estimation error in expected utility maximization
- Decision sensitivity to utility uncertainty scales with cost magnitude and variance in utility estimates
- Oversized model architectures for marginal accuracy gains may be ineffective if downstream utility is poorly characterized

## Why This Works (Mechanism)

### Mechanism 1
Utility estimation error can be as harmful as or more harmful than probability estimation error in expected utility maximization. The sensitivity of expected utility to utility uncertainty scales with the cost magnitude and the variance in utility estimates, whereas probability sensitivity is bounded due to the probabilistic nature of outcomes. Core assumption: Utilities and probabilities are estimated independently with symmetric error distributions. Evidence anchors: [abstract] "Theoretical and simulated results show that an inaccurate utility assessment may as (and sometimes) more harmful than a poor probability estimation." [section 2.2] Analytical formula (6) and Fig. 1 show normalized loss increase ∆/L* increasing with utility standard error, even when probability error is zero.

### Mechanism 2
Oversized model architectures for marginal accuracy gains are ineffective if downstream utility is poorly characterized. Decision-making under uncertainty requires both accurate probability estimates and accurate utility assessments; improving only the former yields diminishing returns. Core assumption: The primary decision objective is maximizing expected utility, not just prediction accuracy. Evidence anchors: [section 1] "This paper argues that AI/ML community has taken so far a too unbalanced approach by devoting excessive attention to the estimation of the state probability to the detriment of accurate and reliable estimations of the utility." [section 1] "we assisted in recent years to a huge effort to reduce the error of prediction, often with enormous computational (and energy) costs and sometimes with very limited effects."

### Mechanism 3
Suboptimal action selection probability increases when the sign of estimated δ differs from the true δ, with the magnitude of loss increase scaling with |δ|. When ˆδ < 0 but δ > 0 (or vice versa), the chosen action does not minimize expected loss; the expected loss increase is the probability of this sign error times |δ|. Core assumption: ˆδ follows a normal distribution with mean δ and variance given by (5). Evidence anchors: [section 2.1] Derivation of Perr = P(ˆδ < 0 | δ > 0) and the expression for ∆ = Perr|δ|. [section 2.1] "Note that the action selection is not optimal (a* ≠ â) when the signs of δ and ˆδ are discordant."

## Foundational Learning

- Concept: Decision theory under uncertainty
  - Why needed here: The paper's core argument rests on expected utility maximization and how errors in probability and utility propagate to decision quality.
  - Quick check question: What is the Bayes action that minimizes expected loss when P(θ=0)=p₀ and costs are c₀₁, c₁₀?

- Concept: Error propagation in multiplicative terms
  - Why needed here: Variance of ˆδ depends on variances of ˆc₀₁, ˆc₁₀, and ˆp₀; understanding how errors compound is critical for interpreting (5).
  - Quick check question: If Var[ˆc₀₁]=0.01, Var[ˆc₁₀]=0.01, and Var[ˆp₀]=0.0025, what is Var[ˆδ] when p₀=0.3, c₀₁=0.3, c₁₀=0.5?

- Concept: Sensitivity analysis of decision thresholds
  - Why needed here: The paper compares sensitivity of expected loss to probability vs utility uncertainty; this requires understanding how small changes in inputs affect decisions.
  - Quick check question: If p₀=0.1 and c₀₁=0.2, c₁₀=0.8, what p₀ value would flip the optimal action?

## Architecture Onboarding

- Component map: Probability estimator -> Utility assessor -> Decision selector -> Evaluation module
- Critical path:
  1. Obtain labeled data for probability estimation
  2. Elicit or learn utility estimates from domain experts or historical outcomes
  3. Propagate estimation errors through δ to quantify decision risk
  4. Optimize estimator complexity based on utility uncertainty rather than pure accuracy
- Design tradeoffs:
  - Model complexity vs. interpretability of utility terms
  - Data quantity for probability estimation vs. quality of utility elicitation
  - Computational cost of fine-tuning probability vs. cost of utility uncertainty quantification
- Failure signatures:
  - High variance in utility estimates with low variance in probability estimates -> focus on utility assessment
  - Utility terms c₀₁, c₁₀ ≈ 0 or equal -> decision sensitivity drops; accuracy focus may be warranted
  - Asymmetric utility distributions -> normal approximation in (5) may fail
- First 3 experiments:
  1. Simulate a binary classification task with known true p₀ and vary utility terms; measure ∆/L* as utility variance increases while probability error is fixed
  2. Fix utility terms, vary the entropy of p₀ distribution, and measure sensitivity of ∆/L* to probability estimation error
  3. Combine uncertain probability and utility estimates; compare analytical ∆ from (6) to empirical ∆ from Monte Carlo sampling

## Open Questions the Paper Calls Out

### Open Question 1
How can AI/ML research better quantify and model utility uncertainty in practical decision-making systems? Basis in paper: [explicit] The paper argues that utility assessment has been neglected in AI/ML research and advocates for more utility-aware methodologies. Why unresolved: Current research focuses heavily on prediction accuracy while utility assessment remains largely qualitative and underdeveloped. What evidence would resolve it: Development of concrete frameworks and methodologies for quantifying utility uncertainty that can be integrated into AI/ML systems.

### Open Question 2
Under what conditions does utility uncertainty have greater impact on decision quality than probability estimation error? Basis in paper: [explicit] The paper's theoretical and simulation results show that inaccurate utility assessment may be as or more harmful than poor probability estimation. Why unresolved: The conditions under which utility uncertainty dominates are not fully characterized, particularly for different types of decision problems. What evidence would resolve it: Empirical studies across diverse decision-making domains comparing the relative impacts of utility vs probability uncertainty.

### Open Question 3
How can utility functions be learned from data rather than relying on expert elicitation? Basis in paper: [explicit] The paper calls for research on assessment of reliable utility from data and mentions task-agnostic reinforcement learning as a potential direction. Why unresolved: Current approaches rely heavily on expert knowledge or fixed utility functions, which may not capture real-world complexity or adapt to changing conditions. What evidence would resolve it: Development of data-driven methods for learning utility functions that can adapt to different contexts and users.

## Limitations
- Analysis assumes symmetric, independent estimation errors for probabilities and utilities, which may not hold in practice
- Normal approximation for utility estimation error may break down with heavy-tailed or skewed distributions
- Focus on binary decisions limits generalizability to multi-class or continuous decision spaces
- No empirical validation is provided beyond simulations with assumed distributions

## Confidence
- **High confidence**: The mathematical framework for expected utility maximization and the analytical derivation of decision sensitivity to probability vs utility uncertainty are sound and internally consistent
- **Medium confidence**: The simulation setup and parameter choices are reasonable, but the lack of real-world validation limits confidence in practical implications
- **Low confidence**: The generalizability of results to non-binary decisions, asymmetric utility distributions, and correlated estimation errors remains unverified

## Next Checks
1. Validate the analytical results with empirical data from a real binary decision-making task (e.g., medical diagnosis) where both probability and utility estimates can be independently assessed for error
2. Extend the analysis to non-normal utility estimation error distributions (e.g., log-normal, t-distribution) and compare sensitivity results to the baseline
3. Apply the framework to a multi-class decision problem and derive the equivalent sensitivity expressions for probability and utility uncertainty in that setting