---
ver: rpa2
title: An Ontology of Co-Creative AI Systems
arxiv_id: '2310.07472'
source_url: https://arxiv.org/abs/2310.07472
tags:
- systems
- human
- creative
- co-creative
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces an ontology of co-creative AI systems, extending
  Lubart''s original framework with three new categories: computer-as-subcontractor,
  computer-as-critic, and computer-as-teammate. The authors address the challenge
  of disambiguating research efforts in the diverse field of human-AI creative collaboration
  by focusing on responsibility division and information exchange between human and
  AI.'
---

# An Ontology of Co-Creative AI Systems

## Quick Facts
- arXiv ID: 2310.07472
- Source URL: https://arxiv.org/abs/2310.07472
- Reference count: 4
- One-line primary result: An ontology extending Lubart's framework with three new categories for AI-human creative collaboration

## Executive Summary
This paper introduces an ontology of co-creative AI systems that extends Lubart's original framework with three new categories: computer-as-subcontractor, computer-as-critic, and computer-as-teammate. The ontology addresses the challenge of disambiguating research efforts in the diverse field of human-AI creative collaboration by focusing on responsibility division and information exchange patterns. The framework provides a structured vocabulary for describing different interaction paradigms in co-creative systems and highlights the need for further research into human-facing aspects and ethical implications of these systems.

## Method Summary
The paper presents a conceptual framework that extends Lubart's original ontology of creativity support tools. The authors propose three new categories emphasizing artificial intelligence capabilities: computer-as-subcontractor (exemplified by text-to-image generators), computer-as-critic (distinguishing professional and audience perspectives), and computer-as-teammate (further divided into peer, apprentice, and master relationships). The ontology categorizes systems based on how responsibilities are divided between human and AI system and the information exchanged between them.

## Key Results
- Extends Lubart's original ontology with three new AI-focused categories
- Introduces distinction between professional-critic and audience-critic feedback perspectives
- Divides computer-as-teammate into peer, apprentice, and master relationship types
- Provides framework for disambiguating co-creative AI research efforts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The ontology disambiguates co-creative AI research by categorizing systems based on responsibility division and information exchange patterns
- Mechanism: By explicitly mapping who has control over creative decisions and what information flows between human and AI, the framework creates clear boundaries between different interaction paradigms
- Core assumption: Different creative collaboration patterns can be meaningfully distinguished by their division of responsibility and information exchange characteristics
- Evidence anchors:
  - [abstract] "focusing on how responsibilities are divided between human and AI system and the information exchanged between them"
  - [section] "based on what responsibilities each party is taking and the information being exchanged"
  - [corpus] Weak - corpus neighbors focus on applications rather than ontological frameworks
- Break condition: When systems blur responsibility boundaries to the point where clear categorization becomes impossible or when information exchange patterns don't align with responsibility division

### Mechanism 2
- Claim: Extending Lubart's framework with AI-specific categories captures the evolution of human-AI creative collaboration
- Mechanism: The three new categories (computer-as-subcontractor, computer-as-critic, computer-as-teammate) address capabilities that were speculative in 2005 but are now realized, providing more precise vocabulary for describing current systems
- Core assumption: The progression from "colleague" to more specific AI-focused categories reflects actual technological capabilities and use patterns
- Evidence anchors:
  - [section] "We extend Lubart's original ontology of creativity support tools with three new categories emphasizing artificial intelligence"
  - [section] "The last category, colleague envisioned a time when artificial intelligence would be sufficiently capable to act as a partner to human creators...Nearly 20 years have passed and what was once considered speculative is now verging on reality"
  - [corpus] Weak - corpus papers focus on specific applications rather than ontological evolution
- Break condition: When new interaction patterns emerge that don't fit any of the extended categories, requiring further framework expansion

### Mechanism 3
- Claim: The distinction between professional-critic and audience-critic addresses different feedback needs in creative processes
- Mechanism: By recognizing that feedback can serve different purposes (technical quality vs. user reception), the ontology captures the multifaceted nature of creative critique
- Core assumption: Creative feedback can be meaningfully categorized by its intended perspective and purpose
- Evidence anchors:
  - [section] "We delineate between two types of critics. The Professional-Critic provides feedback from the perspective of established norms and conventions...The Audience provides feedback as if it were a surrogate for the people that will experience the final creative artwork"
  - [abstract] "The computer-as-critic category distinguishes between professional and audience perspectives in providing feedback"
  - [corpus] Missing - no direct corpus evidence supporting this specific distinction
- Break condition: When feedback perspectives become more nuanced than the professional/audience dichotomy can capture

## Foundational Learning

- Concept: Mixed-initiative interaction
  - Why needed here: Understanding when and how human and AI can initiate changes is crucial for distinguishing between subcontractor and teammate models
  - Quick check question: What is the key difference between a subcontractor and a teammate in terms of initiative-taking?

- Concept: Creative agency and responsibility
  - Why needed here: The ontology fundamentally categorizes systems based on how creative agency is divided between human and AI
  - Quick check question: How does the ontology define the boundary between human and AI creative agency in the subcontractor model?

- Concept: Feedback mechanisms in creative systems
  - Why needed here: The critic category relies on understanding different types of feedback and their roles in creative processes
- Quick check question: What distinguishes professional-critic feedback from audience-critic feedback?

## Architecture Onboarding

- Component map:
  - Responsibility tracker: Monitors which party (human/AI) has control over specific creative decisions
  - Information exchange manager: Handles what information flows between human and AI and when
  - Category classifier: Maps current interaction patterns to the appropriate ontology category
  - Feedback processor: Manages different types of critique (professional vs. audience)

- Critical path: Human makes high-level decision → System determines responsibility division → Information exchange occurs → Creative artifact is modified → Feedback is processed (if applicable) → Cycle repeats

- Design tradeoffs:
  - Granularity vs. simplicity: More categories provide better disambiguation but increase complexity
  - Flexibility vs. structure: Allowing systems to span multiple categories enables hybrid approaches but may reduce clarity
  - Static vs. dynamic categorization: Fixed categories are easier to implement but may not capture evolving interaction patterns

- Failure signatures:
  - Ambiguity in responsibility division leading to unclear category assignment
  - Information exchange patterns that don't align with claimed responsibility division
  - Systems that appear to fit multiple categories equally well, suggesting category overlap

- First 3 experiments:
  1. Map existing co-creative systems (e.g., text-to-image generators, writing assistants) to the ontology categories and document any classification challenges
  2. Implement a prototype that tracks responsibility division and information exchange in a simple co-creative task (e.g., collaborative story writing)
  3. Create a visualization tool that shows the current category classification and allows users to understand why their system falls into a particular category

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we determine the optimal distribution of responsibilities between human and AI in co-creative systems to maximize both creative output and user satisfaction?
- Basis in paper: [explicit] The paper emphasizes the need to understand how responsibilities should be divided between humans and AI systems, stating "How should the responsibilities for different parts of the creative process be distributed between humans and AI?"
- Why unresolved: This question is fundamental to the design of co-creative AI systems but requires empirical studies to determine the optimal balance, which may vary depending on the creative domain and individual user preferences.
- What evidence would resolve it: Systematic user studies comparing different responsibility distributions across various creative tasks, measuring both the quality of creative output and user satisfaction.

### Open Question 2
- Question: What are the ethical implications of AI systems that can express human-like traits in co-creative settings, and how can we mitigate potential biases introduced by these systems?
- Basis in paper: [explicit] The paper mentions that "a co-creative agent that expresses human-like traits is deemed 'more reliable', regardless of the actual creative effort of the agent," highlighting potential ethical concerns.
- Why unresolved: The interaction between human-like AI traits and user perception is complex and may lead to unintended consequences in creative collaboration.
- What evidence would resolve it: Empirical studies on user trust and decision-making when interacting with human-like AI agents in creative tasks, coupled with analysis of bias introduction in creative outputs.

### Open Question 3
- Question: How can we design AI systems that can effectively adapt to individual human creators' processes and augment their abilities in real-time during co-creative activities?
- Basis in paper: [explicit] The paper discusses the need for systems to "adapt to the human's process, and how to augment and extend the human creator's abilities."
- Why unresolved: This requires advanced AI capabilities in understanding human creative processes and providing timely, relevant assistance, which is still an open challenge in AI research.
- What evidence would resolve it: Development and evaluation of AI systems that can successfully adapt to and augment human creative processes across multiple creative domains, demonstrating measurable improvements in creative output and user experience.

## Limitations

- The framework may oversimplify complex creative interactions that dynamically shift between categories
- Binary division of responsibility may not capture nuanced collaborative patterns where humans and AI share creative agency fluidly
- Potential difficulty in classifying systems that exhibit characteristics of multiple categories

## Confidence

- High confidence in the taxonomy's internal consistency and logical structure
- Medium confidence in the framework's applicability to real-world systems, as empirical validation was not demonstrated
- Low confidence in the framework's completeness, given the rapidly evolving nature of AI capabilities and creative applications

## Next Checks

1. **Empirical Mapping Study**: Apply the ontology to a diverse sample of 20-30 existing co-creative AI systems to assess classification accuracy and identify edge cases or ambiguities in category boundaries.

2. **Temporal Stability Analysis**: Re-evaluate systems after a 12-month period to determine if the ontology can accommodate evolving interaction patterns and new creative capabilities that may emerge.

3. **User Comprehension Study**: Test whether creative professionals can effectively use the ontology to describe their preferred interaction patterns and understand the implications of different responsibility divisions for their work.