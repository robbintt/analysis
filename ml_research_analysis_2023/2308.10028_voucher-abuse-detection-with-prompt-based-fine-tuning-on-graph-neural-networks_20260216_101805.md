---
ver: rpa2
title: Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks
arxiv_id: '2308.10028'
source_url: https://arxiv.org/abs/2308.10028
tags:
- graph
- detection
- node
- vpgnn
- voucher
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles voucher abuse detection in e-commerce, where
  abusers exploit promotional vouchers through fraudulent orders. The core challenge
  is detecting these abusive orders with limited labeled data and fluid abuse patterns.
---

# Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural Networks

## Quick Facts
- arXiv ID: 2308.10028
- Source URL: https://arxiv.org/abs/2308.10028
- Reference count: 40
- Key outcome: VPGNN outperforms state-of-the-art baselines by up to 4.4% in few-shot settings and 23.4% in online deployment

## Executive Summary
This paper addresses voucher abuse detection in e-commerce by proposing VPGNN, a graph neural network framework that leverages prompt-based fine-tuning. The approach reformulates classification into a pairwise matching template consistent with the pretext task, using a novel graph prompting function and context tokens initialized from the pre-trained GNN's readout function. VPGNN demonstrates strong performance in low-resource settings and effective knowledge transfer across markets and time periods.

## Method Summary
VPGNN combines graph neural networks with prompt-based fine-tuning to detect voucher abuse in e-commerce. The method first pre-trains a GNN using DGI (Deep Graph Infomax) to maximize local-global mutual information. During fine-tuning, it reformulates the classification task into a pairwise matching template using a graph prompting function that creates node-token/context-token pairs. Context tokens are initialized by pooling representations of labeled nodes and their neighbors using the pre-trained readout function, then jointly fine-tuned with the GNN parameters using the same pretext loss. This approach requires only limited pseudo-labels and demonstrates strong transfer capabilities.

## Key Results
- Outperforms state-of-the-art baselines by up to 4.4% in few-shot settings
- Achieves 23.4% improvement over existing production models in online deployment
- Demonstrates strong knowledge transfer across markets and time periods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Prompt-based fine-tuning narrows the objective gap between pre-training and downstream tasks by reformulating classification into a pairwise matching template consistent with the pretext task.
- Mechanism: The graph prompting function P transforms each input node into a prompt consisting of a node token and a context token. This creates token pairs that are scored by the same projection head used in pre-training, making the downstream objective similar to the pretext objective of maximizing local-global mutual information.
- Core assumption: The pretext task of maximizing node-graph mutual information can be effectively aligned with the downstream classification task through a suitable prompt reformulation.
- Evidence anchors:
  - [abstract] "We design a novel graph prompting function to reformulate the downstream task into a similar template as the pretext task in pre-training, thereby narrowing the objective gap."
  - [section 4.3] "Our prompt design allows us to reuse not only the pretext projection head without introducing a new classification head, but also the pretext task loss without formulating a new task loss."
  - [corpus] Weak - the related papers focus on different aspects of graph prompting (e.g., multi-task prompting, inductive fine-tuning) rather than the specific alignment mechanism described here.
- Break condition: If the pretext task (DGI-based mutual information maximization) is fundamentally misaligned with the downstream classification objective, the prompt reformulation will not effectively bridge the gap.

### Mechanism 2
- Claim: Context tokens initialized using the pre-trained GNN's readout function provide both informativeness and robustness in low-resource scenarios.
- Mechanism: For each class, the context token is initialized by pooling the representations of labeled nodes and their neighbors using the pre-trained readout function. This captures class-level information more effectively than simple averaging or random initialization.
- Core assumption: The pre-trained readout function can extract meaningful class-level representations from the pooled node embeddings.
- Evidence anchors:
  - [section 4.3] "To improve the informativeness, we reuse the graph Readout function from pre-training... the context token zùëê can be initialized by Œ©(Hùëê ; ùúîpre)"
  - [section 5.2] "VPGNN outperforms all the ablated models consistently... Among the ablated models, No prompt performs rather poorly in most cases, especially under the 10-shot setting."
  - [corpus] Missing - the related papers do not specifically address context token initialization using readout functions.
- Break condition: If the pre-trained readout function fails to capture class-level information effectively, or if the neighbor sampling introduces too much noise, the initialization will not provide the intended benefits.

### Mechanism 3
- Claim: Prompt-based fine-tuning allows effective transfer across markets and time without requiring task-specific projection heads or losses.
- Mechanism: By fine-tuning the pre-trained model parameters (ùúÉ', ùúô') and context tokens Z using the same pretext loss Lpre, VPGNN adapts to new domains while maintaining the knowledge captured during pre-training. The orthogonal constraint on the prompt matrix promotes separability of classes.
- Core assumption: The knowledge captured during pre-training is sufficiently general to be adapted to new domains through prompt tuning alone.
- Evidence anchors:
  - [abstract] "Extensive experiments on both internal and public datasets demonstrate the strength of VPGNN... Moreover, an online deployment of VPGNN in a production environment shows a 23.4% improvement over two existing deployed models."
  - [section 5.2] "VPGNN attains larger improvements relative to the runner-up under the 10-shot setting... showing that VPGNN is a strong few-shot learner suitable for the low-resource settings."
  - [corpus] Weak - while some related papers discuss transfer learning with GNNs, they do not specifically address prompt-based fine-tuning for cross-domain adaptation.
- Break condition: If the pre-training data does not capture sufficiently general patterns, or if the new domain is too dissimilar, prompt-based fine-tuning alone will not achieve effective transfer.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their message-passing mechanism
  - Why needed here: VPGNN relies on GNNs to encode node information into node tokens and to initialize context tokens through the readout function. Understanding GNN architectures and their inductive biases is crucial for grasping how VPGNN processes graph data.
  - Quick check question: What is the key difference between a GNN's node representation and a simple node feature vector, and why does this matter for VPGNN's node token construction?

- Concept: Self-supervised learning and pretext tasks for GNNs
  - Why needed here: VPGNN uses DGI (Deep Graph Infomax) as its pretext task during pre-training. Understanding how self-supervised learning works for graphs and what DGI specifically optimizes for is essential to understand how the pre-training stage prepares the model for downstream tasks.
  - Quick check question: In DGI, what is the relationship between node representations and the graph-level representation, and how does this relationship help with voucher abuse detection?

- Concept: Prompt engineering and fine-tuning in NLP and its adaptation to graphs
  - Why needed here: VPGNN adapts the concept of prompting from NLP to graph data. Understanding how prompts work in NLP (e.g., "I feel [MASK]") and the challenges of adapting this to graphs (incompatibility with nodes and edges) is crucial for understanding VPGNN's novel approach.
  - Quick check question: Why can't we directly apply textual prompting functions to graph-based tasks, and what specific challenges does VPGNN address in its graph prompting function design?

## Architecture Onboarding

- Component map: Pre-training stage (DGI-based self-supervised learning with GNN encoder, readout function, and projection head) -> Prompt generation (graph prompting function that creates node-token/context-token pairs) -> Context token initialization (readout-based pooling of labeled nodes and neighbors) -> Fine-tuning stage (joint optimization of pre-trained GNN parameters, projection head, and context tokens using the pretext loss) -> Deployment pipeline (feature extraction, relation extraction, pseudo-label generation, graph construction, prompt-based fine-tuning, prediction)

- Critical path: Pre-training ‚Üí Context token initialization ‚Üí Prompt-based fine-tuning ‚Üí Prediction
  The most critical components are the pre-trained GNN model, the context token initialization process, and the prompt-based fine-tuning loop. Failure in any of these will significantly impact model performance.

- Design tradeoffs:
  - Using the same pretext projection head and loss simplifies fine-tuning but may limit flexibility in adapting to very different downstream tasks
  - Neighbor sampling for context token initialization improves robustness but introduces hyperparameter tuning complexity (ùúÇ value)
  - Prompt-based fine-tuning reduces labeled data requirements but may not achieve the same performance as full fine-tuning in high-resource scenarios

- Failure signatures:
  - Poor performance on few-shot settings: Indicates issues with context token initialization or prompt design
  - Inability to transfer across domains: Suggests pre-training did not capture sufficiently general patterns
  - Overfitting with many labels: May indicate the orthogonal constraint is too restrictive or the model is too complex

- First 3 experiments:
  1. Ablation study comparing VPGNN with random context token initialization vs. readout-based initialization on a 10-shot voucher abuse detection task
  2. Cross-domain evaluation: Pre-train on VN0909, fine-tune on ID0909 and ID1023, compare performance with and without prompt-based fine-tuning
  3. Neighbor sampling sensitivity: Vary ùúÇ from 0 to 10 on a 10-shot task, plot performance curve to identify optimal sampling depth

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of VPGNN compare to traditional fine-tuning approaches when using extremely limited labeled data (e.g., 1-5 shots) in real-world voucher abuse detection scenarios?
- Basis in paper: [explicit] The paper shows VPGNN outperforms state-of-the-art baselines by up to 4.4% in few-shot settings, but doesn't test with fewer than 10 shots.
- Why unresolved: The paper's experiments start at 10 shots, leaving the performance at lower shot counts unknown.
- What evidence would resolve it: Experiments testing VPGNN with 1-5 shots on the same datasets used in the paper, comparing against traditional fine-tuning baselines.

### Open Question 2
- Question: How does the performance of VPGNN degrade when deployed on entirely new markets or platforms with different voucher abuse patterns than those seen during pre-training?
- Basis in paper: [inferred] The paper demonstrates good knowledge transfer across time and countries, but doesn't test on completely different platforms or markets with potentially different abuse patterns.
- Why unresolved: The paper only tests on datasets from Lazada's Vietnam and Indonesia markets, which may share similar abuse patterns.
- What evidence would resolve it: Deploying VPGNN on voucher abuse detection for a completely different e-commerce platform or market segment and measuring performance degradation.

### Open Question 3
- Question: What is the computational overhead of VPGNN compared to traditional fine-tuning approaches, particularly in terms of memory usage and training time during both pre-training and fine-tuning phases?
- Basis in paper: [inferred] The paper mentions that fine-tuning pre-trained GNNs can be costly for large-scale graphs but doesn't provide specific comparisons of computational resources.
- Why unresolved: The paper focuses on accuracy improvements but doesn't discuss the computational efficiency trade-offs.
- What evidence would resolve it: Detailed benchmarking of VPGNN's memory usage, training time, and inference latency compared to traditional fine-tuning approaches on the same hardware infrastructure.

## Limitations
- Performance depends heavily on the quality of pseudo-labels generated by business rules
- Requires careful hyperparameter tuning for context token initialization (neighbor sampling depth Œ∑)
- The orthogonal constraint on the prompt matrix may restrict the model's capacity to learn complex patterns

## Confidence
- High confidence: The experimental results showing VPGNN's superiority over baselines in few-shot settings (up to 4.4% F1 improvement) and online deployment (23.4% BPWC improvement)
- Medium confidence: The mechanism claims about how prompt-based fine-tuning narrows the objective gap between pre-training and downstream tasks
- Low confidence: The generalizability claims across different markets and time periods

## Next Checks
1. **Robustness to pseudo-label quality**: Systematically vary the quality and quantity of pseudo-labels by adjusting business rule thresholds, then measure VPGNN's performance degradation curve to understand its sensitivity to label noise.
2. **Cross-domain transfer validation**: Pre-train on VN0909, then fine-tune on a completely different market (e.g., not ID0909/1023) and measure performance drop. Compare against standard fine-tuning to isolate the benefit of prompt-based adaptation.
3. **Orthogonal constraint ablation**: Remove the orthogonal constraint on the prompt matrix and measure performance impact across different few-shot settings. This will reveal whether the constraint is beneficial or potentially limiting the model's capacity.