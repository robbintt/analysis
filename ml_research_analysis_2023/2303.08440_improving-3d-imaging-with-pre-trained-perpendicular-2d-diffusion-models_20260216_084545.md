---
ver: rpa2
title: Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models
arxiv_id: '2303.08440'
source_url: https://arxiv.org/abs/2303.08440
tags:
- tpdm
- diffusion
- slice
- inverse
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for 3D medical image reconstruction
  using two perpendicular pre-trained 2D diffusion models. The approach models the
  3D data distribution as a product of 2D distributions from different directions,
  avoiding the curse of dimensionality.
---

# Improving 3D Imaging with Pre-Trained Perpendicular 2D Diffusion Models

## Quick Facts
- arXiv ID: 2303.08440
- Source URL: https://arxiv.org/abs/2303.08440
- Reference count: 40
- Key outcome: First successful MR-ZSR improving slice thickness from 5mm to 1mm with high quality, state-of-the-art performance across multiple 3D medical imaging tasks

## Executive Summary
This paper introduces TPDM (Two Perpendicular Diffusion Models), a method for 3D medical image reconstruction that leverages two pre-trained 2D diffusion models working on perpendicular slice directions. The approach addresses the curse of dimensionality by modeling 3D data distributions as products of 2D distributions, enabling high-quality 3D reconstruction without requiring computationally expensive 3D diffusion models. The method achieves state-of-the-art performance on multiple 3D medical imaging tasks including MRI Z-axis super-resolution, compressed sensing MRI, and sparse-view CT, with notable success in the first-ever high-quality MR-ZSR demonstration.

## Method Summary
TPDM uses two pre-trained 2D diffusion models: a primary model trained on one plane direction (e.g., XY) and an auxiliary model trained on a perpendicular plane (e.g., YZ). During sampling, the models alternate in denoising steps, with the ratio controlled by hyperparameter K. The 3D data distribution is modeled as a product of the two 2D distributions, effectively addressing the curse of dimensionality. For inverse problems, measurement consistency is maintained through a Tweedie denoising estimate (DPS) applied during sampling. The approach is fully unsupervised and requires no retraining for individual inverse problems.

## Key Results
- Achieved first successful MR-ZSR, improving slice thickness from 5mm to 1mm with high quality
- Demonstrated state-of-the-art performance across multiple 3D medical imaging tasks including CS-MRI and SV-CT
- Significant improvements in PSNR and SSIM metrics compared to existing methods
- Successfully generated high-quality 3D voxel volumes unconditionally without measurement guidance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TPDM reduces 3D generative modeling complexity by factorizing the distribution into a product of 2D distributions.
- Mechanism: The 3D data distribution is modeled as p(x) = q(p)(x)^α · q(a)(x)^β / Z, where q(p) and q(a) are 2D distributions along perpendicular slices (e.g., XY and YZ planes).
- Core assumption: The 3D distribution can be decomposed into independent 2D slice distributions without significant loss of global structural dependencies.
- Evidence anchors: [abstract] "By modeling the 3D data distribution as a product of 2D distributions sliced in different directions, our method effectively addresses the curse of dimensionality."

### Mechanism 2
- Claim: Alternating denoising between primary and auxiliary models improves 3D structural consistency.
- Mechanism: At each denoising step, the model randomly applies either the primary model to XY slices or the auxiliary model to YZ slices, creating a stochastic sampling path that respects both directional priors.
- Core assumption: Stochastic alternation between two perpendicular priors is sufficient to capture 3D dependencies better than using a single 2D prior.
- Evidence anchors: [section 3.2] "We propose a simple fix to this problem by using alternating updates" and "conditional sampling is performed alternately using the trained TPDM for each step of time-step denoising."

### Mechanism 3
- Claim: The product distribution approach enables unsupervised 3D generation without retraining.
- Mechanism: By training two independent 2D diffusion models and combining their score functions, TPDM can perform unconditional 3D sampling without needing a dedicated 3D model or task-specific fine-tuning.
- Core assumption: The product of two well-trained 2D diffusion models approximates the true 3D data distribution well enough for unconditional generation.
- Evidence anchors: [section 5.4] "Using TPDM, we attempted to generate a full 3D voxel volume unconditionally" and "we were able to create a complete three-dimensional voxel volume with high resolution and quality."

## Foundational Learning

- Concept: Score-based diffusion models and reverse-time SDEs
  - Why needed here: TPDM builds on score-based diffusion models to learn the gradient of the log probability distribution for sampling.
  - Quick check question: What is the role of the score function ∇_x log p(x) in diffusion models, and how is it estimated during training?

- Concept: Product distributions and conditional independence
  - Why needed here: The core innovation of TPDM relies on modeling 3D distributions as products of 2D distributions, which requires understanding when this factorization is valid.
  - Quick check question: Under what conditions does p(x,y,z) = p(x,y)·p(z) hold, and what are the limitations of this factorization for 3D data?

- Concept: Inverse problem solving with diffusion priors
  - Why needed here: TPDM applies diffusion models to solve inverse problems like MRI reconstruction, requiring understanding of how diffusion priors can be combined with measurement models.
  - Quick check question: How does Bayes' theorem enable the use of diffusion priors for conditional sampling in inverse problems, and what approximation is made when the measurement model is not directly compatible?

## Architecture Onboarding

- Component map: Two pre-trained 2D diffusion models (primary and auxiliary) -> Alternating sampling algorithm with parameter K -> Measurement consistency module (DPS step) -> Product distribution formulation -> Score function combination layer

- Critical path: 
  1. Train two 2D diffusion models on perpendicular slices of a 3D volume dataset
  2. Implement alternating sampling with K parameter control
  3. Integrate measurement consistency via DPS approximation
  4. Test on 3D inverse problems and unconditional generation

- Design tradeoffs:
  - Memory vs. accuracy: Using 2D models reduces memory compared to 3D models but may lose some 3D information
  - Sampling speed vs. quality: Alternating updates are slower than single-model sampling but capture better 3D structure
  - K parameter tuning: Affects the balance between primary and auxiliary model contributions

- Failure signatures:
  - Directional artifacts when one slice direction is poorly reconstructed
  - Blurry outputs when K is too large and one model dominates
  - Inconsistent structures across slice directions
  - Poor performance on tasks requiring strong 3D interactions

- First 3 experiments:
  1. Train two 2D diffusion models on perpendicular slices of a simple 3D dataset and verify they can reconstruct individual slices well
  2. Implement alternating sampling with K=2 and test on a 3D inverse problem (e.g., CS-MRI) to verify improvement over single 2D model
  3. Test unconditional 3D generation to verify the product distribution approach can create coherent 3D volumes without measurement guidance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of primary and auxiliary planes affect the performance of TPDM in different medical imaging modalities?
- Basis in paper: [inferred] The paper mentions different plane choices for MRI and CT tasks, but doesn't explore the impact of these choices on performance.
- Why unresolved: The authors only mention their chosen configurations without providing a systematic comparison of different plane combinations.
- What evidence would resolve it: A comprehensive study comparing TPDM performance with different primary/auxiliary plane combinations across multiple imaging modalities.

### Open Question 2
- Question: What is the optimal value of the hyperparameter K for different types of 3D inverse problems, and how does it vary with dataset size?
- Basis in paper: [explicit] The paper mentions using different K values for MRI and CT models, but doesn't provide a detailed analysis of its impact.
- Why unresolved: The authors only provide specific K values for their experiments without exploring the full range of possibilities or providing a method for determining optimal K.
- What evidence would resolve it: A systematic study varying K across different problem types and dataset sizes, with quantitative analysis of its impact on reconstruction quality.

### Open Question 3
- Question: How does TPDM perform on non-medical 3D imaging tasks, such as satellite imagery or industrial CT scans?
- Basis in paper: [inferred] The paper focuses exclusively on medical imaging applications, leaving the potential of TPDM for other domains unexplored.
- Why unresolved: The authors don't provide any experiments or discussion on non-medical applications of TPDM.
- What evidence would resolve it: Experiments applying TPDM to diverse 3D imaging tasks outside the medical domain, with quantitative comparisons to existing methods.

## Limitations

- The factorization assumption may break down for highly complex 3D structures with strong inter-slice dependencies
- Clinical evaluation for MR-ZSR is limited by small sample size (n=7 patients) and retrospective analysis design
- Computational efficiency of alternating sampling approach is not thoroughly analyzed compared to single-model approaches

## Confidence

- **High confidence**: The core mechanism of using product distributions of 2D models for 3D generation (Mechanism 1) is well-supported by theoretical foundations and experimental results across multiple medical imaging tasks.
- **Medium confidence**: The clinical relevance of MR-ZSR improvements (achieving 1mm slice thickness) is supported by radiologist evaluations but limited by small sample size and retrospective analysis design.
- **Medium confidence**: The claim that TPDM is "fully unsupervised and does not require retraining for individual inverse problems" holds for the tested scenarios but may not generalize to all possible 3D inverse problems without careful adaptation of the measurement consistency module.

## Next Checks

1. **Stress-test factorization assumption**: Apply TPDM to 3D datasets with known complex 3D structures (e.g., branching vasculature, curved anatomical structures) and systematically evaluate reconstruction quality across all three anatomical planes to identify directional artifacts.

2. **Clinical validation expansion**: Conduct a prospective study with larger patient cohorts (n>50) for MR-ZSR, including blinded radiologist assessments comparing TPDM-generated images against native 1mm acquisitions across multiple diagnostic tasks.

3. **Computational efficiency benchmarking**: Measure and compare inference time, memory usage, and sampling steps required by TPDM versus competitive 3D diffusion models on equivalent hardware, analyzing the tradeoff between quality improvements and computational overhead.