---
ver: rpa2
title: Enhanced Local Explainability and Trust Scores with Random Forest Proximities
arxiv_id: '2310.12428'
source_url: https://arxiv.org/abs/2310.12428
tags:
- training
- prediction
- explainability
- random
- predictions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a novel instance-based approach to explainability
  for Random Forest (RF) models using GAP (Geometry and Accuracy Preserving) proximities.
  The core idea leverages the mathematical equivalence between RF and an adaptive
  weighted K-nearest neighbors model, allowing RF predictions to be rewritten as a
  weighted sum of training targets.
---

# Enhanced Local Explainability and Trust Scores with Random Forest Proximities

## Quick Facts
- arXiv ID: 2310.12428
- Source URL: https://arxiv.org/abs/2310.12428
- Reference count: 21
- Primary result: Random Forest predictions can be exactly decomposed into weighted sums of training targets using GAP proximities, enabling instance-based explanations

## Executive Summary
This paper introduces a novel instance-based approach to explainability for Random Forest models using Geometry and Accuracy Preserving (GAP) proximities. The method leverages the mathematical equivalence between RF predictions and weighted sums of training targets, allowing explanations across training observations rather than features. Applied to corporate bond price discovery, the approach demonstrates that predictions can be approximated using only a small fraction of nearest neighbors, providing both attribution and uncertainty estimates. The method shows that larger training errors among nearest neighbors correlate with higher test errors, offering an ex-ante confidence measure for RF predictions.

## Method Summary
The method employs GAP proximities to decompose any Random Forest prediction into a weighted sum of training targets. By computing the RF-GAP proximity matrix using out-of-bag samples, the approach identifies which training observations contribute most to a given prediction. For each test prediction, the method calculates the weighted training error among nearest neighbors to estimate uncertainty in the target variable. This instance-based attribution complements traditional feature-based methods like SHAP by providing context about training data similarity rather than feature importance.

## Key Results
- RF predictions can be exactly rewritten as weighted sums of training targets using GAP proximities
- Predictions can be approximated using only about 1/15 of nearest neighbors on average
- Correlation of 0.49 between training errors of nearest neighbors and test prediction errors
- The method provides both prediction attribution and uncertainty estimates for RF models

## Why This Works (Mechanism)

### Mechanism 1
Random Forest predictions can be decomposed into weighted sums of training targets using GAP proximities. The RF-GAP proximity matrix captures the adaptive weighting structure inherent in random forests, where each prediction is a weighted average of training observations that fall into the same leaf across out-of-bag trees. This works because the GAP proximity formulation preserves both the geometry and accuracy of the original RF model.

### Mechanism 2
Training error among nearest neighbors correlates with test prediction error. By weighting training observations by their GAP proximity to a test point, we can estimate the noise level in the target variable for that region of feature space. This relationship holds when the joint distribution of features and targets remains stable between training and test sets.

### Mechanism 3
Instance-based explanations complement feature-based explanations by providing context about training data similarity. By identifying which training observations contribute most to a prediction (via high GAP proximity), we can understand the local decision context that differs from SHAP's feature attribution approach. This works when similar training observations share similar prediction behavior and error characteristics.

## Foundational Learning

- Random Forest mechanics and bootstrap aggregation
  - Why needed here: Understanding how trees are built and how out-of-bag samples are used is crucial for grasping GAP proximity computation
  - Quick check question: How does the bootstrap sampling in RF create different tree structures, and why does this matter for proximity calculation?

- Proximity measures in machine learning
  - Why needed here: GAP proximity is a specific type of similarity measure that requires understanding of distance metrics and their role in instance-based learning
  - Quick check question: What distinguishes Euclidean distance from RF-GAP proximity, and why is the latter more appropriate for RF explanations?

- SHAP value computation and interpretation
  - Why needed here: The paper explicitly positions GAP proximity as a complement to SHAP, so understanding SHAP's feature attribution is essential for appreciating the contribution
  - Quick check question: How do SHAP values decompose a prediction across features, and what limitations might this create compared to instance-based approaches?

## Architecture Onboarding

- Component map:
  Trained Random Forest model -> GAP proximity matrix computation -> Training error tracking -> Attribution aggregation -> Visualization and interpretation

- Critical path:
  1. Train RF model on labeled data
  2. Compute GAP proximity matrix using out-of-bag samples
  3. For each test prediction, identify nearest neighbors by proximity weight
  4. Calculate weighted training error for identified neighbors
  5. Generate attribution and uncertainty estimates

- Design tradeoffs:
  - Memory vs. accuracy: Storing full proximity matrix vs. computing on-demand
  - Speed vs. granularity: Number of neighbors to include in attribution (95% cumulative weight threshold)
  - Model complexity vs. interpretability: Deeper trees may capture more patterns but create denser proximity matrices

- Failure signatures:
  - Perfect attribution with high test error: Indicates proximity matrix not capturing true similarity
  - Unstable attributions across runs: Suggests insufficient tree depth or too few trees
  - Weak correlation between neighbor training error and test error: May indicate distribution shift or irrelevant features

- First 3 experiments:
  1. Verify GAP proximity reproduces exact RF predictions on training set
  2. Test correlation between neighbor training error and test error on synthetic data with known noise levels
  3. Compare attribution stability between GAP proximity and SHAP on a simple regression problem with known feature importance

## Open Questions the Paper Calls Out

### Open Question 1
How does the GAP proximity-based explainability method compare in computational efficiency to SHAP, particularly for large-scale RF models with millions of training samples? The paper demonstrates GAP proximities on a sub-sample of 10,000 trades but does not address scalability or computational complexity comparisons with SHAP.

### Open Question 2
Can the correlation between nearest neighbor training error and test error (r=0.49) be improved through adaptive weighting schemes or by incorporating additional uncertainty quantification methods? The paper presents this correlation as evidence of the method's utility but does not investigate whether this relationship can be strengthened.

### Open Question 3
How robust are GAP proximities to concept drift and temporal changes in the joint distribution of features and target in financial applications? The paper assumes the joint distribution remains stable but does not test this assumption or evaluate robustness to distribution shifts.

## Limitations
- The mathematical equivalence claim depends on specific implementation details from Rhodes et al. 2023 that are not fully specified
- The 0.49 correlation between neighbor training error and test error shows substantial unexplained variance
- Performance on high-dimensional datasets with sparse training data remains unclear

## Confidence
- High confidence: The conceptual framework of using instance-based explanations to complement feature-based methods like SHAP
- Medium confidence: The empirical finding of 0.49 correlation between neighbor training error and test error
- Low confidence: The exact mathematical equivalence claim without access to the full GAP proximity implementation details

## Next Checks
1. Implement GAP proximity computation and verify that weighted training target sums exactly reproduce RF predictions on the training set across multiple random seeds
2. Test the neighbor training error correlation on synthetic datasets with controlled noise levels and known distribution shifts
3. Compare attribution stability and explanation quality between GAP proximity and SHAP on a benchmark regression dataset with ground truth feature importance