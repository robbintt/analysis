---
ver: rpa2
title: Support-Set Context Matters for Bongard Problems
arxiv_id: '2309.03468'
source_url: https://arxiv.org/abs/2309.03468
tags:
- supports
- positive
- negative
- score
- bongard
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors address the challenge of solving Bongard problems,
  a type of IQ test requiring abstract concept learning from positive and negative
  image sets. They identify that prior methods fail to incorporate cross-image context
  from the full support set, which is critical for solving these problems.
---

# Support-Set Context Matters for Bongard Problems

## Quick Facts
- arXiv ID: 2309.03468
- Source URL: https://arxiv.org/abs/2309.03468
- Reference count: 12
- Key outcome: 75.3% accuracy on Bongard-LOGO, 72.45% on Bongard-HOI, 60.84% on Bongard-Classic

## Executive Summary
The authors address the challenge of solving Bongard problems, a type of IQ test requiring abstract concept learning from positive and negative image sets. They identify that prior methods fail to incorporate cross-image context from the full support set, which is critical for solving these problems. Their core method involves standardizing feature vectors using statistics computed from the support set as a whole, and using a Transformer to learn set-level knowledge. This approach significantly improves accuracy, achieving new state-of-the-art results: 75.3% on Bongard-LOGO, 72.45% on Bongard-HOI, and 60.84% on Bongard-Classic.

## Method Summary
The authors standardize feature vectors using mean and variance computed from all support images (positives and negatives), accentuating differences between classes. They use a Transformer trained to predict prototypes or SVM hyperplanes computed from the full support set, but the Transformer receives only random subsets of supports during training. This forces the model to learn how to complete missing information and generalize across different Bongard problems. The approach is evaluated on three Bongard datasets: Bongard-LOGO (synthetic geometric shapes), Bongard-HOI (real-world human-object interaction images), and Bongard-Classic (original Bongard problems).

## Key Results
- Achieved 75.3% accuracy on Bongard-LOGO, a 15-point improvement over previous methods
- Reached 72.45% accuracy on Bongard-HOI, demonstrating effectiveness on real-world images
- Scored 60.84% on Bongard-Classic, establishing new state-of-the-art performance
- Support-set standardization alone provided significant gains across all datasets
- Transformer-based approaches further improved performance by learning set-level knowledge

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Support-set standardization improves Bongard problem solving by incorporating cross-image context from the full support set.
- Mechanism: Standardizing feature vectors using mean and variance computed from all support images accentuates differences between the two classes, making the key concept more distinguishable.
- Core assumption: The key concept in a Bongard problem can only be distinguished by comparing multiple positive and multiple negative examples simultaneously.
- Evidence anchors:
  - [abstract] "Low accuracy is often attributed to neural nets' lack of ability to find human-like symbolic rules. In this work, we point out that many existing methods are forfeiting accuracy due to a much simpler problem: they do not adapt image features given information contained in the support set as a whole"
  - [section 3.4] "A simple way to implement this cross-image context is to standardize the mean and variance across the support set, to accentuate what is unique in the positives vs. the negatives"
- Break condition: If the support set is too small or contains outliers that don't represent the key concept, standardization could amplify noise rather than useful signal.

### Mechanism 2
- Claim: The Transformer-based approach learns set-level knowledge by mimicking privileged teacher models.
- Mechanism: The Transformer is trained to predict the prototypes or SVM hyperplanes that would be computed from the full support set, but it receives only a random subset of supports during training. This forces the Transformer to learn how to complete missing information and generalize across different Bongard problems.
- Core assumption: Learning to predict the output of simple baseline classifiers (prototypes or SVM) from partial information will result in a more robust and generalizable classifier than directly learning to classify queries.
- Evidence anchors:
  - [section 3.5] "Crucially, we use an asymmetric student-teacher setup: the teacher (i.e., averaging or SVM) uses all available supports, yielding 'clean' training targets. In fact, we allow the teachers to 'cheat' by using labelled queries as additional supports. The student (i.e., the Transformer) receives only a random subset of supports, forcing it to learn to complete missing information."
  - [section 3.5] "Another unique aspect of our approach is that we directly supervise the learning of (ideal) prototypes, or (max-margin) rules, with a regression loss. This is instead of supervising for the correct classification of queries, with for example a cross entropy loss."
- Break condition: If the teacher models (SVM or prototype averaging) are poor at capturing the key concept for a particular Bongard problem, the Transformer will learn to replicate these errors rather than find a better solution.

### Mechanism 3
- Claim: Cross-image context is critical for Bongard problems because the key concept often requires comparing multiple positive and multiple negative examples.
- Mechanism: Unlike standard few-shot learning where the concept is indicated only by positive examples, Bongard problems require understanding what distinguishes the positive class from the negative class by considering the full support set as a whole.
- Core assumption: The ability to solve Bongard problems depends on the model's capacity to extract features that capture the differences between positive and negative supports when considered jointly, rather than treating each support image independently.
- Evidence anchors:
  - [abstract] "This is a critical issue, because unlike in few-shot learning tasks concerning object classification, the 'key concept' in a typical Bongard problem can only be distinguished using multiple positives and multiple negatives."
  - [section 3.4] "The simple baselines in the previous subsection actually miss important contextual information, due to the fact that the features produced by the vision backbone are all independent. In other words, these baselines do not leverage information contained in the support set as a whole."
- Break condition: If the key concept in a Bongard problem can be determined from a single positive and a single negative example (rather than requiring comparison of multiple examples), the benefit of cross-image context would be minimal.

## Foundational Learning

- Concept: Feature standardization and normalization
  - Why needed here: Support-set standardization is the core technique for incorporating cross-image context, and understanding how standardization works is essential for implementing and debugging this method.
  - Quick check question: What is the difference between standardizing features using support-set statistics versus train-set statistics, and why does this difference matter for Bongard problems?

- Concept: Few-shot learning and meta-learning
  - Why needed here: Bongard problems are fundamentally few-shot learning tasks, and the paper builds on and extends existing few-shot learning techniques.
  - Quick check question: How does the support-set standardization technique differ from typical few-shot learning approaches that only use positive examples in the support set?

- Concept: Vision-language models and contrastive learning
  - Why needed here: The paper uses CLIP (a vision-language model trained with contrastive learning) as the vision backbone for natural image Bongard problems.
  - Quick check question: Why might CLIP work well as a vision backbone for Bongard-HOI but not for Bongard-LOGO, and what alternative approach does the paper use for abstract shape problems?

## Architecture Onboarding

- Component map:
  Vision backbone (CLIP or trained ResNet-12) -> Support-set standardization -> Simple baseline classifiers (Prototype, SVM, k-NN) OR Transformer encoder -> Regression loss

- Critical path:
  1. Encode images to feature vectors
  2. Standardize features using support-set statistics
  3. Apply baseline classifier (or Transformer) to predict query class
  4. For Transformer: compute teacher model output, apply support dropout and label noise, train Transformer to predict teacher output via regression loss

- Design tradeoffs:
  - Standardization vs. no standardization: Standardization incorporates cross-image context but may amplify noise in small or outlier-prone support sets
  - Simple baselines vs. Transformer: Simple baselines are parameter-free and interpretable but may miss complex patterns; Transformer can learn more sophisticated representations but requires training
  - Teacher model choice (Prototype vs. SVM): Prototypes are simpler but may be less discriminative; SVM can find max-margin decision boundaries but is more complex

- Failure signatures:
  - Low accuracy on both seen and unseen categories suggests vision backbone or feature extraction is inadequate
  - High variance in accuracy across different Bongard problems suggests sensitivity to support set composition
  - Accuracy improves with standardization but Transformer doesn't add value suggests the concept is simple enough for basic statistics to capture

- First 3 experiments:
  1. Implement and test support-set standardization with a simple prototype classifier on Bongard-LOGO
  2. Compare prototype classifier with and without standardization on a held-out validation set
  3. Implement SVM-Mimic approach and compare its performance to prototype-based approaches on Bongard-HOI

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the optimal methods for incorporating cross-image context into Bongard problem solutions?
- Basis in paper: [explicit] The paper discusses the importance of incorporating cross-image context for Bongard problems and explores various methods, including support-set standardization and Transformer-based approaches.
- Why unresolved: While the paper presents methods that improve performance, it does not definitively establish the optimal approach for incorporating cross-image context.
- What evidence would resolve it: Systematic comparison of different cross-image context incorporation methods on a wide range of Bongard problem datasets, including varying problem complexities and image types, could help determine the most effective approach.

### Open Question 2
- Question: How can Bongard problem-solving capabilities be scaled to more complex and diverse visual concepts?
- Basis in paper: [inferred] The paper mentions that Bongard problems can be made arbitrarily diverse and complex, and current machine learning methods struggle to solve them reliably. This suggests a need for scaling capabilities.
- Why unresolved: The paper does not address the scalability of Bongard problem-solving methods to more complex and diverse visual concepts.
- What evidence would resolve it: Developing and evaluating Bongard problem-solving methods on increasingly complex and diverse datasets, including those with abstract concepts and real-world images, could demonstrate the scalability of these approaches.

### Open Question 3
- Question: How can Bongard problem-solving methods be extended to handle more complex reasoning tasks, such as analogical reasoning or causal reasoning?
- Basis in paper: [inferred] The paper discusses the importance of Bongard problems in measuring abstract reasoning capabilities, suggesting that solving them involves reasoning beyond simple classification.
- Why unresolved: The paper does not explore the extension of Bongard problem-solving methods to handle more complex reasoning tasks.
- What evidence would resolve it: Evaluating Bongard problem-solving methods on tasks that require analogical reasoning or causal reasoning, such as Raven's Progressive Matrices or Bongard problems with causal relationships, could demonstrate the potential for extending these methods to more complex reasoning tasks.

## Limitations

- The paper doesn't establish whether cross-image context is universally critical across all Bongard problem types, particularly for problems with very small support sets where standardization could amplify noise
- The necessity of Transformers for learning set-level knowledge isn't thoroughly validated against simpler alternatives
- The method's performance on Bongard problems requiring relational reasoning between objects isn't explored

## Confidence

**High confidence**: The empirical results showing improved accuracy with support-set standardization (75.3% on Bongard-LOGO, 72.45% on Bongard-HOI, 60.84% on Bongard-Classic) are well-supported by the methodology and comparison to established baselines.

**Medium confidence**: The claim that cross-image context is the primary reason for prior methods' low accuracy is supported by ablation studies but could be confounded by other factors like feature quality or hyperparameter choices in previous work.

**Low confidence**: The assertion that Transformers are necessary for learning set-level knowledge is the least supported claim, as the paper doesn't thoroughly compare against alternative architectures or establish the minimum complexity required for this task.

## Next Checks

1. **Ablation on support set size**: Systematically test the standardization technique on Bongard problems with varying numbers of support examples per class (2, 3, 4, 5+) to identify the minimum effective support set size and determine when standardization becomes counterproductive due to statistical noise.

2. **Alternative set-level architectures**: Implement and compare simpler architectures (e.g., mean/max pooling of standardized features, attention-only models without positional encoding) against the Transformer approach to quantify the actual benefit of the Transformer's inductive bias for this specific task.

3. **Out-of-distribution generalization**: Test the trained models on Bongard problems with concepts that are semantically distant from those in the training data to evaluate whether the method truly learns generalizable reasoning capabilities or simply memorizes patterns from the specific datasets.