---
ver: rpa2
title: MAP- and MLE-Based Teaching
arxiv_id: '2307.05252'
source_url: https://arxiv.org/abs/2307.05252
tags:
- concept
- sampling
- then
- given
- map-td
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a probabilistic model of teaching for MAP
  and MLE learners. Learners are parameterized by priors and conditional likelihoods,
  and can operate in four sampling modes (ordered/unordered, with/without replacement).
---

# MAP- and MLE-Based Teaching

## Quick Facts
- arXiv ID: 2307.05252
- Source URL: https://arxiv.org/abs/2307.05252
- Reference count: 19
- Key outcome: This paper introduces a probabilistic model of teaching for MAP and MLE learners, proving desirable monotonicity properties and characterizing teaching dimensions for subset concepts with labeled examples via graph-theoretic matching numbers.

## Executive Summary
This paper presents a probabilistic model of teaching that extends the traditional framework by allowing learners to use Maximum a-posteriori (MAP) or Maximum likelihood estimation (MLE) inference. The learners are parameterized by priors and conditional likelihoods, and can operate in four sampling modes (ordered/unordered, with/without replacement). The teacher aims to find the smallest set of observations that causes the learner to return a target concept. The paper proves desirable monotonicity properties of the model and shows the equivalence and incomparability of different sampling modes.

## Method Summary
The method involves defining a concept class C, an observation set Z, and a consistency relation |= between concepts and observations. Learners are modeled as MAP or MLE estimators with specific priors and likelihoods. The teaching dimension is computed by finding the smallest teaching set that uniquely identifies the target concept under the learner's inference process. For subset concepts with labeled examples, the teaching dimension is characterized graph-theoretically via saturating matching numbers in bipartite graphs.

## Key Results
- The MAP- and MLE-based teaching model satisfies desirable monotonicity properties
- Different sampling modes are not universally comparable in teaching efficiency
- For subset concepts with labeled examples, teaching dimensions can be characterized exactly via graph-theoretic matching numbers
- The MLE teaching dimension exceeds the MAP teaching dimension by at most 1

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The MAP- and MLE-based teaching model satisfies monotonicity properties that make it more tractable than other models.
- Mechanism: Adding new observations reduces teaching dimension, while adding new concepts increases it.
- Core assumption: The learner parameters and consistency relations are well-defined and the teaching mapping is order-preserving.
- Evidence anchors:
  - [abstract] "We show that this teaching model has some desirable monotonicity properties."
  - [section 3.2] "Lemma 3.5 (Concept-Class Monotonicity)" and "Lemma 3.8 (Observation-Set Monotonicity)"
- Break condition: If the learner's likelihood functions violate the validity condition, monotonicity may fail.

### Mechanism 2
- Claim: Different sampling modes (ordered/unordered, with/without replacement) are not universally comparable in teaching efficiency.
- Mechanism: The optimal teaching dimension depends on the interplay between the concept class structure and the sampling assumptions.
- Core assumption: The concept class and observation space allow for distinct optimal teaching sets under different sampling assumptions.
- Evidence anchors:
  - [abstract] "We clarify how the four sampling modes are related to each other."
  - [section 3.3] "Theorem 3.12" and the lemmas proving pairwise incomparability of sampling modes
- Break condition: If all concepts have identical likelihood profiles across sampling modes, the modes may become equivalent.

### Mechanism 3
- Claim: For subset concepts with labeled examples, the teaching dimension can be characterized exactly via graph-theoretic matching numbers.
- Mechanism: The bipartite graph of concept-observation consistency encodes the minimal teaching sets; saturating matchings correspond to optimal teachers.
- Core assumption: The concept class can be represented as subsets of a finite domain and observations are labeled examples.
- Evidence anchors:
  - [abstract] "we obtain some additional results. First of all, we characterize the MAP- and MLE-teaching dimension ... graph-theoretically."
  - [section 4] "Theorem 4.2" and "Corollary 4.3"
- Break condition: If concepts are probabilistic or not subsets, the graph-theoretic characterization may not apply.

## Foundational Learning

- Concept: Maximum a-posteriori (MAP) and maximum likelihood estimation (MLE) inference
  - Why needed here: The teaching model assumes learners use MAP or MLE to infer concepts from observations.
  - Quick check question: What is the difference between MAP and MLE inference, and when would one be preferred over the other?

- Concept: Consistency relations between concepts and observations
  - Why needed here: The validity condition and teaching strategies rely on concepts being consistent with certain observations.
  - Quick check question: Given a concept and observation space, how do you define and check consistency?

- Concept: Saturating matchings in bipartite graphs
  - Why needed here: The teaching dimension for subset concepts is characterized by the smallest order of a C-saturating matching.
  - Quick check question: What is a saturating matching, and how do you find one of minimum order in a bipartite graph?

## Architecture Onboarding

- Component map:
  - Concept class (C) and observation space (Z) definition
  - Learner model (MAP or MLE) with parameters (priors and likelihoods)
  - Sampling mode (ordered/unordered, with/without replacement) specification
  - Teaching algorithm to find minimal teaching sets
  - Graph-theoretic subroutines for matching-based characterization

- Critical path:
  1. Define C, Z, and consistency relation
  2. Specify learner parameters and sampling mode
  3. Compute MAP-TD or MLE-TD using direct optimization or graph-theoretic characterization
  4. Verify monotonicity and incomparability properties as needed

- Design tradeoffs:
  - Direct optimization of teaching sets vs. graph-theoretic characterization
  - General probabilistic concepts vs. subset concepts with labeled examples
  - Uniform vs. non-uniform priors for MAP learners

- Failure signatures:
  - Non-existence of teaching sets (infinite teaching dimension)
  - Non-unique maximizers in learner inference (question marks returned)
  - Violation of validity condition in learner parameters

- First 3 experiments:
  1. Verify monotonicity properties for a simple concept class and observation space
  2. Compare teaching dimensions under different sampling modes for a given concept class
  3. Compute teaching dimensions using both direct optimization and graph-theoretic characterization for subset concepts with labeled examples

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the optimal parameterizations of MAP and MLE learners that lead to the smallest teaching dimensions?
- Basis in paper: [explicit] The paper discusses "natural parameterizations" of MAP and MLE learners and poses this as an open problem.
- Why unresolved: The paper does not provide specific optimal parameterizations, only proving bounds and properties.
- What evidence would resolve it: Constructing and proving optimality of specific parameterizations for various concept classes.

### Open Question 2
- Question: Does MAP-based teaching of naturally parameterized learners result in intuitive examples that illustrate the target concept well?
- Basis in paper: [explicit] The paper raises this as an open question about the pedagogical value of MAP-based teaching.
- Why unresolved: The paper focuses on theoretical properties and does not evaluate the intuitive quality of teaching sets.
- What evidence would resolve it: User studies comparing teaching sets from MAP-based teaching to human-selected examples.

### Open Question 3
- Question: What is the computational complexity of computing the MAP-teaching dimension for different sampling modes?
- Basis in paper: [explicit] The paper shows MAP-teaching dimension can be computed in polynomial time for certain cases, but does not analyze complexity for all sampling modes.
- Why unresolved: The paper only proves polynomial-time computability for (O,R) mode, not for (O,R) and (O,R) modes.
- What evidence would resolve it: Complexity analysis proving P or NP-hardness for computing MAP-teaching dimension in different sampling modes.

## Limitations
- The framework assumes well-defined priors and likelihoods, which may not hold in real-world teaching scenarios
- The graph-theoretic characterization is limited to subset concepts with labeled examples and may not extend to more complex concept structures
- The paper does not evaluate the pedagogical value or intuitive quality of teaching sets generated by the MAP-based approach

## Confidence
- **High Confidence**: Monotonicity properties and their proofs (Lemmas 3.5, 3.8)
- **Medium Confidence**: Incomparability results between sampling modes (Theorem 3.12)
- **Medium Confidence**: Graph-theoretic characterization for subset concepts (Theorem 4.2)
- **Low Confidence**: Bounds relating teaching dimensions to VC-dimension and antichain number (Corollaries 4.4, 4.5)

## Next Checks
1. Implement the teaching dimension computation algorithm and verify it against known examples from the paper
2. Test the monotonicity properties on concept classes not covered in the paper to check generalizability
3. Empirically compare the four sampling modes on a diverse set of concept classes to validate incomparability claims