---
ver: rpa2
title: A store-and-forward cloud-based telemonitoring system for automatic assessing
  dysarthria evolution in neurological diseases from video-recording analysis
arxiv_id: '2309.09038'
source_url: https://arxiv.org/abs/2309.09038
tags:
- facial
- speech
- dysarthria
- system
- landmark
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces Homely Care, a cloud-based store-and-forward
  telemonitoring system for quantitative assessment of dysarthria evolution in neurological
  diseases. The system integrates a modified Mask R-CNN architecture for facial landmark
  detection, trained on the Toronto NeuroFace dataset of patients with ALS and stroke.
---

# A store-and-forward cloud-based telemonitoring system for automatic assessing dysarthria evolution in neurological diseases from video-recording analysis

## Quick Facts
- arXiv ID: 2309.09038
- Source URL: https://arxiv.org/abs/2309.09038
- Reference count: 40
- Key outcome: Homely Care achieves 1.79 NME for 68 facial landmark detection in ALS patients

## Executive Summary
This work introduces Homely Care, a cloud-based store-and-forward telemonitoring system for quantitative assessment of dysarthria evolution in neurological diseases. The system integrates a modified Mask R-CNN architecture for facial landmark detection, trained on the Toronto NeuroFace dataset of patients with ALS and stroke. The network achieved a normalized mean error of 1.79 for locating 68 facial landmarks and was tested on 11 bulbar-onset ALS patients, showing robust performance under varied lighting and positioning conditions. The system supports remote motor speech assessment via consumer devices and is designed for scalability and integration with other evaluation tasks.

## Method Summary
The system uses a modified Mask R-CNN with ResNet50 backbone and FPN, pre-trained on 300-VW dataset then fine-tuned on Toronto NeuroFace dataset (ALS, stroke, healthy subjects). The model detects 68 facial landmarks through a region proposal network and modified mask branch with transposed convolutions. Videos are captured via ReactJS web app with positioning guidance, uploaded to AWS S3, processed by Lambda functions triggered from SQS queues, and results stored in DynamoDB for clinician review.

## Key Results
- Achieved 1.79 NME for locating 68 facial landmarks in Toronto NeuroFace test set
- Successfully tested on 11 bulbar-onset ALS patients using consumer devices
- Cloud architecture scales automatically with message queue load

## Why This Works (Mechanism)

### Mechanism 1
The modified Mask R-CNN architecture reliably localizes 68 facial landmarks in neurological patients under varied lighting and positioning. The CNN first detects faces via a region proposal network, then regresses landmark coordinates using a modified mask branch with additional transposed convolutions for higher-resolution output. The backbone (ResNet50 + FPN) extracts sufficient hierarchical features to capture subtle facial muscle movements even in dysarthric subjects.

### Mechanism 2
The store-and-forward cloud architecture scales efficiently to handle multimedia uploads and DL processing from multiple users. AWS Lambda functions consume messages from SQS queues, each processing a batch of video files, allowing automatic scaling proportional to load. Processing latency of ~10 min per task is acceptable because clinical monitoring is non-real-time.

### Mechanism 3
The web app guides users to record in optimal conditions, improving CNN performance. Overlay ellipse provides real-time feedback on face positioning; countdown prepares user; clear task instructions reduce recording errors. User compliance with positioning guidance reduces extreme angles/occlusions that the CNN struggles with.

## Foundational Learning

- Concept: Convolutional Neural Networks for object detection
  - Why needed here: The backbone and RPN must detect faces before landmark regression can occur
  - Quick check question: What are the roles of the backbone, RPN, and RoI Align layers in a Mask R-CNN?

- Concept: Cloud-based serverless architectures
  - Why needed here: Lambda functions and SQS queues enable automatic scaling without managing servers
  - Quick check question: How does polling from an SQS queue trigger Lambda scaling in AWS?

- Concept: Normalized Mean Error as evaluation metric
  - Why needed here: NME allows comparison of landmark localization accuracy across different face sizes
  - Quick check question: How is the NME formula normalizing for face size, and why is that important?

## Architecture Onboarding

- Component map: Frontend (ReactJS web app) -> AWS S3 (storage) -> SQS queue -> Lambda functions (processing) -> DynamoDB (metadata) -> Clinician dashboard

- Critical path:
  1. User records video via web app
  2. Web app uploads .zip to S3
  3. Orchestrator Lambda detects new file, decompresses, sends to consumer queue
  4. Consumer Lambda processes video frames through CNN, saves landmark positions
  5. Clinician views results in dashboard

- Design tradeoffs:
  - Store-and-forward vs real-time: Reduces compute cost but delays feedback
  - Consumer-device flexibility vs model performance: Wider access but variable video quality
  - Fine-tuning vs from-scratch training: Higher accuracy but requires labeled pathology data

- Failure signatures:
  - Lambda timeouts → increase memory/timeout settings
  - High NME → retrain with more diverse lighting/expressions
  - Upload failures → check S3 bucket policies and network connectivity

- First 3 experiments:
  1. Test CNN on Toronto NeuroFace test set and record NME per facial region
  2. Simulate concurrent uploads to verify SQS/Lambda scaling
  3. Run end-to-end flow with synthetic videos mimicking patient conditions

## Open Questions the Paper Calls Out

### Open Question 1
How does the proposed facial landmark mask RCNN perform on patients with neurological diseases other than ALS and stroke, such as Parkinson's disease or multiple sclerosis? The study focused on ALS and stroke, and there is a lack of data on the system's applicability to other diseases that also affect facial muscle control.

### Open Question 2
What is the impact of different lighting conditions and backgrounds on the accuracy of the facial landmark detection in real-world scenarios? The study provides qualitative results but lacks a comprehensive quantitative analysis of the system's performance under diverse environmental conditions.

### Open Question 3
How does the Homely Care system integrate with existing clinical workflows and what is the user experience from both the patient and clinician perspectives? The study focuses on the technical development and initial testing of the system but does not explore its real-world usability and acceptance by end-users.

## Limitations

- Clinical validity remains untested - no comparison to expert clinician assessments
- Small test set (11 ALS patients) limits generalizability claims
- Unknown performance on other neurological conditions beyond ALS and stroke
- No detailed analysis of robustness to extreme lighting or background variations

## Confidence

- Facial landmark detection accuracy: High confidence in reported NME (1.79) on Toronto NeuroFace test set
- Cloud architecture scalability: Medium confidence based on AWS documentation but no load testing reported
- Clinical utility for dysarthria assessment: Low confidence due to lack of clinical validation

## Next Checks

1. Conduct a clinical validation study comparing system outputs to expert clinician assessments of speech and orofacial function in a larger, diverse patient cohort
2. Perform stress testing of the cloud infrastructure under simulated concurrent upload loads from 100+ users
3. Evaluate model robustness by testing on videos with varying lighting conditions, face orientations, and occlusions to identify performance degradation thresholds