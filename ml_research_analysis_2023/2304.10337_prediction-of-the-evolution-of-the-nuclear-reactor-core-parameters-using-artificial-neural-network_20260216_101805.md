---
ver: rpa2
title: Prediction of the evolution of the nuclear reactor core parameters using artificial
  neural network
arxiv_id: '2304.10337'
source_url: https://arxiv.org/abs/2304.10337
tags:
- uni00000010
- uni00000013
- core
- nuclear
- reactor
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work explored the application of artificial neural networks
  to predict nuclear reactor core parameters, aiming to accelerate reactor design
  processes. A neural network was trained using data generated by the PARCS reactor
  physics simulator for a Westinghouse PWR core model based on the MIT BEAVRS benchmark.
---

# Prediction of the evolution of the nuclear reactor core parameters using artificial neural network

## Quick Facts
- arXiv ID: 2304.10337
- Source URL: https://arxiv.org/abs/2304.10337
- Reference count: 29
- This work demonstrates that artificial neural networks can predict nuclear reactor core parameters with high accuracy, achieving relative errors of 0.43% for reactivity and 0.91% for cycle length.

## Executive Summary
This study explores the application of artificial neural networks to predict nuclear reactor core parameters, specifically reactivity evolution and cycle length, based on core loading patterns. The research utilizes the PARCS reactor physics simulator to generate training data for a Westinghouse PWR core model based on the MIT BEAVRS benchmark. By converting fuel assembly types to cycle lengths and normalizing the data, the neural network successfully learns the complex relationship between loading patterns and core behavior. The optimal architecture uses 64 neurons in each hidden layer with a 0.1 dropout rate, achieving high prediction accuracy that demonstrates the potential to replace resource-intensive simulator runs in reactor design processes.

## Method Summary
The researchers trained a neural network to predict nuclear reactor core parameters by first generating 10,000 random reactor core configurations using the PARCS simulator for a Westinghouse PWR model. The input data consisted of 32 integers representing fuel assemblies in 1/8th core symmetry, which were preprocessed by converting assembly types to their corresponding cycle lengths. The network architecture included two hidden layers with 64 neurons each, GELU activation functions, and dropout layers for regularization. The model was trained to predict 38 output parameters including reactivity progression throughout the fuel cycle and total cycle length. Data normalization to mean=0 and standard deviation=1 was applied before training with the Adam optimizer and MSE loss function.

## Key Results
- Reactivity predictions achieved an average relative error of 0.43% compared to PARCS simulations
- Cycle length predictions achieved a relative error of 0.91%
- The optimal network architecture used 64 neurons per hidden layer with 0.1 dropout rate
- Data preprocessing through assembly type conversion improved learning efficiency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural network can approximate PARCS-simulated reactivity evolution with high accuracy using only core loading patterns as input.
- Mechanism: The network learns a continuous mapping from 32-dimensional loading pattern vectors to 38-dimensional output vectors representing reactivity at multiple time steps and cycle length, capturing reactor physics trends through supervised training.
- Core assumption: The relationship between core loading patterns and reactivity evolution is smooth and deterministic enough for a sufficiently deep network to approximate.
- Evidence anchors:
  - [abstract] "predictions for reactivity showed an average relative error of 0.43%... cycle length predictions achieved a relative error of 0.91%"
  - [section] "For the selected best architecture predictions were made for different core parameters and their dependence on core loading patterns"
  - [corpus] Weak - no direct neighbor evidence for this specific surrogate approach, though related papers discuss AI in reactor physics
- Break condition: If reactor physics becomes highly nonlinear due to complex feedback loops or stochastic phenomena not captured in PARCS training data.

### Mechanism 2
- Claim: Proper data preprocessing (converting assembly types to cycle lengths) improves ANN learning by encoding domain knowledge into features.
- Mechanism: Replacing discrete assembly type IDs with their corresponding single-assembly cycle lengths creates a feature space that better reflects physical performance characteristics, aiding gradient-based optimization.
- Core assumption: The single-assembly cycle length is a meaningful proxy for the assembly's contribution to overall core reactivity evolution.
- Evidence anchors:
  - [section] "the input data was modified by conversion of numbers of fuel assemblies (integers 1-9) into cycle lengths"
  - [section] "It was believed that it will improve the learning process, as after this conversion the input data could reflect, to some extent, features of the fuel assemblies"
  - [corpus] Missing - no neighbor papers discuss this specific preprocessing strategy
- Break condition: If the linear approximation of single-assembly behavior breaks down in multi-assembly configurations.

### Mechanism 3
- Claim: Dropout regularization prevents overfitting while maintaining sufficient network capacity for accurate predictions.
- Mechanism: Randomly zeroing neuron connections during training forces the network to learn redundant representations, improving generalization to unseen loading patterns.
- Core assumption: The validation/test error trends observed during architecture search generalize to the final trained model's performance.
- Evidence anchors:
  - [section] "between the two hidden layers and between the last hidden layer and the output layer, a so-called dropout layer was added"
  - [section] "The process of randomly zeroing certain connections in a neural network allows for achieving better accuracy of network predictions"
  - [corpus] Weak - neighbor papers discuss AI in reactor physics but don't specifically address dropout regularization
- Break condition: If dropout rate is too high, causing underfitting and poor accuracy on both training and test data.

## Foundational Learning

- Concept: Reactor physics fundamentals (neutron diffusion, criticality, reactivity)
  - Why needed here: Understanding what the ANN is predicting and why certain input features matter
  - Quick check question: What physical quantity does "keff" represent and how does it relate to reactor criticality?

- Concept: Neural network training fundamentals (loss functions, backpropagation, optimization)
  - Why needed here: The paper uses MSE loss, Adam optimizer, and backpropagation - understanding these is crucial for interpreting results
  - Quick check question: Why might the authors have chosen Adam optimizer over standard SGD for this problem?

- Concept: Data preprocessing and feature engineering
  - Why needed here: The conversion of assembly types to cycle lengths and normalization are key to the approach's success
  - Quick check question: What is the purpose of normalizing input features before training a neural network?

## Architecture Onboarding

- Component map: Input layer (32 neurons) → Hidden layer 1 (64 neurons, GELU) → Dropout (0.1) → Hidden layer 2 (64 neurons, GELU) → Dropout (0.1) → Output layer (38 neurons)
- Critical path: Data generation → preprocessing → model training → prediction validation
- Design tradeoffs: Larger networks might capture more complex relationships but risk overfitting; smaller networks train faster but may underfit
- Failure signatures: High validation loss indicating overfitting; low training loss but high test error indicating poor generalization
- First 3 experiments:
  1. Train with 32-64-64-38 architecture, no dropout, measure overfitting
  2. Add dropout layers, compare validation loss curves
  3. Test different activation functions (ReLU vs GELU) while keeping architecture constant

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would varying the sampling density of PARCS simulation data throughout the fuel cycle affect ANN prediction accuracy?
- Basis in paper: [explicit] The authors note that "processes at the beginning of the cycle are more complex they may require denser sampling" but did not explore this in their study.
- Why unresolved: The study used uniform sampling intervals throughout the cycle, despite observing that early-cycle reactivity deviations were larger than later-cycle deviations.
- What evidence would resolve it: Systematic comparison of ANN performance using different sampling densities for early-cycle vs. late-cycle data points.

### Open Question 2
- Question: Could additional reactor parameters beyond reactivity and cycle length be reliably predicted using the same ANN architecture?
- Basis in paper: [inferred] The authors mention that the PARCS output files contain "a huge amount of parameters that were not used in these studies" and suggest potential future work to predict parameters like poison concentrations or fuel temperatures.
- Why unresolved: The study focused only on reactivity evolution and cycle length prediction, leaving the feasibility of predicting other core parameters unexplored.
- What evidence would resolve it: Testing the ANN architecture with different combinations of reactor parameters as outputs and measuring prediction accuracy for each.

### Open Question 3
- Question: How does the ANN's prediction uncertainty compare to traditional uncertainty quantification methods in nuclear reactor simulations?
- Basis in paper: [explicit] The authors state that "comparing the uncertainties resulting from the use of a simulator...it can be said that the data obtained based on neural network predictions have very similar or sometimes lower levels of uncertainty values."
- Why unresolved: The paper provides a qualitative comparison but does not present quantitative uncertainty analysis comparing ANN predictions to traditional methods.
- What evidence would resolve it: Systematic uncertainty quantification comparing ANN predictions against Monte Carlo or other traditional uncertainty methods for the same reactor parameters.

## Limitations

- The approach is constrained to the specific Westinghouse PWR configuration based on MIT BEAVRS benchmark data, limiting generalizability to different reactor designs
- The conversion of fuel assembly types to cycle lengths as preprocessing lacks theoretical justification and may not generalize to other reactor types
- The use of PARCS-generated synthetic data may not capture all real-world physics phenomena, potentially limiting robustness to operational uncertainties

## Confidence

- **High Confidence**: The neural network architecture successfully predicts reactivity and cycle length within stated error margins on the test dataset
- **Medium Confidence**: The approach can generalize to similar PWR configurations with comparable loading patterns and operating conditions
- **Low Confidence**: The preprocessing strategy (converting assembly types to cycle lengths) is universally optimal for nuclear reactor parameter prediction tasks

## Next Checks

1. Test the trained model on out-of-distribution loading patterns (e.g., with fuel shuffling strategies not seen during training) to assess generalization limits
2. Validate predictions against real-world reactor operational data rather than solely relying on PARCS-simulated data
3. Compare the proposed approach with alternative machine learning methods (e.g., random forests, gradient boosting) to establish its relative performance and efficiency