---
ver: rpa2
title: 'Efficiently Tackling Million-Dimensional Multiobjective Problems: A Direction
  Sampling and Fine-Tuning Approach'
arxiv_id: '2304.04067'
source_url: https://arxiv.org/abs/2304.04067
tags:
- e-01
- directions
- algorithm
- e-02
- optimization
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a framework called VMOF for solving very large-scale
  multiobjective optimization problems (VLSMOPs) with more than 100,000 decision variables.
  The core idea is to model VLSMOPs as a recommender system problem, where solutions
  are treated as users and evolutionary directions as items.
---

# Efficiently Tackling Million-Dimensional Multiobjective Problems: A Direction Sampling and Fine-Tuning Approach

## Quick Facts
- arXiv ID: 2304.04067
- Source URL: https://arxiv.org/abs/2304.04067
- Reference count: 40
- Key outcome: VMOF framework transforms VLSMOPs into recommender system problems using Thompson sampling for direction recommendation, achieving superior performance on problems up to 1,000,000 dimensions.

## Executive Summary
This paper introduces VMOF, a novel framework for solving very large-scale multiobjective optimization problems (VLSMOPs) with more than 100,000 decision variables. The core innovation transforms the VLSMOP into a recommender system problem where solutions are treated as users and evolutionary directions as items. Thompson sampling recommends optimal directions for each solution, followed by a fine-tuning process to refine these recommendations. The method demonstrates superior performance compared to existing algorithms, particularly in high-dimensional scenarios.

## Method Summary
VMOF addresses VLSMOPs by modeling them as recommender systems where solutions are users and evolutionary directions are items. The framework uses Thompson sampling to recommend promising directions for each solution based on limited function evaluations. After initial recommendations, a fine-tuning process creates local populations around recommended directions and applies evolutionary operators to refine the search. The approach is tested on benchmark problems LSMOP1-LSMOP9 and real-world TREE problems with dimensions ranging from 100 to 1,000,000.

## Key Results
- VMOF achieves superior performance on benchmark problems LSMOP1-LSMOP9 with dimensions up to 1,000,000
- The method outperforms existing algorithms, particularly in high-dimensional scenarios
- IGD and HV metrics show consistent improvement over NSGA-II and other baseline algorithms

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transforming VLSMOPs into a recommender system problem enables scalable direction sampling under limited function evaluations.
- Mechanism: Treats each solution as a user and each evolutionary direction as an item, using Thompson sampling to recommend promising directions.
- Core assumption: Optimal directions can be inferred from small number of evaluations using Thompson sampling's probabilistic model.
- Evidence anchors: Thompson sampling effectiveness in recommending from large item sets within limited evaluations.

### Mechanism 2
- Claim: Fine-tuning recommended directions locally preserves exploration while refining exploitation.
- Mechanism: Creates population of nearby directions around recommendations and uses evolutionary operators for refinement.
- Core assumption: Local neighborhood around recommended direction contains good approximation of optimal direction.
- Evidence anchors: Manuscript provides design details but lacks external literature support.

### Mechanism 3
- Claim: Dynamic Thompson sampling variant adapts to non-stationary solution quality during evolution.
- Mechanism: Beta distribution parameters updated dynamically after each evaluation.
- Core assumption: Direction quality changes as population evolves.
- Evidence anchors: Dynamic Thompson sampling strategy presented in Algorithm 1.

## Foundational Learning

- Concept: Thompson sampling in multi-armed bandit problems
  - Why needed here: Core mechanism for recommending directions under limited evaluations.
  - Quick check question: What are the parameters α and β in the Beta distribution used for Thompson sampling, and how are they updated?

- Concept: Pareto dominance and non-dominated sorting
  - Why needed here: Algorithm uses dominance relations to evaluate solution quality and update Thompson sampling parameters.
  - Quick check question: How is the reward r_ij defined in terms of Pareto dominance in this algorithm?

- Concept: Decision variable grouping and dimensionality reduction in LSMOPs
  - Why needed here: Context for why existing LSMOP algorithms fail at 100k+ dimensions.
  - Quick check question: What is the primary challenge of LSMSMOPs that existing algorithms cannot address at very large scales?

## Architecture Onboarding

- Component map: Thompson Sampling Module -> Direction Fine-Tuning Module -> Evolution Engine -> Partitioning Logic
- Critical path: 1) Initialize population and directions 2) Partition into groups 3) Thompson sampling to recommend directions 4) Fine-tune directions locally 5) PSO evolution 6) Repeat until termination
- Design tradeoffs:
  - Thompson sampling vs. greedy selection: Balances exploration/exploitation vs. faster but riskier local minima
  - Direction population size vs. evaluation budget: Larger populations improve granularity but increase cost
  - Partitioning randomness vs. structure: Random grouping avoids bias but may miss structured relationships
- Failure signatures:
  - Stagnant IGD: Poor Thompson sampling recommendations or stuck fine-tuning
  - Increasing runtime without improvement: Direction population too large relative to budget
  - Oscillating metrics: Non-stationary reward updates causing unstable recommendations
- First 3 experiments:
  1. Run on LSMOP1 with 100k dimensions, compare IGD to NSGA-II baseline
  2. Vary nd (number of sampled directions) and measure impact on IGD and runtime
  3. Replace Thompson sampling with random selection and observe degradation

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of VMOF scale with problem dimensions beyond 1,000,000?
- Basis in paper: [explicit] Paper tests VMOF on problems up to 1,000,000 dimensions but does not explore higher dimensions.
- Why unresolved: Experimental section only covers dimensions up to 1,000,000.
- What evidence would resolve it: Additional experiments testing VMOF on problems with dimensions exceeding 1,000,000.

### Open Question 2
- Question: How does the Thompson sampling-based direction recommendation compare to other bandit algorithms?
- Basis in paper: [explicit] Paper uses Thompson sampling but does not compare to other bandit algorithms like UCB or epsilon-greedy.
- Why unresolved: While Thompson sampling works well, other bandit algorithms might perform better or worse.
- What evidence would resolve it: Comparative experiments using different bandit algorithms for direction recommendation.

### Open Question 3
- Question: How sensitive is VMOF's performance to the number of recommended directions (nd) in extremely high-dimensional spaces?
- Basis in paper: [explicit] Sensitivity analysis on nd conducted but only for dimensions up to 20,000.
- Why unresolved: Analysis limited to lower dimensions; unclear how nd affects performance in very high-dimensional spaces.
- What evidence would resolve it: Additional sensitivity analysis experiments testing different nd values on problems with 1,000,000+ dimensions.

## Limitations
- Thompson sampling scalability unproven beyond 1,000,000 dimensions
- Fine-tuning mechanism lacks external literature validation
- Computational efficiency concerns for truly massive problems

## Confidence

- Thompson sampling effectiveness in recommender transformation: Medium
- Fine-tuning mechanism performance: Low
- Overall framework scalability claims: Medium

## Next Checks
1. Implement the framework and test on LSMOP1 with 100k dimensions, comparing IGD convergence rates against NSGA-II baseline.
2. Conduct ablation studies varying the number of sampled directions (nd) to identify the sweet spot between computational cost and solution quality.
3. Replace Thompson sampling with random direction selection to quantify the actual contribution of the recommender system approach.