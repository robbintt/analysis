---
ver: rpa2
title: Locally Differentially Private Document Generation Using Zero Shot Prompting
arxiv_id: '2310.16111'
source_url: https://arxiv.org/abs/2310.16111
tags:
- privacy
- score
- language
- dp-prompt
- chatgpt
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents DP-Prompt, a locally differentially private
  mechanism for document generation that uses zero-shot prompting with large language
  models to defend against author de-anonymization attacks. The approach prompts a
  pretrained language model to generate paraphrases of private documents, which are
  then released as sanitized documents.
---

# Locally Differentially Private Document Generation Using Zero Shot Prompting

## Quick Facts
- arXiv ID: 2310.16111
- Source URL: https://arxiv.org/abs/2310.16111
- Authors: 
- Reference count: 40
- Primary result: Achieves 46% reduction in author identification F1 score against static attackers using zero-shot prompting with LLMs

## Executive Summary
This paper introduces DP-Prompt, a locally differentially private mechanism that uses zero-shot prompting with large language models to generate document paraphrases that defend against author de-anonymization attacks. The approach prompts a pretrained LLM to generate paraphrases of private documents using higher decoding temperatures, introducing controlled semantic variation while preserving meaning. When applied with ChatGPT (gpt-3.5), DP-Prompt achieves significant reductions in author identification F1 score while perfectly recovering sentiment classification performance.

## Method Summary
DP-Prompt works by prompting a pretrained large language model to generate paraphrases of private documents using zero-shot prompting. The method leverages temperature scaling during text generation to provide local differential privacy guarantees, with higher temperatures offering stronger privacy protection. The approach is implemented using HuggingFace library with logit clipping and temperature scaling, and can be applied to various LLMs including both proprietary models like ChatGPT and open-source models up to 7 billion parameters.

## Key Results
- Achieves 46% reduction in author identification F1 score against static attackers on IMDB dataset
- Achieves 26% reduction in author identification F1 score against adaptive attackers on IMDB dataset
- Perfectly recovers clean sentiment F1 score while providing privacy guarantees

## Why This Works (Mechanism)

### Mechanism 1
Zero-shot prompting with large language models can generate document paraphrases that reduce author identification without harming downstream utility. The method prompts a pretrained LLM to generate paraphrases of private documents using higher decoding temperatures, introducing controlled semantic variation while preserving meaning. Core assumption: LLMs have sufficient generalization capability to paraphrase documents they haven't been explicitly fine-tuned on.

### Mechanism 2
High decoding temperature in text generation provides local differential privacy. By sampling tokens from the softmax distribution with higher temperature, the generation process introduces enough randomness to satisfy LDP guarantees. Core assumption: Logits are bounded within a known range, allowing for proper sensitivity calculation.

### Mechanism 3
Higher temperatures improve privacy but may degrade utility in some models. Temperature controls the trade-off between privacy and utility - higher temperatures provide stronger privacy guarantees but may reduce semantic fidelity. Core assumption: Different LLMs have different temperature-utility-privacy curves.

## Foundational Learning

- **Differential Privacy (DP) and Local Differential Privacy (LDP)**: Why needed here - The paper relies on DP/LDP to provide formal privacy guarantees for document generation. Quick check: What is the difference between global DP and local DP, and why is LDP more appropriate for document generation?

- **Text generation and temperature scaling**: Why needed here - The method uses temperature scaling in text generation to achieve LDP guarantees. Quick check: How does temperature affect the softmax distribution in text generation, and why does higher temperature provide better privacy?

- **Author attribution and linguistic fingerprinting**: Why needed here - The paper targets author de-anonymization attacks, which rely on identifying linguistic patterns. Quick check: What linguistic features are commonly used for author attribution, and how does paraphrasing disrupt these patterns?

## Architecture Onboarding

- **Component map**: Private document → Prompt template → LLM generation (with temperature) → Sanitized document
- **Critical path**: Document input → Prompt generation → Temperature-controlled sampling → Output sanitization
- **Design tradeoffs**: Temperature vs utility tradeoff, model size vs performance, logit clipping vs generation quality
- **Failure signatures**: Low utility despite high privacy (temperature too high), high privacy risk despite sanitization (temperature too low), model memorization issues
- **First 3 experiments**:
  1. Test DP-Prompt with different temperatures on a small dataset and measure author identification F1 vs sentiment F1
  2. Compare DP-Prompt with existing word-level and sentence-level mechanisms on the same dataset
  3. Test the effect of logit clipping on utility-privacy tradeoff for open-source models

## Open Questions the Paper Calls Out

- **Open Question 1**: How does DP-Prompt perform when applied to document types other than online reviews, such as emails, medical records, or legal documents? The paper only evaluates DP-Prompt on IMDB movie reviews and Yelp business reviews, which are both online review datasets.

- **Open Question 2**: What is the impact of different prompt templates on the privacy-utility tradeoff in DP-Prompt? The paper only uses a single prompt template ("Paraphrase of the document:") in its experiments.

- **Open Question 3**: How does DP-Prompt compare to other document-level privacy mechanisms when applied to open-source language models? The paper compares DP-Prompt to word-level and sentence-level mechanisms when applied to open-source models but lacks direct comparison with other document-level mechanisms.

## Limitations

- The paper does not empirically verify that the bounded logit assumption required for LDP guarantees holds for the specific models used
- Evaluation is limited to sentiment preservation as the sole utility metric, leaving questions about other downstream tasks
- Results are only tested against static and adaptive attackers based on text and embedding similarities, not more sophisticated authorship attribution methods

## Confidence

- **High Confidence**: The empirical results showing DP-Prompt's effectiveness in reducing author identification F1 scores (46% reduction for static attackers, 26% for adaptive attackers) on the IMDB dataset are well-supported by the experimental methodology and comparisons with baselines.

- **Medium Confidence**: The theoretical LDP guarantees provided by Theorem 1 are mathematically sound given the stated assumptions, but the paper does not verify that these assumptions hold in practice for the specific LLMs used.

- **Low Confidence**: The generalizability of results across different document types and domains beyond movie reviews and business reviews is not established.

## Next Checks

1. **Logit Distribution Analysis**: Conduct empirical analysis of the actual logit distributions from the LLMs used to verify the boundedness assumption required for Theorem 1, including measuring sensitivity across different temperature settings.

2. **Ablation Study on Prompt Design**: Perform controlled experiments varying the prompt templates and zero-shot instructions to isolate how much of DP-Prompt's effectiveness comes from the LLM's paraphrasing capability versus the DP mechanism itself.

3. **Cross-Domain Utility Testing**: Evaluate DP-Prompt's utility preservation on a broader range of downstream tasks beyond sentiment analysis, including named entity recognition, topic classification, and question answering.