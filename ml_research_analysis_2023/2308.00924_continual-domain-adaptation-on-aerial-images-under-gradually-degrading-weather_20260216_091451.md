---
ver: rpa2
title: Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather
arxiv_id: '2308.00924'
source_url: https://arxiv.org/abs/2308.00924
tags:
- adaptation
- domain
- target
- continual
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper creates four benchmark datasets for continual domain
  adaptation under gradually degrading weather conditions, using cloud cover and snowfall
  augmentations on real aerial imagery. The authors evaluate one standard and two
  continual domain adaptation models, discovering significant stability issues in
  buffer-fed methods.
---

# Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather

## Quick Facts
- **arXiv ID**: 2308.00924
- **Source URL**: https://arxiv.org/abs/2308.00924
- **Reference count**: 40
- **Primary result**: Gradient normalization improves stability of continual domain adaptation under gradually degrading weather conditions on aerial imagery

## Executive Summary
This paper addresses the challenge of continual domain adaptation on aerial images as weather conditions progressively degrade. The authors create four benchmark datasets by applying cloud cover and snowfall augmentations to real aerial imagery datasets (AID and UCM), simulating gradual weather deterioration. They evaluate standard and continual domain adaptation models, discovering significant stability issues in buffer-fed methods. The paper proposes gradient normalization as a solution, demonstrating that it stabilizes adaptation while generally improving performance. Transformer backbones (ViT and Swin) show superior performance compared to ResNet-50 across the evaluated models.

## Method Summary
The authors develop four benchmark datasets by applying weather degradation augmentations to aerial imagery datasets AID and UCM. Cloud cover degradation creates 7 levels from clear to heavy cloud cover, while snowfall degradation creates 5 levels from clear to heavy snowfall. Three domain adaptation models are evaluated: Continual-SHOT (standard DA under continual setting), ConDA, and UCL-GV (buffer-fed continual DA methods). The models adapt to sequentially presented batches representing increasingly degraded weather conditions, with gradient normalization applied to stabilize the adaptation process.

## Key Results
- Continual domain adaptation models significantly outperform standard approaches on the created benchmarks
- Attention-based transformer backbones (ViT and Swin) generally outperform CNN-based ResNet-50 for continual DA
- Gradient normalization successfully stabilizes adaptation in buffer-fed continual DA methods
- Buffer-fed methods (ConDA and UCL-GV) suffer from significant stability issues without gradient normalization, with performance drops of up to ~40% between batches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Buffer-fed continual DA methods suffer from significant adaptation stability issues during gradual weather degradation
- Mechanism: When models adapt to successive batches without revisiting earlier data, gradient updates can destabilize learned representations, causing performance drops or model collapse
- Core assumption: Continual adaptation without memory replay creates exposure bias that accumulates instability
- Evidence anchors:
  - [abstract] "We discover stability issues during adaptation for existing buffer-fed continual DA methods"
  - [section] "ConDA and UCL-GV may face significant stability issues at times, and model performance may even drop by ~40% from one incoming batch to the next"
  - [corpus] Weak evidence - no corpus papers directly discuss stability issues in buffer-fed continual DA methods
- Break condition: If incoming data distribution changes are too rapid or severe, gradient normalization may not provide sufficient stability

### Mechanism 2
- Claim: Gradient normalization stabilizes continual adaptation by controlling gradient magnitude during optimization
- Mechanism: L2-normalization of gradients before optimization prevents extreme parameter updates that could destabilize the model during single-pass adaptation
- Core assumption: Uncontrolled gradient magnitudes during continual adaptation lead to unstable parameter trajectories
- Evidence anchors:
  - [section] "We propose that normalizing the gradients through the model helps stabilize the adaptation process for the continual models"
  - [section] "Empirically, we conduct L2-normalization of all the gradients after backpropagation through the model, and before optimization for each adaptation iteration"
  - [corpus] Weak evidence - no corpus papers mention gradient normalization for continual DA stability
- Break condition: If learning rate is too high even with gradient normalization, optimization instability may persist

### Mechanism 3
- Claim: Transformer backbones (ViT and Swin) generally outperform ResNet-50 for continual DA due to better global feature capture
- Mechanism: Attention mechanisms in transformers enable better handling of domain shifts by capturing long-range dependencies and global context
- Core assumption: Global feature representations are more robust to gradual domain shifts than local hierarchical features
- Evidence anchors:
  - [section] "attention-based models (ViT and Swin) generally outperform the CNN-based ResNet-50 model for continual DA"
  - [section] "ViT breaks an image into patches of 16 Ã— 16 pixels, embeds each patch into a token and then applies self-attention across each of the token pairs"
  - [corpus] Weak evidence - no corpus papers directly compare transformer vs CNN backbones for continual DA
- Break condition: If training data is extremely limited, transformers' weak inductive bias may cause overfitting despite better global feature capture

## Foundational Learning

- Concept: Domain adaptation and distribution shift
  - Why needed here: The paper addresses domain gaps between source training data and target data under gradually degrading weather conditions
  - Quick check question: What is the difference between domain adaptation and standard supervised learning?

- Concept: Continual learning and catastrophic forgetting
  - Why needed here: Models must adapt to sequential batches without revisiting earlier data, requiring techniques to prevent forgetting
  - Quick check question: How does catastrophic forgetting manifest in neural networks during continual learning?

- Concept: Attention mechanisms and transformer architectures
  - Why needed here: The paper evaluates ViT and Swin transformers as potential improvements over ResNet-50 for continual DA
  - Quick check question: How does self-attention in transformers differ from convolution operations in CNNs?

## Architecture Onboarding

- Component map:
  - Source model: Pre-trained feature extractor (ResNet-50/ViT/Swin) + classifier
  - Target adaptation: Unlocked feature extractor, locked classifier
  - Memory buffer: Class-balanced storage for samples from previous batches
  - Gradient normalization: L2-normalization applied before optimization
  - Loss functions: Cross-entropy with pseudolabels + information maximization variants

- Critical path:
  1. Train source model on clear weather data
  2. Initialize target model with source weights
  3. For each incoming batch:
     - Combine with buffer samples
     - Generate and refine pseudolabels
     - Apply gradient normalization
     - Optimize with cross-entropy and IM losses
     - Update buffer with current batch samples

- Design tradeoffs:
  - Buffer size vs. computational overhead
  - Learning rate vs. adaptation stability
  - Backbone capacity vs. overfitting risk
  - Gradient normalization strength vs. optimization speed

- Failure signatures:
  - Sudden performance drops between batches (instability)
  - Gradual performance degradation (forgetting)
  - Stuck at suboptimal performance (insufficient learning capacity)
  - Model collapse (severe instability)

- First 3 experiments:
  1. Run Continual-SHOT without gradient normalization on AID-CC to establish baseline instability
  2. Enable gradient normalization with learning rate 0.002 to observe stability improvements
  3. Test ConDA with Swin backbone and gradient normalization on UCM-SF to compare transformer performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do other types of weather degradation (fog, rain, haze) affect continual domain adaptation performance on aerial imagery?
- Basis in paper: [explicit] The authors specifically focus on cloud cover and snowfall degradation types but acknowledge that other weather conditions exist
- Why unresolved: The paper only evaluates two weather degradation types, leaving the impact of other weather conditions unexplored
- What evidence would resolve it: Creating and evaluating benchmark datasets with fog, rain, and haze degradation types on the same aerial imagery datasets would provide comparative performance metrics

### Open Question 2
- Question: What is the optimal buffer size for continual domain adaptation across different dataset sizes and weather degradation intensities?
- Basis in paper: [explicit] The authors use a fixed buffer size of 420 samples for all experiments but note this may not be optimal
- Why unresolved: The paper uses a constant buffer size without exploring how buffer size affects performance across different scenarios
- What evidence would resolve it: Systematic experiments varying buffer sizes relative to dataset size and degradation intensity would identify optimal buffer allocation strategies

### Open Question 3
- Question: How do continual domain adaptation models perform on real-world aerial imagery collected under actual weather degradation conditions?
- Basis in paper: [explicit] The authors use synthetically generated weather degradation on real imagery rather than actual degraded imagery
- Why unresolved: The paper relies on synthetic augmentation rather than real-world weather-affected data
- What evidence would resolve it: Evaluating the same models on real aerial imagery collected during various weather conditions would validate synthetic augmentation effectiveness and reveal real-world performance gaps

## Limitations

- The proposed gradient normalization lacks theoretical grounding and may not be optimal across all backbone architectures and dataset sizes
- The paper only evaluates two types of weather degradation (cloud cover and snowfall), limiting generalizability to other weather conditions
- Performance is only measured at the final degraded condition, not characterizing adaptation stability throughout the degradation sequence

## Confidence

- **High**: Discovery of significant stability issues in buffer-fed continual DA methods (performance drops up to ~40% between batches)
- **Medium-High**: Gradient normalization successfully stabilizes adaptation, though optimal normalization strength is not explored
- **Medium-High**: Transformer backbones outperform ResNet-50, but ablation studies isolating attention mechanisms' contributions are lacking

## Next Checks

1. Conduct ablation studies varying gradient normalization strength to determine optimal L2 normalization parameters across different backbone architectures
2. Test the proposed gradient normalization technique on non-aerial continual domain adaptation datasets to assess generalizability
3. Implement and compare alternative stability mechanisms (such as weight regularization or dynamic learning rate adjustment) against gradient normalization