---
ver: rpa2
title: Improving Interpretation Faithfulness for Vision Transformers
arxiv_id: '2311.17983'
source_url: https://arxiv.org/abs/2311.17983
tags:
- attention
- theorem
- faithful
- then
- vits
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Faithful Vision Transformers (FViTs) to address
  the issue of unstable attention-based explanations in Vision Transformers under
  adversarial attacks. The key insight is that attention vectors should not only be
  robust to perturbations for accurate predictions, but also maintain stable top-k
  indices for faithful interpretability.
---

# Improving Interpretation Faithfulness for Vision Transformers

## Quick Facts
- **arXiv ID:** 2311.17983
- **Source URL:** https://arxiv.org/abs/2311.17983
- **Reference count:** 40
- **Key outcome:** Faithful Vision Transformers (FViTs) using Denoised Diffusion Smoothing (DDS) provide more stable attention-based explanations under adversarial attacks while maintaining competitive accuracy

## Executive Summary
This paper addresses the critical issue of unstable attention-based explanations in Vision Transformers (ViTs) when subjected to adversarial attacks. The authors introduce Faithful Vision Transformers (FViTs) that ensure both robust predictions and stable attention vectors. The key innovation is Denoised Diffusion Smoothing (DDS), which combines randomized smoothing with diffusion-based denoising to create attention vectors that are both robust to perturbations and maintain faithful interpretability. Theoretical analysis demonstrates that Gaussian noise is near-optimal for achieving this dual property, and extensive experiments validate the approach across classification and segmentation tasks.

## Method Summary
The paper proposes Denoised Diffusion Smoothing (DDS) as a method to transform standard ViTs into Faithful Vision Transformers (FViTs). DDS works by first adding Gaussian noise to input images (randomized smoothing), then applying a diffusion-based denoising process, and finally computing attention vectors. This two-step process ensures that attention vectors remain stable under adversarial perturbations while maintaining accurate predictions. The method theoretically proves that Gaussian noise is near-optimal for both ℓ2 and ℓ∞-norm cases, and validates this through extensive experiments on ImageNet, Cityscapes, and COCO datasets using ViT, DeiT, and Swin architectures.

## Key Results
- FViTs demonstrate significantly more stable attention vectors under adversarial attacks compared to vanilla ViTs
- The method maintains competitive classification accuracy while improving faithfulness scores
- Gaussian noise is empirically and theoretically shown to be near-optimal for both ℓ2 and ℓ∞-norm perturbations
- Faithful Region estimation algorithm successfully identifies stable attention regions under adversarial conditions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Randomized smoothing with Gaussian noise stabilizes attention vectors under adversarial perturbations
- **Mechanism:** Gaussian noise is added to the input image, creating multiple perturbed versions. The attention mechanism is applied to these perturbed images, and the results are aggregated. This averaging process smooths out the noise in the attention vectors, making them more stable.
- **Core assumption:** The averaging effect of randomized smoothing outweighs the destabilizing effect of individual noise perturbations
- **Evidence anchors:**
  - [abstract]: "we propose a new method called Denoised Diffusion Smoothing (DDS), which adopts randomized smoothing and diffusion-based denoising"
  - [section]: "we find that using randomized smoothing to the vanilla ViT, which is a standard method for certified robustness Cohen et al. (2019), and then applying a denoised diffusion probabilistic model to the perturbed input can adjust it to an FViT"

### Mechanism 2
- **Claim:** Denoised diffusion probabilistic models further stabilize attention vectors by removing noise-induced artifacts
- **Mechanism:** After adding Gaussian noise and applying the attention mechanism, a diffusion-based denoising process is applied to the perturbed image. This denoising step aims to remove the noise while preserving the essential features of the image, leading to more accurate and stable attention vectors.
- **Core assumption:** The denoising process effectively removes noise-induced artifacts without significantly altering the true features of the image
- **Evidence anchors:**
  - [abstract]: "DDS involves two main components: (1) the standard randomized smoothing with Gaussian noise and (2) a denoising diffusion probabilistic model"
  - [section]: "To achieve this, we propose a new method called Denoised Diffusion Smoothing (DDS), which adopts randomized smoothing and diffusion-based denoising"

### Mechanism 3
- **Claim:** Gaussian noise is near-optimal for both ℓ2 and ℓ∞-norm cases in achieving faithful attention vectors
- **Mechanism:** The authors theoretically prove that Gaussian noise is near-optimal for achieving faithful attention vectors under both ℓ2 and ℓ∞-norm perturbations. This suggests that Gaussian noise provides a good balance between noise level and effectiveness in stabilizing attention vectors.
- **Core assumption:** Gaussian noise provides a good trade-off between noise level and effectiveness in stabilizing attention vectors under different perturbation norms
- **Evidence anchors:**
  - [abstract]: "we demonstrate that Gaussian noise is near-optimal for both ℓ2 and ℓ∞-norm cases"
  - [section]: "And we introduce DDS, which leverages a smoothing-diffusion process to obtain faithful ViTs while also enhancing prediction performance"

## Foundational Learning

- **Concept:** Adversarial robustness and its relationship to interpretability
  - **Why needed here:** The paper aims to improve the faithfulness of attention-based explanations in Vision Transformers, which is closely related to adversarial robustness
  - **Quick check question:** How does adversarial robustness impact the stability and reliability of attention-based explanations?

- **Concept:** Randomized smoothing and its application to deep learning models
  - **Why needed here:** The paper uses randomized smoothing as a key component of its method to stabilize attention vectors under perturbations
  - **Quick check question:** How does randomized smoothing work, and how can it be applied to improve the robustness of attention-based explanations?

- **Concept:** Denoising diffusion probabilistic models and their application to image processing
  - **Why needed here:** The paper uses a denoising diffusion probabilistic model to further stabilize attention vectors by removing noise-induced artifacts
  - **Quick check question:** How do denoising diffusion probabilistic models work, and how can they be used to improve the quality of attention-based explanations?

## Architecture Onboarding

- **Component map:** Input image -> Gaussian noise addition -> Attention mechanism (Vision Transformer) -> Diffusion-based denoising -> Output attention vector

- **Critical path:** Input image → Gaussian noise addition → Attention mechanism → Diffusion-based denoising → Output attention vector

- **Design tradeoffs:**
  - Noise level vs. attention vector stability: Higher noise levels may provide better smoothing but can also lead to inaccurate attention vectors
  - Denoising strength vs. feature preservation: Stronger denoising may remove more noise but can also alter the true features of the image
  - Computational cost vs. explanation quality: More complex denoising processes may provide better explanations but can also increase computational cost

- **Failure signatures:**
  - Unstable attention vectors under adversarial perturbations
  - Inaccurate attention vectors due to excessive noise or over-denoising
  - Decreased classification accuracy due to the denoising process

- **First 3 experiments:**
  1. Evaluate the stability of attention vectors under different noise levels without denoising
  2. Evaluate the effectiveness of different denoising techniques in stabilizing attention vectors
  3. Compare the faithfulness of explanations using different noise distributions (e.g., Gaussian vs. uniform)

## Open Questions the Paper Calls Out

- **Open Question 1:** How does the Denoised Diffusion Smoothing (DDS) method perform when applied to other transformer-based architectures beyond Vision Transformers, such as those used in natural language processing or speech recognition?
  - **Basis in paper:** [inferred] The paper focuses on Vision Transformers but mentions that the proposed method can be used as a plugin to provide certified faithfulness for interpretability under adversarial attacks, regardless of the method used to generate attention maps
  - **Why unresolved:** The paper does not explore the application of DDS to other transformer-based architectures outside of computer vision tasks
  - **What evidence would resolve it:** Empirical results showing the effectiveness of DDS on transformer-based models in NLP or speech recognition tasks, compared to existing methods for improving interpretability and robustness in those domains

- **Open Question 2:** What is the theoretical limit of the Faithful Region estimation algorithm (Algorithm 2) in terms of its tightness and accuracy, and how does it scale with the dimensionality of the input data?
  - **Basis in paper:** [explicit] The paper mentions that the Faithful Region estimation is verified empirically through adversarial attacks, but does not provide a theoretical analysis of its tightness or scalability
  - **Why unresolved:** The paper focuses on empirical validation of the Faithful Region estimation but does not explore its theoretical properties or scalability
  - **What evidence would resolve it:** A theoretical analysis of the Faithful Region estimation algorithm, including its tightness bounds and computational complexity as a function of input dimensionality, along with empirical results demonstrating its performance on high-dimensional datasets

- **Open Question 3:** How does the choice of the hyperparameter k (number of top indices to consider for stability) affect the performance and interpretability of Faithful Vision Transformers, and is there an optimal value of k for different tasks or datasets?
  - **Basis in paper:** [explicit] The paper defines Faithful Vision Transformers based on the stability of the top-k indices of the attention vector, but does not explore the impact of different values of k on the model's performance or interpretability
  - **Why unresolved:** The paper uses a fixed value of k throughout the experiments but does not investigate how varying k affects the faithfulness and interpretability of the resulting FViTs
  - **What evidence would resolve it:** A systematic study of the effect of different k values on the performance and interpretability of FViTs across various tasks and datasets, along with an analysis of the trade-offs involved in choosing an appropriate k value for a given application

## Limitations

- The paper relies heavily on theoretical proofs for Gaussian noise optimality that are not empirically validated across diverse datasets
- The denoising diffusion component's architecture and hyperparameters are underspecified, making exact reproduction challenging
- The faithfulness metric (reciprocal of heat map differences) may not capture all aspects of explanation quality

## Confidence

- **High:** The core mechanism of combining randomized smoothing with diffusion denoising is technically sound and supported by theoretical analysis
- **Medium:** Experimental results showing improved robustness under adversarial attacks, though limited to specific datasets and attack configurations
- **Low:** Claims about Gaussian noise being "near-optimal" across all scenarios, as empirical validation is sparse

## Next Checks

1. **Noise Distribution Sensitivity:** Systematically compare DDS performance with different noise distributions (Gaussian, uniform, Laplacian) to verify the claimed near-optimality of Gaussian noise
2. **Cross-Dataset Generalization:** Test FViTs on additional datasets beyond ImageNet, Cityscapes, and COCO to assess robustness claims across diverse domains
3. **Faithfulness Metric Expansion:** Implement alternative faithfulness metrics (e.g., deletion/insertion tests, pointing game) to validate that the proposed metric captures explanation quality comprehensively