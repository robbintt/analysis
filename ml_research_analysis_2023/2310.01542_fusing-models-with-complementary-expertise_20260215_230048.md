---
ver: rpa2
title: Fusing Models with Complementary Expertise
arxiv_id: '2310.01542'
source_url: https://arxiv.org/abs/2310.01542
tags:
- expert
- experts
- learning
- arxiv
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of combining multiple pre-trained
  expert models with complementary knowledge for improved performance on heterogeneous
  data distributions. The authors propose a simple yet effective method called Fusion
  of Experts (FoE) that learns to fuse expert outputs by treating it as a supervised
  learning problem.
---

# Fusing Models with Complementary Expertise

## Quick Facts
- arXiv ID: 2310.01542
- Source URL: https://arxiv.org/abs/2310.01542
- Authors: 
- Reference count: 35
- Key outcome: Proposes Fusion of Experts (FoE) method that learns to fuse complementary expert models through supervised learning, showing significant improvements over individual experts and baselines across multiple tasks including image classification, text classification, summarization, and question answering

## Executive Summary
This paper addresses the challenge of combining multiple pre-trained expert models with complementary knowledge for improved performance on heterogeneous data distributions. The authors propose Fusion of Experts (FoE), a simple yet effective method that treats expert fusion as a supervised learning problem. FoE can be applied to both discriminative and generative tasks, and is evaluated on various benchmarks showing significant improvements over individual experts and other baseline methods like ensembling. The authors also extend their method to the "frugal" setting, proposing FrugalFoE to reduce the number of expert model evaluations at test time while maintaining performance.

## Method Summary
The paper proposes a supervised learning approach to fuse expert models with complementary knowledge. For discriminative tasks, the fuser learns to predict labels from concatenated expert outputs. For generative tasks, it uses averaged last-layer token embeddings from experts as features. The FrugalFoE extension reduces expert queries by treating expert selection as a shortest-path problem, using k-nearest neighbors on validation data to estimate conditional expected loss when adding additional experts. The method is evaluated across multiple tasks including image classification on CIFAR-100, text classification, summarization, question answering, and text generation evaluation.

## Key Results
- Significant performance improvements over individual experts across multiple tasks and datasets
- FrugalFoE successfully reduces expert evaluations while maintaining accuracy, achieving 10-20x reduction in some cases
- Outperforms traditional ensembling methods on tasks with heterogeneous data distributions
- Demonstrates effectiveness for both discriminative (classification) and generative (summarization) tasks

## Why This Works (Mechanism)

### Mechanism 1
The fuser learns which expert to use based on complementary expertise encoded in expert outputs. Concatenating expert outputs creates a high-dimensional feature space where each dimension captures domain-specific patterns. The fuser network learns to map these concatenated features to the correct domain or label by optimizing cross-entropy loss on validation data. This works because expert outputs contain sufficient information to distinguish between domains despite their complementary nature. The approach breaks down when expert outputs become too similar, such as when identical architectures are trained on overlapping data.

### Mechanism 2
FrugalFoE reduces expert queries while maintaining accuracy through a sequential decision process. The algorithm treats expert selection as a shortest-path problem where each node represents a subset of queried experts. At each step, it estimates the conditional expected loss of adding another expert using k-nearest neighbors from validation data, stopping when marginal improvement falls below a threshold. This works because the conditional distribution of loss given observed expert outputs can be accurately estimated using kNN on validation data. The method fails when validation data distribution differs significantly from test data, making kNN estimates unreliable.

### Mechanism 3
Expert embeddings capture domain membership information that enables accurate expert selection. The last-layer embeddings of expert LLMs contain compressed representations of both input and generated text that encode distributional information. Averaging these embeddings across tokens creates a fixed-size vector that serves as an effective domain identifier. This works because LLM embeddings preserve sufficient distributional information for domain classification despite being optimized for generation tasks. The approach breaks down when experts are fine-tuned on very similar domains or when the embedding space becomes saturated.

## Foundational Learning

- **Domain adaptation and distribution shift**: Why needed here because the paper assumes experts are trained on different subdomains and need to generalize to a mixture distribution at test time. Quick check question: What happens to expert performance when test data comes from a different subdomain than training data?

- **Supervised learning with concatenated features**: Why needed here because the fuser is trained as a standard supervised learning problem where inputs are concatenations of expert outputs. Quick check question: How does concatenating expert outputs differ from simple averaging in terms of representational capacity?

- **k-nearest neighbors for conditional expectation estimation**: Why needed here because FrugalFoE uses kNN to estimate the conditional expected loss of querying additional experts without ground truth labels. Quick check question: What are the limitations of using kNN for conditional expectation estimation in high-dimensional spaces?

## Architecture Onboarding

- **Component map**: Input → Expert models → Concatenated outputs → Fuser network → Final prediction
- **Critical path**: Input → Expert outputs → Concatenation → Fuser prediction (or FrugalFoE selection) → Final output
- **Design tradeoffs**:
  - Number of experts vs. computational cost: More experts improve coverage but increase inference time
  - Fuser complexity vs. generalization: Larger fusers can capture more complex relationships but may overfit
  - kNN neighborhood size M vs. estimation accuracy: Larger M provides more stable estimates but may include irrelevant neighbors
- **Failure signatures**:
  - Low expert selection accuracy: Indicates concatenated features lack discriminative power
  - FrugalFoE queries all experts: Suggests the stopping criterion is too conservative or validation data differs from test data
  - Fuser performance worse than individual experts: Indicates experts are not truly complementary or fuser is poorly trained
- **First 3 experiments**:
  1. Train individual experts on separate subdomains and evaluate their performance on the mixture distribution
  2. Implement basic fuser with concatenated expert outputs and compare to ensembling baseline
  3. Run FrugalFoE on CIFAR-100 with varying M and λ parameters to observe query reduction patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of using different fuser architectures (e.g., simple fully-connected neural network vs. kNN) on the performance of FrugalFoE in practice?
- Basis in paper: The paper discusses the trade-offs between using neural networks and kNN classifiers as fusers in the context of FrugalFoE, highlighting the computational efficiency of kNN but also mentioning the potential for better performance with neural networks.
- Why unresolved: The paper does not provide a comprehensive comparison of the performance of different fuser architectures in the context of FrugalFoE across various tasks and datasets.
- What evidence would resolve it: A thorough empirical study comparing the performance of FrugalFoE with different fuser architectures across a diverse set of tasks and datasets would provide insights into the optimal fuser architecture for different scenarios.

### Open Question 2
- Question: How does the choice of the hyperparameter λ in FrugalFoE affect the trade-off between the number of expert evaluations and the final performance?
- Basis in paper: The paper introduces λ as a hyperparameter in FrugalFoE that controls the trade-off between querying costs and errors made by the fuser.
- Why unresolved: The paper does not provide a detailed analysis of the impact of λ on the performance of FrugalFoE, leaving it unclear how to choose an appropriate value for different tasks and datasets.
- What evidence would resolve it: A sensitivity analysis of the performance of FrugalFoE with respect to λ across various tasks and datasets would help understand the impact of this hyperparameter and guide its selection in practice.

### Open Question 3
- Question: Can the concept of FrugalFoE be extended to handle experts with varying costs and expertise levels, rather than assuming equal costs and complementary expertise?
- Basis in paper: The paper focuses on the setting where experts have equal costs and complementary expertise, but acknowledges the potential for extending the approach to more general scenarios.
- Why unresolved: The paper does not explore the challenges and potential solutions for adapting FrugalFoE to handle experts with varying costs and expertise levels.
- What evidence would resolve it: A theoretical analysis of the extension of FrugalFoE to handle experts with varying costs and expertise levels, along with empirical validation on appropriate datasets, would provide insights into the feasibility and performance of such an extension.

## Limitations

- The effectiveness relies heavily on the assumption that expert outputs contain sufficient complementary information for the fuser to distinguish between domains, which may not hold for highly overlapping data distributions
- The kNN-based estimation in FrugalFoE is sensitive to validation data quality and representativeness, potentially leading to suboptimal expert selection when validation and test distributions differ
- The claim that LLM embeddings contain sufficient distributional information for domain identification relies on external work and may not generalize across different model architectures

## Confidence

- **High confidence**: The formulation of expert fusion as a supervised learning problem is well-established and the empirical improvements on standard benchmarks are convincing
- **Medium confidence**: The FrugalFoE algorithm's theoretical grounding is sound, but its practical effectiveness depends heavily on validation data quality and parameter tuning
- **Low confidence**: The claim that LLM embeddings contain sufficient distributional information for domain identification relies on external work and may not generalize across different model architectures

## Next Checks

1. Test FoE performance when experts are trained on increasingly overlapping data distributions to quantify the breakdown point of the complementary expertise assumption
2. Evaluate FrugalFoE on out-of-distribution test data to assess robustness when validation data distribution differs from test data
3. Compare the kNN estimation accuracy with alternative methods (e.g., parametric models) for conditional expected loss estimation in the expert selection process