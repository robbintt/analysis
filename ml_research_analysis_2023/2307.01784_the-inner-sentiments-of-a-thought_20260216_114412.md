---
ver: rpa2
title: The Inner Sentiments of a Thought
arxiv_id: '2307.01784'
source_url: https://arxiv.org/abs/2307.01784
tags:
- sentences
- quantile
- text
- arxiv
- these
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores the emotional dynamics of sentences using large
  language models (LLMs). The authors train models to predict the quantiles of distributions
  of emotional sentiments (valence, determination, admiration, anxiety, annoyance)
  in sentences.
---

# The Inner Sentiments of a Thought

## Quick Facts
- arXiv ID: 2307.01784
- Source URL: https://arxiv.org/abs/2307.01784
- Reference count: 40
- Key outcome: The paper trains models to predict sentiment distributions in sentences using LLM hidden states and demonstrates controlled text generation with specific emotional tones.

## Executive Summary
This paper introduces a method to predict the emotional trajectories of sentences using large language models. The approach trains quantile regression models on GPT-2 hidden states to predict distributions of sentiment scores (valence, determination, admiration, anxiety, annoyance) as sentences are constructed token by token. The authors demonstrate that these predictions can be used to generate text with specific emotional characteristics by re-weighting token probabilities based on their predicted sentiment quantiles. The method is validated on a dataset of 2 million Reddit sentences and shown to capture how conjunctions and intensifiers affect emotional trajectories.

## Method Summary
The method involves training quantile regression models to predict the distribution of final sentiment scores for sentences at each token position. The process starts by extracting hidden states from GPT-2 for all tokens in a sentence corpus, then training separate quantile models for each emotional dimension. These models predict multiple quantiles of the sentiment distribution at each token position. For text generation, the approach re-weights next-token probabilities based on how much each token's predicted distribution falls below a target quantile, then samples from this modified distribution to generate sentences with desired emotional characteristics.

## Key Results
- Quantile models achieve calibration accuracy with maximum absolute deviation under 1% for valence and 2-7% for emotions
- The method successfully predicts how conjunctions like "but" and intensifiers shift emotional trajectories
- Generated sentences targeting specific quantiles show meaningful emotional content, though with some limitations for sparse emotion distributions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The model learns to predict the distribution of final sentiment scores by observing how different sentence prefixes map to different emotional outcomes.
- **Mechanism:** By training on prefixes of increasing length, the model captures the evolving emotional trajectory. Each prefix acts as a context that narrows down possible sentiment outcomes until the full sentence resolves the ambiguity.
- **Core assumption:** The hidden states of GPT-2 encode sufficient information about the emotional potential of the sentence at each token position.
- **Evidence anchors:** [abstract] "We train predictors of the quantiles of the distributions of final sentiments of sentences from the hidden representations of an LLM applied to prefixes of increasing lengths."
- **Break Condition:** If GPT-2's hidden states don't capture the necessary emotional information, the quantile predictions will fail. Also, if the dataset doesn't contain sufficient variation in emotional outcomes for similar prefixes, the model won't learn meaningful distributions.

### Mechanism 2
- **Claim:** Quantile regression allows the model to predict the entire distribution of possible sentiment outcomes rather than just a point estimate.
- **Mechanism:** By predicting multiple quantiles (e.g., 5th, 25th, 50th, 75th, 95th), the model captures the range of possible emotional outcomes and their likelihoods at each token position.
- **Core assumption:** The emotional outcome of a sentence follows a distribution that can be approximated by these quantiles.
- **Evidence anchors:** [abstract] "We train predictors of the quantiles of the distributions of final sentiments of sentences from the hidden representations of an LLM applied to prefixes of increasing lengths."
- **Break Condition:** If the emotional outcomes don't follow a predictable distribution, or if the quantile regression fails to capture the distribution accurately, the model's predictions will be unreliable.

### Mechanism 3
- **Claim:** Re-weighting token probabilities based on their predicted sentiment quantiles steers the language model to generate text with specific emotional characteristics.
- **Mechanism:** By increasing the probability of tokens that predict (and engender) certain emotions, the model generates sentences that reside within the lower or upper tail of the distribution.
- **Core assumption:** The re-weighted probabilities will lead to meaningful changes in the generated text's emotional content.
- **Evidence anchors:** [abstract] "We then show how to exploit the distributional predictions to generate sentences with sentiments in the tails of distributions."
- **Break Condition:** If the re-weighting doesn't significantly alter the generated text's emotional content, or if it leads to incoherent text, the method will fail.

## Foundational Learning

- **Concept:** Quantile Regression
  - **Why needed here:** To predict the entire distribution of possible sentiment outcomes rather than just a point estimate.
  - **Quick check question:** What is the difference between quantile regression and standard regression, and why is it important for predicting sentiment distributions?

- **Concept:** Distributional Reinforcement Learning
  - **Why needed here:** To understand how the model learns to predict distributions of future characteristics (i.e., sentiment) and target particular quantiles.
  - **Quick check question:** How does distributional reinforcement learning differ from standard reinforcement learning, and how does it apply to text generation?

- **Concept:** Language Model Fine-tuning
  - **Why needed here:** To understand how the model was fine-tuned to predict emotional content in text.
  - **Quick check question:** What is the difference between pre-training and fine-tuning a language model, and why is fine-tuning necessary for this task?

## Architecture Onboarding

- **Component map:** GPT-2 (774M parameters) -> Quantile Models (130k parameters each) -> Sentiment/Emotion Models -> Text Generation Pipeline
- **Critical path:**
  1. Tokenize sentences and extract hidden states from GPT-2
  2. Train quantile models to predict sentiment distributions
  3. Validate quantile predictions using unseen sentences
  4. Use quantile models to re-weight token probabilities and generate text
- **Design tradeoffs:**
  - Using GPT-2 vs. more recent, larger models: GPT-2 is more accessible but may have limitations in generating coherent text
  - Predicting distributions vs. point estimates: Distributions provide more nuanced information but are more complex to model
  - Re-weighting probabilities vs. fine-tuning: Re-weighting is less computationally expensive but may be less effective
- **Failure signatures:**
  - Poorly calibrated quantile predictions: Indicates issues with the quantile model or the underlying LLM representations
  - Generated text lacks emotional content: Indicates issues with the re-weighting process or the underlying sentiment models
  - Run-on sentences or grammatical errors: Indicates limitations of the underlying LLM
- **First 3 experiments:**
  1. Validate quantile predictions on a held-out set of sentences
  2. Generate text with varying degrees of negativity/positivity and assess the emotional content
  3. Analyze the emotional trajectories of sentences containing conjunctions like "but" to understand their effect on sentiment

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How can the method be scaled to analyze longer text sequences, such as paragraphs or entire documents?
- **Basis in paper:** [explicit] The authors mention that "A relevant (albeit difficult) next direction would be to develop methods for predicting the emotional arc of text at longer time-horizons â€“ conducting the same sort of analyses and generations at the scale of paragraphs, sections, chapters and beyond."
- **Why unresolved:** The current method is limited to analyzing individual sentences, and extending it to longer text sequences would require addressing issues such as context dependency, computational complexity, and maintaining coherence over longer spans.
- **What evidence would resolve it:** Successful application of the method to longer text sequences, demonstrating accurate emotional trajectory predictions and coherent text generation at paragraph or document scale.

### Open Question 2
- **Question:** How can the accuracy of the quantile models be improved for sparse emotion distributions?
- **Basis in paper:** [explicit] The authors note that "sampling sentences from an extreme quantile for these sparse emotion distributions proved to be more difficult than for valence, with the quantile targeting being imperfect."
- **Why unresolved:** The current quantile models struggle with accurately predicting and generating text for emotions with sparse distributions, such as anxiety and annoyance, compared to valence.
- **What evidence would resolve it:** Improved calibration and generation results for sparse emotion distributions, showing better alignment between predicted and actual quantiles and more accurate text generation targeting extreme quantiles.

### Open Question 3
- **Question:** How can the method be applied to detect and analyze cognitive biases in real-time conversations?
- **Basis in paper:** [explicit] The authors suggest that "If successful, this could be used to flag cognitive biases (e.g., use of absolute language like "always", etc.), which although they are relatively neutral in themselves, can nevertheless lead perniciously to more extreme (and often) negative thoughts. This could be done real-time during telehealth therapy sessions or retrospectively as patients and therapists review previous conversations."
- **Why unresolved:** While the potential application is mentioned, the actual implementation and effectiveness of using the method to detect cognitive biases in real-time conversations have not been demonstrated.
- **What evidence would resolve it:** Successful deployment of the method in real-time conversation analysis, showing accurate detection and flagging of cognitive biases, and demonstrating its usefulness in therapeutic settings.

## Limitations

- The emotion classifier provided by Hume AI is a black box whose accuracy is not independently verified for the dataset used
- Text generation results lack quantitative evaluation and systematic analysis of emotional content
- The method is currently limited to sentence-level analysis and may not scale well to longer text sequences

## Confidence

- **High confidence**: The methodology for extracting hidden states from GPT-2 and training quantile regression models is technically sound and well-specified. The connection to distributional reinforcement learning is valid.
- **Medium confidence**: The claim that quantile predictions accurately capture emotional trajectories and can be used for controlled text generation. This is supported by theoretical reasoning and limited examples but lacks comprehensive empirical validation.
- **Low confidence**: The scalability and generalization of this approach to other languages, domains, or more nuanced emotional dimensions beyond the five studied.

## Next Checks

1. **Quantitative evaluation of generated text**: Apply the re-weighting technique to generate multiple sentences targeting specific quantiles, then use an independent emotion classifier to measure whether the generated text actually achieves the intended sentiment distribution. Report statistical significance and effect sizes.

2. **Ablation study on model size**: Compare the performance of the quantile prediction models when using different layers of GPT-2 (e.g., last layer vs. all layers) and different model sizes to understand the contribution of the underlying representations.

3. **Cross-dataset generalization**: Train the quantile models on SMHD but evaluate them on a completely different dataset (e.g., IMDB reviews or Twitter data) to assess how well the emotional trajectory predictions generalize beyond the training domain.