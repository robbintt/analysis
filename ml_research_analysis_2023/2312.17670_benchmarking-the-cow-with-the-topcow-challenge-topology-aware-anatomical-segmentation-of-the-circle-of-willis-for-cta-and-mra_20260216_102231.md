---
ver: rpa2
title: 'Benchmarking the CoW with the TopCoW Challenge: Topology-Aware Anatomical
  Segmentation of the Circle of Willis for CTA and MRA'
arxiv_id: '2312.17670'
source_url: https://arxiv.org/abs/2312.17670
tags:
- segmentation
- were
- teams
- dice
- case
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: TopCoW challenge benchmarked Circle of Willis (CoW) anatomical
  segmentation for CTA and MRA angiographic modalities. Using a public dataset with
  voxel-level annotations for 13 CoW vessel components from 200 paired MRA/CTA scans,
  the challenge attracted over 250 participants globally.
---

# Benchmarking the CoW with the TopCoW Challenge: Topology-Aware Anatomical Segmentation of the Circle of Willis for CTA and MRA

## Quick Facts
- arXiv ID: 2312.17670
- Source URL: https://arxiv.org/abs/2312.17670
- Reference count: 7
- Primary result: TopCoW challenge benchmarked CoW anatomical segmentation for CTA and MRA, achieving over 90% Dice scores for individual components, over 80% F1 scores for key component detection, and over 70% balanced accuracy for CoW variant classification.

## Executive Summary
The TopCoW challenge was established to address the critical need for accurate Circle of Willis (CoW) anatomical segmentation in clinical settings, particularly for identifying cerebrovascular anomalies and aneurysms. Using a public dataset of 200 paired MRA/CTA scans with voxel-level annotations for 13 CoW vessel components, the challenge attracted over 250 participants globally. The best algorithms achieved high performance across multiple evaluation metrics, demonstrating the feasibility of using deep learning for complex vascular anatomy segmentation. The annotated datasets and top-performing algorithms have been released publicly to foster further methodological development and clinical tool building.

## Method Summary
The challenge employed a multiclass anatomical segmentation framework with emphasis on topological metrics. Participants used deep learning models, primarily 3D nnUNet architectures, with some teams incorporating topology-aware loss functions (clDice), data augmentation, cross-validation, and ensemble methods. The evaluation metrics included Dice similarity coefficient, centerline Dice (clDice), and zero-th Betti number β0 errors. VR technology was utilized for efficient annotation and verification of CoW anatomy in 3D, reducing annotation time to 30-45 minutes per case.

## Key Results
- Top algorithms achieved over 90% Dice scores for segmenting individual CoW components
- Over 80% F1 scores were achieved for detecting key CoW components
- Over 70% balanced accuracy was achieved for classifying CoW variants
- Best algorithms demonstrated clinical potential in classifying fetal-type posterior cerebral artery and locating aneurysms with CoW anatomy

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Virtual Reality (VR) accelerates and improves annotation quality for complex 3D vascular structures.
- **Mechanism:** VR allows annotators to visualize and interact with 3D medical imaging data in real-time, providing depth perception and spatial understanding that is difficult to achieve with traditional 2D slice-by-slice annotation. This leads to faster annotation times (30–45 minutes per case) and potentially higher accuracy due to better visualization of vessel topology.
- **Core assumption:** Annotators can effectively use VR tools to navigate and annotate 3D structures, and the added spatial context translates to measurable improvements in annotation quality and speed.
- **Evidence anchors:**
  - [section] "VR was used to efficiently annotate and verify the CoW anatomy in 3D... The voxel-level annotation for CoW anatomy with VR took around 30–45 minutes."
  - [section] "VR-based annotation/verification workflow can overcome the otherwise too time-consuming annotation process on a complex multiclass anatomical segmentation problem."
- **Break condition:** If annotators lack VR proficiency or if the 3D structures are not well visualized in VR, the expected speed and quality gains may not materialize.

### Mechanism 2
- **Claim:** Multi-class segmentation as a framework captures both vessel morphology and topology, enabling more accurate CoW variant characterization than binary vessel segmentation alone.
- **Mechanism:** By assigning distinct voxel labels to each CoW component (e.g., ACA, MCA, Acom, Pcom), the model learns not just the presence of vessels but their spatial relationships and connectivity patterns. This allows downstream analysis of CoW variants based on the extracted topology from the segmentation mask.
- **Core assumption:** The multiclass labels are sufficient to encode the relevant anatomical and topological information for CoW variant classification, and the segmentation model can learn these relationships from the training data.
- **Evidence anchors:**
  - [abstract] "TopCoW challenge aimed to tackle the CoW characterization problem as a multiclass anatomical segmentation task with an emphasis on topological metrics."
  - [section] "The three evaluation metrics with equal weights were used for multiclass (CoW anatomical vessels) segmentation task: 1. Class-average Dice similarity coefficient 2. clDice on merged binary mask 3. Class-average zero-th Betti number β0 errors"
- **Break condition:** If the multiclass labels do not capture all relevant topological variations (e.g., rare variants like azygos ACA), or if the model cannot learn the complex spatial relationships, the approach will fail to accurately characterize CoW variants.

### Mechanism 3
- **Claim:** High-performance segmentation models for CoW require specific architectural choices and training strategies to handle the unique challenges of small, variable-diameter vessels and complex topology.
- **Mechanism:** Winning teams used 3D deep learning models (primarily nnUNet) with ensembling, topology-aware loss functions (clDice, skeleton recall), and data augmentation. These choices address the challenges of segmenting thin vessels (1-4mm diameter), handling missing components in variants, and preserving connectivity.
- **Core assumption:** The combination of 3D architectures, topology-aware losses, and ensembling is necessary and sufficient to achieve high performance on the CoW segmentation task, and these strategies generalize across different CoW variants.
- **Evidence anchors:**
  - [section] "Winning teams used nnUNet as the basis of the architecture or used it along with other custom architecture setup."
  - [section] "Two winning teams ‘WilliWillsWissen’ and ‘NexToU’ employed methods for topological objects of interest such as the skeletons and centerlines of the vessels."
  - [section] "The winning teams in general achieved top-3 values in Dice scores and β0 errors across all CoW components."
- **Break condition:** If the architectural choices do not adequately address the specific challenges of CoW segmentation (e.g., thin vessels, missing components), or if the training data is insufficient to learn these patterns, performance will degrade.

## Foundational Learning

- **Concept:** Understanding of Circle of Willis (CoW) anatomy and its variants.
  - **Why needed here:** The task involves segmenting and characterizing a specific anatomical structure with many variants. Without understanding the anatomy, it's impossible to design appropriate labels, evaluate performance, or interpret results.
  - **Quick check question:** What are the main components of the CoW, and how do common variants (e.g., fetal PCA, missing Acom) differ in their topology?

- **Concept:** Principles of medical image segmentation, including evaluation metrics (Dice, clDice, Betti numbers).
  - **Why needed here:** The challenge uses specific metrics to evaluate segmentation performance, including topology-aware metrics. Understanding these is crucial for designing models and interpreting results.
  - **Quick check question:** How does clDice differ from standard Dice, and why is it particularly relevant for segmenting tubular structures like blood vessels?

- **Concept:** Basics of deep learning for 3D medical image segmentation.
  - **Why needed here:** The challenge involves developing and evaluating 3D deep learning models. Understanding the principles of 3D CNNs, loss functions, and training strategies is essential for implementing and improving the algorithms.
  - **Quick check question:** What are the key differences between 2D and 3D CNNs for medical image segmentation, and when would you choose one over the other?

## Architecture Onboarding

- **Component map:** Data loading/preprocessing → 3D deep learning model (nnUNet/custom) → Post-processing (topology optimization, ensembling) → Evaluation (Dice, clDice, Betti numbers, topology matching)
- **Critical path:** Data → Model inference → Post-processing → Evaluation. The model architecture and training strategy are the most critical components for achieving high performance.
- **Design tradeoffs:** 3D vs. 2D architectures (3D better for spatial context but more computationally expensive), single vs. multi-stage approaches (multi-stage can improve accuracy but adds complexity), standard vs. topology-aware losses (topology-aware better for preserving vessel connectivity but may be harder to optimize)
- **Failure signatures:** Low Dice scores indicate poor overlap with ground truth, high Betti number errors indicate broken or fragmented vessels, poor topology matching indicates incorrect detection of CoW variants. Qualitative inspection of predictions can reveal specific failure modes (e.g., broken thin vessels, wrong side labels).
- **First 3 experiments:**
  1. Train a baseline 3D nnUNet model on the provided data with standard Dice loss and evaluate using the challenge metrics.
  2. Add topology-aware loss (clDice) to the baseline and compare performance, particularly on thin vessels and topology preservation.
  3. Implement ensembling of multiple models (e.g., different seeds, architectures) and evaluate the impact on overall performance and robustness.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the performance of CoW segmentation algorithms vary across different CoW variants, and what specific challenges do certain variants pose for segmentation accuracy?
- **Basis in paper:** [inferred] The paper discusses performance gaps between Group 1 (non-communicating arteries) and Group 2 (communicating arteries and rare variants) CoW components, with Group 2 showing lower Dice scores and higher topological errors. It also mentions challenges with variants like hypoplastic A1 segments, fetal PCA, and complex variants like 3rd-A2.
- **Why unresolved:** While the paper identifies performance differences between CoW component groups, it does not provide a detailed analysis of how individual CoW variants (e.g., specific configurations of A1, P1 segments, or presence/absence of Acom) affect segmentation accuracy. The topological matching analysis shows low match rates for some variants but lacks a comprehensive breakdown of variant-specific challenges.
- **What evidence would resolve it:** A detailed study comparing segmentation performance across all CoW variants, including variant-specific error analysis and identification of the most challenging variants, would clarify how different anatomical configurations impact algorithm accuracy.

### Open Question 2
- **Question:** What are the most effective strategies for improving the detection and segmentation of thin vessel segments (e.g., around 1 mm in diameter) in CoW anatomy, and how can these strategies be integrated into existing segmentation frameworks?
- **Basis in paper:** [inferred] The paper highlights that thin vessel segments, particularly those around 1 mm in diameter, are prone to topological errors such as fragmentation or false negatives. It also notes that current overlap-based metrics like Dice and clDice are less effective for small structures.
- **Why unresolved:** While the paper identifies thin vessel segments as a challenge, it does not propose or evaluate specific strategies to address this issue. The limitations of current metrics for small structures are noted, but alternative evaluation methods or architectural improvements are not explored.
- **What evidence would resolve it:** Development and validation of specialized architectures or loss functions designed for thin vessel segmentation, along with the use of boundary-based metrics like Hausdorff distance, would provide evidence for effective strategies to improve thin vessel detection and segmentation.

### Open Question 3
- **Question:** How can CoW segmentation algorithms be improved to better preserve and match the topology of CoW variants, particularly for complex configurations like fetal PCA or variants with missing communicating arteries?
- **Basis in paper:** [inferred] The paper discusses the importance of topology-aware segmentation and highlights that even with high segmentation accuracy, topological errors such as crossovers, fragmentation, and incorrect detection of CoW components persist. The topology matching analysis shows low match rates for certain variants, indicating room for improvement.
- **Why unresolved:** Although the paper identifies topological errors as a significant issue, it does not provide specific solutions or evaluate the effectiveness of topology-preserving techniques in CoW segmentation. The use of topological optimizations like clDice and skeleton recall is mentioned but not thoroughly explored for complex variants.
- **What evidence would resolve it:** Implementation and evaluation of advanced topological optimization techniques, such as graph-based approaches or topological constraints, specifically tailored to CoW variants, would demonstrate how to improve topology preservation and matching in segmentation algorithms.

## Limitations
- The annotation process, while accelerated by VR, still required expert time (30-45 minutes per case) and may contain inter-rater variability not fully characterized.
- The dataset, though large for this domain, represents a specific population (mostly males, limited age range) that may not fully capture global CoW anatomical variation.
- The evaluation metrics, while comprehensive, may not fully capture all clinically relevant aspects of segmentation quality, particularly for rare variants or subtle topological differences.

## Confidence
- **High Confidence:** The benchmark framework and dataset construction methodology, the overall performance trends across different algorithms, and the comparative analysis of winning approaches are well-supported by the presented evidence.
- **Medium Confidence:** The clinical utility claims regarding fetal PCA classification and aneurysm detection require further validation in real clinical workflows, though the segmentation results are promising.
- **Low Confidence:** The exact contribution of VR annotation to quality improvements versus traditional methods, and the specific impact of different architectural choices beyond the winning teams' implementations.

## Next Checks
1. Conduct a controlled study comparing VR annotation quality and speed against traditional slice-by-slice annotation methods on the same dataset to quantify the VR advantage.
2. Validate the clinical utility of the top-performing algorithms on external datasets from different institutions and populations to assess generalizability.
3. Perform detailed error analysis on specific failure modes (e.g., thin vessel segmentation, variant classification) using the released algorithms to identify systematic weaknesses and guide future improvements.