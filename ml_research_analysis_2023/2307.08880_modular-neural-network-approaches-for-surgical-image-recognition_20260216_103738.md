---
ver: rpa2
title: Modular Neural Network Approaches for Surgical Image Recognition
arxiv_id: '2307.08880'
source_url: https://arxiv.org/abs/2307.08880
tags:
- modular
- learning
- data
- https
- module
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper investigates the application of modular neural networks
  and self-training to two medical imaging problems: wrist arthroscopy for classifying
  scapholunate instability stages and shoulder arthroscopy for semantic segmentation.
  For the wrist problem, the authors propose a modular system with a gating module
  and a discriminative module, testing three architectures: modular (all stages together),
  modular (1 vs 1), and weighted modular.'
---

# Modular Neural Network Approaches for Surgical Image Recognition

## Quick Facts
- arXiv ID: 2307.08880
- Source URL: https://arxiv.org/abs/2307.08880
- Reference count: 31
- Primary result: Modular learning achieves 98.81% accuracy for wrist arthroscopy classification; self-training improves shoulder segmentation from 76% to 80%

## Executive Summary
This paper explores modular neural networks and self-training for medical image recognition tasks. The authors propose a modular system for wrist arthroscopy classification that decomposes the problem into healthy/pathological detection and stage classification, achieving 98.81% accuracy with a weighted modular approach. For shoulder arthroscopy segmentation, they demonstrate that self-training with probability thresholding can improve segmentation accuracy from 76% to 80% when labeled data is limited. The work shows that modular learning can improve performance but requires careful problem decomposition, while self-training is effective for labeling and segmentation when data annotation is costly.

## Method Summary
The paper investigates two medical imaging problems: wrist arthroscopy classification for scapholunate instability stages and shoulder arthroscopy semantic segmentation. For wrist classification, a modular system with gating and discriminative modules is proposed, testing three architectures: modular (all stages together), modular (1 vs 1), and weighted modular. The weighted modular approach incorporates gating module probabilities as weights. For shoulder segmentation, self-training is used to label unlabeled arthroscopy images by iteratively predicting masks with high confidence using a pixel-wise probability threshold.

## Key Results
- Wrist arthroscopy classification achieved 98.81% accuracy with weighted modular architecture
- Shoulder arthroscopy segmentation improved from 76% to 80% accuracy using self-training with 0.7 probability threshold
- Grad-CAM and Sobol attribution methods successfully located key features in wrist arthroscopy images for interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Modular learning improves performance by decomposing complex classification tasks into simpler sub-tasks, each handled by a specialized module.
- Mechanism: The gating module first determines whether the wrist structure is healthy or pathological. If pathological, the discriminative module processes the image. For the weighted modular variant, the gating module probabilities are used as weights, which improves calibration and accounts for gating errors.
- Core assumption: The classification problem is naturally decomposable into distinct sub-tasks (healthy/pathological, then stage classification).
- Evidence anchors:
  - [abstract] "The principle of the approach is to decompose a complex problem into simpler sub-tasks."
  - [section 3.2] "The system is composed of two modules; the gating module and the discriminative module."
  - [corpus] No corpus neighbors directly discuss modular decomposition, but related surgical phase recognition works use multi-modal and temporal decomposition.
- Break condition: If the gating module is highly uncertain or inaccurate, the benefit of modular decomposition diminishes; the system could fail if the sub-tasks are not truly independent or if errors cascade.

### Mechanism 2
- Claim: Self-training can improve segmentation performance when labeled data is scarce by iteratively pseudo-labeling high-confidence unlabeled images and adding them to the training set.
- Mechanism: A segmentation model is first trained on a small labeled set. It then predicts masks for unlabeled images, filters them by a probability threshold, and adds these high-confidence pseudo-labels back to the training data. This process repeats, refining the model iteratively.
- Core assumption: The decision boundary lies in a low-density region, so high-confidence pseudo-labels are likely correct and help the model generalize.
- Evidence anchors:
  - [abstract] "Self-training is a semi-supervised approach that managed to alleviate this problem and achieve state-of-the-art performances."
  - [section 4.2] "The self-training phase, consists in, first, training the two models with the available annotated images. Then, we predict the mask for all the images in the unlabeled set."
  - [corpus] No corpus neighbors discuss self-training for segmentation, but surgical workflow recognition uses self-distillation, a related semi-supervised technique.
- Break condition: If the initial model is poor or the unlabeled data is too noisy, pseudo-labels may be wrong, leading to model drift and degraded performance.

### Mechanism 3
- Claim: Using a weighted output from the gating module in the modular architecture improves classification accuracy by incorporating uncertainty from the gating decision.
- Mechanism: Instead of treating the gating module output as perfect, the weighted modular approach multiplies the discriminative module's predictions by the gating probabilities. This downweights uncertain gating decisions, leading to better-calibrated final predictions.
- Core assumption: The gating module's prediction probability reflects its confidence, and incorporating this uncertainty improves the final decision.
- Evidence anchors:
  - [section 3.2] "In this case, the gating module assigns a weight to each output and picks the output that yields the highest prediction probability."
  - [section 3.4.1] "We found that weighted modular had better performance than the first case modular architecture with 98.81% accuracy."
  - [corpus] No corpus neighbors discuss weighted modular architectures, but surgical phase recognition works use multi-stage temporal modeling, which is a form of hierarchical decomposition.
- Break condition: If the gating module is consistently confident but wrong, weighting by its probabilities could degrade performance.

## Foundational Learning

- Concept: Convolutional Neural Networks (CNNs) for image classification and segmentation.
  - Why needed here: Both wrist instability classification and shoulder arthroscopy segmentation rely on CNNs (ResNet18 for classification, UNet for segmentation).
  - Quick check question: What is the role of the residual connection in ResNet, and why does it help with deep networks?

- Concept: Semi-supervised learning and self-training.
  - Why needed here: The shoulder segmentation task uses self-training to leverage unlabeled arthroscopy images, reducing the need for costly annotations.
  - Quick check question: How does self-training differ from traditional supervised learning, and what assumption underlies its success?

- Concept: Modular neural networks and gating mechanisms.
  - Why needed here: The wrist classification uses a gating module to route images to the appropriate discriminative module, enabling problem decomposition.
  - Quick check question: What is the purpose of the gating module, and how does it differ from an ensemble of independent models?

## Architecture Onboarding

- Component map: Image → Gating Module (healthy/pathological) → (if pathological) → Discriminative Module → Weighted output → Final prediction

- Critical path:
  1. For classification: Image → Gating Module → (if pathological) → Discriminative Module → Weighted output → Final prediction
  2. For segmentation: Train on labeled set → Predict unlabeled set → Filter by threshold → Add pseudo-labels → Retrain → Repeat

- Design tradeoffs:
  - Modular vs. monolithic: Modular allows problem decomposition and interpretability but requires careful design of sub-tasks
  - Self-training threshold: Higher thresholds reduce noise but may slow learning; lower thresholds speed up but risk propagating errors
  - Weighted vs. unweighted gating: Weighted improves calibration but adds complexity and dependency on gating accuracy

- Failure signatures:
  - Classification: Low gating accuracy, poor discriminative module calibration, or sub-task independence violations
  - Segmentation: Self-training divergence, poor initial model, or threshold too high/low leading to label noise or slow learning

- First 3 experiments:
  1. Train a non-modular ResNet18 on all wrist classes and compare accuracy to modular variants
  2. Implement self-training on shoulder segmentation with a low threshold (e.g., 0.6) and observe accuracy gain
  3. Compare weighted modular vs. unweighted modular classification to quantify the benefit of gating probability weighting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of decomposition strategy in modular learning affect performance across different medical imaging tasks?
- Basis in paper: [explicit] The paper states that modular learning improved performance in the wrist arthroscopy classification problem but did not show the same benefits in the shoulder arthroscopy segmentation problem, attributing this to the decomposition strategy used.
- Why unresolved: The paper only tested one decomposition strategy for the segmentation task and did not explore alternative strategies that might have yielded better results.
- What evidence would resolve it: Comparative experiments testing multiple decomposition strategies for the shoulder arthroscopy segmentation task, demonstrating which approaches work best and why.

### Open Question 2
- Question: What is the optimal threshold strategy for self-training in medical image segmentation, and how does it vary with class distribution?
- Basis in paper: [explicit] The paper experimented with different fixed thresholds (0.6, 0.7, 0.8, 0.9) and found that 0.7 worked best, but also noted that performance degraded at 0.9 due to overfitting on the same samples.
- Why unresolved: The paper only tested fixed thresholds and did not explore dynamic or adaptive thresholding strategies that could better handle class imbalance or changing data distributions during training.
- What evidence would resolve it: Experiments comparing fixed, dynamic, and curriculum-based thresholding strategies across different class distributions and medical imaging tasks.

### Open Question 3
- Question: How does the explainability of modular neural networks compare to traditional neural networks in medical diagnosis?
- Basis in paper: [explicit] The paper used Grad-CAM and Sobol attribution methods to interpret the modular network's decisions, finding that both methods could locate key features but with different visualization qualities.
- Why unresolved: The paper only applied these methods to the modular network and did not compare their effectiveness against traditional non-modular networks for the same task.
- What evidence would resolve it: A comparative study applying the same explainability methods to both modular and non-modular networks on the same medical imaging task, measuring interpretability quality and clinical utility.

## Limitations

- The performance gains from modular learning need validation on independent datasets to confirm generalizability
- The self-training approach shows modest improvement (76% to 80%) and the optimal thresholding strategy remains unclear
- The paper lacks ablation studies on different threshold values and their impact on segmentation quality

## Confidence

- High confidence: The foundational mechanisms of modular learning and self-training are well-established in the literature
- Medium confidence: The reported performance improvements are statistically significant within the tested dataset, but may not generalize across different medical imaging tasks
- Low confidence: The specific benefits of weighted modular architecture over other variants are not fully explained, and the sensitivity of self-training to initial model quality and threshold selection is not thoroughly explored

## Next Checks

1. Apply the modular learning approach to an independent wrist arthroscopy dataset or different anatomical site to verify if performance gains persist across datasets

2. Systematically vary the probability threshold in self-training from 0.5 to 0.95 and measure the impact on segmentation accuracy and convergence speed to identify optimal threshold ranges

3. Perform k-fold cross-validation on the wrist dataset comparing all three modular architectures to assess statistical significance of performance differences