---
ver: rpa2
title: Understanding and Improving Feature Learning for Out-of-Distribution Generalization
arxiv_id: '2304.11327'
source_url: https://arxiv.org/abs/2304.11327
tags:
- features
- learning
- feature
- irmv1
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper theoretically analyzes feature learning in out-of-distribution
  (OOD) generalization, showing that ERM learns both spurious and invariant features,
  with the latter affecting final OOD performance. It proposes Feature Augmented Training
  (FAT), an iterative method that enforces learning of all useful features by retaining
  learned features and augmenting new ones in different data subsets.
---

# Understanding and Improving Feature Learning for Out-of-Distribution Generalization

## Quick Facts
- arXiv ID: 2304.11327
- Source URL: https://arxiv.org/abs/2304.11327
- Reference count: 40
- Key outcome: Feature Augmented Training (FAT) significantly improves OOD performance across various datasets and OOD objectives compared to ERM and other feature learning methods.

## Executive Summary
This paper provides a theoretical analysis of feature learning in out-of-distribution (OOD) generalization, showing that ERM learns both spurious and invariant features, with spurious features learned faster when their correlation with labels is stronger. The authors propose Feature Augmented Training (FAT), an iterative method that enforces learning of all useful features by retaining learned features and augmenting new ones in different data subsets. FAT significantly improves OOD performance across various datasets and OOD objectives compared to ERM and other feature learning methods like Bonsai.

## Method Summary
The paper introduces Feature Augmented Training (FAT), an iterative algorithm that learns all potentially useful features for OOD generalization. FAT works by separating training data into augmentation and retention sets based on prediction accuracy, applying Distributionally Robust Optimization (DRO) to learn new features on the augmentation set while preserving old features on the retention set through empirical risk minimization. This process iterates until no new features can be learned, combining classifiers from all rounds to maximize OOD performance.

## Key Results
- FAT outperforms ERM and other feature learning methods on COLORED MNIST and WILDS benchmark datasets
- OOD objectives like IRMv1 primarily reweight existing features rather than learning new ones
- ERM learns spurious features faster than invariant features when spurious correlations are stronger
- FAT successfully learns richer feature sets leading to improved OOD generalization

## Why This Works (Mechanism)

### Mechanism 1
ERM learns both spurious and invariant features, with spurious features learned faster when their correlation with labels is stronger. This creates a bias toward learning spurious features early in training due to ERM's focus on minimizing empirical risk.

### Mechanism 2
OOD objectives like IRMv1 rarely learn new features but instead amplify or suppress features already learned by ERM. These objectives focus on making representations invariant across environments, which prevents discovery of new features.

### Mechanism 3
FAT iteratively learns all potentially useful features by separating data into subsets containing already-learned features versus new features. It applies DRO to learn new features while minimizing empirical risk on already-learned features, thus building richer feature representations.

## Foundational Learning

- **Feature learning in neural networks**: Understanding how different training objectives learn features and how this affects generalization. Quick check: What's the difference between spurious features and invariant features in the context of OOD generalization?

- **Empirical Risk Minimization (ERM)**: Baseline training objective that learns both spurious and invariant features. Quick check: How does ERM optimize the empirical risk and why might this lead to learning spurious features?

- **Distributionally Robust Optimization (DRO)**: Optimization technique used in FAT to learn new features while retaining old ones. Quick check: What's the key difference between DRO and standard ERM optimization?

## Architecture Onboarding

- **Component map**: 2D data model with invariant and spurious features -> CNN featurizer (two-layer convolutional network) -> Classifier (linear layer) -> FAT algorithm with augmentation and retention sets -> DRO optimization for new feature learning -> ERM optimization for feature retention

- **Critical path**: 1. Initialize model and split data into augmentation and retention sets 2. Apply DRO to augmentation set to learn new features 3. Apply ERM to retention set to preserve old features 4. Iterate until no new features can be learned 5. Combine classifiers from all rounds

- **Design tradeoffs**: Memory vs performance (storing historical subsets), exploration vs retention (balancing new feature learning vs preserving old ones), computational cost vs feature richness (more rounds = more features but higher cost)

- **Failure signatures**: Poor OOD performance despite high ID performance, training accuracy stalls early in FAT rounds, retention accuracy drops significantly in later FAT rounds, DRO optimization fails to converge

- **First 3 experiments**: 1. Run ERM on COLORED MNIST -025 and measure ID vs OOD performance 2. Apply FAT with 2 rounds on COLORED MNIST -025 and compare feature learning 3. Evaluate learned features with various OOD objectives (IRMv1, VREx, etc.)

## Open Questions the Paper Calls Out

### Open Question 1
How do other factors beyond spurious and invariant feature correlation strengths, such as feature learning difficulty and model capacity, influence OOD generalization performance? The authors suggest extending their framework to consider these factors, but the current analysis focuses only on correlation strengths.

### Open Question 2
How can we prevent the learning of undesirable features during the early stages of OOD generalization to alleviate the optimization dilemma? The current framework learns all potentially useful features but doesn't address preventing undesirable feature learning.

### Open Question 3
How does the performance of FAT and other feature learning algorithms vary across different model architectures and datasets? While experiments were conducted on specific datasets and architectures, a comprehensive analysis across diverse scenarios is needed.

## Limitations
- Theoretical analysis relies on a simplified 2D data model that may not capture real-world complexity
- Claims about feature learning mechanisms are primarily based on synthetic experiments with limited real-world validation
- FAT's performance depends on careful hyperparameter tuning, particularly retention penalty and termination criteria
- Paper doesn't extensively explore FAT performance with different neural network architectures or limited data settings

## Confidence
- **High confidence**: ERM learns both spurious and invariant features, with spurious features learned faster when correlations are stronger
- **Medium confidence**: OOD objectives primarily reweight existing features rather than learning new ones
- **Medium confidence**: FAT successfully learns all useful features through iterative augmentation

## Next Checks
1. Test FAT's performance on datasets with overlapping feature sets to validate the assumption that features can be cleanly separated by prediction accuracy
2. Evaluate FAT with different neural network architectures (deeper networks, different architectures) to assess generalizability beyond the two-layer CNN
3. Conduct ablation studies on the retention penalty hyperparameter to understand its impact on feature learning and OOD performance