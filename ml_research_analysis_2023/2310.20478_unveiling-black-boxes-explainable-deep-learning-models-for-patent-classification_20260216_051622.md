---
ver: rpa2
title: 'Unveiling Black-boxes: Explainable Deep Learning Models for Patent Classification'
arxiv_id: '2310.20478'
source_url: https://arxiv.org/abs/2310.20478
tags:
- patent
- classification
- deep
- relevance
- words
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of explaining predictions in
  deep learning-based patent classification, which is critical for building trust
  in these models for real-world applications. The authors propose a novel framework
  that combines deep neural networks (DNN) with layer-wise relevance propagation (LRP)
  to provide human-understandable explanations for patent classification predictions.
---

# Unveiling Black-boxes: Explainable Deep Learning Models for Patent Classification

## Quick Facts
- arXiv ID: 2310.20478
- Source URL: https://arxiv.org/abs/2310.20478
- Reference count: 40
- Key outcome: Novel framework combining DNN with LRP for explainable patent classification, with Bi-LSTM achieving best results

## Executive Summary
This paper addresses the challenge of explaining predictions in deep learning-based patent classification, which is critical for building trust in these models for real-world applications. The authors propose a novel framework that combines deep neural networks (DNN) with layer-wise relevance propagation (LRP) to provide human-understandable explanations for patent classification predictions. They train several DNN models (Bi-LSTM, CNN, and CNN-BiLSTM) on two large patent datasets and use LRP to identify the relevance of words in patent texts for individual predictions. The experimental results demonstrate high performance in terms of various evaluation metrics, with the Bi-LSTM model achieving the best results. The explanations generated for each prediction highlight important relevant words that align with the predicted patent class, making the predictions more understandable.

## Method Summary
The proposed framework trains deep neural network models (Bi-LSTM, CNN, and CNN-BiLSTM) on patent datasets using FastText embeddings. After obtaining predictions from the trained models, the Layer-wise Relevance Propagation (LRP) algorithm is applied to backpropagate the relevance scores from the output layer to the input layer, identifying the contribution of individual words to the final classification. The framework is evaluated on two large patent datasets (AI-Growth-Lab and BigPatent) using precision, recall, and F1-score metrics, and the generated explanations are visualized by highlighting relevant words in red.

## Key Results
- Bi-LSTM model achieves the best performance among the three DNN architectures tested
- LRP successfully identifies relevant words in patent texts that align with predicted patent classes
- FastText embeddings handle irregular scientific terms and out-of-vocabulary words better than other embeddings for patent classification

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Layer-wise Relevance Propagation (LRP) can trace the contribution of individual words to a patent classification prediction by redistributing relevance scores backward from the output layer to the input layer.
- Mechanism: LRP applies a layer-wise conservation principle. Starting from the prediction score (output neuron), relevance is redistributed through each layer according to a redistribution rule that preserves the total relevance. For each neuron in a layer, the relevance is distributed to its inputs proportionally to their contribution to the neuron's activation, ensuring that the sum of relevance propagated backward equals the neuron's relevance.
- Core assumption: The neural network's decision can be meaningfully decomposed into contributions from individual input features (words) via backward propagation.
- Evidence anchors:
  - [abstract] "We train several DNN models, including Bi-LSTM, CNN, and CNN-BiLSTM, and propagate the predictions backward from the output layer up to the input layer of the model to identify the relevance of words for individual predictions."
  - [section] "The LRP algorithm applies the layer-wise conservation principle to calculate the relevance score for features. The computation starts from the output layer and then redistributes the relevance weight, eventually back-propagating it to the input layers [40, 39]."
  - [corpus] The corpus includes a related paper titled 'PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification' which suggests active research into explanation methods for text classification, lending indirect support to the plausibility of LRP for this purpose.
- Break condition: If the model architecture or activation functions are incompatible with the LRP redistribution rules, or if the conservation principle does not hold for the specific network, the relevance scores may be meaningless or misleading.

### Mechanism 2
- Claim: Using FastText embeddings instead of other embeddings (Glove, Word2Vec) improves handling of patent texts containing irregular scientific terms and out-of-vocabulary words.
- Mechanism: FastText represents words as bags of character n-grams, allowing it to generate embeddings for words not seen during training (out-of-vocabulary) by summing the n-gram vectors. This is particularly useful for patents, which often contain novel chemical names, technical jargon, and scientific terms not present in general corpora.
- Core assumption: The character n-gram decomposition captures meaningful semantic and contextual information for scientific terms in patents, even when the exact word is unseen.
- Evidence anchors:
  - [section] "Patents' text contains less used scientific terms and some words that are highly context specific. For example, patent in the field of chemistry has a lot of reagents and chemical names, even for some new patents the reagents' names might be completely new, proposed by the inventors. Considering this intuition, we chose FastText embedding instead of Glove and word2vec."
  - [corpus] The corpus includes a related paper titled 'Research on feature fusion and multimodal patent text based on graph attention network' which suggests ongoing research into handling complex patent text representations, supporting the need for robust embedding strategies.
- Break condition: If the character n-gram decomposition fails to capture the semantic meaning of complex scientific terms, or if the pre-trained FastText model lacks sufficient coverage of technical vocabulary, the embeddings may be noisy or uninformative.

### Mechanism 3
- Claim: Combining multiple deep neural network architectures (Bi-LSTM, CNN, CNN-BiLSTM) provides a robust patent classification framework, with Bi-LSTM achieving the best performance.
- Mechanism: Each architecture captures different aspects of the text. CNNs excel at capturing local patterns and n-gram features, LSTMs capture sequential dependencies, and Bi-LSTMs capture context from both directions. CNN-BiLSTM combines local pattern detection with sequential modeling. By training multiple models, the framework leverages diverse representations, and the best-performing model (Bi-LSTM) is selected for final predictions.
- Core assumption: The patent classification task benefits from capturing both local patterns (e.g., specific chemical terms) and long-range dependencies (e.g., relationships between sections of a patent).
- Evidence anchors:
  - [abstract] "We train several DNN models, including Bi-LSTM, CNN, and CNN-BiLSTM, and propagate the predictions backward from the output layer up to the input layer of the model to identify the relevance of words for individual predictions."
  - [section] "The experimental results on two datasets comprising two-million patent texts demonstrate high performance in terms of various evaluation measures. The explanations generated for each prediction highlight important relevant words that align with the predicted class, making the prediction more understandable."
  - [corpus] The corpus includes a related paper titled 'PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification' which suggests that different model architectures may be used for text classification, supporting the exploration of multiple architectures.
- Break condition: If the task does not require capturing long-range dependencies or if local patterns are sufficient, the more complex models (Bi-LSTM, CNN-BiLSTM) may not provide significant benefits over simpler models like CNN.

## Foundational Learning

- Concept: Layer-wise Relevance Propagation (LRP)
  - Why needed here: LRP is the core mechanism for generating human-understandable explanations for patent classification predictions. Understanding how LRP redistributes relevance scores backward through the network is essential for interpreting the explanations and debugging the model.
  - Quick check question: How does LRP ensure that the total relevance is conserved when redistributing scores from one layer to the previous layer?

- Concept: Word Embeddings (FastText)
  - Why needed here: FastText embeddings provide the semantic and contextual representation of patent text that is fed into the deep neural networks. Understanding how FastText differs from other embeddings (e.g., character n-grams vs. whole-word vectors) is crucial for appreciating why it was chosen for this task.
  - Quick check question: What is the key difference between FastText and Word2Vec that makes FastText more suitable for handling out-of-vocabulary words in patent texts?

- Concept: Deep Neural Network Architectures (Bi-LSTM, CNN, CNN-BiLSTM)
  - Why needed here: These are the classification models used in the framework. Understanding their strengths and weaknesses (e.g., CNNs for local patterns, LSTMs for sequential dependencies) is important for interpreting the model's performance and choosing the right architecture for similar tasks.
  - Quick check question: What is the primary advantage of using a Bi-LSTM over a standard LSTM for text classification tasks?

## Architecture Onboarding

- Component map:
  - Patent text -> FastText embeddings -> DNN model (Bi-LSTM/CNN/CNN-BiLSTM) -> Patent class prediction + LRP explanation

- Critical path:
  1. Load and preprocess patent text
  2. Generate FastText embeddings
  3. Feed embeddings into the DNN model
  4. Obtain class prediction
  5. Apply LRP to compute word relevance scores
  6. Generate explanation by highlighting relevant words

- Design tradeoffs:
  - FastText vs. transformer-based embeddings (e.g., BERT): FastText is faster and handles OOV words better, but may not capture as rich contextual information as transformers.
  - Multiple DNN architectures vs. single architecture: Training multiple architectures provides robustness but increases computational cost.
  - LRP vs. other XAI methods (e.g., SHAP, LIME): LRP provides layer-wise explanations, but may be less flexible than perturbation-based methods.

- Failure signatures:
  - Poor classification performance: Could indicate issues with embeddings, model architecture, or training data.
  - Irrelevant or nonsensical explanations: Could indicate problems with LRP implementation or model interpretability.
  - High computational cost: Could indicate inefficiencies in the pipeline or model architecture.

- First 3 experiments:
  1. Train and evaluate each DNN architecture (Bi-LSTM, CNN, CNN-BiLSTM) on a small subset of the patent data to compare their performance and identify the best baseline model.
  2. Implement LRP for the best-performing DNN architecture and generate explanations for a sample of patent predictions to validate the explanation quality.
  3. Compare the performance and explanation quality of the DNN models using FastText embeddings versus a simpler model (e.g., logistic regression) using TF-IDF features to assess the value added by deep learning and LRP.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective is the proposed LRP-based explanation method in helping human experts understand and trust the patent classification predictions compared to other explanation methods like attention-based approaches?
- Basis in paper: [explicit] The paper discusses using LRP for explanations and mentions that the explanations help understand why patents are classified into specific classes, but does not compare with other explanation methods.
- Why unresolved: The paper only uses LRP for explanations and does not compare its effectiveness with other explanation methods in terms of user understanding and trust.
- What evidence would resolve it: A user study comparing LRP explanations with other methods (e.g., attention-based) in terms of human experts' understanding and trust in the patent classification predictions.

### Open Question 2
- Question: How would the performance and explanations of the patent classification models change if a local word embedding model trained on patent corpus is used instead of pre-trained FastText?
- Basis in paper: [explicit] The paper mentions using FastText pre-trained word embedding and suggests that a local word embedding model trained on patent corpus might capture better contextual and semantic information for scientific terms and jargon.
- Why unresolved: The paper does not experiment with a local word embedding model trained on patent corpus, so the potential improvements in performance and explanations are unknown.
- What evidence would resolve it: Experiments comparing the performance and explanations of the patent classification models using FastText vs. a local word embedding model trained on patent corpus.

### Open Question 3
- Question: How well do the explanations generated by LRP generalize to different levels of the patent classification hierarchy (e.g., sub-group level classes)?
- Basis in paper: [explicit] The paper mentions that the model can explain predictions for multi-label classification and suggests that explaining predictions for different sub-group-level classes will be more challenging.
- Why unresolved: The paper does not provide explanations for sub-group level predictions or evaluate the effectiveness of LRP in generating explanations for different levels of the patent classification hierarchy.
- What evidence would resolve it: Experiments generating and evaluating explanations for sub-group level patent classification predictions using LRP.

## Limitations

- Specific implementation details of the LRP algorithm are not fully described, making exact reproduction challenging
- Hyperparameter settings for DNN models are not specified, which could impact reported performance
- No comparison with alternative explanation methods (e.g., SHAP, LIME, attention-based) to validate LRP's effectiveness

## Confidence

- Medium confidence: The effectiveness of the proposed LRP-based explanation method in helping human experts understand and trust patent classification predictions
- Medium confidence: The superiority of FastText embeddings over other embedding methods for handling patent texts with irregular scientific terms
- High confidence: The overall architecture and workflow of the proposed framework combining DNN with LRP for explainable patent classification

## Next Checks

1. Conduct hyperparameter sensitivity analysis to assess the impact of different learning rates, batch sizes, and epochs on model performance and explanation quality

2. Compare LRP-generated explanations with those produced by alternative XAI methods (SHAP, LIME) to evaluate relative strengths and weaknesses

3. Test the framework's ability to provide accurate and relevant explanations on patent datasets from domains not seen during training (e.g., chemistry patents for a model trained on AI patents)