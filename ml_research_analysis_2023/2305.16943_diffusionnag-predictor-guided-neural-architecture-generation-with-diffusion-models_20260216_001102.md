---
ver: rpa2
title: 'DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion
  Models'
arxiv_id: '2305.16943'
source_url: https://arxiv.org/abs/2305.16943
tags:
- architectures
- neural
- search
- architecture
- surrogate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DiffusionNAG introduces a conditional neural architecture generation
  framework based on diffusion models to overcome limitations of existing NAS methods
  such as inefficient search, high computation overhead, and lack of generalization.
  It represents neural architectures as directed acyclic graphs and introduces a score
  network with positional embeddings to ensure generation of valid architectures.
---

# DiffusionNAG: Predictor-guided Neural Architecture Generation with Diffusion Models

## Quick Facts
- arXiv ID: 2305.16943
- Source URL: https://arxiv.org/abs/2305.16943
- Reference count: 40
- Key outcome: Achieves up to 100x speedup over black-box NAS methods and 20x over TransferNAG while generating valid, high-performing architectures

## Executive Summary
DiffusionNAG introduces a conditional neural architecture generation framework based on diffusion models that addresses key limitations of existing neural architecture search (NAS) methods. By representing architectures as directed acyclic graphs (DAGs) and incorporating positional embeddings, it ensures generation of valid architectures. The method leverages gradients from a pre-trained surrogate model to guide the generation process toward architectures satisfying specific objectives, achieving significant speedups compared to black-box approaches.

## Method Summary
DiffusionNAG generates neural architectures through a conditional framework that combines diffusion models with surrogate model guidance. The approach first trains a score network on the architecture space without requiring accuracy information, then trains a dataset-aware surrogate model using a meta-dataset. Architectures are generated through reverse diffusion guided by the surrogate model's gradients, enabling rapid adaptation to unseen tasks. The method represents architectures as DAGs and uses positional embeddings to ensure validity during the generation process.

## Key Results
- Achieves up to 100x speedup compared to black-box NAS approaches
- Outperforms TransferNAG methods by up to 20x
- Demonstrates superior performance on CIFAR-10, CIFAR-100, Aircraft, and Oxford-IIIT Pets datasets
- Generates architectures with high validity, uniqueness, and novelty rates

## Why This Works (Mechanism)

### Mechanism 1
- Claim: DiffusionNAG achieves faster search by leveraging gradient guidance from a pre-trained surrogate model rather than training architectures independently.
- Mechanism: Instead of sampling architectures and training each one, DiffusionNAG samples noise and uses a surrogate model's gradients to guide the reverse diffusion process toward high-performing architectures.
- Core assumption: The surrogate model's predictions are accurate enough to effectively guide the generation process toward architectures that will actually perform well when trained.
- Evidence anchors:
  - [abstract] "DiffusionNAG outperforms existing NAS methods on four datasets with a speedup of up to 100x compared to black-box approaches and up to 20x compared to TransferNAG methods."
  - [section 3.2] "DiffusionNAG also significantly reduces the number of architectures that need to be trained (Trained Archs) for obtaining high-performing architectures compared to all black-box-based and Transfer-based methods"
  - [corpus] Missing direct evidence for gradient guidance effectiveness specifically
- Break condition: If the surrogate model predictions are inaccurate or the search space has complex interactions that the surrogate cannot capture, the guidance will lead to poor architectures.

### Mechanism 2
- Claim: The diffusion model generates valid directed acyclic graphs (DAGs) by incorporating positional embeddings into the score network.
- Mechanism: Unlike undirected graph diffusion models, DiffusionNAG uses positional embeddings to capture topological ordering of nodes, ensuring generated architectures are valid DAGs.
- Core assumption: Positional embeddings can effectively encode the ordering constraints of DAGs in a way that the diffusion process respects.
- Evidence anchors:
  - [section 2.1] "we introduce a score network that incorporates positional embeddings of nodes in directed acyclic graphs (DAGs)"
  - [section 3.3] "Our framework is able to generate novel architectures that are not found in the training set, as well as unique architectures."
  - [corpus] Missing evidence for DAG generation specifically
- Break condition: If the positional embeddings fail to capture complex DAG constraints or the diffusion process violates them, generated architectures will be invalid.

### Mechanism 3
- Claim: Transferability across datasets is achieved through meta-learning of the surrogate model over a task distribution.
- Mechanism: The surrogate model is trained on multiple tasks (datasets) so it can generalize to unseen datasets without retraining.
- Core assumption: Meta-learning on diverse tasks creates a surrogate model that generalizes to unseen datasets.
- Evidence anchors:
  - [abstract] "It can rapidly adapt to unseen tasks through meta-learning of the surrogate model over a task distribution."
  - [section 2.3] "By utilizing a meta-learned surrogate model for guiding the generation process, DiffusionNAG can rapidly adapt to unseen tasks."
  - [corpus] Missing evidence for meta-learning effectiveness specifically
- Break condition: If the meta-dataset doesn't cover sufficient diversity or the meta-learning fails, the surrogate won't generalize to new datasets.

## Foundational Learning

- Concept: Diffusion models and score matching
  - Why needed here: DiffusionNAG uses a diffusion model to generate architectures by learning to reverse a perturbation process
  - Quick check question: How does the score function relate to the data distribution in diffusion models?

- Concept: Directed acyclic graph (DAG) representation of neural architectures
  - Why needed here: Neural architectures are represented as DAGs, requiring special handling in the generation process
  - Quick check question: What makes DAGs different from undirected graphs in terms of generation constraints?

- Concept: Meta-learning and few-shot adaptation
  - Why needed here: The surrogate model must generalize to unseen datasets through meta-learning
  - Quick check question: How does meta-learning improve generalization to new tasks compared to standard learning?

## Architecture Onboarding

- Component map:
  - Score network (with positional embeddings) -> Surrogate model (meta-learned) -> Forward diffusion -> Reverse diffusion with guidance -> Generated architectures

- Critical path:
  1. Train score network on architecture space
  2. Train meta-learned surrogate model
  3. Generate architectures using reverse diffusion with surrogate guidance
  4. Evaluate generated architectures

- Design tradeoffs:
  - Training time vs. generation quality: More score network training improves quality but increases upfront cost
  - Surrogate accuracy vs. search space coverage: More accurate surrogates may miss good architectures in poorly modeled regions
  - Positional embeddings complexity vs. DAG validity: More complex positional encoding improves validity but increases computational cost

- Failure signatures:
  - Generated architectures have low validity (score network issue)
  - Generated architectures perform poorly despite high surrogate predictions (surrogate model issue)
  - Slow generation or poor adaptation to new datasets (meta-learning issue)

- First 3 experiments:
  1. Train score network on NAS-Bench-201 and verify it generates valid architectures with high uniqueness
  2. Train surrogate model on meta-dataset and test predictions on held-out datasets
  3. Generate architectures for CIFAR-10 and compare performance distribution against baselines

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DiffusionNAG perform on search spaces larger than MobileNetV3, and what are the computational trade-offs?
- Basis in paper: [inferred] The paper mentions the MobileNetV3 search space as an example of a large search space but does not explore significantly larger ones.
- Why unresolved: The paper focuses on two specific search spaces and does not investigate scalability to much larger search spaces.
- What evidence would resolve it: Experiments on significantly larger search spaces (e.g., spaces with 10^20 or more architectures) comparing performance, computational cost, and validity rates.

### Open Question 2
- Question: How sensitive is DiffusionNAG to the choice of surrogate model architecture and training data quality?
- Basis in paper: [explicit] The paper notes that the surrogate model only requires one-time training and discusses using a meta-dataset, but does not systematically analyze sensitivity to surrogate model choices.
- Why unresolved: The paper assumes a good surrogate model exists but does not explore how different surrogate model designs or training data quality affect generation quality.
- What evidence would resolve it: Ablation studies varying surrogate model architectures, training data sizes, and quality metrics, with corresponding impacts on generated architecture performance.

### Open Question 3
- Question: Can DiffusionNAG be extended to generate architectures for non-image tasks such as natural language processing or reinforcement learning?
- Basis in paper: [explicit] The paper validates DiffusionNAG only on computer vision datasets and mentions broader impact but does not test on other domains.
- Why unresolved: The methodology and experiments are confined to image classification tasks, leaving open questions about generalizability to other domains.
- What evidence would resolve it: Experiments applying DiffusionNAG to NAS benchmarks in NLP (e.g., ENAS, DARTS for language tasks) or RL (e.g., controller architectures), with performance comparisons to domain-specific methods.

## Limitations

- Limited validation to computer vision tasks without testing on NLP or RL domains
- Potential sensitivity to surrogate model quality and training data not thoroughly explored
- Unclear scalability to search spaces significantly larger than MobileNetV3

## Confidence

- **High confidence**: The fundamental approach of using diffusion models for architecture generation is sound and the DAG representation with positional embeddings is technically feasible.
- **Medium confidence**: The reported speedups and performance improvements are likely accurate for the tested scenarios but may not generalize to all search spaces.
- **Low confidence**: Claims about meta-learning generalization to unseen tasks and the specific contributions of individual components to overall performance.

## Next Checks

1. **Ablation study**: Remove the surrogate guidance and measure performance/speedup to isolate the contribution of gradient guidance versus other factors.
2. **Generalization test**: Evaluate on datasets completely held out from all training phases (including meta-learning) to verify true transfer capability.
3. **Architecture analysis**: Perform detailed analysis of generated architectures to quantify actual novelty versus minor variations of existing designs.