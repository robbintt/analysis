---
ver: rpa2
title: Debiasing, calibrating, and improving Semi-supervised Learning performance
  via simple Ensemble Projector
arxiv_id: '2310.15764'
source_url: https://arxiv.org/abs/2310.15764
tags:
- epass
- learning
- comatch
- simmatch
- embeddings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes EPASS, a simple yet effective ensemble projector
  method for semi-supervised learning (SSL). EPASS addresses the problem of biased
  embeddings in existing SSL methods by leveraging multiple projectors to ensemble
  embeddings stored in memory banks.
---

# Debiasing, calibrating, and improving Semi-supervised Learning performance via simple Ensemble Projector

## Quick Facts
- arXiv ID: 2310.15764
- Source URL: https://arxiv.org/abs/2310.15764
- Reference count: 40
- Key outcome: EPASS improves SimMatch and CoMatch by 39.47% and 40.24% in top-1 error rate on ImageNet with 100k labeled data

## Executive Summary
This paper introduces EPASS (Ensemble Projectors Aided for Semi-supervised Learning), a simple yet effective method to improve semi-supervised learning performance by leveraging multiple projectors to ensemble embeddings stored in memory banks. EPASS addresses the problem of biased embeddings in existing SSL methods by storing ensemble embeddings from multiple projectors instead of single projector embeddings, leading to stronger feature representations and improved generalization. The method is a plug-and-play module that can be easily incorporated into existing contrastive joint-training SSL frameworks like SimMatch and CoMatch.

## Method Summary
EPASS modifies existing SSL frameworks by replacing the single projector with multiple projectors and storing ensemble embeddings in the memory bank. During training, features from multiple projectors are averaged to create ensemble embeddings, which are then used for contrastive learning and pseudo-labeling. The method maintains the standard SSL training loop with memory banks and EMA teachers but with the key modification of using ensemble embeddings instead of single projector embeddings.

## Key Results
- EPASS improves SimMatch by 39.47% and CoMatch by 40.24% in top-1 error rate on ImageNet with 100k labeled data
- The method reduces Expected Calibration Error (ECE) by a large margin, improving model calibration
- EPASS achieves over 50% accuracy in the first few iterations, demonstrating faster convergence

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multiple projectors provide diverse embeddings that reduce bias in the memory bank.
- Mechanism: By averaging embeddings from multiple projectors, the model captures different perspectives of the input, mitigating the effect of any single projector being biased.
- Core assumption: Each projector learns different features from random initialization.
- Evidence anchors:
  - [abstract] "Unlike standard methods, where the learned embeddings from one projector are stored in memory banks to be used with contrastive learning, EPASS stores the ensemble embeddings from multiple projectors in memory banks."
  - [section 3.2] "Unlike conventional methods such as CoMatch and SimMatch, which assume that the learned embeddings from one projector are absolutely correct, we propose using the ensemble embeddings from multiple projectors to mitigate the bias."
  - [corpus] Weak - no direct evidence in corpus neighbors.
- Break condition: If projectors learn highly correlated features, the ensemble may not reduce bias effectively.

### Mechanism 2
- Claim: Ensemble embeddings improve calibration and reduce overconfidence.
- Mechanism: Averaging embeddings leads to smoother probability distributions, reducing the model's overconfidence in predictions and improving calibration metrics like ECE.
- Core assumption: Averaging embeddings reduces variance in prediction confidence.
- Evidence anchors:
  - [section 5.2] "When EPASS is used with 10% of labels, the ECE value of the model decreases... EPASS helps to reduce the ECE by a large margin and also mitigate the overconfidence of the model."
  - [corpus] Weak - no direct evidence in corpus neighbors.
- Break condition: If the ensemble causes underfitting, calibration may improve at the cost of accuracy.

### Mechanism 3
- Claim: Ensemble embeddings improve convergence speed in semi-supervised learning.
- Mechanism: Diverse embeddings from multiple projectors allow the model to learn more informative representations earlier, speeding up convergence.
- Core assumption: Diverse embeddings capture more useful information per batch.
- Evidence anchors:
  - [section 5.1] "EPASS achieves over 50% of accuracy in the first few iterations... the accuracy of SimMatch and CoMatch with EPASS is consistently increasing with iterations."
  - [corpus] Weak - no direct evidence in corpus neighbors.
- Break condition: If projectors introduce conflicting gradients, convergence may slow instead of speed up.

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: EPASS builds on contrastive learning frameworks like MoCo, where embeddings are stored in memory banks.
  - Quick check question: What is the purpose of storing embeddings in a memory bank in contrastive learning?

- Concept: Semi-supervised learning
  - Why needed here: EPASS is designed to improve performance in semi-supervised learning by leveraging unlabeled data.
  - Quick check question: How does pseudo-labeling help in semi-supervised learning?

- Concept: Ensemble methods
  - Why needed here: EPASS uses an ensemble of projectors to combine multiple views of the input.
  - Quick check question: What is the advantage of using an ensemble of models in machine learning?

## Architecture Onboarding

- Component map:
  - Input → Encoder → Multiple Projectors → Ensemble Embeddings → Memory Bank → Contrastive Loss
  - Input → Encoder → Classifier → Supervised Loss

- Critical path:
  - Input → Encoder → Multiple Projectors → Ensemble Embeddings → Memory Bank → Contrastive Loss
  - Input → Encoder → Classifier → Supervised Loss

- Design tradeoffs:
  - Multiple projectors increase parameter count but improve generalization.
  - Ensemble averaging reduces bias but may introduce noise if projectors conflict.
  - Calibration improvement may come at slight accuracy cost.

- Failure signatures:
  - Slow convergence or divergence if projectors learn highly correlated features.
  - Over-smoothing if ensemble averaging is too aggressive.
  - Memory issues if number of projectors is too high.

- First 3 experiments:
  1. Compare single projector vs. ensemble with 2 projectors on CIFAR-10.
  2. Measure ECE and confidence histograms with different projector counts.
  3. Test convergence speed on ImageNet with varying projector ensemble strategies (mean, concatenation, sum).

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of EPASS scale with the number of projectors used beyond 4?
- Basis in paper: [explicit] The paper tests EPASS with 1-4 projectors but does not explore performance beyond this range.
- Why unresolved: The paper only reports results for up to 4 projectors, leaving open the question of whether increasing the number of projectors further improves performance or leads to diminishing returns.
- What evidence would resolve it: Additional experiments testing EPASS with 5 or more projectors on the same benchmark datasets would clarify the scalability and potential benefits of using more projectors.

### Open Question 2
- Question: Can EPASS be effectively applied to semi-supervised learning tasks in domains other than computer vision, such as natural language processing or speech recognition?
- Basis in paper: [inferred] The paper focuses on computer vision tasks and does not explore EPASS's applicability to other domains.
- Why unresolved: The paper does not investigate whether EPASS's approach of using ensemble projectors can be generalized to non-visual data types or tasks beyond image classification.
- What evidence would resolve it: Implementing and evaluating EPASS on semi-supervised NLP or speech recognition tasks would demonstrate its generalizability and potential benefits in these domains.

### Open Question 3
- Question: How does EPASS perform when applied to semi-supervised object detection or segmentation tasks compared to image classification?
- Basis in paper: [inferred] The paper only evaluates EPASS on image classification tasks, not on object detection or segmentation.
- Why unresolved: The paper does not explore whether EPASS's approach of improving embeddings through ensemble projectors is equally effective for tasks that require localizing objects or segmenting images rather than just classifying them.
- What evidence would resolve it: Conducting experiments applying EPASS to semi-supervised object detection and segmentation benchmarks would reveal its effectiveness for these more complex visual tasks.

### Open Question 4
- Question: What is the computational overhead of EPASS in terms of training time and memory usage compared to the baseline methods?
- Basis in paper: [explicit] The paper mentions that EPASS introduces minimal overhead but does not provide specific quantitative measurements of this overhead.
- Why unresolved: While the paper claims EPASS has minimal overhead, it does not report the exact increase in training time or memory usage compared to the baseline methods it improves upon.
- What evidence would resolve it: Providing detailed measurements of the additional training time and memory required when using EPASS compared to the original methods would quantify its computational overhead.

## Limitations
- The debiasing mechanism is not rigorously proven and relies on empirical observations
- The method is only tested on image classification tasks, not on object detection or segmentation
- No quantitative measurements of computational overhead compared to baseline methods

## Confidence
- **High confidence**: The experimental results showing performance improvements when using EPASS with SimMatch and CoMatch on standard benchmark datasets
- **Medium confidence**: The claims about debiasing and calibration improvements
- **Low confidence**: The generalization of results to other SSL frameworks beyond SimMatch and CoMatch

## Next Checks
1. Analyze feature correlation between projectors to quantify diversity and validate the debiasing mechanism
2. Test EPASS with additional SSL frameworks (e.g., FixMatch, MixMatch) to assess generalizability
3. Conduct ablation studies varying the number of projectors and ensemble strategies to optimize the trade-off between performance and computational overhead