---
ver: rpa2
title: Privacy Preserving Multi-Agent Reinforcement Learning in Supply Chains
arxiv_id: '2312.05686'
source_url: https://arxiv.org/abs/2312.05686
tags:
- secure
- player
- data
- learning
- supply
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles privacy preservation in multi-agent reinforcement
  learning (MARL) for supply chains, where organizations must optimize strategies
  without revealing sensitive data. The authors propose a game-theoretic MPC framework
  that uses SecFloat and EzPC to enable secure, floating-point computations.
---

# Privacy Preserving Multi-Agent Reinforcement Learning in Supply Chains

## Quick Facts
- **arXiv ID**: 2312.05686
- **Source URL**: https://arxiv.org/abs/2312.05686
- **Reference count**: 40
- **Primary result**: Privacy-preserving MADDPG using SecFloat/EzPC reduces supply chain wastage by 68.19% and increases revenue by 42.27% compared to no data sharing

## Executive Summary
This paper addresses the challenge of privacy preservation in multi-agent reinforcement learning (MARL) for supply chain optimization. Organizations need to coordinate strategies without revealing sensitive operational data. The authors propose a game-theoretic MPC framework using SecFloat and EzPC to enable secure floating-point computations for privacy-preserving MARL. By decomposing neural network operations into compatible elementary primitives, they create efficient MADDPG variants that maintain both privacy and performance.

## Method Summary
The method implements MADDPG with privacy preservation using SecFloat and EzPC for secure multi-party computation. The approach breaks down neural network forward and backward passes into elementary operations compatible with SecFloat's API. Custom gadgets (F-SecFloat, B-SecFloat, BL-SecFloat) handle secure forward passes, weight updates, and loss calculations respectively. The framework uses 2-party secret sharing with pre-processing to reduce computational overhead. Training proceeds in two phases: initial training without secret sharing followed by a "go-live" phase with full privacy preservation.

## Key Results
- Secure 2PC reduces supply chain wastage by 68.19% compared to no data sharing
- Average cumulative revenue increases by 42.27% per player using secure computation
- Privacy-preserving MADDPG achieves performance equivalent to explicit data exchange scenarios

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Secure 2PC using SecFloat + EzPC enables privacy-preserving MADDPG in supply chains.
- **Mechanism:** Breaks down neural network forward/backward passes into elementary operations compatible with SecFloat API, enabling efficient secure multi-party computation without explicit data exchange.
- **Core assumption:** The decomposition of MADDPG operations into SecFloat-compatible primitives preserves both privacy and computational accuracy.
- **Evidence anchors:** Abstract states the decomposition approach; section describes creating efficient secure versions of MADDPG.

### Mechanism 2
- **Claim:** F-SecFloat and B-SecFloat gadgets reduce computational overhead compared to native SecFloat implementation.
- **Mechanism:** Pre-processes data once per pass, avoiding repeated cross-party dependencies during each primitive operation.
- **Core assumption:** Pre-processing enables alignment of agents' decision-making at crucial iteration stages, avoiding synchronization failures.
- **Evidence anchors:** Section explains preprocessing overhead and constant preprocessing steps per pass.

### Mechanism 3
- **Claim:** Privacy-preserving MADDPG achieves equivalent performance to explicit data exchange.
- **Mechanism:** Fixed external randomness across modes ensures learning trajectories and final metrics match between secure and clear-text execution.
- **Core assumption:** SecFloat's ULP error bound (< 1) ensures floating-point fidelity between secure and non-secure computations.
- **Evidence anchors:** Abstract reports specific performance metrics; section provides lemma on deviation bounds.

## Foundational Learning

- **Concept:** Secure Multi-Party Computation (MPC)
  - Why needed here: Enables joint computation on private inputs without revealing them to other parties.
  - Quick check question: In a 2-party MPC, what does the (t+1)-out-of-n secret sharing scheme guarantee?

- **Concept:** Floating-point secure computation with ULP error bounds
  - Why needed here: Ensures numerical accuracy of neural network operations in the encrypted domain.
  - Quick check question: What does ULP < 1 guarantee about the difference between secure and real-number results?

- **Concept:** Markov Decision Processes in multi-agent settings
  - Why needed here: Provides the theoretical framework for modeling agent interactions and learning optimal policies.
  - Quick check question: In a 2-player supply chain MDP, what are the state and action spaces for each player?

## Architecture Onboarding

- **Component map:** Input pre-processing → F-SecFloat → B-SecFloat/BL-SecFloat → Update weights → Store in replay buffer
- **Critical path:** Pre-process → F-SecFloat → B-SecFloat/BL-SecFloat → Update weights → Store in replay buffer
- **Design tradeoffs:**
  - Security vs. performance: Secure computation adds overhead but preserves privacy.
  - Precision vs. efficiency: Floating-point operations maintain accuracy but are costlier than fixed-point.
  - Preprocessing vs. runtime: Pre-processing reduces per-operation overhead but requires synchronization.
- **Failure signatures:**
  - Mismatched preprocessing between parties → computation stalls
  - ULP errors exceeding bounds → learning divergence
  - Replay buffer desynchronization → policy updates based on stale data
- **First 3 experiments:**
  1. Run F-SecFloat on a small matrix and verify output matches clear-text forward pass within ULP bound.
  2. Execute B-SecFloat on a known gradient and confirm it produces correct weight updates.
  3. Simulate 2-party MADDPG with explicit data exchange and secure mode, compare cumulative rewards over 100 steps.

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does the privacy-preserving MADDPG framework scale to more than two agents in supply chain settings?
- **Basis in paper:** The paper mentions that the framework can be extended to more than two parties if interactions can be reduced to a series of 2-party interactions, and discusses potential use of a non-colluding universal client-server model.
- **Why unresolved:** The paper does not provide experimental results or detailed analysis for scenarios with more than two agents.
- **What evidence would resolve it:** Experimental results demonstrating the framework's performance with three or more agents, including comparisons of computational overhead and effectiveness.

### Open Question 2
- **Question:** What is the impact of different secure multi-party computation protocols on the efficiency and accuracy of the privacy-preserving MADDPG framework?
- **Basis in paper:** The paper uses the SecFloat framework on EzPC for secure 2PC, but does not explore alternative MPC protocols.
- **Why unresolved:** The paper focuses on a specific implementation and does not compare it with other MPC protocols.
- **What evidence would resolve it:** Comparative studies showing performance metrics (e.g., computational time, communication complexity, accuracy) of the framework using different MPC protocols.

### Open Question 3
- **Question:** How does the privacy-preserving MADDPG framework handle dynamic changes in supply chain structures, such as the addition or removal of agents?
- **Basis in paper:** The paper does not discuss the adaptability of the framework to changes in the supply chain structure.
- **Why unresolved:** The experimental setup assumes a static two-player supply chain, and the paper does not address dynamic scenarios.
- **What evidence would resolve it:** Experiments and analysis showing the framework's performance and adaptability when agents are added or removed from the supply chain.

### Open Question 4
- **Question:** What are the trade-offs between privacy preservation and computational efficiency in the privacy-preserving MADDPG framework?
- **Basis in paper:** The paper discusses the computational overhead associated with secure computation and mentions that the secure version is significantly slower than explicit data exchange.
- **Why unresolved:** While the paper provides some insights into computational overhead, it does not fully explore the trade-offs between privacy and efficiency.
- **What evidence would resolve it:** Detailed analysis of computational time and communication complexity for different levels of privacy preservation, along with strategies to optimize the trade-off.

### Open Question 5
- **Question:** How robust is the privacy-preserving MADDPG framework to adversarial attacks or collusion among agents?
- **Basis in paper:** The paper assumes a semi-honest adversarial model where parties follow the protocol but may try to extract sensitive information.
- **Why unresolved:** The paper does not investigate the framework's robustness against more sophisticated attacks or collusion scenarios.
- **What evidence would resolve it:** Security analysis and experiments demonstrating the framework's resilience to various adversarial strategies and collusion attempts.

## Limitations
- Neural network architectures and exact hyperparameters are unspecified, requiring assumptions that may affect reproducibility
- The paper does not provide source code or detailed implementation specifications for the SecFloat/EzPC integration
- Only 2-party supply chain scenarios are evaluated; scalability to larger multi-agent systems remains unverified

## Confidence
- **High confidence** in the core privacy preservation mechanism and its theoretical guarantees (SecFloat ULP bounds, MPC security properties)
- **Medium confidence** in performance claims due to lack of implementation details and hyperparameter specifications
- **Low confidence** in generalizability beyond the specific 2-player supply chain scenario presented

## Next Checks
1. Implement the secure forward/backward pass using SecFloat with a small test network and verify ULP error remains below 1 across 1000 random operations
2. Execute the complete MADDPG training pipeline on a simplified 2-agent supply chain with synthetic data, measuring both computational overhead and learning convergence
3. Compare secure vs. non-secure execution results across multiple random seeds to validate the claimed equivalence of performance metrics (wastage reduction, revenue improvement)