---
ver: rpa2
title: 'Towards Best Practices of Activation Patching in Language Models: Metrics
  and Methods'
arxiv_id: '2309.16042'
source_url: https://arxiv.org/abs/2309.16042
tags:
- patching
- probability
- logit
- corruption
- window
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper examines the impact of methodological choices in activation
  patching for mechanistic interpretability of language models. The authors investigate
  how different corruption methods (Gaussian noise vs symmetric token replacement)
  and evaluation metrics (probability vs logit difference) affect localization results
  in tasks like factual recall and circuit discovery.
---

# Towards Best Practices of Activation Patching in Language Models: Metrics and Methods

## Quick Facts
- **arXiv ID**: 2309.16042
- **Source URL**: https://arxiv.org/abs/2309.16042
- **Authors**: Multiple researchers in mechanistic interpretability
- **Reference count**: 40
- **Key outcome**: The paper examines how methodological choices in activation patching affect interpretability results, finding that corruption method, evaluation metric, and patching approach significantly impact circuit discovery outcomes.

## Executive Summary
This paper systematically investigates how different methodological choices in activation patching affect the reliability and validity of mechanistic interpretability results in language models. The authors compare Gaussian noise versus symmetric token replacement corruption methods, probability versus logit difference evaluation metrics, and single-layer versus sliding window patching approaches. Their experiments on factual recall, IOI circuit discovery, and arithmetic reasoning reveal that Gaussian noise corruption can introduce out-of-distribution behavior that breaks internal mechanisms, probability metrics can miss negative components, and sliding window patching amplifies weak localization signals through non-linear effects. Based on these findings, the authors recommend using symmetric token replacement for corruption, logit difference as the evaluation metric, and caution when interpreting sliding window results.

## Method Summary
The paper uses activation patching, a causal intervention technique that compares model behavior across three forward passes: clean run, corrupted run, and patched run. The authors implement this framework with different corruption methods (Gaussian noise vs symmetric token replacement), evaluation metrics (probability, logit difference, KL divergence), and patching approaches (single-layer vs sliding window). They apply these methods to GPT-2 XL and GPT-2 small models on factual recall tasks, IOI circuit discovery, and arithmetic reasoning problems. The experiments systematically vary these methodological parameters to assess their impact on localization accuracy and circuit discovery effectiveness.

## Key Results
- Gaussian noise corruption produces inconsistent localization results compared to symmetric token replacement, likely due to inducing out-of-distribution model behavior
- Probability as an evaluation metric can overlook negative model components that hurt performance, while logit difference offers finer-grained detection
- Sliding window patching produces more pronounced localization than single-layer patching through non-linear joint effects between adjacent layers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gaussian noise corruption introduces out-of-distribution (OOD) behavior that breaks internal model mechanisms, leading to unreliable localization results.
- Mechanism: When Gaussian noise is added to token embeddings, it creates inputs that deviate significantly from the training distribution. This forces the model to operate in regions where its learned mechanisms may not function as intended, causing attention patterns and activation behaviors to become unpredictable.
- Core assumption: The model's internal mechanisms are optimized for in-distribution inputs and may fail or behave erratically when presented with OOD examples.
- Evidence anchors:
  - [abstract] "Gaussian noise corruption can lead to inconsistent localization and circuit discovery outcomes compared to symmetric token replacement, potentially due to inducing out-of-distribution model behavior"
  - [section 3.2] "We suspect that the gaps between the corruption methods can be attributed partly to model's OOD behavior under GN corruption. In particular, the Gaussian noise may break model's internal mechanisms by introducing OOD inputs to the layers"
  - [corpus] Weak - no direct corpus support found for this specific mechanism

### Mechanism 2
- Claim: Probability as an evaluation metric can overlook negative model components that hurt performance.
- Mechanism: Probability is a non-negative metric that measures the absolute probability of the correct output. Negative components that actively suppress correct outputs will appear to have small or zero effects, even though they are functionally important. This occurs because probability cannot distinguish between a component that has no effect and one that actively hurts performance.
- Core assumption: Negative model components exist and can be functionally important for understanding circuit behavior.
- Evidence anchors:
  - [abstract] "Probability as a metric can overlook negative model components that hurt performance"
  - [section 4.2] "probability must fail to detect negative model components, if corruption reduces the correct token probability to near zero"
  - [corpus] Weak - no direct corpus support found for this specific mechanism

### Mechanism 3
- Claim: Sliding window patching amplifies weak localization signals through non-linear joint effects.
- Mechanism: When multiple adjacent layers are patched simultaneously, their combined effect can be greater than the sum of individual layer effects. This occurs because the joint intervention may suppress the flow of corrupted information across the window or because multiple layers work together to perform a computation that no single layer can achieve alone.
- Core assumption: Model computation involves interactions between adjacent layers that create non-linear effects.
- Evidence anchors:
  - [abstract] "Sliding window patching produces more pronounced localization than single-layer patching"
  - [section 5] "We speculate that simultaneously patching multiple layers could capture the following non-linear effects and results in inflated localization plots"
  - [corpus] Weak - no direct corpus support found for this specific mechanism

## Foundational Learning

- Concept: Causal mediation analysis and its application to neural network interpretability
  - Why needed here: Understanding how activation patching works as a causal intervention technique is fundamental to interpreting the results and their limitations
  - Quick check question: What are the three forward passes required in activation patching, and what does each represent in terms of causal intervention?

- Concept: Difference between probability and logit difference metrics
  - Why needed here: The choice of metric significantly affects which components are detected as important, particularly for negative components
  - Quick check question: Why would probability fail to detect a component that actively suppresses the correct answer probability?

- Concept: Out-of-distribution behavior and its effects on neural network computation
  - Why needed here: Understanding why Gaussian noise corruption may lead to unreliable results requires knowledge of how models behave on OOD inputs
  - Quick check question: What happens to a neural network's internal mechanisms when it encounters inputs far from its training distribution?

## Architecture Onboarding

- Component map: Factual recall localization pipeline (prompts -> corruption -> three forward passes -> metric calculation -> localization plot) -> IOI circuit discovery pipeline (templates -> corruption -> patching -> metric evaluation -> component detection) -> arithmetic reasoning pipeline (math prompts -> corruption -> patching -> metric analysis)

- Critical path: The most important sequence is: load clean and corrupted prompts → apply corruption method → run three forward passes (clean, corrupted, patched) → compute evaluation metric → aggregate results across components → visualize and interpret localization patterns. Any failure in this pipeline will prevent meaningful results.

- Design tradeoffs: The paper compares Gaussian noise vs symmetric token replacement for corruption, probability vs logit difference for metrics, and single-layer vs sliding window patching. Each choice involves tradeoffs between methodological rigor, interpretability, and computational efficiency.

- Failure signatures: Inconsistent results between corruption methods indicate potential OOD issues. Failure to detect known circuit components suggests metric limitations. Weak localization signals that become strong with sliding windows suggest non-linear effects. Noisy plots indicate either model sensitivity or methodological issues.

- First 3 experiments:
  1. Implement single-layer MLP patching on factual recall with both STR and GN corruption using probability metric to reproduce Figure 2
  2. Implement attention head patching on IOI with STR corruption using logit difference to reproduce Table 1 detections
  3. Implement sliding window vs summation comparison for MLP patching on factual recall with probability metric to reproduce Figure 5

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the fundamental differences in model behavior when using Gaussian noise corruption versus symmetric token replacement in activation patching?
- Basis in paper: [explicit] The paper demonstrates that Gaussian noise corruption can lead to out-of-distribution behavior in model internals, disrupting attention patterns and circuit functionality, while symmetric token replacement maintains in-distribution prompts that preserve model behavior.
- Why unresolved: While the paper provides empirical evidence showing discrepancies between the two methods, a complete theoretical understanding of why Gaussian noise specifically breaks internal mechanisms while token replacement preserves them remains unclear.
- What evidence would resolve it: Controlled experiments varying noise intensity and distribution properties, combined with detailed analysis of intermediate layer activations and attention patterns under both corruption methods.

### Open Question 2
- Question: How can we develop more principled techniques for activation patching that avoid introducing out-of-distribution inputs while maintaining effectiveness?
- Basis in paper: [inferred] The paper raises concerns about Gaussian noise introducing OOD behavior and suggests STR as an alternative, but does not provide a comprehensive framework for developing corruption methods that balance in-distribution preservation with effective circuit discovery.
- Why unresolved: The paper identifies the problem but does not offer a systematic approach to designing corruption methods that avoid OOD issues while still enabling effective localization.
- What evidence would resolve it: Development and validation of new corruption methods that provably maintain in-distribution properties while demonstrating equivalent or superior localization performance compared to existing methods.

### Open Question 3
- Question: What is the optimal balance between single-layer patching and sliding window patching for different types of interpretability tasks?
- Basis in paper: [explicit] The paper compares these methods and finds that sliding window patching can amplify weak localization but may capture non-linear joint effects, suggesting different interpretations are needed for each approach.
- Why unresolved: While the paper provides empirical comparisons, it does not establish clear guidelines for when to use each method or how to interpret their results differently.
- What evidence would resolve it: Systematic experiments across diverse tasks showing when each method is most appropriate, combined with theoretical analysis of what each method actually measures.

## Limitations
- The findings are primarily limited to GPT-2 models and may not generalize to other architectures or larger models
- The proposed mechanisms for why corruption methods differ are speculative and not directly empirically verified
- The comparison between corruption methods may be influenced by implementation details not fully specified in the paper
- The paper does not provide a comprehensive framework for developing new corruption methods that avoid OOD issues

## Confidence
- **High confidence**: The observation that probability metrics can miss negative components and that sliding window patching produces stronger localization signals than single-layer patching
- **Medium confidence**: The recommendation to use symmetric token replacement over Gaussian noise corruption based on observed inconsistencies
- **Low confidence**: The proposed explanations for why these patterns occur, particularly the OOD behavior mechanism and non-linear effects explanation

## Next Checks
1. Test the OOD hypothesis directly: Run the same factual recall experiments with models trained with noise injection during pretraining to see if they show more consistent results between GN and STR corruption methods

2. Validate negative component detection: Design a synthetic circuit where negative components are known to be functionally important, then test whether probability, logit difference, and KL divergence metrics can correctly identify these components under different corruption methods

3. Investigate sliding window non-linear effects: Systematically test different window sizes and layer combinations on the IOI task to determine whether the inflated localization is due to joint suppression of corrupted information flow or synergistic computation between layers, using ablation studies to isolate these effects