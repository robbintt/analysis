---
ver: rpa2
title: 'ONNXExplainer: an ONNX Based Generic Framework to Explain Neural Networks
  Using Shapley Values'
arxiv_id: '2309.16916'
source_url: https://arxiv.org/abs/2309.16916
tags:
- gradients
- shap
- shapley
- input
- onnx
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents ONNXExplainer, a generic framework for explaining
  neural networks using Shapley values in the ONNX ecosystem. It addresses the lack
  of cross-platform support and inefficiency in existing tools like SHAP by providing
  its own automatic differentiation and optimization approach.
---

# ONNXExplainer: an ONNX Based Generic Framework to Explain Neural Networks Using Shapley Values

## Quick Facts
- arXiv ID: 2309.16916
- Source URL: https://arxiv.org/abs/2309.16916
- Reference count: 40
- One-line primary result: Improves explanation latency by up to 500% for neural networks using Shapley values in the ONNX ecosystem

## Executive Summary
ONNXExplainer is a generic framework that enables efficient explanation of neural network decisions using Shapley values within the ONNX ecosystem. It addresses key limitations of existing tools like SHAP by providing custom automatic differentiation and optimization techniques that allow one-shot deployment of neural networks with explanations. The framework achieves significant improvements in both latency and memory consumption compared to state-of-the-art methods, making it suitable for real-time production environments where model interpretability is crucial.

## Method Summary
ONNXExplainer introduces a custom automatic differentiation system specifically designed for the ONNX ecosystem, enabling efficient computation of Shapley values for feature attribution. The framework implements an optimization approach that pre-computes intermediate outputs for reference samples during the forward pass, significantly reducing redundant computations. This allows the forward neural network and its corresponding explanation graph to be saved together in a single ONNX file, eliminating the need for separate explanation APIs and dependencies on other deep learning frameworks.

## Key Results
- Achieves up to 500% improvement in explanation latency for VGG19, ResNet50, DenseNet201, and EfficientNetB0
- Significantly reduces memory consumption compared to SHAP, enabling use of more reference samples
- Enables one-shot deployment of neural networks with explanations in production environments
- Provides cross-platform support across ONNX, TensorFlow, and PyTorch frameworks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ONNXExplainer achieves up to 500% improvement in explanation latency by pre-computing intermediate outputs for reference samples during the forward pass.
- Mechanism: The framework optimizes the computation graph by caching commonly-used intermediate outputs during the forward pass. Instead of recomputing the target output for each reference sample comparison (as SHAP does), ONNXExplainer computes the target once, caches it, and broadcasts it for further use. This reduces redundant computations significantly.
- Core assumption: Pre-computing and caching intermediate outputs does not introduce memory bottlenecks and the computational overhead of caching is outweighed by the savings in repeated calculations.
- Evidence anchors:
  - [abstract] "A novel optimization approach that pre-computes intermediate outputs for the reference samples substantially accelerates the explanations as seen in four benchmarked models in three frameworks (ONNX, TensorFlow, and PyTorch)."
  - [section] "In SHAP when the reference data is fed to the model, there are redundant operators during Shapley value's generation. For example, the target point's output is recomputed every time when comparing with a reference point, thus making SHAP inefficient."
- Break condition: If the number of reference samples is extremely large, the memory required to store intermediate outputs may exceed available resources, negating the performance gains.

### Mechanism 2
- Claim: ONNXExplainer's custom automatic differentiation mechanism enables one-shot deployment of neural networks with explanations in production environments.
- Mechanism: The framework builds its own automatic differentiation system that can compute gradients and multipliers directly in the ONNX ecosystem. This allows the forward neural network and its corresponding graph to calculate Shapley values to be saved together in a single ONNX file, eliminating the need for separate explanation APIs and dependencies on other deep learning frameworks.
- Core assumption: The custom automatic differentiation system accurately replicates the behavior of existing frameworks' automatic differentiation and can handle all necessary operators for the target neural networks.
- Evidence anchors:
  - [abstract] "In ONNXExplainer, we develop its own automatic differentiation and optimization approach, which not only enables One-Shot Deployment of neural networks inference and explanations..."
  - [section] "DeepLIFT needs the back-propagation to compute Shapley values and SHAP is reliant on the tf.gradient for TensorFlow and the torch.autograd.grad for PyTorch, both of which are not serializable."
- Break condition: If the custom automatic differentiation system does not support all operators used in the neural networks or has bugs in gradient computation, the explanations will be incorrect or unavailable.

### Mechanism 3
- Claim: ONNXExplainer significantly reduces memory consumption compared to SHAP, allowing for more reference samples and better explanations within the same hardware constraints.
- Mechanism: By pre-computing intermediate outputs and optimizing the computation graph, ONNXExplainer reduces the memory needed for both forward and backward passes. This allows the use of more reference samples without exceeding memory limits, leading to more accurate explanations.
- Core assumption: The memory savings from optimization are substantial enough to allow a significant increase in the number of reference samples that can be used.
- Evidence anchors:
  - [abstract] "In addition, our approach significantly reduces memory consumption when the number of reference samples is same as SHAP, which allows use of more reference samples and thereby enables better explanation with the same hardware constraints."
  - [section] "Table 2 shows the largest number of reference images that can be used on a V100 GPU for each explainer. In general, the optimized approach can use many more reference images than its counterparts both using single and half precision floating point except for OPT-TF for V19 in half precision."
- Break condition: If the neural network architecture is such that memory savings are minimal, the ability to use more reference samples may not be significantly improved.

## Foundational Learning

- Concept: Automatic Differentiation
  - Why needed here: ONNXExplainer requires computing gradients and multipliers for Shapley values, which necessitates a system to automatically differentiate the neural network operations.
  - Quick check question: What is the difference between forward-mode and reverse-mode automatic differentiation, and why is reverse-mode typically preferred for neural networks?

- Concept: Shapley Values and DeepLIFT
  - Why needed here: ONNXExplainer uses Shapley values, approximated via DeepLIFT, to attribute feature importance in neural network predictions. Understanding how these methods work is crucial for implementing the explanation framework.
  - Quick check question: How does DeepLIFT approximate Shapley values, and what are the key differences between the Rescale Rule and the RevealCancel Rule?

- Concept: ONNX (Open Neural Network Exchange)
  - Why needed here: ONNX is the format used by ONNXExplainer to represent and deploy neural networks. Knowledge of ONNX is essential for parsing models and implementing the framework.
  - Quick check question: What are the advantages of using ONNX for model deployment across different frameworks and hardware, and how does it support interoperability?

## Architecture Onboarding

- Component map:
  Neural Network Parser -> Gradients/Multipliers Computation -> Automatic Differentiation -> Optimization -> Shapley Values Generation

- Critical path: The critical path for generating explanations is: Parse ONNX model → Compute gradients/multipliers → Perform automatic differentiation via DFS → Apply optimization → Generate Shapley values.

- Design tradeoffs:
  - Memory vs. Computation: Pre-computing intermediate outputs saves computation time but increases memory usage. The framework must balance these to optimize performance.
  - Framework Support vs. Complexity: Implementing a custom automatic differentiation system allows for greater control and optimization but increases the complexity of the codebase.

- Failure signatures:
  - Incorrect gradients/multipliers: If the gradients or multipliers are not computed correctly, the Shapley values will be wrong, leading to incorrect feature attributions.
  - Memory overflow: If the number of reference samples is too large, the framework may run out of memory, especially during the pre-computation of intermediate outputs.
  - Slow performance: If the optimization is not effective or the custom automatic differentiation is not efficient, the framework may not provide significant performance improvements over existing methods.

- First 3 experiments:
  1. Implement and test the Neural Network Parser on a simple ONNX model to ensure it correctly builds the forward and backward symbolic graphs.
  2. Implement and verify the gradients/multipliers computation for a set of basic operators (e.g., MatMul, Sigmoid) by comparing the results with a known correct implementation.
  3. Benchmark the latency and memory usage of ONNXExplainer on a small neural network (e.g., VGG19) with a small number of reference samples to validate the optimization approach.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas remain unexplored:
- How the performance scales with increasing model size and complexity for much larger neural networks
- The impact of different reference datasets on explanation quality and interpretability
- How the proposed optimization approach compares to other existing techniques for improving Shapley value computation efficiency

## Limitations
- The automatic differentiation implementation's correctness across all ONNX operators is not independently verified
- Memory consumption claims are based on V100 GPU benchmarks; performance on other hardware may vary
- The scalability of the approach with extremely large reference sets remains untested

## Confidence

- **High Confidence:** The core optimization mechanism (pre-computing intermediate outputs) and its basic effectiveness
- **Medium Confidence:** The 500% improvement claim, as it depends on specific model architectures and hardware configurations
- **Medium Confidence:** The one-shot deployment capability, pending independent verification of the ONNX serialization

## Next Checks

1. **Cross-Operator Verification:** Test ONNXExplainer's automatic differentiation on a comprehensive set of ONNX operators beyond those mentioned in the paper to verify robustness
2. **Memory Scaling Analysis:** Evaluate memory consumption patterns with varying numbers of reference samples (10×, 100×, 1000× baseline) to identify potential bottlenecks
3. **Hardware Portability Test:** Benchmark ONNXExplainer on different GPU architectures (e.g., RTX 3090, A100) to assess hardware dependency of the performance gains