---
ver: rpa2
title: Uncertainty Estimation on Sequential Labeling via Uncertainty Transmission
arxiv_id: '2311.08726'
source_url: https://arxiv.org/abs/2311.08726
tags:
- uncertainty
- token
- entity
- entities
- slpn
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses uncertainty estimation in named entity recognition
  (NER), a sequential labeling task where labels are predicted for each token in a
  sequence. The authors propose a Sequential Labeling Posterior Network (SLPN) that
  considers uncertainty transmitted from other tokens, unlike previous methods that
  only focus on individual token uncertainty.
---

# Uncertainty Estimation on Sequential Labeling via Uncertainty Transmission

## Quick Facts
- arXiv ID: 2311.08726
- Source URL: https://arxiv.org/abs/2311.08726
- Reference count: 15
- Key outcome: Proposed Sequential Labeling Posterior Network (SLPN) improves uncertainty estimation in NER by 5.54 points in AUPR on MIT-Restaurant dataset

## Executive Summary
This paper addresses uncertainty estimation in named entity recognition (NER), a sequential labeling task where labels are predicted for each token in a sequence. The authors propose a Sequential Labeling Posterior Network (SLPN) that considers uncertainty transmitted from other tokens, unlike previous methods that only focus on individual token uncertainty. SLPN uses a revised self-attention mechanism to transmit uncertainty between tokens and defines an evaluation strategy to handle wrong-span cases in entity extraction. Experiments on two datasets show that SLPN significantly improves uncertainty estimation performance, achieving a 5.54-point improvement in AUPR on the MIT-Restaurant dataset.

## Method Summary
The paper proposes a Sequential Labeling Posterior Network (SLPN) that improves uncertainty estimation in NER by transmitting uncertainty between tokens. The model uses evidential deep learning with Dirichlet distributions to predict pseudo-evidence vectors for each token, then employs a revised self-attention mechanism to propagate uncertainty based on these vectors. The attention weights are computed using the pseudo-evidence vectors, and the transmitted uncertainty is calculated by weighting the value matrix with these attention scores. The model is trained using Uncertainty Cross Entropy (UCE) loss and entropy regularization, and evaluated on both out-of-distribution (OOD) and wrong-span (WS) tasks using AUPR and AUROC metrics.

## Key Results
- SLPN achieves 5.54-point improvement in AUPR on MIT-Restaurant dataset compared to baseline methods
- The model significantly outperforms previous uncertainty estimation methods on both OOD and WS tasks
- Ablation studies confirm the importance of uncertainty transmission and softplus activation for performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Uncertainty in NER arises from both token-level uncertainty and uncertainty transmitted from other tokens in the sequence.
- Mechanism: The model uses a revised self-attention mechanism to propagate uncertainty between tokens. The attention weights are computed using the pseudo-evidence vectors βpost from each token, and the transmitted uncertainty βtrans is calculated by weighting the value matrix V with these attention scores.
- Core assumption: Token embeddings in NER are accumulated from other tokens, so uncertainty in one token should influence uncertainty in related tokens.
- Evidence anchors:
  - [abstract] "Previous uncertainty estimation models often overlook two unique characteristics of NER: the connection between entities (i.e., one entity embedding is learned based on the other ones) and wrong span cases in the entity extraction subtask."
  - [section 5.2] "Concretely, shown as Figure 2(a), a token embedding has accumulated all other token embeddings by the Bidirectional RNN (Huang et al., 2015) or transformer (Vaswani et al., 2017). As a result, token uncertainty should comprise two components: uncertainty originating from the token itself and uncertainty transmitted from other tokens."
  - [corpus] Weak evidence - only 25 related papers found, no direct citations to this transmission mechanism.
- Break condition: If token embeddings are computed independently (e.g., using a bag-of-words approach) rather than through sequential accumulation, the transmission mechanism would not apply.

### Mechanism 2
- Claim: The SLPN model can simultaneously estimate both aleatoric (data) and epistemic (model) uncertainty for each token.
- Mechanism: By using evidential deep learning with Dirichlet distributions, the model predicts pseudo-evidence vectors that directly encode uncertainty. The entropy of the Dirichlet distribution measures aleatoric uncertainty, while the total evidence (sum of pseudo-counts) measures epistemic uncertainty.
- Core assumption: The Dirichlet distribution provides a natural framework for representing both types of uncertainty in classification tasks.
- Evidence anchors:
  - [section 5.1] "Evidential deep learning (EDL) methods directly predict the concentrate parameters α with a deterministic model and can measure the aleatoric and epistemic uncertainty simultaneously with a single forward pass, instead of multiple forward passes in BNN."
  - [section 3] "Aleatoric uncertainty (or data uncertainty) is the uncertainty related to the class prediction yi and can be measured by the entropy of categorical distribution (i.e. H(Cat(¯pi))) or negative confidence (i.e. −maxk¯pi)."
  - [corpus] Weak evidence - the corpus doesn't provide additional support for this specific claim about simultaneous uncertainty estimation.
- Break condition: If the pseudo-evidence vectors become degenerate (all concentrated on one class), both uncertainty measures would approach zero regardless of true uncertainty.

### Mechanism 3
- Claim: The softplus activation function is critical for maintaining positive pseudo-evidence values during uncertainty transmission.
- Mechanism: The softplus function ensures that the value matrix V in the attention mechanism remains positive, which is required for evidential neural networks that interpret these values as evidence counts.
- Core assumption: Evidential neural networks require positive evidence values, and the attention mechanism could otherwise produce negative values that break the theoretical foundation.
- Evidence anchors:
  - [section 5.2] "Different from self-attention, we keep the shape of the V the same as βpost,t, as the current V has the evidence information and we want to avoid further projection, which might lose the evidence information. Besides, we apply the sof tplus activation function (Sun et al., 2020) to make sure the value of V is always greater than 0 and in a certain range, which is required by the evidential neural network."
  - [section 6.2] "Since β is expected to be positive, we added the softplus operation in Eq.8 to ensure that the transmitted βtrans i remains positive. When we remove the softplus operation (SLPN w/o softplus) and compare it with SLPN, we observe a significant performance decrease in both UE-NER and NER task performances."
  - [corpus] Weak evidence - no corpus support for this specific technical detail.
- Break condition: If the softplus function is removed or replaced with a different activation that allows negative values, the model's uncertainty estimates become unreliable.

## Foundational Learning

- Concept: Evidential Deep Learning and Dirichlet distributions
  - Why needed here: This paper uses EDL to represent uncertainty as pseudo-evidence, which naturally leads to Dirichlet distributions for modeling class probabilities and their uncertainties.
  - Quick check question: How does a Dirichlet distribution differ from a categorical distribution, and why is this distinction important for uncertainty estimation?

- Concept: Self-attention mechanisms in transformer models
  - Why needed here: The paper adapts the self-attention mechanism to propagate uncertainty between tokens rather than just computing token representations.
  - Quick check question: In standard self-attention, what roles do the query, key, and value matrices play, and how are these roles adapted in the uncertainty transmission mechanism?

- Concept: Named Entity Recognition and BIOES labeling scheme
  - Why needed here: Understanding the NER task structure and the BIOES labeling scheme is essential for interpreting how the model handles entity boundaries and wrong-span cases.
  - Quick check question: What is the difference between B-PER and I-PER labels in the BIOES scheme, and how does this relate to entity extraction in NER?

## Architecture Onboarding

- Component map: Text embedding encoder -> MLP projection layer -> Normalizing flow -> Revised attention mechanism -> Uncertainty aggregation layer -> Final uncertainty estimates

- Critical path: Input tokens → Text embedding encoder → MLP projection → Normalizing flow → Pseudo-evidence vectors → Revised attention → Transmitted uncertainty → Uncertainty aggregation → Final uncertainty estimates

- Design tradeoffs:
  - Using softplus activation ensures positive evidence but may limit the range of uncertainty values
  - The attention mechanism adds computational overhead but captures inter-token dependencies
  - The two-part uncertainty (self + transmitted) provides richer estimates but requires careful calibration

- Failure signatures:
  - Negative pseudo-evidence values indicate softplus was not properly applied
  - Uniform uncertainty across all tokens suggests the attention mechanism is not learning meaningful weights
  - Poor OOD detection performance despite good in-domain performance may indicate miscalibrated uncertainty

- First 3 experiments:
  1. Train the model without the attention mechanism (βtrans = 0) to verify that uncertainty transmission improves performance
  2. Replace softplus with ReLU activation to test if the activation function is truly necessary
  3. Test the model on sequences with artificially injected uncertainty to verify the transmission mechanism works as expected

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed Sequential Labeling Posterior Network (SLPN) compare to other uncertainty estimation methods in terms of computational efficiency and scalability?
- Basis in paper: [inferred] The paper does not provide a detailed comparison of SLPN with other uncertainty estimation methods in terms of computational efficiency and scalability.
- Why unresolved: The paper focuses on the effectiveness of SLPN in improving uncertainty estimation for NER tasks, but does not discuss its computational efficiency or scalability compared to other methods.
- What evidence would resolve it: A detailed analysis of the computational complexity and scalability of SLPN compared to other uncertainty estimation methods would provide insights into its practical applicability and efficiency.

### Open Question 2
- Question: How does the performance of SLPN vary across different types of entities and text domains?
- Basis in paper: [explicit] The paper mentions that the performance of SLPN is evaluated on two datasets, MIT-Restaurant and Movie-Simple, but does not provide a detailed analysis of its performance across different entity types or text domains.
- Why unresolved: The paper focuses on the overall performance of SLPN on the two datasets, but does not provide insights into its performance on specific entity types or text domains.
- What evidence would resolve it: A detailed analysis of SLPN's performance on different entity types and text domains would provide insights into its generalizability and applicability to various NER tasks.

### Open Question 3
- Question: How does the proposed uncertainty transmission mechanism in SLPN affect the interpretability of uncertainty estimates?
- Basis in paper: [inferred] The paper introduces a novel uncertainty transmission mechanism in SLPN, but does not discuss its impact on the interpretability of uncertainty estimates.
- Why unresolved: The paper focuses on the effectiveness of the uncertainty transmission mechanism in improving uncertainty estimation, but does not discuss its implications for the interpretability of the estimates.
- What evidence would resolve it: An analysis of how the uncertainty transmission mechanism affects the interpretability of uncertainty estimates would provide insights into the practical implications of using SLPN in real-world applications.

## Limitations

- The model's performance gains may not generalize to other domains or languages beyond the MIT-Restaurant and Movie-Simple datasets
- The theoretical justification for why the softplus activation is critical for performance is limited, relying mainly on empirical ablation studies
- The corpus analysis reveals only 25 related papers with minimal citations, suggesting the approach may be relatively unexplored or the literature search was limited

## Confidence

**High Confidence**: The experimental methodology is sound, with appropriate evaluation metrics (AUPR, AUROC) for uncertainty estimation tasks and proper handling of wrong-span cases. The use of evidential deep learning with Dirichlet distributions for uncertainty quantification is well-established in the literature. The claim that the revised attention mechanism transmits uncertainty between tokens is directly supported by the mathematical formulation and ablation studies.

**Medium Confidence**: The claim that uncertainty in NER arises from both token-level and transmitted uncertainty is logically compelling given the sequential nature of the task, but the paper provides limited empirical evidence distinguishing these components' contributions. The assertion that the softplus activation is critical for performance is supported by ablation studies but could be due to other factors such as numerical stability rather than the specific mathematical properties of softplus.

**Low Confidence**: The broader claim that this approach represents a fundamental advancement in uncertainty estimation for sequential labeling tasks beyond NER is not fully supported. The paper does not compare against recent transformer-based uncertainty methods or explore whether simpler approaches could achieve similar results. The generalizability of the findings to other sequential labeling tasks (POS tagging, dependency parsing) remains untested.

## Next Checks

1. **Ablation study with alternative activation functions**: Replace softplus with other positive-activation functions (ReLU, ELU, GELU) while keeping all other components constant to determine if the specific choice of softplus is truly critical or if any positive-activation function suffices. This would test whether the performance degradation in ablation studies is due to losing the softplus property or simply having unconstrained evidence values.

2. **Cross-domain transfer evaluation**: Evaluate the SLPN model on out-of-domain NER datasets (e.g., CoNLL-2003, OntoNotes) and other sequential labeling tasks to assess the generalizability of the uncertainty transmission mechanism. This would determine whether the observed improvements are specific to the MIT-Restaurant and Movie-Simple datasets or represent a more fundamental advancement.

3. **Visualization of uncertainty transmission patterns**: Create visualizations showing how uncertainty values propagate through the attention mechanism for different types of entities and contexts. This would provide qualitative evidence that the model is learning meaningful uncertainty relationships rather than simply smoothing values, and help identify cases where the transmission mechanism may be failing or producing spurious results.