---
ver: rpa2
title: Co-guiding for Multi-intent Spoken Language Understanding
arxiv_id: '2312.03716'
source_url: https://arxiv.org/abs/2312.03716
tags:
- slot
- intent
- contrastive
- learning
- semantics
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of joint multiple intent detection
  and slot filling in spoken language understanding (SLU). Existing graph-based models
  only model unidirectional guidance from intent to slot, ignoring the bidirectional
  inter-correlations between the two tasks.
---

# Co-guiding for Multi-intent Spoken Language Understanding

## Quick Facts
- **arXiv ID:** 2312.03716
- **Source URL:** https://arxiv.org/abs/2312.03716
- **Reference count:** 40
- **Key outcome:** Co-guiding Net achieves 21.3% relative improvement over previous best model on MixATIS dataset in overall accuracy for joint multi-intent detection and slot filling

## Executive Summary
This paper addresses the challenge of joint multi-intent detection and slot filling in spoken language understanding by proposing a two-stage framework that enables mutual guidance between the two tasks. The key innovation is the use of heterogeneous semantics-label graphs that model bidirectional interactions between intent and slot information, moving beyond unidirectional guidance approaches. The model demonstrates significant performance improvements on multiple benchmark datasets, with a 21.3% relative improvement in overall accuracy on the MixATIS dataset compared to the previous best model.

## Method Summary
The Co-guiding Net implements a two-stage framework for multi-intent SLU. In stage one, a shared self-attentive encoder produces initial predictions for both intent detection and slot filling. In stage two, two heterogeneous graph attention networks (HGATs) model mutual guidance through semantics-label graphs that capture slot-to-intent and intent-to-slot interactions. The model further incorporates supervised contrastive learning mechanisms to improve semantic representations by pulling together similar instances and pushing apart dissimilar ones. The approach is evaluated on MixATIS, MixSNIPS, and MultiATIS++ datasets, demonstrating significant improvements over existing baselines.

## Key Results
- Achieves 21.3% relative improvement in overall accuracy on MixATIS dataset compared to previous best model
- Improves intent detection accuracy and slot filling F1 score simultaneously through mutual guidance mechanism
- Demonstrates effectiveness across multiple datasets (MixATIS, MixSNIPS) and cross-lingual setting (MultiATIS++)
- Ablation studies show heterogeneous graphs and contrastive learning contribute significantly to performance gains

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** The two-stage framework enables mutual guidance between intent detection and slot filling tasks.
- **Mechanism:** Initial predictions from both tasks are used to create heterogeneous semantics-label graphs that enable bidirectional information flow, allowing slot predictions to guide intent detection and vice versa.
- **Core assumption:** Initial predictions contain sufficient information to guide the other task effectively.
- **Evidence anchors:**
  - [abstract] "The proposed Co-guiding Net implements a two-stage framework to achieve mutual guidances between the tasks."
  - [section 3.2.4] "Then we feed H [I,0] and Esl into S2I-HGAT to model their interactions, allowing the estimated slot label information to guide the intent decoding"
  - [corpus] Weak evidence - related papers discuss mutual guidance but don't provide specific evidence about the two-stage approach

### Mechanism 2
- **Claim:** Heterogeneous semantics-label graphs better represent task relationships than homogeneous graphs.
- **Mechanism:** The proposed S2I-SLG and I2S-SLG graphs distinguish between different types of nodes (semantics vs labels) and edges (slot-to-intent vs intent-to-slot), allowing HGATs to learn task-specific relationships more effectively.
- **Core assumption:** Treating all nodes and edges as the same type limits the model's ability to capture task-specific relationships.
- **Evidence anchors:**
  - [abstract] "existing methods... adopt homogeneous graphs to model the interactions between the slot semantics nodes and intent label nodes, which limit the performance"
  - [section 3.1.1] "S2I-SLG is a heterogeneous graph and an example is shown in Fig. 4 (a). It contains two types of nodes: intent semantics nodes and slot label (SL) nodes"
  - [corpus] Moderate evidence - related papers mention graph heterogeneity but don't provide direct evidence about performance differences

### Mechanism 3
- **Claim:** Supervised contrastive learning mechanisms improve semantic representations by capturing single-task and dual-task contrastive relations.
- **Mechanism:** The proposed contrastive learning approaches pull together representations with similar labels while pushing apart those with different labels, both within tasks (single-task) and across tasks (co-guiding).
- **Core assumption:** Representations with the same/similar labels should be closer in the representation space than those with different labels.
- **Evidence anchors:**
  - [abstract] "we further propose Co-guiding-SCL Net, which exploits the single-task and dual-task semantics contrastive relations"
  - [section 4.1.1] "The function of this contrastive learning mechanism is to pull together the utterance representations that have the same/similar intent labels, while pushing apart the ones having different intent labels"
  - [corpus] Weak evidence - related papers discuss contrastive learning but don't provide specific evidence about dual-task contrastive learning

## Foundational Learning

- **Concept:** Graph Neural Networks (GNNs) and Graph Attention Networks (GATs)
  - Why needed here: The model uses heterogeneous graph attention networks (HGATs) to model interactions between task semantics and labels
  - Quick check question: What is the key difference between GATs and standard graph convolutional networks (GCNs)?

- **Concept:** Multi-task learning and task correlations
  - Why needed here: The model leverages correlations between intent detection and slot filling to improve performance on both tasks
  - Quick check question: How do task correlations typically improve performance in multi-task learning frameworks?

- **Concept:** Contrastive learning in NLP
  - Why needed here: The model uses supervised contrastive learning to improve semantic representations by pulling together similar instances and pushing apart dissimilar ones
  - Quick check question: What is the primary objective of contrastive learning in representation learning?

## Architecture Onboarding

- **Component map:** Input → Shared encoder → Initial estimation → Heterogeneous graphs + HGATs → Final predictions
- **Critical path:** Input utterances flow through a shared BiLSTM + self-attention encoder, then through initial estimation stage to produce task predictions, which are used to construct heterogeneous semantics-label graphs. These graphs feed into HGATs that enable mutual guidance, ultimately producing refined final predictions.
- **Design tradeoffs:**
  - Two-stage vs. single-stage framework: Two-stage allows for mutual guidance but adds complexity
  - Heterogeneous vs. homogeneous graphs: Heterogeneous graphs better capture task-specific relationships but are more complex
  - Contrastive learning integration: Improves representations but adds training complexity
- **Failure signatures:**
  - Performance degradation in one task despite improvements in the other
  - Increased training time without corresponding performance gains
  - Overfitting on smaller datasets due to complex graph structures
- **First 3 experiments:**
  1. Compare single-stage vs. two-stage framework on a small dataset
  2. Test homogeneous vs. heterogeneous graph structures
  3. Evaluate impact of contrastive learning with different temperature settings (τ)

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions in the provided text.

## Limitations

- Performance improvements are primarily validated on English datasets with limited cross-lingual validation beyond zero-shot transfer on MultiATIS++
- The two-stage framework adds significant complexity that may not generalize well to smaller datasets or domains with weaker task correlations
- Contrastive learning components require careful hyperparameter tuning (particularly temperature τ and queue sizes) that may be dataset-specific

## Confidence

- **High Confidence:** The heterogeneous graph structure improvement claims are well-supported by ablation studies showing performance degradation when using homogeneous graphs instead
- **Medium Confidence:** The mutual guidance mechanism effectiveness is supported by strong empirical results but relies heavily on the quality of initial predictions in stage one
- **Medium Confidence:** The contrastive learning benefits are demonstrated but the specific dual-task contrastive learning design lacks extensive ablation studies compared to single-task alternatives

## Next Checks

1. **Ablation Study Extension:** Conduct comprehensive ablations removing the two-stage framework, heterogeneous graphs, and contrastive learning components individually to isolate their individual contributions
2. **Cross-Domain Robustness:** Test the model on non-English SLU datasets and non-conversational domains to assess generalizability of the mutual guidance mechanism
3. **Scaling Analysis:** Evaluate model performance across different dataset sizes to determine if the complexity overhead remains justified for smaller training sets