---
ver: rpa2
title: 'NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation'
arxiv_id: '2311.11961'
source_url: https://arxiv.org/abs/2311.11961
tags:
- data
- anomaly
- anomalies
- labeled
- detection
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method for generating pseudo-anomalies
  to improve semi-supervised anomaly detection performance. The key idea is to leverage
  both limited labeled anomalies and large volumes of unlabeled data to generate additional
  anomaly data for training, thereby enhancing the generalization ability of existing
  detection algorithms.
---

# NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly Generation

## Quick Facts
- arXiv ID: 2311.11961
- Source URL: https://arxiv.org/abs/2311.11961
- Reference count: 40
- Key outcome: NNG-Mix generates pseudo-anomalies by mixing labeled anomalies with their nearest neighbors from unlabeled data, improving semi-supervised anomaly detection by up to 16.4% AUCROC across 57 datasets

## Executive Summary
This paper introduces NNG-Mix, a method for generating pseudo-anomalies to enhance semi-supervised anomaly detection. The approach addresses the challenge of limited labeled anomaly data by leveraging both labeled anomalies and large volumes of unlabeled data to generate additional training samples. NNG-Mix prevents pseudo-anomalies from leaking into normal data distribution by mixing labeled anomalies only with their nearest neighbors from the unlabeled set, while introducing Gaussian noise to expand the anomaly space. Extensive experiments on ADBench show consistent improvements across classical, computer vision, and NLP datasets.

## Method Summary
NNG-Mix generates pseudo-anomalies by mixing labeled anomalies with their k nearest neighbors from unlabeled data, followed by Gaussian noise injection before applying Mixup. The method first identifies the top-k nearest neighbors of each labeled anomaly from the unlabeled set, then adds random Gaussian noise to both samples, and finally performs convex combination using a Beta-distributed mixing parameter. This process efficiently integrates information from both labeled and unlabeled data while preventing the generation of pseudo-anomalies that fall within the distribution of unlabeled normal data. The generated pseudo-anomalies are then combined with original labeled anomalies and unlabeled data for training various anomaly detection algorithms.

## Key Results
- Achieves up to 16.4% improvement on Classical datasets, 8.8% on CV datasets, and 8.0% on NLP datasets
- Consistently outperforms other data augmentation methods across 57 diverse datasets in ADBench
- Demonstrates robustness across various parameter settings and pollution ratios in unlabeled data

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NNG-Mix prevents the generation of pseudo-anomalies that fall within the distribution of unlabeled normal data.
- Mechanism: By restricting the Mixup operation to a labeled anomaly and its k nearest neighbors from the unlabeled data, the generated samples remain in the anomaly space rather than overlapping with the normal distribution.
- Core assumption: The k nearest neighbors of an anomaly from unlabeled data are more likely to be anomalies or boundary cases than pure normal samples.
- Evidence anchors:
  - [abstract]: "To prevent the generation of anomaly samples that are within the distribution of unlabeled data, we exclusively mix the anomalies with their top k nearest neighbors from the unlabeled data."
  - [section]: "Instead of randomly selecting an anomaly sample from A and an unlabeled sample from H to mix, our approach involves obtaining a labeled anomaly sample a1 from A and identifying its top k nearest neighbors, denoted as M from the unlabeled set H."

### Mechanism 2
- Claim: Adding Gaussian noise before Mixup expands the effective anomaly space and improves robustness.
- Mechanism: Random perturbations with zero-mean Gaussian noise broaden the potential space for generating pseudo-anomalies, helping the model generalize to unseen anomalies.
- Core assumption: The underlying anomaly distribution is smooth enough that small perturbations still produce valid anomalies.
- Evidence anchors:
  - [abstract]: "Additionally, we introduce random Gaussian noise to the samples before applying Mixup, thereby expanding the potential space for generating pseudo-anomalies."
  - [section]: "Before applying the convex combination of the two samples using the parameter λ drawn from a beta distribution, we augment both a1 and a2 by adding random Gaussian noise with a zero mean and a standard deviation of σ."

### Mechanism 3
- Claim: NNG-Mix leverages information from both labeled anomalies and unlabeled data without introducing mislabeled samples.
- Mechanism: Mixing anomalies with nearest neighbors ensures that generated pseudo-anomalies are contextually related to the original anomaly while still incorporating unlabeled data characteristics.
- Core assumption: Nearest neighbor search from unlabeled data provides a better mixing partner than random selection from the full dataset.
- Evidence anchors:
  - [abstract]: "Our proposed algorithm, named Nearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information from both labeled and unlabeled data to generate pseudo-anomalies."
  - [section]: "This process aims to prevent the generation of anomalies that reside within the distribution of unlabeled data."

## Foundational Learning

- Concept: Nearest Neighbor Search
  - Why needed here: To find suitable unlabeled data points that are close to labeled anomalies for safe Mixup without crossing into normal data distribution.
  - Quick check question: What metric would you use to compute nearest neighbors in a high-dimensional tabular dataset for this task?

- Concept: Beta Distribution for Mixup Coefficient
  - Why needed here: To generate the convex combination parameter λ that blends two samples, controlling how much of each sample is present in the pseudo-anomaly.
  - Quick check question: How does changing the α parameter in Beta(α, α) affect the diversity of generated pseudo-anomalies?

- Concept: Gaussian Noise Injection
  - Why needed here: To augment samples before mixing, increasing the diversity and coverage of the anomaly space.
  - Quick check question: What happens to pseudo-anomaly quality if the noise standard deviation σ is too large?

## Architecture Onboarding

- Component map: Data Loader -> Nearest Neighbor Module -> Noise Injector -> Mixup Engine -> Pseudo-Anomaly Generator -> Training Pipeline
- Critical path: Nearest Neighbor search → Noise injection → Mixup → Pseudo-anomaly generation → Model training
- Design tradeoffs:
  - Nearest neighbor search accuracy vs. computational cost
  - Noise variance vs. risk of generating invalid anomalies
  - Number of generated pseudo-anomalies vs. overfitting risk
  - k value vs. mixing diversity and safety
- Failure signatures:
  - AUCROC drops when unlabeled data contains high anomaly contamination
  - Poor performance if nearest neighbor search returns mostly normal samples
  - Degraded results if noise scale is too large or too small
- First 3 experiments:
  1. Generate 10× pseudo-anomalies using NNG-Mix with k=10, σ=0.01 on a small classical dataset and train DeepSAD; compare AUCROC to baseline.
  2. Vary k (3, 5, 10, 20) on the same dataset; observe impact on AUCROC and nearest neighbor quality.
  3. Test different σ values (0.01, 0.1, 0.3) to find optimal noise scale for pseudo-anomaly quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of NNG-Mix scale with extremely large unlabeled datasets (e.g., millions of samples)?
- Basis in paper: [explicit] The paper demonstrates effectiveness on 57 datasets but does not explore scalability to extremely large unlabeled datasets
- Why unresolved: The experiments used ADBench datasets which, while diverse, do not include extremely large-scale unlabeled data scenarios
- What evidence would resolve it: Empirical results showing performance trends and computational costs when scaling NNG-Mix to datasets with millions of unlabeled samples

### Open Question 2
- Question: What is the theoretical limit of how many pseudo-anomalies can be generated before diminishing returns or negative effects occur?
- Basis in paper: [inferred] The paper shows performance improvements up to 10× pseudo-anomalies but does not establish upper bounds or explore extreme generation ratios
- Why unresolved: The ablation study only explored up to 100× generation, leaving the question of asymptotic behavior unanswered
- What evidence would resolve it: Systematic experiments varying generation ratios from 1× to 1000×, identifying performance plateaus or degradation points

### Open Question 3
- Question: How does NNG-Mix perform when the unlabeled data contains significant contamination (pollution ratio > 60%)?
- Basis in paper: [explicit] The paper explores pollution ratios up to 100% but primarily focuses on lower contamination levels
- Why unresolved: The analysis shows that performance benefits diminish with higher pollution, but does not establish the absolute performance threshold or failure point
- What evidence would resolve it: Extensive experiments across pollution ratios from 0% to 100% with detailed performance breakdowns for different AD algorithms

### Open Question 4
- Question: Can NNG-Mix be effectively adapted for anomaly detection in non-tabular data domains like graphs, time series, or multi-modal data?
- Basis in paper: [explicit] The paper concludes by suggesting this as future work, noting current experiments are limited to tabular data
- Why unresolved: The method relies on k-nearest neighbor search and convex combinations which may not translate directly to non-Euclidean data structures
- What evidence would resolve it: Demonstrations of NNG-Mix variants applied to graph, time series, or multi-modal datasets with performance comparisons to domain-specific methods

### Open Question 5
- Question: What is the relationship between the number of labeled anomalies and the optimal number of pseudo-anomalies to generate?
- Basis in paper: [inferred] The paper shows that more labeled anomalies improve performance, but does not establish an optimal ratio between labeled and pseudo-anomalies
- Why unresolved: Experiments vary labeled anomaly percentages and pseudo-anomaly multiples independently without exploring their interaction
- What evidence would resolve it: A comprehensive grid search identifying optimal pseudo-anomaly generation ratios for different levels of labeled anomaly availability

## Limitations
- Nearest neighbor metric choice is not specified, which could significantly impact pseudo-anomaly quality and computational efficiency
- Performance degradation in highly contaminated unlabeled datasets is not fully characterized
- Method effectiveness depends on unlabeled data containing mostly normal samples

## Confidence
- High confidence: The overall experimental design and benchmark results showing consistent improvements across 57 datasets
- Medium confidence: The theoretical mechanism of preventing pseudo-anomalies from leaking into normal distribution through nearest neighbor selection
- Medium confidence: The claimed improvements (up to 16.4%, 8.8%, and 8.0%) across different dataset categories, though specific baseline comparisons could be more detailed

## Next Checks
1. **Nearest neighbor sensitivity analysis**: Test different distance metrics (Euclidean, cosine, Mahalanobis) on a representative subset of datasets to determine optimal choice for pseudo-anomaly generation quality
2. **Unlabeled data contamination robustness**: Systematically evaluate NNG-Mix performance as the pollution ratio in unlabeled data increases from 0% to 30% to identify failure thresholds
3. **Noise scale optimization**: Conduct grid search over σ values (0.001 to 0.5) on 5 diverse datasets to find optimal noise variance that balances anomaly space coverage and sample validity