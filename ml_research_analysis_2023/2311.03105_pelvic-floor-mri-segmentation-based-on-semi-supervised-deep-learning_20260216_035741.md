---
ver: rpa2
title: Pelvic floor MRI segmentation based on semi-supervised deep learning
arxiv_id: '2311.03105'
source_url: https://arxiv.org/abs/2311.03105
tags:
- learning
- segmentation
- data
- images
- supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This study proposes a semi-supervised deep learning framework
  to improve pelvic organ segmentation from MRI. The method leverages both labeled
  and unlabeled data through two stages: self-supervised pre-training with image restoration
  tasks and semi-supervised fine-tuning using pseudo labels generated from the pre-trained
  model.'
---

# Pelvic floor MRI segmentation based on semi-supervised deep learning

## Quick Facts
- arXiv ID: 2311.03105
- Source URL: https://arxiv.org/abs/2311.03105
- Reference count: 0
- Primary result: Semi-supervised deep learning framework improves pelvic organ MRI segmentation, achieving 2.65% average Dice coefficient gain over supervised learning alone

## Executive Summary
This study introduces a semi-supervised deep learning framework for pelvic organ segmentation from MRI, addressing the challenge of limited annotated medical imaging data. The method employs a two-stage approach: self-supervised pre-training with image restoration tasks on unlabeled data, followed by semi-supervised fine-tuning using pseudo labels generated from the pre-trained model. Evaluated on bladder and uterus segmentation, the framework demonstrates significant performance improvements, with particularly notable gains for the challenging uterus segmentation task. The approach effectively reduces annotation burden while maintaining high segmentation quality, showing promise for clinical applications in pelvic floor imaging.

## Method Summary
The proposed semi-supervised framework operates in two stages: First, self-supervised pre-training uses image restoration tasks (simultaneous down-sampling and shuffling) on unlabeled MRI data to learn robust visual representations. Second, the pre-trained model generates pseudo labels for unlabeled data, which are then used alongside ground truth labels in a semi-supervised learning setup with separate supervised (CE loss) and unsupervised (MSE loss) branches. The framework leverages multi-view MRI data (axial, coronal, sagittal) to capture complementary anatomical features. Evaluation uses Dice Similarity Coefficient (DSC) on bladder and uterus segmentation from 48 MRI series (16 annotated), with matrix size 256x256 and slice thickness 5mm.

## Key Results
- Semi-supervised learning achieved 2.65% average improvement in Dice coefficient compared to supervised learning alone
- Uterus segmentation showed particularly strong gains, with accuracy improvements reaching 3.70%
- Multi-view training (axial, coronal, sagittal) provided better performance than single-view approaches
- The framework demonstrated effectiveness for challenging organs difficult to segment, reducing annotation burden while maintaining quality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pre-training with image restoration tasks transfers useful visual representations to downstream segmentation.
- Mechanism: Self-supervised pre-training learns low-level image structure and texture from unlabeled data, which acts as a strong initialization for segmentation.
- Core assumption: Low-level image restoration capabilities generalize to anatomical structure understanding.
- Evidence anchors:
  - [abstract] "self-supervised pre-training using image restoration tasks"
  - [section] "In this step, the image restoration task is used for self-supervised training and all MR images can be utilized"
  - [corpus] "Self-supervised learning has yielded numerous advances in medicine, aiding deep learning models in feature extraction without annotated data"
- Break condition: If restoration tasks are too domain-specific (e.g., only handle noise patterns not present in real data), generalization will fail.

### Mechanism 2
- Claim: Pseudo-label generation with a self-supervised pre-trained model improves segmentation by increasing effective labeled data.
- Mechanism: The pre-trained model predicts labels for unlabeled images; these pseudo-labels are used to train the final model, creating a semi-supervised training loop.
- Core assumption: Pseudo-labels generated by a pre-trained model are sufficiently accurate to guide training.
- Evidence anchors:
  - [abstract] "self-supervised segmentation model is used to generate pseudo labels for unlabeled data"
  - [section] "In the second stage, the self-supervised segmentation model is used to generate pseudo labels for unlabeled data"
  - [corpus] "The proposed method obtains better results than transfer learning and supervised training with labeled data only"
- Break condition: If the pseudo-labels are noisy or biased, the semi-supervised training may degrade model performance.

### Mechanism 3
- Claim: Multi-view training improves segmentation performance by learning complementary anatomical features.
- Mechanism: Training on axial, coronal, and sagittal views exposes the model to different anatomical contexts, improving generalization across views.
- Core assumption: Different views capture complementary anatomical information that benefits segmentation.
- Evidence anchors:
  - [section] "three-view training can increase the model performance as it can learn the complementary features from different viewpoints"
  - [section] "It shows that U-Netall has better performance than three models trained for coronal, sagittal, and axial view segmentation"
  - [corpus] "Weakly semi-supervised medical image segmentation is an essential application because it only requires a small amount of scribble..."
- Break condition: If views are highly correlated or noisy, training on multiple views may not add value and could introduce confusion.

## Foundational Learning

- Concept: Self-supervised learning via image restoration
  - Why needed here: Reduces reliance on labeled data, which is scarce in medical imaging
  - Quick check question: Can the model recover a high-resolution image from a degraded input?

- Concept: Pseudo-label generation and usage in semi-supervised learning
  - Why needed here: Expands training data without manual annotation, critical for rare anatomical structures like uterus
  - Quick check question: Are pseudo-labels consistent across multiple model predictions?

- Concept: Multi-view anatomical representation
  - Why needed here: Different MRI views capture complementary anatomical details for better segmentation
  - Quick check question: Does the model perform equally well on unseen views when trained on all three?

## Architecture Onboarding

- Component map:
  - CNN1: Image restoration (self-supervised pre-training)
  - CNN2: Segmentation fine-tuning with labeled data
  - CNN3: Semi-supervised segmentation with labeled + pseudo-labeled data
  - Multi-view data loader
  - Pseudo-label generator

- Critical path:
  1. Pre-train CNN1 on unlabeled image restoration
  2. Initialize CNN2 with CNN1 weights, fine-tune on labeled data
  3. Generate pseudo-labels using CNN2
  4. Initialize CNN3 with CNN1 weights, train on labeled + pseudo-labeled data

- Design tradeoffs:
  - Image degradation type: SR vs PS vs hybrid; SR gave better results
  - Loss function: CE vs DL; CE slightly better for semi-supervised branch
  - View sampling: Train on all views vs sampled subset; all views best

- Failure signatures:
  - Pseudo-labels too noisy → semi-supervised training diverges
  - Image restoration too easy → poor feature transfer
  - Single-view training → poor cross-view generalization

- First 3 experiments:
  1. Train CNN1 with SR-only vs PS-only vs hybrid degradation; compare restoration accuracy
  2. Train CNN2 from scratch vs initialized with CNN1; compare segmentation Dice
  3. Train CNN3 with only labeled data vs with pseudo-labels; compare final segmentation performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal balance between labeled and unlabeled data in the semi-supervised framework for pelvic organ segmentation?
- Basis in paper: [explicit] The paper states that semi-supervised learning has better results than supervised learning alone, but the optimal ratio of labeled to unlabeled data is not specified.
- Why unresolved: The paper does not provide experiments with varying ratios of labeled to unlabeled data, making it unclear how to maximize the performance gains from semi-supervised learning.
- What evidence would resolve it: Systematic experiments testing different proportions of labeled vs. unlabeled data to identify the point of diminishing returns.

### Open Question 2
- Question: How does the performance of the semi-supervised framework generalize to other pelvic organs beyond the bladder and uterus?
- Basis in paper: [inferred] The paper focuses on bladder and uterus segmentation, but pelvic floor imaging includes other organs like rectum and vagina that may have different segmentation challenges.
- Why unresolved: The study's validation is limited to two organs, leaving uncertainty about whether the method's benefits extend to other pelvic structures with different anatomical features and imaging characteristics.
- What evidence would resolve it: Testing the framework on a broader range of pelvic organs to assess its generalizability across different anatomical structures.

### Open Question 3
- Question: How sensitive is the pseudo-label generation process to model confidence thresholds and what impact does this have on final segmentation quality?
- Basis in paper: [inferred] The paper uses MSE loss for unsupervised training with pseudo labels but does not discuss confidence thresholds or quality control measures for pseudo-label selection.
- Why unresolved: Poor quality pseudo-labels could degrade performance, but the paper doesn't address how to ensure only reliable pseudo-labels are used in training.
- What evidence would resolve it: Experiments varying confidence thresholds for pseudo-label acceptance and analyzing their impact on segmentation accuracy and robustness.

## Limitations
- Domain Generalization: Performance gains measured only on single MRI scanner (Philips 3T) and specific patient population, limiting generalizability to other protocols
- Pseudo-label Quality: Actual quality and error characteristics of pseudo-labels not quantified, despite their critical role in the framework
- Computational Overhead: Two-stage framework requires training three separate CNN models, increasing computational requirements without efficiency analysis

## Confidence
- High Confidence: Self-supervised pre-training learning low-level image structure is well-established and performance improvements align with semi-supervised medical imaging literature
- Medium Confidence: Pseudo-label generation claims supported by results but need ablation studies on pseudo-label quality impact
- Low Confidence: Generalizability to different MRI protocols, scanners, and patient populations remains uncertain without external validation

## Next Checks
1. Test the semi-supervised framework on an external dataset from a different institution or MRI vendor to assess domain generalization of the 2.65% performance improvement

2. Perform an ablation study measuring pseudo-label accuracy and analyzing how pseudo-label noise affects the final segmentation performance, particularly for the uterus where gains were highest

3. Evaluate the computational cost (training time, inference speed) of the three-stage approach compared to standard supervised segmentation to determine practical utility in clinical settings