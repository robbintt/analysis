---
ver: rpa2
title: 'Message Propagation Through Time: An Algorithm for Sequence Dependency Retention
  in Time Series Modeling'
arxiv_id: '2309.16882'
source_url: https://arxiv.org/abs/2309.16882
tags:
- training
- sequences
- hidden
- states
- sequence
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Message Propagation Through Time (MPTT) addresses the challenge
  of training recurrent neural networks (RNNs) on long time series data by preserving
  temporal dependencies between sequences. MPTT employs two memory modules and three
  policies to asynchronously manage initial hidden states for RNNs, enabling seamless
  information exchange between sequences while allowing diverse mini-batches throughout
  training epochs.
---

# Message Propagation Through Time: An Algorithm for Sequence Dependency Retention in Time Series Modeling

## Quick Facts
- arXiv ID: 2309.16882
- Source URL: https://arxiv.org/abs/2309.16882
- Reference count: 40
- Key outcome: MPTT outperforms seven competing strategies on climate datasets, achieving best predictions for 113 out of 191 river basins in Great Britain while maintaining faster training times than stateful solutions

## Executive Summary
Message Propagation Through Time (MPTT) addresses the challenge of training recurrent neural networks on long time series data by preserving temporal dependencies between sequences. The algorithm employs two memory modules and three policies to asynchronously manage initial hidden states, enabling seamless information exchange between sequences while allowing diverse mini-batches throughout training epochs. Experimental results on four climate datasets demonstrate MPTT's superior performance compared to seven competing strategies, particularly in modeling both short-term and long-term temporal dependencies.

## Method Summary
MPTT is an algorithm for training RNNs on long time series data that preserves temporal dependencies through asynchronous memory management. It uses two memory modules (key-map and state-map) and three policies (read, write, propagate) to manage initial hidden states for RNNs. The algorithm generates informative initial hidden states by combining past epoch memory with current epoch statistics through a weighted average, regulated by exponential decay and auto-adjusted forgetting mechanisms. This approach supports shuffled sequences and diverse mini-batches while maintaining temporal relationships between sequences.

## Key Results
- MPTT outperforms seven competing strategies on four climate datasets
- Achieves best predictions for 113 out of 191 river basins in Great Britain
- Maintains faster training times compared to stateful solutions while preserving temporal dependencies
- Effectively models both short-term and long-term temporal dependencies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: MPTT generates informative initial hidden states by combining past epoch memory (μ₀) with current epoch statistics (¯h₀, c) through a weighted average.
- Mechanism: The read policy computes the initial hidden state as δμ₀ + c¯h₀ / (δ + c), where δ controls the forgetting rate. This allows the model to use both long-term memory from previous epochs and short-term statistics from the current epoch.
- Core assumption: The weighted combination of past and present hidden state information preserves temporal dependencies better than using only current epoch data.
- Evidence anchors:
  - [abstract]: "MPTT further implements three policies to filter outdated and preserve essential information in the hidden states to generate informative initial hidden states for RNNs"
  - [section]: "Equation 3.8 shows that this process is regulated by exponential decay on the low-quality ¯h₀'s generated by under-trained RNNs in early epochs"
- Break condition: If the message keeper δ is set to 0 and no previous epoch data is used, the algorithm degrades to using only current epoch statistics, potentially losing valuable long-term temporal information.

### Mechanism 2
- Claim: MPTT's asynchronous memory management using key-map and state-map enables shuffled sequences and diverse mini-batches while preserving temporal dependencies.
- Mechanism: The key-map tracks which sequences need information from other sequences, while the state-map stores the necessary hidden state information. This allows sequences to be processed in any order without losing temporal relationships.
- Core assumption: Temporal dependencies can be preserved through memory management even when sequences are processed out of temporal order during training.
- Evidence anchors:
  - [abstract]: "MPTT utilizes two memory modules to asynchronously manage initial hidden states for RNNs, fostering seamless information exchange between samples"
  - [section]: "This approach supports shuffled sequences and diverse mini-batches across epochs, preserving long-term dependencies while improving computational efficiency"
- Break condition: If the key-map becomes too large or the state-map becomes outdated, the asynchronous communication may break down, leading to loss of temporal dependencies.

### Mechanism 3
- Claim: MPTT's three forgetting mechanisms (message keeper, exponential decay, auto-adjusted forgetting) automatically balance the importance of recent vs. historical information.
- Mechanism: The message keeper δ controls whether to use past epoch memory, exponential decay reduces the weight of older information, and auto-adjusted forgetting speeds up decay when more training data is available (larger c).
- Core assumption: Different temporal dependencies require different forgetting rates, and these mechanisms can automatically adapt to the data characteristics.
- Evidence anchors:
  - [abstract]: "MPTT further implements three policies to filter outdated and preserve essential information in the hidden states"
  - [section]: "Equation 3.12 underscores how the decay speed is automatically adjusted by the value of c"
- Break condition: If the automatic adjustment fails to match the actual temporal dependency structure of the data, the model may overfit to recent information or fail to capture long-term dependencies.

## Foundational Learning

- Concept: Temporal dependency in time series
  - Why needed here: MPTT specifically addresses the challenge of preserving temporal dependencies across sequences during mini-batch training
  - Quick check question: What happens to RNN performance when temporal dependencies between sequences are ignored during training?

- Concept: Mini-batch gradient descent
  - Why needed here: MPTT operates within the mini-batch training framework but modifies how hidden states are initialized and propagated
  - Quick check question: How does traditional mini-batch training handle hidden states between sequences?

- Concept: Hidden state propagation in RNNs
  - Why needed here: MPTT's core innovation is in how it manages hidden state information across sequences rather than treating each sequence independently
  - Quick check question: What is the difference between stateful and stateless RNN training approaches?

## Architecture Onboarding

- Component map:
  - Key-map: Dictionary mapping sequence IDs to lists of dependent sequence IDs
  - State-map: Dictionary storing (μ₀, ¯h₀, c) tuples for each sequence
  - Read policy: Generates initial hidden states using equation 3.8
  - Write policy: Updates state-map entries based on current sequence's hidden states
  - Propagate policy: Updates μ₀ at epoch boundaries using equation 3.10

- Critical path:
  1. Initialize key-map and state-map before training
  2. For each mini-batch, apply read policy to initialize hidden states
  3. Train model and compute hidden states
  4. Apply write policy to update state-map for dependent sequences
  5. At epoch end, apply propagate policy to update μ₀ values

- Design tradeoffs:
  - Memory vs. performance: MPTT requires additional memory for key-map and state-map but achieves better temporal dependency retention
  - Speed vs. accuracy: MPTT is slower than RMB but faster than fully sequential approaches while maintaining better performance
  - Complexity vs. flexibility: The asynchronous approach adds complexity but allows for shuffled sequences and diverse mini-batches

- Failure signatures:
  - Poor performance on datasets with weak temporal dependencies (similar to RMB results)
  - Memory overflow errors if key-map becomes too large for very long time series
  - Training instability if message keeper δ is not properly tuned

- First 3 experiments:
  1. Compare MPTT vs RMB on a synthetic dataset with known temporal dependencies (like SWAT datasets in the paper)
  2. Test different message keeper δ values (0 vs 1) to understand the impact on performance
  3. Measure training time and memory usage vs state-based approaches to quantify the efficiency gains

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would MPTT perform on time series data with highly non-stationary temporal dependencies where the dependency structure changes dramatically over time?
- Basis in paper: [inferred] The paper demonstrates MPTT's effectiveness on datasets with different types of temporal dependencies (long-term, seasonal, short-term), but doesn't test scenarios where dependency structure changes over time.
- Why unresolved: The paper's experiments use stationary datasets where the nature of temporal dependencies remains consistent throughout the time series.
- What evidence would resolve it: Testing MPTT on datasets with time-varying dependency structures, such as climate data spanning different climate regimes or financial data across different market conditions, would reveal its robustness to non-stationary dependencies.

### Open Question 2
- Question: What is the optimal message keeper (δ) value for different types of time series data, and can this value be learned dynamically during training rather than being fixed?
- Basis in paper: [explicit] The paper notes that "the optimal choice for MPTT message keeper δ is still uncertain" and that "fixed δ = 1 slightly outperforms δ = 0 in experiments."
- Why unresolved: The experiments only compare fixed values of δ (0 or 1), leaving open the question of whether a dynamic or data-dependent approach would be superior.
- What evidence would resolve it: Comparative experiments testing adaptive δ values that change based on training progress, data characteristics, or learned from validation performance would determine if dynamic message keeping improves MPTT's effectiveness.

### Open Question 3
- Question: How does MPTT scale to extremely long time series (e.g., multi-year or multi-decade sequences) in terms of both memory requirements and computational efficiency?
- Basis in paper: [inferred] The paper mentions the asymptotic space complexity of Θ(M(H + W∆)) and notes that "MPTT is slower than RMB due to its frequent interactions with the memory modules," but doesn't explore extreme scale scenarios.
- Why unresolved: The experiments use sequence lengths up to 366 steps, which may not capture the challenges of much longer time series common in some domains.
- What evidence would resolve it: Scaling experiments with progressively longer sequences (e.g., 10,000+ timesteps) measuring both memory usage and training time, along with performance degradation, would reveal practical limitations and inform optimization strategies.

## Limitations

- The paper's claims about MPTT's superiority rely on comparisons with relatively few baseline algorithms (7 competitors)
- The automatic adjustment of forgetting mechanisms is described conceptually but lacks detailed validation across diverse dataset characteristics
- Computational efficiency gains are reported but not extensively benchmarked against state-of-the-art approaches

## Confidence

- **High Confidence**: The mechanism of using weighted averages to combine past and present hidden state information (Mechanism 1) is well-supported by the mathematical formulation and experimental results
- **Medium Confidence**: The asynchronous memory management approach (Mechanism 2) shows promise but requires more extensive testing across different sequence lengths and temporal dependency structures
- **Medium Confidence**: The three forgetting mechanisms (Mechanism 3) appear theoretically sound but need more empirical validation, particularly regarding the automatic adjustment of decay rates

## Next Checks

1. **Cross-dataset validation**: Test MPTT on datasets with varying temporal dependency patterns (e.g., financial time series, sensor data, biological signals) to verify its general applicability beyond climate data

2. **Memory overhead analysis**: Conduct detailed profiling of memory usage for key-map and state-map as sequence length increases, particularly for extremely long time series, to identify scalability limits

3. **Hyperparameter sensitivity**: Perform systematic ablation studies on message keeper δ and forgetting rate parameters to determine optimal settings for different types of temporal dependencies and assess robustness to hyperparameter choices