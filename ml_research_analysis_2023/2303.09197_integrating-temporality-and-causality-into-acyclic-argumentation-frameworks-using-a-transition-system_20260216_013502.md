---
ver: rpa2
title: Integrating Temporality and Causality into Acyclic Argumentation Frameworks
  using a Transition System
arxiv_id: '2303.09197'
source_url: https://arxiv.org/abs/2303.09197
tags:
- state
- argument
- which
- argumentative
- nition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a method to integrate temporality and causality
  into abstract argumentation frameworks (AAF) by translating them into an action
  language. The proposed approach allows modeling the evolution of the world and establishing
  causal relationships between the enunciation of arguments and their consequences.
---

# Integrating Temporality and Causality into Acyclic Argumentation Frameworks using a Transition System

## Quick Facts
- arXiv ID: 2303.09197
- Source URL: https://arxiv.org/abs/2303.09197
- Reference count: 6
- Key outcome: Formal method to rewrite acyclic abstract argumentation frameworks into an action language, enabling causal explanations and enriched visualizations

## Executive Summary
This paper presents a formal method to integrate temporality and causality into acyclic abstract argumentation frameworks (AAF) by translating them into an action language. The approach models the evolution of argument acceptability over time and establishes causal relationships between argument enunciation and their consequences. An Answer Set Programming (ASP) implementation is provided, along with formal proofs of soundness and completeness. The framework enables extraction of causal chains for explanations and proposes two types of graphical representations to visualize argumentation processes and causal relations.

## Method Summary
The method translates an acyclic AAF into an action language by defining fluents to represent argument presence, acceptability, and attack relations. Actions represent argument enunciation with ranked execution to preserve temporal order. Exogenous events automatically update acceptability when preconditions are met. The entire system is encoded as ASP rules, with causality extracted using NESS causation definitions. The approach generates unique traces of argumentative states and identifies actual causes for explanation purposes.

## Key Results
- Formal translation from acyclic AAF to action language with ranked actions and exogenous events
- Soundness and completeness proofs for the ASP encoding
- Ability to extract causal chains using NESS causation
- Two proposed graphical representations for visualizing argumentation and causal relations

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Temporal ordering of argument enunciation is captured by mapping the dialogue sequence into ranked actions in the action language, ensuring a unique trace of states.
- **Mechanism**: The transformation replaces the static set of arguments A with a sequence Δ of (argument, order) pairs, then maps each argument x to an action enunciate_x with a rank. The semantics require actions to fire in rank order, guaranteeing that the state trace reflects the exact order of argument appearance.
- **Core assumption**: The dialogue order is preserved and no two arguments share the same rank; the action language semantics enforce strict sequential progression.
- **Evidence anchors**:
  - [abstract] "a formal method to rewrite the concepts of acyclic abstract argumentation frameworks into an action language, that allows us to model the evolution of the world"
  - [section] "In order to formalise an AAF in the action language... let us first define the variables necessary to describe the world"
  - [corpus] Weak: no direct citation found linking ranked actions to argumentation order; relies on general action language literature.
- **Break condition**: If two arguments are assigned the same rank, or if the semantics allow concurrent execution of actions, the trace uniqueness and temporal capture fail.

### Mechanism 2
- **Claim**: Acceptability updates are encoded as exogenous events that fire automatically when preconditions are met, allowing the argumentation state to evolve without manual intervention.
- **Mechanism**: Two event types are introduced: makesUnacc_y,x triggers when y attacks x and both are acceptable, marking x unacceptable; makesAcc_x triggers when x is present but not acceptable and none of its attackers are acceptable, marking x acceptable. These events are exogenous and fire immediately in argumentative states.
- **Core assumption**: The attack relation and acceptability conditions can be fully expressed as logical preconditions on fluents; no external constraints or cyclic dependencies exist.
- **Evidence anchors**:
  - [abstract] "a formal method to rewrite the concepts of acyclic abstract argumentation frameworks into an action language"
  - [section] "An argument is acceptable only if it is unattacked or attacked only by unacceptable arguments"
  - [corpus] Weak: no direct paper citations showing acceptability as exogenous events; concept borrowed from action language causality literature.
- **Break condition**: If the attack graph contains cycles or if acceptability depends on external context not captured by fluents, the event preconditions cannot be satisfied correctly.

### Mechanism 3
- **Claim**: Causal explanations are extracted by identifying actual causes and NESS-causes from the event trace, enabling identification of arguments whose absence would change the final acceptability.
- **Mechanism**: Using the actual causation definition from (Sarmiento et al. 2022), the system traces back from final acceptable/rejected arguments to the events that were necessary and sufficient for them. These causal relations can then be visualised and used to construct explanations.
- **Core assumption**: The event trace contains all relevant causal information; the NESS causation definition correctly captures argumentative necessity.
- **Evidence anchors**:
  - [abstract] "establish causal relationships between the enunciation of arguments and their consequences"
  - [section] "The actual causation definition proposed by (Sarmiento et al. 2022) is an action language suitable formalisation of Wright’s NESS test"
  - [corpus] Weak: no explicit citations showing causal extraction from argumentation traces; relies on external action language causality literature.
- **Break condition**: If the causal chain involves hidden dependencies or if the NESS definition misclassifies overdetermined causes, explanations may be misleading.

## Foundational Learning

- **Concept**: Action language semantics with exogenous events and ranked actions
  - Why needed here: To model the evolution of argument acceptability over time and enforce the temporal order of argument enunciation.
  - Quick check question: What distinguishes an exogenous event from a ranked action in this context?

- **Concept**: Acyclic argumentation framework and acceptability semantics
  - Why needed here: The transformation assumes acyclicity to simplify acceptability computation and causal chain extraction.
  - Quick check question: How is acceptability defined for an argument in an acyclic graph?

- **Concept**: NESS causation and actual causality in action languages
  - Why needed here: To extract meaningful causal explanations from the argument interaction trace.
  - Quick check question: What does NESS stand for, and why is it relevant for argumentation causality?

## Architecture Onboarding

- **Component map**: Dialogue parser -> sequence Δ of (argument, order) -> Translator module -> ASP rules -> Solver -> Unique traces -> Causality extractor -> Causal chains -> Visualizer -> State and causal graphs
- **Critical path**: Parse dialogue -> Build ASP program -> Solve -> Extract traces -> Compute causality -> Generate visual explanations
- **Design tradeoffs**:
  - Using exogenous events ensures automatic state updates but may miss complex interdependencies.
  - Encoding acceptability as fluents keeps the model simple but limits expressiveness for non-acyclic graphs.
  - Ranked actions enforce order but require careful assignment to avoid conflicts.
- **Failure signatures**:
  - Non-unique traces -> rank assignment or concurrency semantics issue.
  - Incomplete acceptability updates -> missing or incorrect event preconditions.
  - Incorrect causal chains -> flawed causality definitions or incomplete trace analysis.
- **First 3 experiments**:
  1. Encode a simple two-argument attack and verify that the trace reflects the order and final acceptability.
  2. Introduce a three-argument cycle and confirm the system rejects or flags it as unsupported.
  3. Extract causal explanations for a given dialogue and compare them against manual reasoning.

## Open Questions the Paper Calls Out

- **Open Question 1**: What are the most effective ways to develop causal explanations from the causal chains extracted in this framework, and how can these be applied to real-world argumentative scenarios?
  - Basis in paper: [explicit] The paper mentions the need for further work to develop explanations using the causal chains, emphasizing the importance of short, contrastive explanations and reasoning about counterfactual scenarios.
  - Why unresolved: The paper identifies this as a future direction but does not provide specific methods or algorithms for constructing such explanations.
  - What evidence would resolve it: Developing and testing algorithms for generating concise causal explanations, along with user studies to evaluate their effectiveness in real-world argumentative scenarios.

- **Open Question 2**: How does the proposed action language-based formalization of argumentation compare to alternative approaches, such as structural equations, in terms of computational efficiency and explanatory power?
  - Basis in paper: [explicit] The paper briefly mentions structural equations as an alternative causal model and highlights the differences in computational complexity and philosophical underpinnings.
  - Why unresolved: The paper does not provide a direct comparison between the proposed approach and structural equations in terms of performance or explanatory capabilities.
  - What evidence would resolve it: Conducting empirical studies to compare the computational efficiency and explanatory power of the proposed approach and structural equations on a range of argumentative scenarios.

- **Open Question 3**: How can the graphical representations proposed in this paper be further enhanced to better visualize and communicate the causal relationships between arguments?
  - Basis in paper: [explicit] The paper introduces two types of graphical representations (a simplified form and a tabular form) but acknowledges the need for further work to develop more effective visualizations.
  - Why unresolved: The paper does not explore alternative visualization techniques or evaluate the effectiveness of the proposed representations in conveying causal information.
  - What evidence would resolve it: Designing and testing alternative visualization techniques, such as interactive or dynamic visualizations, and conducting user studies to assess their effectiveness in communicating causal relationships.

## Limitations

- The approach assumes acyclicity of the argumentation graph, which limits applicability to more complex argumentative scenarios.
- The causal explanation extraction relies on external definitions of NESS causation without validation against argumentation-specific benchmarks.
- No empirical evaluation of computational feasibility or scalability of the ASP encoding is provided.

## Confidence

- **High**: Formal definitions of acceptability and core translation from AAF to action language
- **Medium**: Mechanism for causal explanation extraction using NESS causation
- **Low**: Practical utility of causal visualizations without user study or real-world data

## Next Checks

1. Test the ASP implementation on dialogue sequences with known outcomes to verify that the computed causal chains match expected argumentative reasoning.
2. Evaluate the scalability of the approach by encoding progressively larger argumentation graphs and measuring solution time and trace complexity.
3. Validate the correctness of the causal explanation extraction by comparing NESS-derived causes against manually constructed argumentative justifications.