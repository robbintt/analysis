---
ver: rpa2
title: Synthetic Query Generation for Privacy-Preserving Deep Retrieval Systems using
  Differentially Private Language Models
arxiv_id: '2305.05973'
source_url: https://arxiv.org/abs/2305.05973
tags:
- data
- privacy
- synthetic
- training
- retrieval
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for training privacy-preserving deep
  retrieval systems by generating synthetic queries with differentially private (DP)
  language models. Instead of directly training retrieval models with DP, which is
  challenging due to non-per-example decomposable contrastive losses, the approach
  uses DP to fine-tune a public pre-trained LLM on a conditional query generation
  task.
---

# Synthetic Query Generation for Privacy-Preserving Deep Retrieval Systems using Differentially Private Language Models

## Quick Facts
- **arXiv ID:** 2305.05973
- **Source URL:** https://arxiv.org/abs/2305.05973
- **Reference count:** 40
- **Primary result:** Generates synthetic queries with DP LLMs to train privacy-preserving retrieval systems that outperform direct DP training

## Executive Summary
This paper introduces a method for training privacy-preserving deep retrieval systems by generating synthetic queries using differentially private language models. The approach addresses the challenge of direct DP training for retrieval models, which struggle with non-per-example decomposable contrastive losses. By fine-tuning public pre-trained LLMs with DP on a conditional query generation task, the method produces private synthetic queries that can be used to train downstream retrieval models without additional privacy cost. Evaluations demonstrate that retrieval models trained on DP synthetic data achieve significantly better performance than those trained directly with DP on original data, while maintaining strong query-level privacy guarantees and zero-shot generalization capabilities.

## Method Summary
The method trains DP language models (specifically T5) on the task of generating queries conditioned on documents from private datasets. These DP-finetuned models generate synthetic query-document pairs that are representative of the original data but with formal privacy guarantees. The synthetic data is then used to train downstream retrieval models (dual encoders) without additional privacy cost due to the post-processing property of DP. The approach uses DP-SGD for training with gradient clipping and noise addition, and employs nucleus sampling for synthetic query generation. The synthetic queries maintain semantic fidelity to original queries while providing privacy protection, and the method shows strong performance across both in-domain (MSMARCO) and zero-shot (BEIR) evaluations.

## Key Results
- Retrieval models trained on DP synthetic data achieve NDCG@10 up to 0.2590, significantly outperforming direct DP training
- Larger DP-finetuned models generate higher quality synthetic queries, leading to improved retrieval performance
- The method demonstrates strong zero-shot generalization on BEIR datasets
- Synthetic queries successfully resist membership inference attacks while maintaining semantic fidelity to original queries

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Using DP-trained LLMs to generate synthetic queries decouples privacy guarantees from downstream retrieval training
- **Mechanism:** The approach trains a DP LLM on conditional query generation, creating synthetic queries that are representative of original data. These can be used for downstream training without additional privacy cost via post-processing property
- **Core assumption:** Synthetic queries are sufficiently representative of original queries to maintain retrieval quality
- **Evidence anchors:** Abstract states DP LMs generate "private synthetic queries representative of the original data"; section notes post-processing property allows secure sharing without additional privacy cost
- **Break condition:** If synthetic queries aren't representative, retrieval quality degrades; if post-processing property doesn't hold, additional privacy cost is incurred

### Mechanism 2
- **Claim:** Training on synthetic data from DP LLMs outperforms direct DP training of retrieval models
- **Mechanism:** Synthetic data generation introduces public knowledge through pre-trained LLM, augmenting original data and improving generalization
- **Core assumption:** Pre-trained LLM has sufficient knowledge to generate high-quality synthetic queries that augment original data
- **Evidence anchors:** Abstract notes "significant enhancement in retrieval quality compared to direct DP-training"; section observes synthetic data augments original data and improves generalization
- **Break condition:** If pre-trained LLM lacks sufficient knowledge or augmentation doesn't improve generalization, performance won't outperform direct DP training

### Mechanism 3
- **Claim:** Larger DP-finetuned LLMs generate higher quality synthetic queries, improving retrieval performance
- **Mechanism:** Larger models have more parameters and capacity to learn complex patterns, generating more diverse and representative synthetic queries
- **Core assumption:** Larger models can generate more diverse and representative synthetic queries
- **Evidence anchors:** Abstract states "Larger DP-finetuned models further improve performance"; section notes synthetic data augments original data
- **Break condition:** If larger models don't generate more diverse queries or increased diversity doesn't lead to better generalization, performance improvement won't be observed

## Foundational Learning

- **Concept:** Differential Privacy (DP)
  - **Why needed here:** Foundation for ensuring query-level privacy in synthetic query generation
  - **Quick check question:** What is the main difference between example-level privacy and query-level privacy in this context?

- **Concept:** Contrastive Learning
  - **Why needed here:** Crucial for understanding challenges of direct DP training in retrieval systems
  - **Quick check question:** How does the in-batch softmax loss in contrastive learning differ from per-example decomposable losses?

- **Concept:** Large Language Models (LLMs)
  - **Why needed here:** Core component for generating synthetic queries; understanding capabilities and limitations essential
  - **Quick check question:** What are the key advantages of using encoder-decoder LLMs like T5 for conditional text generation tasks?

## Architecture Onboarding

- **Component map:** Private training data (query-document pairs) -> Publicly pre-trained LLM (T5) -> DP training mechanism (DP-SGD) -> DP-finetuned LLM -> Synthetic query generation -> Downstream retrieval model training

- **Critical path:**
  1. Train DP-finetuned LLM on conditional query generation task
  2. Generate synthetic queries using DP-finetuned LLM
  3. Train downstream retrieval model on synthetic data

- **Design tradeoffs:**
  - Privacy vs. utility: Stricter DP guarantees (lower Îµ) may lead to lower utility in synthetic queries and downstream models
  - Model size vs. performance: Larger DP-finetuned LLMs may generate better synthetic queries but require more computational resources
  - Data augmentation vs. overfitting: Synthetic data may introduce public knowledge but could lead to overfitting if not properly regularized

- **Failure signatures:**
  - Poor retrieval performance: May indicate synthetic queries aren't representative or downstream model isn't properly trained
  - High privacy leakage: May indicate DP-finetuned LLM isn't properly trained or synthetic queries contain sensitive information
  - Computational inefficiency: May indicate DP training or synthetic generation isn't properly optimized

- **First 3 experiments:**
  1. Train small DP-finetuned LLM (T5-Small) on MSMARCO subset; evaluate synthetic query quality using BLEU and MAUVE scores
  2. Train downstream retrieval model (T5-Base dual encoder) on synthetic data; evaluate on MSMARCO test set
  3. Repeat experiment 2 with larger DP-finetuned LLMs (T5-Large, T5-XL); compare retrieval performance to identify impact of model size

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions but identifies several areas for future work including exploring alternative architectures, investigating the trade-off between privacy and utility more systematically, and extending the approach to other recommendation domains beyond information retrieval.

## Limitations
- The empirical privacy analysis demonstrates resistance to membership inference attacks but lacks formal privacy guarantees about the complete pipeline
- The approach assumes publicly pre-trained LLMs have sufficient coverage of domain-specific queries, which may not hold for highly specialized domains
- The scalability to extremely large-scale retrieval systems with billions of parameters remains unexplored

## Confidence
**High Confidence Claims:**
- Using DP-trained LLMs for synthetic query generation works in principle and provides practical privacy benefits
- Post-processing property of DP applies to synthetic query generation, allowing downstream training without additional privacy cost
- Larger DP-finetuned models generally produce better synthetic queries and downstream performance

**Medium Confidence Claims:**
- Performance gains over direct DP training are primarily due to augmentation effect from public knowledge in pre-trained LLMs
- Synthetic queries maintain semantic fidelity while providing privacy protection
- Zero-shot generalization on BEIR indicates robust synthetic data quality

**Low Confidence Claims:**
- Exact magnitude of privacy protection against sophisticated adversarial attacks
- Scalability to extremely large-scale retrieval systems with billions of parameters
- Long-term effectiveness as language models and retrieval systems continue to evolve

## Next Checks
1. **Formal Privacy Analysis:** Conduct rigorous differential privacy analysis of the complete pipeline, including synthetic generation process, to provide formal privacy guarantees beyond empirical membership inference resistance

2. **Domain Transfer Robustness:** Evaluate approach on datasets from domains with substantially different query distributions (medical, legal, technical) to assess limitations of public pre-training knowledge

3. **Adversarial Robustness Testing:** Design targeted adversarial attacks specifically crafted to exploit potential vulnerabilities in synthetic query generation, including attacks leveraging structural properties of generation process