---
ver: rpa2
title: 'RemovalNet: DNN Fingerprint Removal Attacks'
arxiv_id: '2308.12319'
source_url: https://arxiv.org/abs/2308.12319
tags:
- removal
- victim
- distance
- surrogate
- fingerprint
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates DNN fingerprint removal attacks for the
  first time. The proposed REMOVAL NET removes fingerprint-specific knowledge from
  a victim model via min-max bilevel optimization while maintaining general semantic
  knowledge to preserve accuracy.
---

# RemovalNet: DNN Fingerprint Removal Attacks

## Quick Facts
- arXiv ID: 2308.12319
- Source URL: https://arxiv.org/abs/2308.12319
- Authors: 
- Reference count: 40
- Key outcome: Proposed REMOVAL NET removes DNN fingerprints via min-max bilevel optimization, achieving 100x higher model distance than baselines while using only 0.2% substitute data and maintaining high accuracy.

## Executive Summary
This paper introduces REMOVAL NET, the first systematic approach for removing digital fingerprints from DNN models. The method employs min-max bilevel optimization to simultaneously remove fingerprint-specific knowledge while preserving general semantic knowledge through knowledge distillation. Extensive experiments on five datasets demonstrate superior effectiveness, efficiency, and fidelity compared to baseline attacks.

## Method Summary
REMOVAL NET addresses DNN fingerprint removal through a novel min-max bilevel optimization framework. The lower-level optimization removes fingerprint-specific knowledge by maximizing distance between victim and surrogate model outputs, while the upper-level optimization preserves task performance by distilling the victim model's general semantic knowledge. The approach combines latent-level removal (altering feature map activation patterns) and logits-level removal (shifting decision boundary behavior) to obfuscate behavioral patterns across multiple verification dimensions. The method requires only 0.2% of substitute data and converges in 1000 iterations while maintaining high fidelity.

## Key Results
- Model distance increases by 100x compared to baseline attacks
- Achieves high fidelity with preserved accuracy after fingerprint removal
- Uses only 0.2% of substitute data and requires 1000 iterations
- Effective against multiple fingerprinting verification methods including DeepJudge, ZEST, ModelDiff, and IPGuard

## Why This Works (Mechanism)

### Mechanism 1
Bilevel optimization enables targeted removal of fingerprint-specific knowledge while preserving general semantic knowledge. Lower-level optimization removes fingerprint-specific behavior by maximizing distance between victim and surrogate model outputs. Upper-level optimization preserves task performance by distilling victim's general semantic knowledge. Core assumption: Fingerprint-specific and general semantic knowledge can be disentangled and optimized separately. Break condition: If fingerprint-specific and general semantic knowledge are not separable, or if removing one inevitably damages the other.

### Mechanism 2
Latent-level and logits-level removal together obfuscate behavioral patterns across multiple verification dimensions. Latent-level removal alters feature map activation patterns. Logits-level removal shifts decision boundary behavior. Combined, they evade both representation-based and boundary-based fingerprinting methods. Core assumption: Different fingerprinting methods rely on different behavioral aspects that can be independently perturbed. Break condition: If fingerprinting methods adapt to detect both representation and boundary changes simultaneously.

### Mechanism 3
Iterative perturbation of reversed latent space and logits creates non-robust features that break fingerprinting without catastrophic forgetting. Reverse-engineering creates perturbed representations that maintain semantic meaning while differing behaviorally. Iterative least-likely boundary strategy finds logits perturbations that maintain classification while shifting decision boundaries. Core assumption: Small perturbations can significantly alter behavioral patterns while preserving core functionality. Break condition: If perturbations needed for fingerprinting removal cause unacceptable performance degradation.

## Foundational Learning

- Concept: Bilevel optimization
  - Why needed here: The removal attack requires simultaneously optimizing two conflicting objectives - removing fingerprints while preserving performance.
  - Quick check question: What distinguishes bilevel optimization from standard multi-objective optimization?

- Concept: Feature detachment and latent space manipulation
  - Why needed here: Removing fingerprints requires understanding how to modify internal representations without breaking the model's core functionality.
  - Quick check question: How does feature detachment differ from standard feature extraction?

- Concept: Decision boundary analysis and manipulation
  - Why needed here: Many fingerprinting methods rely on boundary behavior, so understanding how to shift boundaries without losing accuracy is crucial.
  - Quick check question: What mathematical properties make decision boundaries detectable for fingerprinting?

## Architecture Onboarding

- Component map: Substitute set selection → Latent-level removal (feature shuffling, distance maximization) → Logits-level removal (ILBS, boundary interpolation) → Bilevel optimization loop
- Critical path: Substitute selection → Bilevel optimization (1000 iterations) → Model evaluation against fingerprinting metrics
- Design tradeoffs: Balance between fingerprint removal effectiveness and fidelity preservation; computational efficiency vs. attack success rate
- Failure signatures: High accuracy drop indicates over-aggressive fingerprint removal; low distance scores indicate insufficient fingerprint obfuscation
- First 3 experiments:
  1. Verify substitute set selection maintains diversity and distribution similarity
  2. Test bilevel optimization convergence with synthetic data where ground truth fingerprints are known
  3. Validate individual latent-level and logits-level components work separately before integration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does REMOVALNET perform against black-box fingerprinting defenses like ModelDiff and IPGuard?
- Basis in paper: [explicit] The paper states REMOVALNET is effective against these defenses but doesn't provide detailed comparisons.
- Why unresolved: The paper focuses on white-box defenses and doesn't thoroughly evaluate black-box scenarios.
- What evidence would resolve it: Detailed experiments comparing REMOVALNET's performance against black-box fingerprinting methods on multiple datasets.

### Open Question 2
- Question: What is the impact of dataset inference techniques on REMOVALNET's effectiveness?
- Basis in paper: [explicit] The paper discusses dataset inference as a potential countermeasure but doesn't evaluate it experimentally.
- Why unresolved: The paper identifies dataset inference as a promising direction but doesn't test it against REMOVALNET.
- What evidence would resolve it: Experimental results showing whether dataset inference can detect REMOVALNET-created surrogate models.

### Open Question 3
- Question: How does REMOVALNET perform on non-vision domains like NLP and graph neural networks?
- Basis in paper: [explicit] The paper states it focuses on computer vision tasks and acknowledges potential extension to other domains.
- Why unresolved: The paper only evaluates REMOVALNET on vision tasks and doesn't test it on other model types.
- What evidence would resolve it: Experimental results showing REMOVALNET's effectiveness on NLP and graph neural network models.

## Limitations

- The fundamental assumption that fingerprint-specific and general semantic knowledge can be completely disentangled without performance impact remains theoretically unproven
- The 100x improvement over baselines lacks comparison against simpler optimization strategies
- Claims about effectiveness against black-box fingerprinting defenses require further experimental validation

## Confidence

- **High Confidence**: The proposed architecture (latent-level + logits-level removal) is technically sound and the experimental methodology is rigorous
- **Medium Confidence**: The efficiency claims (0.2% data, 1000 iterations) are well-supported but may not generalize to all model types
- **Low Confidence**: The fundamental assumption that fingerprint-specific and general knowledge can be completely disentangled without performance impact

## Next Checks

1. Implement and compare against simpler single-level optimization approaches to validate the necessity of bilevel optimization
2. Test REMOVAL NET on additional architectures (e.g., EfficientNet, MobileNet) to verify generalization claims
3. Conduct controlled experiments to measure the minimum data and iterations needed for complete fingerprint removal across different fingerprint strength levels