---
ver: rpa2
title: 'CACTUS: a Comprehensive Abstraction and Classification Tool for Uncovering
  Structures'
arxiv_id: '2308.12031'
source_url: https://arxiv.org/abs/2308.12031
tags:
- data
- classification
- cactus
- page
- flips
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CACTUS introduces a novel explainable AI framework that uses abstractions
  to partition attribute values into flips, enabling interpretable classification.
  It extends SaNDA by supporting categorical attributes, preserving their semantics,
  optimizing memory, and accelerating computation through parallel processing.
---

# CACTUS: a Comprehensive Abstraction and Classification Tool for Uncovering Structures

## Quick Facts
- arXiv ID: 2308.12031
- Source URL: https://arxiv.org/abs/2308.12031
- Reference count: 40
- Key outcome: CACTUS achieves 95%+ classification accuracy on WDBC and Thyroid datasets while maintaining transparency through flip-based abstractions and knowledge graphs.

## Executive Summary
CACTUS is an explainable AI framework that uses abstractions to partition attribute values into flips (Up, Down, or categorical states) for interpretable classification. It extends the SaNDA method by supporting categorical attributes, optimizing memory usage, and accelerating computation through parallel processing. Applied to Wisconsin Diagnostic Breast Cancer and Thyroid0387 datasets, CACTUS demonstrates high classification accuracy while automatically ranking attributes by discriminative power and constructing knowledge graphs to visualize class-specific relationships.

## Method Summary
CACTUS preprocesses data by cleaning, binarizing, and stratifying, then abstracts attributes into discrete flips representing value ranges or categories. These flips become nodes in knowledge graphs where edges represent relationships. Classification is performed using either PageRank (centrality-based) or Probabilistic methods on these graphs. The framework handles categorical attributes naturally by treating each category as a flip node, computes ranks based on probability distribution changes across classes, and builds class-specific knowledge graphs with community detection to reveal interpretable structures.

## Key Results
- Achieves 95.08% accuracy (PageRank) and 95.43% (Probabilistic) on Wisconsin Diagnostic Breast Cancer dataset
- Achieves 95.4% accuracy on Thyroid0387 dataset
- Automatically ranks attributes by discriminative power and visualizes class-specific relationships through knowledge graphs
- Supports categorical attributes while preserving their semantics and optimizing memory usage

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CACTUS uses abstractions to partition attribute values into flips that preserve semantic meaning while enabling interpretable classification.
- Mechanism: Discrete flips represent value ranges or categories as nodes in knowledge graphs where edges show relationships. Classification uses graph structure via PageRank or probabilistic scoring.
- Core assumption: Flip interactions reflect meaningful relationships between attribute states that capture discriminative power.
- Evidence anchors: Abstract mentions flip abstraction for intuitive representation; section describes automatic categorical attribute recognition.

### Mechanism 2
- Claim: CACTUS achieves high accuracy while maintaining interpretability by ranking flips by discriminative power and visualizing class-specific relationships.
- Mechanism: Computes rank for each flip by measuring conditional probability changes across classes, averages to indicate attribute importance, builds knowledge graphs per class.
- Core assumption: Probability distribution changes correlate with discriminative power and graph centrality or probability scores are valid classification metrics.
- Evidence anchors: Abstract mentions ranking by discriminative power; section describes averaging ranks over marker flips.

### Mechanism 3
- Claim: CACTUS handles categorical attributes naturally, preserving semantics, and optimizes computation via parallel processing and on-the-fly graph construction.
- Mechanism: Categorical attributes become flip nodes maintaining original meaning; connections computed on-the-fly rather than stored; parallelization speeds processing.
- Core assumption: Categorical variables can be meaningfully modeled as flip nodes without losing context, and on-the-fly computation is efficient.
- Evidence anchors: Abstract mentions support for categorical attributes with memory optimization; section describes automatic categorical recognition.

## Foundational Learning

- Concept: Knowledge graphs and community detection
  - Why needed here: CACTUS builds knowledge graphs from flip nodes and uses community detection algorithms to identify groups of flips that behave similarly across classes, revealing interpretable structures.
  - Quick check question: What is the purpose of computing communities in the flip-based knowledge graph, and how does it aid classification interpretation?

- Concept: PageRank and probabilistic classification
  - Why needed here: These are the two classification methods CACTUS offers. PageRank uses graph centrality to score flips, while Probabilistic relies on conditional probabilities.
  - Quick check question: How do the PageRank and Probabilistic classification methods differ in how they use the knowledge graph for assigning class labels?

- Concept: Abstraction and discretization of continuous attributes
  - Why needed here: CACTUS abstracts continuous attributes into discrete flips to enable symbolic reasoning and graph construction, which must preserve discriminative information.
  - Quick check question: Why does CACTUS partition continuous attribute values into Up and Down flips, and what is the risk if the partitioning is poorly chosen?

## Architecture Onboarding

- Component map:
  Preprocessing module -> Abstraction module -> Correlation module -> Configuration layer
  (Preprocessing handles cleaning, binarization, stratification; Abstraction creates flips, builds graphs, computes ranks, performs classification; Correlation computes matrices, builds MSTs; Configuration uses YAML config and Cython compilation)

- Critical path:
  1. Load and preprocess data (clean, binarize, stratify)
  2. Abstract attributes into flips and build knowledge graphs per class
  3. Rank flips by discriminative power and compute classifications
  4. (Optional) Compute correlations and decision trees for auxiliary analysis
  5. Output graphs, metrics, and classification results

- Design tradeoffs:
  - Memory vs speed: On-the-fly graph construction saves memory but may slow computation for large graphs
  - Interpretability vs accuracy: Flip-based abstraction increases transparency but may lose fine-grained information
  - Flexibility vs complexity: YAML config allows customization but adds configuration overhead

- Failure signatures:
  - Low classification accuracy: Could indicate poor flip abstraction, weak discriminative power, or inappropriate binarization
  - Extremely sparse or dense graphs: May signal over/under-abstraction of attributes
  - Community detection returns single community: May indicate insufficient variation in flip relationships

- First 3 experiments:
  1. Run CACTUS on a small synthetic dataset with known class boundaries; verify that the most discriminative flips align with ground truth
  2. Compare CACTUS classification results with a standard ML model (e.g., Random Forest) on the WDBC dataset; analyze differences in interpretability
  3. Modify the YAML config to force a continuous attribute into categorical mode; observe changes in flip abstraction and classification performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CACTUS's performance on small datasets compare to other explainable AI methods beyond the ones tested?
- Basis in paper: The paper focuses on WDBC and Thyroid datasets but does not compare CACTUS to other XAI methods on small datasets.
- Why unresolved: The paper only benchmarks against standard ML models, not specifically XAI approaches designed for small data.
- What evidence would resolve it: Comparative studies of CACTUS vs. other XAI methods (e.g., LIME, SHAP) on multiple small datasets.

### Open Question 2
- Question: Can CACTUS's abstraction mechanism be extended to handle continuous attributes without discretization?
- Basis in paper: The paper mentions abstractions for categorical and discretized continuous attributes but does not explore direct handling of continuous features.
- Why unresolved: Current implementation requires binning or categorization of continuous attributes before abstraction.
- What evidence would resolve it: Experimental results showing CACTUS performance with native continuous attribute handling vs. discretized versions.

### Open Question 3
- Question: How does the choice of community detection algorithm affect the stability and interpretability of CACTUS's knowledge graphs?
- Basis in paper: Multiple algorithms (Greedy, Label Propagation, Louvain) are used, but their comparative impact on graph interpretation is not deeply analyzed.
- Why unresolved: The paper presents results from different algorithms but doesn't systematically evaluate which is most effective for different data types.
- What evidence would resolve it: Systematic comparison of knowledge graph stability and interpretability across different community detection methods on diverse datasets.

## Limitations
- Lacks explicit implementation details for the CACTUS framework, including configuration file format and dependency versions
- Abstraction mechanism for continuous attributes is conceptually described but not rigorously validated against ground truth or compared with standard discretization methods
- No ablation studies to isolate the contribution of each mechanism (flip abstraction, knowledge graphs, parallel processing) to reported accuracy

## Confidence
- High confidence in classification accuracy results on WDBC and Thyroid datasets (95%+ accuracy), as these are standard benchmark datasets with well-documented baselines
- Medium confidence in interpretability claims, as knowledge graph visualizations and discriminative power rankings are demonstrated but not quantitatively validated for their explanatory value
- Low confidence in scalability claims (memory optimization and parallel processing) due to lack of runtime/memory benchmarks on larger datasets

## Next Checks
1. Obtain or reconstruct the CACTUS implementation to verify that abstraction, classification, and visualization steps produce reported results on WDBC and Thyroid datasets
2. Perform ablation study by disabling knowledge graph component and parallel processing to measure their individual contributions to accuracy and runtime performance
3. Test CACTUS on a third, unseen dataset (e.g., Iris or Wine) to evaluate robustness and transferability of the flip-based abstraction approach