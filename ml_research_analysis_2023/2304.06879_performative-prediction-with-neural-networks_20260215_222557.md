---
ver: rpa2
title: Performative Prediction with Neural Networks
arxiv_id: '2304.06879'
source_url: https://arxiv.org/abs/2304.06879
tags:
- distribution
- performative
- function
- classi
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper studies convergence of repeated risk minimization for\
  \ finding performatively stable classifiers in settings where the loss is non-convex\
  \ in model parameters but strongly convex in predictions. By assuming Lipschitz\
  \ continuity of the data distribution with respect to model predictions (rather\
  \ than parameters) and using \u03C7\xB2 divergence, the authors relax the need for\
  \ convexity in parameters."
---

# Performative Prediction with Neural Networks

## Quick Facts
- arXiv ID: 2304.06879
- Source URL: https://arxiv.org/abs/2304.06879
- Reference count: 17
- The paper studies convergence of repeated risk minimization for finding performatively stable classifiers in settings where the loss is non-convex in model parameters but strongly convex in predictions.

## Executive Summary
This paper addresses performative prediction in non-convex settings by relaxing convexity assumptions on model parameters. The key insight is that convergence can be guaranteed if the loss function is strongly convex in predictions rather than parameters. The authors introduce a Resample-if-Rejected (RIR) procedure that satisfies their theoretical requirements and demonstrate linear convergence to performatively stable classifiers under specific conditions.

## Method Summary
The authors study repeated risk minimization (RRM) where the distribution map is Lipschitz continuous with respect to predictions (not parameters), and the loss is strongly convex in predictions. They prove that RRM converges linearly to a unique performatively stable classifier when √(CϵM/γ) < 1, where C is the bounded norm ratio parameter, ϵ is the Lipschitz constant, M bounds the gradient norm, and γ is the strong convexity constant. The RIR procedure models distribution shifts by resampling strategic features with probability g(fθ(x)) = fθ(x) + δ, creating χ²-sensitive distributions that satisfy the required theoretical conditions.

## Key Results
- RRM converges linearly to performatively stable classifiers when √(CϵM/γ) < 1
- RIR procedure satisfies χ² sensitivity and bounded norm ratio with C = 1/δ
- Experiments on credit scoring task show convergence to stable classifiers under RIR distribution shifts
- The framework relaxes convexity requirements by shifting Lipschitz continuity from parameters to predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: RRM converges linearly to a performatively stable classifier under χ² sensitivity
- Mechanism: The proof establishes that if the distribution map is χ²-sensitive and satisfies the bounded norm ratio property, the RRM update function becomes a contraction mapping in prediction space, ensuring linear convergence
- Core assumption: The loss function must be strongly convex in predictions and have bounded gradient norm; the distribution map must be χ²-sensitive rather than Wasserstein-sensitive
- Evidence anchors:
  - [abstract]: "The main theoretical result shows that RRM converges linearly to a unique performatively stable classifier if √CϵM/γ < 1"
  - [section 2.2]: Theorem 2 states "RRM converges to a stable classifier at a linear rate"
  - [corpus]: Weak evidence - related papers focus on different aspects of performative prediction but don't directly address the χ² sensitivity mechanism
- Break condition: If √CϵM/γ ≥ 1, the contraction mapping condition fails and convergence is no longer guaranteed

### Mechanism 2
- Claim: The Resample-if-Rejected procedure satisfies the required distribution assumptions
- Mechanism: The RIR procedure creates a distribution that is both χ²-sensitive and satisfies the bounded norm ratio property through rejection sampling with probability g(fθ(x)) = fθ(x) + δ
- Core assumption: Strategic and non-strategic features must be independent for the procedure to work correctly
- Evidence anchors:
  - [section 3]: "The following theorem shows that the distribution resulting from the RIR procedure satisfies our conditions on the distribution map"
  - [section 3]: Theorem 3 proves RIR is 1/δ-sensitive w.r.t χ² divergence and satisfies bounded norm ratio with C = 1/δ
  - [corpus]: Weak evidence - related papers don't discuss this specific resampling mechanism
- Break condition: If predictions fθ(x) fall outside [0, 1-δ], the rejection probability becomes invalid

### Mechanism 3
- Claim: Non-convex loss functions can still converge due to strong convexity in prediction space
- Mechanism: By shifting the Lipschitz continuity assumption from parameters to predictions, the framework relaxes the convexity requirement on the loss function with respect to parameters while maintaining convergence guarantees
- Core assumption: The loss must remain strongly convex in the prediction space, even if non-convex in parameter space
- Evidence anchors:
  - [abstract]: "we are able to significantly relax the assumptions on the loss function. In particular, we do not need to assume convexity with respect to the model's parameters"
  - [section 1.2]: "we can relax the convexity condition on the loss function and prove the existence and uniqueness of a performative stable classifier"
  - [corpus]: Weak evidence - related papers focus on convergence but don't emphasize the parameter vs prediction convexity distinction
- Break condition: If the loss is not strongly convex in predictions, the key inequality (17) fails

## Foundational Learning

- Concept: Performative prediction framework
  - Why needed here: The entire paper builds on the idea that model deployment changes the data distribution, requiring different convergence analysis than standard supervised learning
  - Quick check question: What distinguishes performative prediction from standard supervised learning in terms of data distribution assumptions?

- Concept: χ² divergence and Wasserstein distance
  - Why needed here: The paper replaces the standard Wasserstein sensitivity assumption with χ² sensitivity, which is more restrictive but enables convergence results for non-convex losses
  - Quick check question: Why does using χ² divergence instead of Wasserstein distance make the assumptions stronger?

- Concept: Contraction mapping and Banach fixed-point theorem
  - Why needed here: The proof relies on showing that the RRM update function is a contraction mapping, which guarantees convergence to a unique fixed point
  - Quick check question: What condition must hold for a function to be a contraction mapping, and how does this relate to the convergence proof?

## Architecture Onboarding

- Component map: Distribution map D(fθ) → RRM updates → convergence check → stable classifier
- Critical path: D(fθ) → RRM updates → convergence check → stable classifier
- Design tradeoffs:
  - Stronger χ² sensitivity vs weaker Wasserstein sensitivity
  - Strong convexity in predictions vs convexity in parameters
  - Bounded norm ratio assumption vs no such requirement
- Failure signatures:
  - Divergence when √CϵM/γ ≥ 1
  - Oscillation between two models (as shown in Proposition 1)
  - Invalid rejection probabilities if fθ(x) ∉ [0, 1-δ]
- First 3 experiments:
  1. Verify convergence with simple neural network and RIR procedure for δ > 0.5
  2. Test divergence behavior when δ < 0.5 (where theory gives no guarantees)
  3. Compare convergence rates for different hidden layer sizes while keeping δ constant

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the minimal assumption on the distribution map that still guarantees convergence of repeated risk minimization when the loss is non-convex in parameters?
- Basis in paper: [inferred] The authors use χ2 divergence sensitivity and bounded norm ratio to prove convergence, but these assumptions are stronger than necessary for some settings. They mention that using Wasserstein distance instead of χ2 breaks their convergence result.
- Why unresolved: The paper proves convergence under strong assumptions (χ2 sensitivity and bounded norm ratio) but does not explore the minimal set of conditions needed. The authors acknowledge this as an open question.
- What evidence would resolve it: A proof showing convergence under weaker assumptions on the distribution map, such as only Wasserstein sensitivity without the bounded norm ratio condition.

### Open Question 2
- Question: How does the choice of divergence measure (χ2 vs Wasserstein) affect the convergence guarantees and practical performance of performative prediction?
- Basis in paper: [explicit] The authors explicitly compare χ2 and Wasserstein distances, showing that χ2 sensitivity is stronger but allows convergence under non-convex losses, while Wasserstein sensitivity alone does not guarantee convergence.
- Why unresolved: The paper does not provide empirical comparisons of performance under different divergence measures or explore whether there are intermediate divergence measures that could provide both practical applicability and theoretical guarantees.
- What evidence would resolve it: Empirical studies comparing performance of RRM under different divergence measures on real-world datasets, along with theoretical analysis of convergence conditions for intermediate divergence measures.

### Open Question 3
- Question: What is the impact of strategic and non-strategive feature independence on the convergence and performance of performative prediction algorithms?
- Basis in paper: [explicit] The authors discuss the Resample-if-Rejected procedure and show that resampling only strategic features works under the assumption of independence between strategic and non-strategic features. They mention this as a special case of their general framework.
- Why unresolved: The paper does not explore what happens when strategic and non-strategic features are correlated, or how different feature correlation structures affect convergence and performance.
- What evidence would resolve it: Analysis of convergence and performance under different feature correlation structures, including both empirical studies and theoretical extensions of the convergence proofs.

## Limitations

- The χ² sensitivity assumption is stronger than standard Wasserstein sensitivity used in related work
- The bounded norm ratio condition creates a hard constraint requiring δ > 0.5 for convergence guarantees
- The independence assumption between strategic and non-strategic features may not hold in many real-world applications

## Confidence

**High confidence**: The convergence result when √(CϵM/γ) < 1 is mathematically rigorous and the proof structure using contraction mapping is sound. The RIR procedure correctly implements the stated distribution shift mechanism.

**Medium confidence**: The practical significance of the convergence guarantees, as experiments only demonstrate one specific neural network architecture on a single credit scoring task. The generalizability to other domains and model architectures remains uncertain.

**Low confidence**: The claim that this approach significantly relaxes convexity assumptions compared to prior work, as the strong convexity requirement in prediction space remains a substantial constraint.

## Next Checks

1. **Sensitivity analysis**: Systematically vary δ across the full range [0, 1] and document the exact threshold where convergence behavior changes, particularly testing values below 0.5 where theory gives no guarantees.

2. **Distribution assumption verification**: For each RIR iteration, empirically measure χ² divergence and bounded norm ratio to verify that the theoretical assumptions hold in practice, not just in expectation.

3. **Architecture robustness test**: Repeat experiments with different neural network architectures (varying hidden layers, activation functions, width) while keeping the RIR procedure constant to isolate whether convergence is architecture-dependent.