---
ver: rpa2
title: Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic
  Retinopathy
arxiv_id: '2308.09945'
source_url: https://arxiv.org/abs/2308.09945
tags:
- retinopathy
- dataset
- diabetic
- classification
- deep
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a deep learning approach for detecting and
  grading diabetic retinopathy (DR) using fundus retinal images. The method employs
  a dual-branch network architecture that leverages two pre-trained deep learning
  models (ResNet50 and EfficientNetB0) as feature extractors, fine-tuned on a large
  multi-center dataset including APTOS 2019.
---

# Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic Retinopathy

## Quick Facts
- arXiv ID: 2308.09945
- Source URL: https://arxiv.org/abs/2308.09945
- Reference count: 40
- Key outcome: Dual-branch CNN using ResNet50 and EfficientNetB0 achieves 98.50% accuracy for binary DR detection and 93.00% QWK for stage grading on APTOS 2019 dataset

## Executive Summary
This paper presents a deep learning approach for detecting and grading diabetic retinopathy using fundus retinal images. The method employs a dual-branch network architecture that leverages two pre-trained deep learning models (ResNet50 and EfficientNetB0) as feature extractors, fine-tuned on a large multi-center dataset including APTOS 2019. To address class imbalance, the authors apply image augmentations and use a complement cross entropy loss function. The approach achieves state-of-the-art results with 98.50% accuracy for binary classification and 93.00% quadratic weighted kappa for stage grading, demonstrating its potential as a reliable screening and grading tool for diabetic retinopathy.

## Method Summary
The proposed method uses a dual-branch deep learning network architecture that combines ResNet50 and EfficientNetB0 as feature extractors. The network is trained using transfer learning on a merged dataset consisting of APTOS 2019 and selected categories from Messidor-2 and IDRiD datasets. To address class imbalance, the authors apply data augmentation techniques and use complement cross entropy loss. The model is optimized using stochastic gradient descent with specific hyperparameters and evaluated using standard metrics including accuracy, sensitivity, specificity, and quadratic weighted kappa.

## Key Results
- Binary classification achieves 98.50% accuracy, 99.46% sensitivity, and 97.51% specificity
- Stage grading achieves 93.00% quadratic weighted kappa, 89.60% accuracy, and 89.60% sensitivity
- The proposed model outperforms existing methods on the same dataset
- Results demonstrate effectiveness for both DR detection and stage grading

## Why This Works (Mechanism)

### Mechanism 1
The dual-branch architecture combining ResNet50 and EfficientNetB0 improves classification performance by leveraging complementary feature extraction strengths. Each branch extracts different levels of abstraction from the fundus image, with ResNet50 capturing more general visual patterns and EfficientNetB0 focusing on fine-grained details, and their concatenation creates a richer feature representation.

### Mechanism 2
Complement cross entropy loss function effectively addresses class imbalance by giving more importance to minority class samples. CCE neutralizes the probabilities of incorrect classes and ensures the ground truth class has higher softmax probability than incorrect classes, which is particularly beneficial when some DR stages have fewer training examples.

### Mechanism 3
Selective merging of specific categories from multiple datasets with targeted augmentations optimizes training efficiency while maintaining performance. By merging only categories with fewer images from Messidor-2 and IDRiD datasets with APTOS 2019, and applying augmentations only to these categories, the model receives additional training data where it's most needed without unnecessary computational overhead.

## Foundational Learning

- Concept: Transfer learning using pre-trained models
  - Why needed here: Diabetic retinopathy detection requires learning complex visual patterns from limited medical imaging data; pre-trained models already learned general visual features from ImageNet, providing a strong starting point.
  - Quick check question: Why would we use a model pre-trained on natural images (ImageNet) for medical image classification?

- Concept: Class imbalance and its impact on model performance
  - Why needed here: The dataset shows significant variation in the number of samples across DR severity levels, which can cause the model to bias toward majority classes and perform poorly on rare but clinically important severe cases.
  - Quick check question: What happens to a classification model when one class has 100 times more training examples than another?

- Concept: Augmentation techniques for medical imaging
  - Why needed here: Medical imaging datasets are often small due to privacy constraints and data collection costs; augmentation artificially expands the dataset while maintaining clinical validity of the images.
  - Quick check question: Which augmentation techniques might be inappropriate for fundus images because they could create clinically unrealistic variations?

## Architecture Onboarding

- Component map: Input (224x224x3 fundus image) → ResNet50 branch → MaxPool → ReLU → EfficientNetB0 branch → MaxPool → ReLU → Concatenation → FC(4096) → BatchNorm → ReLU → Dropout(0.25) → FC(1024) → BatchNorm → ReLU → Dropout(0.25) → FC(output) → Softmax
- Critical path: Image preprocessing → Dual feature extraction → Feature concatenation → Classification head → Output
- Design tradeoffs: Dual-branch adds complexity and computation but potentially improves performance; dropout layers prevent overfitting but may slow convergence; selective dataset merging reduces training time but requires careful category selection
- Failure signatures: Poor performance on minority classes suggests augmentation or loss function issues; low accuracy on specific severity levels suggests feature extraction limitations; overfitting on training data suggests regularization needs adjustment
- First 3 experiments:
  1. Train each pre-trained model (ResNet50 and EfficientNetB0) separately on the dataset to establish baseline performance
  2. Implement and test the dual-branch architecture with both models to verify performance improvement over individual models
  3. Apply complement cross entropy loss and compare performance with standard cross entropy to validate the impact of addressing class imbalance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed dual-branch architecture compare to ensemble methods using the same pre-trained models in terms of computational efficiency and performance?
- Basis in paper: [explicit] The authors mention using a dual-branch architecture combining ResNet50 and EfficientNetB0, but do not compare it to ensemble methods using the same models.
- Why unresolved: The paper does not provide a direct comparison between the dual-branch approach and ensemble methods, which could offer insights into the optimal way to combine multiple pre-trained models.
- What evidence would resolve it: A head-to-head comparison of the dual-branch model and ensemble methods using the same pre-trained models on the same dataset and evaluation metrics.

### Open Question 2
- Question: How does the performance of the proposed model change when applied to datasets with different demographic characteristics or imaging protocols?
- Basis in paper: [inferred] The authors mention that the model was trained on a multi-center dataset including APTOS 2019, but do not provide results on other datasets with different demographic characteristics or imaging protocols.
- Why unresolved: The paper does not evaluate the model's generalizability to different populations or imaging settings, which is crucial for real-world deployment.
- What evidence would resolve it: Testing the model on multiple datasets with diverse demographic characteristics and imaging protocols, and comparing the performance across these datasets.

### Open Question 3
- Question: How does the model's performance vary with the severity of diabetic retinopathy within each class?
- Basis in paper: [explicit] The authors mention that the model's performance was poorer for severe and proliferative diabetic retinopathy cases due to their visual similarity, but do not provide a detailed analysis of performance across different severity levels within each class.
- Why unresolved: The paper does not provide a comprehensive analysis of the model's performance across different severity levels within each class, which is important for understanding its clinical utility.
- What evidence would resolve it: A detailed analysis of the model's performance across different severity levels within each class, including confusion matrices and per-class evaluation metrics.

## Limitations

- The exact merging strategy for combining APTOS 2019 with Messidor-2 and IDRiD datasets is unspecified
- Augmentation parameters are not detailed, making exact reproduction difficult
- Limited validation on independent datasets raises concerns about overfitting to APTOS characteristics

## Confidence

- High Confidence: The general methodology of using transfer learning with pre-trained models for diabetic retinopathy classification is well-established and technically sound
- Medium Confidence: The claim that the proposed model outperforms existing methods is supported by comparison metrics, but the lack of direct comparison with the exact same datasets limits the strength of this claim
- Low Confidence: The specific performance numbers are difficult to verify without access to the exact dataset merging strategy and augmentation parameters

## Next Checks

1. **Dataset Verification**: Recreate the exact dataset composition by identifying which specific classes from Messidor-2 and IDRiD were merged with APTOS 2019 categories 1, 3, and 4, and verify the class distribution ratios used during training.

2. **Component Ablation Study**: Conduct controlled experiments to isolate the contribution of each key component (dual-branch architecture, complement cross entropy loss, selective dataset merging) by testing the model with variations: single-branch ResNet50, standard cross entropy loss, and full dataset usage without selective merging.

3. **External Validation**: Test the trained model on an independent diabetic retinopathy dataset not used in training (such as EyePACS or Messidor-1) to assess generalizability and verify that the high performance metrics are not specific to the APTOS dataset characteristics.