---
ver: rpa2
title: Empirical Study of PEFT techniques for Winter Wheat Segmentation
arxiv_id: '2310.01825'
source_url: https://arxiv.org/abs/2310.01825
tags:
- peft
- tuning
- techniques
- prompt
- crop
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper explores parameter-efficient fine-tuning (PEFT) techniques
  for crop type segmentation using the state-of-the-art TSViT model. The authors investigate
  various PEFT methods, including BitFit, LoRA, Adaptformer, and prompt tuning, to
  efficiently adapt the pre-trained model to the task of winter wheat field segmentation
  using Sentinel-2 satellite imagery.
---

# Empirical Study of PEFT techniques for Winter Wheat Segmentation

## Quick Facts
- arXiv ID: 2310.01825
- Source URL: https://arxiv.org/abs/2310.01825
- Reference count: 16
- Key outcome: Achieves F1-score of 85% with only 0.72% of parameters trained using Adaptformer PEFT technique

## Executive Summary
This paper investigates parameter-efficient fine-tuning (PEFT) techniques for winter wheat field segmentation using Sentinel-2 satellite imagery. The authors apply various PEFT methods including BitFit, LoRA, Adaptformer, and prompt tuning to the TSViT model, achieving comparable results to full fine-tuning while training only 0.7% of model parameters. The best performance is obtained using Adaptformer, which achieves an F1-score of 85% while training only 0.72% of the model parameters. The study demonstrates the effectiveness of PEFT techniques on both a dataset from Lebanon and a German dataset, highlighting their potential for accurate and efficient crop monitoring in regions with limited data availability.

## Method Summary
The study uses Sentinel-2 satellite imagery time series (9 images from November to July, 10 spectral bands) to segment winter wheat fields. The TSViT model, a temporal transformer followed by a spatial transformer, is adapted using PEFT techniques including BitFit, LoRA, Visual Prompt Tuning (VPT), and AdaptFormer. The model is trained using Adam optimizer, batch size 16, 20 epochs with a constant learning rate, and evaluated using F1-score and IoU on labeled datasets from Lebanon (Beqaa-Lebanon) and Germany (Munich 480). Cross-validation is used to select the best model per epoch.

## Key Results
- Adaptformer achieved the best performance with an F1-score of 85% while training only 0.72% of parameters
- VPT with external deep prompts achieved an F1-score of 83.5% at dimensions 16×16
- PEFT techniques achieved comparable results to full fine-tuning while training only 0.7% of parameters
- Both BitFit and VPT provided comparable but fewer results than full fine-tuning, with at least 27% better F1-score than the simple Head-tuning baseline

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Training only a small subset of parameters (0.7%) achieves comparable performance to full fine-tuning.
- Mechanism: By keeping most model weights frozen and only updating a small set of trainable parameters, the model retains learned representations while adapting to the new task.
- Core assumption: The frozen parameters contain relevant knowledge for the new task, and the trainable subset is sufficient to capture task-specific variations.
- Evidence anchors:
  - [abstract] "Using PEFT techniques, we achieved notable results comparable to those achieved using full fine-tuning methods while training only a mere 0.7% parameters of the whole TSViT architecture."
  - [section] "Using PEFT techniques, we achieved notable results comparable to those achieved using full fine-tuning methods while training only a mere 0.7% parameters of the whole TSViT architecture."
  - [corpus] Weak: No direct evidence from neighbors; most related works focus on yield prediction, not segmentation or PEFT.
- Break condition: If the frozen parameters are too specialized to the original task, the trainable subset may be insufficient to adapt to the new task, leading to poor performance.

### Mechanism 2
- Claim: Adaptformer technique outperforms other PEFT methods and achieves the best performance.
- Mechanism: Adaptformer introduces two additional layers in the feed-forward steps, allowing for efficient parameter utilization and task-specific adaptation.
- Core assumption: The additional layers in Adaptformer can capture the most important parameters for the task, leading to better performance than other PEFT methods.
- Evidence anchors:
  - [section] "AdaptFormer revealed the best performance among all PEFT techniques and the baselines with a F1-score of 84.9% when the adapter's temporal and spatial dimensions were equal to 8."
  - [section] "Both Bitfit and VPT provided comparable but fewer results than full fine-tuning, while still having at least 27% better F1-score than the simple Head-tuning baseline."
  - [corpus] Weak: No direct evidence from neighbors; most related works focus on yield prediction, not segmentation or PEFT.
- Break condition: If the additional layers in Adaptformer do not capture the most important parameters for the task, its performance may not be significantly better than other PEFT methods.

### Mechanism 3
- Claim: Visual Prompt Tuning (VPT) with external deep prompts achieves better performance than shallow prompts.
- Mechanism: VPT adds additional prompt parameters to the input of the transformer, allowing the model to understand different tasks better. Deep prompts provide more information than shallow prompts.
- Core assumption: Deep prompts contain more relevant information for the task than shallow prompts, leading to better performance.
- Evidence anchors:
  - [section] "Series 2: We used an external deep prompt that shows outstanding performance, where the highest F1-score of 83.5% is achieved at dimensions 16 ∗ 16."
  - [section] "Series 3: We used an external shallow prompt and witnessed a dip in performance, with F1 scores of 81.36% and 79% for dimensions 8 ∗ 8 and 4 ∗ 4, respectively."
  - [corpus] Weak: No direct evidence from neighbors; most related works focus on yield prediction, not segmentation or PEFT.
- Break condition: If the additional information in deep prompts is not relevant to the task, their performance may not be significantly better than shallow prompts.

## Foundational Learning

- Concept: Vision Transformers (ViT) and their application in satellite image time series analysis
  - Why needed here: The paper uses the TSViT model, which is based on the Vision Transformer architecture, to process satellite image time series for crop monitoring.
  - Quick check question: How does the Vision Transformer architecture differ from traditional convolutional neural networks, and what advantages does it offer for processing satellite image time series?

- Concept: Parameter-Efficient Fine-Tuning (PEFT) techniques
  - Why needed here: The paper explores various PEFT techniques to efficiently adapt the pre-trained TSViT model to the task of winter wheat field segmentation.
  - Quick check