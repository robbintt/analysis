---
ver: rpa2
title: Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant
  Abilities with Linguistically-Diverse Prompts
arxiv_id: '2306.11372'
source_url: https://arxiv.org/abs/2306.11372
tags:
- language
- languages
- translation
- english
- supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an unsupervised prompting method for low-resource
  language translation by leveraging linguistically diverse exemplars from high-resource
  languages to promote translation into English, followed by back-translation to create
  intra-lingual prompts for translation into the low-resource language. Experiments
  with BLOOM and InstructGPT show that this approach performs on par with supervised
  few-shot prompting across 13 Indic and 21 African languages for both English-to-low-resource
  and low-resource-to-English translation tasks.
---

# Democratizing LLMs for Low-Resource Languages by Leveraging their English Dominant Abilities with Linguistically-Diverse Prompts

## Quick Facts
- arXiv ID: 2306.11372
- Source URL: https://arxiv.org/abs/2306.11372
- Reference count: 26
- Key outcome: Unsupervised prompting method using linguistically-diverse exemplars achieves performance comparable to supervised few-shot prompting for low-resource language translation

## Executive Summary
This paper addresses the challenge of translating low-resource languages using large language models (LLMs) that are predominantly trained on English data. The authors propose a method called Linguistically-Diverse Prompting (LDP) that leverages the observation that LLMs understand any language reasonably well before they can generate it fluently. By using synthetic exemplars from diverse high-resource languages translated to English, the method promotes translation into English, then uses back-translation to create intra-lingual prompts for translation into the target low-resource language.

The approach is evaluated on 13 Indic and 21 African languages, showing that LDP performs on par with supervised few-shot prompting for English-to-low-resource and low-resource-to-English translation. For non-English translation directions, it even outperforms supervised prompting by up to 3 chrF++. The method also demonstrates strong results in zero-shot multilingual summarization. Fine-tuning a 7B model with generated data helps it perform competitively with a 175B model.

## Method Summary
The method involves creating linguistically-diverse prompts using synthetic exemplars from high-resource languages translated to English. The process starts by sampling sentences from unlabeled data in the low-resource language, translating them to English using unsupervised machine translation, and creating prompt exemplars that show translation from various high-resource languages to English. For English-to-low-resource translation, back-translation is used to create intra-lingual prompts by translating English exemplars back to the target language. The LLM is then prompted with these diverse exemplars to perform translation tasks. Fine-tuning is applied to attention layer parameters to improve performance on low-resource languages.

## Key Results
- LDP achieves comparable performance to supervised few-shot prompting across 13 Indic and 21 African languages
- For non-English translation directions, LDP outperforms supervised prompting by up to 3 chrF++
- Zero-shot multilingual summarization shows strong results with LDP
- Fine-tuning a 7B model with generated data enables competitive performance with a 175B model

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** LLMs have already learned most task concepts during pre-training, and in-context exemplars primarily help locate the intended task.
- **Mechanism:** The model marginalizes over task probabilities using exemplar evidence: p(y|x) = Σ_task p(y|task,x)p(task|x). Exemplars provide evidence for the model to identify and select the correct task.
- **Core assumption:** LLMs implicitly learn knowledge during pre-training that can be activated through appropriate in-context examples.
- **Evidence anchors:**
  - [abstract] "Large language models (LLMs) are known to effectively perform tasks by simply observing few exemplars"
  - [section] "Most of the knowledge is learned during pre-training, and in-context exemplars x are only to provide evidence for the model to marginalize and locate the intended task via a bayesian inference process"

### Mechanism 2
- **Claim:** LLMs understand any language reasonably well before they can generate it fluently.
- **Mechanism:** Language understanding develops earlier than language generation capabilities. The model can comprehend input in any language but struggles to generate outputs in low-resource languages due to insufficient exposure.
- **Core assumption:** Generative abilities improve later in training when more data is seen, while encoding abilities develop earlier.
- **Evidence anchors:**
  - [section] "the models intuitively learn to perform language encoding and understanding at an earlier time, before learning to generate language"
  - [section] "the models may be able to comprehend any language with reasonable competency, and only struggle to generate the intended language"

### Mechanism 3
- **Claim:** Translation tasks between low-resource language X and dominant language E are asymmetric - X→E is understanding, E→X is generation.
- **Mechanism:** X→E translation is treated as an NLU task in X where the model explains meaning in fluent E. E→X is treated as an NLG task in X where the model must generate in an unfamiliar language.
- **Core assumption:** The difficulty of E→X stems from generating in an unfamiliar language rather than understanding the English input.
- **Evidence anchors:**
  - [section] "translation tasks between X and E are no longer symmetric and can be interpreted more broadly as follows: X → E translation is a language understanding task (NLU) in X"
  - [section] "E → X translation is a language generation task (NLG) inX, which is often harder to master than NLU"

## Foundational Learning

- **Concept:** In-context learning and task localization
  - Why needed here: Understanding how exemplars help the model identify the correct task is crucial for designing effective prompts
  - Quick check question: How does the model use exemplars to determine which task to perform on a given input?

- **Concept:** Language model pre-training dynamics
  - Why needed here: Knowing that understanding develops before generation explains why X→E translation works better than E→X
  - Quick check question: Why might a model understand a language before it can fluently generate that language?

- **Concept:** Tokenization and language coverage
  - Why needed here: Tokenization affects how well the model handles different scripts and languages, especially for low-resource languages
  - Quick check question: How does tokenization impact model performance on languages with non-Latin scripts?

## Architecture Onboarding

- **Component map:** Unlabeled data → synthetic exemplars → in-context prompts → LLM generation
- **Critical path:** For X→En translation: (1) Sample sentences from unlabeled X corpus, (2) Translate to English using unsupervised MT, (3) Create LDP exemplars with diverse high-resource languages, (4) Prompt LLM with exemplars + test input, (5) Generate English translation
- **Design tradeoffs:** Using native language tags vs English tags, back-translation vs no back-translation, parameter-efficient fine-tuning vs full fine-tuning. Native tags help En→X but require unlabeled data. Back-translation improves En→X significantly. Full fine-tuning of attention weights works better than LoRA for low-resource languages.
- **Failure signatures:** Wrong language generation (model outputs Hindi instead of Marathi), extreme tokenization fragmentation (10 English tokens → 160 Tamil tokens), poor performance on non-Latin scripts due to fragmented byte-level tokenization.
- **First 3 experiments:**
  1. Test LDP with English tags vs native tags for En→X translation to verify language recognition issue
  2. Compare single high-resource language exemplars vs diverse language exemplars for X→En translation
  3. Evaluate the impact of back-translation exemplars on En→X translation quality

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of high-resource languages for LDP exemplars affect translation performance for different low-resource languages?
- Basis in paper: [explicit] The paper states that choosing a wide variety of languages across different regions may be the optimal choice for LDP language exemplars, and that using a single related language can be disastrous.
- Why unresolved: The paper only tests a limited set of high-resource languages (Arabic, Chinese, Vietnamese, French) and does not systematically explore the impact of different combinations or numbers of exemplar languages.
- What evidence would resolve it: Conducting controlled experiments with different sets of high-resource languages (e.g., only European, only Asian, or a mix) and measuring translation performance for various low-resource language groups.

### Open Question 2
- Question: What is the impact of the number of LDP exemplars on translation quality, and is there a point of diminishing returns?
- Basis in paper: [inferred] The paper uses 4 LDP exemplars for each experiment but does not explore the effect of varying this number.
- Why unresolved: The optimal number of exemplars for LDP prompting is not investigated, and it's unclear if increasing the number would improve or harm performance.
- What evidence would resolve it: Systematically varying the number of LDP exemplars (e.g., 1, 2, 4, 8) and measuring the resulting translation quality across different language pairs.

### Open Question 3
- Question: How does the performance of LDP compare to other zero-shot or unsupervised methods that do not rely on English as a pivot language?
- Basis in paper: [inferred] The paper focuses on English-pivoting methods and does not compare LDP to non-English pivoting approaches.
- Why unresolved: It's unclear whether LDP's reliance on English as an intermediate language is a limitation or if it's the most effective approach for low-resource language translation.
- What evidence would resolve it: Comparing LDP to zero-shot translation methods that directly translate between low-resource languages without using English as an intermediary.

## Limitations

- Reliance on unsupervised MT systems for generating synthetic exemplars introduces quality dependencies
- The method's dependence on available parallel data for back-translation may limit scalability for extremely low-resource languages
- Experimental scope focuses primarily on Indic and African languages, leaving generalization to other language families uncertain

## Confidence

**High Confidence:** The core finding that LDP performs comparably to supervised few-shot prompting for English-to-low-resource translation (based on consistent experimental results across 34 languages and two model families).

**Medium Confidence:** The claim that understanding develops before generation in LLMs, supported by theoretical reasoning but requiring more direct empirical validation of language comprehension capabilities.

**Medium Confidence:** The assertion that LDP outperforms supervised prompting for non-English translation directions by up to 3 chrF++, given that this represents a specific finding that may depend on language pair selection and exemplar quality.

## Next Checks

1. **Language Comprehension Validation:** Design experiments to directly test whether LLMs truly understand low-resource languages before they can generate them, using comprehension-based tasks (paraphrasing, inference, question answering) rather than just translation accuracy.

2. **Exemplar Quality Impact:** Systematically vary the quality of synthetic exemplars generated by unsupervised MT systems and measure the impact on downstream translation performance to establish the relationship between exemplar quality and task performance.

3. **Cross-Language Family Generalization:** Test the LDP method on languages from different language families (e.g., Turkic, Dravidian, Sino-Tibetan) with varying typological properties to validate whether the observed improvements generalize beyond the Indo-European and Niger-Congo languages studied.