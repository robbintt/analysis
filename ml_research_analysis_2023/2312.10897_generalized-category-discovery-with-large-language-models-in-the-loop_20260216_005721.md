---
ver: rpa2
title: Generalized Category Discovery with Large Language Models in the Loop
arxiv_id: '2312.10897'
source_url: https://arxiv.org/abs/2312.10897
tags:
- samples
- query
- categories
- category
- llms
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper introduces Loop, an end-to-end active-learning framework
  for generalized category discovery (GCD) that leverages large language models (LLMs)
  to improve performance and generate semantic category names without human effort.
  The key innovations are: (1) Local Inconsistent Sampling (LIS) to select samples
  likely misclassified based on neighborhood prediction inconsistency and entropy,
  (2) Scalable Query to let LLMs choose true neighbors from multiple candidates, and
  (3) Refined Neighborhood Contrastive Learning (RNCL) to learn clustering-friendly
  representations.'
---

# Generalized Category Discovery with Large Language Models in the Loop

## Quick Facts
- arXiv ID: 2312.10897
- Source URL: https://arxiv.org/abs/2312.10897
- Reference count: 40
- Key outcome: Loop achieves 7.67% average improvement over state-of-the-art GCD methods and generates accurate category names with minimal LLM queries (average $0.4 per dataset)

## Executive Summary
This paper introduces Loop, an end-to-end active-learning framework for generalized category discovery (GCD) that leverages large language models (LLMs) to improve performance and generate semantic category names without human effort. The framework addresses the challenge of discovering both known and novel categories in unlabeled data by combining local inconsistent sampling, scalable LLM queries, and refined neighborhood contrastive learning. Experiments on three benchmark datasets demonstrate significant improvements in both known and novel category recognition.

## Method Summary
Loop operates through a cyclical process where a base model is first pre-trained on labeled and unlabeled data using cross-entropy and masked language modeling loss. The framework then employs Local Inconsistent Sampling (LIS) to select samples likely misclassified based on neighborhood prediction inconsistency and entropy. These samples are queried using a Scalable Query strategy that leverages LLMs to choose true neighbors from multiple candidates. Refined Neighborhood Contrastive Learning (RNCL) then learns clustering-friendly representations based on the corrected neighborhood relationships. Finally, cluster interpretation decouples novel categories and generates category names through LLM feedback.

## Key Results
- Achieves 7.67% average improvement over state-of-the-art GCD methods across three benchmark datasets
- Generates accurate category names with minimal LLM queries (average $0.4 per dataset)
- Demonstrates significant improvements in both known and novel category recognition

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LIS identifies samples with high probability of misclassification by combining local prediction inconsistency and entropy
- Mechanism: Samples with diverse neighbor predictions (high Ci) and high prediction entropy (Hi) are near decision boundaries where clusters meet, making them prone to misclassification
- Core assumption: Clustering assumption holds - samples close in feature space should have same predictions
- Evidence anchors:
  - [abstract] "we first propose Local Inconsistent Sampling (LIS) to select samples that have a higher probability of falling to wrong clusters, based on neighborhood prediction consistency and entropy"
  - [section 3.2] "samples with local inconsistent predictions are near decision boundaries and have a higher probability of falling to wrong clusters"
  - [corpus] Weak evidence - no direct comparison studies found in related papers
- Break condition: If clustering assumption fails (e.g., multi-modal clusters), LIS may select incorrectly

### Mechanism 2
- Claim: Scalable Query leverages LLM comparison abilities to find true neighbors when category labels are unknown
- Mechanism: Instead of asking for categories, query asks LLM to compare semantic similarity between sample and multiple candidate neighbors
- Core assumption: LLMs are more accurate at semantic similarity comparison than category selection
- Evidence anchors:
  - [abstract] "we propose a Scalable Query strategy to allow LLMs to choose true neighbors of the selected samples from multiple candidate samples"
  - [section 3.3] "LLMs are more competent at comparing semantic similarities between sentences than choosing from multiple category names"
  - [corpus] Assumption: Based on Zhang et al. (2023) work, but not explicitly validated for GCD setting
- Break condition: If LLM cannot distinguish subtle semantic differences between categories

### Mechanism 3
- Claim: RNCL with refined neighborhood relationships improves clustering by pulling samples closer to their true neighbors
- Mechanism: After LLM feedback corrects neighborhood relationships, contrastive learning pulls samples toward their true cluster members
- Core assumption: Corrected neighborhood relationships reflect true category membership
- Evidence anchors:
  - [abstract] "Based on the feedback from LLMs, we perform Refined Neighborhood Contrastive Learning (RNCL) to pull samples and their neighbors closer to learn clustering-friendly representations"
  - [section 3.4] "we can correct the selected samples and learn clustering-friendly representations by pulling samples closer to their neighbor samples"
  - [corpus] Weak evidence - neighborhood contrastive learning effectiveness established but not specifically for post-LLM feedback
- Break condition: If LLM feedback is noisy or inconsistent, contrastive learning may reinforce incorrect relationships

## Foundational Learning

- Concept: Entropy as uncertainty measure
  - Why needed here: LIS uses prediction entropy to select samples far from cluster centers
  - Quick check question: If a sample has uniform probability across all clusters, what is its entropy value?

- Concept: Contrastive learning objectives
  - Why needed here: RNCL uses neighborhood contrastive loss to learn clustering-friendly representations
  - Quick check question: In contrastive learning, what happens to the distance between positive pairs versus negative pairs?

- Concept: Active learning query strategies
  - Why needed here: Scalable Query adapts active learning for open-world setting where labels are unknown
  - Quick check question: How does Scalable Query differ from traditional uncertainty sampling?

## Architecture Onboarding

- Component map: Encoder → LIS → LLM Query → RNCL → Cluster Interpretation
- Critical path: LIS → LLM Query → RNCL (feedback loop)
- Design tradeoffs: More query options improves accuracy but increases cost; interval updates reduce computation but may miss dynamic changes
- Failure signatures: High entropy samples not improving → LLM queries ineffective; poor clustering → neighborhood retrieval issues
- First 3 experiments:
  1. Baseline: Run without LLM queries to establish performance floor
  2. Ablation: Test different |q| values to find optimal query cost/accuracy tradeoff
  3. Visualization: Plot t-SNE embeddings before/after RNCL to verify neighborhood corrections

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal sampling strategy for selecting informative samples when the number of samples increases?
- Basis in paper: [inferred] The paper mentions that increasing the number of samples for querying LLMs improves model performance, but the growth rate gradually slows down due to the increasing difficulty of selecting informative samples.
- Why unresolved: The paper does not provide a detailed analysis of the optimal sampling strategy or the point at which the performance gain plateaus.
- What evidence would resolve it: Experimental results showing the performance gain of different sampling strategies at various sample sizes, along with an analysis of the optimal strategy for different dataset sizes.

### Open Question 2
- Question: How can the Scalable Query strategy be improved to acquire more accurate supervision?
- Basis in paper: [inferred] The paper states that the Scalable Query strategy can only provide neighborhood information, which is relatively weak supervision compared to category supervision in traditional active learning.
- Why unresolved: The paper does not explore alternative query strategies or methods to enhance the quality of supervision obtained from LLMs.
- What evidence would resolve it: Experimental results comparing the performance of different query strategies, including those that provide more detailed or accurate supervision information.

### Open Question 3
- Question: How can the feedback from LLMs be made more controllable and secure, especially for sensitive industries?
- Basis in paper: [explicit] The paper acknowledges that Loop relies on the feedback of LLM APIs, which is uncontrollable, and uploading data to query LLMs may be risky for some sensitive industries.
- Why unresolved: The paper does not propose solutions or alternatives to address the concerns of data privacy and the uncontrollable nature of LLM feedback.
- What evidence would resolve it: Experimental results demonstrating the effectiveness of privacy-preserving techniques or alternative methods for obtaining LLM feedback without compromising data security.

## Limitations
- Heavy reliance on LLM quality for query selection and cluster interpretation
- LIS method assumes clustering assumptions hold locally, which may fail in multi-modal scenarios
- Scalability concerns for very large datasets due to LLM query costs

## Confidence
- High confidence: The core active learning loop design and its theoretical foundation are sound
- Medium confidence: The performance improvements are significant but may depend on dataset characteristics
- Low confidence: The generalizability to other domains beyond the three tested datasets remains unverified

## Next Checks
1. Test Loop framework on a dataset with significantly more novel categories (e.g., 50+) to assess scalability limits
2. Conduct ablation studies comparing different LLM models (GPT-3.5 vs GPT-4) for query efficiency and accuracy
3. Evaluate performance degradation when clustering assumption is intentionally violated by introducing overlapping categories