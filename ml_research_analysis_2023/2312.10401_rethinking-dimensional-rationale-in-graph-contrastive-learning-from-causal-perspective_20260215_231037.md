---
ver: rpa2
title: Rethinking Dimensional Rationale in Graph Contrastive Learning from Causal
  Perspective
arxiv_id: '2312.10401'
source_url: https://arxiv.org/abs/2312.10401
tags:
- graph
- learning
- uni00000013
- uni00000011
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a graph contrastive learning approach that
  explores dimensional rationale (DR) in graph representations, which is more intrinsic
  than structural rationale explored in prior work. The method uses a causal perspective
  and structural causal model to identify DR as a causal confounder, then employs
  a learnable dimensional rationale acquiring network and redundancy reduction constraint
  to address this.
---

# Rethinking Dimensional Rationale in Graph Contrastive Learning from Causal Perspective

## Quick Facts
- arXiv ID: 2312.10401
- Source URL: https://arxiv.org/abs/2312.10401
- Authors: 
- Reference count: 19
- Key outcome: Introduces DRGCL, a graph contrastive learning approach using dimensional rationale as a causal confounder, achieving top-3 results across multiple graph benchmarks with average rank 2.8 in unsupervised learning and highest accuracy in transfer learning on molecular property prediction.

## Executive Summary
This paper addresses the limitations of structural rationale (SR) in graph contrastive learning by introducing dimensional rationale (DR) as a more intrinsic approach. The authors formalize DR as a causal confounder in the structural causal model and employ a learnable dimensional rationale acquiring network updated via bi-level meta-learning. The method is validated across multiple graph benchmarks, showing significant improvements in both discriminability and transferability compared to state-of-the-art methods. DRGCL consistently ranks among top-3 results, demonstrating the effectiveness of addressing dimensional rationale from a causal perspective.

## Method Summary
DRGCL employs graph neural networks as encoders to generate initial graph embeddings, then applies a learnable dimensional rationale weight to mask specific dimensions. A redundancy reduction constraint is applied to ensure the learned dimensions are decorrelated. The method uses bi-level meta-learning to update the dimensional rationale weights based on downstream performance. During pre-training, the model optimizes both standard contrastive loss and a redundancy reduction loss, while the meta-learning outer loop updates the DR weights to maximize transferability. For transfer learning, the pre-trained model is fine-tuned on downstream molecular property prediction tasks.

## Key Results
- DRGCL achieves average rank 2.8 in unsupervised learning across 7 TU datasets
- DRGCL achieves highest average accuracy in transfer learning on 9 molecular property prediction tasks
- The method outperforms state-of-the-art graph contrastive learning approaches in both discriminability and transferability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Dimensional rationale acts as a causal confounder between graph embeddings and contrastive labels, requiring backdoor adjustment for proper learning.
- Mechanism: The structural causal model reveals that dimensional rationale influences both learned graph embeddings and contrastive labels. Without adjustment, spurious correlation interferes with downstream performance.
- Core assumption: The causality graph E ← R → Y is accurate, and R represents a confounder rather than mediator or collider.
- Evidence anchors: [abstract] formalization of causality among variables; [section 3.2] identification of R as causal confounder; [corpus] weak corpus support for DR as confounder
- Break condition: If backdoor adjustment fails to capture true causal effect, or if R is actually mediator rather than confounder, theoretical justification collapses.

### Mechanism 2
- Claim: Dimensional rationale is more intrinsic than structural rationale because it preserves information-decoupled features in high-dimensional graph embeddings.
- Mechanism: DR captures dimensions most relevant to downstream tasks, whereas SR only masks structural elements which may still contain redundant information. Redundancy reduction constraint enforces decorrelation between dimensions.
- Core assumption: Graph representation space contains redundant dimensions, and DR can identify task-relevant ones without losing discriminative information.
- Evidence anchors: [abstract] DR is intrinsic to representations; [section 4.2] redundancy reduction reduces redundancy between representations; [corpus] moderate support from invariant feature preservation literature
- Break condition: If redundancy reduction over-prunes useful dimensions or representation space doesn't contain significant redundancy, DRGCL's advantage diminishes.

### Mechanism 3
- Claim: Bi-level meta-learning effectively optimizes dimensional rationale weight by treating it as learnable parameter guiding contrastive loss minimization.
- Mechanism: Outer loop updates DR weights based on encoder/projection head performance, while inner loop optimizes encoder parameters. This creates feedback loop where DR weights evolve to preserve task-relevant information.
- Core assumption: Meta-learning objective correctly captures relationship between DR weights and downstream performance.
- Evidence anchors: [abstract] learnable dimensional rationale acquiring network updated via bi-level meta-learning; [section 4.3] second-derivative technique for bi-level optimization; [corpus] strong support from meta-learning for confounders literature
- Break condition: If meta-learning optimization is unstable or second-derivative computation becomes too noisy, DR acquisition may fail to converge.

## Foundational Learning

- Concept: Structural Causal Model (SCM) and backdoor adjustment
  - Why needed here: Understanding why DR acts as confounder and how to deconfound it is central to DRGCL's theoretical foundation
  - Quick check question: What is the backdoor path in the SCM E ← R → Y, and why does it create spurious correlation?

- Concept: Graph Contrastive Learning (GCL) framework and InfoNCE loss
  - Why needed here: DRGCL builds directly on GCL, modifying loss and embedding extraction process
  - Quick check question: How does standard InfoNCE loss differ from DR-aware InfoNCE loss?

- Concept: Redundancy reduction via decorrelation (Hotelling's methods)
  - Why needed here: Redundancy reduction constraint is key to ensuring DR captures independent information dimensions
  - Quick check question: What is purpose of normalizing representations and minimizing auto-correlation matrix off-diagonals?

## Architecture Onboarding

- Component map: Graph → Encoder (fθ) → Embeddings (h) → DR Weight (R) → DR Projection (gDRIN) → Contrastive Space, Embeddings (h) → Redundancy Reduction Head (gRR) → Redundancy Space

- Critical path:
  1. Sample graphs and create augmentations
  2. Encode to get embeddings h
  3. Apply DR weight: h ⊙ R
  4. Project to latent spaces (DR and RR)
  5. Compute DR-aware contrastive loss and redundancy loss
  6. Perform meta-learning update on R
  7. Regular update on encoder and projection heads

- Design tradeoffs:
  - Meta-learning adds computational overhead but enables adaptive DR discovery
  - Redundancy reduction may lose some information but improves generalization
  - DR weight dimensionality equals embedding dimensionality, increasing parameter count

- Failure signatures:
  - DR weights collapse to all zeros or all ones (no selective masking)
  - Redundancy reduction produces collapsed representations (all dimensions identical)
  - Meta-learning becomes unstable (exploding/vanishing gradients in second derivative)

- First 3 experiments:
  1. Verify DR weight learning: Train with fixed R (all ones) vs. learned R, compare downstream performance
  2. Test redundancy reduction: Train with and without RR loss, measure dimension correlation and accuracy
  3. Validate backdoor adjustment: Compare SCM-based analysis with empirical correlation between E and Y with/without R conditioning

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The meta-learning component significantly increases computational complexity without quantitative analysis of scalability
- The causal modeling assumptions are not empirically validated against alternative causal structures
- Limited evaluation on graph types beyond standard TU datasets and molecular graphs

## Confidence

- High: DRGCL achieves superior empirical performance on benchmark datasets compared to state-of-the-art methods
- Medium: The theoretical justification for treating DR as causal confounder and necessity of backdoor adjustment
- Low: The claim that DR is intrinsically superior to SR without considering task-specific characteristics or domain constraints

## Next Checks
1. Ablation of causal modeling: Train DRGCL variants where DR is treated as mediator or ignored entirely, comparing downstream performance to validate backdoor adjustment assumption
2. Meta-learning vs. alternative DR acquisition: Compare bi-level meta-learning with simpler approaches like reinforcement learning or gradient-based hyperparameter optimization for DR weight learning
3. Dimensionality sensitivity analysis: Systematically vary dimensionality of DR weights and redundancy reduction strength to identify optimal configurations and failure thresholds