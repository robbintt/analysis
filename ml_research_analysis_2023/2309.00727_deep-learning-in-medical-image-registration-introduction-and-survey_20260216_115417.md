---
ver: rpa2
title: 'Deep learning in medical image registration: introduction and survey'
arxiv_id: '2309.00727'
source_url: https://arxiv.org/abs/2309.00727
tags:
- registration
- image
- medical
- deep
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey provides a comprehensive review of deep learning in
  medical image registration (MIR), covering key algorithms, transformations, evaluation
  metrics, and applications. It introduces a symbolic framework for IR components
  and analyzes 96 recent MIR papers, categorizing them by modality, directionality,
  and correspondence.
---

# Deep learning in medical image registration: introduction and survey

## Quick Facts
- arXiv ID: 2309.00727
- Source URL: https://arxiv.org/abs/2309.00727
- Reference count: 24
- This survey comprehensively reviews deep learning in medical image registration, analyzing 96 recent papers and introducing a symbolic framework for registration components.

## Executive Summary
This survey provides a comprehensive overview of deep learning approaches in medical image registration (MIR), covering key algorithms, transformations, evaluation metrics, and applications. It introduces a symbolic framework to describe MIR components and analyzes 96 recent papers, categorizing them by modality, directionality, and correspondence types. The paper discusses both deep learning methods like Voxelmorph and Synthmorph, as well as classical approaches, highlighting their strengths and limitations. The survey emphasizes the need for clinical validation and larger, diverse datasets to advance MIR reliability.

## Method Summary
The survey systematically analyzes 96 recent MIR papers using a symbolic framework that describes registration components including transformations, similarity measures, regularization, and evaluation metrics. It categorizes methods by modality type, registration directionality (monomodal vs multimodal), and correspondence (dense vs sparse). The analysis covers both deep learning approaches (supervised, unsupervised, weakly supervised) and classical iterative methods, providing quantitative comparisons where available and identifying key research trends and challenges.

## Key Results
- Deep learning registration (e.g., Voxelmorph) reduces runtime from hours to seconds by moving optimization from run-time to training-time
- Unsupervised deep registration uses fixed images as implicit ground truth, avoiding expensive expert annotations
- Multi-stage registration (coarse-fine, pyramid) improves accuracy by progressively refining deformation from global to local scales

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Deep learning registration (e.g., Voxelmorph) reduces runtime from hours to seconds by moving optimization from run-time to training-time.
- Mechanism: During training, a deep network learns a general deformation field estimator; at inference, it simply applies the learned weights without iterative optimization.
- Core assumption: The learned deformation field is sufficiently general to handle unseen cases within the same domain distribution.
- Evidence anchors:
  - [abstract]: "Voxelmorph cut the registration runtime to minutes/seconds compared to hours needed by non-deep learning methods"
  - [section 6.3.2]: "The main reason for the longer RT in iterative approaches is the optimization done during the runtime, however, Voxelmorph-like approaches do not optimize the variables during the run phase, instead, all the variables are optimized in the training phase"
- Break condition: If test data distribution shifts significantly (e.g., different modality, pathology), the learned weights may produce poor registrations and require re-training or fine-tuning.

### Mechanism 2
- Claim: Unsupervised deep registration uses fixed images as implicit ground truth, avoiding expensive expert annotations.
- Mechanism: The network learns to warp the moving image so that it resembles the fixed image; similarity loss (e.g., MSE, CC) drives the deformation field without explicit labels.
- Core assumption: Fixed and moving images are from similar modalities and contain comparable anatomical structures so that the fixed image can serve as a proxy target.
- Evidence anchors:
  - [abstract]: "Unsupervised MIR approaches do not entail an external supervision signal. Instead, the fixed image (input) was assumed to replace the ground truth label"
  - [section 6.3.1]: "The assumption may not work well if the fixed image and the moving image are of different modalities (e.g., one is 3D MRI, and the other is 2D X-ray)"
- Break condition: Large domain gaps (different modalities, contrasts) break the fixed-image-as-ground-truth assumption, requiring modality adaptation or synthetic data.

### Mechanism 3
- Claim: Multi-stage registration (coarse-fine, pyramid) improves accuracy by progressively refining the deformation from global to local scales.
- Mechanism: First stage uses rigid or affine alignment to roughly align the images, reducing the search space for the second stage which performs finer deformable registration.
- Core assumption: Large-scale misalignments can be corrected by simple transforms, leaving residual deformations small enough for the fine stage to handle effectively.
- Evidence anchors:
  - [section 6.6.1]: "A coarse-fine registration consists of two stages: The first stage is called coarse registration, which aims at finding a fast registration solution but not optimal. That solution is fine-tuned later in the second stage"
  - [section 6.6.2]: "A pyramid consists of multi-scale images, where registration occurs at multiple stages"
- Break condition: If the coarse stage fails to correct large misalignments, the fine stage may converge to a poor local optimum.

## Foundational Learning

- Concept: Image registration transforms a moving image to align with a fixed image in a common reference space.
  - Why needed here: Registration is the core task; all algorithms aim to estimate a transformation that satisfies correspondence constraints.
  - Quick check question: What is the difference between domain and codomain in an image registration context?
- Concept: Transformation types (rigid, affine, deformable) and their mathematical constraints.
  - Why needed here: Different applications require different deformation rigidity; algorithm choice depends on expected tissue motion.
  - Quick check question: Does a rigid transformation preserve distances between all point pairs?
- Concept: Loss functions (MSE, cross-correlation, Jacobian regularization) and their properties.
  - Why needed here: Loss drives the optimization; understanding its behavior is critical for diagnosing registration quality.
  - Quick check question: Why is cross-correlation more robust to contrast differences than MSE?

## Architecture Onboarding

- Component map: Input pipeline → Preprocessor (resampling, normalization) → Registration model (CNN/Transformer) → Spatial transformer → Post-processor (resampling) → Evaluation metrics
- Critical path: Data loading → Model forward pass → Loss computation → Gradient back-propagation (training) or metric computation (inference)
- Design tradeoffs:
  - Accuracy vs. runtime: deep networks are fast at inference but require large training data
  - Modality generalization vs. specialization: unsupervised methods are cheaper but less robust across domains
  - Model complexity vs. memory: deeper architectures yield better performance but need more GPU memory
- Failure signatures:
  - Poor alignment in low-contrast regions → check loss sensitivity and regularization
  - Runtime slower than expected → inspect spatial transformer and resampling overhead
  - Inconsistent results across runs → check random seed and model initialization
- First 3 experiments:
  1. Train a simple Voxelmorph-like network on synthetic affine deformations; verify runtime drop vs. iterative method
  2. Compare MSE vs. cross-correlation loss on multi-modal data; measure registration accuracy
  3. Implement a two-stage coarse-fine pipeline; test whether coarse alignment improves fine-stage convergence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of transformer-based models compare to convolutional models in medical image registration, particularly for large-scale datasets?
- Basis in paper: [explicit] The paper discusses the potential of transformers in MIR but notes their limited utilization due to the relatively small number of images in MIR datasets compared to other domains. It also mentions the difficulty of developing transformers for MIR due to the large number of trainable parameters compared to convolutional units.
- Why unresolved: While the paper mentions the potential of transformers, it does not provide a direct comparison of their performance against convolutional models in MIR tasks.
- What evidence would resolve it: A comprehensive study comparing transformer-based and convolutional models on the same large-scale MIR datasets, evaluating their performance in terms of accuracy, runtime, and resource utilization.

### Open Question 2
- Question: Can end-to-end deep learning models eliminate the need for explicit image registration in medical image analysis pipelines?
- Basis in paper: [explicit] The paper discusses the potential of end-to-end deep learning models to perform medical image analysis tasks without explicit registration steps, citing a study on breast cancer prediction using vision transformers and multi-view images.
- Why unresolved: While the paper presents this as a potential research direction, it does not provide conclusive evidence on the effectiveness and limitations of end-to-end models in replacing explicit registration.
- What evidence would resolve it: Comparative studies evaluating the performance of end-to-end models versus traditional pipelines with explicit registration on various medical image analysis tasks, assessing their accuracy, efficiency, and robustness.

### Open Question 3
- Question: How can the interpretability of deep learning models in medical image registration be improved to gain trust and facilitate clinical adoption?
- Basis in paper: [explicit] The paper highlights the need for more clinical-based evaluation and the involvement of domain experts from the medical field in the evaluation of MIR tools. It also mentions the challenges of MIR assessment, including the lack of ground truth labels and the instability of outcomes for some algorithms.
- Why unresolved: While the paper acknowledges the importance of interpretability, it does not provide specific solutions or methodologies to address this challenge.
- What evidence would resolve it: Research on developing interpretable deep learning models for MIR, incorporating techniques such as attention visualization, feature importance analysis, and explainable AI methods. Additionally, studies evaluating the impact of model interpretability on clinical decision-making and trust.

## Limitations

- Data Dependency: Performance heavily depends on training data quality and distribution, with limited evaluation of cross-domain generalization
- Clinical Validation Gap: Most evaluation uses technical metrics rather than clinically meaningful outcomes, limiting real-world applicability
- Modality Generalization: Unsupervised methods break down for multi-modal registration when fixed-image-as-ground-truth assumption fails

## Confidence

- High Confidence: Runtime improvements of deep learning methods over classical iterative approaches are well-established through multiple cited studies and direct performance comparisons
- Medium Confidence: The categorization framework for MIR methods is systematic but may not capture all practical nuances of implementation differences
- Low Confidence: Claims about transformer-based models revolutionizing registration are forward-looking and speculative, based on early results rather than established practice

## Next Checks

1. Cross-Institution Generalization: Evaluate Voxelmorph on datasets from different hospitals/scanning protocols to quantify performance drop and identify failure modes

2. Clinical Task Validation: Design a study where registration outputs are used in downstream clinical workflows (e.g., surgical planning) and measure impact on clinical decisions rather than technical metrics

3. Multi-Modal Robustness: Systematically test unsupervised registration across modality pairs (CT-MR, US-MR, X-ray-CT) to quantify where the fixed-image assumption fails and what adaptation strategies are needed