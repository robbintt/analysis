---
ver: rpa2
title: Extending Explainable Boosting Machines to Scientific Image Data
arxiv_id: '2305.16526'
source_url: https://arxiv.org/abs/2305.16526
tags:
- class
- image
- data
- features
- feature
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work extends Explainable Boosting Machines (EBMs) to scientific
  image data, addressing the need for interpretable machine learning in scientific
  applications. The authors propose a Gabor Wavelet Transform-based method to extract
  and tabularize visual features from images, enabling the application of EBMs to
  image classification tasks.
---

# Extending Explainable Boosting Machines to Scientific Image Data

## Quick Facts
- arXiv ID: 2305.16526
- Source URL: https://arxiv.org/abs/2305.16526
- Reference count: 40
- Primary result: Extends EBMs to scientific image data using Gabor Wavelet Transform, achieving accuracy on par with neural networks while providing superior interpretability.

## Executive Summary
This work addresses the challenge of applying highly interpretable Explainable Boosting Machines (EBMs) to scientific image data. The authors propose a method that uses Gabor Wavelet Transform to extract and tabularize visual features from images, enabling EBMs to perform classification tasks on scientific imagery. Demonstrated on cold-atom soliton image data, this approach achieves classification accuracy comparable to state-of-the-art neural network methods while providing superior explanations that align with human intuition about the data. The method reveals important features and pairwise interactions, validated through feature importance graphs and dependence plots consistent with domain knowledge.

## Method Summary
The method extends EBMs to image classification by first converting images into tabular features using a Gabor Wavelet Transform-based approach. This involves optimizing Gabor kernel parameters on a per-image basis to identify regions of interest, then extracting ℓ2-norm features from four quadrants around the detected excitation center. These raw Gabor features (GF) are combined with engineered features (EGF) derived from pairwise ratios to form the final feature table. EBMs are then trained on these tabular features, modeling both univariate functions and pairwise interactions. The approach is validated on a dataset of over 16,000 BEC soliton images, demonstrating classification performance on par with neural networks while providing interpretable explanations through feature importance graphs and dependence plots.

## Key Results
- EBM-based approach achieves classification accuracy comparable to state-of-the-art neural network methods on BEC soliton image data
- EBM provides superior explanations that align with human intuition about soliton excitations
- Feature importance graphs and dependence plots reveal physically meaningful features and pairwise interactions consistent with domain knowledge
- Engineered features (ratios of quadrant responses) substantially improve performance, especially for underrepresented classes like vortices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Gabor Wavelet Transform preserves spatial structure while converting images into tabular features that EBMs can consume.
- Mechanism: GWT convolves images with parameterized Gabor kernels that capture local scale, orientation, and wavelength. By optimizing kernel parameters per image, the method identifies and extracts the excitation region and its shoulders. Quadrant-based feature extraction yields tabular descriptors (ℓ2-norms) of these localized responses.
- Core assumption: The dominant solitonic excitation occupies a well-defined spatial region whose local features are best represented by a single Gabor kernel.
- Evidence anchors:
  - [abstract] "propose a Gabor Wavelet Transform-based method to extract and tabularize visual features from images"
  - [section] "By optimizing the parameters defining the Gabor kernel on a per-image basis, we can determine the locations and the size (scale) of the regions of interest."
  - [corpus] Weak: no explicit mention of GWT in neighbors, though EBM interpretability is discussed.
- Break condition: If the image contains multiple excitations at different orientations or scales, a single kernel may fail to capture all relevant features.

### Mechanism 2
- Claim: EBMs reveal physically meaningful pairwise interactions between tabularized features that align with human intuition about soliton data.
- Mechanism: EBMs model univariate functions and pairwise interactions, visualized as feature importance graphs and dependence plots. For soliton images, EBMs rank quadrant-based ℓ2-norms and engineered ratios (e.g., TL/TR) by importance, revealing that asymmetries in excitation shoulders are predictive of vortex class.
- Core assumption: The physics of soliton excitations is encoded in measurable asymmetries of the excitation profile that can be represented by pairwise feature ratios.
- Evidence anchors:
  - [abstract] "EBM-based approach provides superior explanations that align with human intuition about the data"
  - [section] "This correlation is confirmed by the EBMs, consistently ranking TR and BR as the two most important features."
  - [corpus] Weak: EBM interpretability is discussed but not specifically tied to pairwise interactions in image data.
- Break condition: If feature engineering misses a critical interaction, EBM explanations will be incomplete.

### Mechanism 3
- Claim: Engineered features derived from raw Gabor features improve EBM performance on underrepresented classes (e.g., vortices).
- Mechanism: Raw Gabor features (TL, TR, BL, BR, x*, y*) are combined into ratios (e.g., TL/TR, BL/BR) to capture asymmetric responses. These engineered features are then included in the EBM feature table, improving recall and precision for minority classes.
- Core assumption: Pairwise ratios of quadrant responses encode discriminative information not captured by individual raw features.
- Evidence anchors:
  - [abstract] "show that our approach provides better explanations than other state-of-the-art ML explainability methods for images"
  - [section] "Given that different pairs of GF features are important for different classes, we add all primary pairs as engineered GF (EGF) features"
  - [corpus] Weak: No neighbor paper discusses engineered feature construction for EBM.
- Break condition: If the ratio features introduce redundancy or noise, EBM performance may degrade.

## Foundational Learning

- Concept: Gabor Wavelet Transform and parameter optimization
  - Why needed here: To convert spatial image data into interpretable tabular form suitable for EBMs.
  - Quick check question: What does the ℓ2-norm of a convolved region measure in this context?

- Concept: Explainable Boosting Machines and pairwise interaction visualization
  - Why needed here: To interpret which image features drive classification and how they interact.
  - Quick check question: How does EBM’s feature importance plot differ from a simple correlation heatmap?

- Concept: Feature engineering from raw tabular data
  - Why needed here: To enhance EBM discrimination on imbalanced classes by encoding domain knowledge.
  - Quick check question: Why might TL/TR be more informative than TL alone for vortex detection?

## Architecture Onboarding

- Component map: Image → GWT optimization → Convolution → Quadrant extraction → ℓ2-norm computation → Tabularizer → EBM trainer → Interpreter
- Critical path: Image → GWT optimization → Feature extraction → EBM training → Interpretability analysis
- Design tradeoffs:
  - GWT single-kernel vs multi-kernel: Single kernel is faster but may miss multi-orientation features.
  - ℓ2-norm vs histogram: ℓ2-norm is simpler and more robust to noise; histograms capture richer distribution but need tuning.
  - EBM vs NN: EBM gives interpretability but may be less flexible than deep nets.
- Failure signatures:
  - Poor accuracy: GWT kernel parameters not well tuned; features do not capture relevant physics.
  - Misleading explanations: EBM overfits; engineered features introduce spurious interactions.
  - Slow runtime: Excessive parameter grid search in GWT; large EBM feature space.
- First 3 experiments:
  1. Run GWT on a single labeled image, plot the optimized filter response, verify excitation region detection.
  2. Train EBM on GF features only, inspect feature importance to confirm y* importance for longitudinal vs partial classes.
  3. Add EGF features, retrain EBM, compare accuracy and feature importance to assess impact.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the Gabor Wavelet Transform (GWT) approach scale when applied to scientific images with multiple orientations or more complex feature structures compared to single-orientation data like solitons in BECs?
- Basis in paper: [explicit] The authors mention that "for structurally more complex data where feature orientation or scale needs to be considered, extracting meaningful features might necessitate the designing of a proper GWT-based filter bank."
- Why unresolved: The paper only demonstrates the method on data with a single dominant orientation. Scaling to multiple orientations would require repeating the process with different fixed angles, which could increase computational complexity significantly.
- What evidence would resolve it: Experimental results showing classification accuracy and interpretability of the GWT approach on datasets with multiple orientations or more complex feature structures, comparing it to the current single-orientation results.

### Open Question 2
- Question: What is the optimal balance between raw Gabor features (GF) and engineered Gabor features (EGF) for maximizing both classification accuracy and interpretability in scientific image analysis?
- Basis in paper: [explicit] The authors note that adding EGF results in substantial improvements in performance, especially for underrepresented classes, but they don't systematically explore the trade-off between feature complexity and model performance.
- Why unresolved: The paper presents results with all engineered features added, but doesn't investigate which combinations of raw and engineered features provide the best balance between accuracy and interpretability.
- What evidence would resolve it: A systematic ablation study varying the number and type of engineered features, measuring both classification performance and interpretability metrics across different scientific image datasets.

### Open Question 3
- Question: How does the performance of EBM-based approaches with GWT features compare to other interpretable methods (like decision trees or rule-based models) when applied to scientific image data?
- Basis in paper: [inferred] While the paper compares EBM to neural network approaches, it doesn't directly compare to other glass-box models that could also be adapted to image data through feature extraction.
- Why unresolved: The authors focus on comparing EBMs to black-box models (neural networks) but don't benchmark against other interpretable models that might have different strengths and weaknesses.
- What evidence would resolve it: Direct comparison of EBM with GWT features against decision trees, rule-based models, or other interpretable models on the same scientific image datasets, measuring both accuracy and interpretability metrics.

## Limitations
- Method transferability: Validated only on BEC soliton images with specific geometry; generalization to other scientific domains untested
- Hyperparameter sensitivity: Parameter space optimization for GWT not detailed; performance may depend heavily on choice of grid or optimization algorithm
- EBM model complexity: Number of pairwise interactions and maximum tree depth not specified, making overfitting risk difficult to assess

## Confidence

- Claim: EBM explanations align with human intuition → High confidence
- Claim: Engineered features improve minority class performance → Medium confidence
- Claim: EBM matches NN accuracy → Medium confidence

## Next Checks

1. Cross-domain validation: Apply the GWT+EBM pipeline to a different scientific image dataset (e.g., cell microscopy) and assess feature interpretability and classification performance.

2. Ablation study on engineered features: Train EBMs with and without EGF features, report accuracy, precision, recall for each class, and inspect changes in feature importance rankings.

3. Robustness to GWT parameters: Vary GWT kernel parameter grid resolution and optimization method, measure impact on classification accuracy and stability of explanations across folds.