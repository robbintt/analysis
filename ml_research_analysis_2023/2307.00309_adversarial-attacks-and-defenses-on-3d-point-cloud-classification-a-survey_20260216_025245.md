---
ver: rpa2
title: 'Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey'
arxiv_id: '2307.00309'
source_url: https://arxiv.org/abs/2307.00309
tags:
- point
- adversarial
- cloud
- attacks
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This survey provides a comprehensive review of adversarial attacks
  and defenses on 3D point cloud classification, addressing the lack of surveys specifically
  focused on this topic. It categorizes the seven most common approaches for generating
  adversarial point clouds and the three main categories of defense methods: input
  transformation, data optimization, and deep model modification.'
---

# Adversarial Attacks and Defenses on 3D Point Cloud Classification: A Survey

## Quick Facts
- arXiv ID: 2307.00309
- Source URL: https://arxiv.org/abs/2307.00309
- Reference count: 40
- Primary result: Comprehensive survey of 7 attack methods and 3 defense categories for 3D point cloud classification

## Executive Summary
This survey addresses the gap in comprehensive reviews specifically focused on adversarial attacks and defenses for 3D point cloud classification. The paper systematically categorizes seven common attack generation approaches and three main defense categories (input transformation, data optimization, deep model modification). It provides a taxonomy of datasets and victim models used in recent studies, highlighting the unique challenges posed by the irregular structure of point clouds compared to 2D images.

## Method Summary
The survey synthesizes existing literature on 3D adversarial attacks and defenses by categorizing attack methods into seven approaches including sparse and dense perturbations, adversarial point attachment/removal, and optimization-based methods. Defense strategies are organized into three categories: input transformation techniques like statistical outlier removal, data optimization through adversarial training, and deep model modifications. The analysis uses ModelNet40 as a representative dataset with standard classifiers like PointNet and DGCNN for evaluating attack success rates and defense effectiveness.

## Key Results
- 3D adversarial attacks can be generated through seven distinct approaches targeting point cloud classifiers
- Defense methods fall into three main categories: input transformation, data optimization, and deep model modification
- The irregular structure of 3D point clouds presents unique challenges compared to defending 2D images
- Effectiveness of defenses depends on attack type, model complexity, and point cloud structure

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Systematic categorization of seven attack methods and three defense categories provides structured overview
- Mechanism: Organization enables researchers to understand field landscape and identify research gaps
- Core assumption: Identified categories represent most significant approaches in literature
- Evidence anchors: Abstract mentions categorization; section details defense categories; corpus provides limited direct support
- Break Condition: New methods emerge that don't fit current categories or significant approaches are missed

### Mechanism 2
- Claim: Irregular structure of point clouds compared to 2D images creates unique defense challenges
- Mechanism: Highlighting structural differences emphasizes 3D-specific challenges like irregular point distribution
- Core assumption: Structural differences significantly impact defense effectiveness
- Evidence anchors: Abstract discusses 3D-specific challenges; section compares 2D and 3D structures; corpus lacks direct evidence
- Break Condition: 2D defense techniques prove effective for 3D without significant modifications

### Mechanism 3
- Claim: Taxonomy of datasets and models helps researchers select appropriate evaluation resources
- Mechanism: Organizing available resources enables proper experimental setup and result comparison
- Core assumption: Listed datasets and models are representative of field standards
- Evidence anchors: Abstract mentions taxonomy; section lists common datasets; corpus lacks direct evidence
- Break Condition: New widely-adopted datasets or models are excluded from taxonomy

## Foundational Learning

- Concept: 3D point clouds and their representation
  - Why needed here: Understanding point cloud structure is crucial for comprehending attack manipulation and defense mechanisms
  - Quick check question: What are main differences between 3D point clouds and 2D images in data representation and structure?

- Concept: Adversarial attacks and their objectives
  - Why needed here: Understanding attack goals and methods is essential for grasping defense challenges
  - Quick check question: What are main types of adversarial attacks on 3D point clouds and how do they differ in objectives and methods?

- Concept: Defense strategies against adversarial attacks
  - Why needed here: Familiarity with defense categories is necessary to understand protection approaches
  - Quick check question: How do three main defense categories differ in protecting 3D point cloud classifiers?

## Architecture Onboarding

- Component map: Introduction -> Attack Methods -> Defense Strategies -> Dataset Taxonomy -> Challenges/Future Directions
- Critical path: Understand 3D point clouds and attacks → Explore attack methods → Examine defense strategies → Analyze challenges and future directions
- Design tradeoffs: Balance depth of method coverage with breadth of topics; too much detail makes survey long, too little provides insufficient understanding
- Failure signatures: Unclear categorization of methods or inadequate address of 3D structure challenges reduces survey effectiveness
- First 3 experiments:
  1. Reproduce 3D FGSM attack on ModelNet40 to understand methodology
  2. Implement statistical outlier removal defense and evaluate against reproduced attack
  3. Compare standard vs adversarial training classifiers on ModelNet40 benchmark

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is optimal balance between Chamfer distance and attack success rate for adversarial point clouds?
- Basis in paper: Paper mentions trade-off between Chamfer distance and attack success rate
- Why unresolved: No specific guidelines provided for finding optimal balance
- What evidence would resolve it: Empirical studies varying Chamfer distance and measuring attack success rates across different attacks and defenses

### Open Question 2
- Question: How do different 3D point cloud attacks compare in transferability across deep learning models?
- Basis in paper: Paper mentions transferability concept but lacks comprehensive comparison
- Why unresolved: No detailed analysis of transferability across different attack types
- What evidence would resolve it: Experimental studies evaluating transferability of different attack types across various 3D point cloud classifiers

### Open Question 3
- Question: How effective are defense methods against adaptive attacks designed to circumvent them?
- Basis in paper: Paper mentions adversarial training limitations against adaptive attacks
- Why unresolved: No detailed analysis of defense effectiveness against adaptive attacks
- What evidence would resolve it: Experimental studies evaluating defense performance against adaptive attacks specifically designed to circumvent them

## Limitations

- Primary reliance on 2019-2022 literature may miss most current developments
- Seven attack methods and three defense categories may not be exhaustive
- Comparison between 2D and 3D structures lacks direct empirical evidence from corpus

## Confidence

- High Confidence: Existence of 3D adversarial attacks and general defense categorization
- Medium Confidence: Specific seven attack methods and three defense categories based on recent studies
- Low Confidence: Claim about irregular structure being primary defense challenge lacks direct evidence

## Next Checks

1. Verify effectiveness of seven attack methods on ModelNet40 using public code to ensure accurate categorization
2. Implement and evaluate three defense categories on same dataset to assess relative performance
3. Review 2023-2024 literature to identify new methods not captured in current taxonomy and assess need for updates