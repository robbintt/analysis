---
ver: rpa2
title: 'Probing the Creativity of Large Language Models: Can models produce divergent
  semantic association?'
arxiv_id: '2310.11158'
source_url: https://arxiv.org/abs/2310.11158
tags:
- creativity
- language
- semantic
- llms
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether large language models can exhibit
  creativity by measuring their ability to generate divergent semantic associations
  using the Divergent Association Task (DAT). The study compares different LLMs and
  decoding strategies, including greedy search and top-p sampling with temperature
  scaling.
---

# Probing the Creativity of Large Language Models: Can models produce divergent semantic association?

## Quick Facts
- arXiv ID: 2310.11158
- Source URL: https://arxiv.org/abs/2310.11158
- Reference count: 10
- Key outcome: GPT-4 outperforms 96% of humans on the DAT using greedy search, while GPT-3.5-Turbo exceeds average human performance

## Executive Summary
This paper investigates whether large language models (LLMs) can exhibit creativity by measuring their ability to generate divergent semantic associations using the Divergent Association Task (DAT). The study compares different LLMs and decoding strategies, including greedy search and top-p sampling with temperature scaling. Results show that GPT-4 outperforms 96% of humans on the DAT using greedy search, while GPT-3.5-Turbo exceeds average human performance. Stochastic decoding strategies improve DAT scores for most models except GPT-4 but face a trade-off between creativity and stability. These findings suggest that advanced LLMs can generate divergent semantic associations, a fundamental aspect of creativity, with GPT-4 demonstrating implicit control over probability distribution for stable creative generation.

## Method Summary
The study evaluates creativity in LLMs using the DAT task, where models generate 10 unrelated nouns. Five models (GPT-4, GPT-3.5-Turbo, Oasst-Llama-30B, Vicuna-13B, ChatGLM-6B) are tested using greedy search and top-p sampling decoding strategies. DAT scores are calculated as the average cosine distance between word embeddings of the first seven valid nouns. Results are compared against human performance data (8572 participants) and analyzed for relationships between DAT scores and surprisal (negative log word frequency).

## Key Results
- GPT-4 outperforms 96% of humans on DAT using greedy search decoding
- GPT-3.5-Turbo exceeds average human performance on DAT
- Stochastic decoding strategies improve DAT scores for most models except GPT-4, but introduce stability trade-offs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 exhibits advanced human-level creativity in generating divergent semantic associations when using greedy search decoding.
- Mechanism: GPT-4 implicitly modulates the probability distribution to generate semantically unrelated words, achieving higher DAT scores without relying on stochastic sampling strategies.
- Core assumption: The probability distribution learned by GPT-4 aligns well with high-quality creative generation, allowing it to produce novel and valuable content stably.
- Evidence anchors:
  - [abstract]: "When using the greedy search strategy, GPT-4 outperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level."
  - [section]: "We find GPT-4 demonstrates advanced human-level creativity stably, while GPT-3.5-turbo exceeds the average human level."
  - [corpus]: Weak - no direct evidence found in corpus, but the abstract and section support this mechanism.
- Break condition: If GPT-4's probability distribution becomes misaligned with creative generation, or if the greedy search strategy is no longer optimal for the task.

### Mechanism 2
- Claim: Stochastic decoding strategies (top-p sampling with temperature scaling) can improve DAT scores for most models except GPT-4, but face a trade-off between creativity and stability.
- Mechanism: By introducing randomness into the decoding process, stochastic strategies allow models to explore a wider range of semantic associations, potentially generating more divergent content. However, this comes at the cost of increased instability and the risk of producing low-quality or invalid answers.
- Core assumption: The balance between creativity and stability is crucial for effective creative generation, and different models may have varying optimal points for this balance.
- Evidence anchors:
  - [abstract]: "Stochastic sampling and temperature scaling are effective to obtain higher DAT scores for models except GPT-4, but face a trade-off between creativity and stability."
  - [section]: "When using top-p sampling, models other than GPT-4 are capable of getting the DAT much higher than greedy search, but they also become unstable that probably generate answers with low DAT scores."
  - [corpus]: Weak - no direct evidence found in corpus, but the abstract and section support this mechanism.
- Break condition: If the trade-off between creativity and stability becomes too severe, or if the model's ability to modulate the probability distribution is insufficient to maintain quality under increased randomness.

### Mechanism 3
- Claim: The DAT score is influenced by word frequency, and controlling for surprisal (negative log word frequency) can reveal the true semantic divergence capabilities of models.
- Mechanism: Rare words tend to have unstable semantic distances due to lack of training, potentially confounding the DAT score. By controlling for surprisal, we can isolate the effect of semantic divergence from the effect of word frequency, providing a more accurate assessment of the model's creative abilities.
- Core assumption: Word frequency is a confounding variable in the DAT score, and controlling for it is necessary to accurately compare the semantic divergence capabilities of different models.
- Evidence anchors:
  - [section]: "Theoretically, surprisal is corresponding to the novelty that is an element of creativity, and the original DAT metric including word frequency effect is valid for human as well... But as mentioned in Section 3.3, word frequency might be a confounding variable when calculating semantic distance."
  - [corpus]: Weak - no direct evidence found in corpus, but the section supports this mechanism.
- Break condition: If the relationship between surprisal and DAT score is not consistent across models, or if controlling for surprisal does not significantly alter the relative performance of models.

## Foundational Learning

- Concept: Semantic networks and their role in creative thinking
  - Why needed here: Understanding how semantic networks influence the ability to generate divergent associations is crucial for interpreting the results of the DAT and assessing the creativity of LLMs.
  - Quick check question: How do semantic networks facilitate remote association and inhibition of common ideas in creative thinking?

- Concept: Decoding strategies and their impact on language generation
  - Why needed here: Different decoding strategies can significantly affect the quality and diversity of generated text, and understanding their strengths and limitations is essential for designing effective creative generation tasks.
  - Quick check question: What are the key differences between deterministic (e.g., greedy search) and stochastic (e.g., top-p sampling) decoding strategies, and how do they influence the generated content?

- Concept: Word frequency and its effect on semantic distance measurements
  - Why needed here: Word frequency can confound the measurement of semantic distance, particularly for rare words, and controlling for it is necessary to accurately assess the semantic divergence capabilities of models.
  - Quick check question: How does word frequency influence the stability of semantic distance measurements, and why is it important to control for it when evaluating creative generation?

## Architecture Onboarding

- Component map: Prompts -> LLMs (GPT-4, GPT-3.5-Turbo, Oasst-Llama-30B, Vicuna-13B, ChatGLM-6B) -> Decoding strategies (greedy search, top-p sampling) -> Generated nouns -> DAT score calculation -> Comparison with human performance

- Critical path:
  1. Generate nouns using the specified LLMs and decoding strategies
  2. Filter out invalid words (e.g., verbs)
  3. Select the first seven valid words from each model's output
  4. Calculate the DAT score using the average cosine distance between word embeddings
  5. Compare DAT scores across models, decoding strategies, and human performance

- Design tradeoffs:
  - Deterministic vs. stochastic decoding strategies: Balancing stability and creativity
  - Word frequency control: Ensuring accurate measurement of semantic divergence while maintaining the integrity of the DAT task
  - Sample size: Determining the appropriate number of samples for stable results while considering computational efficiency

- Failure signatures:
  - Low DAT scores across all models and decoding strategies: May indicate issues with the task design or evaluation method
  - Inconsistent DAT scores for a single model across different runs: Could suggest instability in the model's generation process or issues with the decoding strategy
  - Significant deviation from human performance: May indicate limitations in the model's ability to generate divergent semantic associations or issues with the evaluation method

- First 3 experiments:
  1. Compare the DAT scores of GPT-4 and GPT-3.5-Turbo using greedy search decoding to establish a baseline for advanced LLMs.
  2. Investigate the effect of top-p sampling with varying temperature settings on the DAT scores of the smaller models (Oasst-Llama-30B, Vicuna-13B, ChatGLM-6B) to identify the optimal balance between creativity and stability.
  3. Control for word frequency by calculating the surprisal of generated words and analyzing its relationship with the DAT score to isolate the effect of semantic divergence from word frequency.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the superiority of GPT-4 in the DAT persist when controlling for word frequency?
- Basis in paper: [explicit] The paper mentions that GPT-4 and GPT-3.5-Turbo outperform average human performance even when controlling for surprisal, but notes that GPT-4's superiority is attenuated.
- Why unresolved: While the paper controls for surprisal, it doesn't fully isolate the effect of word frequency on semantic distance calculations.
- What evidence would resolve it: A study that uses word embeddings that are explicitly controlled for frequency effects, or a method that normalizes semantic distances based on word frequency distributions.

### Open Question 2
- Question: Can LLMs generate creative content beyond divergent semantic associations, such as novel combinations of concepts or ideas?
- Basis in paper: [inferred] The paper focuses on measuring creativity through divergent semantic associations but acknowledges that creativity is a complex concept that requires evaluation from multiple perspectives.
- Why unresolved: The study uses a specific task (DAT) that measures one aspect of creativity (divergent thinking) but doesn't explore other dimensions of creative ability.
- What evidence would resolve it: Tests of LLMs on tasks that require combining concepts in novel ways, generating metaphors, or producing original solutions to open-ended problems.

### Open Question 3
- Question: How do different decoding strategies affect the quality and stability of creative outputs in LLMs?
- Basis in paper: [explicit] The paper investigates the effect of greedy search and top-p sampling with temperature scaling on DAT scores, finding a trade-off between creativity and stability for stochastic methods.
- Why unresolved: While the paper compares two decoding strategies, it doesn't explore the full range of possible decoding methods or their effects on different types of creative tasks.
- What evidence would resolve it: Systematic comparison of multiple decoding strategies (e.g., beam search, nucleus sampling with different parameters) across various creative tasks, measuring both quality and consistency of outputs.

## Limitations
- The DAT task measures only one specific aspect of creativity (divergent semantic association), which may not fully capture the multifaceted nature of human creativity.
- The comparison between LLMs and humans is based on different response modalities, potentially introducing systematic biases.
- The study relies on pre-trained GLoVe embeddings for semantic distance calculations, which may not perfectly align with the semantic representations learned by modern LLMs.

## Confidence
- High: The finding that GPT-4 outperforms 96% of humans on the DAT using greedy search is well-supported by the experimental results and consistent across multiple runs.
- Medium: The observation that stochastic decoding strategies improve DAT scores for most models except GPT-4 is supported by the data, but the trade-off between creativity and stability requires further investigation.
- Low: The conclusion that word frequency significantly confounds DAT scores and requires surprisal control is based on theoretical reasoning rather than strong empirical evidence from the current study.

## Next Checks
1. Conduct cross-validation using multiple semantic similarity measures (e.g., BERT-based embeddings, Word2Vec) to verify that the observed differences in DAT scores are not artifacts of the specific embedding method used.

2. Perform ablation studies with different prompt formulations and decoding strategies to determine whether the observed performance differences are robust to changes in experimental conditions.

3. Test the models on additional creativity assessment tasks (e.g., Remote Associates Test, Torrance Tests of Creative Thinking) to evaluate whether the observed capabilities generalize beyond divergent semantic association to other creative domains.