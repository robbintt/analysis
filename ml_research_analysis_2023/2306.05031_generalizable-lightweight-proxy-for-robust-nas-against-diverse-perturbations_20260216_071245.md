---
ver: rpa2
title: Generalizable Lightweight Proxy for Robust NAS against Diverse Perturbations
arxiv_id: '2306.05031'
source_url: https://arxiv.org/abs/2306.05031
tags:
- clean
- search
- proxy
- robust
- architectures
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a lightweight proxy-based method for neural
  architecture search (NAS) that prioritizes robustness against diverse perturbations,
  such as adversarial attacks and common corruptions, while maintaining computational
  efficiency. Traditional NAS methods focus solely on clean data performance, leaving
  models vulnerable to real-world perturbations.
---

# Generalizable Lightweight Proxy for Robust NAS against Diverse Perturbations

## Quick Facts
- **arXiv ID**: 2306.05031
- **Source URL**: https://arxiv.org/abs/2306.05031
- **Reference count**: 18
- **Primary result**: CRoZe achieves 8.95% higher robust accuracy with 14.7x less search time compared to robust NAS baselines.

## Executive Summary
This paper proposes CRoZe, a lightweight proxy-based method for neural architecture search (NAS) that prioritizes robustness against diverse perturbations while maintaining computational efficiency. Traditional NAS methods focus solely on clean data performance, leaving models vulnerable to real-world perturbations like adversarial attacks and common corruptions. Existing robust NAS approaches address this through adversarial training but are computationally expensive. CRoZe overcomes these limitations by evaluating robustness through consistency measures across features, parameters, and gradients between clean and perturbed inputs in a single gradient step, avoiding iterative training and adversarial training while achieving superior performance.

## Method Summary
CRoZe is a consistency-based zero-cost proxy that evaluates the robustness of neural architectures by measuring similarities between clean and perturbed networks across three dimensions: feature consistency (cosine similarity of layer outputs), parameter consistency (similarity of updated parameters), and gradient consistency (similarity of gradients from clean and perturbed inputs). The method uses a double-perturbation scheme combining layer-wise parameter perturbations with adversarial input perturbations (FGSM) to generate a strong robustness signal. Architectures are evaluated through a single gradient update without iterative training, and the proxy is integrated with random search or evolutionary search algorithms to discover robust architectures in NAS-Bench-201 and DARTS search spaces.

## Key Results
- CRoZe achieves superior Spearman's correlation with robust performance compared to existing zero-cost proxies
- Discovers architectures with up to 8.95% higher robust accuracy compared to robust NAS baselines
- Requires 14.7x less search time than traditional robust NAS methods
- Effectively balances clean accuracy and robustness across CIFAR-10, CIFAR-100, and ImageNet16-120 datasets

## Why This Works (Mechanism)

### Mechanism 1
The proxy evaluates robustness by measuring consistency across features, parameters, and gradients between clean and perturbed inputs in a single gradient step. Clean and robust networks are initialized randomly and updated once using gradients from clean and perturbed inputs respectively. Feature consistency uses cosine similarity between outputs of each layer, parameter similarity compares single-step updated parameters, and gradient similarity compares gradients of clean and robust networks. The core assumption is that architectures extracting similar features and maintaining similar parameters/gradients across clean and perturbed inputs will generalize well to diverse perturbations without overfitting to any single type.

### Mechanism 2
Layer-wise parameter perturbations followed by adversarial input perturbations generate a stronger robustness signal than either alone. Parameters are perturbed by adding a scaled gradient step respecting the norm of original parameters, then adversarial input perturbations are generated using FGSM on already perturbed parameters. This double perturbation forces the proxy to evaluate robustness under worst-case conditions. The core assumption is that combining parameter and input perturbations approximates the behavior of a fully trained robust network in a single step.

### Mechanism 3
CRoZe achieves high Spearman correlation with final robust performance by avoiding biases toward any single perturbation type. By measuring consistency across features, parameters, and gradients simultaneously, CRoZe captures a holistic robustness signal not tied to specific perturbation distributions. The core assumption is that feature variance across diverse perturbations is minimized for truly robust architectures, and CRoZe rewards architectures with low variance.

## Foundational Learning

- **Concept**: Spearman rank correlation as a proxy evaluation metric
  - Why needed here: To quantify how well the proxy's rankings match the rankings of actual robust performance across architectures
  - Quick check question: If CRoZe scores are [0.9, 0.8, 0.7] and true robust accuracies are [95%, 90%, 85%], what is the Spearman correlation?

- **Concept**: Cosine similarity for feature consistency
  - Why needed here: To measure how aligned feature representations are between clean and perturbed inputs across network layers
  - Quick check question: Given feature vectors z_m = [1, 2, 3] and z_r_m = [2, 4, 6], what is their cosine similarity?

- **Concept**: Gradient-based adversarial perturbations (FGSM)
  - Why needed here: To generate perturbed inputs that maximize the loss, creating a strong test of robustness within the proxy
  - Quick check question: What is the formula for FGSM perturbation δ given input x, label y, and model parameters θ?

## Architecture Onboarding

- **Component map**: Input pipeline -> Surrogate networks (clean f_θ, robust f_θ_r) -> Layer-wise parameter perturbation -> FGSM input perturbation -> Forward pass (clean & robust) -> Consistency computation (feature/parameter/gradient) -> CRoZe scoring -> Architecture ranking

- **Critical path**: Input → Surrogate network initialization → Layer-wise parameter perturbation → FGSM input perturbation → Forward pass (clean & robust) → Consistency computation → CRoZe score → Architecture ranking

- **Design tradeoffs**:
  - Single-step vs multi-step updates: Single step is faster but may miss some robustness signals
  - Layer-wise vs global parameter perturbation: Layer-wise is more targeted but adds complexity
  - FGSM vs PGD for input perturbation: FGSM is faster but PGD may provide stronger signals

- **Failure signatures**:
  - CRoZe scores correlate poorly with final robust accuracy
  - High variance in CRoZe scores across different batches
  - Architectures with high CRoZe scores overfit to the specific perturbation type used

- **First 3 experiments**:
  1. Verify CRoZe correlation on NAS-Bench-201 with clean vs perturbed inputs
  2. Test ablation of feature/parameter/gradient components on CIFAR-10
  3. Validate CRoZe performance in DARTS search space against baseline NAS methods

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of CRoZe compare to other robust NAS methods on larger-scale datasets such as ImageNet, and does it maintain its computational efficiency advantage? The paper mentions experiments on CIFAR-10, CIFAR-100, and ImageNet16-120, but not the full ImageNet dataset. Evaluating CRoZe on ImageNet would provide insights into its scalability and real-world applicability.

### Open Question 2
Can the CRoZe proxy be extended to handle other types of perturbations beyond adversarial attacks and common corruptions, such as natural distribution shifts or out-of-distribution samples? The paper focuses on adversarial perturbations and common corruptions but does not explore other types of perturbations that models might encounter in real-world scenarios. Exploring the generalization of CRoZe to a broader range of perturbations would enhance its practical relevance and robustness.

### Open Question 3
How does the choice of the hyperparameters β (step size for parameter perturbations) and γ (learning rate for gradient updates) affect the performance of CRoZe, and is there an optimal strategy for selecting these hyperparameters? The paper mentions the use of β and γ but does not provide a detailed analysis of their impact on performance or discuss strategies for hyperparameter selection.

## Limitations
- The paper lacks precise details on the layer-wise parameter perturbation implementation (β, gradient step size), which could affect reproducibility
- The search algorithm (random search vs. evolutionary search) and sampling strategy in warmup+move are not fully specified
- While claiming to avoid biases toward any single perturbation type, the specific perturbation combinations and their relative weights are not detailed

## Confidence

- **High Confidence**: CRoZe achieves superior Spearman correlation with robust performance and discovers architectures with higher robust accuracy (8.95% improvement)
- **Medium Confidence**: CRoZe's computational efficiency (14.7x less search time) and the specific mechanism of double perturbation combining layer-wise parameter and input perturbations
- **Low Confidence**: The claim that CRoZe avoids biases toward any single perturbation type without overfitting to the specific adversarial attack used

## Next Checks

1. **Implement the missing layer-wise parameter perturbation details**: Test different β values and gradient step sizes to determine their impact on CRoZe's correlation with robust performance and ensure the perturbation generation matches the intended double-perturbation scheme.

2. **Validate search algorithm specification**: Determine whether random search or evolutionary search was used, implement the correct sampling strategy from warmup+move, and verify that the search process matches the reported 14.7x efficiency gain.

3. **Test perturbation generalization**: Evaluate CRoZe's performance when using different adversarial attacks (beyond FGSM) and common corruptions not included in the original perturbation set to confirm it avoids overfitting to specific perturbation types and maintains high correlation with held-out perturbations.