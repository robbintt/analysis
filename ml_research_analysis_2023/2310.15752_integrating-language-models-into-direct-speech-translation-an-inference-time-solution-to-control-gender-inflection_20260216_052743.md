---
ver: rpa2
title: 'Integrating Language Models into Direct Speech Translation: An Inference-Time
  Solution to Control Gender Inflection'
arxiv_id: '2310.15752'
source_url: https://arxiv.org/abs/2310.15752
tags:
- gender
- speech
- language
- translation
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first inference-time solution to control
  speaker-related gender inflections in direct speech translation. The method partially
  replaces the biased internal language model implicitly learned by the ST decoder
  with gender-specific external language models.
---

# Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection

## Quick Facts
- arXiv ID: 2310.15752
- Source URL: https://arxiv.org/abs/2310.15752
- Reference count: 29
- Outperforms base models by up to 31.0 points in gender accuracy for feminine forms in English-to-Spanish/French/Italian ST

## Executive Summary
This paper introduces the first inference-time method to control gender inflections for speaker-dependent words in direct speech translation. The approach addresses bias in the decoder's implicit language model by integrating gender-specific external language models trained on monolingual text. By partially replacing the biased internal model with external gender-specific priors through log-linear interpolation, the method achieves significant improvements in gender accuracy while maintaining translation quality. The gains are particularly pronounced (up to 32.0 points) when speakers' vocal traits conflict with their gender.

## Method Summary
The method trains gender-specific external language models (ELMs) on monolingual text corpora containing masculine or feminine speaker-dependent words. During inference, these ELMs are integrated with the base speech translation model through log-linear interpolation, with an optional step to remove the biased internal language model (ILM) by estimating it as the average decoder output over the training set. The final token distribution combines the base model posterior, ELM prior, and (optionally) subtracted ILM, with weights βILM and βELM controlling their relative influence.

## Key Results
- Outperforms base models by up to 31.0 points in gender accuracy for feminine forms
- Improves over best training-time mitigation strategy by up to 1.6 points
- Gains reach 32.0 points in challenging conditions with vocal trait/gender conflicts

## Why This Works (Mechanism)

### Mechanism 1
The ST decoder's internal language model (ILM) is biased toward masculine forms due to under-representation of feminine speaker-dependent words in training data. The ILM implicitly learned from training data carries statistical patterns that favor masculine translations when no explicit speaker gender is provided. This bias is compounded when vocal traits are used as a fallback, reinforcing masculine defaults.

### Mechanism 2
External language models (ELMs) trained on gender-specific monolingual text can override the biased ILM during inference by providing gender-accurate priors. ELMs are trained on large monolingual corpora containing speaker-dependent words with explicit gender cues. During inference, these models supply gender-specific token probabilities that can counteract the ILM's masculine bias when combined via log-linear interpolation.

### Mechanism 3
ILM removal amplifies the effectiveness of ELM integration by reducing the conflicting influence of the biased internal model. The ILM is estimated as the average decoder output over the entire training set, representing the learned linguistic bias. Subtracting this component from the base model's posterior reduces the dominance of the masculine bias, allowing the ELM's gender-specific priors to have greater influence.

## Foundational Learning

- **Autoregressive decoder modeling in sequence-to-sequence architectures**
  - Why needed here: Understanding how the ST decoder implicitly learns an ILM is crucial to grasping why bias occurs and how ELM integration can correct it.
  - Quick check question: In an autoregressive decoder, what does the model condition on when predicting the next token?

- **Log-linear interpolation of language model scores**
  - Why needed here: The method relies on combining the base model posterior, ELM prior, and ILM estimate via weighted log-linear combination; understanding this is key to tuning βILM and βELM.
  - Quick check question: How does changing the weight βELM affect the influence of the external language model on the final output distribution?

- **Gender-marked morphology in target languages**
  - Why needed here: The effectiveness of the approach depends on the target language having explicit gender inflections that can be controlled; understanding this helps assess applicability to other language pairs.
  - Quick check question: What linguistic feature in Spanish, French, or Italian allows speaker-dependent words to be marked for gender?

## Architecture Onboarding

- **Component map**: Audio waveform → 12-layer Conformer encoder → 6-layer Transformer decoder (pMB) → Log-linear fusion with pELM and pILM → Output token

- **Critical path**: 1. Audio → Encoder → Decoder (pMB) 2. ELM forward pass (pELM) 3. ILM estimation (pILM) 4. Log-linear fusion → Output token. The ELM and ILM computations can be parallelized to reduce latency.

- **Design tradeoffs**: Higher βELM improves gender accuracy but may reduce translation quality if the ELM overfits to training data. Removing ILM (higher βILM) can improve debiasing but risks losing useful linguistic patterns from the base model. Using character-level ELM tokenization could improve generalization but increases computational cost.

- **Failure signatures**: If βELM is too high, outputs may contain grammatical errors or unnatural phrasing due to over-reliance on ELM. If βILM is too high, the system may fail to correct gender bias, producing masculine defaults. If the ELM vocabulary doesn't match the base model's BPE, unknown token errors may occur.

- **First 3 experiments**:
  1. Validate that the base model produces masculine defaults for ambiguous speaker-dependent words by running inference on MuST-SHE Category 1 without gender metadata.
  2. Test ELM integration alone (βILM=0, βELM varied) to confirm gender accuracy improvements without ILM removal.
  3. Perform ablation study comparing MB-ILM+ELM with MB+ELM to quantify the contribution of ILM removal to overall performance.

## Open Questions the Paper Calls Out

### Open Question 1
How would the proposed inference-time solution perform on languages with non-binary gender systems, and what adaptations would be necessary to handle such cases? The paper acknowledges that current ST corpora only represent binary linguistic forms and encourages extending the method to non-binary forms by integrating a third, non-binary ELM. This remains unresolved as ST corpora representing non-binary speakers are not yet available.

### Open Question 2
What is the impact of using character-based vocabularies instead of BPE for training the external language models (ELMs) on gender translation accuracy and overall translation quality? The authors mention that using BPE splits less frequent feminine forms into less compact sequences of tokens, which can penalize generalization on morphology and gender translation. They suggest that training the ELMs with a character-based vocabulary has the potential to enhance gender accuracy and increase the significant gains already achieved, but don't provide experimental results.

### Open Question 3
How does the proposed inference-time solution scale to other language pairs beyond English to Romance languages, and what challenges might arise in adapting the method to different language families? The authors acknowledge that their experiments exclusively evaluate the approach on English to Romance language translations and note that conducting experiments on different language pairs would be valuable but demanding in terms of annotating data. They don't provide experimental results or discuss specific challenges in adapting the method to other language families.

## Limitations

- The core assumption about ILM bias requires empirical validation through controlled experiments showing the ILM's learned distribution
- Effectiveness of ILM removal is asserted but not rigorously tested in isolation through ablation studies
- Generalization capability remains uncertain for out-of-domain speaker-dependent vocabulary

## Confidence

- **High confidence**: Experimental results showing improved gender accuracy when using ELM integration (up to 31.0 points gain for feminine forms)
- **Medium confidence**: Claim that ILM removal amplifies ELM effectiveness, supported by results but lacks direct ablation evidence
- **Medium confidence**: Assertion that training corpora contain gender bias, reasonable given prior research but not systematically analyzed

## Next Checks

1. Conduct an ablation study comparing MB+ELM versus MB-ILM+ELM configurations to quantify the specific contribution of ILM removal to gender accuracy improvements, controlling for all other variables.

2. Analyze the gender distribution of speaker-dependent words in the actual training corpus to empirically validate the claimed training data imbalance that motivates the ILM bias hypothesis.

3. Test the approach on out-of-domain MuST-SHE categories (2 and 3) to assess generalization capability and identify failure modes when speaker-dependent words fall outside the ELM training distribution.