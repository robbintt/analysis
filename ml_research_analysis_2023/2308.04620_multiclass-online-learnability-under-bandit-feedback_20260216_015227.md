---
ver: rpa2
title: Multiclass Online Learnability under Bandit Feedback
arxiv_id: '2308.04620'
source_url: https://arxiv.org/abs/2308.04620
tags:
- bldim
- online
- bandit
- ldim
- feedback
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper studies online multiclass classification under bandit
  feedback. The main contributions are: 1) Showing that the finiteness of the Bandit
  Littlestone dimension (BLdim) is necessary and sufficient for bandit online learnability
  even when the label space is unbounded.'
---

# Multiclass Online Learnability under Bandit Feedback

## Quick Facts
- **arXiv ID**: 2308.04620
- **Source URL**: https://arxiv.org/abs/2308.04620
- **Reference count**: 2
- **Primary result**: Finiteness of Bandit Littlestone dimension is necessary and sufficient for bandit online learnability even with unbounded label spaces

## Executive Summary
This paper establishes a fundamental characterization of online multiclass classification under bandit feedback. The authors prove that the finiteness of the Bandit Littlestone dimension (BLdim) is both necessary and sufficient for bandit online learnability, even when the label space is unbounded. They propose an agnostic online learning algorithm using EXP4 with carefully constructed experts that achieves a regret bound of O(√(Ldim(H)·BLdim(H)·T·ln(BLdim(H)·T))), removing the dependence on label space size |Y| that plagued previous work. The paper also demonstrates a strict separation between online learnability under full-information and bandit feedback when the label space is unbounded.

## Method Summary
The algorithm uses EXP4 with a carefully constructed expert set where each expert runs an independent copy of the Standard Optimal Algorithm (SOA). Experts are parameterized by subsets L ∈ LT and functions φ ∈ ΦL, where LT contains all subsets of [T] of size at most Ldim(H). The key insight is that predictions are always contained in H(x), bounding the support size for EXP4 by BLdim(H) + 1. This construction allows the regret bound to avoid dependence on |Y|. The learning rate is set as η = √(ln|E| / (T(BLdim(H)+1))), and the algorithm proceeds in rounds with EXP4 selecting experts based on their performance while SOA within each expert makes predictions and updates its state.

## Key Results
- BLdim(H) < ∞ is necessary and sufficient for bandit online learnability even when |Y| is unbounded
- Proposed algorithm achieves expected regret at most 4√(Ldim(H)·BLdim(H)·T·ln(BLdim(H)·T))
- Demonstrated separation between full-information and bandit learnability for unbounded label spaces
- Improved regret bound removes dependence on |Y| compared to previous O(√(T·|Y|·Ldim(H))) bounds

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The finiteness of BLdim characterizes bandit online learnability even with unbounded label spaces
- Mechanism: By constructing experts that track SOA and using EXP4, the learner achieves regret bounds depending only on BLdim and Ldim, not on |Y|
- Core assumption: For any instance x, the projection H(x) has size at most BLdim(H) + 1, and there exists an expert in the constructed set that matches the optimal hypothesis h⋆ over the entire stream
- Evidence anchors: [abstract] states BLdim sufficiency; Lemma 6 shows |H(x)| ≤ BLdim(H) + 1; corpus neighbors focus on related topics but don't directly support this mechanism
- Break condition: If BLdim is infinite, by Lemma 8 the class is not bandit online learnable, breaking sufficiency

### Mechanism 2
- Claim: EXP4 with carefully constructed experts achieves improved regret bound without |Y| dependence
- Mechanism: Experts are parameterized by subsets L ∈ LT and functions φ ∈ ΦL, each running SOA. Predictions are always in H(x), bounding EXP4 support size
- Core assumption: The expert set is sufficiently rich to include one matching the optimal hypothesis h⋆ over the entire stream
- Evidence anchors: [section] proves expert construction and regret bound; [abstract] mentions improved bound; corpus lacks direct evidence about expert construction
- Break condition: If the expert set isn't sufficiently rich, no expert matches h⋆, invalidating the regret bound

### Mechanism 3
- Claim: Separation between full-information and bandit learnability occurs when |Y| is unbounded
- Mechanism: Ldim characterizes full-information learnability, but BLdim is needed for bandit learnability. When |Y| is unbounded, Ldim can be finite while BLdim is infinite
- Core assumption: There exists H where Ldim(H) = 1 but BLdim(H) = ∞ (e.g., constant functions with Y = N)
- Evidence anchors: [abstract] states separation claim; [section] constructs H = {ha : a ∈ N} showing Ldim(H) = 1, BLdim(H) = ∞; corpus doesn't discuss this separation
- Break condition: If the constructed example is invalid or dimensions don't behave as claimed, separation claim fails

## Foundational Learning

- **Concept**: Bandit online learning model
  - Why needed here: The paper studies online multiclass classification under bandit feedback, where the learner only receives a loss indicator {ŷt ≠ yt} rather than the true label yt
  - Quick check question: In the bandit feedback model, does the learner observe the true label yt after making a prediction ŷt? (Answer: No, only whether the prediction was correct.)

- **Concept**: Littlestone dimension (Ldim) and Bandit Littlestone dimension (BLdim)
  - Why needed here: These combinatorial dimensions characterize online learnability under full-information and bandit feedback, respectively. The paper shows that BLdim is necessary and sufficient for bandit learnability even with unbounded label spaces
  - Quick check question: Which dimension, Ldim or BLdim, is used to characterize bandit online learnability in this paper? (Answer: BLdim.)

- **Concept**: Standard Optimal Algorithm (SOA) and its mistake bound
  - Why needed here: SOA is used as a subroutine in the expert construction. It makes at most Ldim(H) mistakes on any realizable sequence under full-information feedback, which is leveraged to ensure the existence of a good expert
  - Quick check question: What is the maximum number of mistakes SOA makes on a realizable sequence, in terms of Ldim(H)? (Answer: At most Ldim(H) mistakes.)

## Architecture Onboarding

- **Component map**: Construct experts → Run EXP4 with these experts → EXP4 selects predictions based on expert advice → SOA within each expert makes predictions and updates state → Repeat for T rounds
- **Critical path**: The critical path flows from expert construction through EXP4 execution to prediction selection, with SOA providing the underlying predictions within each expert
- **Design tradeoffs**: The main tradeoff is between expert set richness (affecting regret via ln|E|) and computational complexity. Larger expert sets provide better coverage but increase computational cost and the ln|E| term in the regret bound
- **Failure signatures**: Infinite BLdim prevents sublinear regret; expert construction failure to include an expert matching h⋆ invalidates the regret bound; support size not bounded by BLdim(H) + 1 makes EXP4 bound depend on |Y|
- **First 3 experiments**:
  1. Verify that for a simple hypothesis class with finite BLdim (e.g., binary classification), the algorithm achieves the claimed regret bound
  2. Test the algorithm on a hypothesis class where Ldim(H) = 1 but BLdim(H) = ∞ (e.g., constant functions with Y = N) to confirm it doesn't achieve sublinear regret
  3. Check expert construction by verifying that for any instance x, predictions made by all experts are contained in H(x), ensuring support size is bounded

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the lower bound on expected regret in the agnostic setting be improved from Ω(√T |Y|Ldim(H)) to Ω(√Ldim(H)BLdim(H)T)?
- Basis in paper: [explicit] The paper states "we leave it as an interesting open question on whether this lowerbound can be improved to Ω(√Ldim(H)BLdim(H)T)."
- Why unresolved: Authors provide only Ω(√T |Y|Ldim(H)) lower bound and conjecture it can be improved to match their upper bound of O(√Ldim(H)BLdim(H)T)
- What evidence would resolve it: Proof that there exists a hypothesis class where expected regret is at least Ω(√Ldim(H)BLdim(H)T) would resolve affirmatively

### Open Question 2
- Question: Is the finiteness of the Bandit Littlestone dimension necessary and sufficient for bandit online learnability in the realizable setting when the label space is unbounded?
- Basis in paper: [explicit] Paper shows BLdim finiteness is necessary and sufficient for agnostic setting, but only mentions realizable setting in passing
- Why unresolved: Paper focuses on agnostic setting and doesn't explicitly address realizable setting with unbounded label space
- What evidence would resolve it: Proof that BLdim finiteness is both necessary and sufficient for bandit online learnability in realizable setting with unbounded label space would resolve affirmatively

### Open Question 3
- Question: Can the upper bound on expected regret in the agnostic setting be improved from O(√Ldim(H)BLdim(H)T ln(BLdim(H)T)) to O(√Ldim(H)BLdim(H)T)?
- Basis in paper: [inferred] Paper achieves O(√Ldim(H)BLdim(H)T ln(BLdim(H)T)) and mentions conjectured lower bound
- Why unresolved: Current upper bound has additional logarithmic factor ln(BLdim(H)T) compared to conjectured lower bound
- What evidence would resolve it: Proof that there exists an agnostic online learner under bandit feedback with expected regret at most O(√Ldim(H)BLdim(H)T) would resolve affirmatively

## Limitations

- Computational complexity may be prohibitive as expert set construction could be exponentially large in Ldim(H)
- The algorithm provides theoretical guarantees but lacks empirical validation on real datasets
- The paper focuses on the agnostic setting, leaving open questions about the realizable setting with unbounded label spaces

## Confidence

- **High confidence**: The theoretical characterization of BLdim as necessary and sufficient for bandit learnability; the regret bound structure and its dependence on BLdim rather than |Y|
- **Medium confidence**: The computational feasibility of the algorithm for moderate Ldim(H); the tightness of the separation between full-information and bandit learnability
- **Low confidence**: The practical performance of the algorithm on real datasets, as no empirical validation is provided

## Next Checks

1. **Verify BLdim characterization**: Construct a hypothesis class with known BLdim and test whether the algorithm achieves sublinear regret when BLdim is finite and fails to do so when BLdim is infinite

2. **Computational complexity analysis**: Implement the expert construction for small Ldim(H) values (e.g., Ldim(H) = 2 or 3) and measure the actual computational overhead to quantify the practical limitations

3. **Support size verification**: For the constructed experts, verify empirically that for any instance x, the predictions made by all experts are contained in H(x), ensuring the EXP4 regret bound doesn't depend on |Y|