---
ver: rpa2
title: Operationalising Representation in Natural Language Processing
arxiv_id: '2306.08193'
source_url: https://arxiv.org/abs/2306.08193
tags:
- information
- about
- system
- property
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper proposes an operational framework for evaluating whether\
  \ components of neural NLP models represent properties of inputs. Drawing on philosophical\
  \ ideas from cognitive science, it introduces three criteria\u2014Information, Use,\
  \ and Misrepresentation\u2014and operationalizes them using probing classifiers."
---

# Operationalising Representation in Natural Language Processing

## Quick Facts
- arXiv ID: 2306.08193
- Source URL: https://arxiv.org/abs/2306.08193
- Reference count: 11
- This paper operationalizes philosophical criteria for representation using probing classifiers in NLP

## Executive Summary
This paper bridges philosophy of mind and NLP interpretability by proposing a framework to evaluate whether neural model components represent input properties. Drawing on philosophical work from cognitive science, it operationalizes three criteria - Information, Use, and Misrepresentation - using probing classifiers and interventions on model activations. The framework provides a systematic way to test representational claims about NLP models, connecting theoretical debates about representation to practical interpretability research.

## Method Summary
The method involves training probing classifiers on intermediate model activations to predict target properties, then applying interventions to test whether those properties are represented according to three criteria. For Information, probe cross-entropy loss bounds mutual information. For Use, ablate interventions reduce information about the property while preserving other information. For Misrepresentation, correct interventions modify downstream interpretations toward true label distributions. The framework evaluates representational claims by measuring how interventions affect system performance.

## Key Results
- Probing classifiers can operationalize the Information criterion by lower bounding mutual information through cross-entropy loss
- Abate interventions can test the Use criterion by degrading performance when information about a property is reduced
- Correct interventions can test Misrepresentation by improving performance when probe predictions are moved toward true labels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Probing classifiers can operationalize the Information criterion by lower bounding mutual information between model activations and linguistic properties.
- Mechanism: The cross-entropy loss of a probe upper bounds the conditional entropy of the property given the activation. Since mutual information is entropy minus conditional entropy, a successful probe (loss below threshold) guarantees mutual information above a threshold.
- Core assumption: Probe architecture is sufficiently expressive to capture all ways the downstream system could decode information about the property.

### Mechanism 2
- Claim: The ablate intervention operationalizes the Use criterion by reducing information about a property relative to all plausible downstream decoders.
- Mechanism: An intervention is applied that reduces the information an activation bears about a property (measured by probe uncertainty) while preserving information about other properties (measured by Kullback-Leibler divergence). If system performance degrades, the information was used.
- Core assumption: The set of plausible proxies GZ,SDec for the downstream system is sufficiently comprehensive to capture all ways the system could decode the property.

### Mechanism 3
- Claim: The correct intervention operationalizes the Misrepresentation criterion by modifying downstream interpretations toward the true label distribution.
- Mechanism: An intervention moves probe predictions for the property toward the true label distribution while preserving predictions for other properties. If system performance improves, the original activation misrepresented the property.
- Core assumption: The true label distribution pZ(s) is known and can be used as the target for the intervention.

## Foundational Learning

- Concept: Mutual information as a measure of statistical dependence between activations and properties
  - Why needed here: Forms the theoretical basis for operationalizing the Information criterion
  - Quick check question: If a probe achieves zero cross-entropy loss, what does this imply about the mutual information between activations and the property?

- Concept: Causal interventions on model activations and their effects on downstream behavior
  - Why needed here: Central to operationalizing both Use and Misrepresentation criteria
  - Quick check question: What distinguishes an intervention that satisfies the ablate condition from one that doesn't?

- Concept: Probe selection and its role in identifying plausible decoders for downstream information processing
  - Why needed here: Critical for defining the set GZ,SDec and ensuring interventions are meaningful
  - Quick check question: Why might a highly expressive probe give misleading results about whether a property is represented?

## Architecture Onboarding

- Component map: Input s → Upstream system SEnc → Intermediate activation h(s) → Downstream system SDec → Output S(s)
- Critical path: Probe training → Intervention design → Performance evaluation → Representational claim assessment
- Design tradeoffs:
  - Expressiveness vs. generalization in probe selection
  - Granularity of intervention vs. computational cost
  - Control condition strictness vs. practical feasibility
- Failure signatures:
  - False negatives: Intervention doesn't degrade performance but information was actually used
  - False positives: Intervention degrades performance but not due to the targeted property
  - Ambiguity: Intervention affects multiple properties making attribution difficult
- First 3 experiments:
  1. Train probes for part-of-speech tags on BERT activations and verify mutual information is captured
  2. Apply ablate intervention for number agreement and measure degradation in subject-verb agreement task
  3. Apply correct intervention for gender representation and measure change in biased predictions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific constraints define membership in GZ,SDec (the set of plausible proxies for how the downstream system decodes information)?
- Basis in paper: The paper acknowledges this as an open problem, noting that membership will be refined by both theoretical and empirical, model-specific insights.
- Why unresolved: The paper provides general categories of constraints (architectural, hyperparameter, complexity) but does not specify how to operationalize these for different downstream systems.
- What evidence would resolve it: Empirical studies demonstrating how different probe selection techniques (e.g., controlling for model complexity, regularization) affect the identification of information pathways in various model architectures.

### Open Question 2
- Question: How can we effectively approximate the control condition for properties we haven't explicitly probed for?
- Basis in paper: The paper acknowledges that controlling for all possible properties is impossible and suggests approximating through regularizing interventions to minimize distance from original activations.
- Why unresolved: The paper doesn't provide concrete methods for determining which properties to control for or how to quantify the degree of acceptable violation of the control condition.
- What evidence would resolve it: Experimental results comparing intervention outcomes with different sets of controlled properties and varying degrees of regularization, showing their impact on representational claims.

### Open Question 3
- Question: How do gradient-based intervention methods compare to input-based and projection-based methods in satisfying the ablate, modify, and control conditions?
- Basis in paper: The paper discusses these different intervention types and their theoretical properties regarding the conditions, but doesn't provide direct empirical comparisons.
- Why unresolved: While the paper outlines the theoretical properties of each method, it doesn't empirically test which methods best approximate the ideal conditions in practice.
- What evidence would resolve it: Comparative studies applying multiple intervention methods to the same representational claims, measuring their effectiveness in satisfying the operationalized criteria.

## Limitations
- The framework relies heavily on probe selection, which can lead to false negatives if GZ,SDec is incomplete
- Misrepresentation criterion requires known true label distributions, limiting applicability
- Interventions may affect multiple correlated properties simultaneously, making attribution difficult

## Confidence

- **High**: The theoretical connection between probe cross-entropy loss and mutual information (Information criterion)
- **Medium**: The operationalization of the Use criterion through ablate interventions, as this depends heavily on probe selection and intervention design
- **Low**: The Misrepresentation criterion, which requires known true label distributions and may be difficult to operationalize in practice

## Next Checks

1. **Probe Expressiveness Validation**: Systematically test how probe architecture choice affects the Information criterion results across different properties and model layers to establish bounds on probe selection.

2. **Intervention Specificity Test**: Design controlled experiments where interventions are applied to correlated properties to measure cross-contamination effects and validate the ablate condition.

3. **Ground Truth Dependency Analysis**: Evaluate the Misrepresentation criterion on synthetic data with known ground truth to determine sensitivity to label noise and distributional assumptions.