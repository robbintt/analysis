---
ver: rpa2
title: Semi-automatic Data Enhancement for Document-Level Relation Extraction with
  Distant Supervision from Large Language Models
arxiv_id: '2311.07314'
source_url: https://arxiv.org/abs/2311.07314
tags:
- relation
- triples
- which
- language
- work
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a framework that integrates a large language
  model (LLM) and a natural language inference (NLI) module to automatically generate
  relation triples and augment document-level relation extraction (DocRE) datasets.
  The LLM generates relation triples as proposals, which are then aligned with predefined
  relation types using the NLI module.
---

# Semi-automatic Data Enhancement for Document-Level Relation Extraction with Large Language Models

## Quick Facts
- **arXiv ID**: 2311.07314
- **Source URL**: https://arxiv.org/abs/2311.07314
- **Reference count**: 14
- **Primary result**: Framework generates 2078 additional triples for Re-DocRED, improving zero-shot GPT performance and model recall

## Executive Summary
This paper introduces a framework that combines a large language model (LLM) with natural language inference (NLI) to automatically augment document-level relation extraction (DocRE) datasets. The approach generates relation triples using GPT-3.5, aligns them with predefined relation types using an NLI module, and filters them based on entity constraints. The method is applied to enhance the Re-DocRED dataset, creating DocGNRE with 2078 additional triples. Experiments demonstrate improved performance in zero-shot DocRE tasks and enhanced recall for previous models on the supplementary test set.

## Method Summary
The framework uses GPT-3.5 to generate relation triples as proposals, constrained by provided entity lists and instructed to generate at least 20 triples per document. These generated triples are then aligned with predefined relation types using a T5-based NLI model that scores entailment between generated relations and hypotheses constructed from predefined types. Triples meeting type constraints and exceeding an entailment score threshold (>0.6) are retained. The method includes human verification for test set quality. For training data augmentation, the framework generates additional triples to supplement existing datasets, providing supervision signals particularly for rare relations.

## Key Results
- Framework generates 2078 additional triples for Re-DocRED dataset
- Improves zero-shot GPT performance on DocRE tasks
- Enhances recall of previous models on the supplementary test set
- DocGNRE provides more complete and accurate test set for DocRE

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: NLI alignment bridges the gap between LLM-generated relations and predefined relation types
- **Mechanism**: GPT generates natural language relation triples that may not match predefined types. The NLI module scores entailment between GPT-generated triples and hypotheses from predefined types, selecting the highest-scoring match
- **Core assumption**: NLI models can accurately measure semantic equivalence between generated and predefined relations
- **Evidence anchors**:
  - [abstract] "To align GPT-generated relations and predefined relation types, we first combine Natural Language Inference (NLI) models (MacCartney, 2009) with GPT"
  - [section 2.2] "We employ a Natural Language Inference (NLI) model, which has demonstrated effectiveness in assessing factual consistency"
- **Break condition**: If NLI scores are too close between multiple types or below threshold (0.6), alignment fails

### Mechanism 2
- **Claim**: Prompt engineering with entity constraints and iterative generation improves LLM output quality
- **Mechanism**: Initial prompt requests "at least 20 triples" using only given entities, followed by iterative prompts to generate more. This balances accuracy and quantity while constraining entity usage
- **Core assumption**: LLMs maintain quality when generating in batches of 20 or fewer triples per prompt
- **Evidence anchors**:
  - [section 2.1] "We set 'at least 20 triples' in the initial prompt... We employ an iterative approach by feeding the previous GPT answers as input while instructing GPT to 'Please keep generating 20 more triples'"
- **Break condition**: If entity constraints are violated frequently or generated triples become repetitive/incorrect

### Mechanism 3
- **Claim**: Distant supervision from LLM-generated triples enhances DocRE model training
- **Mechanism**: GPT+NLI framework generates additional training triples that supplement existing datasets, providing supervision signals for rare relations
- **Core assumption**: LLM-generated triples, even if noisy, provide useful signal for training when filtered through NLI alignment
- **Evidence anchors**:
  - [abstract] "We propose a method integrating a Large Language Model (LLM) and a natural language inference (NLI) module to generate relation triples, thereby augmenting document-level relation datasets"
  - [section 3.2] "We test the SOTA document-level RE model... All experiment settings are the same as Ma et al. (2023) except for training data in the +GPT setting"
- **Break condition**: If generated triples introduce too much noise or bias toward common relations

## Foundational Learning

- **Concept**: Natural Language Inference (NLI) fundamentals
  - **Why needed here**: Core mechanism for aligning LLM outputs with predefined relation types
  - **Quick check question**: How does an NLI model determine if premise entails hypothesis?

- **Concept**: Document-level relation extraction challenges
  - **Why needed here**: Understanding why sentence-level approaches fail at document scale
  - **Quick check question**: What makes DocRE more challenging than sentence-level RE?

- **Concept**: Large language model in-context learning limitations
  - **Why needed here**: Explains why vanilla in-context learning fails for DocRE
  - **Quick check question**: Why can't GPT directly learn 97 fine-grained relation types in zero-shot setting?

## Architecture Onboarding

- **Component map**: GPT (LLM module) → Entity filtering → NLI module → Triple alignment → Dataset augmentation
- **Critical path**: LLM generation → NLI scoring → Triple selection → Human verification (test set only)
- **Design tradeoffs**: Accuracy vs. quantity in LLM generation, noise tolerance vs. strict filtering
- **Failure signatures**: Low NLI scores, entity constraint violations, repetitive generation patterns
- **First 3 experiments**:
  1. Test GPT zero-shot performance on Re-DocRED test set (Table 2)
  2. Evaluate NLI alignment accuracy on sample GPT-generated triples
  3. Train DocRE model on DocRED+GPT-generated triples and measure recall improvement

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How does the proposed framework perform when applied to datasets other than DocRED or Re-DocRED?
- **Basis in paper**: [explicit] The authors mention that their method "holds the potential for broader applications in domain-specific relation type definitions."
- **Why unresolved**: The paper only demonstrates the effectiveness of the framework on the DocRED and Re-DocRED datasets, and does not provide any results or analysis for other datasets.
- **What evidence would resolve it**: Conducting experiments on other document-level relation extraction datasets with different domain-specific relation types would provide evidence of the framework's generalizability.

### Open Question 2
- **Question**: How does the proposed framework handle entity pairs that are not present in the provided entity list?
- **Basis in paper**: [inferred] The paper mentions that the LLM is constrained to utilize only the entities present in the provided list, and a filtering process is implemented to remove undesired triples with incorrect entity pairs.
- **Why unresolved**: The paper does not provide details on how the framework handles entity pairs that are not present in the provided entity list, which could be a potential limitation.
- **What evidence would resolve it**: Experiments that include entity pairs not present in the provided entity list, and an analysis of how the framework handles such cases, would provide insights into this limitation.

### Open Question 3
- **Question**: How does the proposed framework compare to other state-of-the-art document-level relation extraction models in terms of performance and efficiency?
- **Basis in paper**: [explicit] The authors mention that they test the SOTA document-level RE model (Ma et al., 2023) on their DocGNRE dataset and retrain it with their distant training set.
- **Why unresolved**: The paper does not provide a comprehensive comparison of the proposed framework with other state-of-the-art models in terms of performance and efficiency.
- **What evidence would resolve it**: Conducting experiments that compare the proposed framework with other state-of-the-art models on various document-level relation extraction datasets, and analyzing the results in terms of performance and efficiency, would provide a clear comparison.

## Limitations

- NLI alignment quality uncertainty: The alignment mechanism's robustness to semantic variations remains unclear, with the 0.6 threshold appearing arbitrary without ablation studies
- Entity constraint enforcement: Limited analysis of how often entity violations occur and their impact on downstream performance
- Distant supervision noise tolerance: No systematic analysis of how different levels of noise in generated triples affect model training and final performance

## Confidence

- **High confidence**: The framework's basic architecture (LLM generation → NLI alignment → dataset augmentation) is well-defined and the experimental methodology is reproducible
- **Medium confidence**: The claim that the approach improves recall on long-tail relations is supported by experiments, but the magnitude of improvement and its statistical significance could be more rigorously demonstrated
- **Low confidence**: The assertion that the DocGNRE dataset provides "more complete and accurate" test sets lacks comprehensive human evaluation metrics beyond basic verification

## Next Checks

1. Conduct ablation studies varying the NLI threshold (0.5, 0.6, 0.7) to determine optimal alignment quality vs. quantity tradeoff
2. Analyze entity constraint violation rates across different document types and assess their correlation with final model performance degradation
3. Perform controlled experiments comparing model training with clean vs. noisy LLM-generated triples to quantify noise tolerance limits