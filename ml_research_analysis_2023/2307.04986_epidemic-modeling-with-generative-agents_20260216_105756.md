---
ver: rpa2
title: Epidemic Modeling with Generative Agents
arxiv_id: '2307.04986'
source_url: https://arxiv.org/abs/2307.04986
tags:
- agents
- agent
- epidemic
- human
- health
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a generative agent-based model (GABM) to
  improve epidemic modeling by integrating human behavior using large language models.
  In this approach, each agent independently reasons and decides whether to go outside,
  based on personal traits, health symptoms, and information about local case counts.
---

# Epidemic Modeling with Generative Agents

## Quick Facts
- arXiv ID: 2307.04986
- Source URL: https://arxiv.org/abs/2307.04986
- Reference count: 26
- Key outcome: Generative agents reduce mobility and flatten epidemic curves when given health information

## Executive Summary
This paper introduces a generative agent-based model (GABM) that integrates human behavior into epidemic modeling using large language models. Each agent independently reasons about whether to go outside based on personal health symptoms, demographic traits, and local case counts. The model was tested under three conditions: no health feedback, self-health feedback only, and both self-health and societal health feedback. Results show that agents with health information reduce mobility, leading to flatter epidemic curves and lower peak infections, demonstrating that generative AI can endogenously capture complex behavioral responses to epidemics.

## Method Summary
The model combines agent-based simulation with large language model reasoning. Agents possess realistic personas including demographic information and Big Five personality traits. Each day, agents query ChatGPT to decide whether to stay home based on their health status and information about local case counts. The simulation tracks disease transmission through agent interactions, with agents transitioning between susceptible, infectious, and recovered states. Three experimental conditions test the impact of health information on epidemic dynamics: no feedback, self-health feedback only, and full feedback with both personal and societal health information.

## Key Results
- Agents with health information reduce mobility, leading to flatter epidemic curves and lower peak infections
- Full feedback condition reproduces realistic epidemic waves and endemic states
- Regression analyses show personality traits, age, and gender influence agents' decisions to stay home

## Why This Works (Mechanism)

### Mechanism 1
Generative agents can autonomously decide whether to go outside based on personal health and societal health information. Each agent is prompted with personalized information including symptoms and daily case counts, then queries an LLM to decide whether to stay home. The LLM processes this contextual information and outputs a binary decision plus reasoning. Core assumption: LLMs can accurately simulate human decision-making given relevant personal and societal context.

### Mechanism 2
Agents' collective behavior can flatten epidemic curves by self-isolating in response to case increases. When agents receive information about rising local cases, they are more likely to stay home, reducing contact rates and slowing disease transmission. Core assumption: Agents will accurately interpret and respond to case information in ways that mirror real human behavior.

### Mechanism 3
Agent decisions are influenced by personality traits, age, and gender, creating heterogeneous responses to the epidemic. Agents are assigned personality traits and demographic information that are included in their prompts, influencing their risk assessment and decision-making. Core assumption: Personality traits and demographics significantly impact how individuals assess and respond to epidemic risks.

## Foundational Learning

- **Agent-based modeling (ABM)**: Used to simulate disease spread through agent interactions. Quick check: How do agents in this model interact to spread disease?
- **Large language models (LLMs)**: Provide agents with reasoning and decision-making capabilities. Quick check: What specific information is provided to the LLM to guide agent decisions?
- **SIR model fundamentals**: Understanding disease progression states (Susceptible, Infectious, Recovered) is crucial for interpreting results. Quick check: What are the three disease states in this model and how do agents transition between them?

## Architecture Onboarding

- **Component map**: World class -> Citizen class -> LLM API integration -> Data collection module
- **Critical path**: Agent prompt generation → LLM decision → Location update → Interaction processing → Disease transmission → Health state update
- **Design tradeoffs**: LLM-based reasoning provides realistic behavior but is computationally expensive vs. rule-based approaches that are faster but less nuanced
- **Failure signatures**: Non-binary LLM responses, API timeouts, unrealistic agent behavior patterns, failure to flatten curves
- **First 3 experiments**: 1) Base run with no health information to verify ABM baseline behavior, 2) Self-health feedback only to test individual quarantine behavior, 3) Full feedback with both health and societal information to test collective behavioral response

## Open Questions the Paper Calls Out

### Open Question 1
How does the computational cost of generative agent-based models scale with population size and simulation duration? The paper reports that running a 1,000-agent model for 90+ hours costs about $20, but does not explore how costs change with different population sizes or simulation lengths.

### Open Question 2
What is the impact of agent personality traits on epidemic outcomes beyond individual-level decision-making? While the paper shows personality influences individual decisions, it does not examine how personality distributions in the population shape epidemic curves or total cases.

### Open Question 3
How robust are the epidemic wave patterns to variations in the LLM's reasoning quality or prompt design? The model relies on LLM-generated reasoning, but the paper does not test sensitivity to prompt variations, LLM model changes, or reasoning quality degradation.

## Limitations
- The LLM's ability to accurately simulate human decision-making under varying conditions remains uncertain
- The model assumes perfect information flow about case counts, which may not reflect real-world information access
- The computational cost of running LLM queries limits scalability to larger populations

## Confidence
- **High confidence**: Agents reduce mobility when given health information, leading to flatter epidemic curves
- **Medium confidence**: Personality traits and demographics measurably influence agent decisions
- **Medium confidence**: The model can reproduce realistic epidemic wave patterns under full feedback conditions
- **Low confidence**: The specific LLM prompt structure and parameter values used in the study

## Next Checks
1. Validate the LLM's decision-making consistency by running multiple simulations with identical initial conditions and measuring response variance
2. Test the model's sensitivity to information quality by introducing misinformation or delayed case count reporting to assess robustness
3. Compare LLM-based agent behavior with rule-based behavioral models using the same epidemic parameters to quantify the added value of generative reasoning