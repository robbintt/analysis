---
ver: rpa2
title: Predicting Three Types of Freezing of Gait Events Using Deep Learning Models
arxiv_id: '2310.06322'
source_url: https://arxiv.org/abs/2310.06322
tags:
- data
- feature
- gait
- freezing
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper develops deep learning models using transformer encoder\
  \ architecture plus Bidirectional LSTM layers to predict three types of freezing\
  \ of gait (FOG) events in Parkinson\u2019s Disease patients. Models were trained\
  \ on time-series acceleration data from lower back sensors, with feature sets varying\
  \ from raw acceleration signals to engineered features like jerk and metadata."
---

# Predicting Three Types of Freezing of Gait Events Using Deep Learning Models

## Quick Facts
- arXiv ID: 2310.06322
- Source URL: https://arxiv.org/abs/2310.06322
- Reference count: 21
- Key outcome: Deep learning models using transformer encoder + Bidirectional LSTM layers predict three types of freezing of gait (FOG) events in Parkinson’s Disease patients, achieving a MAP score of 0.427 on testing data, ranking in the top 5 of a Kaggle competition.

## Executive Summary
This paper develops deep learning models to predict three types of freezing of gait (FOG) events—start hesitation, turn, and walking—in Parkinson’s Disease patients using time-series acceleration data from lower back sensors. The models combine transformer encoder architecture with Bidirectional LSTM layers and explore seven different feature sets, including raw acceleration, jerk, time features, and metadata. The best-performing model, which includes acceleration, jerk, and time features, achieved a MAP score of 0.427 on testing data. The work highlights the importance of jerk features for capturing sudden changes in movement that precede FOG events and demonstrates that semi-pseudo labeling improves model robustness. However, overfitting remains a significant challenge due to the model’s complexity.

## Method Summary
The authors developed deep learning models using a transformer encoder architecture plus Bidirectional LSTM layers to predict three types of FOG events. Models were trained on time-series 3D acceleration data from lower back sensors, with feature sets varying from raw acceleration signals to engineered features like jerk and metadata. The best model used acceleration, jerk, and time features, achieving a MAP score of 0.427 on testing data. Semi-pseudo labeling on Notype data was applied to improve model robustness. The approach ranked in the top 5 of a Kaggle competition, though overfitting due to model complexity was identified as a limitation.

## Key Results
- The best-performing model achieved a MAP score of 0.427 on testing data, ranking in the top 5 of a Kaggle competition.
- Models using jerk features outperformed those without jerk by an average of 7.5% in testing MAP scores.
- Semi-pseudo labeling on Notype data improved model robustness and increased correlation between training and test MAP scores.
- Subject clustering features degraded performance, suggesting patient-specific information may be excessive.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The transformer encoder + Bidirectional LSTM layers capture both temporal dependencies and bidirectional context, improving FOG type classification.
- Mechanism: The transformer encoder uses self-attention to weigh the importance of different time steps in the acceleration signal, while the Bidirectional LSTM layers capture context from both past and future time steps. This combination allows the model to learn complex patterns in the gait data that precede different types of FOG events.
- Core assumption: FOG events have distinguishable temporal patterns in acceleration data that can be captured by sequence models.
- Evidence anchors:
  - [abstract] "develop various deep learning models using the transformer encoder architecture plus Bidirectional LSTM layers and different feature sets to predict the three different types of freezing of gait events"
  - [section] "The TransBiLSTM model is inspired by the first-place winner solution of the Parkinson's Disease Freezing of Gait Prediction competition, which uses 5 transformer encoder layers, 3 Bidirectional LSTM layers, and one final Dense layer"
- Break condition: If FOG events don't have consistent temporal patterns or if the sensor data quality is too low to capture these patterns, the model would fail to learn meaningful representations.

### Mechanism 2
- Claim: Including jerk features (rate of change of acceleration) improves model performance by capturing sudden changes in movement that precede FOG events.
- Mechanism: Jerk is calculated as the derivative of acceleration, representing rapid changes in motion. FOG events involve sudden muscle contractions that manifest as abrupt changes in acceleration patterns. By including jerk features, the model can better identify these sudden changes that are characteristic of FOG events.
- Core assumption: FOG events are preceded by sudden changes in acceleration that are captured by jerk calculations.
- Evidence anchors:
  - [abstract] "We develop various deep learning models using the transformer encoder architecture plus Bidirectional LSTM layers and different feature sets to predict the three different types of freezing of gait events"
  - [section] "On average, models that use jerk perform 7.5% better in testing MAP scores than models that do not use jerk as features"
- Break condition: If jerk features are noisy or if the sampling rate of the accelerometer is too low to accurately capture acceleration derivatives, the benefit of jerk features would diminish.

### Mechanism 3
- Claim: Semi-pseudo labeling on Notype data improves model generalization by providing additional training examples with inferred labels.
- Mechanism: The semi-pseudo labeling approach uses a high-performing preliminary model to predict FOG types on Notype data (which lacks FOG type labels). These predictions are used to create additional training examples, expanding the training dataset and helping the model learn from a more diverse set of examples.
- Core assumption: The preliminary model can make sufficiently accurate predictions on Notype data to serve as pseudo-labels for training.
- Evidence anchors:
  - [abstract] "we also recognize overfitting in training data that could be potentially improved through pseudo labelling on additional data and model architecture simplification"
  - [section] "Retraining Defog models with semi pseudo labelled data significantly increases the correlation between MAP scores obtained in training and testing MAP scores"
- Break condition: If the preliminary model makes many incorrect predictions on Notype data, the pseudo-labels would introduce noise and potentially degrade model performance.

## Foundational Learning

- Concept: Time-series analysis and feature engineering
  - Why needed here: The FOG prediction task involves analyzing sequential acceleration data and extracting meaningful features (like jerk, magnitude) that capture the dynamics of gait patterns.
  - Quick check question: How would you calculate jerk from acceleration data in a time-series context?

- Concept: Deep learning for sequence modeling
  - Why needed here: The transformer encoder and Bidirectional LSTM layers are used to learn temporal dependencies in the gait data, which is essential for predicting FOG events.
  - Quick check question: What is the difference between a standard LSTM and a Bidirectional LSTM, and why might bidirectionality be useful for FOG prediction?

- Concept: Overfitting and regularization in machine learning
  - Why needed here: The paper identifies overfitting as a significant issue, and understanding techniques to mitigate overfitting (like pseudo-labeling, model simplification) is crucial for improving model performance.
  - Quick check question: What are three strategies to reduce overfitting in a deep learning model?

## Architecture Onboarding

- Component map:
  - Input layer: Time-series acceleration data (vertical, mediolateral, anteroposterior)
  - Feature engineering layer: Calculation of jerk, acceleration magnitude, time fractions
  - Transformer encoder layers: 5 layers with multi-head attention (6 heads, size 320)
  - Bidirectional LSTM layers: 3 layers producing 320-dimensional outputs
  - Dense layer: Final classification layer outputting probabilities for three FOG types
  - Training pipeline: Cross-validation, MAP score monitoring, semi-pseudo labeling

- Critical path: Acceleration data → Feature engineering → Transformer encoder → Bidirectional LSTM → Dense layer → FOG type prediction

- Design tradeoffs:
  - Complexity vs. overfitting: The model has over 20 million parameters, which provides high capacity but increases overfitting risk
  - Feature selection: Including jerk features improves performance but adds complexity
  - Semi-pseudo labeling: Expands training data but introduces potential label noise

- Failure signatures:
  - Large gap between training and validation MAP scores indicates overfitting
  - Low correlation between validation and test MAP scores suggests poor generalization
  - Inclusion of subject clustering features actually decreases performance, indicating that patient-specific information may be counterproductive

- First 3 experiments:
  1. Compare model performance with and without jerk features to quantify their impact
  2. Test different pseudo-labeling thresholds (e.g., only use predictions with confidence above 0.8) to optimize semi-pseudo labeling
  3. Simplify the model architecture by reducing the number of transformer encoder layers to assess the impact on overfitting and generalization

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of model architecture simplification on overfitting and generalization performance in FOG prediction?
- Basis in paper: [explicit] The authors note that model overfitting may be due to overly complicated neural networks with 20-21 million parameters, and suggest simplifying the model architecture as a future improvement.
- Why unresolved: The paper does not test or compare simplified architectures, so the relationship between model complexity and performance remains unclear.
- What evidence would resolve it: Comparative experiments showing performance changes when reducing model parameters or layers.

### Open Question 2
- Question: How effective would pseudo-labelling be if applied to a larger, more diverse dataset?
- Basis in paper: [explicit] The authors found that semi-pseudo labelling with Notype data improved model robustness and correlation between training and test scores, but note that more data could potentially alleviate overfitting further.
- Why unresolved: Only one round of pseudo-labelling was performed, and the diversity of the additional data was limited.
- What evidence would resolve it: Experiments with multiple rounds of pseudo-labelling on varied datasets and their effect on model performance and overfitting.

### Open Question 3
- Question: Does subject clustering information provide meaningful predictive value in FOG detection models?
- Basis in paper: [explicit] Feature Set G, which included subject clustering, performed worse than other feature sets, suggesting that subject-specific information may be excessive or redundant.
- Why unresolved: The authors do not explore why clustering information degrades performance or whether it could be useful in a different model context.
- What evidence would resolve it: Controlled experiments isolating the effect of subject clustering features on model performance.

## Limitations
- The model architecture is overly complex (20-21 million parameters), leading to significant overfitting between training and validation MAP scores.
- The semi-pseudo labeling approach introduces potential label noise, as pseudo-labels are based on predictions from a preliminary model.
- The Defog dataset is small (91 files), limiting the generalizability of the findings to broader patient populations.

## Confidence
- **High Confidence**: The core methodology of using transformer encoders plus Bidirectional LSTM layers for FOG prediction is well-established and the paper's ranking in the top 5 of a Kaggle competition provides external validation.
- **Medium Confidence**: The effectiveness of jerk features is supported by quantitative results (7.5% improvement), but the mechanism could benefit from more detailed analysis of which specific patterns in jerk data are most predictive.
- **Medium Confidence**: The semi-pseudo labeling approach shows promise in improving robustness, but the lack of detail on implementation and potential label noise introduces uncertainty about its reliability.

## Next Checks
1. Conduct ablation studies to isolate the contribution of each feature set (A-G) and verify that jerk features consistently improve performance across different model configurations and data subsets.

2. Implement cross-dataset validation by testing the trained model on the Tdcsfog dataset to assess generalization beyond the Defog dataset and identify any domain shift issues.

3. Perform statistical analysis on the semi-pseudo labeled data to quantify the accuracy of pseudo-labels and evaluate the impact of label noise on final model performance.