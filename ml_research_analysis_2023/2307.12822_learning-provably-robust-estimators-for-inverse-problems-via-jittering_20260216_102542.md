---
ver: rpa2
title: Learning Provably Robust Estimators for Inverse Problems via Jittering
arxiv_id: '2307.12822'
source_url: https://arxiv.org/abs/2307.12822
tags:
- jittering
- robust
- training
- estimator
- noise
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies whether jittering, a simple regularization technique
  that adds isotropic Gaussian noise during training, can be used to train neural
  networks for worst-case robustness in inverse problems. The authors first provide
  theoretical results for linear denoising of signals lying in a subspace.
---

# Learning Provably Robust Estimators for Inverse Problems via Jittering

## Quick Facts
- arXiv ID: 2307.12822
- Source URL: https://arxiv.org/abs/2307.12822
- Authors: 
- Reference count: 40
- Key outcome: This paper studies whether jittering, a simple regularization technique that adds isotropic Gaussian noise during training, can be used to train neural networks for worst-case robustness in inverse problems.

## Executive Summary
This paper investigates the use of jittering—adding isotropic Gaussian noise during training—as a method to improve worst-case robustness of neural network estimators for inverse problems. The authors first provide theoretical results for linear denoising in a subspace model, characterizing the optimal worst-case robust estimator and showing that jittering yields optimal robust denoisers. They then conduct experiments training deep neural networks (U-nets) for natural image denoising, deconvolution, and accelerated MRI reconstruction, comparing standard training, adversarial training, and training with jittering. The results demonstrate that jittering significantly enhances worst-case robustness, especially for denoising, and is computationally cheaper than adversarial training.

## Method Summary
The method involves training neural network estimators (U-nets) for inverse problems using jittering, which adds isotropic Gaussian noise to measurements during training. The jittering noise level is tuned as a function of the desired robustness level. The trained estimators are then evaluated on their worst-case robustness under ℓ2 perturbations, compared to standard and adversarially trained models. The experiments cover denoising, deconvolution, and MRI reconstruction tasks using datasets like ImageNet and fastMRI.

## Key Results
- Jittering with an optimally chosen noise level minimizes the worst-case robust risk for linear denoising in the subspace model.
- Jittering is computationally cheaper than adversarial training for learning robust estimators.
- Training on real data with slight noise enhances robustness to adversarial perturbations.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Jittering with an optimally chosen noise level minimizes the worst-case robust risk for linear denoising in the subspace model.
- Mechanism: During training, Gaussian noise is injected into the measurements, which biases the learned estimator toward robustness against adversarial perturbations of a given energy level.
- Core assumption: The signal lies in a low-dimensional subspace and the noise is Gaussian with known variance.
- Evidence anchors:
  - [abstract] "we characterize the optimal ℓ2-worst-case robust estimator for linear denoising and show that jittering yields optimal robust denoisers."
  - [section] "choosing the variance of the jittering noise level accordingly as a function of the desired robustness level ϵ yields an optimal worst-case robust estimator"
  - [corpus] Weak – the corpus neighbors do not contain direct theoretical claims about jittering optimality in linear denoising.
- Break condition: If the signal does not lie in a subspace or noise is not Gaussian, the optimal noise level formula no longer holds.

### Mechanism 2
- Claim: Jittering is computationally cheaper than adversarial training for learning robust estimators.
- Mechanism: Jittering only requires sampling Gaussian noise and adding it to training data, whereas adversarial training requires solving an inner maximization problem (e.g., via projected gradient ascent) for each update.
- Core assumption: The training pipeline can incorporate noise injection without breaking backpropagation or convergence.
- Evidence anchors:
  - [abstract] "jittering can be an effective method for learning robust neural network estimators for inverse problems... since jittering can also be implemented easily and needs far less computational resources than adversarial training."
  - [section] "Performing adversarial training is by a factor of the projected gradient ascent steps more expensive than standard training."
  - [corpus] Weak – neighbors discuss robustness but not computational comparisons between jittering and adversarial training.
- Break condition: If noise sampling becomes a bottleneck due to batch size or if the inner optimization in adversarial training is heavily optimized.

### Mechanism 3
- Claim: Training on real data with slight noise enhances robustness to adversarial perturbations.
- Mechanism: Real data often contains inherent measurement noise; this implicitly acts as jittering, biasing the learned estimator toward robustness.
- Core assumption: The real-world noise distribution is close to isotropic Gaussian and within the perturbation regime studied.
- Evidence anchors:
  - [abstract] "Moreover, our results imply that training on real data which often contains slight noise is somewhat robustness enhancing."
  - [section] "This indicates that training on real data which often contains slight measurements noise is robustness enhancing."
  - [corpus] Weak – no direct evidence in neighbors about real-world noise enhancing robustness; inference based on experimental results.
- Break condition: If real-world noise is non-Gaussian or structured (e.g., signal-dependent), the implicit robustness enhancement may be reduced or reversed.

## Foundational Learning

- Concept: Subspace signal model
  - Why needed here: The theoretical results rely on the signal being generated from a Gaussian distribution within a known subspace; this structure enables closed-form optimal estimators.
  - Quick check question: What is the mathematical form of the signal generation process in the subspace model?
- Concept: Robust risk and worst-case perturbations
  - Why needed here: The paper defines robustness in terms of the expected worst-case error over an ℓ2 ball; understanding this is key to interpreting the theory and experiments.
  - Quick check question: How is the robust risk formally defined and how does it differ from standard MSE?
- Concept: Jittering vs. adversarial training
  - Why needed here: Both methods aim to improve robustness but differ in computational cost and mechanism; knowing the distinction is crucial for implementation decisions.
  - Quick check question: What is the main computational difference between jittering and adversarial training during training?

## Architecture Onboarding

- Component map: Signal x -> Forward model A -> Measurement y -> Noise z -> Estimator f_θ -> Reconstruction
- Critical path:
  1. Sample clean signal x from subspace.
  2. Generate measurement y = Ax + z.
  3. During training, optionally add jittering noise w to y.
  4. Pass through f_θ to get reconstruction.
  5. Compute loss (standard, robust, or jittering).
  6. Backpropagate and update θ.
- Design tradeoffs:
  - Jittering noise level vs. robustness: too small → insufficient robustness; too large → reduced accuracy.
  - Network capacity vs. overfitting: high-capacity U-Net may fit noise if not regularized.
  - Training time vs. robustness quality: adversarial training is more expensive but may yield better worst-case performance for some tasks.
- Failure signatures:
  - If jittering noise level is poorly tuned, robust risk may plateau above adversarial training’s performance.
  - For ill-posed inverse problems (e.g., deconvolution), jittering may under-perform adversarial training.
  - If perturbation level ϵ exceeds signal energy, estimator collapses to zero (theoretically and empirically).
- First 3 experiments:
  1. Train a U-Net on synthetic denoising data (A=I) with jittering at several σ_w levels; evaluate robust risk vs. adversarial training.
  2. Repeat (1) for deconvolution with a known Gaussian kernel; compare jittering vs. adversarial robustness.
  3. Tune jittering noise level on a validation set for each task and measure GPU time vs. robust risk to confirm computational advantage.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does jittering generalize to other noise distributions beyond Gaussian for robust training in inverse problems?
- Basis in paper: [explicit] The paper states jittering adds isotropic Gaussian noise during training and shows effectiveness for denoising and some inverse problems, but does not explore other noise distributions.
- Why unresolved: The paper focuses on Gaussian jittering and does not investigate alternative noise models or their impact on robustness.
- What evidence would resolve it: Systematic experiments comparing jittering with different noise distributions (e.g., Laplacian, uniform) for various inverse problems and robustness metrics.

### Open Question 2
- Question: What is the theoretical characterization of the optimal robust estimator for nonlinear inverse problems beyond linear subspace models?
- Basis in paper: [explicit] The paper conjectures optimal estimators for linear inverse problems beyond denoising but does not provide a rigorous proof or characterization for nonlinear cases.
- Why unresolved: The complexity of nonlinear inverse problems makes deriving closed-form optimal estimators challenging, and the paper only provides partial results for linear cases.
- What evidence would resolve it: Rigorous mathematical proofs or tight bounds on the optimal robust estimator for specific nonlinear inverse problems, validated through experiments.

### Open Question 3
- Question: How does the choice of network architecture (e.g., U-net depth, residual connections) impact the effectiveness of jittering for robustness in inverse problems?
- Basis in paper: [inferred] The paper uses U-nets but does not systematically explore how architectural choices affect jittering's robustness benefits.
- Why unresolved: The interaction between network architecture and regularization techniques like jittering is complex and not fully understood.
- What evidence would resolve it: Controlled experiments varying U-net architectures while keeping jittering constant, measuring robustness and standard performance trade-offs.

## Limitations
- The theoretical optimality of jittering holds strictly under a subspace signal model with Gaussian noise; extension to real-world image distributions and structured noise remains empirically supported but not proven.
- The optimal jittering noise level formula is derived for linear estimators; its applicability to deep nonlinear networks (U-nets) is validated experimentally but lacks theoretical guarantees.
- For ill-posed inverse problems like deconvolution and MRI, jittering is less effective than adversarial training, suggesting limitations in generalizing the theoretical benefits.

## Confidence
- High confidence in experimental results showing jittering improves worst-case robustness for denoising.
- Medium confidence in the claim that jittering is computationally cheaper than adversarial training, supported by stated complexity but lacking direct timing benchmarks.
- Medium confidence in the implication that training on real data with inherent noise enhances robustness, based on experimental trends but not rigorously quantified.

## Next Checks
1. Vary perturbation radius ϵ: Systematically test whether jittering’s robustness advantage diminishes as ϵ approaches or exceeds signal energy, as predicted by theory.
2. Non-Gaussian noise injection: Replace isotropic Gaussian jittering noise with structured or signal-dependent noise during training and measure impact on worst-case robustness.
3. Transfer to different architectures: Repeat experiments with deeper U-nets or other network families (e.g., ResNets) to assess whether jittering benefits are architecture-dependent.