---
ver: rpa2
title: Robust Graph Contrastive Learning with Information Restoration
arxiv_id: '2307.12555'
source_url: https://arxiv.org/abs/2307.12555
tags:
- graph
- node
- learning
- attacks
- loss
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the vulnerability of graph contrastive learning
  (GCL) to adversarial structural attacks that poison graph topology. The authors
  propose a novel framework called GCHS that integrates a homophily-driven learnable
  sanitation view to enhance robustness.
---

# Robust Graph Contrastive Learning with Information Restoration

## Quick Facts
- arXiv ID: 2307.12555
- Source URL: https://arxiv.org/abs/2307.12555
- Reference count: 40
- Primary result: GCHS achieves state-of-the-art robustness in GCL under structural attacks, outperforming 7 baselines on 6 datasets

## Executive Summary
This paper addresses the vulnerability of graph contrastive learning (GCL) to adversarial structural attacks that poison graph topology. The authors propose GCHS, a framework that integrates a homophily-driven learnable sanitation view to enhance robustness. By learning to sanitize poisoned graphs through edge-dropping with learned probabilities, GCHS restores the mutual information between graphs and their representations that is degraded by attacks. The method employs Gumbel-Softmax reparametrization for gradient-based optimization and introduces an unsupervised hyperparameter tuning strategy based on pseudo normalized cut loss. Extensive experiments demonstrate that GCHS consistently outperforms state-of-the-art baselines in node classification and graph clustering tasks under various attack strengths, while achieving the lowest Graph Representation Vulnerability (GRV) scores.

## Method Summary
GCHS introduces a homophily-driven learnable sanitation view that stochastically removes edges with learned probabilities to restore graph homophily and mutual information. The framework jointly trains an edge-dropping sanitizer and a GNN encoder using gradient-based optimization with Gumbel-Softmax reparametrization. The sanitation view operates on poisoned graphs to produce augmented views for contrastive learning, optimizing a combined objective of infoNCE loss and graph homophily restoration. A key innovation is the unsupervised hyperparameter tuning via pseudo normalized cut loss, which eliminates the need for node labels during training. The method is evaluated on six benchmark datasets under structural attacks (Mettack and CLGA) and compared against seven state-of-the-art baselines.

## Key Results
- GCHS achieves 5-10% higher node classification accuracy than baselines under structural attacks
- Consistently lower GRV scores indicate better robustness from information-theoretic perspective
- Unsupervised hyperparameter tuning via pseudo normalized cut loss correlates with classification accuracy
- Ablation studies confirm the effectiveness of both sanitation view and unsupervised tuning

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph structural attacks reduce the mutual information between the graph and its representations, degrading GCL performance.
- Mechanism: Attacks insert inter-class edges that break homophily, leading to less similar embeddings for connected nodes and more similar embeddings for disconnected nodes, which contradicts the contrastive learning objective.
- Core assumption: The effectiveness of GCL relies on maximizing mutual information between graph structure and learned representations.
- Evidence anchors:
  - [abstract] "we discover that... these attacks also diminish the mutual information between the graph and its representations"
  - [section V-B] Theorem 1 proves that both Mettack and CLGA minimize mutual information through their attack objectives

### Mechanism 2
- Claim: The homophily-driven learnable sanitation view restores graph homophily by stochastically removing edges with learned probabilities.
- Mechanism: A Gumbel-Softmax reparametrization enables gradient-based learning of edge-dropping probabilities that maximize the combined objective of infoNCE loss and graph homophily (Tr(X^T LS X)).
- Core assumption: Most real-world graphs exhibit homophily, and attacks primarily insert inter-class edges that reduce this property.
- Evidence anchors:
  - [section VI-B] Describes the edge-dropping sanitizer using Bernoulli distribution parameterized by learned probabilities
  - [section VI-B3] Explains the dual objective of restoring mutual information and graph homophily

### Mechanism 3
- Claim: The unsupervised hyperparameter tuning via pseudo normalized cut loss eliminates the need for node labels during training.
- Mechanism: The normalized cut loss measures clustering quality based on edge cuts, providing a label-free metric to select the optimal hyperparameter η by monitoring its value during training.
- Core assumption: High-quality node embeddings produce better graph clustering, which correlates with lower normalized cut loss.
- Evidence anchors:
  - [section VI-D] Describes using pseudo normalized cut loss to tune η without accessing node labels
  - [section VI-D] Shows correlation between minimum pseudo normalized cut loss and classification accuracy

## Foundational Learning

- Concept: Graph neural networks and their message passing mechanism
  - Why needed here: Understanding how GNNs encode graph structure into node representations is fundamental to grasping why GCL is vulnerable to attacks
  - Quick check question: How does a two-layer GCN transform node features and adjacency matrix into embeddings?

- Concept: Mutual information and its role in contrastive learning
  - Why needed here: The paper's theoretical analysis and defense mechanism both rely on mutual information as the key quantity to preserve
  - Quick check question: What is the relationship between infoNCE loss and mutual information in contrastive learning?

- Concept: Homophily in graphs and its measurement
  - Why needed here: The defense mechanism leverages graph homophily as a supervisory signal, and attacks are shown to reduce homophily
  - Quick check question: How do you measure graph homophily using node attributes versus node labels?

## Architecture Onboarding

- Component map: Poisoned graph → Learnable sanitation view (edge-dropping sanitizer) → Augmented views → Shared GNN encoder → Contrastive loss + graph homophily term → Updated sanitizer parameters and GNN encoder
- Critical path: Edge-dropping sanitizer → GNN encoder → Contrastive learning → Homophily restoration → Improved robustness
- Design tradeoffs: Stochastic edge dropping provides flexibility but introduces randomness; using graph homophily as supervision avoids labels but may not capture all attack effects
- Failure signatures: Poor performance despite sanitation suggests either ineffective sanitizer parameters or attacks that don't primarily insert inter-class edges
- First 3 experiments:
  1. Test the sanitation view's ability to remove edges in a controlled setting with known attack patterns
  2. Evaluate the impact of different η values on the balance between infoNCE loss and homophily restoration
  3. Compare performance against baselines on clean graphs to establish the robustness-accuracy tradeoff

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed homophily-driven sanitation view be adapted to defend against attacks that specifically target heterophily in graphs, rather than homophily?
- Basis in paper: [explicit] The paper discusses attacks that tend to insert inter-class edges and reduce homophily, but does not address attacks targeting heterophily.
- Why unresolved: The paper focuses on defending against attacks that disrupt homophily, but does not explore scenarios where the graph is inherently heterophilous or the attacker targets heterophily.
- What evidence would resolve it: Experiments showing the effectiveness of the sanitation view on heterophilous graphs or graphs with targeted heterophily attacks would demonstrate its adaptability.

### Open Question 2
- Question: Can the unsupervised hyperparameter tuning strategy based on pseudo normalized cut loss be extended to other graph learning tasks beyond node classification and graph clustering?
- Basis in paper: [explicit] The paper uses pseudo normalized cut loss for tuning hyperparameters in the context of node classification and graph clustering tasks.
- Why unresolved: The paper does not explore the applicability of this tuning strategy to other graph learning tasks such as link prediction or graph classification.
- What evidence would resolve it: Demonstrating the effectiveness of the tuning strategy on other graph learning tasks would validate its broader applicability.

### Open Question 3
- Question: How does the performance of the proposed method scale with graph size and density, and what are the computational bottlenecks for very large graphs?
- Basis in paper: [inferred] The paper does not explicitly discuss scalability or computational limitations for very large graphs, despite mentioning time cost in Table V.
- Why unresolved: The paper focuses on the effectiveness of the method on six benchmark datasets, but does not provide insights into its performance on larger or denser graphs.
- What evidence would resolve it: Experiments on larger or denser graphs, along with analysis of computational bottlenecks, would provide insights into scalability and limitations.

## Limitations
- Limited evaluation on graphs with weak or no homophily where the core assumption may break down
- Effectiveness depends on the assumption that attacks primarily insert inter-class edges rather than remove edges
- Computational overhead from joint training of sanitation view and GNN encoder

## Confidence
- Mutual information degradation by attacks: High
- Homophily restoration through learnable sanitation: Medium
- Unsupervised hyperparameter tuning effectiveness: Medium

## Next Checks
1. Test GCHS on heterophilic graphs where the homophily assumption breaks down
2. Evaluate performance against edge-removal attacks to verify the sanitation mechanism's effectiveness
3. Conduct ablation studies to isolate the contributions of the sanitation view versus the unsupervised hyperparameter tuning