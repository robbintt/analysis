---
ver: rpa2
title: Towards Open-World Recommendation with Knowledge Augmentation from Large Language
  Models
arxiv_id: '2306.10933'
source_url: https://arxiv.org/abs/2306.10933
tags:
- knowledge
- user
- recommendation
- llms
- reasoning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper introduces KAR, a framework that augments recommender\
  \ systems with open-world knowledge from large language models (LLMs). KAR extracts\
  \ two types of external knowledge\u2014reasoning knowledge on user preferences and\
  \ factual knowledge on items\u2014using factorization prompting to address the compositional\
  \ gap in LLMs."
---

# Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models

## Quick Facts
- arXiv ID: 2306.10933
- Source URL: https://arxiv.org/abs/2306.10933
- Reference count: 40
- Primary result: Improves AUC by 1.15–1.59% and reduces Logloss by 2.16–3.13% across nine CTR models

## Executive Summary
This paper introduces KAR, a framework that augments recommender systems with open-world knowledge from large language models (LLMs). KAR addresses the compositional gap in LLMs by using factorization prompting to extract reasoning knowledge on user preferences and factual knowledge on items. A hybrid-expert adaptor transforms this knowledge into augmented vectors compatible with any recommendation model. The framework pre-stores knowledge to ensure efficient inference, enabling real-world deployment on platforms like Huawei's news and music services with 7% and 1.7% improvements in online A/B tests.

## Method Summary
KAR uses factorization prompting to break down complex preference reasoning into scenario-specific factors, alleviating the compositional gap in LLMs. The generated reasoning and factual knowledge are encoded using models like BERT or ChatGLM, then transformed into augmented vectors through a hybrid-expert adaptor consisting of shared and dedicated experts with gating networks. These vectors are integrated into the input layer of any CTR model. To ensure efficient inference, knowledge is pre-stored offline, enabling low-latency predictions compatible with industrial requirements.

## Key Results
- Improves AUC by 1.15–1.59% and reduces Logloss by 2.16–3.13% across nine CTR models
- Achieves 7% improvement in online A/B tests on Huawei news platform
- Achieves 1.7% improvement in online A/B tests on Huawei music platform

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Factorization prompting breaks down complex preference reasoning into sub-factors, alleviating the compositional gap in LLMs.
- Mechanism: Decomposing user preferences into scenario-specific factors (e.g., genre, director, actors) allows the LLM to reason about each factor independently, then combine them for accurate reasoning.
- Core assumption: User preferences are compositional and can be meaningfully factored into interpretable dimensions.
- Evidence anchors:
  - [abstract] "We introduce factorization prompting to elicit accurate reasoning on user preferences."
  - [section 4.2.1] "LLMs often suffer from the compositional gap where the model fails at generating the correct answer to the compositional question but can correctly answer all its sub-questions."
- Break condition: If user preferences are not compositional or factors overlap too much, decomposition may lose important interactions.

### Mechanism 2
- Claim: Hybrid-expert adaptor transforms semantic space vectors into recommendation-compatible augmented vectors.
- Mechanism: Shared experts capture common aspects across reasoning and factual knowledge, while dedicated experts model unique characteristics. The gating network dynamically weights expert outputs to produce compact, domain-adapted vectors.
- Core assumption: The semantic space from LLMs can be linearly or non-linearly mapped to the recommendation space without significant information loss.
- Evidence anchors:
  - [abstract] "The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task."
  - [section 4.3.2] Mathematical formulation of shared and dedicated experts with gating networks.
- Break condition: If semantic space is too dissimilar from recommendation space, transformation may fail to preserve critical information.

### Mechanism 3
- Claim: Pre-storing LLM-generated knowledge vectors enables low-latency inference compatible with industrial RS requirements.
- Mechanism: Knowledge generation and encoding are performed once offline, storing reasoning and factual representations. During inference, these pre-stored vectors are retrieved and combined with backbone model inputs.
- Core assumption: User preferences and item knowledge are relatively stable over short time periods, making pre-computation feasible.
- Evidence anchors:
  - [abstract] "We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM."
  - [section 4.5] Detailed explanation of pre-storing strategy and inference time analysis.
- Break condition: If user preferences change rapidly or item knowledge becomes stale, pre-stored vectors may become outdated.

## Foundational Learning

- Concept: Factorization Machines (FM)
  - Why needed here: KAR's factorization prompting is inspired by FM's approach to decomposing interactions into factorized components.
  - Quick check question: How do FM models decompose high-order interactions differently from standard deep learning approaches?

- Concept: Mixture of Experts (MoE)
  - Why needed here: The hybrid-expert adaptor uses MoE principles to combine shared and dedicated experts for knowledge transformation.
  - Quick check question: What is the key difference between MoE and standard ensemble methods in terms of gating mechanisms?

- Concept: CTR Prediction Fundamentals
  - Why needed here: KAR is model-agnostic and enhances any CTR model by adding augmented vectors to the input layer.
  - Quick check question: In CTR prediction, what is the typical relationship between feature interaction order and model complexity?

## Architecture Onboarding

- Component map: LLM generation → Knowledge encoding → Hybrid-expert transformation → CTR model prediction
- Critical path: LLM generation → Knowledge encoding → Hybrid-expert transformation → CTR model prediction
- Design tradeoffs:
  - Knowledge quality vs. latency: More detailed factorization prompts improve reasoning but increase generation time
  - Expert network complexity vs. adaptation accuracy: More experts improve transformation but increase parameters
  - Vector dimension size vs. storage efficiency: Higher dimensions preserve more information but require more storage
- Failure signatures:
  - Poor CTR performance despite KAR integration: Likely knowledge transformation or factorization prompting issues
  - High latency during inference: Possible pre-storing mechanism failure or database retrieval issues
  - Inconsistent results across different backbone models: May indicate knowledge augmentation incompatibility
- First 3 experiments:
  1. Baseline: Run backbone CTR model without KAR augmentation
  2. Single factor test: Implement KAR with only one scenario-specific factor (e.g., genre only)
  3. Knowledge encoder comparison: Test KAR with different encoders (BERT vs ChatGLM) while keeping factorization prompting constant

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the specific scenarios where factorization prompting outperforms other prompting strategies in knowledge extraction?
- Basis in paper: [explicit] The paper discusses factorization prompting as a solution to the compositional gap but doesn't provide direct comparisons with alternative prompting methods.
- Why unresolved: The paper focuses on demonstrating KAR's effectiveness but doesn't benchmark different prompting approaches against each other.
- What evidence would resolve it: Head-to-head comparisons of factorization prompting vs. alternative prompting strategies across multiple recommendation domains.

### Open Question 2
- Question: How does KAR's performance scale with different LLM sizes, particularly for smaller models that might be more practical for deployment?
- Basis in paper: [inferred] The paper mentions using API-based LLMs but doesn't explore how performance varies with model size or test with smaller, more deployable models.
- Why unresolved: The experiments focus on demonstrating effectiveness rather than exploring the relationship between model size and performance.
- What evidence would resolve it: Systematic evaluation of KAR using LLMs of varying sizes (from small to large) to identify the minimum effective model size.

### Open Question 3
- Question: What are the long-term effects of pre-storing knowledge representations on recommendation accuracy when user preferences evolve over time?
- Basis in paper: [explicit] The paper discusses pre-storing knowledge to address inference latency but acknowledges that user behaviors evolve over time.
- Why unresolved: The experiments use static datasets and don't investigate how pre-stored knowledge affects performance as user preferences change.
- What evidence would resolve it: Longitudinal studies tracking KAR's performance over time as user behavior patterns shift, with and without knowledge updates.

## Limitations

- Factorization prompting assumes user preferences are compositional and decomposable into scenario-specific factors, which may not generalize across all recommendation domains
- Pre-storing strategy may struggle with rapidly changing user preferences or time-sensitive knowledge
- Heavy reliance on LLM-generated knowledge without extensive error analysis of potential hallucinations or reasoning failures

## Confidence

**High Confidence Claims:**
- KAR framework architecture and implementation details (based on clear mathematical formulations and code availability)
- Offline experimental results showing consistent improvements across multiple CTR models (well-documented and reproducible)
- Pre-storing strategy effectively reduces inference latency (directly demonstrated with measurements)

**Medium Confidence Claims:**
- Factorization prompting successfully addresses compositional gap in LLMs (supported by ablation studies but limited qualitative analysis)
- Hybrid-expert adaptor effectively transforms semantic space vectors (based on quantitative results without detailed ablation of architectural components)
- Online A/B test results showing 7% and 1.7% improvements (reported but not independently verified)

**Low Confidence Claims:**
- Generalizability of KAR across all recommendation domains (limited to movies and music in experiments)
- Scalability to massive industrial datasets (not thoroughly tested beyond reported platforms)
- Robustness against adversarial or noisy user behavior (not evaluated)

## Next Checks

1. **Knowledge Quality Analysis**: Conduct a systematic evaluation of the LLM-generated knowledge quality, including hallucination detection and reasoning accuracy across different factorization factors. Compare human-annotated ground truth with LLM outputs for a subset of users and items.

2. **Temporal Stability Test**: Evaluate KAR's performance when user preferences and item knowledge change rapidly over time. Design experiments with time-based data splits and measure degradation in AUC and Logloss as the gap between pre-stored knowledge generation and inference increases.

3. **Cross-Domain Generalization**: Test KAR on diverse recommendation domains beyond movies and music, such as e-commerce products or social media content. Compare performance across domains with varying levels of compositional structure in user preferences and item characteristics.