---
ver: rpa2
title: Linking convolutional kernel size to generalization bias in face analysis CNNs
arxiv_id: '2302.03750'
source_url: https://arxiv.org/abs/2302.03750
tags:
- bias
- image
- perturbation
- network
- kernel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents a causal framework to link architectural hyperparameters
  to algorithmic bias in CNNs. The method trains multiple network versions differing
  only in a chosen hyperparameter (e.g., kernel size), applies out-of-distribution
  perturbations to test images, and uses regression to estimate causal effects on
  performance across demographic groups.
---

# Linking convolutional kernel size to generalization bias in face analysis CNNs

## Quick Facts
- arXiv ID: 2302.03750
- Source URL: https://arxiv.org/abs/2302.03750
- Reference count: 40
- Key outcome: A causal framework shows convolutional kernel size induces subgroup-specific frequency biases in face analysis CNNs, with Black and Indian groups showing stronger effects on adversarial perturbation robustness.

## Executive Summary
This work presents a causal framework to link architectural hyperparameters to algorithmic bias in CNNs. The method trains multiple network versions differing only in a chosen hyperparameter (e.g., kernel size), applies out-of-distribution perturbations to test images, and uses regression to estimate causal effects on performance across demographic groups. Experiments on face gender classification using FairFace and UTKFace datasets reveal that increasing convolutional kernel size shifts feature focus to lower frequencies and reduces high-frequency sensitivity. This frequency bias varies by race/gender, with Black and Male subgroups showing consistently lower high-frequency feature content. Causal regression shows kernel size changes have stronger effects on perturbation robustness for Black and Indian groups.

## Method Summary
The method trains K versions of a CNN architecture, each with a different value of a chosen hyperparameter (here, convolutional kernel size ranging from 3×3 to 11×11). These models are evaluated on test images perturbed with adversarial attacks (FGSM and CW) and frequency energy injections. The performance metrics (adversarial perturbation distance and accuracy under frequency perturbations) are then used in a multivariable linear regression model to estimate the causal effect of kernel size on model performance, controlling for protected attributes like race and gender. The regression coefficients (β) quantify how kernel size differentially affects each subgroup's performance.

## Key Results
- Increasing convolutional kernel size shifts feature focus to lower frequencies and reduces high-frequency sensitivity in face analysis CNNs
- Black and Male subgroups show consistently lower high-frequency feature content across all kernel sizes
- Causal regression reveals kernel size changes have stronger effects on perturbation robustness for Black and Indian groups compared to White and East Asian groups

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Modifying convolutional kernel size in a CNN layer induces a shift in the frequency content of learned features, and this shift varies systematically across demographic subgroups.
- **Mechanism:** Kernel size determines the spatial support of convolution operations. Smaller kernels have higher frequency selectivity in the Fourier domain due to the uncertainty principle, while larger kernels aggregate more low-frequency information. The regression framework isolates the causal effect of kernel size by training models with fixed architectural differences, perturbing test data to expose OOD performance, and using linear regression to attribute performance changes to kernel size while controlling for protected attributes.
- **Core assumption:** The regression identifies causal effects under the conditional independence assumption: $E[x_k \cdot \epsilon_{1ik} | \mathbf{Z}_i] = 0$, where $\mathbf{Z}_i$ includes image attributes and perturbation levels.
- **Evidence anchors:**
  - [abstract]: "modifying convolutional kernel size shifts feature focus to lower frequencies and reduces high-frequency sensitivity"
  - [section]: "convolutional kernel size has been shown to bias CNNs towards different frequencies"
  - [corpus]: Weak or missing direct evidence linking kernel size to frequency content in this specific causal framework; assumption based on prior literature.
- **Break condition:** If the conditional independence assumption is violated (e.g., kernel size correlates with other architectural choices that also affect frequency content), the regression estimates become biased.

### Mechanism 2
- **Claim:** Adversarial perturbation distance is inversely related to the model's sensitivity to high-frequency features, and this relationship differs across demographic subgroups.
- **Mechanism:** Adversarial attacks exploit high-frequency features in model representations. When a model's features are biased toward high frequencies (smaller kernels), it requires smaller perturbations to fool the model. The regression framework measures kernel size's causal effect on perturbation distance across subgroups, revealing that Black and Indian subgroups have lower perturbation distances, indicating higher high-frequency sensitivity.
- **Core assumption:** Adversarial perturbation distance is a valid proxy for the model's reliance on high-frequency features, and this proxy is equally meaningful across demographic subgroups.
- **Evidence anchors:**
  - [abstract]: "increasing convolutional kernel size shifts feature focus to lower frequencies and reduces high-frequency sensitivity"
  - [section]: "the CW perturbation is an order of magnitude smaller due to the effect of its regularization" and "perturbation distance increases with FLKS for all race groups"
  - [corpus]: Weak or missing evidence that adversarial distance is a consistent measure across demographics; assumption based on general adversarial robustness literature.
- **Break condition:** If adversarial examples exploit different feature subspaces across subgroups (not just high frequencies), the perturbation distance no longer reflects frequency sensitivity differences.

### Mechanism 3
- **Claim:** The causal framework's regression coefficients ($\beta$) quantify the differential impact of kernel size on OOD performance across protected attribute subgroups, enabling identification of subgroup-specific architectural biases.
- **Mechanism:** The regression model predicts performance metrics (e.g., error rate or perturbation distance) as a function of kernel size, frequency perturbation level, and protected attributes. The coefficients $\beta$ capture how kernel size affects performance for each subgroup, with significant differences indicating subgroup-specific biases.
- **Core assumption:** The linear regression model adequately captures the relationship between kernel size, frequency perturbation, and performance, and the coefficients $\beta$ are stable across different specifications of the control variables $\mathbf{Z}_i$.
- **Evidence anchors:**
  - [section]: "We use the regression coefficients to measure the hyperparameter's causal effects on model performances across data subgroups"
  - [section]: "the coefficients for Black and Indian are significantly higher than that of other race groups"
  - [corpus]: Weak or missing evidence on the stability of $\beta$ coefficients across different model architectures; assumption based on general regression theory.
- **Break condition:** If the relationship between kernel size and performance is non-linear or involves interactions not captured by the regression model, the $\beta$ coefficients will not accurately represent causal effects.

## Foundational Learning

- **Concept:** Fourier Transform and frequency domain representation
  - **Why needed here:** Understanding how convolutional kernel size affects frequency content of learned features requires knowledge of how spatial operations map to frequency domain properties.
  - **Quick check question:** What is the relationship between the size of a convolutional kernel and its frequency selectivity in the Fourier domain?

- **Concept:** Causal inference and regression analysis
  - **Why needed here:** The framework uses regression to estimate causal effects of architectural hyperparameters on model performance, controlling for confounding variables.
  - **Quick check question:** What is the key assumption required for regression to identify causal effects, and how does the framework attempt to satisfy it?

- **Concept:** Adversarial examples and their relationship to model features
  - **Why needed here:** Adversarial attacks are used as OOD perturbations to expose differences in feature sensitivity across subgroups, based on the assumption that they exploit high-frequency features.
  - **Quick check question:** Why are adversarial examples typically high-frequency in nature, and how does this relate to the model's learned features?

## Architecture Onboarding

- **Component map:** Model training -> OOD perturbation -> Causal analysis -> Performance comparison
- **Critical path:**
  1. Train K models with different kernel sizes
  2. Apply OOD perturbations to test set
  3. Collect predictions and compute performance metrics
  4. Run regression analysis to estimate causal effects
  5. Compare $\beta$ coefficients across subgroups
- **Design tradeoffs:**
  - Kernel size vs. frequency sensitivity: Smaller kernels increase high-frequency sensitivity but may reduce robustness
  - Regression complexity vs. interpretability: Including more controls improves causal identification but reduces coefficient interpretability
  - OOD perturbation type: Adversarial attacks are realistic but may exploit non-frequency features; frequency injections are cleaner but less realistic
- **Failure signatures:**
  - Regression coefficients $\beta$ are not stable across different specifications of control variables
  - Adversarial perturbation distances do not correlate with expected frequency sensitivity patterns
  - Performance differences across subgroups are not explained by kernel size effects in the regression
- **First 3 experiments:**
  1. Train two models with kernel sizes 3 and 11 on FairFace, apply FGSM attacks, and compare perturbation distances across race groups
  2. Train three models with kernel sizes 3, 7, and 11 on UTKFace, apply frequency energy injections, and plot accuracy vs. frequency for each race group
  3. Run the full regression analysis on FairFace data with kernel sizes 3, 5, 7, 9, and 11, and compare $\beta$ coefficients for Black vs. White subgroups

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How does modifying convolutional kernel sizes in multiple layers compare to modifying only the first layer in terms of their impact on algorithmic bias across demographic groups?
- **Basis in paper:** [explicit] The paper states "Interestingly, both scenarios yielded similar results" when comparing modifying only the first layer versus all layers, but provides results for all layers only in supplementary material.
- **Why unresolved:** The main paper does not provide detailed quantitative comparison between these two scenarios, making it unclear if there are subtle differences in how multi-layer modifications affect bias differently than single-layer modifications.
- **What evidence would resolve it:** A direct statistical comparison of regression coefficients and frequency bias measures between single-layer and multi-layer kernel size modifications across all demographic groups.

### Open Question 2
- **Question:** What is the relationship between frequency biases in learned features and real-world out-of-distribution artifacts like motion blur or fog that commonly affect face analysis systems?
- **Basis in paper:** [inferred] The paper mentions that "next steps in this research space include similar analyses into...real-world OOD artifacts like shot noise, fog, and motion blur" but does not explore these connections experimentally.
- **Why unresolved:** The paper only tests frequency-based perturbations in controlled settings, leaving the connection to real-world degradation patterns unexplored.
- **What evidence would resolve it:** Experimental results showing how kernel size modifications affect model robustness to real-world artifacts across demographic groups, with frequency analysis of these artifacts.

### Open Question 3
- **Question:** How do different activation functions interact with kernel size to influence frequency biases and demographic performance disparities?
- **Basis in paper:** [explicit] The paper mentions "next steps in this research space include similar analyses into a more comprehensive set of network hyperparameters, such as activation functions" but does not investigate this interaction.
- **Why unresolved:** The study focuses exclusively on kernel size while acknowledging activation functions as another potential source of implicit bias, creating a gap in understanding how these hyperparameters work together.
- **What evidence would resolve it:** Comparative experiments testing combinations of kernel sizes and activation functions (ReLU, Leaky ReLU, GELU, etc.) across demographic groups with frequency analysis of learned features.

## Limitations
- The causal framework relies on linear regression assumptions that may not fully capture the complex relationship between kernel size, frequency content, and subgroup performance
- The use of adversarial perturbation distance as a proxy for frequency sensitivity is an assumption that requires further validation across diverse demographic groups
- The study focuses on single-layer kernel modifications, leaving open questions about how multi-layer architectural choices interact to produce bias

## Confidence
- **High confidence**: The experimental methodology for training models with varying kernel sizes and applying OOD perturbations is well-specified and reproducible
- **Medium confidence**: The claim that kernel size affects frequency sensitivity is supported by the analysis but relies on the adversarial perturbation distance proxy
- **Medium confidence**: The finding that Black and Indian subgroups show stronger kernel size effects is based on the regression analysis but could be influenced by dataset characteristics or other uncontrolled factors

## Next Checks
1. **Validate frequency proxy**: Conduct controlled experiments with synthetic data to verify that adversarial perturbation distance correlates with actual frequency sensitivity across different demographic subgroups
2. **Test model stability**: Train multiple models with the same kernel size but different random seeds to assess the stability of the β coefficients across runs
3. **Analyze feature distributions**: Visualize and compare the frequency content of learned features across demographic groups for each kernel size to directly validate the frequency bias claim