---
ver: rpa2
title: 'APE-then-QE: Correcting then Filtering Pseudo Parallel Corpora for MT Training
  Data Creation'
arxiv_id: '2312.11312'
source_url: https://arxiv.org/abs/2312.11312
tags:
- corpus
- parallel
- filtering
- translation
- pseudo-parallel
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a repair-filter-use methodology that uses an
  Automatic Post-Editing (APE) system to correct errors on the target side of the
  MT training data, and then uses a Quality Estimation (QE) model to select the sentence
  pairs from the original and corrected sentence pairs based on quality scores. The
  approach improves the performance of the English-Marathi and Marathi-English MT
  systems by 5.64 and 9.91 BLEU points, respectively, over the baseline model trained
  on the whole pseudo-parallel corpus.
---

# APE-then-QE: Correcting then Filtering Pseudo Parallel Corpora for MT Training Data Creation

## Quick Facts
- arXiv ID: 2312.11312
- Source URL: https://arxiv.org/abs/2312.11312
- Reference count: 16
- Primary result: Improves English-Marathi and Marathi-English MT systems by 5.64 and 9.91 BLEU points respectively using APE-then-QE methodology

## Executive Summary
This paper presents a methodology for creating high-quality training data for machine translation by first correcting errors in pseudo-parallel corpora using Automatic Post-Editing (APE), then filtering the corpus using Quality Estimation (QE). The approach is particularly valuable for low-resource languages where high-quality parallel corpora are scarce. By applying this APE-then-QE pipeline to English-Marathi translation, the authors demonstrate significant improvements in MT system performance, showing that the method can effectively enhance data quality even when starting from noisy MT outputs.

## Method Summary
The APE-then-QE methodology involves training an APE model to correct systematic errors in MT-generated target sentences, followed by using a QE model to select the higher quality sentence pairs between original and corrected versions. The process starts with a large pseudo-parallel corpus (3.28M sentence pairs for En-Mr), applies APE correction to target-side translations, then uses QE to score and filter sentence pairs. The final filtered corpus is used to train NMT systems, resulting in improved translation quality as measured by BLEU scores.

## Key Results
- APE-then-QE approach improves En-Mr MT system by 5.64 BLEU points over baseline
- APE-then-QE approach improves Mr-En MT system by 9.91 BLEU points over baseline
- Method demonstrates effectiveness for low-resource language pairs with limited parallel data
- Approach is language pair-agnostic and requires APE/QE data for implementation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: APE system corrects systematic translation errors in target-side MT outputs, improving data quality
- Mechanism: APE model takes source text and noisy MT output as input, generates corrected target translation using dual-encoder single-decoder architecture
- Core assumption: APE model generalizes to correct similar types of errors present in pseudo-parallel corpus
- Evidence anchors: [abstract] "We use the APE model to rectify errors in the target side of the noisy pseudo-parallel corpus"; [section] "We borrow the same training strategy to train our En-Mr APE system"

### Mechanism 2
- Claim: QE model selects higher quality sentence pair between original and APE-corrected pairs
- Mechanism: QE assigns quality scores to both original and APE-corrected target sentences, selects pair with higher score
- Core assumption: QE quality score accurately reflects true translation quality
- Evidence anchors: [abstract] "We select the sentence pairs from the original and corrected sentence pairs based on the quality scores"; [section] "Next, we employ Quality Estimation to assign quality scores"

### Mechanism 3
- Claim: Filtering and using high-quality sentence pairs improves MT system performance
- Mechanism: Correcting errors with APE and selecting high-quality pairs using QE results in training corpus with fewer errors and higher overall quality
- Core assumption: Training on higher quality parallel data leads to better MT performance
- Evidence anchors: [abstract] "By training with this filtered corpus, we observe an improvement in the Machine Translation system's performance by 5.64 and 9.91 BLEU points"; [section] "We observe that APE and QE-assisted corpus filtering significantly improves the performance"

## Foundational Learning

- Concept: Automatic Post-Editing (APE)
  - Why needed here: APE corrects systematic errors in MT outputs, improving training data quality
  - Quick check question: What is the input and output of an APE system, and how does it learn to correct MT errors?

- Concept: Quality Estimation (QE)
  - Why needed here: QE assigns quality scores to translations without reference translations, enabling selection of high-quality sentence pairs
  - Quick check question: How does a QE model estimate the quality of a translation, and what are the key features it uses?

- Concept: Neural Machine Translation (NMT) training data requirements
  - Why needed here: Understanding data requirements is crucial for appreciating impact of data quality on MT performance
  - Quick check question: What are key characteristics of high-quality training data for NMT systems, and how does data quality affect MT performance?

## Architecture Onboarding

- Component map: Source text -> APE system -> Corrected target text; Source text + Original/Corrected target -> QE system -> Quality scores -> Filtered parallel corpus -> MT system

- Critical path:
  1. Preprocess pseudo-parallel corpus
  2. Apply APE to correct target-side errors
  3. Use QE to score original and APE-corrected pairs
  4. Select high-quality pairs based on QE scores
  5. Train MT system on filtered corpus

- Design tradeoffs:
  - APE model complexity vs. correction accuracy
  - QE model accuracy vs. computational cost
  - Corpus filtering threshold vs. data quantity
  - MT model size vs. training data size

- Failure signatures:
  - APE model introduces new errors or over-corrects
  - QE model assigns inconsistent or biased scores
  - Filtered corpus is too small or unrepresentative
  - MT system overfits to filtered corpus

- First 3 experiments:
  1. Train APE model on synthetic and real APE triplets, evaluate on held-out APE test set
  2. Train QE model on QE data, evaluate on held-out QE test set
  3. Apply APE and QE to pseudo-parallel corpus, train MT system on filtered data, evaluate on MT test set

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the APE-then-QE approach perform on language pairs other than English-Marathi?
- Basis in paper: [inferred] The paper mentions that the approach is language pair-agnostic and can be applied to any language pair, but experiments are limited to English-Marathi due to lack of APE and QE resources
- Why unresolved: The paper does not provide empirical evidence or results for other language pairs
- What evidence would resolve it: Experimental results on APE-then-QE approach for multiple language pairs would resolve this question

### Open Question 2
- Question: What is the impact of different threshold values in the QE-based filtering on the performance of the NMT system?
- Basis in paper: [explicit] The paper mentions using a threshold value of -0.5 for the En-Mr language pair in QE-based filtering, but does not explore the impact of different threshold values
- Why unresolved: The paper does not provide a sensitivity analysis or comparison of different threshold values
- What evidence would resolve it: A study comparing the performance of the NMT system using different threshold values in QE-based filtering would resolve this question

### Open Question 3
- Question: How does the combination of word and sentence level QE compare to sentence level QE alone in selecting high-quality sentence pairs?
- Basis in paper: [explicit] The paper mentions plans to use a combination of word and sentence level QE in the future but does not provide any results or comparison
- Why unresolved: The paper does not provide any empirical evidence or results for the combination of word and sentence level QE
- What evidence would resolve it: Experimental results comparing the performance of word and sentence level QE combination versus sentence level QE alone would resolve this question

### Open Question 4
- Question: What is the computational cost of training the APE and QE systems compared to the improvement in NMT performance?
- Basis in paper: [inferred] The paper mentions the training details and the use of GPUs but does not provide a cost-benefit analysis of the APE and QE systems
- Why unresolved: The paper does not provide any information on the computational resources required or a comparison of the cost versus the improvement in NMT performance
- What evidence would resolve it: A detailed analysis of the computational cost of training the APE and QE systems and the corresponding improvement in NMT performance would resolve this question

## Limitations
- Limited evaluation to single language pair (English-Marathi) with specific corpus size
- No detailed analysis of error types corrected by APE system or quality distribution of filtered corpus
- Computational overhead of applying APE and QE to millions of sentence pairs not discussed
- Effectiveness depends heavily on quality of APE and QE training data, which is not thoroughly explored

## Confidence

- High confidence: General APE-then-QE methodology is sound and theoretically well-founded, with clear connections to existing work in automatic post-editing and quality estimation. Experimental results show consistent BLEU score improvements over baseline model for both English-Marathi and Marathi-English translation directions.

- Medium confidence: Specific implementation details and hyperparameters of APE and QE models are not fully disclosed, making it difficult to reproduce exact results. Paper does not provide detailed error analysis or quality distribution analysis of filtered corpus, limiting understanding of methodology's impact on data quality.

- Low confidence: Methodology's effectiveness for low-resource languages or very small pseudo-parallel corpora is not demonstrated. Potential negative impacts of APE and QE models, such as introducing new errors or filtering out valuable data, are not quantified or discussed in detail.

## Next Checks

1. Conduct detailed error analysis of APE-corrected sentences to quantify types of errors corrected and potential for introducing new errors. Evaluate impact of different APE model architectures and training strategies on quality of corrected sentences.

2. Perform quality distribution analysis of filtered corpus to understand impact of QE-based filtering on overall quality of training data. Experiment with different filtering thresholds and assess trade-off between corpus size and quality.

3. Evaluate methodology on multiple language pairs with varying levels of resource availability and corpus sizes. Compare performance of APE-then-QE approach with other corpus filtering techniques and assess effectiveness in low-resource scenarios.