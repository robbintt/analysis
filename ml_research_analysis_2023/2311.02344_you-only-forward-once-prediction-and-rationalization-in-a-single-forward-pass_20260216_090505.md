---
ver: rpa2
title: 'You Only Forward Once: Prediction and Rationalization in A Single Forward
  Pass'
arxiv_id: '2311.02344'
source_url: https://arxiv.org/abs/2311.02344
tags:
- yofo
- rationales
- rationale
- layer
- tokens
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel approach to unsupervised rationale
  extraction that addresses limitations of prior two-phase models, such as interlocking
  and spurious correlations. The proposed method, YOFO (You Only Forward Once), uses
  a pre-trained language model like BERT to simultaneously generate predictions and
  rationales in a single forward pass.
---

# You Only Forward Once: Prediction and Rationalization in A Single Forward Pass

## Quick Facts
- arXiv ID: 2311.02344
- Source URL: https://arxiv.org/abs/2311.02344
- Reference count: 37
- Achieves up to 18.4% improvement in token-level F1 for rationale extraction

## Executive Summary
This paper introduces YOFO (You Only Forward Once), a novel approach to unsupervised rationale extraction that addresses limitations of prior two-phase models. YOFO uses a single pre-trained language model to simultaneously generate predictions and rationales in one forward pass, avoiding the interlocking and spurious correlation issues that plague generator-predictor frameworks. The method progressively removes unimportant tokens during forward propagation rather than selecting important ones, achieving state-of-the-art performance on benchmark datasets.

## Method Summary
YOFO modifies a pre-trained language model like BERT to perform prediction and rationalization simultaneously through progressive token removal. Instead of having separate generator and predictor components, YOFO applies binary masks at each layer to remove unimportant tokens based on attention scores. The model is trained with sparsity and contiguous regularization terms, encouraging concise and coherent rationales. Token decay strategies (Cliff, Linear, Exponential, Logarithmic) control the sparsity level throughout the forward pass.

## Key Results
- Achieves up to 18.4% improvement in token-level F1 for rationale extraction on benchmark datasets
- Outperforms state-of-the-art methods on BeerAdvocate and Hotel Review datasets
- Effectively mitigates interlocking and spurious correlation issues inherent in two-phase models
- Generates more coherent and human-readable rationales compared to baseline approaches

## Why This Works (Mechanism)

### Mechanism 1: Single-Pass Architecture
YOFO avoids interlocking by using a single pre-trained language model to simultaneously generate predictions and rationales in one forward pass, rather than having separate generator and predictor components. This eliminates the dependency between components that causes interlocking in RNP frameworks.

### Mechanism 2: Progressive Token Removal
YOFO applies binary masks at each layer to remove unimportant tokens based on attention scores, allowing the model to focus on relevant information progressively. This differs from direct selection approaches by gradually pruning the input space.

### Mechanism 3: Contiguous Penalty
YOFO adds regularization term |ùëöùëñ ‚àí ùëöùëñ ‚àí1| to encourage smooth transitions in token selection across layers, generating more coherent and readable rationales by minimizing length changes between consecutive layers.

## Foundational Learning

- **Token selection and masking techniques**: Why needed here - YOFO relies on progressive token removal using binary masks at each layer. Quick check question: How would you implement a binary mask that selects important tokens based on attention scores?
- **Attention mechanisms and transformer architectures**: Why needed here - YOFO modifies attention scores by applying masks, requiring understanding of how attention works in transformers. Quick check question: What happens to gradient flow when you multiply attention scores by a binary mask?
- **Regularization techniques and loss function design**: Why needed here - YOFO combines task loss, sparsity penalty, and contiguous penalty in its overall loss function. Quick check question: How would you balance multiple loss terms with different scales?

## Architecture Onboarding

- **Component map**: Input text ‚Üí Word embedding ‚Üí Pre-trained language model layers ‚Üí Token selection masks ‚Üí Classification head
- **Critical path**: Text embedding ‚Üí Layer-wise token masking ‚Üí Final classification ‚Üí Rationale extraction from token masks
- **Design tradeoffs**: Progressive token removal vs. complete token interaction in early layers; Contiguity penalty strength vs. rationale sparsity; Number of layers dedicated to information gathering vs. rationalization
- **Failure signatures**: Poor rationale quality (low F1) with good task accuracy suggests overfitting or incorrect token decay strategy; Very low accuracy suggests token removal is too aggressive; High sparsity but low contiguity suggests contiguous penalty is too weak
- **First 3 experiments**: 1) Implement basic YOFO without contiguous penalty to verify progressive token removal works; 2) Test different token decay strategies (linear, exponential, logarithmic) to find optimal sparsity schedule; 3) Compare YOFO with BERT-RNP baseline on small dataset to verify interlocking problem is mitigated

## Open Questions the Paper Calls Out

### Open Question 1
How does the token decay strategy in YOFO compare to other token reduction methods like TR-BERT and Power-BERT in terms of maintaining model performance while achieving sparsity? The paper mentions YOFO's token decay strategy but doesn't provide direct comparison of effectiveness against other token reduction methods.

### Open Question 2
Can the YOFO framework be effectively applied to other pre-trained language models beyond BERT, such as GPT or RoBERTa, and what are the potential benefits or drawbacks? The paper uses BERT but mentions any pre-trained language model can be deployed, without exploring other models.

### Open Question 3
How does the Contiguous Penalty in YOFO influence the quality of extracted rationales in terms of human readability and coherence? The paper introduces this penalty but doesn't provide detailed analysis of its specific effects on human readability.

## Limitations

- Limited empirical validation of interlocking problem avoidance - theoretical claims lack rigorous controlled experiments
- Reliance on attention scores as token importance indicators may not generalize across all domains and tasks
- Computational overhead compared to two-phase models not discussed, which is important for practical deployment
- Limited evaluation to two review datasets, raising questions about generalizability to other NLP tasks

## Confidence

- **High Confidence (90%+)**: Core experimental results showing YOFO's superiority on BeerAdvocate and Hotel Review datasets; ablation studies demonstrating importance of regularization terms
- **Medium Confidence (70-89%)**: Theoretical claims about avoiding interlocking and spurious correlation; single-pass architecture providing plausible mechanism
- **Low Confidence (below 70%)**: Generalizability to other NLP tasks and domains beyond the two review datasets tested

## Next Checks

1. **Interlocking Problem Validation**: Design controlled experiment demonstrating interlocking failure cases in RNP frameworks, then show YOFO successfully avoiding these failures in identical setup

2. **Attention Score Reliability Test**: Conduct ablation study evaluating YOFO's performance with different attention-based token selection methods to validate attention scores as reliable indicators of token importance

3. **Computational Efficiency Analysis**: Measure wall-clock training time and inference latency of YOFO versus RNP baselines on identical hardware, including memory usage and scalability analysis for practical deployment insights