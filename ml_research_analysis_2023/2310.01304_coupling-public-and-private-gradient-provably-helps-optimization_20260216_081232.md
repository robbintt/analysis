---
ver: rpa2
title: Coupling public and private gradient provably helps optimization
arxiv_id: '2310.01304'
source_url: https://arxiv.org/abs/2310.01304
tags:
- private
- public
- training
- data
- privacy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "The paper analyzes the convergence of differentially private optimization\
  \ that linearly combines public and private gradients with a weighting coefficient\
  \ \u03B1. In contrast to previous works that choose \u03B1 as a constant, the authors\
  \ show that the optimal \u03B1 depends on training hyperparameters including privacy\
  \ budget, number of iterations, batch size, and model size."
---

# Coupling public and private gradient provably helps optimization

## Quick Facts
- arXiv ID: 2310.01304
- Source URL: https://arxiv.org/abs/2310.01304
- Reference count: 40
- The paper proves that coupling public and private gradients with an optimal hyperparameter-dependent weighting coefficient α accelerates convergence in differentially private optimization.

## Executive Summary
This paper addresses the challenge of training machine learning models on a mix of public and private data while maintaining differential privacy. The key insight is that linearly combining public and private gradients with a carefully chosen weighting coefficient α can significantly improve the utility-privacy trade-off compared to using either dataset alone. The authors provide theoretical convergence guarantees for non-convex optimization and derive a formula for the optimal α that depends on privacy budget, number of iterations, batch size, and model size. Empirical results on vision and language benchmarks demonstrate that the proposed coupling method achieves higher accuracy than non-mixed training approaches while satisfying the same privacy guarantees.

## Method Summary
The method combines gradients from public and private datasets using a weighting coefficient α. For each iteration, per-sample gradients are computed for both public and private batches. Private gradients are clipped and Gaussian noise is added to ensure differential privacy. The final gradient update is a linear combination: α times the public gradient plus (1-α) times the private gradient. The optimal α is derived from a theoretical analysis and depends on hyperparameters including the privacy budget (ε), number of iterations (T), batch size (B), and model size (d). The authors provide a closed-form formula for α in Corollary 4.3.2 and suggest using SGD or AdamW optimizers depending on the task.

## Key Results
- The optimal weighting coefficient α accelerates convergence compared to using only public or only private gradients
- The optimal α is determined by multiple hyperparameters including privacy budget, number of iterations, batch size, and model size
- Coupling public and private gradients with optimal α provides better utility-privacy trade-off than using either dataset alone

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Coupling public and private gradients with a hyperparameter-dependent weighting coefficient α accelerates convergence compared to using either dataset alone.
- Mechanism: The optimal α balances the optimization error (dominated by private data noise) and the generalization error (improved by public data), leading to faster convergence toward the true optimum.
- Core assumption: The loss function is non-convex, positive, and Lipschitz smooth; gradients from public and private data are sampled i.i.d. from the same distribution.
- Evidence anchors:
  - [abstract]: "We prove the acceleration in the convergence of non-convex loss and the effects of hyper-parameters such as privacy budget, number of iterations, batch size, model size on the choice of the weighting coefficient."
  - [section 4]: "Under Theorem 4.1 and Theorem 4.2, running DP-SGD for T iterations and setting the learning rate η ∝ 1/√T, with arbitrarily small probability c > 0, min_{0≤t≤T} P(||gt|| > f_r^{-1}(...) ) ≲ c"
  - [corpus]: No direct evidence found; weak support from general gradient mixing literature.
- Break condition: If the public and private data distributions differ significantly, or if the noise level in private gradients overwhelms the benefit of mixing.

### Mechanism 2
- Claim: The optimal α is determined by multiple hyperparameters including privacy budget, number of iterations, batch size, and model size.
- Mechanism: As these hyperparameters change, the relative importance of optimization error versus generalization error shifts, requiring a different α to maintain optimal convergence speed.
- Core assumption: The relationship between hyperparameters and the optimal α can be derived from the convergence analysis.
- Evidence anchors:
  - [abstract]: "We show that the optimal weighting coefficients α between the public gradient and the private gradient are determined by multiple hyperparameters, including the privacy budget, number of iterations, batch size, model size."
  - [section 4.3]: "Corollary 4.3.2. Denote the learning rate for public and private data as ηpub = ηα and ηpriv = η(1 − α), respectively. And the total dataset size is n = npub + npriv... Then under Theorem 4.3, we suggest to apply the following α = ηpub / (ηpriv + ηpub) = 1 / (1 + B · √(2LL0 / (B2+σ2d)))"
  - [corpus]: No direct evidence found; weak support from general hyperparameter tuning literature.
- Break condition: If the assumptions of smoothness or gradient noise bounds are violated, or if the model architecture changes significantly.

### Mechanism 3
- Claim: Coupling with optimal α provides better utility-privacy trade-off than using only public or only private data.
- Mechanism: By leveraging both datasets, the method achieves higher accuracy than either dataset alone while maintaining the same privacy guarantee as private-only training.
- Core assumption: The public dataset, though smaller, provides valuable gradient information that complements the private data.
- Evidence anchors:
  - [abstract]: "Empirical experiments on language and vision benchmarks demonstrate that coupling public and private gradients with a well-chosen α effectively improves the utility-privacy trade-off."
  - [section 5.1]: "From Table 3, we find that the mixed training, e.g. DPMD and Coupling, can achieve higher accuracy than non-mixed training, thus highlighting the importance of leveraging both public and private data."
  - [corpus]: No direct evidence found; weak support from general mixed-data training literature.
- Break condition: If the public dataset is too small or too different from the private data, or if the privacy budget is extremely tight.

## Foundational Learning

- Concept: Differential Privacy (DP)
  - Why needed here: The paper's main contribution is to improve DP optimization by coupling public and private gradients.
  - Quick check question: What is the main purpose of adding noise to gradients in DP-SGD?

- Concept: Convex and Non-convex Optimization
  - Why needed here: The paper analyzes convergence for both convex and non-convex loss functions.
  - Quick check question: How does the convergence analysis differ between convex and non-convex settings?

- Concept: Hyperparameter Tuning in Machine Learning
  - Why needed here: The optimal weighting coefficient α depends on multiple hyperparameters that need to be tuned.
  - Quick check question: What are some common strategies for tuning hyperparameters in deep learning?

## Architecture Onboarding

- Component map: Per-sample gradient computation -> Gradient clipping and noise addition -> Linear combination with weight α -> Gradient descent update -> Privacy accounting

- Critical path:
  1. Compute per-sample gradients for public and private data
  2. Clip and add noise to private gradients
  3. Combine gradients with weight α
  4. Update model parameters
  5. Perform privacy accounting

- Design tradeoffs:
  - Choosing α: Higher α gives more weight to public data (less noise, but less data), while lower α gives more weight to private data (more data, but more noise)
  - Batch size: Larger batch sizes reduce gradient variance but may require more memory
  - Privacy budget: Tighter privacy budgets require more noise, which can be partially mitigated by increasing α

- Failure signatures:
  - If α is set too high, the model may overfit to the small public dataset
  - If α is set too low, the model may not benefit enough from the public data to overcome the noise in private gradients
  - If the public and private data distributions differ significantly, coupling may not provide benefits

- First 3 experiments:
  1. Implement coupling with a fixed α (e.g., 0.5) and compare accuracy to public-only and private-only training on a small vision dataset
  2. Implement the optimal α formula and validate its effect on convergence speed and final accuracy
  3. Test the effect of varying the public data ratio (rpub) on the optimal α and overall performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal value of the weighting coefficient α for different model architectures (CNN, ResNet, ViT, DeiT) when using different datasets?
- Basis in paper: [explicit] The paper states that the optimal α depends on hyperparameters including model size (d), number of iterations (T), batch size (B), privacy budget (ϵ), and model structure. The authors show in Figure 3 that different model architectures (ViT-tiny, ViT-small, ViT-base, ViT-large, DeiT-small) have different optimal α values.
- Why unresolved: While the paper demonstrates the effect of model architecture on the optimal α, it does not provide a comprehensive study of the optimal α values for different model architectures across various datasets.
- What evidence would resolve it: A thorough experimental analysis comparing the optimal α values for different model architectures on various datasets, such as MNIST, CIFAR10, CIFAR100, SST-2, and QNLI.

### Open Question 2
- Question: How does the choice of the privacy budget (ϵ) affect the optimal value of the weighting coefficient α?
- Basis in paper: [explicit] The paper states that the optimal α is increasing with the privacy budget (ϵ) and decreasing with the privacy level (µ). It also mentions that a larger privacy budget leads to a higher optimal α value.
- Why unresolved: Although the paper demonstrates the relationship between the privacy budget and the optimal α, it does not provide a detailed analysis of how different privacy budget values affect the optimal α across various datasets and model architectures.
- What evidence would resolve it: An extensive study of the optimal α values for different privacy budget levels (ϵ) on various datasets and model architectures, showing the impact of the privacy budget on the optimal α.

### Open Question 3
- Question: What is the impact of the warm-up training with public data on the convergence and the optimal value of the weighting coefficient α?
- Basis in paper: [explicit] The paper mentions that a warm-up training with a small amount of public data can lead to faster convergence speed, higher accuracy, and smaller loss. However, it does not provide a detailed analysis of the impact of warm-up training on the optimal α value.
- Why unresolved: While the paper demonstrates the benefits of warm-up training, it does not explore how the warm-up training affects the optimal α value and the convergence of the model.
- What evidence would resolve it: A comprehensive study comparing the optimal α values and convergence rates with and without warm-up training on various datasets and model architectures.

## Limitations

- The optimal α formula relies on theoretical assumptions that may not hold in practice for complex models or noisy datasets
- The empirical validation is limited to a few standard vision and language tasks with fixed privacy budgets
- The convergence proof assumes i.i.d. gradient sampling and Lipschitz smoothness, which may not hold in practice

## Confidence

- **High** for the claim that coupling public and private gradients improves the utility-privacy trade-off compared to using either dataset alone, supported by empirical results across multiple tasks
- **Medium** for the theoretical derivation of the optimal α and its dependence on hyperparameters, as the proof is rigorous but the practical applicability may be limited by assumptions
- **Low** for the claim that the optimal α can be easily computed from the given formula in Corollary 4.3.2, as the formula's dependence on task-specific parameters is not fully explored

## Next Checks

1. **Validate the optimal α formula**: Recompute α from Corollary 4.3.2 for each task using reported hyperparameters and verify if the stated values match the theoretical prediction

2. **Test robustness to distribution shift**: Evaluate the coupling method on a split of the training data where public and private subsets have different label distributions to assess sensitivity to data heterogeneity

3. **Explore privacy budget sensitivity**: Run experiments with a range of ε values (e.g., ε ∈ {0.5, 1, 2, 4}) to determine how the optimal α and overall performance scale with varying privacy constraints