---
ver: rpa2
title: HPE:Answering Complex Questions over Text by Hybrid Question Parsing and Execution
arxiv_id: '2305.07789'
source_url: https://arxiv.org/abs/2305.07789
tags:
- question
- arxiv
- questions
- answer
- h-expression
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the challenge of answering complex questions
  over text by proposing a hybrid framework combining neural and symbolic reasoning.
  The key idea is to parse complex questions into an intermediate representation called
  H-expression, which consists of simple questions (primitives) and symbolic operations
  (JOIN, AND, COMPARE, MINUS, ADDITION).
---

# HPE:Answering Complex Questions over Text by Hybrid Question Parsing and Execution

## Quick Facts
- arXiv ID: 2305.07789
- Source URL: https://arxiv.org/abs/2305.07789
- Reference count: 9
- Key outcome: Outperforms existing methods on MuSiQue, 2WikiQA, HotpotQA, and NQ in supervised, few-shot, and zero-shot settings by combining neural and symbolic reasoning through H-expressions.

## Executive Summary
This work addresses the challenge of answering complex questions over text by proposing a hybrid framework combining neural and symbolic reasoning. The key idea is to parse complex questions into an intermediate representation called H-expression, which consists of simple questions (primitives) and symbolic operations (JOIN, AND, COMPARE, MINUS, ADDITION). An H-parser converts questions to H-expressions, while a hybrid executor uses a neural reader to answer primitive questions and deterministic rules to execute symbolic operations, backtracking to derive the final answer. Experiments on MuSiQue, 2WikiQA, HotpotQA, and NQ show that this approach outperforms existing methods in supervised, few-shot, and zero-shot settings. The H-expression format offers better interpretability and precision compared to end-to-end neural approaches while preserving the advantages of neural readers for simple questions.

## Method Summary
The HPE framework uses a two-stage process: First, a T5-based H-parser converts complex questions into H-expressions consisting of primitives (single-hop questions) and symbolic operations. Second, a hybrid executor compiles these expressions into binary trees and uses a FiD neural reader to answer primitives while applying deterministic rules for symbolic operations like JOIN, AND, COMPARE, MINUS, and ADDITION. The approach decouples question parsing from answer generation, allowing better generalization to unseen questions. The model is pre-trained on PAQ and fine-tuned on QA datasets.

## Key Results
- Outperforms existing methods on MuSiQue, 2WikiQA, HotpotQA, and NQ in supervised settings
- Demonstrates strong few-shot performance (as few as 32 examples)
- Shows zero-shot capability on MuSiQue without requiring any training data from that dataset

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The H-expression format allows complex questions to be decomposed into single-hop primitives connected by symbolic operations, which can then be executed deterministically using a neural reader for each primitive.
- Mechanism: The H-parser converts a complex question into an intermediate H-expression consisting of primitives (single-hop questions) and operations (JOIN, AND, COMPARE, MINUS, ADDITION). The H-executor then compiles this into a binary tree structure, executes primitives using a neural reader, and applies symbolic rules to combine answers in a bottom-up manner.
- Core assumption: Single-hop questions are sufficiently easier to answer than multi-hop questions, and symbolic operations can correctly combine primitive answers to derive the final answer.
- Evidence anchors:
  - [abstract]: "H-expression is introduced as a simple explicit representation of original complex questions, which in the fashion of only contain primitives and operations as in (Liu et al., 2022)."
  - [section]: "We define a primitive as a single-hop question, which is the atomic element consisting of the complex question. We use the operation to represent the relation between primitives."
  - [corpus]: Weak - the corpus mentions related work on semantic parsing but doesn't directly support the specific claim about H-expressions improving performance on complex questions.
- Break condition: If single-hop questions are not sufficiently easier to answer, or if symbolic operations cannot correctly combine primitive answers, the H-expression approach will fail to improve performance.

### Mechanism 2
- Claim: Decoupling question parsing from answer generation allows better generalization to unseen questions, especially in few-shot and zero-shot settings.
- Mechanism: The framework splits the reasoning process into H-parser (which learns to structurally parse complex questions) and H-executor (which learns to resolve simple questions). This disentanglement allows each component to specialize and generalize better to new domains.
- Core assumption: Learning to parse complex questions structurally is different from learning to resolve simple questions, and these can be learned independently to improve overall performance.
- Evidence anchors:
  - [abstract]: "Our design, on the other hand, naturally splits the reasoning process into H-parser and H-executor, through which it intends to disentangle learning to parse complex questions structurally from learning to resolve simple questions therein."
  - [section]: "End-to-end neural approaches are data hungry and may significantly suffer from poor generalization to unseen data, especially in limited resource scenarios. Our design, on the other hand, naturally splits the reasoning process into H-parser and H-executor."
  - [corpus]: Weak - the corpus doesn't provide direct evidence for this specific claim about improved generalization through decoupling.
- Break condition: If the two components cannot be effectively learned independently, or if the gains from specialization are outweighed by the complexity of coordinating them, the decoupling approach may not improve generalization.

### Mechanism 3
- Claim: The explicit H-expression representation provides better interpretability by exposing the reasoning process, allowing easier identification and correction of errors.
- Mechanism: The execution process of the HPE model is the same as its reasoning process, with the H-expression providing a transparent representation of how the final answer is derived from primitive answers.
- Core assumption: A transparent representation of the reasoning process facilitates understanding and debugging of the model's predictions.
- Evidence anchors:
  - [abstract]: "The resulting H-expressions closely guide the execution process, offering higher precision besides better interpretability while still preserving the advantages of the neural readers for resolving its primitive elements."
  - [section]: "The execution process of our model is the same as its reasoning process. Transparency of our approach facilitates spotting and fixing erroneous cases."
  - [corpus]: Weak - the corpus doesn't provide direct evidence for this specific claim about improved interpretability through H-expressions.
- Break condition: If the H-expression representation is too complex or difficult to understand, or if the symbolic operations are not intuitive, the claimed interpretability benefits may not be realized.

## Foundational Learning

- Concept: Semantic parsing
  - Why needed here: The H-parser component needs to convert natural language questions into structured H-expressions, which is a form of semantic parsing.
  - Quick check question: Can you explain how semantic parsing differs from syntactic parsing, and why it's important for question answering over text?

- Concept: Multi-hop reasoning
  - Why needed here: The paper addresses complex questions that require reasoning across multiple pieces of evidence, which is a form of multi-hop reasoning.
  - Quick check question: What are the key challenges in multi-hop reasoning, and how does the H-expression approach address them?

- Concept: Neural module networks
  - Why needed here: The paper mentions neural module networks as related work, so understanding their approach and limitations is important for contextualizing the HPE framework.
  - Quick check question: How do neural module networks differ from the HPE approach, and what are the advantages and disadvantages of each?

## Architecture Onboarding

- Component map: Question → H-parser → H-expression → H-executor → Binary tree → Primitive execution (neural reader) → Symbolic operations → Final answer
- Critical path: Complex question is parsed into H-expression, compiled into binary tree, primitives answered by neural reader, symbolic operations executed deterministically, final answer derived
- Design tradeoffs: The HPE approach trades off some flexibility for improved interpretability and generalization. It requires more complex parsing and execution logic compared to end-to-end neural approaches.
- Failure signatures: If the H-parser fails to generate correct H-expressions, or if the symbolic operations cannot correctly combine primitive answers, the model will produce incorrect final answers. If the neural reader fails to answer single-hop questions accurately, this will also lead to incorrect final answers.
- First 3 experiments:
  1. Test the H-parser on a held-out set of complex questions to evaluate its ability to generate correct H-expressions.
  2. Test the H-executor with ground-truth H-expressions to isolate the performance of the symbolic execution component.
  3. Test the full HPE pipeline on a simple dataset (e.g., SQuAD) to ensure the basic functionality is working before moving to more complex datasets.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the exposure bias problem in the bottom-up question answering process be effectively addressed?
- Basis in paper: [inferred] The paper mentions that the bottom-up question answering process could suffer from exposure bias since the next step question answering may depend on the previous predicted answers.
- Why unresolved: The paper suggests that generating multiple answers using beam search in each step may greatly solve this issue, but it also notes that general beam search needs to be revised to provide sufficient coverage of semantic meanings.
- What evidence would resolve it: Experiments demonstrating the effectiveness of revised beam search methods in reducing exposure bias and improving the overall performance of the HPE framework.

### Open Question 2
- Question: How can the HPE framework be extended to handle new reasoning types without requiring retraining of the question parser?
- Basis in paper: [explicit] The paper acknowledges that when a new reasoning type comes, retraining the question parser is necessary.
- Why unresolved: The paper proposes using in-context learning in a large language model to generate H-expressions as a future work, but it does not provide a concrete solution.
- What evidence would resolve it: A proposed method or architecture that enables the HPE framework to adapt to new reasoning types without retraining the question parser, along with experimental results demonstrating its effectiveness.

### Open Question 3
- Question: How can the interpretability of the HPE framework be further improved to facilitate understanding and fixing errors?
- Basis in paper: [explicit] The paper highlights the strong interpretability of the HPE framework, exposing its underlying reasoning process, and mentions that once the source of an error is identified, it can be fixed.
- Why unresolved: While the paper demonstrates the interpretability of the HPE framework, it does not provide a detailed analysis of how to systematically understand and fix errors.
- What evidence would resolve it: A comprehensive error analysis framework that provides insights into the sources of errors, along with guidelines or tools for fixing them, accompanied by experimental results showing improved error handling and model performance.

## Limitations

- The H-expression approach requires more complex parsing and execution logic compared to end-to-end neural approaches
- The performance depends heavily on the accuracy of the H-parser in generating correct H-expressions
- When new reasoning types are introduced, retraining of the question parser is necessary

## Confidence

- High: Core empirical results showing HPE outperforms baselines on MuSiQue, 2WikiQA, HotpotQA, and NQ
- Medium: Claims about H-expressions enabling deterministic symbolic execution of complex questions
- Low: Claims about decoupling improving generalization, and claims about interpretability benefits

## Next Checks

1. **Ablation on primitive difficulty**: Systematically vary the difficulty of single-hop questions in the MuSiQue dataset and measure how this affects overall HPE performance to validate the core assumption that primitives are "easier" than full complex questions.

2. **Isolation of generalization factors**: Create controlled experiments comparing HPE to a monolithic neural model that also uses H-expressions as intermediate representations, but without the decoupled architecture, to isolate whether generalization improvements come from decoupling versus structure.

3. **Interpretability user study**: Conduct a small-scale user study where human evaluators attempt to trace through model predictions using H-expressions versus traditional attention visualizations, measuring time-to-understanding and error-identification accuracy.