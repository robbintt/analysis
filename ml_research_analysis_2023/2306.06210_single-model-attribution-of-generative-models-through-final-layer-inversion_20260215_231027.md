---
ver: rpa2
title: Single-Model Attribution of Generative Models Through Final-Layer Inversion
arxiv_id: '2306.06210'
source_url: https://arxiv.org/abs/2306.06210
tags:
- attribution
- which
- images
- samples
- generated
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of single-model attribution in
  the open-world setting, which involves determining whether a given sample was generated
  by a specific generative model or not. The authors propose FLIPAD, a novel approach
  based on final-layer inversion and anomaly detection.
---

# Single-Model Attribution of Generative Models Through Final-Layer Inversion

## Quick Facts
- arXiv ID: 2306.06210
- Source URL: https://arxiv.org/abs/2306.06210
- Reference count: 40
- Key outcome: Achieves >99% attribution accuracy on DCGAN, WGAN-GP, LSGAN, and EBGAN models using final-layer inversion and anomaly detection

## Executive Summary
This paper addresses the problem of single-model attribution in the open-world setting, where the goal is to determine whether a given sample was generated by a specific generative model. The authors propose FLIPAD, a novel approach that combines final-layer inversion with anomaly detection. By extracting features through inverting the final layer of a generative model and using these features to train an anomaly detector, FLIPAD can effectively distinguish between samples generated by the target model and those from other sources. The method is theoretically grounded, computationally efficient, and demonstrates state-of-the-art performance across multiple generative model architectures and datasets.

## Method Summary
FLIPAD addresses single-model attribution by extracting features through final-layer inversion and using these features to train an anomaly detector. The method formulates final-layer inversion as a convex lasso optimization problem, which is computationally efficient and theoretically sound. Features extracted from this inversion process are then used to train a DeepSAD anomaly detector that classifies samples as either generated by the target model or not. The approach requires collecting 10,000 generated samples from the target model and 10,000 real samples from the training set, then computing expected activations by passing noise samples through the model.

## Key Results
- Achieves over 99% average attribution accuracy across multiple generative model architectures (DCGAN, WGAN-GP, LSGAN, EBGAN)
- Outperforms existing attribution methods in the open-world setting
- Demonstrates effectiveness on both traditional GANs and modern diffusion models
- Maintains high accuracy across different domains (CelebA, LSUN datasets)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Final-layer inversion extracts distinguishing features by comparing to expected activations
- Mechanism: The method reconstructs plausible hidden representations that could have generated a given output, then uses anomaly detection on these activations to determine if the sample matches the model
- Core assumption: The generative model's activations follow a predictable distribution that differs systematically between real and generated samples
- Evidence anchors: [abstract] "extract features by inverting the final layer of the generative model and then using these features to train an anomaly detector", [section 4.2] "By reverting this process, i.e., inferring an appropriate hidden representation that is leading to a given sample, we obtain better evidence"
- Break condition: If the final activation is non-invertible or the model architecture makes final-layer inversion infeasible (e.g., with ReLU activations)

### Mechanism 2
- Claim: Optimization problem reduces to convex lasso for efficient, unique solutions
- Mechanism: The final-layer inversion problem can be reformulated as a lasso optimization, which is computationally tractable and guarantees a unique solution
- Core assumption: Convolution layers in the generator can be modeled as linear transformations with sparse solutions
- Evidence anchors: [section 4.2] "the utilized final-layer inversion can be reduced to a convex lasso optimization problem", [section B.1] "we can rewrite (5) as follows: ... which is equivalent to the well-known (modified) lasso optimization problem"
- Break condition: If the generator architecture deviates significantly from assumptions (e.g., complex skip connections or non-linear transformations at final layer)

### Mechanism 3
- Claim: Anomaly detection on extracted features generalizes better than direct image analysis
- Mechanism: Features derived from model inversion capture intrinsic model characteristics rather than superficial image artifacts, making them more robust to image perturbations
- Core assumption: Structural differences in activations between real and generated samples are more informative than pixel-level differences
- Evidence anchors: [section 5] "FLIPAD is able to achieve excellent results with an average attribution accuracy of over 99% in most cases", [section 4.1] "we can argue that xâ€² has not been generated by Gk" - demonstrating that hidden representations reveal generation feasibility
- Break condition: If the generative model produces samples with activations that closely mimic real data distributions

## Foundational Learning

- Concept: Convex optimization and lasso regression
  - Why needed here: The method relies on reformulating final-layer inversion as a convex lasso problem for efficient solution
  - Quick check question: What property of lasso regression ensures sparsity in the solution, and why is this beneficial for activation reconstruction?

- Concept: Anomaly detection and semi-supervised learning
  - Why needed here: The method uses DeepSAD, a semi-supervised anomaly detection technique, to classify samples based on extracted features
  - Quick check question: How does DeepSAD differ from standard supervised classification, and why is this distinction important for open-world attribution?

- Concept: Convolutional neural network architecture and feature extraction
  - Why needed here: Understanding how final-layer inversion works requires knowledge of how CNNs generate images through successive transformations
  - Quick check question: In a typical CNN generator, what role does the final activation layer play, and why is inverting it informative for attribution?

## Architecture Onboarding

- Component map: Input samples -> Final-layer inversion (lasso optimization) -> Feature extraction -> DeepSAD anomaly detection -> Attribution decision

- Critical path:
  1. Extract features by solving optimization problem (5)
  2. Train DeepSAD on extracted features from both generated and real samples
  3. Use trained DeepSAD to classify new samples

- Design tradeoffs:
  - Final-layer inversion vs. full model inversion: More efficient but requires invertible final activation
  - Feature dimensionality: Higher dimensions capture more information but increase computational cost
  - Anomaly detection method: DeepSAD chosen for high-dimensional data but other methods could be substituted

- Failure signatures:
  - Poor reconstruction accuracy in optimization problem indicates model architecture issues
  - DeepSAD failing to converge suggests feature quality problems or insufficient training data
  - High false positive rate may indicate need for threshold adjustment or better feature extraction

- First 3 experiments:
  1. Implement final-layer inversion on a simple DCGAN and verify feature extraction works
  2. Test DeepSAD on extracted features with synthetic inlier/outlier data to validate classification
  3. Evaluate attribution performance on a single model with known generated vs. real samples

## Open Questions the Paper Calls Out

- How does FLIPAD perform on generative models with non-invertible activation functions like ReLU?
- Can FLIPAD be extended to handle generative models with residual connections to the output?
- How does FLIPAD perform in scenarios where the generative model has been fine-tuned or altered after initial training?
- What is the impact of using different anomaly detection methods instead of DeepSAD in FLIPAD?

## Limitations
- Requires invertible final activation functions (not applicable to models with ReLU)
- Needs 10,000 generated samples from target model, which could be prohibitive for complex models
- Effectiveness depends on quality of anomaly detector and representativeness of training data

## Confidence
- High confidence: Mathematical formulation of final-layer inversion as convex lasso problem and computational efficiency
- Medium confidence: Attribution accuracy claims (>99% average) based on experiments with DCGAN, WGAN-GP, LSGAN, and EBGAN on CelebA and LSUN

## Next Checks
1. Verify that final-layer inversion produces meaningful features by comparing feature distributions between real and generated samples
2. Test attribution performance when the generative model is fine-tuned after initial training
3. Evaluate the impact of using different anomaly detection methods (e.g., SVDD, One-Class SVM) in place of DeepSAD