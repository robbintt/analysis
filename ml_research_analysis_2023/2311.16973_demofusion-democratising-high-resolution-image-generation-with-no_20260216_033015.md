---
ver: rpa2
title: 'DemoFusion: Democratising High-Resolution Image Generation With No $$$'
arxiv_id: '2311.16973'
source_url: https://arxiv.org/abs/2311.16973
tags:
- resolution
- demofusion
- image
- images
- diffusion
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper introduces DemoFusion, a training-free framework that
  enables high-resolution image generation by extending existing Latent Diffusion
  Models (LDMs) like SDXL from 1024x1024 to 4096x4096 or higher. DemoFusion achieves
  this by introducing three key mechanisms: Progressive Upscaling, Skip Residual,
  and Dilated Sampling.'
---

# DemoFusion: Democratising High-Resolution Image Generation With No $$$

## Quick Facts
- arXiv ID: 2311.16973
- Source URL: https://arxiv.org/abs/2311.16973
- Authors: 
- Reference count: 40
- Key outcome: Extends SDXL from 1024x1024 to 4096x4096 resolution without training, achieving SOTA FID (65.73) and IS (16.41) scores at 2048x2048.

## Executive Summary
DemoFusion is a training-free framework that extends existing Latent Diffusion Models (LDMs) like SDXL to generate high-resolution images up to 4096x4096 without additional training. The method introduces three key mechanisms—Progressive Upscaling, Skip Residual, and Dilated Sampling—that work together to progressively build high-resolution images while maintaining global semantic coherence and rich local details. DemoFusion achieves state-of-the-art performance on standard metrics at high resolutions while operating on a single RTX 3090 GPU, though it requires more inference time due to its progressive nature.

## Method Summary
DemoFusion is a training-free framework that extends existing LDMs to generate high-resolution images without additional training. It operates by progressively building high-resolution images through iterative "upsample-diffuse-denoise" loops, starting from low-resolution content generated by the base LDM. The framework introduces three key mechanisms: Progressive Upscaling, which enables resolution extension through iterative refinement; Skip Residual, which maintains global semantic consistency between resolution levels using noise-inverted representations; and Dilated Sampling, which improves global coherence by expanding the receptive field of denoising paths. The method achieves high-resolution generation (up to 4096x4096) on consumer-grade hardware but requires more inference time than standard generation.

## Key Results
- Achieves state-of-the-art FID score of 65.73 and IS score of 16.41 at 2048x2048 resolution
- Extends SDXL resolution from 1024x1024 to 4096x4096 without additional training
- Maintains global semantic coherence and rich local details better than baseline methods
- Operates on a single RTX 3090 GPU without requiring large GPU memory

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Progressive Upscaling allows DemoFusion to build high-resolution images from low-resolution content without requiring large GPU memory.
- Mechanism: The framework starts by generating a low-resolution image using the base LDM, then progressively upsamples and refines it through multiple "upsample-diffuse-denoise" loops. Each loop uses the noise-inverted lower-resolution image as initialization for the higher-resolution step.
- Core assumption: The base LDM has sufficient prior knowledge of localized patches at higher resolutions, as evidenced by its ability to generate partial high-resolution content when directly prompted.
- Evidence anchors:
  - [abstract] "We demonstrate that existing Latent Diffusion Models (LDMs) possess untapped potential for higher-resolution image generation."
  - [section] "However, we observe that text-to-image LDMs encounter many cropped photos during their training process. These cropped photos either exist inherently in the training set or are intentionally cropped for data augmentation."
  - [corpus] Weak: No direct corpus evidence for this specific progressive upscaling mechanism; relies on general LDM training behavior.
- Break condition: If the base LDM lacks sufficient prior knowledge of high-resolution patches, or if the noise inversion process fails to preserve semantic coherence between resolution levels.

### Mechanism 2
- Claim: Skip Residual maintains global semantic consistency between high and low-resolution images during progressive upscaling.
- Mechanism: Within each iteration, DemoFusion uses noise-inverted representations from the corresponding time-step in the preceding diffusion process as skip residuals. This fuses multiple "upsample-diffuse-denoise" loops with different intersection time-steps.
- Core assumption: Noise-inverted representations from lower resolutions can serve as effective global guidance for higher-resolution generation without losing semantic coherence.
- Evidence anchors:
  - [abstract] "DemoFusion achieves this by introducing three key mechanisms: Progressive Upscaling, Skip Residual, and Dilated Sampling."
  - [section] "We introduce the skip residual as a general solution, which can be informally considered as a weighted fusion of multiple 'upsample-diffuse-denoise' loops with a series of different intersection time-steps t."
  - [corpus] Weak: No direct corpus evidence for skip residual mechanism; relies on the authors' experimental findings.
- Break condition: If the weighted fusion of multiple time-steps introduces excessive noise or fails to maintain semantic coherence, or if the cosine decay factor is not properly tuned.

### Mechanism 3
- Claim: Dilated Sampling improves global semantic coherence by giving each denoising path more global context.
- Mechanism: Instead of dilating convolutional kernels, DemoFusion dilates the sampling within the latent representation. Global denoising paths are processed similarly to local paths in MultiDiffusion, with Gaussian filtering applied before dilated sampling.
- Core assumption: Expanding the receptive field through dilated sampling can provide better global context than overlapped patch denoising alone.
- Evidence anchors:
  - [abstract] "DemoFusion achieves this by introducing three key mechanisms: Progressive Upscaling, Skip Residual, and Dilated Sampling."
  - [section] "We introduce dilated sampling to give each denoising path more global context. The technique of dilating convolutional kernels to expand their receptive field is conventional in various dense prediction tasks."
  - [corpus] Weak: No direct corpus evidence for this specific dilated sampling approach; relies on general dilated convolution literature.
- Break condition: If the dilated sampling introduces excessive graininess or if the Gaussian filtering is insufficient to prevent blurriness in the final output.

## Foundational Learning

- Concept: Latent Diffusion Models (LDMs)
  - Why needed here: DemoFusion builds upon existing LDMs like SDXL, extending their resolution capabilities without additional training.
  - Quick check question: What are the two core components of the diffusion model that take place in the latent space?

- Concept: MultiDiffusion
  - Why needed here: DemoFusion extends MultiDiffusion's approach of fusing multiple overlapped denoising paths, but addresses its limitation of lacking global semantic coherence for specific objects.
  - Quick check question: How does MultiDiffusion achieve panorama generation, and what limitation does it have for object-centric images?

- Concept: Progressive Image Generation
  - Why needed here: The progressive upscaling mechanism relies on the principle of first synthesizing a semantically coherent overall structure at low resolution, then increasing resolution to add detailed local features.
  - Quick check question: What is the benefit of progressively generating images from low to high resolution in terms of computational resources and semantic coherence?

## Architecture Onboarding

- Component map: Progressive Upscaling -> Skip Residual -> Dilated Sampling
- Critical path: The progressive upscaling loop, which iteratively upsamples, diffuses, and denoises the latent representation.
- Design tradeoffs: DemoFusion trades increased inference time for higher resolution generation without additional training. The progressive nature allows for rapid preview generation but requires more passes overall.
- Failure signatures: DemoFusion may fail to generate coherent content when dealing with sharp close-up images, as it relies on the base LDM's prior knowledge of cropped images. Small repetitive content in background regions may also persist despite mitigation efforts.
- First 3 experiments:
  1. Implement Progressive Upscaling alone on SDXL to verify that the base LDM can generate higher-resolution content when initialized from noise-inverted low-resolution images.
  2. Add Skip Residual to the Progressive Upscaling implementation to test its effectiveness in maintaining global semantic coherence between resolution levels.
  3. Incorporate Dilated Sampling into the full DemoFusion pipeline and compare the results with MultiDiffusion and SDXL+BSRGAN on both global coherence and local detail metrics.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would DemoFusion perform with custom-trained LDMs specifically designed for the framework, rather than using pre-trained models like SDXL?
- Basis in paper: [inferred] The paper mentions that "Training a bespoke LDM for a DemoFusion-like framework may be a promising direction to explore" and that DemoFusion's performance is "directly correlated with the underlying LDM."
- Why unresolved: The paper only demonstrates DemoFusion on existing pre-trained models (SDXL, SD 1.5, SD 2.1) without exploring custom-trained models optimized for the progressive upscaling approach.
- What evidence would resolve it: Experimental results comparing DemoFusion performance on custom-trained LDMs versus pre-trained models, showing quantitative metrics (FID, IS, CLIP scores) and qualitative improvements in coherence and detail.

### Open Question 2
- Question: What is the optimal balance between stride size and computational efficiency for different types of images and content?
- Basis in paper: [explicit] The paper discusses that "the stride size dh and dw in MultiDiffusion determines the extent of the seam issue" and shows experimental results with different stride sizes, but doesn't provide a comprehensive analysis of optimal settings.
- Why unresolved: The paper only tests a few stride configurations and doesn't explore how stride size affects different image types (portraits, landscapes, abstract art) or content densities.
- What evidence would resolve it: Systematic experiments varying stride sizes across different image categories and content types, measuring both visual quality (seam visibility, detail preservation) and computational costs (inference time, memory usage).

### Open Question 3
- Question: How does DemoFusion's progressive generation approach affect user workflow and creative iteration compared to traditional high-resolution generation methods?
- Basis in paper: [explicit] The paper mentions that "progressive generation allows the users to preview low-resolution results rapidly, facilitating rapid iteration on the prompt" but doesn't provide user studies or workflow analysis.
- Why unresolved: The paper focuses on technical implementation and quantitative metrics but doesn't investigate the practical impact on creative workflows, user satisfaction, or prompt refinement processes.
- What evidence would resolve it: User studies comparing creative workflows using DemoFusion versus traditional methods, measuring metrics like iteration speed, user satisfaction, prompt refinement efficiency, and final output quality.

## Limitations
- DemoFusion requires significantly more inference time due to its progressive generation approach
- Performance depends heavily on the base LDM's prior knowledge of high-resolution patches
- May struggle with sharp close-up images and content requiring very fine details
- Requires careful hyperparameter tuning that may not generalize across all content types

## Confidence
- High Confidence: The progressive upscaling mechanism is well-supported by LDM training behavior on cropped images
- Medium Confidence: Skip residual mechanism shows promise but relies on empirical weighting that may need adjustment
- Low Confidence: Dilated sampling approach's superiority over traditional methods is asserted but not rigorously proven

## Next Checks
1. **Cross-model generalization test**: Evaluate DemoFusion with base models beyond SDXL (such as Stable Diffusion 1.5 or 2.1) to verify that the progressive upscaling mechanism works consistently across different LDM architectures.

2. **Content-type stress test**: Systematically test DemoFusion on sharp close-up images, text-heavy images, and scenes with repetitive patterns to identify specific failure modes and quantify the degradation in output quality.

3. **Computational efficiency analysis**: Benchmark DemoFusion against native high-resolution diffusion models (like SD3) on identical hardware to establish the actual trade-off between resolution capability and generation speed, including memory usage patterns across different resolution targets.