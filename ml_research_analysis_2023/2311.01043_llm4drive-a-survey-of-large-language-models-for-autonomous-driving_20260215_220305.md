---
ver: rpa2
title: 'LLM4Drive: A Survey of Large Language Models for Autonomous Driving'
arxiv_id: '2311.01043'
source_url: https://arxiv.org/abs/2311.01043
tags:
- driving
- autonomous
- language
- arxiv
- chen
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This survey paper provides a comprehensive review of Large Language
  Models (LLMs) for Autonomous Driving (LLM4AD), systematically categorizing and analyzing
  various applications including planning, perception, question answering, and generation.
  The paper highlights how LLMs can enhance autonomous driving by addressing limitations
  in current systems, such as the lack of transparency in end-to-end approaches and
  the challenge of handling rare driving scenarios.
---

# LLM4Drive: A Survey of Large Language Models for Autonomous Driving

## Quick Facts
- **arXiv ID**: 2311.01043
- **Source URL**: https://arxiv.org/abs/2311.01043
- **Reference count**: 16
- **Key outcome**: Comprehensive survey categorizing LLM applications in autonomous driving, highlighting interpretability benefits and few-shot learning potential

## Executive Summary
This survey provides a systematic review of Large Language Models (LLMs) for Autonomous Driving (LLM4AD), examining how these models can enhance traditional autonomous driving systems. The paper identifies four main application areas: planning, perception, question answering, and generation. LLMs offer potential solutions to key limitations in current autonomous driving approaches, particularly the lack of transparency in end-to-end systems and challenges in handling rare driving scenarios. The survey emphasizes that by combining LLMs with foundation vision models, autonomous driving systems could achieve open-world understanding and reasoning capabilities while maintaining interpretability.

## Method Summary
The paper reviews various LLM4AD approaches through systematic categorization of existing research. Methods include fine-tuning pre-trained LLMs on driving datasets and prompt engineering techniques to adapt LLMs to specific driving tasks. The survey analyzes different datasets used in the field (BDD-X, HAD, Talk2Car, DriveLM, DRAMA, Rank2Tell, NuPrompt, NuScenes-QA) and summarizes evaluation metrics across different tasks. Rather than presenting original experiments, the paper synthesizes findings from 16 referenced studies to provide a comprehensive overview of the current state of LLM applications in autonomous driving.

## Key Results
- LLMs can provide interpretability to autonomous driving systems, addressing the "black box" problem of end-to-end approaches
- LLMs enable few-shot learning capabilities that help handle rare driving scenarios not well-represented in training data
- Natural language interfaces powered by LLMs allow for more intuitive human-machine interaction in autonomous vehicles

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs enhance autonomous driving by providing interpretability and reasoning capabilities that address the "black box" problem of end-to-end systems.
- Mechanism: LLMs can process natural language inputs and outputs, enabling transparent decision-making explanations that traditional deep learning models cannot provide. This allows autonomous driving systems to not only make decisions but also justify them in human-understandable terms.
- Core assumption: LLMs possess sufficient common sense knowledge and reasoning capabilities to handle driving scenarios and explain decisions effectively.
- Evidence anchors:
  - [abstract] "end-to-end autonomous driving systems have the potential to avoid error accumulation due to their fully data-driven training process, although they often lack transparency due to their 'black box' nature"
  - [abstract] "Large language models (LLMs) have demonstrated abilities including understanding context, logical reasoning, and generating answers"
  - [section 3.1] "DriveGPT4 [Xu et al., 2023] presents a multimodal LLM...it also responds in real-time, explaining why the action was taken"
- Break condition: If LLM reasoning is not robust enough to handle edge cases or produces inconsistent explanations that don't match actual driving decisions.

### Mechanism 2
- Claim: LLMs enable few-shot learning capabilities that help autonomous driving systems handle rare scenarios not well-represented in training data.
- Mechanism: By leveraging the pre-trained knowledge embedded in LLMs, autonomous driving systems can adapt to novel situations with minimal additional training data, addressing the long-tail problem in driving scenarios.
- Core assumption: LLMs contain relevant general knowledge about driving situations and can transfer this knowledge to specific autonomous driving contexts.
- Evidence anchors:
  - [abstract] "By combining LLM with foundation vision models, it could open the door to open-world understanding, reasoning, and few-shot learning"
  - [section 1] "By leveraging the visual-language model (VLM)'s robust and comprehensive capabilities of open-world understanding and in-context learning, it becomes possible to address the long-tail problem for perception networks"
  - [section 2] "Large language models, with their extensive knowledge base and exceptional generalization, could facilitate easier learning of complex driving behaviors"
- Break condition: If the LLM's pre-trained knowledge is not sufficiently aligned with real-world driving scenarios or cannot be effectively transferred to specific driving contexts.

### Mechanism 3
- Claim: LLMs improve autonomous driving planning through natural language interfaces that allow for more intuitive human-machine interaction.
- Mechanism: By accepting natural language commands and generating language-based responses, LLMs enable users to communicate with autonomous vehicles in ways similar to human-human interaction, improving usability and trust.
- Core assumption: Natural language communication is more intuitive and effective for human-machine interaction than traditional control interfaces.
- Evidence anchors:
  - [section 3.1] "Talk2BEV [Dewangan et al., 2023] introduces a large vision-language model (LVLM) interface for bird's-eye view (BEV) maps in autonomous driving contexts"
  - [section 3.1] "Receive Reason and React [Cui et al., 2023b] and Drive as You Speak [Cui et al., 2023a] integrate the language and reasoning capabilities of LLMs into autonomous vehicles"
  - [section 3.3] "Question-Answering is an important task that has a wide range of applications in intelligent transportation, assisted driving, and autonomous vehicles"
- Break condition: If natural language interfaces prove to be less efficient or reliable than traditional control methods, especially in time-critical driving situations.

## Foundational Learning

- Concept: Vision-Language Model (VLM) integration
  - Why needed here: LLMs alone cannot directly process visual sensor data; they need to be integrated with vision models to understand driving scenes.
  - Quick check question: How do VLMs bridge the gap between textual reasoning and visual perception in autonomous driving?

- Concept: Prompt engineering and fine-tuning
  - Why needed here: LLMs require adaptation to specific driving tasks through either prompt design or fine-tuning on driving datasets.
  - Quick check question: What are the tradeoffs between prompt engineering and fine-tuning approaches for LLM adaptation in autonomous driving?

- Concept: Chain-of-thought reasoning
  - Why needed here: Autonomous driving requires complex reasoning that benefits from breaking down decisions into sequential logical steps.
  - Quick check question: How does chain-of-thought prompting improve the quality of driving decisions compared to direct prompting?

## Architecture Onboarding

- Component map: Perception module (vision-language model for scene understanding) → Planning module (LLM for decision-making and reasoning) → Question Answering module (for human interaction) → Generation module (for synthetic data creation)

- Critical path: The most critical path involves perception → planning → action, where the vision-language model provides scene understanding to the LLM, which then makes driving decisions that are executed by the vehicle control system.

- Design tradeoffs: Tradeoffs include (1) Model size vs. inference speed, (2) Fine-tuning vs. prompt engineering for adaptation, (3) Rule-based safety constraints vs. LLM flexibility, (4) Centralized LLM vs. distributed specialized models

- Failure signatures: Common failure modes include (1) Hallucinations in decision-making, (2) Inconsistent explanations between decisions and justifications, (3) Slow inference times for real-time driving, (4) Poor generalization to novel scenarios

- First 3 experiments:
  1. Implement a basic VQA system using an existing LLM and vision model to answer simple driving scene questions
  2. Create a prompt-based planning system that takes in bird's-eye view maps and outputs driving commands
  3. Build a synthetic data generation pipeline using diffusion models conditioned on driving scenarios

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we develop a unified metric for evaluating LLM4AD performance across planning, perception, and generation tasks?
- Basis in paper: [explicit] The paper explicitly states that "LLM4AD regarding the planning task lacks a unified metric and cannot uniformly evaluate the pros and cons between each method and traditional counterparts."
- Why unresolved: Current LLM4AD research uses diverse and task-specific metrics (e.g., BLEU-4, METEOR, L2 error, collision rate), making it difficult to compare performance across different applications and methods.
- What evidence would resolve it: A standardized evaluation framework with consistent metrics applicable to all LLM4AD tasks, validated through extensive benchmarking on diverse datasets.

### Open Question 2
- Question: How can we effectively integrate LLMs with traditional autonomous driving modules to create hybrid systems that leverage the strengths of both approaches?
- Basis in paper: [inferred] The paper discusses the limitations of both traditional modular systems (cumulative errors) and end-to-end approaches (lack of transparency), suggesting that LLMs could address these issues by providing interpretability and reasoning capabilities.
- Why unresolved: While the paper highlights the potential benefits of combining LLMs with traditional modules, it doesn't provide concrete solutions for integration or address challenges such as maintaining real-time performance and handling the computational overhead of LLMs.
- What evidence would resolve it: Development and demonstration of hybrid autonomous driving systems that combine LLM-based reasoning with traditional perception and planning modules, showing improved performance and interpretability compared to purely traditional or purely LLM-based approaches.

### Open Question 3
- Question: What are the long-term safety and reliability implications of using LLMs in autonomous driving systems, particularly in edge cases and rare scenarios?
- Basis in paper: [explicit] The paper mentions that LLMs could help address the "long-tail problem" for perception networks and provide intuitive explanations for decisions, but doesn't discuss long-term safety implications.
- Why unresolved: While LLMs show promise in handling complex scenarios, their behavior in rare or unexpected situations is not well-understood. The potential for "hallucinations" or incorrect reasoning could pose safety risks in autonomous driving applications.
- What evidence would resolve it: Extensive testing of LLM-based autonomous driving systems in simulated and real-world edge cases, demonstrating consistent safety and reliability performance over extended periods.

## Limitations

- The survey lacks quantitative benchmarks comparing LLM-based approaches against traditional autonomous driving methods
- Published in early 2024, the survey may miss rapid developments in the field, particularly regarding more recent foundation models
- Claims about LLM capabilities are based on general LLM literature rather than specifically validated in autonomous driving contexts

## Confidence

- High confidence: The survey's categorization of LLM4AD applications and methodology types is well-supported by the cited literature
- Medium confidence: Claims about LLMs enabling few-shot learning and handling long-tail scenarios are reasonable extrapolations but lack direct autonomous driving validation
- Low confidence: Specific performance claims and quantitative comparisons between different LLM4AD approaches are not supported by the survey data

## Next Checks

1. Implement a controlled experiment comparing LLM-based planning approaches against traditional rule-based planners on standardized driving scenarios, measuring safety metrics (collision rate, rule compliance) and computational efficiency

2. Test the few-shot learning claims by evaluating how well LLMs adapt to rare driving scenarios (extreme weather, unusual obstacles) with minimal fine-tuning data compared to traditional perception systems

3. Develop a framework for incorporating formal safety guarantees with LLM-based decision-making to address the critical concern of maintaining safety standards in autonomous systems that use probabilistic language models