---
ver: rpa2
title: 'FormalGeo: An Extensible Formalized Framework for Olympiad Geometric Problem
  Solving'
arxiv_id: '2310.18021'
source_url: https://arxiv.org/abs/2310.18021
tags:
- geometric
- geometry
- search
- formal
- property
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents FormalGeo, the first comprehensive formalized
  framework for solving International Mathematical Olympiad (IMO)-level geometric
  problems. The authors introduce the Geometry Formalization Theory (GFT) to unify
  geometric knowledge representation and develop a formal system consisting of 88
  predicates and 196 theorems.
---

# FormalGeo: An Extensible Formalized Framework for Olympiad Geometric Problem Solving

## Quick Facts
- arXiv ID: 2310.18021
- Source URL: https://arxiv.org/abs/2310.18021
- Reference count: 40
- Key outcome: FormalGeo is the first comprehensive formalized framework for solving IMO-level geometric problems, achieving 39.7% problem-solving accuracy using forward random search with 2.42% failure rate for backward depth-first search.

## Executive Summary
FormalGeo presents a comprehensive formalized framework for solving International Mathematical Olympiad (IMO)-level geometric problems. The authors introduce the Geometry Formalization Theory (GFT) to unify geometric knowledge representation and develop a formal system consisting of 88 predicates and 196 theorems. The framework includes FGPS, a Python-based solver using forward/backward search algorithms, and the FormalGeo7k dataset with 6,981 annotated geometry problems. Experiments demonstrate the effectiveness of the backward depth-first search method with only 2.42% failure rate, while the forward random search method achieves 39.7% problem-solving accuracy.

## Method Summary
FormalGeo uses a search-based approach to geometric problem solving, employing forward and backward search strategies with various algorithms (BFS, DFS, RS, BS). The system represents geometric knowledge through 88 predicates and 196 theorems defined in Geometric Predicate Logic (GPL), which unifies logical operations, geometric relations, and algebraic calculations. The FGPS solver executes theorem applications through a structured process involving parsing, ordering, and execution phases. Problems are solved by expanding goals into subgoals and recursively working toward known conditions, with search tree pruning strategies to manage combinatorial explosion.

## Key Results
- Backward depth-first search method achieves only 2.42% problem-solving failure rate
- Forward random search method yields 39.7% problem-solving accuracy on FormalGeo7k dataset
- Formal system consists of 88 predicates and 196 theorems covering comprehensive geometric knowledge
- FGPS implemented in Python demonstrates practical effectiveness for SAT-level geometry problems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FormalGeo unifies geometric knowledge representation through GFT, reducing combinatorial explosion in theorem search.
- Mechanism: GFT introduces geometry ontology and representation theory that systematically maps geometric knowledge across four quadrants (static/dynamic × shape/number). This creates a consistent formal system where all geometric relations, logical operations, and algebraic calculations are unified under geometric predicate logic (GPL).
- Core assumption: A unified formal representation prevents redundant theorem applications and inconsistent knowledge states during search.
- Evidence anchors:
  - [abstract]: "We propose the geometry formalization theory (GFT) to guide the development of the geometry formal system"
  - [section]: "Geometry formalization theory investigates how to express geometric knowledge using formal language"
  - [corpus]: Weak evidence - no direct comparison to non-unified systems, but neighboring work (FGeo-DRL) builds on FormalGeo suggesting its effectiveness
- Break condition: If the unified representation introduces overhead that outweighs search pruning benefits, or if geometric knowledge domains are not properly covered by the four quadrants.

### Mechanism 2
- Claim: The backward depth-first search method achieves low failure rate (2.42%) by working from goals to known conditions.
- Mechanism: Backward search starts from problem goals, expands them into subgoals using applicable theorems, and recursively works toward known conditions. This approach naturally prunes irrelevant theorem applications since only theorems that can contribute to goal derivation are considered.
- Core assumption: Problem-solving goals have a more constrained search space than starting from known conditions, leading to more efficient pruning.
- Evidence anchors:
  - [abstract]: "The backward depth-first search method only yields a 2.42% problem-solving failure rate"
  - [section]: "Backward search starts from the problem-solving goal, expands it into multiple sub-goals, and repeats this process until all sub-goals are resolved"
  - [corpus]: Weak evidence - no direct comparison with alternative search strategies in corpus, but FGeo-HyperGNet builds on this suggesting practical effectiveness
- Break condition: When problems have multiple equally valid solution paths, backward search may explore suboptimal branches before finding correct ones, increasing search time.

### Mechanism 3
- Claim: GPL executor's parsing and ordering phases significantly improve theorem application efficiency.
- Mechanism: The GPL executor expands complex GPL statements into disjunctive normal form (DNF), reorders statements to prioritize geometric constraints over algebraic constraints, and executes relations in an order that minimizes combinatorial explosion. This structured execution reduces unnecessary equation solving attempts.
- Core assumption: Geometric constraints can be evaluated more efficiently than algebraic constraints, and early filtering of invalid geometric relations prevents expensive algebraic computations.
- Evidence anchors:
  - [section]: "The process of geometric problem solving can be represented as a sequence of theorem applications. Theorems are defined using GPL"
  - [section]: "The GPL executor expands complex GPL statements into disjunctive normal form (DNF) using the distributive law"
  - [corpus]: Weak evidence - no direct performance measurements comparing different execution orders, but FGeo-TP builds on this suggesting practical value
- Break condition: If the reordering heuristics are not optimal for specific problem types, leading to increased execution time despite theoretical improvements.

## Foundational Learning

- Concept: Geometric Predicate Logic (GPL)
  - Why needed here: GPL provides the unified formal language that allows mechanical execution of geometric theorems, enabling automated reasoning
  - Quick check question: What are the three main operations in GPL and what logical operations do they correspond to?

- Concept: Topological Mapping Method
  - Why needed here: This method transforms geometric diagrams into formal representations that computers can process, bridging the gap between visual and symbolic geometric knowledge
  - Quick check question: How does the topological mapping method handle non-closed geometric figures?

- Concept: Search Tree Pruning Strategies
  - Why needed here: The vast search space in geometric problem solving requires efficient pruning to avoid combinatorial explosion and achieve reasonable solution times
  - Quick check question: What is the main difference between forward and backward search approaches in terms of search space exploration?

## Architecture Onboarding

- Component map: Input problem → CDL Parser → Data Loader (validity check and diagram construction) → Core Solving Engine (GPL execution and equation solving) → Output solution. The GPL Executor is the bottleneck as it handles all theorem applications.
- Critical path: Input problem → CDL Parser → Data Loader (validity check and diagram construction) → Core Solving Engine (GPL execution and equation solving) → Output solution. The GPL Executor is the bottleneck as it handles all theorem applications.
- Design tradeoffs: The system prioritizes extensibility and consistency over raw performance. Using formal languages and unified representation adds overhead but enables integration with AI systems and ensures correctness. The tradeoff between forward and backward search represents different balances of search space exploration and pruning efficiency.
- Failure signatures: High timeout rates indicate insufficient pruning or overly complex problems for current theorem library. Unsolved problems with short search times suggest missing relevant theorems. Invalid condition errors point to parser or diagram construction issues. Inconsistent solutions indicate problems with GPL execution or equation solving.
- First 3 experiments:
  1. Measure the impact of different GPL statement orderings on execution time for a fixed set of theorems
  2. Compare forward vs backward search success rates on problems of varying difficulty levels
  3. Test the topological construction method's correctness by comparing reconstructed diagrams against originals for various problem types

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal abstract hierarchy level for theorem definitions to minimize problem-solving time?
- Basis in paper: [explicit] The paper discusses how different ways of defining theorems (direct combination vs. decomposition) can impact problem-solving speed, and mentions that FormalGeo tends to favor higher abstract hierarchy to minimize solving time.
- Why unresolved: The paper states that they leave more detailed comparative experiments and mechanistic analyses for future work.
- What evidence would resolve it: Systematic experiments comparing problem-solving times across different theorem definition hierarchies (K values) with varying problem complexities.

### Open Question 2
- Question: How can deep learning techniques be effectively integrated into the search tree pruning process to reduce the 39.7% failure rate in forward random search?
- Basis in paper: [explicit] The paper mentions that incorporating deep learning techniques could achieve lower failure rates than the current 39.7% problem-solving accuracy of forward random search.
- Why unresolved: The paper states this as a future direction but doesn't provide implementation details or experimental results.
- What evidence would resolve it: Implementation and evaluation of deep learning-based search tree pruning methods, with quantitative comparison to current search strategies.

### Open Question 3
- Question: What is the theoretical upper bound of problem-solving success rate given the current formal system's 88 predicates and 196 theorems?
- Basis in paper: [inferred] The paper shows that even with sophisticated search strategies, success rates drop significantly for harder problems (39.7% overall, much lower for difficult problems), suggesting limitations in the formal system's expressiveness or completeness.
- Why unresolved: The paper doesn't analyze the formal system's theoretical limitations or completeness relative to IMO-level problems.
- What evidence would resolve it: Formal proof of the completeness or incompleteness of the current formal system for IMO-level problems, and identification of specific theorem gaps.

## Limitations

- The 39.7% accuracy rate is based on SAT-level problems and may not generalize to genuine IMO-level problems
- The system lacks baseline comparisons with existing geometry solvers to establish relative performance
- The claim of "comprehensive formalization" is not empirically validated for all possible IMO geometry problems

## Confidence

**High Confidence**: The formalization framework (GFT) and its implementation through 88 predicates and 196 theorems is well-specified and technically sound. The search-based solving approach using forward/backward search is clearly described and methodologically rigorous.

**Medium Confidence**: The 39.7% problem-solving accuracy claim is supported by experiments but lacks comprehensive validation across diverse problem types and difficulty levels. The effectiveness of GPL execution and pruning strategies is theoretically justified but not empirically benchmarked against alternatives.

**Low Confidence**: The assertion that this is the "first comprehensive formalized framework" for IMO-level problems cannot be fully verified without exhaustive literature review. The practical limitations for real-world IMO competition problems remain unclear.

## Next Checks

1. **Cross-Dataset Validation**: Test FGPS on a separate dataset of verified IMO-level geometry problems (distinct from FormalGeo7k) to assess generalizability beyond SAT-level problems.

2. **Comparative Benchmarking**: Implement and compare against at least two alternative geometry solvers (symbolic or neural) on the same problem set to establish relative performance and identify specific strengths/weaknesses.

3. **Failure Mode Analysis**: Systematically analyze the 60.3% of problems that remain unsolved to categorize failure patterns (missing theorems, search inefficiency, parsing errors) and identify specific extensions needed for comprehensive coverage.