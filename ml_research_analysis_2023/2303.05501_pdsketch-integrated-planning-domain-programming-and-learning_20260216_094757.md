---
ver: rpa2
title: 'PDSketch: Integrated Planning Domain Programming and Learning'
arxiv_id: '2303.05501'
source_url: https://arxiv.org/abs/2303.05501
tags:
- item
- robot
- action
- learning
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces PDSketch, a framework integrating model learning
  and online planning for building flexible and general robots. PDSketch allows users
  to define high-level structures in transition models, such as object and feature
  dependencies, which are then filled in by trainable neural networks.
---

# PDSketch: Integrated Planning Domain Programming and Learning

## Quick Facts
- arXiv ID: 2303.05501
- Source URL: https://arxiv.org/abs/2303.05501
- Reference count: 40
- One-line primary result: PDSketch improves data efficiency, model generalization, and runtime efficiency in planning tasks by integrating model learning with structured domain representations

## Executive Summary
PDSketch introduces a framework that integrates model learning and online planning by allowing users to define high-level structures in transition models, such as object and feature dependencies. These structures are filled in by trainable neural networks, and domain-independent planning heuristics are automatically generated from the defined structures. The framework demonstrates significant improvements in data efficiency, model generalization, and runtime efficiency compared to unstructured models and baselines on BabyAI and Painting Factory environments.

## Method Summary
PDSketch combines model learning with online planning by defining structured transition models that encode locality and sparsity properties of environmental dynamics. Users specify domain structure in a first-order logic-based language, including predicates, actions, and types. Neural networks learn the grounding functions for these structures from trajectory data. The framework generates domain-independent heuristics from the structured models, which accelerate A* planning for novel goals. Training uses a bisimulation objective combining goal prediction and next-state prediction losses, while planning uses heuristics derived from the structured representations.

## Key Results
- PDSketch models with more structure (PDS-Abs and PDS-Rob) outperform baselines by significant margins, achieving success rates up to 1.00 in BabyAI and 0.99 in Painting Factory
- Domain-independent heuristics derived from structured models improve planning efficiency by 5x compared to learning-based heuristics at 0.8 success rate
- PDSketch demonstrates compositional generalization, enabling planning for unseen tasks with new first-order logic goal descriptions without additional training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Structured transition models with locality and sparsity improve data efficiency by reducing the hypothesis space neural networks must explore
- Mechanism: By encoding object-centric, factored representations and sparse action effects, PDSketch constrains learning to only model relevant dependencies rather than learning a monolithic transition function
- Core assumption: Environmental dynamics are indeed local and sparse, accurately representable using object-centric factored structures
- Evidence anchors: [abstract], [section 2.1]
- Break condition: Fails in environments with dense, global interactions or long-range dependencies

### Mechanism 2
- Claim: Domain-independent heuristics derived from structured models accelerate planning runtime efficiency by providing informative guidance to A* search
- Mechanism: PDSketch automatically generates optimistic or discretized approximations of transition models usable with standard planning heuristics like hFF
- Core assumption: Structured representation is rich enough to approximate true transition dynamics accurately for heuristic purposes
- Evidence anchors: [abstract], [section 2.3], [section 3.1]
- Break condition: Heuristics become too optimistic or coarse, failing to guide search effectively

### Mechanism 3
- Claim: PDSketch language enables compositional generalization to novel goals and environments by grounding predicates and actions in learned neural networks
- Mechanism: Users define high-level structures in first-order logic while the system learns grounding functions, allowing application to new goal specifications without retraining
- Core assumption: Learned predicate groundings generalize across different object instances and environmental configurations
- Evidence anchors: [abstract], [section 3.1], [section 3.2]
- Break condition: Predicate groundings fail to generalize to novel object types or configurations

## Foundational Learning

- Concept: Object-centric state representation
  - Why needed here: PDSketch assumes states are factored into objects and their attributes
  - Quick check question: If an image shows a robot and two blocks, what would the factored state representation look like in PDSketch?

- Concept: First-order logic for goal specification
  - Why needed here: Goals are expressed as first-order logic formulas over predicates
  - Quick check question: How would you express "all red blocks are on blue blocks" in PDSketch's goal language?

- Concept: Neural network parameter sharing via PDSketch
  - Why needed here: PDSketch automatically shares neural network parameters across object instances
  - Quick check question: In the PDSketch definition `(??f (item-image ?o))`, what does the `??f` function do, and how is it applied?

## Architecture Onboarding

- Component map: PDSketch domain definition -> Neural modules -> State encoder -> Planner (A* with heuristics) -> Primitive policies

- Critical path: 1. Define domain structure in PDSketch language, 2. Train neural modules on demonstration data, 3. Compile model into planner with heuristics, 4. Execute planning for new goals

- Design tradeoffs:
  - More structure vs. flexibility: Detailed structures improve data efficiency but require more domain knowledge
  - Optimistic vs. And-Or compilation: Optimistic is faster but less accurate; And-Or is more precise but computationally heavier
  - Discretization granularity: Finer discretization gives better heuristics but increases planning complexity

- Failure signatures:
  - Poor data efficiency: Model not capturing relevant dependencies (check structure definition)
  - Planning failures: Heuristics too optimistic or too coarse (check compilation method)
  - Generalization failures: Learned groundings not robust (check training data diversity)

- First 3 experiments:
  1. Implement a simple PDSketch domain (e.g., BabyAI) with minimal structure and verify basic planning works
  2. Add one structured predicate (e.g., "facing") and measure impact on data efficiency
  3. Compare optimistic vs. And-Or compilation on a continuous domain and measure planning runtime

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PDSketch handle uncertainty and stochasticity in the environment during planning?
- Basis in paper: [explicit] The paper mentions recovering the most accurate possible deterministic model on the latent space
- Why unresolved: The paper doesn't elaborate on handling uncertainty beyond assuming a deterministic model
- What evidence would resolve it: Experiments showing PDSketch's performance in stochastic environments or theoretical analysis of uncertainty handling

### Open Question 2
- Question: What is the computational complexity of generating domain-independent heuristics for PDSketch models?
- Basis in paper: [inferred] The paper mentions using hFF heuristics and discretization but doesn't discuss computational complexity
- Why unresolved: Complexity of generating heuristics for complex, high-dimensional continuous spaces isn't addressed
- What evidence would resolve it: Analysis of time and space complexity for heuristic generation in various PDSketch domains

### Open Question 3
- Question: How does PDSketch scale to environments with very large numbers of objects or complex relational structures?
- Basis in paper: [inferred] The paper shows results on BabyAI (up to 8 objects) and Painting Factory but doesn't explore scalability limits
- Why unresolved: Performance on larger, more complex environments is unknown
- What evidence would resolve it: Experiments with increasingly complex environments showing performance trends

## Limitations

- Experiments conducted on only two domains (BabyAI and Painting Factory) with relatively simple dynamics, raising questions about scalability to more complex environments
- Lack of ablation studies to isolate contributions of different structural components, making it difficult to determine which improvements come from structured representation versus other factors
- No analysis of failure cases or performance degradation when structure assumptions (locality, sparsity) are violated

## Confidence

- Structured transition models improving data efficiency: Medium
- Domain-independent heuristics accelerating planning runtime: Medium
- Compositional generalization through predicate grounding: High

## Next Checks

1. Test PDSketch on a domain with dense, non-local interactions to verify whether structured models maintain their data efficiency advantage or break down when locality assumptions are violated

2. Conduct controlled ablation experiments removing individual structural components (e.g., removing object dependencies, removing sparse action effects) to quantify each component's contribution to overall performance

3. Evaluate planning performance on problems requiring long-horizon reasoning beyond the training distribution to test the limits of compositional generalization claims