---
ver: rpa2
title: 'Unexplored Frontiers: A Review of Empirical Studies of Exploratory Search'
arxiv_id: '2312.13695'
source_url: https://arxiv.org/abs/2312.13695
tags:
- search
- exploratory
- information
- studies
- were
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This systematic review examines 231 exploratory search publications
  from 2010-2021, finding that the field is highly interdisciplinary but limited in
  scope. Most studies (77%) focus on evaluating experimental retrieval systems rather
  than investigating user search processes, with a disproportionate emphasis on Computer
  Science literature search.
---

# Unexplored Frontiers: A Review of Empirical Studies of Exploratory Search

## Quick Facts
- arXiv ID: 2312.13695
- Source URL: https://arxiv.org/abs/2312.13695
- Reference count: 40
- Most studies focus on evaluating experimental retrieval systems rather than investigating user search processes, with disproportionate emphasis on Computer Science literature search

## Executive Summary
This systematic review analyzes 231 empirical studies of exploratory search published between 2010-2021, revealing significant limitations in current research practices. The field is highly interdisciplinary but predominantly focused on Computer Science literature search, using convenience samples of students and academics. Studies overwhelmingly employ quantitative evaluation methods with inconsistent metrics, primarily using web and scientific literature domains. The review identifies a critical need for broader domain coverage, more diverse participant recruitment, greater use of qualitative methods, and standardized evaluation metrics to advance the field beyond its current WEIRD population focus.

## Method Summary
The review employed QUOROM statement-based systematic methodology across ACM Digital Library, Web of Science, and ScienceDirect databases using "exploratory search" as search term. After removing duplicates and applying inclusion criteria (peer-reviewed, English language, substantively about exploratory search), 231 publications underwent concept-centric coding for bibliographic data, study settings, and evaluation methodologies. The analytical framework examined publication venues, search domains, task types, experimental designs, participant characteristics, and data collection methods through structured coding units.

## Key Results
- 77% of studies focus on evaluating experimental retrieval systems rather than investigating user search processes
- 75% of studies use convenience samples composed exclusively of students and other academics
- Majority of studies use web and scientific literature domains with within-subject designs and small sample sizes (median 24 participants)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Systematic review methodology reveals consistent patterns across 231 exploratory search publications from 2010-2021
- Mechanism: Structured coding of bibliographic data, study settings, and evaluation methodologies using pre-defined analytical units creates reproducible insights about research trends
- Core assumption: The selected sample of 231 publications represents a comprehensive view of the field's empirical research practices

### Mechanism 2
- Claim: Interdisciplinary research in exploratory search creates complementary methodological approaches across information science, information systems, and human-computer interaction
- Mechanism: Different disciplines contribute distinct research traditions - information science focuses on information seeking behaviors, information systems on technological solutions, and HCI on user interface design and experience
- Core assumption: The disciplinary boundaries identified in publication venues accurately reflect distinct research traditions and methodological approaches

### Mechanism 3
- Claim: Current evaluation practices in exploratory search research are limited by over-reliance on convenience samples and lack of standardized metrics
- Mechanism: Convenience sampling of students and academics combined with inconsistent evaluation metrics creates findings that may not generalize beyond WEIRD populations
- Core assumption: The methodological limitations identified (convenience samples, inconsistent metrics) actually impact the validity and generalizability of research findings

## Foundational Learning

- Systematic review methodology
  - Why needed here: Provides structured framework for analyzing large corpus of research literature and identifying patterns across publications
  - Quick check question: What are the key steps in conducting a systematic review according to QUOROM guidelines?

- Interdisciplinary research analysis
  - Why needed here: Understanding how different disciplines contribute distinct perspectives and methodologies to exploratory search research
  - Quick check question: How do information science, information systems, and human-computer interaction approaches differ in their focus on exploratory search?

- Research evaluation methodology
  - Why needed here: Critical for understanding the strengths and limitations of empirical studies in the field
  - Quick check question: What are the main differences between within-subject and between-subject experimental designs in exploratory search studies?

## Architecture Onboarding

- Component map:
  Literature search -> Duplicate removal -> Validity assessment -> Article coding -> Analysis and visualization -> Review synthesis

- Critical path:
  1. Database search and initial screening
  2. Duplicate removal and article selection
  3. Validity assessment and final selection
  4. Systematic coding of pre-defined analytical units
  5. Data analysis and pattern identification
  6. Critical discussion and synthesis

- Design tradeoffs:
  - Comprehensive vs. focused review scope (covering all empirical studies vs. specific aspects)
  - Manual coding vs. automated text analysis (ensuring accuracy vs. scalability)
  - Discipline-specific vs. cross-disciplinary analysis (depth vs. breadth of insights)

- Failure signatures:
  - High inter-rater disagreement during article selection (indicates unclear inclusion criteria)
  - Low consistency in coding across articles (suggests ambiguous analytical framework)
  - Dominant patterns driven by single prolific research groups (indicates potential bias)

- First 3 experiments:
  1. Replicate article selection process on smaller subset to validate inter-rater reliability
  2. Test coding framework on sample articles to refine analytical units
  3. Conduct sensitivity analysis by varying inclusion criteria to assess impact on findings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the key cognitive and behavioral differences between exploratory and lookup search tasks that current research has failed to adequately capture?
- Basis in paper: The review highlights that only 5.9% of studies contrasted exploratory and lookup search tasks, suggesting a gap in understanding fundamental differences between these search types.
- Why unresolved: Most studies focus on either exploratory or lookup search in isolation, rather than directly comparing them to identify distinct cognitive and behavioral patterns.
- What evidence would resolve it: Comparative studies using think-aloud protocols, eye tracking, and qualitative analysis to capture real-time cognitive processes during both search types.

### Open Question 2
- Question: How can exploratory search systems be designed to effectively adapt to users' changing information needs during search sessions?
- Basis in paper: The review notes that very few studies investigated how search systems could adapt to whether users were conducting lookup or exploratory search, indicating a gap in adaptive system design.
- Why unresolved: Current systems primarily focus on either exploratory or lookup search modes rather than dynamically adjusting to users' evolving needs during a session.
- What evidence would resolve it: Longitudinal studies tracking user behavior across multiple search sessions with adaptive interfaces that modify their behavior based on detected search patterns.

### Open Question 3
- Question: What are the most effective methods for evaluating exploratory search systems beyond traditional quantitative metrics like task time and relevant documents?
- Basis in paper: The review criticizes the overreliance on easily measurable quantitative metrics and the lack of consensus on evaluation methods, while qualitative methods like think-aloud protocols were rarely used.
- Why unresolved: The field has not developed standardized, validated evaluation methods that capture the complex cognitive and interpretive aspects of exploratory search.
- What evidence would resolve it: Comparative studies testing multiple evaluation approaches (including qualitative methods) across diverse domains to identify which metrics best predict successful exploratory search outcomes.

## Limitations

- The review's findings may not capture emerging trends after 2021 due to temporal limitations
- Reliance on convenience sampling data from existing studies inherits biases present in original research
- Database selection and search string limitations may have missed relevant publications

## Confidence

- **High Confidence**: Claims about publication patterns and venue distributions are well-supported by systematic analysis of 231 publications
- **Medium Confidence**: Conclusions about methodological limitations and need for standardized metrics are reasonable inferences from observed inconsistencies
- **Low Confidence**: Assertions about broader implications for research advancement are speculative extensions beyond empirical findings

## Next Checks

1. Conduct inter-rater reliability test with multiple independent coders applying the same framework to 20-30 publications
2. Perform gap analysis by searching additional databases (PubMed, IEEE Xplore) to verify coverage completeness
3. Conduct sensitivity analysis by varying time window (2015-2021 vs 2010-2016) to assess pattern stability across periods