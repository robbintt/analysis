---
ver: rpa2
title: Comparative Performance Evaluation of Large Language Models for Extracting
  Molecular Interactions and Pathway Knowledge
arxiv_id: '2307.08813'
source_url: https://arxiv.org/abs/2307.08813
tags:
- protein
- answer
- which
- proteins
- pathway
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper evaluates the effectiveness of large language models
  (LLMs) for extracting molecular interactions and pathway knowledge from scientific
  literature. The authors compare the performance of various LLMs, including Galactica,
  LLaMA, Alpaca, and RST, against baseline models like BioGPT and BioMedLM on three
  tasks: recognizing protein-protein interactions, identifying genes associated with
  pathways, and determining gene regulatory relationships.'
---

# Comparative Performance Evaluation of Large Language Models for Extracting Molecular Interactions and Pathway Knowledge

## Quick Facts
- arXiv ID: 2307.08813
- Source URL: https://arxiv.org/abs/2307.08813
- Reference count: 27
- The paper evaluates LLMs for extracting molecular interactions and pathway knowledge from scientific literature, finding that while larger models outperform smaller ones, they still struggle with domain-specific problems and are outperformed by models trained on narrower, domain-specific datasets.

## Executive Summary
This paper evaluates the effectiveness of large language models (LLMs) for extracting molecular interactions and pathway knowledge from scientific literature. The authors compare various LLMs including Galactica, LLaMA, Alpaca, and RST against baseline models like BioGPT and BioMedLM across three tasks: recognizing protein-protein interactions, identifying genes associated with pathways, and determining gene regulatory relationships. The study reveals that while larger LLMs generally outperform smaller models, they still struggle with domain-specific problems and are outperformed by models trained on narrower, domain-specific datasets. The research highlights the potential of LLMs for certain biological knowledge extraction tasks while emphasizing the need for domain-specific augmentation to achieve optimal performance.

## Method Summary
The study evaluates multiple LLMs on three biological knowledge extraction tasks using three different databases: STRING for protein-protein interaction recognition, KEGG for pathway gene identification, and INDRA for gene regulatory relationship extraction. The authors employ various prompt engineering techniques, including task-specific formatting and ablation studies to determine optimal shot numbers for prompts. Model performance is assessed using precision metrics for generated proteins/genes and micro F-scores for binary and multiple-choice classification tasks. The evaluation compares general-purpose LLMs (Galactica, LLaMA, Alpaca, RST) against domain-specific models (BioGPT-Large, BioMedLM) to quantify performance differences and identify areas where domain-specific knowledge is crucial.

## Key Results
- Larger LLMs (RST, Galactica) generally outperform smaller models on biological knowledge extraction tasks
- Domain-specific models (BioGPT, BioMedLM) outperform general LLMs on specialized tasks despite being smaller
- Task-specific prompt engineering and shot selection significantly impact model performance
- All models struggle with recognizing diverse protein groups and highly correlated gene regulatory relationships

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs struggle with domain-specific biological tasks unless augmented with task-specific formatting and prompt engineering
- Mechanism: General LLMs trained on broad corpora perform poorly on specialized tasks like protein-protein interaction (PPI) recognition or gene regulatory relationship extraction because they lack the domain-specific knowledge representation that smaller, domain-trained models possess
- Core assumption: The performance gap between general and domain-specific models stems from training data composition and the absence of specialized biological knowledge
- Evidence anchors:
  - [abstract] "while larger LLMs generally outperform smaller models, they still struggle with domain-specific problems and are outperformed by models trained on narrower, domain-specific datasets"
  - [section] "the current state-of-the-art LLMs still struggled with domain-targeted problems, being outperformed by smaller, domain-specifically trained models"

### Mechanism 2
- Claim: Larger LLMs exhibit better linguistic understanding for gene regulatory relationship extraction than smaller models
- Mechanism: Larger models trained on more diverse and extensive datasets demonstrate superior reading comprehension of gene regulatory relation texts, as they can infer complex relationships between entities from context
- Core assumption: Model size and training data diversity correlate with improved comprehension of nuanced biological text
- Evidence anchors:
  - [section] "the larger models, with the exception of LLaMA, outperformed the smaller models such as BioGPT-Large and BioMedLM"
  - [section] "This suggests that models trained on larger and more diverse datasets possess a stronger ability to comprehend the meaning of text compared to models trained on narrower and smaller datasets"

### Mechanism 3
- Claim: Task-specific prompt construction and shot selection significantly impact LLM performance on biological knowledge extraction
- Mechanism: The number of examples (shots) in prompts affects the model's ability to generate accurate biological knowledge, with too few shots providing insufficient context and too many causing confusion or exceeding context limits
- Core assumption: The optimal number of shots is task-dependent and requires empirical validation
- Evidence anchors:
  - [section] "In order to determine the optimal number of shots required to construct a prompt for the tasks, we performed an ablation study"
  - [section] "The shot number associated with the highest performance in test samples was selected for implementation"

## Foundational Learning

- **Protein-protein interactions (PPIs)**
  - Why needed here: PPIs are fundamental to understanding biological pathways and cellular functions, and the paper evaluates LLMs' ability to recognize these interactions
  - Quick check question: What is the primary function of protein-protein interactions in biological systems?

- **Gene regulatory relationships**
  - Why needed here: Understanding how genes regulate each other is crucial for elucidating biological pathways and disease mechanisms, which is a key task evaluated in the paper
  - Quick check question: What type of biological information do gene regulatory relationships provide?

- **Pathway analysis**
  - Why needed here: Pathways represent complex networks of molecular interactions, and the paper assesses LLMs' ability to identify genes associated with specific pathways
  - Quick check question: Why is pathway analysis important in understanding biological systems?

## Architecture Onboarding

- **Component map**: STRING DB -> PPI recognition task -> LLMs (Galactica, LLaMA, Alpaca, RST) -> Evaluation metrics
- **Critical path**: Prompt construction → Model inference → Result evaluation against ground truth in databases
- **Design tradeoffs**: Larger models offer better comprehension but require more computational resources; smaller, domain-specific models are more efficient but less generalizable
- **Failure signatures**: High false positive rates in yes/no tasks, inability to recognize diverse protein/gene names, hallucinations in generated lists
- **First 3 experiments**:
  1. Evaluate prompt construction variations for STRING Task1 (PPI recognition) to optimize shot number
  2. Compare general vs. domain-specific models on KEGG pathway recognition to quantify performance gaps
  3. Test reading comprehension of gene regulatory relations using INDRA data to assess model understanding of complex biological texts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal size and architecture of language models for biological knowledge extraction tasks?
- Basis in paper: [inferred] The paper compares the performance of various LLMs with different sizes and architectures (e.g., Galactica, LLaMA, Alpaca, RST) and finds that larger models generally outperform smaller ones, but also notes that domain-specific models trained on narrower datasets can outperform larger LLMs
- Why unresolved: The paper does not provide a definitive answer on the optimal size and architecture of LLMs for biological knowledge extraction tasks, as it only compares a limited set of models and does not explore the full range of possible architectures and sizes
- What evidence would resolve it: A comprehensive study comparing the performance of a wide range of LLM architectures and sizes on various biological knowledge extraction tasks, including both general and domain-specific models, would provide insights into the optimal size and architecture for these tasks

### Open Question 2
- Question: How can LLMs be effectively augmented with domain-specific knowledge to improve their performance on biological knowledge extraction tasks?
- Basis in paper: [explicit] The paper concludes that LLMs may need to be augmented with domain-specific knowledge to achieve optimal performance on biological knowledge extraction tasks, but does not provide specific strategies for such augmentation
- Why unresolved: The paper identifies the need for domain-specific augmentation but does not explore specific methods or strategies for achieving this, leaving the question open for further research
- What evidence would resolve it: Studies investigating various methods for augmenting LLMs with domain-specific knowledge, such as fine-tuning on domain-specific datasets, incorporating domain-specific ontologies, or using knowledge graphs, would provide insights into effective strategies for improving LLM performance on biological tasks

### Open Question 3
- Question: What are the limitations of LLMs in understanding complex biological relationships, and how can these limitations be addressed?
- Basis in paper: [explicit] The paper highlights that LLMs struggle with identifying groups of proteins with diverse functions and recognizing highly correlated gene regulatory relationships, indicating limitations in understanding complex biological relationships
- Why unresolved: The paper identifies these limitations but does not provide a comprehensive analysis of the underlying reasons or potential solutions, leaving the question open for further investigation
- What evidence would resolve it: Research exploring the specific challenges LLMs face in understanding complex biological relationships, such as the inability to capture context or the lack of interpretability, would help identify the root causes of these limitations and suggest potential solutions

## Limitations

- The evaluation focuses on a narrow set of biological tasks without testing models on broader biological knowledge extraction scenarios
- The comparison between general and domain-specific models may be influenced by dataset size and training data composition rather than inherent model capabilities
- The study does not address potential biases in the biological databases used for evaluation (STRING, KEGG, INDRA)

## Confidence

**High Confidence Claims:**
- Larger LLMs generally outperform smaller models on biological knowledge extraction tasks
- Domain-specific models (BioGPT, BioMedLM) outperform general LLMs on specialized tasks
- Task-specific prompt engineering and shot selection significantly impact model performance

**Medium Confidence Claims:**
- The performance gap between general and domain-specific models is primarily due to training data composition
- Models trained on larger and more diverse datasets demonstrate superior reading comprehension of biological text
- The optimal number of shots for prompt construction is task-dependent

**Low Confidence Claims:**
- General LLMs will consistently underperform domain-specific models across all biological knowledge extraction tasks
- Current LLMs cannot achieve acceptable performance on domain-specific biological problems without augmentation

## Next Checks

1. **Dataset Bias Analysis**: Conduct a systematic evaluation of potential biases in the STRING, KEGG, and INDRA databases to determine whether performance differences between models are influenced by database-specific characteristics rather than model capabilities.

2. **Cross-Database Generalization Test**: Evaluate the same models on an independent biological database not used in the original study to assess whether performance patterns observed in this study generalize to new datasets.

3. **Incremental Domain Knowledge Assessment**: Test whether progressively adding domain-specific training data to general LLMs can close the performance gap with specialized models, determining the minimum domain knowledge required for acceptable performance.