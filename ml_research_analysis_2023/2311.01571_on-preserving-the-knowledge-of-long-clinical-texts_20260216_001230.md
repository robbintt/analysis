---
ver: rpa2
title: On Preserving the Knowledge of Long Clinical Texts
arxiv_id: '2311.01571'
source_url: https://arxiv.org/abs/2311.01571
tags:
- clinical
- prediction
- text
- aggregation
- ensemble
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of processing long clinical texts
  using transformer-based models, which are limited by input length. The authors propose
  a novel method that combines ensemble learning with text aggregation to preserve
  the knowledge of long clinical texts.
---

# On Preserving the Knowledge of Long Clinical Texts

## Quick Facts
- arXiv ID: 2311.01571
- Source URL: https://arxiv.org/abs/2311.01571
- Reference count: 40
- The proposed method achieves 84.52% macro-averaged ROC-AUC for mortality prediction and 72.78% for length of stay prediction

## Executive Summary
This paper addresses the challenge of processing long clinical texts using transformer-based models limited by input length constraints. The authors propose a novel method combining ensemble learning with text aggregation to preserve knowledge from long clinical notes. The approach involves fine-tuning multiple pre-trained BERT-like transformers on clinical outcome tasks and aggregating predictions from overlapping text chunks. Results show superior performance compared to baseline models on mortality and length of stay prediction tasks.

## Method Summary
The method processes long clinical texts by splitting them into 512-token chunks with 50-token overlap using a sliding window approach. Multiple pre-trained transformer models (CORe and BioDischargeSummaryBERT) are fine-tuned independently on clinical outcome tasks. Predictions from both ensemble models and overlapping chunks are aggregated through averaging to produce final predictions. The approach combines the diversity benefits of ensemble learning with the comprehensive coverage of text aggregation to handle long clinical notes effectively.

## Key Results
- Aggregated ensemble approach with text overlap achieved 84.52% macro-averaged ROC-AUC for mortality prediction
- Same approach achieved 72.78% macro-averaged ROC-AUC for length of stay prediction
- Outperformed baseline models using individual transformers with truncation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Text aggregation with overlapping chunks preserves context continuity that would be lost with truncation
- Mechanism: Splitting long texts into 512-token chunks with 50-token overlap retains boundary information and ensures critical information straddling chunk boundaries is preserved in adjacent chunks
- Core assumption: Overlapping tokens contain sufficient contextual continuity to bridge segment boundaries
- Evidence anchors: Abstract states the method "splits long texts into multiple segments by keeping an overlapping portion between segments to preserve the information from one segment to another"; section describes chunk processing through models
- Break condition: If overlap size is too small to capture meaningful context or creates redundant processing that degrades performance

### Mechanism 2
- Claim: Ensemble of multiple BERT-based models reduces individual model biases and improves robustness
- Mechanism: Multiple pre-trained models are fine-tuned independently then predictions are averaged, reducing variance and compensating for individual model weaknesses
- Core assumption: Different models capture complementary patterns in the data
- Evidence anchors: Abstract mentions method "achieved better results than baselines, ensembling, and aggregation individually"; section provides ensemble prediction formula
- Break condition: If models are too similar in architecture and training data, ensemble provides minimal benefit

### Mechanism 3
- Claim: Combining ensemble and aggregation leverages both model diversity and comprehensive text coverage
- Mechanism: System processes overlapping text chunks through ensemble of models, then aggregates both chunk-level and model-level predictions
- Core assumption: Both ensemble diversity and chunk-wise aggregation contribute independently to performance improvement
- Evidence anchors: Abstract describes combining "ensemble learning with text aggregation"; section explains final prediction articulation
- Break condition: If computational overhead outweighs performance gains

## Foundational Learning

- Concept: BERT transformer architecture and input length limitations
  - Why needed here: Understanding why standard BERT cannot process long clinical texts directly
  - Quick check question: What is the maximum token length for standard BERT and what happens when input exceeds this limit?

- Concept: Ensemble learning principles
  - Why needed here: The method combines multiple models to improve prediction robustness
  - Quick check question: How does averaging predictions from multiple models reduce variance compared to using a single model?

- Concept: Text chunking and sliding window techniques
  - Why needed here: The method splits long texts into manageable chunks with overlap
  - Quick check question: Why is overlap necessary between consecutive text chunks when using sliding window approaches?

## Architecture Onboarding

- Component map: Clinical notes preprocessing -> Two baseline models (CORe, BioDischargeSummaryBERT) -> Ensemble layer -> Aggregation layer -> Final prediction combination

- Critical path: Clinical note → tokenization → chunking with overlap → each chunk processed by each model in ensemble → model predictions per chunk averaged → chunk predictions averaged for final output

- Design tradeoffs:
  - Overlap size: Larger overlap preserves more context but increases computational cost
  - Number of models in ensemble: More models increase robustness but add training/inference time
  - Chunk size: Must balance between context preservation and computational efficiency

- Failure signatures:
  - Poor performance on tasks requiring long-range dependencies across chunks
  - High variance in predictions when models disagree significantly
  - Degradation when overlap is too small to capture meaningful context

- First 3 experiments:
  1. Test baseline CORe and BioDischargeSummaryBERT individually on mortality prediction with 512-token limit
  2. Test aggregation with 50-token overlap on both models separately
  3. Test ensemble of both models without aggregation to establish baseline ensemble performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed method compare to other state-of-the-art models for clinical outcome prediction tasks?
- Basis in paper: Authors mention method outperforms baseline models but don't provide direct comparison with other state-of-the-art models
- Why unresolved: No direct comparison with other state-of-the-art models using same performance metrics and datasets
- What evidence would resolve it: Direct comparison of proposed method with other state-of-the-art models using same metrics and datasets

### Open Question 2
- Question: What are the potential limitations of the proposed method in terms of computational overhead and scalability?
- Basis in paper: Authors mention method involves training multiple large language models which may require significant computational resources
- Why unresolved: No specific details on computational requirements or scalability provided
- What evidence would resolve it: Detailed analysis of computational requirements and scalability including training time, memory usage, and potential bottlenecks

### Open Question 3
- Question: How does the proposed method handle variability in clinical text data across different hospitals or healthcare systems?
- Basis in paper: Authors mention method is designed to handle long clinical texts and diverse datasets but don't provide specific adaptation details
- Why unresolved: No discussion of challenges or limitations in adapting method to new clinical text data or domains
- What evidence would resolve it: Thorough analysis of method's ability to handle variability across different hospitals including challenges and limitations

## Limitations
- Computational overhead of processing multiple overlapping chunks through multiple ensemble models is substantial but not quantified
- Method's effectiveness on clinical tasks beyond mortality and length of stay prediction remains unknown
- Paper doesn't address potential bias from concatenating specific note sections while excluding others

## Confidence

**High Confidence**: The core observation that ensemble models combined with text aggregation improve performance on long clinical text tasks (84.52% ROC-AUC for mortality prediction, 72.78% for length of stay)

**Medium Confidence**: The specific mechanisms proposed (50-token overlap, ensemble composition of exactly 2 models) - while the general approach is sound, lacks detailed ablation studies

**Low Confidence**: The generalizability of the method to other clinical tasks or different clinical note structures - only evaluates two specific prediction tasks

## Next Checks

1. **Overlap Size Sensitivity Analysis**: Run experiments with 25, 50, and 100 token overlaps to determine if 50 tokens is optimal and whether smaller overlaps can achieve similar performance with reduced computational cost

2. **Single Model Performance Comparison**: Implement and test a single model with text aggregation (without ensemble) to quantify the specific contribution of ensemble versus aggregation components

3. **Computational Efficiency Benchmark**: Measure and report actual training and inference time for proposed method compared to baselines, including GPU memory usage and throughput metrics to assess practical deployment feasibility