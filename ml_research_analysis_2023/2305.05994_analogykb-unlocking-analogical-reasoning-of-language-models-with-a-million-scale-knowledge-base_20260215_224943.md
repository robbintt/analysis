---
ver: rpa2
title: 'ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale
  Knowledge Base'
arxiv_id: '2305.05994'
source_url: https://arxiv.org/abs/2305.05994
tags:
- analogy
- analogies
- relations
- data
- relation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of enabling language models
  to perform analogical reasoning by creating a large-scale analogy knowledge base.
  The core method involves extracting two types of analogies from existing knowledge
  graphs: same-relation analogies and analogous-relation analogies, with the latter
  identified using large language models and human verification.'
---

# ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base

## Quick Facts
- arXiv ID: 2305.05994
- Source URL: https://arxiv.org/abs/2305.05994
- Reference count: 37
- Key outcome: Creates ANALOGY KB, a million-scale knowledge base that significantly improves language models' analogical reasoning capabilities

## Executive Summary
This paper addresses the challenge of enabling language models to perform analogical reasoning by creating a large-scale analogy knowledge base. The core method involves extracting two types of analogies from existing knowledge graphs: same-relation analogies and analogous-relation analogies, with the latter identified using large language models and human verification. Evaluations show that training models on this knowledge base significantly improves performance on analogy recognition and generation tasks, achieving state-of-the-art results and even rivaling human performance in some benchmarks.

## Method Summary
The authors construct ANALOGY KB by first extracting same-relation analogies directly from Wikidata and ConceptNet knowledge graphs. They then use InstructGPT-002 to identify analogous relation pairs through few-shot prompting, followed by automatic filtering using symmetry and meta-relation rules. Human verification validates the final analogous relation pairs. The resulting knowledge base is used to fine-tune smaller language models, which then demonstrate improved analogical reasoning capabilities on benchmark tasks.

## Key Results
- ANALOGY KB contains over 1 million analogy pairs across two types: same-relation and analogous-relation analogies
- Models trained on ANALOGY KB achieve state-of-the-art performance on multiple analogy recognition benchmarks (E-KAR, BATS, UNIT)
- Smaller LMs fine-tuned on ANALOGY KB rival or exceed larger LLMs like InstructGPT-002 on analogy tasks
- The approach successfully transfers analogical reasoning capabilities to both smaller LMs and LLMs

## Why This Works (Mechanism)

### Mechanism 1
InstructGPT models can effectively identify analogous relations by leveraging few-shot in-context learning without explicit training. InstructGPT uses prompt examples to understand the task of finding analogous relations, then generates relation pairs by recognizing structural similarities between KG relations. Core assumption: InstructGPT's zero-shot/few-shot learning capabilities are sufficient to generalize relational structures into analogous pairs. Evidence: "analogies of analogous relations, which are identified with a selection and filtering pipeline enabled by large language models (InstructGPT)" and "we propose to exploit LLMs (e.g., InstructGPT002) to acquire analogies of analogous relations". Break condition: If InstructGPT cannot generalize beyond surface-level relation similarity to deeper structural analogy, it will produce incorrect analogous pairs.

### Mechanism 2
Automatic filtering rules (symmetry and meta-relation) significantly improve data quality by removing noisy outputs from InstructGPT. Rule 1 enforces bidirectional selection (if R1 is analogous to R2, then R2 must be analogous to R1). Rule 2 generalizes relations into abstract meta-relations to validate analogies. Core assumption: Symmetry is a valid constraint for analogous relations, and meta-relations capture the essence of analogical similarity. Evidence: "To eliminate the noise from the outputs of InstructGPT 002, we devise two filtering rules based on 1) the symmetry of analogy and 2) meta relation" and Table 4 showing improvement from InstructGPT alone to +Rule1&2+Human. Break condition: If symmetry or meta-relation summarization fails to capture valid analogies, they may incorrectly filter out correct pairs.

### Mechanism 3
Training smaller LMs on ANALOGY KB transfers analogical reasoning capabilities that rival larger LLMs. By fine-tuning on structured analogy data, smaller LMs learn to map relational structures and generate valid analogies through pattern recognition. Core assumption: The relational structure in ANALOGY KB is learnable by smaller LMs and generalizes to unseen analogies. Evidence: "Evaluations on a series of datasets of two analogical reasoning tasks (analogy recognition and generation) demonstrate that ANALOGY KB successfully enables both smaller LMs and LLMs to gain better analogical reasoning capabilities." and Table 5 showing RoBERTa-Large + ANALOGY KB outperforms InstructGPT002. Break condition: If the analogies in ANALOGY KB don't capture the underlying principles needed for generalization, smaller LMs will fail on novel analogy tasks.

## Foundational Learning

- Concept: Relational structures in knowledge graphs
  - Why needed here: Understanding how term pairs form analogies based on shared relational structures is fundamental to building ANALOGY KB
  - Quick check question: If (apple, isA, fruit) and (lion, isA, animal) share the same relation, what kind of analogy do they form?

- Concept: Few-shot learning and in-context prompting
  - Why needed here: InstructGPT's ability to perform analogy relation identification without training is key to the automated pipeline
  - Quick check question: What is the difference between few-shot learning and zero-shot learning in the context of LLMs?

- Concept: Data filtering and quality control
  - Why needed here: The automatic filtering rules and human verification ensure high-quality analogy pairs despite noisy LLM outputs
  - Quick check question: Why might symmetry be a useful constraint when filtering analogous relations?

## Architecture Onboarding

- Component map: KG Data Sources (Wikidata, ConceptNet) → Relation Extraction → Same-Relation Analogy Generation → InstructGPT Analogy Detection → Automatic Filtering (Rules 1&2) → Human Verification → ANALOGY KB Storage → Training Pipeline: ANALOGY KB → LM Fine-tuning → Analogy Recognition/Generation Evaluation

- Critical path:
  1. Collect term pairs from KGs
  2. Generate same-relation analogies directly
  3. Use InstructGPT to find analogous relation pairs
  4. Apply symmetry and meta-relation filtering
  5. Human verification
  6. Store in ANALOGY KB
  7. Fine-tune LMs on KB data

- Design tradeoffs:
  - Automation vs. Quality: More automation reduces cost but requires more filtering; human verification improves quality but increases cost
  - KG Coverage vs. Focus: Including more KGs increases coverage but may introduce noise; focusing on specific domains improves quality but limits applicability
  - Model Size vs. Performance: Larger models may perform better but are more expensive to run; smaller models are efficient but may need more training data

- Failure signatures:
  - High false positive rate in analogous relation detection → Inspect InstructGPT prompt effectiveness
  - Low performance on complex analogies → Check if ANALOGY KB contains sufficient complex relational examples
  - Human verification bottleneck → Review filtering rule effectiveness and consider additional automated quality checks

- First 3 experiments:
  1. Run InstructGPT on a small sample of relation pairs to evaluate its ability to identify valid analogies before scaling up
  2. Test filtering rules on a subset of InstructGPT outputs to measure precision improvement
  3. Fine-tune a small LM on a 1k sample from ANALOGY KB and evaluate on a simple analogy benchmark to verify transfer learning effectiveness

## Open Questions the Paper Calls Out
- How can ANALOGY KB be extended to handle analogies involving multiple relations and entities or events?
- What are the most effective training methods or prompting strategies for improving analogy-making capabilities in language models using ANALOGY KB?
- How does the performance of language models on analogy recognition tasks change when trained on ANALOGY KB compared to other knowledge bases or datasets?

## Limitations
- The approach may not scale effectively to truly novel analogy types beyond those in the training data
- Human verification remains a bottleneck that limits the practical scalability of the approach
- The effectiveness of the method on real-world reasoning applications beyond benchmark tasks remains unproven

## Confidence
**High Confidence**: The methodology for creating same-relation analogies from knowledge graphs is straightforward and well-validated. The improvement in analogy recognition tasks (E-KAR, BATS) when training on ANALOGY KB is clearly demonstrated with statistical significance.

**Medium Confidence**: The analogous-relation generation pipeline using InstructGPT-002 with filtering rules produces high-quality results, but the exact effectiveness of each filtering component is not separately quantified. The claim that smaller LMs can rival larger models on analogy tasks is supported but may not generalize beyond the specific benchmarks tested.

**Low Confidence**: The scalability of the approach to truly novel analogy types and its effectiveness in real-world reasoning applications beyond benchmark tasks remains unproven. The paper doesn't address potential biases in the knowledge graph sources or how they might affect the quality and diversity of generated analogies.

## Next Checks
1. Measure the precision and recall of each filtering rule (symmetry, meta-relation) separately by comparing InstructGPT outputs before and after each rule application, with human evaluation on a stratified sample.

2. Evaluate models trained on ANALOGY KB on out-of-distribution analogy benchmarks that require reasoning about concepts not present in the original knowledge graphs to assess true analogical reasoning capability.

3. Test the InstructGPT-002 pipeline on progressively larger relation pair samples to identify the point at which quality degrades or human verification becomes a bottleneck, determining practical scaling limits.