---
ver: rpa2
title: Decentralised and collaborative machine learning framework for IoT
arxiv_id: '2312.12190'
source_url: https://arxiv.org/abs/2312.12190
tags:
- learning
- nodes
- algorithm
- prototypes
- incremental
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a decentralized and collaborative machine learning
  framework for IoT devices. The framework uses an incremental learning algorithm
  called XuILVQ and two random-based protocols to exchange local models among computing
  elements in the network.
---

# Decentralised and collaborative machine learning framework for IoT

## Quick Facts
- arXiv ID: 2312.12190
- Source URL: https://arxiv.org/abs/2312.12190
- Reference count: 25
- Primary result: Decentralized approach achieves similar accuracy to centralized approach while reducing communication overhead and training time

## Executive Summary
This paper proposes a decentralized and collaborative machine learning framework for IoT devices that uses incremental learning algorithm XuILVQ and random-based protocols to exchange local models among computing elements in the network. The framework is particularly useful for resource-constrained devices typical in IoT deployments. The proposed system was compared to a centralized incremental learning approach in terms of accuracy, training time, and robustness, demonstrating that the decentralized approach achieves similar accuracy while reducing communication overhead and training time.

## Method Summary
The framework uses XuILVQ algorithm for incremental learning and prototype generation, combined with Adaptive Random Forest (ARF) for classification in hybrid scenarios. Two decentralized protocols are implemented: random sharing and relative threshold. The Phishing dataset from River library (1250 samples, 10 features) is partitioned among 5-7 nodes with one node having fewer samples (50 vs 200-300). Experiments compare centralized vs decentralized approaches using F-score, training time, and communication complexity as metrics. The decentralized protocols exchange learned prototypes instead of raw data, allowing knowledge transfer without privacy leakage.

## Key Results
- Decentralized approach achieves similar F-score accuracy to centralized approach
- Communication overhead is significantly reduced through prototype-based sharing
- Training time is reduced compared to centralized approach, especially beneficial for resource-constrained devices
- Relative threshold protocol shows potential efficiency gains in larger networks by sharing only with underperforming peers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decentralised prototype sharing preserves accuracy while reducing communication overhead
- Mechanism: Nodes exchange learned prototypes instead of raw data, allowing knowledge transfer without privacy leakage
- Core assumption: Prototypes capture sufficient information to improve other nodes' models
- Evidence anchors:
  - [abstract] "The framework is particularly useful for resource-constrained devices, typical in IoT deployments"
  - [section III-A] "The dual nature of the prototypes makes them a suitable means of synthesizing the knowledge to be transferred to another node for learning purposes"
- Break condition: If prototypes become too generic or overfit to local data, cross-node improvement stalls

### Mechanism 2
- Claim: Hybrid approach balances model accuracy and resource constraints
- Mechanism: ILVQ generates interpretable prototypes for sharing, while ARF handles real-time prediction
- Core assumption: Predictive accuracy can be maintained by decoupling prototype generation from classification
- Evidence anchors:
  - [section III-B] "In this scenario we use a combination of ILVQ and the Adaptive Random Forest (ARF) algorithm to separate the tasks of predictive and prototype generation"
  - [section V-A] XuILVQ runtime is faster than KNN in high-dimensional scenarios
- Break condition: If ARF performance degrades significantly compared to ILVQ-only, the hybrid benefit disappears

### Mechanism 3
- Claim: Relative threshold protocol optimizes communication efficiency
- Mechanism: Nodes only share prototypes with underperforming peers, reducing redundant updates
- Core assumption: Local performance is a good proxy for potential gain from shared prototypes
- Evidence anchors:
  - [section III-A] "the relative threshold protocol share its local model to other nodes only when these ones are underperforming"
  - [section V-C] Results show similar performance to random protocol with potential efficiency gains in larger networks
- Break condition: In homogeneous networks, performance differences vanish and protocol offers no advantage

## Foundational Learning

- Concept: Incremental Learning
  - Why needed here: IoT devices receive data streams continuously; models must adapt without full retraining
  - Quick check question: What happens if a node receives a class never seen before? (Answer: XuILVQ registers it as a new prototype)

- Concept: Prototype-based Learning
  - Why needed here: Prototypes are compact, interpretable representations suitable for constrained devices and efficient sharing
  - Quick check question: How does XuILVQ decide whether to add a new prototype? (Answer: Based on distance thresholds and class novelty)

- Concept: Gossip Protocols
  - Why needed here: Decentralized communication without central server; ensures robustness and scalability
  - Quick check question: What network condition is required for full propagation? (Answer: At least one path from informed to uninformed nodes)

## Architecture Onboarding

- Component map: XuILVQ -> ARF -> Sharing protocols -> Communication queues -> Performance tracking
- Critical path: Receive new sample -> Update local model (ILVQ/ARF) -> Check sharing condition (protocol-dependent) -> Send prototypes if triggered -> Process received prototypes -> Continue to next sample
- Design tradeoffs: Sharing frequency vs. communication cost (controlled by parameter t), Prototype quality vs. memory usage (denoise parameter Î»), Accuracy vs. computational load (ILVQ-only vs. hybrid)
- Failure signatures: Stalled accuracy improvement despite sharing, Memory exhaustion from too many prototypes, Communication bottlenecks from high sharing probability
- First 3 experiments: 1) Single-node baseline: Run XuILVQ on full dataset centrally, measure accuracy and runtime, 2) Symmetric 5-node network: All nodes equal size, test random sharing with varying t, 3) Asymmetric 5-node network: One small node, test both protocols, measure convergence speed for the small node

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of sharing parameter (T) impact the trade-off between communication complexity and F-score in decentralized machine learning?
- Basis in paper: [explicit] The paper discusses the trade-off between communication load and accuracy (F-score) as a function of T
- Why unresolved: While the paper identifies a general optimal range for T, the specific impact of different T values on various network configurations and datasets remains unexplored
- What evidence would resolve it: Conducting experiments with a wider range of T values and different network sizes, topologies, and datasets

### Open Question 2
- Question: How do different network topologies affect the performance and convergence of decentralized machine learning algorithms?
- Basis in paper: [inferred] The paper assumes a complete network graph, but acknowledges that the dynamics of decentralized learning might differ in more complex topologies
- Why unresolved: The paper does not explore the impact of different network topologies on the performance and convergence of decentralized machine learning algorithms
- What evidence would resolve it: Implementing and comparing decentralized machine learning algorithms on various network topologies

### Open Question 3
- Question: How does the size of the local datasets affect the learning process and final model accuracy in decentralized machine learning?
- Basis in paper: [explicit] The paper introduces asymmetry in the size of local datasets by assigning a smaller dataset to one node
- Why unresolved: While the paper explores the impact of dataset size asymmetry on a single node, it does not investigate how varying dataset sizes across all nodes affect overall learning process and final model accuracy
- What evidence would resolve it: Conducting experiments with different dataset size distributions among nodes

## Limitations
- Core XuILVQ algorithm implementation details are not fully specified in the paper
- No explicit validation of prototype quality retention across heterogeneous node distributions
- Limited experimental scope (single dataset, fixed network sizes)

## Confidence

- Mechanism 1 (Prototype sharing accuracy): Medium
- Mechanism 2 (Hybrid approach benefits): Low-Medium
- Mechanism 3 (Relative threshold efficiency): Low

## Next Checks
1. Implement XuILVQ from first principles and validate prototype generation against known benchmarks
2. Test both sharing protocols across multiple datasets with varying class distributions and imbalance ratios
3. Extend experiments to 20+ nodes with dynamic topology changes to verify communication efficiency claims