---
ver: rpa2
title: 'SMORE: Score Models for Offline Goal-Conditioned Reinforcement Learning'
arxiv_id: '2311.02013'
source_url: https://arxiv.org/abs/2311.02013
tags:
- offline
- learning
- gcrl
- distribution
- objective
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper presents SMORE, a novel discriminator-free method for
  offline goal-conditioned reinforcement learning (GCRL) that outperforms state-of-the-art
  baselines on benchmark tasks. SMORE formulates GCRL as an occupancy matching problem
  and derives a dual objective that leverages offline data without requiring a learned
  discriminator, addressing the issue of cascading errors in discriminator-based methods.
---

# SMORE: Score Models for Offline Goal-Conditioned Reinforcement Learning

## Quick Facts
- arXiv ID: 2311.02013
- Source URL: https://arxiv.org/abs/2311.02013
- Authors: [Authors not specified in source]
- Reference count: 40
- Key outcome: SMORE is a novel discriminator-free method for offline goal-conditioned reinforcement learning that outperforms state-of-the-art baselines on benchmark tasks, demonstrating robustness to environment stochasticity and low expert coverage in offline datasets.

## Executive Summary
SMORE introduces a novel discriminator-free approach to offline goal-conditioned reinforcement learning (GCRL) that addresses the issue of cascading errors from discriminator inaccuracy in prior methods. The key insight is formulating GCRL as an occupancy matching problem and deriving a dual objective that learns unnormalized scores representing the importance of actions for reaching goals. By avoiding discriminators entirely, SMORE achieves superior performance on benchmark tasks while being more robust to low expert coverage and stochastic environments in offline datasets.

## Method Summary
SMORE learns unnormalized scores (importance weights) instead of normalized densities or discriminators by framing GCRL as occupancy matching and deriving a dual objective. The method uses a mixture distribution matching approach that leverages offline data more effectively than prior methods. SMORE employs a Bellman-regularized contrastive procedure to learn scores, which is more stable than learning density ratios or discriminators. The architecture consists of a score function S, a model M, and a policy π, trained through a critical path involving sampling from offline datasets and goal-transition distributions, updating scores via the SMORE objective, updating the model via expectile regression, and updating the policy via advantage-weighted regression.

## Key Results
- SMORE significantly outperforms prior state-of-the-art methods on robot manipulation and locomotion tasks in offline GCRL benchmarks
- The method demonstrates robustness to environment stochasticity and low expert coverage in offline datasets
- SMORE scales well to high-dimensional vision-based tasks, achieving competitive success rates or outperforming baselines on unseen compound tasks

## Why This Works (Mechanism)

### Mechanism 1
SMORE learns unnormalized scores (importance weights) instead of normalized densities or discriminators, avoiding cascading errors from discriminator inaccuracy. By framing GCRL as occupancy matching and deriving a dual objective, SMORE learns scores that indicate the importance of taking an action at a state for reaching a goal. These scores are updated via a Bellman-regularized contrastive procedure, which is more stable than learning density ratios or discriminators. Core assumption: Learning unnormalized scores via contrastive methods is more stable and effective than learning normalized densities or discriminators, especially in the offline setting with limited or noisy data.

### Mechanism 2
The mixture distribution matching objective allows SMORE to leverage offline data more effectively than prior methods. SMORE matches a mixture of the current policy's state-action-goal occupancy distribution and the offline data distribution to a mixture of the goal-transition distribution and the offline data. This allows the method to learn from offline data while still optimizing for the GCRL objective. Core assumption: The mixture distribution matching objective is a valid and effective way to learn from offline data in the GCRL setting.

### Mechanism 3
SMORE is robust to environment stochasticity and low expert coverage in offline datasets. The discriminator-free nature of SMORE prevents cascading errors from discriminator inaccuracy, making it more robust to noise and low coverage. The method's ability to learn unnormalized scores also contributes to its robustness. Core assumption: The absence of a discriminator and the use of unnormalized scores make SMORE inherently more robust to noise and low coverage in offline data.

## Foundational Learning

- **Occupancy matching and GCRL**: Understanding occupancy matching is crucial for grasping how SMORE formulates GCRL as an optimization problem. Quick check: What is the goal-transition distribution in the context of GCRL, and how does it relate to occupancy matching?

- **Convex duality in RL**: The dual formulation of the occupancy matching problem is central to SMORE's approach. Quick check: How does applying convex duality to the occupancy matching problem lead to a discriminator-free objective?

- **Contrastive learning in RL**: SMORE uses a Bellman-regularized contrastive procedure to learn scores. Quick check: How does the contrastive learning procedure in SMORE differ from traditional contrastive learning approaches in RL?

## Architecture Onboarding

- **Component map**: Score function S (parameterized by ϕ) -> Model M (parameterized by ψ) -> Policy π (parameterized by θ)
- **Critical path**: 
  1. Sample a batch from the offline dataset and the goal-transition distribution
  2. Update the score function S using the SMORE objective
  3. Update the model M using expectile regression
  4. Update the policy π using advantage-weighted regression
- **Design tradeoffs**: Learning scores vs. learning densities or discriminators; using a mixture distribution vs. directly matching occupancy distributions; choice of f-divergence (Pearson χ2 vs. KL)
- **Failure signatures**: Poor performance on goal-reaching tasks; instability in learning scores or policy; sensitivity to hyperparameters (e.g., mixture ratio β)
- **First 3 experiments**:
  1. Train SMORE on a simple goal-reaching task with a small, clean dataset to verify basic functionality
  2. Evaluate SMORE's robustness to noise by training on a dataset with added noise and comparing performance to baselines
  3. Test SMORE's performance with varying levels of expert coverage in the offline dataset to assess its robustness to low coverage

## Open Questions the Paper Calls Out

### Open Question 1
How does SMORE's performance compare to other methods when using smaller offline datasets with varying quality, and what is the minimum dataset size required for SMORE to achieve acceptable performance? The paper mentions that SMORE is robust to decreasing expert coverage in offline datasets, but it doesn't explore the performance of SMORE with smaller datasets or provide a minimum dataset size requirement.

### Open Question 2
Can SMORE be extended to handle continuous action spaces in addition to discrete action spaces, and how does this extension affect the performance of SMORE? The paper mentions that SMORE learns unnormalized scores over actions at a state to reach the goal, but it doesn't discuss how SMORE handles continuous action spaces.

### Open Question 3
How does SMORE perform in tasks with high-dimensional observation spaces, such as 3D environments or tasks with multiple objects, and what are the limitations of SMORE in handling such complex tasks? The paper mentions that SMORE is tested on a vision-based manipulation benchmark with high-dimensional observation spaces, but it doesn't explore its performance in more complex tasks with multiple objects or 3D environments.

## Limitations
- The paper lacks direct empirical evidence comparing SMORE's performance to discriminator-based methods in the same benchmark tasks
- Core mechanism relies on learning unnormalized scores via contrastive methods without ablation studies isolating the impact of the contrastive component
- Claims about robustness to low expert coverage lack specific ablations showing SMORE's performance degradation patterns versus baselines

## Confidence
- High confidence in SMORE's state-of-the-art performance claims on benchmark tasks, as the paper provides comprehensive experimental results across multiple domains and comparison to established baselines
- Medium confidence in the mechanism claims about why the discriminator-free approach works, as the theoretical foundation is sound but lacks direct empirical validation
- Low confidence in claims about robustness to low expert coverage without specific ablations showing SMORE's performance degradation patterns versus baselines

## Next Checks
1. Run ablation studies removing the contrastive component to quantify its specific contribution to SMORE's performance gains
2. Test SMORE with varying amounts of expert data in the offline dataset to empirically validate its robustness claims compared to discriminator-based methods
3. Implement a discriminator-based baseline using the same architecture and training setup as SMORE to directly compare the impact of the discriminator-free approach on benchmark tasks