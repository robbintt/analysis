---
ver: rpa2
title: 'Continual Diffusion: Continual Customization of Text-to-Image Diffusion with
  C-LoRA'
arxiv_id: '2304.06027'
source_url: https://arxiv.org/abs/2304.06027
tags:
- diffusion
- learning
- continual
- concepts
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of catastrophic forgetting in continual
  customization of text-to-image diffusion models. The authors propose C-LoRA, a method
  that uses continual, self-regularized low-rank adaptation in the cross-attention
  layers of Stable Diffusion to learn new concepts sequentially without forgetting
  past concepts.
---

# Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA

## Quick Facts
- **arXiv ID**: 2304.06027
- **Source URL**: https://arxiv.org/abs/2304.06027
- **Reference count**: 40
- **Primary result**: C-LoRA achieves state-of-the-art performance in continual customization of text-to-image diffusion, with average MMD score of 2.01 on Celeb-A HQ dataset after training on 10 concepts sequentially.

## Executive Summary
This paper addresses catastrophic forgetting in continual customization of text-to-image diffusion models. The authors propose C-LoRA, which uses continual, self-regularized low-rank adaptation in the cross-attention layers of Stable Diffusion to learn new concepts sequentially without forgetting past concepts. The method introduces personalized tokens with random initialization and removes object names from prompts to reduce interference between concepts. C-LoRA is evaluated on two tasks: continual customization of text-to-image diffusion and continual learning for image classification, demonstrating superior performance compared to existing methods.

## Method Summary
C-LoRA modifies the cross-attention weight matrices (WK,V) in Stable Diffusion using low-rank adaptation (LoRA), constraining parameter changes to a small subspace to reduce interference with previously learned representations. The method introduces a self-regularization loss that penalizes updates to parameters modified by previous concepts using the element-wise product of past and current LoRA updates. Personalized tokens are randomly initialized and object names are removed from prompts to prevent token interference. The approach is evaluated on continual customization tasks using Celeb-A HQ and Google Landmarks datasets, and on continual learning for image classification using ImageNet-R.

## Key Results
- C-LoRA achieves average MMD score of 2.01 on Celeb-A HQ dataset after training on 10 concepts sequentially, compared to 7.29 for Custom Diffusion (Merge) and 8.03 for Custom Diffusion (Sequential).
- On continual learning for image classification, C-LoRA achieves state-of-the-art performance on ImageNet-R with average accuracy of 78.16% over 10 tasks, compared to 75.58% for CODA-Prompt.
- The method effectively prevents catastrophic forgetting while maintaining parameter efficiency through low-rank adaptation.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Catastrophic forgetting occurs when sequentially learning fine-grained concepts in text-to-image diffusion models because new concept training overwrites parameters critical for previous concepts.
- Mechanism: By modifying only cross-attention weight matrices (WK,V) using low-rank adaptations (LoRA), the method constrains parameter changes to a small, targeted subspace, reducing interference with previously learned representations.
- Core assumption: Cross-attention layers are the primary source of interference when learning sequential concepts, and low-rank adaptation provides sufficient representational capacity while limiting parameter updates.
- Evidence anchors:
  - [abstract] "C-LoRA, composed of a continually self-regularized low-rank adaptation in cross attention layers of the popular Stable Diffusion model."
  - [section 3.1] "we only modify WK,V, which project the text features... Following Kumari et al. [25], we only modify WK,V, which project the text features, and we refer to these as simply WK,V."
  - [corpus] Weak evidence - no direct corpus papers confirm this specific claim about cross-attention layers being primary source of interference.

### Mechanism 2
- Claim: Self-regularization using past LoRA parameters prevents forgetting by penalizing updates to parameters that have been modified by previous concepts.
- Mechanism: The regularization term Lforget = ||(Σt'-1^t-1 AK,V_t' BK,V_t') ⊙ AK,V_t BK,V_t||^2_2 penalizes the element-wise product of past and current LoRA updates, discouraging changes to parameters already influenced by previous concepts.
- Core assumption: The element-wise product of past and current LoRA parameters effectively identifies which parameter subspaces have been modified, and penalizing these updates prevents catastrophic forgetting.
- Evidence anchors:
  - [section 3.2] "we penalize the LoRA parameters AK,V_t and BK,V_t for altering spots that have been edited by previous concepts... we use the summed products of past LoRA parameters themselves to penalize the future changes."
  - [abstract] "we propose the C-LoRA method, which efficiently adapts to new concepts while preserving the knowledge of past concepts through continual, self-regularized, low-rank adaptation in cross attention layers of Stable Diffusion."
  - [corpus] Weak evidence - while self-regularization is mentioned in related works, the specific element-wise product approach is novel and not directly confirmed by corpus.

### Mechanism 3
- Claim: Random initialization of personalized tokens with removal of object names prevents interference by ensuring unique, non-overlapping embeddings for each concept.
- Mechanism: By initializing personalized tokens V* as random embeddings and removing concept names from prompts, each concept receives a unique embedding that doesn't overlap with others, reducing interference during training.
- Core assumption: Random initialization creates embeddings that are sufficiently distant in the embedding space, and removing object names prevents shared semantic overlap that could cause interference.
- Evidence anchors:
  - [section 3.3] "we add N personalized tokens V*1,V*2,...,V*N... we initialize with random embeddings in the token embedding space... we remove any object names from the input sequence to encourage unique personalized embeddings."
  - [abstract] "we propose a custom tokenization strategy that (i) removes the word of the customized object (typically used in prior works) and (ii) is initialized as random embeddings (rather than arbitrary embeddings of lesser-used words, as done previously)"
  - [corpus] Moderate evidence - related works mention token interference but don't specifically validate the random initialization approach.

## Foundational Learning

- **Concept: Low-rank matrix approximation (LoRA)**
  - Why needed here: Enables parameter-efficient adaptation by decomposing weight updates into low-rank matrices, reducing the number of parameters that need to be stored and trained while maintaining sufficient capacity for concept learning.
  - Quick check question: How does decomposing weight matrices into AK,V_t ∈ R^(D1×r) and BK,V_t ∈ R^(r×D2) reduce the total number of parameters compared to full fine-tuning?

- **Concept: Catastrophic forgetting in continual learning**
  - Why needed here: Understanding that sequential learning causes interference where new concept training overwrites parameters important for previous concepts is crucial for designing effective regularization strategies.
  - Quick check question: Why does training a model sequentially on similar concepts (like faces) cause more forgetting than training on dissimilar concepts?

- **Concept: Cross-attention mechanism in diffusion models**
  - Why needed here: Cross-attention layers are the primary mechanism through which text prompts condition image generation, making them critical targets for adaptation when learning new concepts.
  - Quick check question: In the cross-attention formula Fattn(Q,K,V) = σ(QK^T/√d')V, which matrices are modified in C-LoRA and why?

## Architecture Onboarding

- **Component map**: Stable Diffusion backbone (frozen) → Cross-attention layers (U-Net) → LoRA adapters (AK,V_t, BK,V_t matrices) → Personalized token embeddings (V*1...V*N) → Self-regularization loss component
- **Critical path**: Tokenization → Cross-attention modification → Self-regularization → Inference with multiple concepts
- **Design tradeoffs**: LoRA rank vs. parameter efficiency vs. concept capacity; regularization strength vs. plasticity vs. forgetting; random token initialization vs. semantic initialization
- **Failure signatures**: High MMD scores indicate poor concept learning; high FMMD scores indicate catastrophic forgetting; artifacts in multi-concept generations indicate token interference
- **First 3 experiments**:
  1. Single-concept customization using C-LoRA vs. full fine-tuning to verify parameter efficiency
  2. Two-concept sequential learning to observe forgetting behavior with different regularization strengths
  3. Multi-concept generation with different token initialization strategies to validate interference reduction

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of C-LoRA scale with very large task sequences (e.g., 50 or 100 concepts) compared to smaller sequences?
- Basis in paper: [explicit] The paper states that the authors caution against training on large task sequences of 50 or 100 faces, as their approach may suffer in such scenarios.
- Why unresolved: The paper only provides results for task sequences of up to 10 concepts. The authors acknowledge this limitation but do not provide experimental evidence for larger task sequences.
- What evidence would resolve it: Experiments comparing C-LoRA's performance on task sequences of varying lengths, especially much larger sequences than tested in the paper, would help determine the scalability of the approach.

### Open Question 2
- Question: What is the impact of using different regularization strategies (e.g., replay-based methods) compared to the self-regularization approach in C-LoRA?
- Basis in paper: [explicit] The paper mentions that prior experience would first suggest using replay data for knowledge distillation, but they found generative replay induces new artifacts and catastrophic forgetting.
- Why unresolved: While the authors discuss why they chose self-regularization over replay-based methods, they do not provide a direct comparison of different regularization strategies within their C-LoRA framework.
- What evidence would resolve it: Experiments comparing C-LoRA with different regularization strategies (e.g., adding replay-based methods as an additional component) would help determine the optimal approach for preventing forgetting.

### Open Question 3
- Question: How does the performance of C-LoRA compare to other parameter-efficient fine-tuning methods (e.g., adapters, prompt learning) in the continual learning setting for image classification?
- Basis in paper: [inferred] The paper demonstrates that C-LoRA achieves state-of-the-art performance in the continual learning setting for image classification, outperforming prompting methods like L2P, DualPrompt, and CODA-Prompt.
- Why unresolved: While the paper shows C-LoRA's superiority over prompting methods, it does not directly compare C-LoRA to other parameter-efficient fine-tuning methods like adapters in the same setting.
- What evidence would resolve it: Experiments comparing C-LoRA to other parameter-efficient fine-tuning methods (e.g., adapters, prompt learning) in the continual learning setting for image classification would help determine the relative effectiveness of different approaches.

## Limitations
- The self-regularization mechanism using element-wise products of past and current LoRA parameters is presented without thorough theoretical justification or ablation studies exploring alternative formulations.
- The paper focuses on faces and landmarks, which are visually similar concepts, without testing whether the method works equally well for more diverse concept types.
- The approach may not scale well to very large task sequences (50+ concepts), as acknowledged by the authors but not empirically validated.

## Confidence
- **High confidence**: The core claim that C-LoRA achieves state-of-the-art performance on continual customization tasks, with MMD scores of 2.01 compared to 7.29 for Custom Diffusion (Merge) and 8.03 for Custom Diffusion (Sequential) on Celeb-A HQ. The experimental methodology is clear, and the metrics (MMD, forgetting) are standard in the field.
- **Medium confidence**: The effectiveness of the self-regularization mechanism in preventing catastrophic forgetting. While the results show improvement over baselines, the specific mathematical formulation and its relationship to forgetting is not fully justified theoretically or empirically explored through ablation studies.
- **Low confidence**: The claim that random initialization of personalized tokens with object name removal is the optimal strategy for preventing token interference. The paper presents this as a novel contribution but doesn't provide strong evidence that this is superior to other tokenization strategies, nor does it explore the space of possible approaches.

## Next Checks
1. **Ablation study on self-regularization**: Systematically vary the regularization strength λ and compare against alternative regularization formulations (Frobenius norm, cosine similarity, or no regularization) to quantify the contribution of the self-regularization mechanism to overall performance.

2. **Token initialization analysis**: Visualize and compare the embedding space distances between random-initialized tokens versus semantically-meaningful tokens, and evaluate whether removing object names actually improves concept learning or simply reduces interference at the cost of semantic clarity.

3. **Cross-component interference validation**: Implement and evaluate a variant that applies regularization to self-attention weights or residual connections in addition to cross-attention, to test whether cross-attention is indeed the primary source of interference or if a more comprehensive approach would be beneficial.