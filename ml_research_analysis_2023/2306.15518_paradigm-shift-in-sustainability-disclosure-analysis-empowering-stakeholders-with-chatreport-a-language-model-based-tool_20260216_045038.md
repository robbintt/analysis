---
ver: rpa2
title: 'Paradigm Shift in Sustainability Disclosure Analysis: Empowering Stakeholders
  with CHATREPORT, a Language Model-Based Tool'
arxiv_id: '2306.15518'
source_url: https://arxiv.org/abs/2306.15518
tags:
- report
- risks
- climate-related
- risk
- climate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces CHATREPORT, a Large Language Model-based tool
  for automating the analysis of corporate sustainability reports against TCFD guidelines.
  The approach integrates expert knowledge through an iterative prompt development
  loop, addressing the challenges of high manual analysis costs and limited transparency
  in sustainability reporting.
---

# Paradigm Shift in Sustainability Disclosure Analysis: Empowering Stakeholders with CHATREPORT, a Language Model-Based Tool

## Quick Facts
- **arXiv ID**: 2306.15518
- **Source URL**: https://arxiv.org/abs/2306.15518
- **Reference count**: 40
- **Primary result**: CHATREPORT automates TCFD-compliant sustainability analysis, scoring reports 0-100 and enabling stakeholder access to previously opaque assessments.

## Executive Summary
CHATREPORT introduces a Large Language Model-based tool that automates the analysis of corporate sustainability reports against TCFD guidelines. The system integrates expert knowledge through an iterative prompt development loop, addressing the challenges of high manual analysis costs and limited transparency in sustainability reporting. By vectorizing reports, summarizing disclosures, evaluating TCFD conformity with generated scores (0-100), and answering customized questions, CHATREPORT enhances accessibility, scalability, and comparability of sustainability assessments, potentially disrupting reliance on rating agencies and supporting stakeholders in making informed decisions.

## Method Summary
CHATREPORT processes 9,781 corporate sustainability reports using a four-module pipeline: Report Embedding (RE) for vectorizing and storing report chunks, Report Summarization (RS) for TCFD-based summaries, TCFD Conformity Assessment (TCA) for scoring report compliance, and Customized Question Answering (CQA) for user-specific queries. The system employs semantic search with vector embeddings to efficiently process long reports, integrates expert knowledge through iterative prompt refinement, and uses ChatGPT API with LangChain and FAISS vector database. Expert involvement ensures domain-specific accuracy while maintaining scalability across the large dataset.

## Key Results
- CHATREPORT processed 9,781 sustainability reports from 2010-2022, showing increasing TCFD conformity over time
- JP Morgan Chase's TCFD score increased from 0 in 2015 to 61 in 2021
- Shell achieved a 50 overall TCFD score in 2022
- The tool demonstrates potential to democratize sustainability analysis and reduce reliance on opaque rating agencies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrating expert knowledge through an iterative prompt development loop improves LLM accuracy in sustainability report analysis.
- Mechanism: Domain experts provide feedback on LLM outputs, which is then used to refine prompts, resulting in more precise, critical, and domain-specific analyses.
- Core assumption: Expert feedback is actionable and directly improves prompt quality.
- Evidence anchors: Abstract mentions collaboration with climate science, finance, economic policy, and computer science experts; section describes feasible workflow for involving domain experts in AI tool development.
- Break condition: Expert feedback becomes inconsistent or uninformative, leading to prompt overfitting or reduced generalizability.

### Mechanism 2
- Claim: Semantic search with vector embeddings enables efficient processing of long sustainability reports by the LLM.
- Mechanism: Reports are split into chunks, embedded into vectors, stored in a database, and relevant chunks are retrieved based on semantic similarity to queries.
- Core assumption: Embedding and retrieval system accurately identifies the most relevant content for each analysis task.
- Evidence anchors: Abstract states CHATREPORT vectorizes reports and evaluates TCFD conformity; section describes splitting reports into chunks and transforming them into vector space representations.
- Break condition: Retrieval misses critical information or retrieves irrelevant chunks, leading to incomplete or inaccurate analyses.

### Mechanism 3
- Claim: CHATREPORT's transparency and accessibility features reduce reliance on opaque rating agencies for sustainability assessments.
- Mechanism: By making prompts, generated data, and scores publicly available, stakeholders can independently assess reports and make informed decisions.
- Core assumption: Public access to tools and data enables stakeholders to conduct their own analyses without needing rating agencies.
- Evidence anchors: Abstract mentions making prompt templates, generated data, and scores available to encourage transparency; section describes making generated data and scores available for further exploration and research.
- Break condition: Stakeholders lack technical expertise to use the tool effectively or prefer human-curated ratings over automated analyses.

## Foundational Learning

- **Large Language Models (LLMs) and their limitations**
  - Why needed: Understanding LLM capabilities and weaknesses is crucial for designing effective prompts and interpreting outputs.
  - Quick check: What are the main limitations of LLMs that CHATREPORT needs to address?

- **Task Force on Climate-related Financial Disclosures (TCFD) framework**
  - Why needed: CHATREPORT's analysis is structured around TCFD recommendations, so understanding this framework is essential.
  - Quick check: What are the four pillars of the TCFD framework and how do they relate to sustainability reporting?

- **Prompt engineering techniques**
  - Why needed: Effective prompts are key to CHATREPORT's accuracy, so understanding prompt design principles is critical.
  - Quick check: How does the expert-involved prompt development loop improve over standard prompt engineering approaches?

## Architecture Onboarding

- **Component map**: RE -> RS -> TCA -> CQA (Report Embedding feeds into Report Summarization, which feeds into TCFD Conformity Assessment, which feeds into Customized Question Answering)

- **Critical path**: The critical path for analyzing a sustainability report is: split and embed report → retrieve relevant chunks → generate TCFD conformity score and analysis → answer customized questions using the same retrieval system.

- **Design tradeoffs**: CHATREPORT trades off perfect accuracy for scalability and accessibility. The use of semantic search may miss some relevant information, but enables processing of very long reports. Public access to tools democratizes analysis but may lead to misinterpretation without proper guidance.

- **Failure signatures**: If CHATREPORT consistently gives low scores to diverse reports, there may be a bias in the TCA module. If analyses miss key information, the RE module's retrieval may be too narrow. If customized questions get irrelevant answers, the CQA module's guidelines may be too generic.

- **First 3 experiments**:
  1. Run CHATREPORT on a small set of reports with known TCFD compliance to validate the TCA scoring.
  2. Compare CHATREPORT's analyses with expert manual reviews to assess accuracy and identify common failure modes.
  3. Test the tool's performance on reports of varying lengths and structures to evaluate the robustness of the RE module's chunking and retrieval.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of hallucination on the reliability of CHATREPORT's TCFD conformity scores?
- Basis in paper: [explicit] The paper acknowledges hallucination as a significant unresolved problem in NLP and discusses its potential impact on CHATREPORT's outputs.
- Why unresolved: While the paper mentions hallucination as a concern, it does not provide empirical evidence or quantification of its impact on the accuracy of the TCFD conformity scores.
- What evidence would resolve it: Systematic evaluation of CHATREPORT's outputs against human expert assessments to measure the frequency and severity of hallucinations in the generated scores and analyses.

### Open Question 2
- Question: How does the semantic search module's potential neglect of critical text chunks affect the comprehensiveness of CHATREPORT's analysis?
- Basis in paper: [explicit] The paper mentions that the semantic search module might occasionally overlook critical text chunks, which could impact the analysis.
- Why unresolved: The paper does not provide data on the frequency of this occurrence or its impact on the quality of the analysis.
- What evidence would resolve it: Analysis of a large sample of reports to determine the frequency of missed critical information and its impact on the final analysis and scores.

### Open Question 3
- Question: How can CHATREPORT's bias towards the firm's perspective be mitigated to provide more objective sustainability assessments?
- Basis in paper: [explicit] The paper acknowledges the inherent bias towards the firm's perspective in the extracted information and suggests incorporating external perspectives and independent sources of information as a potential solution.
- Why unresolved: The paper does not provide a concrete methodology for incorporating external perspectives or empirical evidence of its effectiveness in reducing bias.
- What evidence would resolve it: Implementation and evaluation of a modified CHATREPORT that incorporates external data sources, followed by a comparison of its assessments with those of the original tool to measure the reduction in bias.

## Limitations

- **Prompt transparency**: Exact prompt templates and iterative refinement processes are not provided, limiting external validation of claimed accuracy improvements from expert feedback.
- **Scoring criteria ambiguity**: The methodology for generating TCFD conformity scores lacks explicit criteria for partial compliance and weighting of qualitative vs. quantitative disclosures.
- **Impact evidence gaps**: While claiming to reduce reliance on rating agencies, the paper lacks empirical evidence of stakeholder adoption or market impact.

## Confidence

- **High confidence**: CHATREPORT's technical architecture (RE, RS, TCA, CQA modules) is clearly specified and aligns with standard LLM-based document analysis approaches.
- **Medium confidence**: The claim that CHATREPORT improves TCFD conformity assessment is supported by trend data showing increasing scores over time, but lacks ground truth scores and direct comparisons with human expert ratings.
- **Low confidence**: The assertion that CHATREPORT will disrupt rating agency dominance lacks empirical support without evidence of stakeholder adoption, market impact, or comparative performance against established rating methodologies.

## Next Checks

1. **Ground truth validation**: Obtain a sample of sustainability reports with expert-annotated TCFD conformity scores to validate CHATREPORT's TCA module accuracy and identify systematic biases in scoring.

2. **Expert comparison study**: Conduct a blind comparison between CHATREPORT analyses and human expert reviews on the same reports to quantify accuracy differences and identify failure modes unique to automated analysis.

3. **Stakeholder impact assessment**: Survey corporate sustainability officers, investors, and analysts to assess whether CHATREPORT's transparency features actually influence their decision-making processes or reduce reliance on traditional rating agencies.