---
ver: rpa2
title: 'Chasing Fairness Under Distribution Shift: A Model Weight Perturbation Approach'
arxiv_id: '2303.03300'
source_url: https://arxiv.org/abs/2303.03300
tags:
- fairness
- distribution
- shift
- perturbation
- source
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses fairness degradation under distribution shift
  by establishing an equivalence between distribution shift and model weight perturbation.
  The authors propose Robust Fairness Regularization (RFR), which enforces fairness
  under the worst-case weight perturbation for each sensitive attribute group.
---

# Chasing Fairness Under Distribution Shift: A Model Weight Perturbation Approach

## Quick Facts
- **arXiv ID:** 2303.03300
- **Source URL:** https://arxiv.org/abs/2303.03300
- **Reference count:** 19
- **Primary result:** RFR achieves up to 84.8% improvement on fairness metrics for mild distribution shifts

## Executive Summary
This paper addresses fairness degradation under distribution shift by establishing an equivalence between distribution shift and model weight perturbation. The authors propose Robust Fairness Regularization (RFR), which enforces fairness under the worst-case weight perturbation for each sensitive attribute group. RFR is implemented via a computationally efficient approximation using first-order Taylor expansion, requiring only two forward and two backward passes per update. Experiments on synthetic and real distribution shifts (spatial and temporal) across three datasets show that RFR achieves better fairness-accuracy tradeoffs than baselines.

## Method Summary
The paper establishes a theoretical connection between distribution shift, data perturbation, and weight perturbation using optimal transport theory. It proposes Robust Fairness Regularization (RFR) that enforces fairness under worst-case weight perturbations within Lp-norm balls for each sensitive attribute group. The method approximates the worst-case perturbation using first-order Taylor expansion, making it computationally efficient with only two forward and two backward passes per update. RFR combines classification loss, demographic parity loss, and robust fairness regularization terms.

## Key Results
- RFR achieves better fairness-accuracy tradeoffs than baselines on three datasets
- Up to 84.8% improvement on fairness metrics for mild distribution shifts
- RFR maintains robustness across both synthetic and real distribution shifts (spatial and temporal)
- Performance degrades as distribution shift intensity increases beyond mild ranges

## Why This Works (Mechanism)

### Mechanism 1
- Distribution shift is equivalent to weight perturbation through optimal transport and first-order Taylor expansion
- Core assumption: Loss function is locally linearizable around current parameters with bounded shifts
- Evidence: Theoretical connection established in sections 2.2 and 3.1
- Break condition: Highly non-linear loss landscapes or unbounded distribution shifts

### Mechanism 2
- Fairness under distribution shift requires both source fairness and low prediction difference between source and target
- Core assumption: Demographic parity metric is appropriate and prediction differences can be bounded
- Evidence: Analysis of sufficient conditions in section 3.1
- Break condition: Inappropriate fairness metric or inability to bound prediction differences

### Mechanism 3
- RFR achieves robust fairness by considering worst-case weight perturbations for each group
- Core assumption: First-order Taylor approximation and Lp-norm constraints are appropriate
- Evidence: Method description in section 3.2
- Break condition: Poor Taylor approximation or inappropriate Lp-norm constraints

## Foundational Learning

- **Concept: Optimal Transport**
  - Why needed: Establishes equivalence between distribution shift and data perturbation
  - Quick check: What is the mathematical definition of optimal transport between two distributions?

- **Concept: First-Order Taylor Expansion**
  - Why needed: Approximates worst-case weight perturbation and its gradient for computational efficiency
  - Quick check: How does Taylor expansion allow approximation of worst-case perturbations?

- **Concept: Lp-Norm Perturbation Ball**
  - Why needed: Constrains worst-case weight perturbations for computational efficiency
  - Quick check: What is an Lp-norm perturbation ball and how does it balance robustness and efficiency?

## Architecture Onboarding

- **Component map:** Classification loss -> Demographic parity loss -> Robust fairness regularization term (worst-case weight perturbations via Taylor expansion)
- **Critical path:** Computation of robust fairness regularization term via worst-case weight perturbation and gradient calculation
- **Design tradeoffs:** Computational efficiency vs robustness through Taylor approximation and Lp-norm constraints
- **Failure signatures:** Poor Taylor approximation, inappropriate Lp-norm constraints, or unsuitable fairness metrics
- **First 3 experiments:**
  1. Test equivalence between distribution shift and weight perturbation on synthetic dataset
  2. Evaluate RFR effectiveness on real-world dataset with mild distribution shift
  3. Test sensitivity to Lp-norm choice and Taylor approximation across datasets

## Open Questions the Paper Calls Out

1. How does RFR performance degrade as distribution shift intensity increases beyond mild ranges tested?
2. What is the theoretical relationship between Lp norm choice and RFR effectiveness across different shift types?
3. How does RFR compare to general distribution shift adaptation techniques that don't explicitly target fairness?

## Limitations

- Theoretical equivalence relies on first-order approximations that may break down for large shifts
- Limited ablation studies on hyperparameter impact and Lp-norm constraint choices
- Analysis restricted to demographic parity and equal opportunity metrics only

## Confidence

- **High confidence:** Computational efficiency of RFR (2 forward/backward passes) is well-established
- **Medium confidence:** Theoretical framework connecting distribution shift to weight perturbation relies on approximations
- **Medium confidence:** Empirical results show promising fairness-accuracy tradeoffs but limited to specific datasets

## Next Checks

1. Conduct ablation studies on Lp-norm constraint choices (p=1 vs p=2) across different datasets
2. Test RFR robustness to larger distribution shifts and non-linear loss landscapes
3. Evaluate RFR using additional fairness metrics (equalized odds, predictive parity)