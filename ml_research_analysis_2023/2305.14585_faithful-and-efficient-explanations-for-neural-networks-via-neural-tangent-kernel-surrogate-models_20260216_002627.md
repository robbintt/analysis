---
ver: rpa2
title: Faithful and Efficient Explanations for Neural Networks via Neural Tangent
  Kernel Surrogate Models
arxiv_id: '2305.14585'
source_url: https://arxiv.org/abs/2305.14585
tags:
- neural
- kernel
- pntk
- attribution
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper evaluates kernel-based surrogate models for neural networks
  using pseudo neural tangent kernels (pNTK). The authors propose using kGLM models
  trained on pNTK features to approximate neural network decision functions.
---

# Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models

## Quick Facts
- arXiv ID: 2305.14585
- Source URL: https://arxiv.org/abs/2305.14585
- Authors: 
- Reference count: 40
- Primary result: pNTK achieves higher Kendall-τ correlation with neural networks (τ up to 0.88) than alternatives while maintaining similar test accuracy (TAD within 2.2%)

## Executive Summary
This paper introduces a method for creating faithful and efficient explanations of neural networks using kernel-based surrogate models built on pseudo neural tangent kernels (pNTK). The authors propose training kernel generalized linear models (kGLMs) using pNTK as the kernel function to approximate neural network decision functions. Experiments across vision and language models demonstrate that pNTK achieves higher correlation with neural network predictions than alternative methods like TraceIn and Trak, while maintaining similar predictive performance and enabling effective data attribution for detecting poisoned training examples.

## Method Summary
The method trains neural networks on various datasets, computes the pNTK kernel matrix from averaged Jacobian vectors using cosine similarity, then trains kGLM models using these kernels as features. The approach compares pNTK against alternatives (TraceIn, Trak, Conjugate Kernel, Embedding Kernel) across multiple architectures (MLP, CNN, ResNet, MobileNet, BERT) and datasets (MNIST, CIFAR-10, COLA). Evaluation metrics include Kendall-τ rank correlation between surrogate and neural network softmax probabilities, Test Accuracy Differential (TAD), and precision/recall for poisoned data attribution tasks.

## Key Results
- pNTK achieves Kendall-τ correlation up to 0.88 with neural network decision functions
- pNTK maintains similar test accuracy to neural networks (TAD within 2.2%)
- pNTK outperforms alternatives in poisoned data attribution tasks with highest precision and recall
- Normalized pNTK provides more balanced attributions than unnormalized versions

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The pNTK kernel acts as a more faithful surrogate feature space for neural networks than alternatives like TraceIn or Trak.
- **Mechanism**: The pNTK computes a cosine similarity between averaged Jacobian vectors of the neural network outputs, capturing the local geometry of the decision function in parameter space. This normalized similarity measure smooths out contributions across the training dataset and reflects how similar data points influence the model similarly.
- **Core assumption**: The cosine normalization in pNTK prevents training data with large Jacobian magnitudes from dominating the kernel, leading to more balanced attributions.
- **Evidence anchors**:
  - [abstract] "we establish that a normalized psuedo neural tangent kernel (pNTK) is more correlated to the neural network decision functions than embedding based and influence based alternatives"
  - [section 4.3] "we observe that the pNTK forms surrogate models with the highest correlation to the underlying neural network decision function (measured by τ) and is furthermore consistent in replicating the performance of these networks"
  - [corpus] Weak evidence; no direct neighbor papers discuss pNTK fidelity comparisons.

### Mechanism 2
- **Claim**: The pNTK-based kernel GLM achieves high fidelity to the underlying neural network's softmax probabilities, as measured by Kendall-τ correlation.
- **Mechanism**: By training a kernel GLM using pNTK as the kernel function, the surrogate model learns weighted combinations of training data similarities that approximate the softmax outputs of the neural network. High Kendall-τ values indicate the surrogate's rank ordering of predictions matches the neural network's.
- **Core assumption**: The relationship between pNTK similarities and neural network outputs is monotonic, enabling invertible mapping functions to linearize the surrogate.
- **Evidence anchors**:
  - [abstract] "we establish that a normalized psuedo neural tangent kernel (pNTK) is more correlated to the neural network decision functions than embedding based and influence based alternatives"
  - [section 3.3] "If the relationship between the kGLM and neural network is strictly monotonic, then an invertible mapping function exists between the kGLM softmax probabilities and the neural network's"
  - [corpus] Weak evidence; no direct neighbor papers discuss Kendall-τ as evaluation metric.

### Mechanism 3
- **Claim**: The pNTK kernel enables effective data attribution for detecting poisoned training examples.
- **Mechanism**: The pNTK-based kernel GLM generates attributions that, when summed over the training dataset, equal the model's activation for each class. In poisoned data scenarios, these attributions highlight training examples that strongly influence misclassifications, enabling precision and recall metrics for detecting poisoned data.
- **Core assumption**: The pNTK similarity captures meaningful relationships between poisoned and test data, so that poisoned training examples receive high attribution when the model is tricked.
- **Evidence anchors**:
  - [abstract] "we show that the attributions created from the normalized pNTK more accurately select perturbed training data in a data poisoning attribution task than these alternatives"
  - [section 4.4] "Both normalized and unnormalized pNTK attributions perform best on precision and recall, but the normalized pNTK continues to be most correlated to the neural network"
  - [corpus] Weak evidence; no direct neighbor papers discuss poisoned data attribution with NTK methods.

## Foundational Learning

- **Concept**: Neural Tangent Kernel (NTK) and its empirical approximation (eNTK)
  - **Why needed here**: Understanding the NTK framework is crucial because pNTK is a computationally efficient approximation of the eNTK, which itself approximates the infinite-width neural network behavior. This conceptual foundation explains why kernel methods can serve as surrogate models.
  - **Quick check question**: What is the relationship between the NTK, eNTK, and pNTK, and why is the pNTK approximation necessary for practical applications?

- **Concept**: Kernel methods and kernel generalized linear models (kGLMs)
  - **Why needed here**: The paper relies on kernel methods as a way to implicitly map data into high-dimensional feature spaces where linear models can be trained. kGLMs are the specific framework used to create surrogate models of neural networks using kernel functions like pNTK.
  - **Quick check question**: How does a kernel GLM differ from a standard linear model, and why is the kernel function choice critical for fidelity to the neural network?

- **Concept**: Kendall-τ rank correlation as an evaluation metric
  - **Why needed here**: The paper uses Kendall-τ to measure the correlation between the surrogate model's predictions and the neural network's predictions. Understanding this metric is essential to interpret the results and evaluate surrogate model quality.
  - **Quick check question**: What does a Kendall-τ value of 0.88 indicate about the relationship between the kGLM and neural network predictions, and how does this differ from Pearson correlation?

## Architecture Onboarding

- **Component map**: Neural network -> Jacobian computation -> pNTK kernel calculation -> kGLM training -> Attribution generation -> Evaluation

- **Critical path**:
  1. Train neural network on dataset
  2. Compute pNTK kernel matrix using trained network's Jacobians
  3. Train kGLM using pNTK kernel and same training data
  4. Evaluate kGLM fidelity (Kendall-τ, test accuracy differential)
  5. Generate and evaluate attributions (data poisoning detection)

- **Design tradeoffs**:
  - pNTK vs full NTK: pNTK is computationally cheaper but may lose some information captured by the full NTK
  - Cosine normalization: normalizes kernel values but may obscure magnitude-based distinctions
  - Linear vs non-linear surrogate: linear kGLM enables simple attribution but may not capture all neural network behaviors
  - Single vs multiple model instances: single model pNTK analysis is more interpretable but may miss ensemble effects

- **Failure signatures**:
  - Low Kendall-τ values (<0.5) indicating poor surrogate fidelity
  - Large test accuracy differential (>5%) suggesting kGLM underperforms neural network
  - Poor precision/recall on poisoned data attribution tasks
  - Numerical instability in Jacobian computation for very deep or wide networks
  - Memory errors when computing pNTK for large datasets (N^2 kernel matrix)

- **First 3 experiments**:
  1. Train a small MLP on MNIST and compute pNTK, then train kGLM and evaluate Kendall-τ correlation
  2. Compare pNTK-based kGLM fidelity against TraceIn and Trak on CIFAR10 with ResNet18
  3. Evaluate pNTK attribution performance on a synthetic poisoned CIFAR10 dataset

## Open Questions the Paper Calls Out
- How does the computational complexity of pNTK scale with training dataset size, and what are the practical limits for large-scale models?
- Can the surrogate modeling framework be extended to adversarial training regimes and other non-standard training paradigms?
- How sensitive are the attribution results to different choices of layers used for embedding kernel calculations?

## Limitations
- The core claims rely heavily on Kendall-τ correlation as the primary fidelity metric, which may not capture all aspects of surrogate model quality
- Computational efficiency claims lack explicit runtime comparisons with alternatives
- Poisoned data attribution results use synthetic poisoning scenarios that may not reflect real-world attack patterns
- The linearization assumption for neural network surrogate modeling may break down for deeper architectures or non-standard training procedures

## Confidence
- **High confidence**: pNTK achieves higher Kendall-τ correlation than alternatives (τ up to 0.88)
- **Medium confidence**: pNTK maintains similar test accuracy to neural networks (TAD within 2.2%)
- **Medium confidence**: pNTK outperforms alternatives in poisoned data attribution

## Next Checks
1. Conduct runtime complexity analysis comparing pNTK kernel computation against TraceIn and Trak across different dataset sizes and network architectures to verify computational efficiency claims.
2. Test pNTK-based attribution on real-world poisoning datasets (e.g., from adversarial machine learning benchmarks) to validate practical effectiveness beyond synthetic scenarios.
3. Evaluate surrogate model fidelity using additional metrics beyond Kendall-τ, such as calibration error and class-wise accuracy differences, to provide a more comprehensive assessment of pNTK performance.