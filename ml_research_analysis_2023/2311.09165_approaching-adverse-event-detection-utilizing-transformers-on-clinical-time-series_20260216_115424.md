---
ver: rpa2
title: Approaching adverse event detection utilizing transformers on clinical time-series
arxiv_id: '2311.09165'
source_url: https://arxiv.org/abs/2311.09165
tags:
- data
- time-series
- clustering
- https
- clinical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This research aimed to develop an anomaly detection system for
  identifying deviations from expected clinical trajectories using vital sign recordings.
  A self-supervised framework based on the STraTS transformer architecture was employed
  to represent time series data in a latent space.
---

# Approaching adverse event detection utilizing transformers on clinical time-series

## Quick Facts
- arXiv ID: 2311.09165
- Source URL: https://arxiv.org/abs/2311.09165
- Reference count: 36
- Key outcome: A self-supervised STraTS transformer-based framework was developed to encode irregularly sampled clinical time-series into latent representations, which were then clustered to explore potential patient phenotypes, showing promise but requiring more comprehensive demographic data for full evaluation.

## Executive Summary
This research develops an unsupervised anomaly detection system for identifying deviations from expected clinical trajectories using vital sign recordings. The approach employs a modified STraTS transformer architecture to encode irregularly sampled time-series data into a latent space, which is then clustered using various techniques to explore potential patient phenotypes. Preliminary results demonstrate the framework's ability to identify clusters from clinical time series data, though the study acknowledges the need for enhanced datasets with additional demographic information to achieve more comprehensive evaluation and clinical validation.

## Method Summary
The method employs a self-supervised STraTS transformer architecture to encode irregularly sampled clinical time-series (NEWS vital signs) into latent representations. The encoded representations are clustered using K-means, HDBSCAN, GMM, and Spectral Clustering, with and without PCA dimensionality reduction. The model fuses temporal embeddings with static demographic information (gender, ward type) to create patient representations. The framework is evaluated on two subsets of data based on minimum time-series lengths (m≥4 and m≥8), with clustering performance assessed using Silhouette scores.

## Key Results
- STraTS successfully encoded irregularly sampled clinical time-series into meaningful latent representations suitable for clustering.
- Demographic fusion with temporal embeddings improved clustering structure compared to temporal embeddings alone.
- PCA reduction to 3 dimensions enhanced cluster separation and Silhouette scores compared to full latent space clustering.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The STraTS transformer can learn meaningful patient phenotypes from irregularly sampled vital signs by encoding time series into a latent space.
- Mechanism: STraTS treats each vital sign measurement as a separate triplet (time, feature, value), allowing it to naturally handle missing data and irregular sampling without imputation. This triplet-based embedding is then processed by multi-head attention and fusion with static demographic features, producing a compact patient representation suitable for clustering.
- Core assumption: The temporal and demographic patterns in vital signs are discriminative enough to form clinically meaningful clusters.
- Evidence anchors:
  - [abstract] The paper employs "a self-supervised framework based on the STraTS transformer architecture to represent the time series data in a latent space" and then clusters these representations.
  - [section 3.1] The NEWS dataset has "irregularly sampled" data with "high variability" and the STraTS architecture is chosen to handle this by "treat[ing] each measurement as a unique data-point".
  - [corpus] The corpus contains several transformer-based methods for clinical time series and ADE detection, indicating active research in this area. However, no direct evidence that STraTS specifically has been validated for clustering in this context.

### Mechanism 2
- Claim: Combining variable time-series embeddings with static demographic embeddings improves clustering separation compared to using either alone.
- Mechanism: The STraTS model produces a time-series embedding (eT) and a separate demographic embedding (ed). These are concatenated before clustering, allowing the model to capture both dynamic physiological patterns and stable patient characteristics (e.g., gender, ward type) in a single representation.
- Core assumption: Static demographic features contain clinically relevant signal that complements temporal patterns in vital signs.
- Evidence anchors:
  - [section 3.1] The paper states that "fusion to concatenate demographic information like age, sex and comorbidities... is typically very important for characterizing patient behavior."
  - [section 4.2] Experiments compare clustering with and without demographic fusion; figures suggest that demographic information influences cluster structure.
  - [corpus] The corpus contains studies that combine clinical notes and EHR for readmission prediction, supporting the value of multimodal inputs. However, there is no direct evidence that demographic fusion improves clustering specifically in this STraTS setup.

### Mechanism 3
- Claim: Clustering in the reduced PCA space of the STraTS latent representation yields better separation than clustering in the full latent space.
- Mechanism: After STraTS encoding, PCA is applied to reduce dimensionality to 3 components before clustering. This reduces noise and focuses the clustering on the dominant variation in the latent space.
- Core assumption: The first three principal components capture most of the meaningful variation for clustering, and noise in higher dimensions is detrimental to cluster separation.
- Evidence anchors:
  - [section 4.2] The paper explicitly compares clustering on raw encoded vectors (d=40) versus PCA-reduced dimensions, with better silhouette scores reported for PCA-reduced embeddings.
  - [section 4.2] Figures 3 and 4 show clearer cluster separation after PCA reduction.
  - [corpus] The corpus contains several studies using PCA/t-SNE for visualization and clustering, indicating this is a common and reasonable approach. However, no direct evidence that PCA reduction is superior for this specific STraTS-based task.

## Foundational Learning

- Concept: Self-supervised representation learning
  - Why needed here: Labeled clinical trajectories for adverse events are scarce; self-supervision (e.g., masked prediction) allows the model to learn useful representations from unlabeled data.
  - Quick check question: What is the objective used to train STraTS in this study, and why is it appropriate for unsupervised learning?

- Concept: Transformer-based sequence modeling
  - Why needed here: Clinical time series are irregular and multivariate; transformers can model complex dependencies across time and features without assuming regular sampling.
  - Quick check question: How does STraTS handle irregular sampling differently from RNN-based approaches?

- Concept: Clustering evaluation metrics (Silhouette score)
  - Why needed here: To quantitatively compare the quality of clusters produced by different methods and hyperparameter settings.
  - Quick check question: What does a higher Silhouette score indicate about the clusters, and what are its limitations in this context?

## Architecture Onboarding

- Component map: Input (multivariate time series + static demographics) -> STraTS encoder (triplet embedding → MHA blocks → contextual embedding → fusion with demographics) -> Output (fixed-length latent vector) -> Clustering (PCA optional → K-means / HDBSCAN / GMM / SC)

- Critical path:
  1. Data preprocessing (normalization, imputation, filtering)
  2. STraTS encoding (hyperparameters: dvar, dstat, MHA blocks, heads)
  3. Optional PCA reduction
  4. Clustering and evaluation

- Design tradeoffs:
  - Full latent space (d=40) vs PCA-reduced (3D): More dimensions preserve detail but risk noise; fewer dimensions simplify clustering but may lose signal.
  - Demographic fusion vs no fusion: Fusion adds information but requires careful handling of missing values.
  - Clustering algorithm choice: K-means is fast but assumes globular clusters; HDBSCAN handles noise and irregular shapes; GMM allows probabilistic assignments.

- Failure signatures:
  - Low Silhouette scores across all methods: Either the latent representation lacks discriminative power, or the data simply does not contain separable phenotypes.
  - Clusters aligned with gender but not other clinical variables: Suggests demographics dominate the signal, not physiological patterns.
  - High variance in cluster assignments across runs: Could indicate instability in the STraTS encoder or poor choice of hyperparameters.

- First 3 experiments:
  1. Train STraTS on dataset A (m ≥ 4) with and without demographic fusion; cluster in both raw and PCA-reduced spaces; compare Silhouette scores.
  2. Repeat experiment 1 on dataset B (m ≥ 8) to see if longer series improve clustering.
  3. Replace STraTS with a simple PCA baseline on statistical descriptors (min, max, mean) and compare clustering quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does incorporating more comprehensive demographic information (age, comorbidities, etc.) affect the clustering performance and clinical interpretability of the STraTS-based model?
- Basis in paper: [explicit] The authors mention that "a more diverse data material should be considered, requiring more in-depth demographic knowledge about the patients like age and comorbidities" and that "Information from patients journal may supply the model with information about patient characteristics, currently not accessible for machine learning processing due to privacy constraints."
- Why unresolved: The study only used limited demographic information (gender and ward type) due to data availability. The authors acknowledge the need for more comprehensive demographic data but have not yet tested its impact.
- What evidence would resolve it: Future experiments incorporating additional demographic variables and comparing clustering performance and clinical interpretability with the current model.

### Open Question 2
- Question: Can semi-supervised learning approaches, incorporating expert clinical knowledge, improve the identification of clinically relevant patient phenotypes in the anomaly detection system?
- Basis in paper: [explicit] The authors suggest that "a more in-depth supervision of a dedicated clinician or medical researcher should be targeted in future studies" and that "Considering the richness and complexity of possible human clinical conditions, it seems natural to take into account previous medical knowledge in future iterations of developing anomaly detection systems based on clinical time-series."
- Why unresolved: The study employed only unsupervised learning techniques. The potential benefits of incorporating expert knowledge through semi-supervised approaches have not been explored.
- What evidence would resolve it: Comparative studies between unsupervised and semi-supervised models, with input from clinical experts, to assess improvements in phenotype identification and clinical relevance.

### Open Question 3
- Question: How does the sample size of the time series data affect the model's ability to capture clinically relevant patterns, and what is the optimal minimum length for accurate anomaly detection?
- Basis in paper: [explicit] The authors experimented with two minimum time series lengths (4 and 8 data points) and observed differences in clustering performance. They note that "When the number of samples in the time-series decreases, so does the influence of transformer part of network in favor of the demographic vector."
- Why unresolved: The study only tested two specific minimum lengths. The relationship between time series length and model performance is not fully characterized, and the optimal minimum length for accurate anomaly detection is unknown.
- What evidence would resolve it: Systematic experiments varying the minimum time series length and analyzing the impact on clustering performance and clinical relevance, potentially identifying an optimal minimum length for the specific clinical context.

## Limitations
- The study relies on unsupervised clustering without explicit adverse event labels, making it difficult to validate clinical relevance of discovered clusters.
- The dataset lacks comprehensive demographic information (age, comorbidities), limiting the model's ability to capture full patient phenotypes.
- The use of imputed gender data introduces potential bias in demographic embeddings and clustering results.

## Confidence
- **High confidence**: STraTS can encode irregularly sampled clinical time-series into a latent representation suitable for downstream analysis.
- **Medium confidence**: Combining demographic and temporal embeddings improves clustering structure compared to temporal embeddings alone.
- **Low confidence**: The discovered clusters represent clinically meaningful patient phenotypes or adverse event risk profiles.

## Next Checks
1. Obtain clinical outcome labels (e.g., adverse events, readmissions) and evaluate whether discovered clusters correlate with these outcomes using supervised metrics.
2. Compare STraTS-based clustering against a strong baseline using handcrafted clinical features (e.g., NEWS scores, comorbidities) to assess relative performance.
3. Conduct an ablation study removing demographic fusion to quantify its specific contribution to clustering quality and determine if observed patterns are driven by demographics rather than physiology.