---
ver: rpa2
title: One-dimensional convolutional neural network model for breast cancer subtypes
  classification and biochemical content evaluation using micro-FTIR hyperspectral
  images
arxiv_id: '2310.15094'
source_url: https://arxiv.org/abs/2310.15094
tags:
- cancer
- breast
- spectra
- cm-1
- tissue
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study developed a 1D convolutional neural network (CaReNet-V1)
  for breast cancer subtype classification using micro-FTIR hyperspectral images.
  The model successfully distinguished cancer tissue from adjacent tissue with 89%
  accuracy, and achieved high accuracy for HER2 (83%) and triple-negative breast cancer
  (86%) subtypes.
---

# One-dimensional convolutional neural network model for breast cancer subtypes classification and biochemical content evaluation using micro-FTIR hyperspectral images

## Quick Facts
- arXiv ID: 2310.15094
- Source URL: https://arxiv.org/abs/2310.15094
- Reference count: 40
- Key outcome: 1D CNN achieved 89% accuracy for cancer vs adjacent tissue, with 83% for HER2 and 86% for triple-negative subtypes

## Executive Summary
This study presents a 1D convolutional neural network (CaReNet-V1) for breast cancer subtype classification using micro-FTIR hyperspectral images. The model successfully distinguishes cancer tissue from adjacent tissue with 89% accuracy and achieves high accuracy for HER2 (83%) and triple-negative breast cancer (86%) subtypes. A novel 1D adaptation of Grad-CAM is used to identify key biochemical wavenumbers contributing to predictions, providing interpretable results linked to molecular signatures. The approach demonstrates potential for automated, label-free breast cancer subtype assessment and may support diagnosis, treatment evaluation, and therapeutic development.

## Method Summary
The method uses dual K-means clustering to isolate tissue and paraffin regions from raw FTIR spectra, followed by EMSC preprocessing and normalization. CaReNet-V1, a 1D CNN architecture based on VGG/ResNet designs, processes 467-point biofingerprint spectra with HeNormal initialization and zero-padding. The model is trained with Adam optimizer (lr=1e-3) for 50 epochs using batch size 250, with balanced stratified 4-fold cross-validation. A 1D adaptation of Grad-CAM identifies key biochemical wavenumbers (1640-1600 cm⁻¹, 1550-1510 cm⁻¹, 1320-1280 cm⁻¹, 1080-980 cm⁻¹) for subtype classification.

## Key Results
- Cancer tissue classification accuracy: 89%
- HER2 subtype classification accuracy: 83%
- Triple-negative breast cancer classification accuracy: 86%
- Luminal A and B subtype accuracies: 74% and 68% respectively

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The dual K-means clustering isolates tissue and paraffin regions before deep learning, improving spectral quality and model performance.
- Mechanism: Raw spectra are first truncated to the amide I/II region (1700–1500 cm⁻¹) and clustered to identify tissue; a second truncation to the paraffin band (1480–1450 cm⁻¹) isolates paraffin, with tissue spectra masked to zero intensity. This ensures only relevant biochemical signals enter EMSC preprocessing.
- Core assumption: Tissue and paraffin have distinct spectral signatures that can be cleanly separated by K-means clustering.
- Evidence anchors: [section] "Firstly, for the tissue identification, raw spectra were truncated at the Amide I and II region (1700 to 1500 cm⁻¹) and modeled with k=2." [section] "Secondly, for the paraffin identification, raw spectra were truncated at the highest paraffin intensity band (1480 to 1450 cm⁻¹) and also modeled with k=2, but spectra previously clustered as tissue were set to zero intensity."
- Break condition: If tissue and paraffin spectral overlap increases (e.g., due to section thickness variations), K-means may misclassify spectra, degrading model input quality.

### Mechanism 2
- Claim: 1D convolutional layers exploit the continuous spectral axis, achieving high accuracy with fewer parameters than 2D CNNs.
- Mechanism: The CaReNet-V1 architecture processes 467 spectral points directly, using HeNormal initialization and zero-padding. This dimensionality reduction from image space to spectral space reduces parameters (~277k) and memory footprint, enabling efficient training.
- Core assumption: Spectral features are spatially distributed along the wavenumber axis and can be captured by 1D convolutions.
- Evidence anchors: [section] "CaReNet-V1 architecture, using 467x1 input shape, resulted in 277,236 parameters." [section] "Using single spectra increases the dataset size, where one mosaic of 320x320 turns into 102,400 single spectra, facilitating the training with even a couple of mosaics."
- Break condition: If biochemical features are not well aligned along the spectral axis (e.g., due to instrument drift), 1D convolutions may fail to capture relevant patterns.

### Mechanism 3
- Claim: 1D Grad-CAM links model decisions to specific biochemical wavenumbers, providing interpretable biomarker insights.
- Mechanism: Grad-CAM gradients are computed for each spectral point, then averaged and normalized to produce a heatmap of wavenumbers that maximally activate each class. These maps map directly to known biochemical signatures (e.g., amide I/II for proteins, PO₂⁻ for nucleic acids).
- Evidence anchors: [section] "The model enabled the evaluation of the most contributing wavenumbers to the predictions, providing a direct relationship with the biochemical content." [section] "Regions that contributed the most for LA classification (Fig. 5 (a)) are around 1750-1680 and 1260-1240 cm⁻¹..."
- Break condition: If the gradient signal is noisy or gradients vanish in deeper layers, Grad-CAM may produce misleading importance maps.

## Foundational Learning

- Concept: Fourier Transform Infrared (FTIR) micro-spectroscopy and spectral preprocessing
  - Why needed here: Understanding how raw hyperspectral data is transformed into analyzable spectra (truncation, outlier removal, EMSC, normalization) is essential for debugging model inputs and preprocessing pipelines.
  - Quick check question: What is the purpose of masking the paraffin region (1500–1350 cm⁻¹) during EMSC modeling?

- Concept: Convolutional Neural Networks and residual learning
  - Why needed here: CaReNet-V1 uses a residual-style architecture; knowing how residual connections help gradient flow explains why 1D CNNs succeeded where simpler models failed.
  - Quick check question: How does HeNormal initialization benefit training of deep CNNs compared to uniform initialization?

- Concept: Gradient-weighted Class Activation Mapping (Grad-CAM)
  - Why needed here: Grad-CAM is repurposed here for spectral data; understanding its mechanics (gradient pooling, ReLU, normalization) is critical for interpreting the biochemical relevance of model decisions.
  - Quick check question: In 1D Grad-CAM, what does the heatmap represent in terms of wavenumbers?

## Architecture Onboarding

- Component map: Input → 1D Conv layers (HeNormal, zero-padding) → Residual blocks → Global pooling → Dense layers → Output (sigmoid for type, softmax for subtype) → Grad-CAM module (gradient pooling over wavenumbers)
- Critical path: Spectral preprocessing → Single-spectrum batching → Forward pass through CaReNet-V1 → Class prediction → Grad-CAM computation → Biochemical interpretation
- Design tradeoffs: 1D CNN reduces parameters and memory but loses spatial context; single-spectrum batching increases dataset size but may introduce class noise; Grad-CAM adds interpretability but relies on stable gradients.
- Failure signatures: Poor clustering leads to noisy spectra; overfitting on few patients; vanishing gradients in deep layers; Grad-CAM maps dominated by noise rather than biochemical peaks.
- First 3 experiments:
  1. Verify K-means clustering isolates tissue/paraffin by visualizing cluster assignments and spectra.
  2. Train CaReNet-V1 on synthetic spectra with known biochemical peaks to confirm Grad-CAM localizes correctly.
  3. Compare 1D CNN performance to 2D CNN baseline using the same preprocessed dataset to quantify efficiency gains.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CaReNet-V1's performance change when trained and tested on a larger, more diverse breast cancer dataset with more patients and tissue samples?
- Basis in paper: [inferred] The authors suggest adding more breast cancer biopsies in future studies to improve performance evaluation and achieve better real-world performance.
- Why unresolved: The current study used only 60 cores from 30 patients, limiting the generalizability of the model.
- What evidence would resolve it: Testing CaReNet-V1 on a larger, multi-institutional dataset with hundreds of patients and diverse tissue samples would demonstrate its robustness and clinical applicability.

### Open Question 2
- Question: Can CaReNet-V1 be adapted to predict individual biomarker levels (e.g., HER2, Ki67) and other histopathological features beyond molecular subtypes?
- Basis in paper: [explicit] The authors mention that "individual receptor expressions should be assessed along biopsies augmentation" and that "some tests with the current dataset have demonstrated poor performance of CaReNet-V1 for these predictions."
- Why unresolved: The current model focuses on subtype classification but struggles with individual biomarker prediction, limiting its clinical utility for treatment planning.
- What evidence would resolve it: Training and validating CaReNet-V1 on datasets with detailed biomarker annotations would determine if it can accurately predict individual receptor levels and other histopathological features.

### Open Question 3
- Question: How does CaReNet-V1's performance compare to traditional machine learning approaches (e.g., SVM, random forest) and other deep learning architectures for FTIR-based breast cancer classification?
- Basis in paper: [inferred] The authors tested traditional 1D CNNs like VGG and ResNet but found CaReNet-V1 to be the best, yet no direct comparison with other ML approaches is provided.
- Why unresolved: Without benchmarking against established ML methods, it's unclear whether the deep learning approach offers significant advantages over simpler, more interpretable models.
- What evidence would resolve it: Conducting head-to-head comparisons of CaReNet-V1 with traditional ML algorithms and other deep learning architectures on the same dataset would clarify its relative performance and clinical value.

## Limitations
- The dual K-means clustering approach for tissue/paraffin segmentation is described but not validated against alternative methods; its effectiveness depends on consistent spectral signatures across samples.
- While the 1D CNN achieves good accuracy, the dataset is relatively small (60 images), raising concerns about generalizability to broader patient populations.
- The 1D Grad-CAM adaptation is novel for spectral data but lacks comparative validation against established biochemical analysis methods.

## Confidence

- **High confidence:** Cancer vs adjacent tissue classification (89% accuracy) - this binary task is well-established in the literature and shows robust performance.
- **Medium confidence:** Molecular subtype classification (LA: 74%, LB: 68%, HER2: 83%, TNBC: 86%) - while accuracies are good, especially for HER2 and TNBC, the lower LA/LB performance suggests limitations in distinguishing these subtypes.
- **Medium confidence:** Biochemical interpretation via 1D Grad-CAM - the approach is promising but requires further validation against known biochemical markers.

## Next Checks

1. **Cross-institutional validation:** Test the model on FTIR hyperspectral images from different breast cancer cohorts to assess generalizability and robustness to spectral variability.
2. **Biochemical validation:** Compare 1D Grad-CAM-identified wavenumbers with established biochemical markers using complementary techniques (e.g., immunohistochemistry or mass spectrometry) to confirm molecular relevance.
3. **Ablation study:** Evaluate model performance with and without the K-means clustering preprocessing step to quantify its contribution to accuracy and identify potential failure modes.