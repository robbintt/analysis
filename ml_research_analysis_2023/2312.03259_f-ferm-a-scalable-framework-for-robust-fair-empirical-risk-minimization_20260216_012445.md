---
ver: rpa2
title: 'f-FERM: A Scalable Framework for Robust Fair Empirical Risk Minimization'
arxiv_id: '2312.03259'
source_url: https://arxiv.org/abs/2312.03259
tags:
- fairness
- learning
- data
- distribution
- fair
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces f-FERM, a unified stochastic optimization
  framework for fair empirical risk minimization using f-divergence measures. The
  key innovation is a provably convergent algorithm that enables fair learning with
  small mini-batches, overcoming limitations of existing methods that are not amenable
  to stochastic optimization.
---

# f-FERM: A Scalable Framework for Robust Fair Empirical Risk Minimization

## Quick Facts
- arXiv ID: 2312.03259
- Source URL: https://arxiv.org/abs/2312.03259
- Reference count: 40
- Key outcome: Introduces f-FERM, a unified stochastic optimization framework for fair empirical risk minimization using f-divergences, achieving superior fairness-accuracy tradeoffs with small mini-batches.

## Executive Summary
This paper presents f-FERM, a novel stochastic optimization framework for training fair machine learning models using f-divergence measures. The key innovation lies in leveraging the variational representation of f-divergences to enable scalable, convergent algorithms compatible with mini-batch stochastic optimization. The framework extends to distributionally robust settings, handling potential training-test distribution shifts while maintaining fairness guarantees. Through extensive experiments on benchmark datasets, f-FERM demonstrates superior performance in balancing fairness and accuracy compared to existing methods.

## Method Summary
The f-FERM framework reformulates fair empirical risk minimization using f-divergences as regularizers. By exploiting the Legendre-Fenchel duality and variational representation of f-divergences, the authors derive a convergent stochastic optimization algorithm. The method handles both discrete and continuous sensitive attributes, with closed-form expressions available for common f-divergences like χ², KL, and reverse KL. The framework naturally extends to distributionally robust settings by incorporating ℓp norm uncertainty sets around the training distribution, ensuring fairness preservation under distribution shifts.

## Key Results
- Achieves superior fairness-accuracy tradeoffs across different batch sizes on benchmark datasets compared to state-of-the-art approaches
- Demonstrates improved robustness to distribution shifts when extended to the distributionally robust setting
- Provides theoretical convergence guarantees with rates of O(ε^-8) for general f-divergences and O(ε^-4) for strongly convex cases

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: The Legendre-Fenchel transformation linearizes the dependence of the f-divergence regularizer on input data points, enabling unbiased gradient estimation.
- **Mechanism**: By reformulating the f-divergence using its variational representation, the objective function becomes a pointwise supremum over affine transformations of the data. This allows the gradient to be expressed as a linear combination of data point functions, making it compatible with stochastic gradient descent.
- **Core assumption**: The f-divergence regularizer must be convex and have a well-defined Legendre-Fenchel transform.
- **Evidence anchors**:
  - [abstract]: "By leveraging the variational representation of f-divergences, the authors derive an efficient first-order stochastic algorithm..."
  - [section]: "Using the variational representation of f-divergences, we present a convergent stochastic optimization framework for fair learning via f-divergences."
- **Break condition**: If the f-divergence is non-convex or lacks a tractable variational form, the linearization approach fails and unbiased gradient estimation becomes impossible.

### Mechanism 2
- **Claim**: The f-FERM framework achieves superior fairness-accuracy tradeoffs by minimizing an upper bound on popular fairness violation measures.
- **Mechanism**: The f-divergence regularizers either cover or provide upper bounds for well-known fairness violations like ℓp distances, Rényi correlation, and demographic parity violation. Minimizing these regularizers implicitly controls these fairness metrics.
- **Core assumption**: The chosen f-divergence must be a valid measure of statistical independence between sensitive attributes and predictions.
- **Evidence anchors**:
  - [section]: "Further, unlike Rényi correlation [Baharlouei et al., 2020], we can utilize Legendre-Fenchel duality (and variational representation) to develop (provably) convergent algorithms with stochastic (mini-batch) updates."
  - [section]: "Further, we prove that these f-divergences either cover or provide upper bounds for the popular notions of fairness violations in the literature, such as ℓp distances, Rényi correlation [Baharlouei et al., 2020], and demographic parity (equalized odds) violation."
- **Break condition**: If the f-divergence does not adequately capture the desired notion of fairness or provides a loose upper bound, the fairness-accuracy tradeoff may be suboptimal.

### Mechanism 3
- **Claim**: The distributionally robust extension of f-FERM handles potential distribution shifts from training to test data using ℓp norm uncertainty sets.
- **Mechanism**: By incorporating uncertainty sets around the training distribution, the framework ensures fairness is preserved (up to a small violation) even when the test distribution changes slightly. This is achieved through a Lagrangian relaxation and Taylor approximation of the inner maximization problem.
- **Core assumption**: The distribution shift between training and test data is small enough to be captured by the ℓp norm uncertainty set.
- **Evidence anchors**:
  - [abstract]: "Furthermore, they extend f-FERM to the distributionally robust setting, handling potential distribution shifts from training to test data using ℓp norm uncertainty sets."
  - [section]: "This formulation guarantees that the model fairness is preserved (up to a violence of f-divergence less than κ) even when the test distribution slightly changes."
- **Break condition**: If the distribution shift is large or the uncertainty set is not appropriately sized, the robustness guarantees may not hold and fairness may degrade on the test data.

## Foundational Learning

- **Concept**: Convex conjugates and Legendre-Fenchel transformation
  - Why needed here: The Legendre-Fenchel transformation is used to linearize the f-divergence regularizer, enabling unbiased gradient estimation and stochastic optimization.
  - Quick check question: Can you explain how the Legendre-Fenchel transformation linearizes a convex function?

- **Concept**: f-divergences and their variational representations
  - Why needed here: f-divergences are used as fairness regularizers, and their variational representations are crucial for deriving the stochastic optimization algorithm.
  - Quick check question: What is the variational representation of the χ² divergence, and how does it relate to the f-FERM framework?

- **Concept**: Nonconvex-concave min-max optimization
  - Why needed here: The f-FERM problem is a nonconvex-concave min-max optimization problem, and understanding its properties is essential for deriving convergence guarantees.
  - Quick check question: How does the concavity of the f-divergence regularizer in the dual variable enable the use of first-order methods?

## Architecture Onboarding

- **Component map**: Data preprocessing -> Model architecture (softmax layer) -> Optimization algorithm (SGDA) -> Regularization (f-divergence) -> Evaluation (fairness-accuracy metrics)

- **Critical path**:
  1. Preprocess data and extract sensitive attributes
  2. Define model architecture with probability outputs
  3. Implement SGDA algorithm with f-divergence regularizers
  4. Tune hyperparameters (λ, batch size, etc.)
  5. Evaluate fairness-accuracy tradeoffs and robustness to distribution shifts

- **Design tradeoffs**:
  - Choice of f-divergence: Different f-divergences may lead to different fairness-accuracy tradeoffs and computational efficiency
  - Batch size: Smaller batch sizes enable scalability but may affect convergence and performance
  - Regularization strength (λ): Balancing fairness and accuracy requires careful tuning of λ

- **Failure signatures**:
  - Poor fairness-accuracy tradeoff: May indicate inappropriate choice of f-divergence or suboptimal λ
  - Convergence issues: Could be due to batch size, learning rate, or the nonconvex nature of the problem
  - Sensitivity to distribution shifts: May suggest the need for a more robust uncertainty set or larger δ

- **First 3 experiments**:
  1. Compare different f-divergences (χ², KL, reverse KL, etc.) on a benchmark dataset with a single sensitive attribute and small batch sizes.
  2. Evaluate the impact of batch size on fairness-accuracy tradeoffs and convergence speed.
  3. Test the distributionally robust extension of f-FERM on a dataset with simulated distribution shifts and compare to non-robust baselines.

## Open Questions the Paper Calls Out
- **Question**: Can the f-FERM framework be extended to handle fairness constraints for continuous sensitive attributes and target variables, beyond the discrete case considered in the paper?
- **Basis in paper**: [explicit] The paper mentions that extending f-FERM to continuous variables is challenging due to the need to compute integrals over the probability distribution, and leaves this as a future direction.
- **Why unresolved**: The paper does not provide any concrete approaches or results for extending f-FERM to continuous variables, leaving the feasibility and performance of such an extension unclear.
- **What evidence would resolve it**: A proposed approach for extending f-FERM to continuous variables, along with experimental results demonstrating the performance of the extended method on benchmark datasets with continuous sensitive attributes and target variables.

## Limitations
- Limited analysis of convergence rates for different f-divergence functions beyond the strongly convex case
- Focus on small distribution shifts in the distributionally robust extension, with unclear performance for large shifts
- No concrete approach provided for extending the framework to continuous sensitive attributes and target variables

## Confidence
- Variational representation and stochastic optimization: High
- Fairness-accuracy tradeoff claims: Medium-High
- Distributionally robust extension: Medium

## Next Checks
1. Implement and test the algorithm with different f-divergences on a benchmark dataset to verify the claimed fairness-accuracy tradeoffs
2. Evaluate convergence behavior across different batch sizes to validate scalability claims
3. Test the distributionally robust extension with simulated distribution shifts to assess robustness guarantees