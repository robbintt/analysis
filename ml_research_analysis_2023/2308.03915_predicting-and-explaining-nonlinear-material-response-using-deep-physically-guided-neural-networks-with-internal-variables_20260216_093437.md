---
ver: rpa2
title: Predicting and explaining nonlinear material response using deep Physically
  Guided Neural Networks with Internal Variables
arxiv_id: '2308.03915'
source_url: https://arxiv.org/abs/2308.03915
tags:
- material
- data
- networks
- neural
- variables
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Physically Guided Neural Networks with Internal
  Variables (PGNNIVs) to predict and explain nonlinear material response from force-displacement
  data alone, without needing internal variable measurements. PGNNIVs enforce physical
  constraints via specific hidden layers and use supervised training on measured data.
---

# Predicting and explaining nonlinear material response using deep Physically Guided Neural Networks with Internal Variables

## Quick Facts
- **arXiv ID**: 2308.03915
- **Source URL**: https://arxiv.org/abs/2308.03915
- **Reference count**: 40
- **Primary result**: PGNNIVs predict nonlinear material response from force-displacement data alone, achieving <10% displacement error and <5% stress/strain error without needing internal variable measurements.

## Executive Summary
This paper introduces Physically Guided Neural Networks with Internal Variables (PGNNIVs) that can predict and explain nonlinear material response using only force-displacement data, without requiring measurements of internal variables like stress or strain. PGNNIVs enforce physical constraints through specific hidden layers and use supervised training on measured data. The method demonstrates high accuracy in predicting both internal (stress/strain) and external (displacement) variables for unseen load cases across linear, hardening/softening, and hyperelastic materials. By placing this approach within Explainable AI, the paper highlights how PGNNIVs can identify constitutive model parameters and uncover nonlinear constitutive laws, providing both predictive capability and explanatory insight into material behavior.

## Method Summary
PGNNIVs combine a predictive network Y that maps measurable forces to displacements with an explanatory network H that learns the constitutive law mapping strains to stresses. The architecture enforces equilibrium and compatibility equations through penalty terms in the loss function, allowing the networks to learn from force-displacement data alone without requiring internal variable measurements. The predictive network uses an autoencoder-like structure to capture load case variability, while the explanatory network employs a moving multilayer perceptron with convolutional filters for efficient element-wise processing. Physical constraints are embedded as regularization terms, with parametric and non-parametric versions available for constitutive law discovery and parameter identification respectively.

## Key Results
- PGNNIVs achieve relative errors below 10% for displacements and 5% for stresses/strains across multiple material types
- The method successfully identifies constitutive model parameters and uncovers nonlinear constitutive laws from force-displacement data alone
- PGNNIVs demonstrate superior extrapolation and generalization compared to standard neural networks when predicting responses to unseen load cases

## Why This Works (Mechanism)

### Mechanism 1
PGNNIVs predict both external (displacement) and internal (stress/strain) variables from force-displacement data alone by using physics-informed constraints on hidden layers to enforce equilibrium and compatibility equations. The predictive network maps measurable forces to displacements while the explanatory network learns the constitutive law mapping strains to stresses. Physical constraints are embedded as penalty terms in the loss function. The core assumption is that material response follows known continuum mechanics principles even if the exact constitutive law is unknown.

### Mechanism 2
PGNNIVs identify constitutive model parameters and discover constitutive laws without prior parametric assumptions by learning the strain-stress relationship directly from data. The explanatory network H can be constrained to specific functional forms with free parameters for parametric discovery, or implemented as a flexible neural network for non-parametric discovery. The core assumption is that constitutive behavior can be represented by a neural network or parametric function of strain.

### Mechanism 3
PGNNIVs achieve better extrapolation and generalization compared to standard neural networks by incorporating physical constraints that regularize the learning process. These constraints prevent overfitting to training data and ensure predictions respect physical laws, leading to better performance on unseen load cases. The core assumption is that physical constraints are valid across the entire range of possible inputs, not just the training data.

## Foundational Learning

- **Neural network fundamentals**: Understanding forward propagation, backpropagation, and loss functions is essential as PGNNIVs build on standard neural network architectures with physical constraint modifications. Quick check: Can you explain how a neural network computes its output given an input and how it updates its weights during training?

- **Continuum mechanics basics**: Knowledge of equilibrium equations, compatibility conditions, and constitutive relations is necessary as PGNNIVs embed these physical principles as constraints in the neural network architecture. Quick check: Can you write down the equilibrium equation for a solid in both spatial and material coordinates?

- **Dimensionality reduction and manifold learning**: Understanding autoencoder concepts is important as the predictive network acts as a reduced order model to capture variability in load cases. Quick check: What is the difference between PCA and manifold learning approaches like autoencoders?

## Architecture Onboarding

- **Component map**: Input layer (force/displacement boundary conditions) → Predictive network Y (forces to displacements) → Strain calculation → Explanatory network H (strains to stresses) → Physical constraint evaluation → Output layer (predicted displacements and internal variables)

- **Critical path**: Input → Y network → displacement prediction → strain calculation → H network → stress prediction → physical constraint evaluation → loss calculation → weight updates

- **Design tradeoffs**: Network complexity vs. data requirements (more complex networks capture more behaviors but need more data), physics constraint strength vs. flexibility (stronger constraints ensure validity but may limit capturing deviations), parametric vs. non-parametric H (parametric allows direct parameter identification but requires functional assumptions; non-parametric is more flexible but less interpretable)

- **Failure signatures**: High training loss but low validation loss indicates overfitting (consider stronger physical constraints or more data), high loss on both training and validation suggests network capacity too low or learning rate too small, physical constraints dominating loss means constraint weights are too high, predicted stresses violating material limits indicates network not capturing material nonlinearity correctly

- **First 3 experiments**: 1) Train PGNNIV on synthetic linear elastic data with known parameters, compare predicted vs. true parameters, 2) Train PGNNIV on synthetic nonlinear data (softening/hardening), test prediction accuracy on unseen load cases, 3) Compare PGNNIV performance vs. standard neural network on same dataset, focusing on extrapolation to new load cases

## Open Questions the Paper Calls Out

### Open Question 1
How does the accuracy of PGNNIVs scale with the complexity of the constitutive model and the dimensionality of the problem? The paper demonstrates good accuracy for simple 2D problems with linear and nonlinear materials but acknowledges that extensions to 3D problems with more complex geometries and constitutive laws remain open challenges. This remains unresolved because the paper does not explore performance on more complex problems or provide systematic analysis of accuracy scaling. What would resolve it: Numerical experiments comparing PGNNIVs to other methods on problems with increasing complexity, including 3D geometries, time-dependent materials, and heterogeneous conditions.

### Open Question 2
How can the interpretability of PGNNIVs be improved, particularly for the explanatory network H? The paper notes that physical knowledge is encoded in the weights of the predictive network Y, but is more structured in the explanatory network H, yet H's interpretability remains limited. This remains unresolved because the paper does not propose specific methods to improve H's interpretability or discuss how to extract physical insights from its structure. What would resolve it: Techniques for visualizing or analyzing H's structure, such as sensitivity analysis, feature importance ranking, or model compression methods.

### Open Question 3
How can PGNNIVs be adapted to handle noisy data from real-world experiments? The paper generates synthetic data for training but acknowledges that real-world data is often noisy and limited in quantity. This remains unresolved because the paper does not discuss handling noise in data or training with limited data. What would resolve it: Numerical experiments comparing PGNNIV performance on noisy versus clean data, and techniques for data augmentation or regularization to improve robustness to noise.

## Limitations
- The paper demonstrates strong performance on synthetic data but real-world validation remains untested
- Specific network architectures and hyperparameters for different material types are not fully detailed, making exact reproduction challenging
- The claim of working without internal variable measurements requires careful examination of what data is actually needed during training

## Confidence
- **High confidence**: The core mechanism of using physics constraints to regularize neural networks and improve generalization is well-established in the literature
- **Medium confidence**: Specific implementation details for handling different material types and exact architecture choices are not fully specified
- **Medium confidence**: The claim of working without internal variable measurements is plausible but requires careful examination of training data requirements

## Next Checks
1. **Architecture Specification Validation**: Request and implement the exact network architectures (layer sizes, activation functions, etc.) for predictive and explanatory networks across all material types tested

2. **Real Data Testing**: Apply PGNNIV to experimental force-displacement data from actual material tests (e.g., tensile tests) to verify performance beyond synthetic FEM data

3. **Constraint Sensitivity Analysis**: Systematically vary the strength of physical constraints in the loss function and measure impact on prediction accuracy and generalization to quantify the optimal balance between physics enforcement and data-driven learning