---
ver: rpa2
title: Extraction of Medication and Temporal Relation from Clinical Text using Neural
  Language Models
arxiv_id: '2310.02229'
source_url: https://arxiv.org/abs/2310.02229
tags:
- which
- learning
- information
- text
- temporal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates deep learning models for extracting medication
  mentions and temporal relations from clinical text. The authors use BiLSTM-CRF and
  CNN-BiLSTM models for medication entity recognition, and a BERT-CNN model for temporal
  relation extraction on i2b2 datasets.
---

# Extraction of Medication and Temporal Relation from Clinical Text using Neural Language Models

## Quick Facts
- arXiv ID: 2310.02229
- Source URL: https://arxiv.org/abs/2310.02229
- Reference count: 40
- Primary result: CNN-BiLSTM achieves 78.17 F1 for medication NER; BERT-CNN achieves 65.03 F1 for temporal relation extraction

## Executive Summary
This paper investigates deep learning approaches for extracting medication mentions and temporal relations from clinical text using i2b2 datasets. The authors compare BiLSTM-CRF and CNN-BiLSTM models for medication entity recognition, finding the CNN-BiLSTM slightly outperforms with 78.17 F1 score. For temporal relation extraction, they employ a BERT-CNN model achieving 65.03 F1. The study also implements post-processing rules to generate structured medication usage status. Key limitations include limited training data and class imbalance in medication-date relations, with future work planned on domain-specific BERT models and data augmentation.

## Method Summary
The study employs three main deep learning approaches: BiLSTM-CRF and CNN-BiLSTM for medication entity recognition, and BERT-CNN for temporal relation extraction. The CNN-BiLSTM model fuses character-level CNN features with word-level BiLSTM context modeling, while the BERT-CNN leverages pre-trained contextualized embeddings with convolutional feature refinement. The i2b2-2009 and i2b2-2012 clinical text datasets are preprocessed through tokenization and parsing before model training. Post-processing rules combine extracted relations with admission/discharge dates to generate structured medication usage status.

## Key Results
- CNN-BiLSTM slightly outperforms BiLSTM-CRF for medication NER with 78.17 F1 score
- BERT-CNN model achieves 65.03 F1 for temporal relation extraction (BEFORE/AFTER/OVERLAP)
- Post-processing rules successfully convert relation predictions into structured medication usage status

## Why This Works (Mechanism)

### Mechanism 1
- Claim: CNN-BiLSTM outperforms BiLSTM-CRF for NER by fusing character-level CNN features with word-level BiLSTM context modeling.
- Mechanism: The CNN extracts subword patterns (prefixes/suffixes), concatenates them with GloVe embeddings, then BiLSTM learns sequence dependencies; CRF optionally constrains label transitions.
- Core assumption: Character-level morphological features improve recognition of medical terms with rare or unseen words.
- Evidence anchors:
  - [abstract] "CNN-BiLSTM slightly wins the BiLSTM-CRF model... yielding 75.67, 77.83, and 78.17 for precision, recall, and F1 scores"
  - [section] "This enables the model to make better use of character-level features such as prefixes and suffixes, which can reduce the work of manual feature construction."
- Break condition: If medical vocabulary is already in GloVe, or if domain-specific tokenization removes benefit of subword patterns.

### Mechanism 2
- Claim: BERT-CNN improves temporal relation extraction by leveraging pre-trained contextualized embeddings and local convolutional feature refinement.
- Mechanism: BERT encodes full EMR context; CNN kernels with different widths extract n-gram patterns for relation classification; output layer maps to BEFORE/AFTER/OVERLAP.
- Core assumption: Contextual word embeddings capture syntactic/semantic cues for temporal relation that static embeddings miss.
- Evidence anchors:
  - [abstract] "BERT-CNN model also produced reasonable evaluation scores 64.48, 67.17, and 65.03 for P/R/F1"
  - [section] "BERT+CNN model can achieve a relatively good classification result, indicating that the pre-trained model BERT-base can extract the semantic information well of dialogue text."
- Break condition: If dataset is too small for BERT's capacity, or if temporal cues are purely lexical without context.

### Mechanism 3
- Claim: Post-processing rules convert relation predictions into structured medication status by combining admission/discharge dates with extracted medication-date relations.
- Mechanism: Admission date AFTER medication + discharge date BEFORE/OVERLAP → "IN USE"; admission date OVERLAP + discharge date OVERLAP → "IN USE"; otherwise "OUT OF USE" or "UNKNOWN".
- Core assumption: Clinical narratives reliably mention medication status around admission/discharge timestamps.
- Evidence anchors:
  - [abstract] "We also designed a set of post-processing roles to generate structured output on medications and the temporal relation."
  - [section] "We apply an open resource tool SparkNLP... to generate more informative results and a structured representation table."
- Break condition: If medication events are not anchored to admission/discharge times, or if narratives omit explicit temporal markers.

## Foundational Learning

- **BiLSTM and CRF**: Why needed here: BiLSTM captures sequential dependencies; CRF enforces valid label transitions in NER. Quick check question: What label transition would CRF forbid that a vanilla BiLSTM might allow?
- **CNN for character-level features**: Why needed here: Medical terms often contain meaningful prefixes/suffixes not captured by word embeddings. Quick check question: How does max-pooling over character convolutions help generalize to unseen words?
- **BERT and Transformer attention**: Why needed here: Temporal relations depend on full sentence context, not just local windows. Quick check question: Why does BERT's bidirectional context help distinguish BEFORE vs AFTER relations?

## Architecture Onboarding

- **Component map**: Raw text → GATE/Ctakes tokenization → BiLSTM-CRF or CNN-BiLSTM NER → BERT-CNN relation extraction → Post-processing rules → Structured CSV output
- **Critical path**: NER accuracy → Relation extraction precision → Post-processing rule coverage → Final structured output correctness
- **Design tradeoffs**: BiLSTM-CRF is lighter and faster; CNN-BiLSTM has higher accuracy but needs more data; BERT-CNN is most accurate but computationally heavy
- **Failure signatures**: NER recall <80% → many missed medications; relation precision <70% → wrong temporal status; post-processing rules miss 30% → incomplete status assignment
- **First 3 experiments**:
  1. Train BiLSTM-CRF vs CNN-BiLSTM on 2009 dataset, compare NER F1
  2. Fine-tune BERT-base on 2012 relation subset, evaluate BEFORE/AFTER/OVERLAP classification
  3. Apply post-processing rules on small sample, manually validate medication status classification

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would domain-specific pre-trained language models like Med-BERT perform compared to general BERT models for medication and temporal relation extraction in clinical texts?
- Basis in paper: [explicit] The authors mention investigating domain-specific pre-trained BERT models like Med-BERT for future work to improve model performance.
- Why unresolved: The study only used the general BERT-base model and did not compare it with domain-specific models.
- What evidence would resolve it: Running experiments using Med-BERT or other clinical domain-specific pre-trained models on the same i2b2 datasets and comparing the results with the BERT-base model's performance.

### Open Question 2
- Question: What is the optimal approach for handling the imbalance in medication-date relation samples in the training data?
- Basis in paper: [explicit] The authors note that the proportion of data annotated with relationships between medications and corresponding dates is inadequate, leading to poor performance in extracting MEDICATION-DATE relations.
- Why unresolved: The study did not explore different techniques for handling data imbalance, such as oversampling, undersampling, or using class weights.
- What evidence would resolve it: Conducting experiments with various data imbalance handling techniques and comparing their impact on the model's performance in extracting medication-date relations.

### Open Question 3
- Question: How effective are data augmentation techniques, such as using synthetic data, in improving the model's performance for medication and temporal relation extraction?
- Basis in paper: [explicit] The authors mention data-set augmentation, e.g., using synthetic data, as a potential avenue for future work to improve model performances.
- Why unresolved: The study did not employ any data augmentation techniques to increase the size or diversity of the training data.
- What evidence would resolve it: Implementing data augmentation techniques, such as generating synthetic clinical texts or applying data transformation methods, and evaluating their impact on the model's performance.

## Limitations
- Limited training data size compared to general-domain NLP datasets
- Class imbalance in medication-date relation samples affecting performance
- Post-processing rules may not generalize across diverse clinical documentation styles

## Confidence
- **High confidence**: The general architecture choices (BiLSTM-CRF for NER, BERT for contextual embeddings) are well-established and theoretically sound
- **Medium confidence**: The specific performance improvements reported (CNN-BiLSTM vs BiLSTM-CRF, BERT-CNN for temporal relations) are likely accurate but may not generalize to larger or different datasets
- **Medium confidence**: The post-processing rules for generating structured output are plausible but not rigorously validated against clinical standards

## Next Checks
1. **Dataset Size Impact**: Train the same models on progressively larger subsets of the i2b2 data to determine whether performance scales with data size, particularly for the CNN-BiLSTM component
2. **Cross-Domain Validation**: Apply the trained models to clinical text from different institutions or EHR systems to assess generalizability beyond the i2b2 corpus
3. **Manual Annotation Verification**: Select 100 medication mentions and 100 temporal relations from the test set and have domain experts verify whether the model predictions align with clinical interpretation standards