---
ver: rpa2
title: 'OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning'
arxiv_id: '2306.11249'
source_url: https://arxiv.org/abs/2306.11249
tags:
- recurrent-free
- predrnn
- learning
- recurrent-based
- convlstm
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: OpenSTL is a comprehensive benchmark for spatio-temporal predictive
  learning that systematically evaluates recurrent-based and recurrent-free models
  across diverse tasks. The authors find that recurrent-free models achieve competitive
  performance with significantly higher efficiency, especially in real-world video
  prediction and weather forecasting tasks.
---

# OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning

## Quick Facts
- arXiv ID: 2306.11249
- Source URL: https://arxiv.org/abs/2306.11249
- Reference count: 40
- Key outcome: Recurrent-free models achieve competitive performance with significantly higher efficiency, especially in real-world video prediction and weather forecasting tasks

## Executive Summary
OpenSTL is a comprehensive benchmark that systematically evaluates recurrent-based and recurrent-free models for spatio-temporal predictive learning across diverse tasks. The benchmark reveals that recurrent-free models, particularly those using MetaFormers, can achieve comparable or superior performance to recurrent-based models while offering significant efficiency advantages. This challenges the traditional dominance of recurrent architectures in capturing temporal dependencies and suggests new directions for efficient spatio-temporal modeling.

## Method Summary
OpenSTL provides a unified framework for comparing spatio-temporal predictive learning methods by implementing 14 representative STL methods across five diverse tasks: Moving MNIST, KTH, Human3.6M, Kitti&Caltech, TaxiBJ, and WeatherBench. The framework standardizes evaluation metrics including MSE, MAE, RMSE, SSIM, PSNR, LPIPS, FPS, FLOPs, and parameter counts. Models are implemented with consistent encoder-decoder architectures, differing primarily in their temporal modeling modules (recurrent-based vs recurrent-free approaches like MetaFormers).

## Key Results
- Recurrent-free models achieve a good balance between efficiency and performance compared to recurrent models
- Recurrent-free models demonstrate significant superiority over recurrent models in weather forecasting tasks
- MetaFormers effectively boost recurrent-free spatial-temporal predictive learning by reformulating the problem as a vision backbone task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Recurrent-free models achieve comparable performance to recurrent-based models with significantly higher efficiency in spatio-temporal predictive learning.
- Mechanism: Recurrent-free models leverage a general architecture that combines spatial encoding via 2D convolutions with temporal modeling in a low-dimensional latent space using MetaFormers or similar modules. This global temporal inductive bias captures low-frequency dependencies efficiently, avoiding the sequential computation bottleneck of recurrent architectures.
- Core assumption: The spatial-temporal patterns in the datasets can be adequately captured without explicit frame-by-frame temporal modeling, particularly for tasks with lower frequency dynamics or when high efficiency is prioritized.
- Evidence anchors:
  - [abstract] "recurrent-free models achieve a good balance between efficiency and performance than recurrent models"
  - [section] "While recurrent-based models have been well developed, we rethink the potential of recurrent-free models based on insights from OpenSTL"
  - [corpus] Weak evidence. Corpus lacks direct comparison of recurrent-free vs recurrent-based efficiency metrics.
- Break condition: Tasks requiring precise modeling of high-frequency temporal changes where sequential tracking of frame-by-frame changes is critical.

### Mechanism 2
- Claim: MetaFormers provide effective temporal modeling in recurrent-free architectures by reformulating spatio-temporal prediction as a vision backbone task.
- Mechanism: MetaFormers replace traditional temporal modules by stacking low-dimensional representations along the temporal dimension and applying transformer-like attention mechanisms across frames. This enables efficient capture of global temporal dependencies without recurrent computation.
- Core assumption: The spatial encoding produced by 2D convolutions contains sufficient temporal structure when stacked, allowing transformer modules to model temporal dependencies effectively.
- Evidence anchors:
  - [abstract] "we further extend the common MetaFormers to boost recurrent-free spatial-temporal predictive learning"
  - [section] "Thus, we employ MetaFormers [51] as the temporal module by changing the input channels from the original C to inter-frame channels T × C"
  - [corpus] Weak evidence. No corpus papers directly validate MetaFormer extensions for spatio-temporal prediction.
- Break condition: When local temporal patterns are dominant and require fine-grained sequential modeling that global attention cannot capture.

### Mechanism 3
- Claim: Recurrent-based models excel at capturing high-frequency spatio-temporal dependencies due to their sequential tracking of frame-by-frame changes.
- Mechanism: The recurrent structure in models like ConvLSTM and ST-LSTM maintains memory states that propagate temporal information sequentially, providing local temporal inductive bias that is beneficial for high-frequency dynamics.
- Core assumption: High-frequency temporal changes in the data require sequential processing to maintain precise temporal relationships between consecutive frames.
- Evidence anchors:
  - [abstract] "recurrent-based models excel in capturing temporal dependencies, while recurrent-free models achieve comparable performance with significantly higher efficiency"
  - [section] "The effectiveness of recurrent-based models in capturing high-frequency spatio-temporal dependencies can be attributed to their sequential tracking of frame-by-frame changes"
  - [corpus] Weak evidence. Corpus lacks specific analysis of high-frequency vs low-frequency temporal modeling.
- Break condition: When computational efficiency is prioritized over capturing subtle high-frequency temporal changes.

## Foundational Learning

- Concept: Understanding the distinction between local and global temporal inductive biases
  - Why needed here: Different model architectures (recurrent vs recurrent-free) provide different inductive biases for temporal modeling, affecting their suitability for various spatio-temporal prediction tasks
  - Quick check question: What type of temporal patterns (high-frequency vs low-frequency) would benefit more from sequential tracking versus global attention mechanisms?

- Concept: Knowledge of transformer architectures and their adaptation for vision tasks
  - Why needed here: MetaFormers and similar modules extend transformer principles to spatio-temporal domains, requiring understanding of self-attention mechanisms and their application beyond natural language processing
  - Quick check question: How does stacking low-dimensional spatial representations along the temporal dimension enable transformer modules to model temporal dependencies?

- Concept: Familiarity with different types of spatio-temporal data and their characteristics
  - Why needed here: The benchmark covers diverse datasets from synthetic trajectories to real-world video and weather forecasting, each with distinct spatial and temporal properties affecting model selection
  - Quick check question: How would the temporal frequency characteristics of traffic flow data differ from those of video prediction tasks, and what architectural implications would this have?

## Architecture Onboarding

- Component map: Encoder (2D Conv) -> Temporal Module (MetaFormer/IncepU/TAU/gSTA) -> Decoder (2D Conv Upsampling)
- Critical path:
  1. Input frames → spatial encoding (encoder)
  2. Encoded features → temporal modeling (temporal module)
  3. Temporally processed features → spatial decoding (decoder)
  4. Output prediction → evaluation against ground truth
- Design tradeoffs:
  - Recurrent-based: Better for high-frequency temporal patterns but computationally expensive
  - Recurrent-free: Higher efficiency and good for low-frequency patterns but may miss fine temporal details
  - Spatial resolution vs computational cost: Higher resolution increases memory and compute requirements significantly
- Failure signatures:
  - Blurry predictions in recurrent-free models for high-frequency tasks
  - Slow inference speeds in recurrent-based models for real-time applications
  - Poor performance on datasets with subtle temporal dynamics requiring sequential processing
- First 3 experiments:
  1. Compare a simple recurrent-free model (ConvMixer-based) against ConvLSTM on Moving MNIST to observe efficiency vs accuracy tradeoff
  2. Test MetaFormer variants (ViT, Swin, Uniformer) in the temporal module to identify which transformer architecture works best for spatio-temporal data
  3. Evaluate model performance on low-frequency tasks (traffic flow, weather forecasting) to confirm recurrent-free superiority in macro-scale predictions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can recurrent-free models consistently outperform recurrent-based models across all spatio-temporal predictive learning tasks?
- Basis in paper: [explicit] The authors find that recurrent-free models achieve a good balance between efficiency and performance than recurrent models in various tasks, and demonstrate significant superiority over their counterparts in weather forecasting.
- Why unresolved: The paper provides evidence of recurrent-free models' superiority in certain tasks (e.g., weather forecasting), but doesn't conclusively demonstrate consistent outperformance across all possible spatio-temporal predictive learning tasks.
- What evidence would resolve it: Comprehensive benchmarking of recurrent-free and recurrent-based models across a wider variety of spatio-temporal predictive learning tasks, including different domains, scales, and data types, would provide more definitive evidence of their relative performance.

### Open Question 2
- Question: What are the fundamental differences between the spatial encoding and temporal modeling in MetaVP and the token mixing and channel mixing in MetaFormer that make them effective for recurrent-free models?
- Basis in paper: [explicit] The authors note a correspondence between the spatial encoding and temporal modeling in MetaVP and the token mixing and channel mixing in MetaFormer, but question whether this can be further leveraged to improve recurrent-free models.
- Why unresolved: The paper acknowledges the connection between these concepts but doesn't delve into the specific mechanisms or theoretical foundations that make them effective.
- What evidence would resolve it: Detailed analysis of the mathematical and architectural similarities and differences between MetaVP's spatial encoding/temporal modeling and MetaFormer's token mixing/channel mixing, along with empirical studies of their impact on recurrent-free model performance, would provide insights into their effectiveness.

### Open Question 3
- Question: How can the strengths of both recurrent-based and recurrent-free models be effectively combined to enhance spatio-temporal predictive learning?
- Basis in paper: [inferred] The authors mention that while recurrent architectures are beneficial in capturing temporal dependencies, they are not always necessary, especially for computationally expensive tasks. This suggests the potential for hybrid approaches.
- Why unresolved: The paper focuses on comparing recurrent-based and recurrent-free models but doesn't explore potential hybrid architectures that could leverage the strengths of both approaches.
- What evidence would resolve it: Development and evaluation of hybrid architectures that incorporate elements of both recurrent-based and recurrent-free models, along with ablation studies to isolate the contributions of each component, would provide insights into the potential benefits of such approaches.

## Limitations
- Limited empirical validation of efficiency claims with quantitative FLOPs and parameter comparisons
- Dataset generalization gaps not fully explored across different data distributions
- Implementation dependencies may affect reproducibility of reported performance improvements

## Confidence
- High confidence: The core claim that recurrent-free models can achieve competitive performance while being more efficient
- Medium confidence: The specific performance comparisons between model families across different tasks
- Low confidence: The assertion that MetaFormers significantly improve recurrent-free STL performance

## Next Checks
1. Conduct detailed FLOPs and parameter count comparisons between recurrent and recurrent-free models across all benchmark tasks to verify the claimed efficiency advantages
2. Perform ablation studies varying key hyperparameters (learning rate, batch size, temporal window size) for both recurrent and recurrent-free models to assess robustness
3. Train models on one dataset and evaluate on another to assess cross-dataset generalization of performance patterns