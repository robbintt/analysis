---
ver: rpa2
title: Question Decomposition Improves the Faithfulness of Model-Generated Reasoning
arxiv_id: '2307.11768'
source_url: https://arxiv.org/abs/2307.11768
tags:
- reasoning
- answer
- question
- decomposition
- human
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Large language models are becoming harder to verify for correctness
  and safety as they tackle more complex tasks. To address this, one approach is to
  have models generate step-by-step reasoning (Chain-of-Thought, or CoT).
---

# Question Decomposition Improves the Faithfulness of Model-Generated Reasoning

## Quick Facts
- arXiv ID: 2307.11768
- Source URL: https://arxiv.org/abs/2307.11768
- Reference count: 40
- Primary result: Question decomposition methods significantly improve the faithfulness of model-generated reasoning while maintaining strong question-answering performance

## Executive Summary
Large language models are becoming harder to verify for correctness and safety as they tackle more complex tasks. To address this, one approach is to have models generate step-by-step reasoning (Chain-of-Thought, or CoT). However, CoT reasoning is not always faithful to the model's actual reasoning process. This paper explores question decomposition as an alternative to CoT, where models break questions into subquestions, answer them, and then recombine the answers. Two decomposition methods are studied: factored decomposition (answering subquestions in separate contexts) and chain-of-thought decomposition (similar to CoT but with subquestions and answers). Both methods maintain strong question-answering performance, sometimes approaching CoT, while significantly improving the faithfulness of the model's stated reasoning. Factored decomposition shows the largest improvement in faithfulness, reducing biased reasoning and increasing sensitivity to reasoning perturbations. These findings demonstrate that question decomposition can elicit more faithful reasoning from models, potentially enabling better verification of their correctness and safety.

## Method Summary
The paper evaluates three prompting strategies for question-answering tasks: zero-shot/few-shot prompting, Chain-of-Thought (CoT), and two decomposition methods (factored decomposition and CoT decomposition). Factored decomposition answers subquestions in separate contexts to reduce biased reasoning, while CoT decomposition uses a single context similar to CoT but with explicit subquestions and answers. The methods are tested on four multiple-choice question-answering datasets (HotpotQA, StrategyQA, OpenBookQA, TruthfulQA) using 300 test questions per task. Faithfulness is measured through perturbation experiments including truncation and corruption sensitivity, and biased context experiments. The study uses a pretrained language model similar to Claude 1.3 and evaluates both question-answering accuracy and reasoning faithfulness.

## Key Results
- Factored decomposition shows the largest improvement in reasoning faithfulness, reducing biased reasoning and increasing sensitivity to reasoning perturbations
- Both decomposition methods maintain strong question-answering performance, sometimes approaching CoT performance levels
- Decomposition methods significantly reduce the model's susceptibility to biasing features in the original question context

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposition-based methods improve faithfulness by reducing biased reasoning
- Mechanism: When answering subquestions in separate contexts, biasing features from the original question (like demographic information or suggested answers) cannot influence the subquestion responses
- Core assumption: The subquestions generated during decomposition do not contain the biasing features present in the original question
- Evidence anchors:
  - [abstract] "Factored decomposition shows the largest improvement in faithfulness, reducing biased reasoning and increasing sensitivity to reasoning perturbations"
  - [section] "We expect a reduction in biased reasoning because each subquestion qi is answered in an independent context from all other subquestions and the original question q"
  - [corpus] Weak evidence - related work mentions mitigating spurious correlations but doesn't directly test this mechanism
- Break condition: If subquestions inadvertently copy biasing features from the original question into the subquestion context

### Mechanism 2
- Claim: Decomposition improves faithfulness by reducing ignored reasoning
- Mechanism: The model generates clearer relationships between subquestion answers and later subquestions/final answer, making it harder to ignore reasoning steps
- Core assumption: The model conditions more strongly on reasoning when the reasoning explicitly defines relationships between steps
- Evidence anchors:
  - [abstract] "CoT decomposition... uses one context to generate subquestions, answer subquestions, and answer the original question... CoT decomposition may mitigate ignored reasoning for similar reasons to factored decomposition"
  - [section] "The answers to earlier subquestions often have a clearly specified relationship to later subquestions... At the final step, where the model uses the collected reasoning sample to answer the question, the model can potentially still ignore subquestions and subanswers that do not fit its biases"
  - [corpus] Weak evidence - related work on faithfulness doesn't explicitly test this causal relationship
- Break condition: If the model learns to generate reasoning that appears structured but doesn't actually condition on it

### Mechanism 3
- Claim: Decomposition improves faithfulness through intermediate supervision
- Mechanism: Breaking down complex reasoning into simpler subquestions provides more frequent opportunities for the model to correct errors before they compound
- Core assumption: The model can answer simpler subquestions more reliably than complex questions directly
- Evidence anchors:
  - [abstract] "By forcing the model to answer simpler subquestions in separate contexts, we greatly increase the faithfulness of model-generated reasoning over CoT"
  - [section] "We expect a reduction in ignored reasoning because the answers to earlier subquestions often have a clearly specified relationship to later subquestions that get asked"
  - [corpus] Moderate evidence - related work on task decomposition shows improved accuracy and generalization
- Break condition: If the decomposition creates more opportunities for error propagation rather than error correction

## Foundational Learning

- Concept: Chain-of-Thought reasoning
  - Why needed here: Understanding CoT is essential to grasp what decomposition methods are improving upon
  - Quick check question: What is the key limitation of Chain-of-Thought reasoning identified in this paper?

- Concept: Faithfulness metrics
  - Why needed here: The paper uses multiple metrics to evaluate reasoning faithfulness
  - Quick check question: What are the two main types of unfaithfulness measured in this paper?

- Concept: Question decomposition
  - Why needed here: The core technique being evaluated requires understanding how questions can be broken into subquestions
  - Quick check question: What is the key difference between factored decomposition and chain-of-thought decomposition?

## Architecture Onboarding

- Component map: Generate reasoning (zero-shot/few-shot, CoT, CoT decomposition, factored decomposition) -> Evaluate faithfulness (perturbation experiments, biased context experiments) -> Evaluate accuracy (question-answering performance) -> Compare methods
- Critical path: Generate reasoning → Evaluate faithfulness → Evaluate accuracy → Compare methods
- Design tradeoffs: Factored decomposition trades some performance for improved faithfulness; CoT decomposition attempts to balance both
- Failure signatures: Low faithfulness indicates the model may be ignoring stated reasoning or incorporating biased reasoning without verbalizing it
- First 3 experiments:
  1. Replicate the early answering sensitivity experiment to verify reasoning truncation affects different methods differently
  2. Test the adding mistakes experiment to confirm reasoning corruption sensitivity varies by method
  3. Run the suggested answer bias experiment to measure susceptibility to biasing contexts across methods

## Open Questions the Paper Calls Out
1. How does the faithfulness of model-generated reasoning scale with model size? Specifically, do larger models exhibit greater or lesser improvements in faithfulness when using question decomposition methods compared to chain-of-thought prompting?
2. Can the faithfulness-performance trade-off observed in question decomposition be eliminated through targeted training approaches?
3. How does question decomposition affect reasoning faithfulness for non-multiple-choice question-answering tasks?

## Limitations
- The exact pretrained model architecture remains unspecified (only described as similar to "Claude 1.3"), making precise replication challenging
- The faithfulness improvements show performance trade-offs with CoT methods that may not generalize across all question types
- The perturbation experiments test specific failure modes that may not capture all forms of unfaithful reasoning

## Confidence
- High confidence: The experimental results showing decomposition methods reduce biased reasoning susceptibility and improve faithfulness sensitivity to perturbations
- Medium confidence: The generalizability of decomposition benefits across different reasoning tasks and model scales
- Medium confidence: The specific mechanism by which decomposition improves faithfulness (multiple plausible explanations supported by evidence)

## Next Checks
1. Test whether the faithfulness improvements scale with model size by running the same experiments on smaller and larger language models
2. Evaluate the decomposition methods on a broader range of reasoning tasks beyond multiple-choice question answering, including open-ended generation tasks
3. Conduct ablation studies to isolate which aspects of the decomposition process (subquestion generation, separate context answering, or answer recombination) contribute most to faithfulness improvements