---
ver: rpa2
title: Exploration of the Rashomon Set Assists Trustworthy Explanations for Medical
  Data
arxiv_id: '2308.11446'
source_url: https://arxiv.org/abs/2308.11446
tags:
- rashomon
- data
- profiles
- values
- measure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces a method to explore the Rashomon set, which
  is a collection of models with similar performance but potentially different explanations
  of the data. The core idea is to use eXplainable Artificial Intelligence (XAI) techniques
  to compare the profiles of models, which show the dependence of predictions on variable
  values.
---

# Exploration of the Rashomon Set Assists Trustworthy Explanations for Medical Data

## Quick Facts
- arXiv ID: 2308.11446
- Source URL: https://arxiv.org/abs/2308.11446
- Reference count: 35
- One-line primary result: A method to explore the Rashomon set using profile dissimilarities (PDI) effectively identifies models with different explanations in medical data.

## Executive Summary
This paper introduces a method to explore the Rashomon set, which consists of models with similar predictive performance but potentially different explanations of the data. The core idea is to use eXplainable Artificial Intelligence (XAI) techniques to compare the profiles of models, which show the dependence of predictions on variable values. A new measure, the Profile Disparity Index (PDI), is proposed to quantify the differences in variable effects between models. The Rashomon_DETECT algorithm is introduced to select the k most distinct models from the Rashomon set based on their profile dissimilarities. The method is applied to a real-world medical dataset on hemophagocytic lymphohistiocytosis (HLH) patients and benchmarked on other medical datasets. The results demonstrate the effectiveness of the approach in identifying models with different explanations and highlight the importance of considering multiple explanations in high-stakes applications like medicine.

## Method Summary
The method involves training multiple models on medical datasets and forming a Rashomon set of models with similar performance. Profiles are generated using Partial Dependence Plots (PDPs) to visualize how predictions depend on variable values. The Profile Disparity Index (PDI) is introduced to quantify differences in these profiles between models. The Rashomon_DETECT algorithm iteratively selects models that are most dissimilar to the already chosen set, ensuring maximal behavioral diversity. The selected models are then analyzed to provide multiple perspectives on the data, which can assist in making more trustworthy decisions in medical applications.

## Key Results
- The Profile Disparity Index (PDI) effectively quantifies differences in variable effects between models with similar predictive performance.
- The Rashomon_DETECT algorithm successfully identifies the k most distinct models from the Rashomon set based on profile dissimilarities.
- Application to the HLH dataset and other medical datasets demonstrates the method's effectiveness in identifying models with different explanations, highlighting the importance of considering multiple perspectives in medical decision-making.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Models with similar predictive performance can differ significantly in how they interpret variable effects, and this difference is captured by comparing their Partial Dependence Profiles (PDPs) using the Profile Disparity Index (PDI).
- Mechanism: The PDI quantifies the proportion of the profile domain where two models' predictions change in opposite directions with respect to a variable. By averaging these differences across all variables and model pairs, the Rashomon_DETECT algorithm identifies the most behaviorally distinct models within the Rashomon set.
- Core assumption: Profile shapes reflect the underlying reasoning of models, and differences in these shapes indicate fundamentally different explanations of the data, even if predictive performance is similar.
- Evidence anchors:
  - [abstract] "To quantify differences in variable effects among models, we introduce the Profile Disparity Index (PDI) based on measures from functional data analysis."
  - [section] "The proposed PDI measure consistently attains a value of 0 for scenarios 1 and 2, representing smooth profiles with a consistent monotonic relationship (both profiles increase)."
  - [corpus] Weak: No direct corpus mention of PDP/PDI but related works discuss Rashomon sets and explanation multiplicity.
- Break condition: If the core assumption fails—i.e., if profile shapes do not reliably reflect model reasoning—then PDI may not distinguish meaningful differences.

### Mechanism 2
- Claim: The Rashomon_DETECT algorithm iteratively selects models that are most dissimilar to the already chosen set, ensuring maximal behavioral diversity.
- Mechanism: Starting from a reference model, the algorithm computes average profile dissimilarities between candidate models and the current selection. At each step, it adds the model with the largest average dissimilarity, effectively exploring the extremes of the Rashomon set.
- Core assumption: Dissimilarity between profiles is a valid proxy for difference in model behavior, and selecting models with maximal dissimilarity yields a representative sample of the Rashomon set.
- Evidence anchors:
  - [section] "The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced Rashomon_DETECT algorithm."
  - [section] "It operates on the set of the created models ˆF and is based on the calculation of the average dissimilarities between profiles for pairs of models."
  - [corpus] Weak: Related works discuss enumerating Rashomon sets but do not describe iterative dissimilarity-based selection.
- Break condition: If the dissimilarity measure is not discriminative enough (e.g., in highly oscillatory profiles), the algorithm may fail to select truly distinct models.

### Mechanism 3
- Claim: By analyzing multiple distinct models from the Rashomon set, practitioners can select the one that best aligns with domain knowledge or use an ensemble for more trustworthy conclusions.
- Mechanism: After detecting diverse models, their PDPs and PDI values are examined to understand how each model interprets the data. This allows selection based on clinical relevance, stability, or interpretability rather than pure performance.
- Core assumption: Domain knowledge can guide the selection of the most appropriate model among those with similar performance, and multiple perspectives improve trustworthiness.
- Evidence anchors:
  - [abstract] "If differently behaving models are detected in the Rashomon set, their combined analysis leads to more trustworthy conclusions, which is of vital importance for high-stakes applications such as medical applications."
  - [section] "If the interpretations of that models are different, the results and final decision should be reinforced, for example by domain knowledge or other XAI techniques."
  - [corpus] Weak: No direct corpus evidence; assumption based on the paper's stated goal.
- Break condition: If domain knowledge is unavailable or conflicting, this mechanism cannot effectively guide model selection.

## Foundational Learning

- Concept: Functional data analysis and distance metrics between curves (e.g., L2, derivatives-based measures).
  - Why needed here: To quantify differences between model profiles, which are functional representations of how predictions depend on variable values.
  - Quick check question: What is the difference between the L2 distance between profiles and the L2 distance between their derivatives, and when might each be appropriate?

- Concept: Partial Dependence Plots (PDPs) and Accumulated Local Effects (ALE) as model-agnostic explanation methods.
  - Why needed here: PDPs are used to construct the profiles that are compared by PDI; understanding their construction and interpretation is essential for using the algorithm.
  - Quick check question: How does a PDP differ from an ALE plot, and what assumptions does each make about variable relationships?

- Concept: The Rashomon effect and Rashomon sets in machine learning.
  - Why needed here: The entire method is built around the idea that multiple models can achieve similar performance but differ in their internal reasoning; understanding this concept is foundational.
  - Quick check question: Why might two models with nearly identical AUC values have very different PDPs for the same variable?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training (multiple algorithms) -> Hyperparameter tuning -> AUC evaluation -> Rashomon set identification -> Profile computation (PDPs) -> Profile dissimilarity calculation (PDI, L2, etc.) -> Rashomon_DETECT algorithm -> Result analysis (PDP visualization, model selection)
- Critical path: Model training and evaluation -> Rashomon set formation -> Profile generation -> Dissimilarity computation -> Model selection
- Design tradeoffs: Using PDI focuses on monotonicity differences but may miss magnitude differences; using L2 captures overall shape but may be sensitive to noise; using derivatives captures trend differences but requires smoothness
- Failure signatures: If all models in the Rashomon set have very similar profiles, PDI will be near zero for all pairs; if profiles are highly oscillatory, derivative-based measures may be unstable; if variable sets differ, missing profiles must be handled (e.g., imputed as constant zero)
- First 3 experiments:
  1. Generate synthetic data with known monotonic and non-monotonic relationships; train linear and tree-based models; compute PDPs and PDI; verify PDI distinguishes monotonic from non-monotonic profile pairs
  2. Use a small medical dataset; train multiple models; form Rashomon set; apply Rashomon_DETECT with PDI; visualize PDPs of selected models; check if differences align with clinical intuition
  3. Benchmark on multiple medical datasets; compare results using PDI vs. L2 vs. derivative-based measures; assess which measure best identifies behaviorally distinct models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of dissimilarity measure (PDI vs L2) affect the identification of diverse models in the Rashomon set for medical datasets?
- Basis in paper: [explicit] The paper compares PDI with L2 measures in various scenarios and shows that PDI performs better in most cases, especially when profiles exhibit monotonic relationships or large oscillations.
- Why unresolved: The paper only provides a benchmark on a few medical datasets and does not explore the impact of different measures on the final model selection and interpretation.
- What evidence would resolve it: A comprehensive study comparing the performance of different measures on a large number of medical datasets, including their impact on model selection and interpretation.

### Open Question 2
- Question: How can the Rashomon_DETECT algorithm be extended to handle categorical variables and interactions between variables?
- Basis in paper: [inferred] The paper mentions that vector distances are used as an alternative for categorical variables, but it does not explore the impact of interactions between variables on the identification of diverse models.
- Why unresolved: The current implementation of the algorithm does not consider interactions between variables, which can be crucial in medical applications where the effect of one variable may depend on the value of another.
- What evidence would resolve it: An extension of the Rashomon_DETECT algorithm that incorporates interactions between variables and demonstrates its effectiveness on medical datasets.

### Open Question 3
- Question: How can the Rashomon_DETECT algorithm be used to select the most appropriate model for a specific patient or subgroup of patients?
- Basis in paper: [explicit] The paper mentions that the algorithm can be used to provide a collection of models with different perspectives on the analyzed phenomenon, which can assist clinicians in selecting the model most appropriate for a given patient.
- Why unresolved: The paper does not provide a concrete method for selecting the most appropriate model for a specific patient or subgroup of patients based on the identified diverse models.
- What evidence would resolve it: A study that demonstrates the effectiveness of the Rashomon_DETECT algorithm in selecting the most appropriate model for a specific patient or subgroup of patients, using real-world medical data.

## Limitations
- The method's effectiveness depends on the quality and appropriateness of the profile dissimilarity measure (PDI, L2, derivatives) for capturing meaningful differences in model behavior.
- The reliance on domain knowledge for final model selection is a potential weakness in cases where such knowledge is unavailable or conflicting.
- The paper provides a solid foundation, but further experimentation and benchmarking are needed to establish robustness and generalizability across diverse datasets and model types.

## Confidence
- Mechanism 1: Medium
- Mechanism 2: Medium
- Mechanism 3: Medium

## Next Checks
1. Test the algorithm on synthetic datasets with known monotonic and non-monotonic relationships to verify PDI's ability to distinguish profile types.
2. Apply the method to a wider range of real-world datasets, including non-medical domains, to assess generalizability.
3. Compare the Rashomon_DETECT algorithm's results with alternative approaches for exploring model diversity, such as Bayesian model averaging or ensemble methods.