---
ver: rpa2
title: Interventionally Consistent Surrogates for Agent-based Simulators
arxiv_id: '2312.11158'
source_url: https://arxiv.org/abs/2312.11158
tags:
- surrogate
- surrogates
- agent-based
- interventions
- causal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a framework for learning interventionally consistent
  surrogate models for agent-based simulators, using causal abstractions to ensure
  surrogates preserve ABM behavior under policy interventions. The method learns a
  surrogate and intervention map by minimizing abstraction error over interventionally
  consistent training data, using gradient-based optimization.
---

# Interventionally Consistent Surrogates for Agent-based Simulators

## Quick Facts
- arXiv ID: 2312.11158
- Source URL: https://arxiv.org/abs/2312.11158
- Authors: 
- Reference count: 16
- Key outcome: This paper proposes a framework for learning interventionally consistent surrogate models for agent-based simulators, using causal abstractions to ensure surrogates preserve ABM behavior under policy interventions.

## Executive Summary
This paper introduces a framework for learning surrogate models of agent-based simulators that preserve interventionally consistent behavior. The approach uses causal abstractions to ensure surrogates behave consistently with the original ABM under policy interventions. By learning a τ-ω transformation, the method creates surrogates that can accurately predict intervention effects while operating at a higher level of abstraction. Experiments with a spatial SIRS ABM demonstrate that surrogates trained on interventional data significantly outperform those trained on observational data in predicting intervention effects.

## Method Summary
The framework learns interventionally consistent surrogates by jointly optimizing surrogate model parameters and an intervention map. The method minimizes abstraction error (measured by KL divergence) between the surrogate and ABM distributions over interventionally consistent training data. The surrogate and intervention map are trained using gradient-based optimization on a combination of observational and interventional data generated from the ABM. The approach allows for the creation of computationally efficient surrogates that maintain the causal behavior of the original ABM under policy interventions.

## Key Results
- Surrogates trained on interventional data significantly outperform those trained on observational data in predicting intervention effects
- The best-performing surrogate combines a mechanistic ODE with a recurrent neural network (LODE-RNN)
- The framework demonstrates improved accuracy in predicting intervention effects as measured by average mean squared error and average negative log-likelihood

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The framework preserves ABM behavior under policy interventions by explicitly modeling causal relationships between interventions and system states.
- Mechanism: The method uses causal abstractions to ensure that surrogates maintain the same causal structure as the original ABM under interventions. By learning a τ-ω transformation, the surrogate can replicate the ABM's response to interventions while operating at a higher level of abstraction.
- Core assumption: The causal structure of the ABM can be adequately captured and preserved through the τ-ω transformation learned during training.
- Evidence anchors:
  - [abstract] "Our proposed approach facilitates rapid experimentation with policy interventions in complex systems, while inducing surrogates to behave consistently with high probability with respect to the agent-based simulator across interventions of interest."
  - [section 2.3] "An exact τ-ω transformation between the SCM M underlying an ABM and the SCM M′ underlying the candidate surrogate model would...provide guarantees of interventional consistency when a policymaker would study real-world interventions through the surrogate model."
- Break condition: If the τ-ω transformation cannot adequately capture the complex causal relationships in the ABM, the surrogate may fail to preserve behavior under interventions.

### Mechanism 2
- Claim: Training with interventional data significantly improves surrogate accuracy in predicting intervention effects.
- Mechanism: The framework learns interventionally consistent surrogates by minimizing abstraction error over interventionally consistent training data. This ensures the surrogate accurately captures how the ABM responds to policy interventions.
- Core assumption: Including interventional data from the ABM in the learning process is necessary for the surrogate to accurately model intervention effects.
- Evidence anchors:
  - [abstract] "Experiments with a spatial SIRS ABM show that surrogates trained on interventional data significantly outperform those trained on observational data in predicting intervention effects, as measured by average mean squared error and average negative log-likelihood."
  - [section 5.2] "We observe that far lower values of the error metrics are obtained by the interventionally, rather than observationally, trained surrogates when assessing interventional consistency."
- Break condition: If the interventional data used for training does not adequately represent the range of possible interventions, the surrogate may still fail to accurately predict intervention effects.

### Mechanism 3
- Claim: The combination of mechanistic ODE models with neural networks improves surrogate performance.
- Mechanism: Hybrid models that combine mechanistic ODE models with flexible neural network components (e.g., RNNs) can better capture both the known dynamics of the system and learn complex patterns from data.
- Core assumption: The underlying system dynamics can be partially captured by a mechanistic model, which can then be enhanced by neural networks to learn more complex behaviors.
- Evidence anchors:
  - [section 5.2] "We also observe that the LODE-RNN – which combines the 'mechanistic' SIRS ODE with a flexible RNN – achieves the best interventional and observational consistencies of the three families of surrogates."
  - [section 5] "Surrogate family 2 consists of a latent ODE-RNN (LODE-RNN) constructed by running a recurrent neural network (RNN) with trainable parameters ψ over the output of the classical SIRS ODE."
- Break condition: If the mechanistic model does not accurately represent the underlying system dynamics, the hybrid approach may not improve performance over purely data-driven models.

## Foundational Learning

- Concept: Causal abstraction and structural causal models (SCMs)
  - Why needed here: Understanding causal abstractions and SCMs is crucial for grasping how the framework ensures interventional consistency between ABMs and their surrogates.
  - Quick check question: How does the τ-ω transformation in causal abstraction relate to the relationship between an ABM and its surrogate?

- Concept: Interventions in causal models
  - Why needed here: Interventions are central to the framework's approach, as it aims to ensure surrogates behave consistently with ABMs under policy interventions.
  - Quick check question: What is the difference between an observational distribution and an interventional distribution in the context of causal models?

- Concept: Kullback-Leibler (KL) divergence
  - Why needed here: KL divergence is used as a measure of abstraction error in the framework, which is minimized during the learning process.
  - Quick check question: How does KL divergence measure the difference between two probability distributions, and why is it suitable for measuring abstraction error in this context?

## Architecture Onboarding

- Component map: ABM (SCM) -> τ map (aggregation) -> Surrogate (parameterizable SCM) -> ω map (intervention) -> Trained surrogate
- Critical path:
  1. Define the ABM as an SCM
  2. Specify the τ map (aggregation function)
  3. Choose a surrogate model family
  4. Generate training data (observational and interventional)
  5. Train the surrogate to minimize abstraction error
  6. Evaluate the surrogate's interventional consistency
- Design tradeoffs:
  - Complexity of surrogate model vs. computational efficiency
  - Amount of interventional vs. observational training data
  - Choice of abstraction error metric (e.g., KL divergence vs. other measures)
  - Flexibility of the ω map (e.g., neural network vs. simpler function)
- Failure signatures:
  - High abstraction error on interventional test data
  - Poor performance on out-of-distribution interventions
  - Overfitting to training interventions
  - Inability to capture complex causal relationships in the ABM
- First 3 experiments:
  1. Train a simple surrogate (e.g., LODE) on only observational data and evaluate its performance on interventional test data.
  2. Train the same surrogate on interventional data and compare its performance to the observationally trained model.
  3. Experiment with different surrogate architectures (e.g., LODE-RNN vs. LRNN) to identify the best-performing model family.

## Open Questions the Paper Calls Out
- Question: How does the choice of intervention set I affect the performance of interventionally trained surrogates?
- Basis in paper: [explicit] The paper mentions that "policymakers will often hold prior preferences over possible interventions" and that the interventional distribution η can implicitly favor surrogates that perform well with respect to interventions of high interest.
- Why unresolved: The paper does not explore how different choices of intervention sets I impact the performance of the trained surrogates.
- What evidence would resolve it: Conducting experiments with different intervention sets I and comparing the performance of the resulting surrogates.

## Limitations
- The method's effectiveness depends on accurately modeling the τ-ω transformation, which may be difficult for highly complex ABMs
- Experimental validation is limited to a single ABM (spatial SIRS), raising questions about generalizability
- The framework assumes access to interventional data from the ABM, which may be computationally expensive or infeasible for large-scale systems

## Confidence
- High: The framework's theoretical foundations in causal abstractions and SCMs are well-established
- Medium: Empirical results demonstrate effectiveness for the specific ABM case study
- Medium: The claim about hybrid ODE-neural network models performing best is supported but could benefit from broader validation

## Next Checks
1. Test the framework on a diverse set of ABMs (e.g., economic, social, or transportation systems) to evaluate generalizability
2. Conduct ablation studies to quantify the impact of different surrogate architectures and training data compositions
3. Implement a cost-benefit analysis comparing computational savings from using surrogates versus running the full ABM for policy experiments