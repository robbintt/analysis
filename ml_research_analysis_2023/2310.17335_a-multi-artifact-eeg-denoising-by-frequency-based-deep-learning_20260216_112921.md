---
ver: rpa2
title: A multi-artifact EEG denoising by frequency-based deep learning
arxiv_id: '2310.17335'
source_url: https://arxiv.org/abs/2310.17335
tags:
- signal
- signals
- artifacts
- noise
- denoising
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study introduces a frequency-based deep learning model for
  EEG denoising, specifically targeting ocular and muscular artifacts. The model leverages
  prior knowledge about noise spectral features to adaptively compute optimal convolutional
  filters for noise separation.
---

# A multi-artifact EEG denoising by frequency-based deep learning

## Quick Facts
- arXiv ID: 2310.17335
- Source URL: https://arxiv.org/abs/2310.17335
- Reference count: 30
- Introduces a frequency-based deep learning model that denoises EEG signals by adaptively computing optimal convolutional filters in the frequency domain.

## Executive Summary
This study presents a novel frequency-based deep learning approach for denoising EEG signals contaminated with ocular and muscular artifacts. The model leverages prior knowledge about noise spectral features to compute optimal convolutional filters that separate artifacts from neural signals. Unlike traditional time-domain approaches, this method processes signals in the frequency domain, learning an empirical relationship between spectral characteristics of noise and noisy signals. The model demonstrates robust performance on the EEGdenoiseNet dataset, achieving competitive results in both temporal and spectral metrics while requiring only a single trained model to handle multiple artifact types.

## Method Summary
The proposed model operates on Power Spectral Densities (PSDs) of EEG signals and noise, using kernel evaluator blocks to compute complex-valued convolutional filters. These filters are estimated through 1D convolutions on PSD inputs (noise PSD, noisy signal PSD, and their ratio) with tanh activations, then converted to time-domain filters via inverse FFT. The estimated filters are applied to the time-domain noisy signal through cascaded 1D convolutions with ELU activations. The model is trained on synthetic data generated from clean EEG and artifacts using the EEGdenoiseNet dataset, with a loss function combining temporal and spectral reconstruction errors plus log-cosh regularization.

## Key Results
- Achieved third best performance in temporal domain metrics and second best in spectral metrics on EEGdenoiseNet dataset
- Matched or outperformed benchmark models in removing both ocular and muscular artifacts
- Demonstrated effective multi-artifact denoising without requiring separate training for each artifact type
- Showed strong performance across various signal-to-noise ratios (SNRs) during testing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The model achieves effective denoising by leveraging prior knowledge of noise spectral features to adaptively compute optimal convolutional filters in the frequency domain.
- Mechanism: The kernel evaluator blocks process the PSDs of both the noise and noisy signal to estimate complex-valued convolutional filters. These filters are then applied in the time domain via inverse FFT, enabling precise frequency-domain noise separation that traditional time-domain approaches cannot achieve.
- Core assumption: The relationship between signal and noise is linear (additive), and the PSD of the noise is known or can be estimated.
- Evidence anchors:
  - [abstract] "leverages prior knowledge about noise spectral features to adaptively compute optimal convolutional filters for noise separation"
  - [section] "the PSD estimate of the noise is given; the relation between signal and noise is known"
  - [corpus] Weak evidence - no direct mention of frequency-based convolutional filtering in corpus neighbors

### Mechanism 2
- Claim: The model's architecture allows it to handle both ocular and muscular artifacts with a single trained model without requiring separate training for each artifact type.
- Mechanism: By training on both artifact types simultaneously using the EEGdenoiseNet dataset, the model learns a generalized mapping from noisy to clean signals that captures the spectral characteristics of both high-frequency muscular artifacts and low-frequency ocular artifacts.
- Core assumption: Both artifact types can be represented as additive noise in the signal, and their spectral features are sufficiently distinct to be separable by learned filters.
- Evidence anchors:
  - [abstract] "without the need to perform any training on the particular type of artifact"
  - [section] "a single model has been trained on both EMG and EOG artifacts at the same time"
  - [corpus] Weak evidence - no direct mention of multi-artifact handling in corpus neighbors

### Mechanism 3
- Claim: The model preserves the spectral information of clean EEG signals while effectively removing artifacts, as evidenced by strong performance in both temporal and spectral metrics.
- Mechanism: The loss function combines temporal (RRMSEt) and spectral (RRMSEf) reconstruction errors with log-cosh regularization, ensuring the model learns to maintain both time-domain waveform fidelity and frequency-domain spectral structure of the underlying neural activity.
- Core assumption: The clean EEG signal has distinctive spectral characteristics that can be preserved while removing artifact components.
- Evidence anchors:
  - [abstract] "achieving strong results in both temporal and spectral metrics"
  - [section] "the proposed model demonstrated robust performance, achieving the third best results in the temporal domain metrics... and the second best result in the spectral metric"
  - [corpus] Weak evidence - no direct mention of spectral preservation in corpus neighbors

## Foundational Learning

- Concept: Frequency domain signal processing
  - Why needed here: The model operates on Power Spectral Densities (PSDs) rather than raw time-domain signals, requiring understanding of Fourier transforms and spectral analysis
  - Quick check question: What is the relationship between a signal's time-domain representation and its frequency-domain representation via the Fourier transform?

- Concept: Convolutional neural networks in non-standard domains
  - Why needed here: The model uses 1D convolutions on PSDs (frequency domain) rather than on time-domain signals, which is a non-standard application requiring understanding of how convolutions operate on spectral data
  - Quick check question: How do convolutional filters applied to frequency-domain data differ from those applied to time-domain data in terms of what features they can extract?

- Concept: Loss function design for multi-objective optimization
  - Why needed here: The model uses a weighted combination of temporal, spectral, and log-cosh losses, requiring understanding of how different loss components interact and how to balance them
  - Quick check question: How does combining temporal and spectral reconstruction errors in the loss function affect the model's ability to preserve both waveform shape and frequency content?

## Architecture Onboarding

- Component map: Input PSDs + time-domain signal → Kernel evaluator blocks → Filter estimation → Time-domain convolutions → Output
- Critical path: PSDs → Kernel evaluator → Filter estimation → Time-domain convolutions → Output
- Design tradeoffs:
  - Frequency vs. time domain: Operating in frequency domain allows explicit noise spectral modeling but requires careful handling of the Fourier transform
  - Single vs. separate models: Single model for both artifact types simplifies deployment but may limit specialized performance
  - Filter length: Using filters as long as the input signal captures global features but increases computational cost
- Failure signatures:
  - Poor spectral metrics with good temporal metrics: Filters may be removing too much high-frequency content
  - Good spectral metrics with poor temporal metrics: Model may be preserving spectral shape but not temporal structure
  - Inconsistent performance across SNR ranges: Runtime noise PSD estimation may be inaccurate
- First 3 experiments:
  1. Test the kernel evaluator independently on synthetic PSD data to verify filter estimation accuracy
  2. Validate the IRFFT operation by comparing time-domain filters obtained through the full pipeline versus direct estimation
  3. Evaluate model performance on each artifact type separately to identify any bias in the multi-artifact training approach

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed frequency-based deep learning model for EEG denoising compare to other state-of-the-art methods when dealing with non-physiological artifacts such as electrical interference and cable movement?
- Basis in paper: [inferred] The paper focuses on denoising EEG signals from physiological artifacts like ocular and muscular movements, but does not discuss the model's performance on non-physiological artifacts.
- Why unresolved: The paper does not provide any information or experimental results related to the model's performance on non-physiological artifacts.
- What evidence would resolve it: Experimental results comparing the model's performance on non-physiological artifacts with other state-of-the-art methods.

### Open Question 2
- Question: What is the impact of varying the signal-to-noise ratio (SNR) on the model's denoising performance, and how does it affect the model's ability to preserve the spectral information of the clean EEG signal?
- Basis in paper: [explicit] The paper mentions that the SNR is randomly sampled during the training phase and that the model is tested on a range of SNR values.
- Why unresolved: The paper does not provide a detailed analysis of the model's performance at different SNR levels or how it affects the preservation of spectral information.
- What evidence would resolve it: A comprehensive analysis of the model's performance at various SNR levels and its impact on preserving spectral information.

### Open Question 3
- Question: How does the proposed model's performance change when applied to real-time EEG data, considering its current design and computational requirements?
- Basis in paper: [inferred] The paper does not discuss the model's applicability to real-time EEG data or its computational requirements.
- Why unresolved: There is no information provided on the model's performance in real-time scenarios or its computational efficiency.
- What evidence would resolve it: Experimental results demonstrating the model's performance on real-time EEG data and an analysis of its computational requirements.

## Limitations

- The claimed advantages of the frequency-based approach over existing methods are not rigorously demonstrated through controlled experiments
- The single-model approach for both artifact types may obscure performance differences that separate models would reveal
- The computational complexity of full-length filters is noted but not quantified against alternative architectures

## Confidence

- **High Confidence**: The model's technical implementation using PSDs and FFT operations is sound and well-specified.
- **Medium Confidence**: The denoising performance metrics and comparative results against benchmarks appear valid, though the lack of statistical significance testing is concerning.
- **Low Confidence**: The claimed advantages of the frequency-based approach over existing methods are not rigorously demonstrated through controlled experiments.

## Next Checks

1. **Ablation Study**: Train and evaluate the model without the prior noise PSD information to quantify the actual contribution of the frequency-based approach.
2. **Artifact-Specific Evaluation**: Test separate models for EOG and EMG artifacts to determine if the single-model approach compromises specialized performance.
3. **Computational Analysis**: Benchmark the model's runtime and memory requirements against comparable EEG denoising approaches, particularly for the full-length filter implementation.