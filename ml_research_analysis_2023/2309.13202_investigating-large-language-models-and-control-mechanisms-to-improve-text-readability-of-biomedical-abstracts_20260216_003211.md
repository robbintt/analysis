---
ver: rpa2
title: Investigating Large Language Models and Control Mechanisms to Improve Text
  Readability of Biomedical Abstracts
arxiv_id: '2309.13202'
source_url: https://arxiv.org/abs/2309.13202
tags:
- language
- biomedical
- bart
- text
- simplification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the use of large language models (LLMs)
  and control mechanisms to improve the readability of biomedical abstracts. The authors
  fine-tune various LLMs, including T5, SciFive, BART, GPT-3.5, GPT-4, and BioGPT,
  on a publicly available dataset of plain language adaptations of biomedical abstracts
  (PLABA).
---

# Investigating Large Language Models and Control Mechanisms to Improve Text Readability of Biomedical Abstracts

## Quick Facts
- arXiv ID: 2309.13202
- Source URL: https://arxiv.org/abs/2309.13202
- Reference count: 39
- Key outcome: BART-Large with Control Token mechanisms achieved highest SARI score (46.54); T5-base achieved highest BERTscore (72.62); human evaluation showed BART-L-w-CTs better simplicity (2.9 vs 2.2) while T5-base better meaning preservation (3.1 vs 2.6)

## Executive Summary
This paper investigates the use of large language models (LLMs) for improving the readability of biomedical abstracts through text simplification. The authors fine-tune various encoder-decoder models including T5, SciFive, and BART, as well as decoder-only models like GPT-3.5, GPT-4, and BioGPT on the PLABA dataset. They also apply control token mechanisms to BART-based models to explicitly guide syntactic and lexical simplification. The study evaluates models using both automatic metrics and human assessment, finding that while BART-Large with control tokens excels at generating simpler text, T5-base better preserves meaning.

## Method Summary
The study fine-tunes multiple LLMs on the PLABA dataset containing 7,643 sentence pairs of biomedical abstracts and their simplified versions. Models include T5, SciFive, BART (with and without control tokens), GPT-3.5, GPT-4, and BioGPT. Control tokens for BART models guide simplification through attributes like dependency tree depth, word rank, Levenshtein distance, and length ratio. Evaluation uses automatic metrics (BLEU, ROUGE, SARI, BERTscore) and human assessment on meaning preservation and simplicity using 5-point Likert scales. The dataset is split approximately 8:1:1 for training, validation, and testing.

## Key Results
- BART-Large with Control Token mechanisms achieved the highest SARI score (46.54) among all models
- T5-base reported the highest BERTscore (72.62) indicating strong meaning preservation
- In human evaluation, BART-L-w-CTs achieved better simplicity score (2.9 vs 2.2) over T5-base, while T5-base achieved better meaning preservation score (3.1 vs 2.6) over BART-L-w-CTs

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Domain-specific fine-tuning on biomedical abstracts improves simplification performance compared to generic pre-training
- **Mechanism:** Fine-tuning adapts model representations to biomedical terminology and sentence structures, improving lexical and syntactic simplification
- **Core assumption:** Biomedical abstracts have distinct linguistic patterns requiring specialized training data
- **Evidence anchors:** The authors fine-tune various LLMs on PLABA dataset; SciFive demonstrates advanced performances on biomedical NLP tasks
- **Break condition:** If fine-tuning dataset is too small or not representative, model may not learn effective simplification patterns

### Mechanism 2
- **Claim:** Control token mechanisms applied to BART models improve simplification quality by explicitly controlling complexity
- **Mechanism:** Control tokens like `<DEPENDENCYTREEDEPTH>`, `<WORDRANK>`, and `<LENGTHRATIO>` guide models to produce outputs with desired properties
- **Core assumption:** Explicit control over simplification factors leads to more consistent and interpretable outputs
- **Evidence anchors:** Control tokens applied to BART-based models; four attributes listed (DTD, WR, LV, LR)
- **Break condition:** If control token values are not properly optimized or don't align with human preferences, outputs may degrade

### Mechanism 3
- **Claim:** Combining automatic metrics and human evaluation provides comprehensive assessment
- **Mechanism:** Automatic metrics quantify simplification aspects while human evaluation captures subjective quality
- **Core assumption:** Combination provides more reliable assessment than either alone
- **Evidence anchors:** Models evaluated using BLEU, ROUGE, SARI, BERTscore, and human evaluation; human results show trade-offs between simplicity and meaning preservation
- **Break condition:** If evaluation metrics don't align with simplification goals, they may not accurately reflect performance

## Foundational Learning

- **Concept:** Text Simplification
  - **Why needed here:** The paper aims to improve readability of biomedical abstracts by simplifying complex language and terminology
  - **Quick check question:** What are key challenges in biomedical text simplification compared to general text simplification?

- **Concept:** Large Language Models
  - **Why needed here:** The paper investigates state-of-the-art LLMs for biomedical text simplification
  - **Quick check question:** How do encoder-decoder models (e.g., T5, BART) differ from decoder-only models (e.g., GPT) in architecture and training?

- **Concept:** Evaluation Metrics
  - **Why needed here:** The paper uses automatic metrics (BLEU, ROUGE, SARI, BERTscore) and human evaluation to assess model performance
  - **Quick check question:** What are strengths and limitations of each evaluation metric used in the paper?

## Architecture Onboarding

- **Component map:** PLABA dataset → model fine-tuning → model inference → evaluation (automatic + human) → analysis of results
- **Critical path:** The critical path is: PLABA dataset → model fine-tuning → model inference → evaluation (automatic + human) → analysis of results
- **Design tradeoffs:** Using larger models may improve performance but increase computational cost; control tokens improve quality but add complexity
- **Failure signatures:** If outputs too similar to input (low SARI), indicates poor simplification; if too simplified and lose information (low BERTscore), indicates poor meaning preservation
- **First 3 experiments:**
  1. Fine-tune T5-base on PLABA dataset and evaluate using SARI and BERTscore
  2. Fine-tune BART-large with control tokens on PLABA dataset and evaluate using SARI and BERTscore
  3. Compare outputs of T5-base and BART-large with control tokens using human evaluation

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How would models perform if trained on dataset with larger number of references per sentence?
- **Basis in paper:** [explicit] PLABA dataset has limited number of references per sentence, which might affect model's performance; authors suggest more references could improve performance
- **Why unresolved:** Paper does not explore impact of increasing references; would require retraining on dataset with more references and re-evaluation
- **What evidence would resolve it:** Create new dataset with more references, retrain models, evaluate using BLEU, ROUGE, SARI, BERTscore, and human evaluation

### Open Question 2
- **Question:** How do control token mechanisms affect BART model performance and can they be further optimized?
- **Basis in paper:** [explicit] BART-Large with control tokens achieved highest SARI score, but paper doesn't explore impact of different control token configurations or further optimization
- **Why unresolved:** Paper doesn't investigate effects of varying control token configurations or optimizing mechanisms; would require additional experiments
- **What evidence would resolve it:** Conduct experiments with different control token configurations, optimize mechanisms, evaluate using BLEU, ROUGE, SARI, BERTscore, and human evaluation

### Open Question 3
- **Question:** How do models perform on biomedical text simplification when evaluated on datasets from different languages or domains?
- **Basis in paper:** [inferred] Paper focuses on English biomedical abstracts without exploring performance on other languages or domains; mentions developments in biomedical language models for other languages
- **Why unresolved:** Paper doesn't evaluate models on different languages or domains, which could provide insights into generalizability and adaptability
- **What evidence would resolve it:** Evaluate models on datasets from different languages or domains using BLEU, ROUGE, SARI, BERTscore, and human evaluation

## Limitations
- PLABA dataset contains only 7,643 sentence pairs, relatively small for fine-tuning large language models
- Evaluation methodology relies on automatic metrics that may not fully capture biomedical text simplification quality
- Control token optimization process not fully specified, effectiveness may vary across biomedical sub-domains

## Confidence

**High confidence**: Experimental methodology is sound and follows established practices; use of multiple evaluation metrics and human evaluation provides reasonable assessment; reported results are internally consistent

**Medium confidence**: Claim that BART-Large with control tokens achieves best overall performance is supported by SARI score but must be balanced against human evaluation showing T5-base better preserves meaning

**Low confidence**: Generalization to other biomedical domains or different scientific abstracts is uncertain given limited dataset size and specific PLABA corpus characteristics

## Next Checks

1. **Dataset size sensitivity analysis**: Conduct experiments with varying proportions of PLABA dataset (25%, 50%, 75%, 100%) to determine minimum effective training data size and assess model performance scaling

2. **Cross-domain validation**: Test best-performing models (BART-L-w-CTs and T5-base) on separate biomedical abstract corpus not used in training to evaluate generalization performance and identify domain-specific biases

3. **Control token parameter optimization**: Systematically vary control token values (DTD, WR, LV, LR) across broader range to identify optimal settings for biomedical text simplification and determine whether current values represent local optima