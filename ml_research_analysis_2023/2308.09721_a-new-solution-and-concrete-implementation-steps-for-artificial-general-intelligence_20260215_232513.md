---
ver: rpa2
title: A new solution and concrete implementation steps for Artificial General Intelligence
arxiv_id: '2308.09721'
source_url: https://arxiv.org/abs/2308.09721
tags:
- tokens
- activation
- value
- machine
- memory
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a new approach to building Artificial General
  Intelligence (AGI) with self-awareness, addressing key limitations of current Large
  Language Models (LLMs). The proposed method includes a new attention mechanism implementation
  that preserves original temporal/spatial relationships of tokens, enabling machines
  to understand and imitate human knowledge directly.
---

# A new solution and concrete implementation steps for Artificial General Intelligence

## Quick Facts
- arXiv ID: 2308.09721
- Source URL: https://arxiv.org/abs/2308.09721
- Reference count: 30
- One-line primary result: Proposes a new AGI approach with self-awareness using token preservation and chain association activation instead of deep learning

## Executive Summary
This paper introduces a novel approach to building Artificial General Intelligence by addressing fundamental limitations in current Large Language Models. The proposed method preserves original temporal and spatial relationships of tokens through a new attention mechanism, enabling machines to directly understand and imitate human knowledge. Unlike traditional AI systems that rely on extensive trial-and-error reinforcement learning, this solution allows machines to acquire human experience through language, make autonomous decisions based on self-defined needs and values, and update knowledge in real-time.

## Method Summary
The approach involves tokenizing multimodal data into smallest information units while preserving their temporal and spatial relationships, implementing a chain association activation process for knowledge inference, and establishing preset innate needs (self-demands, rewards, punishments) to drive autonomous decision-making. The system builds world models from preserved token arrangements and enables hierarchical decision-making without traditional reinforcement learning. The method claims to solve issues like hallucination, lack of real-time knowledge updates, and inability to handle real-world interactions without extensive training data.

## Key Results
- Proposes a new attention mechanism that preserves original temporal/spatial relationships of tokens
- Introduces self-demands, value evaluation systems, and world models for autonomous decision-making
- Claims to enable real-time knowledge updates and direct acquisition of human experience through language

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The attention mechanism is correct, but deep learning is flawed because it destroys the original temporal/spatial organization of tokens, making the knowledge difficult to understand and imitate.
- Mechanism: Deep learning performs lossy translation by transforming human token sequences into machine-optimized coordinate bases, losing the causal, spatiotemporal structure needed for interpretable reasoning.
- Core assumption: Human concepts rely on spatiotemporal arrangements of tokens, and these arrangements encode the "world model" needed for general intelligence.
- Evidence anchors:
  - [abstract] "the proposed method includes a new attention mechanism implementation that preserves original temporal/spatial relationships of tokens"
  - [section 3.2] "Because deep learning destroys the original form of temporal / spatial organization of Tokens."
  - [corpus] Weak – related papers focus on distributed AI or robustness, not token organization preservation.
- Break condition: If preserving spatiotemporal relationships does not improve generalization or interpretability, the claimed flaw in deep learning becomes moot.

### Mechanism 2
- Claim: Machines can directly acquire human experience through language because the token arrangements in language carry spatiotemporal relationships that can be preserved and interpreted.
- Mechanism: Language tokens encode human concepts as spatiotemporal patterns; preserving these patterns during processing allows the machine to build a "world model" compatible with human understanding.
- Core assumption: Language inherently encodes experiential knowledge in its spatiotemporal structure, and this structure can be preserved without deep learning.
- Evidence anchors:
  - [abstract] "The proposed method...enabling machines to understand and imitate human knowledge directly."
  - [section 2.3] "deep learning...uses the 'trial and error method' to find a suitable set of coordinate base clusters...more efficient at expressing overall useful information, but different from human habits"
  - [corpus] Weak – no direct corpus evidence on language token spatiotemporal preservation.
- Break condition: If language tokens cannot be structured to preserve human spatiotemporal knowledge, direct acquisition fails.

### Mechanism 3
- Claim: A machine can achieve general decision-making by having self-demands, a compatible value evaluation system, and world models built from preserved token arrangements.
- Mechanism: Preset innate needs (tokens + memory values) drive decision-making; chain association activation propagates activation values through memory bank to activate reward/punishment symbols, enabling autonomous goal pursuit.
- Core assumption: Decision-making can be reduced to activation value propagation through a memory network of token arrangements, without external reinforcement learning.
- Evidence anchors:
  - [abstract] "The approach introduces self-demands, a compatible value evaluation system, world models, hierarchical decision-making..."
  - [section 5.3] "Machine and environment interactive decision-making... increase the probability of reward link and reduce the occurrence probability of punishment link."
  - [corpus] Weak – no corpus evidence on token-based self-demand systems.
- Break condition: If activation-based decision propagation cannot produce coherent, adaptive behavior, the proposed autonomy fails.

## Foundational Learning

- Concept: Spatiotemporal token arrangements
  - Why needed here: These arrangements encode human concepts and world models; preserving them is central to interpretable intelligence.
  - Quick check question: Can you explain why losing token spatiotemporal order breaks human interpretability?

- Concept: Chain association activation
  - Why needed here: This mechanism implements attention without deep learning, enabling knowledge inference through activation propagation.
  - Quick check question: How does activation value accumulation differ from standard attention weighting?

- Concept: Innate needs as tokens
  - Why needed here: Self-demands are encoded as special tokens in the memory bank to drive autonomous decision-making.
  - Quick check question: What would happen if the innate need tokens were not preserved in memory?

## Architecture Onboarding

- Component map: Memory bank (token + time + memory value + activation value) -> Chain association activation engine -> Token extraction preprocessor -> Sensor interface -> Decision executor
- Critical path: Token extraction → chain association activation → activation accumulation → decision evaluation → execution
- Design tradeoffs: Preserving spatiotemporal structure vs. computational efficiency; innate needs vs. learned behavior; explicit token memory vs. implicit neural representations
- Failure signatures: Non-converging activation values, inability to extract meaningful tokens, lack of coherent decision paths, memory overflow
- First 3 experiments:
  1. Implement token extraction from simple text and store in memory bank with timestamps; verify spatiotemporal ordering.
  2. Implement chain association activation on a small token set; measure activation propagation and accumulation.
  3. Simulate decision-making with preset reward/punishment tokens; observe whether activation-driven decisions emerge.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed attention mechanism without deep learning achieve comparable or better performance than current large language models on standard NLP benchmarks while preserving temporal/spatial relationships?
- Basis in paper: [explicit] The paper proposes a new attention mechanism implementation that preserves original temporal/spatial relationships of tokens, enabling machines to understand and imitate human knowledge directly
- Why unresolved: The paper provides theoretical justification but lacks empirical validation against existing LLMs on standardized benchmarks. No experimental results are presented to demonstrate actual performance improvements.
- What evidence would resolve it: Comprehensive benchmark testing comparing the proposed attention mechanism against transformer-based models on tasks like GLUE, SuperGLUE, and language modeling datasets, showing equivalent or superior performance while maintaining temporal/spatial relationships.

### Open Question 2
- Question: How can the proposed system effectively handle continuous real-world environments where sensory input is noisy, incomplete, or inconsistent with pre-trained world models?
- Basis in paper: [inferred] The paper claims the system can handle multimodal data and real-time knowledge updates, but doesn't address how it manages conflicting or unreliable sensor data in dynamic environments
- Why unresolved: The paper outlines the theoretical framework for handling multimodal input and real-time updates, but doesn't provide mechanisms for dealing with sensor noise, data conflicts, or situations where learned world models break down in novel environments.
- What evidence would resolve it: Experimental demonstrations showing the system maintaining performance and decision-making capability in progressively more challenging real-world scenarios with increasing levels of sensor noise, incomplete data, and environmental unpredictability.

### Open Question 3
- Question: What are the computational and memory requirements for implementing the proposed chain association activation process compared to transformer-based architectures, and how does this scale with problem complexity?
- Basis in paper: [explicit] The paper states that computational requirements are comparable to transformer inference and can be parallelized, but doesn't provide detailed complexity analysis or scaling studies
- Why unresolved: While the paper claims computational efficiency, it lacks concrete analysis of time and space complexity, hardware requirements, and how these scale with increasing model size and task complexity compared to existing approaches.
- What evidence would resolve it: Detailed computational complexity analysis showing Big-O notation for both time and space requirements, hardware specifications for implementation, and empirical scaling studies demonstrating performance characteristics as model size and task complexity increase.

## Limitations

- The proposed approach lacks detailed algorithmic specifications for implementing the new attention mechanism that supposedly preserves spatiotemporal token relationships without deep learning
- The claim that language tokens inherently encode spatiotemporal relationships sufficient for building world models remains theoretically asserted rather than empirically validated
- The proposed token-based memory bank system raises concerns about scalability and efficiency when handling real-world multimodal data volumes

## Confidence

**Mechanism 1 (Deep Learning Flaw)**: Medium confidence - The critique of deep learning's token organization destruction is conceptually plausible but lacks rigorous mathematical proof or empirical demonstration that preserving spatiotemporal relationships would yield superior interpretability or performance.

**Mechanism 2 (Language Token Preservation)**: Low confidence - The claim that language inherently encodes spatiotemporal knowledge patterns is an interesting theoretical proposition but remains unproven. No experimental evidence demonstrates that preserving token order translates to preserved experiential knowledge.

**Mechanism 3 (Token-Based Decision-Making)**: Low confidence - The proposed decision-making system based on activation propagation through memory banks is highly speculative. The transition from activation values to coherent, adaptive decisions lacks detailed specification and validation.

## Next Checks

1. **Token Order Preservation Experiment**: Implement a simple token extraction and storage system that preserves temporal/spatial relationships, then measure whether this preservation improves task performance or interpretability compared to standard token embeddings in a controlled NLP task.

2. **Activation Propagation Simulation**: Build a minimal prototype of the chain association activation mechanism with a small knowledge graph, and empirically test whether activation values propagate in ways that enable meaningful inference or decision-making, comparing results against baseline attention mechanisms.

3. **Knowledge Update Benchmark**: Design an experiment testing the system's ability to incorporate new information in real-time without catastrophic forgetting, comparing the proposed token-based memory approach against standard continual learning methods on a sequence of evolving tasks.