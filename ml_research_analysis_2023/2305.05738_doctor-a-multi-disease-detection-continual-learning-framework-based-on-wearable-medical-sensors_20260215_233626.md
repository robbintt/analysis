---
ver: rpa2
title: 'DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable
  Medical Sensors'
arxiv_id: '2305.05738'
source_url: https://arxiv.org/abs/2305.05738
tags:
- data
- detection
- doctor
- training
- framework
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes DOCTOR, a continual learning (CL) framework
  for multi-disease detection based on wearable medical sensors. DOCTOR uses a multi-headed
  DNN and replay-based CL algorithm to continually learn new missions with different
  data distributions, classification classes, and disease detection tasks.
---

# DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors

## Quick Facts
- arXiv ID: 2305.05738
- Source URL: https://arxiv.org/abs/2305.05738
- Reference count: 33
- Primary result: Achieves competitive performance with small model size (<350KB) across three disease detection datasets

## Executive Summary
DOCTOR is a continual learning framework designed for multi-disease detection using wearable medical sensors. The framework addresses the challenge of catastrophic forgetting when learning new disease detection tasks while preserving performance on previously learned tasks. By combining a multi-headed DNN architecture with replay-based continual learning algorithms, DOCTOR can detect multiple diseases simultaneously while maintaining a compact model size suitable for edge deployment.

## Method Summary
DOCTOR employs a multi-headed deep neural network architecture where each disease detection task has its own output head, trained independently with shared lower layers. The continual learning mechanism uses data preservation to keep informative subsets from previous missions and synthetic data generation (via GMME and KDE) to create additional training examples. During training on new missions, the model replays a balanced mix of data from current and previous missions to prevent catastrophic forgetting. The framework is evaluated across three scenarios: domain-incremental (same task, different distributions), class-incremental (new classes added), and task-incremental (new detection tasks).

## Key Results
- Outperforms naive fine-tuning approaches in preventing catastrophic forgetting
- Achieves very competitive average test accuracy and macro F1-score relative to ideal joint-training framework
- Maintains small model size of less than 350KB while demonstrating promising potential for simultaneous multi-disease detection
- Successfully handles three different continual learning scenarios across three disease datasets (CovidDeep, DiabDeep, MHDeep)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The multi-headed DNN architecture allows simultaneous detection of multiple diseases by learning separate classification probability distributions for each disease task.
- Mechanism: Each disease detection task gets its own output head in the DNN, trained independently with its own softmax layer and loss function, while sharing lower layers.
- Core assumption: Different disease detection tasks are sufficiently independent that they can be learned in parallel without significant interference.
- Evidence anchors:
  - [abstract] "The multi-headed DNN enables DOCTOR to detect multiple diseases simultaneously based on user WMS data."
  - [section 4.2.3] "When a new disease detection task arrives, the framework generates a new detection head in the output layer of the DNN model in the model expansion step. The new detection head is added in parallel to the other ones."
- Break condition: Tasks become highly correlated or share very similar feature requirements, causing interference in shared layers.

### Mechanism 2
- Claim: The replay-style CL algorithm prevents catastrophic forgetting by preserving informative data from previous missions and generating synthetic data for replay during training.
- Mechanism: During training on new missions, the algorithm replays a balanced mix of data from the current mission and preserved/generated data from previous missions, ensuring the model doesn't forget previously learned tasks.
- Core assumption: Replaying representative data from previous missions during training on new missions is sufficient to maintain performance on old tasks.
- Evidence anchors:
  - [abstract] "The replay-based CL algorithm preserves the most informative subset of training data from previous missions and generates synthetic data to counteract catastrophic forgetting."
  - [section 4.3.1] "The data preservation method preserves subsets of training data from previous missions without incurring excessive computational costs."
- Break condition: The preserved/replayed data becomes too outdated or unrepresentative of the current model's decision boundaries.

### Mechanism 3
- Claim: The synthetic data generation module preserves data privacy while providing sufficient training examples for replay by modeling the joint multivariate probability distributions of real training data.
- Mechanism: The module uses both parametric (GMME) and non-parametric (KDE) density estimation methods to model the probability distribution of real training data, then samples synthetic data from these distributions for replay.
- Core assumption: The learned probability distributions accurately capture the underlying data distribution, allowing synthetic data to effectively represent real data for training purposes.
- Evidence anchors:
  - [abstract] "The synthetic data generation module models the probability distribution of the real training data and generates synthetic data for generative replay while retaining data privacy."
  - [section 4.3.2] "It models the joint multivariate probability distribution of the real training data from previous missions. Next, it generates synthetic data by sampling from the learned distribution."
- Break condition: The synthetic data generation fails to capture important distributional features, leading to poor generalization or biased predictions.

## Foundational Learning

- Concept: Catastrophic forgetting in neural networks
  - Why needed here: The paper explicitly addresses this problem as the main motivation for using continual learning, where models "overfit on new data and forget what they had learned in previous missions"
  - Quick check question: If a model is trained on task A, then fine-tuned on task B without any special mechanisms, what typically happens to its performance on task A?

- Concept: Continual learning (CL) scenarios
  - Why needed here: The framework is evaluated across three CL scenarios (domain-, class-, and task-incremental), each requiring different architectural adaptations
  - Quick check question: In class-incremental CL, what architectural change is needed when new classes are introduced?

- Concept: Density estimation methods (parametric vs non-parametric)
  - Why needed here: The synthetic data generation module uses both GMME (parametric) and KDE (non-parametric) methods to model probability distributions
  - Quick check question: What is the key difference between parametric and non-parametric density estimation approaches?

## Architecture Onboarding

- Component map: Input layer (155 neurons) -> Hidden layers (256, 128, 128 neurons with ReLU) -> Multi-head output layer (variable heads) -> Each head contains softmax layer for classification probability distribution

- Critical path:
  1. Data preprocessing (synchronization, windowing, feature extraction, normalization)
  2. Model expansion (adding heads/neurons as needed for new tasks)
  3. Training with replay (balanced mini-batches from current and previous missions)
  4. Multi-disease detection at inference (parallel processing through all heads)

- Design tradeoffs:
  - Model size vs performance: Small model (<350KB) achieved competitive performance but may limit capacity for very complex tasks
  - Data preservation vs privacy: Real data preservation gives better performance but may violate privacy requirements; synthetic data preserves privacy but may introduce bias
  - Complexity vs generalization: Multi-head architecture enables multi-disease detection but adds complexity compared to single-task models

- Failure signatures:
  - Catastrophic forgetting: Test accuracy on previous missions drops significantly when learning new missions
  - Model bias: Performance heavily skewed toward missions with more training data
  - Synthetic data issues: Imbalanced class representation in generated data leading to biased predictions
  - Overfitting: Model performs well on training data but poorly on test data, especially in synthetic data scenarios

- First 3 experiments:
  1. Domain-incremental scenario with CovidDeep dataset: Test basic replay mechanism with same task but different data distributions
  2. Class-incremental scenario with DiabDeep dataset: Test model expansion and learning new classes while preserving old ones
  3. Task-incremental scenario with MHDeep dataset: Test full multi-head architecture and simultaneous multi-disease detection capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can DOCTOR be extended to handle medical image data, given its current reliance on tabular data and synthetic data generation methods tailored for tabular data?
- Basis in paper: [inferred] The paper mentions that the synthetic data generation module can only learn the probability distributions of tabular data, and suggests that a generative model for images would be needed for medical image data.
- Why unresolved: The paper does not provide a solution for extending DOCTOR to handle medical image data. It only suggests potential generative models (GANs or diffusion models) that could be used.
- What evidence would resolve it: Successful implementation and evaluation of DOCTOR using a generative model for medical images, demonstrating comparable performance to the tabular data approach.

### Open Question 2
- Question: How can the synthetic data generation module be modified to address the potential class imbalance issue in the generated synthetic data?
- Basis in paper: [inferred] The paper discusses that the current GMME and KDE methods do not account for stratification, which could lead to imbalanced synthetic data and biased predictions.
- Why unresolved: The paper suggests learning individual probability distributions for each class as a potential solution but notes it would complicate the training process and increase computational costs. No specific implementation is provided.
- What evidence would resolve it: Implementation and evaluation of the modified synthetic data generation module that learns individual distributions for each class, demonstrating improved performance and balanced predictions across classes.

### Open Question 3
- Question: How does DOCTOR perform in real-world scenarios with continuous data streams and varying data distributions over time?
- Basis in paper: [inferred] The paper mentions that DOCTOR can adapt to data from different distributions in the domain-incremental scenario, but does not evaluate its performance with continuous data streams or long-term deployment.
- Why unresolved: The experiments conducted use fixed datasets with predefined splits, not continuous data streams or long-term deployment scenarios.
- What evidence would resolve it: Long-term deployment of DOCTOR with real-world continuous data streams, demonstrating its ability to adapt to changing data distributions and maintain performance over extended periods.

## Limitations

- Evaluation limited to three specific disease datasets, potentially limiting generalizability to other medical conditions
- Small model size (<350KB) may compromise performance on more complex disease detection tasks requiring larger model capacity
- Synthetic data generation methods may introduce bias if class distributions are not properly balanced

## Confidence

- **High**: The replay-based CL mechanism effectively prevents catastrophic forgetting (supported by comparative results against naive fine-tuning)
- **Medium**: The multi-head architecture enables simultaneous multi-disease detection (demonstrated but not extensively validated across diverse task combinations)
- **Medium**: Synthetic data generation preserves privacy while maintaining performance (evidence is mixed between parametric and non-parametric methods)

## Next Checks

1. **Cross-dataset validation**: Test DOCTOR on additional disease detection tasks with different sensor modalities to assess generalizability beyond the three evaluated datasets
2. **Privacy-performance tradeoff analysis**: Systematically compare real data preservation vs synthetic data generation across multiple privacy thresholds and disease detection tasks
3. **Scalability assessment**: Evaluate performance degradation as the number of concurrent disease detection tasks increases beyond the tested scenarios