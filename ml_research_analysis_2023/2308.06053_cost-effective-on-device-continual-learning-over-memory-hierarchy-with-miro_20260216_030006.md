---
ver: rpa2
title: Cost-effective On-device Continual Learning over Memory Hierarchy with Miro
arxiv_id: '2308.06053'
source_url: https://arxiv.org/abs/2308.06053
tags:
- memory
- accuracy
- miro
- training
- energy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of achieving cost-effective
  continual learning (CL) on resource-constrained edge devices. The core idea is to
  leverage a hierarchical memory system (HEM) that combines fast, limited memory with
  slower, larger storage for episodic replay.
---

# Cost-effective On-device Continual Learning over Memory Hierarchy with Miro

## Quick Facts
- arXiv ID: 2308.06053
- Source URL: https://arxiv.org/abs/2308.06053
- Reference count: 40
- Primary result: Achieves 7-66% energy savings and 1.35-15.37% accuracy improvements on edge devices through dynamic HEM optimization

## Executive Summary
This paper addresses the challenge of achieving cost-effective continual learning (CL) on resource-constrained edge devices. The core idea is to leverage a hierarchical memory system (HEM) that combines fast, limited memory with slower, larger storage for episodic replay. Miro, a system runtime, is proposed to dynamically optimize HEM configuration for energy efficiency and accuracy. Miro employs online profiling and adaptive parameter tuning, focusing on stream buffer and episodic memory sizes, and data swapping strategies. Extensive evaluations on diverse datasets demonstrate Miro's superiority over baseline systems, achieving significant energy savings (7–66% in small/medium experiments, 46.05% in large-scale) while improving accuracy (1.35–15.37% in small/medium, 23.37% in large-scale). Miro's lightweight profiling approach adds only 7–10% overhead, making it a practical solution for cost-effective on-device CL.

## Method Summary
The paper proposes Miro, a system runtime that optimizes hierarchical episodic memory (HEM) for continual learning on edge devices. Miro dynamically configures memory hierarchy parameters (episodic memory size, stream buffer size) through online profiling, balancing accuracy and energy consumption. The system uses a utility function that maximizes accuracy gain per energy unit, employs cutline filtering to ensure quality configurations, and adapts data swapping ratios based on I/O conditions. The approach is evaluated across multiple datasets including CIFAR100, Tiny-ImageNet, UrbanSound8K, DSADS, and ImageNet1k.

## Key Results
- Achieves 7-66% energy savings compared to baseline systems in small/medium-scale experiments
- Improves accuracy by 1.35-15.37% in small/medium experiments while maintaining energy efficiency
- Demonstrates 46.05% energy savings and 23.37% accuracy improvement in large-scale experiments
- Maintains only 7-10% profiling overhead while delivering significant performance gains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Miro improves cost-effectiveness by dynamically optimizing the memory hierarchy configuration (EM and SB sizes) based on real-time resource states.
- Mechanism: Miro profiles multiple EM/SB size combinations during task transitions, estimates their accuracy-energy trade-offs using a lightweight online profiler, and selects the configuration with the highest utility (accuracy gain per energy unit) within the current memory budget.
- Core assumption: The optimal EM/SB configuration varies across tasks due to changing data drift and model conditions, making static or historical configurations suboptimal.
- Evidence anchors:
  - [abstract]: "Miro, a novel system runtime that carefully integrates our insights into the CL framework by enabling it to dynamically configure the CL system based on resource states for the best cost-effectiveness."
  - [section 4.3.3]: "Miro constructs a conf search space by taking into account the new task size and the current memory budget. It then launches mini-training tasks to quickly obtain accuracy and energy estimates for each candidate conf."
- Break condition: If the profiling overhead becomes too high relative to the energy savings, or if the accuracy-energy trade-off landscape becomes flat (making configuration choices irrelevant).

### Mechanism 2
- Claim: Miro manages I/O bandwidth efficiently for data swapping by adapting the swap ratio based on system-wide I/O usage.
- Mechanism: Miro monitors I/O queue states (congested, idle, stable) and adjusts the swap ratio incrementally when idle or decreases it rapidly when congested, maximizing data diversity without causing I/O bottlenecks.
- Core assumption: I/O operations are asynchronous and have negligible impact on training time and energy consumption compared to GPU processing.
- Evidence anchors:
  - [section 3.3.1]: "I/O activity driven by data swapping accounts for a small portion of the power consumption (∼0.1W)... the I/O power consumption is insignificant relative to the GPU power."
  - [section 4.2]: "Miro sets a swap ratio that attempts to fully utilize the available I/O bandwidth... Miro continuously monitors system-wide I/O usage to refine the data swapping strategy."
- Break condition: If I/O bandwidth becomes a significant bottleneck due to other system processes, or if the swap ratio adjustments cannot keep up with rapid I/O state changes.

### Mechanism 3
- Claim: Miro uses a cutline-based filtering approach to ensure selected configurations meet a minimum accuracy threshold while optimizing for energy efficiency.
- Mechanism: Miro ranks candidate configurations by accuracy, applies a cutline to filter out configurations below a certain accuracy percentile, and then selects the configuration with the highest utility (accuracy/energy) from the remaining candidates.
- Core assumption: A small subset of high-accuracy configurations exists that also offers good energy efficiency, and this subset can be effectively identified using the cutline approach.
- Evidence anchors:
  - [section 4.3.2]: "We introduce cutline, a straightforward yet powerful technique that enables us to narrow down high-accuracy confs by their accuracy ranks... if we search for the conf with the best utility, we obtain the conf (1K, 2K), which is a valid choice."
  - [section 6.3]: "We found that setting the cutline between 20–50% works well for our benchmarks."
- Break condition: If the cutline is set too high, excluding potentially good configurations, or too low, including configurations that don't meet the minimum accuracy requirement.

## Foundational Learning

- Concept: Continual Learning (CL) and Catastrophic Forgetting
  - Why needed here: Understanding CL is crucial because Miro is designed to address the challenge of catastrophic forgetting in on-device learning by leveraging episodic memory and a hierarchical memory system.
  - Quick check question: What is catastrophic forgetting, and why is it a significant challenge in continual learning?

- Concept: Memory Hierarchy and Hierarchical Episodic Memory (HEM)
  - Why needed here: Miro's core innovation is optimizing HEM for cost-effectiveness, so understanding how HEM works and its components (EM, SB, storage) is essential.
  - Quick check question: How does HEM differ from traditional single-level episodic memory, and what are the benefits of using HEM for continual learning on edge devices?

- Concept: Energy Efficiency Metrics and Utility Function
  - Why needed here: Miro's goal is to achieve cost-effectiveness, which involves balancing accuracy and energy consumption. Understanding energy efficiency metrics and the utility function used by Miro is crucial for evaluating its performance.
  - Quick check question: What is the utility function used by Miro, and how does it help in selecting the most cost-effective configuration?

## Architecture Onboarding

- Component map: Miro runtime -> Profiler -> Estimate -> Adapt -> HEM (EM, SB, Storage)
- Critical path: Task arrival → Profiling (evaluate EM/SB configurations) → Probe (monitor resource states) → Estimate (compute new parameter values) → Adapt (apply new configuration) → Training with HEM
- Design tradeoffs:
  - Profiling overhead vs. energy savings: More extensive profiling can lead to better configurations but increases overhead
  - Cutline strictness vs. configuration options: A stricter cutline ensures higher accuracy but may limit the number of viable configurations
  - Swap ratio vs. I/O contention: A higher swap ratio increases data diversity but may cause I/O bottlenecks
- Failure signatures:
  - Profiling overhead exceeds energy savings: Profiler optimizations may be needed
  - I/O contention affects training time: Swap ratio adaptation may need tuning
  - Selected configuration doesn't meet accuracy requirements: Cutline or utility function may need adjustment
- First 3 experiments:
  1. Evaluate Miro's performance on a small dataset (e.g., CIFAR100) with varying memory budgets and compare against baseline systems (CarM, BestStatic, BestHistory)
  2. Test Miro's I/O management by simulating different I/O contention scenarios and measuring the impact on swap ratio adaptation
  3. Validate the cutline-based filtering approach by varying the cutline value and observing its effect on configuration selection and overall cost-effectiveness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can Miro be adapted to handle storage capacity limitations when scaling up to a very large number of tasks?
- Basis in paper: [explicit] The paper mentions that when scaling up to a very large number of tasks, realistic on-device CL based on HEM may exceed the storage capacity, and suggests two possible options: embracing larger external storage or evicting some in-storage samples from each class.
- Why unresolved: The paper only mentions the two options but does not provide a detailed solution or implementation for handling storage capacity limitations in Miro.
- What evidence would resolve it: A detailed solution or implementation that demonstrates how Miro can be adapted to handle storage capacity limitations when scaling up to a very large number of tasks, including the effectiveness of the proposed solution.

### Open Question 2
- Question: How can Miro be improved with more fine-grained, task-level resource allocation policies for both memory and I/O to enhance the effectiveness of HEM for scenarios with high temporal locality?
- Basis in paper: [explicit] The paper mentions that for scenarios like video analytics with high temporal locality, Miro needs to be improved with more fine-grained, task-level resource allocation policies for both memory and I/O to allow HEM to use in-storage data collected from recent tasks more aggressively.
- Why unresolved: The paper only mentions the need for improvement but does not provide a detailed solution or implementation for enhancing Miro with more fine-grained, task-level resource allocation policies.
- What evidence would resolve it: A detailed solution or implementation that demonstrates how Miro can be improved with more fine-grained, task-level resource allocation policies for both memory and I/O, including the effectiveness of the proposed solution in enhancing the effectiveness of HEM for scenarios with high temporal locality.

### Open Question 3
- Question: How can Miro's profiling approach be optimized for workloads like video analytics, where consecutive tasks defined by fixed time windows often exhibit high temporal locality and similar class distributions?
- Basis in paper: [explicit] The paper mentions that for workloads like video analytics with high temporal locality, it may be possible to treat two adjacent tasks as a single, larger task that does not require parameter reconfiguration, but does not provide a detailed solution or implementation for optimizing Miro's profiling approach in such scenarios.
- Why unresolved: The paper only mentions the possibility of optimizing Miro's profiling approach for such scenarios but does not provide a detailed solution or implementation.
- What evidence would resolve it: A detailed solution or implementation that demonstrates how Miro's profiling approach can be optimized for workloads like video analytics, including the effectiveness of the proposed solution in reducing profiling overhead and improving cost-effectiveness.

## Limitations

- Energy measurements are based on controlled experimental conditions that may not fully reflect real-world edge device variability and interference patterns
- Scalability claims rely on assumptions about storage capacity that may not hold for all edge deployment scenarios
- Effectiveness of the cutline filtering approach depends heavily on dataset characteristics and task similarity

## Confidence

- **High confidence** in the core mechanism of dynamic HEM configuration optimization - the profiling methodology and utility function are clearly specified and technically sound
- **Medium confidence** in the I/O bandwidth management claims - while the approach is logical, the experimental validation focuses on controlled conditions
- **Medium confidence** in the overall cost-effectiveness improvements - the 7-66% energy savings are impressive but may vary significantly based on deployment conditions

## Next Checks

1. Conduct ablation studies to isolate the individual contribution of each Miro optimization component (profiling, cutline filtering, I/O management) to the overall performance gains
2. Test Miro's performance under realistic edge device conditions with concurrent applications and varying system loads to validate the I/O management claims
3. Evaluate the system's behavior with heterogeneous task distributions and varying task similarities to assess the robustness of the cutline-based filtering approach