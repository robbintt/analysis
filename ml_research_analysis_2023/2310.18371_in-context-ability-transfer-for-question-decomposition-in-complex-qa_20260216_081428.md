---
ver: rpa2
title: In-Context Ability Transfer for Question Decomposition in Complex QA
arxiv_id: '2310.18371'
source_url: https://arxiv.org/abs/2310.18371
tags:
- u1d460
- u1d456
- question
- complex
- u1d45e
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of complex question answering
  (QA) that requires multi-step reasoning and question decomposition. While existing
  approaches rely on manual annotations or model fine-tuning, the authors propose
  ICAT (In-Context Ability Transfer), a method that induces reasoning capabilities
  in large language models (LLMs) without fine-tuning or manual annotation.
---

# In-Context Ability Transfer for Question Decomposition in Complex QA

## Quick Facts
- arXiv ID: 2310.18371
- Source URL: https://arxiv.org/abs/2310.18371
- Authors: 
- Reference count: 40
- Key outcome: ICAT transfers complex QA abilities via in-context learning without fine-tuning, outperforming existing prompt-based solutions

## Executive Summary
This paper introduces ICAT (In-Context Ability Transfer), a method that enables large language models to perform complex question decomposition without manual annotation or model fine-tuning. By carefully selecting exemplars from related datasets with annotated rationales, ICAT transfers reasoning abilities to target tasks through in-context learning. The authors also propose an automated uncertainty-aware exemplar selection approach using Frechet Term Distance (FTD) to dynamically select relevant examples. Experiments on numerical reasoning, compositional QA, and heterogeneous QA tasks demonstrate that ICAT achieves strong performance while requiring no model training.

## Method Summary
ICAT transfers reasoning abilities from annotated datasets to LLMs by selecting relevant exemplars as demonstrations in prompts. The method uses either static exemplar selection (manual curation) or dynamic selection based on Frechet Term Distance (FTD), which measures distributional similarity between token embeddings of test questions and exemplars. For a given complex question, ICAT constructs a prompt containing instructions, selected exemplars showing question decomposition, and the test question itself. The LLM then generates decomposed sub-questions and reasoning chains, with final answers aggregated from sub-question responses.

## Key Results
- ICAT achieves strong performance on complex QA tasks without model training or manual annotation
- Dynamic FTD-based exemplar selection improves performance over static selection and baseline methods
- Ability transfer from related datasets enables effective question decomposition across multiple QA domains

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Transferring pre-existing reasoning abilities from annotated datasets to LLMs via in-context learning can enable effective complex question decomposition without manual annotation.
- Mechanism: ICAT reuses annotated rationales or sub-questions from related datasets (transfer datasets) as demonstrations in prompts, allowing the LLM to induce decomposition capabilities by aligning its reasoning to the exemplars.
- Core assumption: The reasoning ability demonstrated in a transfer dataset is transferable to a target dataset if the exemplar distributions are sufficiently similar.
- Evidence anchors:
  - [abstract] "ICAT transfers the ability to decompose complex questions to simpler questions or generate step-by-step rationales to LLMs, by careful selection from available data sources of related tasks."
  - [section 3.2] "Given a new question, we propose both static and dynamic selection approaches to automatically select relevant abilities necessary for decomposing the complex question."
- Break condition: If the transfer dataset lacks exemplars that capture the target task's reasoning structure, or if the exemplar selection fails to capture relevant semantic features, the ability transfer will not succeed.

### Mechanism 2
- Claim: Dynamic exemplar selection using Frechet Term Distance (FTD) improves performance by selecting high-quality, diverse demonstrations that are semantically aligned with the test question.
- Mechanism: FTD measures the distributional similarity between token embeddings of a test question and exemplars in the transfer dataset, selecting those with low FTD to ensure both relevance and diversity.
- Core assumption: Token-level embedding distributions are robust indicators of semantic similarity, and FTD's use of multivariate Gaussian fitting makes it invariant to embedding method variations.
- Evidence anchors:
  - [section 3.4] "We propose a new uncertainty-aware exemplar selection approach for selecting examples from transfer datasets."
  - [section 3.4.1] "The proposed metric FTD is less sensitive to choice of embedding and provides robust performance across datasets."
- Break condition: If the embedding model fails to capture key semantic features, or if the transfer dataset is too small to provide diverse exemplars, FTD may not improve selection quality.

### Mechanism 3
- Claim: Using few-shot demonstrations with chain-of-thought (COT) reasoning chains in prompts enables LLMs to perform multi-step reasoning without fine-tuning.
- Mechanism: Prompts containing examples of complex questions, their decomposed sub-questions, and final answers guide the LLM to generate similar reasoning chains for new questions.
- Core assumption: LLMs can learn to generalize decomposition patterns from a small number of high-quality demonstrations.
- Evidence anchors:
  - [abstract] "ICAT induces reasoning capabilities in LLMs without any LLM fine-tuning or manual annotation of in-context samples."
  - [section 3.3] "For ICAT static selection, we carefully select exemplars such that they cover diverse question types."
- Break condition: If the demonstrations are not diverse or do not cover the target question types, the LLM may fail to generate correct decompositions.

## Foundational Learning

- Concept: In-context learning (ICL)
  - Why needed here: ICL allows LLMs to perform tasks by conditioning on a few examples without model fine-tuning, which is central to ICAT's approach.
  - Quick check question: What is the main advantage of ICL over fine-tuning for complex QA tasks?

- Concept: Chain-of-thought (COT) reasoning
  - Why needed here: COT provides a structured way to decompose complex questions into simpler sub-questions, enabling step-by-step reasoning.
  - Quick check question: How does COT improve LLM performance on multi-step reasoning tasks compared to vanilla few-shot prompting?

- Concept: Transfer learning
  - Why needed here: ICAT relies on transferring reasoning abilities from related datasets to the target task, leveraging pre-existing annotated data.
  - Quick check question: Why is the choice of transfer dataset critical for successful ability transfer in ICAT?

## Architecture Onboarding

- Component map:
  - Transfer datasets -> Exemplar selection module -> LLM inference engine -> Final answer

- Critical path:
  1. Select transfer dataset(s) with relevant reasoning abilities
  2. Choose exemplars using static or dynamic selection
  3. Construct prompt with instructions and exemplars
  4. Feed prompt to LLM and generate decomposition
  5. Aggregate sub-question answers to form final answer

- Design tradeoffs:
  - Static vs dynamic exemplar selection: Static is simpler but may not adapt to test question distribution; dynamic is more robust but computationally heavier
  - Transfer dataset choice: More related datasets improve performance but may limit availability; less related datasets require more diverse exemplars

- Failure signatures:
  - Incorrect or incomplete decompositions indicate exemplar selection or prompt construction issues
  - Hallucinations or factually inconsistent answers suggest LLM reasoning failures or lack of grounding
  - Poor performance across multiple tasks may indicate transfer dataset irrelevance or insufficient exemplar diversity

- First 3 experiments:
  1. Evaluate static exemplar selection on a single complex QA dataset to establish baseline performance
  2. Compare dynamic FTD-based selection against KNN and MMR on the same dataset to assess improvement
  3. Test transfer from multiple related datasets to a target dataset to measure impact of dataset relatedness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the effectiveness of ICAT's dynamic exemplar selection (FTD) compare to static selection methods across different LLM scales and task complexities?
- Basis in paper: [explicit] The paper mentions that FTD offers superior performance across SvAmp and MultiArith and is competitive or offers gains over existing auto-exemplar selection approaches like KNN and MMR. However, it also notes that static selection methods can sometimes be competitive with dynamic selection.
- Why unresolved: The paper does not provide a comprehensive comparison of FTD against static selection across various LLM scales and task complexities. It only briefly mentions the performance on specific datasets.
- What evidence would resolve it: A detailed experimental study comparing FTD and static selection methods across different LLM scales (e.g., gpt-3.5-turbo, text-davinci-003, etc.) and task complexities (e.g., numerical reasoning, compositional QA, heterogeneous QA) with statistical significance tests.

### Open Question 2
- Question: How does the choice of transfer datasets affect the performance of ICAT, especially when similar tasks are not available?
- Basis in paper: [explicit] The paper discusses the importance of dataset relatedness and provides an example of FinQA←AquaRat vs FinQA←TabMwp, showing that TabMwp performs better due to its ability to parse tables. However, it does not explore scenarios where similar tasks are not available.
- Why unresolved: The paper does not investigate the performance of ICAT when transfer datasets do not closely match the target task, which is a common scenario in real-world applications.
- What evidence would resolve it: Experiments comparing the performance of ICAT using various transfer datasets with different levels of similarity to the target task, including cases where no closely related datasets are available.

### Open Question 3
- Question: What are the limitations of using Frechet Term Distance (FTD) for exemplar selection, and how does it perform in scenarios with noisy or incomplete data?
- Basis in paper: [explicit] The paper proposes FTD as an uncertainty-aware exemplar selection method and claims it is less sensitive to the choice of embedding model. However, it does not discuss potential limitations or performance in noisy or incomplete data scenarios.
- Why unresolved: The paper does not provide a thorough analysis of FTD's limitations or its robustness to data quality issues, which are critical factors in real-world applications.
- What evidence would resolve it: Experiments testing FTD's performance on datasets with varying levels of noise and incompleteness, along with a comparison to other exemplar selection methods under similar conditions.

## Limitations
- Limited ablation studies across all datasets, with only 2 of 5 datasets tested for key variations
- Restricted evaluation scope using only one LLM variant (gpt-3.5-turbo) and limited transfer datasets
- Lack of error analysis to understand hallucination rates and failure modes in decomposition generation

## Confidence
- Mechanism of ability transfer: Medium - supported by multiple datasets but limited ablation studies
- FTD metric effectiveness: Medium - theoretical justification is strong but empirical validation is incomplete
- Generalizability across tasks: Low - evaluated on only 5 datasets with no cross-task scaling analysis

## Next Checks
1. Implement comprehensive ablation studies across all five datasets to test the impact of transfer dataset selection, exemplar diversity, and prompt construction variations
2. Conduct error analysis on decomposed sub-questions to quantify hallucination rates and factual consistency issues
3. Test ICAT performance across multiple LLM variants (different sizes and architectures) to assess scalability and model dependency