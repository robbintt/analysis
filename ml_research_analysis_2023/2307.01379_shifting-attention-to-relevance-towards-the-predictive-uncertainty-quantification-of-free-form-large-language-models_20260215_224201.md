---
ver: rpa2
title: 'Shifting Attention to Relevance: Towards the Predictive Uncertainty Quantification
  of Free-Form Large Language Models'
arxiv_id: '2307.01379'
source_url: https://arxiv.org/abs/2307.01379
tags:
- uncertainty
- llms
- tokens
- sentences
- estimation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of uncertainty estimation in
  free-form large language models (LLMs), where linguistic redundancy causes some
  tokens to be treated equally despite varying relevance. The authors propose Shifting
  Attention to Relevance (SAR), a method that jointly examines token- and sentence-level
  relevance and reassigns attention to more meaningful components.
---

# Shifting Attention to Relevance: Towards the Predictive Uncertainty Quantification of Free-Form Large Language Models

## Quick Facts
- arXiv ID: 2307.01379
- Source URL: https://arxiv.org/abs/2307.01379
- Authors: 
- Reference count: 18
- Primary result: Proposed SAR method achieves up to 2.9% higher AUROC on CoQA and 8.3% on SciQ compared to baseline uncertainty estimation methods

## Executive Summary
This paper addresses the challenge of uncertainty estimation in free-form large language models (LLMs), where linguistic redundancy causes some tokens to be treated equally despite varying relevance. The authors propose Shifting Attention to Relevance (SAR), a method that jointly examines token- and sentence-level relevance and reassigns attention to more meaningful components. SAR is evaluated on popular "off-the-shelf" LLMs (e.g., OPT, LLaMA) and commercial models (e.g., Davinci) across multiple free-form question-answering tasks. Results demonstrate that SAR significantly outperforms baseline methods, achieving up to 2.9% higher AUROC on CoQA and 8.3% on SciQ. The method is generation-efficient and effective even with few generations.

## Method Summary
SAR addresses uncertainty estimation in LLMs by recognizing that tokens are created unequally in reflecting meaning, yet are equally valued when estimating uncertainty. The method generates multiple sentences per prompt using greedy search (for correctness) and multinomial sampling (temperature 0.5) for uncertainty estimation. It computes token-level relevance by measuring semantic change after token removal using sentence transformers, then adjusts token-level uncertainty based on normalized relevance scores. Sentence-level relevance is computed via weighted semantic similarity with other generated sentences, and uncertainty scores are adjusted accordingly. The token- and sentence-level shifted scores are combined to produce final uncertainty estimates, which outperform baseline methods on AUROC metrics across multiple datasets and model sizes.

## Key Results
- SAR achieves up to 2.9% higher AUROC on CoQA compared to baseline uncertainty estimation methods
- SAR outperforms baselines by up to 8.3% on SciQ dataset
- Method demonstrates generation efficiency, working effectively even with few generations
- SAR shows consistent performance improvements across different model scales (OPT-2.7B to LLaMA-13B)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linguistic redundancy causes some tokens to be semantically less important yet contribute heavily to uncertainty estimates.
- Mechanism: Tokens with low semantic relevance (e.g., articles, prepositions) are assigned equal uncertainty weight as high-relevance tokens (e.g., nouns, verbs) in standard entropy-based UQ methods, leading to overestimation.
- Core assumption: Semantic importance of a token can be quantified by measuring the semantic change before and after its removal.
- Evidence anchors:
  - [abstract] "Our research is derived from the heuristic facts that tokens are created unequally in reflecting the meaning of generations by auto-regressive LLMs, i.e., some tokens are more relevant (or representative) than others, yet all the tokens are equally valued when estimating uncertainty."
  - [section 3.2] "To measure how important zi is in reflecting the semantics of s, we compare the semantic change before and after removing this token..."
- Break condition: If semantic similarity metrics fail to capture token importance accurately, or if linguistic redundancy does not correlate with token relevance.

### Mechanism 2
- Claim: Shifting attention to more relevant tokens and sentences improves uncertainty estimation by reducing noise from irrelevant components.
- Mechanism: SAR reweights token-level uncertainty by normalized relevance scores and adjusts sentence-level uncertainty by enhancing the generative probability of semantically consistent sentences.
- Core assumption: Relevant tokens/sentences are more indicative of the true uncertainty and should contribute more to the final UQ score.
- Evidence anchors:
  - [abstract] "We propose Shifting Attention to more Relevant (SAR) components at both token- and sentence-levels for better UQ."
  - [section 4.2] "SAR corrects generative inequalities by reviewing the relevance of each token and/or sentence and emphasizing uncertainty estimation attention to those more relevant components."
- Break condition: If relevance scores do not correlate with actual semantic importance, or if adjusting attention introduces bias in uncertainty estimation.

### Mechanism 3
- Claim: Combining token-level and sentence-level attention shifting provides orthogonal benefits and improves overall UQ performance.
- Mechanism: Token-level shifting focuses on individual token importance, while sentence-level shifting emphasizes the coherence among multiple generations; together they address different aspects of generative inequality.
- Core assumption: Token-level and sentence-level relevance assessments capture complementary information that jointly improves uncertainty estimation.
- Evidence anchors:
  - [section 4.3] "Token-level shifting and sentence-level shifting are orthogonal and they can be naturally combined."
  - [section 5.2] "For instance, TOKEN SAR and SENT SAR achieve 0.723 AUROC in the OPT-30b-CoQA setting yet combining them results in 0.748 AUROC."
- Break condition: If token-level and sentence-level relevance do not provide complementary information, or if combining them introduces redundancy.

## Foundational Learning

- Concept: Semantic similarity measurement using sentence transformers (e.g., Cross-Encoder RoBERTa-large).
  - Why needed here: To quantify the relevance of tokens and sentences by measuring semantic change or consistency.
  - Quick check question: How would you compute the semantic similarity between two sentences using a pre-trained sentence transformer model?

- Concept: Uncertainty quantification metrics such as AUROC and predictive entropy.
  - Why needed here: To evaluate the performance of uncertainty estimation methods and compare them against baselines.
  - Quick check question: What is the difference between predictive entropy and length-normalized predictive entropy in the context of uncertainty estimation?

- Concept: Token-level and sentence-level generative probabilities in auto-regressive models.
  - Why needed here: To understand how tokens and sentences contribute to the overall uncertainty and how their probabilities can be adjusted.
  - Quick check question: How is the generative probability of a sentence calculated from the token-level probabilities in an auto-regressive model?

## Architecture Onboarding

- Component map: Input prompt → LLM generation → Multiple sentence outputs → Relevance computation (token-level and sentence-level) → Normalized relevance scores → Uncertainty computation (baseline methods) → SAR-adjusted uncertainty scores → Evaluation (AUROC, correctness metrics) → Performance comparison

- Critical path:
  1. Generate multiple sentences for a given prompt.
  2. Compute token-level relevance by measuring semantic change upon token removal.
  3. Compute sentence-level relevance by measuring semantic similarity with other generated sentences.
  4. Adjust uncertainty estimates using SAR (token-level and/or sentence-level shifting).
  5. Evaluate performance using AUROC and correctness metrics.

- Design tradeoffs:
  - Computational cost vs. accuracy: SAR requires additional semantic similarity computations, which may increase latency.
  - Model access: SAR needs access to token logits for adjusting probabilities; may not be feasible with black-box models.
  - Hyperparameter tuning: Temperature parameter t controls the scale of sentence-level shifting and may require tuning for optimal performance.

- Failure signatures:
  - Performance degradation if relevance scores are inaccurate or do not correlate with semantic importance.
  - Overfitting to specific datasets or model architectures if not properly validated.
  - Increased computational overhead without significant performance gains.

- First 3 experiments:
  1. Evaluate SAR on a simple QA dataset (e.g., CoQA) with a small LLM (e.g., OPT-2.7b) to validate the core mechanism.
  2. Compare SAR against baseline methods (e.g., Predictive Entropy, Semantic Entropy) to quantify performance improvements.
  3. Analyze the impact of different relevance thresholds and temperature parameters on SAR's performance to identify optimal settings.

## Open Questions the Paper Calls Out
None explicitly stated in the provided content.

## Limitations
- Dependence on accurate semantic relevance scoring - if the Cross-Encoder model misestimates token importance, shifted uncertainty estimates could become misleading
- Computational overhead from repeated sentence similarity calculations and pairwise comparisons across generated sentences
- Assumption of access to token logits for probability adjustments, limiting applicability to black-box commercial APIs
- Validation primarily on QA tasks raises questions about generalizability to other domains

## Confidence
- High confidence: The core mechanism of addressing token-level generative inequality through relevance-aware attention shifting is well-supported by both theoretical motivation and empirical results (AUROC improvements up to 8.3% on SciQ)
- Medium confidence: The claim that SAR works effectively even with few generations is supported by ablation studies, but the optimal number of generations for balancing accuracy and efficiency requires further investigation
- Medium confidence: While the computational efficiency claim is supported by generation counts, the actual inference-time overhead from relevance computations was not explicitly measured or reported

## Next Checks
1. **Cross-domain robustness test**: Evaluate SAR on non-QA tasks (e.g., summarization, translation, or creative writing) to verify whether relevance-based attention shifting generalizes beyond question-answering contexts.

2. **Black-box compatibility validation**: Test whether SAR can approximate uncertainty estimates when only access to model outputs (not logits) is available, perhaps by using temperature-based sampling or proxy relevance scores.

3. **Computational overhead measurement**: Quantify the exact inference-time overhead introduced by token-level semantic similarity calculations and sentence-level pairwise comparisons, and compare against the performance gains in AUROC to establish the efficiency trade-off.