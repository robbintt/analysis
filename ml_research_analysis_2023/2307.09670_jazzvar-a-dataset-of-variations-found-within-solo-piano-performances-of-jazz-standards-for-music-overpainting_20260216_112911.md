---
ver: rpa2
title: 'JAZZVAR: A Dataset of Variations found within Solo Piano Performances of Jazz
  Standards for Music Overpainting'
arxiv_id: '2307.09670'
source_url: https://arxiv.org/abs/2307.09670
tags:
- jazz
- music
- dataset
- original
- pianists
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The JAZZVAR dataset contains 502 pairs of manually extracted "Original"
  lead sheet segments and "Variation" segments from solo jazz piano performances,
  providing a foundation for music overpainting - a novel generative task that creates
  variations while preserving melodic and harmonic structure. The dataset enables
  exploration of how jazz pianists uniquely interpret standards, with analysis showing
  that variations exhibit higher pitch range, pitch class entropy, and number of pitches
  compared to originals.
---

# JAZZVAR: A Dataset of Variations found within Solo Piano Performances of Jazz Standards for Music Overpainting

## Quick Facts
- arXiv ID: 2307.09670
- Source URL: https://arxiv.org/abs/2307.09670
- Reference count: 23
- Dataset contains 502 pairs of Original lead sheet segments and Variation segments from solo jazz piano performances

## Executive Summary
The JAZZVAR dataset addresses a critical gap in music information retrieval by providing 502 manually curated pairs of lead sheet segments ("Originals") and their corresponding variations extracted from solo jazz piano performances. This resource enables the novel task of music overpainting - generating variations that preserve melodic and harmonic structure while adding expressive complexity. The dataset fills a void left by existing jazz datasets that typically focus on improvisation sections rather than variations within standards. Analysis reveals that variations exhibit higher pitch range, pitch class entropy, and number of pitches compared to originals, providing measurable targets for generative models.

## Method Summary
The dataset was created by first obtaining lead sheets for jazz standards and their corresponding solo piano performances. Researchers manually extracted 4-bar Original segments from lead sheets, then searched AMT transcriptions of performances to find melodically and harmonically similar Variation segments. The 502 pairs were then analyzed using MIR features including pitch class entropy, pitch range, polyphony, number of pitches, and scale consistency. A baseline Music Transformer model was trained on concatenated Original+Variation pairs, using the Original segment as a primer to generate new Variation segments. The Music Transformer architecture, adapted from Huang et al. (2019), treats Original and Variation as one continuous sequence during training.

## Key Results
- JAZZVAR contains 502 pairs of manually matched Original and Variation segments from solo jazz piano performances
- Variations show statistically higher pitch range (47.20 vs 36.44), pitch class entropy (3.13 vs 2.94), and number of pitches compared to Originals
- The baseline Music Transformer successfully generates variations from Original primers, producing more complex outputs than inputs
- The dataset enables exploration of jazz pianists' unique interpretation styles across three prominent performers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Manual pair matching ensures semantic alignment between originals and variations
- Mechanism: Researchers manually curated 502 pairs by finding melodic/harmonic correspondences in AMT transcriptions, preserving the perceptual relationship needed for overpainting
- Core assumption: Human perception of "melodic and harmonic similarity" is reliable enough for training a generative model
- Evidence anchors:
  - [abstract] "Each Variation in the dataset is accompanied by a corresponding Original segment containing the melody and chords"
  - [section] "We find Variation segments by searching for passages that are melodically and harmonically similar to Original segments"
  - [corpus] Weak - no citations yet, dataset is new
- Break condition: If AMT transcription errors obscure the intended melodic/harmonic structure, manual matching may not capture true correspondences

### Mechanism 2
- Claim: Dataset statistics reveal meaningful variation patterns that a transformer can learn
- Mechanism: Analysis shows variations have higher pitch range, pitch class entropy, and number of pitches, providing a measurable target for generative models
- Core assumption: The observed statistical differences represent the space of valid variations a model should generate
- Evidence anchors:
  - [section] "Pitch Class Entropy... higher mean pitch class entropy in the Variation segments (3.13) compared to the Original segments (2.94)"
  - [section] "Pitch Range... mean pitch range in the Variation segments (47.20) is considerably larger than in the Original segments (36.44)"
  - [corpus] Weak - no citations yet, dataset is new
- Break condition: If the model learns to simply increase entropy without preserving melodic/harmonic structure, it fails the overpainting task

### Mechanism 3
- Claim: Transformer architecture conditioned on original segments can generate coherent variations
- Mechanism: Concatenating original+variation pairs trains the model to map inputs to valid outputs, with originals serving as priming sequences
- Core assumption: The concatenated training format enables the transformer to learn the mapping function I(O) = V
- Evidence anchors:
  - [section] "we adopted the design of Music Transformer... we concatenated the Variation segments to the end of the Original segments"
  - [section] "we treated the Original segment as a primer and generated a Variation segment"
  - [corpus] Weak - only mentions related transformer work without specific citations to overpainting
- Break condition: If the model cannot maintain melodic/harmonic coherence while increasing complexity, it fails to perform true overpainting

## Foundational Learning

- Concept: Music Information Retrieval (MIR) feature extraction
  - Why needed here: The dataset analysis relies on computing pitch class entropy, pitch range, polyphony, and scale consistency
  - Quick check question: What MIR feature would you use to measure the diversity of pitch usage in a segment?

- Concept: Automatic Music Transcription (AMT) evaluation
  - Why needed here: The dataset depends on AMT accuracy for finding variation candidates in performances
  - Quick check question: How would transcription errors in jazz piano performances affect the quality of the Original-Variation pairs?

- Concept: Transformer sequence modeling for music
  - Why needed here: The Music Transformer is used to learn the mapping from original segments to variations
  - Quick check question: What architectural choice allows transformers to model long-range musical dependencies better than RNNs?

## Architecture Onboarding

- Component map: Dataset curation -> Feature analysis -> Transformer training -> Generation pipeline
- Critical path: Manual pair creation -> Statistical validation -> Model training -> Primer-based generation
- Design tradeoffs: Manual curation ensures quality but limits scale; AMT enables automation but introduces noise
- Failure signatures: Generated variations lack melodic coherence; statistics don't match target distribution; model overfits to specific pianists
- First 3 experiments:
  1. Generate variations from a simple known original and verify melodic/harmonic preservation
  2. Compare generated statistics to dataset targets (entropy, pitch range, etc.)
  3. Test model on unseen originals to assess generalization across pianists

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the diversity and complexity of variations in the JAZZVAR dataset compare to other existing jazz datasets?
- Basis in paper: [explicit] The paper mentions that existing jazz datasets often focus on improvisation sections within jazz performances, while JAZZVAR focuses on variations found within solo piano performances of jazz standards.
- Why unresolved: The paper does not provide a direct comparison of the diversity and complexity of variations in JAZZVAR to other datasets.
- What evidence would resolve it: A quantitative analysis comparing the musical features (e.g., pitch class entropy, pitch range, polyphony) of variations in JAZZVAR to those in other jazz datasets.

### Open Question 2
- Question: How does the Music Overpainting task differ from other generative music tasks like compositional style transfer and music infilling?
- Basis in paper: [explicit] The paper states that Music Overpainting creates small variations within the same style and retains perceptible similarities in the underlying melodic contour and harmonic structure of the music segment, while compositional style transfer and music infilling have different objectives.
- Why unresolved: The paper does not provide a detailed comparison of the differences between Music Overpainting and other generative music tasks.
- What evidence would resolve it: A detailed analysis of the outputs from Music Overpainting, compositional style transfer, and music infilling tasks, highlighting the differences in their approaches and results.

### Open Question 3
- Question: How can the JAZZVAR dataset be expanded to include a larger number of Original and Variation pairs?
- Basis in paper: [inferred] The paper mentions the possibility of expanding the dataset through manual matching or automatic methods, but does not provide specific details on how to achieve this.
- Why unresolved: The paper does not provide a concrete plan or methodology for expanding the dataset.
- What evidence would resolve it: A detailed methodology outlining the steps and techniques required to automatically match Original and Variation segments, along with a plan for implementing this approach.

## Limitations
- Manual curation bottleneck limits scalability to other jazz standards or instruments
- Dataset quality depends entirely on AMT accuracy, which is particularly challenging for jazz piano
- Unclear whether learned variation patterns will generalize beyond the three pianists represented

## Confidence
- High confidence in dataset construction methodology and statistical analysis
- Medium confidence in model effectiveness for generating variations
- Low confidence in practical applications for performer identification and expressive performance analysis

## Next Checks
1. **Transcription accuracy audit**: Evaluate AMT quality on the source jazz piano performances by comparing transcriptions to ground truth annotations for a subset of segments.

2. **Cross-pianist generalization test**: Train models on pairs from two pianists and evaluate performance on the third pianist's variations to assess generalization capabilities.

3. **Human preference study**: Conduct a listening test comparing model-generated variations to actual performer variations, asking listeners to identify which preserve melodic/harmonic structure better.