---
ver: rpa2
title: 'gRoMA: a Tool for Measuring the Global Robustness of Deep Neural Networks'
arxiv_id: '2301.02288'
source_url: https://arxiv.org/abs/2301.02288
tags:
- robustness
- groma
- neural
- global
- input
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces gRoMA, a scalable tool for measuring the
  global categorial robustness of deep neural networks (DNNs). The problem addressed
  is the lack of methods to assess the probability of encountering adversarial inputs
  across all inputs within a specific output category, which is critical for deploying
  DNNs in safety-critical systems.
---

# gRoMA: a Tool for Measuring the Global Robustness of Deep Neural Networks

## Quick Facts
- arXiv ID: 2301.02288
- Source URL: https://arxiv.org/abs/2301.02288
- Reference count: 31
- Primary result: gRoMA measures global robustness of DNNs with formal error bounds using Hoeffding's inequality

## Executive Summary
This paper introduces gRoMA, a scalable tool for measuring the global categorial robustness of deep neural networks (DNNs). The problem addressed is the lack of methods to assess the probability of encountering adversarial inputs across all inputs within a specific output category, which is critical for deploying DNNs in safety-critical systems. gRoMA uses a probabilistic approach by repeatedly applying the RoMA algorithm on randomly sampled inputs from a target category and aggregating the results to compute a global robustness score. The method operates on pre-trained, black-box DNNs without requiring internal assumptions. Evaluation on the DenseNet model over CIFAR10 showed significant variability in robustness across categories, with the airplane category achieving 99.91% robustness and an error probability below 0.2%. The tool is highly scalable, requiring under 21 minutes per category, and provides formal error bounds using Hoeffding's inequality, making it suitable for safety-critical system certification.

## Method Summary
gRoMA measures global categorial robustness by sampling inputs from target categories, applying RoMA for local robustness assessment, and aggregating results with Hoeffding's inequality bounds. The method treats DNNs as black-boxes, requiring only input-output queries. For each category, it draws n random samples, measures their local robustness using RoMA, computes the average as PGCR, and calculates error bounds. The approach scales to large models and provides formal guarantees on estimation accuracy.

## Key Results
- Achieved 99.91% robustness for the airplane category on DenseNet over CIFAR10
- Error probability below 0.2% for most robust categories
- Required under 21 minutes per category for evaluation
- Demonstrated significant variability in robustness across different categories

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Probabilistic sampling of category-representative inputs enables global robustness estimation without exhaustive input-space coverage.
- Mechanism: The tool repeatedly draws random samples from the target category, measures local adversarial robustness for each, and aggregates these scores to estimate the overall probability of encountering adversarial inputs in that category.
- Core assumption: The randomly drawn samples adequately represent the distribution of inputs in the category, so the aggregate statistic reflects true global robustness.
- Evidence anchors:
  - [abstract] "gRoMA uses a probabilistic approach by repeatedly applying the RoMA algorithm on randomly sampled inputs from a target category and aggregating the results to compute a global robustness score."
  - [section] "In line 1, gRoMA begins by creating a vector, ⃗X, of perturbed inputs — by drawing from I, at random, n samples of inputs labeled as l."
- Break condition: If the sampling distribution is heavily skewed or does not cover critical regions of the input space, the global estimate will be biased.

### Mechanism 2
- Claim: Using Hoeffding's inequality provides a formal probabilistic error bound on the estimated robustness score.
- Mechanism: The aggregation step applies Hoeffding's inequality to bound the deviation between the estimated PGCR and the true PGCR, given the sample size and observed variability.
- Core assumption: The local robustness scores are independent and bounded, satisfying Hoeffding's theorem prerequisites.
- Evidence anchors:
  - [abstract] "The tool is highly scalable, requiring under 21 minutes per category, and provides formal error bounds using Hoeffding's inequality."
  - [section] "For computing the PGCR score's probabilistic error bound, we used Hoeffding's Inequality [12]."
- Break condition: If local robustness scores are correlated or unbounded, Hoeffding's inequality no longer applies, invalidating the error bound.

### Mechanism 3
- Claim: Treating the DNN as a black-box enables scalability and avoids assumptions about internal structure.
- Mechanism: The method only queries the DNN for input-output pairs and does not require access to internal weights or activation functions, allowing it to work on pre-trained, arbitrary architectures.
- Core assumption: The black-box queries are sufficient to accurately measure local robustness without inspecting gradients or internal states.
- Evidence anchors:
  - [abstract] "Our tool operates on pre-trained, black-box classification DNNs, and generates input samples belonging to an output category of interest."
  - [section] "RoMA handles black-box DNNs, without any a priori assumptions."
- Break condition: If the black-box queries cannot sufficiently explore the neighborhood of inputs to detect adversarial examples, the local robustness estimate will be incomplete.

## Foundational Learning

- Concept: Probabilistic estimation and confidence intervals
  - Why needed here: Understanding how Hoeffding's inequality yields error bounds and why averaging local robustness scores approximates global robustness.
  - Quick check question: Given n samples with local robustness scores between 0 and 1, Hoeffding's inequality bounds the deviation of the average from the true mean. What happens to the bound as n increases?

- Concept: Adversarial examples and local robustness
  - Why needed here: Grasping what an adversarial input is, how ϵ-local-robustness is defined, and why robustness can vary across input regions.
  - Quick check question: If a DNN is ϵ-locally-robust at point ⃗x₀, what must be true about all inputs within the ∞-norm ball of radius ϵ around ⃗x₀?

- Concept: Random sampling and representativeness
  - Why needed here: Recognizing how drawing n samples from the category set I approximates the true input distribution and why sample size affects estimation accuracy.
  - Quick check question: If you sample 10 images from a category versus 1000, how does this affect the reliability of the PGCR estimate and its error bound?

## Architecture Onboarding

- Component map:
  Input interface -> Sampling engine -> Local robustness evaluator -> Aggregator -> Error analyzer -> Output interface

- Critical path:
  1. Load model and dataset.
  2. For each category, draw n samples.
  3. For each sample, run RoMA to get plr.
  4. Aggregate plr scores.
  5. Compute Hoeffding error bound.
  6. Output results.

- Design tradeoffs:
  - Sample size vs. runtime: Larger n improves accuracy and tightens error bounds but increases computation time.
  - Local robustness method choice: RoMA is black-box and scalable, but may be less precise than white-box formal verification.
  - Error bound choice: Hoeffding's inequality is simple and non-parametric, but assumes bounded, independent scores.

- Failure signatures:
  - If PGCR values are very low for all categories, suspect the adversarial perturbation budget (ϵ) is too large or the model is generally fragile.
  - If error bounds are extremely wide, suspect too few samples or high variability in local robustness scores.
  - If PGCR values are inconsistent across repeated runs, suspect sampling bias or insufficient sample size.

- First 3 experiments:
  1. Run gRoMA on DenseNet over CIFAR10 with n=10 per category; record PGCR and error; observe if results are stable.
  2. Increase n to 50 and compare PGCR and error bounds; check if error decreases as predicted by Hoeffding.
  3. Run gRoMA on a different pre-trained model (e.g., ResNet) on CIFAR10; compare robustness patterns across models.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the choice of sampling method for drawing input samples impact the accuracy of gRoMA's global robustness measurements?
- Basis in paper: [inferred] The paper mentions that gRoMA draws 100 arbitrary images for each CIFAR10 category to represent the input space. It also suggests future work to validate the accuracy using different input distributions and sampling methods.
- Why unresolved: The paper only evaluates gRoMA using a single sampling approach (100 arbitrary images per category) without exploring how different sampling strategies might affect the results.
- What evidence would resolve it: Comparative experiments showing gRoMA's results using different sampling methods (e.g., stratified sampling, importance sampling) and measuring the variance in PGCR scores across methods.

### Open Question 2
- Question: Can gRoMA be effectively extended to measure robustness for regression neural networks, or are there fundamental limitations to its approach?
- Basis in paper: [explicit] The paper mentions future plans to extend gRoMA to additional types of DNNs, including regression networks, suggesting this is an open question.
- Why unresolved: The current formulation of gRoMA is designed for classification networks with categorical outputs, and it's unclear how well the probabilistic framework would translate to continuous output spaces in regression.
- What evidence would resolve it: A working implementation of gRoMA for regression networks demonstrating comparable accuracy and scalability, or a theoretical analysis explaining why the approach may not extend well to regression tasks.

### Open Question 3
- Question: What is the relationship between local robustness (measured by RoMA) and global robustness (measured by gRoMA) in terms of correlation and predictive power?
- Basis in paper: [inferred] The paper uses RoMA as a subroutine within gRoMA but doesn't analyze how well local robustness scores predict global robustness or whether there's a strong correlation between them.
- Why unresolved: While both concepts are discussed, the paper doesn't provide empirical evidence about how local and global robustness measurements relate to each other across different networks and categories.
- What evidence would resolve it: Statistical analysis showing the correlation between RoMA scores at individual points and gRoMA scores for the same categories, including scatter plots and correlation coefficients across multiple networks.

## Limitations

- The tool's accuracy heavily depends on the representativeness of the sampled inputs, and if the sampling distribution is skewed or fails to cover critical regions of the input space, the global robustness estimate will be biased.
- The error bounds computed using Hoeffding's inequality assume independence and boundedness of local robustness scores, which may not hold if scores are correlated or unbounded, invalidating the theoretical guarantees.
- The method relies on the effectiveness of the RoMA algorithm for local robustness measurement, but the exact implementation details and configuration parameters are not specified, potentially leading to inconsistent results.

## Confidence

- High confidence in the core mechanism: Probabilistic sampling combined with local robustness aggregation is a well-established approach in statistical estimation, and the use of Hoeffding's inequality for error bounds is theoretically sound when assumptions are met.
- Medium confidence in scalability claims: While the tool is described as highly scalable, the actual runtime and resource requirements may vary depending on the specific DNN architecture, dataset size, and hardware configuration.
- Low confidence in absolute robustness values: Without access to the exact RoMA implementation and configuration parameters, the reported PGCR scores and error bounds may not be reproducible, and the actual robustness of the DenseNet model could differ from the reported values.

## Next Checks

1. Verify the independence and boundedness assumptions of Hoeffding's inequality by analyzing the correlation structure and range of local robustness scores across different sample sizes and input categories.
2. Implement a controlled experiment comparing gRoMA's PGCR estimates with ground truth robustness values obtained through exhaustive verification or alternative estimation methods on a small, tractable dataset.
3. Conduct a sensitivity analysis by varying the sample size n and observing the impact on PGCR estimates and error bounds, checking if the observed behavior aligns with the theoretical predictions of Hoeffding's inequality.