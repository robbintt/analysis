---
ver: rpa2
title: Leveraging Pre-trained Large Language Models to Construct and Utilize World
  Models for Model-based Task Planning
arxiv_id: '2305.14909'
source_url: https://arxiv.org/abs/2305.14909
tags:
- object
- action
- pddl
- robot
- furniture
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new paradigm for leveraging large language
  models (LLMs) in planning tasks by extracting an explicit world (domain) model in
  PDDL rather than using LLMs directly as planners. The approach uses GPT-4 to generate
  high-quality PDDL models for over 40 actions across two IPC domains and a household
  domain, then corrects any errors using natural language feedback from PDDL validators
  or humans.
---

# Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning

## Quick Facts
- arXiv ID: 2305.14909
- Source URL: https://arxiv.org/abs/2305.14909
- Reference count: 40
- Primary result: Introduces a new paradigm for using LLMs in planning by extracting PDDL models and using external planners

## Executive Summary
This paper presents a novel approach to leveraging large language models (LLMs) for planning tasks by extracting explicit world models in Planning Domain Definition Language (PDDL) rather than using LLMs directly as planners. The method uses GPT-4 to generate PDDL action models from natural language descriptions, then corrects errors using natural language feedback from PDDL validators or humans. The corrected PDDL models are then used with standard domain-independent planners to solve planning tasks. This approach achieves a 95% success rate on 48 challenging planning tasks across household and logistics domains.

## Method Summary
The method involves three main stages: PDDL construction, error correction, and planning. First, GPT-4 is prompted with domain information and action descriptions to generate PDDL models action by action. Second, the generated PDDL is validated using PDDL validators or human feedback, with errors identified through natural language translation of PDDL representations. Third, the corrected PDDL models are used as input to domain-independent planners like Fast Downward to generate valid plans. The approach leverages LLMs' natural language processing capabilities while relying on sound external planners for combinatorial search, addressing LLMs' limitations in plan correctness.

## Key Results
- 95% success rate on 48 challenging planning tasks across household and logistics domains
- GPT-4 outperforms GPT-3.5-Turbo in generating correct PDDL models, especially when provided with more detailed action descriptions
- Error correction through natural language feedback significantly improves PDDL model quality
- The framework successfully constructs PDDL models for over 40 actions across two IPC domains and a household domain

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can serve as a bridge between natural language action descriptions and formal PDDL representations.
- Mechanism: LLMs parse action descriptions, extract relevant parameters, and construct preconditions and effects using the PDDL syntax.
- Core assumption: LLMs have sufficient world knowledge to infer implicit constraints and dependencies from natural language.
- Evidence anchors:
  - [abstract] "we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners."
  - [section] "we utilize LLMs to extract a symbolic representation of the actions in the form of PDDL action models."
  - [corpus] "LLMs have shown remarkable performance in natural language processing tasks" (from corpus neighbor 1).
- Break condition: If the LLM lacks relevant world knowledge or the action description is too ambiguous, the generated PDDL may be incorrect or incomplete.

### Mechanism 2
- Claim: LLMs can translate PDDL models into natural language and vice versa, enabling users without PDDL expertise to correct errors.
- Mechanism: LLMs convert PDDL representations into natural language descriptions of predicates and parameters, which users can inspect and provide feedback on. The feedback is then encoded back into PDDL by the LLM.
- Core assumption: LLMs can effectively translate between PDDL and natural language without significant loss of information.
- Evidence anchors:
  - [abstract] "we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans."
  - [section] "The LLM middle layer translates PDDL representation to natural language and presents it to users for inspection."
  - [corpus] "ensuring that actions are consistent within domains still remains a challenging task" (from corpus neighbor 3, implying need for correction).
- Break condition: If the translation between PDDL and natural language introduces ambiguity or errors, the correction process may fail.

### Mechanism 3
- Claim: The extracted PDDL model can be used with sound external planners to guarantee plan correctness.
- Mechanism: The PDDL model is used as input to domain-independent planners like Fast Downward, which perform combinatorial search to find valid plans.
- Core assumption: The PDDL model accurately represents the domain constraints and dependencies.
- Evidence anchors:
  - [abstract] "Our framework not only enjoys the correctness guarantee offered by the external planners"
  - [section] "once a PDDL model is constructed, it can be seamlessly used by any domain-independent planner"
  - [corpus] "planning problems into the Planning Domain Definition Language (PDDL) has been proposed" (from corpus neighbor 1).
- Break condition: If the PDDL model contains errors or inconsistencies, the external planner may fail to find a valid plan or generate incorrect plans.

## Foundational Learning

- Concept: Planning Domain Definition Language (PDDL)
  - Why needed here: PDDL is the formal language used to represent the world model and planning problems.
  - Quick check question: What are the main components of a PDDL domain definition?
- Concept: Classical planning problems
  - Why needed here: Understanding the formal representation of planning problems is crucial for constructing PDDL models.
  - Quick check question: What is the difference between a lifted action model and a grounded action model in classical planning?
- Concept: LLM prompting and in-context learning
  - Why needed here: Effective prompting is essential for extracting accurate PDDL models from LLMs.
  - Quick check question: How can you structure a prompt to elicit a specific output format from an LLM?

## Architecture Onboarding

- Component map:
  - User interface for task specification -> LLM-based PDDL constructor -> PDDL validator/human feedback interface -> Domain-independent planner -> Plan output
- Critical path:
  1. User provides action descriptions and domain context
  2. LLM constructs initial PDDL models
  3. PDDL validator or human feedback identifies errors
  4. LLM incorporates feedback and corrects PDDL models
  5. Corrected PDDL models are used with external planner to generate plans
- Design tradeoffs:
  - Action-by-action vs. batch PDDL construction: Action-by-action allows for incremental feedback but may be slower.
  - Level of detail in action descriptions: More detailed descriptions can lead to more accurate PDDL but require more user effort.
- Failure signatures:
  - Incorrect or incomplete PDDL models generated by LLM
  - Failure of external planner to find a valid plan
  - User feedback not effectively incorporated by LLM
- First 3 experiments:
  1. Construct PDDL models for a simple domain (e.g., Blocksworld) using detailed action descriptions and evaluate correctness.
  2. Test the feedback incorporation mechanism by introducing errors in the initial PDDL and providing corrective feedback.
  3. Use the corrected PDDL models to solve planning problems in a more complex domain (e.g., Household) and measure success rate.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How well can LLMs scale to construct PDDL models for domains with more intricate logic and larger action sets?
- Basis in paper: [inferred] The paper evaluates GPT-4 on two IPC domains (Tyreworld with 13 actions and Logistics with 6 actions) and a Household domain with 22 actions, but does not test domains with hundreds of actions or more complex logical structures.
- Why unresolved: The experiments are limited to domains with relatively small action sets and simpler logical dependencies. It remains unclear whether the observed performance would generalize to domains with hundreds of actions, complex conditional effects, or intricate logical relationships between actions.
- What evidence would resolve it: Testing GPT-4 (or other LLMs) on benchmark domains from the International Planning Competition with hundreds of actions and complex logical structures, and measuring the quality of the generated PDDL models in terms of correctness and completeness.

### Open Question 2
- Question: How can the framework be extended to support partial observability in the environment?
- Basis in paper: [explicit] The paper states "our framework assumes full observability, meaning that the agent must fully explore the environment to acquire object states at the beginning. It would be useful to support partial observability."
- Why unresolved: The current approach requires complete knowledge of the initial state, which may not be realistic in many real-world scenarios where the agent has limited perception capabilities or the environment is partially observable.
- What evidence would resolve it: Developing techniques to incorporate probabilistic reasoning or belief state representations into the PDDL models, and evaluating the framework's performance in partially observable domains such as those used in robotics planning competitions.

### Open Question 3
- Question: How can the framework handle noisy perception when grounding predicate values from observations?
- Basis in paper: [explicit] The paper assumes "the grounding of predicate values is done perfectly" and notes "it would be useful to take into account that perception can be noisy in practice."
- Why unresolved: In real-world applications, observations from sensors or vision-language models may be uncertain or erroneous, leading to incorrect grounding of predicate values and potentially invalid plans.
- What evidence would resolve it: Integrating techniques for handling uncertainty in perception, such as probabilistic grounding methods or active perception strategies, and evaluating the framework's robustness to perceptual noise in simulated or real-world environments.

## Limitations

- The approach assumes full observability of the environment, requiring complete knowledge of initial states
- Performance may not scale well to domains with hundreds of actions or highly complex logical structures
- The method relies on accurate natural language descriptions and may struggle with ambiguous or incomplete action specifications

## Confidence

- Claim: LLMs can effectively construct PDDL models from natural language descriptions
  - Confidence: Medium
- Claim: Natural language feedback can successfully correct PDDL model errors
  - Confidence: Medium
- Claim: The approach generalizes well to domains with complex logical structures
  - Confidence: Low

## Next Checks

1. Test the approach on a wider range of domains, including those with higher complexity and branching factors, to assess scalability and generalization.
2. Conduct a user study to evaluate the effectiveness of the error correction process and gather feedback on the usability of the system.
3. Compare the performance and efficiency of the proposed approach with other LLM-based planning methods, such as LLM planners, to better understand its strengths and weaknesses.