---
ver: rpa2
title: 'Multi-annotator Deep Learning: A Probabilistic Framework for Classification'
arxiv_id: '2304.02539'
source_url: https://arxiv.org/abs/2304.02539
tags:
- annotator
- madl
- annotators
- learning
- class
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors address the problem of learning deep neural networks
  from noisy multi-annotator labels, where annotators may have varying expertise,
  biases, or correlations. They propose a probabilistic framework called multi-annotator
  deep learning (MaDL) that jointly learns a ground truth model and an annotator performance
  model.
---

# Multi-annotator Deep Learning: A Probabilistic Framework for Classification

## Quick Facts
- arXiv ID: 2304.02539
- Source URL: https://arxiv.org/abs/2304.02539
- Reference count: 14
- Key outcome: Proposes MaDL framework achieving state-of-the-art performance on multi-annotator classification tasks with robust handling of correlated annotators

## Executive Summary
This paper addresses the challenge of learning from noisy multi-annotator labels where annotators may have varying expertise, biases, or correlations. The authors propose Multi-Annotator Deep Learning (MaDL), a probabilistic framework that jointly learns a ground truth model and an annotator performance model. MaDL uses annotator embeddings to detect correlations and employs a weighted loss function to mitigate bias from correlated annotation patterns. The framework demonstrates superior performance compared to existing techniques across multiple datasets.

## Method Summary
MaDL is an end-to-end framework that jointly trains a ground truth (GT) model and an annotator performance (AP) model. The GT model predicts true class labels using a deep neural network, while the AP model estimates annotator confusion matrices and learns annotator embeddings to capture correlation patterns. The framework employs a weighted maximum-likelihood approach where annotator weights are inversely proportional to their density in the embedding space, reducing the influence of correlated annotator groups. The AP model can capture class-dependent and optionally instance-dependent performance, with three sub-networks handling annotator embeddings, instance embeddings, and their interaction.

## Key Results
- MaDL achieves state-of-the-art performance on multiple datasets including labelme, music, letter, fmnist, cifar10, and svhn
- The framework demonstrates robustness against many correlated spamming annotators
- MaDL outperforms existing techniques including CL, REAC, UNION, LIA, and CoNAL across various evaluation metrics (ACC, NLL, BS, BAL-ACC)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weighted loss function with annotator weights inversely proportional to annotator density mitigates bias from correlated annotators
- Mechanism: By assigning lower weights to annotators in dense clusters (highly correlated groups), the loss function treats each annotator group as equally important regardless of its size, preventing large groups of correlated annotators from dominating the learning signal
- Core assumption: Annotators with similar embeddings share correlated annotation patterns
- Evidence anchors: [section] "We aim to extend our loss function so that its evaluation is independent of the annotator groups' cardinalities... each groupAg, independent of its cardinality|Ag|, equally contributes to the weighted log-likelihood function" [abstract] "Together with a weighted loss function, we improve the learning from correlated annotation patterns"

### Mechanism 2
- Claim: Learning annotator embeddings in latent space enables detection and quantification of annotator correlations
- Mechanism: The framework learns low-dimensional representations (embeddings) for each annotator, where distance in embedding space corresponds to similarity in annotation behavior, allowing the model to identify groups of annotators with correlated patterns
- Core assumption: Annotators with similar embedding vectors exhibit correlated annotation behaviors
- Evidence anchors: [section] "We learn embeddings of annotators to account for possible correlations among them" and "we assume that annotators with similar embeddings share correlated annotation patterns" [abstract] "We learn annotator embeddings to estimate annotators' densities within a latent space as proxies of their potentially correlated annotations"

### Mechanism 3
- Claim: Modular architecture allowing class- and instance-dependent performance modeling improves GT estimation
- Mechanism: By estimating confusion matrices that vary by both annotator and class (and optionally instance), the model can capture nuanced differences in annotator expertise across different types of instances, leading to more accurate GT estimates
- Core assumption: Annotator performance varies systematically across classes and instances
- Evidence anchors: [section] "Class-dependent annotator performance... AP models estimating such accuracy values have low complexity... many other AP models assume a dependency between APs and instances' GT labels" [abstract] "The ground truth model learns to predict instances' true class labels, while the annotator performance model infers probabilistic estimates of annotators' performances"

## Foundational Learning

- Concept: Maximum likelihood estimation with latent variables
  - Why needed here: The framework needs to estimate both GT labels and annotator performance parameters from noisy observations, where GT labels are latent variables
  - Quick check question: What optimization method is typically used when dealing with latent variables in probabilistic models?

- Concept: Confusion matrix parameterization
  - Why needed here: The AP model estimates confusion matrices to represent annotator performance, requiring understanding of how to parameterize and constrain these matrices
  - Quick check question: How many parameters are needed to fully specify a C×C confusion matrix?

- Concept: Kernel density estimation
  - Why needed here: Used to estimate annotator probability densities from embeddings for computing annotator weights
  - Quick check question: What kernel function is used in the framework to compute similarities between annotator embeddings?

## Architecture Onboarding

- Component map: Input → GT model (DNN for class probabilities) → AP model (annotator embedding, instance embedding, interaction) → weighted loss combining both outputs → parameter updates for both models simultaneously
- Critical path: Input → GT model → AP model → weighted loss → parameter updates for both models simultaneously
- Design tradeoffs: More complex AP model (instance+class-dependent) vs. simpler models; learnable kernel bandwidth vs. fixed; residual connections vs. plain concatenation
- Failure signatures: Overconfident predictions in regions without observed instances; AP estimates that don't vary across classes/instances when they should; poor performance with correlated annotators
- First 3 experiments:
  1. Test MaDL(X,I) vs MaDL(X,F) on a simple synthetic dataset to verify class-dependent modeling helps
  2. Evaluate impact of annotator weights by comparing MaDL(W) vs MaDL(W) on correlated annotator set
  3. Test embedding size sensitivity by varying Q=R parameter on a mid-sized dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the optimal embedding size vary with the number of annotators and instance features?
- Basis in paper: [inferred] The ablation study showed Q = R = 16 works best for datasets with real-world annotators, but Q = R = 8 was superior for the letter dataset with simulated annotators
- Why unresolved: The paper only tested two embedding sizes (8 and 16) and did not explore the relationship with the number of annotators or feature dimensionality
- What evidence would resolve it: Systematic experiments varying embedding size, number of annotators, and feature dimensionality to identify optimal configurations

### Open Question 2
- Question: What are the theoretical guarantees for specific ground truth and annotator performance distribution types?
- Basis in paper: [inferred] The authors note that elaborating on the theoretical foundations of multi-annotator supervised learning techniques is essential for future work
- Why unresolved: The paper focuses on empirical evaluations and does not provide theoretical analysis of MaDL's performance guarantees
- What evidence would resolve it: Mathematical proofs or bounds on MaDL's performance under various assumptions about the ground truth and annotator performance distributions

### Open Question 3
- Question: How does modeling instance-dependent annotator performance impact learning when annotators provide few annotations per instance?
- Basis in paper: [explicit] The paper mentions that MaDL optionally allows dropping the instance dependency, which can benefit tasks where each annotator provides only a few annotations
- Why unresolved: The experiments did not explicitly test the impact of instance-dependent performance modeling in low-annotation scenarios
- What evidence would resolve it: Comparative experiments showing the performance difference between instance-dependent and instance-independent models when annotators provide few annotations per instance

### Open Question 4
- Question: How does the choice of kernel function affect the estimation of annotator correlations?
- Basis in paper: [explicit] The authors mention that alternatives to the radial basis function, such as the cosine similarity function, could be tested for estimating annotator correlations
- Why unresolved: The paper only uses the radial basis function and does not explore the impact of different kernel functions on performance
- What evidence would resolve it: Experiments comparing the performance of MaDL using different kernel functions for estimating annotator correlations

## Limitations

- The framework's performance heavily depends on the quality of annotator embedding space, which may not capture all relevant correlation patterns in practice
- The computational complexity scales linearly with the number of annotators, which could be prohibitive for datasets with very large annotator pools
- The effectiveness of the weighted loss function relies on accurate density estimation, which may be challenging with limited annotator data or in high-dimensional embedding spaces

## Confidence

**High Confidence**: The modular architecture design with separate GT and AP models is well-founded, as evidenced by the extensive literature on confusion matrix-based multi-annotator learning. The general approach of using embeddings to capture annotator similarity is also well-supported.

**Medium Confidence**: The specific weighted loss function that inversely weights by annotator density is novel and theoretically sound, but the empirical evidence for its effectiveness is primarily from the authors' experiments. The claim about robustness against correlated spamming annotators needs further validation on more diverse datasets.

**Low Confidence**: The assumption that learned embeddings will always capture the relevant aspects of annotator behavior is optimistic. The framework's performance on extremely sparse annotation scenarios (where few annotators label each instance) is not well-established.

## Next Checks

1. **Correlation Pattern Sensitivity Test**: Systematically vary the degree and structure of annotator correlation (linear, hierarchical, random) and measure MaDL's performance degradation relative to baselines to quantify robustness claims.

2. **Embedding Space Validation**: For a controlled synthetic dataset with known annotator correlation patterns, verify that the learned embeddings actually reflect these patterns by computing correlation between embedding distances and actual annotation agreement.

3. **Scalability Benchmark**: Measure MaDL's computational time and memory requirements as a function of annotator count on a fixed dataset, comparing against theoretical O(A) scaling to identify practical limits for deployment.