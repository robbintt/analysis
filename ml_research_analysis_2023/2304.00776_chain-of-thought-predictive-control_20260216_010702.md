---
ver: rpa2
title: Chain-of-Thought Predictive Control
arxiv_id: '2304.00776'
source_url: https://arxiv.org/abs/2304.00776
tags:
- learning
- state
- states
- arxiv
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Chain-of-Thought Predictive Control (CoTPC) addresses the challenge
  of learning generalizable policies from large-scale yet highly suboptimal demonstrations
  in low-level control tasks like contact-rich object manipulation. The method identifies
  hierarchical task structures by extracting key states from demonstrations that mark
  completion of subgoals, forming a chain-of-thought (CoT).
---

# Chain-of-Thought Predictive Control

## Quick Facts
- arXiv ID: 2304.00776
- Source URL: https://arxiv.org/abs/2304.00776
- Authors: 
- Reference count: 25
- Primary result: Achieves 60.8% success rate on seen seeds and 38.0% on unseen geometries for peg insertion in ManiSkill2

## Executive Summary
Chain-of-Thought Predictive Control (CoTPC) is a novel imitation learning method that addresses the challenge of learning generalizable policies from highly suboptimal demonstrations in low-level contact-rich object manipulation tasks. The method extracts hierarchical task structures by identifying key states that mark completion of subgoals, forming a chain-of-thought (CoT). CoTPC uses a Transformer-based architecture to dynamically predict both actions and key states at each inference step, leveraging learnable prompt tokens and hybrid masking for improved feature representation. This approach enables coherent long-term planning and improves robustness to noise and discontinuities in demonstrations.

The method significantly outperforms strong baselines on challenging tasks from the ManiSkill2 benchmark, demonstrating both optimization and generalization advantages. CoTPC achieves success rates up to 60.8% on seen seeds and 38.0% on unseen geometries for peg insertion, validating its effectiveness in learning from suboptimal demonstrations while maintaining strong generalization capabilities.

## Method Summary
CoTPC addresses the challenge of learning generalizable policies from large-scale yet highly suboptimal demonstrations in low-level control tasks like contact-rich object manipulation. The method identifies hierarchical task structures by extracting key states from demonstrations that mark completion of subgoals, forming a chain-of-thought (CoT). CoTPC uses a Transformer-based architecture to jointly predict actions and key states dynamically at each inference step, leveraging learnable prompt tokens and hybrid masking for better feature representation. This approach enables coherent long-term planning and improves robustness to noise and discontinuities in demonstrations.

The model encodes state and action tokens using separate encoders, applies hybridly masked multi-head attention, and uses coupled action and key state decoders. The key state decoder is a non-linear MLP that predicts key states in the latent space, encouraging better representation than manual state observations. CoTPC is trained using behavior cloning loss plus an auxiliary MSE loss for key state prediction, allowing it to learn joint predictions of key states and actions conditioned on trajectory history.

## Key Results
- Achieves 60.8% success rate on seen seeds for peg insertion in ManiSkill2
- Achieves 38.0% success rate on unseen geometries for peg insertion
- Significantly outperforms strong baselines on challenging contact-rich manipulation tasks

## Why This Works (Mechanism)

### Mechanism 1
CoTPC improves optimization by learning joint predictions of key states and actions conditioned on trajectory history. The Transformer architecture predicts key states (CoT) and actions together, with key state tokens having all-to-all attention while action tokens have causal attention. This allows the model to use long-term hierarchical guidance from predicted key states when generating actions at each step. The key assumption is that key states admit fewer variations than other states and share generalizable patterns across demos, even those with heavy noise and randomness.

### Mechanism 2
Dynamic CoT prediction enables closed-loop control and better handles uncertainty compared to static prediction. At each inference step, CoTPC updates its predictions of the entire CoT and current action based on the current trajectory context. This is analogous to closed-loop control where the system continuously adjusts its plan. The key assumption is that the environment or task requires dynamic adjustment of subgoal-level plans, such as in dynamic environments or tasks requiring dynamic control.

### Mechanism 3
Predicting CoT in the latent space leads to better feature representation than predicting in the observation space. The key state decoder is a non-linear MLP that predicts key states in the latent space, which encourages better representation of the predicted CoT than the manually designed state observation. The key assumption is that the latent space representation learned through the BC loss and auxiliary key state prediction loss provides a better representation of the predicted CoT than the raw state observations.

## Foundational Learning

- Concept: Hierarchical reinforcement learning (HRL) and temporal abstraction
  - Why needed here: CoTPC leverages hierarchical structures in low-level control tasks by extracting key states that mark completion of subgoals, similar to how HRL decomposes complex tasks into simpler sub-problems via temporal abstractions.
  - Quick check question: Can you explain how HRL uses temporal abstractions to tackle complex sequential decision-making problems, and how CoTPC applies this idea to imitation learning from sub-optimal demonstrations?

- Concept: Behavior cloning (BC) and distribution shift
  - Why needed here: CoTPC is a BC method that learns policies from pre-collected demonstrations without rewards or online interactions. It addresses the distribution shift challenge by using a non-Markovian policy that considers history and by leveraging hierarchical guidance from key states.
  - Quick check question: What is the distribution shift problem in BC, and how does CoTPC's use of a non-Markovian policy and key state guidance help mitigate this issue?

- Concept: Sequence modeling and Transformer architectures
  - Why needed here: CoTPC uses a customized Transformer to learn joint predictions of key states and actions conditioned on trajectory history. The Transformer's ability to model long-range dependencies and its attention mechanism are crucial for predicting the entire CoT and generating coherent long-term action guidance.
  - Quick check question: How does the Transformer architecture in CoTPC enable joint prediction of key states and actions, and what role does the hybrid masking strategy play in this process?

## Architecture Onboarding

- Component map: State token encoder -> Action token encoder -> Hybridly masked multi-head attention -> Action decoder -> Key state decoder

- Critical path:
  1. Encode state and action tokens using fa and fs
  2. Apply hybridly masked multi-head attention to features
  3. Pass through additional attention layers (if any)
  4. Use action decoder (ga) to predict current action
  5. Use key state decoder (gcot) to predict current key states

- Design tradeoffs:
  - Number of key states (K) vs. model complexity and prediction accuracy
  - Context size (T) vs. computational efficiency and ability to capture long-range dependencies
  - Latent space prediction vs. observation space prediction for key states
  - Dynamic vs. static CoT prediction based on task requirements

- Failure signatures:
  - Poor performance on seen seeds: Model may not be learning the hierarchical patterns or may be overfitting to the demonstrations
  - Poor generalization to unseen seeds: Model may not be capturing the generalizable decision patterns or may be relying too heavily on specific demonstration details
  - Instability during training: Learning rate, batch size, or architectural choices may need tuning

- First 3 experiments:
  1. Verify that the Transformer backbone can learn to predict actions from the demonstration data without key state guidance (baseline comparison)
  2. Test the impact of the number of key states (K) on model performance and generalization
  3. Compare the performance of latent space key state prediction vs. observation space prediction on a held-out validation set

## Open Questions the Paper Calls Out

### Open Question 1
How can key state selection be automated for tasks beyond contact-rich manipulation? The paper notes that key states can be "potentially automated with pre-trained vision-language models (zero-shot image retrieval)" but only demonstrates manual heuristics for manipulation tasks. This remains unresolved as the paper only validates key state extraction for a limited set of manipulation tasks using simple heuristic rules, not addressing how to automatically identify key states for other task types.

### Open Question 2
What is the optimal number of key states to predict for different task complexities? The paper mentions that K (number of key states) is "task-specific" but only uses 2-3 key states across different tasks without exploring the impact of varying this parameter. This remains unresolved as the paper fixes the number of key states based on task structure but doesn't systematically study how performance changes with different numbers of predicted key states.

### Open Question 3
How does CoTPC's performance scale with demonstration quality beyond the "sub-optimal" regime studied? The paper focuses on highly sub-optimal demonstrations but mentions future work on "diverse demos across different low-level control tasks" without testing performance on varying demonstration qualities. This remains unresolved as the evaluation only uses one quality level of demonstrations, leaving questions about performance with near-optimal, mixed-quality, or expert demonstrations.

## Limitations

- The key state extraction method relies on heuristic rules that may not generalize to more complex tasks with less obvious subgoal structures
- The approach assumes that key states can be reliably identified and share generalizable patterns across noisy demonstrations, which may not hold for all task types
- Performance evaluation is limited to the ManiSkill2 benchmark, raising questions about generalizability to other domains

## Confidence

- High confidence in the core finding that CoTPC achieves state-of-the-art performance on ManiSkill2 tasks, as this is directly measurable and supported by comprehensive experimental results
- Medium confidence in the mechanism claims about joint prediction and hierarchical guidance, as the paper relies heavily on qualitative explanations rather than rigorous ablation studies
- Low confidence in the generalizability claims beyond the ManiSkill2 benchmark, as the paper demonstrates strong performance on four specific manipulation tasks but doesn't establish whether the approach transfers to other domains

## Next Checks

1. **Ablation study on key state prediction frequency**: Implement and compare static vs. dynamic CoT prediction with varying update frequencies (e.g., every N steps vs. every step) to quantify the performance trade-off and identify the minimum frequency needed for robust performance.

2. **Cross-domain transferability test**: Apply the CoTPC framework to a non-ManiSkill2 domain (e.g., robotic assembly tasks or navigation problems) using the same key state extraction heuristics to evaluate whether the approach generalizes beyond the original benchmark.

3. **Latent space interpretability analysis**: Visualize and analyze the latent space representations learned by the key state decoder to verify that predicted key states actually capture meaningful task-relevant features, not just arbitrary patterns that correlate with success.