---
ver: rpa2
title: Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language
  Understanding
arxiv_id: '2305.13512'
source_url: https://arxiv.org/abs/2305.13512
tags:
- language
- chatgpt
- examples
- spoken
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether large language models (LLMs) like
  ChatGPT can effectively perform spoken language understanding (SLU) tasks, specifically
  intent classification and slot filling. The authors evaluate several LLMs of varying
  sizes (including ChatGPT, GPT-3.5, GPT2, and OPT) on SLU benchmarks using zero-shot
  and few-shot in-context learning with prompts.
---

# Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding

## Quick Facts
- arXiv ID: 2305.13512
- Source URL: https://arxiv.org/abs/2305.13512
- Reference count: 0
- Key outcome: Large language models like ChatGPT can perform intent classification with high accuracy but struggle with slot filling and ASR robustness in spoken language understanding tasks.

## Executive Summary
This paper investigates whether large language models (LLMs) like ChatGPT can effectively perform spoken language understanding (SLU) tasks, specifically intent classification and slot filling. The authors evaluate several LLMs of varying sizes on SLU benchmarks using zero-shot and few-shot in-context learning with prompts. For intent classification on the SLURP dataset, ChatGPT achieves 79.25% accuracy with zero-shot prompting, close to supervised models, while smaller models perform poorly. On the multilingual MINDS-14 dataset, ChatGPT generalizes well across languages with zero or few shots. However, performance drops significantly for slot filling (F1 score ~13%) and when using ASR transcripts instead of oracle transcripts, indicating sensitivity to ASR errors and limitations in handling the slot filling task.

## Method Summary
The study evaluates large language models (ChatGPT, GPT-3.5, GPT2, and OPT) on SLU benchmarks using zero-shot and few-shot in-context learning with prompts. For intent classification and slot filling tasks, the authors use the SLURP dataset (141k samples, 60 intents, 56 slots) and MINDS-14 multilingual dataset (14 intents, 14 languages). They compare performance using oracle transcripts versus ASR transcripts from Whisper. Prompts include task descriptions, examples, and instructions. The models' predictions are evaluated against ground truth labels for accuracy (intent classification) and F1 score (slot filling).

## Key Results
- ChatGPT achieves 79.25% intent classification accuracy with zero-shot prompting on SLURP, close to supervised models
- ChatGPT generalizes well to multilingual intent classification across 14 languages with zero or few shots
- Slot filling performance is poor (F1 score ~13%) and significantly degrades with ASR transcripts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ChatGPT achieves high intent classification accuracy through emergent abilities unique to large models.
- Mechanism: Large-scale pretraining on diverse textual data enables zero-shot or few-shot in-context learning for intent classification when given oracle transcripts.
- Core assumption: Sufficient model scale and pretraining data allow the model to comprehend task descriptions and align with desired outputs without parameter updates.
- Evidence anchors:
  - [abstract] "the emergent ability unique to the largest models as they can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts."
  - [section 3.1] "ChatGPT achieves an accuracy of 79.25% with zero shot, and 83.93% with only 20 examples... on par with, or not far from, many supervised NLU models trained on the full oracle transcripts dataset."
  - [corpus] Weak - no direct evidence in neighbor papers, but related to general emergent abilities of large language models.
- Break condition: Model scale falls below the threshold where emergent abilities manifest (evidenced by GPT2 and OPT models performing poorly).

### Mechanism 2
- Claim: ChatGPT generalizes well to multilingual intent classification due to inherent multilinguality.
- Mechanism: The model's pretraining on diverse language data enables it to transfer language understanding capabilities to low-resource languages with minimal examples.
- Core assumption: The model has been exposed to sufficient multilingual data during pretraining to develop language-agnostic semantic understanding.
- Evidence anchors:
  - [section 3.1] "ChatGPT generalizes to all of these languages with similar or better performance compared to the supervised LaBSE... The model can almost perfectly solve the task on English and the rather low-resource French with zero shot, as well as Polish using only 14 examples or 1 shot per category to align with the task."
  - [abstract] "They can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts."
  - [corpus] Weak - no direct evidence in neighbor papers about multilingual generalization, though related to multilingual SLU benchmarks.
- Break condition: Language is too distant from training data or task requires deep cultural/language-specific knowledge.

### Mechanism 3
- Claim: ChatGPT's performance degrades significantly on slot filling due to task complexity and annotation scheme ambiguity.
- Mechanism: The slot filling task requires fine-grained entity extraction with overlapping label meanings, which is difficult to capture through prompting without comprehensive training data.
- Core assumption: The model can understand the task conceptually but struggles with the specific labeling scheme and fine distinctions between entity types.
- Evidence anchors:
  - [abstract] "We show, however, that the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU."
  - [section 3.1] "the situation is different. As in Table 4, the F1 score is poor and much lower than the models like HerMiT with 78.19% F1."
  - [section 4] "the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU."
- Break condition: Task requires very fine-grained distinctions or has a complicated annotation scheme that cannot be fully conveyed through a few examples.

## Foundational Learning

- Concept: Zero-shot and few-shot learning through prompting
  - Why needed here: Understanding how LLMs can perform tasks without traditional fine-tuning is central to the paper's evaluation of ChatGPT on SLU.
  - Quick check question: How does in-context learning differ from traditional zero-shot learning in terms of model parameter updates?

- Concept: Emergent abilities in large language models
  - Why needed here: The paper attributes ChatGPT's success to emergent abilities that appear only at sufficient scale, which is key to understanding why it outperforms smaller models.
  - Quick check question: What evidence does the paper provide that emergent abilities are unique to the largest models and not just better performance?

- Concept: ASR error impact on textual models
  - Why needed here: The paper demonstrates significant performance degradation when using ASR transcripts instead of oracle transcripts, highlighting a key limitation.
  - Quick check question: Why does the model's performance drop significantly when using ASR transcripts, and what does this reveal about its limitations?

## Architecture Onboarding

- Component map: Input prompt -> LLM processing -> Predicted intents/slots -> Evaluation against ground truth
- Critical path: 1. Design task-specific prompt with clear instructions and examples; 2. Input prompt and questions to the LLM; 3. Parse model's response to extract predictions; 4. Compare predictions to ground truth labels; 5. Analyze results and error cases
- Design tradeoffs: Prompt length vs. model performance (longer prompts may improve performance but hit token limits); Zero-shot vs. few-shot (zero-shot is more practical but few-shot can improve performance); Task simplicity vs. model capability (simpler tasks work better)
- Failure signatures: Poor performance on smaller models (below emergent ability threshold); Significant degradation with ASR transcripts due to limited phonetic awareness; Struggles with slot filling and tasks requiring fine-grained distinctions; Errors often reasonable interpretations but differ from dataset labels due to annotation scheme ambiguity
- First 3 experiments: 1. Evaluate intent classification on SLURP with zero-shot prompting using oracle transcripts; 2. Compare performance across different model sizes (ChatGPT vs. GPT2/OPT) on same task; 3. Test multilingual generalization by evaluating on MINDS-14 across different languages with zero/few shots

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can large language models be better adapted for slot filling tasks in spoken language understanding?
- Basis in paper: [explicit] The paper explicitly states that ChatGPT's performance on slot filling is much worse than intent classification, with F1 scores around 13% compared to 79% for intent classification.
- Why unresolved: The paper suggests that slot filling is more challenging due to its complex task definition and the ambiguity of entity types, but does not provide concrete solutions for improving performance.
- What evidence would resolve it: Experiments demonstrating improved slot filling performance through novel prompting strategies, fine-tuning approaches, or architectural modifications to LLMs would help resolve this question.

### Open Question 2
- Question: Can the robustness of large language models to ASR errors be significantly improved without extensive fine-tuning?
- Basis in paper: [explicit] The paper shows that LLM performance drops significantly when using ASR transcripts instead of oracle transcripts, and attempts to mitigate this through prompting are only partially successful.
- Why unresolved: The paper demonstrates the sensitivity to ASR errors but does not explore all possible solutions beyond simple prompting strategies, leaving open the question of whether more sophisticated approaches could yield better results.
- What evidence would resolve it: Comparative studies of various approaches (e.g., phonetic-aware prompting, error correction models, multi-modal integration) showing substantial improvements in ASR robustness without extensive fine-tuning would provide answers.

### Open Question 3
- Question: How does the effectiveness of in-context learning scale with model size and task complexity in spoken language understanding?
- Basis in paper: [explicit] The paper demonstrates that larger models like ChatGPT perform significantly better than smaller models (GPT2, OPT) in zero-shot and few-shot scenarios for intent classification, suggesting emergent abilities.
- Why unresolved: While the paper shows the superiority of larger models, it does not comprehensively explore the relationship between model size, task complexity, and the effectiveness of in-context learning across different SLU tasks.
- What evidence would resolve it: Systematic experiments varying model sizes and task complexities across a range of SLU tasks, measuring performance and identifying thresholds where emergent abilities appear, would help understand this scaling relationship.

## Limitations
- Significant performance degradation when using ASR transcripts instead of oracle transcripts
- Poor performance on slot filling tasks (F1 score ~13% vs. 78% for specialized models)
- Potential dataset-specific annotation scheme ambiguities affecting error analysis generalizability

## Confidence
- Intent classification results: High confidence, particularly for zero-shot and few-shot performance on oracle transcripts
- Multilingual generalization: High confidence, with consistent performance across 14 languages
- ASR transcript results: Medium confidence due to significant performance degradation suggesting sensitivity to transcription quality
- Error analysis generalizability: Low confidence, as annotation scheme ambiguities may be specific to SLURP dataset

## Next Checks
1. Test the same prompt-based approach on a different SLU benchmark with a more standardized annotation scheme to determine if slot filling performance remains poor or if the issue is dataset-specific.

2. Evaluate the impact of ASR quality on performance by testing with multiple ASR systems of varying accuracy levels to establish the relationship between transcription error rates and model performance.

3. Compare the performance of ChatGPT on intent classification with other large language models (Claude, LLaMA, etc.) to determine if the observed emergent abilities are unique to OpenAI's models or represent a broader trend in the field.