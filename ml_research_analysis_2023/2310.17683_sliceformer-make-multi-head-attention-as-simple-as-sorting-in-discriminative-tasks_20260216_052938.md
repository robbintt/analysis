---
ver: rpa2
title: 'Sliceformer: Make Multi-head Attention as Simple as Sorting in Discriminative
  Tasks'
arxiv_id: '2310.17683'
source_url: https://arxiv.org/abs/2310.17683
tags:
- attention
- sliceformer
- transformer
- operation
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Sliceformer, a novel model that replaces the
  traditional multi-head attention (MHA) mechanism with a simple "slicing-sorting"
  operation. The proposed method projects inputs linearly to a latent space and sorts
  them along different feature dimensions, generating implicit attention maps with
  sparse, full-rank, and doubly-stochastic structures.
---

# Sliceformer: Make Multi-head Attention as Simple as Sorting in Discriminative Tasks

## Quick Facts
- arXiv ID: 2310.17683
- Source URL: https://arxiv.org/abs/2310.17683
- Reference count: 40
- Key outcome: Replaces MHA with sorting-based attention for improved efficiency and comparable performance

## Executive Summary
Sliceformer introduces a novel approach to replace traditional multi-head attention with a simple "slicing-sorting" operation for discriminative tasks. By projecting inputs to a latent space and sorting along feature dimensions, the model generates implicit attention maps with desirable structural properties. Experiments demonstrate competitive performance across various tasks including long-range sequence classification, image classification, and molecular property prediction, while offering significant computational advantages over standard Transformer architectures.

## Method Summary
Sliceformer replaces the traditional QKV-based attention mechanism with a linear projection followed by column-wise sorting. The input is first projected to a latent space, then each column is sorted independently to generate implicit attention maps. The method employs interleaving ascending and descending sorting patterns across layers to increase diversity. This approach eliminates the need for query-key computation and softmax operations, resulting in lower computational complexity (O(DN log N) vs O(DN²)) and reduced memory requirements (O(log N) vs O(N²)).

## Key Results
- Achieves comparable or better performance than Transformer and variants on discriminative tasks
- Demonstrates 1.0x-3.3x faster training and 1.0x-2.7x faster inference
- Shows reduced memory usage (1.0x-4.0x less memory) compared to Transformer models
- Empirical evidence suggests suppression of mode collapse risk in data representation

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sorting along feature dimensions creates implicit permutation matrices that satisfy sparse, full-rank, and doubly-stochastic structural constraints
- Mechanism: The sorting operation produces permutation matrices for each slice, which are inherently sparse (only diagonal and one non-diagonal element per row), full-rank (permutations are invertible), and doubly stochastic (each row and column sums to 1)
- Core assumption: Sorting preserves representational capacity while imposing desirable mathematical properties
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If sorting fails to maintain relative ordering information needed for downstream tasks

### Mechanism 2
- Claim: Replacing QKV with linear projection and sorting reduces computational complexity while maintaining performance
- Mechanism: Eliminates Q and K matrices, requiring only O(DN log N) for sorting vs O(DN²) for traditional attention
- Core assumption: Linear projection and sorting can capture relationships without explicit query-key comparisons
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If linear projection fails to adequately transform input space

### Mechanism 3
- Claim: Interleaving ascending and descending sorting orders across layers increases diversity of implicit attention maps
- Mechanism: Different sorting orders (ascending/descending) applied to different channels and interleaved across layers using sinusoidal function
- Core assumption: Diverse permutation patterns across layers help learn richer representations
- Evidence anchors: [abstract], [section], [corpus]
- Break condition: If interleaving pattern introduces noise rather than meaningful diversity

## Foundational Learning

- Concept: Permutation matrices and their properties
  - Why needed here: Understanding that sorting produces permutation matrices is crucial to grasping why attention maps are sparse, full-rank, and doubly stochastic
  - Quick check question: What are the three defining properties of a permutation matrix, and how does sorting guarantee each one?

- Concept: Computational complexity analysis (time and space)
  - Why needed here: Key advantage is reduced complexity compared to traditional MHA
  - Quick check question: How does time complexity of sorting M D columns of length N compare to computing attention maps via softmax(QK⊤/√D)?

- Concept: Matrix rank and its implications for model capacity
  - Why needed here: Paper claims low-rank attention maps risk mode collapse, while full-rank permutation matrices avoid this
  - Quick check question: Why does applying rank-deficient attention map to value matrices risk mode collapse in output representations?

## Architecture Onboarding

- Component map: Input projection layer (WV) -> Sorting module -> Output concatenation -> Layer stacking
- Critical path: X → WV → V → Sortcol(V) → Output
- Design tradeoffs:
  - Simplicity vs. capacity: Permutation matrices are simple but less expressive than learned attention weights
  - Computational efficiency vs. representational power: Lower complexity comes at potential cost of reduced flexibility
  - Fixed vs. adaptive sorting: Uses fixed sorting orders, while adaptive sorting could capture more complex relationships
- Failure signatures:
  - Performance degradation on tasks requiring fine-grained attention patterns
  - Sensitivity to input scaling or normalization (sorting is scale-dependent)
  - Potential loss of positional information if sorting dominates representation
- First 3 experiments:
  1. Implement basic Sliceformer with ascending sorting on MNIST and compare to vanilla Transformer
  2. Test different sorting strategies (max-exchange vs. full sorting) on same dataset to measure performance/complexity tradeoff
  3. Apply interleaving sorting patterns across layers and measure impact on convergence and final accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the exact theoretical relationship between the "slicing-sorting" operation and the attention mechanism in Transformers?
- Basis in paper: [explicit] The paper states that the "slicing-sorting" operation implicitly generates an attention map with sparse, full-rank, and doubly-stochastic structures, but does not provide rigorous theoretical analysis of this relationship
- Why unresolved: Paper focuses on empirical results without formal mathematical proof
- What evidence would resolve it: Rigorous mathematical proof demonstrating equivalence or similarity between mechanisms

### Open Question 2
- Question: How does performance of Sliceformer compare to other state-of-the-art models in generative tasks?
- Basis in paper: [inferred] Paper focuses on discriminative tasks and does not explore performance in generative tasks
- Why unresolved: No experimental results or analysis of Sliceformer's performance in generative tasks
- What evidence would resolve it: Experimental results comparing performance to other models in generative tasks

### Open Question 3
- Question: What are the limitations of Sliceformer in terms of model capacity and how can they be addressed?
- Basis in paper: [explicit] Paper mentions limited model capacity as main drawback, as implicit attention map is merely a permutation matrix
- Why unresolved: No detailed analysis of limitations or potential solutions provided
- What evidence would resolve it: Detailed analysis of limitations and potential solutions, such as differentiable learnable slicing-sorting operation

## Limitations
- Limited model capacity due to permutation matrix constraints
- Fixed sorting patterns may not adapt to all task requirements
- Potential information loss from discarding explicit query-key interactions

## Confidence

**Major Claims Confidence:**
- Mechanism 1 (Permutation matrix properties): High
- Mechanism 2 (Complexity reduction): High
- Mechanism 3 (Interleaving sorting orders): Medium
- Overall effectiveness: Medium

**Critical Uncertainties:**
- Impact of fixed sorting patterns on tasks requiring adaptive attention
- Sensitivity to input scaling and normalization requirements
- Generalization across diverse data distributions and task types
- Potential information loss from discarding explicit query-key interactions

## Next Checks

1. **Ablation on Sorting Strategies**: Compare ascending, descending, and random sorting patterns on a controlled dataset to isolate contribution of sorting order to model performance.

2. **Rank Analysis of Output Matrices**: Systematically measure rank distribution of Sliceformer outputs across layers and compare to traditional attention models to validate full-rank claim.

3. **Failure Case Analysis**: Identify specific task types or data patterns where Sliceformer underperforms Transformers, and analyze whether this relates to fixed nature of sorting-based attention.