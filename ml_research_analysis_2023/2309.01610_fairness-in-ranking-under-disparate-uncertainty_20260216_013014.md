---
ver: rpa2
title: Fairness in Ranking under Disparate Uncertainty
arxiv_id: '2309.01610'
source_url: https://arxiv.org/abs/2309.01610
tags:
- ranking
- group
- groups
- cost
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Equal-Opportunity Ranking (EOR), a fairness
  criterion for ranking that accounts for disparate uncertainty between groups in
  relevance estimates. EOR ensures that in expectation the fraction of relevant candidates
  selected from each group in any top-k prefix is equal, even when uncertainty differs
  between groups.
---

# Fairness in Ranking under Disparate Uncertainty

## Quick Facts
- arXiv ID: 2309.01610
- Source URL: https://arxiv.org/abs/2309.01610
- Authors: 
- Reference count: 40
- This paper proposes Equal-Opportunity Ranking (EOR), a fairness criterion for ranking that accounts for disparate uncertainty between groups in relevance estimates.

## Executive Summary
This paper introduces Equal-Opportunity Ranking (EOR), a fairness criterion for ranking systems that addresses disparate uncertainty in relevance estimates between groups. Unlike conventional approaches like Probability Ranking Principle (PRP) or Demographic Parity, EOR ensures that in expectation the fraction of relevant candidates selected from each group in any top-k prefix is equal. The authors present an efficient O(n log n) algorithm to compute EOR rankings and prove approximation guarantees on both fairness and cost optimality. Empirical evaluation demonstrates that EOR reliably achieves fairness while maintaining effective rankings, outperforming conventional baselines on synthetic data, US Census data, and Amazon search queries.

## Method Summary
The Equal-Opportunity Ranking (EOR) algorithm addresses fairness in ranking under disparate uncertainty by equalizing the fraction of relevant candidates selected from each group in expectation. The algorithm iteratively builds a ranking by selecting at each step the candidate that minimizes the gap δ between groups' accumulated relevance proportions. This approach generalizes the concept of group-wise calibration, where probability estimates are calibrated within each group independently. The EOR algorithm has O(n log n) complexity and comes with theoretical guarantees on both fairness and cost optimality, showing that the total cost to the principal is within a bounded factor φ of the optimal cost.

## Key Results
- EOR achieves fairness (δ ≤ 0.1) on synthetic datasets with disparate uncertainty between groups while maintaining high expected utility
- On US Census data, EOR achieves 3.7x lower maximum unfairness compared to PRP while sacrificing only 1% in expected utility
- EOR significantly outperforms baselines like PRP and Demographic Parity on Amazon search queries, achieving near-zero unfairness with minimal utility loss

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: EOR fairness balances group-wise selection by equalizing the fraction of relevant candidates selected from each group in expectation.
- **Mechanism**: The algorithm computes a ranking by iteratively selecting the next item from the group that minimizes the gap in accumulated relevance proportions between groups, using the formula: $$\delta(\sigma) = \max_g \left\{ \frac{n(g|\sigma)}{n(g)} \right\} - \min_g \left\{ \frac{n(g|\sigma)}{n(g)} \right\}$$
- **Core assumption**: Relevance estimates P(r_i|D) are group-wise calibrated, meaning calibration holds within each group independently.
- **Evidence anchors**:
  - [abstract] "EOR optimizes for an even cost burden on all groups, unlike the conventional Probability Ranking Principle"
  - [section 4] "We use the notion of group-wise calibration [4, 27] with the probability estimates calibrated within groups"
  - [corpus] No direct evidence; this is a theoretical assumption not explicitly validated in the paper
- **Break condition**: If the relevance model is not group-wise calibrated, the fairness guarantees no longer hold.

### Mechanism 2
- **Claim**: EOR ranking minimizes the cost burden on both groups while maintaining near-optimal effectiveness.
- **Mechanism**: The algorithm guarantees that the cost to the principal (expected number of missed relevant candidates) is within a factor φ of the optimal cost, where φ depends on the difference in relevance probabilities between groups.
- **Core assumption**: The EOR algorithm's selection rule at each step produces a ranking with bounded unfairness δ.
- **Evidence anchors**:
  - [abstract] "prove approximation guarantees on both fairness and cost optimality"
  - [section 6] "we prove an approximation guarantee showing that the gap in total cost to the principal compared to an optimal algorithm is bounded by a small amount"
  - [corpus] Weak evidence; the paper provides theoretical bounds but no empirical validation of the cost approximation in practice
- **Break condition**: If the gap in relevance probabilities between groups is too large, the approximation factor φ may become too high, making the solution impractical.

### Mechanism 3
- **Claim**: EOR ranking generalizes to multiple groups beyond the binary case.
- **Mechanism**: The algorithm extends the selection rule to minimize the maximum gap in accumulated relevance proportions across all groups, using the same iterative selection process.
- **Core assumption**: The multi-group fairness criterion δ(σ) correctly captures unfairness between any pair of groups.
- **Evidence anchors**:
  - [abstract] "We now consider the problem of selecting top k candidates from multiple groups by generalizing Algorithm 1"
  - [section 7] "The following selection rule of minimizing δ then provides the selected group g_l and candidate l to append to the EOR ranking"
  - [corpus] No direct evidence; the paper provides the extension but no empirical validation on more than two groups
- **Break condition**: If there are too many groups with very different relevance distributions, the algorithm may become computationally expensive or the fairness guarantee may weaken.

## Foundational Learning

- **Concept**: Group-wise calibration of relevance estimates
  - **Why needed here**: The EOR fairness criterion relies on accurate group-wise expected numbers of relevant candidates, which requires that probability estimates are calibrated within each group
  - **Quick check question**: What happens to EOR fairness guarantees if the relevance model systematically overestimates probabilities for one group?

- **Concept**: Cost burden analysis in ranking
  - **Why needed here**: The paper defines fairness in terms of equalizing the cost burden on groups, where cost is the probability of missing out on selection if truly relevant
  - **Quick check question**: How does the definition of cost burden differ from traditional fairness metrics like demographic parity?

- **Concept**: Approximation algorithms for ranking
  - **Why needed here**: The EOR algorithm provides theoretical guarantees that it's near-optimal in terms of cost while maintaining fairness, using LP duality and gap analysis
  - **Quick check question**: Why can't we simply solve the ranking problem optimally with an ILP, and what's the tradeoff made by the approximation algorithm?

## Architecture Onboarding

- **Component map**: Relevance probabilities P(r_i|D) and group membership -> Group-wise sorted candidates -> EOR algorithm (iterative selection minimizing δ) -> Ranked list with fairness guarantees
- **Critical path**:
  1. Preprocess data to obtain group-calibrated relevance probabilities
  2. Sort candidates within each group by decreasing P(r_i|D)
  3. Iteratively select next candidate by minimizing δ across groups
  4. Output final ranking
- **Design tradeoffs**:
  - Fairness vs. efficiency: EOR sacrifices some effectiveness (slightly lower DCG) to achieve fairness
  - Computational complexity: O(n log n) is acceptable for moderate-sized datasets
  - Generalization: The algorithm extends to multiple groups but may become more complex
- **Failure signatures**:
  - High variance in δ(σ_k) across different prefixes k indicates poor fairness
  - Large discrepancy between subgroup costs suggests the algorithm isn't working as intended
  - If the approximation factor φ is too high, the solution may be impractical
- **First 3 experiments**:
  1. Test on synthetic data with known disparate uncertainty to verify fairness guarantees
  2. Compare EOR vs. PRP and DP baselines on a real dataset with two clear groups
  3. Evaluate the multi-group extension on a dataset with more than two groups to check generalization

## Open Questions the Paper Calls Out
- How can the EOR framework be extended to handle multi-dimensional or ordinal relevance scores beyond binary relevance? (The authors note "We conjecture that our framework can be extended to categorical or real-valued relevances.")
- What are the computational trade-offs of the EOR algorithm when scaling to very large datasets with millions of candidates? (The current algorithm has O(n log n) complexity, but the paper does not explore its performance at scale.)
- How sensitive is the EOR algorithm to the choice of the fairness tolerance parameter δ, and what are principled ways to select it? (The authors introduce δ-EOR fairness but do not provide guidance on selecting δ in practice.)

## Limitations
- The theoretical fairness guarantees depend critically on the assumption of group-wise calibrated relevance estimates, which is not empirically validated in the experiments
- The approximation guarantees on cost optimality are only theoretically proven, with no empirical validation of how close the algorithm gets to optimal cost in practice
- The multi-group extension is presented algorithmically but lacks experimental validation on datasets with more than two groups

## Confidence
- High confidence: The fairness mechanism of EOR (equalizing the fraction of relevant candidates selected from each group) is clearly defined and demonstrated through experiments on synthetic and real datasets
- Medium confidence: The approximation guarantee that EOR maintains near-optimal cost is theoretically sound but lacks empirical validation
- Medium confidence: The multi-group extension is algorithmically valid but unverified through experiments

## Next Checks
1. Conduct experiments to empirically measure the approximation factor φ between EOR and optimal cost on synthetic datasets where optimal solutions can be computed
2. Test the multi-group EOR algorithm on datasets with 3+ groups to verify its fairness guarantees and computational efficiency
3. Validate the group-wise calibration assumption by examining whether the relevance models used in the experiments actually produce calibrated probability estimates within each group