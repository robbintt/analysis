---
ver: rpa2
title: 'Certainty In, Certainty Out: REVQCs for Quantum Machine Learning'
arxiv_id: '2310.10629'
source_url: https://arxiv.org/abs/2310.10629
tags:
- quantum
- standard
- reversed
- training
- uncertainty
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method called Reversed Variational Quantum
  Circuits (REVQCs) to improve single-sample accuracy in quantum machine learning.
  The core idea is to train a quantum circuit in reverse by using its adjoint to map
  low-variance target values to high-variance input data.
---

# Certainty In, Certainty Out: REVQCs for Quantum Machine Learning

## Quick Facts
- arXiv ID: 2310.10629
- Source URL: https://arxiv.org/abs/2310.10629
- Reference count: 13
- Primary result: REVQCs achieve 10-15% higher single-sample accuracy compared to standard VQCs on MNIST and MNIST Fashion binary classification tasks

## Executive Summary
This paper introduces Reversed Variational Quantum Circuits (REVQCs) as an alternative training method for quantum machine learning that addresses the epistemic uncertainty inherent in standard Variational Quantum Circuits (VQCs). The key insight is that REVQCs train the adjoint of the VQC circuit, mapping high-variance target outputs to low-variance input data during training. This reversed approach enables the model to learn precise center points in Hilbert space for each class, resulting in significantly improved single-sample classification accuracy. The authors demonstrate that REVQCs achieve 10-15% higher single-sample accuracy compared to standard VQCs on binary classification tasks using MNIST and MNIST Fashion datasets.

## Method Summary
REVQCs are implemented by training the adjoint of a standard VQC circuit using mean squared error loss, where the model learns to map low-variance target values to high-variance input data. During inference, the forward VQC produces discrete predictions with minimal variance. The method uses PennyLane for quantum circuit simulation with 8 qubits and PCA dimensionality reduction for image preprocessing. Three different CNN unitary architectures (CNN7, CNN8, CNN9) are tested. The training objective focuses on maximizing single-sample accuracy rather than expectation value accuracy, which the authors argue is more meaningful for discrete classification tasks.

## Key Results
- REVQCs achieve 10-15% higher single-sample accuracy compared to standard VQCs on MNIST and MNIST Fashion binary classification tasks
- The method successfully learns precise center points in Hilbert space for each class, enabling discrete classification
- REVQCs demonstrate reduced epistemic uncertainty compared to standard VQCs when mapping input data to target outputs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reversed training maps high-variance inputs to low-variance outputs, reducing epistemic uncertainty
- Mechanism: REVQC learns the adjoint circuit parameters so that during inference, the VQC outputs discrete predictions with minimal variance
- Core assumption: Quantum circuits are bijective and reversible, allowing parameter learning in reverse direction
- Evidence anchors:
  - [abstract] "We propose Reversed Variational Quantum Circuits (REVQCs) as an alternative for training, which are simply the adjoints of VQC circuits"
  - [section 3.1] "In quantum computing, every operation on a circuit has a conjugate inverse, known as an adjoint, that is easily derived"
  - [corpus] No direct corpus evidence for this specific mechanism
- Break condition: If the quantum circuit is not fully reversible or contains non-unitary operations

### Mechanism 2
- Claim: Single-sample accuracy is a more meaningful metric than expectation value accuracy
- Mechanism: Direct sampling captures true classification performance without averaging over multiple measurements
- Core assumption: The goal is discrete classification, not probability estimation
- Evidence anchors:
  - [abstract] "We make a case for setting high single-sample accuracy as a primary goal"
  - [section 5.1] "The only measure of uncertainty which is possible when comparing discrete outputs to discrete targets is accuracy"
  - [corpus] Weak evidence - corpus mentions related quantum computing concepts but not this specific argument
- Break condition: If the quantum hardware noise is so high that single samples become unreliable

### Mechanism 3
- Claim: REVQC training creates more precise receptive fields with better class separation
- Mechanism: By training in reverse, the model learns exact center points in Hilbert space for each class
- Core assumption: Quantum models are linear on pure states and can represent class boundaries precisely
- Evidence anchors:
  - [section 5.2] "REVQC can force its predictions to have minimal variance as compared to the samples in the input-space"
  - [section 5.2] "REVQC learns the exact center point in the sets of Hilbert space vectors associated with each class"
  - [corpus] No corpus evidence for this specific mechanism
- Break condition: If the data distribution is too complex for linear separation in Hilbert space

## Foundational Learning

- Concept: Quantum circuit reversibility and adjoints
  - Why needed here: Understanding why REVQCs work requires knowing that quantum gates have well-defined inverses
  - Quick check question: If a quantum circuit applies gates G1, G2, G3 in sequence, what is the adjoint circuit?

- Concept: Quantum state representations (pure vs mixed states)
  - Why needed here: The paper argues that VQCs operate on mixed states due to input uncertainty, which affects training
  - Quick check question: What is the difference between a pure state vector and a mixed state density matrix?

- Concept: Quantum measurement and expectation values
  - Why needed here: The paper discusses how measuring Pauli-Z operators gives discrete outputs and expectation values
  - Quick check question: If a qubit is in state |0âŸ©, what is the expectation value of a Pauli-Z measurement?

## Architecture Onboarding

- Component map: Input embedding -> Quantum circuit (VQC/REVQC) -> Measurement -> Classification
- Critical path: Image preprocessing (PCA) -> Dual-angle embedding -> Quantum circuit execution -> Pauli-Z measurement -> Discrete output
- Design tradeoffs: Single-sample accuracy vs. expectation value accuracy, circuit depth vs. expressivity
- Failure signatures: Poor class separation in Hilbert space, high variance in single-sample predictions, inability to learn precise center points
- First experiments: 1) Test REVQCs on binary MNIST classification with different circuit depths, 2) Compare single-sample vs. expectation value accuracy on validation sets, 3) Analyze Hilbert space clustering for each class

## Open Questions the Paper Calls Out

The paper explicitly notes that it uses dense angle-embedding as described by LaRose & Coyle (2020) but did not improve upon this encoding method. The authors acknowledge this as a limitation and suggest that exploring alternative encoding methods could be valuable future work. They also note that the experiments focus exclusively on binary classification tasks, leaving open questions about how REVQCs would perform on multi-class classification problems.

## Limitations

- Experimental results are limited to binary classification on simplified MNIST datasets, limiting generalizability to more complex problems
- The paper does not address computational efficiency or runtime comparisons between VQC and REVQC training approaches
- All experiments are conducted in simulation, without validation on actual quantum hardware where noise and decoherence effects could impact performance

## Confidence

- **High Confidence**: The theoretical framework for REVQCs and the mathematical foundations of quantum circuit reversibility are well-established
- **Medium Confidence**: The experimental results showing 10-15% improvement in single-sample accuracy are promising but limited to specific datasets and binary classification tasks
- **Low Confidence**: Claims about REVQCs being superior for all quantum machine learning applications due to reduced epistemic uncertainty, as this requires broader empirical validation

## Next Checks

1. Test REVQCs on multi-class classification problems and more complex datasets beyond MNIST to assess scalability and generalizability
2. Compare training time and computational resources required for REVQC versus traditional VQC approaches to evaluate practical utility
3. Implement REVQCs on actual quantum hardware to validate performance in the presence of realistic noise and decoherence effects, rather than just simulators