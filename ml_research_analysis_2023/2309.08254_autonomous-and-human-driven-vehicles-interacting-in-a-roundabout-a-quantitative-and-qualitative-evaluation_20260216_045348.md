---
ver: rpa2
title: 'Autonomous and Human-Driven Vehicles Interacting in a Roundabout: A Quantitative
  and Qualitative Evaluation'
arxiv_id: '2309.08254'
source_url: https://arxiv.org/abs/2309.08254
tags:
- traffic
- scenario
- policy
- learning
- vehicles
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a study evaluating the effects of autonomous
  vehicles (AVs) in a roundabout scenario using reinforcement learning. The authors
  integrate three realistic simulators - SUMO, VI-WorldSim, and a high-fidelity cockpit
  - to learn a policy minimizing traffic time and pollution.
---

# Autonomous and Human-Driven Vehicles Interacting in a Roundabout: A Quantitative and Qualitative Evaluation

## Quick Facts
- arXiv ID: 2309.08254
- Source URL: https://arxiv.org/abs/2309.08254
- Authors: 
- Reference count: 40
- Primary result: Increasing AV penetration reduces average crossing time for both AVs and HVs by up to 10.72% and 8.52% respectively, with significant decreases in fuel consumption and emissions.

## Executive Summary
This paper presents a study evaluating the effects of autonomous vehicles (AVs) in a roundabout scenario using reinforcement learning. The authors integrate three realistic simulators - SUMO, VI-WorldSim, and a high-fidelity cockpit - to learn a policy minimizing traffic time and pollution. Results show that increasing AV penetration reduces average crossing time for both AVs and human-driven vehicles (HVs) by up to 10.72% and 8.52% respectively. Fuel consumption and emissions also decrease significantly. Qualitative evaluation using the cockpit with human participants reveals that scenarios with 80% AVs are perceived as safer and smoother than those with 20% AVs. Overall, the study demonstrates the benefits of optimizing AV dynamics and provides insights into future human-AV coexistence in urban transportation.

## Method Summary
The study uses Proximal Policy Optimization (PPO) to learn AV behaviors in a realistic roundabout scenario in Milan, Italy. The method integrates three simulators: SUMO for microscopic traffic simulation, VI-WorldSim for visual simulation, and a high-fidelity cockpit at DrisMi Lab for human-in-the-loop evaluation. Traffic data from field measurements calibrates the simulation. The RL policy optimizes for reduced crossing time and pollution, with both quantitative metrics and qualitative human feedback collected to evaluate performance across different AV penetration levels.

## Key Results
- Increasing AV penetration reduces average crossing time by up to 10.72% for AVs and 8.52% for HVs
- Fuel consumption and emissions decrease significantly with higher AV penetration
- Human participants perceive 80% AV penetration scenarios as safer and smoother than 20% AV penetration scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Reinforcement learning policies trained in SUMO transfer to human-in-the-loop scenarios when combined with VI-WorldSim and a high-fidelity cockpit.
- Mechanism: The RL policy learns optimal acceleration and lane-changing decisions in SUMO's microscopic traffic model. VI-WorldSim integrates SUMO's vehicle states with real-time cockpit data, allowing the learned policy to control AVs while HVs are driven by humans. This preserves policy effectiveness in realistic conditions.
- Core assumption: SUMO's traffic dynamics are sufficiently realistic that RL policies optimized in it remain effective when deployed in VI-WorldSim's real-time simulation with human drivers.
- Evidence anchors:
  - [abstract] "we qualitatively evaluate the learned policy using a cutting-edge cockpit to assess its performance in near-real-world conditions."
  - [section] "To enhance the realism of our study, we leverage a high-fidelity cockpit... enabling us to evaluate, to the best of our knowledge for the first time, the scenario from a qualitative perspective."
  - [corpus] Weak - no direct comparative evidence of SUMO-to-real transfer is cited.
- Break condition: Policy performance degrades significantly in VI-WorldSim due to differences in traffic dynamics, latency, or human driving patterns not captured in SUMO.

### Mechanism 2
- Claim: Higher AV penetration reduces crossing time and emissions for both AVs and HVs.
- Mechanism: AVs, guided by RL, make coordinated, optimal decisions that reduce stop-and-go behavior and improve traffic flow. This coordination creates a smoother traffic environment, indirectly benefiting HVs by reducing their delays and improving fuel efficiency.
- Core assumption: AVs' coordinated behavior creates network effects that improve traffic flow for all vehicles, not just AVs.
- Evidence anchors:
  - [abstract] "Results show that increasing AV penetration reduces average crossing time for both AVs and human-driven vehicles (HVs) by up to 10.72% and 8.52% respectively."
  - [section] "As the A V penetration rate increases, the ripple effects are felt across the entire traffic ecosystem..."
  - [corpus] Weak - while similar findings exist, direct comparative evidence for this specific roundabout scenario is absent.
- Break condition: Network effects saturate or reverse at high AV penetration, or AV coordination introduces new bottlenecks.

### Mechanism 3
- Claim: Human participants perceive higher AV penetration scenarios as safer and smoother.
- Mechanism: AVs' predictable, rule-following behavior reduces uncertainty for human drivers, leading to improved subjective safety and traffic smoothness perception.
- Core assumption: Human drivers interpret AV behavior as more predictable and less aggressive than human-driven traffic.
- Evidence anchors:
  - [abstract] "Qualitative evaluation using the cockpit with human participants reveals that scenarios with 80% AVs are perceived as safer and smoother than those with 20% AVs."
  - [section] "participants in the study highlight that the scenario with 80% AVs is perceived as safer than the scenario with 20% AVs."
  - [corpus] Weak - limited literature directly compares human perception of mixed AV/HV scenarios in roundabout settings.
- Break condition: Human perception shifts negatively due to AV behavior perceived as overly cautious or unfamiliar.

## Foundational Learning

- Concept: Reinforcement Learning and Proximal Policy Optimization (PPO)
  - Why needed here: The core of the AV control policy is learned via PPO, which optimizes AV actions to minimize traffic time and pollution.
  - Quick check question: How does PPO's clipped surrogate objective prevent destructive policy updates during training?

- Concept: Multi-agent Reinforcement Learning (MARL) in traffic simulation
  - Why needed here: The system involves multiple AVs and HVs, requiring understanding of how RL policies generalize across agents in shared environments.
  - Quick check question: What are the key challenges in scaling RL policies from single AV control to mixed traffic scenarios?

- Concept: Traffic simulation fidelity and calibration
  - Why needed here: SUMO's realism depends on accurate calibration to real-world traffic patterns, which is critical for policy effectiveness.
  - Quick check question: What parameters are most sensitive to calibration in SUMO roundabout scenarios?

## Architecture Onboarding

- Component map: SUMO -> Flow -> Ray RLlib -> OpenAI Gym -> VI-WorldSim -> High-fidelity cockpit
- Critical path:
  1. SUMO simulates traffic with calibrated HV models
  2. Flow exposes SUMO as RL environment to PPO
  3. PPO trains AV policy to minimize time and emissions
  4. Trained policy deployed in VI-WorldSim with cockpit integration
  5. Human participants drive HVs while AVs follow learned policy
  6. Quantitative and qualitative metrics collected
- Design tradeoffs:
  - Simulation fidelity vs. computational cost: Higher fidelity improves policy realism but increases training time
  - AV penetration levels: Balancing realism with experimental feasibility
  - Qualitative vs. quantitative evaluation: Subjective human perception vs. objective metrics
- Failure signatures:
  - AV policy causes traffic jams or unsafe conditions in simulation
  - Human participants report discomfort or safety concerns
  - Quantitative metrics show no improvement or degradation with increased AV penetration
- First 3 experiments:
  1. Train PPO policy with 0% AV penetration baseline, verify HV behavior matches field measurements
  2. Incrementally increase AV penetration (10%, 20%, 50%) and measure crossing time/emissions
  3. Conduct qualitative evaluation with human participants comparing 20% vs. 80% AV penetration scenarios

## Open Questions the Paper Calls Out
- Question: How do the safety perceptions of autonomous vehicles (AVs) vary across different demographic groups of participants?
- Question: What is the long-term impact of increased AV penetration on traffic flow and safety in real-world urban environments?
- Question: How do different reinforcement learning algorithms affect the performance and behavior of autonomous vehicles in complex traffic scenarios?

## Limitations
- Limited sample size in human-in-the-loop evaluation may not capture full spectrum of human driving behaviors and perceptions
- Single roundabout scenario limits generalizability to other traffic configurations and urban environments
- Simulation-to-real transfer of RL policies remains unproven without field testing

## Confidence
- **High Confidence**: Quantitative results showing reduced crossing times and emissions with increased AV penetration
- **Medium Confidence**: Qualitative findings regarding human perception of safety and smoothness
- **Low Confidence**: Assumption that SUMO's traffic dynamics accurately represent real-world conditions for effective policy transfer

## Next Checks
1. Deploy trained RL policy in controlled field test with AVs in real roundabout to validate simulation results
2. Conduct larger-scale qualitative evaluation with diverse participant groups including different demographics
3. Test RL policy in multiple traffic scenarios beyond roundabout (intersections, highways, urban grids) to evaluate generalizability