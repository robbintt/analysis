---
ver: rpa2
title: 'Weakly-supervised positional contrastive learning: application to cirrhosis
  classification'
arxiv_id: '2307.04617'
source_url: https://arxiv.org/abs/2307.04617
tags:
- learning
- histo
- contrastive
- images
- cirrhosis
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of classifying liver cirrhosis
  using weakly-labeled medical imaging data, where high-confidence labels are scarce
  and costly. The authors propose a weakly-supervised positional (WSP) contrastive
  learning strategy that leverages both continuous depth information and weak discrete
  labels via a kernel-based loss function.
---

# Weakly-supervised positional contrastive learning: application to cirrhosis classification

## Quick Facts
- arXiv ID: 2307.04617
- Source URL: https://arxiv.org/abs/2307.04617
- Authors: 
- Reference count: 40
- Primary result: Weakly-supervised positional contrastive learning improves liver cirrhosis classification AUC by 5-26% over baseline methods

## Executive Summary
This paper addresses the challenge of classifying liver cirrhosis using weakly-labeled medical imaging data, where high-confidence labels are scarce and costly. The authors propose a weakly-supervised positional (WSP) contrastive learning strategy that leverages both continuous depth information and weak discrete labels via a kernel-based loss function. The method is evaluated on two datasets, D1_histo and D2_histo, with the proposed model improving classification AUC by 5% on D1_histo and 26% on D2_histo compared to baseline models. The code is available at https://github.com/Guerbet-AI/wsp-contrastive.

## Method Summary
The paper introduces a weakly-supervised positional contrastive learning method that integrates spatial context of 2D slices with weak labels using a composite kernel loss function. The approach leverages continuous depth information and discrete radiological annotations as positive samples, allowing the model to learn representations that encode both positional and class information. The method is applied to liver cirrhosis classification using CT scans, with pretraining on a large weakly-labeled dataset followed by fine-tuning on smaller strongly-labeled datasets. The composite kernel loss function combines Gaussian kernels on normalized depth positions with discrete label kernels to create a more informative representation space.

## Key Results
- Proposed WSP model improves classification AUC by 5% on internal dataset (D1_histo) compared to baseline models
- WSP model achieves 26% AUC improvement on public TCGA-LIHC dataset (D2_histo)
- Method demonstrates robustness to hyperparameter σ variation while maintaining performance gains
- WSP outperforms existing contrastive learning methods (SimCLR, BYOL, SupCon) on both datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The weakly-supervised positional (WSP) contrastive learning method improves classification performance by leveraging both continuous depth information and weak discrete labels simultaneously.
- Mechanism: The WSP method integrates spatial context of each 2D slice and a weak label via a kernel-based loss function, which considers both continuous depth positions and discrete radiological annotations as positive samples, thereby improving the representation space.
- Core assumption: Continuous depth information and weak discrete labels are complementary features that, when combined, enhance the model's ability to distinguish between different classes of liver cirrhosis.
- Evidence anchors:
  - [abstract]: "The proposed model improves the classification AUC by 5% with respect to a baseline model on our internal dataset, and by 26% on the public LIHC dataset from the Cancer Genome Atlas."
  - [section 2]: "we propose to use a degree of 'positiveness' between samples by defining a kernel functionw on depth positions."
- Break condition: If the continuous depth information or weak discrete labels do not provide meaningful separation between classes, the WSP method's performance improvement would be negligible.

### Mechanism 2
- Claim: The WSP method's kernel-based loss function allows for efficient use of large batch sizes, which is crucial for handling large 3D images at full resolution.
- Mechanism: By using a normalized kernel function wσ(d, di) = Kσ(d - di) on depth positions, the method can handle large batch sizes without the need for similar spatial resolution across images, which is rarely the case for abdominal CT/MRI acquisitions.
- Core assumption: The kernel function can effectively capture the similarity between samples based on their depth positions, allowing for efficient batch processing.
- Evidence anchors:
  - [abstract]: "These methods typically require large batch sizes, which poses a difficulty in the case of large 3D images at full resolution, due to limited GPU memory."
  - [section 2]: "we propose to use a degree of 'positiveness' between samples by defining a kernel functionw on depth positions."
- Break condition: If the kernel function fails to capture meaningful depth-based similarities, the method would not benefit from large batch sizes, leading to suboptimal performance.

### Mechanism 3
- Claim: The WSP method's composite kernel loss function allows for simultaneous integration of continuous depth information and weak discrete labels, leading to a more informative representation space.
- Mechanism: The composite kernel loss function combines the depth-based kernel wσ and the discrete label-based kernel wδ, ensuring that samples are considered similar only if they have a high degree of positiveness in both dimensions.
- Core assumption: The combined effect of depth and discrete label information provides a richer representation space than either feature alone.
- Evidence anchors:
  - [section 2]: "we propose to leverage both continuous d and discrete y labels, by combining (here by multiplying) the previously defined kernels, wσ and wδ, into a composite kernel loss function."
  - [section 4]: "There is a clear separation between slices of different classes... and at the same time it seems that the depth position has been encoded in the x-axis."
- Break condition: If the composite kernel fails to integrate depth and discrete label information effectively, the representation space would not show the expected separation and encoding, leading to poor classification performance.

## Foundational Learning

- Concept: Contrastive learning
  - Why needed here: Contrastive learning is the foundation for the WSP method, as it allows the model to learn representations by comparing similar and dissimilar samples.
  - Quick check question: What is the primary goal of contrastive learning in the context of medical image classification?

- Concept: Kernel functions
  - Why needed here: Kernel functions are used to measure the similarity between samples based on their depth positions and discrete labels, which is crucial for the WSP method's composite kernel loss function.
  - Quick check question: How do kernel functions help in defining the degree of 'positiveness' between samples in the WSP method?

- Concept: Weakly-supervised learning
  - Why needed here: Weakly-supervised learning is essential for leveraging large volumes of weakly-labeled images, which are more readily available than high-confidence labels in medical imaging.
  - Quick check question: Why is weakly-supervised learning particularly useful in the context of medical image classification?

## Architecture Onboarding

- Component map: 2D slices -> TinyNet/ResNet-18 backbone -> Data augmentation (rotations, crops, flips) -> Balanced sampling -> Composite kernel loss function -> Classification output
- Critical path:
  1. Pretrain the backbone networks on the Dradio dataset using the WSP method
  2. Train a regularized logistic regression on the frozen representations of the D1_histo and D2_histo datasets
  3. Evaluate the model's performance using 5-fold cross-validation
- Design tradeoffs:
  - Using 2D slices instead of 3D volumes to handle anisotropy and limited GPU memory
  - Balancing the batch size to maximize slice heterogeneity while maintaining computational efficiency
  - Choosing the appropriate kernel function parameters (e.g., σ) to capture meaningful similarities
- Failure signatures:
  - Poor separation between classes in the representation space
  - Inconsistent performance across different datasets
  - Overfitting due to insufficient regularization or data augmentation
- First 3 experiments:
  1. Compare the WSP method with SimCLR and BYOL on the D1_histo dataset to evaluate the impact of integrating depth information
  2. Test the WSP method with different kernel function parameters (e.g., varying σ) to assess robustness
  3. Evaluate the WSP method's performance on the D2_histo dataset to ensure generalizability across different datasets

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the proposed weakly-supervised positional (WSP) contrastive learning method perform when applied to other medical imaging tasks beyond liver cirrhosis classification?
- Basis in paper: [explicit] The authors suggest that their method could be easily translated to other medical problems, such as pancreas cancer prediction using the presence of intrapancreatic fat, diabetes mellitus, or obesity as discrete meta-labels.
- Why unresolved: The paper only demonstrates the effectiveness of the WSP method on liver cirrhosis classification using three datasets. The generalizability of the method to other medical imaging tasks is not explored.
- What evidence would resolve it: Conducting experiments applying the WSP method to other medical imaging tasks, such as pancreas cancer prediction, and comparing its performance to existing methods.

### Open Question 2
- Question: What is the impact of different values of the hyperparameter σ on the performance of the proposed WSP method?
- Basis in paper: [explicit] The authors mention that the proposed kernel method is quite robust to the variation of σ and provide a table (Table 3) showing the resulting 5-fold cross-validation AUCs of the proposed method using the TinyNet backbone, varying the value of σ.
- Why unresolved: While the authors provide some evidence of the method's robustness to σ, they do not explore the optimal value of σ for different medical imaging tasks or datasets.
- What evidence would resolve it: Conducting a comprehensive sensitivity analysis of the WSP method with respect to σ for various medical imaging tasks and datasets to determine the optimal value of σ.

### Open Question 3
- Question: How does the proposed WSP method compare to other state-of-the-art contrastive learning methods when applied to 3D medical imaging data?
- Basis in paper: [inferred] The authors mention that working with 3D volumes is challenging due to limited GPU memory and suggest using 2D slices instead. However, they also acknowledge the importance of volumetric positional information for some medical applications.
- Why unresolved: The paper only demonstrates the effectiveness of the WSP method on 2D slices. The performance of the method when applied to 3D medical imaging data is not explored.
- What evidence would resolve it: Conducting experiments applying the WSP method to 3D medical imaging data and comparing its performance to existing methods that can handle 3D data, such as 3D patch-based methods or methods that integrate depth information.

## Limitations

- Method relies heavily on accurate depth normalization across heterogeneous 3D volumes, which may not generalize well to organs with less predictable anatomical positioning
- Kernel-based loss function introduces hyperparameters (σ values) that could be dataset-specific, potentially limiting robustness
- Evaluation focuses on binary classification of cirrhosis without testing on multi-class or regression tasks that might be more clinically relevant

## Confidence

- **High Confidence**: The 26% AUC improvement on TCGA-LIHC dataset is well-supported with 5-fold cross-validation and multiple baseline comparisons
- **Medium Confidence**: The mechanism by which depth information integrates with weak labels appears sound but could benefit from more ablation studies isolating each component's contribution
- **Medium Confidence**: The claim about handling large 3D images efficiently is reasonable but not directly validated with memory usage measurements

## Next Checks

1. Test the method on multi-class cirrhosis staging (F0-F4) to verify generalization beyond binary classification
2. Conduct ablation studies varying σ parameters to establish robustness ranges and sensitivity analysis
3. Evaluate performance when depth information is partially corrupted or missing to assess method reliability under realistic clinical conditions