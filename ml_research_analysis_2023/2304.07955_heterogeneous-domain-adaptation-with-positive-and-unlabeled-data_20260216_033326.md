---
ver: rpa2
title: Heterogeneous Domain Adaptation with Positive and Unlabeled Data
arxiv_id: '2304.07955'
source_url: https://arxiv.org/abs/2304.07955
tags:
- data
- positive
- features
- target
- domain
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a new challenging setting called positive
  and unlabeled heterogeneous unsupervised domain adaptation (PU-HUDA), where the
  source domain only has positive data and the target domain has unlabeled data with
  heterogeneous features. To tackle this problem, the paper proposes a novel method
  called predictive adversarial domain adaptation (PADA), which integrates feature
  space alignment and PU learning in a unified adversarial training framework.
---

# Heterogeneous Domain Adaptation with Positive and Unlabeled Data

## Quick Facts
- arXiv ID: 2304.07955
- Source URL: https://arxiv.org/abs/2304.07955
- Reference count: 34
- Key outcome: PADA improves test accuracy by ~4% on average compared to using only common features and by ~6% in a particular setting on three datasets.

## Executive Summary
This paper addresses the challenging setting of positive and unlabeled heterogeneous unsupervised domain adaptation (PU-HUDA), where the source domain only has positive data and the target domain has unlabeled data with different feature spaces. The proposed method, Predictive Adversarial Domain Adaptation (PADA), integrates feature space alignment and PU learning in a unified adversarial training framework. PADA consists of a classifier to predict likely positive examples from unlabeled target data and a feature transformer to map target features into the source feature space, both trained to fool a common discriminator. Experiments on Movielens-Netflix, 20-Newsgroups, and Default of credit card clients datasets show that PADA outperforms several baseline methods, with particularly strong performance when using the soft labeling mechanism.

## Method Summary
PADA tackles PU-HUDA by learning a feature transformer F that maps target features into the source feature space, a classifier C that identifies positive examples in the target domain, and a discriminator D that distinguishes source data from likely positive target examples. The method employs asymmetric transformation (only transforming target features) and includes a soft labeling mechanism where a base classifier C0 trained on common features provides guidance to C during early training. The adversarial training ensures that F aligns only the positive portion of the target domain with the source, avoiding the label-gap problem that affects naive combinations of existing methods.

## Key Results
- PADA improves test accuracy by approximately 4% on average compared to using only common features across three datasets.
- In a specific setting, PADA achieves about 6% improvement in test accuracy.
- The soft labeling mechanism enhances PADA's performance, especially when the number of common features is limited.
- PADA outperforms several baseline methods, including naive combinations of existing HUDA and PU learning methods.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Adversarial training between the feature transformer and discriminator reduces the distribution divergence specifically between the whole source data and the positive data in the target domain, avoiding the label-gap problem.
- Mechanism: PADA trains a feature transformer F to fool a discriminator D that determines whether an example is from the source domain or a likely positive example in the target domain. This forces F to map both domains into a space where only the positive target data is aligned with the source, not the negative target data.
- Core assumption: The classifier C can reliably identify likely positive examples from the unlabeled target data, which then guides the feature transformer to focus on aligning only the positive portion.
- Evidence anchors: [abstract] "PADA consists of a classifier to predict likely positive examples from the unlabeled target data and a feature transformer to transform the target feature space to that of the source, both trained to fool a common discriminator."

### Mechanism 2
- Claim: The soft labeling mechanism accelerates training by using a stable base classifier trained on common features to guide the main classifier early in training.
- Mechanism: PADA first trains a base classifier C0 using only common features via PAN. Then, during training of the main classifier C and feature transformer F, the loss includes an additional term that aligns C's predictions with C0's soft labels on the target data, providing stable gradients when F is not yet fully trained.
- Core assumption: Common features contain enough discriminative information for C0 to achieve reasonable accuracy, making its soft labels useful for guiding C.
- Evidence anchors: [section 5.2] "If the common features contain some useful information for classification, C0 should attain some degree of classification accuracy. Therefore, we can use C0 to guide the learning of C."

### Mechanism 3
- Claim: Asymmetric transformation (only transforming target features) is sufficient and more efficient than transforming both domains.
- Mechanism: PADA transforms only the target features into the source feature space via F, while keeping the source features fixed. This avoids the complexity of learning bi-directional mappings and leverages the asymmetry where source has labels and target does not.
- Core assumption: The source and target domains share a meaningful set of common features that can serve as anchors for the transformation.
- Evidence anchors: [section 5.1] "Given the asymmetry of the source and target data, we employ an asymmetric transformation [5]."

## Foundational Learning

- Concept: Positive and Unlabeled (PU) Learning
  - Why needed here: The source domain only provides positive examples, and the target domain provides unlabeled examples (both positive and negative). PU learning methods are required to handle this label structure.
  - Quick check question: In PU learning, why can't we simply treat unlabeled examples as negative? (Answer: Because unlabeled examples contain both positive and negative cases, treating them all as negative introduces false negatives and degrades classifier performance.)

- Concept: Heterogeneous Domain Adaptation (HDA)
  - Why needed here: The source and target domains have different feature spaces (e.g., different sets of features or feature dimensions), so direct application of standard domain adaptation methods is not possible.
  - Quick check question: What is the main challenge in HDA compared to homogeneous DA? (Answer: Aligning feature spaces that are structurally different, often requiring feature transformation or mapping.)

- Concept: Adversarial Training for Domain Alignment
  - Why needed here: To reduce the distribution divergence between domains without labels, adversarial training is used where a feature transformer tries to fool a discriminator into thinking transformed target examples come from the source domain.
  - Quick check question: How does adversarial training help in domain adaptation? (Answer: It encourages the feature transformer to produce target features that are indistinguishable from source features, reducing domain shift.)

## Architecture Onboarding

- Component map:
  - Source data (Xs = [Sc; Ss]) -> Feature transformer F -> Transformed target data
  - Target data (Xt = [Tc; Tt]) -> Feature transformer F -> Transformed target data
  - Transformed target data -> Classifier C -> Positive/negative predictions
  - Source data + Transformed target data -> Discriminator D -> Domain classification
  - Common features -> Base classifier C0 -> Soft labels for C

- Critical path:
  1. Train base classifier C0 on common features using PAN.
  2. Iteratively train F to transform target features, C to classify positives, and D to discriminate source vs. positive target examples.
  3. Use soft labels from C0 to stabilize early training of C.
  4. Repeat soft labeling until convergence.
  5. Evaluate C on target test set.

- Design tradeoffs:
  - Asymmetric vs. symmetric transformation: Asymmetric is simpler and sufficient when only target is unlabeled.
  - Linear vs. non-linear components: Linear components are used for simplicity and interpretability; non-linear may improve performance but increase complexity.
  - Number of common features: More common features improve stability but reduce the usefulness of target-specific features.

- Failure signatures:
  - If C fails to identify positives accurately, F may align the wrong portions of the target domain.
  - If common features are uninformative, C0 provides poor guidance, slowing training.
  - If target-specific features are uncorrelated with source-specific features, knowledge transfer is limited.

- First 3 experiments:
  1. Run PADA on Movielens-Netflix with 4 common features and evaluate accuracy vs. COMP (only common features).
  2. Vary the number of common features from 2 to 16 and observe the impact on PADA and COMP performance.
  3. Test PADA with soft labeling disabled (no C0 guidance) to measure the contribution of the soft labeling mechanism.

## Open Questions the Paper Calls Out

- Question: How does the proposed method handle the distribution divergence between the source common features and target common features?
  - Basis in paper: [inferred] The paper mentions in the conclusion that this aspect was not considered in the current study.
  - Why unresolved: The current method does not explicitly address the potential divergence between the common feature distributions of the source and target domains.
  - What evidence would resolve it: Experimental results showing improved performance when explicitly modeling and reducing the divergence between common feature distributions.

- Question: What is the optimal number of common features needed for the proposed method to outperform baseline methods?
  - Basis in paper: [explicit] The paper shows experimental results varying the number of common features from 2 to 16, but doesn't identify an optimal range.
  - Why unresolved: The experiments show that performance degrades as common features decrease, but don't pinpoint the threshold where the method becomes ineffective.
  - What evidence would resolve it: A systematic study identifying the minimum number of common features required for the method to outperform baselines across different datasets.

- Question: How does the soft labeling mechanism's effectiveness vary with different positive-to-negative ratio settings in the target domain?
  - Basis in paper: [explicit] The paper experiments with positive ratios of 0.5, 0.3, and 0.1, showing varying effectiveness of the soft labeling mechanism.
  - Why unresolved: The paper shows the soft labeling mechanism is most effective at certain ratios, but doesn't explain why or how to optimize it for different ratios.
  - What evidence would resolve it: Analysis showing how the soft labeling mechanism's parameters should be adjusted based on the target domain's positive ratio.

## Limitations

- The effectiveness of PADA depends critically on the classifier's ability to accurately identify positive examples from unlabeled target data early in training.
- The method relies on common features for the soft labeling mechanism, which may not be discriminative enough in all scenarios.
- The asymmetric transformation approach assumes sufficient correlation between common and domain-specific features, which may not hold universally.

## Confidence

- **High confidence**: The overall framework of integrating PU learning with HDA through adversarial training is sound and well-motivated by the problem definition.
- **Medium confidence**: The specific mechanism of using soft labels from C0 to guide C during training is well-described but depends on unstated implementation details of PAN.
- **Medium confidence**: The quantitative improvements (4% average accuracy gain, 6% in specific settings) are reported, but the exact experimental conditions and hyperparameters are not fully specified.

## Next Checks

1. **Validation of Classifier Accuracy**: Measure the accuracy of classifier C in identifying positive examples from the unlabeled target data during training. If accuracy is below a reasonable threshold (e.g., 70%), the entire alignment mechanism may be compromised.

2. **Sensitivity to Common Feature Quality**: Systematically vary the quality and quantity of common features and measure the impact on PADA performance compared to COMP. This would validate whether the soft labeling mechanism truly provides the claimed benefits when common features are limited.

3. **Comparison of Asymmetric vs. Symmetric Transformation**: Implement a variant of PADA that transforms both source and target features into a shared space and compare performance. This would test whether the claimed efficiency of asymmetric transformation comes at the cost of accuracy.