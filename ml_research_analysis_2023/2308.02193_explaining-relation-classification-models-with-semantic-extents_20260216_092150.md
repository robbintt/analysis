---
ver: rpa2
title: Explaining Relation Classification Models with Semantic Extents
arxiv_id: '2308.02193'
source_url: https://arxiv.org/abs/2308.02193
tags:
- semantic
- relation
- extents
- classification
- samples
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of explainability in relation
  classification models, which are often black boxes despite their high accuracy.
  The authors introduce the concept of semantic extents, defined as the most influential
  parts of text for a classification decision.
---

# Explaining Relation Classification Models with Semantic Extents

## Quick Facts
- arXiv ID: 2308.02193
- Source URL: https://arxiv.org/abs/2308.02193
- Reference count: 35
- Key outcome: Introduces semantic extents to explain relation classification models, finding that humans use more context than models and that models often rely on shortcut patterns

## Executive Summary
This paper addresses the explainability challenge in relation classification by introducing semantic extents - the most influential text portions for classification decisions. The authors provide annotation tools and compare human versus model decision patterns, revealing that humans consistently request more context than models to make confident classifications. The study shows that models often achieve high confidence using only argument spans, suggesting they learn shortcut patterns from training data rather than genuine language understanding.

## Method Summary
The authors develop a framework for identifying semantic extents through both expansion (starting from arguments and adding context tokens based on dependency parsing heuristics) and reduction (removing least influential tokens using gradient-based input reduction). They create a web annotation tool for human labeling of semantic extents and apply this methodology to the ACE 05 dataset using a RoBERTa model. The approach enables systematic comparison between human and model decision patterns, revealing differences in context dependency and potential shortcut learning.

## Key Results
- Humans request significantly more context tokens than models for confident classifications
- Model predictions based solely on arguments show higher confidence but are less context-dependent
- Reductive semantic extents often become ungrammatical fragments that are difficult to interpret
- Semantic extents can help identify when models rely on spurious correlations rather than full semantics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Semantic extents capture the most influential text regions for a classification decision through iterative expansion or reduction
- Mechanism: The algorithm starts with only the relation arguments and expands by adding tokens prioritized by dependency-parse heuristics until the model prediction stabilizes; alternatively, it reduces by removing tokens with minimal gradient influence until the prediction changes
- Core assumption: The final token set after expansion/reduction constitutes the minimal necessary context for the decision, and stable predictions imply sufficiency
- Evidence anchors:
  - [abstract]: "Semantic extents are the most influential parts of texts concerning classification decisions."
  - [section]: "We apply a convenient extension rule: if an average language user cannot specify a convenient extension, we assume such does not exist."
- Break condition: If a consistent extension exists that changes the prediction, the current set is not a semantic extent; if the heuristic prioritizes tokens irrelevant to semantics, the extent will be noisy

### Mechanism 2
- Claim: Human decision patterns differ from model patterns because humans rely more on context-dependent cues, whereas models exploit shortcut correlations in data
- Mechanism: Human annotators iteratively request context tokens until they can classify; models often classify from arguments alone with high confidence, indicating reliance on spurious correlations rather than full semantics
- Core assumption: High confidence on argument-only inputs reflects shortcut learning rather than genuine language understanding
- Evidence anchors:
  - [abstract]: "Our results indicate that human decisions are more context-dependent than model decisions."
  - [section]: "Predictions that fall in the first category are significantly more likely to be correct and show higher confidence with less deviation."
- Break condition: If models achieve high accuracy without relying on shortcuts, or if human annotators also classify from arguments alone, the claim fails

### Mechanism 3
- Claim: Input reductions can serve as reductive semantic extents, but they may yield ungrammatical fragments that are hard to interpret
- Mechanism: Gradient-based input reductions iteratively remove least-influential tokens; the surviving tokens approximate the decision-relevant subset, analogous to semantic extents but via deletion
- Core assumption: The minimal set after reduction retains enough structure to be meaningful, or at least comparable to human judgments
- Evidence anchors:
  - [section]: "Reductive semantic extents may be sentence fragments without grammatical structure and unintuitive for humans."
  - [section]: "Figure 10 shows that reductive extents tend to contain more tokens than extensive extents."
- Break condition: If reductions produce random fragments or the remaining tokens are semantically unrelated to the decision, the approach fails

## Foundational Learning

- Concept: Relation classification task definition
  - Why needed here: All subsequent analysis hinges on clear boundaries between argument spans and relation labels
  - Quick check question: Given a sentence with entities A and B, what constitutes a valid relation classification sample?

- Concept: Dependency parsing and syntactic heuristics
  - Why needed here: Expansion priority order (argument subtree → verbs on path → between arguments) depends on syntactic structure
  - Quick check question: In the parse tree of "He worked at NBC", which tokens fall in the verb-on-path stage?

- Concept: Gradient-based saliency and input reduction
  - Why needed here: Reductive semantic extents rely on gradient approximations to identify token influence
  - Quick check question: How is token influence approximated in input reduction?

## Architecture Onboarding

- Component map:
  - Preprocessing pipeline (spaCy tokenization + ACE 05 parsing)
  - Annotation tool (web UI for semantic extent labeling)
  - RoBERTa model wrapper (argument-separated inputs + softmax logits)
  - Expansion engine (dependency-based token addition)
  - Reduction engine (gradient-based beam search)
  - Evaluation scripts (F1, confidence, adversarial testing)

- Critical path:
  1. Load ACE 05 data → preprocess → extract argument pairs
  2. For each sample, run model prediction on full text
  3. Run expansion/reduction to obtain semantic extents
  4. Compare human vs model extents and analyze patterns
  5. Generate adversarial samples and re-evaluate

- Design tradeoffs:
  - Heuristic vs learned token priority: fast but brittle vs accurate but slower
  - Extensive vs reductive extent: intuitive but potentially noisy vs compact but ungrammatical
  - High vs low confidence threshold: fewer but cleaner extents vs more but spurious ones

- Failure signatures:
  - Model predicts correctly on arguments only → possible shortcut
  - Human and model extents diverge completely → model not capturing semantics
  - Reductions yield uninterpretable fragments → reduction method unsuitable

- First 3 experiments:
  1. Run expansion on a small sample set; verify human annotators need more context than model does
  2. Compare F1 scores for samples where model uses only arguments vs those needing full context
  3. Generate adversarial samples for argument-only decisions; check if predictions change

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do semantic extents vary across different relation classification datasets beyond ACE 05?
- Basis in paper: [explicit] The authors state that semantic extents can increase reliability in critical areas like healthcare or finance, implying broader applicability
- Why unresolved: The study only evaluates semantic extents on the ACE 05 dataset. The authors acknowledge that real-world applications involve more complex scenarios
- What evidence would resolve it: Applying semantic extents to diverse relation classification datasets and comparing results to ACE 05 findings

### Open Question 2
- Question: Can semantic extents be used to systematically detect and mitigate biases in relation classification models?
- Basis in paper: [inferred] The authors mention that models learn spurious patterns from data and that semantic extents can reveal counterintuitive ties, suggesting potential for bias detection
- Why unresolved: While the paper hints at bias detection, it doesn't provide a systematic approach or empirical evidence for bias mitigation using semantic extents
- What evidence would resolve it: Developing and testing a methodology that uses semantic extents to identify and correct biased decision patterns in relation classification models

### Open Question 3
- Question: How do different model architectures and training strategies affect the alignment between human and model semantic extents?
- Basis in paper: [explicit] The authors compare semantic extents for humans and RoBERTa-based models, revealing differences in decision patterns
- Why unresolved: The study focuses on a single model architecture (RoBERTa). The impact of different architectures or training strategies on semantic extent alignment is unknown
- What evidence would resolve it: Comparing semantic extents across various model architectures and training strategies, analyzing how these factors influence alignment with human decision patterns

## Limitations
- The human annotation study is limited to 100 sentences with only 3 annotators, which may not capture full variability in human decision patterns
- The heuristic-based expansion algorithm is brittle and its sensitivity to different syntactic heuristics is not systematically evaluated
- The interpretation that models learn "spurious" patterns is observational without controlled experiments to verify this claim

## Confidence
- High confidence: The methodology for defining and collecting semantic extents is well-specified and reproducible
- Medium confidence: The observation that humans request more context than models do is supported by the annotation study
- Low confidence: The interpretation that models learn "spurious" patterns from data, while plausible, requires more rigorous validation

## Next Checks
1. **Adversarial robustness validation**: Systematically test whether argument-only predictions are more vulnerable to adversarial perturbations than context-aware predictions, directly measuring if "shortcut" decisions are less robust

2. **Heuristic sensitivity analysis**: Repeat the human-model comparison using multiple expansion heuristics (different dependency-based, position-based, and learned heuristics) to assess whether the observed pattern differences are consistent across approaches

3. **Cross-dataset generalization**: Apply the semantic extent methodology to a different relation classification dataset (e.g., SemEval 2010 Task 8) to determine if human-model pattern differences persist across domains and annotation schemes