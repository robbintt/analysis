---
ver: rpa2
title: Self-training with dual uncertainty for semi-supervised medical image segmentation
arxiv_id: '2304.04441'
source_url: https://arxiv.org/abs/2304.04441
tags:
- segmentation
- uncertainty
- training
- image
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper tackles semi-supervised medical image segmentation
  by addressing the challenge of leveraging unlabeled data effectively. The authors
  propose a self-training framework enhanced with dual uncertainty estimation: sample-level
  uncertainty, which sorts unlabeled samples based on model stability, and pixel-level
  uncertainty, derived from the output differences of two decoders with different
  upsampling methods.'
---

# Self-training with dual uncertainty for semi-supervised medical image segmentation

## Quick Facts
- arXiv ID: 2304.04441
- Source URL: https://arxiv.org/abs/2304.04441
- Reference count: 40
- This paper introduces a self-training framework with dual uncertainty estimation (sample-level and pixel-level) that achieves superior segmentation performance on ACDC and Prostate datasets compared to existing self-training and consistency-based approaches.

## Executive Summary
This paper addresses semi-supervised medical image segmentation by proposing a self-training framework enhanced with dual uncertainty estimation. The authors tackle the challenge of leveraging unlabeled data effectively by introducing both sample-level uncertainty (estimated from multiple model checkpoints) and pixel-level uncertainty (derived from two decoders with different upsampling methods). These uncertainty estimates guide the selective inclusion of unlabeled samples and the weighting of pseudo-label losses during training. Evaluated on the ACDC and Prostate datasets, the method achieves state-of-the-art performance, notably improving Dice scores over existing approaches while demonstrating robustness to various semi-supervised settings.

## Method Summary
The proposed method combines self-training with dual uncertainty estimation to improve semi-supervised medical image segmentation. Sample-level uncertainty is computed by comparing predictions from K models saved during pre-training, allowing samples to be sorted and included progressively from easiest to hardest. Pixel-level uncertainty is estimated using KL divergence between two decoders with different upsampling methods (transposed convolution and bilinear interpolation). The framework uses an uncertainty-rectified loss that downweights high-uncertainty pixels in pseudo-label training while also minimizing uncertainty directly. The method is evaluated on ACDC and Prostate datasets with various labeled/unlabeled splits, demonstrating consistent improvements over baseline self-training and consistency-based approaches.

## Key Results
- Achieves Dice score improvements of 2.5-4.1 percentage points over existing self-training methods on ACDC dataset
- Demonstrates 1.8-3.2 percentage points Dice improvement on Prostate dataset across different labeled/unlabeled splits
- Shows consistent performance gains in both high-label (10%) and low-label (1%) semi-supervised settings
- Outperforms state-of-the-art consistency-based methods while requiring fewer computational resources

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sample-level uncertainty estimates model stability by comparing predictions from multiple checkpoints saved during pre-training.
- Mechanism: The method saves K model checkpoints during pre-training, then evaluates the same unlabeled samples across these checkpoints. Higher variance in predictions across checkpoints indicates lower sample-level certainty. Samples are sorted by this variance and added to training from easiest to hardest.
- Core assumption: Segmentation stability across checkpoints is a reliable proxy for sample difficulty in the semi-supervised context.
- Evidence anchors:
  - [abstract] "we saved several moments of the model during pre-training, and used the difference between their predictions on unlabeled samples as the sample-level uncertainty estimate for that sample."
  - [section] "Specifically, we saved K models at certain time points during the initial training process, denoted as F1(θ),F2(θ),..., Fk(θ)respectively. Then, we input the unlabeled samples Xt into these saved models to obtain the corresponding predictions... We estimate the sample-level uncertainty of each sample by using the differences between these predictions."
- Break condition: If checkpoints are too close in training time, the variance may be insufficient to differentiate sample difficulty reliably.

### Mechanism 2
- Claim: Pixel-level uncertainty is estimated by comparing outputs from two decoders with different upsampling methods.
- Mechanism: A secondary decoder using bilinear interpolation is added alongside the original decoder using transposed convolution. The KL divergence between their softmax outputs serves as a pixel-level uncertainty map, which is then used to weight the pseudo-label loss, downweighting high-uncertainty pixels.
- Core assumption: Different upsampling methods introduce sufficient architectural variance to generate meaningful uncertainty estimates without requiring multiple forward passes.
- Evidence anchors:
  - [abstract] "we added a decoder with different upsampling methods to the segmentation network and used the difference between the outputs of the two decoders as pixel-level uncertainty."
  - [section] "we added a new decoder to the U-net, where the original decoder uses transpose convolution for upsampling and the new decoder uses bilinear interpolation for upsampling. We measure the pixel-level uncertainty using the KL divergence between the outputs of the two decoders."
- Break condition: If both decoders converge to similar outputs, the KL divergence may be too small to provide discriminative uncertainty signals.

### Mechanism 3
- Claim: Uncertainty-rectified loss improves segmentation by adaptively weighting pixel losses based on uncertainty estimates.
- Mechanism: Cross-entropy loss is multiplied by an exponential decay term based on pixel-level KL divergence. This reduces the influence of high-uncertainty pixels while also including a term to minimize uncertainty directly during training, encouraging the model to produce more consistent predictions.
- Core assumption: Assigning lower weights to high-uncertainty pixels during training reduces the propagation of noisy pseudo-labels and stabilizes the learning process.
- Evidence anchors:
  - [abstract] "we selectively retrained unlabeled samples and assigned pixel-level uncertainty to pseudo labels to optimize the self-training process."
  - [section] "Based on the measured uncertainty, we adjusted the cross-entropy loss based on pseudo label to emphasize the reliable parts and ignore the unreliable parts of the predictions."
- Break condition: If uncertainty estimates are systematically biased (e.g., consistently underestimating uncertainty in hard regions), the adaptive weighting could degrade performance.

## Foundational Learning

- Concept: Semi-supervised learning
  - Why needed here: The paper addresses the challenge of leveraging large amounts of unlabeled medical image data to improve segmentation accuracy when labeled data is scarce.
  - Quick check question: What is the primary benefit of using unlabeled data in semi-supervised learning for medical image segmentation?

- Concept: Uncertainty estimation in deep learning
  - Why needed here: Uncertainty estimation is critical for identifying unreliable pseudo-labels and avoiding error propagation during self-training, especially in medical imaging where mistakes can have serious consequences.
  - Quick check question: What are the two main types of uncertainty commonly distinguished in deep learning, and how do they differ?

- Concept: Self-training and pseudo-labeling
  - Why needed here: The paper builds upon self-training, where a model iteratively generates and refines pseudo-labels for unlabeled data to improve segmentation performance without additional manual annotation.
  - Quick check question: In self-training, what is the primary risk associated with using low-quality pseudo-labels, and how can it affect model performance?

## Architecture Onboarding

- Component map: U-Net backbone with two decoders (original + auxiliary with bilinear upsampling) -> Sample-level uncertainty estimator (K checkpoint models) -> Pixel-level uncertainty estimator (KL divergence between decoder outputs) -> Uncertainty-rectified loss function (weighted cross-entropy + uncertainty minimization) -> Self-training loop with progressive sample inclusion

- Critical path:
  1. Pre-train initial model and save K checkpoints
  2. Compute sample-level uncertainty for all unlabeled samples
  3. Sort and partition unlabeled samples by uncertainty
  4. Generate pseudo-labels for reliable subset
  5. Train with supervised and uncertainty-rectified unsupervised loss
  6. Update pseudo-labels and repeat with next subset

- Design tradeoffs:
  - Adding a second decoder increases memory and computation but provides pixel-level uncertainty without multiple forward passes
  - Saving K checkpoints requires additional storage but enables sample-level uncertainty estimation without retraining
  - Progressive inclusion of samples from easy to hard stabilizes training but may slow convergence

- Failure signatures:
  - If KL divergence between decoders is consistently near zero, pixel-level uncertainty estimates may be uninformative
  - If sample-level uncertainty variance is too small, the sorting mechanism may not effectively differentiate sample difficulty
  - If uncertainty estimates are biased, the adaptive loss weighting could systematically harm performance

- First 3 experiments:
  1. Verify that KL divergence between decoders increases in ambiguous regions (e.g., boundaries) compared to homogeneous regions
  2. Test that sample-level uncertainty correlates with segmentation difficulty by manually inspecting high and low uncertainty samples
  3. Confirm that uncertainty-rectified loss produces smoother segmentation boundaries compared to standard cross-entropy with pseudo-labels

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the sample-level uncertainty estimation method perform when the number of saved models K is significantly increased beyond the range tested?
- Basis in paper: [explicit] The paper uses K models saved during pre-training but does not explore the effect of varying K on performance.
- Why unresolved: The paper does not report results for different values of K, leaving uncertainty about the optimal number of models for uncertainty estimation.
- What evidence would resolve it: Systematic experiments comparing performance across a wide range of K values, including very large K, would clarify the impact on segmentation accuracy and computational efficiency.

### Open Question 2
- Question: How does the proposed method handle class imbalance in medical image datasets, particularly for rare classes?
- Basis in paper: [inferred] The paper does not address class imbalance, which is a common challenge in medical image segmentation.
- Why unresolved: The method focuses on uncertainty estimation and sample sorting but does not incorporate strategies for handling imbalanced class distributions.
- What evidence would resolve it: Experiments demonstrating the method's performance on highly imbalanced datasets, along with comparisons to specialized class imbalance techniques, would provide insights into its robustness.

### Open Question 3
- Question: What is the impact of using different upsampling methods in the dual-decoder architecture on the pixel-level uncertainty estimation?
- Basis in paper: [explicit] The paper uses transpose convolution and bilinear interpolation but does not explore other combinations.
- Why unresolved: The choice of upsampling methods could significantly affect the quality of pixel-level uncertainty estimates and subsequent loss rectification.
- What evidence would resolve it: Comparative studies using various upsampling method combinations (e.g., nearest neighbor, pixel shuffling) would reveal the optimal configuration for uncertainty estimation.

## Limitations

- The proposed method relies heavily on checkpoint selection criteria during pre-training for sample-level uncertainty estimation, which is not fully specified and could significantly impact performance
- Computational overhead from maintaining two decoders and multiple checkpoint models may limit scalability to larger datasets or more complex segmentation tasks
- The progressive inclusion strategy's optimal ordering and thresholds may be dataset-dependent and require careful tuning

## Confidence

- High Confidence: The core methodology of using pixel-level uncertainty through dual decoders and uncertainty-weighted loss is well-established and technically sound
- Medium Confidence: The effectiveness of sample-level uncertainty sorting mechanism depends on appropriate checkpoint selection, which is not fully specified
- Medium Confidence: The progressive inclusion strategy's optimal ordering and thresholds may be dataset-dependent and require careful tuning

## Next Checks

1. **Ablation Study**: Systematically evaluate the contribution of each uncertainty type by removing sample-level or pixel-level components separately to quantify their individual impact on performance

2. **Checkpoint Sensitivity Analysis**: Test different checkpoint selection strategies (e.g., fixed intervals vs. performance-based) to determine optimal timing for saving models and assess robustness to this hyperparameter

3. **Generalization Testing**: Apply the method to additional medical imaging datasets with different modalities (e.g., CT, ultrasound) and anatomical structures to evaluate cross-domain effectiveness beyond cardiac and prostate segmentation