---
ver: rpa2
title: 'WS-SfMLearner: Self-supervised Monocular Depth and Ego-motion Estimation on
  Surgical Videos with Unknown Camera Parameters'
arxiv_id: '2308.11776'
source_url: https://arxiv.org/abs/2308.11776
tags:
- depth
- camera
- intrinsic
- estimation
- parameters
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents WS-SfMLearner, a self-supervised monocular
  depth and ego-motion estimation system for surgical videos with unknown camera parameters.
  The method introduces a camera intrinsic parameter prediction module and uses a
  cost-volume-based supervision strategy to improve depth and ego-motion accuracy.
---

# WS-SfMLearner: Self-supervised Monocular Depth and Ego-motion Estimation on Surgical Videos with Unknown Camera Parameters

## Quick Facts
- arXiv ID: 2308.11776
- Source URL: https://arxiv.org/abs/2308.11776
- Reference count: 15
- Key outcome: Achieves 0.062 absolute relative depth error on SCARED dataset with unknown camera parameters

## Executive Summary
WS-SfMLearner addresses the challenge of estimating depth and ego-motion from monocular surgical videos where camera intrinsic parameters are unknown. The method builds upon self-supervised learning frameworks by introducing a camera intrinsic parameter prediction module and a cost-volume-based supervision strategy. This allows the system to learn depth and ego-motion estimation without requiring known camera parameters or ground truth depth labels. The approach demonstrates competitive performance with state-of-the-art methods while eliminating the need for camera parameter calibration.

## Method Summary
The WS-SfMLearner system extends the AF-SfMLearner baseline by adding a camera intrinsic CNN that predicts focal length and principal point offset from image features. A cost-volume module provides auxiliary supervision by computing geometric consistency across multiple depth planes, improving both depth and camera parameter predictions. The system is trained on surgical video sequences from the SCARED dataset using photometric consistency losses, with the cost volume providing additional geometric supervision. The camera intrinsic CNN uses a ResNet-18 encoder followed by separate decoders for pose and camera parameters, with training conducted using Adam optimizer and a learning rate schedule that decays by 0.1 every 10 epochs.

## Key Results
- Achieves absolute relative depth error of 0.062 on SCARED dataset
- Improves camera parameter prediction accuracy compared to baseline approaches
- Reduces rotation and trajectory errors in ego-motion estimation
- Competitive depth estimation performance compared to state-of-the-art methods despite unknown camera parameters

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The cost-volume-based supervision improves depth and ego-motion accuracy by providing geometric consistency across multiple viewpoints
- Mechanism: The cost volume module warps source feature maps to the target frame using predicted ego-motion and camera intrinsics at multiple depth planes, then computes L1 distances to measure geometric compatibility. This provides auxiliary supervision that regularizes the camera parameter predictions and depth estimates
- Core assumption: The geometric consistency measured by cost volume is a reliable indicator of depth and camera parameter accuracy
- Evidence anchors:
  - [abstract] "We proposed a cost-volume-based supervision manner to give the system auxiliary supervision for camera parameters prediction"
  - [section] "After warping source feature maps with predicted ego-motion, intrinsic parameters, and defined depth plane to target domain, we calculate the l1 distance between target feature map and synthesized target feature map to build the cost volume"

### Mechanism 2
- Claim: Predicting camera intrinsics directly within the network enables learning from surgical videos without known camera parameters
- Mechanism: The camera intrinsic CNN predicts focal length and principal point offset from ResNet-18 features, allowing the system to adapt to different camera configurations automatically rather than requiring known parameters
- Core assumption: The CNN can learn to predict accurate camera intrinsics from image features alone, without explicit supervision
- Evidence anchors:
  - [abstract] "We proposed a cost-volume-based supervision manner to give the system auxiliary supervision for camera parameters prediction"
  - [section] "In the camera decoder route, the feature from the encoder passes through a convolution layer and average pooling layer, then to the focal length convolution and offset convolution layer to generate the focal length and principal point offset of camera intrinsic parameters"

### Mechanism 3
- Claim: The WS-SfMLearner system achieves state-of-the-art depth estimation performance despite unknown camera parameters
- Mechanism: By combining AF-SfMLearner baseline with camera intrinsic prediction and cost-volume supervision, the system maintains the depth estimation accuracy of fully supervised methods while removing the need for known camera parameters
- Core assumption: The auxiliary supervision from cost volume can compensate for the uncertainty introduced by predicting camera intrinsics
- Evidence anchors:
  - [abstract] "Experiments on the SCARED dataset demonstrate that WS-SfMLearner achieves competitive depth estimation performance compared to state-of-the-art methods"
  - [section] "Table 1 shows the quantitative results for depth estimation. The depth estimation results show even with unknown camera intrinsic parameters, our WS-SfMLearner could predict high quality depth maps competitive with other state-of-the-art methods"

## Foundational Learning

- Concept: Self-supervised learning for depth estimation
  - Why needed here: The surgical video datasets lack ground truth depth maps, making supervised learning impossible
  - Quick check question: How does the system use photometric consistency to learn depth without ground truth labels?

- Concept: Camera intrinsic parameters and their role in 3D reconstruction
  - Why needed here: Surgical videos often lack recorded camera parameters, yet accurate depth estimation requires them for proper projection geometry
  - Quick check question: What are the key camera intrinsic parameters and how do they affect the projection of 3D points to 2D image coordinates?

- Concept: Cost volume construction and usage
  - Why needed here: The cost volume provides geometric consistency supervision that improves both depth and camera parameter predictions
  - Quick check question: How does the system construct the cost volume by warping features across multiple depth planes?

## Architecture Onboarding

- Component map: Input frames ‚Üí Camera Intrinsic CNN ‚Üí AF-SfMLearner + Cost Volume ‚Üí Depth map prediction
- Critical path: Input frames ‚Üí Camera Intrinsic CNN ‚Üí AF-SfMLearner + Cost Volume ‚Üí Depth map prediction
- Design tradeoffs: Predicting camera intrinsics adds uncertainty but enables learning from more datasets; cost volume supervision improves accuracy but increases computational complexity
- Failure signatures: Poor depth predictions when camera motion is minimal; inaccurate camera intrinsics when training data lacks diversity; cost volume supervision fails when optical flow predictions are unreliable
- First 3 experiments:
  1. Test camera intrinsic prediction accuracy on a dataset with known parameters to verify the CNN can learn intrinsics
  2. Evaluate depth estimation with known vs. predicted camera intrinsics to quantify the impact of parameter uncertainty
  3. Measure cost volume geometric consistency scores to validate the auxiliary supervision provides meaningful gradients

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of WS-SfMLearner change when using different numbers of past frames (N) in the cost volume module?
- Basis in paper: [explicit] The paper states "In the cost volume computing, we only use past frames as nearby view of target frames, ùêºùë†(ùëù) ùúñ { ùêºùë°‚àí1(ùëù), ‚Ä¶ , ùêºùë°‚àíùëÅ(ùëù)}."
- Why unresolved: The paper does not provide an analysis of how the choice of N affects the depth estimation accuracy or the stability of the camera intrinsic prediction.
- What evidence would resolve it: Experiments comparing depth estimation metrics (e.g., Abs Rel, RMSE) and camera intrinsic prediction accuracy for different values of N.

### Open Question 2
- Question: Can the depth plane distribution in the cost volume module be learned adaptively rather than using a linear distribution?
- Basis in paper: [explicit] The paper mentions "The cost volume method can still be improved by learning depth plane distribution rather than using linear distribution directly, which will be considered in our future work."
- Why unresolved: The paper proposes this as future work but does not provide any experimental results or insights into how adaptive depth plane learning would impact performance.
- What evidence would resolve it: Implementation and evaluation of an adaptive depth plane learning strategy, comparing its performance to the linear distribution approach.

### Open Question 3
- Question: How does WS-SfMLearner perform on surgical datasets with significantly different camera motions or intrinsic parameters compared to the SCARED dataset?
- Basis in paper: [inferred] The paper demonstrates good performance on the SCARED dataset but does not evaluate generalization to other surgical datasets with varying camera characteristics.
- Why unresolved: The paper's experiments are limited to a single dataset, and it is unclear how well the method would generalize to datasets with different camera motion patterns or intrinsic parameters.
- What evidence would resolve it: Experiments on multiple surgical datasets with diverse camera characteristics, comparing depth estimation and camera intrinsic prediction accuracy across datasets.

## Limitations
- Camera intrinsic prediction accuracy not directly validated with ground truth parameters
- Limited evaluation to single SCARED dataset, raising generalization concerns
- Cost volume supervision relies on geometric consistency assumptions that may fail in textureless surgical scenes

## Confidence

**Confidence Labels:**
- Depth estimation performance: High
- Camera intrinsic prediction accuracy: Low
- Cost volume supervision effectiveness: Medium

## Next Checks
1. Validate camera intrinsic predictions on a dataset with known camera parameters to measure prediction accuracy directly
2. Test depth estimation performance with ground truth vs. predicted camera intrinsics on the same scenes to quantify the impact of parameter uncertainty
3. Evaluate generalization to a different surgical dataset to verify the method works beyond SCARED domain