---
ver: rpa2
title: Sample Complexity Bounds for Estimating Probability Divergences under Invariances
arxiv_id: '2311.02868'
source_url: https://arxiv.org/abs/2311.02868
tags:
- theorem
- probability
- distance
- measure
- invariances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies how group invariances improve sample complexity
  for estimating probability divergences on manifolds. The authors analyze Wasserstein
  distance, Sobolev Integral Probability Metrics, Maximum Mean Discrepancy, and density
  estimation problems under Lie group actions.
---

# Sample Complexity Bounds for Estimating Probability Divergences under Invariances

## Quick Facts
- arXiv ID: 2311.02868
- Source URL: https://arxiv.org/abs/2311.02868
- Reference count: 40
- This paper studies how group invariances improve sample complexity for estimating probability divergences on manifolds.

## Executive Summary
This paper establishes theoretical sample complexity bounds for estimating probability divergences under group invariances on manifolds. The authors demonstrate that when probability measures are invariant under Lie group actions, sample complexity improves both through multiplicative factors related to group size and through improved convergence rate exponents. The results generalize finite group results to arbitrary Lie groups and smooth manifolds, providing new bounds for Wasserstein distance, Sobolev IPMs, MMD, and density estimation problems.

## Method Summary
The paper analyzes probability divergences using Fourier expansions in terms of Laplace-Beltrami eigenfunctions on manifolds. For G-invariant measures, the analysis leverages the sparsity induced by invariance to reduce effective dimensionality. The approach involves computing invariant empirical estimators using truncated Fourier series, where the truncation frequency balances bias and variance. The theoretical framework assumes smooth Lie group actions on connected compact smooth manifolds, with convergence rates derived through spectral analysis of the Laplace-Beltrami operator.

## Key Results
- Invariances provide a two-fold gain: multiplicative factor reduction by group size or quotient space volume, and improved convergence rate exponent
- For finite groups, convergence rate scales as vol(M)/(n|G|), effectively making each sample worth |G| samples in non-invariant case
- The convergence rate exponent improves from 1/dim(M) to 1/dim(M/G) where M/G is the quotient space
- Sobolev space assumptions on density lead to faster Fourier coefficient decay, enabling optimal truncation strategies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Invariances improve sample complexity by effectively multiplying the number of samples by a factor related to the group size or quotient space volume
- Mechanism: When a probability measure is invariant under a group action, Fourier coefficients corresponding to non-invariant eigenfunctions are zero. This sparsity reduces effective dimensionality, allowing each sample to provide information equivalent to multiple samples in the non-invariant case
- Core assumption: The probability measure is invariant under the group action, and the group acts smoothly on the manifold
- Evidence anchors:
  - [abstract]: "Our results indicate a two-fold gain: (1) reducing the sample complexity by a multiplicative factor corresponding to the group size (for finite groups) or the normalized volume of the quotient space (for groups of positive dimension)"
  - [section 4.1]: "This could be interpreted as each sample being worth the same as |G|samples under invariances compared to the general (non-invariant) case"
- Break condition: If the measure is not truly invariant under the group action, or if the group action is not smooth, the sparsity argument fails and no sample complexity gain is realized

### Mechanism 2
- Claim: Invariances improve the convergence rate exponent by reducing the effective dimension of the problem
- Mechanism: The dimension of the quotient space M/G is less than or equal to the dimension of M. Since the convergence rate exponent depends on the dimension, using M/G instead of M in the exponent formula leads to faster convergence
- Core assumption: The quotient space M/G has a well-defined dimension that is less than the dimension of M
- Evidence anchors:
  - [abstract]: "The new sample complexity bound shows two different aspects of gain of invariances. First, the quantity κG is observed to be a non-increasing function of the quotient space's dimension d"
  - [section 4.1]: "the new exponent is 1/d with d = dim(M/G), which can be potentially much greater than 1/dim(M)"
- Break condition: If the quotient space M/G does not have a lower dimension than M, or if the convergence rate does not depend on dimension in the claimed way, the exponent improvement does not occur

### Mechanism 3
- Claim: For smooth distributions, the Fourier coefficients decay faster, allowing truncation at a finite frequency that balances bias and variance
- Mechanism: When the density is in a Sobolev space H^s(M), the Fourier coefficients decay as λ^(-s). This allows choosing a truncation frequency T that depends on s, the number of samples n, and the smoothness, optimizing the trade-off between bias and variance
- Core assumption: The density dμ/dx belongs to a Sobolev space H^s(M) for some s ≥ 0
- Evidence anchors:
  - [section 4.2]: "The parameter T indicates when the sum is terminated. Note that estimating the higher-order coefficients in the Fourier basis requires many samples, and so if the Fourier coefficients decay quickly, one can neglect them and truncate the sum at a finite T with a small error"
  - [section 4.1]: "The decay of the Fourier coefficients is provided using the Sobolev space assumption"
- Break condition: If the density is not smooth enough to belong to a Sobolev space, or if the decay rate is not as assumed, the truncation strategy does not work and the improved rate is not achieved

## Foundational Learning

- Concept: Laplace-Beltrami operator and its eigenfunctions on manifolds
  - Why needed here: The paper uses the Fourier expansion in terms of Laplace-Beltrami eigenfunctions to analyze the convergence rates. Understanding this operator and its spectrum is crucial for following the proofs
  - Quick check question: What is the relationship between the eigenvalues of the Laplace-Beltrami operator and the dimension of the manifold?

- Concept: Group actions and invariant functions
  - Why needed here: The paper studies probability measures invariant under group actions. Understanding what it means for a function or measure to be invariant under a group action is essential for grasping the main results
  - Quick check question: If a function f is invariant under a group G, what can you say about its Fourier coefficients corresponding to non-invariant eigenfunctions?

- Concept: Sobolev spaces on manifolds
  - Why needed here: The paper assumes the density belongs to a Sobolev space H^s(M) to get faster convergence rates. Understanding Sobolev spaces and their properties on manifolds is necessary for following the proofs in sections 4.2-4.6
  - Quick check question: How does the smoothness parameter s in H^s(M) affect the decay rate of Fourier coefficients?

## Architecture Onboarding

- Component map: Samples from G-invariant measure -> Fourier coefficient computation -> Truncation at optimal T -> Reconstructed estimated measure
- Critical path:
  1. Verify the measure is G-invariant
  2. Compute the Fourier coefficients of the measure using the samples
  3. Truncate the Fourier series at an optimal frequency T
  4. Reconstruct the estimated measure from the truncated series
- Design tradeoffs:
  - Choosing T too small leads to high bias but low variance
  - Choosing T too large leads to low bias but high variance
  - The optimal T depends on the smoothness of the density, the group action, and the number of samples
- Failure signatures:
  - If the estimated measure is not a valid probability measure (e.g., has negative values), the truncation frequency T may be too small
  - If the convergence rate is much slower than expected, the measure may not be truly invariant under the group action
- First 3 experiments:
  1. Test the algorithm on a simple example like estimating a uniform distribution on a circle under rotation invariance
  2. Vary the smoothness parameter s of the density and observe how the convergence rate changes
  3. Compare the performance of the invariant estimator to a non-invariant estimator on a measure with known invariance properties

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the sample complexity gain scale when the group action is not isometric on the manifold?
- Basis in paper: [inferred] The paper assumes the group action is isometric for simplicity, but does not explore non-isometric cases
- Why unresolved: The isometric assumption simplifies the analysis but may not hold for all practical applications where group actions are not necessarily distance-preserving
- What evidence would resolve it: Analysis of sample complexity bounds for non-isometric group actions on manifolds, comparing convergence rates to the isometric case

### Open Question 2
- Question: What is the optimal trade-off between the group size and the manifold dimension for maximizing the sample complexity gain?
- Basis in paper: [inferred] The paper shows that both group size and quotient space dimension affect the sample complexity, but does not provide a comprehensive analysis of their interplay
- Why unresolved: The relationship between group size and manifold dimension is complex, and there may be regimes where one factor dominates the other in terms of sample complexity gain
- What evidence would resolve it: Theoretical bounds and empirical studies comparing sample complexity gains across different combinations of group sizes and manifold dimensions

### Open Question 3
- Question: How do the sample complexity bounds extend to non-compact manifolds or manifolds with boundary?
- Basis in paper: [explicit] The paper explicitly states that the results can be generalized to manifolds with boundaries but focuses on boundaryless manifolds for simplicity
- Why unresolved: The analysis relies heavily on properties of compact manifolds, and extending the results to non-compact or boundary-containing cases requires addressing new technical challenges
- What evidence would resolve it: Extension of the convergence rate analysis to non-compact manifolds and manifolds with boundary, including any necessary modifications to the proof techniques

### Open Question 4
- Question: Can the sample complexity gains be further improved by incorporating additional structure or assumptions about the probability distributions?
- Basis in paper: [inferred] The paper considers smooth distributions and invariant measures, but does not explore other potential structures that could lead to improved sample complexity
- Why unresolved: There may be other properties of the probability distributions, such as sparsity or low-rank structure, that could be leveraged to achieve better sample complexity bounds
- What evidence would resolve it: Investigation of sample complexity bounds for probability distributions with additional structures, comparing the gains to the current results for smooth and invariant distributions

## Limitations

- Theoretical analysis relies heavily on assumptions about smoothness of group actions and spectral properties of the Laplace-Beltrami operator
- Paper lacks empirical validation of convergence rate bounds and practical implications for real-world applications
- Assumes perfect knowledge of group invariance structure, which may not hold in practical settings

## Confidence

- **High Confidence**: The general framework of using Fourier/Laplace-Beltrami analysis for invariant measures is well-established in the literature. The reduction in effective dimension through quotient spaces is mathematically sound.
- **Medium Confidence**: The specific convergence rate bounds and the two-fold gain mechanism are theoretically derived but lack empirical validation. The assumption that each sample provides information equivalent to |G| samples in the non-invariant case needs experimental verification.
- **Low Confidence**: The practical implications of the results for real-world machine learning applications are not clearly established. The computational complexity of implementing the invariant estimators is not discussed.

## Next Checks

1. **Empirical Convergence Rate Validation**: Implement the invariant estimator for a simple manifold (e.g., sphere with rotation invariance) and compare the empirical convergence rate to the theoretical bounds across different sample sizes and group structures.

2. **Robustness to Invariance Violation**: Test the algorithm's performance when the true measure is only approximately invariant under the group action, quantifying the degradation in convergence rate as a function of the degree of invariance violation.

3. **Computational Complexity Analysis**: Measure the actual computational overhead of implementing the invariant estimator compared to standard non-invariant approaches, particularly for high-dimensional manifolds and large groups, to assess practical feasibility.