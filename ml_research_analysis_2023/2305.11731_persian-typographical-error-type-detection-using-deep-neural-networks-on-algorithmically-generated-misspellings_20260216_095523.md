---
ver: rpa2
title: Persian Typographical Error Type Detection Using Deep Neural Networks on Algorithmically-Generated
  Misspellings
arxiv_id: '2305.11731'
source_url: https://arxiv.org/abs/2305.11731
tags:
- persian
- error
- errors
- typographical
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The authors introduce FarsTypo, a dataset of 3.4 million POS-tagged
  Persian words with algorithmically-generated misspellings, to improve Persian spell-checking.
  They propose a Many-to-Many Deep Sequential Neural Network that combines word and
  character embeddings with bidirectional LSTM layers to perform token classification
  across 51 error types.
---

# Persian Typographical Error Type Detection Using Deep Neural Networks on Algorithmically-Generated Misspellings

## Quick Facts
- **arXiv ID**: 2305.11731
- **Source URL**: https://arxiv.org/abs/2305.11731
- **Reference count**: 10
- **Primary result**: Introduces FarsTypo dataset and achieves 97.62% accuracy in Persian typo detection using deep neural networks

## Executive Summary
This paper addresses the challenge of Persian typographical error detection by introducing FarsTypo, a dataset of 3.4 million POS-tagged Persian words with algorithmically-generated misspellings. The authors develop a Many-to-Many Deep Sequential Neural Network that combines word and character embeddings with bidirectional LSTM layers to perform token classification across 51 error types. Tested on both synthetic and real-world datasets, their approach demonstrates superior performance compared to industrial spell-checkers while maintaining efficient inference speed. The work establishes a strong baseline for future research in Persian spelling error detection.

## Method Summary
The authors propose a Many-to-Many Deep Sequential Neural Network that uses both word and character embeddings processed through bidirectional LSTM layers to classify Persian words into 51 error types. The model is trained on FarsTypo, a dataset containing 3.4 million POS-tagged Persian words with algorithmically-generated misspellings covering 10 general error types broken into detailed classes. The approach employs K-Fold Cross-validation (5 folds) with 60% training, 20% validation, and 20% testing splits. The algorithmically-generated errors include insertion, deletion, substitution, transposition, similarity confusion, repetition, spacing, Persian-to-Arabic conversions, silent letters, and other prevalent errors.

## Key Results
- Achieves 97.62% accuracy, 98.83% precision, and 98.61% recall on 51-class error detection
- Outperforms industrial spell-checkers in both accuracy and speed across multiple test cases
- Demonstrates superior performance on real-world misspellings from Wikipedia, PerspellData, and Shargh test cases
- Establishes FarsTypo as the first large-scale Persian misspelling dataset with POS tags

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Bidirectional LSTM layers improve Persian typo detection by capturing context from both past and future words in a sentence.
- **Mechanism**: The bidirectional architecture processes text in both forward and backward directions, allowing the model to learn contextual dependencies that help distinguish between non-word and real-word errors.
- **Core assumption**: Persian sentence structure contains sufficient sequential dependencies that bidirectional processing can exploit for error detection.
- **Evidence anchors**:
  - [section]: "Our approach to predicting error types is to train a neural network on a parallel dataset of misspelt words and their typographical error types... a Many-to-Many Deep Long Short-Term Memory (LSTM) Neural Network architecture"
  - [section]: "the bidirectionallayersservedrelativelymoreaccurateusingeitherwordorcharacterembeddings"
  - [corpus]: Weak - corpus doesn't directly mention bidirectional architecture
- **Break condition**: If Persian sentences lack strong contextual dependencies between words, bidirectional processing provides minimal benefit over unidirectional.

### Mechanism 2
- **Claim**: Combining word and character embeddings captures both semantic and orthographic information for better error detection.
- **Mechanism**: Word embeddings provide semantic context while character embeddings handle out-of-vocabulary (OOV) words and morphological variations common in Persian.
- **Core assumption**: Persian has significant OOV cases and morphological complexity that character-level processing can address.
- **Evidence anchors**:
  - [section]: "we leverage both word and character embeddings, respectively, to provide better infrastructure for the model to improve performance through updating relevant weights"
  - [section]: "characterembedding,incontrast,hasproventobesuperioratrepresentingOOVwords"
  - [corpus]: Weak - corpus doesn't explicitly discuss embedding combination strategy
- **Break condition**: If the dataset lacks sufficient OOV cases or if character embeddings introduce noise that outweighs their benefits.

### Mechanism 3
- **Claim**: Algorithmically-generated synthetic errors with controlled randomness improves model generalization compared to rule-based methods.
- **Mechanism**: The error generation algorithm applies Persian-specific error types with controlled randomness rather than purely random mutations, creating more realistic training examples.
- **Core assumption**: Persian-specific error patterns can be systematically generated to approximate real user mistakes.
- **Evidence anchors**:
  - [section]: "Unlike most prior studies, which mainly focused on random character inserting, deletion, substitution, or transposition, this study also examines errortypes commontoPersian writers"
  - [section]: "The algorithm is designed to mimic the randomness of making a typographical error, but this uncertainty can also have negative consequences"
  - [corpus]: Weak - corpus doesn't discuss error generation methodology in detail
- **Break condition**: If synthetic errors don't capture the true distribution of user errors, model performance on real data will suffer.

## Foundational Learning

- **Concept**: Bidirectional Recurrent Neural Networks
  - **Why needed here**: Persian typo detection requires understanding context from both directions to distinguish between non-word and real-word errors
  - **Quick check question**: How does a bidirectional RNN process information differently from a standard RNN, and why is this beneficial for typo detection?

- **Concept**: Character-level embeddings for OOV handling
  - **Why needed here**: Persian has complex morphology and many OOV cases that standard word embeddings cannot represent effectively
  - **Quick check question**: What are the advantages of character-level embeddings over word embeddings when dealing with morphologically rich languages?

- **Concept**: Token classification with softmax
  - **Why needed here**: The task requires classifying each word into one of 51 error type categories, making token classification the appropriate framework
  - **Quick check question**: How does token classification differ from sequence labeling, and why is softmax activation suitable for this 51-class problem?

## Architecture Onboarding

- **Component map**: Input layer → Word embedding layer → Character embedding layer → Bidirectional LSTM layers → TimeDistributed Dense layer → Output layer
- **Critical path**: Embedding layers → Bidirectional LSTM → TimeDistributed Dense → Softmax output
- **Design tradeoffs**:
  - Bidirectional vs unidirectional: Bidirectional provides better context but doubles computation
  - Word vs character embeddings: Word embeddings capture semantics but fail on OOV; character embeddings handle OOV but lose semantic information
  - Algorithmically-generated vs human-labeled errors: Synthetic data is scalable but may not capture all real error patterns
- **Failure signatures**:
  - High accuracy on training but poor on test: Overfitting to synthetic error patterns
  - Poor performance on OOV words: Insufficient character embedding training or representation
  - Slow inference: Bidirectional layers or large embedding dimensions
- **First 3 experiments**:
  1. Test unidirectional vs bidirectional LSTM to measure context impact
  2. Test word-only vs character-only vs combined embeddings to evaluate representation benefits
  3. Test different error generation rates (s parameter) to find optimal synthetic data balance

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How would the model's performance change if the maximum number of allowed errors per word (m) in the error generation algorithm was increased beyond 2?
- **Basis in paper**: [explicit] The paper states "the utmost two typos are made by users per word, where more errors will draw the writer's attention and later be corrected. Hence, we apply either one or a combination of two errors to a given word."
- **Why unresolved**: The paper only tests with a maximum of 2 errors per word based on assumed user behavior patterns. Testing with higher values (3, 4, etc.) could reveal whether the model generalizes better or worse with more complex misspellings.
- **What evidence would resolve it**: Experimental results showing accuracy, precision, and recall scores when training the model on datasets generated with m=3, m=4, and higher values, compared to the current m=2 baseline.

### Open Question 2
- **Question**: Would incorporating contextual information from surrounding sentences (beyond just the current sentence) improve the model's ability to detect real-word errors?
- **Basis in paper**: [inferred] The paper mentions that bidirectional LSTM layers process "textual information from the past and future of a timeframe through both forward and backward processing," but only within the current sentence. The discussion notes that real-word errors require sentence-level processing, suggesting broader context might help.
- **Why unresolved**: The current architecture only considers the current sentence for context, but real-word errors often depend on broader discourse context. The paper doesn't explore whether expanding the context window to multiple sentences would improve performance.
- **What evidence would resolve it**: Comparative results showing whether a model trained with multi-sentence context windows outperforms the current single-sentence approach on real-word error detection tasks.

### Open Question 3
- **Question**: How would the model's performance be affected if the dataset included more diverse error types beyond the 50 classes currently implemented?
- **Basis in paper**: [explicit] The paper mentions "certain combinations of two error types cannot be applied correspondingly to a word" and notes there "could have been more classes designed." It also lists "other prevalent errors" that weren't fully incorporated.
- **Why unresolved**: The current dataset excludes some error combinations and certain prevalent error types due to algorithmic limitations. The paper doesn't test whether including these additional error types would improve overall error detection capability.
- **What evidence would resolve it**: Performance metrics (accuracy, precision, recall) from models trained on expanded datasets that include the currently excluded error combinations and additional prevalent error types, compared to the current 50-class model.

## Limitations

- The dataset relies entirely on algorithmically-generated synthetic errors, which may not fully capture the complexity and diversity of real-world Persian typographical errors.
- The evaluation focuses heavily on accuracy, precision, and recall metrics without deeper error analysis showing which specific error types the model struggles with most.
- The comparison with industrial spell-checkers is limited to three test cases, which may not represent the full spectrum of real-world usage scenarios.

## Confidence

- **High Confidence**: The architectural claims about bidirectional LSTM layers improving context capture and the combination of word and character embeddings handling both semantic and morphological information.
- **Medium Confidence**: The claim that algorithmically-generated errors with controlled randomness provides better generalization than rule-based methods.
- **Low Confidence**: The performance superiority over industrial spell-checkers, as the comparison is based on only three test cases.

## Next Checks

1. **Error Distribution Analysis**: Conduct a detailed analysis of model performance across the 51 error types to identify specific weaknesses and patterns in misclassification, particularly focusing on the most common Persian error types.

2. **Real-World Error Testing**: Evaluate the model on a diverse set of human-annotated Persian errors from multiple domains (social media, news articles, academic texts) to assess generalization beyond algorithmically-generated synthetic errors.

3. **Ablation Study**: Perform systematic ablation testing by removing each major component (bidirectional layers, character embeddings, word embeddings) individually to quantify their specific contributions to the final performance metrics.