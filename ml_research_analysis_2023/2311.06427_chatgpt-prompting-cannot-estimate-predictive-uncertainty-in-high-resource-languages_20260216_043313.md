---
ver: rpa2
title: ChatGPT Prompting Cannot Estimate Predictive Uncertainty in High-Resource Languages
arxiv_id: '2311.06427'
source_url: https://arxiv.org/abs/2311.06427
tags:
- chatgpt
- languages
- confidence
- accuracy
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies whether ChatGPT is equally accurate across high-resource
  languages and whether it gives reliable confidence estimates. The authors prompt
  ChatGPT to perform sentiment analysis and common sense reasoning in English, French,
  Italian, Spanish, and German, and to provide a confidence score for each answer.
---

# ChatGPT Prompting Cannot Estimate Predictive Uncertainty in High-Resource Languages

## Quick Facts
- arXiv ID: 2311.06427
- Source URL: https://arxiv.org/abs/2311.06427
- Reference count: 29
- ChatGPT's confidence estimates are poorly calibrated and never give low confidence values, despite similar accuracy across high-resource languages.

## Executive Summary
This paper investigates whether ChatGPT performs equally well across high-resource languages (English, French, Italian, Spanish, German) and whether its confidence estimates are reliable. The authors evaluate ChatGPT on sentiment analysis and common sense reasoning tasks, finding that accuracy is similar across all languages with no significant differences. However, ChatGPT's confidence estimates are poorly calibrated, typically overconfident by 10-16%, and never produce confidence values below 50%. The study concludes that while ChatGPT performs equally well across high-resource languages, its confidence estimates cannot be trusted for uncertainty quantification.

## Method Summary
The authors prompt ChatGPT to perform sentiment analysis and common sense reasoning in five high-resource languages, collecting confidence scores for each response. They use the UMSAB dataset for sentiment analysis and the XCSR dataset for common sense reasoning, sampling 50 examples per task per language. Confidence calibration is evaluated using Expected Calibration Error (ECE) and Maximum Calibration Error (MCE), while accuracy differences across languages are tested using chi-squared tests. The study relies on ChatGPT's internal confidence estimates rather than external calibration methods.

## Key Results
- ChatGPT accuracy is statistically similar across all five tested high-resource languages for both sentiment analysis and common sense reasoning.
- ChatGPT exhibits poor confidence calibration with ECE values around 13% across all languages, ranging from 10% (German) to 16% (French).
- ChatGPT's confidence scores are bounded below at 50%, never producing confidence values below this threshold.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** ChatGPT's multilingual performance across high-resource languages is approximately equal.
- **Mechanism:** ChatGPT's training data likely contains enough content in each high-resource language to achieve comparable performance.
- **Core assumption:** The quality and representativeness of training data for each language is sufficient for high-resource languages to perform similarly.
- **Evidence anchors:**
  - [abstract] "The results show that all the selected high-resource languages perform similarly..."
  - [section] "A chi-squared test of independence was performed... The test showed no significant association between the two variables..."
  - [corpus] Weak - no direct citation to training data composition.
- **Break condition:** If any high-resource language's training data is significantly less representative or of lower quality.

### Mechanism 2
- **Claim:** ChatGPT provides poor confidence calibration across languages.
- **Mechanism:** ChatGPT's internal confidence estimation mechanism is uncalibrated, producing overconfident estimates regardless of language or task.
- **Core assumption:** ChatGPT's confidence estimates are not grounded in actual prediction accuracy.
- **Evidence anchors:**
  - [abstract] "ChatGPT does not have a good confidence calibration, often being overconfident and never giving low confidence values."
  - [section] "The ECE shows similar results across all languages, at around 13, with German having the lowest (10) and French having the highest (16)."
  - [corpus] Weak - no citation of internal confidence modeling architecture.
- **Break condition:** If confidence calibration improves through model updates or different prompting strategies.

### Mechanism 3
- **Claim:** ChatGPT's confidence range is artificially bounded, never dropping below 50%.
- **Mechanism:** The model's confidence generation mechanism has a lower bound that prevents very low confidence values, possibly due to architectural constraints or fine-tuning objectives.
- **Core assumption:** The model's confidence output is constrained by its training or architecture.
- **Evidence anchors:**
  - [abstract] "ChatGPT does not have a good confidence calibration, often being overconfident and never giving low confidence values."
  - [section] "ChatGPT never gave a confidence value below 50%."
  - [corpus] Weak - no citation of architectural constraints on confidence outputs.
- **Break condition:** If the model is updated to allow lower confidence ranges or if alternative prompting strategies elicit lower confidence values.

## Foundational Learning

- **Concept: Calibration in machine learning**
  - Why needed here: Understanding calibration is crucial to interpreting the paper's findings on confidence estimates and their accuracy.
  - Quick check question: If a model is perfectly calibrated, what should the relationship be between its confidence scores and actual accuracy?

- **Concept: High-resource vs. low-resource languages**
  - Why needed here: The paper compares performance across languages with varying amounts of available training data, making this distinction critical.
  - Quick check question: What is the typical threshold used to classify a language as "high-resource" in NLP?

- **Concept: Sentiment analysis and common sense reasoning tasks**
  - Why needed here: These are the two NLP tasks used to evaluate ChatGPT's performance and confidence across languages.
  - Quick check question: What are the typical output categories for a sentiment analysis task?

## Architecture Onboarding

- **Component map:**
  - Prompt engineering and translation
  - Data preprocessing and sampling
  - ChatGPT interaction and response collection
  - Confidence calibration metrics (ECE, MCE)
  - Statistical analysis (chi-squared tests)

- **Critical path:**
  1. Define prompts for each task and language
  2. Preprocess and sample datasets
  3. Collect responses from ChatGPT
  4. Calculate accuracy and confidence metrics
  5. Perform statistical tests and calibration analysis

- **Design tradeoffs:**
  - Manual data collection vs. API usage (time vs. control)
  - Small sample size for manageability vs. statistical power
  - Translated prompts for fairness vs. potential quality issues

- **Failure signatures:**
  - Inconsistent responses across repeated queries
  - Language-specific performance drops not explained by data volume
  - Unusually high or low confidence values compared to accuracy

- **First 3 experiments:**
  1. Repeat the same prompts multiple times to assess response consistency
  2. Test the effect of different prompt formulations on confidence calibration
  3. Compare ChatGPT's performance to fine-tuned models on the same tasks and languages

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does ChatGPT's poor confidence calibration generalize to other high-resource languages not tested in this study?
- Basis in paper: [explicit] The authors conclude that ChatGPT is equally accurate in high-resource languages but its confidence estimates are unreliable. They tested five high-resource languages but did not test all high-resource languages.
- Why unresolved: The study only tested five high-resource languages. There are many other high-resource languages that could have different calibration properties.
- What evidence would resolve it: Testing ChatGPT's confidence calibration in additional high-resource languages like Portuguese, Dutch, Russian, Japanese, etc. and comparing the results to the languages tested in this study.

### Open Question 2
- Question: How does ChatGPT's confidence calibration compare to other large language models like GPT-4, Claude, etc.?
- Basis in paper: [inferred] The authors conclude that ChatGPT has poor confidence calibration, but do not compare it to other models. The study of ChatGPT's confidence calibration has not been carried out before.
- Why unresolved: This study only examined ChatGPT. Other large language models may have better or worse confidence calibration.
- What evidence would resolve it: Conducting similar confidence calibration experiments on other large language models and comparing the results to ChatGPT's performance.

### Open Question 3
- Question: What is the underlying cause of ChatGPT's poor confidence calibration?
- Basis in paper: [inferred] The authors observe that ChatGPT is often overconfident and never gives low confidence values, but do not investigate the cause. The study of ChatGPT's confidence calibration has not been carried out before.
- Why unresolved: The study identifies the problem but does not explore its root cause. It could be due to the model architecture, training data, fine-tuning process, etc.
- What evidence would resolve it: Analyzing ChatGPT's internal representations, training process, and architecture to identify factors that may contribute to poor confidence calibration. Comparing to models with better calibration could also provide insights.

## Limitations

- The study's scope is limited to only five high-resource languages, making it difficult to generalize findings across the broader landscape of high-resource languages.
- The datasets used (UMSAB and XCSR) represent specific domains, so findings may not extend to other NLP tasks.
- The statistical analysis uses relatively small sample sizes per language (50 examples per task per language), which may limit the power to detect subtle differences in performance.

## Confidence

**High Confidence:**
- ChatGPT's accuracy is statistically similar across the five tested high-resource languages for both sentiment analysis and common sense reasoning tasks.
- ChatGPT exhibits poor calibration in its confidence estimates, with ECE values around 13% across all languages.
- ChatGPT's confidence scores are bounded below at 50%, never producing lower confidence values.

**Medium Confidence:**
- The lack of significant accuracy differences across languages indicates that ChatGPT's performance is equally good in high-resource languages.
- The consistent calibration errors across languages suggest a fundamental issue with ChatGPT's confidence estimation mechanism rather than language-specific problems.

## Next Checks

1. **Cross-task generalization**: Test ChatGPT's confidence calibration across additional NLP tasks (e.g., named entity recognition, question answering) to determine if the bounded confidence phenomenon persists across different task types.

2. **Language diversity validation**: Include additional high-resource languages (e.g., Portuguese, Dutch, Russian) to verify whether the observed pattern of equal accuracy and poor calibration holds across a broader set of high-resource languages.

3. **Alternative confidence elicitation**: Experiment with different prompting strategies (e.g., asking for confidence ranges instead of point estimates, using calibration datasets) to determine if the bounded confidence issue can be mitigated through prompt engineering.