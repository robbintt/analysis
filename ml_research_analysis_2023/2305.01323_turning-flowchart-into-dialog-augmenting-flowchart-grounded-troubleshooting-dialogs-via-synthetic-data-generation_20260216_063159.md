---
ver: rpa2
title: 'Turning Flowchart into Dialog: Augmenting Flowchart-grounded Troubleshooting
  Dialogs via Synthetic Data Generation'
arxiv_id: '2305.01323'
source_url: https://arxiv.org/abs/2305.01323
tags:
- dialogue
- data
- planda
- owchart
- path
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of scarce training data for flowchart-grounded
  troubleshooting dialogue (FTD) systems by proposing a plan-based synthetic data
  generation approach called PlanDA. PlanDA generates diverse synthetic dialogue data
  at scale by transforming concise flowcharts into dialogues using a variational-based
  framework with hierarchical planning strategies, including global and local latent
  planning variables.
---

# Turning Flowchart into Dialog: Augmenting Flowchart-grounded Troubleshooting Dialogs via Synthetic Data Generation

## Quick Facts
- arXiv ID: 2305.01323
- Source URL: https://arxiv.org/abs/2305.01323
- Reference count: 24
- The paper proposes PlanDA, a plan-based synthetic data generation approach for augmenting flowchart-grounded troubleshooting dialogue systems, showing significant improvements in downstream task performance.

## Executive Summary
This paper addresses the challenge of scarce training data for flowchart-grounded troubleshooting dialogue (FTD) systems by proposing PlanDA, a plan-based synthetic data generation approach. PlanDA generates diverse synthetic dialogue data at scale by transforming concise flowcharts into dialogues using a variational-based framework with hierarchical planning strategies, including global and local latent planning variables. Experiments on the FloDial dataset demonstrate that synthetic dialogues produced by PlanDA improve the performance of downstream tasks, including flowchart path retrieval and response generation, particularly in Out-of-Flowchart settings.

## Method Summary
PlanDA is a plan-based synthetic data generation approach that uses a variational-based framework with hierarchical planning. It employs global latent variables to model dialogue acts and local latent variables to control utterance diversity. The model is initialized from BART-large and fine-tuned using a KL thresholding strategy. Synthetic dialogues are generated by sampling from the trained PlanDA model and used to augment the original training data, improving downstream FTD model performance.

## Key Results
- PlanDA outperforms strong baseline models (GPT-2, BART, DialoGPT, BlenderBot) in downstream metrics
- The ablation of local planning variable leads to more performance degradation than the ablation of global
- Synthetic dialogue produced by PlanDA improves performance of downstream tasks, especially for uncovered paths in the flowchart

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Latent dialogue act variables improve semantic coherence of synthetic dialogues
- Mechanism: The global latent variable z_a_i models the dialogue act sequence, providing a high-level sketch of the conversation structure
- Core assumption: Dialogue acts capture the functional intent of utterances and can guide generation toward coherent conversations
- Evidence anchors:
  - [abstract] "global latent variables are responsible for modeling the dialogue acts between the dialogue turns, providing a high-level sketch"
  - [section 2.3] "we employ intermediate latent variables in PlanDA. Dialogue acts are an intuitive choice to characterize these variables, as they describe the basic function of a dialogue turn/utterance"
  - [corpus] No direct corpus evidence; this is a design choice based on dialogue act theory
- Break condition: If dialogue acts don't align with actual conversation functions or if the latent space doesn't capture meaningful act transitions

### Mechanism 2
- Claim: Local latent variables enable lexical diversity while maintaining faithfulness to flowchart content
- Mechanism: The local latent variable z_y_i,j controls utterance diversity at the token level, conditioned on the global act and flowchart path
- Core assumption: There exists a distribution of valid utterances for each (act, path) combination that maintains both diversity and relevance
- Evidence anchors:
  - [abstract] "local latent variables control the diversity of generated synthetic dialogues during sentence realization"
  - [section 2.3] "local latent variables zy_ij, responsible for generating lexically diverse utterances for each turn"
  - [corpus] "synthetic dialogue produced by PlanDA improves the performance of downstream tasks" suggests the diversity doesn't harm downstream utility
- Break condition: If the local variable space collapses to a single mode or generates utterances that violate the flowchart logic

### Mechanism 3
- Claim: The hierarchical planning structure (global + local) outperforms flat or single-level generation approaches
- Mechanism: The combination of dialogue act planning (global) and utterance realization (local) creates a two-stage generation process that separates structure from surface form
- Core assumption: Separating high-level intent from low-level lexical choice improves both quality and diversity compared to end-to-end generation
- Evidence anchors:
  - [section 3.2] "the ablation of local planning variable leads to more performance degradation than the ablation of global" shows both levels matter
  - [table 1] "PlanDA outperforms strong baseline models (GPT-2, BART, DialoGPT, BlenderBot)" in downstream metrics
  - [corpus] Limited evidence; comparisons are against synthetic data rather than real human conversations
- Break condition: If the hierarchical structure introduces artifacts or if the two levels become too tightly coupled to separate

## Foundational Learning

- Concept: Variational Autoencoders (VAEs) and evidence lower bound (ELBO) optimization
  - Why needed here: PlanDA uses VAE-style latent variable modeling with ELBO as the training objective to handle the integration over latent variables
  - Quick check question: What is the ELBO and why do we maximize it instead of the full likelihood when training models with latent variables?

- Concept: Dialogue act taxonomy and function
  - Why needed here: The model assumes dialogue acts are meaningful functional labels that can guide conversation generation
  - Quick check question: What are the seven dialogue acts used in this paper and what functional role does each serve in troubleshooting conversations?

- Concept: Flowchart structure and path extraction
  - Why needed here: The input to PlanDA is a flowchart path, and understanding how decision and action nodes connect is critical for generating valid dialogues
  - Quick check question: In the flowcharts used here, what distinguishes decision nodes from action nodes and how do they connect in a valid path?

## Architecture Onboarding

- Component map: Flowchart path extractor -> Global latent planner -> Local latent planner -> Hierarchical encoder-decoder -> Training loop
- Critical path:
  1. Extract flowchart path
  2. Encode path to obtain h_x_i
  3. Sample global latent z_a_i ~ p(z_a|path)
  4. Autoregressively generate dialogue acts a_i
  5. For each act, sample local latent z_y_i,j ~ p(z_y|path, act)
  6. Generate utterance y_i,j conditioned on (h_x_i, a_i, z_y_i,j)

- Design tradeoffs:
  - Hierarchical vs. flat generation: Hierarchical allows separation of structure from surface form but adds complexity
  - Fixed dialogue act set vs. learned acts: Fixed set provides interpretability but may miss nuances
  - Pre-trained initialization vs. from-scratch: Pre-training speeds convergence but may introduce domain bias

- Failure signatures:
  - Repetitive or degenerate utterances: May indicate local latent space collapse
  - Disconnected dialogue acts: May indicate poor global planning or incorrect act taxonomy
  - Faithful to flowchart but unnatural conversations: May indicate over-reliance on path structure vs. natural dialogue flow

- First 3 experiments:
  1. Generate synthetic dialogues for a simple 2-node flowchart path and inspect the dialogue acts and utterances manually
  2. Train with only global latent variable (remove local) and compare diversity metrics (Distinct-2/3) to full model
  3. Train with synthetic data augmentation on a small subset of FloDial and measure downstream task improvement on in-flowchart setting

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of PlanDA vary with different sizes of the training dataset for generating synthetic dialogues?
- Basis in paper: [explicit] The paper mentions that PlanDA's performance improves with the size of synthetic data used for augmentation, but does not provide a detailed analysis of how performance scales with training data size.
- Why unresolved: The paper does not provide a comprehensive analysis of how PlanDA's performance changes with varying sizes of the training dataset.
- What evidence would resolve it: Conducting experiments with different sizes of training datasets and analyzing the corresponding performance of PlanDA would provide insights into its scalability and effectiveness.

### Open Question 2
- Question: How does PlanDA handle the generation of synthetic dialogues for complex, multi-turn interactions that are not well-represented in the training data?
- Basis in paper: [inferred] The paper discusses PlanDA's ability to generate diverse synthetic dialogues but does not explicitly address its performance in handling complex, multi-turn interactions.
- Why unresolved: The paper does not provide specific examples or metrics related to the generation of complex dialogues.
- What evidence would resolve it: Evaluating PlanDA's performance on complex, multi-turn dialogues that are underrepresented in the training data would demonstrate its capability to handle such scenarios.

### Open Question 3
- Question: What are the potential limitations of using dialogue acts as global latent variables in PlanDA, and how might these limitations affect the quality of generated synthetic dialogues?
- Basis in paper: [explicit] The paper introduces dialogue acts as global latent variables but does not discuss potential limitations or their impact on dialogue quality.
- Why unresolved: The paper does not explore the constraints or challenges associated with using dialogue acts as global latent variables.
- What evidence would resolve it: Analyzing cases where dialogue acts might not capture the full complexity of user intentions or where they lead to repetitive or unnatural dialogues would highlight potential limitations.

## Limitations
- The dialogue act taxonomy is manually defined and may not capture all functional nuances in troubleshooting conversations
- The assumption that global and local latent variables can be meaningfully separated may not hold for all dialogue types
- The method's performance on complex, multi-branch flowcharts is not thoroughly evaluated

## Confidence

**High Confidence**: The experimental results showing PlanDA's superior performance on downstream tasks (BLEU, R@1, R@5 metrics) are well-supported by the data. The ablation studies demonstrating the importance of both global and local latent variables are convincing.

**Medium Confidence**: The claim that hierarchical planning outperforms flat generation approaches is supported by comparisons to baselines but lacks direct comparison to other hierarchical methods. The assertion that latent dialogue acts improve semantic coherence is reasonable given the design but not definitively proven.

**Low Confidence**: The scalability claims regarding "large-scale" synthetic data generation are not quantified. The paper doesn't provide concrete numbers on generation speed or the actual volume of synthetic data produced relative to real data.

## Next Checks

1. **Human Evaluation**: Conduct a human study comparing PlanDA-generated dialogues with real dialogues and other synthetic generation methods on fluency, coherence, and troubleshooting effectiveness metrics.

2. **Cross-Domain Transfer**: Test PlanDA on flowcharts from domains not represented in FloDial to assess generalization beyond the vehicle and laptop domains.

3. **Latent Space Analysis**: Visualize and analyze the learned global and local latent spaces to verify they capture meaningful dialogue act transitions and utterance diversity rather than memorizing training patterns.