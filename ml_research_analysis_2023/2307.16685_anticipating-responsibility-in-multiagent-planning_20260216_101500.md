---
ver: rpa2
title: Anticipating Responsibility in Multiagent Planning
arxiv_id: '2307.16685'
source_url: https://arxiv.org/abs/2307.16685
tags:
- responsibility
- plan
- agent
- some
- agents
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces the concept of responsibility anticipation
  in multi-agent planning, where agents aim to anticipate whether their actions may
  lead to them being responsible for a particular outcome. The authors define several
  notions of causal and agentive responsibility (active, passive, and contributive)
  and show how these can be used to anticipate responsibility.
---

# Anticipating Responsibility in Multiagent Planning

## Quick Facts
- arXiv ID: 2307.16685
- Source URL: https://arxiv.org/abs/2307.16685
- Reference count: 40
- Key outcome: Introduces responsibility anticipation in multi-agent planning with formal definitions and complexity analysis

## Executive Summary
This paper presents a formal framework for reasoning about responsibility in multi-agent planning, introducing the concept of responsibility anticipation where agents can anticipate whether their actions may lead to them being responsible for particular outcomes. The authors define four types of responsibility (active, passive, contributive, and active attributable responsibility) and show how these can be used to anticipate responsibility in multi-agent planning scenarios. They prove that minimizing anticipated responsibility for negative outcomes can enable coordination without communication, and analyze the computational complexity of determining different types of responsibility attribution and anticipation.

## Method Summary
The method involves defining a planning domain with agents, actions, propositions, and an action theory, then using LTLf formulas to specify outcomes. Responsibility attribution and anticipation problems are solved by checking if an agent could have acted differently to avoid the outcome. The paper outlines how to implement this using PDDL solvers, translating responsibility problems into PDDL format. The approach handles partial information about initial states through epistemic equivalence sets, allowing agents to reason about responsibility without full knowledge of the current state.

## Key Results
- Proved that minimizing anticipated causal passive responsibility enables coordination without communication
- Established complexity hierarchy: CPR anticipation is NP-complete while CAR anticipation is in Δ²P
- Demonstrated implementation approach using PDDL solvers
- Showed that responsibility anticipation can be used for multi-agent planning with partial information

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Anticipating responsibility allows agents to coordinate without communication.
- Mechanism: By minimizing anticipated causal passive responsibility for negative outcomes, agents can ensure a shared goal is achieved even when no single agent can guarantee success alone.
- Core assumption: Agents have partial information about initial states but full knowledge of the action theory and possible actions of others.
- Evidence anchors:
  - [abstract]: "minimizing anticipated responsibility for negative outcomes can help agents coordinate and achieve shared goals even without communication"
  - [section 4.4]: "We prove that there is always a plan that does not anticipate AAR for ¬φ. This means that artificial agents can be formally verified to never be potentially actively responsible for the violation of some value."

### Mechanism 2
- Claim: Different types of responsibility anticipation have varying computational complexity.
- Mechanism: The paper shows that CPR anticipation is NP-complete while CAR anticipation is in Δ²P, providing a complexity hierarchy for responsibility attribution and anticipation problems.
- Core assumption: The planning domain uses LTLf for specifying outcomes and has partial information about initial states.
- Evidence anchors:
  - [section 5.2]: "Theorem 6. CAR-ATTRIBUTION is a member of P^NP[2], CPR-ATTRIBUTION is NP-Complete, CCR-ATTRIBUTION is a member of ΣP² and AAR-ATTRIBUTION is a member of ΔP²."
  - [section 5.2]: "Theorem 7. CAR-ANTICIPATION is a member of Δ²p, CPR-ANTICIPATION is NP-Complete, CCR-ANTICIPATION is NP-Complete, and AAR-ANTICIPATION is a member ofΔP²."

### Mechanism 3
- Claim: The model can be implemented using PDDL solvers for practical applications.
- Mechanism: The paper outlines how to reduce responsibility attribution and anticipation problems to PDDL, demonstrating that pre-existing planning solvers can be applied to these problems.
- Core assumption: The multi-agent extension of PDDL 3.1 proposed by Kovacs can express the required temporal and multi-agent features.
- Evidence anchors:
  - [section 5.1]: "we outline how our model can be implemented in the multi-agent extension of PDDL 3.1 proposed by Kovacs [15]."
  - [section 5.1]: "Running the first problem checks if ω actually occurs, the second problem fixes the actions of all agents besides A1 and checks if A1 could have acted differently and avoided ω."

## Foundational Learning

- Concept: Linear Temporal Logic over Finite Traces (LTLf)
  - Why needed here: LTLf is used to specify the outcomes that agents are responsible for or aim to achieve/avoid.
  - Quick check question: What is the difference between LTLf and standard LTL, and why is LTLf more appropriate for this planning model?

- Concept: Multi-agent planning with partial information
  - Why needed here: Agents must reason about their responsibility when they don't know the initial state or others' actions.
  - Quick check question: How does the epistemic equivalence set model differ from other approaches to modeling partial information in multi-agent planning?

- Concept: Complexity classes (P, NP, ΣP², ΔP²)
  - Why needed here: Understanding the computational complexity of different responsibility attribution and anticipation problems is crucial for practical implementation.
  - Quick check question: What is the difference between NP-complete and ΣP² problems, and why does this distinction matter for responsibility anticipation?

## Architecture Onboarding

- Component map: Planning Domain -> Responsibility Attribution Module -> Responsibility Anticipation Module -> PDDL Interface -> Complexity Analyzer
- Critical path:
  1. Define planning domain (agents, actions, propositions, action theory)
  2. Specify outcomes using LTLf formulas
  3. Implement responsibility attribution algorithms
  4. Implement responsibility anticipation algorithms
  5. Integrate with PDDL solvers
  6. Test with example domains

- Design tradeoffs:
  - Expressiveness vs. tractability: LTLf provides rich expressiveness but increases computational complexity
  - Partial information vs. coordination: Limited information enables anticipation-based coordination but complicates planning
  - Modular vs. integrated responsibility types: Separate anticipation definitions for each responsibility type vs. unified approach

- Failure signatures:
  - Inability to find responsibility anticipation plans: May indicate overly restrictive action theory or LTLf formulas
  - Excessive computation time: May suggest need for approximation algorithms or problem decomposition
  - Incorrect responsibility attribution: May indicate bugs in the action theory or LTLf formula evaluation

- First 3 experiments:
  1. Implement the "Crossing a Junction" example from the paper and verify responsibility attribution results
  2. Test responsibility anticipation in a simple multi-agent domain where coordination without communication is possible
  3. Measure computation times for different responsibility problems on domains of increasing size to validate complexity claims

## Open Questions the Paper Calls Out

- How can we extend the model to handle beliefs about the likely actions of other agents, as in Lorini's work?
- Can we develop a more efficient algorithm for computing CCR anticipation that doesn't require checking all coalitions exponentially?
- How can we extend the model to allow plan comparison based on anticipated responsibility for multiple different outcomes?

## Limitations

- The paper's complexity claims are theoretically proven but lack empirical validation across diverse planning domains
- Implementation details for CCR anticipation are noted as computationally demanding but no practical approximations or optimizations are discussed
- The PDDL implementation assumes compatibility with the multi-agent extension of PDDL 3.1, but this compatibility is not fully verified for all temporal features of LTLf

## Confidence

- **High Confidence**: The theoretical framework for responsibility attribution and anticipation is well-defined and logically consistent. The complexity results are formally proven.
- **Medium Confidence**: The claim that minimizing anticipated responsibility enables coordination without communication is supported by proofs but not extensively tested in practical scenarios.
- **Low Confidence**: The practical implementation using PDDL solvers and the computational feasibility for large-scale domains are not empirically validated.

## Next Checks

1. **Empirical Complexity Validation**: Test the computational complexity of different responsibility anticipation problems across planning domains of increasing size to empirically validate the theoretical complexity claims.

2. **PDDL Implementation Verification**: Implement the responsibility anticipation model using PDDL solvers and verify that the solvers can handle the required temporal operators and epistemic equivalence sets for realistic scenarios.

3. **Coordination Performance Evaluation**: Design a multi-agent planning task where agents must coordinate without communication and measure whether minimizing anticipated responsibility actually leads to successful coordination in practice.