---
ver: rpa2
title: 'XAI-CLASS: Explanation-Enhanced Text Classification with Extremely Weak Supervision'
arxiv_id: '2311.00189'
source_url: https://arxiv.org/abs/2311.00189
tags:
- text
- classification
- lass
- xai-c
- methods
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces XAI-CLASS, a novel explanation-enhanced extremely
  weakly-supervised text classification method that incorporates word saliency prediction
  as an auxiliary task. The proposed method employs a multi-round question-answering
  process to generate pseudo-training data and trains a multi-task framework that
  simultaneously learns both text classification and word saliency prediction.
---

# XAI-CLASS: Explanation-Enhanced Text Classification with Extremely Weak Supervision

## Quick Facts
- arXiv ID: 2311.00189
- Source URL: https://arxiv.org/abs/2311.00189
- Reference count: 14
- Key outcome: Achieves Micro-F1 scores of 0.8820, 0.7529, and 0.8395 on AGNews, 20Newsgroup, and UCINews datasets respectively

## Executive Summary
XAI-CLASS introduces a novel approach to extremely weakly-supervised text classification that enhances both performance and explainability through iterative mutual enhancement between classification and saliency prediction. The method operates under the most minimal supervision setting - using only class names without requiring them to appear in documents or having any keyword vocabularies. By leveraging pre-trained language models in a multi-round question-answering process, XAI-CLASS generates high-quality pseudo-training data while simultaneously learning to identify salient words that explain classification decisions. This dual objective framework addresses the common trade-off between classification accuracy and model interpretability in weakly-supervised settings.

## Method Summary
XAI-CLASS employs a multi-round question-answering process where two pre-trained language models iteratively refine each other's outputs - one generating class labels and another identifying salient tokens. The method uses a multi-task learning framework with a shared BERT backbone that jointly optimizes text classification and word saliency prediction. Saliency is predicted using attention weights from the last layer, creating intrinsic explanations during training rather than post-hoc. The approach requires no keyword vocabularies or pre-existing label-word mappings, making it suitable for scenarios with minimal supervision.

## Key Results
- Outperforms existing weakly-supervised text classification methods on multiple datasets (AGNews, 20Newsgroup, UCINews, IMDB, Twitter, MIMIC-III)
- Achieves Micro-F1 scores of 0.8820, 0.7529, and 0.8395 on AGNews, 20Newsgroup, and UCINews respectively
- Demonstrates improved explainability through attention-based saliency prediction that captures meaningful word importance during training

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative mutual enhancement between text classification and saliency prediction improves pseudo-label quality over single-round generation.
- Mechanism: The model alternates between querying a text classification PLM (T_C) for class labels and a saliency PLM (T_E) for salient tokens. Each round uses the other's output as additional input, creating a feedback loop that refines both predictions until convergence.
- Core assumption: PLMs can effectively use each other's outputs as meaningful input features for refinement.
- Evidence anchors:
  - [abstract]: "XAI-C LASS begins by employing a multi-round question-answering process to generate pseudo-training data that promotes the mutual enhancement of class labels and corresponding explanation word generation."
  - [section]: "We repeat equations 4 and 2, respectively, to ensure high confidence in both T_C and T_E predictions, i.e., the predictions from both PLMs do not further change after one round."
  - [corpus]: Weak evidence - corpus shows related work on "Mutually-Enhancing Text Granularities" but doesn't directly validate this specific mechanism.
- Break condition: When T_C and T_E predictions stop changing between rounds, indicating convergence.

### Mechanism 2
- Claim: Multi-task learning with attention-based saliency prediction provides intrinsic explainability beyond post-hoc methods.
- Mechanism: The model jointly optimizes text classification and saliency prediction using a shared BERT backbone. Saliency is predicted using attention weights from the last layer, creating explanations during training rather than after.
- Core assumption: Attention weights from the last layer correlate with meaningful saliency information.
- Evidence anchors:
  - [abstract]: "XAI-C LASS begins by employing a multi-round question-answering process to generate pseudo-training data that promotes the mutual enhancement of class labels and corresponding explanation word generation."
  - [section]: "We then apply a linear classifier W ∈ R|D|×1 to this attention matrix Ã: ˆy = ÃW + b where b ∈ R|D|×1 is the bias vector."
  - [corpus]: Weak evidence - corpus mentions "Weakly Supervised Open-world Text Classification" but doesn't specifically address attention-based saliency.
- Break condition: When the attention-based saliency loss no longer improves model performance or explainability metrics.

### Mechanism 3
- Claim: Extremely weak supervision using only class names is sufficient when combined with iterative PLM querying.
- Mechanism: The method uses only class names as supervision, leveraging PLMs' knowledge to generate both labels and explanations through structured querying without requiring keyword vocabularies or pre-existing label-word mappings.
- Core assumption: PLMs contain sufficient world knowledge to map class names to appropriate documents and explanations without additional supervision.
- Evidence anchors:
  - [abstract]: "In this study, we focus on the extremely weakly-supervised setting that utilizes only the class names as supervision."
  - [section]: "Importantly, we do not assume that the class names need to have appeared in the input documents."
  - [corpus]: Weak evidence - corpus shows related work on "Extremely Weak Supervision" but doesn't validate the sufficiency claim.
- Break condition: When performance plateaus or degrades as class names become too abstract or domain-specific for PLMs to handle effectively.

## Foundational Learning

- Concept: Iterative refinement through mutual feedback
  - Why needed here: Enables progressive improvement of both classification and explanation quality without human intervention
  - Quick check question: What happens if you skip rounds 2 and 3 in the multi-round process? (Answer: Performance typically drops as shown in Figure 3)

- Concept: Attention mechanisms as feature extractors
  - Why needed here: Provides a differentiable path for saliency prediction that can be optimized jointly with classification
  - Quick check question: Why use attention from the last layer specifically? (Answer: Last layer attention captures the most refined contextual representations)

- Concept: Weak supervision through structured prompting
  - Why needed here: Enables leveraging PLMs' knowledge without requiring large labeled datasets
  - Quick check question: What makes this "extremely" weak vs. just "weakly" supervised? (Answer: Only class names are used, no keywords, seed words, or label-word mappings)

## Architecture Onboarding

- Component map:
  - PLM T_C (FLAN-T5 variants) - generates class labels
  - PLM T_E (BERT variants) - generates saliency tokens
  - Multi-task BERT encoder - learns joint representations
  - Linear classifier + sigmoid - produces final saliency predictions
  - Hyperparameter λ - balances classification vs. saliency objectives

- Critical path: Document → T_C → class label → T_E → saliency tokens → Multi-task model → final predictions

- Design tradeoffs:
  - PLM choice affects both performance and computational cost
  - Number of rounds trades accuracy for runtime
  - λ value balances explainability vs. classification performance

- Failure signatures:
  - No improvement after multiple rounds suggests poor PLM choices or incompatible class names
  - High saliency loss with low classification loss indicates misalignment between tasks
  - Performance worse than baselines suggests pseudo-label generation is failing

- First 3 experiments:
  1. Test single-round vs. multi-round performance on AGNews to verify iterative benefit
  2. Vary λ from 0 to 1 to find optimal balance between tasks
  3. Compare different PLM combinations (e.g., FLAN-T5-large vs. base) for T_C and T_E

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does XAI-CLASS perform on fine-grained or multi-label text classification tasks, given its assumption of a disjoint label space?
- Basis in paper: [explicit] The paper mentions that XAI-CLASS operates under the assumption of a disjoint label space and is not specifically tailored for fine-grained or multi-label text classification tasks.
- Why unresolved: The paper does not provide experimental results or analysis of XAI-CLASS's performance on fine-grained or multi-label text classification tasks.
- What evidence would resolve it: Experiments comparing XAI-CLASS's performance on fine-grained or multi-label text classification tasks with other methods specifically designed for these tasks.

### Open Question 2
- Question: What is the impact of increasing the number of rounds in the iterative mutual enhancement process on XAI-CLASS's performance?
- Basis in paper: [explicit] The paper mentions that XAI-CLASS requires careful consideration when selecting the number of rounds of question answering and is not designed to scale to a large number of rounds.
- Why unresolved: The paper does not provide a detailed analysis of the impact of increasing the number of rounds on XAI-CLASS's performance.
- What evidence would resolve it: Experiments showing the performance of XAI-CLASS with varying numbers of rounds, beyond the optimal number reported in the paper.

### Open Question 3
- Question: How does XAI-CLASS handle potential biases present in the training data of the pre-trained language models (PLMs) it relies on?
- Basis in paper: [explicit] The paper acknowledges that XAI-CLASS relies on PLMs, which may make decisions based on biases present in the training data.
- Why unresolved: The paper does not provide a detailed discussion or experiments on how XAI-CLASS addresses or mitigates potential biases in the PLMs.
- What evidence would resolve it: Experiments or analysis showing how XAI-CLASS performs on datasets with known biases and how it compares to other methods in terms of bias mitigation.

## Limitations
- The approach relies heavily on PLMs, which may inherit biases from their training data
- Performance may degrade on specialized domains where PLMs lack sufficient context
- The assumption that attention weights correlate with meaningful saliency may not hold universally

## Confidence

**Confidence Labels:**
- High confidence: The multi-task learning framework combining classification and saliency prediction is technically sound and well-implemented
- Medium confidence: The iterative mutual enhancement mechanism shows strong results but depends heavily on PLM quality and domain fit
- Medium confidence: The extremely weak supervision approach is novel but its effectiveness varies with class name specificity and domain knowledge requirements

## Next Checks

1. Test XAI-CLASS on specialized domain datasets (e.g., medical or legal text) to evaluate PLM-based pseudo-label generation performance when domain knowledge is limited
2. Conduct ablation studies removing the multi-round process to quantify the exact contribution of iterative mutual enhancement
3. Compare attention-based saliency predictions with human-annotated saliency scores on a subset of documents to validate the quality of automatically generated explanations