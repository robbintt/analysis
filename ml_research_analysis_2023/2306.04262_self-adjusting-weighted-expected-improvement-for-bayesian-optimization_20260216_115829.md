---
ver: rpa2
title: Self-Adjusting Weighted Expected Improvement for Bayesian Optimization
arxiv_id: '2306.04262'
source_url: https://arxiv.org/abs/2306.04262
tags:
- step
- steps
- sawei
- regret
- figure
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Self-Adjusting Weighted Expected Improvement (SAWEI) proposes a
  data-driven method for balancing exploration and exploitation in Bayesian optimization
  by adaptively adjusting the weight parameter of Weighted Expected Improvement based
  on the Upper Bound Regret (UBR) convergence. When UBR gradients approach zero, SAWEI
  adjusts the exploration-exploitation trade-off in the opposite direction of the
  current search attitude, using a simple additive change.
---

# Self-Adjusting Weighted Expected Improvement for Bayesian Optimization

## Quick Facts
- **arXiv ID**: 2306.04262
- **Source URL**: https://arxiv.org/abs/2306.04262
- **Reference count**: 40
- **Key outcome**: SAWEI proposes a data-driven method for balancing exploration and exploitation in Bayesian optimization by adaptively adjusting the weight parameter of Weighted Expected Improvement based on the Upper Bound Regret (UBR) convergence.

## Executive Summary
Self-Adjusting Weighted Expected Improvement (SAWEI) proposes a data-driven method for balancing exploration and exploitation in Bayesian optimization by adaptively adjusting the weight parameter of Weighted Expected Improvement based on the Upper Bound Regret (UBR) convergence. When UBR gradients approach zero, SAWEI adjusts the exploration-exploitation trade-off in the opposite direction of the current search attitude, using a simple additive change. On the BBOB benchmark, SAWEI achieves favorable anytime performance and ranks among the top methods, with the general trend of moving from exploration (EI) to exploitation (modulated PI). On HPOBench, SAWEI also shows strong anytime performance and ranks highly, but with the opposite trend—moving from EI to more exploration. This domain-dependent behavior demonstrates SAWEI's ability to automatically adapt to different problem structures.

## Method Summary
SAWEI adjusts the weight parameter α of Weighted Expected Improvement (WEI) dynamically during Bayesian optimization. The adjustment is triggered when the gradient of the Upper Bound Regret (UBR) over recent steps approaches zero, indicating convergence of the current search attitude. The direction of adjustment is determined by comparing the magnitudes of the exploration term (a_explore) and exploitation term (a_exploit) of WEI for the last chosen point. If exploration dominated, α is increased to push toward exploitation, and vice versa. The method uses a gradual adjustment (Δα = 0.1) and starts from a balanced EI-like state (α = 0.5), transitioning to more exploitative or explorative stances as the problem demands.

## Key Results
- On BBOB benchmark, SAWEI exhibits favorable anytime performance and ranks among the top methods, trending from exploration to exploitation.
- On HPOBench, SAWEI shows strong anytime performance and ranks highly, with the opposite trend—moving from EI to more exploration.
- SAWEI demonstrates domain-dependent behavior, automatically adapting to different problem structures without requiring prior knowledge of the optimization landscape.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAWEI uses UBR convergence as a trigger to adjust the exploration-exploitation balance dynamically during optimization.
- Mechanism: When the gradient of UBR over recent steps approaches zero, the algorithm interprets this as convergence of the current search attitude and flips the direction of the weight adjustment (Δα = ±0.1) opposite to the dominant term (exploration vs. exploitation).
- Core assumption: UBR reliably signals convergence of the current acquisition function's search strategy, and reversing the direction of the adjustment will escape local regions and improve global search.
- Evidence anchors:
  - [abstract] "We propose Self-Adjusting Weighted Expected Improvement (SAWEI), where we let the exploration-exploitation trade-off self-adjust in a data-driven manner, based on a convergence criterion for BO."
  - [section 3] "We propose a new method, dubbed Self-Adjusting Weighted Expected Improvement (SAWEI). Inspired by a termination criterion for BO (Makarova et al., 2022), we adjust the weight α whenever BO tends to converge, indicated by the Upper Bound Regret (UBR)."
  - [corpus] Weak or missing; no direct comparison to UBR-based triggers in cited neighbors.

### Mechanism 2
- Claim: SAWEI adjusts α in the opposite direction of the current search attitude, enabling automatic domain adaptation.
- Mechanism: By comparing the magnitudes of the exploration term (a_explore) and exploitation term (a_exploit) of WEI for the last chosen point, the algorithm determines whether exploration or exploitation dominated. If exploration dominated, it increases α to push toward exploitation, and vice versa.
- Core assumption: The relative magnitudes of these terms accurately reflect the search attitude that led to convergence, and flipping α will yield better sampling.
- Evidence anchors:
  - [section 3] "We set Δα = 0.1 to allow for gradual changes. We determine the sign of Δα by the recent search attitude: Depending on whether the exploration-term a_explore or exploitation-term a_exploit of Equation (1) is larger for the last selected point x_next, the current search attitude was either steered more for exploring or exploiting, respectively."
  - [corpus] Weak or missing; no direct comparison to attitude-based α adjustment in cited neighbors.

### Mechanism 3
- Claim: SAWEI achieves favorable anytime performance by smoothly transitioning from exploration to exploitation (or vice versa) without requiring pre-defined schedules.
- Mechanism: The gradual, data-driven adjustment of α allows the algorithm to start from a balanced EI-like state (α = 0.5) and transition to a more exploitative or explorative stance as the problem demands, improving both early and late-stage performance.
- Core assumption: The problem structure evolves during optimization such that early exploration and later exploitation (or vice versa) are optimal, and the gradual adjustment avoids abrupt performance drops.
- Evidence anchors:
  - [section 4] "SAWEI also exhibits a favorable any-time performance... making it a consistent and robust default choice."
  - [section 4] "In general, the tendency of the α-schedules traversed by SAWEI is moving from exploration to exploitation... On HPOBench... the general trend to start from EI (α = 0.5) and go to Explore (α = 0)."
  - [corpus] Weak or missing; no direct comparison to anytime performance of UBR-triggered adjustment in cited neighbors.

## Foundational Learning

- **Concept**: Gaussian Process surrogate models and their role in Bayesian Optimization.
  - **Why needed here**: SAWEI relies on GP predictions (mean and variance) to compute WEI terms and UBR; understanding how GP uncertainty propagates is essential for debugging and tuning.
  - **Quick check question**: How does the choice of kernel and hyperparameters in the GP affect the exploration-exploitation trade-off in WEI?

- **Concept**: Acquisition function design and the trade-off between exploration and exploitation.
  - **Why needed here**: SAWEI modifies WEI by adjusting α; understanding how different α values map to exploration/exploitation behaviors is key to interpreting results.
  - **Quick check question**: What is the relationship between α = 0, α = 0.5, and α = 1 in WEI in terms of exploration and exploitation?

- **Concept**: Convergence criteria for iterative optimization algorithms.
  - **Why needed here**: UBR is used as a convergence signal; understanding how and when UBR stabilizes is crucial for tuning SAWEI's sensitivity (ε) and adjustment step (Δα).
  - **Quick check question**: What are the mathematical conditions under which UBR converges, and how do they relate to the GP's uncertainty estimates?

## Architecture Onboarding

- **Component map**: Initial Design → Surrogate Model (GP) → Acquisition Function (WEI) → Next Point Selection → Function Evaluation → History Update → Surrogate Retraining → UBR Calculation → Smooth UBR → Gradient Check → α Adjustment → Repeat.

- **Critical path**:
  1. Compute WEI for candidate points.
  2. Select next point and record attitude terms.
  3. Update GP and compute UBR.
  4. Smooth UBR and check gradient.
  5. If converged, adjust α and loop.

- **Design tradeoffs**:
  - Sensitivity (ε) vs. frequency of adjustments: Lower ε → more frequent adjustments, but risk of noise; higher ε → less responsive, but more stable.
  - Adjustment step (Δα) vs. granularity: Smaller steps → smoother transitions, but slower adaptation; larger steps → faster adaptation, but risk of overshooting.
  - Horizon for gradient check (n) vs. responsiveness: Shorter horizon → more sensitive to recent changes, but noisier; longer horizon → smoother, but slower to react.

- **Failure signatures**:
  - α oscillates or gets stuck at extremes (0 or 1) → check UBR smoothing or gradient tolerance.
  - Performance lags behind static baselines → verify attitude detection logic and that UBR is actually signaling convergence.
  - Excessive computational overhead → profile UBR calculation and GP retraining steps.

- **First 3 experiments**:
  1. Run SAWEI with ε = 0.1, Δα = 0.1, n = 1 on a simple 1D BBOB function; log α and UBR over time to verify adjustment logic.
  2. Compare SAWEI vs. static WEI baselines (α = 0, 0.5, 1) on a few BBOB functions; check anytime and final performance.
  3. Run SAWEI on a simple HPOBench task; compare trajectory of α to BBOB results to observe domain adaptation.

## Open Questions the Paper Calls Out

- **Open Question 1**: How can SAWEI be extended to allow more flexible adjustment strategies beyond simple additive changes to the weight parameter?
  - **Basis in paper**: [explicit] The authors mention this as a limitation in Section 5, noting that SAWEI does not allow jumps or resetting α, which could be beneficial.
  - **Why unresolved**: The paper only implements a simple additive adjustment mechanism (Δα = 0.1) and does not explore alternative adjustment strategies.
  - **What evidence would resolve it**: Experimental results comparing SAWEI with different adjustment strategies (multiplicative, exponential, or learned adjustments) on various benchmark problems.

- **Open Question 2**: How does the choice of initial α value affect SAWEI's performance across different problem types?
  - **Basis in paper**: [inferred] The authors mention in Section 5 that they did not experiment with the initial value of α, which may not be optimal for every tested function.
  - **Why unresolved**: The experiments used a fixed initial α = 0.5 without exploring how different starting values impact performance.
  - **What evidence would resolve it**: Systematic experiments varying initial α values across different problem types and benchmark suites.

- **Open Question 3**: Can the UBR convergence criterion be made more robust to noise and model uncertainty?
  - **Basis in paper**: [explicit] The authors use UBR based on the work by Makarova et al. (2022) but don't explore robustness to noise or model uncertainty.
  - **Why unresolved**: The current implementation assumes noise-free or low-noise settings and uses a simple smoothing approach with moving IQM.
  - **What evidence would resolve it**: Comparative studies of SAWEI with different UBR variants (e.g., using variance estimates, different smoothing windows, or alternative convergence criteria) on noisy benchmark problems.

## Limitations
- The reliance on UBR as a convergence signal introduces sensitivity to the choice of smoothing window and gradient tolerance, which are not deeply explored.
- The mechanism for flipping α based on recent search attitude may not hold in multi-modal landscapes where exploration and exploitation alternate rapidly.
- The opposite trends observed between BBOB and HPOBench suggest domain-dependent behavior, but the paper does not investigate the underlying reasons or provide guidance on when each trend is expected.

## Confidence

- **High Confidence**: The mechanism of using UBR convergence as a trigger for adjusting α is clearly described and consistently applied across experiments. The basic mathematical formulation of SAWEI and its components (WEI, UBR) is sound.
- **Medium Confidence**: The effectiveness of SAWEI on BBOB and HPOBench benchmarks is demonstrated, but the domain-dependent trends in α adjustment are not fully explained. The sensitivity of performance to hyperparameters like ε and Δα is not thoroughly analyzed.
- **Low Confidence**: The interpretation of why SAWEI exhibits opposite trends on BBOB vs. HPOBench is speculative, and the paper does not provide sufficient theoretical or empirical grounding for this observation. The robustness of SAWEI to noisy evaluations or multi-modal functions is not tested.

## Next Checks

1. **Sensitivity Analysis**: Run SAWEI on a subset of BBOB and HPOBench benchmarks with varying ε (e.g., 0.01, 0.05, 0.1) and Δα (e.g., 0.05, 0.1, 0.2) to quantify the impact of these hyperparameters on performance and stability.
2. **Multi-Modal Landscape Test**: Evaluate SAWEI on a known multi-modal synthetic function (e.g., Hartmann 6D) to observe whether the α adjustment logic adapts appropriately or gets stuck oscillating between exploration and exploitation.
3. **Direct Mechanism Ablation**: Compare SAWEI to a variant where α is adjusted based only on UBR convergence (ignoring search attitude) and another where α is adjusted based only on search attitude (ignoring UBR). This will help isolate the contribution of each mechanism to the overall performance.