---
ver: rpa2
title: On existence, uniqueness and scalability of adversarial robustness measures
  for AI classifiers
arxiv_id: '2310.14421'
source_url: https://arxiv.org/abs/2310.14421
tags:
- data
- adversarial
- https
- page
- panels
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of existence, uniqueness, and
  computational scalability of adversarial robustness measures (MAP and MAD) for AI
  classifiers. The core method idea is to formulate and prove simply-verifiable mathematical
  conditions for existence, uniqueness, and explicit analytical computation of MAP
  and MAD for various classes of AI classifiers, including locally uniquely-invertible
  classifiers, generalized linear models (GLM), and entropic AI (EAI).
---

# On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers

## Quick Facts
- arXiv ID: 2310.14421
- Source URL: https://arxiv.org/abs/2310.14421
- Reference count: 17
- Primary result: Mathematical conditions proven for existence, uniqueness, and computational scalability of minimal adversarial paths (MAP) and minimal adversarial distances (MAD) for different AI classifier types

## Executive Summary
This paper establishes theoretical foundations for computing minimal adversarial paths and distances for AI classifiers by proving conditions for existence, uniqueness, and computational scalability. The authors develop analytical solutions for locally uniquely-invertible classifiers, GLM models, and entropic AI (eSPA) classifiers, demonstrating polynomial complexity for eSPA with linear scaling in the number of Voronoi cells. The work bridges adversarial robustness theory with practical interpretability, showing how eSPA can provide mathematically-guaranteed minimal therapeutic interventions for biomedical risk mitigation.

## Method Summary
The paper formulates and proves mathematical conditions for MAP/MAD existence, uniqueness, and computational scalability across different classifier types. For locally uniquely-invertible classifiers, it uses regularization with local inverse functions to obtain closed-form solutions. For GLM classifiers, it leverages monotonic probability functions to transform constraints into linear forms. For eSPA classifiers, it exploits piecewise-linear decision boundaries and reduces MAP/MAD computation to quadratic programming across Voronoi cells. The methods are validated on synthetic Swiss roll data and biomedical applications including health insurance claims and heart attack lethality prediction.

## Key Results
- For locally uniquely-invertible classifiers, unique MAP/MAD solutions exist in closed-form with computational cost scaling defined by inverse function computation
- GLM classifiers admit explicit O(D) MAP/MAD solutions due to monotonic probability functions
- eSPA classifiers provide polynomial complexity in dimension D and linear complexity in Voronoi cells K, with superior interpretability for therapeutic interventions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Existence and uniqueness of MAP/MAD can be guaranteed for locally uniquely-invertible classifiers through regularization
- Mechanism: By reformulating the adversarial attack problem with a regularized objective that includes both distance minimization and a "soft" constraint on class probability change, the problem becomes convex and admits a closed-form solution when the classifier is locally uniquely-invertible
- Core assumption: The classifier function PL(·) is locally uniquely-invertible in a neighborhood S(X) of the input X, meaning there exists a local inverse P†L,S(X)(·)
- Evidence anchors:
  - [abstract] "Simply-verifiable mathematical conditions for existence, uniqueness and explicit analytical computation of minimal adversarial paths (MAP) and minimal adversarial distances (MAD) for (locally) uniquely-invertible classifiers"
  - [section] "Theorem 1. Let X, ˜X ∈ RD, dist (X, ˜X) = ∥X − ˜X∥2 2, and PL(·) be a (locally) uniquely-invertible classifier function in the neighbourhood S(X) of X. Then, for any δ ≥ 0 and ϵ problem (4) has a unique solution X*ϵ,δ"
- Break condition: The solution X*ϵ,δ falls outside the neighborhood S(X) where the local invertibility holds, or the classifier is not locally uniquely-invertible in any neighborhood around X

### Mechanism 2
- Claim: For Generalized Linear Models (GLM), MAP/MAD computation is both unique and computationally scalable (O(D))
- Mechanism: GLM classifiers have monotonic scalar-valued affiliation probability functions PL(·) that are globally uniquely-invertible with respect to the scalar product θTX, allowing transformation of the constraint into a linear form that can be incorporated into the regularization term
- Core assumption: The PL(·) function is monotonic and globally uniquely-invertible with respect to the scalar product θTX, not necessarily with respect to X itself
- Evidence anchors:
  - [abstract] "for generalized linear models (GLM)"
  - [section] "For example, PL(·) of a logistic regression is a logistic sigmoid function - and its analytical inverse P†L,S(X)(·) is a logit function. Then, deploying the same mathematical instruments... one obtains that the solution of (4-5) exists, is always unique and takes the following explicit form"
- Break condition: The GLM assumption fails (e.g., non-monotonic PL(·) or non-linear relationships that cannot be expressed as a scalar product)

### Mechanism 3
- Claim: For entropic AI (eSPA) classifiers, MAP/MAD conditions are guaranteed with polynomial complexity in dimension D and linear complexity in the number K of Voronoi cells
- Mechanism: eSPA classifiers produce piecewise-linear classifier boundaries, and finding MAP/MAD reduces to solving multiple quadratic programming problems across the Voronoi cells, with conditions for non-emptiness verified via linear algebra criteria
- Core assumption: The eSPA classifier function PeSPA L(X) is piecewise-linear with K Voronoi cells, and the boundaries between cells are defined by hyperplanes orthogonal to normalized vectors connecting cell centers
- Evidence anchors:
  - [abstract] "for entropic AI (EAI)"
  - [section] "As proven in [9], for any (yet-unlabelled) feature vector X ∈ R D×1 and any L ∈ { 1, . . . , M}, eSPA classifier affiliation is a piecewise-linear function defined by the boundaries of the K Voronoi cells"
- Break condition: The piecewise-linear assumption fails (e.g., non-convex boundaries or when the linear inequality constraints define empty sets for all cells)

## Foundational Learning

- Concept: Convex optimization and regularization
  - Why needed here: The paper transforms non-convex adversarial attack problems into convex regularized optimization problems to guarantee existence and uniqueness of solutions
  - Quick check question: What mathematical property ensures that a regularized convex optimization problem has a unique global minimum?

- Concept: Local vs global invertibility
  - Why needed here: Different classifier families require different invertibility conditions - local invertibility for general classifiers, global invertibility for GLMs, and piecewise-linear structure for eSPA
  - Quick check question: How does local unique-invertibility differ from global unique-invertibility in terms of neighborhood requirements?

- Concept: Piecewise-linear classifier boundaries
  - Why needed here: eSPA classifiers rely on piecewise-linear decision boundaries to enable tractable MAP/MAD computation through quadratic programming
  - Quick check question: Why do piecewise-linear boundaries make adversarial attack computation more tractable than non-convex boundaries?

## Architecture Onboarding

- Component map: Input feature vector -> Classifier type identification -> MAP/MAD computation engine -> Solution validation -> Output adversarial path and distance
- Critical path: Input feature vector → Classifier type identification → MAP/MAD computation (using appropriate algorithm for classifier type) → Solution validation (checking neighborhood conditions or constraint feasibility) → Output adversarial path and distance
- Design tradeoffs: Local invertibility offers generality but requires neighborhood checks and may fail for some δ values; GLM provides analytical solutions with O(D) complexity but is limited to linear models; eSPA offers polynomial complexity and interpretability but requires training eSPA models first
- Failure signatures: No solution found (when X*ϵ,δ ∉ S(X) for invertible classifiers); empty constraint sets (when linear inequalities define empty sets for eSPA); computational complexity blowup (when K is very large for eSPA); numerical instability in computing local inverses
- First 3 experiments:
  1. Implement and test MAP/MAD computation for logistic regression on synthetic Swiss roll data, comparing with ground truth local inverses
  2. Implement eSPA classifier training and MAP/MAD computation on the same synthetic data, verifying polynomial complexity scaling
  3. Apply the complete pipeline to a small biomedical dataset, computing patient-specific risk-mitigating interventions and validating with domain experts

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the computational costs of MAP and MAD scale for classifiers beyond GLM, locally uniquely-invertible classifiers, and eSPA, such as deep neural networks with non-linear activation functions?
- Basis in paper: [explicit] The paper provides explicit computational cost scalings for GLM classifiers (O(D)), locally uniquely-invertible classifiers (defined by the scaling of computing the inverse C(δ, X)), and eSPA (polynomial in dimension D and linear in the number K of Voronoi cells). However, it does not address the computational costs for other types of classifiers, such as deep neural networks with non-linear activation functions
- Why unresolved: The paper focuses on proving the existence, uniqueness, and computational scalability of MAP and MAD for specific classes of AI classifiers but does not extend the analysis to other commonly used classifiers like deep neural networks with non-linear activation functions
- What evidence would resolve it: A theoretical analysis or empirical study demonstrating the computational cost scaling of MAP and MAD for deep neural networks with non-linear activation functions, possibly through the formulation of new theorems or algorithms

### Open Question 2
- Question: What are the practical implications of the non-convexity of class affiliation probability functions on the robustness of AI classifiers against adversarial attacks?
- Basis in paper: [explicit] The paper highlights that class affiliation probability functions are non-convex, even for basic AI benchmarks like the double-spiral Swiss roll example. This non-convexity is suggested to impact the effectiveness of adversarial attacks and the computation of MAP and MAD
- Why unresolved: While the paper acknowledges the non-convexity of class affiliation probability functions, it does not delve into the practical implications of this non-convexity on the robustness of AI classifiers against adversarial attacks or how it affects the computation of MAP and MAD in real-world scenarios
- What evidence would resolve it: Empirical studies comparing the robustness of AI classifiers with convex versus non-convex class affiliation probability functions against adversarial attacks, along with an analysis of how non-convexity affects the computation of MAP and MAD in practical applications

### Open Question 3
- Question: How can the conditions for existence, uniqueness, and computational scalability of MAP and MAD be extended to classifiers that are not (locally) uniquely-invertible or piecewise-linear?
- Basis in paper: [inferred] The paper provides conditions for existence, uniqueness, and computational scalability of MAP and MAD for (locally) uniquely-invertible classifiers, GLM classifiers, and eSPA classifiers. However, it does not address how these conditions might be extended to classifiers that do not fit into these categories, such as those with complex, non-linear decision boundaries
- Why unresolved: The mathematical conditions provided are specific to certain types of classifiers and may not be directly applicable to all classifiers, especially those with complex, non-linear decision boundaries that do not meet the criteria of (local) unique-invertibility or piecewise-linearity
- What evidence would resolve it: The development of new mathematical frameworks or algorithms that can handle the computation of MAP and MAD for a broader class of classifiers, including those with complex, non-linear decision boundaries, potentially through the use of advanced optimization techniques or machine learning methods

## Limitations

- The local invertibility assumption may fail for complex classifiers in high-dimensional spaces
- eSPA performance depends heavily on proper Voronoi cell partitioning, which may become computationally expensive for large K
- The biomedical applications assume feature controllability that may not reflect real therapeutic constraints

## Confidence

- Theoretical framework for GLM and eSPA classifiers: High
- Local invertibility conditions: Medium
- Computational scalability claims: Medium
- Biomedical application recommendations: Low

## Next Checks

1. Test MAP/MAD computation on non-invertible regions of neural networks to verify failure conditions
2. Benchmark eSPA scalability on high-dimensional data (D > 100) with varying K values
3. Validate the therapeutic intervention recommendations from eSPA classifiers with domain experts