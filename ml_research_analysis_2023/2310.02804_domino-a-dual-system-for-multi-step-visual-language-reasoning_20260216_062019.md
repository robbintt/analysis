---
ver: rpa2
title: 'DOMINO: A Dual-System for Multi-step Visual Language Reasoning'
arxiv_id: '2310.02804'
source_url: https://arxiv.org/abs/2310.02804
tags:
- data
- reasoning
- answer
- system-2
- domino
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work presents DOMINO, a dual-system for multi-step visual
  language reasoning. DOMINO leverages an LLM for task decomposition and a visual
  encoder-text decoder for information extraction from charts/plots.
---

# DOMINO: A Dual-System for Multi-step Visual Language Reasoning

## Quick Facts
- arXiv ID: 2310.02804
- Source URL: https://arxiv.org/abs/2310.02804
- Reference count: 40
- Key outcome: DOMINO achieves 5.7% higher accuracy than the best fully-supervised end-to-end approach on chart reasoning tasks by using a dual-system architecture that alternates between LLM task decomposition and targeted visual information extraction.

## Executive Summary
DOMINO introduces a novel dual-system approach for multi-step visual language reasoning that combines a large language model (LLM) for task decomposition with a visual encoder-text decoder for targeted information extraction from charts and plots. The system alternates between System-1 (visual encoder) and System-2 (LLM) to break down complex questions into atomic visual queries and reason over the extracted information. By fine-tuning the LLM on only 100 examples of task decomposition, DOMINO significantly outperforms both fully-supervised end-to-end approaches and few-shot pipeline methods on both in-distribution and out-of-distribution datasets, achieving state-of-the-art results on ChartQA and PlotQA benchmarks.

## Method Summary
DOMINO employs a dual-system architecture where System-2 (LLaMA-2 70B) decomposes complex questions into atomic steps and System-1 (DePlot-based visual encoder) extracts specific information from charts based on those steps. The authors define three atomic operations - Describe, Extract-Point, and Extract-Group - to capture common visual information needs. System-1 is trained on synthetic data generated from ChartQA and PlotQA training sets using templates for each operation, while System-2 is fine-tuned on 100 annotated examples of task decomposition. The systems alternate, with System-2 generating queries for System-1 or synthesizing final answers, enabling efficient and targeted chart reasoning without processing entire charts upfront.

## Key Results
- DOMINO outperforms fully-supervised end-to-end approaches by 5.7% and pipeline methods with FlanPaLM (540B) by 7.5% on challenging human-authored question datasets
- The approach achieves state-of-the-art results on both ChartQA and PlotQA benchmarks
- Fine-tuning System-2 on only 100 examples further improves accuracy by 1.7% on ChartQA
- DOMINO shows superior performance on in-distribution data while maintaining strong results on out-of-distribution datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Alternating between System-1 and System-2 reduces cognitive load on the LLM by only asking it to reason about one visual extraction at a time
- Mechanism: The LLM generates a step-by-step reasoning trace where each step either queries the visual encoder or synthesizes the final answer, avoiding the need to process the entire chart upfront
- Core assumption: The LLM can decompose complex reasoning into atomic visual queries that are well-defined and executable by the visual encoder
- Evidence anchors: [abstract] states System-2 breaks down questions into atomic sub-steps guiding System-1, and [section 3.2] describes the alternating pattern where System-2 selects atomic operations to ask System-1 for information

### Mechanism 2
- Claim: Using predefined atomic operations allows visual encoder training on synthetic data, improving efficiency and accuracy
- Mechanism: The authors generate synthetic query-answer pairs for each atomic operation using templates and existing chart QA datasets, creating large training sets without manual annotation
- Core assumption: The atomic operations are general enough to cover types of visual information needed for most chart QA questions
- Evidence anchors: [section 3.1] defines the three atomic operations, and [section 4.1] describes using samples from training sets with templates to generate training data

### Mechanism 3
- Claim: Fine-tuning the LLM on a small number of annotated reasoning traces significantly improves its ability to decompose complex questions
- Mechanism: The authors collect 100 high-quality examples where complex questions are annotated with their decomposition into atomic steps and final answers, then fine-tune the LLM using language modeling loss
- Core assumption: The LLM can learn to decompose questions effectively from a small number of examples without overfitting
- Evidence anchors: [abstract] states fine-tuning System-2 on small data improves accuracy by 5.7%, and [section 6] mentions fine-tuning with 100 examples annotated with reasoning process

## Foundational Learning

- **Chain-of-thought prompting**: Allows the LLM to break down complex reasoning into intermediate steps, crucial for decomposing questions about charts
  - Quick check: Can you explain how chain-of-thought prompting helps a model solve a multi-step math problem?

- **Vision-language pretraining**: The visual encoder (DePlot) is pretrained on chart understanding, essential for its ability to extract information from charts
  - Quick check: What are the benefits of pretraining a model on a large dataset before fine-tuning it on a specific task?

- **Synthetic data generation**: Enables creation of large training sets for the visual encoder without manual annotation
  - Quick check: How can synthetic data be used to train a model when real data is scarce or expensive to obtain?

## Architecture Onboarding

- **Component map**: LLM (System-2) -> Visual encoder (System-1) -> Extracted information -> LLM reasoning
- **Critical path**: LLM decomposes question -> LLM generates query for visual encoder -> Visual encoder extracts information -> LLM reasons with extracted information -> Repeat until final answer
- **Design tradeoffs**: Using a small set of atomic operations simplifies visual encoder training but may limit expressiveness; fine-tuning the LLM improves reasoning but requires annotated data
- **Failure signatures**: If the LLM cannot decompose the question, System-1 won't be invoked correctly; if the visual encoder cannot extract requested information, the LLM will have incorrect data to reason with
- **First 3 experiments**:
  1. Run the model on a simple question with a known answer to verify the basic pipeline works
  2. Test the Describe operation separately to ensure the visual encoder can provide a high-level chart description
  3. Test the model on a complex question with multiple steps to verify the alternating pattern works as intended

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does DOMINO's performance compare to other methods on datasets with natural language questions versus synthetic questions?
- Basis in paper: [explicit] The paper mentions DOMINO performs better on ChartQA with natural questions but struggles on synthetic datasets like PlotQA and DVQA
- Why unresolved: The paper provides some comparison but doesn't deeply analyze reasons behind performance differences on natural vs synthetic datasets
- What evidence would resolve it: A detailed ablation study comparing DOMINO's performance on different types of questions (natural vs synthetic) with varying complexity levels

### Open Question 2
- Question: How does the length and complexity of the underlying table in a chart affect DOMINO's performance?
- Basis in paper: [explicit] The paper mentions analyzing DOMINO's performance based on table length, showing it performs better on more complex charts
- Why unresolved: While the paper shows some analysis, it doesn't fully explore the relationship between table complexity and performance
- What evidence would resolve it: A comprehensive study varying table sizes and complexities, measuring DOMINO's accuracy and error types across different scenarios

### Open Question 3
- Question: How does fine-tuning System-2 with different amounts of data affect DOMINO's performance on in-distribution and out-of-distribution datasets?
- Basis in paper: [explicit] The paper mentions fine-tuning System-2 with 100 examples and studying data efficiency, but doesn't explore the full range of data amounts
- Why unresolved: The paper only provides a limited view of how fine-tuning affects performance
- What evidence would resolve it: An extensive study varying the number of fine-tuning examples from 0 to 1000+, measuring performance on both in-distribution and out-of-distribution datasets

## Limitations

- The approach's effectiveness depends heavily on the LLM's ability to decompose questions into the three predefined atomic operations, with no clear fallback for questions requiring different operations
- Synthetic data generation for the visual encoder lacks empirical validation of quality and coverage compared to real annotated data
- The 100 annotated examples for fine-tuning System-2 represent a minimal dataset that may not capture the full diversity of question types, raising concerns about potential overfitting

## Confidence

**High Confidence**: The core dual-system architecture and alternating pattern between System-1 and System-2 are well-defined and logically sound, with compelling experimental results showing DOMINO outperforming fully-supervised end-to-end approaches and few-shot pipeline methods on both in- and out-of-distribution data.

**Medium Confidence**: The mechanism of using synthetic data to train the visual encoder is reasonable but lacks direct empirical validation; the authors provide theoretical justification but don't show how synthetic data quality compares to real annotated data or demonstrate coverage of generated examples.

**Low Confidence**: The scalability of the approach to questions requiring atomic operations beyond the three predefined types (Describe, Extract-Point, Extract-Group) is unclear; the paper doesn't address what happens when System-2 encounters questions that don't decompose neatly into these operations.

## Next Checks

1. **Decomposition Quality Analysis**: Analyze the 100 fine-tuning examples to quantify how often System-2 successfully decomposes questions into valid atomic steps; calculate the percentage of cases where decomposition requires non-standard operations or fails entirely.

2. **Synthetic Data Coverage Validation**: Generate a random sample of questions from test sets and manually verify whether each question can be answered using only the three predefined atomic operations; calculate coverage percentage and identify patterns in questions falling outside this scope.

3. **Zero-Shot Generalization Test**: Evaluate DOMINO on a dataset with questions having different structural patterns than ChartQA and PlotQA (e.g., PlotQA-Delta or different chart type) without any fine-tuning to assess true generalization capability beyond the training distribution.