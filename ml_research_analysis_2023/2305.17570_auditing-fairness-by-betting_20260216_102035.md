---
ver: rpa2
title: Auditing Fairness by Betting
arxiv_id: '2305.17570'
source_url: https://arxiv.org/abs/2305.17570
tags:
- time
- test
- data
- sequential
- fairness
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents a method for auditing the fairness of classification
  and regression models in real-world settings. The authors formulate the problem
  as sequential hypothesis testing, allowing for continuous monitoring of incoming
  data and the ability to stop collecting samples at arbitrary data-dependent stopping
  times.
---

# Auditing Fairness by Betting

## Quick Facts
- arXiv ID: 2305.17570
- Source URL: https://arxiv.org/abs/2305.17570
- Reference count: 40
- Key outcome: Sequential betting tests provide anytime-valid fairness auditing that is more powerful than fixed-time permutation tests

## Executive Summary
This paper introduces a novel approach for auditing the fairness of deployed classification and regression models using sequential hypothesis testing. The authors leverage recent advances in testing by betting to create procedures that can continuously monitor incoming data and stop collecting samples at arbitrary, data-dependent times while maintaining valid type-I error control. The method handles distribution shift and time-varying data collection policies, making it suitable for real-world deployment scenarios. Experiments on credit default and US census data demonstrate that their sequential betting approach outperforms traditional fixed-time permutation tests in both false positive rates and expected stopping times.

## Method Summary
The method formulates fairness auditing as sequential hypothesis testing where an auditor maintains a wealth process that grows exponentially when unfairness is detected. Using Online Newton Step (ONS) betting strategies, the approach tests for differences in group means between protected classes. The framework incorporates importance weighting to handle arbitrary data collection policies and adapts to distribution shift by reformulating null and alternative hypotheses. When the wealth process exceeds a threshold (1/α), the null hypothesis of fairness is rejected. The method provides anytime-valid inference, meaning type-I error control is maintained regardless of when the test stops.

## Key Results
- Sequential betting tests achieve lower false positive rates than fixed-time permutation tests without Bonferroni correction
- The method demonstrates faster stopping times under unfairness compared to both M1 (no correction) and M2 (Bonferroni correction) baselines
- Experiments show the approach handles distribution shift effectively when mean differences persist after drift begins
- Importance weighting enables unbiased fairness assessment even with non-uniform sampling policies

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequential betting strategies enable anytime-valid fairness audits without fixed sample sizes
- Mechanism: The auditor maintains a wealth process that grows exponentially under unfairness by betting on the difference between group means. When wealth crosses 1/α, the null is rejected
- Core assumption: The payoff function satisfies E[St|Ft−1] ≤ 1 under fairness, ensuring the wealth process is a nonnegative supermartingale under H0
- Evidence anchors:
  - [abstract]: "we take advantage of recent progress in safe, anytime-valid inference (SAVI) to construct sequential procedures"
  - [section 3.1]: "Rejecting when Kt > 1/α thus gives to a valid level-α sequential test"
  - [corpus]: Weak evidence - no direct citation of sequential betting for fairness in corpus
- Break condition: If the data collection policy becomes unbounded or the essential infimum of weights vanishes, the martingale property fails

### Mechanism 2
- Claim: Importance weighting handles arbitrary data collection policies without violating type-I error control
- Mechanism: Samples are reweighted by the ratio of population density to sampling policy density, creating unbiased estimates of group means even under biased sampling
- Core assumption: The weights ωb_t(x) = ρb(x)/πb_t(x) are finite for all x, t, and b
- Evidence anchors:
  - [section 3.3]: "Following standard propensity weighting techniques... introduce the weighted estimates ωb_t(x) := ρb(x)/πb_t(x)"
  - [section 3.3]: "This enables an unbiased estimate of µb = Eρ[φ(X)|ξb] when Xt is sampled according to πb_t"
  - [corpus]: Weak evidence - no direct citation of importance weighting for fairness auditing in corpus
- Break condition: If πb_t(x) → 0 for some x with positive ρb(x), weights become infinite and the martingale property breaks

### Mechanism 3
- Claim: The betting framework adapts to distribution shift without modification to the core algorithm
- Mechanism: The null and alternative are reformulated to allow time-varying means, and the wealth process naturally tracks departures from fairness as they emerge
- Core assumption: After some time n, the absolute difference between group means remains bounded away from zero
- Evidence anchors:
  - [section 3.4]: "we must reformulate our null and alternative hypotheses and our analysis will change"
  - [section 3.4]: "Proposition 3... has power one under the alternative if ∆inf := inf t⩾n ∆t > 0 where n is some time at which drift begins"
  - [corpus]: Weak evidence - no direct citation of distribution shift handling in fairness auditing in corpus
- Break condition: If means converge after diverging, the test may fail to reject even though temporary unfairness occurred

## Foundational Learning

- Concept: Sequential hypothesis testing with arbitrary stopping times
  - Why needed here: Traditional fixed-sample tests cannot handle continuous monitoring or early stopping without inflating type-I error
  - Quick check question: What mathematical tool ensures valid inference when stopping at data-dependent times?

- Concept: Game-theoretic probability and nonnegative martingales
  - Why needed here: Provides the foundation for constructing wealth processes that grow under alternatives while remaining bounded under nulls
  - Quick check question: How does Ville's inequality relate to sequential test validity?

- Concept: Importance weighting and inverse probability weighting
  - Why needed here: Enables unbiased estimation of group means when data is collected by non-uniform policies
  - Quick check question: What condition on the sampling policy ensures finite weights?

## Architecture Onboarding

- Component map: Auditor → Data Collector → Weight Calculator → Betting Engine → Wealth Tracker → Decision Maker
- Critical path: Receive audit → Compute weights → Calculate payoff → Update wealth → Check rejection threshold
- Design tradeoffs: Exact type-I error control vs computational efficiency; handling distribution shift vs requiring minimum separation time
- Failure signatures: Wealth process stagnating near 1 suggests no unfairness detected; weights becoming infinite indicates sampling policy issues
- First 3 experiments:
  1. Simulate Bernoulli observations with known mean difference and verify wealth growth and rejection timing
  2. Test importance weighting by comparing weighted vs unweighted estimates under known sampling bias
  3. Introduce gradual distribution shift and verify the test adapts to detect emerging unfairness

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the betting-style sequential test perform when the fairness violation is not a simple difference in means, but involves more complex group fairness definitions like counterfactual fairness or individual fairness?
- Basis in paper: [explicit] The paper focuses on group fairness based on equality of means, but acknowledges that other fairness definitions exist in the literature
- Why unresolved: The betting framework is designed for testing differences in means. Extending it to other fairness definitions would require new betting strategies and theoretical analysis
- What evidence would resolve it: Experiments comparing the betting test to other methods on datasets with different fairness violations, or theoretical work extending the betting framework to other fairness notions

### Open Question 2
- Question: How sensitive is the betting test to the choice of significance level α, and is there an optimal way to choose α in practice?
- Basis in paper: [inferred] The paper shows results for various values of α, but doesn't discuss how to choose it in practice or analyze the sensitivity
- Why unresolved: The significance level is a hyperparameter that affects the trade-off between false positive rate and stopping time. Understanding its sensitivity and finding optimal ways to set it would be practically valuable
- What evidence would resolve it: Empirical studies varying α on multiple datasets to understand its impact, or theoretical work on optimal α selection

### Open Question 3
- Question: How does the betting test perform in high-dimensional settings, where the number of features is large compared to the sample size?
- Basis in paper: [inferred] The experiments use datasets with a moderate number of features, but the betting framework is nonparametric and could potentially handle high-dimensional data
- Why unresolved: The betting test's performance in high dimensions is unclear, and the theoretical analysis may not directly extend to that setting
- What evidence would resolve it: Experiments on high-dimensional datasets, or theoretical analysis of the betting test's behavior in high dimensions

### Open Question 4
- Question: How does the betting test compare to other sequential fairness testing methods, such as those based on martingale methods or concentration inequalities?
- Basis in paper: [explicit] The paper mentions that other sequential tests exist, but doesn't compare the betting test to them
- Why unresolved: The betting test is one approach to sequential fairness testing, but its relative performance compared to other methods is unknown
- What evidence would resolve it: Empirical comparisons of the betting test to other sequential fairness tests on various datasets and fairness definitions

## Limitations

- The method requires that sampling policies maintain sufficient density across all regions of the covariate space, which may not hold in real-world scenarios where certain subgroups are undersampled
- The distribution shift analysis assumes persistent differences after drift begins, potentially missing transient fairness violations
- Computational complexity scales with the number of batches, making real-time monitoring challenging for high-frequency data streams

## Confidence

- High confidence in the martingale-based proof technique and type-I error control under standard assumptions (sections 2-3)
- Medium confidence in the practical performance given the limited empirical validation to two datasets and specific model architectures
- Low confidence in the method's behavior under severe covariate shift or when the essential infimum of weights approaches zero

## Next Checks

1. Stress test the importance weighting under extreme sampling biases where πb_t(x) approaches zero for some x, measuring how quickly weights become unstable
2. Evaluate the test's power under gradual distribution shift where the mean difference oscillates around zero, checking for false rejections
3. Benchmark computational efficiency by scaling the number of batches and measuring runtime growth, comparing against fixed-time permutation tests