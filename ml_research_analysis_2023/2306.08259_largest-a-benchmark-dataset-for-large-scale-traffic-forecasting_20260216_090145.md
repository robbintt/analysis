---
ver: rpa2
title: 'LargeST: A Benchmark Dataset for Large-Scale Traffic Forecasting'
arxiv_id: '2306.08259'
source_url: https://arxiv.org/abs/2306.08259
tags:
- traffic
- data
- forecasting
- datasets
- flow
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LargeST is a benchmark dataset for large-scale traffic forecasting
  that addresses key limitations of existing datasets, including small graph sizes,
  short temporal coverage, and lack of metadata. It contains 8,600 sensors in California
  with 5 years of traffic flow data and comprehensive metadata.
---

# LargeST: A Benchmark Dataset for Large-Scale Traffic Forecasting

## Quick Facts
- arXiv ID: 2306.08259
- Source URL: https://arxiv.org/abs/2306.08259
- Reference count: 37
- Large-scale traffic forecasting benchmark with 8,600 sensors and 5 years of data

## Executive Summary
LargeST addresses key limitations of existing traffic forecasting datasets by providing a large-scale benchmark with comprehensive metadata and extensive temporal coverage. The dataset contains 8,600 sensors across California with 5 years of traffic flow data at 5-minute intervals. It is organized into four sub-datasets of varying sizes to enable evaluation at different scales. Data analysis reveals strong correlations between traffic flow and factors such as region, time of day/week, and metadata like highway categories and number of lanes. Experiments with 11 baseline methods demonstrate the need for models that are accurate, efficient, and scalable for real-world applications.

## Method Summary
LargeST is constructed from 8,600 traffic sensors in California with 5 years of historical data (2017-2021) at 5-minute intervals. The dataset is organized into four sub-datasets (CA, GLA, GBA, SD) with varying numbers of nodes to enable evaluation at different scales. Each sensor includes comprehensive metadata including coordinates, district, highway location, direction, and number of lanes. The data is aggregated from 5-minute intervals to 15-minute windows for experiments. Models are evaluated using MAE, RMSE, and MAPE for horizons 3, 6, and 12 steps, with additional efficiency metrics measuring training and inference time.

## Key Results
- LargeST contains 8,600 sensors with 5 years of traffic flow data, addressing limitations of small graph sizes and short temporal coverage in existing datasets
- Data analysis reveals strong correlations between traffic flow and metadata factors including highway categories, number of lanes, and temporal features
- Experiments with 11 baseline methods show scalability challenges, with only half of models able to run on the largest dataset (CA)
- Metadata enrichment and temporal depth enable more comprehensive evaluation of model performance and interpretability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph size scaling reveals model capacity limits
- Mechanism: Larger graphs with more nodes increase parameter and memory demands, exposing scalability bottlenecks in existing models
- Core assumption: Traffic forecasting models optimized for small graphs fail on larger datasets due to architectural constraints
- Evidence anchors:
  - [abstract] "promising results achieved on current public datasets may not be applicable to practical scenarios due to limitations within these datasets"
  - [section] "the majority of them turn out to be not scalable to larger sensor networks"
  - [corpus] weak evidence, no direct comparison of model performance on differently sized graphs
- Break condition: When memory or parameter constraints prevent model execution

### Mechanism 2
- Claim: Temporal coverage depth uncovers long-term patterns
- Mechanism: Longer temporal spans enable detection of seasonal trends and long-range dependencies missed by shorter datasets
- Core assumption: Traffic patterns exhibit meaningful variations across seasons and years
- Evidence anchors:
  - [abstract] "temporal coverage of these datasets is typically short, posing hurdles in studying long-term patterns"
  - [section] "allows for the study of long-term patterns, such as seasonal trends on a weekly or monthly basis"
  - [corpus] no explicit evidence of pattern detection in longer time series
- Break condition: When temporal correlations are negligible or irrelevant to forecasting accuracy

### Mechanism 3
- Claim: Metadata enriches model interpretability and feature space
- Mechanism: Highway categories and lane counts provide contextual features that correlate with traffic flow patterns
- Core assumption: Physical characteristics of road infrastructure directly influence traffic behavior
- Evidence anchors:
  - [abstract] "datasets often lack adequate metadata for sensors, which compromises the reliability and interpretability of the data"
  - [section] "traffic forecasting benefits from the provided node features in designing models"
  - [corpus] no corpus evidence linking metadata to improved model predictions
- Break condition: When metadata features show no correlation with target variables

## Foundational Learning

- Graph neural networks
  - Why needed here: Capture spatial dependencies between traffic sensors in road network
  - Quick check question: How does message passing in GNNs model traffic flow between neighboring sensors?

- Temporal modeling
  - Why needed here: Model temporal dependencies in traffic patterns across time steps
  - Quick check question: What advantages do TCNs have over RNNs for traffic forecasting?

- Metadata integration
  - Why needed here: Incorporate highway characteristics and lane counts as additional predictive features
  - Quick check question: How can node-level metadata improve traffic flow predictions?

## Architecture Onboarding

- Component map: Data preprocessing -> Graph adjacency matrix computation -> Model training loop -> Performance evaluation
- Critical path: Data preprocessing → Graph adjacency matrix computation → Model training loop → Performance evaluation
- Design tradeoffs: Model complexity vs. scalability, temporal resolution vs. computational cost
- Failure signatures: Out-of-memory errors on larger datasets, poor performance on longer horizons
- First 3 experiments:
  1. Compare baseline performance on smallest vs. largest sub-dataset
  2. Evaluate impact of metadata inclusion on forecasting accuracy
  3. Test different temporal aggregation intervals (5min vs. 15min) on model performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different types of metadata (highway categories, number of lanes, etc.) contribute individually to traffic forecasting accuracy, and what is their relative importance?
- Basis in paper: [explicit] The paper identifies metadata characteristics showing strong correlations with traffic flow values, suggesting their potential value for improving predictive performance.
- Why unresolved: The paper conducts data analysis showing correlations between metadata and traffic flow, but does not perform controlled experiments to isolate and quantify the individual contribution of each metadata type to model performance.
- What evidence would resolve it: Experiments comparing model performance with and without specific metadata types, or feature ablation studies showing the impact of each metadata feature on prediction accuracy.

### Open Question 2
- Question: What is the optimal balance between model complexity and efficiency for large-scale traffic forecasting, and how does this balance change with dataset size?
- Basis in paper: [explicit] The paper observes that newer methods show increasing accuracy but also increasing complexity, which negatively impacts efficiency and scalability. It notes that simpler methods like GWNET often perform competitively while being more efficient.
- Why unresolved: The paper demonstrates a trade-off between complexity and performance but does not systematically explore the optimal complexity-efficiency trade-off or how it scales with dataset size.
- What evidence would resolve it: Comprehensive benchmarking studies varying model complexity and architecture choices across different dataset scales to identify optimal configurations.

### Open Question 3
- Question: How do different temporal aggregation strategies (5-minute, 15-minute, hourly) affect the performance and scalability of traffic forecasting models?
- Basis in paper: [inferred] The paper aggregates data from 5-minute intervals to 15-minute windows for experiments, suggesting this is a parameter worth exploring. The temporal coverage analysis also highlights the importance of temporal features.
- Why unresolved: The paper uses a specific aggregation level but does not investigate how different temporal resolutions impact model performance, efficiency, or scalability.
- What evidence would resolve it: Systematic experiments comparing model performance across multiple temporal aggregation levels to identify optimal temporal resolution for different forecasting horizons and dataset sizes.

## Limitations
- No direct evidence that metadata features actually improve model predictions
- Lack of systematic testing to quantify model scalability limits across different graph sizes
- Temporal scaling benefits not empirically validated with pattern detection analysis

## Confidence

**High Confidence**: Dataset construction methodology, data quality (8,600 sensors, 5-year coverage), baseline model implementations

**Medium Confidence**: Claims about metadata importance, temporal scaling benefits

**Low Confidence**: Claims about model scalability limits without systematic testing, impact of metadata on model performance

## Next Checks
1. **Metadata Impact Validation**: Conduct ablation studies removing metadata features to quantify their actual contribution to forecasting accuracy across different models
2. **Temporal Pattern Analysis**: Perform time series analysis on the 5-year data to identify and validate the presence of long-term seasonal patterns that shorter datasets miss
3. **Graph Scaling Benchmark**: Systematically test each baseline model's performance and resource usage (memory, time) across all four sub-datasets to quantify scalability bottlenecks with concrete metrics