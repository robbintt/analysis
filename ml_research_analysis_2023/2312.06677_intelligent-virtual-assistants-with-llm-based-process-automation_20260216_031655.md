---
ver: rpa2
title: Intelligent Virtual Assistants with LLM-based Process Automation
arxiv_id: '2312.06677'
source_url: https://arxiv.org/abs/2312.06677
tags:
- action
- language
- arxiv
- large
- task
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces an intelligent virtual assistant based on
  large language models (LLMs) to automate multi-step operations within mobile apps
  based on natural language instructions. The LLMPA system includes modules for instruction
  decomposition, interface element detection, action prediction, and error checking.
---

# Intelligent Virtual Assistants with LLM-based Process Automation

## Quick Facts
- arXiv ID: 2312.06677
- Source URL: https://arxiv.org/abs/2312.06677
- Reference count: 37
- Primary result: LLM-based virtual assistant successfully automates multi-step mobile app operations with 93.71% step success rate and 70.42% task success rate in Alipay deployment

## Executive Summary
This paper introduces LLMPA (Large Language Model-based Process Automation), an intelligent virtual assistant that automates complex multi-step operations within mobile applications using natural language instructions. The system integrates instruction decomposition, interface element detection, action prediction, and error checking modules to handle real-world tasks in the Alipay mobile payment app. The LLMPA framework demonstrates significant improvements over existing solutions by leveraging large language models to understand context, decompose tasks, and predict next actions while maintaining robust performance through a controllable calibration mechanism.

## Method Summary
The LLMPA system employs a multi-module architecture centered around a large language model. It begins with instruction decomposition to break complex tasks into manageable sub-steps, then uses interface element detection (via YOLOX) to identify interactive components. The action prediction module, guided by elaborate instruction chains and previous action descriptions, predicts the next executable action. A controllable calibration module validates predicted actions for executability and logical consistency. The system was trained on 2000 manually annotated tasks from the Alipay app and evaluated through weekly fine-tuning cycles.

## Key Results
- Step Success Rate of 93.71% achieved in online deployment
- Task Success Rate of 70.42% demonstrates effective completion of complex multi-step operations
- Successful handling of ambiguous and incomplete natural language instructions
- Real-world deployment validated in widely-used Alipay mobile payment application

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Large Language Models (LLMs) enable intelligent virtual assistants to parse and understand complex multi-step natural language instructions that go beyond simple pre-defined commands.
- Mechanism: LLMs leverage their training on vast amounts of text data to comprehend context, infer intent, and break down goals into actionable steps. This allows them to handle ambiguous or incomplete instructions that current assistants struggle with.
- Core assumption: The LLM has been trained on sufficient task-specific data to understand the domain and generate appropriate responses.
- Evidence anchors: [abstract] "recent breakthroughs in large language models (LLMs) show promise for overcoming existing barriers by enhancing natural language processing and reasoning capabilities"
- Break condition: The LLM lacks sufficient training data for the target domain or the instructions are too complex or ambiguous for the model to handle.

### Mechanism 2
- Claim: The LLMPA architecture decomposes tasks into manageable steps and provides explicit guidance to the LLM for predicting the next action.
- Mechanism: The Instruction Chains Generator creates a hierarchical breakdown of the task into sub-steps. The Previous Action Description Generator provides context by describing the prior action and its effects. These are combined with the current page content to construct a prompt for the LLM to predict the next action.
- Core assumption: The LLM can effectively use the decomposed instruction chains and previous action descriptions to make accurate next action predictions.
- Evidence anchors: [abstract] "LLM-based Process Automation (LLMPA) has modules for decomposing instructions, generating descriptions, detecting interface elements, predicting next actions, and error checking"
- Break condition: The LLM struggles to use the provided context and instruction chains to make accurate predictions, or the action space is too large and complex.

### Mechanism 3
- Claim: The Controllable Calibration module mitigates the risk of LLM hallucinations and ensures predicted actions are executable and logically consistent.
- Mechanism: The module checks if the predicted element can be interacted with (click, scroll, type) and if the action makes logical sense based on the key paths learned from previous actions. Non-compliant predictions are sent back for revision.
- Core assumption: The learned key paths accurately capture the logical flow of actions for the task, and the executability checks are reliable.
- Evidence anchors: [abstract] "ensuring robust performance and handling variability in real-world user commands"
- Break condition: The calibration checks are too restrictive and prevent valid actions, or they are too lenient and allow erroneous predictions.

## Foundational Learning

- Concept: Natural Language Understanding (NLU)
  - Why needed here: The assistant needs to accurately interpret user instructions and extract the intent and parameters from natural language.
  - Quick check question: Given the instruction "Order a pepperoni pizza for delivery to 123 Main St", what is the user's intent and what are the key parameters?

- Concept: Task Decomposition
  - Why needed here: Complex tasks need to be broken down into smaller, manageable sub-steps that can be executed sequentially.
  - Quick check question: For the task "Book a round-trip flight from NYC to LA", what are the key sub-steps involved?

- Concept: Context Awareness
  - Why needed here: The assistant needs to maintain awareness of the current state of the task and the effects of previous actions to make informed decisions about the next steps.
  - Quick check question: If the previous action was "Click on the 'Add to Cart' button for item X", what is the likely effect on the current state and what might be the next logical action?

## Architecture Onboarding

- Component map: Chatbot (multi-turn dialogue + intent extraction) -> LLMPA Agent (Instruction Chains Generator + Previous Action Description Generator + Object Detection + Action Prediction + Controllable Calibration) -> Executor (simulates actions on the app) -> Environmental context (current page content from UI trees)

- Critical path: User instruction → Chatbot intent extraction → LLMPA Agent (decompose task → predict next action → check validity) → Executor (perform action) → Repeat until task completion

- Design tradeoffs:
  - Granularity of instruction chains: More detailed chains improve action prediction but require more training data and increase complexity
  - Context window size: Larger context improves understanding but increases computational cost and may hit token limits
  - Calibration strictness: Stricter checks improve reliability but may slow down task completion or miss valid actions

- Failure signatures:
  - LLM predictions are consistently incorrect or nonsensical
  - Executor fails to find the predicted elements on the screen
  - Task gets stuck in a loop or fails to progress
  - Actions are performed out of logical order

- First 3 experiments:
  1. Test the end-to-end pipeline with a simple, well-defined task (e.g., "Open the Alipay app and navigate to the home screen"). Verify that the assistant can complete the task successfully.
  2. Evaluate the impact of instruction chains on action prediction accuracy by comparing performance with and without the Instruction Chains Generator.
  3. Assess the effectiveness of the Controllable Calibration module by measuring the reduction in invalid or illogical actions when it is enabled vs. disabled.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the LLMPA system be optimized for on-device deployment on mobile devices, given the resource-intensive nature of large language models?
- Basis in paper: [inferred] The paper discusses the challenges of deploying large language models on mobile devices due to their resource-intensive nature and suggests that further work is needed to optimize models for on-device usage.
- Why unresolved: While the paper acknowledges the need for optimization, it does not provide specific solutions or strategies for achieving efficient on-device deployment of the LLMPA system.
- What evidence would resolve it: Development and testing of lightweight model architectures, quantization techniques, or other optimization methods that enable efficient on-device inference while maintaining the system's performance.

### Open Question 2
- Question: How can the training data for the LLMPA system be expanded to encompass more diverse user utterances and reduce potential biases or errors?
- Basis in paper: [inferred] The paper mentions that the system is constrained by the training data and that expanding the data to include more diverse user utterances is important for future work.
- Why unresolved: The paper does not provide specific details on the current training data or strategies for expanding it to cover a wider range of user interactions and reduce potential biases.
- What evidence would resolve it: Analysis of the current training data, identification of underrepresented user interactions, and implementation of data collection and augmentation techniques to create a more diverse and representative dataset.

### Open Question 3
- Question: What are the limitations of the current LLMPA system in handling unfamiliar phrasings or requests that are not well-represented in the training data?
- Basis in paper: [explicit] The paper states that the system remains constrained by the training data, meaning that unfamiliar phrasings or requests may still pose a challenge.
- Why unresolved: While the paper acknowledges this limitation, it does not provide specific examples or quantify the extent to which the system struggles with out-of-distribution inputs.
- What evidence would resolve it: Empirical evaluation of the system's performance on a dataset containing unfamiliar phrasings or requests, along with analysis of the failure cases and potential reasons for the system's inability to handle such inputs effectively.

## Limitations

- Evaluation limited to single mobile application (Alipay), restricting generalizability to other apps and domains
- Controllable Calibration module effectiveness in preventing hallucinations asserted but not quantitatively validated against baseline
- Evaluation lacks metrics for task completion time and computational overhead critical for real-world deployment
- System performance heavily dependent on quality and diversity of training data, which remains a constraint

## Confidence

- **High Confidence**: The LLMPA system can successfully complete multi-step tasks in Alipay based on natural language instructions
- **Medium Confidence**: The Instruction Chains Generator and Previous Action Description Generator effectively guide the LLM for next action prediction
- **Low Confidence**: The Controllable Calibration module significantly reduces LLM hallucinations and ensures logical consistency of actions

## Next Checks

1. **Cross-Application Evaluation**: Test the LLMPA system on at least two additional mobile applications with different UI layouts and interaction patterns to assess generalizability

2. **Calibration Module A/B Test**: Conduct a controlled experiment comparing task success rates and hallucination frequency with and without the Controllable Calibration module enabled

3. **Runtime Performance Analysis**: Measure end-to-end task completion time and computational resource usage for a representative sample of tasks to evaluate deployment feasibility