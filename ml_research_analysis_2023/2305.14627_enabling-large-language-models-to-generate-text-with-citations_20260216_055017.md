---
ver: rpa2
title: Enabling Large Language Models to Generate Text with Citations
arxiv_id: '2305.14627'
source_url: https://arxiv.org/abs/2305.14627
tags:
- citation
- passages
- question
- recall
- vanilla
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This work introduces ALCE, the first benchmark for automatically\
  \ evaluating large language models' ability to generate text with citations. The\
  \ authors develop automatic metrics along three dimensions\u2014fluency, correctness,\
  \ and citation quality\u2014and demonstrate their strong correlation with human\
  \ judgements."
---

# Enabling Large Language Models to Generate Text with Citations

## Quick Facts
- arXiv ID: 2305.14627
- Source URL: https://arxiv.org/abs/2305.14627
- Reference count: 22
- Primary result: Current LLMs lack complete citation support 49% of the time on ELI5 dataset

## Executive Summary
This paper introduces ALCE, the first benchmark for evaluating large language models' ability to generate text with citations. The benchmark automatically assesses three dimensions—fluency, correctness, and citation quality—using NLI models and other metrics. Experiments with state-of-the-art LLMs reveal substantial room for improvement, with even the best models struggling to provide comprehensive citations. The work identifies key challenges including retrieval quality, context window limitations, and the need for better synthesis strategies.

## Method Summary
The method involves retrieving relevant passages using dense retrievers (GTR/DPR for Wikipedia, BM25 for Sphere), generating answers with citations through various synthesis strategies (VANILLA, SUMM/SNIPPET, INTERACT, INLINE_SEARCH, CLOSED BOOK), and evaluating outputs using automatic metrics. Evaluation combines MAUVE for fluency, NLI-based metrics for citation quality, and dataset-specific correctness metrics (EM recall for ASQA, recall-5 for QAMPARI, claim recall for ELI5). The framework requires questions, retrieval corpora, and implementations of different synthesis approaches.

## Key Results
- Current LLMs lack complete citation support 49% of the time on ELI5 dataset
- Retrieval quality directly impacts citation performance and correctness
- Automatic metrics show strong correlation with human judgements for citation quality
- Even state-of-the-art models have substantial room for improvement in citation generation

## Why This Works (Mechanism)

### Mechanism 1
Citations improve factual correctness and verifiability by allowing users to verify claims against original sources. This reduces hallucination risk when LLMs cite supporting passages. The mechanism assumes users can effectively judge whether cited passages support generated claims, using NLI models to automate this verification.

### Mechanism 2
Automatic metrics reliably evaluate citation quality by using NLI models to determine entailment between cited passages and generated statements. MAUVE measures fluency while specialized metrics assess correctness. This approach assumes NLI models can accurately capture semantic relationships between passages and claims.

### Mechanism 3
Retrieval quality is crucial for final citation performance since better retrievers provide more relevant passages in context. The mechanism assumes increasing retrieval recall will proportionally improve LLM citation performance, though context window limitations may create bottlenecks.

## Foundational Learning

- **Natural Language Inference (NLI)**: Needed to determine if cited passages entail generated claims for citation quality evaluation. Quick check: Can you explain the difference between "entailment" and "contradiction" in NLI?

- **Dense Passage Retrieval**: Essential for finding relevant passages that LLMs can cite, directly impacting citation quality. Quick check: How does dense retrieval differ from traditional keyword-based retrieval?

- **Context Window Limitations**: Understanding how limited context windows affect passage incorporation is crucial for constraining citation capabilities. Quick check: What happens when you exceed an LLM's context window with too many passages?

## Architecture Onboarding

- **Component map**: Question → Retriever → LLM with prompt → Generation with citations → Automatic evaluation (MAUVE + NLI + correctness metrics)
- **Critical path**: Retriever quality → Context incorporation → Citation generation → Evaluation
- **Design tradeoffs**: More passages improve recall but may exceed context window; summaries save space but lose information
- **Failure signatures**: High citation recall but low precision (irrelevant citations), low correctness despite good retrieval
- **First 3 experiments**:
  1. Compare different retrievers (DPR vs GTR) on citation quality
  2. Test effect of number of passages in context on citation performance
  3. Evaluate closed-book vs open-book models with post-hoc citation

## Open Questions the Paper Calls Out

- **Open Question 1**: Can we develop a better ϕ function that can detect "partial support" in citations, as opposed to the current binary "support" or "no support" determination? The current NLI model cannot detect "partial support" and leads to higher false positive rates.

- **Open Question 2**: How can we improve retrieval quality and coverage of relevant passages given that current retrievers still have substantial room for improvement? The paper suggests this is crucial but doesn't explore advanced retrieval methods beyond simple off-the-shelf retrievers.

- **Open Question 3**: Can we develop LLMs with longer context windows that can effectively incorporate more retrieved passages? The paper identifies this as a major challenge but doesn't explore longer-context LLMs.

## Limitations

- The evaluation framework relies heavily on NLI models that may not perfectly capture semantic entailment, particularly for complex claims.
- The benchmark's reliance on English-only datasets and English-centric corpora limits generalizability to other languages and domains.
- The analysis is constrained by current LLM context window limitations, which may artificially cap citation quality even when retrieval is strong.

## Confidence

**High Confidence**: The finding that current LLMs have substantial room for improvement in citation generation (49% lacking complete citations on ELI5) is well-supported by multiple experiments.

**Medium Confidence**: The correlation between automatic metrics and human judgments is demonstrated but relies on a single human evaluation study with limited scale.

**Low Confidence**: Claims about relative effectiveness of different LLM architectures may be influenced by implementation choices and prompt engineering details that aren't fully transparent.

## Next Checks

1. **Cross-dataset consistency test**: Apply ALCE benchmark to additional datasets beyond ASQA, QAMPARI, and ELI5 to verify robustness of automatic metrics and confirm consistent LLM struggles across domains.

2. **Manual validation of NLI-based metrics**: Conduct larger-scale human evaluation (minimum 200 samples) comparing NLI model predictions with human judgments on citation quality to quantify potential systematic biases.

3. **Context window stress test**: Systematically vary number of retrieved passages (k=5, 10, 25, 50, 100) while measuring marginal benefit to citation quality to determine whether limitations are due to architecture constraints or suboptimal synthesis strategies.