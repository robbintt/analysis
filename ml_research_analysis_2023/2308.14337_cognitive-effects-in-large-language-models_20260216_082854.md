---
ver: rpa2
title: Cognitive Effects in Large Language Models
arxiv_id: '2308.14337'
source_url: https://arxiv.org/abs/2308.14337
tags:
- gpt-3
- effect
- word
- were
- number
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates whether GPT-3 exhibits five well-known
  cognitive effects that are typically observed in human cognition. The authors tested
  GPT-3 on priming, distance, SNARC, size congruity, and anchoring effects using novel
  text-based experimental designs that translate traditional cognitive tasks into
  language model prompts.
---

# Cognitive Effects in Large Language Models

## Quick Facts
- **arXiv ID:** 2308.14337
- **Source URL:** https://arxiv.org/abs/2308.14337
- **Reference count:** 38
- **Key outcome:** GPT-3 exhibits priming, distance, SNARC, and size congruity effects but not anchoring effect, suggesting these cognitive-like behaviors arise from architecture rather than direct training data copying.

## Executive Summary
This paper investigates whether GPT-3 exhibits five well-known cognitive effects that are typically observed in human cognition. The authors tested GPT-3 on priming, distance, SNARC, size congruity, and anchoring effects using novel text-based experimental designs that translate traditional cognitive tasks into language model prompts. Results show that GPT-3 demonstrates the priming, distance, SNARC, and size congruity effects, but not the anchoring effect. These findings suggest that GPT-3's cognitive-like behaviors are not simply mimicked from training data but may be inherent to its architecture, raising important questions about the nature of its internal representations and decision-making processes.

## Method Summary
The study used GPT-3 (text-davinci-003) with logprobs=5 to obtain probability distributions for responses to text-based prompts designed to test each cognitive effect. The experiments translated traditional cognitive psychology tasks into language model prompts using animals, numbers, months, letters, and sequences as stimuli. Confidence was measured as the probability assigned to correct predictions. Multiple experimental variations were tested for each effect, including different prompt formats, word lengths, and response requirements to validate the robustness of findings.

## Key Results
- GPT-3 demonstrates priming effect with semantically related words showing higher confidence than unrelated pairs
- Distance effect observed where letter spacing affects recognition confidence in predictable patterns
- SNARC effect found with number magnitude classification showing left-right spatial associations
- Size congruity effect present for animal comparisons but absent or reversed for numerical comparisons
- Anchoring effect not observed in any experimental variation tested

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3's cognitive effects are not directly copied from training data but arise from its internal processing.
- Mechanism: The model generalizes patterns from diverse text exposure, forming internal representations that mimic human cognitive biases without exact replication.
- Core assumption: Training data contains implicit references to cognitive effects but not explicit task formats used in experiments.
- Evidence anchors:
  - [abstract] "These findings suggest that GPT-3's cognitive-like behaviors are not simply mimicked from training data but may be inherent to its architecture"
  - [section] "it is unlikely that these papers have text with formats similar to our queries, and it would be absurd to expect GPT-3 to generalize such as 'people respond faster to words recognition when words following associated words'"
  - [corpus] Weak: Neighbors discuss similar biases but don't confirm exact task formats
- Break condition: If exact query formats appear verbatim in training data, the mechanism fails.

### Mechanism 2
- Claim: Transformer architecture enables selective attention that mirrors human cognitive processing.
- Mechanism: Self-attention mechanisms allow GPT-3 to prioritize relevant parts of input sequences, creating cognitive-like behavior patterns.
- Core assumption: Attention mechanisms in transformers can approximate human selective processing.
- Evidence anchors:
  - [section] "GPT-3’s capacity to selectively attend to certain segments of its input sequence, due to its transformer-based architecture, could account for certain outcomes"
  - [abstract] "raises important questions about the nature of its internal representations and decision-making processes"
  - [corpus] Weak: No direct corpus evidence about attention mechanisms causing cognitive effects
- Break condition: If attention weights show no correlation with experimental outcomes, the mechanism fails.

### Mechanism 3
- Claim: GPT-3's uncertainty patterns follow human-like cognitive principles.
- Mechanism: The model exhibits systematic confidence variations that mirror human reaction time patterns in cognitive tasks.
- Core assumption: Confidence probability distributions can proxy for human cognitive difficulty.
- Evidence anchors:
  - [section] "we measure GPT-3’s confidence, the probability it assigns to the correct prediction, in proportion to the overall probability assigned to relevant predictions"
  - [abstract] "We found that LLMs are indeed prone to several human cognitive effects"
  - [corpus] Weak: Neighbors discuss bias but not confidence patterns specifically
- Break condition: If confidence patterns show no systematic relationship to experimental conditions, the mechanism fails.

## Foundational Learning

- Concept: Cognitive psychology effects (priming, distance, SNARC, size congruity, anchoring)
  - Why needed here: Understanding these effects is essential to design appropriate text-based experiments
  - Quick check question: Can you explain the difference between priming and anchoring effects in human cognition?

- Concept: Transformer architecture and self-attention mechanisms
  - Why needed here: The model's internal processing determines how it exhibits cognitive-like behaviors
  - Quick check question: How does self-attention differ from traditional recurrent neural network processing?

- Concept: Experimental design in cognitive psychology
  - Why needed here: Converting real-world experiments to text-based formats requires understanding of underlying principles
  - Quick check question: What is the relationship between reaction time and task difficulty in cognitive experiments?

## Architecture Onboarding

- Component map: Tokenization -> Embedding -> Transformer blocks (self-attention + feed-forward) -> Output probability distribution -> Sampling or analysis
- Critical path: Tokenization → Embedding → Transformer blocks (self-attention + feed-forward) → Output probability distribution → Sampling or analysis
- Design tradeoffs: Large parameter count enables complex pattern recognition but reduces interpretability. Randomness parameters affect reproducibility but enable more natural responses.
- Failure signatures: High confidence on all outputs (masking effects), complete failure to recognize patterns, or inconsistent responses across identical queries indicate experimental design issues.
- First 3 experiments:
  1. Test priming effect with semantically related vs unrelated word pairs using the "sentence" variation format
  2. Test distance effect with animal size comparisons using varied spacing between letters
  3. Test SNARC effect with number magnitude classification using left/right response mappings

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does GPT-3's display of cognitive effects indicate genuine cognitive processes or merely pattern recognition from training data?
- Basis in paper: [explicit] The authors discuss whether effects are "imitated or reinvented" by GPT-3 and note that training data likely contains papers describing these effects, yet the effects likely cannot be directly replicated from text formats in training data.
- Why unresolved: The paper shows GPT-3 exhibits effects like priming, distance, SNARC, and size congruity, but cannot definitively determine if these arise from genuine cognitive processes or sophisticated pattern matching.
- What evidence would resolve it: Experiments testing GPT-3's generalization of effects to novel contexts not present in training data, or ablation studies examining which architectural components are necessary for the effects.

### Open Question 2
- Question: What specific mechanisms in GPT-3's transformer architecture enable the distance effect and SNARC effect?
- Basis in paper: [explicit] The authors hypothesize a "mental number line" for distance effect and suggest transformer attention mechanisms may focus on priming words, but cannot pinpoint exact architectural causes.
- Why unresolved: While the effects are demonstrated, the paper can only speculate about attention mechanisms and mental representations without concrete evidence of how transformer layers produce these cognitive phenomena.
- What evidence would resolve it: Detailed analysis of attention weight patterns during effect-evoking prompts, or experiments with modified transformer architectures to test which components are necessary.

### Open Question 3
- Question: Why does GPT-3 show the size congruity effect for animals but not for numbers?
- Basis in paper: [explicit] The authors observe the effect exists for animal comparisons (capitalization affecting size judgments) but is "limited or even opposite when it comes to numbers."
- Why unresolved: The paper does not provide a satisfactory explanation for this differential manifestation of the effect across domains.
- What evidence would resolve it: Systematic experiments varying the type of magnitude comparison (animals, numbers, months, letters) with different manipulations of presentation size to identify what triggers the effect.

## Limitations

- The study cannot definitively prove cognitive effects arise from architecture rather than sophisticated pattern matching from training data
- Anchoring effect's absence could reflect genuine architectural differences or experimental design limitations
- Confidence measurements using probability distributions may not fully capture the complexity of human cognitive processes

## Confidence

- **High confidence:** GPT-3 demonstrates priming, distance, SNARC, and size congruity effects with statistically significant confidence variations across experimental conditions. The experimental methodology and results are clearly presented and reproducible.
- **Medium confidence:** The claim that cognitive effects are not directly copied from training data, given the lack of systematic verification of training corpus content and the difficulty in proving negative space (what's not in training data).
- **Low confidence:** The assertion that observed effects are "inherent to architecture" rather than emergent properties of the specific training process or hyperparameters used.

## Next Checks

1. Conduct systematic analysis of GPT-3's training corpus to identify whether exact experimental formats or semantically similar patterns exist, using embedding similarity searches and n-gram frequency analysis.

2. Replicate experiments across multiple GPT-3 variants (different sizes and training iterations) to determine if cognitive effects persist consistently or vary with model scale and training parameters.

3. Test whether confidence patterns correlate with specific architectural components by comparing GPT-3's behavior with transformer variants lacking certain attention mechanisms or using different positional encoding schemes.