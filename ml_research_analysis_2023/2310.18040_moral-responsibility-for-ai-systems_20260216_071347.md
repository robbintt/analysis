---
ver: rpa2
title: Moral Responsibility for AI Systems
arxiv_id: '2310.18040'
source_url: https://arxiv.org/abs/2310.18040
tags:
- nition
- causal
- responsibility
- condition
- outcome
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper formalizes moral responsibility for AI systems by integrating
  causal models with epistemic conditions. It defines responsibility as requiring
  both causation and awareness of consequences, using a formal framework that can
  be implemented in AI systems.
---

# Moral Responsibility for AI Systems

## Quick Facts
- arXiv ID: 2310.18040
- Source URL: https://arxiv.org/abs/2310.18040
- Reference count: 39
- One-line primary result: Formalizes moral responsibility for AI systems using CNESS causation and epistemic conditions

## Executive Summary
This paper presents a formal framework for moral responsibility in AI systems that integrates causal models with epistemic conditions. The approach defines responsibility as requiring both causation and awareness of consequences, using CNESS causation (a refined version of NESS that handles indirect causation) combined with an epistemic condition that balances outcome minimization with causation probability. The framework produces graded responsibility judgments that align with empirical findings and can be implemented in AI decision-making systems. The work addresses the growing need for ethical AI as automated systems take on increasingly significant decision-making roles.

## Method Summary
The framework formalizes moral responsibility through a two-part definition: a causal condition using CNESS causation (Counterfactual NESS) that combines causal sufficiency with counterfactual difference-making, and an epistemic condition that requires the agent to either minimize the probability of the outcome or, if that's equal, minimize the probability of causing the outcome. The degree of responsibility is defined as a weighted combination of the Eells measure of causal strength (outcome probability difference) and the actual causation measure, with a parameter α expressing their relative importance. The framework is demonstrated through detailed examples including late preemption, loaded gun, and bombing scenarios.

## Key Results
- CNESS causation handles indirect causation correctly where NESS fails
- The epistemic condition balances outcome minimization with causation probability
- Degree of responsibility measure captures graded judgments matching empirical findings

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The CNESS definition of causation handles indirect causation correctly where NESS fails
- Mechanism: CNESS adds counterfactual difference-making to NESS by requiring that no subpath would NESS-cause the outcome if the candidate cause took an alternative value
- Core assumption: Causal influence can be transmitted through intermediate variables in a path
- Evidence anchors:
  - [abstract] "The approach combines causal sufficiency with counterfactual analysis (CNESS causation)"
  - [section] "The Counterfactual NESS definition (CNESS) takes the NESS definition and adds a subtle counterfactual difference-making condition"
  - [corpus] Weak - no direct corpus evidence on CNESS handling indirect causation
- Break condition: If intermediate variables are not properly represented in the causal model structure

### Mechanism 2
- Claim: The epistemic condition balances outcome minimization with causation probability
- Mechanism: Responsibility requires either minimizing the probability of the outcome, or if that's equal, then minimizing the probability of causing the outcome
- Core assumption: An agent's epistemic state about their ability to affect outcomes is captured in their subjective probability distribution over causal settings
- Evidence anchors:
  - [abstract] "an epistemic condition that balances outcome minimization with causation probability"
  - [section] "Therefore I propose the following definition of moral responsibility" with the two-part epistemic condition
  - [corpus] Weak - corpus mentions responsibility but doesn't detail this specific epistemic balance mechanism
- Break condition: If the agent's subjective probabilities are not well-calibrated or if they have incomplete information about causal structure

### Mechanism 3
- Claim: The degree of responsibility measure captures graded responsibility judgments that align with empirical findings
- Mechanism: The measure combines the Eells measure of causal strength (outcome probability difference) with the actual causation measure, weighted by α
- Core assumption: People's responsibility judgments vary based on how much an agent could have reduced the probability of the outcome
- Evidence anchors:
  - [abstract] "Since responsibility is often taken to come in degrees, in Section 6 I define the degree of responsibility"
  - [section] "I suggest the following definition, where the value of α expresses the relative importance of both measures"
  - [corpus] Weak - corpus doesn't discuss the degree of responsibility measure specifically
- Break condition: If the weighting parameter α is not appropriately tuned for the domain or if the causal model structure changes

## Foundational Learning

- Concept: Causal models and structural equations
  - Why needed here: The entire formalization of moral responsibility relies on representing causal relationships between actions and outcomes using causal models
  - Quick check question: In a causal model, if Y = f(X,Z) and we intervene X ← x', what happens to the equation for Y?

- Concept: Actual causation definitions (NESS, HP, CNESS)
  - Why needed here: The causal condition of responsibility requires a formal definition of causation that can handle complex scenarios like indirect causation and overdetermination
  - Quick check question: What is the key difference between NESS-causation and CNESS-causation?

- Concept: Epistemic states and subjective probabilities
  - Why needed here: The epistemic condition requires representing what the agent believes about the possible outcomes of their actions before taking them
- Quick check question: How is an epistemic state represented in this framework?

## Architecture Onboarding

- Component map: Causal model representation (signature and equations) -> Causation evaluation module (NESS, HP, CNESS algorithms) -> Epistemic state module (probability distributions over causal settings) -> Responsibility judgment engine (applies causal and epistemic conditions) -> (Optional) Degree of responsibility calculator (combines causal strength measures)

- Critical path: Causal model → Causation evaluation → Epistemic state assessment → Responsibility judgment → (Optional) Degree calculation

- Design tradeoffs:
  - CNESS vs HP causation: CNESS handles indirect causation better but may be computationally more complex
  - Binary vs graded responsibility: Binary is simpler but graded captures more nuance
  - Subjective vs objective probabilities: Subjective captures agent's beliefs but may be harder to estimate

- Failure signatures:
  - Missing intermediate variables in causal model → Incorrect causation judgments
  - Uncalibrated probability estimates → Wrong epistemic condition assessments
  - Incorrect weighting parameter α → Mis-calibrated degree of responsibility

- First 3 experiments:
  1. Implement CNESS causation evaluation on a simple causal chain (A→B→C) and verify it handles indirect causation correctly
  2. Test the epistemic condition on the Bombing example to verify it distinguishes between actions that minimize outcome probability vs causation probability
  3. Calculate degree of responsibility on the two-assassin example to verify it produces graded judgments matching intuition

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the CNESS definition of causation relate to the alternative definition presented in Beckers (2021)?
- Basis in paper: [explicit] The paper states "I tentatively conjecture that the CNESS definition implies my other definition, and not vice versa."
- Why unresolved: The precise relationship between CNESS and the alternative definition is described as a subject of further investigation, with only a tentative conjecture provided.
- What evidence would resolve it: A formal proof or counterexample demonstrating the relationship between CNESS and the alternative definition of causation.

### Open Question 2
- Question: What is the optimal value of α in the degree of responsibility formula that balances the Eells measure and actual causation measure?
- Basis in paper: [explicit] The paper mentions "the value of α expresses the relative importance of both measures" but doesn't specify what this value should be.
- Why unresolved: The paper treats α as a parameter but doesn't provide guidance on its optimal value or how it might vary across different contexts or applications.
- What evidence would resolve it: Empirical studies comparing responsibility judgments with different α values, or theoretical arguments for specific values based on desired properties.

### Open Question 3
- Question: How should robustness of causation be formally incorporated into the degree of responsibility measure?
- Basis in paper: [inferred] The paper mentions that "recent research suggests plays a role in responsibility judgments that is somewhat independent of causal strength" but doesn't provide a concrete method for incorporating it.
- Why unresolved: While the paper acknowledges the importance of robustness, it only sketches how it could be enhanced rather than providing a formal integration.
- What evidence would resolve it: A formal definition of robustness in causal terms and empirical validation showing how it affects responsibility judgments beyond causal strength.

## Limitations

- CNESS causation is computationally intensive for complex causal models
- The epistemic condition assumes agents have well-calibrated subjective probability distributions
- The degree of responsibility measure depends on domain-specific calibration of the α parameter

## Confidence

- High Confidence: The basic causal model representation and CNESS causation definition
- Medium Confidence: The epistemic condition combining outcome minimization with causation probability minimization
- Medium Confidence: The degree of responsibility measure

## Next Checks

1. **Empirical Validation**: Test the framework against human responsibility judgments in controlled scenarios to verify alignment with moral intuitions
2. **Scalability Assessment**: Implement the CNESS algorithm on larger causal models (10+ variables) to evaluate computational feasibility
3. **Robustness Testing**: Evaluate how sensitive the responsibility judgments are to variations in the epistemic state representations and probability estimates