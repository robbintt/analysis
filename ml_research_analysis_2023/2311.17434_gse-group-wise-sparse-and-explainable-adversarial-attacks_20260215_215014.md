---
ver: rpa2
title: 'GSE: Group-wise Sparse and Explainable Adversarial Attacks'
arxiv_id: '2311.17434'
source_url: https://arxiv.org/abs/2311.17434
tags:
- adversarial
- attacks
- attack
- group-wise
- sparse
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of generating group-wise sparse
  and explainable adversarial attacks that can fool deep neural networks with minimal
  pixel perturbations. The authors propose a novel two-phase algorithm called GSE
  (Group-wise Sparse and Explainable) that combines non-convex regularization with
  Nesterov's accelerated gradient descent.
---

# GSE: Group-wise Sparse and Explainable Adversarial Attacks

## Quick Facts
- arXiv ID: 2311.17434
- Source URL: https://arxiv.org/abs/2311.17434
- Authors: 
- Reference count: 3
- Primary result: Achieves up to 50.9% group-wise sparsity on CIFAR-10 with 100% attack success rate

## Executive Summary
This paper addresses the challenge of generating sparse and explainable adversarial attacks that fool deep neural networks with minimal pixel perturbations. The authors propose GSE, a novel two-phase algorithm that combines non-convex regularization with Nesterov's accelerated gradient descent. The method first optimizes a quasinorm adversarial loss using the 1/2-quasinorm proximal operator, then transitions to projected Nesterov's accelerated gradient descent with 2-norm regularization. Extensive experiments demonstrate significant improvements in group-wise sparsity while maintaining high attack success rates and improved interpretability.

## Method Summary
The GSE algorithm operates in two phases: first, it uses forward-backward splitting with a 1/2-quasinorm proximal operator to identify semantically meaningful sparse regions for perturbation, with dynamic lambda adjustment using Gaussian blur; second, it transitions to projected Nesterov's accelerated gradient descent with 2-norm regularization constrained to the identified sparse subspace. The method is evaluated on CIFAR-10 and ImageNet datasets using ResNet and VGG architectures, measuring attack success rate, sparsity metrics (ACP, ANC), perturbation magnitude, and interpretability scores.

## Key Results
- Achieves up to 50.9% group-wise sparsity on CIFAR-10 (38.4% on ImageNet) compared to state-of-the-art methods
- Maintains 100% attack success rate across all experiments
- Reduces computation time by 38.2% compared to baseline methods
- Generates perturbations that target semantically meaningful regions as evidenced by high interpretability scores

## Why This Works (Mechanism)

### Mechanism 1
The 1/2-quasinorm proximal operator in the first phase enables effective group-wise sparsity by targeting nearby pixels with reduced regularization parameters. The algorithm starts with 1/2-quasinorm regularization and dynamically adjusts regularization parameters using a Gaussian blur kernel on the mask of perturbed pixels, creating a diffusion effect where pixels near already perturbed areas receive lower regularization.

Core assumption: Proximity-based adjustment of regularization parameters effectively identifies semantically meaningful regions that should be perturbed together.
Evidence anchors:
- [abstract] "Subsequently, the algorithm transitions to a projected Nesterov's accelerated gradient descent with 2-norm regularization applied to perturbation magnitudes."
- [section] "In each iteration, the core operation of our algorithm involves the optimization of a quasinorm adversarial loss. This optimization is achieved by employing the 1/2-quasinorm proximal operator for some iterations, a method tailored for nonconvex programming."

### Mechanism 2
The two-phase approach balances exploration of sparse solutions with convergence stability. The first phase uses nonconvex 1/2-quasinorm regularization to explore the sparse solution space and identify promising regions, then transitions to projected Nesterov's accelerated gradient descent with 2-norm regularization for better convergence properties while maintaining the identified sparse structure.

Core assumption: The transition point (k iterations) is sufficient to identify semantically meaningful sparse regions before switching to a more stable optimization method.
Evidence anchors:
- [abstract] "Subsequently, the algorithm transitions to a projected Nesterov's accelerated gradient descent with 2-norm regularization applied to perturbation magnitudes."
- [section] "In all subsequent iterations, we employ projected NAG to approximate a solution to a simplified problem min w∈V L(x + w, t) + µ∥w∥2..."

### Mechanism 3
The subspace projection in the second phase maintains group-wise sparsity by constraining perturbations to only those pixel groups identified in the first phase. After identifying which pixel groups should be perturbed based on their lambda values, the algorithm projects all subsequent updates onto the subspace spanned by these identified pixel groups.

Core assumption: The pixel groups identified in the first phase correspond to semantically meaningful regions that should be perturbed together.
Evidence anchors:
- [abstract] "In all subsequent iterations, we employ projected NAG to approximate a solution to a simplified problem min w∈V L(x + w, t) + µ∥w∥2, where V := span({ei,j,c | λ(k) i,j,c < λ (0) i,j,c}) ⊆ RM ×N ×C..."
- [section] "As V is spanned by these standard unit vectors, we can express the projection onto V as [PV (w)]i,j,c = (wi,j,c, if ei,j,c ∈ V, 0, otherwise)."

## Foundational Learning

- Concept: Proximal operators for nonconvex optimization
  - Why needed here: The 1/2-quasinorm regularization is nonconvex, requiring specialized optimization techniques
  - Quick check question: What property of the 1/2-quasinorm makes it particularly effective for inducing sparsity compared to ℓ1 regularization?

- Concept: Nesterov's accelerated gradient descent and its projected variant
  - Why needed here: The second phase uses projected Nesterov's accelerated gradient descent, which requires understanding both the acceleration mechanism and how projection onto subspaces works
  - Quick check question: How does projected NAG differ from standard NAG in terms of convergence properties and applicability to constrained optimization?

- Concept: Group-wise sparsity and its relationship to semantic interpretability
  - Why needed here: The paper's main contribution is creating group-wise sparse attacks that are also interpretable
  - Quick check question: Why would perturbing all channels of a pixel together lead to more semantically meaningful adversarial examples?

## Architecture Onboarding

- Component map: Input preprocessing -> Phase 1 optimization (k iterations) -> Lambda adjustment -> Phase 2 optimization -> Output adversarial example
- Critical path: Input → Phase 1 optimization (k iterations) → Lambda adjustment → Phase 2 optimization → Output adversarial example
- Design tradeoffs: The algorithm trades off between exploration (Phase 1 with nonconvex regularization) and exploitation/convergence (Phase 2 with projected NAG). The Gaussian blur kernel size trades off between computational efficiency and the spatial extent of group-wise sparsity.
- Failure signatures:
  - High computation time with poor sparsity suggests the lambda adjustment mechanism isn't working effectively
  - Low attack success rate suggests the Phase 1 exploration isn't finding good perturbation regions
  - Poor interpretability (low IS scores) suggests the group-wise sparsity isn't aligning with semantically meaningful regions
- First 3 experiments:
  1. Test with CIFAR-10 dataset on a pre-trained ResNet20 classifier, comparing ACP and ANC metrics against baseline methods
  2. Vary the Gaussian blur kernel size (n) to find the optimal balance between group-wise sparsity and computational efficiency
  3. Test the transition point (k iterations) sensitivity by running Phase 1 for different numbers of iterations and measuring the impact on final sparsity and attack success rate

## Open Questions the Paper Calls Out

### Open Question 1
How can the proposed GSE algorithm be extended to handle other types of non-convex regularization terms beyond the 1/2-quasinorm? The paper focuses on using the 1/2-quasinorm proximal operator and mentions that "our method operates independently of predefined structures, such as pixel partitions." It does not explore the potential of using other non-convex regularization terms or how the algorithm would need to be modified to accommodate them.

### Open Question 2
Can the GSE algorithm be adapted to generate group-wise sparse perturbations for tasks beyond image classification, such as object detection or semantic segmentation? The paper demonstrates effectiveness on image classification but does not explore applications to other computer vision tasks. Adapting the algorithm may require modifications to the loss function, regularization terms, or evaluation metrics.

### Open Question 3
How does the choice of the Gaussian blur kernel size and the tradeoff parameter q affect the performance and interpretability of the generated perturbations? The paper mentions specific values used but does not provide a detailed analysis of how these hyperparameters influence the results or guidance on how to choose them for different datasets or tasks.

## Limitations

- The effectiveness of the Gaussian blur-based lambda adjustment mechanism is primarily demonstrated empirically without theoretical guarantees
- The relationship between group-wise sparsity and semantic interpretability lacks rigorous mathematical formalization
- The claim of "explainability" relies on visual inspection of CAM/ASM visualizations rather than quantitative measures

## Confidence

The confidence in the proposed mechanisms is **Medium**. The theoretical foundation of using nonconvex regularization for sparsity is well-established, but the specific combination of 1/2-quasinorm proximal operators with Gaussian-blurred lambda adjustment represents a novel approach that lacks extensive validation in the literature.

## Next Checks

1. Conduct ablation studies removing the Gaussian blur mechanism to quantify its specific contribution to group-wise sparsity versus using uniform regularization
2. Test the algorithm's sensitivity to the transition point (k iterations) across multiple datasets to establish guidelines for optimal hyperparameter selection
3. Evaluate the perturbations' impact on different semantic regions using quantitative measures beyond visual inspection, such as measuring perturbation density in object versus background regions