---
ver: rpa2
title: Using Kernel SHAP XAI Method to optimize the Network Anomaly Detection Model
arxiv_id: '2308.00074'
source_url: https://arxiv.org/abs/2308.00074
tags:
- features
- detection
- network
- anomaly
- used
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel approach to optimize network anomaly
  detection using the kernelSHAP method from Explainable AI (XAI). The study addresses
  the challenge of explaining why certain network instances are anomalies and others
  are not, due to the unbounded and unsupervised nature of anomaly detection.
---

# Using Kernel SHAP XAI Method to optimize the Network Anomaly Detection Model

## Quick Facts
- arXiv ID: 2308.00074
- Source URL: https://arxiv.org/abs/2308.00074
- Reference count: 38
- One-line result: Proposed OPT_Model achieves 0.90 accuracy and 0.76 F-score on CICIDS2017 dataset using kernelSHAP-based feature selection.

## Executive Summary
This paper presents a novel approach to optimize network anomaly detection by leveraging the kernelSHAP method from Explainable AI. The study addresses the challenge of explaining why certain network instances are anomalies by using kernelSHAP to compute Shapley values based on autoencoder reconstruction error. By selecting the top contributing features, the authors build an optimized model that outperforms the initial model in terms of accuracy, recall, precision, and F-score.

## Method Summary
The authors propose using kernelSHAP to compute Shapley values for each feature based on reconstruction error from an autoencoder trained only on benign data. The background set consists of 200 attack instances clustered with kmeans. Top features with highest Shapley values are selected to build an optimized model (OPT_Model) that outperforms the initial model (Model_1) in terms of accuracy, recall, precision, and F-score. The approach is validated on the CICIDS2017 dataset, achieving an overall accuracy of 0.90 and F-score of 0.76.

## Key Results
- OPT_Model achieves 0.90 accuracy and 0.76 F-score on CICIDS2017 dataset
- Feature selection based on Shapley values improves model performance
- The approach outperforms the initial model (Model_1) in accuracy, recall, precision, and F-score

## Why This Works (Mechanism)

### Mechanism 1
Using kernelSHAP to compute Shapley values based on reconstruction error provides a model-agnostic way to identify which features contribute most to anomalies in an autoencoder-based network intrusion detection system. The autoencoder is trained only on benign data; reconstruction error (RE) for attack samples is higher. KernelSHAP explains each feature's contribution to the RE for attack instances. Features with high Shapley values are selected to build an optimized model, improving accuracy and recall. Core assumption: Higher reconstruction error correlates with anomalous behavior, and Shapley values can effectively rank features' influence on that error.

### Mechanism 2
Selecting a subset of features with the highest Shapley values improves model performance without losing generalization. By training the autoencoder on a reduced feature set identified via Shapley values, the model becomes less complex, less prone to noise, and more accurate at distinguishing attack instances. Core assumption: A smaller, more relevant feature set retains the discriminative power needed for accurate anomaly detection.

### Mechanism 3
Using a background set of attack instances to compute Shapley values ensures that the feature selection process is guided by actual anomaly patterns. The background set (200 attack instances) is clustered to reduce computation and passed to kernelSHAP explainer to compute feature contributions to RE, thus capturing attack-relevant features. Core assumption: Attack instances in the background set are representative of the broader attack space in the test set.

## Foundational Learning

- **Autoencoder reconstruction error as anomaly score**: Why needed - The method relies on the premise that benign data is reconstructed with low error, while anomalous data produces high error. Quick check - What does a high reconstruction error indicate in an autoencoder trained only on benign data?
- **Shapley values and feature attribution**: Why needed - KernelSHAP assigns each feature a contribution score to the reconstruction error, enabling unsupervised feature selection. Quick check - How does kernelSHAP differ from simple correlation-based feature selection?
- **Model-agnostic explainability**: Why needed - KernelSHAP can be applied to any model output, making it suitable for explaining autoencoder behavior without modifying the model. Quick check - Why is model-agnostic explainability important for deep learning anomaly detection?

## Architecture Onboarding

- **Component map**: CICIDS2017 → StandardScaler → Feature set → Autoencoder (Model_1) → All 78 features → Reconstruction error → KernelSHAP explainer → Background set (200 attack samples) → Shapley values → Feature selection → Top 40 features → OPT_Model → Threshold selection → ROC curve → Binary classification
- **Critical path**: CICIDS2017 → Model_1 training → Background set → KernelSHAP → OPT_Model training → Evaluation
- **Design tradeoffs**: Full feature set vs. selected features: Accuracy vs. interpretability and computational cost; Background set size: More samples → better representation but higher computation time; Threshold selection: Balance between false positives and false negatives using ROC
- **Failure signatures**: High variance in reconstruction error → poor separation of benign vs. attack; Shapley values unstable across runs → unreliable feature selection; Threshold too low/high → poor precision or recall
- **First 3 experiments**: 1) Train Model_1 on all features, plot reconstruction error distribution for benign vs. attack; 2) Compute Shapley values on background set, plot top 10 features by contribution; 3) Train OPT_Model on top 40 features, compare accuracy and F1-score to Model_1

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of the OPT_Model change when using different background set sizes or compositions for computing Shapley values? Basis in paper: The paper mentions that the kernelSHAP method's time complexity increases with larger background sets and that selecting an appropriate background set is important. What evidence would resolve it: Comparative experiments showing model performance with varying background set sizes and compositions, including analysis of computational time and Shapley value stability.

### Open Question 2
How would the OPT_Model perform on other network traffic datasets beyond CICIDS2017, such as CICDoS2019 or real-world enterprise network data? Basis in paper: The paper only evaluates the model on the CICIDS2017 dataset, which may have specific characteristics that favor the approach. What evidence would resolve it: Cross-dataset evaluation of the OPT_Model on multiple network traffic datasets, comparing performance metrics and feature importance patterns.

### Open Question 3
What is the impact of using different autoencoder architectures (e.g., variational autoencoder, denoising autoencoder) on the performance of the OPT_Model? Basis in paper: The paper uses a standard autoencoder with a specific architecture but doesn't explore alternative architectures. What evidence would resolve it: Experiments comparing the OPT_Model's performance when using different autoencoder architectures while keeping the feature selection method constant.

## Limitations

- The paper lacks explicit details on autoencoder architecture, including layer sizes, activation functions, and optimizer settings beyond the basic outline
- The selection and preprocessing of the background set for kernelSHAP (specifically the kmeans clustering step) is not fully explained
- The choice of the threshold for classifying anomalies is not clearly justified
- The evaluation is based solely on the CICIDS2017 dataset, which may not generalize well to other network datasets or real-world scenarios

## Confidence

- **High**: The use of kernelSHAP for feature attribution and the overall approach of selecting features based on Shapley values for improving anomaly detection are well-grounded in the literature
- **Medium**: The reported performance metrics (accuracy, recall, precision, F-score) are based on the CICIDS2017 dataset, but the lack of detailed methodology and external validation limits confidence in the generalizability of the results
- **Low**: The specific implementation details of the autoencoder and the kernelSHAP explainer, including hyperparameter choices and the exact process of background set preparation, are not fully disclosed

## Next Checks

1. Verify Feature Selection: Replicate the feature selection process using the provided methodology, focusing on the computation of Shapley values from the reconstruction error and the selection of the top 40 features. Compare the selected features with those in the paper to ensure consistency.
2. Reconstruct Autoencoder Architecture: Attempt to reconstruct the autoencoder architecture (number of layers, neurons, activation functions, optimizer) based on the description and any available supplementary materials. Train the autoencoder on the CICIDS2017 dataset and compare the reconstruction error distribution for benign and attack instances.
3. External Validation: Test the optimized model (OPT_Model) on a different network dataset or a subset of CICIDS2017 not used in the original study to assess the generalizability of the results. Compare the performance metrics with those reported in the paper.