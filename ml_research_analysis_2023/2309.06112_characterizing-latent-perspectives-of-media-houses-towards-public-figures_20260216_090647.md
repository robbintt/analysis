---
ver: rpa2
title: Characterizing Latent Perspectives of Media Houses Towards Public Figures
arxiv_id: '2309.06112'
source_url: https://arxiv.org/abs/2309.06112
tags:
- entity
- described
- sentences
- corpus
- language
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes a zero-shot generative approach for characterizing
  public figures using GPT-2. The method fine-tunes a GPT-2 model twice: first with
  a corpus of disambiguated entity mentions, then with programmatically constructed
  demonstration sentences in the pattern "X is described as ...".'
---

# Characterizing Latent Perspectives of Media Houses Towards Public Figures

## Quick Facts
- arXiv ID: 2309.06112
- Source URL: https://arxiv.org/abs/2309.06112
- Reference count: 24
- One-line primary result: Zero-shot generative approach for characterizing public figures using GPT-2 with F1 scores 0.842-0.960

## Executive Summary
This paper introduces a zero-shot generative approach for characterizing public figures using GPT-2 without predefined class labels. The method employs a two-stage fine-tuning process where GPT-2 is first adapted to domain-specific news corpora and then fine-tuned on programmatically constructed demonstration sentences in the pattern "X is described as...". Manual prompts are used to generate entity-specific characterizations, which are validated through semantic textual similarity and sentiment analysis. The approach demonstrates strong performance across four media houses, achieving encouraging results in generating diverse and subjective entity characterizations.

## Method Summary
The approach involves two stages of GPT-2 fine-tuning. First, the model is fine-tuned on disambiguated entity mentions from news corpora to adapt to the domain. Second, it is fine-tuned on programmatically constructed demonstration sentences created by extracting clauses from entity sentences and converting them to the pattern "X is described as [gerund]...". Finally, the model generates characterizations for test entities using manual prompts like "is described as having characteristics" or "is described as being", with outputs validated against the fine-tuning corpus using semantic textual similarity and sentiment analysis.

## Key Results
- F1 scores ranging from 0.842-0.960 across four media houses
- Semantic match rates between 28-65% for generated sentences
- Demonstrated ability to generate diverse, subjective characterizations without predefined class labels
- Manual prompts like "is described as having characteristics" and "is described as being" function reasonably well

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-2 can generate entity characterizations through domain adaptation and demonstration fine-tuning
- Mechanism: Fine-tune GPT-2 on disambiguated entity mentions, then on demonstration sentences in "X is described as..." pattern, and prompt with test entities using natural language prefixes
- Core assumption: The model captures semantic relationships between entities and characterizations during fine-tuning and generalizes to unseen entities
- Evidence anchors: [abstract] zero-shot approach for generative characterizations; [section 3.1] domain adaptation prerequisite; [section 4.2] FT2 sentences constructed with "is described as" pattern

### Mechanism 2
- Claim: Programmatically constructed demonstration sentences effectively teach entity characterization patterns
- Mechanism: Extract clauses and parts (Subject, Verb, Object, Adverbials), convert verbs to gerunds, and construct sentences following "X is described as [gerund] [other parts]"
- Core assumption: Structured transformation preserves semantic meaning while creating consistent demonstration format
- Evidence anchors: [section 4.2] FT2 sentences constructed by suffixing Subject with "is described as", converting Verb to Gerund; Weak evidence: limited examples of transformation process

### Mechanism 3
- Claim: Manual prompts in natural language constrain model to generate entity-specific characterizations
- Mechanism: Use natural language prefixes like "X is described as having characteristics" to prime the model
- Core assumption: Chosen prompts are common in corpus and model learned relationship during fine-tuning
- Evidence anchors: [section 4.3] Manual prompts chosen based on prevalence in spoken and written language; [section 5] Prompts function reasonably well for generating non-extractive characterizations

## Foundational Learning

- Concept: Fine-tuning language models on domain-specific corpora
  - Why needed here: GPT-2 needs to understand language patterns and entities specific to news media before generating accurate characterizations
  - Quick check question: What is the minimum loss threshold achieved during first fine-tuning phase for all media houses?

- Concept: Programmatically constructing demonstration data from existing text
  - Why needed here: Manually creating demonstration sentences for all entities would be impractical, so system extracts and transforms existing entity descriptions
  - Quick check question: What are the main parts of clauses that are extracted to construct demonstration sentences?

- Concept: Semantic textual similarity for evaluation
  - Why needed here: Generated characterizations are subjective without predefined classes, so semantic similarity to corpus provides objective measure
  - Quick check question: What cosine similarity threshold is used to consider generated sentence as true positive?

## Architecture Onboarding

- Component map: Data Ingestion -> Pre-processing -> FT1 Fine-tuning -> Demonstration Construction -> FT2 Fine-tuning -> Generation -> Validation
- Critical path: Data Ingestion → Pre-processing → FT1 Fine-tuning → Demonstration Construction → FT2 Fine-tuning → Generation → Validation
- Design tradeoffs: Trades computational resources for automation vs. manual demonstration creation; accepts some precision loss for broader coverage
- Failure signatures: Low semantic similarity scores, inconsistent entity mentions across articles, poor grammatical construction in generated sentences
- First 3 experiments:
  1. Run co-reference resolution on small article sample and manually verify entity disambiguation accuracy
  2. Fine-tune GPT-2 on subset of disambiguated articles and evaluate loss convergence
  3. Generate sentences for few test entities using different prompts and manually assess semantic coherence

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does generative approach performance compare to extractive methods across different media houses and entity types?
- Basis in paper: [explicit] Mentions most current approaches are extractive but doesn't provide direct comparisons
- Why unresolved: Paper focuses on validating generative approach independently rather than benchmarking against extractive alternatives
- What evidence would resolve it: Direct performance comparisons of generative approach against extractive methods on same datasets and metrics

### Open Question 2
- Question: What is optimal balance between fine-tuning data size and demonstration patterns for best performance?
- Basis in paper: [inferred] Uses different amounts of data for FT1/FT2 and explores various prompts but doesn't systematically study data size vs pattern diversity impact
- Why unresolved: Presents results from fixed experimental setup without exploring parameter space
- What evidence would resolve it: Systematic experiments varying fine-tuning data volume and demonstration pattern diversity

### Open Question 3
- Question: How well does approach generalize to entities from domains beyond political figures and celebrities?
- Basis in paper: [explicit] Tests on person entities but focuses on political figures and celebrities without exploring other domains
- Why unresolved: Evaluation limited to specific types of person entities in news articles
- What evidence would resolve it: Testing on person entities from diverse domains like scientific, academic, or business contexts

### Open Question 4
- Question: What is impact of co-reference resolution quality on final characterization performance?
- Basis in paper: [explicit] Mentions using co-reference resolution as pre-processing step but doesn't analyze its impact on results
- Why unresolved: Treats co-reference resolution as necessary pre-processing without investigating influence on characterization quality
- What evidence would resolve it: Experiments comparing characterization performance with different co-reference resolution quality levels

## Limitations
- Approach relies heavily on quality of co-reference resolution and entity disambiguation, which are not thoroughly evaluated
- Semantic textual similarity threshold of 0.6 applied without justification of optimality
- Method's generalizability beyond news media is unclear due to domain-specific fine-tuning
- Manual prompts selected based on prevalence rather than systematic evaluation

## Confidence

**High confidence**: Two-stage fine-tuning methodology is well-established and reported performance metrics (F1 0.842-0.960) are consistent with evaluation approach

**Medium confidence**: Programmatic construction of demonstration sentences appears sound but paper provides limited examples and validation of transformation process

**Low confidence**: Selection of manual prompts and their effectiveness lacks systematic evaluation; paper shows prompts "function reasonably well" but doesn't explore space of possible prompts or relative effectiveness

## Next Checks

1. Manual validation of generated sentences: Select 50 randomly generated characterizations from each media house and have human annotators assess semantic similarity to corpus and grammatical correctness, comparing against automated STS scores

2. Prompt ablation study: Systematically test different prompt formulations (e.g., "is known for", "is characterized by", "has been described as") to determine which patterns yield highest semantic similarity and F1 scores

3. Cross-domain evaluation: Apply fine-tuned models to non-news text (e.g., Wikipedia articles or social media posts) to assess whether characterizations remain coherent and relevant when domain shifts