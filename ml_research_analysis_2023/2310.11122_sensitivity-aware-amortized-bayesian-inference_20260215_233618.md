---
ver: rpa2
title: Sensitivity-Aware Amortized Bayesian Inference
arxiv_id: '2310.11122'
source_url: https://arxiv.org/abs/2310.11122
tags:
- bayesian
- inference
- data
- sensitivity
- prior
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces sensitivity-aware amortized Bayesian inference
  (SA-ABI), a method for efficiently integrating sensitivity analyses into simulation-based
  inference with neural networks. The core idea is to encode structural similarities
  between alternative likelihood and prior specifications during training using weight
  sharing, allowing for rapid assessment of sensitivity to these choices during inference.
---

# Sensitivity-Aware Amortized Bayesian Inference

## Quick Facts
- arXiv ID: 2310.11122
- Source URL: https://arxiv.org/abs/2310.11122
- Reference count: 17
- Key outcome: Introduces sensitivity-aware amortized Bayesian inference (SA-ABI) for efficiently integrating sensitivity analyses into simulation-based inference with neural networks.

## Executive Summary
This paper introduces sensitivity-aware amortized Bayesian inference (SA-ABI), a method for efficiently integrating sensitivity analyses into simulation-based inference with neural networks. The core idea is to encode structural similarities between alternative likelihood and prior specifications during training using weight sharing, allowing for rapid assessment of sensitivity to these choices during inference. The approach also leverages the speed of neural networks to assess sensitivity to data perturbations and preprocessing steps, avoiding the need to refit the model for each configuration. Additionally, deep ensembles are used to detect sensitivity arising from unreliable approximation due to model misspecification. The method is demonstrated on three real-world scenarios, showcasing its effectiveness in parameter estimation and model comparison while providing insights into otherwise hidden relationships between modeling choices and inferential conclusions.

## Method Summary
SA-ABI extends standard simulation-based training by incorporating context variables into the neural network's amortization scope. Context variables encode the choice of likelihood, prior, approximator, and data configurations. During training, the method utilizes weight sharing to encode structural similarities between alternative likelihood and prior specifications with minimal computational overhead. The rapid inference of neural networks is leveraged to assess sensitivity to data perturbations and preprocessing steps. Deep ensembles are employed to detect sensitivity arising from unreliable approximation due to model misspecification. The method is applicable to both parameter estimation and model comparison tasks, using negative log-posterior and cross-entropy losses respectively.

## Key Results
- SA-ABI enables efficient sensitivity analyses by encoding structural similarities between modeling choices during training.
- The method allows for rapid assessment of sensitivity to data perturbations and preprocessing steps without model refitting.
- Deep ensembles are used to detect sensitivity arising from unreliable approximation due to model misspecification.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Weight sharing across context variables enables amortization of sensitivity analyses with minimal computational overhead.
- Mechanism: By explicitly encoding structural similarities between different likelihood/prior/data configurations as context variables during training, a single neural network can perform inference under any specified context without retraining.
- Core assumption: Structural similarities between context configurations can be effectively captured through shared weights.
- Evidence anchors:
  - [abstract] "First, we utilize weight sharing to encode the structural similarities between alternative likelihood and prior specifications in the training process with minimal computational overhead."
  - [section 3.2] "Amortization over the context space leverages structural similarities between context configurations via weight sharing."
- Break condition: If structural similarities between context configurations are too weak or diverse, weight sharing may not effectively capture the required variations.

### Mechanism 2
- Claim: Deep ensembles provide a principled way to quantify approximator sensitivity arising from unreliable approximation.
- Mechanism: By training multiple neural networks with the same architecture but different initializations, we can measure the variability of their predictions on empirical data.
- Core assumption: Variability across ensemble members on empirical data is a reliable indicator of simulation gaps or model misspecification.
- Evidence anchors:
  - [abstract] "Finally, we propose to use deep ensembles to detect sensitivity arising from unreliable approximation (e.g., due to model misspecification)."
  - [section 3.3] "We hypothesize that the variability of ensemble approximations on empirical data despite consistent performance in the closed world indicates a simulation gap."
- Break condition: If ensemble members consistently converge to similar solutions despite simulation gaps, variability may not effectively capture approximation sensitivity.

### Mechanism 3
- Claim: The speed of neural networks enables rapid assessment of data sensitivity through large-scale data perturbations without the need for model refitting.
- Mechanism: Amortized Bayesian inference allows for near-instant inference on new data sets, enabling the exploration of data sensitivity through bootstrapping, leave-one-out folds, or different preprocessing choices.
- Core assumption: The neural network approximation is sufficiently accurate and fast to enable meaningful sensitivity analyses across many data perturbations.
- Evidence anchors:
  - [abstract] "Second, we leverage the rapid inference of neural networks to assess sensitivity to data perturbations and preprocessing steps."
  - [section 3.4] "In contrast, ABI methods amortize across data sets of fixed as well as flexible sizes."
- Break condition: If the neural network approximation is too slow or inaccurate, the speed advantage of ABI may not be sufficient for meaningful data sensitivity analyses.

## Foundational Learning

- Concept: Amortized Bayesian Inference (ABI)
  - Why needed here: ABI is the core computational framework that enables the proposed sensitivity analyses.
  - Quick check question: What is the key advantage of ABI over traditional simulation-based inference methods?

- Concept: Context Variables
  - Why needed here: Context variables are the explicit encoding of likelihood, prior, approximator, and data configurations that enable the proposed sensitivity analyses.
  - Quick check question: How are context variables incorporated into the training and inference processes?

- Concept: Deep Ensembles
  - Why needed here: Deep ensembles are used to quantify approximator sensitivity.
  - Quick check question: What does high variability across ensemble members on empirical data indicate?

## Architecture Onboarding

- Component map: Context encoding -> Weight sharing across contexts -> Neural network training -> Inference with specified context -> Sensitivity analysis
- Critical path: Training data generation → Context encoding → Neural network training → Inference with specified context → Sensitivity analysis
- Design tradeoffs:
  - Weight sharing vs. separate training for each context configuration
  - Ensemble size vs. computational cost for approximator sensitivity
  - Training data diversity vs. computational cost for amortization
- Failure signatures:
  - Poor calibration of posterior predictions
  - High variability across ensemble members on simulated data
  - Inability to capture structural similarities between context configurations
- First 3 experiments:
  1. Reproduce Experiment 1 from the paper to verify prior sensitivity analysis
  2. Implement context encoding for a simple likelihood configuration and test inference under different contexts
  3. Train a deep ensemble and measure variability on both simulated and empirical data

## Open Questions the Paper Calls Out
- How effective are transfer learning techniques in extending sensitivity-aware amortized Bayesian inference to unseen likelihood and prior configurations?
- Can the proposed approach be extended to handle continuous context variables beyond the discrete and scaling schemes discussed?
- How does the proposed method compare to other approaches for assessing sensitivity in Bayesian inference, such as the infinitesimal jackknife or Pareto-smoothed importance sampling?

## Limitations
- The method's effectiveness depends on the ability to capture structural similarities between context configurations through weight sharing.
- The reliability of deep ensembles for detecting simulation gaps depends on the variability of ensemble predictions on empirical data.
- The performance of the method depends on the accuracy and speed of the neural network approximation for complex models or high-dimensional data.

## Confidence
- **High Confidence**: The core idea of encoding context variables for sensitivity analysis and leveraging amortization for rapid inference.
- **Medium Confidence**: The effectiveness of weight sharing for capturing structural similarities and the reliability of deep ensembles for detecting simulation gaps.
- **Low Confidence**: The generalizability of the method to highly complex models and the robustness of the neural network approximation for all types of sensitivity analyses.

## Next Checks
1. Replicate the prior sensitivity analysis from Experiment 1 using the provided implementation to verify the method's effectiveness in detecting prior misspecification.
2. Test the method's robustness to highly diverse context configurations by implementing and training on a more complex model with a wide range of likelihood and prior variations.
3. Evaluate the deep ensemble approach by measuring the variability of ensemble predictions on both simulated and empirical data for a range of models, including those with known simulation gaps.