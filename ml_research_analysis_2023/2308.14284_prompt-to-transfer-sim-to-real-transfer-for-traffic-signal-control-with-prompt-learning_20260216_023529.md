---
ver: rpa2
title: 'Prompt to Transfer: Sim-to-Real Transfer for Traffic Signal Control with Prompt
  Learning'
arxiv_id: '2308.14284'
source_url: https://arxiv.org/abs/2308.14284
tags:
- traffic
- dynamics
- control
- learning
- signal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes PromptGAT, a novel method to mitigate the sim-to-real
  transfer problem in traffic signal control using large language models (LLMs). PromptGAT
  leverages LLMs to infer real-world traffic dynamics based on contextual information
  like weather and road type.
---

# Prompt to Transfer: Sim-to-Real Transfer for Traffic Signal Control with Prompt Learning

## Quick Facts
- arXiv ID: 2308.14284
- Source URL: https://arxiv.org/abs/2308.14284
- Reference count: 13
- Key outcome: PromptGAT improves sim-to-real transfer in traffic signal control by up to 43% in average travel time, 51% in throughput, and 43% in queue length reduction

## Executive Summary
This paper addresses the critical sim-to-real transfer gap in traffic signal control by introducing PromptGAT, a novel method that leverages large language models (LLMs) to infer realistic traffic dynamics. By prompting GPT-4.0 with contextual information about weather and road conditions, PromptGAT generates enhanced forward model predictions that enable more accurate grounded action transformation. The method significantly improves the transferability of reinforcement learning policies from simulation to real-world traffic environments, demonstrating substantial performance gains across multiple metrics.

## Method Summary
PromptGAT extends the Grounded Action Transformation (GAT) framework by incorporating LLM-derived knowledge to enhance forward model predictions. The method uses DQN for policy learning in simulation, then employs a two-step process: first, an LLM (GPT-4.0) is prompted with traffic state, weather, and road type contexts to generate estimates of vehicle dynamics; second, these LLM-derived estimates are fused with observed traffic states to train an enhanced forward model. The inverse model then uses these improved predictions to transform actions from simulation into grounded actions that better account for real-world dynamics variations, ultimately producing policies that perform better when deployed to real-world environments.

## Key Results
- Up to 43% improvement in average travel time compared to direct transfer
- 51% improvement in throughput over baseline methods
- 43% reduction in average queue length in real-world scenarios

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs provide generalizable inference about system dynamics that transfer across unseen weather and road conditions
- Mechanism: By prompting LLMs with traffic state, weather, and road type contexts, the model generates reasonable estimates of vehicle dynamics (acceleration, deceleration, delay) that align with real-world physical expectations
- Core assumption: LLMs trained on diverse web data capture sufficient implicit knowledge about how weather and road conditions affect vehicle behavior
- Evidence anchors: [abstract] states LLMs are "trained on mass knowledge and proved to be equipped with astonishing inference abilities"; [section] shows "LLM's inference results show a similar curve across metrics, and from v1 to v4, the LLM is also reflecting the same tendency as shown by Real settings"
- Break condition: If LLM fails to produce physically plausible dynamics estimates for novel combinations of weather and road conditions

### Mechanism 2
- Claim: Incorporating LLM-derived dynamics knowledge into the forward model reduces prediction error and improves policy transfer
- Mechanism: The LLM-generated dynamics estimates are fused with observed traffic states to create enriched feature representations that guide the forward model to better approximate real-world transitions
- Core assumption: The forward model can effectively integrate these enriched features to improve its state transition predictions
- Evidence anchors: [abstract] reports "up to 43% improvement in average travel time, 51% in throughput, and 43% in queue length reduction"; [section] shows "improvement of the mitigated gap (absolute values) across multiple metrics is positively correlated to the improvement of the forward model's accuracy"
- Break condition: If the forward model cannot effectively process or utilize the LLM-derived features

### Mechanism 3
- Claim: Grounding the agent's actions using LLM-enhanced forward model predictions leads to more realistic policies that perform better in real-world environments
- Mechanism: The inverse model uses predictions from the LLM-enhanced forward model to transform actions from simulation into grounded actions that account for real-world dynamics variations
- Core assumption: Action transformation using more accurate forward model predictions will produce actions better suited to real-world conditions
- Evidence anchors: [abstract] states "PromptGAT enables the agent to learn more realistic policies and improves the transferability of reinforcement learning models from simulation to reality"; [section] shows "when the PromptGAT provides a better depiction inference on the system dynamics, the inverse model's action would be better grounded to the realistic scenario"
- Break condition: If the action transformation process fails to produce meaningful improvements in real-world policy performance

## Foundational Learning

- Concept: Reinforcement Learning in Traffic Signal Control
  - Why needed here: The paper builds on RL-based TSC methods and addresses their sim-to-real transfer limitations
  - Quick check question: What are the key components of an MDP formulation for traffic signal control problems?

- Concept: Grounded Action Transformation (GAT)
  - Why needed here: PromptGAT extends the GAT framework by incorporating LLM-derived knowledge
  - Quick check question: How does GAT modify simulation dynamics to match real-world behavior without changing the simulator parameters?

- Concept: Prompt Engineering for LLMs
  - Why needed here: The method relies on carefully designed prompts to elicit useful dynamics information from LLMs
  - Quick check question: What are the key elements of an effective prompt template for obtaining structured outputs from LLMs?

## Architecture Onboarding

- Component map: Traffic signal control policy (DQN) -> LLM inference module (GPT-4.0) -> Prompt-based dynamics modeling module -> Forward model (fϕ+) -> Inverse model (hϕ−) -> Real-world simulator (SUMO) -> Simulation simulator (CityFlow)

- Critical path: 1. Collect real-world trajectories in SUMO 2. Generate LLM dynamics estimates using prompt templates 3. Fuse LLM outputs with traffic state features 4. Train forward model on enriched data 5. Train inverse model on simulation data 6. Apply grounded action transformation to improve policy transfer

- Design tradeoffs:
  - Using LLM vs. learning dynamics from data only: LLM provides generalization but adds dependency on external model
  - Complexity of prompt templates vs. quality of responses: More detailed prompts may yield better estimates but require careful design
  - Computational cost of LLM inference vs. potential performance gains: LLM calls add latency to training pipeline

- Failure signatures:
  - LLM produces physically implausible dynamics estimates
  - Forward model fails to effectively integrate LLM-derived features
  - No improvement in policy transfer performance despite LLM integration
  - High variance in LLM responses across similar inputs

- First 3 experiments:
  1. Verify LLM produces reasonable dynamics estimates by comparing to ground truth values across different weather/road conditions
  2. Compare forward model prediction accuracy with and without LLM-derived features
  3. Evaluate policy transfer performance using direct transfer, vanilla GAT, and PromptGAT across multiple real-world configurations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we determine the optimal prompt template and context selection for different traffic scenarios and LLM models?
- Basis in paper: [inferred] The paper mentions using a specific prompt template and context selection, but does not provide a systematic approach for determining the optimal template and context for different scenarios and models.
- Why unresolved: The paper does not explore or discuss the impact of different prompt templates and context selections on the performance of PromptGAT.
- What evidence would resolve it: Comparative studies of PromptGAT performance using various prompt templates and context selections for different traffic scenarios and LLM models.

### Open Question 2
- Question: Can PromptGAT be extended to handle multi-agent traffic signal control problems?
- Basis in paper: [inferred] The paper focuses on single-agent traffic signal control, but does not explore the potential application of PromptGAT in multi-agent scenarios.
- Why unresolved: The paper does not provide any insights or experimental results on the performance of PromptGAT in multi-agent traffic signal control problems.
- What evidence would resolve it: Experimental results and analysis of PromptGAT performance in multi-agent traffic signal control problems.

### Open Question 3
- Question: How does the performance of PromptGAT scale with the size and complexity of the traffic network?
- Basis in paper: [inferred] The paper does not discuss the scalability of PromptGAT in terms of traffic network size and complexity.
- Why unresolved: The paper does not provide any experimental results or analysis on the performance of PromptGAT for larger and more complex traffic networks.
- What evidence would resolve it: Experimental results and analysis of PromptGAT performance for traffic networks of varying sizes and complexities.

### Open Question 4
- Question: How can PromptGAT be adapted to handle real-time traffic data and dynamic traffic conditions?
- Basis in paper: [inferred] The paper does not discuss the potential adaptation of PromptGAT to handle real-time traffic data and dynamic traffic conditions.
- Why unresolved: The paper does not provide any insights or experimental results on the performance of PromptGAT in real-time and dynamic traffic scenarios.
- What evidence would resolve it: Experimental results and analysis of PromptGAT performance in real-time and dynamic traffic scenarios, including the integration of real-time traffic data.

## Limitations

- The method relies heavily on GPT-4.0's ability to generalize across weather and road conditions without direct validation against ground truth values
- Critical implementation details such as prompt templates, model architectures, and hyperparameter settings are not fully specified
- Performance evaluation uses only one real-world simulator (SUMO), limiting generalizability to other traffic simulation environments

## Confidence

- High confidence: The PromptGAT framework architecture and its integration with GAT is technically sound
- Medium confidence: The reported performance improvements (43% ATT reduction, 51% throughput increase) are significant but require independent validation
- Low confidence: Claims about LLM inference quality and its direct contribution to performance gains, due to missing validation evidence

## Next Checks

1. Conduct controlled experiments comparing LLM-derived dynamics estimates against ground truth values across all weather and road conditions to verify physical plausibility
2. Perform ablation studies isolating the contribution of LLM features from other components of the forward model to quantify their specific impact
3. Test the approach on additional traffic simulators beyond SUMO to evaluate cross-platform transferability of the method