---
ver: rpa2
title: Attention for Causal Relationship Discovery from Biological Neural Dynamics
arxiv_id: '2311.06928'
source_url: https://arxiv.org/abs/2311.06928
tags:
- neuron
- attention
- causal
- history
- each
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Causalformer, a transformer-based method for
  discovering Granger causality in networks with complex nonlinear dynamics, as in
  neurobiological and biophysical networks. Causalformer extends the spacetimeformer
  architecture to jointly forecast future activities and learn causal relationships
  among neurons.
---

# Attention for Causal Relationship Discovery from Biological Neural Dynamics

## Quick Facts
- arXiv ID: 2311.06928
- Source URL: https://arxiv.org/abs/2311.06928
- Authors: 
- Reference count: 40
- Key outcome: Transformer-based method for discovering Granger causality in networks with complex nonlinear dynamics, achieving superior performance on larger network sizes (N=20, 40)

## Executive Summary
This paper proposes Causalformer, a transformer-based method for discovering Granger causality in neurobiological networks with complex nonlinear dynamics. The approach extends spacetimeformer architecture to jointly forecast future neural activities and learn causal relationships among neurons through decoder cross-attention matrices. The method achieves performance equal or superior to the popular MVGC method, particularly for larger network sizes, suggesting transformers have potential for uncovering Granger causal relationships in large-scale neuronal population recordings.

## Method Summary
Causalformer is a transformer-based architecture that jointly forecasts future neural activities and discovers causal relationships through decoder cross-attention. The encoder uses local self-attention to learn disentangled history representations for each neuron, while the decoder employs global cross-attention to capture causal relationships. The cross-attention weights between neurons serve as a posterior distribution over possible edges in the connectivity graph. The method is trained on synthetic neuronal datasets generated with the Izhikevich model and evaluated using AUROC scores comparing inferred connectivity to ground truth.

## Key Results
- Causalformer achieves performance equal or superior to MVGC, particularly for larger network sizes (N=20, 40)
- Decoder cross-attention matrices effectively capture Granger causal relationships among neurons
- AUROC scores validate the method's ability to discover true connectivity from neural dynamics

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Causalformer's decoder cross-attention matrix captures Granger causality because it encodes information flow from neuron i's history to neuron j's future.
- Mechanism: The cross-attention weights represent how much each neuron's past contributes to predicting another neuron's future, which directly aligns with Granger causality's definition.
- Core assumption: The model's architecture enforces that history representations remain disentangled (no cross-neuron mixing in encoder) while future predictions depend only on past information (no leakage in decoder).
- Evidence anchors:
  - [abstract] "we show that the cross attention module effectively captures the causal relationship among neurons"
  - [section] "the decoder cross attention matrix can be seen as a posterior distribution over the possible edges in the graph given the history and the future nodes"
  - [corpus] Weak evidence; related works focus on causal discovery but don't specifically validate cross-attention as causality estimator.
- Break condition: If the encoder allows history mixing between neurons, or if future information leaks into the encoder representations, the cross-attention will no longer reflect true causal relationships.

### Mechanism 2
- Claim: Causalformer outperforms MVGC on larger networks because it captures nonlinear dynamics that linear VAR models miss.
- Mechanism: The nonlinear feed-forward transformations in Causalformer can model complex, nonlinear interactions between neurons that become more prevalent as network size increases.
- Core assumption: Neuronal population dynamics in larger random networks exhibit stronger nonlinear dependencies that linear Granger causality cannot capture.
- Evidence anchors:
  - [abstract] "we achieve performance equal or superior to that for the most popular Granger causality analysis method" with superior results for N=20,40
  - [section] "increasingly complicated connectivity patterns in larger networks can amplify the nonlinear aspect of neuronal population dynamics"
  - [corpus] Weak evidence; related works mention nonlinear Granger causality but don't specifically compare transformer vs linear methods on network size effects.
- Break condition: If the nonlinear dynamics in larger networks don't actually increase (e.g., if connectivity patterns remain simple despite size), the advantage over MVGC may disappear.

### Mechanism 3
- Claim: AUROC provides a threshold-free evaluation of causal discovery by considering all possible attention weight thresholds.
- Mechanism: Instead of selecting arbitrary thresholds for declaring causality, AUROC integrates performance across all thresholds by comparing the full distribution of attention weights against ground truth.
- Core assumption: Higher cross-attention weights should correspond to higher probability of actual causal connections, making the full distribution informative.
- Evidence anchors:
  - [section] "instead of zero, we seek positive scalars as the threshold... we used the Area Under the Receiver Operating Characteristic (AUROC) as used in [18], bypassing the selection of a specific threshold"
  - [section] "we computed AUROC using F directly, considering all Fij regardless of its magnitude"
  - [corpus] No direct evidence; related works don't discuss threshold-free evaluation in causal discovery context.
- Break condition: If the cross-attention distribution doesn't monotonically relate to true causality (e.g., if random weights produce similar distributions), AUROC scores become meaningless.

## Foundational Learning

- Concept: Granger causality
  - Why needed here: The entire paper builds on Granger causality as the theoretical foundation for what constitutes a "causal relationship" between neurons
  - Quick check question: If knowing neuron A's past improves prediction of neuron B's future beyond what neuron B's own past provides, what type of relationship exists between A and B?

- Concept: Transformer attention mechanism
  - Why needed here: Understanding how self-attention and cross-attention work is essential to grasp why decoder cross-attention can capture causal relationships
  - Quick check question: In cross-attention, what serves as the query and what serves as the key/value when the decoder attends to encoder outputs?

- Concept: Time series forecasting
  - Why needed here: Causalformer is fundamentally a forecasting model that learns to predict future neural activity from past observations
  - Quick check question: If a model predicts xt+1 from (xt, xt-1, ..., xt-c), what is the forecast horizon and what is the history window?

## Architecture Onboarding

- Component map: Encoder (local self-attention per neuron) -> Decoder (local cross-attention + global cross-attention) -> Output predictions
- Critical path: Encoder learns disentangled history representations -> Decoder's global cross-attention computes causal relationships -> Cross-attention matrix interpreted as connectivity
- Design tradeoffs: Local attention in encoder prevents information mixing but limits context; global cross-attention enables causality discovery but increases computation
- Failure signatures: Poor prediction performance indicates model didn't learn dynamics; random cross-attention matrices suggest encoder-decoder information isolation failed
- First 3 experiments:
  1. Train Causalformer on small network (N=5) and visualize cross-attention vs ground truth connectivity
  2. Vary history window length c and observe impact on prediction accuracy and AUROC
  3. Replace decoder global cross-attention with learned graph attention and compare causal discovery performance

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Causalformer perform on real-world neuronal spike train data, which is sparse and binary, compared to continuous membrane potential data?
- Basis in paper: [inferred] The paper validates Causalformer on synthetic membrane potential data but acknowledges the need to test robustness on sparse spike trains.
- Why unresolved: The paper only tests on continuous membrane potential data, not sparse spike trains which are more common in real-world neuronal recordings.
- What evidence would resolve it: Testing Causalformer on real or simulated spike train data and comparing performance metrics (e.g., AUROC) to those achieved on membrane potential data.

### Open Question 2
- Question: How does Causalformer compare to other transformer-based models designed for non-stationary time series or improved scalability when applied to neuronal causal discovery?
- Basis in paper: [explicit] The paper mentions that incorporating ideas from transformers handling non-stationarity or improved scalability is an important future direction.
- Why unresolved: The paper only compares Causalformer to MVGC and doesn't explore other transformer architectures that may be better suited for neuronal data characteristics.
- What evidence would resolve it: Comparing Causalformer to transformer models like Informer or models using performers on neuronal causal discovery tasks.

### Open Question 3
- Question: How does the identifiability of cross-attention in Causalformer vary across different random initializations and network architectures?
- Basis in paper: [explicit] The paper mentions that cross-attention matrices usually differ across random initializations and suggests examining identifiability more closely.
- Why unresolved: The paper uses an ensemble of models to address this issue but doesn't thoroughly examine the consistency of cross-attention matrices across different initializations.
- What evidence would resolve it: Conducting a systematic study of cross-attention matrix stability across multiple random seeds and comparing results to ground-truth connectivity.

## Limitations
- Evaluation limited to synthetic data with known ground truth, not validated on real biological neural recordings
- Claims about capturing nonlinear dynamics rely on assumptions about network size effects that need empirical validation
- Practical utility for neuroscience applications where specific threshold selection matters is unclear despite threshold-free AUROC evaluation

## Confidence

**High confidence**: The mechanism that transformer cross-attention can encode information flow relationships is supported by architectural design and empirical results showing superior performance over MVGC for larger networks.

**Medium confidence**: The claim that Causalformer outperforms MVGC specifically due to capturing nonlinear dynamics requires the assumption that larger networks inherently exhibit stronger nonlinear dependencies - an assumption that needs validation on real data.

**Medium confidence**: The threshold-free evaluation approach using AUROC is methodologically sound but practical implications for neuroscience applications where specific threshold selection is often necessary remain unclear.

## Next Checks

1. **Architecture ablation study**: Remove the local attention constraint in the encoder to allow cross-neuron mixing, then measure degradation in AUROC scores to empirically validate the architectural assumptions about information isolation.

2. **Real data validation**: Apply Causalformer to publicly available calcium imaging or electrophysiology datasets with known circuit architectures (e.g., organoid cultures or controlled stimulation experiments) to test generalizability beyond synthetic data.

3. **Nonlinear dynamics characterization**: Quantitatively measure the degree of nonlinearity in the synthetic datasets across different network sizes and connection probabilities, then correlate this with the performance gap between Causalformer and MVGC to validate the proposed mechanism.