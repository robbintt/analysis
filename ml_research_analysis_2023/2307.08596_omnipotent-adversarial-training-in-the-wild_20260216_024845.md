---
ver: rpa2
title: Omnipotent Adversarial Training in the Wild
arxiv_id: '2307.08596'
source_url: https://arxiv.org/abs/2307.08596
tags:
- label
- noise
- training
- dataset
- best
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Omnipotent Adversarial Training (OAT) is proposed to address the
  challenge of training robust deep learning models on imbalanced and noisy datasets.
  OAT introduces an oracle that uses feature embeddings and k-NN to correct labels,
  along with dataset re-sampling and contrastive self-supervised learning.
---

# Omnipotent Adversarial Training in the Wild

## Quick Facts
- arXiv ID: 2307.08596
- Source URL: https://arxiv.org/abs/2307.08596
- Reference count: 40
- Key outcome: OAT achieves up to 80.72% clean accuracy and 42.84% robust accuracy on highly imbalanced and noisy datasets, outperforming state-of-the-art methods by over 50% and 20% respectively.

## Executive Summary
This paper addresses the challenge of training robust deep learning models on imbalanced and noisy datasets by proposing Omnipotent Adversarial Training (OAT). The method introduces an oracle that uses feature embeddings and k-NN to correct labels, along with dataset re-sampling and contrastive self-supervised learning. OAT also incorporates logits adjustment adversarial training to handle data imbalance. Extensive experiments on CIFAR-10 and CIFAR-100 demonstrate that OAT significantly outperforms existing methods, achieving state-of-the-art clean and robust accuracy under various noise and imbalance conditions.

## Method Summary
OAT consists of two main stages: oracle training and adversarial training. In the oracle training stage, dataset re-sampling is applied to address imbalance, followed by label refurbishment using a k-NN algorithm on feature embeddings from contrastive self-supervised learning. The adversarial training stage uses logits adjustment to compensate for label distribution bias and incorporates an MSE penalty between the oracle and AT-model outputs to improve robustness. The method is evaluated on CIFAR-10 and CIFAR-100 with various combinations of label noise and imbalance ratios.

## Key Results
- OAT achieves up to 80.72% clean accuracy on highly imbalanced and noisy datasets
- OAT achieves up to 42.84% robust accuracy under adversarial attacks
- OAT outperforms state-of-the-art methods by over 50% in clean accuracy and 20% in robust accuracy

## Why This Works (Mechanism)
### Mechanism 1
- Claim: Oracle with k-NN refurbishment can recover correct labels even under high noise
- Mechanism: Feature embeddings from self-supervised contrastive learning preserve semantic class structure, allowing k-NN to correctly group samples by class even when labels are noisy. The oracle refurbishes labels based on majority vote among nearest neighbors in embedding space.
- Core assumption: Self-supervised training creates embeddings where semantically similar samples are close in feature space, and k-NN can correctly identify majority class among neighbors despite label noise.
- Evidence anchors:
  - [abstract] "We adopt a novel method to predict labels using high-dimensional feature embeddings and a k-nearest neighbors algorithm"
  - [section] "models trained in a contrastive self-supervised manner will automatically map the data belonging to the same class into the neighbor feature embedding [24]"
  - [corpus] Weak - no direct corpus evidence for k-NN label refurbishment under high noise
- Break condition: If self-supervised embeddings don't preserve class structure (e.g., poor contrastive learning), k-NN will fail to identify correct majority class.

### Mechanism 2
- Claim: Logits adjustment compensates for label distribution bias in imbalanced datasets
- Mechanism: By adding log-probabilities of estimated class frequencies to model logits during training, the model's confidence scores are adjusted to approximate Bayes-optimal predictions, reducing bias toward head classes.
- Core assumption: The estimated label distribution from the oracle accurately reflects the true underlying distribution, allowing effective bias correction.
- Evidence anchors:
  - [abstract] "We further propose logits adjustment adversarial training to overcome the data imbalance challenge, which can help the model learn a Bayes-optimal distribution"
  - [section] "the logits adjustment translates the model's confidence scores into Bayes-optimal predictions [34] under the current label distribution"
  - [corpus] Moderate - related work on logits adjustment exists (Menon et al. 2021) but not under adversarial training with noisy labels
- Break condition: If oracle's label distribution estimate is severely biased or inaccurate, logits adjustment will mis-calibrate model outputs.

### Mechanism 3
- Claim: Interaction between oracle and AT-model via MSE penalty improves robustness
- Mechanism: Adding MSE loss between oracle's and AT-model's softmax outputs encourages the AT-model to learn from the oracle's more accurate predictions, providing adaptive label smoothing that mitigates overfitting to noisy labels.
- Core assumption: The oracle provides consistently better label predictions than the AT-model, especially in early training stages when the AT-model overfits to label noise.
- Evidence anchors:
  - [abstract] "We introduce interactions between the oracle and the model to make the model obtain high clean accuracy and robustness even on an imbalanced dataset with massive label noise"
  - [section] "we adopt a penalty term described as follows: LMSE = −Ex∽D′ C MSE(σ(O(x)), σ(M(x)))"
  - [corpus] Weak - no direct corpus evidence for this specific oracle-AT interaction mechanism
- Break condition: If oracle predictions are not consistently better than AT-model (e.g., oracle also overfits to noise), MSE penalty may propagate errors.

## Foundational Learning
- Concept: Adversarial training fundamentals
  - Why needed here: OAT extends standard adversarial training to handle noisy/imbalanced data; understanding PGD-based AE generation and loss computation is essential
  - Quick check question: What is the difference between PGD-AT and TRADES in terms of their loss objectives?
- Concept: Contrastive self-supervised learning
  - Why needed here: Oracle training uses BYOL-based contrastive learning to create semantically meaningful embeddings for k-NN label refurbishment
  - Quick check question: How does BYOL differ from SimCLR in terms of architecture and training objective?
- Concept: Long-tailed classification and imbalance correction
  - Why needed here: OAT addresses both label noise and data imbalance simultaneously; understanding re-sampling and logits adjustment is crucial
  - Quick check question: Why does random oversampling of minority classes help in long-tailed learning?

## Architecture Onboarding
- Component map: Oracle (OF + OC + OH/OP) -> k-NN splitting -> label refurbishment -> logits adjustment AT with oracle interaction
- Critical path: Oracle training → k-NN splitting → label refurbishment → logits adjustment AT with oracle interaction
- Design tradeoffs:
  - Oracle training vs. AT-model training: Separate architectures allow specialized training but add complexity
  - k-NN k value: Larger k provides stability but may blur class boundaries; smaller k is sensitive to noise
  - Label refurbishment threshold θr: Higher threshold preserves more clean labels but may miss some noisy ones
- Failure signatures:
  - Oracle performance degrades: Check contrastive learning loss, k-NN accuracy on clean validation set
  - AT-model overfits to noise: Monitor clean accuracy on clean validation subset, check label refurbishment quality
  - Imbalanced performance persists: Verify label distribution estimation, check logits adjustment implementation
- First 3 experiments:
  1. Train oracle on clean CIFAR-10, evaluate k-NN accuracy on clean vs. noisy versions
  2. Test logits adjustment on clean long-tailed CIFAR-10 with oracle's estimated distribution vs. ground truth
  3. Run end-to-end OAT on balanced CIFAR-10 with 20% symmetric noise, compare to PGD-AT

## Open Questions the Paper Calls Out
- Open Question 1: How can OAT be improved to maintain performance under massive asymmetric label noise, where the model experiences significant performance drops?
- Open Question 2: How does the performance of OAT scale with more complex datasets (e.g., ImageNet) compared to CIFAR-10 and CIFAR-100?
- Open Question 3: Can the oracle in OAT be replaced or augmented with other methods (e.g., semi-supervised learning or meta-learning) to improve label correction and distribution estimation?

## Limitations
- Effectiveness of k-NN label refurbishment is assumed to hold for noise ratios up to 80% but lacks direct empirical validation across diverse dataset characteristics
- MSE-based oracle-AT interaction mechanism is introduced without theoretical justification or ablation studies demonstrating its necessity
- The paper only evaluates OAT on CIFAR-10 and CIFAR-100, which are relatively small and simple datasets compared to real-world applications

## Confidence
- High confidence: General framework design and experimental methodology
- Medium confidence: Effectiveness of logits adjustment for handling data imbalance under adversarial training
- Low confidence: Oracle-AT interaction mechanism due to lack of ablation studies and theoretical grounding

## Next Checks
1. Ablation study isolating the contribution of each OAT component (oracle refurbishment, logits adjustment, MSE interaction) on CIFAR-10 with varying noise levels
2. Evaluation on additional datasets (e.g., SVHN, Tiny ImageNet) with different data distributions to test generalizability
3. Theoretical analysis of the convergence properties of the oracle training stage under high label noise conditions