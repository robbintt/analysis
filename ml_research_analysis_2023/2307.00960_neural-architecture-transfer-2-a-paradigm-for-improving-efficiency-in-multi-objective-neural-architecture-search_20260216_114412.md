---
ver: rpa2
title: 'Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in Multi-Objective
  Neural Architecture Search'
arxiv_id: '2307.00960'
source_url: https://arxiv.org/abs/2307.00960
tags:
- natv2
- accuracy
- search
- performance
- sub-networks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Neural Architecture Transfer 2 (NATv2), an
  enhanced version of the Neural Architecture Transfer (NAT) algorithm for multi-objective
  neural architecture search. NATv2 addresses the limitations of NAT by leveraging
  the improved super-networks generated by the Once-For-All-2 (OFAv2) technique and
  incorporating new policies for initialization, pre-processing, and updating the
  networks archive.
---

# Neural Architecture Transfer 2: A Paradigm for Improving Efficiency in Multi-Objective Neural Architecture Search

## Quick Facts
- **arXiv ID:** 2307.00960
- **Source URL:** https://arxiv.org/abs/2307.00960
- **Reference count:** 40
- **Primary result:** NATv2 achieves 2.63% higher accuracy on Tiny ImageNet than NAT while reducing parameters by 21.84% and MACs by 7.63%

## Executive Summary
Neural Architecture Transfer 2 (NATv2) enhances the original NAT algorithm by leveraging improved super-networks from OFAv2 and introducing new policies for archive management and post-processing. The method addresses NAT's limitations by utilizing OFAv2's parallel blocks, dense skip connections, and early exits to create a richer architectural search space. Additionally, NATv2 implements a larger archive initialization strategy and a fine-tuning post-processing pipeline to further enhance extracted sub-network performance. Experimental results demonstrate significant improvements in accuracy, parameter efficiency, and computational complexity compared to the original NAT.

## Method Summary
NATv2 operates on super-networks generated by OFAv2 using Extended Progressive Shrinking, replacing the original OFA super-network. The method employs a new encoding scheme to handle OFAv2's enhanced architectural features including parallel blocks and early exits. A larger archive of 300 diverse, high-performing sub-networks is initialized to improve the performance predictor's training data. Multi-objective evolutionary search using NSGA3 extracts optimal sub-networks, which are then fine-tuned using a combination of training and validation data. The approach targets image classification tasks on CIFAR-10, CIFAR-100, and Tiny ImageNet datasets.

## Key Results
- Achieves 2.63% higher average accuracy on Tiny ImageNet compared to NAT
- Reduces parameters by 21.84% while maintaining or improving accuracy
- Decreases computational complexity (MACs) by 7.63% across datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: NATv2 achieves superior performance by replacing the OFA super-network with an OFAv2 super-network that supports parallel blocks, dense skip connections, and early exits.
- Mechanism: The OFAv2 super-network provides a richer and more flexible architecture space, allowing NATv2 to extract sub-networks with more diverse topologies and better computational efficiency.
- Core assumption: The enhanced architectural features in OFAv2 (parallel blocks, dense skip connections, early exits) lead to better-performing sub-networks when used with NATv2's search algorithm.
- Evidence anchors:
  - [abstract] "NATv2 achieves qualitative improvements in the extractable sub-networks by exploiting the improved super-networks generated by OFAv2..."
  - [section] "NATv2 replaces the original super-network, OFAMobileNetV3, used in NAT and pre-trained with OFA's Progressive Shrinking algorithm, with super-networks generated by OFAv2."
- Break condition: If the OFAv2 super-network fails to converge or underperforms the original OFA super-network during training, the claimed benefits would not materialize.

### Mechanism 2
- Claim: NATv2 improves the performance predictor by using a larger archive of high-quality sub-networks and a more diverse training set.
- Mechanism: By initializing the archive with top-performing sub-networks and maintaining a larger fixed-size archive, NATv2 provides better training data for the predictor, leading to more accurate performance estimates.
- Core assumption: A larger and more diverse archive of high-quality sub-networks leads to better predictor performance.
- Evidence anchors:
  - [abstract] "To enhance the NATv2 archive, new policies are implemented for initialization, pre-processing, and updates."
  - [section] "NATv2 takes a different approach to managing the archive of optimal sub-networks... The changes primarily affect two key stages of the NAT algorithm: the archive initialisation and archive growth steps."
- Break condition: If the predictor fails to generalize well despite the larger archive, or if the additional computational cost of maintaining the larger archive outweighs the benefits, this mechanism would break.

### Mechanism 3
- Claim: NATv2 incorporates a post-processing pipeline based on fine-tuning to further enhance model performance.
- Mechanism: After the evolutionary search, NATv2 fine-tunes the extracted sub-networks using a combination of training and validation sets, potentially including the AEP technique for early exit networks.
- Core assumption: Fine-tuning the extracted sub-networks can significantly improve their performance without dramatically increasing their complexity.
- Evidence anchors:
  - [abstract] "In addition, a post-processing pipeline based on fine-tuning is introduced, which further enhances model performance at a marginal increase in parameters and MACs."
  - [section] "The post-processing step is applied after the conclusion of the algorithm to fine-tune and refine the selected architectures, ultimately improving their performance."
- Break condition: If the fine-tuning process leads to overfitting or if the marginal increase in parameters and MACs becomes significant, this mechanism would break.

## Foundational Learning

- Concept: Neural Architecture Search (NAS)
  - Why needed here: NATv2 is an extension of NAS techniques, so understanding the basics of NAS is crucial to grasp the improvements and innovations introduced by NATv2.
  - Quick check question: What are the three key characteristics of NAS algorithms as classified by Elsken et al.?

- Concept: Multi-objective optimization
  - Why needed here: NATv2 aims to find sub-networks that achieve the best trade-off across multiple objectives (e.g., accuracy, number of parameters, MACs). Understanding multi-objective optimization is essential to appreciate the challenges and solutions in NATv2.
  - Quick check question: How does NATv2 handle the multi-objective nature of the search process?

- Concept: Super-networks and sub-networks
  - Why needed here: NATv2 operates on super-networks generated by OFAv2 and extracts sub-networks that satisfy different constraints. Understanding the concept of super-networks and sub-networks is fundamental to understanding NATv2's workflow.
  - Quick check question: What is the difference between a super-network and a sub-network in the context of NATv2?

## Architecture Onboarding

- Component map:
  OFAv2 super-network generation -> NATv2 algorithm (encoding, archive management, predictor) -> Post-processing pipeline (fine-tuning) -> Evaluation on image classification datasets

- Critical path:
  1. Generate OFAv2 super-network using Extended Progressive Shrinking (EPS)
  2. Initialize NATv2 archive with top-performing sub-networks
  3. Perform multi-objective evolutionary search using improved predictor
  4. Extract best sub-networks from archive
  5. Apply post-processing (fine-tuning) to further enhance performance

- Design tradeoffs:
  - Larger archive size vs. computational cost
  - Richer super-network architecture vs. training complexity
  - Post-processing benefits vs. increased parameters and MACs

- Failure signatures:
  - Predictor fails to accurately estimate sub-network performance
  - Evolutionary search converges to suboptimal solutions
  - Post-processing leads to overfitting or significant complexity increase

- First 3 experiments:
  1. Compare the performance of NATv2 with different performance predictors (e.g., LGBM, CatBoost) on a small dataset.
  2. Evaluate the impact of the new encoding method on the diversity and quality of extracted sub-networks.
  3. Assess the effectiveness of the post-processing pipeline by comparing fine-tuned sub-networks with their non-fine-tuned counterparts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of NATv2 scale with different dataset complexities beyond CIFAR10, CIFAR100, and Tiny ImageNet?
- Basis in paper: [explicit] The paper mentions that NATv2's effectiveness increases with the complexity of the problem, but only tests on three specific datasets.
- Why unresolved: The paper only provides experimental results on three datasets, which may not fully represent the performance on a wider range of real-world scenarios.
- What evidence would resolve it: Conducting experiments on additional datasets with varying levels of complexity and domain specificity would provide a more comprehensive understanding of NATv2's scalability.

### Open Question 2
- Question: What is the optimal archive size (As) for NATv2, and how does it affect the algorithm's performance and computational efficiency?
- Basis in paper: [inferred] The paper sets As to 300 without providing a detailed analysis of how this value was chosen or how it impacts the results.
- Why unresolved: The choice of archive size could significantly influence the trade-off between exploration and exploitation in the evolutionary search process, affecting both performance and efficiency.
- What evidence would resolve it: A systematic study varying the archive size and analyzing its impact on search performance, convergence speed, and computational costs would help determine the optimal value.

### Open Question 3
- Question: How does NATv2 compare to other state-of-the-art NAS methods in terms of search efficiency and final model quality?
- Basis in paper: [explicit] The paper compares NATv2 to its predecessor NAT but does not provide a comprehensive comparison with other recent NAS techniques.
- Why unresolved: Without a broader comparison, it's unclear how NATv2 stands relative to the current state of the art in terms of both the efficiency of the search process and the quality of the resulting architectures.
- What evidence would resolve it: Benchmarking NATv2 against other recent NAS methods like DARTS, NSGANet, and others on the same datasets and evaluation metrics would provide a clearer picture of its relative performance.

## Limitations
- Limited evaluation scope: Only tested on three datasets (CIFAR-10, CIFAR-100, Tiny ImageNet) without broader generalization analysis
- Missing comprehensive ablation studies: No detailed analysis of how individual improvements contribute to overall performance
- Limited comparison to recent methods: Only compared to predecessor NAT, lacking benchmarks against state-of-the-art NAS techniques

## Confidence
- **High Confidence:** The core architectural changes (OFAv2 super-network, new encoding) are well-documented and theoretically sound
- **Medium Confidence:** The performance improvements are demonstrated but lack comprehensive ablation studies and comparisons to recent methods
- **Low Confidence:** The effectiveness of the post-processing pipeline and its impact on the overall efficiency of the method

## Next Checks
1. **Ablation Study on Archive Size:** Conduct experiments varying the archive size to quantify the trade-off between predictor accuracy and computational overhead.

2. **Post-processing Impact Analysis:** Measure the marginal increase in parameters and MACs from fine-tuning and assess whether the performance gains justify the additional complexity.

3. **Comparison with Recent NAS Methods:** Benchmark NATv2 against state-of-the-art NAS algorithms on multiple datasets to establish its relative performance and efficiency.