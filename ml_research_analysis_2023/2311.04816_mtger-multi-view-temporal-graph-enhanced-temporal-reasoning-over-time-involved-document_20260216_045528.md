---
ver: rpa2
title: 'MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved
  Document'
arxiv_id: '2311.04816'
source_url: https://arxiv.org/abs/2311.04816
tags:
- temporal
- graph
- question
- reasoning
- time
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses document-level temporal reasoning, where the
  goal is to answer time-sensitive questions by finding facts that occurred at a specific
  time in a document. The key challenge is the intricate intertwining of facts and
  time in documents, making explicit modeling of temporal relationships crucial.
---

# MTGER: Multi-view Temporal Graph Enhanced Temporal Reasoning over Time-Involved Document

## Quick Facts
- **arXiv ID**: 2311.04816
- **Source URL**: https://arxiv.org/abs/2311.04816
- **Reference count**: 40
- **Key outcome**: MTGER achieves up to 9% performance boost on TimeQA and SituatedQA datasets compared to state-of-the-art QA models, providing more consistent answers under question perturbations.

## Executive Summary
This paper addresses document-level temporal reasoning, where the goal is to answer time-sensitive questions by finding facts that occurred at a specific time in a document. The key challenge is the intricate intertwining of facts and time in documents, making explicit modeling of temporal relationships crucial. The proposed method, MTGER, constructs multi-view temporal graphs to explicitly model temporal and discourse relationships among facts. The multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion. Additionally, a self-supervised time-comparing objective is designed to enhance the model's implicit reasoning capability.

## Method Summary
MTGER constructs heterogeneous temporal graphs with fact nodes and time nodes (in four temporal states) connected by discourse and temporal relation edges. The framework uses two complementary graph views - time-focused (facts connected through time bridges) and fact-focused (relative event orderings) - that are fused adaptively. A question-guided fusion mechanism dynamically selects relevant graph information for each question. The model is trained with a teacher-forcing loss and a self-supervised time-comparing objective that encourages the model to distinguish correct from incorrect temporal alignments.

## Key Results
- Achieves up to 9% performance improvement over state-of-the-art QA models on TimeQA and SituatedQA datasets
- Multi-view temporal graphs with adaptive fusion provide complementary information leading to better performance
- Question-guided text-graph fusion improves consistency of answers under question perturbations
- Self-supervised time-comparing objective enhances implicit temporal reasoning capability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multi-view temporal graphs explicitly model both absolute time relationships and relative event relationships, improving implicit reasoning.
- Mechanism: The framework constructs two complementary graph views - a time-focused view where time nodes interact directly and facts interact indirectly through time bridges, and a fact-focused view where relative temporal relationships between facts are modeled directly. This dual perspective allows the model to capture both absolute temporal constraints (like "1995 < 2000") and relative event orderings (like "event A happens before event B") simultaneously.
- Core assumption: Temporal reasoning requires both absolute timestamp comparisons and relative event ordering, and modeling both perspectives provides complementary information that single-view approaches miss.
- Evidence anchors:
  - [abstract]: "the multi-view mechanism captures both time-focused and fact-focused information, allowing the two views to complement each other through adaptive fusion"
  - [section 2.3]: "Multiple views make it possible to model both absolute relationships between time expression (e.g. 1995 is before 2000 because 1995 < 2000) and relative relationships between events (e.g. Messi joins Inter Miami CF after his World Cup championship)"
  - [corpus]: Weak - only 5 related papers found, none directly addressing multi-view temporal graph mechanisms

### Mechanism 2
- Claim: Heterogeneous graph structure with different relation types enables explicit modeling of temporal and discourse relationships between facts.
- Mechanism: The framework builds a heterogeneous temporal graph with distinct node types (global node, fact nodes, time nodes with four temporal states) and multiple edge types (discourse relations between facts, temporal relations between times, bridging edges from times to facts). This explicit structure allows the model to reason about how events relate to each other temporally and how facts connect through shared topics or temporal proximity.
- Core assumption: The temporal and discourse relationships in documents contain crucial information for reasoning that is not captured by treating text as a simple sequence, and these relationships can be effectively modeled through graph structures.
- Evidence anchors:
  - [abstract]: "the heterogeneous temporal graphs explicitly model the temporal and discourse relationships among facts"
  - [section 2.3]: "In the temporal layer, we build edges according to the temporal relationship between time nodes, including before, after and overlap. In the factual layer, we build edges according to the discourse relationship between fact nodes."
  - [corpus]: Weak - limited corpus evidence for heterogeneous temporal graph approaches in QA

### Mechanism 3
- Claim: Question-guided text-graph fusion dynamically selects the most relevant graph information for each question, improving answer accuracy.
- Mechanism: The framework uses the question embedding to attend over the fused graph representation, then uses this attended representation to attend over the text representation. An adaptive gate combines the original text representation with this question-attended text representation, allowing the model to selectively incorporate graph information that is most relevant to answering the specific question.
- Core assumption: Different questions require different aspects of the temporal graph information, and a dynamic fusion mechanism can better identify and utilize the most relevant temporal relationships than a static combination approach.
- Evidence anchors:
  - [section 2.5]: "Next, we dynamically fuse the text representation and the graph representation guided by the question to get the time-enhanced representation Hf use"
  - [section 4.2]: "Question-guided text-graph fusion module dynamically selects the graph information that is more relevant to the question. As shown in Table 5(a), removing this module results in the performance degradation"
  - [corpus]: Weak - limited evidence for question-guided fusion mechanisms in temporal reasoning

## Foundational Learning

- Concept: Graph Neural Networks for heterogeneous graphs
  - Why needed here: The framework uses heterogeneous graph neural networks to process the multi-type nodes and relations in the temporal graph, requiring understanding of how GNNs handle different edge types and node categories
  - Quick check question: How does a heterogeneous GNN differ from a standard GNN in processing nodes with different types and edges with different relation types?

- Concept: Temporal reasoning and temporal expressions
  - Why needed here: The framework explicitly models temporal relationships using time expressions like "before 1995" or "between 1980-1990", requiring understanding of how to extract, normalize, and reason about temporal information in text
  - Quick check question: How would you normalize the temporal expression "the late 1990s" into a time interval for graph construction?

- Concept: Multi-view learning and adaptive fusion
  - Why needed here: The framework uses two complementary graph views and an adaptive fusion mechanism to combine them, requiring understanding of how to train and fuse multiple perspectives of the same data
  - Quick check question: What are the key differences between simple concatenation fusion and adaptive gate-based fusion for combining multi-view representations?

## Architecture Onboarding

- Component map: Text Encoder -> Graph Construction -> Graph Reasoning (Multi-view + Adaptive Fusion) -> Text-Graph Fusion -> Decoder -> Answer
- Critical path: Text → Graph Construction → Graph Reasoning (Multi-view + Adaptive Fusion) → Text-Graph Fusion → Decoder → Answer
- Design tradeoffs:
  - Using separate paragraph encoding vs. full-document encoding for computational efficiency vs. cross-paragraph context
  - Multi-view graphs vs. single graph for capturing complementary temporal perspectives vs. increased complexity
  - Question-guided fusion vs. static fusion for adaptive relevance vs. additional parameters and training complexity

- Failure signatures:
  - Poor performance on implicit reasoning questions → Graph construction or reasoning not capturing temporal relationships
  - Inconsistent answers to question perturbations → Text-graph fusion not properly incorporating temporal constraints
  - No improvement over baseline → Multi-view mechanism not effectively complementing or adaptive fusion not working

- First 3 experiments:
  1. Test graph construction on a small document to verify correct node extraction and edge building
  2. Evaluate single-view graph performance vs. multi-view to confirm complementary benefits
  3. Test question-guided fusion ablation to verify dynamic selection improves performance

## Open Questions the Paper Calls Out
- The paper suggests that a neural symbolic reasoning module could be added to provide better interpretability of the reasoning process, but does not explore this direction.
- The paper mentions that fact nodes are defined at the sentence-level granularity, but suggests that a fine-grained event-level temporal graph could be constructed by combining an event extraction system, which is left for future work.

## Limitations
- The heterogeneous graph construction details remain underspecified, particularly how discourse relationships between facts are automatically identified and how temporal relations between time expressions are determined.
- The paper does not provide a temporal reasoning process, making it difficult to interpret how the model arrives at its answers.
- The improvement over single-view approaches is modest (3.1% F1), suggesting the complementary benefits may be limited in practice.

## Confidence

| Claim | Confidence |
|-------|------------|
| Multi-view temporal graph effectiveness | Medium |
| Question-guided fusion benefits | Medium |
| Self-supervised time-comparing objective | Low-Medium |

## Next Checks
1. Implement a controlled ablation test comparing performance of time-focused view alone, fact-focused view alone, and multi-view with different fusion strategies to quantify the exact complementary benefits.
2. Conduct sensitivity analysis by systematically varying question time expressions (e.g., "1995" vs "late 90s") and measuring consistency in answers to evaluate the robustness of the question-guided fusion mechanism.
3. Design a synthetic test where temporal graph edges are manually constructed to verify whether the heterogeneous GNN can effectively propagate information along the intended temporal and discourse relationships.