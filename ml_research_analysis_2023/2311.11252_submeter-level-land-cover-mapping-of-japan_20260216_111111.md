---
ver: rpa2
title: Submeter-level Land Cover Mapping of Japan
arxiv_id: '2311.11252'
source_url: https://arxiv.org/abs/2311.11252
tags:
- land
- cover
- data
- openearthmap
- mapping
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study presents the first submeter-level land cover mapping
  of the entire country of Japan using aerial images provided by the Geospatial Information
  Authority of Japan. Leveraging the OpenEarthMap dataset, a benchmark for global
  high-resolution land cover classification mapping, a human-in-the-loop mapping framework
  was introduced.
---

# Submeter-level Land Cover Mapping of Japan

## Quick Facts
- arXiv ID: 2311.11252
- Source URL: https://arxiv.org/abs/2311.11252
- Reference count: 33
- Primary result: First submeter-level land cover mapping of Japan achieving 80.20% overall accuracy using human-in-the-loop framework

## Executive Summary
This study presents the first submeter-level land cover mapping of the entire country of Japan using aerial images provided by the Geospatial Information Authority of Japan. Leveraging the OpenEarthMap dataset, a benchmark for global high-resolution land cover classification mapping, a human-in-the-loop mapping framework was introduced. This framework efficiently handles challenging scenes that cannot be accurately classified by the OpenEarthMap pretrained model, requiring only a small additional labeled dataset. The U-Net-EfficientNet-B4 model was used for mapping, achieving an overall accuracy (OA) of 80.20% and an average accuracy (AA) of 75.59% across eight land cover classes.

## Method Summary
The study employed a human-in-the-loop deep learning framework using a U-Net-EfficientNet-B4 model trained on the OpenEarthMap dataset with additional labeled data from Japan. Aerial images from GSI were first mapped using the pretrained OpenEarthMap model, then failure cases were identified through visual inspection. A small amount of additional labeled data from challenging areas was collected and used to retrain the model. The process achieved significant accuracy improvements while minimizing annotation costs.

## Key Results
- Overall accuracy of 80.20% achieved on Japanese land cover mapping
- Average accuracy of 75.59% across eight land cover classes
- 16 percentage point improvement over initial OpenEarthMap model performance
- Successfully mapped entire country of Japan at submeter resolution

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retraining with a small amount of additional labeled data from out-of-distribution regions can significantly improve model performance.
- Mechanism: The OpenEarthMap model, trained on a globally diverse dataset, generalizes well but struggles with region-specific characteristics that are underrepresented in the original training data. By annotating and retraining on these failure cases, the model learns to handle these specific patterns.
- Core assumption: The model can effectively learn from a small set of targeted examples if they are representative of the challenging cases.
- Evidence anchors: Abstract mentions 16 percentage point improvement after retraining with small additional labeled data.

### Mechanism 2
- Claim: The human-in-the-loop framework efficiently identifies and labels the most impactful failure cases.
- Mechanism: Humans visually inspect the initial mapping results to identify obvious failures, focusing on areas where the model's predictions are significantly wrong. This targeted annotation process ensures that the additional labeled data is highly relevant.
- Core assumption: Human visual inspection is effective in identifying the most critical failure cases for annotation.
- Evidence anchors: Section describes visual checking of obvious failures from mapping results to select images for annotation.

### Mechanism 3
- Claim: The use of OpenEarthMap as a base dataset provides a strong foundation for generalization to new regions.
- Mechanism: OpenEarthMap is a globally diverse dataset covering 44 countries and 97 regions, providing a wide range of land cover types and scenarios. This diversity allows the model to learn general patterns applicable across different regions.
- Core assumption: The diversity and quality of the OpenEarthMap dataset are sufficient to provide a strong base for generalization.
- Evidence anchors: Abstract states OpenEarthMap serves as a benchmark dataset for global submeter-level land cover mapping.

## Foundational Learning

- Concept: Understanding of land cover classification and its applications
  - Why needed here: Land cover classification is the core task of this study
  - Quick check question: What are some applications of land cover classification?

- Concept: Familiarity with deep learning models for image segmentation, particularly U-Net and EfficientNet
  - Why needed here: The study uses a U-Net model with EfficientNet-B4 as the backbone
  - Quick check question: What are the key components of a U-Net model, and how does EfficientNet improve upon traditional CNN architectures?

- Concept: Knowledge of evaluation metrics for land cover classification
  - Why needed here: The study uses OA, AA, and IoU metrics to assess performance
  - Quick check question: How do overall accuracy, average accuracy, and IoU differ in their evaluation of classification performance?

## Architecture Onboarding

- Component map: Aerial imagery from GSI -> Pre-trained U-Net-EfficientNet-B4 model -> Human-in-the-loop framework -> Retrained model -> Submeter-level land cover maps of Japan

- Critical path: 1. Train initial model on OpenEarthMap 2. Apply model to GSI aerial imagery 3. Identify failure cases through visual inspection 4. Annotate and add new labeled data 5. Retrain model with extended dataset 6. Evaluate and deploy final model

- Design tradeoffs:
  - Annotation cost vs. model accuracy: Balancing the amount of additional labeled data needed for significant improvement
  - Model complexity vs. computational efficiency: Choosing a model that is both accurate and efficient for large-scale mapping
  - Generalization vs. specificity: Using a globally diverse dataset as a base while fine-tuning for specific regions

- Failure signatures:
  - High error rates in specific land cover classes (e.g., bareland, rangeland)
  - Misclassifications in regions with unique characteristics (e.g., coastal areas, runways)
  - Inconsistencies at image boundaries or in areas with heterogeneous data sources

- First 3 experiments:
  1. Train the initial U-Net-EfficientNet-B4 model on the OpenEarthMap dataset and evaluate its performance on a subset of GSI aerial imagery
  2. Visually inspect the model's predictions on GSI imagery to identify the most common failure cases and annotate a small set of these images
  3. Retrain the model with the additional labeled data and evaluate its performance on a test set, comparing it to the initial model's results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What specific improvements in accuracy could be achieved by further increasing the resolution of the land cover mapping beyond the current submeter level?
- Basis in paper: The paper discusses the first submeter-level land cover mapping of Japan and mentions that improvement in resolution is crucial for obtaining more detailed spatial information. However, it does not explore the potential benefits of even higher resolutions.
- Why unresolved: The study focuses on the challenges and achievements of submeter-level mapping and does not investigate the impact of higher resolutions on mapping accuracy.
- What evidence would resolve it: Comparative studies showing accuracy improvements with higher resolution imagery would provide insights into the potential benefits of increasing resolution further.

### Open Question 2
- Question: How does the performance of the U-Net-EfficientNet-B4 model compare to other state-of-the-art deep learning models for land cover mapping?
- Basis in paper: The paper uses a U-Net-EfficientNet-B4 model for mapping and mentions that this model has demonstrated both lightweight and high accuracy. However, it does not compare its performance to other models.
- Why unresolved: The study focuses on the effectiveness of the U-Net-EfficientNet-B4 model but does not provide a comprehensive comparison with other models.
- What evidence would resolve it: Comparative experiments with other deep learning models on the same dataset would provide insights into the relative performance of the U-Net-EfficientNet-B4 model.

### Open Question 3
- Question: What are the potential challenges and solutions for extending the proposed human-in-the-loop framework to other countries with limited high-resolution remote sensing data?
- Basis in paper: The paper mentions the potential of applying the proposed framework to other countries, particularly those with limited available high-resolution remote sensing data, such as African countries. However, it does not explore the specific challenges and solutions for such extensions.
- Why unresolved: The study focuses on the application of the framework to Japan and does not delve into the unique challenges and solutions for other countries with different data availability and geographic characteristics.
- What evidence would resolve it: Case studies and pilot projects applying the framework to other countries with limited data would provide insights into the specific challenges and potential solutions for such extensions.

## Limitations
- The exact number and distribution of additional labeled data points used for retraining in Japan remains unspecified
- Specific implementation details of the human-in-the-loop framework are not fully detailed
- Limited comparison with other state-of-the-art deep learning models for land cover mapping

## Confidence

- High confidence: The general framework and methodology are well-established and clearly described
- Medium confidence: The reported accuracy improvements are plausible given the approach, but the lack of detail on the additional labeled data makes exact replication challenging
- Medium confidence: The comparison with other models provides useful context, but differences in input resolutions and classes limit direct comparisons

## Next Checks

1. Quantify the annotation cost: Determine the exact number of additional labeled samples needed and the time required for human annotation to achieve the reported accuracy improvement
2. Cross-regional validation: Apply the retrained model to a different geographic region with similar characteristics to Japan to assess its generalization capability
3. Ablation study: Conduct experiments to isolate the contribution of each component (OpenEarthMap pretraining, human-in-the-loop annotation, model architecture) to the final performance