---
ver: rpa2
title: Learning Semantic Segmentation with Query Points Supervision on Aerial Images
arxiv_id: '2309.05490'
source_url: https://arxiv.org/abs/2309.05490
tags:
- segmentation
- semantic
- image
- supervised
- images
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a weakly supervised learning approach for
  semantic segmentation of aerial images using only query point annotations. The method
  extends point labels to superpixels and trains a segmentation model with a masked
  weighted loss, achieving competitive results with significantly reduced annotation
  effort.
---

# Learning Semantic Segmentation with Query Points Supervision on Aerial Images

## Quick Facts
- arXiv ID: 2309.05490
- Source URL: https://arxiv.org/abs/2309.05490
- Reference count: 40
- Primary result: Achieves mIoU of 0.756 with 50 query points per image, only 8% lower than fully supervised training

## Executive Summary
This paper introduces a weakly supervised learning approach for semantic segmentation of aerial images using only query point annotations. The method extends point labels to superpixels and trains a segmentation model with a masked weighted loss, achieving competitive results with significantly reduced annotation effort. Evaluated on the LandCoverAI dataset using DeepLabV3, UNet, and FCNet backbones, the approach reaches a mean IoU of 0.756 with 50 query points per image, only 8% lower than fully supervised training. It generalizes well to other domains like the OxfordIIITPet dataset (mIoU 0.8747) and maintains strong performance across different backbone architectures. The method is publicly available and offers a practical solution for efficient satellite image segmentation.

## Method Summary
The proposed method uses query point annotations to create pseudo-annotations for semantic segmentation by extending point labels to superpixels. Specifically, the approach generates superpixels using the DAL-HERS algorithm and propagates point labels to entire superpixels based on majority vote within each superpixel. A weighted masked loss function is then used during training, computing Mean Square Error only on pixels within labeled superpixels while normalizing by class frequency to handle class imbalance. The method is evaluated on aerial imagery using various backbone architectures including DeepLabV3, UNet, and FCNet, demonstrating competitive performance compared to fully supervised approaches while significantly reducing annotation effort.

## Key Results
- Achieved mIoU of 0.756 with only 50 query points per image, compared to 0.820 with full supervision
- Maintained strong performance across different backbone architectures (DeepLabV3, UNet, FCNet)
- Generalizes well to other domains, reaching mIoU of 0.8747 on OxfordIIITPet dataset
- Reduces annotation effort by requiring only point labels instead of full pixel-wise segmentation masks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Query point labels are effectively extended to superpixels, creating richer pseudo-annotations for training semantic segmentation models.
- Mechanism: The approach uses a superpixel algorithm (DAL-HERS) to group similar pixels, then propagates point labels to entire superpixels based on majority vote, expanding sparse point supervision to dense region supervision.
- Core assumption: Superpixels generated by DAL-HERS accurately capture semantically meaningful regions that align with object boundaries in aerial imagery.
- Evidence anchors:
  - [abstract] "Specifically, we generate superpixels and extend the query point labels into those superpixels that group similar meaningful semantics."
  - [section] "Here, the assignment of labeled key points Lp in the corresponding superpixel region can be expressed as: Ls = (mode(Lp), if ∃p ∈ P such that p ∈ S no label, otherwise)"

### Mechanism 2
- Claim: The weighted masked loss function improves training by focusing optimization on labeled regions while balancing class frequencies.
- Mechanism: The loss computes MSE only on pixels within labeled superpixels and normalizes by class frequency to prevent dominant classes from overwhelming the gradient.
- Core assumption: Normalizing by class frequency during masked loss computation leads to better gradient balance and improved model convergence.
- Evidence anchors:
  - [section] "This loss function consists of a Mean Square Error (MSE), which we multiply with a binary mask that contains one where the image is labeled and zero where the image is unlabeled."
  - [section] "Also, this loss function corrects the class imbalance by dividing the masked loss by the percent of each class, penalizing the classes with the highest percentage."

### Mechanism 3
- Claim: Using fewer labeled pixels (query points) while maintaining competitive mIoU is achievable because superpixel-based supervision provides sufficient spatial context.
- Mechanism: By extending point labels to superpixels, the approach provides more supervisory signals than point-only methods while avoiding the cost of full pixel labeling.
- Core assumption: The spatial context embedded in superpixels is sufficient to guide the model to learn meaningful object boundaries and shapes.
- Evidence anchors:
  - [abstract] "We benchmark our weakly supervised training approach on an aerial image dataset and different semantic segmentation architectures, showing that we can reach competitive performance compared to fully supervised training while reducing the annotation effort."
  - [section] "Specifically, we generate superpixels and extend the query point labels into those superpixels that group similar meaningful semantics."

## Foundational Learning

- Concept: Superpixel algorithms and their role in weakly supervised learning
  - Why needed here: Understanding how superpixels group similar pixels and preserve boundaries is crucial for interpreting how query points get extended to meaningful regions.
  - Quick check question: What property of superpixels makes them useful for extending sparse annotations in weakly supervised segmentation?

- Concept: Semantic segmentation loss functions and their variants
  - Why needed here: The weighted masked loss is central to the approach; knowing how MSE, cross-entropy, and masked variants differ is essential for implementation and debugging.
  - Quick check question: How does a masked loss differ from standard cross-entropy in terms of gradient computation?

- Concept: Class imbalance handling in segmentation
  - Why needed here: The approach normalizes by class frequency to balance gradients; understanding this helps in diagnosing convergence issues.
  - Quick check question: Why might dividing the loss by class percentage help with segmentation performance on imbalanced datasets?

## Architecture Onboarding

- Component map:
  - Query point selection (manual or algorithmic)
  - Superpixel extraction (DAL-HERS)
  - Point-to-superpixel label extension (majority vote within superpixels)
  - Segmentation backbone (DeepLabV3, UNet, FCNet)
  - Weighted masked loss function
  - Training loop with Adam optimizer

- Critical path:
  1. Generate superpixels from input image
  2. Extend query point labels to superpixels
  3. Compute pseudo-annotation mask
  4. Forward pass through segmentation model
  5. Compute weighted masked loss
  6. Backpropagate and update model

- Design tradeoffs:
  - Superpixel count: More superpixels → finer supervision but potentially noisier labels; fewer → coarser but cleaner labels
  - Loss function: MSE vs cross-entropy affects gradient stability and convergence speed
  - Backbone choice: Trade-off between accuracy (DeepLabV3) and efficiency (UNet, FCNet)

- Failure signatures:
  - Poor mIoU with many query points → superpixel boundaries not aligned with semantic boundaries
  - Unstable training → class imbalance not properly handled or learning rate too high
  - Slow convergence → insufficient supervisory signals or overly complex backbone for data size

- First 3 experiments:
  1. Vary number of query points (e.g., 10, 20, 50) while keeping superpixel count fixed; measure mIoU
  2. Vary number of superpixels (e.g., 80, 100, 200) while keeping query points fixed; measure mIoU
  3. Compare weighted masked MSE loss vs standard cross-entropy on same dataset; measure mIoU and training stability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the proposed weakly supervised method scale when applied to very large-scale satellite image datasets (e.g., BigEarthNet with over 590,000 images)?
- Basis in paper: [explicit] The paper mentions future work plans to test the method on other large-scale satellite image datasets and explores domain generalization on OxfordIIITPet dataset.
- Why unresolved: The current experiments are limited to the LandCoverAI dataset (10,674 images) and one additional dataset (OxfordIIITPet). The method's performance on truly large-scale remote sensing datasets remains untested.
- What evidence would resolve it: Systematic evaluation on datasets like BigEarthNet or similar large-scale remote sensing archives, comparing performance metrics (mIoU) and annotation efficiency gains against fully supervised baselines.

### Open Question 2
- Question: What is the optimal number of query points per class for achieving maximum annotation efficiency without significant performance degradation?
- Basis in paper: [explicit] The paper varies the number of query points (10, 20, 30, 40, 50) and shows performance improvements with more points, but does not identify an optimal trade-off point.
- Why unresolved: The experiments show a general trend of improved performance with more points, but do not determine the point of diminishing returns where additional annotation effort no longer yields meaningful accuracy gains.
- What evidence would resolve it: Detailed ablation studies across a wider range of point densities (e.g., 5, 15, 25, 35, 45, 55) with cost-benefit analysis measuring annotation time versus mIoU improvement to identify the optimal balance.

### Open Question 3
- Question: How does the proposed method perform when applied to multi-spectral satellite imagery beyond RGB (e.g., incorporating NIR, SWIR bands)?
- Basis in paper: [inferred] The LandCoverAI dataset uses RGB imagery, and the method could theoretically benefit from additional spectral information present in multi-spectral data.
- Why unresolved: The current implementation and evaluation are limited to RGB imagery, and the method's ability to leverage additional spectral bands for improved segmentation accuracy is unexplored.
- What evidence would resolve it: Implementation of the framework to process multi-spectral inputs (e.g., 4-band RGB+NIR or 8-band Sentinel-2 data) with comparative performance analysis against the RGB-only version.

## Limitations
- The method's performance heavily depends on the quality of superpixel segmentation, which may vary across different aerial image datasets and sensor resolutions.
- The choice of DAL-HERS superpixel algorithm is not justified over alternatives, and its hyperparameters are not specified, potentially affecting reproducibility.
- The assumption that superpixels accurately capture semantically meaningful regions is not rigorously tested across diverse datasets and sensor configurations.

## Confidence
- **High Confidence**: The core methodology of extending point labels to superpixels and using weighted masked loss is clearly described and validated through experiments on LandCoverAI and OxfordIIITPet datasets.
- **Medium Confidence**: The claim that 50 query points achieve 92% of fully supervised performance is well-supported, but the exact relationship between query point count and mIoU may be dataset-dependent.
- **Low Confidence**: The assumption that superpixels generated by DAL-HERS accurately capture semantically meaningful regions for all types of aerial imagery is not rigorously tested across diverse datasets and sensor configurations.

## Next Checks
1. **Superpixel Quality Assessment**: Conduct experiments varying the number of superpixels (e.g., 50, 100, 200) while keeping query points fixed to determine optimal superpixel granularity for different object scales in aerial imagery.

2. **Cross-Dataset Generalization**: Evaluate the approach on additional aerial/satellite datasets with different resolutions, sensor types, and geographic regions to assess robustness and identify dataset-specific limitations.

3. **Alternative Superpixel Methods**: Compare DAL-HERS against other superpixel algorithms (SLIC, Felzenszwalb) to determine if the performance gains are specific to DAL-HERS or can be achieved with more standard methods.