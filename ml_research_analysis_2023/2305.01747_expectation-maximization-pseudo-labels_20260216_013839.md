---
ver: rpa2
title: Expectation Maximization Pseudo Labels
arxiv_id: '2305.01747'
source_url: https://arxiv.org/abs/2305.01747
tags:
- pseudo
- segmentation
- learning
- data
- semi-supervised
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper interprets pseudo-labelling as Expectation-Maximization
  (EM) and explores its generalisation using variational inference. The authors propose
  a method called Bayesian Pseudo Labels (BPL) which learns a threshold to automatically
  select high-quality pseudo labels.
---

# Expectation Maximization Pseudo Labels

## Quick Facts
- arXiv ID: 2305.01747
- Source URL: https://arxiv.org/abs/2305.01747
- Reference count: 40
- Key outcome: Introduces Bayesian Pseudo Labels (BPL) that learns a threshold for automatic high-quality pseudo label selection, achieving competitive results on medical image segmentation tasks with lower computational burden and improved robustness

## Executive Summary
This paper establishes a theoretical connection between pseudo-labelling and the Expectation-Maximization (EM) algorithm in semi-supervised segmentation. The authors propose Bayesian Pseudo Labels (BPL), which extends traditional pseudo-labelling by learning a threshold for pseudo-label selection via variational inference. This approach enables adaptive selection of high-quality pseudo-labels based on model confidence rather than fixed thresholds. Experiments demonstrate that BPL achieves competitive performance on multiple medical imaging tasks while providing better robustness to out-of-distribution noise and adversarial attacks, along with potential for uncertainty quantification.

## Method Summary
The method interprets pseudo-labelling as an EM algorithm where the E-step generates pseudo-labels and the M-step updates model parameters. BPL generalizes this by treating the threshold for pseudo-label selection as a latent variable learned through variational inference. The approach combines supervised loss (Dice loss) with unsupervised loss incorporating an Evidence Lower Bound (ELBO) term. The threshold is modeled as a distribution with learnable parameters, and the reparameterization trick enables gradient-based optimization. The method is evaluated on 3D binary segmentation of lung vessels from CT volumes, 2D multi-class segmentation of brain tumors from MRI volumes, and other medical imaging tasks.

## Key Results
- BPL achieves competitive segmentation performance compared to state-of-the-art methods across multiple medical imaging datasets
- The method demonstrates lower computational burden while maintaining or improving accuracy
- BPL shows higher robustness to out-of-distribution noise and adversarial attacks compared to baseline methods
- The learned threshold automatically adapts to data characteristics, reducing sensitivity to fixed hyperparameter choices

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Pseudo-labelling in semi-supervised segmentation can be interpreted as an Expectation-Maximization (EM) algorithm, where the E-step generates pseudo-labels and the M-step updates model parameters using these pseudo-labels.
- Mechanism: The algorithm iteratively alternates between estimating the posterior of latent variables (pseudo-labels) given current model parameters (E-step) and maximizing the likelihood of the data given these estimated pseudo-labels (M-step). This iterative process guarantees convergence to a local optimum.
- Core assumption: The cluster assumption holds, meaning that similar data points are likely to have similar labels, justifying the use of maximum predicted probability for pseudo-label generation.
- Evidence anchors:
  - [abstract]: "We elucidate the empirical successes of pseudo-labelling by establishing a link between this technique and the Expectation Maximisation algorithm."
  - [section 3.3]: "Therefore, the pseudo-labelling itself is the E-step... The above Eq. 5 is normally solved by setting the partial derivatives... which can be calculated with modern automatic differentiation based deep learning toolbox such as Pytorch."
- Break condition: If the cluster assumption fails significantly, the E-step may generate incorrect pseudo-labels that mislead the M-step, causing the algorithm to converge to poor local optima.

### Mechanism 2
- Claim: Bayesian Pseudo Labels (BPL) generalize the original pseudo-labelling by treating the threshold for pseudo-label selection as a latent variable and learning it via variational inference.
- Mechanism: Instead of using a fixed threshold (typically 0.5), BPL introduces a probabilistic threshold that is learned during training. This allows the model to adaptively select high-quality pseudo-labels based on the confidence of predictions, reducing the impact of noisy labels.
- Core assumption: The threshold for pseudo-label selection can be modeled as a distribution over the range [0,1], and this distribution can be learned to approximate the true posterior.
- Evidence anchors:
  - [abstract]: "Following this insight, we present a full generalisation of pseudo-labels under Bayes' theorem, termed Bayesian Pseudo Labels. Subsequently, we introduce a variational approach to generate these Bayesian Pseudo Labels, involving the learning of a threshold to automatically select high-quality pseudo labels."
  - [section 4.1]: "To address this potential issue, we provide an alternative approach to learn to approximate the true posterior of the pseudo labels. This alternative approach can be seen as a generalisation of the empirical estimation approach in SegPL in section 3."
- Break condition: If the prior distribution for the threshold is poorly chosen or if the variational approximation is inadequate, BPL may fail to learn an optimal threshold, leading to performance degradation.

### Mechanism 3
- Claim: The use of variational inference in BPL provides a principled way to handle the uncertainty in pseudo-label selection, improving robustness to out-of-distribution noise and adversarial attacks.
- Mechanism: By modeling the threshold as a random variable with a learned distribution, BPL introduces stochasticity into the pseudo-label selection process. This stochasticity acts as a regularizer, making the model more robust to variations in the input data and less sensitive to adversarial perturbations.
- Core assumption: The stochastic threshold introduces beneficial noise that regularizes the model and improves generalization.
- Evidence anchors:
  - [abstract]: "Experiments on 3D binary segmentation of lung vessels from CT volumes, 2D multi-class segmentation of brain tumours from MRI volumes... demonstrate the effectiveness of the proposed method... with lower computational burden and higher robustness to out-of-distribution noise and adversarial attacks."
  - [section 6.7]: "We investigate the robustness of SegPL on out-of-distribution (OOD) noise... SegPL outperformed all of the baselines across all of the tested experimental settings."
- Break condition: If the stochasticity introduced by the variational threshold is too high, it may lead to unstable training and poor convergence.

## Foundational Learning

- Concept: Expectation-Maximization (EM) algorithm
  - Why needed here: The paper interprets pseudo-labelling as an EM algorithm, so understanding EM is crucial for grasping the theoretical foundation of the method.
  - Quick check question: What are the E-step and M-step in the EM algorithm, and how do they relate to pseudo-labelling in semi-supervised learning?

- Concept: Variational Inference
  - Why needed here: BPL uses variational inference to learn the threshold for pseudo-label selection. Understanding variational inference is essential for comprehending how BPL generalizes the original pseudo-labelling approach.
  - Quick check question: What is the Evidence Lower Bound (ELBO) in variational inference, and how is it used to approximate the true posterior distribution?

- Concept: Semi-supervised Learning
  - Why needed here: The paper focuses on semi-supervised segmentation of medical images, so understanding the principles of semi-supervised learning is necessary for appreciating the context and motivation of the work.
  - Quick check question: What are the main challenges in semi-supervised learning, and how does pseudo-labelling address these challenges?

## Architecture Onboarding

- Component map: Backbone U-Net -> Threshold Network -> Stochastic Threshold Sampling -> Pseudo-label Generation -> Loss Computation
- Critical path: Forward pass through the backbone to generate predictions → Threshold network predicts the threshold distribution → Stochastic threshold is sampled and applied to generate pseudo-labels → Loss is computed and backpropagated to update both the backbone and threshold network
- Design tradeoffs:
  - Fixed vs. Learned Threshold: Using a fixed threshold (e.g., 0.5) is simple but may be suboptimal. Learning the threshold via variational inference is more flexible but adds complexity.
  - Stochastic vs. Deterministic Threshold: A stochastic threshold introduces beneficial noise but may lead to unstable training. A deterministic threshold is more stable but may overfit.
- Failure signatures:
  - Poor convergence: The model may fail to converge if the threshold network is not properly initialized or if the learning rate is too high.
  - Overconfident predictions: The model may become overconfident in its predictions, leading to poor generalization. This can be mitigated by using a prior that encourages uncertainty.
  - Sensitivity to hyperparameters: The performance of BPL may be sensitive to the choice of hyperparameters, such as the prior mean and variance of the threshold distribution.
- First 3 experiments:
  1. Implement SegPL with a fixed threshold (e.g., 0.5) and compare its performance to supervised training on a small labeled dataset.
  2. Implement BPL with a learned threshold and compare its performance to SegPL and supervised training on the same dataset.
  3. Experiment with different priors for the threshold distribution (e.g., different means and variances) and observe their impact on the performance of BPL.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of SegPL and SegPL-VI vary with different prior distributions for the threshold T?
- Basis in paper: [explicit] The authors mention that Gaussian prior is used due to simplicity, but other priors like categorical and Beta distributions could be explored.
- Why unresolved: The paper only briefly mentions the potential impact of different priors without conducting a comprehensive comparison.
- What evidence would resolve it: Conducting experiments with different prior distributions and comparing the performance of SegPL and SegPL-VI would provide evidence on the optimal prior for the threshold T.

### Open Question 2
- Question: How does the number of labeled data points affect the prevention of collapsed representations in SegPL?
- Basis in paper: [inferred] The authors mention that studying the impact of labeled data on preventing collapsed representations is an interesting future work.
- Why unresolved: The paper does not provide any experimental results or analysis on the relationship between the number of labeled data points and the prevention of collapsed representations.
- What evidence would resolve it: Conducting experiments with varying numbers of labeled data points and analyzing the impact on the prevention of collapsed representations would provide evidence on the optimal number of labeled data points for SegPL.

### Open Question 3
- Question: How does the convergence property of SegPL-VI differ from that of SegPL, and how can it be improved for uncertainty quantification?
- Basis in paper: [inferred] The authors mention that future work can look into the convergence property of SegPL-VI and improving it for uncertainty quantification.
- Why unresolved: The paper does not provide any analysis or experimental results on the convergence property of SegPL-VI or how it can be improved for uncertainty quantification.
- What evidence would resolve it: Conducting experiments to analyze the convergence property of SegPL-VI and exploring methods to improve it for uncertainty quantification would provide evidence on the optimal approach for uncertainty quantification in SegPL-VI.

## Limitations

- The paper lacks comprehensive ablation studies on the threshold learning mechanism and its sensitivity to hyperparameters
- Robustness experiments are limited to specific types of perturbations without exploring a wider range of adversarial attacks
- The potential for uncertainty quantification is mentioned but not thoroughly validated with concrete uncertainty estimation methods
- No quantitative comparison of computational burden is provided despite claims of lower computational requirements

## Confidence

The confidence in the EM interpretation is **High**, as it is well-grounded in established theory. However, confidence in the effectiveness of BPL is **Medium** due to limited ablation studies on the threshold learning mechanism and its sensitivity to hyperparameters. A key limitation is the lack of analysis on how the learned threshold distribution evolves during training and its impact on segmentation quality.

## Next Checks

1. **Ablation Study on Threshold Learning**: Conduct an ablation study to assess the impact of different priors and threshold learning mechanisms on BPL's performance.

2. **Robustness Analysis**: Extend the robustness experiments to include a wider range of adversarial attacks and out-of-distribution noise types.

3. **Uncertainty Quantification Validation**: Implement and evaluate a specific uncertainty quantification method (e.g., Monte Carlo dropout) to assess BPL's potential in this area.