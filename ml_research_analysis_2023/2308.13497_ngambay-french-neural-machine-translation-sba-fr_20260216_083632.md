---
ver: rpa2
title: Ngambay-French Neural Machine Translation (sba-Fr)
arxiv_id: '2308.13497'
source_url: https://arxiv.org/abs/2308.13497
tags:
- data
- languages
- translation
- language
- machine
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the first neural machine translation system
  for Ngambay (sba), a low-resource Chadian language, to French. The authors created
  a new sba-Fr parallel corpus by combining a manually curated Ngambay-French dictionary
  dataset with web-scraped Bible verses, resulting in 33,073 sentence pairs.
---

# Ngambay-French Neural Machine Translation (sba-Fr)

## Quick Facts
- arXiv ID: 2308.13497
- Source URL: https://arxiv.org/abs/2308.13497
- Reference count: 8
- Key outcome: M2M100 achieved BLEU scores of 33.06 on original data and 53.10 with synthetic data augmentation for Ngambay-French translation.

## Executive Summary
This paper presents the first neural machine translation system for Ngambay (sba), a low-resource Chadian language, to French. The authors created a new sba-Fr parallel corpus by combining a manually curated Ngambay-French dictionary dataset with web-scraped Bible verses, resulting in 33,073 sentence pairs. They fine-tuned three transformer-based models (M2M100, ByT5, MT5) on this data. The M2M100 model achieved the best performance, with BLEU scores of 33.06 on the original data and 53.10 after incorporating synthetic parallel data generated via noisy French-to-Ngambay translation. The authors demonstrate the potential of guided data collection for low-resource languages and show that fine-tuning multilingual models with synthetic data significantly improves translation quality.

## Method Summary
The authors created a new sba-Fr parallel corpus by combining a manually curated Ngambay-French dictionary dataset (1,176 sentence pairs) with web-scraped Bible verses (34,647 sentence pairs), resulting in 33,073 sentence pairs after quality control. They fine-tuned three transformer-based models (M2M100, ByT5, MT5) using HuggingFace's transformer tool with a learning rate of 5e-5, batch size of 5, maximum source and target lengths of 200, beam size of 10, and 60 epochs. To improve translation quality, they generated synthetic parallel data by translating French monolingual sentences to Ngambay using the fine-tuned M2M100 model and retrained the model on the combined original and synthetic data.

## Key Results
- M2M100 model achieved BLEU score of 33.06 on original sba-Fr data
- Incorporating synthetic data improved BLEU score to 53.10
- M2M100 outperformed ByT5 and MT5 models on this task

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fine-tuning multilingual pre-trained models on low-resource language pairs improves translation quality compared to training from scratch.
- Mechanism: The model leverages shared linguistic knowledge across languages learned during pre-training, reducing the amount of parallel data needed for good performance on the target language pair.
- Core assumption: The pre-trained model's multilingual embedding space captures transferable features relevant to the target low-resource language.
- Evidence anchors:
  - [abstract] states the authors fine-tuned three transformer-based models (M2M100, ByT5, MT5) on the sba-Fr dataset and achieved high BLEU scores.
  - [section 6] describes the pre-trained models used and their multilingual training.
  - [corpus] shows related work on fine-tuning pre-trained models for low-resource languages, supporting this mechanism.
- Break condition: If the pre-trained model lacks representation of the target language or its linguistic features are too dissimilar from supported languages.

### Mechanism 2
- Claim: Incorporating synthetic parallel data generated via noisy back-translation significantly improves translation quality.
- Mechanism: The model is exposed to more diverse target language text, improving its ability to generate fluent and accurate translations in the target language.
- Core assumption: The synthetic data, while noisy, provides useful signal for learning target language fluency and reducing exposure bias.
- Evidence anchors:
  - [abstract] states the M2M100 model achieved a BLEU score of 53.10 after incorporating synthetic parallel data generated via noisy French-to-Ngambay translation.
  - [section 7.1] describes the data augmentation process using French monolingual data to generate synthetic bitext.
  - [corpus] includes related work on using back-translation for data augmentation in low-resource NMT, supporting this mechanism.
- Break condition: If the synthetic data quality is too low due to translation errors, it may introduce noise that degrades model performance.

### Mechanism 3
- Claim: Guided data collection for low-resource languages can produce sufficient bitext data for training effective NMT models.
- Mechanism: By curating parallel data from multiple sources (dictionaries, religious texts) and quality checking with native speakers, a reasonably sized and aligned corpus can be constructed.
- Core assumption: Even small amounts of carefully curated parallel data are sufficient to train NMT models when combined with pre-training and data augmentation techniques.
- Evidence anchors:
  - [abstract] states the authors created a new sba-Fr parallel corpus of 33,073 sentence pairs by combining a manually curated dictionary dataset with web-scraped Bible verses.
  - [section 5] describes the data creation process, including quality control by native speakers.
  - [corpus] shows related work on creating parallel corpora for low-resource African languages, supporting this mechanism.
- Break condition: If the available data sources are too limited or the language pair has significant structural differences, guided collection may not yield enough quality data.

## Foundational Learning

- Concept: Neural Machine Translation (NMT)
  - Why needed here: The paper focuses on building NMT systems for low-resource languages, so understanding NMT concepts is crucial.
  - Quick check question: What is the key difference between traditional phrase-based MT and NMT approaches?

- Concept: Transformer Architecture
  - Why needed here: The models used (M2M100, ByT5, MT5) are based on the transformer architecture, which is essential to understand for interpreting the results.
  - Quick check question: How do the encoder and decoder in a transformer model interact during the translation process?

- Concept: Data Augmentation Techniques
  - Why needed here: The paper employs back-translation to generate synthetic parallel data, a common technique in low-resource NMT.
  - Quick check question: What is the purpose of adding noise to the back-translation process when generating synthetic data?

## Architecture Onboarding

- Component map: Data Collection -> Model Selection -> Data Augmentation -> Training -> Evaluation
- Critical path: Data collection → Model fine-tuning on original data → Data augmentation → Fine-tuning on augmented data → Evaluation
- Design tradeoffs:
  - Using pre-trained models vs. training from scratch: Pre-trained models require less data but may not capture unique features of the target language
  - Manual data curation vs. automatic scraping: Manual curation ensures quality but is time-consuming, while automatic scraping is faster but may introduce noise
  - Noisy back-translation vs. clean back-translation: Noisy back-translation introduces more diversity but may add noise, while clean back-translation is less diverse but more reliable
- Failure signatures:
  - Low BLEU scores on both original and augmented data: Indicates issues with model architecture, data quality, or training process
  - Significant drop in BLEU score after adding synthetic data: Suggests the synthetic data quality is too low or introduces conflicting signals
  - Disparity between training and validation BLEU scores: Indicates overfitting to the training data
- First 3 experiments:
  1. Fine-tune M2M100 on the original sba-Fr dataset and evaluate with BLEU score
  2. Generate synthetic parallel data via noisy back-translation of French monolingual data
  3. Fine-tune M2M100 on the combined original and synthetic data, evaluate with BLEU score

## Open Questions the Paper Calls Out
No open questions are explicitly called out in the paper.

## Limitations
- Evaluation relies solely on BLEU scores, which may not fully capture translation quality for morphologically rich languages like Ngambay
- Small size of original parallel corpus (33,073 sentence pairs) raises questions about model's generalization to broader domains beyond religious texts
- Synthetic data generation process lacks detailed specification, making it difficult to assess the quality and reliability of the augmentation approach

## Confidence
- **High Confidence**: The core claim that fine-tuning multilingual pre-trained models on low-resource language pairs improves translation quality is well-supported by the experimental results and aligns with established practices in the field.
- **Medium Confidence**: The assertion that incorporating synthetic parallel data significantly improves translation quality is supported by the BLEU score improvement, but the lack of detailed synthetic data generation specifications introduces some uncertainty about reproducibility.
- **Low Confidence**: The claim that guided data collection can produce sufficient bitext data for effective NMT models is based on a single case study and may not generalize to other low-resource language pairs with different characteristics.

## Next Checks
1. Conduct a human evaluation study to assess translation quality beyond BLEU scores, focusing on adequacy, fluency, and domain-specific accuracy for Ngambay-French translations
2. Test the trained models on out-of-domain data (e.g., news articles, conversational text) to evaluate their ability to generalize beyond the religious text domain of the training data
3. Perform a detailed analysis of the synthetic parallel data quality, including manual inspection of generated sentence pairs and comparison of translation accuracy before and after incorporating synthetic data