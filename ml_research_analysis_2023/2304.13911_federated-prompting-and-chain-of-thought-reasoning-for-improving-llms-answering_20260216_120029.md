---
ver: rpa2
title: Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering
arxiv_id: '2304.13911'
source_url: https://arxiv.org/abs/2304.13911
tags:
- questions
- answers
- llms
- reasoning
- answer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study proposes federated prompting techniques to improve the
  accuracy of large language models (LLMs) in answering frequently asked questions
  from distributed users. The key idea is to leverage synonymous questions from a
  crowd-sourced database to enhance answer precision without requiring sophisticated
  model tuning.
---

# Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering

## Quick Facts
- arXiv ID: 2304.13911
- Source URL: https://arxiv.org/abs/2304.13911
- Authors: 
- Reference count: 27
- Key outcome: Fed-SP-SC achieves 14-18% accuracy improvement over standalone LLMs using self-consistency voting on synonymous questions

## Executive Summary
This paper introduces federated prompting techniques to enhance large language model (LLM) accuracy on frequently asked questions without model tuning or data exchange. The approach leverages a crowd-sourced database of synonymous questions to improve answer precision through two methods: Fed-SP-SC for questions with identical parameters using self-consistency voting, and Fed-DP-CoT for questions with different parameters using chain-of-thought reasoning. Experiments on GSM8K and SVAMP datasets demonstrate significant accuracy improvements while preserving user privacy through centralized storage rather than direct data exchange.

## Method Summary
The federated prompting framework retrieves synonymous questions from a centralized database and uses them to enhance LLM answers through two complementary approaches. Fed-SP-SC applies self-consistency to multiple synonymous questions with identical parameters, selecting the most frequently generated answer. Fed-DP-CoT uses consistent answers from synonymous questions with different parameters as chain-of-thought prompts for the original query. Both methods preserve privacy by avoiding direct data exchange between distributed users while still capturing the benefits of collaborative learning through centralized question-answer storage.

## Key Results
- Fed-SP-SC achieves 14-18% accuracy improvement over standalone LLMs on GSM8K and SVAMP datasets
- Fed-DP-CoT delivers 10-15% accuracy increase by using chain-of-thought reasoning
- Self-consistency voting effectively filters noisy responses when multiple SP-questions are available
- CoT disclaimers provide 2% additional accuracy improvement by preventing negative impact from incorrect pseudo-labels

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Fed-SP-SC improves accuracy by leveraging self-consistency voting across synonymous SP-questions with identical parameters.
- Mechanism: Multiple SP-questions with same parameters are retrieved and answered by LLM. Self-consistency aggregates these answers and selects the most frequently voted answer as final answer.
- Core assumption: Synonymous questions with same parameters should produce same correct answer, so majority voting filters out noisy responses.
- Evidence anchors:
  - [abstract]: "Fed-SP-SC employs self-consistency to select the most commonly voted answer"
  - [section]: "Assuming that we have generated a total of n answers of synonymous questions during the Fed-SP-SC process, we can ensure the consistency with SC procedure, i.e., we make a majority vote and select the most voted answer ASC as the final answer"

### Mechanism 2
- Claim: Fed-DP-CoT improves accuracy by using consistent answers from DP-questions as chain-of-thought prompts for original query.
- Mechanism: For DP-questions (synonymous but different parameters), consistent answers are generated using Fed-SP-SC, then concatenated with their reasoning steps to form CoT prompt used as prefix to original query.
- Core assumption: DP-questions share same reasoning structure despite different parameters, so consistent answers provide useful reasoning hints.
- Evidence anchors:
  - [abstract]: "Fed-DP-CoT uses chain-of-thought reasoning"
  - [section]: "We utilize these DP-questions with pseudo-labels together as CoT for the original query-question. To be specific, we concatenate DP-questions with their answers as a single prompt, followed by the error disclaimer"

### Mechanism 3
- Claim: Federated approach preserves user privacy by avoiding data exchange among distributed users while improving answer quality.
- Mechanism: Instead of sharing raw questions between users, system stores all question-answer pairs in centralized database. When user queries, system retrieves similar questions from database to enhance answer.
- Core assumption: Centralized storage doesn't violate privacy as much as direct data exchange, while still capturing federated learning benefits.
- Evidence anchors:
  - [abstract]: "These methods preserve user privacy by avoiding data exchange among distributed users"
  - [section]: "Inherited from Federated Learning, our Fed-SP-SC and Fed-DP-COT methods can collaboratively enhance the question-answering process of the LLM while preserving their anonymity. There would be no data exchange or leakage among distributed users"

## Foundational Learning

- Concept: Chain-of-Thought (CoT) prompting
  - Why needed here: Helps LLMs break down complex reasoning tasks into intermediate steps, improving ability to solve multi-step problems like arithmetic word problems
  - Quick check question: What is the purpose of adding "Let's think step by step" to a prompt?

- Concept: Self-Consistency (SC) decoding
  - Why needed here: Improves answer reliability by sampling multiple reasoning paths and selecting most commonly agreed answer, filtering out noise and outliers
  - Quick check question: How does self-consistency differ from standard greedy decoding in LLMs?

- Concept: Federated Learning principles
  - Why needed here: Allows distributed users to benefit from each other's questions without sharing raw data, preserving privacy while improving model performance
  - Quick check question: What is the key privacy benefit of federated learning compared to centralized training?

## Architecture Onboarding

- Component map:
  User Query Interface -> Database -> SP-Question Retriever -> LLM Service -> Fed-SP-SC Engine -> Answer Aggregator
  User Query Interface -> Database -> DP-Question Retriever -> LLM Service -> Fed-DP-CoT Engine -> Answer Aggregator

- Critical path:
  1. User submits query
  2. System retrieves SP-questions (if any)
  3. If SP-questions exist, Fed-SP-SC engine applies self-consistency
  4. If no SP-questions or Fed-SP-SC fails, system retrieves DP-questions
  5. Fed-DP-CoT engine creates CoT prompt from DP-questions
  6. LLM generates final answer
  7. Answer is stored in database

- Design tradeoffs:
  - Privacy vs. Performance: Centralized database improves performance but requires trust in data storage
  - Accuracy vs. Latency: Fed-DP-CoT may take longer but provides better accuracy than Fed-SP-SC alone
  - Complexity vs. Benefit: The disclaimer in CoT prompts adds complexity but improves accuracy by 2%

- Failure signatures:
  - Low accuracy despite Fed-SP-SC: SP-questions may not be truly synonymous
  - Inconsistent answers from DP-questions: Pseudo-labels may be incorrect or reasoning structures differ
  - Privacy concerns: If database can be linked to individual users

- First 3 experiments:
  1. Test Fed-SP-SC accuracy on GSM8K with varying numbers of SP-questions (1-9)
  2. Compare Fed-DP-CoT accuracy with and without disclaimer in CoT prompts
  3. Measure privacy impact by attempting to link stored questions to user identities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of retrieved synonymous questions impact the effectiveness of Fed-SP-SC and Fed-DP-CoT methods?
- Basis in paper: [explicit] The paper states "The quality of the synonymous questions can affect the accuracy significantly, as seen in the larger improvement from the synonymous questions generated by GPT-3.5 compared to GPT-3."
- Why unresolved: The paper only compares performance of GPT-3 and GPT-3.5 for generating synonymous questions, but doesn't investigate impact of other factors such as number of retrieved questions or diversity of parameters in DP-questions.
- What evidence would resolve it: Systematic experiments varying quality, quantity, and diversity of retrieved synonymous questions to measure impact on Fed-SP-SC and Fed-DP-CoT performance.

### Open Question 2
- Question: How does the choice of sampled reasoning paths affect the performance of Fed-SP-SC and Fed-DP-CoT methods?
- Basis in paper: [explicit] The paper mentions "We study the effect of using different number of sampled reasoning paths for Fed-SP-SC (Sec. 4.2) to apply self-consistency."
- Why unresolved: The paper only provides preliminary analysis of effect of varying number of reasoning paths, but doesn't investigate impact of other factors such as diversity of reasoning paths or order in which they are sampled.
- What evidence would resolve it: Systematic experiments varying diversity, order, and number of reasoning paths to measure impact on Fed-SP-SC and Fed-DP-CoT performance.

### Open Question 3
- Question: How can the federated question-answering system be extended to handle more complex reasoning tasks beyond arithmetic and common sense questions?
- Basis in paper: [inferred] The paper focuses on arithmetic and common sense reasoning tasks, but doesn't discuss how proposed methods can be extended to handle other types of reasoning tasks such as symbolic reasoning or natural language inference.
- Why unresolved: The paper doesn't provide any insights into how federated question-answering system can be adapted to handle more complex reasoning tasks.
- What evidence would resolve it: Demonstrations of federated question-answering system successfully applied to variety of reasoning tasks beyond arithmetic and common sense questions.

## Limitations
- Database dependency creates single point of failure and requires sufficient question diversity for consistent performance
- Parameterization assumptions may not hold for domains where parameter changes fundamentally alter problem-solving approaches
- Model dependence on OpenAI's text-davinci models limits generalizability to other LLM architectures

## Confidence
- **High Confidence**: Self-consistency mechanism in Fed-SP-SC is well-established and 14-18% improvement is supported by direct experimental comparison
- **Medium Confidence**: Fed-DP-CoT's CoT effectiveness shows promise with 10-15% improvement, but disclaimer's 2% contribution suggests sensitivity to prompt engineering
- **Low Confidence**: Privacy preservation claim lacks threat modeling and centralized database creates security vulnerabilities

## Next Checks
1. **Database Coverage Analysis**: Measure Fed-SP-SC and Fed-DP-CoT accuracy as function of database size and question diversity to determine minimum coverage thresholds required for consistent performance across different domains

2. **Cross-Model Generalization**: Reproduce experiments using multiple LLM providers (Anthropic, Google, open-source models) to assess whether accuracy improvements transfer across different model architectures and reasoning capabilities

3. **Privacy Threat Assessment**: Conduct controlled experiments attempting to infer user identities from stored question-answer pairs and test database anonymization techniques to evaluate re-identification success rates under different attack scenarios