---
ver: rpa2
title: Explaining How a Neural Network Play the Go Game and Let People Learn
arxiv_id: '2310.09838'
source_url: https://arxiv.org/abs/2310.09838
tags:
- interactions
- interaction
- stones
- network
- game
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of explaining how neural networks
  encode knowledge for the game of Go, specifically aiming to teach human players
  novel strategies learned by AI. The authors propose a method to extract interaction
  primitives between stones encoded by the value network.
---

# Explaining How a Neural Network Play the Go Game and Let People Learn

## Quick Facts
- arXiv ID: 2310.09838
- Source URL: https://arxiv.org/abs/2310.09838
- Reference count: 23
- Primary result: Method extracts sparse interaction primitives from Go-playing neural network, enabling human players to learn novel strategies

## Executive Summary
This paper addresses the challenge of explaining how neural networks encode knowledge for the game of Go by extracting interaction primitives between stones. The authors propose an extension to the original Harsanyi dividend formulation by including both AND and OR relationships, solving the saturation problem of advantage scores, and computing attributions of common coalitions shared by different interactions. Experiments with KataGo demonstrate that the extracted interactions are sparse, with only a small number having significant effects, and that the method produces interpretable shape patterns that both confirm known Go knowledge and reveal novel insights.

## Method Summary
The method extracts interaction primitives from KataGo's value network by computing AND and OR interactions between stones on the Go board. It generates board states through self-play, selects subsets of 10 stones per state, and computes all possible masked variants to extract interaction effects. The approach extends the original interaction formulation to include OR relationships alongside AND relationships, addresses the saturation problem through bias adjustment, and computes coalition attributions using a Shapley-based method to identify common shape patterns. The disentangled advantage terms (v_and and v_or) are learned via L1 regularization to enforce sparsity.

## Key Results
- Extracted interactions are sparse, with only a small number having significant effects on network output
- The revised method reduces complexity by alleviating the saturation problem and minimizing high-order interactions
- Human Go players interpret extracted shape patterns, finding both familiar and novel strategic insights
- Approximation accuracy of network outputs using extracted interactions validates the method's effectiveness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Interaction sparsity allows the value network to be explained using only a small number of shape patterns.
- Mechanism: The method identifies that only a few interactions (AND/OR relationships between stones) have significant effects on the network output, while most interactions are negligible. This sparsity enables compact representation of the network's inference logic.
- Core assumption: The neural network has learned to encode sparse interactions during training, following patterns observed in well-trained DNNs.
- Evidence anchors:
  - [abstract] "Experiments show the effectiveness of our method" and "the extracted interactions are sparse, with only a small number having significant effects"
  - [section 3.2] "a well-trained DNN usually only encodes a small number of interactions in some common conditions"
  - [corpus] Weak evidence - only 5 of 8 neighbor papers are directly related to game-playing AI
- Break condition: If the network is poorly trained or the game complexity exceeds the model's capacity, interactions may no longer be sparse, making explanation intractable.

### Mechanism 2
- Claim: Extending AND interactions to OR interactions captures more complex game logic.
- Mechanism: By adding OR interactions alongside AND interactions, the method can represent scenarios where the presence of any stone in a set (rather than all stones) affects the value. This dual representation better matches the complex strategic considerations in Go.
- Core assumption: The value network encodes both conjunctive (AND) and disjunctive (OR) relationships between stones.
- Evidence anchors:
  - [section 3.2] "we extend AND interactions in Equation (1) to OR interactions" and the mathematical formulation
  - [section 3.2] "we consider the advantage score... intrinsically contains the following two terms"
  - [corpus] No direct evidence from neighbor papers
- Break condition: If the value network primarily uses one type of relationship (only AND or only OR), extending to both may introduce unnecessary complexity without improving explanation quality.

### Mechanism 3
- Claim: Computing coalition attributions reveals common shape patterns across different game states.
- Mechanism: By identifying coalitions (combinations of stones appearing in multiple interactions) and computing their attributions, the method extracts reusable shape patterns that are not tied to specific board positions. This enables transfer of knowledge across different game contexts.
- Core assumption: Common shape patterns exist that are reused across different game states, and these can be identified by finding stone combinations appearing in multiple interactions.
- Evidence anchors:
  - [section 3.3] "we identify some specific combinations of stones that frequently appear in different interaction primitives. We refer to these combinations as 'common coalitions'"
  - [section 3.3] "we further compute the attribution φ(T) of each coalition T to the advantage score"
  - [corpus] Weak evidence - neighbor papers focus on different aspects of game AI
- Break condition: If interactions are too specific to individual game states without common coalitions, the method cannot extract transferable patterns.

## Foundational Learning

- Concept: Harsanyi dividend/interaction
  - Why needed here: Provides the mathematical foundation for quantifying how combinations of stones affect the network's output, enabling interpretable explanations
  - Quick check question: What property ensures that the sum of all interaction effects equals the total network output?

- Concept: Shapley value attribution
  - Why needed here: Offers a principled way to distribute credit among stones in a coalition, helping to quantify the contribution of each stone to the overall advantage
  - Quick check question: How does the Shapley value differ from simple marginal contribution in cooperative game theory?

- Concept: Sparse representation in deep networks
  - Why needed here: Understanding why neural networks tend to learn sparse representations helps justify why only a small number of interactions are significant
  - Quick check question: What are common conditions under which neural networks learn sparse representations?

## Architecture Onboarding

- Component map:
  - Value network (KataGo) -> Interaction extraction module -> Coalition identification -> Attribution computation -> Human interpretation interface

- Critical path:
  1. Generate board states using KataGo self-play
  2. Extract AND/OR interactions for selected stones
  3. Identify common coalitions across interactions
  4. Compute coalition attributions
  5. Present results to human experts for validation

- Design tradeoffs:
  - Computational cost vs. interaction granularity (limiting to 10 stones vs. full board)
  - Sparsity enforcement vs. approximation accuracy (threshold ξ for salient interactions)
  - AND/OR distinction vs. model complexity (whether to use both or just one type)

- Failure signatures:
  - High-order interactions dominate (indicates saturation problem not properly addressed)
  - No common coalitions found (suggests interactions are too specific to individual states)
  - Attribution values are uniformly distributed (indicates poor differentiation between important and unimportant coalitions)

- First 3 experiments:
  1. Verify interaction sparsity on a small board state with 10 stones by computing all 2^10 masked states
  2. Test coalition attribution by comparing results on two similar board states with shared patterns
  3. Validate human interpretability by having Go players rate the usefulness of extracted patterns on a 5-point scale

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design more efficient methods to extract common coalitions (shape patterns) from a large number of interaction primitives?
- Basis in paper: [inferred] The paper mentions that the number of interaction primitives is still too large to teach people, and a more efficient way is needed to discover novel shapes from these interaction primitives.
- Why unresolved: The paper does not provide a detailed solution or algorithm for efficiently extracting common coalitions from the large number of interaction primitives.
- What evidence would resolve it: A method or algorithm that can efficiently identify and extract common coalitions from a large set of interaction primitives, along with experimental results demonstrating its effectiveness.

### Open Question 2
- Question: How can we improve the interpretability of shape patterns that conflict with human understanding of the game of Go?
- Basis in paper: [explicit] The paper mentions that some shape patterns extracted from the value network conflict with human understanding, and provides examples of such cases.
- Why unresolved: The paper does not provide a solution or method to improve the interpretability of these conflicting shape patterns.
- What evidence would resolve it: A method or approach that can improve the interpretability of conflicting shape patterns, along with experimental results demonstrating its effectiveness in helping human players understand these patterns.

### Open Question 3
- Question: How can we develop a more accurate attribution method for coalitions in the context of the game of Go?
- Basis in paper: [explicit] The paper mentions that there is no widely accepted method to estimate the attribution of a coalition of input variables, and applies a specific method to define the attribution of a coalition.
- Why unresolved: The paper does not compare the effectiveness of the applied attribution method with other methods or propose improvements to the existing method.
- What evidence would resolve it: A comparison of different attribution methods for coalitions in the context of the game of Go, along with experimental results demonstrating the effectiveness of the proposed method or improvements.

## Limitations
- Sparsity assumption may not generalize to all neural network architectures or game domains beyond Go
- Effectiveness relies heavily on quality of KataGo's self-play data generation
- Human interpretability of extracted patterns is subjective and varies across players with different skill levels

## Confidence
- **High confidence**: The mathematical formulation for extracting AND/OR interactions and computing coalition attributions is sound
- **Medium confidence**: The sparsity property of neural network interactions is demonstrated but may be domain-specific
- **Low confidence**: The generalizability of the method to other games or neural network architectures

## Next Checks
1. Test the method on a different neural network architecture (e.g., a custom-trained smaller network) to verify sparsity assumptions hold across implementations
2. Conduct a larger-scale human study with Go players of varying ranks to assess the consistency of pattern interpretation
3. Apply the extraction method to board states from actual game records rather than self-play to test real-world applicability