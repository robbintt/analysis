---
ver: rpa2
title: Are Existing Out-Of-Distribution Techniques Suitable for Network Intrusion
  Detection?
arxiv_id: '2308.14376'
source_url: https://arxiv.org/abs/2308.14376
tags:
- detection
- detectors
- attacks
- traffic
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates whether existing Out-Of-Distribution (OOD)
  techniques can detect unknown intrusions in network traffic. The study explores
  if techniques like confidence-based, gradient-based, and distance-based methods,
  originally developed for other fields, can identify malicious traffic that does
  not match training patterns.
---

# Are Existing Out-Of-Distribution Techniques Suitable for Network Intrusion Detection?

## Quick Facts
- arXiv ID: 2308.14376
- Source URL: https://arxiv.org/abs/2308.14376
- Reference count: 40
- Key outcome: Simple combinations of OOD detectors can achieve nearly 100% true positive rates in identifying unknown malicious traffic in network intrusion detection.

## Executive Summary
This work investigates whether existing Out-Of-Distribution (OOD) techniques can effectively detect unknown intrusions in network traffic. The study explores confidence-based, gradient-based, and distance-based methods originally developed for other fields, evaluating their ability to identify malicious traffic that doesn't match training patterns. Experiments using synthetic datasets demonstrate that combining certain OOD detectors can achieve near-perfect detection rates for unknown attacks, while improved model embeddings from contrastive learning and multi-class training further enhance performance.

## Method Summary
The study trains FeedForward Neural Networks (FNNs) on network traffic datasets (IDS2017 and IDS2018) using both binary and multi-class settings, with and without Center-Loss for contrastive learning. Six OOD detectors (CONF, MCD, ODIN, MD, KNN, SIM) are evaluated on their ability to distinguish known from unknown attacks. The method involves preprocessing network traffic into NetFlows with 20 selected features, training models on specific scenarios, and testing detector performance on unknown attacks from different datasets.

## Key Results
- Simple combinations of certain OOD detectors (ENS1, ENS2) can identify almost 100% of malicious traffic
- Improved embeddings through Center-Loss and multi-class training enhance OOD detection performance
- Difficulty exists in integrating traffic from different datasets, limiting cross-dataset detection capabilities

## Why This Works (Mechanism)

### Mechanism 1
Gradient-based OOD detectors (ODIN, MD) identify unknown attacks through controlled perturbations that amplify the gap between ID and OOD softmax scores. These methods assume NetFlow features behave similarly to image pixels in gradient sensitivity. Evidence shows high TPR when combined with temperature scaling and perturbation. Break condition: If perturbations are too rigid or feature domains differ significantly from images, detection degrades.

### Mechanism 2
Contrastive Learning (Center-Loss) improves OOD detection by creating more discriminative embeddings. By minimizing distances between same-class embeddings and maximizing distances between different classes, embeddings become more clustered and separable. Evidence indicates better embeddings lead to more reliable distance-based OOD detection. Break condition: If class centers are poorly estimated or training data is noisy, contrastive learning may not improve embeddings.

### Mechanism 3
Multi-class training provides semantically richer embeddings than binary training, enhancing OOD detection. Multi-class supervision captures more nuanced distinctions between attack types, leading to embeddings that better represent the underlying data manifold. Evidence shows multi-class models achieve better detection performance. Break condition: If the number of classes is too large or imbalanced, multi-class training may degrade embedding quality.

## Foundational Learning

- **Concept: Out-of-Distribution (OOD) Detection**
  - Why needed here: To identify malicious traffic that does not match training patterns and avoid false negatives
  - Quick check question: What is the difference between OOD detection and anomaly detection in the context of network intrusion?

- **Concept: Contrastive Learning**
  - Why needed here: To improve the discriminative power of embeddings, which enhances OOD detection performance
  - Quick check question: How does Center-Loss differ from other contrastive learning methods like SimCLR or MoCo?

- **Concept: Gradient-based Perturbations**
  - Why needed here: To amplify the difference between ID and OOD samples for better detection by methods like ODIN and MD
  - Quick check question: Why might gradient-based perturbations be less effective on NetFlow features compared to image pixels?

## Architecture Onboarding

- **Component map**: FNN encoder → embeddings (2D) → classifier → softmax scores; OOD detectors operate on embeddings and/or softmax scores
- **Critical path**: Data preprocessing → model training (with/without Center-Loss) → OOD detector tuning → ensemble evaluation
- **Design tradeoffs**: Using 2D embeddings simplifies visualization but may limit model capacity; gradient-based methods may be less effective on unbounded NetFlow features
- **Failure signatures**: Low TPR on unknown attacks; high FPR on benign traffic; poor performance of gradient-based detectors on NetFlow data
- **First 3 experiments**:
  1. Train FNN on IDS2018 Scenario 1 with Center-Loss; evaluate CONF, MCD, KNN on unknown attacks from IDS2017
  2. Compare TPR of individual detectors on binary vs. multi-class models
  3. Evaluate ensemble performance (ENS1 vs. ENS2) on combined datasets

## Open Questions the Paper Calls Out

### Open Question 1
How effective are OOD techniques in detecting unknown attacks that are semantically similar to known attacks but use different protocols or variations in attack patterns? The paper tests whether shifted versions of known attacks can be detected as OOD, but doesn't analyze semantic similarity detection.

### Open Question 2
What is the impact of feature selection on the performance of OOD techniques in detecting unknown attacks? The paper describes a feature selection procedure but doesn't explore how different feature sets might affect OOD detection performance.

### Open Question 3
How can OOD techniques be integrated into existing NIDS to provide real-time detection of unknown attacks without significantly increasing false positives? The paper discusses the trade-off between detection rates and false positives but doesn't offer a solution for balancing these factors in real-time applications.

## Limitations
- Effectiveness of gradient-based OOD detectors on NetFlow features remains uncertain due to differences from image data
- Reliance on synthetic datasets limits generalizability to real-world network traffic with complex feature distributions
- Difficulty in integrating traffic from different datasets restricts cross-dataset detection capabilities

## Confidence

- **High Confidence**: The complementary nature of different OOD detectors and the overall effectiveness of simple detector combinations (ENS1, ENS2) achieving near-100% TPR
- **Medium Confidence**: The benefits of Center-Loss for creating more discriminative embeddings and the advantage of multi-class training for semantically richer representations
- **Low Confidence**: The robustness of gradient-based perturbation methods on NetFlow features and the assumption that these methods behave similarly to image pixels

## Next Checks

1. **Cross-dataset Validation**: Test the ensemble detectors (ENS1, ENS2) on real-world network traffic from different organizations to verify performance beyond synthetic datasets
2. **Gradient Sensitivity Analysis**: Conduct controlled experiments comparing perturbation effectiveness on NetFlow features versus image pixels to quantify the impact of unbounded feature domains
3. **Ablation Study on Class Balance**: Evaluate how varying class distributions in multi-class training affects embedding quality and subsequent OOD detection performance