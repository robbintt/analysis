---
ver: rpa2
title: Explaining, Analyzing, and Probing Representations of Self-Supervised Learning
  Models for Sensor-based Human Activity Recognition
arxiv_id: '2304.07304'
source_url: https://arxiv.org/abs/2304.07304
tags:
- activity
- supervised
- data
- representations
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper analyzes and compares feature representations learned
  by self-supervised learning (SSL) and supervised models for sensor-based human activity
  recognition. The authors implement two SSL frameworks, SimCLR and VICReg, and a
  supervised baseline, all using a Transformer-based encoder.
---

# Explaining, Analyzing, and Probing Representations of Self-Supervised Learning Models for Sensor-based Human Activity Recognition

## Quick Facts
- arXiv ID: 2304.07304
- Source URL: https://arxiv.org/abs/2304.07304
- Reference count: 40
- Primary result: SSL models show significantly greater robustness to input noise than supervised models in sensor-based HAR, but supervised models produce more subject-homogeneous features that better encode activity type properties.

## Executive Summary
This paper analyzes and compares feature representations learned by self-supervised learning (SSL) and supervised models for sensor-based human activity recognition. The authors implement SimCLR and VICReg SSL frameworks and a supervised baseline, all using a Transformer-based encoder. Through extensive experiments on MobiAct and UCI-HAR datasets, they demonstrate that SSL representations are significantly more robust to noise in unseen data compared to supervised models. However, supervised approaches produce features that are more homogeneous across subjects and better encode the nature of activities (periodic, stable, sporadic).

## Method Summary
The authors implement SimCLR and VICReg SSL frameworks and a supervised baseline, all using a Transformer-based encoder consisting of 3 CNN layers followed by positional encoding and 6 transformer layers. For SSL pre-training, they train the encoder for 200 epochs with contrastive or decorrelation objectives, then fine-tune for activity classification for 100 epochs. They analyze the learned representations using three families of explainability methods: occlusion experiments to test robustness to noise, Guided Grad-CAM for local and global saliency maps to highlight important input channels, and representation probing to assess subject heterogeneity and activity type encoding.

## Key Results
- SSL models show significantly greater robustness to input noise than supervised models, typically outperforming by at least 10% in occlusion experiments
- Supervised models produce features that are more homogeneous across subjects compared to SSL models
- Supervised models better encode information about the nature of activities (periodic, stable, sporadic) compared to SSL models

## Why This Works (Mechanism)

### Mechanism 1
SSL models learn more robust feature representations to input noise than supervised models in unseen data. During pre-training, SSL frameworks like SimCLR and VICReg use augmentations (jitter, scaling, rotation, etc.) that expose the encoder to diverse corrupted views of the same signal. This forces the model to learn representations invariant to noise and corruptions. Supervised models, trained only on clean labeled data, do not develop this noise resilience.

### Mechanism 2
Supervised models learn features that are more homogeneous across subjects compared to SSL models. Supervised training optimizes for activity classification directly, which requires the model to find features that generalize well across different subjects performing the same activity. This leads to more subject-invariant features. SSL pre-training, being task-agnostic, does not impose this constraint and may learn subject-specific cues.

### Mechanism 3
Supervised models better encode information about the nature of activities (periodic, stable, sporadic) compared to SSL models. The supervised loss directly optimizes for activity classification, which requires the model to learn discriminative features that capture the inherent characteristics of each activity type. SSL pre-training, focused on instance-level discrimination, does not explicitly encourage learning these higher-level activity properties.

## Foundational Learning

- Concept: Self-Supervised Learning (SSL) in HAR
  - Why needed here: The paper compares SSL and supervised models for HAR, so understanding how SSL works in this domain is crucial.
  - Quick check question: What are the two main stages of SSL training in HAR, and what is the purpose of each stage?

- Concept: Explainability Methods (Occlusion, Saliency, Probing)
  - Why needed here: The paper uses three families of explainability methods to analyze and compare the representations learned by SSL and supervised models. Understanding these methods is key to interpreting the results.
  - Quick check question: How does occlusion analysis differ from saliency analysis in terms of what it reveals about a model's behavior?

- Concept: Sensor-Based HAR Data Characteristics
  - Why needed here: The paper analyzes representations on two single-device HAR datasets (MobiAct and UCI-HAR). Understanding the data characteristics (e.g., multi-channel IMU signals, activity types) is important for interpreting the results.
  - Quick check question: What are the typical input dimensions and activity categories in sensor-based HAR datasets like MobiAct and UCI-HAR?

## Architecture Onboarding

- Component map: IMU signals -> CNN feature extractor -> Positional encoding -> Transformer layers -> SSL objectives / Classification head

- Critical path: 1. Pre-train encoder using SSL or supervised training 2. Extract features from pre-trained encoder 3. Apply occlusion, saliency, and probing analyses to compare representations

- Design tradeoffs:
  - SSL vs. Supervised: SSL requires more compute for pre-training but can learn from unlabeled data; supervised is simpler but needs labeled data
  - Augmentation strategy: The choice and diversity of augmentations can impact SSL model robustness
  - Encoder architecture: Deeper transformers may capture more complex patterns but are harder to train and interpret

- Failure signatures:
  - SSL models underperform supervised models: May indicate insufficient pre-training data or ineffective augmentations
  - Occlusion analysis shows large performance drops: May indicate over-reliance on specific input channels
  - Probing analysis shows poor subject/activity type encoding: May indicate the model is not learning the desired representation properties

- First 3 experiments:
  1. Replicate occlusion experiments to compare SSL and supervised model robustness to input noise
  2. Generate and analyze Guided Grad-CAM saliency maps to understand channel importance for different activities
  3. Conduct representation probing to assess subject heterogeneity and activity type encoding in learned features

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do SimCLR and VICReg compare in terms of robustness to input corruption in real-world scenarios with partially corrupted test data?
- Basis in paper: [explicit] The paper discusses occlusion experiments comparing robustness of SimCLR and VICReg to corrupted data, showing SSL models are more robust.
- Why unresolved: The paper does not provide a direct comparison between SimCLR and VICReg under the same corruption scenarios, only showing they both outperform supervised models.
- What evidence would resolve it: Conducting experiments that directly compare SimCLR and VICReg under identical corruption scenarios, measuring their performance degradation.

### Open Question 2
- Question: Do the saliency maps generated by Guided Grad-CAM accurately reflect the true importance of input channels in model predictions?
- Basis in paper: [inferred] The paper uses Guided Grad-CAM to generate saliency maps but acknowledges ongoing discussion about the method's sensitivity to the underlying model.
- Why unresolved: There is no clear link between occlusion experiment observations and saliency map results, and the validity of Guided Grad-CAM is questioned in the literature.
- What evidence would resolve it: Comparing Guided Grad-CAM results with other saliency methods like DeepLIFT or Integrated Gradients, and validating against ground truth channel importance.

### Open Question 3
- Question: How do supervised and SSL representations differ in encoding semantic properties of activities, beyond just subject heterogeneity and activity type?
- Basis in paper: [explicit] The paper probes representations for subject heterogeneity and activity type but notes the need for more diverse activity groups in future work.
- Why unresolved: The current probing tasks use only three generic activity groups, limiting the scope of semantic properties analyzed.
- What evidence would resolve it: Conducting probing experiments on datasets with a larger number of diverse activities separated into more specific groups, analyzing additional semantic properties.

## Limitations

- Limited external validation: Minimal related work specifically addressing SSL representation analysis in sensor-based HAR, raising questions about generalizability beyond the two studied datasets
- Augmentation strategy dependence: SSL robustness advantage heavily depends on augmentations realistically reflecting real-world noise patterns
- Subject heterogeneity interpretation: Unclear whether higher subject heterogeneity scores represent a fundamental limitation or simply different learning objectives

## Confidence

- **High confidence**: SSL robustness to input noise (well-supported by occlusion experiments showing 10%+ performance gaps)
- **Medium confidence**: Supervised models' superior subject homogeneity and activity type encoding (probing results are consistent but limited to two datasets)
- **Low confidence**: Generalizability of findings across diverse HAR datasets and real-world deployment scenarios (limited corpus support and single-device focus)

## Next Checks

1. **Augmentation realism validation**: Conduct a systematic analysis comparing the distributions of pre-training augmentations versus actual noise patterns observed in real-world HAR deployments to validate the realism assumption.

2. **Cross-dataset generalization test**: Evaluate the SSL and supervised models on additional multi-device HAR datasets (e.g., PAMAP2, Opportunity) to assess whether the observed representation differences persist across different sensing modalities and collection protocols.

3. **Subject transfer learning experiment**: Design a transfer learning setup where models trained on one subject subset are evaluated on unseen subjects to directly measure subject-invariant learning capabilities beyond the probing analysis.