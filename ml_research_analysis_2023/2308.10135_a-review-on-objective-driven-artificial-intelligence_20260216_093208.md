---
ver: rpa2
title: A Review on Objective-Driven Artificial Intelligence
arxiv_id: '2308.10135'
source_url: https://arxiv.org/abs/2308.10135
tags:
- learning
- information
- intelligence
- these
- representation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper reviews objective-driven artificial intelligence, identifying
  limitations in current AI methods like supervised learning, reinforcement learning,
  and generative models, and proposes Hierarchical planning-based approaches to close
  the gap between human and machine intelligence. The core method involves energy-based
  models (EBM) and Joint embedding predictive architecture (JEPA), which predict latent
  representations rather than raw outputs, allowing the model to prune irrelevant
  information.
---

# A Review on Objective-Driven Artificial Intelligence

## Quick Facts
- arXiv ID: 2308.10135
- Source URL: https://arxiv.org/abs/2308.10135
- Reference count: 13
- Primary result: Proposes Hierarchical planning-based approaches using energy-based models (EBM) and Joint embedding predictive architecture (JEPA) to close the gap between human and machine intelligence

## Executive Summary
This paper reviews objective-driven artificial intelligence approaches that aim to bridge the gap between human and machine intelligence. The authors identify limitations in current AI methods including supervised learning, reinforcement learning, and generative models, proposing hierarchical planning-based architectures as a solution. The core approach involves energy-based models and Joint embedding predictive architecture (JEPA) that predict latent representations rather than raw outputs, enabling the model to prune irrelevant information. Hierarchical planning extends JEPA by stacking layers to handle both short-term and long-term predictions, mimicking human cognitive processes that abstract information at different levels.

## Method Summary
The proposed method centers on Hierarchical planning-based approaches using energy-based models (EBM) and Joint embedding predictive architecture (JEPA). JEPA predicts latent representations rather than raw outputs, allowing the model to naturally discard irrelevant information. The architecture encodes inputs x and y into representations Sx and Sy, then uses a predictor to forecast Sy from Sx (and optional latent variable z). Hierarchical planning extends this by stacking multiple JEPA layers, where lower layers handle detailed short-term predictions while higher layers manage abstract long-term planning. The approach aims to enable AI systems to learn from self-supervised tasks, abstract away non-essential details, and reason at multiple levels of abstraction.

## Key Results
- Energy-based models enable learning compatibility between inputs without relying on negative samples
- Joint embedding predictive architecture (JEPA) allows models to prune irrelevant information by predicting latent representations
- Hierarchical planning extends JEPA by stacking layers to handle both short-term and long-term predictions
- The approach aims to enable more generalizable, efficient, and human-like AI systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Energy-Based Models (EBMs) enable learning compatibility between inputs without relying on negative samples, addressing the inefficiency of contrastive learning in high-dimensional spaces.
- Mechanism: EBMs compute an energy scalar that represents compatibility between two inputs (x and y). By minimizing energy for compatible pairs and regularizing the volume of low-energy regions, the model learns meaningful representations without requiring explicit negative sampling.
- Core assumption: The energy landscape can be shaped such that compatible inputs naturally have low energy while incompatible ones have high energy, without needing exhaustive negative sampling.
- Break condition: If the energy landscape cannot effectively separate compatible from incompatible pairs, or if regularization fails to prevent model collapse.

### Mechanism 2
- Claim: Joint Embedding Predictive Architecture (JEPA) predicts latent representations rather than raw outputs, allowing the model to prune irrelevant information and focus on objective-driven predictions.
- Mechanism: JEPA encodes inputs x and y into representations Sx and Sy, then uses a predictor to forecast Sy from Sx (and optional latent variable z). By predicting representations instead of raw data, the model naturally discards irrelevant details.
- Core assumption: The latent representation contains sufficient information for the prediction task while excluding non-essential details.
- Break condition: If the latent representation cannot capture all necessary information for accurate predictions, or if the predictor fails to generalize.

### Mechanism 3
- Claim: Hierarchical planning extends JEPA by stacking layers to handle both short-term and long-term predictions, mimicking human cognitive processes that abstract information at different levels.
- Mechanism: Multiple JEPA layers are stacked, where each layer further abstracts the input representation. Lower layers handle detailed short-term predictions while higher layers manage abstract long-term planning.
- Core assumption: Information can be progressively abstracted through hierarchical layers while maintaining predictive capability.
- Break condition: If abstraction through layers causes loss of critical information needed for accurate predictions at any level.

## Foundational Learning

- Concept: Self-supervised learning
  - Why needed here: Forms the foundation for learning representations without labeled data, which is essential for building world models that can generalize like humans.
  - Quick check question: How does masked language modeling in BERT help the model learn bidirectional context?

- Concept: Energy-based modeling
  - Why needed here: Provides a framework for learning compatibility between inputs without requiring negative samples, addressing computational inefficiencies in contrastive methods.
  - Quick check question: What is the role of regularization in preventing model collapse in energy-based models?

- Concept: Latent variable modeling
  - Why needed here: Allows the model to capture information not present in the inputs themselves, enabling more complete world representations.
  - Quick check question: How does the latent variable z complement Sx in predicting Sy in JEPA?

## Architecture Onboarding

- Component map: Input encoders (Enc(x), Enc(y)) -> Predictor network -> Energy function -> Regularization terms -> Hierarchical layers
- Critical path: Input → Encoder → Predictor → Output representation → Loss computation → Parameter update
- Design tradeoffs:
  - Depth vs. abstraction quality: More hierarchical layers provide better abstraction but may lose critical information
  - Regularization strength: Stronger regularization prevents collapse but may restrict learning capacity
  - Latent variable size: Larger z captures more information but increases complexity and risk of collapse
- Failure signatures:
  - Model collapse: Predictor ignores x and y, relying solely on z
  - Information loss: Representations become too abstract to make accurate predictions
  - Training instability: Energy landscape becomes flat or highly irregular
- First 3 experiments:
  1. Implement single-layer JEPA on a simple prediction task (e.g., next frame prediction in a controlled video dataset) to verify basic functionality
  2. Add latent variable to the JEPA and test different regularization strengths to find optimal balance
  3. Stack two JEPA layers and test on a task requiring both short-term and long-term predictions (e.g., autonomous driving scenario with immediate and future state prediction)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we design non-contrastive, latent-variable energy-based models that successfully produce good representations of image, video, speech, and other signals without falling into the curse of dimensionality?
- Basis in paper: [explicit] "The challenge of the next few years may be to devise non-contrastive methods for a latent-variable energy-based model that successfully produce good representations of image, video, speech, and other signals and yield top performance in downstream supervised tasks without requiring large amounts of labeled data."
- Why unresolved: Current contrastive methods, while effective, are computationally inefficient in high-dimensional spaces like images and videos. The challenge is to find an alternative approach that avoids the need for negative samples and can scale to complex data types.
- What evidence would resolve it: Development and demonstration of a non-contrastive, latent-variable EBM that achieves state-of-the-art performance on downstream tasks (e.g., image classification, video prediction) using only self-supervised pre-training, with significantly reduced computational costs compared to contrastive methods.

### Open Question 2
- Question: What are the optimal architectural designs for Hierarchical JEPA models to achieve effective long-term predictions in complex, dynamic environments?
- Basis in paper: [inferred] The paper discusses Hierarchical planning as an extension of JEPA, but notes that "There hasn't been much work around this topic yet, but it seems a very reasonable candidate to reason and plan a more complex task than a simple word prediction/ image classification."
- Why unresolved: While the concept of Hierarchical JEPA is promising, the paper does not provide specific architectural details or empirical results. The optimal number of layers, the nature of the latent variables at each level, and the training procedures for such models remain open questions.
- What evidence would resolve it: A comprehensive study comparing different Hierarchical JEPA architectures on a benchmark long-term prediction task (e.g., autonomous driving, robotics control), showing improved performance and sample efficiency compared to non-hierarchical approaches.

### Open Question 3
- Question: How can we effectively measure and compare the "common sense" capabilities of AI models against human intelligence?
- Basis in paper: [inferred] The paper highlights the gap between machine and human intelligence, particularly in common sense reasoning, but does not provide a concrete framework for evaluating this aspect.
- Why unresolved: While the paper discusses the importance of common sense for AI, it does not propose a standardized way to quantify or compare common sense understanding between AI models and humans. This makes it difficult to track progress in this area.
- What evidence would resolve it: Development of a benchmark suite specifically designed to test common sense reasoning in AI models, covering a wide range of scenarios and including comparisons with human performance. This benchmark should be able to differentiate between models with and without genuine common sense understanding.

## Limitations
- No empirical validation or performance metrics provided for any proposed mechanisms
- Architecture details, hyperparameters, and training procedures remain unspecified
- No comparative analysis against existing methods like contrastive learning or traditional planning approaches
- The hierarchical stacking approach lacks mathematical formulation and proof of effectiveness

## Confidence
- High confidence: Basic concepts of EBMs, JEPA, and hierarchical planning are correctly described; the theoretical framework for avoiding contrastive learning's limitations is sound; the general approach of predicting latent representations rather than raw outputs is valid
- Medium confidence: The proposed hierarchical extension of JEPA could theoretically enable multi-level abstraction; energy-based regularization can prevent model collapse in principle; the pruning of irrelevant information through representation prediction is plausible
- Low confidence: Claims about achieving human-like reasoning and generalization without empirical evidence; specific performance advantages over existing methods remain unproven; the practical effectiveness of the hierarchical planning approach is unverified

## Next Checks
1. Implement single-layer JEPA baseline: Create a minimal JEPA implementation on a controlled prediction task (e.g., next frame prediction on Moving MNIST) to verify that representation prediction works as intended and that irrelevant information is pruned compared to pixel-level prediction

2. Test EBM negative sample efficiency: Compare EBM-based representation learning against contrastive methods on a high-dimensional dataset to empirically measure the claimed efficiency gains in avoiding negative sampling

3. Validate hierarchical abstraction: Stack two JEPA layers and test on a task requiring both short-term and long-term predictions (e.g., autonomous driving scenario) to verify that hierarchical abstraction improves performance over single-layer approaches while maintaining critical information across abstraction levels