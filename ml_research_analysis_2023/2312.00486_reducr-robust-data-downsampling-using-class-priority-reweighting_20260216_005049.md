---
ver: rpa2
title: 'REDUCR: Robust Data Downsampling Using Class Priority Reweighting'
arxiv_id: '2312.00486'
source_url: https://arxiv.org/abs/2312.00486
tags:
- loss
- class
- training
- reducr
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: REDUCR introduces a robust online batch selection method that improves
  worst-class generalization performance on imbalanced datasets. The method uses class
  priority reweighting to assign higher importance to underrepresented classes during
  training.
---

# REDUCR: Robust Data Downsampling Using Class Priority Reweighting

## Quick Facts
- arXiv ID: 2312.00486
- Source URL: https://arxiv.org/abs/2312.00486
- Reference count: 40
- Primary result: Improves worst-class test accuracy by ~15% on imbalanced web-scraped datasets compared to state-of-the-art methods

## Executive Summary
REDUCR introduces a robust online batch selection method that improves worst-class generalization performance on imbalanced datasets. The method uses class priority reweighting to assign higher importance to underrepresented classes during training. By leveraging amortised class-irreducible loss models and weighted selection scores, REDUCR selects datapoints that most benefit the worst-performing classes. On web-scraped datasets with imbalanced class distributions, REDUCR significantly improves worst-class test accuracy while maintaining strong average accuracy.

## Method Summary
REDUCR is a robust online batch selection algorithm that uses class priority reweighting to improve worst-class generalization performance on imbalanced datasets. The method pre-trains C amortised class-irreducible loss models upfront, then at each training timestep computes selection scores for datapoints based on model loss, class-irreducible loss, and class-holdout loss. Using multiplicative weights update (MWU), REDUCR adjusts class weights multiplicatively based on how poorly each class performs on the holdout set, biasing selection toward datapoints from underrepresented classes. The selection score balances model loss improvement with class-irreducible and class-holdout losses to prioritize learnable, underrepresented datapoints.

## Key Results
- Improves worst-class test accuracy by around 15% compared to state-of-the-art methods on imbalanced web-scraped datasets
- Maintains strong average accuracy while significantly improving worst-class performance
- Effective across multiple datasets including CIFAR10, CINIC10, Clothing1M, MNLI, and QQP

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Class priority reweighting improves worst-class generalization by increasing the probability mass on underrepresented classes during batch selection.
- Mechanism: REDUCR uses multiplicative weights update (similar to MWU/EXP3) where class weights are adjusted multiplicatively based on how poorly each class performs on the holdout set. Underperforming classes receive higher weights, biasing selection toward datapoints that improve their performance.
- Core assumption: The performance gap between classes is measurable via holdout loss and can be reduced by prioritizing datapoints from poorly performing classes.
- Evidence anchors:
  - [abstract]: "REDUCR assigns priority weights to datapoints in a class-aware manner using an online learning algorithm."
  - [section 4.1]: "class-weights are updated multiplicatively according to how well they perform given the selected batch (they increase for poorly performing classes and decrease otherwise)."
  - [corpus]: Weak - neighbors focus on fairness/robustness but not this specific reweighting mechanism.
- Break condition: If the holdout set does not reflect test-time distribution or if class performance gaps are due to irreducible noise rather than lack of data.

### Mechanism 2
- Claim: Amortized class-irreducible loss models enable efficient selection by precomputing class-specific difficulty estimates.
- Mechanism: Instead of retraining a separate model for each class at every timestep, REDUCR trains C amortised class-irreducible loss models upfront using weighted loss functions that upweight examples from the target class. These models approximate how much additional data from a class could reduce irreducible loss.
- Core assumption: The class-irreducible loss can be approximated offline without significant loss of selection quality.
- Evidence anchors:
  - [section 4.3]: "We propose to approximate these models using amortised class-irreducible loss models, which are trained for each class at the beginning of REDUCR and do not need to be updated at future timesteps."
  - [section 4.2]: Explains that this approximation is "far more tractable than naively re-training a new model."
  - [corpus]: Weak - no direct mention of amortised class-irreducible loss models in neighbors.
- Break condition: If the pre-trained class-irreducible models become outdated due to significant distribution shift during training.

### Mechanism 3
- Claim: The selection score balances model loss improvement with class-irreducible and class-holdout losses to prioritize learnable, underrepresented datapoints.
- Mechanism: REDUCR's selection score is computed as: model loss - class-irreducible loss - class-holdout loss. The class-holdout loss term (averaged over class) ensures that classes with poor generalization are weighted more heavily, while the excess loss (model loss - class-irreducible loss) identifies datapoints with the most potential for improvement.
- Core assumption: The difference between current model loss and irreducible loss (excess loss) is a good proxy for learnability.
- Evidence anchors:
  - [section 4.2]: "Intuitively, if two datapoints are from different classes, REDUCR will take into account the weight of the worst-performing class, which is reflected by the class-holdout loss."
  - [section 4.4]: "REDUCR addresses both of these issues by identifying underrepresented classes and using the class-irreducible loss model to help to determine which points from these classes should be selected."
  - [corpus]: Weak - neighbors focus on robustness/fairness but not this specific score decomposition.
- Break condition: If the class-holdout loss becomes unstable or if clipping of excess loss removes too much signal.

## Foundational Learning

- Concept: Multiplicative Weights Update (MWU) / Exponential Weights Algorithm
  - Why needed here: REDUCR uses MWU to adjust class weights based on performance, ensuring that underrepresented classes get more attention over time.
  - Quick check question: If a class has high holdout loss, should its weight increase or decrease in the next iteration?

- Concept: Amortized Model Training
  - Why needed here: REDUCR pre-trains C class-irreducible loss models to avoid expensive per-timestep retraining, making the method computationally feasible.
  - Quick check question: Why is it better to train the class-irreducible models once upfront rather than updating them at every timestep?

- Concept: Excess Loss as Learnability Signal
  - Why needed here: The difference between model loss and class-irreducible loss indicates how much a datapoint can still be improved, guiding selection toward the most informative examples.
  - Quick check question: If two datapoints have the same model loss, but different class-irreducible losses, which one should REDUCR prefer?

## Architecture Onboarding

- Component map:
  - Class weights vector (w ∈ Δ^C) -> Target model (θ_t) -> C amortised class-irreducible loss models (ϕ_c) -> Holdout dataset (D_ho) -> Selection score calculator

- Critical path:
  1. Initialize class weights uniformly
  2. Pre-train C amortised class-irreducible loss models
  3. At each timestep:
     a. Compute selection scores for all points in batch B_t
     b. Select top-k points based on weighted sum of scores
     c. Update target model with selected batch
     d. Update class weights using class-holdout losses

- Design tradeoffs:
  - Pre-training amortised models vs. per-timestep retraining: computational efficiency vs. adaptability to distribution shift
  - Clipping excess loss: stability vs. potential loss of information
  - Class-holdout loss frequency: accuracy vs. computational cost

- Failure signatures:
  - Weights concentrate on one class too quickly → learning rate η too high
  - Poor worst-class performance despite high average → class-irreducible models not capturing true irreducible loss
  - High variance in results → clipping threshold inappropriate or batch size too small

- First 3 experiments:
  1. Run REDUCR on balanced CIFAR10 to verify it maintains performance while selecting diverse batches
  2. Test sensitivity to learning rate η by running with η ∈ {1e-5, 1e-4, 1e-3} on CIFAR10
  3. Verify amortised class-irreducible models by comparing selection scores with and without them on a small dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does REDUCR's performance scale with increasingly large class imbalance ratios (e.g., 0.1%, 0.01%)?
- Basis in paper: [explicit] The paper notes that experiments with 0.25% and 0.5% percent imbalances on classes 3 and 5 resulted in too few datapoints of the imbalanced class seen during training to achieve good performance.
- Why unresolved: The paper does not explore extreme class imbalance ratios beyond 0.5%, leaving the question of REDUCR's effectiveness at very low class representation open.
- What evidence would resolve it: Conducting experiments with extreme class imbalance ratios (e.g., 0.1%, 0.01%) and comparing REDUCR's performance to baselines would provide insights into its scalability.

### Open Question 2
- Question: How does the performance of REDUCR compare to other robust data downsampling methods on datasets with no class imbalance?
- Basis in paper: [inferred] The paper focuses on the benefits of REDUCR in imbalanced datasets but does not explicitly compare its performance to other methods on balanced datasets.
- Why unresolved: The paper does not provide a direct comparison of REDUCR with other robust data downsampling methods on balanced datasets, leaving the question of its effectiveness in such scenarios open.
- What evidence would resolve it: Conducting experiments comparing REDUCR's performance to other robust data downsampling methods on balanced datasets would provide insights into its effectiveness in different data distribution scenarios.

### Open Question 3
- Question: How does the choice of the gradient weight γ in the class-irreducible loss model training affect REDUCR's performance on different datasets?
- Basis in paper: [explicit] The paper discusses the sensitivity of REDUCR to the gradient weight γ in Appendix A.9.2, showing that higher values of γ result in faster improvement early in training but lower final performance.
- Why unresolved: The paper only explores the sensitivity of REDUCR to γ on the CIFAR10 dataset, leaving the question of its impact on different datasets open.
- What evidence would resolve it: Conducting experiments with different values of γ on various datasets and analyzing the impact on REDUCR's performance would provide insights into the optimal choice of γ for different data distributions.

## Limitations
- The method's effectiveness may degrade if the holdout set distribution drifts significantly during training
- Pre-trained class-irreducible models may become outdated due to distribution shift, affecting selection quality
- The clipping of excess loss, while stabilizing, may discard useful information about datapoint difficulty

## Confidence
- Medium: The paper provides theoretical justification and empirical results, but the underlying assumptions about the reliability of holdout loss and the effectiveness of amortisation need more rigorous validation across diverse datasets and training regimes.

## Next Checks
1. Perform ablation studies on CIFAR10 with varying holdout set sizes to test sensitivity to distribution drift.
2. Compare selection quality with and without amortised class-irreducible models on a small, controlled dataset where the true irreducible loss is known.
3. Analyze the sensitivity of worst-class performance to the learning rate η and clipping threshold across multiple imbalanced variants of CIFAR10.