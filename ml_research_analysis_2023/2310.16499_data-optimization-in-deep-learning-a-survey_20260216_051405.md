---
ver: rpa2
title: 'Data Optimization in Deep Learning: A Survey'
arxiv_id: '2310.16499'
source_url: https://arxiv.org/abs/2310.16499
tags:
- data
- learning
- training
- optimization
- augmentation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper surveys a wide range of existing data optimization methodologies
  for deep learning tasks. A comprehensive taxonomy is constructed for these methodologies
  across eight dimensions, including ultimate goals, application scenarios, data objects,
  optimization pipeline, optimization techniques, and optimization theories.
---

# Data Optimization in Deep Learning: A Survey

## Quick Facts
- arXiv ID: 2310.16499
- Source URL: https://arxiv.org/abs/2310.16499
- Reference count: 40
- This paper surveys data optimization methodologies for deep learning with a comprehensive taxonomy across eight dimensions.

## Executive Summary
This survey provides a systematic overview of data optimization techniques in deep learning by constructing a comprehensive taxonomy across eight dimensions including ultimate goals, application scenarios, data objects, optimization pipeline, optimization techniques, and optimization theories. The paper builds connections among seemingly unrelated data optimization methods across four aspects and summarizes theoretical studies on data optimization. The work aims to promote understanding of existing methods and inspire novel data optimization approaches in deep learning.

## Method Summary
The paper conducts a systematic review of existing data optimization techniques in deep learning, constructing a comprehensive taxonomy with eight dimensions. The methodology involves categorizing optimization techniques based on their ultimate goals, application scenarios, data objects, optimization pipeline steps, optimization techniques, and theoretical foundations. The authors analyze connections among different methods through four aspects: data perception, application scenarios, similarity/opposition, and theoretical frameworks. The approach requires comprehensive literature coverage across multiple deep learning divisions and applications.

## Key Results
- Constructed a comprehensive taxonomy with eight dimensions for data optimization methodologies
- Built connections among seemingly unrelated data optimization methods across four aspects
- Summarized theoretical studies on existing data optimization techniques
- Identified several promising future research directions in data optimization

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data perception as the first pipeline step improves optimization by providing targeted quantification of training data characteristics.
- Mechanism: The paper constructs a multi-dimensional taxonomy for data perception (sample-wise, category-wise, corpus-wise) and multiple types (distribution, cleanliness, difficulty, diversity, balance, consistency, neighborhood, valuation). This structured perception enables downstream optimization techniques to be precisely targeted.
- Core assumption: Accurate quantification of data characteristics at multiple granularities leads to more effective optimization strategies.
- Evidence anchors:
  - [abstract] "The constructed taxonomy considers the diversity of split dimensions, and deep sub-taxonomies are constructed for each dimension."
  - [section] "We construct a sub-taxonomy for data perception in three dimensions as shown in Fig. 7."
  - [corpus] Weak evidence - the corpus contains papers on data augmentation and deep learning but no direct citations about data perception taxonomies.

### Mechanism 2
- Claim: Theoretical formalization connects disparate optimization techniques through common mathematical frameworks.
- Mechanism: The paper presents formalization approaches (probabilistic, constrained optimization, regularization-based) that unify different optimization techniques under common theoretical frameworks, enabling cross-technique insights.
- Core assumption: Mathematical formalization reveals underlying similarities between seemingly unrelated optimization techniques.
- Evidence anchors:
  - [abstract] "Theoretical studies are summarized for the existing data optimization techniques."
  - [section] "It is essential to establish mathematical formulations... Statistical modeling is the primary tool for their formalization."
  - [corpus] Weak evidence - while the corpus contains surveys on deep learning and data augmentation, it lacks specific citations about theoretical formalization connecting optimization techniques.

### Mechanism 3
- Claim: Connections via application scenarios demonstrate the cross-domain applicability of data optimization techniques.
- Mechanism: The paper maps optimization techniques to specific application scenarios (noisy-label learning, imbalanced learning, robust learning, etc.), revealing how techniques from different domains address similar challenges.
- Core assumption: Different application scenarios face similar underlying data challenges that can be addressed by related optimization techniques.
- Evidence anchors:
  - [abstract] "The constructed taxonomy and the revealed connections will enlighten the better understanding of existing methods and the design of novel data optimization techniques."
  - [section] "One of the most focused scenarios of data optimization methods is noisy-label learning... Imbalanced learning is also among the most focused scenarios."
  - [corpus] Moderate evidence - the corpus includes papers on noisy-label learning and imbalanced learning, supporting the claim about cross-domain applicability.

## Foundational Learning

- Concept: Data-centric AI perspective
  - Why needed here: The paper shifts focus from model-centric to data-centric approaches, requiring understanding of data optimization as a distinct field.
  - Quick check question: What are the key differences between model-centric and data-centric approaches in deep learning?

- Concept: Taxonomy construction principles
  - Why needed here: The paper's effectiveness relies on well-designed taxonomy dimensions that capture the diversity of data optimization techniques.
  - Quick check question: What criteria should be used to design effective taxonomy dimensions for data optimization techniques?

- Concept: Theoretical formalization in machine learning
  - Why needed here: The paper uses mathematical formalizations to connect different optimization techniques and explain their effectiveness.
  - Quick check question: What are the common types of mathematical formalizations used in machine learning theory?

## Architecture Onboarding

- Component map:
  - Taxonomy construction (6 main dimensions with sub-taxonomies)
  - Data perception pipeline (3 granularity levels × 8 types × 2 variation modes)
  - Optimization techniques (6 main paths with multiple sub-divisions)
  - Theoretical formalization framework
  - Connection mapping (4 aspects: perception, scenarios, similarity/opposition, theory)

- Critical path:
  1. Construct taxonomy with appropriate dimensions
  2. Implement data perception with multiple granularity and type options
  3. Select and apply optimization techniques based on perceived characteristics
  4. Apply theoretical formalization to understand and connect techniques
  5. Map connections across techniques and scenarios

- Design tradeoffs:
  - Granularity vs. computational cost in data perception
  - Taxonomic breadth vs. depth in taxonomy construction
  - Theoretical rigor vs. practical applicability in formalization
  - Connection comprehensiveness vs. clarity in mapping

- Failure signatures:
  - Taxonomy dimensions don't capture important distinctions between techniques
  - Data perception produces quantities that don't correlate with learning performance
  - Theoretical formalizations fail to explain observed behavior
  - Connections between techniques are forced or superficial

- First 3 experiments:
  1. Implement a basic data perception system with sample-wise loss-based difficulty measurement and test correlation with learning performance
  2. Apply two different optimization techniques to the same dataset and compare effectiveness using the constructed taxonomy
  3. Create a simple theoretical formalization (e.g., probabilistic model) for a specific optimization technique and validate against empirical results

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the principles of data optimization across different technical paths?
- Basis in paper: [explicit] The paper states "There has been no consensus theoretical framework that is suitable for all or most technical paths" and calls for "the construction of the data optimization principles."
- Why unresolved: Different data optimization techniques have been developed independently for specific problems, and there is a lack of unified theoretical understanding connecting them.
- What evidence would resolve it: A comprehensive mathematical framework that can analyze and explain the effectiveness of different data optimization techniques across various learning tasks.

### Open Question 2
- Question: How can we develop interpretable data optimization methods that explain their effects on the training process?
- Basis in paper: [explicit] The paper identifies "Interpretable data optimization" as an under-explored research topic and states "the well explanation of how and which aspects of a data optimization method affects a specific training process is significant beneficial."
- Why unresolved: While interpretable deep learning has received attention, it focuses on models rather than the training process where data optimization is involved.
- What evidence would resolve it: Methodologies that can quantify and visualize the impact of data optimization techniques on model training dynamics and final performance.

### Open Question 3
- Question: How can we design a general data optimization agent that can select appropriate techniques across different technical paths?
- Basis in paper: [explicit] The paper proposes "A more general data optimization agent can be trained by iteratively training on a large number of deep learning tasks via reinforcement learning" and describes a potential framework.
- Why unresolved: Current automatic data optimization methods focus on particular types of technical paths rather than types across different technical paths.
- What evidence would resolve it: A reinforcement learning-based agent that can effectively choose and combine different data optimization techniques for various learning tasks.

## Limitations
- No reported empirical results or performance metrics demonstrating effectiveness
- Unclear methodology for literature selection and taxonomy validation
- Potential bias toward certain optimization techniques or application scenarios
- Missing analysis of computational overhead for data perception

## Confidence
- High confidence: Core claims about taxonomy construction and multi-dimensional data perception
- Medium confidence: Claims about theoretical formalization and cross-domain connections
- Low confidence: Claims about specific quantitative benefits of the proposed approach

## Next Checks
1. Conduct a gap analysis comparing the proposed taxonomy against existing data optimization surveys to identify unique contributions and potential omissions
2. Implement a prototype of the data perception pipeline on a benchmark dataset and measure correlation between perceived characteristics and actual learning performance
3. Apply the theoretical formalization framework to at least two different optimization techniques and verify whether it successfully explains their behavior and reveals meaningful connections