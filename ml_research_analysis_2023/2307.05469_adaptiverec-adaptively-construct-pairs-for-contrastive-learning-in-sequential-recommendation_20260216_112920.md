---
ver: rpa2
title: 'AdaptiveRec: Adaptively Construct Pairs for Contrastive Learning in Sequential
  Recommendation'
arxiv_id: '2307.05469'
source_url: https://arxiv.org/abs/2307.05469
tags:
- pairs
- learning
- contrastive
- recommendation
- negative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AdaptiveRec, a method to address false negatives
  in contrastive learning for sequential recommendation systems. By adaptively constructing
  pairs based on a learnable similarity threshold (SimThres), the model distinguishes
  true negative pairs from false ones during training.
---

# AdaptiveRec: Adaptively Construct Pairs for Contrastive Learning in Sequential Recommendation

## Quick Facts
- arXiv ID: 2307.05469
- Source URL: https://arxiv.org/abs/2307.05469
- Reference count: 9
- Key outcome: AdaptiveRec improves sequential recommendation performance by adaptively filtering false negatives in contrastive learning using a learnable similarity threshold.

## Executive Summary
AdaptiveRec introduces a method to improve contrastive learning in sequential recommendation by adaptively constructing pairs based on a learnable similarity threshold. The approach addresses the problem of false negatives—semantically similar items incorrectly labeled as dissimilar—by dynamically adjusting the threshold for each training batch. A submodel controls this threshold while statistical regularization prevents it from collapsing. Experiments on MovieLens-1M and Amazon Beauty datasets show consistent improvements in NDCG, MRR, and Recall compared to baselines, along with better embedding uniformity and alignment.

## Method Summary
AdaptiveRec enhances contrastive learning by using a learnable similarity threshold (SimThres) to filter negative pairs during training. A submodel outputs batch-specific thresholds for each sequence, which are used to exclude high-similarity pairs from the negative set. Statistical regularization anchors these thresholds to a global percentile to prevent collapse. The method is trained end-to-end with InfoNCE loss and augmented positives, and evaluated on sequential recommendation datasets using standard ranking metrics.

## Key Results
- AdaptiveRec consistently outperforms baselines like DuoRec on NDCG, MRR, and Recall across MovieLens-1M and Amazon Beauty datasets.
- The method achieves better uniformity and alignment in item embeddings compared to fixed-threshold approaches.
- Learnable SimThres shows more stable performance across different evaluation metrics than statistical SimThres.

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** AdaptiveRec distinguishes true negative pairs from false negatives by dynamically adjusting a similarity threshold.
- **Mechanism:** The method introduces a learnable similarity threshold (SimThres) that varies per batch, filtering out pairs with similarity above the threshold from the negative set. This threshold is controlled by a submodel and statistically regularized to prevent collapse.
- **Core assumption:** High similarity pairs in contrastive learning can be semantically similar and thus represent false negatives, not true negatives.
- **Evidence anchors:**
  - [abstract] "adaptive approach to contrastive learning... improves the quality of item embeddings and mitigates the problem of falsely categorizing similar instances as dissimilar."
  - [section 3.2.1] "We construct negative samples based on the similarity with other samples within the batch... considering only those with similarity below a certain threshold."
  - [corpus] Weak evidence: related works focus on augmentation strategies, not threshold-based filtering.
- **Break condition:** If the similarity threshold collapses (e.g., becomes -1), all pairs become positives and the model fails to learn meaningful negatives.

### Mechanism 2
- **Claim:** The regularization term prevents the SimThres from collapsing during training.
- **Mechanism:** A loss term Lreg = ||g({f(si)}B_i=1) - kstat||² is added, where kstat is the statistical percentile of similarity scores. This anchors the learnable threshold to a stable reference.
- **Core assumption:** Without regularization, the learnable threshold would converge to a degenerate value that eliminates all negatives.
- **Evidence anchors:**
  - [section 3.2.2] "To control the value of SimThres and avoid the collapsing phenomenon... we introduce a regularization term... Lreg = ||g({f(si)}B_i=1) - kstat||²."
  - [appendix A] "a simple solution to achieve this is to make M−(i) an empty set... making the model g output -1 becomes the easiest way to optimize Llearn loss."
- **Break condition:** If regularization weight λ is too low or the percentile kstat is poorly estimated, the threshold may still collapse.

### Mechanism 3
- **Claim:** Adaptive thresholding improves both uniformity and alignment of embeddings compared to fixed-threshold baselines.
- **Mechanism:** By filtering out false negatives, the model reduces semantic noise in negative pairs, allowing better separation of positive and negative representations. This improves uniformity (spread of embeddings) and alignment (closeness of positives).
- **Core assumption:** Reducing false negatives directly translates to better embedding quality metrics.
- **Evidence anchors:**
  - [section 4.3] "Our model consistently showed higher performances in all three settings compared to the baseline... Bigger values indicate better performance."
  - [section 4.4] "These high cosine similarity values correspond to semantically similar pairs but are falsely classified as negative pairs, resulting in false negatives."
  - [corpus] Weak evidence: related works focus on augmentation, not embedding quality improvements via threshold adaptation.
- **Break condition:** If the threshold adaptation is too aggressive, it may exclude true negatives, harming alignment.

## Foundational Learning

- **Concept:** Contrastive learning with InfoNCE loss
  - **Why needed here:** The method builds on InfoNCE to distinguish positive and negative pairs, but modifies the negative set selection.
  - **Quick check question:** What is the formula for InfoNCE loss and how does it use positive and negative pairs?

- **Concept:** Data sparsity in recommendation systems
  - **Why needed here:** The paper addresses how sparsity leads to false negatives, motivating the adaptive thresholding.
  - **Quick check question:** Why does data sparsity cause false negatives in contrastive learning for sequential recommendation?

- **Concept:** Statistical regularization in neural networks
  - **Why needed here:** The regularization term prevents the learnable threshold from collapsing to a degenerate value.
  - **Quick check question:** How does adding a regularization term like ||g(...) - kstat||² stabilize a learnable parameter?

## Architecture Onboarding

- **Component map:** Base model f -> Submodel g -> Similarity threshold SimThres -> Filtered negatives M−(i) -> InfoNCE loss with positives

- **Critical path:**
  1. Forward pass through f to get embeddings.
  2. Submodel g computes SimThres for each sequence in batch.
  3. Filter negatives using SimThres to form M−(i).
  4. Compute InfoNCE loss with filtered negatives and augmented positives.
  5. Add regularization loss.
  6. Backpropagate gradients.

- **Design tradeoffs:**
  - Adaptive threshold vs. fixed threshold: more accurate negative selection but adds computational overhead of submodel g.
  - Statistical vs. learnable SimThres: statistical is simpler but may not adapt to batch composition; learnable is flexible but needs regularization.
  - Positive sampling strategy: weighting augmented positives higher improves signal but complicates loss formulation.

- **Failure signatures:**
  - Threshold collapse: all negatives filtered out, loss becomes constant.
  - Poor threshold estimation: too many false negatives included, hurting uniformity.
  - Over-regularization: threshold stuck near kstat, losing adaptability.

- **First 3 experiments:**
  1. Compare NDCG/MRR/Recall with and without adaptive thresholding on MovieLens-1M.
  2. Measure uniformity and alignment metrics for statistical vs. learnable SimThres.
  3. Ablation study: remove regularization term and observe threshold collapse behavior.

## Open Questions the Paper Calls Out
None explicitly stated in the paper.

## Limitations
- The paper does not provide sensitivity analysis for the regularization weight λ or percentile kstat, leaving hyperparameter robustness unclear.
- Limited ablation studies make it difficult to isolate the contribution of individual components like the submodel architecture.
- Claims about improved uniformity and alignment lack qualitative visualization or deeper analysis of embedding structure changes.

## Confidence
- **High confidence:** The core mechanism of adaptive thresholding for filtering false negatives is theoretically sound and well-explained.
- **Medium confidence:** Experimental results show consistent improvements across metrics, but the ablation studies are limited.
- **Low confidence:** The claim about improved uniformity and alignment is supported by metrics but lacks qualitative visualization or deeper analysis of embedding structure changes.

## Next Checks
1. **Threshold Stability Analysis:** Monitor and plot the distribution of SimThres values during training across multiple random seeds to verify that regularization effectively prevents collapse without over-constraining adaptation.

2. **Hyperparameter Sensitivity:** Conduct experiments varying the regularization weight λ and percentile kstat across a wider range to identify stable operating regions and quantify robustness.

3. **Component Ablation:** Isolate the contribution of the learnable submodel versus statistical thresholding by comparing AdaptiveRec against a variant that uses batch-statistics only, measuring both performance and embedding quality metrics.