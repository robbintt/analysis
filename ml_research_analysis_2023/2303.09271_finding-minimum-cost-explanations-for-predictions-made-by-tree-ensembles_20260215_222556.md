---
ver: rpa2
title: Finding Minimum-Cost Explanations for Predictions made by Tree Ensembles
arxiv_id: '2303.09271'
source_url: https://arxiv.org/abs/2303.09271
tags:
- explanations
- explanation
- tree
- algorithm
- minimal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the challenge of explaining predictions from
  tree ensemble models, focusing on generating explanations that are both correct
  and minimally verbose. The authors introduce an abstract interpretation framework
  tailored for tree ensembles, enabling highly efficient determination of explanation
  validity.
---

# Finding Minimum-Cost Explanations for Predictions made by Tree Ensembles

## Quick Facts
- arXiv ID: 2303.09271
- Source URL: https://arxiv.org/abs/2303.09271
- Reference count: 4
- Key outcome: Proposes an abstract interpretation framework and m-MARCO algorithm for computing minimum-cost explanations for tree ensemble predictions, achieving 2,400x speedup over MaxSAT approaches.

## Executive Summary
This paper addresses the challenge of generating explanations for predictions made by tree ensemble models. The authors introduce an abstract interpretation framework specifically designed for tree ensembles, enabling efficient validity checking of explanations. They adapt the MARCO algorithm (m-MARCO) to compute minimum-cost explanations, significantly reducing the number of explanations needed compared to enumerating all minimal explanations. Experimental results demonstrate substantial performance improvements over existing state-of-the-art methods.

## Method Summary
The paper proposes a novel approach using abstract interpretation to generate explanations for tree ensemble predictions. The method consists of an abstract interpretation oracle based on the VoTE abstraction-refinement algorithm for validating explanations, and the m-MARCO algorithm adapted from MARCO to compute minimum-cost explanations. The approach is evaluated on 21 pre-trained XGBoost gradient boosting machines, comparing performance against MaxSAT, SMT, and branch-and-bound approaches for computing minimal and minimum explanations.

## Key Results
- Achieved 2,400x speedup compared to MaxSAT approaches for computing minimal explanations
- m-MARCO algorithm provides a 2x speedup compared to enumerating all minimal explanations
- Minimum explanations are significantly less verbose than minimal explanations, with up to 100,000 minimal explanations for some predictions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The abstract interpretation-based oracle provides a sound and complete method for determining the validity of explanations in tree ensembles.
- Mechanism: By encoding relaxed constraints as intervals in the abstract domain and using an abstraction-refinement loop, the oracle can efficiently check if a given explanation is valid without enumerating all possible input combinations.
- Core assumption: The tree ensemble only contains univariate and linear decision rules, which ensures that the abstraction-refinement algorithm (VoTE) can eventually produce precise output abstractions.
- Evidence anchors:
  - [abstract] "We formalize a sound and complete oracle for determining the correctness of explanations in the abstract interpretation framework, designed specifically for tree ensembles."
  - [section 4.3] "By using Lemma 5, we know that VoTE will eventually invoke pc with a sequence of abstract input tuples ˆXp that form a partition of ˆX such that |γ(ˆyp)| = 1, in which case pc(ˆXp,ˆyp) ̸= Unsure, hence the algorithm is complete."
  - [corpus] Weak evidence; the neighbor papers focus on different methods (MaxSAT, SMT) rather than abstract interpretation.
- Break condition: If the tree ensemble contains non-linear or multivariate decision rules, the abstraction-refinement algorithm may not converge to precise abstractions, breaking the oracle's completeness.

### Mechanism 2
- Claim: The m-MARCO algorithm efficiently computes minimum explanations by leveraging the abstract interpretation oracle and pruning the search space.
- Mechanism: m-MARCO adapts the MARCO algorithm to use the abstract interpretation oracle for checking validity and prunes seeds that would lead to more expensive explanations than the current best, reducing the search space significantly.
- Core assumption: The cost function is monotonic with respect to the number of variables in the explanation, allowing effective pruning of the search space.
- Evidence anchors:
  - [abstract] "We propose an algorithm m-MARCO which is an adaptation of the MARCO algorithm from related work... for the purpose of computing an explanation that is minimum, and demonstrate an overall speedup factor of two compared to the MARCO algorithm which enumerates all minimal explanations."
  - [section 5.2] "In Algorithm 7, we modify the standard MARCO algorithm to search for a single MCS that is minimum with respect to the cost function g. Since we only need to find one MCS, we do not explore MCSes that costs more or equal to the cheapest MCS that we know of, which speeds up the search."
  - [corpus] Weak evidence; the neighbor papers do not discuss minimum-cost explanation algorithms.
- Break condition: If the cost function is not monotonic or has many local minima, the pruning strategy may miss the true minimum explanation.

### Mechanism 3
- Claim: The combination of the abstract interpretation oracle and m-MARCO algorithm achieves a 2,400x speedup over MaxSAT approaches for computing minimal explanations.
- Mechanism: The abstract interpretation oracle is significantly faster than MaxSAT solvers for checking validity, and m-MARCO's pruning strategy further reduces the number of oracle queries needed.
- Core assumption: The abstract interpretation oracle's runtime is orders of magnitude faster than MaxSAT solvers for the specific problem of tree ensemble explanation validity checking.
- Evidence anchors:
  - [abstract] "We demonstrate the performance of our oracle in a case study from related work that computes minimal explanations, and conclude an overall speedup factor of 2,400 compared to current state-of-the-art."
  - [section 6.1.1] "In total, the MaxSAT approach needed 2.4 hours to compute a minimal explanation for all the predictions, while the approach based on abstract interpretation only needed 65 seconds, amounting to an overall speedup factor of 132. When we retrain the models with deeper trees, the speedup factor becomes approximately 2,400."
  - [corpus] Weak evidence; the neighbor papers do not provide performance comparisons with MaxSAT approaches.
- Break condition: If the abstract interpretation oracle's performance advantage over MaxSAT solvers diminishes for larger or more complex tree ensembles, the speedup factor may decrease.

## Foundational Learning

- Concept: Abstract interpretation and Galois connections
  - Why needed here: The abstract interpretation framework is used to construct the sound and complete oracle for explanation validity checking. Understanding Galois connections is crucial for proving the soundness and completeness of the oracle.
  - Quick check question: What is a Galois connection, and how does it ensure the soundness of abstract interpretation?

- Concept: Power set lattice and minimal/maximal subsets
  - Why needed here: The algorithms for computing minimal and minimum explanations rely on exploring the power set lattice of the constraint system and finding minimal unsatifiable subsets (MUSes) and maximal satisfiable subsets (MSSes).
  - Quick check question: How are minimal explanations related to maximal satisfiable subsets in the power set lattice?

- Concept: Tree ensemble prediction functions and abstract transformers
  - Why needed here: The abstract transformers are used to interpret tree ensembles in the abstract domain, which is essential for the oracle's operation.
  - Quick check question: How does the abstract transformer for a decision tree work, and why is it conservative?

## Architecture Onboarding

- Component map: Abstract interpretation oracle (VoTE-based) -> m-MARCO algorithm -> Minimum explanation output

- Critical path: 1. Receive prediction from tree ensemble model 2. Construct abstract input tuple based on given explanation 3. Invoke abstract interpretation oracle to check validity 4. If computing minimum explanation, use m-MARCO to explore search space and find minimum explanation

- Design tradeoffs: Using abstract interpretation provides soundness and completeness but may be slower than heuristic approaches for some cases. m-MARCO algorithm trades off completeness (in terms of enumerating all minimal explanations) for efficiency in finding a single minimum explanation.

- Failure signatures: If oracle returns "Unsure" for valid explanation, may indicate abstraction-refinement loop not converging. If m-MARCO fails to find minimum explanation within reasonable time, pruning strategy may be too aggressive or cost function not well-suited.

- First 3 experiments: 1. Implement abstract interpretation oracle and test on simple tree ensemble with known explanations 2. Integrate oracle with m-MARCO algorithm and test on small dataset with few predictions 3. Compare performance of m-MARCO with branch and bound baseline on larger dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of the m-MARCO algorithm scale with increasing tree ensemble complexity (e.g., number of trees, tree depth, number of features)?
- Basis in paper: [explicit] The paper mentions evaluating the algorithms on ensembles with 50 trees and depths ranging from 3-8, but does not provide detailed scalability analysis.
- Why unresolved: The experiments focus on a specific range of model complexities, and the relationship between runtime and ensemble characteristics is not fully explored.
- What evidence would resolve it: Systematic experiments varying the number of trees, tree depth, and number of features, with runtime measurements and scalability analysis.

### Open Question 2
- Question: How do the explanations generated by the proposed algorithms compare to human-understandable explanations in terms of accuracy and completeness?
- Basis in paper: [inferred] The paper emphasizes the importance of explanations being correct and without redundancy, but does not directly compare the generated explanations to human-provided explanations.
- Why unresolved: The focus is on the algorithmic generation of explanations, but their quality in terms of human comprehension is not evaluated.
- What evidence would resolve it: User studies comparing the generated explanations to human-provided explanations in terms of accuracy, completeness, and understandability.

### Open Question 3
- Question: Can the abstract interpretation framework be extended to handle more complex machine learning models beyond tree ensembles?
- Basis in paper: [explicit] The paper focuses on tree ensembles and mentions the potential for extending the approach to other model types.
- Why unresolved: The abstract interpretation framework is specifically designed for tree ensembles, and its applicability to other models is not explored.
- What evidence would resolve it: Successful adaptation of the abstract interpretation framework to other machine learning models, such as neural networks or support vector machines, with demonstrated improvements in explanation generation.

## Limitations
- The approach is limited to tree ensembles with univariate and linear decision rules
- The pruning strategy in m-MARCO assumes monotonic cost functions
- Performance advantages may diminish for larger or more complex tree ensembles

## Confidence
- Soundness and completeness of abstract interpretation oracle: High
- 2,400x speedup over MaxSAT approaches: High
- Minimum explanations being less verbose than minimal explanations: Medium
- Scalability of m-MARCO algorithm: Medium
- Practical utility of generated explanations: Low

## Next Checks
1. Test the abstract interpretation oracle on tree ensembles with non-linear or multivariate decision rules to verify the claimed limitations.
2. Evaluate the performance of m-MARCO with different cost functions to assess the robustness of the pruning strategy.
3. Compare the minimum explanations generated by m-MARCO with those from alternative methods on a held-out test set to validate their practical utility.