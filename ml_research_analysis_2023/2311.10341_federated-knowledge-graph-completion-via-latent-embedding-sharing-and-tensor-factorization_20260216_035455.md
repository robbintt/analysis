---
ver: rpa2
title: Federated Knowledge Graph Completion via Latent Embedding Sharing and Tensor
  Factorization
arxiv_id: '2311.10341'
source_url: https://arxiv.org/abs/2311.10341
tags:
- tensor
- federated
- knowledge
- graph
- matrix
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of federated knowledge graph completion
  while maintaining privacy in distributed settings. The proposed FLEST method introduces
  a novel approach using federated tensor factorization that decomposes the embedding
  matrix into dictionary and loading matrices, enabling sharing of latent dictionary
  embeddings to reduce privacy risks.
---

# Federated Knowledge Graph Completion via Latent Embedding Sharing and Tensor Factorization

## Quick Facts
- arXiv ID: 2311.10341
- Source URL: https://arxiv.org/abs/2311.10341
- Authors: 
- Reference count: 27
- Key outcome: FLEST achieves MRR scores of 0.137 and 0.252 on WN18RR and FB15k-237 respectively with 5 clients, outperforming locally trained models while maintaining privacy through dictionary matrix sharing.

## Executive Summary
This paper addresses the challenge of federated knowledge graph completion while preserving privacy in distributed settings. The proposed FLEST method introduces a novel approach using federated tensor factorization that decomposes the embedding matrix into dictionary and loading matrices, enabling sharing of latent dictionary embeddings to reduce privacy risks. This approach achieves competitive performance compared to baseline models like FedE and FedR, with FLEST demonstrating superior results on both WN18RR and FB15k-237 datasets. The method effectively balances performance and privacy by sharing only latent dictionary embeddings rather than complete entity or relation embeddings.

## Method Summary
FLEST addresses federated KG completion by decomposing the embedding matrix using Tucker tensor factorization into dictionary matrices (shared across clients) and loading matrices (kept locally). The model employs FedAvg for federated optimization, where clients update local parameters using gradient-based methods while sharing only the dictionary matrices and fusion weights with the server. The loss function combines negative log-likelihood with orthogonality constraints on dictionary matrices and sparsity constraints on loading matrices. Training uses rank=200, batch size=128, learning rate=0.0005, and dropout=0.3 across 100 communication rounds.

## Key Results
- FLEST achieves MRR of 0.137 on WN18RR dataset with 5 clients, outperforming locally trained models
- On FB15k-237 dataset, FLEST reaches MRR of 0.252 with 5 clients while maintaining privacy
- The method demonstrates superior performance compared to FedE and FedR baselines while reducing privacy risks through dictionary matrix sharing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing the embedding matrix into dictionary and loading matrices enables privacy-preserving sharing of latent embeddings while preserving model performance.
- Mechanism: The Tucker decomposition format allows the adjacency tensor to be represented as a product of dictionary matrices (shared) and loading matrices (kept local). By sharing only the low-dimensional dictionary matrices, the model captures shared latent features across clients without exposing complete entity or relation embeddings.
- Core assumption: The dictionary matrix captures sufficient shared latent information to enable effective federated learning while being computationally infeasible to reconstruct entity-level information from the dictionary alone.
- Evidence anchors:
  - [abstract] "FLEST decompose the embedding matrix and enables sharing of latent dictionary embeddings to lower privacy risks."
  - [section] "By sharing the latent dictionary embedding matrix within each mode, even if the dictionary matrix is leaked and the number of latent dimensions is much smaller than the original number of entities, it remains infeasible to recover specific entity-level and relationship-level information."
  - [corpus] Weak evidence. The corpus contains papers on federated KG completion but lacks specific discussion of dictionary/loading matrix decomposition for privacy.
- Break condition: If the dictionary matrix dimensions become too large relative to the number of entities, or if an adversary can reconstruct the loading matrix through other means, the privacy guarantee breaks down.

### Mechanism 2
- Claim: Adding orthogonality constraints to the dictionary matrix and sparsity constraints to the loading matrix improves model performance and privacy.
- Mechanism: Orthogonality ensures that the latent features are distinct and non-redundant, while sparsity in the loading matrix means each entity or relation is represented by a small subset of features, reducing information leakage.
- Core assumption: Orthogonal and sparse representations are both more efficient for learning and more secure for privacy.
- Evidence anchors:
  - [section] "we assume that the vectors in the dictionary should exhibit a high degree of left orthogonality... we aim for sparsity in the load matrix"
  - [section] "Ldic = ||ETdicEdic − I||F + ||RTdicRdic − I||F" and "L(i)loading = ||vec(E(i)loading)||1 + ||vec(R(i)loading)||1"
  - [corpus] No direct evidence in corpus papers about orthogonality/sparsity constraints for federated KG completion.
- Break condition: If the orthogonality or sparsity constraints are too strong, they may prevent the model from learning useful representations, leading to poor performance.

### Mechanism 3
- Claim: The federated optimization framework allows each client to update local parameters using gradient-based methods while sharing only dictionary matrices, achieving a balance between performance and privacy.
- Mechanism: Clients compute gradients locally and update their local loading matrices, dictionary matrices, and fusion weights. They then share only the dictionary matrices and fusion weights with the server, which averages them and redistributes them. This FedAvg-like approach enables collaborative learning without exposing raw data.
- Core assumption: Local gradient computation and parameter averaging are sufficient to achieve global model convergence.
- Evidence anchors:
  - [section] "we can adopt FedAvg (averaging the parameter) [22] to design federated algorithms. Each client optimizes Edic, Rdic, W1, W2 and W3 locally using gradient-based methods"
  - [section] "Edic = 1|C| CX i E(i)(N)dic" showing the averaging step
  - [corpus] Weak evidence. While the corpus mentions federated learning for KG completion, it doesn't specifically discuss this gradient-based federated optimization approach with dictionary sharing.
- Break condition: If the number of communication rounds is insufficient, or if the local datasets are too heterogeneous, the model may not converge or may converge to a suboptimal solution.

## Foundational Learning

- Concept: Tucker tensor decomposition
  - Why needed here: The Tucker format is used to represent the knowledge graph as a third-order tensor, which is then decomposed into factor matrices (embeddings) and a core tensor. This decomposition enables the model to capture complex relationships in the KG.
  - Quick check question: What is the difference between CP decomposition and Tucker decomposition of a tensor?
- Concept: Federated learning and FedAvg algorithm
  - Why needed here: Federated learning allows multiple clients to collaboratively train a model without sharing their raw data. The FedAvg algorithm is used to aggregate local model updates from clients to form a global model.
  - Quick check question: How does FedAvg differ from other federated learning algorithms like FedSGD or FedProx?
- Concept: Knowledge graph embedding methods (e.g., DistMult, ComplEx, RotatE)
  - Why needed here: These are baseline models that the proposed FLEST method is compared against. Understanding their scoring functions and architectures is crucial for evaluating FLEST's performance.
  - Quick check question: What is the key difference between the scoring functions of DistMult and ComplEx?

## Architecture Onboarding

- Component map: Knowledge graph tensor -> Tucker decomposition -> Dictionary matrices + Loading matrices + Core tensor -> Federated optimization with FedAvg
- Critical path:
  1. Initialize parameters on server and clients.
  2. Clients receive dictionary matrices and fusion weights from server.
  3. Clients compute local gradients and update parameters.
  4. Clients send updated dictionary matrices and fusion weights to server.
  5. Server averages parameters and redistributes them.
  6. Repeat steps 2-5 for multiple communication rounds.
- Design tradeoffs:
  - Privacy vs. performance: Sharing more information (e.g., complete embeddings) may improve performance but increase privacy risks.
  - Communication cost vs. model accuracy: More frequent communication may lead to better convergence but increase communication overhead.
  - Orthogonality/sparsity constraints: Stronger constraints may improve privacy but could also hinder the model's ability to learn useful representations.
- Failure signatures:
  - Poor performance: May indicate insufficient communication rounds, too strong constraints, or excessive data heterogeneity.
  - Privacy leaks: If an adversary can reconstruct entity-level information from the dictionary matrices, the privacy guarantee is compromised.
  - Convergence issues: May arise from incompatible local datasets, insufficient local training, or inappropriate learning rates.
- First 3 experiments:
  1. Run FLEST on a single client with a small knowledge graph to verify the Tucker decomposition and loss function implementation.
  2. Run FLEST with two clients on a larger knowledge graph to test the federated optimization and parameter averaging.
  3. Compare FLEST's performance with baseline models (e.g., DistMult, ComplEx) on a standard benchmark dataset (e.g., WN18RR, FB15k-237) to evaluate its effectiveness.

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the analysis, several important questions remain unresolved regarding privacy guarantees, scalability, and performance under different data distribution scenarios.

## Limitations

- Privacy guarantees rely on assumptions about dictionary matrix inversion that lack empirical validation
- Limited evaluation to only two benchmark datasets (WN18RR and FB15k-237)
- Performance sensitivity to hyperparameter choices (α, β, learning rate) without systematic sensitivity analysis
- Scalability to larger knowledge graphs and more clients remains unclear

## Confidence

- Core mechanism (dictionary decomposition for privacy): Medium - theoretically sound but lacks empirical privacy validation
- Performance claims vs. baselines: Medium - competitive on two datasets but limited baseline coverage
- Privacy guarantees: Low - based on assumptions without rigorous empirical validation

## Next Checks

1. **Privacy Analysis**: Conduct an empirical analysis to test whether dictionary matrices can be inverted or exploited to recover entity-level information under various attack scenarios.

2. **Ablation Study**: Remove orthogonality and sparsity constraints individually to quantify their contribution to both performance and privacy.

3. **Data Heterogeneity Stress Test**: Systematically vary the degree of data heterogeneity across clients (from IID to highly non-IID) and measure impact on convergence and performance.