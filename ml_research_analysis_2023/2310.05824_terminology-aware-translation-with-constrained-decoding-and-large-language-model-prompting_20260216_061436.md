---
ver: rpa2
title: Terminology-Aware Translation with Constrained Decoding and Large Language
  Model Prompting
arxiv_id: '2310.05824'
source_url: https://arxiv.org/abs/2310.05824
tags:
- translation
- terminology
- constraints
- language
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores methods to improve terminology translation
  in machine translation systems. The authors train a terminology-aware translation
  model by injecting pseudo-terminology constraints into the training data using word
  alignments.
---

# Terminology-Aware Translation with Constrained Decoding and Large Language Model Prompting

## Quick Facts
- **arXiv ID**: 2310.05824
- **Source URL**: https://arxiv.org/abs/2310.05824
- **Reference count**: 3
- **Primary result**: LLM refinement with terminology constraints achieves up to 83% terminology recall with minimal impact on translation quality

## Executive Summary
This paper investigates methods to improve terminology translation accuracy in machine translation systems. The authors propose a terminology-aware translation model trained with pseudo-terminology constraints injected via word alignments, and evaluate two post-processing approaches: negatively constrained decoding and LLM-based refinement. The LLM approach shows the most promise, achieving high terminology recall while maintaining translation quality, though at higher computational cost compared to the terminology-aware model alone.

## Method Summary
The paper proposes three approaches for terminology-aware translation: (1) training a terminology-aware model by injecting pseudo-terminology constraints into the training data using word alignments, (2) negatively constrained decoding that re-decodes translations while blocking incorrect terminology choices, and (3) LLM refinement that prompts a large language model to refine translations while incorporating terminology constraints. The methods are evaluated on German-English, Chinese-English, and Czech-English translation tasks using WMT blind test sets.

## Key Results
- LLM refinement approach achieves up to 83% terminology recall with minimal impact on COMETQE scores
- Terminology-aware training improves terminology recall but shows slight quality drops compared to standard models
- Negatively constrained decoding often leads to worse results due to alignment errors and mis-translations
- LLM refinement is computationally expensive but most effective for high-accuracy terminology translation

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Terminology-aware training with inline source-side annotation improves translation accuracy for domain-specific terms
- **Mechanism**: During training, source words are tagged with their target terminology equivalents, creating explicit supervision for the model to learn these mappings
- **Core assumption**: The model can effectively learn to copy or transform these tagged terms into the target translation
- **Evidence anchors**:
  - [abstract]: "We annotate random source words with pseudo-terminology translations obtained from word alignment to first train a terminology-aware model"
  - [section 3.1]: "For each sentence, we select all bijective source-target mappings as our terminology candidates... In the training data, we replace srcwordi in the source sentence with: srcwordi __target__ trgwordj __done__"
  - [corpus]: Weak evidence - neighboring papers discuss similar terminology-aware approaches but with different training methods
- **Break condition**: If the word alignment quality is poor or if the model fails to learn the copying behavior from the annotated training data

### Mechanism 2
- **Claim**: LLM refinement with terminology constraints can improve terminology recall without significantly degrading translation quality
- **Mechanism**: A pre-trained LLM is prompted to refine an existing translation while incorporating terminology constraints through natural language instructions
- **Core assumption**: The LLM has sufficient capacity to understand the terminology constraints and integrate them into a coherent translation
- **Evidence anchors**:
  - [abstract]: "Alternatively, we leverage a large language model to refine a hypothesis by providing it with terminology constraints"
  - [section 4.2]: "We investigate the effectiveness of using a large language model to generate terminology terms during translation by adding constraints to Chen et al. (2023)'s translation refinement prompts"
  - [corpus]: Weak evidence - neighboring papers discuss LLM prompting but not specifically for terminology translation
- **Break condition**: If the LLM fails to incorporate the terminology constraints or produces translations that are significantly worse in quality than the original

### Mechanism 3
- **Claim**: Negatively constrained decoding can identify and correct missed terminology translations by blocking incorrect word choices
- **Mechanism**: After an initial translation, word alignments are used to identify which source words were incorrectly translated, and these words are then blocked during a second decoding pass
- **Core assumption**: The word alignment process accurately identifies which source words were mistranslated, and blocking these words will force the model to choose better alternatives
- **Evidence anchors**:
  - [abstract]: "First, we use an alignment process to discover whether a terminology constraint has been violated, and if so, we re-decode with the violating word negatively constrained"
  - [section 4.1]: "we make use of awesome-align, a neural multilingual word aligner... we decode the source sentence again, penalising the words that violated the terminology constraint"
  - [corpus]: Weak evidence - neighboring papers discuss constrained decoding but not specifically for terminology translation
- **Break condition**: If the word alignment is inaccurate or if blocking the incorrect words leads to even worse translations

## Foundational Learning

- **Concept**: Word alignment and its role in terminology extraction
  - **Why needed here**: Word alignment is used to create pseudo-terminology constraints for training and to identify terminology violations during negatively constrained decoding
  - **Quick check question**: How does the quality of word alignment affect the effectiveness of terminology-aware training and negatively constrained decoding?

- **Concept**: Transformer architecture and its training process
  - **Why needed here**: Understanding the Transformer architecture is crucial for implementing the terminology-aware training approach and for interpreting the results
  - **Quick check question**: How does tagging source words with target terminology equivalents affect the Transformer's attention mechanism during training?

- **Concept**: Large language models and prompt engineering
  - **Why needed here**: The LLM refinement approach relies on carefully crafted prompts to incorporate terminology constraints
  - **Quick check question**: How does the structure and content of the prompt affect the LLM's ability to incorporate terminology constraints into the translation?

## Architecture Onboarding

- **Component map**: Training data -> Word alignment -> Terminology-aware model OR Negatively constrained decoder OR LLM refinement module -> Evaluation metrics
- **Critical path**:
  1. Create pseudo-terminology data using word alignment
  2. Train terminology-aware translation model
  3. Translate test data using TAT model
  4. Optionally refine translations using negatively constrained decoding or LLM refinement
  5. Evaluate results
- **Design tradeoffs**:
  - Training data: Using pseudo-terminology data vs. real terminology data
  - Post-processing: LLM refinement (higher quality but more expensive) vs. negatively constrained decoding (cheaper but potentially less effective)
  - Evaluation: Automatic metrics (BLEU, COMETQE) vs. manual evaluation of terminology accuracy
- **Failure signatures**:
  - Poor word alignment quality leading to incorrect pseudo-terminology data
  - Model failing to learn the copying behavior from the annotated training data
  - LLM failing to incorporate terminology constraints or degrading translation quality
  - Negatively constrained decoding leading to worse translations
- **First 3 experiments**:
  1. Train a terminology-aware translation model using pseudo-terminology data and evaluate its performance on a test set
  2. Implement and evaluate the negatively constrained decoding approach on a subset of the test data
  3. Implement and evaluate the LLM refinement approach on a subset of the test data, comparing it to the negatively constrained decoding approach

## Open Questions the Paper Calls Out

### Open Question 1
- **Question**: How can the quality drop in terminology-aware translation models be minimized while maintaining high terminology recall?
- **Basis in paper**: [inferred] The paper notes that terminology-aware training can result in a slight quality drop compared to standard models, as seen in the BLEU and COMETDA scores.
- **Why unresolved**: The paper does not explore methods to mitigate the quality drop while retaining terminology accuracy, leaving this as an open problem.
- **What evidence would resolve it**: Experiments comparing techniques like domain adaptation, fine-tuning, or hybrid approaches to balance quality and terminology recall.

### Open Question 2
- **Question**: Is there a more efficient alternative to LLM-based refinement for terminology injection that balances computational cost and performance?
- **Basis in paper**: [explicit] The paper highlights that LLM-based refinement achieves high terminology recall but is computationally expensive compared to terminology-aware models.
- **Why unresolved**: The paper does not investigate cost-effective alternatives, such as smaller models or rule-based systems, to achieve similar results.
- **What evidence would resolve it**: Comparative studies of alternative methods (e.g., smaller models, rule-based systems) against LLM-based refinement in terms of cost and terminology recall.

### Open Question 3
- **Question**: How can negatively constrained decoding be improved to avoid mis-translations while enforcing terminology constraints?
- **Basis in paper**: [explicit] The paper notes that negatively constrained decoding often leads to worse results in terms of both quality and terminology recall due to alignment errors and unintended mis-translations.
- **Why unresolved**: The paper does not explore refinements to the negatively constrained decoding process, such as iterative improvements or hybrid approaches with positively constrained decoding.
- **What evidence would resolve it**: Experiments testing improved alignment techniques, iterative refinement, or hybrid decoding strategies to enhance performance.

### Open Question 4
- **Question**: Can terminology-aware models be adapted to handle domain-specific terminology more effectively without sacrificing general translation quality?
- **Basis in paper**: [inferred] The paper mentions that domain mismatch (e.g., web novels vs. general data) can lead to poor performance, suggesting a need for better domain adaptation.
- **Why unresolved**: The paper does not explore domain-specific fine-tuning or adaptation strategies to address this issue.
- **What evidence would resolve it**: Experiments comparing domain adaptation techniques (e.g., fine-tuning on domain-specific data) with the current terminology-aware approach.

## Limitations
- LLM refinement approach is computationally expensive and introduces external API dependencies
- Word alignment quality critically affects all three approaches but is not thoroughly evaluated
- Limited evaluation scope - lacks human evaluation of translation fluency when terminology constraints are applied
- Results may not generalize well across different language families and domain-specific terminology

## Confidence
- **High confidence**: The basic terminology-aware training approach shows consistent improvements across all language pairs
- **Medium confidence**: The negatively constrained decoding approach shows variable effectiveness across language pairs
- **Medium confidence**: The LLM refinement approach achieves best terminology recall but introduces significant complexity and cost

## Next Checks
1. **Alignment error analysis**: Conduct systematic evaluation of how word alignment errors affect terminology constraint identification and enforcement across all three approaches
2. **Ablation study on LLM prompts**: Systematically vary the prompt structure, constraint presentation format, and temperature settings for the LLM refinement approach
3. **Cross-domain generalization test**: Evaluate the terminology-aware models on out-of-domain test sets with domain-specific terminology to assess generalization beyond the WMT domain