---
ver: rpa2
title: A Joint Time-frequency Domain Transformer for Multivariate Time Series Forecasting
arxiv_id: '2305.14649'
source_url: https://arxiv.org/abs/2305.14649
tags:
- series
- time
- forecasting
- jtft
- transformer
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes JTFT, a joint time-frequency domain Transformer
  for multivariate time series forecasting. JTFT introduces a sparse frequency domain
  representation using learnable frequencies and a time domain representation from
  the latest data points.
---

# A Joint Time-frequency Domain Transformer for Multivariate Time Series Forecasting

## Quick Facts
- arXiv ID: 2305.14649
- Source URL: https://arxiv.org/abs/2305.14649
- Reference count: 13
- JTFT outperforms state-of-the-art methods, ranking first in 41 out of 48 settings across six real-world datasets

## Executive Summary
This paper introduces JTFT, a novel transformer architecture for multivariate time series forecasting that combines time and frequency domain representations. JTFT addresses the computational inefficiency of traditional transformers and the inability of existing frequency-based methods to capture local dependencies. By learning sparse frequency representations through a customized discrete cosine transform and concatenating them with recent time-domain patches, JTFT achieves linear complexity while maintaining strong predictive performance across diverse forecasting tasks.

## Method Summary
JTFT processes multivariate time series by extracting sparse frequency domain representations using learnable frequencies via a customized discrete cosine transform (CDCT), then concatenates these with the most recent time-domain patches. The joint representation is processed through a transformer encoder for temporal dependencies and low-rank attention layers for cross-channel dependencies. The model employs linear complexity operations throughout, making it scalable for long sequences. During inference, the model uses the most recent observations and learned frequencies to make predictions.

## Key Results
- JTFT achieves state-of-the-art performance across six real-world datasets
- The model ranks first in 41 out of 48 experimental settings with varying prediction lengths and metrics
- JTFT maintains linear computational complexity in both time and space
- Low-rank attention effectively captures cross-channel dependencies while reducing parameter count

## Why This Works (Mechanism)

### Mechanism 1
- Claim: JTFT improves forecasting by combining sparse frequency-domain representations with recent time-domain patches, capturing both long-term and local dependencies while maintaining linear complexity.
- Mechanism: The model uses a customized discrete cosine transform (CDCT) with learnable frequencies to extract sparse frequency components, then concatenates these with the most recent time-domain patches to form a joint representation. This dual-domain approach allows the model to model multi-scale structures and mitigate non-stationarity effects.
- Core assumption: Time series are sparse in the frequency domain, and a small number of learnable frequencies can capture most of the signal's energy while recent time-domain data captures local dynamics.
- Evidence anchors:
  - [abstract]: "JTFT combines time and frequency domain representations to make predictions. The frequency domain representation efficiently extracts multi-scale dependencies while maintaining sparsity by utilizing a small number of learnable frequencies."
  - [section 3.2]: "A customize discrete cosine transform (CDCT) is developed to compute customized FD components, which enables learning of frequencies."
  - [corpus]: Weak evidence. The corpus contains related papers about joint time-frequency modeling, but no direct quantitative comparison to JTFT's specific approach.
- Break condition: If the assumption that time series are sparse in frequency domain fails, or if the learnable frequencies cannot adapt to capture the true signal characteristics, the sparse representation becomes ineffective.

### Mechanism 2
- Claim: The low-rank attention layer efficiently captures cross-channel dependencies without the quadratic complexity of standard attention.
- Mechanism: Instead of full attention across all channels, JTFT uses routers (small learnable vectors) as queries to aggregate messages from all channels, then projects these messages back to channels. This reduces complexity from O(D²L) to O(DL) while maintaining cross-channel information flow.
- Core assumption: Cross-channel dependencies are important for forecasting, but can be captured efficiently through low-rank approximations rather than full attention matrices.
- Evidence anchors:
  - [abstract]: "a low-rank attention layer is proposed to efficiently capture cross-dimensional dependencies, thus preventing performance degradation resulting from the entanglement of temporal and channel-wise modeling."
  - [section 3.3]: "The LMSA is a simplified version of the MSA, in which the linear projection for queries is omitted, and the keys and values share the same linear projection."
  - [corpus]: No direct evidence. The corpus doesn't provide quantitative data on low-rank attention performance.
- Break condition: If the low-rank approximation cannot capture the true cross-channel relationships, or if the reduced parameter count leads to underfitting on datasets with strong cross-channel dependencies.

### Mechanism 3
- Claim: Learnable frequencies in CDCT provide better representation than random frequencies or fixed top frequencies.
- Mechanism: Instead of using predefined uniform frequencies (like DCT) or random frequencies (like FEDformer), JTFT learns optimal frequencies through training, allowing the model to adapt to dataset-specific characteristics.
- Core assumption: The most important frequencies for representing a time series are not uniformly distributed and can be learned from data.
- Evidence anchors:
  - [section 3.2]: "We compare the representation ability of random frequencies (RNDF) and learnable frequencies (LRNF) by examining the errors in reconstructing the input TD series."
  - [figure 2]: Shows LRNF outperforming RNDF in reconstruction error across multiple datasets.
  - [corpus]: No direct evidence. The corpus doesn't provide comparative results for learnable vs random frequencies.
- Break condition: If the optimization landscape for learning frequencies is too complex or prone to local minima, the learned frequencies may not converge to optimal values.

## Foundational Learning

- Concept: Discrete Cosine Transform (DCT) and its properties
  - Why needed here: Understanding how DCT works and why it's preferred over DFT for real-valued signals is crucial for grasping why JTFT uses CDCT as a foundation.
  - Quick check question: Why does DCT roughly halve the length needed to represent a real sequence compared to DFT?

- Concept: Frequency domain sparsity in time series
  - Why needed here: The core assumption that time series are sparse in frequency domain drives the entire JTFT architecture. Understanding this concept is essential for understanding why frequency-domain methods work.
  - Quick check question: What property of many real-world time series makes them sparse in the frequency domain?

- Concept: Transformer attention complexity and approximation methods
  - Why needed here: Understanding the quadratic complexity problem in Transformers and how low-rank approximations work is crucial for grasping JTFT's efficiency improvements.
  - Quick check question: What is the computational complexity of standard self-attention, and how do low-rank approximations reduce this?

## Architecture Onboarding

- Component map: Input → Preprocessing → JTFR → Transformer Encoder → LRA → Prediction Head → Output
- Critical path: Input → Preprocessing → JTFR → Transformer Encoder → LRA → Prediction Head → Output
- Design tradeoffs:
  - Number of learnable frequencies vs. representation accuracy: More frequencies capture more detail but increase complexity
  - Patch size and stride: Affects the granularity of local pattern capture vs. computational cost
  - Low-rank attention rank: Lower rank reduces parameters but may miss important cross-channel relationships
- Failure signatures:
  - High reconstruction error from CDCT → frequency selection problem
  - Performance degrades with increasing channels → low-rank attention insufficient
  - Overfitting on small datasets → too many learnable parameters
- First 3 experiments:
  1. Compare JTFT with fixed vs. learnable frequencies on a small dataset to verify the frequency learning mechanism
  2. Test different numbers of low-rank attention layers to find the optimal balance between performance and efficiency
  3. Vary patch sizes and strides to understand their impact on capturing local vs. global patterns

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different initialization strategies for learnable frequencies in CDCT affect long-term forecasting performance across diverse time series datasets?
- Basis in paper: [explicit] The paper mentions initializing ψ1:kmax−1 according to top frequencies from DCT and compares random vs learnable frequencies, but does not systematically evaluate initialization strategies.
- Why unresolved: The impact of various initialization methods on forecasting accuracy and convergence speed remains unexplored.
- What evidence would resolve it: Systematic ablation studies comparing multiple initialization strategies (e.g., DCT-based, random, learned from data statistics) across diverse datasets and forecasting horizons.

### Open Question 2
- Question: What is the optimal balance between time-domain and frequency-domain representations for different types of non-stationary time series?
- Basis in paper: [inferred] The paper combines time and frequency domain representations to mitigate non-stationarity effects, but does not explore the optimal balance for different non-stationary patterns.
- Why unresolved: The relative importance of TD vs FD components may vary significantly depending on the nature of non-stationarity in different time series.
- What evidence would resolve it: Empirical studies varying the ratio of TD to FD components across datasets with different non-stationary characteristics and analyzing performance trade-offs.

### Open Question 3
- Question: How does the low-rank attention layer's performance scale with increasing dimensionality and sequence length compared to full attention mechanisms?
- Basis in paper: [explicit] The paper introduces low-rank attention to reduce parameter count and computational cost, but does not provide extensive scaling analysis.
- Why unresolved: While computational complexity is analyzed, empirical performance and scalability with respect to dimensionality and sequence length remain unexplored.
- What evidence would resolve it: Comparative experiments measuring accuracy and computational efficiency of low-rank vs full attention across varying dimensionalities and sequence lengths.

## Limitations
- Experimental validation relies entirely on synthetic data and a limited set of six real-world datasets
- The claim that linear complexity holds across all scenarios is supported only by complexity analysis, not empirical wall-clock timing comparisons
- The sparse frequency assumption, while theoretically plausible, lacks statistical validation across different types of non-stationary time series

## Confidence
- High Confidence: The linear complexity claims and architectural design choices are mathematically sound and follow established transformer principles
- Medium Confidence: The performance superiority over state-of-the-art methods is well-demonstrated on the tested datasets, but results may not generalize to time series with different characteristics
- Low Confidence: The claim that learnable frequencies universally outperform fixed or random frequencies across all time series domains lacks comprehensive validation

## Next Checks
1. Implement timing benchmarks comparing JTFT against quadratic-complexity baselines (TFT, Informer) on datasets of increasing channel dimensions to empirically verify the claimed linear scaling
2. For each real-world dataset, measure the actual frequency domain sparsity achieved by learnable frequencies and compare against the theoretical assumption of sparse representations
3. Test JTFT on datasets with markedly different characteristics (e.g., highly non-stationary financial data, chaotic systems) to assess whether the joint time-frequency approach maintains its advantage across diverse time series types