---
ver: rpa2
title: Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks
arxiv_id: '2312.00232'
source_url: https://arxiv.org/abs/2312.00232
tags:
- learning
- uncertainty
- contrastive
- data
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a variational Bayesian approach to graph
  contrastive learning (VGCL) that incorporates uncertainty in the model weights,
  improving both downstream accuracy and uncertainty calibration. The method regularizes
  the variational family with Gaussian hyperpriors, encouraging larger variance in
  the weights to account for the noise in data augmentations.
---

# Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks

## Quick Facts
- **arXiv ID**: 2312.00232
- **Source URL**: https://arxiv.org/abs/2312.00232
- **Reference count**: 40
- **Primary result**: Variational Bayesian approach to graph contrastive learning (VGCL) improves downstream accuracy and uncertainty calibration by encouraging larger weight variance.

## Executive Summary
This paper introduces a variational Bayesian approach to graph contrastive learning (VGCL) that incorporates uncertainty in the model weights, improving both downstream accuracy and uncertainty calibration. The method regularizes the variational family with Gaussian hyperpriors, encouraging larger variance in the weights to account for the noise in data augmentations. Experiments on Cora, Citeseer, and Pubmed citation datasets show that VGCL consistently outperforms deterministic baselines and other Bayesian approaches in node classification accuracy. Additionally, the paper proposes a new uncertainty measure for contrastive learning, the Contrastive Model Disagreement Score (CMDS), which is based on the disagreement in likelihood under different positive samples and weight samples. The CMDS outperforms existing measures in correlating with downstream accuracy and provides better uncertainty calibration when combined with VGCL.

## Method Summary
VGCL extends the InfoNCE contrastive learning objective by modeling the encoder and projection head weights as distributions rather than point estimates. The variational family is a Gaussian distribution over the weights, and the model is trained by optimizing the Evidence Lower Bound (ELBO). Gaussian hyperpriors are placed on the parameters of the variational family to encourage larger weight variance, which compensates for the noise introduced by data augmentations. The CMDS uncertainty measure quantifies the variation in normalized likelihoods across different positive samples and weight samples, capturing both aleatoric and epistemic uncertainty.

## Key Results
- VGCL with hyperpriors consistently outperforms deterministic baselines and other Bayesian approaches on Cora, Citeseer, and Pubmed datasets.
- The CMDS uncertainty measure correlates better with downstream accuracy than existing measures like ASTD, PSFV, Likelihood, and WAIC.
- VGCL improves uncertainty calibration, as shown by improved retention curves and correlation with downstream accuracy.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: VGCL improves accuracy by encouraging larger weight variance via hyperpriors.
- Mechanism: The Gaussian hyperpriors on the variational parameters (µ, p) regularize the variational family to have higher variance, which compensates for the noise introduced by data augmentations. This allows the model to learn more robust representations that generalize better.
- Core assumption: Augmentations are noisy approximations of the true data generating process, and larger epistemic uncertainty in weights is beneficial for contrastive learning.
- Evidence anchors:
  - [abstract]: "We find that regularizing the variational family leads to a remarkable improvement in downstream accuracy."
  - [section]: "We thus hypothesize that a larger uncertainty about the model weights might be beneficial and we incorporate this prior knowledge by regularizing the variational family."
- Break condition: If augmentations are not noisy approximations (e.g., perfect transformations), the regularization could hurt performance.

### Mechanism 2
- Claim: CMDS outperforms existing uncertainty measures by capturing likelihood disagreement under positive samples.
- Mechanism: CMDS quantifies uncertainty based on the variation in normalized likelihoods across different positive samples and weight samples. This captures both aleatoric uncertainty (data variability) and epistemic uncertainty (model parameter uncertainty), providing a more comprehensive uncertainty estimate.
- Core assumption: Likelihood disagreement under positive samples correlates well with downstream accuracy.
- Evidence anchors:
  - [abstract]: "We propose the contrastive model disagreement score (CMDS), a new approach for measuring uncertainty in contrastive learning based on the disagreement between positive samples."
  - [section]: "We empirically show that it outperforms the currently used measures."
- Break condition: If downstream accuracy does not correlate with likelihood disagreement, CMDS will fail to be a good uncertainty measure.

### Mechanism 3
- Claim: Incorporating weight uncertainty improves uncertainty calibration of the model.
- Mechanism: By modeling the weights as distributions rather than point estimates, the model captures epistemic uncertainty. This leads to better calibrated uncertainty estimates, as shown by improved retention curves and correlation with downstream accuracy.
- Core assumption: Modeling epistemic uncertainty in the weights leads to better uncertainty calibration.
- Evidence anchors:
  - [abstract]: "We show that a variational Bayesian neural network approach can be used to improve not only the uncertainty estimates but also the downstream performance."
  - [section]: "We find all the measures to be improved when VGCL is used and weight uncertainty is taken into account."
- Break condition: If the variational approximation is too poor or the prior is misspecified, incorporating weight uncertainty could lead to worse calibration.

## Foundational Learning

- Concept: Evidence Lower Bound (ELBO) in variational inference
  - Why needed here: The paper optimizes an ELBO to learn the parameters of the probabilistic encoder, which includes both the encoder and projection head weights.
  - Quick check question: What is the relationship between the ELBO and the marginal likelihood in Bayesian inference?

- Concept: Contrastive learning and InfoNCE loss
  - Why needed here: The paper builds upon the InfoNCE objective to develop a probabilistic interpretation and extend it with Bayesian methods.
  - Quick check question: How does the InfoNCE loss encourage the model to learn useful representations?

- Concept: Graph Neural Networks (GNNs) and graph convolutions
  - Why needed here: The encoder used in the paper is a two-layer GCN, which processes graph-structured data.
  - Quick check question: How do graph convolutions differ from standard convolutions in image processing?

## Architecture Onboarding

- Component map: Data augmentation -> Two-layer GCN encoder -> Projection head (2 MLP layers) -> Similarity calculation -> Temperature-scaled InfoNCE loss -> Parameter update (via gradients of ELBO)

- Critical path: Data augmentation → Encoder → Projection head → Similarity calculation → Contrastive loss → Parameter update (via gradients of ELBO).

- Design tradeoffs:
  - Accuracy vs. uncertainty calibration: Incorporating weight uncertainty improves calibration but may slightly decrease accuracy.
  - Computational cost: Using a variational family and sampling from it increases computational cost compared to deterministic methods.
  - Prior specification: The choice of hyperpriors affects the learned weight distributions and the resulting performance.

- Failure signatures:
  - Poor accuracy: Could indicate that the variational family is too restrictive, the hyperpriors are misspecified, or the model is overfitting.
  - Poor uncertainty calibration: Could indicate that the variational approximation is poor, the likelihood model is misspecified, or the CMDS is not a good uncertainty measure for the task.

- First 3 experiments:
  1. Train VGCL with and without hyperpriors on Cora dataset and compare test accuracies.
  2. Implement CMDS and compare its correlation with downstream accuracy against existing measures (ASTD, PSFV, Likelihood, WAIC) on Cora.
  3. Train VGCL and a deterministic InfoNCE model on Cora, generate retention curves for both, and compare their uncertainty calibration.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does VGCL's improved performance on graph datasets generalize to other data modalities, such as images or text?
- Basis in paper: [explicit] The paper concludes by suggesting future work to investigate whether VGCL's superior performance transfers from the graph setting onto other modalities (e.g., images).
- Why unresolved: The experiments were conducted exclusively on graph datasets (Cora, Citeseer, Pubmed), and no evidence exists to support or refute generalization to other data types.
- What evidence would resolve it: Experiments on image or text datasets, comparing VGCL's performance to deterministic and other Bayesian baselines.

### Open Question 2
- Question: Can alternative prior distributions or variational families further improve VGCL's performance and uncertainty calibration?
- Basis in paper: [explicit] The paper suggests investigating whether different priors or variational distributions could additionally improve VGCL's performance.
- Why unresolved: The paper only explored Gaussian priors and variational families, leaving the potential of other distributions unexplored.
- What evidence would resolve it: Experiments comparing VGCL's performance and uncertainty calibration using different prior distributions (e.g., Laplace, Cauchy) or more complex variational families (e.g., normalizing flows).

### Open Question 3
- Question: How does the choice of hyperparameters, such as the regularization strength of the variance of the variational family, affect VGCL's performance and uncertainty estimates?
- Basis in paper: [explicit] The paper presents a heatmap showing the impact of different regularization strengths on the learned weight distributions, suggesting that stronger regularization leads to larger weight variances.
- Why unresolved: The paper does not provide a systematic study of how different hyperparameter choices affect VGCL's performance and uncertainty calibration.
- What evidence would resolve it: A comprehensive hyperparameter sensitivity analysis, exploring the impact of different regularization strengths, learning rates, and other relevant hyperparameters on VGCL's performance and uncertainty estimates.

## Limitations
- The generalizability of CMDS to other graph datasets and contrastive learning frameworks beyond citation networks is unclear.
- The choice of Gaussian priors as hyperpriors, while theoretically justified, may not be optimal for all graph structures or augmentation strategies.
- The computational overhead of sampling from the variational family is not thoroughly discussed, which could be a practical limitation for larger graphs.

## Confidence

- **High Confidence**: The mechanism by which hyperpriors encourage larger weight variance is well-supported by the theory of variational inference and the empirical results showing improved downstream accuracy.
- **Medium Confidence**: The claim that CMDS outperforms existing uncertainty measures is supported by correlation analysis with downstream accuracy, but the correlation does not necessarily imply causation or universal applicability.
- **Medium Confidence**: The improvement in uncertainty calibration when using VGCL is demonstrated through retention curves, but the calibration metric used (not explicitly stated in the abstract) and its sensitivity to dataset size are unclear.

## Next Checks

1. **Dataset Generalization**: Evaluate VGCL and CMDS on larger, more diverse graph datasets (e.g., ogbn-arxiv, ogbn-proteins) to assess scalability and generalizability.
2. **Ablation Study on Priors**: Conduct an ablation study varying the hyperprior distributions (e.g., Laplace, Student-t) to determine the sensitivity of VGCL to the choice of priors.
3. **Uncertainty Calibration Metric**: Clarify and report the specific uncertainty calibration metric used (e.g., Expected Calibration Error, Brier score) and analyze its behavior across different dataset sizes and model complexities.