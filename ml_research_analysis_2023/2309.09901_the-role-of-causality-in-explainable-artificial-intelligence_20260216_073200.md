---
ver: rpa2
title: The role of causality in explainable artificial intelligence
arxiv_id: '2309.09901'
source_url: https://arxiv.org/abs/2309.09901
tags:
- causal
- causality
- explanations
- intelligence
- explainable
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This review investigates the relationship between causality and
  eXplainable Artificial Intelligence (XAI) from both theoretical and methodological
  viewpoints. The authors analyze the literature to uncover three main perspectives
  on how these fields relate.
---

# The role of causality in explainable artificial intelligence

## Quick Facts
- arXiv ID: 2309.09901
- Source URL: https://arxiv.org/abs/2309.09901
- Reference count: 20
- Authors: Various researchers in AI and causality fields
- Primary result: Systematic review identifying three perspectives on causality-XAI relationship

## Executive Summary
This systematic review investigates the relationship between causality and eXplainable Artificial Intelligence (XAI) through a structured analysis of 51 peer-reviewed publications. The authors identify three main perspectives: the lack of causality as a limitation of current AI approaches, XAI as a tool for scientific causal exploration, and causality as foundational to XAI through formal tools like Structural Causal Models. The review provides both theoretical insights and practical resources, including a collection of software tools for automating causal tasks.

## Method Summary
The study employed a structured review process across four major databases (Scopus, IEEE Xplore, Web of Science, ACM Guide to Computing Literature) using systematic search strategies. The authors conducted high-level bibliometric analysis, topic clustering, and information extraction to classify perspectives on the causality-XAI relationship. They also compiled a comprehensive collection of software tools for causal discovery and inference tasks, providing practical resources for researchers in the field.

## Key Results
- Three distinct perspectives on causality-XAI relationship identified: causality as limitation, XAI for causality, and causality as foundation for XAI
- Causal tools like Structural Causal Models (SCMs) can improve explanation robustness and enable interventions/counterfactual reasoning
- Making causal models observable (e.g., via DAGs) provides intrinsic interpretability, though complexity may limit practical utility

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** Causality provides formal foundation for robust XAI explanations
- **Mechanism:** SCMs enable interventions and counterfactual reasoning beyond correlation
- **Core assumption:** Causal structure is known or reliably inferable
- **Evidence anchors:** SCMs used to frame CNNs and PDPs with causal inference properties
- **Break condition:** Misspecified or unidentifiable causal structures yield misleading explanations

### Mechanism 2
- **Claim:** XAI generates hypotheses about causal relationships
- **Mechanism:** Counterfactual explanations identify experimental manipulations to test
- **Core assumption:** XAI explanations sufficiently informative for meaningful directions
- **Evidence anchors:** Counterfactuals as imperfect guides to causal inference for scientific discovery
- **Break condition:** Spurious correlation-based XAI methods generate misleading hypotheses

### Mechanism 3
- **Claim:** Observable causal models intrinsically explain systems
- **Mechanism:** DAGs provide transparent representation of system logic
- **Core assumption:** DAG complexity remains manageable and interpretable
- **Evidence anchors:** Causal reasoning as component of XAI and explanation-based constructs
- **Break condition:** Complex DAGs with hundreds of variables negate interpretability benefits

## Foundational Learning

- **Concept: Directed Acyclic Graphs (DAGs)**
  - Why needed here: Graphical representation of causal structures essential for understanding relationships
  - Quick check question: What is the key property of a DAG that distinguishes it from other directed graphs?

- **Concept: Structural Causal Models (SCMs)**
  - Why needed here: Formalize causal relationships and enable interventions/counterfactual reasoning
  - Quick check question: How does an SCM represent the effect of an intervention on a variable?

- **Concept: Counterfactuals (causal vs. XAI sense)**
  - Why needed here: Distinguishing causal counterfactuals from XAI counterfactuals crucial for evaluation
  - Quick check question: What is the key difference between a causal counterfactual and a typical XAI counterfactual explanation?

## Architecture Onboarding

- **Component map:** Data layer -> Causal discovery layer -> SCM layer -> XAI layer -> Interface layer
- **Critical path:**
  1. Acquire data and domain knowledge
  2. Perform causal discovery to build DAG
  3. Fit SCM parameters
  4. Generate explanations using causal inference
  5. Visualize causal model and explanations
- **Design tradeoffs:**
  - Accuracy vs. interpretability: Complex causal models may be more accurate but harder to interpret
  - Data-driven vs. knowledge-driven: Balancing empirical data with expert domain knowledge
  - Generalizability vs. specificity: Causal models may be highly specific to domains
- **Failure signatures:**
  - Explanations unstable across runs or datasets
  - Causal discoveries yield multiple, conflicting models
  - DAG complexity overwhelms interpretability benefits
- **First 3 experiments:**
  1. Implement BN on small dataset (e.g., sprinkler-grass) and visualize DAG
  2. Apply causal discovery algorithm to real dataset and compare to domain knowledge
  3. Generate counterfactual explanations using SCM and evaluate stability vs. standard XAI

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** What specific methodologies can bridge causality and XAI to create truly explainable AI systems?
- **Basis in paper:** The paper identifies three perspectives suggesting causality is propaedeutic to XAI
- **Why unresolved:** Various approaches discussed but no definitive integration framework provided
- **What evidence would resolve it:** Development and validation of framework combining causal reasoning with XAI, demonstrating improved interpretability and robustness

### Open Question 2
- **Question:** How can XAI methods be leveraged to foster scientific exploration for causal inquiry?
- **Basis in paper:** XAI can serve as tool for identifying pursue-worthy experimental manipulations
- **Why unresolved:** Potential acknowledged but specific strategies and examples not detailed
- **What evidence would resolve it:** Case studies showing successful use of XAI in generating testable causal hypotheses and advancing scientific discovery

### Open Question 3
- **Question:** What are limitations of current XAI methods due to lack of causality?
- **Basis in paper:** Lack of causality identified as major limitation affecting robustness and trustworthiness
- **Why unresolved:** Problem identified but extent of impact on explanation quality not quantified
- **What evidence would resolve it:** Comparative studies demonstrating performance differences between XAI with and without causal foundations

## Limitations

- The conceptual framing of causality as "propaedeutic to XAI" relies heavily on theoretical arguments rather than empirical validation
- The claim that making causal models observable constitutes explanation itself lacks quantitative validation of interpretability benefits
- The review focuses primarily on Western academic literature, potentially missing important perspectives from other research communities

## Confidence

- **High confidence**: Identification of three distinct perspectives on causality-XAI relationships well-supported by literature review methodology
- **Medium confidence**: Assertion that causal tools can improve XAI explanation quality based primarily on theoretical frameworks
- **Low confidence**: Claim that XAI methods can effectively guide causal scientific exploration with limited empirical evidence

## Next Checks

1. Conduct controlled experiment comparing explanation stability and actionability between SCM-based XAI and traditional correlation-based XAI methods on benchmark datasets
2. Implement case study where XAI-generated hypotheses are empirically tested for causal validity in a real scientific domain
3. Perform user studies to quantify interpretability benefits (if any) of DAG visualization compared to standard XAI explanation techniques