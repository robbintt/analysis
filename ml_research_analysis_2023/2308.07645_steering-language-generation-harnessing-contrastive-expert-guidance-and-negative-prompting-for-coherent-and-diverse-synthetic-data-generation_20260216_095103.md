---
ver: rpa2
title: 'Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative
  Prompting for Coherent and Diverse Synthetic Data Generation'
arxiv_id: '2308.07645'
source_url: https://arxiv.org/abs/2308.07645
tags:
- data
- synthetic
- steer
- generation
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces STEER, a method for generating synthetic
  data that addresses the trade-off between coherency and diversity in text generation.
  STEER uses contrastive expert guidance and negative prompting to modify the sampling
  distribution during inference, guiding the model to produce coherent and diverse
  synthetic data.
---

# Steering Language Generation: Harnessing Contrastive Expert Guidance and Negative Prompting for Coherent and Diverse Synthetic Data Generation

## Quick Facts
- arXiv ID: 2308.07645
- Source URL: https://arxiv.org/abs/2308.07645
- Reference count: 19
- Outperforms existing methods in coherency and diversity metrics while achieving superior downstream performance

## Executive Summary
STEER is a method for generating synthetic data that addresses the trade-off between coherency and diversity in text generation. It uses contrastive expert guidance and negative prompting to modify the sampling distribution during inference, guiding the model to produce coherent and diverse synthetic data. The method operates at inference time and is architecture-agnostic. Experiments on three distinct tasks show that STEER outperforms existing methods in terms of coherency and diversity metrics, including normalized n-grams, diversity score, cosine similarity, MAUVE, and adversarial AUROC.

## Method Summary
STEER combines contrastive expert guidance with negative prompting to generate synthetic data that balances coherency and diversity. The method fine-tunes a base language model on real data to create a domain model, then modifies the sampling distribution during generation by emphasizing the difference between the fine-tuned and base model logits (contrastive guidance) and discouraging tokens present in previously generated examples (negative prompting). This approach operates at inference time without requiring additional training.

## Key Results
- STEER outperforms existing methods in coherency metrics (cosine similarity, MAUVE, adversarial AUROC)
- STEER achieves superior diversity scores compared to baselines while maintaining coherence
- STEER demonstrates better downstream performance in classification and question-answering tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Contrastive expert guidance improves semantic fidelity by increasing the probability of tokens favored by the fine-tuned domain model while decreasing those favored by the base model.
- Mechanism: The method subtracts a scaled version of the base model's logits from the fine-tuned model's logits during sampling, effectively regularizing generation toward domain-specific language patterns.
- Core assumption: The difference in token distributions between fine-tuned and base models captures meaningful domain characteristics that should be preserved in generation.
- Evidence anchors:
  - [abstract]: "contrastive expert guidance, where the difference between the logit distributions of fine-tuned and base language models is emphasised to ensure domain adherence"
  - [section]: "The contrastive objectivefPθ seeks to maximise the likelihood of the domain model's sequence, while minimising the likelihood of the same sequence under the base model's distribution"
  - [corpus]: Weak - no direct corpus evidence, but related work on contrastive decoding supports the principle

### Mechanism 2
- Claim: Negative prompting increases diversity by discouraging generation of tokens present in previously generated examples.
- Mechanism: The method modifies logits to downweight tokens found in a dynamic set of negative prompts, which includes tokens from both real and synthetic examples generated so far.
- Core assumption: The semantic content of generated text can be effectively controlled by suppressing individual tokens that appeared in prior examples.
- Evidence anchors:
  - [abstract]: "we utilise existing real and synthetic examples as negative prompts to the model"
  - [section]: "The negative prompt ¯c adjusts the next token's log probability, diminishing the likelihood of tokens found in ¯c"
  - [corpus]: Weak - limited corpus evidence, but related work on negative prompting in diffusion models supports the concept

### Mechanism 3
- Claim: The combination of contrastive guidance and negative prompting achieves a better balance between fidelity and diversity than either method alone.
- Mechanism: The final sampling distribution is a sum of the modified logits from both techniques, allowing each to influence generation in complementary ways.
- Core assumption: The effects of contrastive guidance (pushing toward domain characteristics) and negative prompting (pushing away from repetition) are orthogonal and can be combined additively.
- Evidence anchors:
  - [abstract]: "This delicate balancing act is achieved by dynamically moving towards or away from chosen representations in the latent space"
  - [section]: "This combination of contrastive expert guidance with negative prompting ensures a fine balance between adhering to the domain distribution and maintaining diversity"
  - [corpus]: Weak - no direct corpus evidence, but the ablation study results showing hyperparameter effects support the assumption

## Foundational Learning

- Concept: Fine-tuning transformer models on domain-specific data
  - Why needed here: STEER requires a fine-tuned domain model Pθ that captures the semantic characteristics of the target domain
  - Quick check question: What is the difference between the fine-tuned domain model Pθ and the base model Pϕ in terms of their training objectives?

- Concept: Logit manipulation and temperature scaling in autoregressive generation
  - Why needed here: STEER operates by modifying the logits before the softmax to reshape the token probability distribution
  - Quick check question: How does STEER's contrastive expert guidance modify the logits compared to standard contrastive decoding?

- Concept: Negative prompting and classifier-free guidance in diffusion models
  - Why needed here: STEER's negative prompting mechanism is conceptually similar to negative prompts in diffusion models, adapted for autoregressive generation
  - Quick check question: How does STEER's negative prompting mechanism differ from classifier-free guidance in diffusion models?

## Architecture Onboarding

- Component map: Base model Pϕ -> Fine-tuned domain model Pθ -> STEER inference algorithm (contrastive guidance + negative prompting) -> Generated synthetic data
- Critical path: Fine-tune Pϕ on real dataset Dr to create Pθ, then during generation at each step: compute logits from Pθ, apply contrastive expert guidance, apply negative prompting, combine results, sample next token
- Design tradeoffs: Main tradeoff is between fidelity (achieved through contrastive guidance) and diversity (achieved through negative prompting). Higher γ values increase fidelity but may reduce diversity, while higher η values increase diversity but may reduce fidelity.
- Failure signatures: If generated text is incoherent, contrastive guidance may be too strong (γ too high) or negative prompting may be suppressing valid domain vocabulary. If generated text is repetitive, negative prompting may be too weak (η too low).
- First 3 experiments:
  1. Generate text with STEER using only contrastive expert guidance (η=0) and vary γ to observe the effect on fidelity metrics.
  2. Generate text with STEER using only negative prompting (γ=0) and vary η to observe the effect on diversity metrics.
  3. Generate text with STEER using both mechanisms and perform an ablation study by systematically varying both γ and η to find the Pareto-optimal balance.

## Open Questions the Paper Calls Out

- Question: Does STEER's superior performance in synthetic data generation extend to other domains beyond astronomy, toxic comments, and commonsense reasoning?
- Question: How does the performance of STEER compare to other state-of-the-art synthetic data generation methods when applied to larger language models?
- Question: Can STEER be further improved by incorporating additional techniques for controlling the coherency-diversity trade-off?

## Limitations

- Generated synthetic data may lack semantic depth and plausibility despite achieving high diversity and coherence metrics
- STEER's effectiveness across diverse domains is demonstrated on three specific tasks, but broader generalizability is uncertain
- Computational overhead of maintaining and updating negative prompt sets during generation is not thoroughly analyzed

## Confidence

- **High confidence**: STEER's ability to improve diversity and coherence metrics compared to baselines
- **Medium confidence**: STEER's superior downstream performance in classification and question-answering tasks
- **Medium confidence**: The fine-grained control over coherency-diversity trade-off via hyperparameters γ and η

## Next Checks

1. Conduct comprehensive human preference studies comparing STEER-generated synthetic data with baseline methods across all three tasks, focusing on semantic depth, plausibility, and task-specific quality assessments.

2. Evaluate STEER on additional diverse datasets (e.g., legal documents, medical literature, creative writing) to assess its generalizability and identify potential domain-specific limitations or adjustments needed.

3. Measure and compare the wall-clock time and GPU memory usage of STEER against baseline methods during both training (fine-tuning) and inference (generation) phases, particularly examining the overhead of maintaining and updating negative prompt sets.