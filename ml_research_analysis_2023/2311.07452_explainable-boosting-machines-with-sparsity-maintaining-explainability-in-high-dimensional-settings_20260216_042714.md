---
ver: rpa2
title: Explainable Boosting Machines with Sparsity -- Maintaining Explainability in
  High-Dimensional Settings
arxiv_id: '2311.07452'
source_url: https://arxiv.org/abs/2311.07452
tags:
- lasso
- terms
- term
- data
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a method to improve the transparency and scoring
  efficiency of Explainable Boosting Machines (EBMs) in high-dimensional settings.
  EBMs, while competitive in accuracy and interpretability compared to black-box models,
  become less transparent and slower to score as the number of predictor variables
  increases.
---

# Explainable Boosting Machines with Sparsity -- Maintaining Explainability in High-Dimensional Settings

## Quick Facts
- arXiv ID: 2311.07452
- Source URL: https://arxiv.org/abs/2311.07452
- Reference count: 5
- This paper proposes a method to improve transparency and scoring efficiency of Explainable Boosting Machines in high-dimensional settings using LASSO post-processing.

## Executive Summary
Explainable Boosting Machines (EBMs) are highly interpretable models that achieve competitive accuracy compared to black-box models, but they become less transparent and slower to score as the number of predictor variables increases. This paper introduces a post-processing method that applies LASSO regularization to fitted EBM models to introduce sparsity by reweighting and removing less relevant model terms. The approach maintains the model's transparency while significantly reducing scoring time and model complexity, as demonstrated on two real-world datasets. The authors show that this method can retain comparable accuracy while achieving substantial improvements in efficiency and interpretability.

## Method Summary
The authors propose post-processing fitted EBMs using LASSO (Least Absolute Shrinkage and Selection Operator) regularization to introduce sparsity. After fitting an initial EBM model, they extract term contribution matrices from the model predictions, then apply LASSO regression to these contributions to identify and remove less relevant terms. The L1 penalty in LASSO drives some coefficients to zero, effectively removing their associated model terms. The method includes a non-negative constraint to preserve the original directional relationships of term contributions. The approach is implemented using standard LASSO libraries (glmnet in R or scikit-learn in Python) and involves scaling and sweeping operations to modify the original EBM model.

## Key Results
- Successfully reduced ALS dataset from 369 predictors to a much smaller number of terms while maintaining accuracy
- Demonstrated significant improvement in scoring time efficiency for high-dimensional models
- Maintained model transparency and interpretability after sparsity introduction
- Validated approach on two real-world datasets with different dimensionalities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LASSO post-processing of EBMs introduces sparsity by shrinking some term coefficients to zero.
- Mechanism: The L1 penalty in LASSO regression can drive some coefficients to exactly zero, effectively removing their associated model terms from the EBM.
- Core assumption: The term contributions from the initial EBM can be treated as independent features for LASSO regression.
- Evidence anchors:
  - [abstract]: "introduce sparsity by reweighting the individual model terms and removing the less relevant ones"
  - [section]: "the L1 penalty enforced by the LASSO, many of these coefficients can be estimated to be zero"
  - [corpus]: Weak evidence - corpus doesn't directly address LASSO application to EBMs
- Break condition: If the initial EBM terms are highly correlated, LASSO may arbitrarily select one and drop others, potentially harming model interpretability.

### Mechanism 2
- Claim: Post-processing maintains EBM transparency while reducing scoring time.
- Mechanism: By removing terms with zero coefficients, the simplified EBM has fewer calculations per prediction, speeding up inference while preserving the interpretable structure of individual term contributions.
- Core assumption: Each term's contribution to the prediction is independent and can be safely removed if its coefficient is zero.
- Evidence anchors:
  - [abstract]: "allowing these models to maintain their transparency and relatively fast scoring times in higher-dimensional settings"
  - [section]: "reduce the model's complexity and drastically improve scoring time"
  - [corpus]: Weak evidence - corpus focuses on general EBM interpretability but not scoring time optimization
- Break condition: If terms are interdependent (e.g., interaction effects), removing one may distort the meaning of others.

### Mechanism 3
- Claim: Non-negative LASSO constraint preserves the original direction of term contributions.
- Mechanism: Forcing coefficients to be non-negative ensures that term contributions maintain their original directional relationship to the outcome.
- Core assumption: The original EBM's sign convention is meaningful and should be preserved.
- Evidence anchors:
  - [section]: "it seems intuitive to also force the LASSO coefficients be strictly non-negative"
  - [section]: "This approach is referred to as the non-negative LASSO"
  - [corpus]: Weak evidence - corpus doesn't discuss sign constraints in LASSO
- Break condition: If the optimal model requires some terms to have negative coefficients to balance other effects, non-negativity may reduce accuracy.

## Foundational Learning

- Concept: Gradient boosting machine mechanics
  - Why needed here: EBMs are based on gradient boosting, and understanding the boosting process helps explain why EBMs include a term for every feature
  - Quick check question: In gradient boosting, what happens during each iteration when fitting to residuals?

- Concept: LASSO regularization and the L1 penalty
  - Why needed here: The core sparsity mechanism relies on understanding how L1 penalty drives coefficients to zero
  - Quick check question: How does L1 regularization differ from L2 in terms of coefficient shrinkage?

- Concept: GAMs (Generalized Additive Models) and shape functions
  - Why needed here: EBMs are a type of GAM, and the shape functions represent non-linear relationships that LASSO is reweighting
  - Quick check question: What is the advantage of modeling each feature with its own shape function rather than assuming linearity?

## Architecture Onboarding

- Component map: EBM fit -> Term contribution extraction -> LASSO path fitting -> Model editing -> Performance evaluation
- Critical path: EBM fit → Term contributions → LASSO fit → Model edit → Performance check
- Design tradeoffs:
  - Trade-off between model simplicity and accuracy when selecting λ
  - Non-negative constraint may improve interpretability but could reduce accuracy
  - Using test data for LASSO fitting introduces data leakage
- Failure signatures:
  - Too few terms selected → Underfitting, high bias
  - Too many terms selected → No simplification benefit
  - Negative coefficients (if non-negative constraint removed) → Possible direction reversal in term effects
- First 3 experiments:
  1. Fit EBM on ALS data, extract term contributions, run LASSO with different λ values, plot MSE vs. number of terms
  2. Compare original EBM vs. post-processed EBM on test set (MSE, scoring time, term count)
  3. Apply non-negative LASSO vs. regular LASSO and measure impact on accuracy and interpretability

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the LASSO-based post-processing affect model performance when applied to EBMs with a larger number of interaction terms?
- Basis in paper: [inferred] The paper suggests that the LASSO approach can be generalized to include pairwise interaction terms, but does not provide empirical evidence for its effectiveness in such cases.
- Why unresolved: The paper's examples focus on models with a limited number of interaction terms, leaving uncertainty about the method's scalability and performance with more complex models.
- What evidence would resolve it: Empirical studies comparing model performance before and after LASSO post-processing for EBMs with varying numbers of interaction terms, especially in high-dimensional settings.

### Open Question 2
- Question: What are the implications of using the LASSO approach for model interpretability in terms of the trade-off between sparsity and accuracy?
- Basis in paper: [explicit] The paper discusses the reduction in model complexity and improvement in scoring efficiency but does not extensively explore the interpretability implications of the sparsity introduced by the LASSO.
- Why unresolved: While the paper mentions maintaining transparency and explainability, it does not delve into how the reduced number of terms affects the interpretability of the model's predictions.
- What evidence would resolve it: Comparative studies assessing the interpretability of EBMs before and after LASSO post-processing, focusing on how the reduced model terms impact the clarity and comprehensibility of the model's explanations.

### Open Question 3
- Question: How does the choice of the LASSO regularization parameter (λ) impact the balance between model complexity and prediction accuracy?
- Basis in paper: [inferred] The paper mentions the use of cross-validation or an independent test set to select the optimal λ but does not provide detailed analysis on how different λ values affect the model's performance and complexity.
- Why unresolved: The impact of λ on the trade-off between sparsity and accuracy is not thoroughly explored, leaving questions about the optimal choice of λ for different datasets and model complexities.
- What evidence would resolve it: Experimental results showing the performance of EBMs with LASSO post-processing across a range of λ values, including metrics on model accuracy, sparsity, and interpretability.

## Limitations
- Limited empirical validation on only two datasets without extensive ablation studies
- Potential data leakage from using test data for LASSO coefficient estimation
- No comparison with alternative feature selection methods for EBM post-processing

## Confidence
- Medium for sparsity mechanism
- Medium for scoring time claims
- Low for interpretability preservation

## Next Checks
1. Re-run experiments with nested cross-validation to avoid data leakage from using test data in LASSO fitting.
2. Compare LASSO-based sparsity with other feature selection methods (e.g., stepwise selection, random forests importance) on the same datasets.
3. Analyze the correlation structure of EBM terms to assess whether LASSO arbitrarily selects among correlated terms, potentially harming interpretability.