---
ver: rpa2
title: Gradient Estimation for Unseen Domain Risk Minimization with Pre-Trained Models
arxiv_id: '2302.01497'
source_url: https://arxiv.org/abs/2302.01497
tags:
- generalization
- pre-trained
- domain
- gradient
- domains
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of domain generalization by
  proposing a new method called GESTUR that leverages large-scale pre-trained models.
  The core idea is to estimate unobservable gradients that minimize risks in unseen
  domains, thereby relieving the gradient bias towards source domains.
---

# Gradient Estimation for Unseen Domain Risk Minimization with Pre-Trained Models

## Quick Facts
- **arXiv ID**: 2302.01497
- **Source URL**: https://arxiv.org/abs/2302.01497
- **Reference count**: 40
- **Primary result**: Proposes GESTUR method that estimates unobservable gradients using pre-trained models to minimize risks in unseen domains, achieving state-of-the-art performance on DomainBed benchmark

## Executive Summary
This paper addresses the challenge of domain generalization by proposing GESTUR, a method that leverages large-scale pre-trained models to estimate unobservable gradients for unseen domains. The core innovation is a two-expert architecture where a Task Expert learns task-specific knowledge from source domains while a Generalization Expert preserves the pre-trained model's generalization ability through exponential moving average (EMA). By estimating gradients that minimize risks in unseen domains and using them to adjust the biased gradients of the Task Expert, GESTUR effectively reduces gradient bias toward source domains. Extensive experiments on five domain generalization benchmarks demonstrate that GESTUR outperforms baseline methods, particularly when using larger pre-trained models like CLIP and SWAG.

## Method Summary
GESTUR employs a two-expert architecture consisting of a Task Expert (TE) and a Generalization Expert (GE), both initialized from the same pre-trained model. TE learns task-specific knowledge directly from source domains, while GE learns indirectly through EMA updates from TE while preserving generalization. The key innovation is that GE estimates unobservable gradients (the difference between GE and TE parameters) which are then used to adjust TE's biased gradients. This gradient adjustment relieves the bias toward source domains, allowing the model to generalize better to unseen domains. The final model is GE, which has learned task-specific knowledge while maintaining the pre-trained model's generalization ability.

## Key Results
- GESTUR outperforms baseline methods on all five DomainBed benchmark datasets (PACS, VLCS, OfficeHome, TerraIncognita, DomainNet)
- Performance gap between GESTUR and ERM increases with larger pre-trained models, with CLIP and SWAG showing significant improvements over ResNet-50
- Linear probing experiments show GESTUR preserves pre-trained model generalization while learning task-specific knowledge
- Gradient conflict analysis demonstrates that GESTUR reduces the proportion of conflicting gradients between source and unseen domains

## Why This Works (Mechanism)

### Mechanism 1
GESTUR reduces gradient bias toward source domains by estimating unobservable gradients that minimize risks in unseen domains. The method uses two experts - a Task Expert (TE) and a Generalization Expert (GE). TE learns task-specific knowledge from source domains directly, while GE learns indirectly via EMA from TE while preserving generalization. GE estimates unobservable gradients (gu) as the difference between GE and TE parameters, which are then added to TE's biased gradients to relieve bias. Core assumption: Large-scale pre-trained models can act as a loose approximation of the oracle model for unseen domains, and their generalization ability can be preserved while learning task-specific knowledge.

### Mechanism 2
EMA between TE and GE preserves generalization ability while allowing task-specific knowledge transfer. GE parameters are updated via EMA with TE parameters: θGE = mθGE + (1-m)θTE, where m is the moving average coefficient. This slow parameter change preserves generalization while allowing knowledge transfer. Core assumption: EMA provides a stable way to transfer knowledge without introducing harmful gradient bias that would degrade generalization.

### Mechanism 3
The gradient scale factor λ controls how much the estimated unobservable gradients influence TE's optimization, with larger pre-trained models requiring larger λ. The estimated gradient gu is scaled by λ∥gf∥2/∥gu∥2 before being added to TE's gradient. Larger pre-trained models act as better approximations of the oracle model, so their gradient estimates should have more influence. Core assumption: Larger pre-trained models act as better approximations of the oracle model, so their gradient estimates should have more influence.

## Foundational Learning

- **Domain Generalization**: Learning models that perform well on unseen domains without access to target domain data during training. Why needed: This paper specifically addresses domain generalization using pre-trained models, so understanding the problem setup and evaluation protocols (like DomainBed) is essential. Quick check: What is the key difference between domain adaptation and domain generalization?

- **Gradient Bias**: When optimization gradients are computed only from source domains, they may not represent the true gradients needed for unseen domains. Why needed: The core innovation addresses gradient bias by estimating gradients for unseen domains using pre-trained models. Quick check: Why does fine-tuning pre-trained models on source domains introduce gradient bias?

- **Exponential Moving Average (EMA)**: A technique for maintaining model parameters that change slowly over time by averaging with previous parameters. Why needed: EMA is used to transfer knowledge from TE to GE while preserving GE's generalization ability. Quick check: How does EMA help in maintaining generalization compared to direct parameter updates?

## Architecture Onboarding

- **Component map**: Source domain data → TE gradient computation → TE parameter update → GE EMA update → GE gradient estimation → TE gradient adjustment → TE parameter update (loop)

- **Critical path**: Source domain data flows through TE to learn task-specific knowledge, while GE updates via EMA and estimates unobservable gradients that are fed back to adjust TE's gradients, creating a feedback loop that relieves gradient bias.

- **Design tradeoffs**: Using EMA vs direct fine-tuning preserves generalization but may slow task-specific learning; estimating vs directly computing gradients avoids need for target domain data but relies on pre-trained model quality; two-expert architecture provides separation of concerns but doubles computational cost.

- **Failure signatures**: Poor performance on source domains indicates TE isn't learning task-specific knowledge effectively; no improvement over ERM suggests estimated gradients aren't relieving bias or pre-trained model isn't good approximation; GE performs worse than TE indicates EMA is failing to preserve generalization or knowledge transfer is harmful.

- **First 3 experiments**:
  1. Implement basic GESTUR architecture with RN50 on PACS dataset, test with different λ values (0.01, 0.05, 0.1, 0.5)
  2. Compare GESTUR w/ TE vs GESTUR w/ GE on VLCS dataset to verify EMA's role in preserving generalization
  3. Analyze gradient conflict reduction by computing cosine similarity between true and estimated unobservable gradients during training

## Open Questions the Paper Calls Out

### Open Question 1
How can the method be adapted to handle cases where the pre-trained model has not encountered data from the target unseen domain during its pre-training phase? The paper acknowledges this limitation, stating that when unseen domains that pre-trained models did not encounter are given, the pre-trained models might not act as an approximation of the oracle model of the domains.

### Open Question 2
What is the theoretical justification for using EMA to transfer knowledge from TE to GE, and how does it compare to other knowledge transfer methods in terms of preserving generalization ability? While EMA is shown to work empirically, there is no theoretical analysis comparing its effectiveness to other knowledge transfer techniques in preserving generalization while learning task-specific knowledge.

### Open Question 3
How does the performance of GESTUR scale with increasingly larger pre-trained models, and is there a point of diminishing returns? The paper observes that the performance gap between the proposed method and ERM increases as the size of the pre-trained model increases, but it does not explore whether this trend continues indefinitely or plateaus.

## Limitations
- Heavy dependency on pre-trained models as approximations of oracle models for unseen domains, which may fail when target domains differ significantly from web-crawled data
- No theoretical guarantees about the quality of estimated unobservable gradients or their effectiveness in relieving gradient bias
- Requires extensive hyperparameter tuning, particularly for the gradient scale factor λ which varies significantly across different pre-trained models

## Confidence

**High Confidence**: Experimental results showing GESTUR outperforming ERM and other domain generalization methods on multiple benchmarks. The ablation studies demonstrating the importance of both TE and GE components are well-supported.

**Medium Confidence**: The claim that larger pre-trained models act as better approximations of oracle models, requiring larger gradient scale factors. While supported by empirical evidence, this relationship needs more theoretical justification.

**Low Confidence**: The assertion that GESTUR successfully preserves pre-trained model generalization ability while learning task-specific knowledge. The evidence is primarily empirical and doesn't fully explain the mechanism by which EMA prevents overfitting to source domains.

## Next Checks

1. **Cross-dataset Generalization Test**: Evaluate GESTUR on datasets where pre-trained models have minimal exposure during training (e.g., medical imaging datasets) to test the limits of the pre-trained model approximation assumption.

2. **Gradient Estimation Quality Analysis**: Systematically measure the cosine similarity between estimated and true unobservable gradients across different dataset pairs and pre-trained model sizes to quantify estimation accuracy.

3. **EMA Coefficient Sensitivity Study**: Conduct an extensive grid search over EMA coefficients (m values) across all five benchmark datasets to identify optimal ranges and test the robustness of the generalization preservation mechanism.