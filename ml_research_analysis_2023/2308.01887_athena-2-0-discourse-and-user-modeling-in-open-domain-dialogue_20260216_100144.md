---
ver: rpa2
title: 'Athena 2.0: Discourse and User Modeling in Open Domain Dialogue'
arxiv_id: '2308.01887'
source_url: https://arxiv.org/abs/2308.01887
tags:
- user
- athena
- response
- topic
- dialogue
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Athena 2.0 is UCSC's conversational agent for Amazon's Alexa Prize
  Socialbot Grand Challenge 4. It uses a novel knowledge-grounded discourse model
  that tracks entity links and constraints named-entity recognition, linking, and
  coreference resolution.
---

# Athena 2.0: Discourse and User Modeling in Open Domain Dialogue

## Quick Facts
- **arXiv ID:** 2308.01887
- **Source URL:** https://arxiv.org/abs/2308.01887
- **Reference count:** 40
- **Key outcome:** Athena 2.0 achieves 15% improvement in NER/NEL and 30% over DBPedia Spotlight, with rule-based coreference at 69.93% F1, and board games/hobbies as highest-rated topics.

## Executive Summary
Athena 2.0 is UCSC's conversational agent for Amazon's Alexa Prize Socialbot Grand Challenge 4, integrating a novel knowledge-grounded discourse model with user modeling to improve open-domain dialogue. The system tracks entity mentions and constraints named-entity recognition, linking, and coreference resolution using contextual information stored in a discourse state table. It employs a hybrid response generation architecture combining scripted flow-based, knowledge-grounded, and neural methods, alongside a user model that personalizes topic selection and responses over multiple conversations. Athena demonstrates improved engagement, coherence, and personalization, achieving notable performance gains in entity tracking and user satisfaction.

## Method Summary
Athena 2.0's architecture comprises an automatic speech recognition (ASR) module, a natural language understanding (NLU) module with topic and intent detection, a dialogue manager, and a text-to-speech (TTS) module. The dialogue manager includes a discourse model that tracks entities, pronouns, and topics across turns, enabling constrained named-entity recognition and linking (NER/NEL) and coreference resolution. Response generators include flow-based RGs for scripted dialogues, knowledge-grounded RGs for factual responses from Wikidata, centering RGs for topical variety, and neural RGs for open-ended generation. The user model personalizes topic selection by accumulating user preferences over multiple conversations. The system is trained on synthetic data for NER/NEL, uses annotated coreference data, and is evaluated through A/B testing and standard NLP metrics.

## Key Results
- 15% improvement in NER/NEL accuracy over previous Athena versions
- 30% improvement in NER/NEL over DBPedia Spotlight baseline
- Rule-based coreference model achieves 69.93% F1 score, outperforming neural baselines

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Athena 2.0's discourse model improves entity tracking by constraining NER/NEL and coreference resolution to the dialogue context.
- Mechanism: The discourse model stores and updates entity mentions, their types, and speaker information, which downstream modules use to filter and rank entity candidates.
- Core assumption: Context-specific entity information is more discriminative than global popularity or gazetteer matching alone.
- Evidence anchors:
  - [abstract] "Athena 2.0 utilizes a novel knowledge-grounded discourse model that tracks the entity links that Athena introduces into the dialogue, and uses them to constrain named-entity recognition and linking, and coreference resolution."
  - [section 3.1] "The discourse model facilitates information sharing by storing its data in a state table that is accessible to all Athena modules."
  - [corpus] "Enhancing Dialogue Systems with Discourse-Level Understanding Using Deep Canonical Correlation Analysis" (weak correlation to Athena's discourse model, mainly thematic overlap).
- Break condition: If the discourse model is not updated correctly or the state table is inaccessible to downstream modules, the constraining benefit disappears.

### Mechanism 2
- Claim: Athena's hybrid Flow-RG and KG-RG architecture supports both structured and open-ended conversation generation.
- Mechanism: Flow-RGs provide scripted, context-aware transitions and multi-turn dialogue paths, while KG-RGs inject knowledge from Wikidata to ground responses in real facts.
- Core assumption: Combining rule-based flow control with knowledge-grounded generation yields richer and more coherent dialogues than either approach alone.
- Evidence anchors:
  - [section 5.1] "Flow-based RGs... lack somewhat in robustness, and requiring a great deal of handcrafting, call-flows are still the most reliable way to generate contextually appropriate responses in a dialogue system."
  - [section 5.2] "Our KG RGs are created using Wikidata... Each topic attempts to continue the conversation by either responding with a fact about the entity which was mentioned in the previous turn."
  - [corpus] "Beyond Task-Oriented and Chitchat Dialogues: Proactive and Transition-Aware Conversational Agents" (weak correlation, thematic but not architectural alignment).
- Break condition: If the Flow-RGs become too rigid or the KG-RGs fail to retrieve relevant facts, the hybrid balance collapses.

### Mechanism 3
- Claim: The user model personalizes topic selection and response generation, improving engagement.
- Mechanism: User model accumulates preferences, interests, and history over multiple conversations, then biases topic selection and tailors responses accordingly.
- Core assumption: Personalized dialogue increases user engagement compared to generic topic selection.
- Evidence anchors:
  - [section 6] "We build a user model incrementally over multiple conversations with each user... The user model promotes topics that it believes users are most likely interested in hearing about without needing to explicitly ask for their input."
  - [section 7] "In live A/B testing we have seen a statistically significant improvement in user rating when comparing our personalized topic selection strategy against our default topic selection strategy."
  - [corpus] "Let's Get Personal: Personal Questions Improve SocialBot Performance in the Alexa Prize" (strong thematic correlation, reinforcing the user model approach).
- Break condition: If the user model accumulates incorrect or noisy data, personalization can backfire and reduce engagement.

## Foundational Learning

- Concept: Named Entity Recognition and Linking (NER/NEL)
  - Why needed here: To identify and link entity mentions in user utterances to knowledge graph entities, enabling knowledge-grounded responses.
  - Quick check question: How does the discourse model improve NER/NEL accuracy compared to using only a gazetteer and popularity ranking?

- Concept: Coreference Resolution
  - Why needed here: To resolve pronouns and anaphoric expressions to the correct entity mentions, ensuring coherence across turns.
  - Quick check question: Why does Athena use a rule-based coreference model before the neural one, and how do they interact?

- Concept: Dialogue Acts and Response Ranking
  - Why needed here: To classify user intents and rank candidate responses for coherence and engagement.
  - Quick check question: What features from the discourse model are used by the response ranker to maintain entity-based coherence?

## Architecture Onboarding

- Component map: ASR -> NLU (topic/intent + discourse model) -> Dialogue Manager (action/constraint/topic/initiative/RG dispatcher/response ranker) -> Response Generators (Flow-RG, KG-RG, Center RG, Neural RG) -> TTS
- Critical path: User utterance -> NLU -> Discourse Model update -> Action Manager -> Constraint Manager -> RG Dispatcher -> Response Pool -> Response Ranker -> Response Builder -> TTS
- Design tradeoffs: Flow-RGs offer high coherence but low flexibility; KG-RGs provide factual depth but may stall if facts run out; Neural RGs offer variety but are slower and less controllable; Centering RGs supply topical variety but may lack deep coherence.
- Failure signatures: Low-rated responses from red question/goodbye RGs indicate adversarial users; empty response pools trigger fallback; coherence failures show up as repeated or irrelevant responses.
- First 3 experiments:
  1. Verify discourse model state consistency after each user turn.
  2. Test RG dispatcher correctly selects RGs given action/constraint combinations.
  3. Run response ranker on a small candidate pool and check ranking aligns with annotated quality.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the impact of using a finer-grained dialogue act scheme compared to the coarse-grained approach on the quality of generated responses?
- Basis in paper: [explicit] The paper discusses using a more discriminative set of dialogue acts compared to the 11 coarse-grained tags in the PD-NRG approach.
- Why unresolved: The paper mentions the hypothesis but does not provide experimental results comparing the two approaches.
- What evidence would resolve it: Conduct an experiment comparing the quality of responses generated using the fine-grained and coarse-grained dialogue act schemes.

### Open Question 2
- Question: How does the performance of the Discourse Driven Neural Response Generator (DD-NRG) compare to Athena's current response generation methods in terms of user satisfaction?
- Basis in paper: [explicit] The paper evaluates DD-NRG on metrics like coherence, making sense, and taking conversation forward, but does not compare it directly to Athena's existing methods.
- Why unresolved: The paper does not provide a direct comparison between DD-NRG and Athena's current response generation methods in terms of user satisfaction.
- What evidence would resolve it: Conduct a user study comparing user satisfaction with responses generated by DD-NRG and Athena's current methods.

### Open Question 3
- Question: What are the limitations of the rule-based coreference resolution model, and how can they be addressed?
- Basis in paper: [explicit] The paper mentions that the rule-based model is heavily dependent on the quality of information in the discourse model and may not handle unpredictable conversation flows or pronouns referring to entities within the user's current utterance.
- Why unresolved: The paper does not provide a detailed analysis of the limitations of the rule-based model or potential solutions.
- What evidence would resolve it: Conduct an error analysis of the rule-based model's performance and explore alternative approaches, such as neural models or ensemble methods, to address the identified limitations.

## Limitations
- Exact contribution of each discourse component to overall performance is not isolated in ablation studies.
- Reliance on AWS infrastructure and proprietary tools creates deployment and reproducibility challenges.
- Coreference resolution model may not scale well to highly complex or ambiguous dialogues.

## Confidence

- **High confidence**: The architecture and flow of Athena 2.0, including the modular dialogue manager and response generation pipeline, are clearly specified and internally consistent.
- **Medium confidence**: The reported performance improvements in NER/NEL and coreference resolution are supported by quantitative results, but lack detailed ablation or cross-validation to isolate contributing factors.
- **Low confidence**: The user model's personalization effectiveness and the long-term engagement benefits of the discourse model are not fully demonstrated due to limited live testing data and lack of demographic or topic-level analysis.

## Next Checks

1. Conduct ablation studies to measure the marginal impact of the discourse model on NER/NEL and coreference accuracy, isolating contributions from entity tracking, pronoun resolution, and topic history.
2. Evaluate coreference resolution performance on a broader set of real user utterances, including complex and ambiguous cases, to assess robustness beyond the test set.
3. Analyze user model personalization benefits across different user demographics and topic categories, identifying scenarios where personalization is most and least effective.