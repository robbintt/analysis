---
ver: rpa2
title: Penalising the biases in norm regularisation enforces sparsity
arxiv_id: '2303.01353'
source_url: https://arxiv.org/abs/2303.01353
tags:
- norm
- lemma
- equation
- when
- function
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the sparsity of solutions obtained by neural
  networks when the parameters' norm is penalized. It shows that penalizing the norm
  of bias terms in the regularizer leads to unique and sparse solutions, while omitting
  the bias norm allows for non-sparse solutions.
---

# Penalising the biases in norm regularisation enforces sparsity

## Quick Facts
- arXiv ID: 2303.01353
- Source URL: https://arxiv.org/abs/2303.01353
- Reference count: 40
- Key outcome: Penalizing bias terms in norm regularization enforces sparsity in neural network solutions by adding a √(1+x²) weighting factor that makes the representational cost sensitive to function shifts

## Executive Summary
This paper investigates how penalizing the norm of bias terms in neural network regularization affects the sparsity of learned solutions. The authors show that including bias penalties in the regularizer leads to unique and sparse solutions, characterized by a total variation functional with a √(1+x²) weighting factor. This weighting enforces sparsity in the number of kinks (ReLU neurons) in the minimal norm interpolator. The paper provides theoretical characterization and empirical validation through toy examples, demonstrating that penalizing bias terms is crucial for obtaining sparse estimators when training neural networks.

## Method Summary
The paper uses a dynamic programming approach to characterize minimal norm interpolators for one-hidden ReLU layer networks with unidimensional data. The method involves computing the representational cost R₁(f) = ∫|√(1+x²)f''(x)|dx and formulating the problem as a dynamic program with state variables representing slopes at each data point. The authors prove that penalizing biases adds the √(1+x²) multiplicative weight in the total variation, which enforces uniqueness and sparsity of the minimal norm interpolator. Experiments compare the number of kinks in solutions obtained with and without bias penalization.

## Key Results
- Penalizing bias terms in the regularizer adds a √(1+x²) weighting factor to the total variation functional
- This weighting enforces uniqueness and sparsity of the minimal norm interpolator in the number of kinks
- Omitting bias penalty allows non-sparse solutions with many kinks
- The minimal parameters' norm needed to represent a function is characterized by the weighted total variation of its second derivative

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Penalizing the bias terms in the norm regularization enforces sparsity in the number of kinks (ReLU neurons) in the minimal norm interpolator.
- Mechanism: The representational cost R₁(f) includes a weighting factor √(1+x²) for the second derivative f''. When bias terms are penalized, this weighting term appears, favoring solutions with fewer kinks. Without bias penalty, this weighting disappears, allowing non-sparse solutions with many kinks.
- Core assumption: The minimal norm interpolator is unique and corresponds to the trained network when using small regularization parameters.
- Evidence anchors:
  - [abstract]: "This additional weighting is of utmost significance as it is shown in this work to enforce uniqueness and sparsity (in number of kinks) of the minimal norm interpolator."
  - [section]: Theorem 1 states that penalizing biases adds a √(1+x²) multiplicative weight in the total variation, while [section 5] shows this leads to unique and sparse solutions.
  - [corpus]: No direct evidence, but related work on implicit regularization supports the connection between norm regularization and sparsity.
- Break condition: If the implicit regularization during training doesn't treat bias and weight parameters equally, the sparsity advantage may disappear.

### Mechanism 2
- Claim: The weighting factor √(1+x²) in the representational cost makes the norm sensitive to function shifts, unlike when biases are ignored.
- Mechanism: When bias terms are penalized, the representational cost is not shift invariant. This property is crucial for the analysis technique that proves uniqueness and sparsity of the minimal norm interpolator.
- Core assumption: The representational cost characterizes the minimal parameters' norm needed to represent a function.
- Evidence anchors:
  - [abstract]: "This weighting factor disappears when the norm of bias terms is not regularised."
  - [section]: The paper notes that without bias penalty, "the representational cost is given by the total variation of f''" without the √(1+x²) factor.
  - [corpus]: No direct evidence, but the concept of shift invariance in function spaces is well-established.
- Break condition: If the function to be represented has specific properties that make shift invariance irrelevant, this mechanism may not apply.

### Mechanism 3
- Claim: The minimal norm interpolator has at most one kink per activation cone, and under certain data assumptions, it is among the sparsest interpolators.
- Mechanism: Lemma 1 shows that minimal norm interpolators have at most n-1 kinks. Theorem 3 proves that under Assumption 1 (no convex regions with ≥6 points), the minimal norm interpolator is among the sparsest.
- Core assumption: The data points are ordered (x₁ < x₂ < ... < xₙ) and satisfy Assumption 1.
- Evidence anchors:
  - [abstract]: "Conversely, omitting the bias' norm allows for non-sparse solutions."
  - [section]: Lemma 4 and Theorem 3 provide the mathematical framework for sparse recovery.
  - [corpus]: No direct evidence, but sparse recovery in deconvolution problems is related.
- Break condition: If the data has convex regions with ≥6 points, the minimal norm interpolator may not be sparse.

## Foundational Learning

- Concept: Dynamic programming with continuous state space
  - Why needed here: Lemma 2 recasts the minimization problem as a dynamic program with state variables sᵢ representing slopes at each data point. This reformulation is crucial for proving uniqueness and sparsity properties.
  - Quick check question: Can you explain how the dynamic program formulation in Lemma 2 simplifies the analysis of minimal norm interpolators?

- Concept: Total variation of the second derivative as a functional norm
  - Why needed here: Theorem 1 characterizes the representational cost R₁(f) as the total variation of √(1+x²)f'', weighted by the bias penalty. This functional norm quantifies the minimal parameters' norm needed to represent a function.
  - Quick check question: How does the √(1+x²) weighting in Theorem 1 affect the representational cost compared to when biases are not penalized?

- Concept: ReLU activation cones and their properties
  - Why needed here: The analysis relies on partitioning the parameter space into activation cones (Cᵢ) and showing that minimal norm interpolators have at most one kink per cone. This geometric interpretation is key to proving sparsity.
  - Quick check question: Can you describe how the activation cones Cᵢ are defined and why minimal norm interpolators have at most one kink per cone?

## Architecture Onboarding

- Component map:
  - Neural network representation: f_θ(x) = a₀x + b₀ + Σⱼ₌₁ᵐ aⱼσ(wⱼx + bⱼ)
  - Representational cost: R₁(f) = ∫|√(1+x²)f''(x)|dx
  - Dynamic program: sᵢ represents slope at xᵢ, with cost functions cᵢ and gᵢ
  - Sparsity condition: Assumption 1 on data points' arrangement

- Critical path:
  1. Characterize representational cost with bias penalty (Theorem 1)
  2. Show existence of minimal norm interpolator (Lemma 1)
  3. Reformulate as dynamic program (Lemma 2)
  4. Prove uniqueness and sparsity (Theorems 2 and 3)

- Design tradeoffs:
  - Including bias penalty: Enforces sparsity but may lead to underfitting (Goodfellow et al., 2016)
  - Ignoring bias penalty: Allows non-sparse solutions, potentially overfitting
  - Dynamic programming approach: Simplifies analysis but requires careful handling of continuous state space

- Failure signatures:
  - Non-unique minimal norm interpolator: Indicates insufficient bias penalty or violation of data assumptions
  - Non-sparse solution: Suggests bias penalty is too weak or data has large convex regions
  - Computational issues: May arise from discretizing continuous state space in dynamic program

- First 3 experiments:
  1. Train a one-hidden ReLU layer network with and without bias penalty on a simple toy dataset. Compare number of kinks in the final estimator.
  2. Generate synthetic data with known convex regions. Verify if the minimal norm interpolator is sparse under Assumption 1.
  3. Vary the regularization strength and observe its effect on sparsity and generalization performance.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the sparsity result of Theorem 3 be extended to cases with convex regions of more than 6 points?
- Basis in paper: [inferred] The paper states that Theorem 3 requires Assumption 1, which assumes no convex regions with at least 6 points. It mentions that the minimal norm interpolator is rarely among the sparsest interpolators for large convex regions with 35 points, and its number of kinks could be arbitrarily close to the trivial upper bound.
- Why unresolved: The paper only provides a counterexample for 6 points and states it becomes much harder to derive conditions for sparse recovery with more than 6 points.
- What evidence would resolve it: A mathematical proof showing either the sparsity result holds or fails for convex regions with more than 6 points.

### Open Question 2
- Question: Does the empirical similarity between weight decay (no bias penalization) and ℓ2 regularization (including biases) arise from implicit regularization that treats bias and weight parameters similarly?
- Basis in paper: [explicit] The paper conjectures that the empirical similarity between weight decay and ℓ2 regularization might be explained by implicit regularization, which still occurs and takes the bias terms into account.
- Why unresolved: The paper only states this as a conjecture and mentions that theoretical results on implicit bias focus on unregularized training.
- What evidence would resolve it: Empirical studies comparing the implicit regularization effects of weight decay and ℓ2 regularization on bias and weight parameters.

### Open Question 3
- Question: Can the characterization of minimal norm interpolators be extended to multivariate functions or classification problems?
- Basis in paper: [explicit] The paper mentions that characterizing minimal norm interpolators seems very challenging in the multivariate case and that extending results to classification problems might help understand differences between regression and classification.
- Why unresolved: The paper only discusses the univariate case and does not provide a solution for multivariate or classification settings.
- What evidence would resolve it: Mathematical proofs characterizing minimal norm interpolators for multivariate functions or classification problems.

## Limitations
- Analysis limited to one-hidden layer ReLU networks with unidimensional inputs
- Sparsity properties rely on specific data assumptions (Assumption 1) that may not always hold
- Empirical validation limited to toy examples, lacking extensive experiments on real-world datasets

## Confidence
- Theoretical claims: High
- Practical implications and generalizability: Medium

## Next Checks
1. **Empirical validation on real-world datasets**: Test the sparsity claims on diverse real-world regression tasks to assess practical relevance.
2. **Scalability analysis**: Investigate the computational complexity of the dynamic programming approach and explore efficient approximations for larger networks.
3. **Robustness to data assumptions**: Systematically study how violations of Assumption 1 affect the sparsity properties and identify scenarios where the results may break down.