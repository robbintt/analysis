---
ver: rpa2
title: Transferable Adversarial Robustness for Categorical Data via Universal Robust
  Embeddings
arxiv_id: '2306.04064'
source_url: https://arxiv.org/abs/2306.04064
tags:
- adversarial
- training
- robust
- embeddings
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of achieving adversarial robustness
  for machine learning models applied to tabular data containing categorical features.
  The authors propose a novel approach that enables adversarial training for neural
  networks on categorical data and transfers this robustness to other classifiers
  like decision trees and random forests through universal robust embeddings.
---

# Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings

## Quick Facts
- arXiv ID: 2306.04064
- Source URL: https://arxiv.org/abs/2306.04064
- Reference count: 15
- This paper proposes a method for achieving adversarial robustness for machine learning models on tabular data with categorical features, enabling transfer of this robustness to decision trees and random forests through universal robust embeddings.

## Executive Summary
This paper addresses the challenge of achieving adversarial robustness for machine learning models applied to tabular data containing categorical features. The authors propose a novel approach that enables adversarial training for neural networks on categorical data and transfers this robustness to other classifiers like decision trees and random forests through universal robust embeddings. Their method involves continuous relaxation of the discrete optimization problem, using projected gradient descent with a cost-aware threat model that reflects real-world financial constraints on adversaries. The proposed bilevel alternating minimization framework produces robust embeddings that significantly outperform existing techniques in terms of both robustness and computational efficiency.

## Method Summary
The method employs continuous relaxation of the discrete optimization problem for categorical features, enabling gradient-based adversarial training. It uses a bilevel alternating minimization framework where embedding matrices Q are optimized to maximize adversarial loss while simultaneously training model parameters θ. The approach includes a cost-aware threat model that constrains adversaries based on financial costs of feature transformations. For transferring robustness to tree-based models, a merging algorithm clusters and merges embeddings to preserve robustness information while maintaining compatibility with decision trees and random forests.

## Key Results
- Achieved up to 24% increase in robust accuracy on fraud detection and credit scoring tasks
- Universal robust embeddings transferred robustness to decision trees and random forests without requiring adversarial training for these models
- Maintained high clean accuracy while significantly improving robust accuracy against cost-bounded adversarial attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Continuous relaxation of discrete optimization problem enables gradient-based adversarial training for categorical data
- Mechanism: Instead of optimizing over discrete categorical values, the method optimizes over the convex hull of one-hot encoded vectors, allowing gradient-based methods to be applied
- Core assumption: The convex hull relaxation provides a tight enough approximation to the original discrete problem for effective adversarial training
- Evidence anchors:
  - [abstract] "continuous relaxation of the discrete optimization problem"
  - [section 4.1] "we employ a relaxation technique: instead of working with the discrete set of feature vectors, we consider the convex hull of their one-hot encoding vectors"
  - [corpus] No direct evidence found in corpus neighbors about this specific mechanism
- Break condition: If the convex hull relaxation becomes too loose for the specific categorical feature distributions, the adversarial examples may not be realistic enough to transfer robustness

### Mechanism 2
- Claim: Bilevel alternating minimization framework produces universal robust embeddings that can transfer robustness to tree-based models
- Mechanism: The framework optimizes embedding matrices Q to maximize adversarial loss while simultaneously training model parameters θ, creating embeddings that are inherently robust to adversarial perturbations
- Core assumption: Embeddings learned through this bilevel optimization contain information that tree-based models can use to maintain robustness when trained on them
- Evidence anchors:
  - [abstract] "These embeddings, created using a bilevel alternating minimization framework, can be transferred to boosted trees or random forests making them robust without the need for adversarial training"
  - [section 4.2] "We observed that directly transferring the embeddings Q has little effect in terms of improving the robustness of decision trees... To address this issue... we propose a merging algorithm"
  - [corpus] No direct evidence found in corpus neighbors about bilevel optimization for robustness transfer
- Break condition: If tree-based models cannot effectively learn from the merged embeddings or if the merging algorithm destroys too much information, robustness transfer will fail

### Mechanism 3
- Claim: Cost-aware threat model with heterogeneous feature costs provides more realistic evaluation of adversarial robustness
- Mechanism: Each feature transformation has an associated cost, and the adversary is constrained by a total budget, reflecting real-world limitations on adversarial capabilities
- Core assumption: Financial costs accurately represent the difficulty of feature transformations in real-world scenarios
- Evidence anchors:
  - [abstract] "using projected gradient descent with a cost-aware threat model that reflects real-world financial constraints on adversaries"
  - [section 1] "a realistic threat model would constrain the adversary with respect to their financial capabilities"
  - [corpus] Constrained Adaptive Attacks paper (paper_id 246444) mentions "realistic protocol to properly evaluate the adversarial robustness of deep neural networks for tabular data"
- Break condition: If the cost assignments don't accurately reflect real-world difficulty of transformations, the evaluation may not represent actual adversarial capabilities

## Foundational Learning

- Concept: Convex relaxation and projection onto convex sets
  - Why needed here: The method relies on projecting onto the intersection of convex sets (simplex for one-hot constraints and weighted l1 ball for cost constraints)
  - Quick check question: What algorithm is used to project onto the intersection of multiple convex constraints?

- Concept: Bilevel optimization and alternating minimization
  - Why needed here: The method uses bilevel optimization where inner level optimizes model parameters while outer level optimizes embedding matrices
  - Quick check question: How does alternating gradient descent solve the bilevel optimization problem in this context?

- Concept: One-hot encoding and categorical feature representation
  - Why needed here: The method builds on one-hot encoding as the basis for the continuous relaxation
  - Quick check question: How is the cost matrix Ci used to compute the weighted l1 norm for categorical features?

## Architecture Onboarding

- Component map:
  - Input layer: Categorical features with one-hot encoding
  - Embedding layer: Parameterized by matrices Q, learned through bilevel optimization
  - Neural network: Takes embeddings as input, trained with Cat-PGD adversarial training
  - Merging algorithm: Clusters and merges embeddings for tree-based model transfer
  - Tree-based models: Trained on merged embeddings without adversarial training

- Critical path:
  1. Initialize Q matrices randomly
  2. For each training iteration:
     - Update neural network parameters θ with normal gradient descent
     - Generate adversarial examples using Cat-PGD
     - Update Q matrices to maximize adversarial loss
  3. Apply merging algorithm to Q matrices
  4. Train tree-based models on merged embeddings

- Design tradeoffs:
  - Continuous relaxation vs. discrete optimization: Continuous relaxation enables gradient-based methods but may introduce approximation error
  - First-layer vs. last-layer embeddings: First-layer embeddings preserve more information but may be less abstract
  - Merging threshold: Higher thresholds preserve more distinct embeddings but may reduce robustness transfer

- Failure signatures:
  - No improvement in robust accuracy after training: May indicate poor convex relaxation or ineffective bilevel optimization
  - High clean accuracy but low robust accuracy: May indicate overfitting to clean examples
  - Tree-based models show no robustness improvement: May indicate merging algorithm is too aggressive or embeddings lack robustness information

- First 3 experiments:
  1. Train TabNet with Cat-PGD on IEEECIS dataset with ε=$1, compare clean and robust accuracy to baseline
  2. Apply bilevel optimization to produce embeddings, merge with τ=0.1, train LGBM on merged embeddings, evaluate robustness
  3. Vary merging threshold τ from 0.0 to 0.2, measure impact on both clean and robust accuracy of tree-based models

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but based on the limitations and scope of the work, several important questions arise:

1. How does the performance of universal robust embeddings vary across different threat models with different cost structures?
2. What is the theoretical upper bound on robust accuracy achievable through universal robust embeddings when transferring from neural networks to decision trees?
3. How does the dimensionality of robust embeddings affect both clean accuracy and robust accuracy in tree-based models?
4. Can the bilevel alternating minimization framework be extended to optimize robustness for both the neural network and tree-based models simultaneously?

## Limitations

- The convex relaxation approximation quality is not rigorously bounded, potentially limiting the effectiveness of adversarial examples
- The cost-aware threat model requires accurate cost assignments that may not reflect real-world transformation difficulties
- The merging algorithm for transferring robustness to tree-based models lacks theoretical guarantees and depends on sensitive hyperparameters

## Confidence

**High Confidence**: The core contribution of enabling adversarial training for categorical data through continuous relaxation is technically sound and well-supported by the mathematical formulation. The empirical improvements in robust accuracy (up to 24%) are substantial and clearly demonstrated.

**Medium Confidence**: The bilevel optimization framework for generating universal robust embeddings is theoretically justified, but the convergence properties and sensitivity to hyperparameters (learning rates, iteration counts) are not thoroughly explored. The merging algorithm for transferring robustness shows promise but lacks theoretical guarantees.

**Low Confidence**: The generalizability of the approach across diverse categorical distributions and the robustness of the merging algorithm to different distance metrics and thresholds are not sufficiently validated. The paper focuses on specific datasets without extensive ablation studies.

## Next Checks

1. **Relaxation Quality Analysis**: Quantify the approximation error introduced by the convex relaxation by comparing adversarial examples generated through the relaxed method versus those from exact discrete optimization on small-scale problems where enumeration is feasible.

2. **Cost Matrix Sensitivity**: Conduct ablation studies varying the cost assignments for categorical features to determine how sensitive the robust accuracy improvements are to different cost configurations, including scenarios where costs don't reflect actual transformation difficulties.

3. **Merging Algorithm Robustness**: Systematically vary the distance threshold τ across multiple orders of magnitude and test with different distance metrics (cosine, Euclidean, Mahalanobis) to establish the stability and sensitivity of the robustness transfer mechanism.