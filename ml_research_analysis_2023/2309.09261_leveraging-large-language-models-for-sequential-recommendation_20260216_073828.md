---
ver: rpa2
title: Leveraging Large Language Models for Sequential Recommendation
arxiv_id: '2309.09261'
source_url: https://arxiv.org/abs/2309.09261
tags:
- recommendation
- sequential
- embeddings
- item
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper explores the application of large language models (LLMs)
  to sequential recommendation problems. Three approaches are proposed: (1) using
  LLM embeddings to find semantically similar items (LLMSeqSim), (2) fine-tuning an
  LLM to generate recommendations based on session prompts (LLMSeqPrompt), and (3)
  initializing a sequential model (BERT4Rec) with LLM embeddings (LLM2BERT4Rec).'
---

# Leveraging Large Language Models for Sequential Recommendation

## Quick Facts
- arXiv ID: 2309.09261
- Source URL: https://arxiv.org/abs/2309.09261
- Reference count: 40
- Key outcome: LLM embeddings improve BERT4Rec NDCG by 15-20% when used to initialize item representations

## Executive Summary
This paper investigates how large language models can enhance sequential recommendation systems through three distinct approaches. The first uses LLM embeddings to find semantically similar items, the second fine-tunes an LLM for session-based recommendations, and the third initializes a sequential model (BERT4Rec) with LLM embeddings. Experiments on Amazon Beauty and Delivery Hero datasets demonstrate that initializing BERT4Rec with LLM embeddings provides the most significant performance gains, improving NDCG by 15-20%. The LLMSeqSim approach also shows competitive performance, particularly on the Beauty dataset. These results highlight the potential of LLMs to provide semantically rich item representations that capture meaningful relationships useful for recommendation tasks.

## Method Summary
The paper proposes three LLM-based approaches for sequential recommendation. LLMSeqSim computes session embeddings from product embeddings and recommends items with similar embeddings using cosine, Euclidean, or dot product similarity. LLMSeqPrompt fine-tunes an LLM on prompt-completion pairs where prompts are sessions (without last item) and completions are the next item, using frequency of duplicate outputs as confidence proxy. LLM2BERT4Rec initializes BERT4Rec item embeddings with LLM embeddings reduced to match BERT4Rec's embedding size via PCA. All approaches use OpenAI's text-embedding-ada-002 model to generate 1536-dimensional embeddings for catalog items.

## Key Results
- LLM2BERT4Rec improves NDCG by 15-20% compared to vanilla BERT4Rec on Amazon Beauty dataset
- LLMSeqSim provides competitive performance, particularly excelling on the Beauty dataset
- LLMSeqPrompt shows mixed results with significant variance between datasets and requires careful handling of hallucinations
- Performance on Delivery Hero dataset is notably worse than Amazon Beauty, suggesting domain dependency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Initializing BERT4Rec with LLM embeddings improves NDCG by 15-20% because LLM embeddings encode richer semantic information about items than random ID embeddings.
- Mechanism: PCA reduces LLM embeddings (1536D) to match BERT4Rec's embedding size (e.g., 64D), then these semantic embeddings are used to initialize item representations. This provides a better starting point for learning sequential patterns.
- Core assumption: The semantic information in LLM embeddings captures meaningful relationships between items that are useful for recommendation.
- Evidence anchors:
  - [abstract]: "initializing the state-of-the-art sequential recommendation model BERT4Rec with embeddings obtained from an LLM improves NDCG by 15-20%"
  - [section]: "we initializeBERT4Rec's item embeddings using the LLM embeddings... In order to align the embedding dimension... we employ Principal Components Analysis (PCA)"
  - [corpus]: Found 25 related papers, average neighbor FMR=0.425. Evidence supports semantic embeddings are valuable, but specific 15-20% gain is from this paper's experiments.
- Break condition: If the semantic information in LLM embeddings is not relevant to the specific domain or user preferences in the dataset, the performance gain would diminish or disappear.

### Mechanism 2
- Claim: Using LLM embeddings to find semantically similar items (LLMSeqSim) can provide competitive performance by leveraging holistic similarity notions.
- Mechanism: Session embeddings are created by averaging or otherwise combining product embeddings from the session. Then items with similar embeddings are recommended based on cosine/Euclidean/dot product similarity.
- Core assumption: Items that are semantically similar according to LLM embeddings are likely to be relevant to the user's current session.
- Evidence anchors:
  - [abstract]: "a simple approach that leverages LLM embeddings for producing recommendations, can provide competitive performance by highlighting semantically related items"
  - [section]: "we compute a session embedding for each session... we compare the session embedding to the embeddings of the items in the product catalog using cosine, Euclidean, and dot product similarity"
  - [corpus]: Related work exists on semantic embeddings for recommendation, supporting this approach, but specific competitive performance depends on dataset characteristics.
- Break condition: If the dataset has items with infrequent occurrences or diverse categories where semantic similarity doesn't align with user preferences, this approach would fail.

### Mechanism 3
- Claim: Fine-tuning an LLM with session prompts and completions can generate recommendations by leveraging the model's generative capabilities and learned domain knowledge.
- Mechanism: The LLM is fine-tuned on prompt-completion pairs where prompts are sessions (without last item) and completions are the next item. During inference, the model generates recommendations, duplicates are ranked by frequency, and hallucinations are mapped to real items via embedding similarity.
- Core assumption: The LLM can learn to generate relevant next items when fine-tuned on domain-specific session data, and its tendency to repeat outputs reflects confidence.
- Evidence anchors:
  - [abstract]: "we fine-tune an LLM with dataset-specific information in the form of prompt-completion pairs and ask the model to produce next item recommendations"
  - [section]: "we fine-tune the model until the validation loss converges... we make no strong assumption regarding the order of the returned recommendations. Therefore, we use the tendency of the model to provide duplicate recommendations as a proxy of its confidence"
  - [corpus]: Limited evidence in related papers for this specific approach; performance varies significantly by dataset.
- Break condition: If the fine-tuning data is insufficient or the LLM cannot learn meaningful patterns from the limited context, or if hallucinations cannot be properly mapped to real items, the approach would fail.

## Foundational Learning

- Concept: Transformer architecture and self-attention mechanism
  - Why needed here: BERT4Rec and other sequential models are built on transformer architecture, understanding self-attention is crucial for how these models process item sequences
  - Quick check question: How does self-attention allow a transformer to weigh the importance of different items in a sequence when predicting the next item?

- Concept: Embedding similarity measures (cosine, Euclidean, dot product)
  - Why needed here: LLMSeqSim relies on comparing session embeddings to item embeddings using similarity measures to find relevant recommendations
  - Quick check question: Given two vectors A=[1,2] and B=[2,4], calculate their cosine similarity and explain what it tells us about their relationship

- Concept: Principal Component Analysis (PCA) for dimensionality reduction
  - Why needed here: LLM embeddings (1536D) must be reduced to match BERT4Rec's embedding size (e.g., 64D) while preserving semantic information
  - Quick check question: If you have 3 items with 4D embeddings and apply PCA to reduce to 2D, what information is preserved and what might be lost?

## Architecture Onboarding

- Component map:
  Data pipeline -> LLM embedding generation -> Model training -> Evaluation
  (Load and preprocess datasets) -> (Query OpenAI API for item embeddings) -> (Train LLM2BERT4Rec or LLMSeqPrompt) -> (Calculate NDCG, MRR, etc.)

- Critical path:
  1. Data preprocessing and splitting
  2. LLM embedding generation for all catalog items
  3. Model training (especially for LLM2BERT4Rec and LLMSeqPrompt variants)
  4. Inference on test set
  5. Metric calculation and analysis

- Design tradeoffs:
  - Embedding dimensionality: Higher dimensions preserve more information but increase computation and may cause overfitting
  - Similarity measure choice: Different measures may perform better for different datasets
  - Session embedding strategy: Using only last item vs. full session average affects performance
  - Fine-tuning approach: More epochs may improve LLMSeqPrompt but risk overfitting

- Failure signatures:
  - Poor NDCG improvement despite semantic embeddings: Semantic information may not be relevant to user preferences
  - LLMSeqSim performs poorly on datasets with many rare items: Embedding similarity breaks down with sparse data
  - LLMSeqPrompt generates many hallucinations: Model hasn't learned meaningful patterns or mapping strategy fails
  - PCA loses too much information: Dimensionality reduction too aggressive, semantic information lost

- First 3 experiments:
  1. Compare BERT4Rec with random initialization vs. BERT4Rec with LLM embeddings (LLM2BERT4Rec) on a small validation set to verify the 15-20% NDCG improvement
  2. Test different session embedding strategies (last item only, weighted average, full average) for LLMSeqSim to find optimal approach
  3. Run LLMSeqPrompt with different fine-tuning epochs and evaluate on validation set to find convergence point and assess hallucination rate

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different LLM architectures and training corpora impact the performance of LLM-enhanced sequential recommendation models?
- Basis in paper: [inferred] from the conclusion mentioning future exploration of alternative LLMs with different architectures and training corpora
- Why unresolved: The paper only used one specific OpenAI embedding model (text-embedding-ada-002) and did not compare results across different LLM architectures or training approaches
- What evidence would resolve it: Systematic experiments comparing LLM2BERT4Rec performance across multiple LLM architectures (e.g., GPT, BERT, LLaMA) and training corpora would show which combinations yield optimal sequential recommendation performance

### Open Question 2
- Question: Does incorporating additional item attributes beyond product names (such as category information) into LLM prompts further improve recommendation performance?
- Basis in paper: [explicit] from the conclusion stating "it is open so far if passing other types of information besides product names, e.g., category information, to an LLM can help to further improve the performance of the models"
- Why unresolved: The experiments only used product names as input to the LLM embeddings, limiting understanding of whether richer contextual information could enhance performance
- What evidence would resolve it: Experiments comparing LLM-enhanced models using various combinations of item attributes (names, categories, descriptions) against the baseline using only names would quantify the impact of additional contextual information

### Open Question 3
- Question: How well do the proposed LLM-based sequential recommendation approaches generalize across different domains and dataset characteristics?
- Basis in paper: [explicit] from the conclusion stating "we plan to investigate if our findings generalize to different domains, using alternative datasets with diverse characteristics"
- Why unresolved: The experiments were limited to two datasets (Amazon Beauty and Delivery Hero QCommerce), both of which have specific characteristics (e.g., Beauty has strong brand name signals, Delivery Hero has many infrequent items)
- What evidence would resolve it: Comprehensive evaluation across diverse domains (e.g., music streaming, news, social media) with varying characteristics (session lengths, catalog sizes, item popularity distributions) would demonstrate the robustness and generalizability of the LLM-based approaches

## Limitations

- The performance improvement may be dataset-dependent, with significantly worse results on Delivery Hero compared to Amazon Beauty
- The computational overhead of generating LLM embeddings for large catalogs and potential information loss during PCA dimensionality reduction are not fully characterized
- The handling of hallucinations in LLMSeqPrompt through embedding mapping is a heuristic that may not scale well to larger, more diverse catalogs

## Confidence

- High confidence: The basic premise that semantically rich item representations can improve sequential recommendation is well-supported by the empirical results, particularly for the Amazon Beauty dataset.
- Medium confidence: The specific 15-20% improvement figure for LLM2BERT4Rec is based on experiments on two datasets, but the substantial performance degradation on Delivery Hero suggests this may not generalize across all domains.
- Low confidence: The LLMSeqPrompt approach shows mixed results with significant variance between datasets, and the handling of hallucinations through embedding mapping is a heuristic that may not scale well to larger, more diverse catalogs.

## Next Checks

1. Conduct ablation studies on the PCA dimensionality reduction to determine the optimal balance between embedding size and semantic information preservation.
2. Test the approaches on additional datasets with different characteristics (e.g., higher item frequency, different domain) to assess generalizability.
3. Implement a more rigorous evaluation of the LLMSeqPrompt approach by comparing hallucination rates and mapping effectiveness across multiple mapping strategies (not just embedding similarity).