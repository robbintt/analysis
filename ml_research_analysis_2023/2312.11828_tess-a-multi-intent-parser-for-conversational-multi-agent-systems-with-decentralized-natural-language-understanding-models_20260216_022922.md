---
ver: rpa2
title: 'TESS: A Multi-intent Parser for Conversational Multi-Agent Systems with Decentralized
  Natural Language Understanding Models'
arxiv_id: '2312.11828'
source_url: https://arxiv.org/abs/2312.11828
tags:
- agents
- multi-intent
- intent
- parse
- agent
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of parsing multi-intent utterances
  in decentralized multi-agent conversational systems. The proposed method, TESS,
  uses a syntactic parser with heuristic rules to split user utterances and then evaluates
  agent confidence scores to determine the optimal parse.
---

# TESS: A Multi-intent Parser for Conversational Multi-Agent Systems with Decentralized Natural Language Understanding Models

## Quick Facts
- arXiv ID: 2312.11828
- Source URL: https://arxiv.org/abs/2312.11828
- Reference count: 8
- Key outcome: Achieves 87-99% accuracy on single-intent phrases and 60% correct agent selection for multi-intent utterances while being up to 48x faster than deep learning baselines

## Executive Summary
This paper introduces TESS, a syntactic parser that addresses multi-intent utterance parsing in decentralized multi-agent conversational systems. TESS uses heuristic rules to split utterances and evaluates agent confidence scores to determine optimal parses, avoiding the need for deep learning models. Tested on ATIS, MultiWOZ, and MixATIS datasets, TESS achieves comparable accuracy to deep learning baselines while providing significant speed improvements. The approach is particularly suited for resource-constrained environments where agents are independently maintained and cannot share internal knowledge.

## Method Summary
TESS uses a context-free grammar with heuristic rules to generate parse trees of all possible utterance splits based on conjunctions, punctuation, and token dependencies. Each parse node is evaluated using agent confidence scores computed as either average probability mass or joint probability. A min-max style backup algorithm recursively determines the optimal parse from root to leaves. The system is tested against deep learning baselines (AGIF and AMR) on multi-intent classification accuracy and parse time using RASA NLU agents trained on ATIS and MultiWOZ datasets.

## Key Results
- Achieves 87-99% accuracy on single-intent phrases across all three datasets
- Reaches 60% correct agent selection accuracy for multi-intent utterances (vs 50% for AMR baseline)
- Up to 48x faster than deep learning baselines while maintaining comparable accuracy
- Response time does not significantly impact pipeline latency compared to AMR

## Why This Works (Mechanism)

### Mechanism 1
- Claim: TESS uses syntactic parsing with heuristic rules to split multi-intent utterances, then evaluates agent confidence scores to determine optimal parse.
- Mechanism: The parser generates a tree of all possible utterance splits using conjunctions, punctuation, and token dependencies. Each node represents a parse state, and agent confidence scores are computed for each candidate utterance. A min-max style backup algorithm selects the parse with highest expected utility.
- Core assumption: The optimal parse can be determined by evaluating agent confidence scores without requiring deep learning models.
- Evidence anchors:
  - [abstract]: "uses a syntactic parser with heuristic rules to split user utterances and then evaluates agent confidence scores to determine the optimal parse"
  - [section 3.1]: "The first step is to generate the TESS tree with all possible parse combinations... Each node N = {Ei} in the parse tree represents the state of the multi-intent parse... TESS then computes the score of each evaluate node as per Equation 4"
- Break condition: If agents cannot accurately evaluate sub-utterances or if confidence scores are poorly calibrated, the optimal parse may be incorrectly selected.

### Mechanism 2
- Claim: TESS achieves comparable accuracy to deep learning baselines while being up to 48x faster.
- Mechanism: By avoiding deep learning models and using lightweight syntactic parsing with heuristic rules, TESS significantly reduces computational overhead while maintaining accuracy through effective agent confidence evaluation.
- Core assumption: Syntactic parsing with heuristic rules can capture multi-intent structure effectively without deep learning.
- Evidence anchors:
  - [abstract]: "achieves comparable accuracy to deep learning baselines while being up to 48x faster"
  - [section 4.5]: "TESS does not significantly slow down the response time of the pipeline compared to AMR (especially when GPUs are not available)"
- Break condition: If multi-intent utterances have complex structures not captured by simple heuristic rules, accuracy may degrade compared to deep learning approaches.

### Mechanism 3
- Claim: TESS works in decentralized multi-agent systems where agents are independently maintained and cannot share internal knowledge.
- Mechanism: Each agent evaluates only the utterances it receives without needing knowledge of other agents' capabilities. The parser orchestrates based on agent confidence scores without requiring centralized control or knowledge.
- Core assumption: Agents can accurately self-report their relevance to sub-utterances without coordination or shared knowledge.
- Evidence anchors:
  - [section 2.2.1]: "agents are sourced and maintained independently... it is impossible to predict the correct way to parse a user utterance without knowledge of what each individual agent does"
  - [section 2.2.2]: "the correct production can only be determined once E(A, ϕ) has been evaluated ∀A"
- Break condition: If agents provide unreliable confidence scores or if utterances require coordination between agents for accurate parsing, the decentralized approach may fail.

## Foundational Learning

- Concept: Syntactic parsing and context-free grammars
  - Why needed here: TESS uses a context-free grammar to generate parse trees of utterance splits based on conjunctions, punctuation, and token dependencies
  - Quick check question: What are the three operations used in TESS to build the parse tree, and what does each operation accomplish?

- Concept: Agent confidence evaluation and probability scoring
  - Why needed here: Agents evaluate candidate utterances and return confidence scores, which TESS uses to determine optimal parses through average probability mass or joint probability calculations
  - Quick check question: How does TESS compute the score for each node in the parse tree, and what are the two scoring schemes mentioned?

- Concept: Min-max style backup algorithms for decision making
  - Why needed here: TESS uses a min-max style backup computation to recursively determine the optimal parse from root to leaves based on agent confidence scores
  - Quick check question: What is the formula used by TESS to compute the score of each node during the backup process, and what does each term represent?

## Architecture Onboarding

- Component map: User utterance -> TESS parser -> Agent evaluation -> Min-max backup -> Agent selection -> Execution
- Critical path: User utterance → TESS parsing → Agent evaluation → Min-max backup → Agent selection → Execution
- Design tradeoffs:
  - Speed vs. accuracy: TESS prioritizes speed through syntactic parsing over potentially higher accuracy of deep learning approaches
  - Decentralization vs. coordination: TESS trades centralized knowledge for agent independence and scalability
  - Heuristic rules vs. learned patterns: TESS uses predefined rules rather than learned patterns, limiting coverage but improving efficiency
- Failure signatures:
  - Poor agent confidence calibration leads to incorrect parses
  - Complex multi-intent structures not captured by heuristic rules
  - Agents unable to accurately evaluate sub-utterances
  - High computational overhead when many agents are involved
- First 3 experiments:
  1. Test TESS on simple multi-intent utterances with clear conjunctions (e.g., "Book hotel and flight") to verify basic parsing works
  2. Evaluate agent confidence scoring by comparing TESS parse selection against ground truth on benchmark datasets
  3. Measure computational overhead by timing TESS parse execution versus baseline deep learning parsers on CPU-only hardware

## Open Questions the Paper Calls Out

- How can TESS be extended to handle multi-agent single-intent utterances, where a single grammatical intent requires multiple agents to execute due to the way agents are constructed in the aggregate?
- How does the performance of TESS compare when using different scoring mechanisms for node evaluation, such as joint probability versus average probability?
- How can the calibration of confidence scores from independent agents in a multi-agent system be improved to enhance TESS's parsing accuracy?

## Limitations

- Performance critically depends on agents providing well-calibrated confidence scores in decentralized systems
- Heuristic rules may not capture all possible multi-intent structures, especially complex or domain-specific utterance patterns
- Evaluation limited to three specific datasets that may not represent full diversity of real-world multi-intent utterances

## Confidence

**High Confidence Claims:**
- 87-99% accuracy on single-intent phrases across datasets
- 60% correct agent selection accuracy for multi-intent utterances
- Up to 48x speedup compared to deep learning baselines
- TESS response time does not significantly impact pipeline latency

**Medium Confidence Claims:**
- TESS works effectively in decentralized multi-agent systems
- Agent confidence scores reliably indicate intent relevance
- Heuristic rules capture most common multi-intent structures

**Low Confidence Claims:**
- TESS generalizes to unseen domains and utterance patterns
- Performance scales linearly with number of agents
- Heuristic rules remain effective as system complexity increases

## Next Checks

1. **Confidence Calibration Testing**: Conduct systematic evaluation of agent confidence score calibration across different utterance types and domains. Compare TESS performance when using raw confidence scores versus calibrated scores to quantify sensitivity to confidence reliability.

2. **Heuristic Rule Coverage Analysis**: Perform ablation studies removing different types of heuristic rules (conjunctions, punctuation, token dependencies) to identify which rules contribute most to performance. Test TESS on utterances that deliberately violate heuristic assumptions to measure failure rates.

3. **Cross-Domain Generalization**: Evaluate TESS on datasets from different domains (e.g., healthcare, finance, customer service) to assess how well the approach generalizes beyond ATIS and MultiWOZ. Measure performance degradation and identify specific utterance patterns that cause failures.