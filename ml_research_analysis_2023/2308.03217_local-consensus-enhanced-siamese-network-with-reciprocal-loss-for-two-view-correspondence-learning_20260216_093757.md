---
ver: rpa2
title: Local Consensus Enhanced Siamese Network with Reciprocal Loss for Two-view
  Correspondence Learning
arxiv_id: '2308.03217'
source_url: https://arxiv.org/abs/2308.03217
tags:
- feature
- network
- correspondence
- consensus
- features
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper addresses the challenge of improving two-view correspondence
  learning for tasks like camera pose estimation and feature matching. The authors
  propose two key innovations: a Local Feature Consensus (LFC) plugin block that augments
  features by aggregating neighboring ones with mutual neighborhood consensus, and
  a Siamese network extension with a reciprocal loss that exploits mutual projection
  information between image pairs.'
---

# Local Consensus Enhanced Siamese Network with Reciprocal Loss for Two-view Correspondence Learning

## Quick Facts
- arXiv ID: 2308.03217
- Source URL: https://arxiv.org/abs/2308.03217
- Reference count: 36
- Key outcome: Achieves state-of-the-art performance on YFCC100M and SUN3D with mAP5° improvements up to 41.91% on SUN3D and 18.24% on YFCC100M

## Executive Summary
This paper addresses two-view correspondence learning by introducing a Local Feature Consensus (LFC) block and extending MSA-Net to a Siamese architecture with reciprocal loss. The LFC block strengthens inlier correlation through mutual consensus among neighboring features, while the Siamese extension exploits bidirectional consistency for improved robustness. The method achieves significant performance gains on benchmark datasets while maintaining parameter efficiency.

## Method Summary
The method extends MSA-Net with two key innovations: a Local Feature Consensus (LFC) block that aggregates neighboring features through mutual neighborhood consensus, and a Siamese network extension with reciprocal loss that exploits mutual projection information between image pairs. The LFC block reconstructs features via attention-like similarity weighting before aggregation, while the Siamese extension processes both forward and reverse correspondence matrices with shared weights and bidirectional supervision.

## Key Results
- Achieves state-of-the-art performance on YFCC100M and SUN3D datasets
- mAP5° improvements of up to 41.91% on SUN3D and 18.24% on YFCC100M compared to baseline MSA-Net
- F-scores reaching 76.48% (known scenes) and 72.16% (unknown scenes)
- Maintains competitive parameter efficiency while achieving superior correspondence prediction

## Why This Works (Mechanism)

### Mechanism 1
Local feature consensus strengthens inlier correlation and suppresses outlier distraction by reconstructing neighboring features via mutual consensus before aggregation. Inliers share more consistent learned features due to uniform cross-view transformation, so consensus amplifies inlier correlation and reduces outlier influence during fusion. Core assumption: Inlier features are more similar than outlier features in learned feature space. Break condition: If inlier features become dissimilar due to noise or large viewpoint changes.

### Mechanism 2
Siamese extension with reciprocal loss doubles effective training data and enforces bidirectional consistency by processing both forward and reverse correspondence matrices through a shared network. This implicitly regularizes the model to maintain symmetry between forward and reverse predictions. Core assumption: Ground truth correspondence labels and essential matrices are consistent under reversal. Break condition: If ground truth is noisy or asymmetric, reciprocal loss may introduce harmful regularization.

### Mechanism 3
Deformable attention-based feature fusion attends to a small set of key feature points for effective aggregation by computing weights via softmax over a learned linear projection of the central feature. This allows the model to focus on the most informative neighbors dynamically. Core assumption: A learned weighting based on the central feature can better identify which neighbors to emphasize than fixed averaging. Break condition: If learned weighting fails to distinguish inliers from outliers.

## Foundational Learning

- **Epipolar geometry and essential matrix**: Understanding how point correspondences constrain camera geometry is fundamental since the method supervises both correspondence classification and essential matrix estimation. Quick check: Given inlier correspondences between two images, what is the rank and internal constraint of the essential matrix?

- **Attention mechanisms and self-attention**: The LFC block uses attention-like operations for mutual consensus and deformable attention for fusion. Quick check: In standard self-attention, how are query, key, and value matrices computed and combined?

- **Siamese networks and shared weights**: The reciprocal loss approach extends the model to Siamese architecture. Quick check: In Siamese networks with shared weights, what happens to gradient flow when different inputs are processed through same parameters?

## Architecture Onboarding

- **Component map**: Input (putative correspondence matrix C) -> Perceptron layer -> LFC block -> ACL blocks (×3) -> Cluster block -> Prediction block -> Output (probability, residual, essential matrix)

- **Critical path**: Forward pass: C → LFC → ACLs → cluster → prediction → P, R, E; Reverse pass: C' → LFC → ACLs → cluster → prediction → P', R', E'; Loss: L(C) + L(C') with classification and geometric loss

- **Design tradeoffs**: LFC placement after perceptron layer for efficiency; k=9 neighbors balances context and outlier inclusion; Siamese doubles training data but inference passes

- **Failure signatures**: Degraded performance with high inlier/outlier similarity or extreme viewpoint changes; overfitting with large k relative to inlier ratio; training instability with unbalanced reciprocal loss weight

- **First 3 experiments**: 1) Train baseline MSA-Net without LFC/Siamese; 2) Add LFC block only (k=9); 3) Add Siamese extension only; compare performance to isolate component contributions

## Open Questions the Paper Calls Out

- **How does LFC block performance vary at different positions within MSA-Net architecture?** The paper only reports results for insertion after first perceptron layer without exploring alternatives or providing systematic comparison across positions.

- **What is the impact of varying k on computational efficiency beyond performance metrics?** The paper provides qualitative statements about computational cost without quantifying it or analyzing trade-offs between k, performance, and efficiency.

- **How does the method perform on datasets with non-rigid transformations or significant viewpoint changes?** Evaluation is limited to YFCC100M and SUN3D datasets, which may not represent full spectrum of transformation types the method could encounter.

## Limitations

- Method effectiveness depends critically on assumption that inlier features are more similar than outliers in learned feature space, which may break down in challenging scenarios
- Generalization to extreme camera motion or textureless scenes remains untested despite significant benchmark improvements
- Claims about computational efficiency compared to other state-of-the-art methods are not quantitatively supported

## Confidence

**High Confidence Claims**: Architectural design of LFC block and Siamese extension is clearly specified and reproducible; performance improvements on YFCC100M and SUN3D are well-documented; reciprocal loss formulation is sound.

**Medium Confidence Claims**: Choice of k=9 neighbors is empirically justified but may not be optimal for all scenarios; relative contribution of LFC vs Siamese components to overall performance is not isolated in ablation studies.

**Low Confidence Claims**: Claims about computational efficiency compared to other methods are not quantitatively supported; method's robustness to noisy correspondences and outliers in extreme conditions is not thoroughly evaluated.

## Next Checks

1. **Ablation Study**: Implement and evaluate variants with only LFC block, only Siamese extension, and both components to quantify their individual contributions to performance gains.

2. **Extreme Condition Testing**: Evaluate the method on image pairs with large viewpoint changes (>60°), significant illumination variations, and textureless regions to assess robustness limits.

3. **Computational Efficiency Analysis**: Measure and compare actual inference time and parameter count against other state-of-the-art correspondence learning methods to verify efficiency claims.