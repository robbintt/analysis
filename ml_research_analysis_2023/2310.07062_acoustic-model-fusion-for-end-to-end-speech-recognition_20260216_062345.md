---
ver: rpa2
title: Acoustic Model Fusion for End-to-end Speech Recognition
arxiv_id: '2310.07062'
source_url: https://arxiv.org/abs/2310.07062
tags:
- fusion
- system
- external
- speech
- internal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces AM fusion, a technique that integrates an
  external acoustic model (AM) into an end-to-end (E2E) speech recognition system
  to address domain mismatch issues. The approach involves computing AM scores for
  each first-pass hypothesis in the N-best list for re-ranking.
---

# Acoustic Model Fusion for End-to-end Speech Recognition

## Quick Facts
- arXiv ID: 2310.07062
- Source URL: https://arxiv.org/abs/2310.07062
- Reference count: 0
- One-line primary result: AM fusion achieves up to 14.3% relative WER reduction across various test sets, with notable improvements in named entity recognition.

## Executive Summary
This paper introduces AM fusion, a technique that integrates an external acoustic model (AM) into an end-to-end (E2E) speech recognition system to address domain mismatch issues. The approach involves computing AM scores for each first-pass hypothesis in the N-best list for re-ranking. Experiments show that AM fusion achieves up to 14.3% relative word error rate reduction across various test sets, with notable improvements in named entity recognition. The method is particularly effective for under-represented words and phrases, demonstrating the potential of external AM integration in enhancing E2E ASR systems.

## Method Summary
The method involves training an end-to-end Conformer-wp model on a large dataset, followed by first-pass decoding to generate N-best hypotheses. In the second pass, an external AM (Conformer-mono or SNDCNN-tri) computes acoustic scores for each hypothesis via force alignment using a lexicon. These scores are then interpolated with the E2E model's scores in log-linear space using tunable weights (λAM, λLM) to produce the final hypothesis. The approach leverages the E2E model's strong first-pass decoding while using the external AM to refine hypotheses, especially for rare or domain-specific terms.

## Key Results
- AM fusion achieves up to 14.3% relative WER reduction across various test sets
- Notable improvements in named entity recognition, particularly for under-represented words and phrases
- Larger WER improvements observed on TTS and VA test sets compared to DICT, indicating effectiveness for under-trained words in named entities

## Why This Works (Mechanism)

### Mechanism 1
- Claim: AM fusion improves recognition of under-represented wordpieces by explicitly injecting pronunciation knowledge from an external acoustic model.
- Mechanism: During second-pass rescoring, the external AM computes phonetic likelihoods for each N-best hypothesis. These likelihoods are interpolated with the E2E model's scores, effectively boosting hypotheses that align better with domain-specific pronunciations not well captured in the E2E training data.
- Core assumption: The external AM provides complementary pronunciation information that the E2E model lacks due to domain mismatch or insufficient training data for rare words.
- Evidence anchors:
  - [abstract] "AM fusion achieves up to 14.3% relative word error rate reduction across various test sets, with notable improvements in named entity recognition."
  - [section 3.2] "In order to explicitly inject the pronunciation knowledge into the system, we further decompose the internal AM with approximation built on Markov and Viterbi assumption... The external AM score is computed by force-aligning the N-best hypotheses with the audio provided an lexicon."
  - [corpus] Weak evidence - no direct mention of pronunciation knowledge injection.

### Mechanism 2
- Claim: AM fusion allows tunable interpolation between internal and external acoustic models, providing more flexible domain adaptation than LM fusion alone.
- Mechanism: The fusion equation (Eq. 7, 8) includes a weight λAM that directly scales the external AM's contribution. This enables independent control over acoustic modeling strength separate from language modeling, allowing compensation for domain mismatch in the internal AM without overly relying on the external LM.
- Core assumption: The internal and external AMs can be meaningfully combined in log-linear space, and their respective contributions can be tuned to optimize recognition accuracy.
- Evidence anchors:
  - [section 3.1] "AM fusion provides an equivalent system of an AM log PIAM (X|Ŷ) + λAM log PAM (X|Ŷ) and an LM log PILM (Ŷ) + λLM log PLM (Ŷ)."
  - [section 3.2] "We can manipulate the weights of the external LM (λLM) and AM (λAM) to achieve any weighted combination of the AM, internal and external LM as per requirement."
  - [corpus] Weak evidence - no direct mention of tunable interpolation benefits.

### Mechanism 3
- Claim: By separating AM fusion into a second pass, the approach leverages the E2E model's strong first-pass decoding while using the external AM to refine hypotheses, especially for rare or domain-specific terms.
- Mechanism: The first pass uses the E2E model with optional LM fusion to generate an N-best list. The second pass then rescoring these hypotheses with external AM scores allows targeted improvement without the computational cost of full two-pass decoding or the risk of the external AM degrading common word recognition.
- Core assumption: The N-best list from the first pass contains hypotheses close enough to the reference that the external AM can meaningfully improve the top result.
- Evidence anchors:
  - [section 3.2] "In practice, we separate the recognition as a two-pass process. The first pass operates in a streaming mode... The N-best hypotheses are preserved as the input to the second pass. In the second pass, an external AM score is computed by force-aligning the N-best hypotheses with the audio provided an lexicon."
  - [section 4.2] "WERR is larger on TTS and V A than on DICT, which shows that AM fusion helps under-trained words in named entities."
  - [corpus] Weak evidence - no direct mention of two-pass benefits.

## Foundational Learning

- Concept: Acoustic Model (AM) vs. Language Model (LM) in ASR
  - Why needed here: Understanding the distinction between acoustic modeling (mapping audio to phonetic units) and language modeling (constraining output sequences) is crucial to grasp why fusing an external AM can address domain mismatch issues that LM fusion cannot.
  - Quick check question: What is the primary function of an acoustic model in an ASR system, and how does it differ from a language model?

- Concept: End-to-End (E2E) ASR Architecture
  - Why needed here: AM fusion is proposed as an enhancement to E2E ASR systems. Knowing how E2E models implicitly learn AM, LM, and lexicon components is essential to understand where domain mismatch can occur and how external AM integration can help.
  - Quick check question: In an E2E ASR system, how are the traditional AM, LM, and lexicon components typically represented, and what is the main advantage of this unified approach?

- Concept: Log-Linear Interpolation in ASR Decoding
  - Why needed here: AM fusion operates by interpolating scores in log-linear space. Understanding this technique is necessary to comprehend how the external AM's contributions are combined with the E2E model's scores during rescoring.
  - Quick check question: What is log-linear interpolation, and how is it commonly used in ASR systems to combine different knowledge sources (e.g., AM and LM scores)?

## Architecture Onboarding

- Component map: Audio input -> First-pass E2E decoding (with LM if used) -> N-best hypotheses -> Second-pass AM rescoring -> Fusion of E2E scores, AM scores, and LM scores -> Final hypothesis selection

- Critical path:
  1. Audio input → First-pass E2E decoding (with LM if used) → N-best hypotheses.
  2. N-best hypotheses + audio + lexicon → Second-pass AM rescoring.
  3. Fusion of E2E scores, AM scores, and LM scores → Final hypothesis selection.

- Design tradeoffs:
  - AM fusion vs. LM fusion: AM fusion directly addresses domain mismatch in the acoustic model, while LM fusion addresses language model coverage. AM fusion is more effective for pronunciation issues, but requires an external AM and lexicon.
  - First-pass vs. second-pass AM fusion: First-pass fusion could provide more improvement but is more complex due to different modeling units (wordpieces vs. phonemes). Second-pass fusion is simpler but limited by first-pass N-best quality.
  - External AM choice: More powerful AMs (e.g., SNDCNN-tri) provide greater improvement but may have higher computational cost. Simpler AMs (e.g., Conformer-mono) are faster but may offer less benefit.

- Failure signatures:
  - Degraded WER: If the external AM's pronunciation lexicon is incompatible with the E2E model's subword tokenization, or if the AM scores are not properly scaled for interpolation.
  - No improvement: If the first-pass N-best list is of poor quality, or if the external AM's domain is too different from the target domain.
  - Increased latency: If the second-pass rescoring is not optimized, or if the external AM is too large/complex.

- First 3 experiments:
  1. Implement AM fusion on a simple dataset (e.g., Librispeech) using a pre-trained external AM (e.g., Conformer-mono) and measure WER improvement.
  2. Vary the λAM weight to find the optimal interpolation point between the E2E model and external AM.
  3. Compare AM fusion performance on in-domain vs. out-of-domain external AMs to assess domain adaptation benefits.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does AM fusion compare to traditional hybrid ASR systems in terms of handling out-of-vocabulary words?
- Basis in paper: [inferred] The paper discusses AM fusion's effectiveness in improving recognition of under-represented words and phrases, particularly named entities, but does not directly compare it to hybrid systems in this aspect.
- Why unresolved: The paper focuses on comparing AM fusion to E2E systems with and without LM fusion, but does not provide a direct comparison with hybrid systems.
- What evidence would resolve it: A comparative study between AM fusion-enhanced E2E systems and traditional hybrid ASR systems, specifically measuring their performance on out-of-vocabulary words and named entities.

### Open Question 2
- Question: What is the optimal strategy for balancing the weights of external AM and LM in AM fusion?
- Basis in paper: [explicit] The paper mentions that tunable weights λLM and λAM are introduced to balance the external and internal language models, but does not provide a detailed analysis of the optimal strategy.
- Why unresolved: The paper acknowledges the need for balancing these weights but does not explore the optimal strategy or provide a systematic approach for weight selection.
- What evidence would resolve it: A comprehensive study analyzing the impact of different weight combinations on various datasets and scenarios, potentially leading to a generalized weight selection strategy.

### Open Question 3
- Question: How does the effectiveness of AM fusion vary with different acoustic modeling units (e.g., monophones, triphones, wordpieces)?
- Basis in paper: [explicit] The paper experiments with different acoustic modeling units (Conformer-wp, Conformer-mono, SNDCNN-tri) and shows varying levels of improvement with AM fusion, but does not provide a detailed analysis of the relationship between modeling units and fusion effectiveness.
- Why unresolved: While the paper demonstrates that different modeling units lead to different improvements, it does not explore the underlying reasons or provide a theoretical framework for understanding this relationship.
- What evidence would resolve it: A detailed analysis correlating the properties of different acoustic modeling units with the effectiveness of AM fusion, potentially leading to insights on the optimal choice of modeling units for different scenarios.

## Limitations
- External AM dependency: Effectiveness heavily depends on the quality and domain alignment of the external AM
- First-pass N-best quality: AM fusion is limited by the quality of the N-best hypotheses from the first pass
- Computational overhead: Introduces additional computational cost compared to single-pass E2E systems

## Confidence

- **High Confidence**: The paper provides sufficient details on the AM fusion mechanism, the experimental setup, and the evaluation metrics. The reported WER improvements and named entity recognition benefits are supported by the experimental results on the specified datasets.

- **Medium Confidence**: The choice of external AM models (Conformer-mono and SNDCNN-tri) and their training details are not fully specified. The impact of the external AM's domain and quality on the fusion performance is not thoroughly analyzed.

- **Low Confidence**: The generalizability of the AM fusion approach to other domains, languages, and E2E architectures is not extensively validated. The long-term stability and robustness of the fusion system under varying conditions are not evaluated.

## Next Checks

1. **Domain Adaptation Study**: Conduct experiments with external AMs trained on different domains (e.g., conversational speech, telephony, broadcast news) to assess the impact of domain mismatch on AM fusion performance. Compare the results with internal AM fusion and LM fusion to determine the most effective approach for each domain.

2. **N-Best Quality Analysis**: Investigate the relationship between first-pass N-best list quality and AM fusion effectiveness. Measure the oracle WER of the N-best list and correlate it with the actual WER improvement achieved through AM fusion. Explore techniques to enhance the first-pass decoding, such as increasing beam size or using ensemble models, to improve the potential for AM fusion.

3. **Real-Time Streaming Evaluation**: Implement AM fusion in a streaming E2E ASR system and measure the impact on real-time performance. Compare the latency and accuracy trade-offs with other fusion techniques (e.g., LM fusion, hybrid systems) to determine the practical viability of AM fusion for streaming applications.