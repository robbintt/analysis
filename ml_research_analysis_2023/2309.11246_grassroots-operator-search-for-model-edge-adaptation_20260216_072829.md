---
ver: rpa2
title: Grassroots Operator Search for Model Edge Adaptation
arxiv_id: '2309.11246'
source_url: https://arxiv.org/abs/2309.11246
tags:
- search
- operator
- rate
- operators
- space
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces Grassroots Operator Search (GOS), a novel
  Hardware-Aware Neural Architecture Search (HW-NAS) methodology that adapts deep
  learning models for edge devices by replacing inefficient operators. GOS addresses
  the bias in traditional NAS approaches by constructing new operators from scratch
  using mathematical instructions rather than relying on pre-defined operator sets.
---

# Grassroots Operator Search for Model Edge Adaptation

## Quick Facts
- arXiv ID: 2309.11246
- Source URL: https://arxiv.org/abs/2309.11246
- Reference count: 37
- Key outcome: Achieved 3.17x average speedup on edge devices while maintaining accuracy through iterative operator replacement

## Executive Summary
Grassroots Operator Search (GOS) introduces a novel Hardware-Aware Neural Architecture Search methodology that adapts deep learning models for edge devices by iteratively replacing inefficient operators with mathematically constructed alternatives. The approach addresses the bias in traditional NAS methods by constructing new operators from scratch using basic mathematical instructions rather than relying on predefined operator sets. Tested on Raspberry Pi 3 and Redmi Note 7S devices with various architectures including ResNet18, InceptionV3, and MobileNetV3, GOS achieved consistent improvements with an average 3.17x speedup while maintaining high accuracy. The method also demonstrated effectiveness in a practical use case of pulse rate estimation on wristband devices, achieving state-of-the-art performance with reduced computational complexity.

## Method Summary
GOS adapts deep learning models for edge devices by replacing inefficient operators through an iterative evolutionary search algorithm. The method constructs new operators from scratch using mathematical instructions rather than predefined operator sets, focusing on the most inefficient operators identified through hardware-specific latency and parameter analysis. Each operator is represented as a computation graph of basic mathematical operations, allowing the evolutionary algorithm to discover novel implementations that maintain accuracy while improving efficiency. The search optimizes for multiple hardware metrics including latency and parameter count while maintaining accuracy within an epsilon threshold, using crowding distance to maintain diversity in the Pareto front. After operator replacement, the adapted operators undergo fine-tuning for few epochs before validation on target edge devices.

## Key Results
- Achieved consistent improvements across multiple architectures with an average 3.17x speedup on edge devices
- Maintained high accuracy during operator replacement, staying within epsilon threshold constraints
- Demonstrated practical effectiveness in pulse rate estimation task with state-of-the-art performance and reduced computational complexity
- Successfully adapted models for two different edge platforms: Raspberry Pi 3 and Redmi Note 7S

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Iterative operator replacement focused on hardware inefficiency achieves faster convergence than full architecture search
- Mechanism: By analyzing each operator's latency and parameter count, the method identifies and replaces only the most inefficient operators in a model, rather than searching the entire architecture space
- Core assumption: The bottleneck in model efficiency is localized to specific operators rather than requiring complete architectural redesign
- Evidence anchors: [abstract] "Our approach is grassroots since it relies on the mathematical foundations to construct new and efficient operators for DL architectures"; [section 3.1] "Our technique aims to break the time-consuming barrier of non-restrictive search spaces by concentrating on the adaptation of individual operators step-by-step"

### Mechanism 2
- Claim: Mathematical instruction-based search space enables novel operator discovery beyond predefined operator sets
- Mechanism: Operators are represented as computation graphs of basic mathematical instructions (matrix operations, activations, etc.), allowing evolutionary algorithms to discover new implementations that maintain accuracy while improving efficiency
- Core assumption: Novel efficient operators can be constructed from combinations of basic mathematical operations that maintain the same input/output shapes
- Evidence anchors: [section 3.1] "We express each operator as a set of mathematical instructions that capture its behavior" and "Our approach is grassroots since it relies on the mathematical foundations"; [section 3.2] "The computation graph is a directed acyclic graph (DAG) with N nodes and E edges" describing the mathematical instruction representation

### Mechanism 3
- Claim: Multi-objective evolutionary search with crowding distance effectively balances hardware efficiency and accuracy
- Mechanism: The evolutionary algorithm optimizes for both latency and parameter count while maintaining accuracy within an epsilon threshold, using crowding distance to maintain diversity in the Pareto front
- Core assumption: Hardware efficiency improvements can be achieved without significant accuracy degradation when operators are carefully selected and adapted
- Evidence anchors: [section 3.2] "We rely on the crowding distance [23] to minimize multiple objectives under an accuracy constraint" and "The operator's latency is computed with the difference between the original model's latency and the latency of the adapted model"; [section 4.2] "Our operator replacement method consistently outperformed the original models with an average speedup of 3.17" while maintaining accuracy

## Foundational Learning

- Concept: Computation graphs and DAG representation
  - Why needed here: Understanding how operators are represented as directed acyclic graphs of mathematical instructions is fundamental to grasping the search methodology
  - Quick check question: How does the input/output shape constraint affect valid mutation operations in the computation graph?

- Concept: Multi-objective optimization with Pareto fronts
  - Why needed here: The method balances multiple hardware efficiency metrics (latency, parameters) while maintaining accuracy, requiring understanding of Pareto optimization concepts
  - Quick check question: Why is crowding distance used instead of simple weighted sum for the multi-objective fitness function?

- Concept: Evolutionary algorithms and tournament selection
  - Why needed here: The operator adaptation process uses evolutionary search with mutation and crossover operations to explore the mathematical instruction space
  - Quick check question: How does tournament selection ensure both exploitation of good solutions and exploration of novel ones?

## Architecture Onboarding

- Component map: Operator complexity analysis -> Computation graph generation -> Evolutionary search engine -> Fine-tuning module -> Validation on target device
- Critical path: Operator selection → Computation graph generation → Evolutionary search → Fine-tuning → Validation on target device
- Design tradeoffs: Granularity of mathematical instruction set vs search space size, number of instructions per operator vs generation time, epsilon accuracy tolerance vs hardware efficiency gains
- Failure signatures: Accuracy degradation beyond epsilon threshold, inability to reduce latency/parameters, search convergence to invalid operators, excessive fine-tuning time
- First 3 experiments:
  1. Replace convolution operators in ResNet18 on Raspberry Pi with generated variants, measure latency reduction and accuracy maintenance
  2. Test batch normalization operator replacement on MobileNetV3, verify mathematical instruction adaptations maintain normalization properties
  3. Implement pulse rate estimation use case with RF model optimization, compare latency and accuracy against baseline

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the GOS methodology scale when applied to very large models with hundreds of layers or complex architectures like transformers?
- Basis in paper: [explicit] The paper mentions that GOS stops after modifying at least 10 layers, suggesting a limit to the number of iterations, but doesn't explore scaling to larger architectures.
- Why unresolved: The paper focuses on models with relatively few layers (ResNet18, InceptionV3, MobileNetV3) and doesn't demonstrate performance on larger models or transformers.
- What evidence would resolve it: Experiments showing GOS performance on models with 100+ layers or transformer architectures, including computational complexity analysis and hardware efficiency improvements.

### Open Question 2
- Question: Can the mathematical instruction search space be further optimized to reduce the sparsity problem observed in random generation?
- Basis in paper: [explicit] Figure 2 shows high sparsity in the search space with random sampling, requiring adaptation from original operators to achieve better results.
- Why unresolved: The paper doesn't explore alternative search space formulations, meta-learning approaches, or instruction pruning strategies to address the sparsity issue.
- What evidence would resolve it: Comparative experiments testing alternative search space designs, instruction reduction techniques, or meta-learning methods that improve the ratio of valid operators found through random sampling.

### Open Question 3
- Question: What is the generalization capability of operators discovered through GOS across different hardware platforms?
- Basis in paper: [inferred] The paper focuses on platform-specific optimization (Raspberry Pi vs Redmi Note 7S) but doesn't investigate whether operators optimized for one platform maintain efficiency on others.
- Why unresolved: Each experiment trains models specifically for a single target device without testing cross-platform transferability of the discovered operators.
- What evidence would resolve it: Experiments measuring performance of operators optimized for one platform (e.g., Raspberry Pi) when deployed on different hardware (e.g., Redmi Note 7S or other edge devices), including comparative efficiency metrics.

## Limitations

- The methodology's effectiveness on very large models with hundreds of layers or complex architectures like transformers remains unproven
- The mathematical instruction-based search space exhibits high sparsity with random sampling, requiring adaptation from original operators
- The computational cost of the GOS search process compared to runtime savings on edge devices lacks cost-benefit analysis

## Confidence

**Medium Confidence**: The iterative operator replacement approach achieving 3.17x average speedup while maintaining accuracy - supported by experimental results but limited to specific models and datasets.

**Low Confidence**: The mathematical instruction-based search space enabling novel operator discovery - theoretical foundation exists but practical effectiveness unproven across diverse operator types.

**Medium Confidence**: The multi-objective evolutionary search with crowding distance effectively balancing efficiency and accuracy - methodology described clearly but validation is limited to the presented experiments.

## Next Checks

1. **Cross-model validation**: Apply GOS to additional architecture families beyond ResNet18, InceptionV3, and MobileNetV3 to verify the generalizability of the iterative operator replacement approach across diverse model architectures.

2. **Operator type analysis**: Systematically test operator replacement across different operator categories (convolutions, batch normalization, pooling, etc.) to determine which operator types benefit most from mathematical instruction-based optimization.

3. **Baseline comparison study**: Implement a full architecture search baseline using the same hardware constraints to quantify the claimed efficiency gains of the iterative approach versus complete architectural redesign.