---
ver: rpa2
title: A prediction and behavioural analysis of machine learning methods for modelling
  travel mode choice
arxiv_id: '2301.04404'
source_url: https://arxiv.org/abs/2301.04404
tags:
- data
- methods
- which
- choice
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper conducts a systematic comparison of machine learning
  (ML) and discrete choice models (DCMs) for travel mode choice prediction, addressing
  limitations in existing literature. It evaluates models across multiple datasets
  (real and synthetic) and performance metrics, including out-of-sample predictive
  accuracy, market share estimates, behavioral indicators (like Willingness to Pay),
  and computational efficiency.
---

# A prediction and behavioural analysis of machine learning methods for modelling travel mode choice

## Quick Facts
- arXiv ID: 2301.04404
- Source URL: https://arxiv.org/abs/2301.04404
- Reference count: 20
- Primary result: XGBoost and RF achieve highest predictive accuracy but poor behavioral indicator estimates compared to MNL and DNN

## Executive Summary
This paper systematically compares machine learning (ML) and discrete choice models (DCMs) for travel mode choice prediction, addressing technical limitations in existing literature. Using 15 datasets (3 real, 12 synthetic), the study evaluates models across predictive accuracy, market share estimates, behavioral indicators (like Willingness to Pay), and computational efficiency. While extreme gradient boosting and random forests achieve the highest predictive accuracy, they perform worse in estimating behavioral indicators and market shares compared to multinomial logit (MNL) and deep neural networks (DNNs). The research demonstrates that ML techniques can improve estimates of behavioral indices such as Willingness to Pay, but proper validation schemes and hyperparameter optimization are critical for fair comparison.

## Method Summary
The study uses 70% training/30% test split with 5-fold CV for hyperparameter tuning using Tree-structured Parzen Estimators (TPE). Models include MNL, SVM, RF, XGBoost, NN, and DNN, evaluated on accuracy, GMPCA, market shares, and WTP calculations. The research addresses technical limitations like inappropriate validation schemes, incorrect sampling for hierarchical data, and lack of external validation through systematic methodology across synthetic and real datasets.

## Key Results
- XGBoost and Random Forests achieve highest predictive accuracy but provide poorer behavioral indicator estimates than MNL and DNN
- MNL models are robust across various scenarios and datasets
- ML techniques can improve estimates of behavioral indices such as Willingness to Pay when properly calibrated
- Hyperparameter optimization and proper data splitting are critical for fair ML vs. RUM comparison

## Why This Works (Mechanism)

### Mechanism 1
RUMs compute choice probabilities using specified utility functions and assumed error distributions (e.g., Gumbel for logit), enabling analytical derivation of behavioral indices like Willingness to Pay. ML methods estimate probabilities directly without utility structure, making behavioral metric extraction harder unless additional steps are taken. Core assumption: utility function structure is known for RUMs; ML models lack explicit utility specification.

### Mechanism 2
Tree-based ensemble methods (XGBoost, RF) optimize classification accuracy directly, not probability calibration. Their non-differentiable structure complicates derivative-based behavioral index calculation (e.g., WTP). DNNs and MNL better preserve probability smoothness needed for behavioral interpretation. Core assumption: behavioral indicators rely on accurate probability derivatives, harder to compute for tree-based models.

### Mechanism 3
Poor validation schemes (e.g., not accounting for panel data) cause data leakage and inflate ML performance. Systematic hyperparameter tuning using cross-validation prevents bias and ensures comparable model quality. Core assumption: validation methodology must respect data hierarchy and avoid leakage.

## Foundational Learning

- Concept: Random Utility Models (RUMs) and utility maximization
  - Why needed: Understanding RUMs is essential to grasp how traditional travel mode choice models work and differ from ML approaches
  - Quick check: In a logit model, what distribution is assumed for the error term, and how does it affect the choice probability formula?

- Concept: Machine Learning classifiers and probability calibration
  - Why needed: ML models often output class scores, not calibrated probabilities; knowing how to calibrate them is key for behavioral analysis
  - Quick check: What is Platt scaling, and when is it used in SVM classification?

- Concept: Willingness to Pay (WTP) and its derivation from choice models
  - Why needed: WTP is a central behavioral indicator; understanding its computation from derivatives of choice probabilities is crucial for comparing RUMs and ML models
  - Quick check: How is WTP defined in terms of marginal utilities in a linear utility model?

## Architecture Onboarding

- Component map: Data preprocessing -> Model suite (MNL, SVM, RF, XGBoost, NN, DNN) -> Hyperparameter tuning (TPE, 5-fold CV) -> Validation (5-fold CV, hold-out test) -> Behavioral analysis (Market share, WTP)
- Critical path: Load and preprocess datasets → Split into training (70%) and test (30%) sets respecting panel structure → Run TPE hyperparameter optimization using 5-fold CV for each model → Train final models with optimized hyperparameters → Evaluate accuracy, GMPCA on test set → Compute market shares and WTP from probability outputs
- Design tradeoffs: Tree-based models (RF, XGBoost) offer high accuracy but poor behavioral interpretability due to non-differentiability; DNNs provide good balance if properly regularized; MNL is interpretable and robust but may mis-specify non-linear utilities; SVM gives good probability estimation when calibrated but can be computationally heavy
- Failure signatures: Inflated ML accuracy due to data leakage from improper panel data handling; invalid WTP estimates (NaN, infinite) from numerical derivative approximation on non-differentiable models; poor extrapolation for tree-based models outside training domain; DNN instability due to hyperparameter sensitivity or overfitting
- First 3 experiments: 1) Train MNL and XGBoost on Optima dataset, compare accuracy and GMPCA on test set; 2) Compute WTP distributions for NN and SVM on synthetic linear utility data, compare with true values; 3) Evaluate market share extrapolation for RF and DNN on synthetic data with modified features outside [0,1] domain

## Open Questions the Paper Calls Out

### Open Question 1
How can machine learning models be integrated into practice for travel mode choice modeling, given their potential to correct estimates from MNL models? While the paper proposes screening results based on inconsistency, it does not provide a clear methodology for integration. Developing a systematic approach to combine MNL and ML outputs, validated on real-world datasets, would resolve this.

### Open Question 2
What is the impact of different hyperparameter optimization techniques on the performance of machine learning models for travel mode choice prediction? The paper uses TPE but does not explore other methods. Comparative studies using different optimization techniques across various datasets to assess their impact on model accuracy and behavioral indicators would resolve this.

### Open Question 3
How does the inclusion of additional socioeconomic variables affect the performance and interpretability of machine learning models in travel mode choice? The paper focuses on existing datasets with predefined variables, implying a potential gap in exploring the impact of additional variables. Experiments incorporating diverse socioeconomic variables into models and analyzing changes in predictive accuracy and behavioral indicators would resolve this.

## Limitations
- Tree-based models struggle with behavioral index estimation due to non-differentiability, limiting interpretability
- Evaluation relies on synthetic datasets with known utility functions that may not capture real-world complexities
- Extrapolation performance beyond [0,1] domain remains largely theoretical with minimal empirical validation

## Confidence

- High: Predictive accuracy comparisons across models are well-supported with systematic hyperparameter tuning and proper validation
- Medium: Behavioral indicator comparisons are valid but limited by the non-differentiability of tree-based models
- Low: Extrapolation performance beyond [0,1] domain remains largely theoretical with minimal empirical validation

## Next Checks

1. Test whether smoothing techniques (e.g., isotonic calibration) improve behavioral index estimation for RF and XGBoost models
2. Validate market share estimates under scenarios with modified feature distributions outside the training domain
3. Compare WTP estimates from numerical derivatives with analytical solutions on synthetic datasets to quantify approximation errors