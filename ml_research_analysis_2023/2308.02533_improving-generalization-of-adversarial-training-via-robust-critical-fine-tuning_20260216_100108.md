---
ver: rpa2
title: Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning
arxiv_id: '2308.02533'
source_url: https://arxiv.org/abs/2308.02533
tags:
- robustness
- module
- adversarial
- robust
- fine-tuning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the trade-off between generalization and adversarial
  robustness in deep neural networks. The proposed method, Robust Critical Fine-Tuning
  (RiFT), identifies non-robust-critical modules in adversarially trained models using
  a metric called Module Robust Criticality (MRC).
---

# Improving Generalization of Adversarial Training via Robust Critical Fine-Tuning

## Quick Facts
- arXiv ID: 2308.02533
- Source URL: https://arxiv.org/abs/2308.02533
- Reference count: 40
- One-line primary result: RiFT improves generalization by ~2% and out-of-distribution robustness by ~2% while maintaining adversarial robustness in adversarially trained models.

## Executive Summary
This paper addresses the fundamental trade-off between generalization and adversarial robustness in deep neural networks. The proposed Robust Critical Fine-Tuning (RiFT) method identifies non-robust-critical modules in adversarially trained models using Module Robust Criticality (MRC) and fine-tunes these modules on standard data. The method then interpolates between adversarially trained and fine-tuned weights to achieve simultaneous improvements in both generalization and out-of-distribution robustness while maintaining adversarial robustness. Experiments demonstrate consistent performance gains across multiple datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet) and architectures (ResNet18, ResNet34, WideResNet34-10).

## Method Summary
RiFT operates in three stages: First, it performs adversarial training on the target dataset to obtain an initial robust model. Second, it calculates Module Robust Criticality (MRC) for each module by measuring the maximum robustness loss under constrained weight perturbations, identifying non-robust-critical modules. Third, it fine-tunes the identified non-robust-critical module on standard data, then interpolates between the adversarially trained and fine-tuned weights to find an optimal balance. The interpolation coefficient is chosen to maximize generalization improvement while maintaining or slightly improving adversarial robustness.

## Key Results
- RiFT improves generalization by approximately 2% across CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets
- Out-of-distribution robustness improves by around 2% on corrupted test sets
- Adversarial robustness is maintained or slightly enhanced compared to baseline adversarial training
- The method consistently outperforms standard adversarial training and can be combined with other techniques like TWINS

## Why This Works (Mechanism)

### Mechanism 1
Fine-tuning on non-robust-critical modules can improve both generalization and adversarial robustness simultaneously by exploiting redundant capacity. The features learned during fine-tuning on these modules are complementary to those learned during adversarial training.

### Mechanism 2
MRC provides an upper bound on the potential loss of adversarial robustness when fine-tuning specific modules by analyzing worst-case weight perturbations. This identifies modules that can be fine-tuned without harming robustness.

### Mechanism 3
Interpolation between adversarially trained and fine-tuned weights finds an optimal balance by linearly combining beneficial properties from both models.

## Foundational Learning

- Concept: Adversarial training and its trade-off with generalization
  - Why needed here: Understanding the baseline problem that RiFT addresses - the inherent trade-off between adversarial robustness and generalization in deep neural networks
  - Quick check question: What is the primary goal of adversarial training, and what is its main drawback according to the paper?

- Concept: Module criticality and its role in model performance
  - Why needed here: Recognizing that different modules in a neural network contribute differently to model performance, and that some modules have redundant capacity that can be exploited
  - Quick check question: How does the concept of module criticality differ from traditional notions of parameter importance in neural networks?

- Concept: Fine-tuning strategies and their impact on model properties
  - Why needed here: Understanding how fine-tuning can be used to improve model properties without starting from scratch, and the potential risks and benefits associated with fine-tuning different parts of a model
  - Quick check question: What are the potential risks of fine-tuning an adversarially trained model, and how does RiFT mitigate these risks?

## Architecture Onboarding

- Component map: Adversarial training -> MRC calculation -> Fine-tuning -> Interpolation
- Critical path: 1) Perform adversarial training 2) Calculate MRC for each module 3) Fine-tune non-robust-critical module 4) Interpolate weights to find optimal model
- Design tradeoffs: Choice of fine-tuning learning rate affects interpolation factor; constraint on weight perturbations in MRC affects module identification; number of modules fine-tuned impacts effectiveness
- Failure signatures: Significant degradation in adversarial robustness after fine-tuning; minimal generalization improvement; interpolation fails to balance objectives
- First 3 experiments: 1) Verify non-robust-critical modules by perturbing weights and measuring robustness impact 2) Fine-tune single non-robust-critical module and evaluate impact 3) Perform interpolation and find optimal interpolation factor

## Open Questions the Paper Calls Out

### Open Question 1
What is the exact relationship between the scale of the dataset (number of classes and samples) and the existence of non-robust-critical modules in adversarially trained models? The paper observes that more complex tasks lead to fewer non-robust-critical modules but provides no theoretical explanation.

### Open Question 2
How does the choice of interpolation factor (α*) affect the trade-off between generalization and adversarial robustness in RiFT? The paper mentions the relationship with fine-tuning learning rate but lacks detailed analysis of different α* values.

### Open Question 3
Can the concept of Module Robust Criticality (MRC) be extended to capture the importance of multiple modules simultaneously? The paper suggests this could address limitations but doesn't provide a concrete method.

## Limitations

- The exact implementation details of MRC calculation and interpolation procedure are not fully specified, affecting reproducibility
- Empirical support for the specific mechanism of simultaneous improvement is weak in the provided corpus
- The paper lacks theoretical justification for why fine-tuning non-robust-critical modules improves both generalization and robustness

## Confidence

- **High Confidence**: The trade-off between generalization and adversarial robustness is well-established
- **Medium Confidence**: The concept of Module Robust Criticality and its potential to identify fine-tunable modules is theoretically sound
- **Low Confidence**: The claim that RiFT significantly improves both generalization and out-of-distribution robustness requires more rigorous validation

## Next Checks

1. Conduct experiments to validate that MRC accurately identifies non-robust-critical modules by perturbing weights and measuring the actual impact on adversarial robustness
2. Perform ablation studies to determine the optimal number of modules to fine-tune simultaneously and the effect of different learning rates on the interpolation balance
3. Compare RiFT's performance against other state-of-the-art methods for improving generalization in adversarially trained models, such as TWINS or other fine-tuning approaches