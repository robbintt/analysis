---
ver: rpa2
title: 'Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled
  Text'
arxiv_id: '2311.18805'
source_url: https://arxiv.org/abs/2311.18805
tags:
- scrambled
- llms
- gpt-4
- performance
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates the ability of large language models (LLMs)
  to handle character-level permutations, specifically scrambled text. To measure
  this, the authors propose the Scrambled Bench, a test suite including tasks to recover
  original sentences from scrambled ones and answer questions given scrambled context.
---

# Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text

## Quick Facts
- **arXiv ID**: 2311.18805
- **Source URL**: https://arxiv.org/abs/2311.18805
- **Reference count**: 40
- **Primary result**: GPT-4 can almost perfectly reconstruct original sentences from scrambled ones, decreasing the edit distance by 95%, a task that poses significant challenges for other LLMs and even humans.

## Executive Summary
This paper investigates the ability of large language models (LLMs) to handle character-level permutations, specifically scrambled text. To measure this, the authors propose the Scrambled Bench, a test suite including tasks to recover original sentences from scrambled ones and answer questions given scrambled context. Surprisingly, most powerful LLMs, particularly GPT-4, demonstrate the capability to handle scrambled text to varying degrees, even when all letters within each word are entirely scrambled. GPT-4 can almost perfectly reconstruct original sentences, decreasing the edit distance by 95%, a task that poses significant challenges for other LLMs and even humans.

## Method Summary
The authors introduce the Scrambled Bench test suite to evaluate LLMs' ability to process scrambled text. This includes two tasks: Scrambled Sentence Recovery (ScrRec) and Scrambled Question Answering (ScrQA). They test various scramble types (Random Scramble, Keep First, Keep First and Last) and rates (20%, 50%, 100%) on datasets like RealtimeQA, DREAM, and AQuA-RAT. The evaluation covers both closed-source models (GPT-4, GPT-3.5-turbo) and open-source models (Falcon-180b, Llama-2-70b), using metrics such as edit distance, recovery rate, accuracy, and relative performance gain. The study also includes finetuning experiments on open-source models to probe the relationship between scrambling ability and model parameters.

## Key Results
- GPT-4 can almost perfectly reconstruct original sentences from scrambled ones, decreasing the edit distance by 95%.
- For the scrambled question answering task, GPT-4 can maintain a very high proportion of its original accuracy using scrambled context.
- GPT-4 significantly outperforms other LLMs in handling scrambled text, even when all letters within each word are entirely scrambled.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-4 can reconstruct scrambled sentences by leveraging internal language understanding beyond token-level dependencies.
- Mechanism: GPT-4 uses contextual embeddings and positional information to infer word identities despite scrambled letters, reducing edit distance by 95% even in 100% randomly scrambled text.
- Core assumption: The model's training includes exposure to varied text forms, enabling robustness to scrambled input that disrupts tokenization.
- Evidence anchors:
  - [abstract] "GPT-4 can almost perfectly reconstruct the original sentences from scrambled ones, decreasing the edit distance by 95%, even when all letters within each word are entirely scrambled."
  - [section] "Counter-intuitively, we show that most powerful LLMs are able to handle scrambled sentences to varying degrees, when we scramble words while keeping the first and last letters unchanged."
  - [corpus] Weak evidence: Related works focus on word/sub-word permutations, not character-level scrambling; corpus does not directly support this mechanism.
- Break condition: If the scrambling disrupts all letter position information (e.g., 100% random with no first/last letter preserved), other models fail, but GPT-4 still performs well, suggesting unique robustness.

### Mechanism 2
- Claim: GPT-4 maintains high accuracy in question answering with scrambled context by utilizing semantic understanding rather than exact token matching.
- Mechanism: The model extracts meaning from context despite token-level noise, preserving relative performance gains (RPG) above 87% even with 100% scrambled evidence.
- Core assumption: GPT-4's training objective emphasizes comprehension over strict adherence to input tokenization.
- Evidence anchors:
  - [abstract] "For the scrambled question answering task, GPT-4 can maintain a very high proportion of its original accuracy using scrambled context."
  - [section] "GPT-4 maintains 87.8% of its original performance even with 100% scrambled evidences."
  - [corpus] Weak evidence: Related studies on word order insensitivity do not address character-level scrambling; corpus lacks direct support.
- Break condition: If context is too long or diverse (e.g., DREAM dataset), even GPT-4's performance degrades, indicating limits of semantic robustness.

### Mechanism 3
- Claim: GPT-4's resilience stems from training on denoising tasks or large-scale exposure to text with errors.
- Mechanism: Exposure to noisy text during training enables the model to correct or bypass scrambled input during inference.
- Core assumption: Training data included diverse error types or denoising objectives that generalize to character scrambling.
- Evidence anchors:
  - [section] "One potential hypothesis is that this capability might stem from training methods, such as including denoising tasks or utilizing a huge corpus of text data with various errors."
  - [section] "FT-RS shows significant improvement over w/o-FT baseline across all tasks, and it achieves positive RR in RS setting, which even surpasses the performance of Falcon-180b."
  - [corpus] Weak evidence: No direct corpus support; related works focus on word order or sub-word perturbations, not character scrambling.
- Break condition: If finetuning on scrambled text improves other models (e.g., Llama-2-13b), but GPT-4's advantage persists, suggesting training beyond denoising is involved.

## Foundational Learning

- Concept: Tokenization and its disruption by character scrambling
  - Why needed here: Scrambled text drastically changes tokenization, challenging models that rely on fixed token vocabularies.
  - Quick check question: How does scrambling "hello" to "hlelo" affect its tokenization in standard subword tokenizers?

- Concept: Edit distance as a metric for text reconstruction
  - Why needed here: Edit distance quantifies how well a model recovers original text from scrambled input, essential for evaluating ScrRec performance.
  - Quick check question: What is the edit distance between "kitten" and "sitting"?

- Concept: Emergent abilities in large language models
  - Why needed here: GPT-4's ability to handle extreme scrambling may be an emergent property not present in smaller models.
  - Quick check question: What is an example of an emergent ability in LLMs that appears only at scale?

## Architecture Onboarding

- Component map: Input (Scrambled text) -> Processor (LLM) -> Output (Recovered sentence or answer) -> Metrics (Edit distance, recovery rate, accuracy, relative performance gain)
- Critical path:
  1. Generate scrambled text (RS, KF, KFL types)
  2. Input to LLM and collect output
  3. Compare output to original text using edit distance or accuracy metrics
  4. Analyze performance across scramble types and rates
- Design tradeoffs:
  - Scramble complexity vs. model capability: Higher scramble rates challenge all models but reveal GPT-4's unique resilience.
  - Zero-shot vs. few-shot settings: Few-shot improves open-source models but GPT-4 excels in both.
  - Dataset choice: RealtimeQA reduces contamination risk but may limit generalizability.
- Failure signatures:
  - Negative recovery rate or accuracy indicates model cannot handle scrambling.
  - Large performance gaps between scramble types suggest reliance on first/last letter cues.
  - Performance degradation with longer or more diverse texts (e.g., DREAM) indicates context limits.
- First 3 experiments:
  1. Test zero-shot ScrRec on 100% randomly scrambled RealtimeQA text with GPT-4 vs. open-source models.
  2. Compare performance on KF vs. KFL scramble types to assess letter position importance.
  3. Evaluate ScrQA on DREAM dataset to measure robustness to longer, diverse texts.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the specific reason GPT-4 can handle scrambled text so well compared to other LLMs?
- Basis in paper: [explicit] The authors mention that GPT-4 significantly outperforms other models but cannot definitively conclude why.
- Why unresolved: The paper states that investigating the reason is difficult because the closed-source models are not directly accessible and little information is known about them (e.g., exact parameter size).
- What evidence would resolve it: Detailed analysis of GPT-4's training process, including whether it involved denoising tasks or exposure to text with various errors, could provide insights. Comparing GPT-4's architecture and training data with other LLMs might also reveal key differences.

### Open Question 2
- Question: How does the ability to handle scrambled text scale with parameter size in LLMs?
- Basis in paper: [explicit] The authors investigate the relationship between the ability to handle scrambled text and parameter scale, but the results are not conclusive.
- Why unresolved: The parameter sizes of GPT-4 and GPT-3.5-turbo are unknown, making it difficult to draw definitive conclusions about the relationship between parameter size and the ability to handle scrambled text.
- What evidence would resolve it: Experiments with LLMs of varying known parameter sizes, including GPT-4 and GPT-3.5-turbo, could provide insights into how the ability to handle scrambled text scales with model size.

### Open Question 3
- Question: How do other types of input perturbations, beyond character-level permutations, affect LLMs' ability to process text?
- Basis in paper: [explicit] The authors acknowledge that there are various ways to disrupt tokenization (e.g., inserting letters, substituting letters) but only investigate character-level permutations.
- Why unresolved: The paper focuses solely on character-level permutations, leaving the impact of other perturbations unexplored.
- What evidence would resolve it: Experiments with LLMs using other types of input perturbations, such as inserting or substituting letters, could reveal how robust they are to different forms of text corruption.

## Limitations

- The mechanism by which GPT-4 achieves its scrambled text handling capability remains speculative, with weak evidence supporting training exposure to denoising tasks or error-prone text.
- The evaluation scope is limited, not exploring the full space of possible scrambling strategies or their impact on model performance.
- Potential data contamination is not fully addressed, with concerns about prior exposure to evaluation datasets affecting results.

## Confidence

- **High confidence**: GPT-4 demonstrates superior performance in recovering original sentences from scrambled text (edit distance reduction by 95%) and maintaining high accuracy in question answering with scrambled context (RPG above 87%).
- **Medium confidence**: The claim that GPT-4's resilience stems from training on denoising tasks or large-scale exposure to text with errors.
- **Low confidence**: The generalizability of results to other domains or languages.

## Next Checks

1. Verify Data Contamination: Confirm that the RealtimeQA dataset used for evaluation was indeed published after the training cutoffs of GPT-4 and other models to rule out data contamination as a source of performance gains.

2. Explore Additional Scramble Types: Extend the evaluation to include a wider range of scrambling strategies, such as those mentioned in the paper (KR2, KL&KR1, KF&KR1) and potentially more extreme variations, to fully characterize GPT-4's robustness limits.

3. Test on Multilingual Datasets: Replicate the experiments on non-English datasets to assess whether GPT-4's scrambled text handling capability generalizes across languages, addressing the current limitation to English text.