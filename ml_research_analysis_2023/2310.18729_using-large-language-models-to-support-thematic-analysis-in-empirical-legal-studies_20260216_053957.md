---
ver: rpa2
title: Using Large Language Models to Support Thematic Analysis in Empirical Legal
  Studies
arxiv_id: '2310.18729'
source_url: https://arxiv.org/abs/2310.18729
tags:
- themes
- codes
- theft
- thematic
- initial
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a framework to support thematic analysis in
  empirical legal studies using large language models. The framework facilitates expert-LLM
  collaboration for generating initial codes, searching for themes, and classifying
  data.
---

# Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies

## Quick Facts
- arXiv ID: 2310.18729
- Source URL: https://arxiv.org/abs/2310.18729
- Reference count: 25
- Primary result: LLM-generated codes and themes can effectively support thematic analysis in legal studies when combined with expert supervision

## Executive Summary
This paper proposes a framework to support thematic analysis in empirical legal studies using large language models, specifically GPT-4. The framework facilitates expert-LLM collaboration for generating initial codes, searching for themes, and classifying data. Experiments with 785 criminal court opinions on theft cases in Czechia demonstrate that GPT-4 can generate reasonable initial codes, improve them with expert feedback, and autonomously discover themes that map fairly well to expert-identified themes. The findings suggest that LLMs can effectively support thematic analysis in empirical legal studies and other inductive coding projects, though subject matter expert supervision remains important.

## Method Summary
The framework uses GPT-4 in a zero-shot setting with expert feedback to support thematic analysis of 785 criminal court opinions on theft cases. The pipeline involves batching data points, generating initial codes with research questions and contextual resources, incorporating expert feedback to refine codes, collating potential themes from initial codes, discovering high-level themes, and assigning themes to data points. The approach leverages GPT-4's strong zero-shot capabilities and instruction-following ability to infer thematic patterns from raw text without pre-training on labeled examples.

## Key Results
- GPT-4 generated reasonable initial codes, with 72.6% deemed reasonable after the first round
- Expert feedback improved code quality significantly, with 88.8% of codes perceived as reasonable after feedback (+16.2% improvement)
- Autonomously discovered themes mapped fairly well to expert-identified themes, with the LLM identifying 8 themes compared to the 14 identified by legal experts
- The model performed well in zero-shot classification of facts descriptions in terms of themes

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The LLM can generate reasonable initial codes when provided with structured prompts and batches of data points
- Mechanism: GPT-4's strong zero-shot capabilities allow it to infer thematic patterns from raw text without pre-training on labeled examples, especially when the prompt includes research questions and contextual resources
- Core assumption: The model's pretraining on diverse text enables it to understand legal terminology and modus operandi descriptions well enough to produce relevant codes
- Evidence anchors:
  - [abstract] "GPT-4 generated reasonable initial codes"
  - [section 6] "After the first round, 72.6% of the 785 predicted codes were deemed reasonable"
- Break condition: If the factual descriptions contain highly domain-specific jargon or complex legal reasoning not captured in the model's pretraining data, code quality degrades sharply

### Mechanism 2
- Claim: Expert feedback improves the quality of initial codes generated by the LLM
- Mechanism: The model can incorporate natural language instructions specifying what to focus on (e.g., target, modus operandi) and what to avoid (e.g., multiplicity of offense), updating its output generation accordingly
- Core assumption: GPT-4's instruction-following capability is robust enough to translate qualitative feedback into improved code generation
- Evidence anchors:
  - [abstract] "capable of improving the quality of the codes based on expert feedback"
  - [section 6] "After the expert feedback was provided... 88.8% of the codes were perceived as reasonable (+16.2% improvement)"
- Break condition: If feedback instructions are contradictory or too complex, the model may produce inconsistent or degraded codes

### Mechanism 3
- Claim: The LLM can autonomously discover high-level themes from collated initial codes and assign data points to these themes
- Mechanism: The model clusters similar initial codes into potential themes, then further condenses these into a compact set of high-level themes, leveraging its ability to generalize patterns across text
- Core assumption: The initial codes produced by the model are sufficiently granular and coherent to enable meaningful theme discovery through iterative clustering
- Evidence anchors:
  - [abstract] "themes autonomously discovered by the LLM appear to map fairly well to the themes arrived at by legal experts"
  - [section 6] "The number of themes discovered by the LLM (8) was less than the number of themes arrived at by the legal experts (14)"
- Break condition: If the initial codes are too heterogeneous or lack clear thematic distinctions, the model may produce an overly broad or fragmented set of themes

## Foundational Learning

- Concept: Thematic analysis phases and methodology
  - Why needed here: Understanding the six phases (especially phases 2-3 for initial coding and theme searching) is critical for interpreting how the LLM supports the analysis and what outputs to expect
  - Quick check question: What are the key outputs expected from phases 2 and 3 of thematic analysis, and how does the LLM's role align with these outputs?

- Concept: Zero-shot learning and instruction-following in LLMs
  - Why needed here: The paper relies on GPT-4's ability to perform complex NLP tasks without labeled examples, guided only by prompts and instructions. This is central to understanding the feasibility of the framework
  - Quick check question: How does zero-shot learning differ from few-shot or fine-tuned learning, and why is it particularly useful for thematic analysis?

- Concept: Qualitative vs. quantitative coding in legal text analysis
  - Why needed here: The framework bridges inductive (thematic) and deductive (theme classification) coding. Knowing the distinction helps in understanding when and how each approach is applied in the pipeline
  - Quick check question: What is the key difference between inductive and deductive coding, and how does the LLM switch between these modes in the proposed framework?

## Architecture Onboarding

- Component map:
  Data batching and preprocessing -> Initial code generation -> Expert feedback loop -> Potential theme collation -> High-level theme discovery -> Theme assignment

- Critical path:
  1. Batch data points -> 2. Generate initial codes -> 3. Expert feedback (if needed) -> 4. Collate potential themes -> 5. Discover high-level themes -> 6. Assign themes to data points

- Design tradeoffs:
  - Batching improves efficiency but may lose context between batches
  - Zero-shot classification avoids labeling overhead but may lack precision for niche themes
  - Expert feedback improves quality but adds time and dependency on domain expertise

- Failure signatures:
  - Low-quality initial codes: overly generic or missing key thematic elements
  - Misaligned themes: discovered themes don't map well to expert-identified themes
  - Inconsistent theme assignment: model assigns conflicting themes to similar data points

- First 3 experiments:
  1. Run the pipeline on a small subset (e.g., 50 cases) without expert feedback to benchmark baseline code and theme quality
  2. Introduce expert feedback on initial codes and measure improvement in code coherence and theme alignment
  3. Compare zero-shot theme assignment performance (R@1, R@3) against a manually annotated gold standard

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the quality of initial codes generated by LLMs compare to those generated by human experts in thematic analysis?
- Basis in paper: [explicit] The paper mentions that GPT-4 generated reasonable initial codes, and the quality improved with expert feedback
- Why unresolved: While the paper suggests that LLM-generated codes are of reasonable quality, it doesn't provide a direct comparison with human-generated codes
- What evidence would resolve it: A study comparing the quality of initial codes generated by LLMs and human experts, using the same dataset and evaluation criteria

### Open Question 2
- Question: What is the optimal balance between LLM autonomy and human expert supervision in thematic analysis?
- Basis in paper: [explicit] The paper suggests that subject matter expert supervision remains important, but also shows that LLMs can perform well autonomously
- Why unresolved: The paper doesn't provide a clear guideline on how much human intervention is needed for optimal results
- What evidence would resolve it: A study testing different levels of human intervention and their impact on the quality and efficiency of thematic analysis

### Open Question 3
- Question: How well do autonomously discovered themes by LLMs align with expert-identified themes across different domains?
- Basis in paper: [explicit] The paper shows that LLM-discovered themes map fairly well to expert-identified themes in the context of theft cases
- Why unresolved: The paper only tests this in the context of theft cases; it's unclear if the results would generalize to other domains
- What evidence would resolve it: Replicating the study in different domains (e.g., medical research, social sciences) to test the generalizability of the findings

## Limitations

- The framework's generalizability beyond theft cases in Czech criminal law remains uncertain
- Expert feedback mechanism lacks detailed documentation of the feedback process and iteration counts
- Single case study without systematic validation across different legal domains or jurisdictions

## Confidence

- **High Confidence**: The claim that GPT-4 can generate reasonable initial codes with structured prompts and improve them with expert feedback
- **Medium Confidence**: The assertion that autonomously discovered themes map fairly well to expert-identified themes
- **Low Confidence**: The framework's effectiveness for thematic analysis in legal studies more broadly

## Next Checks

1. Apply the framework to a different legal domain (e.g., contract law or constitutional law) in the same jurisdiction to assess robustness to topic variation
2. Test the framework on criminal court opinions from another jurisdiction with a different legal system (e.g., common law) to evaluate cross-jurisdictional applicability
3. Replicate the experiments using the same dataset but with publicly available prompt templates for thematic analysis to assess the impact of prompt specificity on results