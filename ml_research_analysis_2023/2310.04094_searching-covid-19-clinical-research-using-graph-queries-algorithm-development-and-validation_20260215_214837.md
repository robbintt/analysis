---
ver: rpa2
title: 'Searching COVID-19 Clinical Research Using Graph Queries: Algorithm Development
  and Validation'
arxiv_id: '2310.04094'
source_url: https://arxiv.org/abs/2310.04094
tags:
- search
- network
- graph
- abstract
- graphical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "GRAPH-SEARCH enables querying COVID-19 literature using graphical\
  \ abstracts\u2014small concept graphs inspired by those in scientific publications.\
  \ The method annotates abstracts from the CORD-19 corpus using UMLS and CIDO ontologies,\
  \ builds a co-occurrence network of 128,249 entities and 47,198,965 relationships,\
  \ and allows users to express queries as graphs."
---

# Searching COVID-19 Clinical Research Using Graph Queries: Algorithm Development and Validation

## Quick Facts
- arXiv ID: 2310.04094
- Source URL: https://arxiv.org/abs/2310.04094
- Reference count: 35
- Key outcome: GRAPH-SEARCH enables querying COVID-19 literature using graphical abstracts—small concept graphs inspired by those in scientific publications. The method annotates abstracts from the CORD-19 corpus using UMLS and CIDO ontologies, builds a co-occurrence network of 128,249 entities and 47,198,965 relationships, and allows users to express queries as graphs. It finds matches by retrieving shortest paths in the network, ranks results by explained relationships and NPMI scores, and supports interactive path selection and refinement. A web interface facilitates exploration, query formulation, and result interpretation. Informal user feedback indicates high satisfaction with usability, query expressiveness, and result relevance, highlighting the system’s value for scientific hypothesis exploration and literature discovery in clinical domains.

## Executive Summary
This paper presents GRAPH-SEARCH, a novel system for querying COVID-19 clinical research literature using graphical abstracts as query language. The system leverages a co-occurrence network built from CORD-19 abstracts, where concepts are linked based on their co-occurrence patterns weighted by normalized pointwise mutual information (NPMI). Users can express complex biomedical hypotheses as visual graphs, which are then matched against the network to retrieve relevant publications ranked by explained relationships and NPMI scores. While informal user feedback suggests high satisfaction with the system’s usability and result relevance, the evaluation lacks quantitative validation against standard information retrieval benchmarks.

## Method Summary
The method involves annotating CORD-19 abstracts with terms from UMLS and CIDO ontologies using named entity recognition, then constructing a co-occurrence network where entities are connected based on their NPMI-weighted relationships. Graph queries are expressed as graphical abstracts, and the system finds matches by retrieving shortest paths between concept pairs in the network. Publications are ranked by the number of explained relationships and NPMI scores, with an interactive web interface supporting query refinement and result exploration.

## Key Results
- GRAPH-SEARCH builds a co-occurrence network of 128,249 entities and 47,198,965 relationships from CORD-19 abstracts.
- The system enables querying COVID-19 literature using graphical abstracts as visual query language.
- Informal user feedback indicates high satisfaction with usability, query expressiveness, and result relevance for scientific hypothesis exploration.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graphical abstracts as query language enable intuitive expression of complex biomedical hypotheses
- Mechanism: Visual nodes represent concepts from UMLS/CIDO ontologies; edges express co-occurrence relationships; users interactively select shortest paths in the co-occurrence network to expand queries
- Core assumption: Experts can map their research hypotheses to graphical abstract structures and understand the implications of co-occurrence statistics
- Evidence anchors:
  - [abstract] "Graphical abstracts are small graphs of concepts that visually summarize the main findings of scientific articles"
  - [section] "Our graphical language captures some of them, by using - as query language - hierarchical structures of concepts, interlinked by relationships"
  - [corpus] No direct corpus evidence; relies on informal user study feedback
- Break condition: Users cannot translate domain knowledge into graphical abstract structures, or co-occurrence network fails to capture relevant relationships

### Mechanism 2
- Claim: Co-occurrence network construction from CORD-19 abstracts enables literature retrieval via graph matching
- Mechanism: NER and entity linking map abstract text to UMLS/CIDO terms; co-occurrence relationships are weighted by NPMI; graph queries find shortest paths between concept pairs
- Core assumption: Co-occurrence patterns in abstracts reflect meaningful biomedical relationships that can be leveraged for literature discovery
- Evidence anchors:
  - [abstract] "We build a co-occurrence network that includes all relevant concepts mentioned in the corpus, establishing connections when their mutual information is relevant"
  - [section] "We annotate all the abstracts with terms from the UMLS and CIDO... Then, we build a comprehensive network that includes all relevant clinical and biological concepts mentioned in the corpus, linking them based on their co-occurrence"
  - [corpus] Weak: Only informal user feedback provided; no quantitative evaluation of retrieval effectiveness
- Break condition: NPMI-based co-occurrence fails to capture true semantic relationships, or shortest path search produces irrelevant results

### Mechanism 3
- Claim: Interactive path selection and ranking improve relevance of retrieved publications
- Mechanism: System suggests top-10 shortest paths by average NPMI; users select most relevant paths; publications are ranked by explained relationships and NPMI scores
- Core assumption: Users can effectively evaluate path relevance and that the scoring function aligns with user-defined relevance
- Evidence anchors:
  - [abstract] "It also supports partial matches and suggests potential query completions using shortest paths"
  - [section] "Candidate shortest paths are ranked by the average of the NPMI property associated with each relationship along the path; we retain the top ten paths in the ranking"
  - [corpus] No corpus evidence; relies entirely on informal user feedback
- Break condition: Path selection process becomes too time-consuming or user selections do not improve result relevance

## Foundational Learning

- Concept: UMLS and CIDO ontologies
  - Why needed here: Provide standardized biomedical vocabularies for entity recognition and linking
  - Quick check question: What is the difference between UMLS and CIDO in terms of coverage scope?

- Concept: Pointwise Mutual Information (PMI) and Normalized PMI (NPMI)
  - Why needed here: Quantify strength of co-occurrence relationships for graph construction and path ranking
  - Quick check question: How does NPMI normalization prevent bias toward high-frequency concepts?

- Concept: Graph database query processing (Neo4j Cypher)
  - Why needed here: Enable efficient shortest path search and relationship traversal in large co-occurrence networks
  - Quick check question: What is the time complexity of the allShortestPaths function in Neo4j for sparse graphs?

## Architecture Onboarding

- Component map: Frontend (Vue.js + D3.js) → Backend (Python + Swagger) → Neo4j (co-occurrence network) + MariaDB (metadata)
- Critical path: User query → Graphical abstract creation → Shortest path search → Publication retrieval → Result ranking and display
- Design tradeoffs: NPMI threshold selection (balance between specificity and recall), path expansion depth (computational cost vs. expressiveness), ontology selection (coverage vs. complexity)
- Failure signatures: Slow query response (graph size too large), irrelevant results (poor NPMI scoring or ontology coverage), UI confusion (inadequate user guidance for path selection)
- First 3 experiments:
  1. Create simple graphical abstract with two connected concepts; verify shortest path retrieval works
  2. Test NPMI thresholding by varying NPMI cutoff and observing network density changes
  3. Simulate user path selection workflow with pre-defined query and verify publication ranking accuracy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the accuracy and completeness of the co-occurrence network depend on the advances in NER methods employed during the entity mining and linking steps?
- Basis in paper: [explicit] "The completeness and accuracy of the information captured in the co-occurrence network strictly depend on the advances of the NER methods employed during the steps of entity mining and linking."
- Why unresolved: The paper does not provide quantitative analysis or experimental results comparing the performance of different NER methods on the CORD-19 dataset.
- What evidence would resolve it: Comparative studies evaluating various NER methods on the CORD-19 dataset, measuring their impact on the accuracy and completeness of the resulting co-occurrence network.

### Open Question 2
- Question: What is the effectiveness of graphical-abstract-search in terms of equal language expressivity and richness/appropriateness of proposed results compared to traditional keyword search?
- Basis in paper: [explicit] "We also aim to conduct extensive empirical studies, to measure the effectiveness of graphical-abstract-search in terms of equal language expressivity and richness/appropriateness of proposed results."
- Why unresolved: The paper does not present empirical studies comparing the performance of graphical-abstract-search with traditional keyword search methods.
- What evidence would resolve it: User studies and quantitative comparisons evaluating the effectiveness of graphical-abstract-search versus keyword search in terms of query expressiveness, result relevance, and user satisfaction.

### Open Question 3
- Question: How does the use of 'utility' terms (e.g., 'induces', 'increases') affect the selection of relevant publications, and what are the challenges in capturing their intended semantics?
- Basis in paper: [explicit] "Users commented on the richness of the result set; they reported that the relevance of found publications with respect to their initial query was from ‘quite high’ to ‘high’. They appreciated the ease of browsing/analyzing the results, as sorting is made available using different measures (e.g., NPMI, number of explained relations, and number of citations), and explained relationships are graphically shown in small sub-graphs, allowing for immediate inspection."
- Why unresolved: The paper mentions that users appreciated the use of utility terms but does not provide detailed analysis of their impact on search results or discuss the challenges in capturing their intended semantics.
- What evidence would resolve it: Analysis of the impact of utility terms on search results, including their effect on the relevance of retrieved publications and the challenges in capturing their intended semantics.

## Limitations
- Evaluation relies entirely on informal user feedback rather than quantitative metrics or comparison with standard IR benchmarks.
- Claims about improved literature discovery and user satisfaction lack rigorous validation through systematic studies.
- System’s scalability and effectiveness on non-COVID-19 literature remains unknown, as does the impact of ontology coverage gaps on query expressiveness.

## Confidence
- **High Confidence**: The technical implementation details (co-occurrence network construction, Neo4j integration, web interface) are well-documented and reproducible.
- **Medium Confidence**: The system architecture and query processing pipeline are sound, but effectiveness claims lack rigorous validation.
- **Low Confidence**: Claims about improved literature discovery and user satisfaction are based on informal feedback without systematic evaluation.

## Next Checks
1. Conduct quantitative evaluation comparing GRAPH-SEARCH retrieval effectiveness against standard keyword search using precision, recall, and NDCG metrics on a labeled test set.
2. Perform user study with controlled tasks measuring time-to-discovery and relevance judgment accuracy compared to traditional search interfaces.
3. Test system scalability by indexing a broader corpus (e.g., full PubMed) and measuring query response times and network density changes.