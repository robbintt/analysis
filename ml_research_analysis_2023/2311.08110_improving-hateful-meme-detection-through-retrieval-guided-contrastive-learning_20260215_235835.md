---
ver: rpa2
title: Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning
arxiv_id: '2311.08110'
source_url: https://arxiv.org/abs/2311.08110
tags:
- memes
- hateful
- examples
- dataset
- negative
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses hateful meme detection by proposing a retrieval-guided
  contrastive learning method that improves sensitivity to subtle differences between
  memes with opposite meanings. The method incorporates hard negative and pseudo-gold
  positive examples retrieved dynamically during training, aligning embeddings of
  same-class semantically similar memes while separating those of opposite-class confounding
  memes.
---

# Improving Hateful Meme Detection through Retrieval-Guided Contrastive Learning

## Quick Facts
- arXiv ID: 2311.08110
- Source URL: https://arxiv.org/abs/2311.08110
- Reference count: 13
- Primary result: Achieves 86.7% AUROC on HatefulMemes dataset, outperforming larger models

## Executive Summary
This paper addresses the challenge of detecting hateful memes by proposing a retrieval-guided contrastive learning method that improves sensitivity to subtle differences between memes with opposite meanings. The approach dynamically retrieves hard negative and pseudo-gold positive examples during training, creating a hatefulness-aware embedding space that separates confounder memes while aligning same-class semantically similar memes. The method achieves state-of-the-art performance on the HatefulMemes dataset and enables retrieval-based KNN inference that allows developers to update the detection system without retraining, making it practical for real-world deployment.

## Method Summary
The method combines cross-entropy loss with a retrieval-guided contrastive loss that uses dynamically retrieved hard negative and pseudo-gold positive examples. During training, a CLIP-based vision-language encoder creates joint embeddings that are stored in a Faiss database. For each training example, the system retrieves similar memes with opposite labels (hard negatives) and same labels (pseudo-gold positives), then optimizes both the classification objective and contrastive objective to create a well-separated embedding space. The trained encoder can be used with either logistic regression or KNN inference, with the latter allowing zero-shot transfer to new datasets without additional training.

## Key Results
- Achieves 86.7% AUROC on HatefulMemes test set, outperforming much larger fine-tuned models
- Demonstrates effective zero-shot transfer to Harmful-Memes dataset without retraining
- Shows that KNN inference with the learned embedding space maintains high accuracy while enabling system updates through database additions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Retrieval-guided contrastive learning improves hateful meme detection by creating a hatefulness-aware embedding space that separates confounder memes with opposite meanings.
- Mechanism: Dynamically retrieves hard negative examples (semantically similar memes with opposite labels) and pseudo-gold positive examples (semantically similar memes with same labels) during training, then uses contrastive loss to push apart embeddings of opposite-class memes while pulling together same-class embeddings.
- Core assumption: Confounder memes that are visually and textually similar but have opposite hatefulness labels will have embeddings that are close in standard CLIP-based systems, causing misclassification.
- Evidence anchors:
  - [abstract] "Our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in memes that are vital for correct hatefulness classification."
  - [section] "We find that a key factor contributing to misclassification is that confounder memes are located in close proximity in the embedding space due to the high similarity of text/image content."
  - [corpus] Weak - no direct corpus evidence supporting this specific mechanism for hateful memes.

### Mechanism 2
- Claim: The KNN-based inference approach works because the learned embedding space successfully separates hateful and benign memes, allowing majority voting on nearest neighbors to achieve high accuracy.
- Mechanism: After training with retrieval-guided contrastive learning, the embedding space becomes structured such that memes of the same class cluster together while different classes are separated, enabling effective KNN classification without retraining.
- Core assumption: The contrastive learning objective successfully creates a well-separated embedding space that generalizes to unseen data.
- Evidence anchors:
  - [abstract] "We demonstrate a retrieval-based hateful memes detection system, which is capable of making hatefulness classification based on data unseen in training from a database."
  - [section] "We show that the encoder trained on Harmful-Memes can be applied to HatefulMemes without additional training while maintaining high AUC and accuracy using the KNN majority voting classifier."
  - [corpus] Weak - no direct corpus evidence supporting KNN inference performance for hateful memes.

### Mechanism 3
- Claim: Using hard negative and pseudo-gold positive examples during training provides more informative gradient signals than random negative sampling, leading to better hatefulness discrimination.
- Mechanism: By retrieving examples that are most similar to the anchor but have different labels (hard negatives) or same labels (pseudo-gold positives), the contrastive loss receives stronger and more relevant training signals that improve the embedding space quality.
- Core assumption: Dynamically retrieved examples provide better training signals than randomly sampled examples.
- Evidence anchors:
  - [section] "We dynamically retrieve these examples during training and train with the Retrieval-Guided Contrastive Loss in addition to cross-entropy loss."
  - [section] "Introducing training signals with hard negative examples can effectively enhance the embedding space."
  - [corpus] Weak - no direct corpus evidence supporting this specific retrieval-guided approach for hateful memes.

## Foundational Learning

- Concept: Contrastive learning and metric learning
  - Why needed here: The paper builds on contrastive learning principles to create a hatefulness-aware embedding space by pulling together same-class examples and pushing apart different-class examples.
  - Quick check question: What is the difference between contrastive loss and triplet loss, and when would you use each?

- Concept: Multimodal representation learning
  - Why needed here: The system needs to jointly understand visual and textual modalities in memes to detect hatefulness, requiring knowledge of how to fuse and process multimodal data.
  - Quick check question: How do CLIP-based models encode and fuse vision and language representations, and what are the limitations of this approach?

- Concept: Retrieval-based learning and nearest neighbor search
  - Why needed here: The method uses Faiss for efficient nearest neighbor search to retrieve hard negatives and pseudo-gold positives during training and for KNN inference at test time.
  - Quick check question: What are the trade-offs between dense and sparse retrieval methods, and when would you choose one over the other?

## Architecture Onboarding

- Component map: Image pixels (Ii) and overlaid text (Ti) for each meme -> Frozen CLIP encoder + trainable MLP for joint representation -> Faiss database for nearest neighbor search -> Training with cross-entropy loss + Retrieval-Guided Contrastive Loss -> Logistic regression classifier or KNN majority voting

- Critical path:
  1. Encode training data into retrieval database G
  2. For each training example, retrieve hard negatives and pseudo-gold positives
  3. Compute contrastive loss using retrieved examples
  4. Optimize joint loss function
  5. For inference, encode test example and retrieve nearest neighbors for KNN voting

- Design tradeoffs:
  - Dense vs sparse retrieval: Dense retrieval (used here) captures semantic similarity but is computationally expensive; sparse retrieval (BM25) is faster but may miss semantic nuances
  - Number of retrieved examples: More examples provide better gradient signals but increase computational cost and may introduce noise
  - Loss function choice: NLL loss vs triplet loss - NLL performed better in experiments but triplet loss is also viable

- Failure signatures:
  - Performance degradation when retrieval database becomes stale or outdated
  - KNN inference fails if embedding space becomes too clustered or too dispersed
  - Model overfits to retrieved examples if retrieval is not diverse enough

- First 3 experiments:
  1. Baseline: Train with only cross-entropy loss (no contrastive learning) to establish performance floor
  2. Ablation: Train with contrastive loss but without retrieved examples (only in-batch negatives) to measure retrieval contribution
  3. Encoder comparison: Test different VL encoders (CLIP, OpenCLIP, AltCLIP, ALIGN) with RGCL to verify method agnosticism

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of RGCL vary with different choices of VL encoders beyond CLIP variants?
- Basis in paper: [explicit] The paper mentions experimenting with various CLIP variants and ALIGN, but does not explore other types of VL encoders like those based on different architectures or training objectives.
- Why unresolved: The paper focuses on CLIP-based encoders and only briefly mentions ALIGN as an alternative. A comprehensive evaluation across diverse VL encoder architectures would provide a more complete understanding of RGCL's generalizability.
- What evidence would resolve it: Experiments comparing RGCL's performance with different VL encoder architectures (e.g., those based on ResNet, Swin Transformer, or different training objectives) would clarify its effectiveness across a wider range of models.

### Open Question 2
- Question: What is the impact of using different similarity metrics and loss functions in the RGCL objective?
- Basis in paper: [explicit] The paper briefly mentions testing cosine similarity, inner product, and L2 distance as similarity metrics, as well as triplet loss as an alternative to NLL loss, but does not provide a detailed analysis of their impact on performance.
- Why unresolved: While the paper suggests cosine similarity performs slightly better, a thorough investigation of different similarity metrics and loss functions could reveal the optimal combination for RGCL.
- What evidence would resolve it: Experiments comparing the performance of RGCL with different similarity metrics and loss functions on the HatefulMemes dataset would identify the most effective combination.

### Open Question 3
- Question: How does the performance of RGCL change with different numbers of hard negative and pseudo-gold positive examples?
- Basis in paper: [explicit] The paper mentions experimenting with one and two hard negative and pseudo-gold positive examples, but does not explore a wider range of values or provide a systematic analysis of their impact on performance.
- Why unresolved: The optimal number of hard negative and pseudo-gold positive examples may vary depending on the dataset and model architecture. A more comprehensive study would help determine the ideal values for RGCL.
- What evidence would resolve it: Experiments varying the number of hard negative and pseudo-gold positive examples in RGCL and measuring the corresponding performance on the HatefulMemes dataset would reveal the optimal values for these hyperparameters.

## Limitations
- The computational complexity of dynamic retrieval during training may limit scalability to very large datasets
- Performance depends heavily on maintaining a high-quality, up-to-date retrieval database for KNN inference
- The approach hasn't been validated across diverse hatefulness patterns that may emerge after training data collection

## Confidence
- High confidence: The core methodology of using retrieval-guided contrastive learning is technically sound and the reported performance improvements over baseline CLIP-based approaches are plausible given the mechanism described.
- Medium confidence: The claimed state-of-the-art performance against larger models needs independent verification, particularly given the computational efficiency claims relative to much larger models.
- Medium confidence: The KNN inference approach's effectiveness depends on maintaining a high-quality, up-to-date retrieval database, which the paper doesn't fully address.

## Next Checks
1. Reproduce baseline comparisons: Independently implement the cross-entropy only baseline and verify the claimed performance gap before adding contrastive learning components.
2. Database maintenance evaluation: Test the KNN inference system's performance as the retrieval database ages or becomes outdated to assess the practical limitations of the approach.
3. Retrieval quality analysis: Measure the semantic similarity distributions of retrieved hard negative and pseudo-gold positive examples to verify they represent meaningful training signals rather than random noise.