---
ver: rpa2
title: On the Creativity of Large Language Models
arxiv_id: '2304.00008'
source_url: https://arxiv.org/abs/2304.00008
tags:
- creativity
- llms
- language
- creative
- proceedings
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores whether Large Language Models (LLMs) can be
  considered creative by analyzing them under various creativity theories, including
  Boden's three criteria (value, novelty, and surprise) and the perspectives of product,
  process, press, and person. The authors argue that while LLMs can produce valuable
  and novel outputs, they struggle with generating truly surprising or transformational
  creativity due to their autoregressive nature and reliance on learned distributions.
---

# On the Creativity of Large Language Models

## Quick Facts
- arXiv ID: 2304.00008
- Source URL: https://arxiv.org/abs/2304.00008
- Reference count: 29
- Primary result: LLMs can produce valuable and novel outputs but struggle with transformational creativity due to autoregressive limitations

## Executive Summary
This paper explores whether Large Language Models can be considered creative by analyzing them through established creativity theories including Boden's three criteria (value, novelty, and surprise) and perspectives of product, process, press, and person. The authors argue that while LLMs can generate valuable and novel artifacts, they face significant limitations in producing truly surprising or transformational outputs due to their autoregressive nature and reliance on learned distributions. The paper also discusses practical implications including copyright frameworks and societal impacts on creative industries.

## Method Summary
The paper presents a theoretical analysis of LLMs' creative capabilities through the lens of established creativity frameworks rather than empirical evaluation. It examines theoretical criteria including Boden's three criteria (value, novelty, surprise) and other perspectives (product, process, press, person) without specifying particular models or datasets. The analysis focuses on philosophical and conceptual mapping of creativity dimensions to LLM capabilities, identifying strengths and limitations through theoretical reasoning rather than quantitative metrics.

## Key Results
- LLMs can produce valuable and novel artifacts due to scale and training data diversity
- Autoregressive architecture limits LLMs' ability to generate truly surprising or transformational outputs
- LLMs lack key components of human creativity including intrinsic motivation, self-evaluation, and adaptation to societal feedback

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can produce valuable and novel artifacts due to their scale and training data diversity.
- Mechanism: LLMs are trained on massive corpora, exposing them to a wide variety of styles and topics, allowing them to recombine elements in new ways that may be valuable and novel to human readers.
- Core assumption: Training data contains sufficient variety to allow for novel recombination.
- Evidence anchors:
  - [abstract]: "the generated outputs are often of astonishing quality"
  - [section]: "LLMs are capable of producing artifacts that are valuable, achieving novelty and surprise appears to be more challenging"
  - [corpus]: Weak - no corpus paper directly addresses value/novelty claim; weak anchor.
- Break condition: If the training data is too homogeneous or the model is overfit, novelty and value will be limited.

### Mechanism 2
- Claim: LLMs struggle with transformational creativity due to autoregressive training.
- Mechanism: Autoregressive models predict the next token based on learned distributions, making them inherently conservative and less likely to break from existing patterns.
- Core assumption: Autoregressive training restricts the model's ability to generate truly surprising outputs.
- Evidence anchors:
  - [section]: "The autoregressive nature of classic LLMs make them unlikely to generate surprising products"
  - [section]: "Transformational creativity is not achievable by means of the current LLM training solutions"
  - [corpus]: Weak - no corpus paper directly addresses autoregressive limitations; weak anchor.
- Break condition: If training methods shift away from autoregressive architectures, transformational creativity may become possible.

### Mechanism 3
- Claim: LLMs lack the process and press components of creativity, limiting their creative potential.
- Mechanism: LLMs do not possess intrinsic motivation, self-evaluation, or adaptation to societal feedback, which are key aspects of human creativity.
- Core assumption: Creativity requires not just the product, but also the process and societal context.
- Evidence anchors:
  - [section]: "LLMs lack the intention to write" and "do not contain such self-feedback loop"
  - [section]: "LLMs currently lack the ability of adapting through multiple iterations in the way described above"
  - [corpus]: Weak - no corpus paper directly addresses process/press components; weak anchor.
- Break condition: If LLMs are given mechanisms for self-evaluation and adaptation, they may better simulate the creative process and press.

## Foundational Learning

- Concept: Creativity theories (Boden's criteria, product/process/press/person perspectives)
  - Why needed here: Understanding these frameworks is essential to analyze whether LLMs meet the standards of creativity.
  - Quick check question: Can you name Boden's three criteria for creativity and explain how each relates to LLM outputs?

- Concept: Autoregressive language modeling
  - Why needed here: This is the core mechanism by which LLMs generate text, and it directly impacts their creative potential.
  - Quick check question: How does the autoregressive nature of LLMs limit their ability to generate truly surprising or transformational outputs?

- Concept: Copyright and intellectual property for AI-generated works
  - Why needed here: As LLMs become more capable, legal frameworks for protecting and attributing their outputs will become increasingly important.
  - Quick check question: Why are current copyright laws inadequate for AI-generated works, and what are some proposed solutions?

## Architecture Onboarding

- Component map:
  Transformer architecture with attention mechanisms -> Large-scale pretraining on diverse text corpora -> Fine-tuning for specific tasks or styles -> Sampling strategies (e.g., temperature, top-k, nucleus sampling)

- Critical path:
  1. Pretrain transformer on massive text corpus
  2. Fine-tune on task-specific data if needed
  3. Generate text by sampling from the model's output distribution
  4. Apply post-processing or human curation as desired

- Design tradeoffs:
  - Model size vs. computational cost and inference speed
  - Training data diversity vs. domain specificity
  - Sampling randomness vs. coherence and control

- Failure signatures:
  - Repetitive or nonsensical outputs (overfitting or poor sampling)
  - Bias or harmful content (problematic training data)
  - Lack of novelty or surprise (conservative sampling or limited training data)

- First 3 experiments:
  1. Generate text with different sampling strategies (e.g., temperature, top-k) and evaluate novelty and coherence
  2. Fine-tune the model on a specific creative task (e.g., poetry, storytelling) and compare to base model outputs
  3. Implement a simple self-evaluation mechanism and test its impact on output quality and creativity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can LLMs achieve transformational creativity through alternative training architectures or fine-tuning techniques?
- Basis in paper: [explicit] The paper states that "transformational creativity is not achievable by means of the current LLM training solutions" and suggests that "alternative learning architectures are probably necessary."
- Why unresolved: Current LLMs rely on autoregressive training that limits their ability to generate truly surprising or transformational outputs. The paper identifies this as a fundamental limitation but does not provide concrete solutions or evidence of successful approaches.
- What evidence would resolve it: Empirical demonstrations of LLMs achieving transformational creativity through novel training architectures, successful implementation of techniques that allow models to "forget" learned rules, or case studies showing unexpected creative outputs that fundamentally change the state of a creative field.

### Open Question 2
- Question: Can LLMs develop creative self-awareness to evaluate and improve their own outputs?
- Basis in paper: [explicit] The paper identifies this as the "hard problem in machine creativity," noting that "a crucial aspect of the creative process is the perception and the ability of self-evaluating the generated outputs" which current LLMs lack.
- Why unresolved: While LLMs can recognize certain limitations after generating text, they cannot truly self-evaluate their creative quality or learn from their own outputs in a meaningful way. The paper distinguishes this from theory of mind, suggesting it's a distinct and more fundamental challenge.
- What evidence would resolve it: Development of LLMs capable of genuine self-assessment of their creative outputs, demonstrated ability to learn and improve from their own generated content, or creation of feedback loops where models can iteratively refine their work based on self-evaluation metrics.

### Open Question 3
- Question: Can LLMs be integrated into the creative cycle of individuals, field, and domain to achieve ongoing adaptation and influence?
- Basis in paper: [explicit] The paper discusses how LLMs currently "lack the ability of adapting through multiple iterations" in the creative cycle, being "immutable entities" that reflect a fixed state of the domain rather than participating in its evolution.
- Why unresolved: Current LLMs are trained on static datasets and cannot continuously learn from new creative works or adapt to changing cultural contexts. The paper suggests continual learning as a promising direction but notes it remains unexplored for creative applications.
- What evidence would resolve it: Implementation of LLMs that can continuously learn from new creative inputs, demonstrable influence of LLM-generated content on creative fields and domains, or case studies showing LLMs actively participating in and evolving with creative communities over time.

## Limitations
- The analysis relies heavily on theoretical frameworks without empirical validation of LLMs' creative capabilities
- No concrete metrics or evaluation procedures are defined for assessing creativity dimensions
- The paper does not address how different sampling strategies might impact creativity outcomes

## Confidence

**High Confidence**: The theoretical framework mapping between creativity theories and LLM capabilities is well-established and logically sound. The analysis of how autoregressive architectures limit surprise and transformational creativity follows established ML principles.

**Medium Confidence**: The claim that LLMs can produce valuable and novel outputs is supported by the paper's reasoning but lacks empirical validation through systematic evaluation.

**Low Confidence**: The assertion that LLMs cannot achieve transformational creativity is particularly uncertain, as it depends on future developments in training methodologies that are not yet demonstrated.

## Next Checks
1. **Empirical Evaluation**: Design and conduct controlled experiments testing LLMs against each creativity dimension (value, novelty, surprise) using standardized evaluation metrics and human judges.

2. **Sampling Strategy Impact**: Systematically compare different sampling approaches (temperature, top-k, nucleus sampling) on the creativity dimensions to determine if current architectures can achieve higher surprise scores.

3. **Self-Evaluation Mechanism**: Implement and test a simple self-evaluation loop for LLM outputs, measuring whether iterative refinement improves creativity scores and potentially addresses the process and press limitations identified in the paper.