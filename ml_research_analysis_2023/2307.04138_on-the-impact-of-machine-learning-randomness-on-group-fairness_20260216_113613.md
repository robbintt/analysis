---
ver: rpa2
title: On The Impact of Machine Learning Randomness on Group Fairness
arxiv_id: '2307.04138'
source_url: https://arxiv.org/abs/2307.04138
tags:
- fairness
- data
- training
- epoch
- across
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates the sources of high variance in group fairness
  metrics during neural network training. The authors demonstrate that randomness
  in data reshuffling during training, rather than weight initialization, is the dominant
  source of fairness variance.
---

# On The Impact of Machine Learning Randomness on Group Fairness

## Quick Facts
- arXiv ID: 2307.04138
- Source URL: https://arxiv.org/abs/2307.04138
- Reference count: 40
- Key outcome: Data reshuffling during training is the dominant source of variance in group fairness metrics, not weight initialization

## Executive Summary
This paper investigates the sources of high variance in group fairness metrics during neural network training. The authors demonstrate that randomness in data reshuffling, rather than weight initialization, is the dominant source of fairness variance. This occurs because under-represented groups have higher prediction uncertainty, making their outcomes more sensitive to changes in data order. The authors propose using fairness variance across epochs in a single training run as a computationally efficient alternative to multiple runs, and show that custom data orders can improve fairness comparably to existing bias mitigation algorithms.

## Method Summary
The paper uses the Folktables dataset (ACSIncome, ACSEmployment tasks) and CelebA dataset with gender as sensitive attribute. A feed-forward network with one hidden layer of 64 neurons and ReLU activation is trained using cross-entropy loss for 300 epochs with batch size 128 and learning rate 1e-3. The authors compare fairness variance across runs with different randomness conditions (both sources varying, only initialization varying, only reshuffling varying) and measure fairness metrics including average odds, equal opportunity, and demographic parity alongside F1 score.

## Key Results
- Data reshuffling during training is the dominant source of variance in group fairness metrics
- Under-represented groups have higher prediction uncertainty, making their outcomes more sensitive to data order changes
- Fairness variance across multiple training runs can be approximated by sampling across epochs within a single run
- Custom data orders can manipulate group-level accuracy with negligible impact on overall accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Data reshuffling during training is the dominant source of variance in group fairness metrics.
- Mechanism: Under-represented groups have higher prediction uncertainty. This makes their outcomes more sensitive to changes in data order, which reshuffles at each epoch and alters gradient updates.
- Core assumption: Neural network convergence is influenced more by recent gradient updates than distant ones.
- Evidence anchors:
  - [abstract] "The authors demonstrate that randomness in data reshuffling during training, rather than weight initialization, is the dominant source of fairness variance."
  - [section 4] "We show that the variance in group fairness measures is rooted in the high volatility of the learning process on under-represented groups. Further, we recognize the dominant source of randomness as the stochasticity of data order during training."
  - [corpus] Weak—corpus contains related fairness topics but no direct mention of reshuffling dominance.
- Break condition: If groups are balanced in training data, the sensitivity to reshuffling would be uniform and variance would drop.

### Mechanism 2
- Claim: Fairness variance across multiple training runs can be approximated by sampling across epochs within a single run.
- Mechanism: Data order in the final epoch of each run is a random permutation. The distribution of permutations across epochs in one run is identical to the distribution across different runs, so fairness metrics follow the same distribution.
- Core assumption: Random permutations of the training data are uniformly distributed across epochs in a single run and across runs.
- Evidence anchors:
  - [abstract] "we propose that using fairness variance across epochs in a single training run is a good proxy to study fairness variance across multiple runs."
  - [section 7.1] "Thus, we propose evaluating fairness of intermediate checkpoints in a single training run as a proxy for multiple runs."
  - [corpus] Weak—no corpus evidence for the uniformity of permutation distributions.
- Break condition: If the permutation distribution is not uniform, the approximation fails.

### Mechanism 3
- Claim: Custom data orders can manipulate group-level accuracy with negligible impact on overall accuracy.
- Mechanism: By changing the distribution of data in the most recent gradient updates, the loss landscape is temporarily altered, allowing group-level accuracy to be controlled within a single epoch.
- Core assumption: Recent gradient updates have an immediate and dominant effect on model behavior.
- Evidence anchors:
  - [section 6.2] "We demonstrate how to create custom data orders that can efficiently control group-level performances (and thus in turn, model fairness), with a minor impact on the overall accuracy."
  - [abstract] "we show how one can control group-level accuracy (i.e., model fairness), with high efficiency and negligible impact on the model's overall performance, by simply changing the data order for a single epoch."
  - [corpus] Weak—no corpus evidence for custom data order manipulation.
- Break condition: If gradient updates have no immediate effect, the manipulation fails.

## Foundational Learning

- Concept: Group fairness metrics and their definitions (demographic parity, equal opportunity, average odds).
  - Why needed here: The paper studies variance in these metrics across training runs.
  - Quick check question: Can you compute average odds from true positive and false positive rates for each group?

- Concept: Stochastic gradient descent and random reshuffling.
  - Why needed here: The paper identifies reshuffling as the main source of variance, so understanding SGD mechanics is essential.
  - Quick check question: How does reshuffling at each epoch differ from sampling with replacement?

- Concept: Prediction uncertainty estimation (Monte Carlo dropout, Bayesian neural networks).
  - Why needed here: The paper links higher prediction uncertainty in under-represented groups to higher variance in fairness metrics.
  - Quick check question: How does prediction uncertainty differ between groups in a biased dataset?

## Architecture Onboarding

- Component map: Data pipeline → Random reshuffling → Mini-batch gradient updates → Model weights → Fairness metric computation
- Critical path: Data order → Gradient update → Weight change → Prediction for each group → Fairness metric
- Design tradeoffs:
  - Using multiple training runs gives exact variance but is computationally expensive.
  - Using multiple epochs in one run is cheaper but assumes permutation uniformity.
  - Manipulating data order for fairness control risks overfitting to the order.
- Failure signatures:
  - Low variance across runs despite different initializations (suggests reshuffling dominance).
  - High correlation of fairness metrics across epochs within a run (supports the proxy assumption).
  - Large shifts in group accuracy after a single epoch of reordered data (indicates immediate impact).
- First 3 experiments:
  1. Train a model with fixed reshuffling and fixed initialization; record fairness variance across runs. Expect low variance.
  2. Train a model with fixed reshuffling but different initializations; record fairness variance. Expect high variance.
  3. Train a model normally; sample checkpoints across epochs; compare fairness distribution to multiple runs. Expect similarity.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does data order randomness impact fairness metrics other than average odds, equal opportunity, and demographic parity?
- Basis in paper: [explicit] The paper focuses on these three metrics but states that the non-determinism in fairness originates from high prediction uncertainty for minority groups, which would be reflected in any fairness metric defined on these predictions.
- Why unresolved: The authors did not experimentally test other fairness metrics to confirm this hypothesis.
- What evidence would resolve it: Empirical results showing fairness variance patterns for additional metrics like consistency, individual fairness, or other group fairness definitions.

### Open Question 2
- Question: What are the theoretical foundations explaining why minority groups have higher prediction uncertainty and are more sensitive to data reshuffling?
- Basis in paper: [explicit] The paper observes this phenomenon empirically but does not provide a theoretical explanation for why under-represented groups have higher prediction uncertainty.
- Why unresolved: The authors focus on empirical observations rather than theoretical analysis of the underlying mechanisms.
- What evidence would resolve it: Theoretical analysis connecting representation imbalance to prediction uncertainty, or mathematical proofs explaining the relationship between group size and sensitivity to data order changes.

### Open Question 3
- Question: How does the proposed efficient variance estimation method (sampling across epochs) compare to multiple runs in terms of computational cost and accuracy for very large-scale models?
- Basis in paper: [explicit] The paper proposes using variance across epochs as a computationally efficient alternative to multiple runs and provides preliminary evidence for this claim on relatively small models.
- Why unresolved: The experiments are conducted on relatively small models and datasets, not reflecting the computational demands of large-scale models like GPT-3.
- What evidence would resolve it: Empirical comparison of the two methods on large-scale models, measuring both computational cost and accuracy of variance estimation.

## Limitations

- The core claim that reshuffling dominates over initialization has Medium confidence, relying on empirical observations from limited datasets without theoretical guarantees
- The mechanism linking under-representation to reshuffling sensitivity is plausible but not rigorously proven
- The custom data order manipulation approach has Medium confidence with unproven long-term stability and generalization effects

## Confidence

- Reshuffling vs initialization variance hypothesis: Medium
- Epoch variance as proxy for run variance: Medium
- Custom data order manipulation: Medium

## Next Checks

1. Test the reshuffling vs initialization variance hypothesis on additional datasets with different group imbalance patterns to establish generality
2. Verify the permutation uniformity assumption by comparing epoch-wise fairness distributions against true multi-run distributions on larger sample sizes
3. Evaluate whether custom data order improvements persist after fine-tuning and whether they introduce overfitting patterns that degrade out-of-distribution performance