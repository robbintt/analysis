---
ver: rpa2
title: Enhancing Emergency Decision-making with Knowledge Graphs and Large Language
  Models
arxiv_id: '2311.08732'
source_url: https://arxiv.org/abs/2311.08732
tags:
- emergency
- knowledge
- should
- hazardous
- leakage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The study addresses the challenge of providing reliable decision
  support in emergencies by developing E-KELL, a system that integrates knowledge
  graphs (KGs) and large language models (LLMs). E-KELL structures emergency knowledge
  from regulations and standards into a KG and uses a prompt chain to guide LLMs in
  reasoning over it.
---

# Enhancing Emergency Decision-making with Knowledge Graphs and Large Language Models

## Quick Facts
- arXiv ID: 2311.08732
- Source URL: https://arxiv.org/abs/2311.08732
- Reference count: 2
- The study constructs a structured emergency knowledge graph and guides LLMs to reason over it via a prompt chain, achieving high scores of 9.06, 9.09, 9.03, and 9.09 in comprehensibility, accuracy, conciseness, and instructiveness from a group of emergency commanders and firefighters.

## Executive Summary
This study addresses the challenge of providing reliable decision support in emergencies by developing E-KELL, a system that integrates knowledge graphs (KGs) and large language models (LLMs). E-KELL structures emergency knowledge from regulations and standards into a KG and uses a prompt chain to guide LLMs in reasoning over it. In real-world evaluations, E-KELL achieved high scores of 9.06, 9.09, 9.03, and 9.09 in comprehensibility, accuracy, conciseness, and instructiveness from a group of emergency commanders and firefighters, demonstrating significant improvement compared to baseline models.

## Method Summary
E-KELL constructs a KG from Chinese emergency standards and regulations, semi-automatically extracting triples using LLM-based prompts followed by expert manual refinement. The system uses vector embedding and similarity search to retrieve relevant KG segments for user queries, then guides LLMs (specifically ChatGLM-6B) to reason over these segments using carefully designed prompt chains. The approach leverages first-order logic operations for complex queries and includes two user interfaces: a PC interface for commanders and a mixed reality interface for frontline operators.

## Key Results
- E-KELL achieved high expert scores of 9.06 (comprehensibility), 9.09 (accuracy), 9.03 (conciseness), and 9.09 (instructiveness)
- The system outperformed baseline models in all evaluation metrics
- Expert evaluations were conducted with 19 volunteers (9 commanders, 10 firefighters) across 20 sample queries

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The integration of structured knowledge graphs with LLM reasoning significantly reduces hallucinations by constraining outputs to verified triples.
- Mechanism: E-KELL structures emergency knowledge into a KG and uses a prompt chain to guide LLM reasoning over only the relevant KG segments. This limits the LLM's response generation to facts present in the KG, rather than relying on its internal, potentially unreliable, knowledge base.
- Core assumption: LLMs can accurately follow logical reasoning prompts over structured KG segments when provided with clear step-by-step instructions.
- Evidence anchors:
  - [abstract] "The study constructs a structured emergency knowledge graph and guides LLMs to reason over it via a prompt chain."
  - [section] "We introduce a module at the outset of Choudhary's framework, which automatically decomposes queries guided by the prompt. The method above can transform queries into corresponding logical expressions."
  - [corpus] Weak evidence - no direct comparison of hallucination rates between KG-augmented and baseline LLM responses.
- Break condition: If the KG contains errors or is incomplete, the LLM may still produce unreliable outputs based on flawed input triples.

### Mechanism 2
- Claim: Using neighborhood expansion retrieval ensures LLM reasoning focuses on the most relevant KG segments, improving response accuracy.
- Mechanism: The system retrieves only the k-level neighborhood of relevant entities in the KG based on the query, rather than the entire KG. This reduces noise and helps the LLM focus on the specific knowledge needed to answer the query.
- Core assumption: The k-level neighborhood expansion retrieves all and only the relevant triples needed to answer the query accurately.
- Evidence anchors:
  - [section] "It can be accomplished by relaxing the similarity requirements in retrieval or by neighborhood expansion based on retrieval results. These segments of the knowledge graph serve as the foundation for LLM's reasoning."
  - [section] "The k-level neighborhood expansion is defined as..."
  - [corpus] No direct evidence on retrieval accuracy or impact on response quality.
- Break condition: If the neighborhood expansion is too narrow, relevant information may be missed. If too broad, irrelevant information may overwhelm the LLM.

### Mechanism 3
- Claim: Semi-automatic KG construction guided by LLM with expert manual tuning balances quality and scalability.
- Mechanism: The system uses LLM to initially extract triples from text documents, then experts manually refine the KG. This leverages LLM's text processing capabilities while ensuring accuracy through human oversight.
- Core assumption: LLM-extracted triples require significant manual refinement to achieve high quality, but LLM assistance reduces the overall workload.
- Evidence anchors:
  - [section] "We adopt an LLM-based approach to deconstruct triples from the text... A semi-automatic approach is employed to reduce the workload while striving to ensure the quality of knowledge graph construction."
  - [section] "The extensive triples obtained undergo manual fine-tuning to create the final KG."
  - [corpus] No evidence on the ratio of automatic to manual work or the quality improvement from manual refinement.
- Break condition: If manual refinement is too time-consuming, the approach may not scale well. If LLM extraction quality is too low, manual effort may be prohibitive.

## Foundational Learning

- Concept: First-order logic (FOL) operations for KG querying (projection, intersection, union, negation)
  - Why needed here: E-KELL uses FOL to express complex queries over the KG, which the LLM then reasons about. Understanding these operations is crucial for designing effective queries and prompts.
  - Quick check question: What is the difference between a projection query and an intersection query in FOL, and when would you use each?

- Concept: Vector database embedding and similarity search for KG retrieval
  - Why needed here: The KG is converted to vectors for efficient retrieval of relevant segments based on user queries. Understanding this process is important for optimizing retrieval performance.
  - Quick check question: How does the choice of embedding model and similarity metric affect the relevance of retrieved KG segments?

- Concept: Prompt engineering principles for LLM reasoning
  - Why needed here: E-KELL relies heavily on carefully designed prompts to guide LLM reasoning over the KG. Understanding prompt engineering best practices is crucial for effective system design.
  - Quick check question: What are the key differences between zero-shot, few-shot, and chain-of-thought prompting, and when would you use each?

## Architecture Onboarding

- Component map:
  Knowledge Graph Construction -> Vector Embedding -> Query Processing -> LLM Reasoning -> Response Generation
  Text mining from standards -> Llama index vectorization -> Text2vec similarity search -> ChatGLM-6B reasoning -> User interface

- Critical path: User query -> Vector similarity search -> KG segment retrieval -> Prompt generation -> LLM reasoning -> Response

- Design tradeoffs:
  - KG completeness vs. construction cost: More comprehensive KGs improve reasoning but require more manual effort.
  - Retrieval precision vs. recall: Tighter neighborhood expansion improves precision but may miss relevant information.
  - Prompt complexity vs. LLM performance: More complex prompts may improve reasoning but could exceed LLM context limits.

- Failure signatures:
  - Irrelevant or inaccurate responses: Likely due to poor KG quality or retrieval issues.
  - LLM refuses to answer or gives generic responses: Possibly due to overly complex prompts or context length limits.
  - Slow response times: May indicate inefficient vector search or overly large KG segments.

- First 3 experiments:
  1. Test KG construction pipeline: Feed sample text through the entire pipeline (extraction -> refinement -> embedding) and manually verify triple quality.
  2. Evaluate retrieval performance: Measure precision and recall of neighborhood expansion for various query types.
  3. Benchmark prompt effectiveness: Compare LLM performance on KG reasoning tasks using different prompt structures.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the E-KELL system be effectively adapted to handle real-time data streams during emergency situations?
- Basis in paper: [explicit] The paper mentions the need for E-KELL to have real-time data interfaces for data like deployable resources and sensor parameters.
- Why unresolved: The paper acknowledges the importance of real-time data but does not provide specific methods for integrating such data streams into the E-KELL framework.
- What evidence would resolve it: A detailed design or prototype demonstrating how real-time data is ingested, processed, and utilized within the E-KELL system would address this question.

### Open Question 2
- Question: What are the potential limitations of using KG-enhanced LLMs for decision support in diverse emergency scenarios beyond hazardous chemical leaks?
- Basis in paper: [inferred] The paper focuses on hazardous chemical leaks but suggests the framework can be transferred to other domains, implying potential applicability to various emergencies.
- Why unresolved: The paper does not explore the system's performance or limitations in other emergency contexts, such as natural disasters or pandemics.
- What evidence would resolve it: Testing the E-KELL system in multiple emergency scenarios and comparing its effectiveness and limitations across different types of emergencies would provide insights into its broader applicability.

### Open Question 3
- Question: How can the E-KELL system ensure the accuracy and reliability of its knowledge base when dealing with rapidly evolving emergency situations?
- Basis in paper: [explicit] The paper discusses the need for continuous updates and manual fine-tuning of the knowledge graph, indicating a focus on maintaining accuracy.
- Why unresolved: The paper does not detail mechanisms for dynamically updating the knowledge base in response to real-time changes or emerging information during emergencies.
- What evidence would resolve it: A method or system for automatically updating the knowledge graph with new information during an emergency, along with an evaluation of its impact on decision-making accuracy, would address this question.

## Limitations
- The evaluation relies heavily on subjective expert scoring rather than objective performance metrics
- The manual refinement process for KG construction is not quantified, raising scalability concerns
- Specific prompt templates for guiding LLM reasoning are not fully disclosed, limiting reproducibility

## Confidence
- High Confidence: The system architecture integrating KGs and LLMs for emergency decision-making is technically sound and addresses a real-world need
- Medium Confidence: The reported expert scores indicate high user satisfaction, but lack of objective performance metrics and real-world validation limits confidence in practical effectiveness
- Low Confidence: The scalability of the semi-automatic KG construction process and long-term maintenance in dynamic scenarios are not adequately addressed

## Next Checks
1. Conduct a longitudinal study to assess the system's performance and user satisfaction over multiple emergency scenarios, comparing outcomes with and without E-KELL support
2. Implement an automated KG update mechanism and evaluate its effectiveness in maintaining KG accuracy and relevance over time
3. Develop a benchmark dataset of emergency decision-making queries with ground truth answers to objectively measure E-KELL's performance