---
ver: rpa2
title: 'Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive
  Signals for Revision Policies in Incremental Processing'
arxiv_id: '2310.18229'
source_url: https://arxiv.org/abs/2310.18229
tags:
- skip
- revisions
- reading
- position
- head
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper investigates whether regressions and skips in human eye-tracking
  reading data can serve as useful signals for predicting revisions in incremental
  NLP models. Using generalised mixed-effects models, the authors find that the probability
  of regressions and skips by humans is a significant predictor of revisions in BiLSTM
  and Transformer models across various languages, with consistent results for different
  tasks such as dependency parsing and POS-tagging.
---

# Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing

## Quick Facts
- arXiv ID: 2310.18229
- Source URL: https://arxiv.org/abs/2310.18229
- Reference count: 13
- Primary result: Human eye-tracking regressions and skips predict revisions in incremental NLP models across multiple languages and architectures

## Executive Summary
This paper investigates whether human eye-tracking patterns during reading can serve as predictive signals for when incremental NLP models should revise their output. Using generalized linear mixed models, the authors find that regression and skip probabilities from eye-tracking data are significant predictors of model revisions in both BiLSTM and Transformer architectures across multiple languages and tasks. The findings suggest that human cognitive signals can inform revision policies in incremental processors, particularly for syntactically demanding tasks where frequent revisions are necessary.

## Method Summary
The study combines eye-tracking corpora (MECO-L1, MECO-L2, Nicenboim, PoTeC, Provo, RastrOS) with pre-trained NLP models for dependency parsing and POS-tagging. Texts from eye-tracking data are fed incrementally to restart-incremental versions of Stanza BiLSTM and Explosion Transformer models. A data structure maps tokens to human reading behavior (regression and skip probabilities) and model revisions. Binomial generalized linear mixed models (GLMM) are fitted to predict revisions based on token position, regression probability, and skip probability, comparing baseline models with only token position to full models including eye-tracking measures.

## Key Results
- Human regression and skip probabilities are significant predictors of model revisions across BiLSTM and Transformer architectures
- Regression probability positively correlates with revisions, while skip probability negatively correlates
- Results are consistent across five languages (English, German, Italian, Russian, Spanish) and both dependency parsing and POS-tagging tasks
- The relationship holds despite different encoding mechanisms between BiLSTM and Transformer models

## Why This Works (Mechanism)

### Mechanism 1
Human regressions signal cognitive difficulty or ambiguity in text interpretation, which parallels the challenges incremental NLP models face when needing to revise outputs. The model's revision policy responds to similar linguistic cues that trigger human regressions.

### Mechanism 2
Words triggering regressions cause more model revisions due to ambiguity or processing difficulty, while skipped words are processed smoothly without revision needs, creating opposite correlations between regressions and skips with revision probability.

### Mechanism 3
The universality of cognitive reading processes across languages and the similarity of incremental processing challenges across different NLP architectures explain why the human-model correlation generalizes across languages, model types, and tasks.

## Foundational Learning

- **Generalized Linear Mixed Models (GLMM)**: Used to model relationships between human gaze patterns and model revisions while accounting for nested data structure. *Quick check: What advantage does GLMM provide over simple linear regression for this nested data?*

- **Incremental processing**: The mode where models produce output based on incoming input prefixes, creating the context for revisions. *Quick check: How does incremental processing differ from non-incremental processing in NLP?*

- **Restart-incremental interface**: Allows non-incremental models to process input incrementally by restarting at each new token. *Quick check: What is the main tradeoff of using a restart-incremental interface versus truly incremental models?*

## Architecture Onboarding

- **Component map**: Eye-tracking corpora → NLP models (BiLSTM/Transformer) → GLMM analysis framework
- **Critical path**: Extract human gaze patterns → Feed texts to models incrementally → Analyze relationship using GLMM
- **Design tradeoffs**: Pre-trained models provide realistic settings but may not capture all incremental processing nuances
- **Failure signatures**: Weak or non-existent correlation between human gaze patterns and model revisions indicates revision policy based on non-linguistic factors
- **First 3 experiments**:
  1. Replicate with different eye-tracking corpora to test generalizability
  2. Investigate relationship between other eye-tracking measures (e.g., fixation duration) and revisions
  3. Develop revision policy incorporating human gaze patterns as input features

## Open Questions the Paper Calls Out
- Can the magnitude of regression coefficients differ between tasks when predicting effective revisions?
- Can other eye-tracking measures like number of fixations predict revisions and effective revisions?
- Can eye-tracking models predict regressions and skips on truly unseen data in real-time?

## Limitations
- Study uses pre-trained models with restart-incremental interfaces rather than truly incremental architectures
- Limited to specific tasks (dependency parsing and POS-tagging) and a small set of languages
- Causal mechanisms linking human cognitive processes to model revisions remain speculative

## Confidence
- **High confidence**: Statistical significance of regression and skip probabilities as revision predictors
- **Medium confidence**: Generalizability across languages and tasks
- **Medium confidence**: Practical utility of eye-tracking signals for revision policies

## Next Checks
1. Cross-linguistic validation with typologically diverse languages (morphologically rich, free word order)
2. Architectural ablation study comparing truly incremental vs restart-incremental models
3. Predictive policy evaluation implementing revision policies using human gaze patterns