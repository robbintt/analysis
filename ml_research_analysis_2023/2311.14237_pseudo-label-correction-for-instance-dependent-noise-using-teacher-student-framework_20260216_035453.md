---
ver: rpa2
title: Pseudo-label Correction for Instance-dependent Noise Using Teacher-student
  Framework
arxiv_id: '2311.14237'
source_url: https://arxiv.org/abs/2311.14237
tags:
- noise
- label
- learning
- labels
- network
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the problem of learning with instance-dependent
  label noise, where each image has a varying probability of being corrupted. The
  proposed method, P-LC (pseudo-label correction), uses a teacher-student framework
  where the student generates pseudo labels and the teacher decides whether to use
  these pseudo labels or the original labels.
---

# Pseudo-label Correction for Instance-dependent Noise Using Teacher-student Framework

## Quick Facts
- arXiv ID: 2311.14237
- Source URL: https://arxiv.org/abs/2311.14237
- Reference count: 0
- This paper addresses the problem of learning with instance-dependent label noise using a teacher-student framework for pseudo-label correction.

## Executive Summary
This paper presents P-LC, a method for handling instance-dependent label noise in image classification using a teacher-student framework. The approach uses a triple encoder teacher network with triplet loss to learn discriminative embeddings, which then corrects pseudo-labels generated by a student CNN classifier. The method shows superior performance compared to state-of-the-art approaches, particularly in high noise settings, while also introducing a technique for noise level estimation.

## Method Summary
P-LC addresses instance-dependent label noise by training a teacher network (triple encoder with triplet loss) and student network (CNN/ResNet classifier) on clean data. The student generates pseudo-labels for noisy data, and the teacher corrects these labels by comparing similarity between anchor images and pseudo-labels versus original labels using learned embeddings. The student then retrains on the corrected dataset. The method also includes a noise level estimation technique that calculates the proportion of different labels between corrected and noisy datasets.

## Key Results
- Classification accuracies on MNIST: 94.81% (20% noise), 94.26% (30% noise), 93.71% (40% noise), and 93.07% (50% noise)
- P-LC outperforms state-of-the-art methods, especially in high noise settings
- Method self-adjusts to varying noise levels without explicit tuning
- Noise level estimation technique introduced and evaluated

## Why This Works (Mechanism)

### Mechanism 1
The teacher network learns to distinguish positive pairs from negative pairs using triplet loss, enabling accurate pseudo-label correction. The teacher encodes an anchor image alongside positive and negative samples, minimizing distance between anchor-positive while maximizing anchor-negative distance. This learned embedding space allows the teacher to determine which pseudo-label is more likely correct by comparing similarity.

### Mechanism 2
P-LC self-adjusts to varying noise levels by progressively trusting pseudo-labels over original labels as noise increases. As noise level increases, more instances will have student-generated pseudo-labels that differ from original labels, and the teacher network's correction mechanism naturally increases the proportion of corrections made.

### Mechanism 3
Hard pseudo-label correction outperforms soft label correction methods in high noise settings. P-LC uses hard pseudo-labels (one-hot encoded) rather than soft labels, avoiding the computational cost and performance degradation associated with label smoothing techniques that decrease accuracy in high noise environments.

## Foundational Learning

- **Triplet loss for metric learning**: Needed for teacher network to learn discriminative embeddings that compare similarity between images; Quick check: How does triplet loss ensure that positive pairs are closer than negative pairs in the embedding space?
- **Teacher-student knowledge distillation**: Framework leverages teacher's ability to correct student's predictions, creating a self-improving loop; Quick check: What is the key difference between conventional teacher-student frameworks and the P-LC approach?
- **Instance-dependent label noise (IDN)**: Understanding IDN is crucial as P-LC specifically addresses this realistic noise scenario where corruption probability varies per instance; Quick check: How does IDN differ from symmetric noise and class-conditional noise?

## Architecture Onboarding

- **Component map**: Clean data -> Train teacher and student networks -> Student generates pseudo-labels on noisy data -> Teacher corrects labels using embedding similarity -> Student retrains on corrected data -> Evaluate on test set
- **Critical path**: 1) Train teacher and student on clean data Dclean, 2) Student generates pseudo-labels for noisy data Dnoise, 3) Teacher corrects labels by comparing similarity to pseudo-labels vs original labels, 4) Student retrains on corrected data Dcorrected, 5) Evaluate on test set
- **Design tradeoffs**: Using hard vs soft pseudo-labels (hard labels are computationally cheaper but may lose information), sampling strategy (more samples improve accuracy but increase computation), network architecture (deeper networks may learn better embeddings but require more data)
- **Failure signatures**: High discrepancy between estimated noise level and actual noise level, performance degradation on high noise settings, inconsistent improvement across different datasets
- **First 3 experiments**: 1) Verify teacher network learns discriminative embeddings by checking triplet loss convergence on clean data, 2) Test correction accuracy on a small subset of noisy data with known ground truth, 3) Compare performance against baseline (CE loss) on MNIST with 20% noise before scaling to other datasets

## Open Questions the Paper Calls Out

- **Open Question 1**: How does P-LC performance compare to other state-of-the-art methods on real-world datasets with instance-dependent label noise? The paper focuses on synthetic instance-dependent noise and does not test on real-world datasets.
- **Open Question 2**: How does the noise level estimation technique perform on datasets with varying noise levels and different types of noise? The paper only provides results on three benchmark datasets with instance-dependent noise at four specific noise levels.
- **Open Question 3**: Can the teacher-student framework be extended to handle multi-label classification tasks with instance-dependent label noise? The paper focuses on single-label classification tasks and does not discuss multi-label applicability.

## Limitations
- Exact noise injection mechanism for IDN is not specified beyond being "CNN-based likelihood method"
- No ablation studies on critical hyperparameters like embedding dimension, triplet loss margin, or sampling strategy
- Specific CNN/ResNet architectures for student network are not provided

## Confidence
- **High confidence**: Core mechanism of using triplet loss for teacher network embedding learning
- **Medium confidence**: Experimental results showing superior performance over baselines
- **Medium confidence**: Noise level estimation technique is simple and intuitive but not extensively validated

## Next Checks
1. Generate controlled instance-dependent noise with known patterns on MNIST to verify correction accuracy and noise level estimation
2. Test different embedding dimensions and triplet loss margins to determine sensitivity to these hyperparameters
3. Evaluate P-LC on CIFAR-10/100 to assess generalizability beyond current three datasets