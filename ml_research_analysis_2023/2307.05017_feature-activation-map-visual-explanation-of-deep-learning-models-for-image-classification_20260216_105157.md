---
ver: rpa2
title: 'Feature Activation Map: Visual Explanation of Deep Learning Models for Image
  Classification'
arxiv_id: '2307.05017'
source_url: https://arxiv.org/abs/2307.05017
tags:
- image
- learning
- feature
- proposed
- classification
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces a novel model-agnostic visual explanation
  algorithm named feature activation map (FAM), which addresses the critical gap of
  visualizing FC-free deep learning models in image classification tasks. The proposed
  FAM algorithm determines the importance coefficients by using the contribution weights
  to the similarity score, and then linearly combines these weights with the activation
  maps from the last convolutional layer to form the explanation maps for visualization.
---

# Feature Activation Map: Visual Explanation of Deep Learning Models for Image Classification

## Quick Facts
- arXiv ID: 2307.05017
- Source URL: https://arxiv.org/abs/2307.05017
- Reference count: 40
- Key outcome: Introduces FAM, a model-agnostic visual explanation algorithm that achieves IoU of 43.45%-52.29% and energy-based point game proportions of 36.00%-54.33% across different models and tasks.

## Executive Summary
This paper introduces Feature Activation Map (FAM), a novel model-agnostic visual explanation algorithm designed to interpret deep learning models without fully-connected (FC) layers in image classification tasks. The proposed method addresses a critical gap by enabling visualization of FC-free models through similarity-based classification. FAM calculates channel-wise contribution weights from similarity scores between feature vectors and linearly combines these weights with activation maps from the last convolutional layer to generate explanation maps.

The algorithm is evaluated across ten widely used CNN models for few-shot learning, contrastive learning, and image retrieval tasks. FAM demonstrates strong localization capacities (IoU 43.45%-52.29%) and faithfulness metrics (average drop 7.97%-14.67%, increase in confidence 39.79%-45.13%), establishing its effectiveness as a general-purpose explanation tool for modern deep learning architectures that bypass traditional FC layers.

## Method Summary
FAM calculates channel-wise contribution weights from similarity scores between image embeddings, then linearly combines these weights with activation maps from the last convolutional layer. For cosine similarity, contribution weights are computed as normalized dot products between feature vectors. The algorithm includes optional transformation module handling for models using FC layers as feature transformation. FAM works by extracting activation maps from the last convolutional layer, computing feature vectors via global average pooling, calculating similarity scores between query and support images, deriving channel-wise contribution weights, normalizing them, linearly combining with activation maps, and upsampling for visualization.

## Key Results
- Achieves localization capacities with IoU ranging from 43.45% to 52.29% across different models and tasks
- Demonstrates energy-based point game proportions ranging from 36.00% to 54.33% for various models
- Shows faithfulness with average drop ranging from 7.97% to 14.67% and increase in confidence ranging from 39.79% to 45.13% for various models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: FAM derives importance coefficients from similarity scores instead of FC layer weights, enabling explanation of FC-free models.
- Mechanism: Channel-wise contribution weights are calculated from similarity between feature vectors (obtained via pooling from activation maps). These weights replace FC-derived importance coefficients in the CAM framework.
- Core assumption: The contribution of a feature (channel) to the similarity score reflects its importance for the model's decision.
- Evidence anchors: [abstract] "The proposed FAM algorithm determines the importance coefficients by using the contribution weights to the similarity score"; [section] "The importance coefficients are crucial for visualizing explanation maps... All the existing CAM-based methods show that the importance coefficients cannot be obtained without FC layers."
- Break condition: If the similarity metric does not meaningfully reflect feature importance, or if pooling loses critical spatial information.

### Mechanism 2
- Claim: FAM can visualize models without FC layers by leveraging similarity-based classification.
- Mechanism: For similarity-based models, the prediction is made by comparing feature embeddings (via cosine similarity or other metrics). FAM uses the contribution of each channel to this similarity as the importance coefficient.
- Core assumption: The similarity comparison paradigm inherently captures the relevant features for classification, making them suitable for explanation.
- Evidence anchors: [abstract] "The proposed FAM algorithm determines the importance coefficients by using the contribution weights to the similarity score"; [section] "The contribution of a certain channel can reflect the contribution of a feature. Hence, the channel-wise contribution weights play the role of importance coefficients."
- Break condition: If the similarity metric is not a good proxy for feature importance, or if the model uses complex transformations that obscure channel contributions.

### Mechanism 3
- Claim: FAM is model-agnostic and works across different architectures and tasks.
- Mechanism: By using only the last convolutional layer's activation maps and a similarity-based contribution calculation, FAM avoids dependencies on specific model components like FC layers or specific pooling strategies.
- Core assumption: The last convolutional layer captures the most semantically meaningful features for the task, and pooling preserves their discriminative information.
- Evidence anchors: [abstract] "The proposed FAM algorithm determines the importance coefficients by using the contribution weights to the similarity score"; [section] "Because both semantic and spatial information can be preserved in deeper convolutional layer, the feature map out of the last convolutional layer is employed in the proposed FAM algorithm."
- Break condition: If the last convolutional layer does not contain task-relevant features, or if pooling significantly degrades the feature representation.

## Foundational Learning

- Concept: Class Activation Maps (CAM)
  - Why needed here: FAM is built upon the CAM framework, replacing the FC-derived importance coefficients with similarity-based ones.
  - Quick check question: What are the limitations of CAM that FAM addresses?

- Concept: Similarity-based classification
  - Why needed here: FAM is designed for models that use similarity comparison (e.g., few-shot learning, contrastive learning) instead of FC layers.
  - Quick check question: How does similarity-based classification differ from FC-based classification in terms of feature extraction and decision-making?

- Concept: Channel-wise feature importance
  - Why needed here: FAM assigns importance to individual channels in the activation map based on their contribution to the similarity score.
  - Quick check question: Why might the contribution of a channel to the similarity score reflect its importance for the model's decision?

## Architecture Onboarding

- Component map: Feature extractor (CNN backbone) -> Last convolutional layer (provides activation maps) -> Pooling function (e.g., GAP, GMP) to embed activation maps into feature vectors -> Similarity metric function (e.g., cosine similarity, Euclidean distance) -> Linear combination of activation maps with normalized contribution weights -> Upsampling (e.g., bilinear interpolation) for visualization

- Critical path: Input image → Feature extraction → Activation maps → Pooling → Feature vectors → Similarity calculation → Contribution weight calculation → Normalization → Linear combination → Upsampling → Explanation map

- Design tradeoffs:
  - Pooling function: Different pooling strategies may capture different aspects of the feature maps.
  - Similarity metric: The choice of similarity metric affects how contribution weights are calculated.
  - Backbone architecture: FAM should work with various CNN backbones, but performance may vary.

- Failure signatures:
  - Explanation maps that do not highlight relevant regions.
  - Low localization capacity (IoU, energy-based point game proportion).
  - Low faithfulness (high average drop, low increase in confidence).

- First 3 experiments:
  1. Implement FAM on a simple CNN model (e.g., ResNet18) for image classification and visualize explanation maps on a test dataset.
  2. Evaluate FAM's localization capacity using IoU and energy-based point game proportion on a dataset with ground truth bounding boxes.
  3. Assess FAM's faithfulness using average drop and increase in confidence metrics.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the FAM algorithm perform when applied to other similarity metrics beyond cosine similarity, such as Euclidean distance or learned metrics?
- Basis in paper: [explicit] The paper mentions that "any similarity metric can be applied in the proposed framework of FAM" but only provides detailed formulations for cosine similarity.
- Why unresolved: The paper only demonstrates FAM with cosine similarity for few-shot learning, contrastive learning, and image retrieval tasks. The performance and behavior of FAM with other similarity metrics remains unexplored.
- What evidence would resolve it: Experimental results comparing FAM performance using different similarity metrics (cosine, Euclidean, learned metrics) across the same tasks and models.

### Open Question 2
- Question: How does FAM's localization performance compare to gradient-based CAM methods when applied to models that do use FC layers as classifiers?
- Basis in paper: [inferred] The paper positions FAM as a solution for FC-free models, but doesn't compare its localization performance to established CAM methods on FC-based models.
- Why unresolved: The paper establishes FAM's effectiveness for FC-free models but doesn't benchmark against traditional CAM methods on standard classification tasks, leaving uncertainty about its relative performance.
- What evidence would resolve it: Direct comparison of FAM vs Grad-CAM, Grad-CAM++, and other gradient-based methods on standard CNN architectures (ResNet, VGG) using IoU and point game metrics.

### Open Question 3
- Question: What is the computational overhead of FAM compared to traditional CAM methods, and how does it scale with model size and input resolution?
- Basis in paper: [inferred] The paper describes FAM's methodology but doesn't provide computational complexity analysis or runtime comparisons with existing explanation methods.
- Why unresolved: While FAM introduces a new approach for FC-free models, the practical efficiency and scalability implications are not addressed, which is important for real-world deployment.
- What evidence would resolve it: Runtime measurements comparing FAM to Grad-CAM and other methods across different model sizes and input resolutions, including GPU memory usage analysis.

## Limitations
- FAM's effectiveness depends on the assumption that channel-wise contributions to similarity scores meaningfully reflect feature importance
- The algorithm's performance on highly complex architectures beyond standard CNNs remains unexplored
- The paper lacks analysis of computational overhead compared to existing explanation methods

## Confidence
- **High confidence** in FAM's core mechanism for explaining similarity-based models, supported by quantitative metrics across multiple model types
- **Medium confidence** in model-agnostic claims, as the evaluation focuses primarily on CNN architectures with standard activation map structures
- **Low confidence** in generalizability to non-CNN architectures (Vision Transformers, etc.) or models using complex attention mechanisms

## Next Checks
1. **Ablation study on pooling strategies**: Test FAM with different pooling functions (GMP, GeM, attention-based pooling) to determine sensitivity to this design choice and identify optimal configurations for different model types.

2. **Cross-architecture generalization**: Apply FAM to Vision Transformer models and hybrid architectures to validate model-agnostic claims beyond standard CNNs, measuring localization and faithfulness metrics for comparison.

3. **Computational efficiency analysis**: Benchmark FAM's runtime and memory requirements against Grad-CAM, Score-CAM, and other popular explanation methods across different backbone architectures and input resolutions to establish practical viability.