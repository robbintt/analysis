---
ver: rpa2
title: 'Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient
  Module Operation'
arxiv_id: '2308.08090'
source_url: https://arxiv.org/abs/2308.08090
tags:
- uni00000011
- uni00000013
- uni00000057
- uni0000004c
- uni00000055
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of untruthfulness and toxicity
  in large language models (LLMs) by proposing a novel parameter-efficient module
  operation approach called Extraction-before-Subtraction (Ext-Sub). The core method
  idea involves extracting and eliminating the deficiency capability within an anti-expert
  parameter-efficient module (PEM) while preserving its general capabilities, and
  then subtracting this extracted deficiency from an expert PEM.
---

# Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation

## Quick Facts
- **arXiv ID**: 2308.08090
- **Source URL**: https://arxiv.org/abs/2308.08090
- **Reference count**: 18
- **Primary result**: A novel parameter-efficient approach (Extraction-before-Subtraction) that improves LLM truthfulness and detoxification while preserving fundamental capabilities

## Executive Summary
This paper addresses the challenge of unlearning untruthfulness and toxicity in large language models (LLMs) through a novel parameter-efficient module operation approach called Extraction-before-Subtraction (Ext-Sub). The method works by first extracting the general capability from an anti-expert parameter-efficient module (PEM) and then subtracting the isolated deficiency capability from an expert PEM. The approach demonstrates significant improvements in truthfulness and detoxification metrics while largely preserving the fundamental abilities of LLMs on standard benchmarks.

## Method Summary
The Ext-Sub approach operates on LoRA parameter-efficient modules trained on different instruction datasets. First, an expert PEM is trained on regular instruction data while an anti-expert PEM is trained on untruthful/toxic instruction data. The method then extracts the general capability from the anti-expert PEM by projecting its vectors onto a hyperplane defined by the expert PEM, leaving the deficiency capability as the orthogonal remainder. Finally, this extracted deficiency capability is subtracted from the expert PEM with a hyperparameter λ, effectively removing the undesirable behaviors while preserving core capabilities. The approach is evaluated on LLaMA-7B using Alpaca-GPT4 and WizardLM datasets.

## Key Results
- Truthfulness improvements on TruthfulQA benchmark with maintained or slightly improved fundamental abilities (MMLU, GSM, BBH scores)
- Effective detoxification demonstrated on HaluEval benchmark while preserving language generation quality
- Compositional unlearning capability allowing simultaneous unlearning of multiple deficiency types
- Prevention of text degeneration that occurs with direct subtraction methods

## Why This Works (Mechanism)

### Mechanism 1
The anti-expert PEM contains both general capability (shared with expert PEM) and deficiency capability (unique to anti-expert PEM). By projecting anti-expert PEM vectors onto a hyperplane defined by the sum of unit vectors from both expert and anti-expert PEMs, we can extract the general capability. The remainder after projection represents the deficiency capability. This relies on the core assumption that different vector directions in LoRA weight space represent different capabilities, and the general capability is the common feature shared between expert and anti-expert PEMs.

### Mechanism 2
Subtracting extracted deficiency capability from expert PEM improves truthfulness and detoxification without significant degradation of fundamental abilities. The deficiency capability extracted from anti-expert PEM is orthogonal to the general capability hyperplane. By subtracting this deficiency from the expert PEM, we remove the untruthful/toxic patterns while preserving the core capabilities. This works because the deficiency capability exhibits minimal overlap with the basic expert PEM, making direct subtraction effective.

### Mechanism 3
The Extraction-before-Subtraction approach prevents text degeneration that occurs with direct subtraction. By first extracting only the deficiency capability (and not the general capability) from anti-expert PEM, we avoid removing valuable language modeling and logical narrative skills that are present in both PEMs. This is crucial because anti-expert PEMs possess valuable capabilities (language modeling and logical narrative) that should be preserved during unlearning.

## Foundational Learning

- **Vector projection and hyperplane geometry in high-dimensional spaces**: The method relies on projecting anti-expert PEM vectors onto a hyperplane defined by expert PEM vectors to extract general capability. Quick check: Given two vectors v1 and v2, how do you compute the projection of v2 onto the hyperplane defined by v1?

- **Parameter-efficient modules (PEMs) and their operation**: The approach operates on LoRA modules, which are a type of PEM, and uses arithmetic operations on these modules. Quick check: What is the mathematical representation of a LoRA module, and how does it modify the forward pass in a transformer?

- **Text generation quality metrics and evaluation**: The method must preserve text generation quality while removing deficiency capabilities, requiring understanding of metrics like BLEU, ROUGE, and 4-gram repetition. Quick check: What is the difference between BLEU and ROUGE-L metrics, and why might 4-gram repetition be important for evaluating text degeneration?

## Architecture Onboarding

- **Component map**: LoRA modules (expert PEM and anti-expert PEM) → vector projection operation → deficiency extraction → parameter subtraction → modified expert PEM
- **Critical path**: 1) Train expert PEM on regular instruction data 2) Train anti-expert PEM on untruthful/toxic instruction data 3) Extract general capability from anti-expert PEM via vector projection 4) Extract deficiency capability as remainder 5) Subtract deficiency from expert PEM
- **Design tradeoffs**: The method trades storage efficiency for effectiveness (storing full LoRA matrices rather than low-rank approximations) and requires careful hyperparameter tuning of the subtraction weight λ
- **Failure signatures**: 1) Text degeneration (repetitive output) 2) Degradation in fundamental abilities (MMLU, GSM, BBH scores drop) 3) Insufficient improvement in truthfulness/toxicity metrics 4) Instability with different λ values
- **First 3 experiments**:
  1. Train expert PEM and anti-expert PEM on Alpaca-GPT4 dataset, then apply Ext-Sub with λ=1.0 and measure truthfulness improvement on TruthfulQA
  2. Repeat experiment with WizardLM dataset to test generalization across instruction datasets
  3. Apply compositional unlearning by combining truthfulness and toxicity PEMs, testing different subtraction orders

## Open Questions the Paper Calls Out

### Open Question 1
What is the precise mechanism by which the extraction-before-subtraction approach prevents harmful forgetting of fundamental abilities while removing deficiency capabilities? The paper mentions that the extraction process separates general and deficiency capabilities from the anti-expert PEM, but it does not explain how this separation prevents forgetting of fundamental abilities. A detailed analysis of the impact of the extraction process on the model's internal representations and its correlation with the preservation of fundamental abilities would help clarify the mechanism.

### Open Question 2
How does the proposed approach perform when applied to larger language models with varying scales? The paper mentions that the experiments were conducted on LLaMA-7B, but does not provide information on the approach's performance on larger or smaller language models. Conducting experiments on language models of different sizes and reporting the results would help determine the approach's effectiveness across various scales.

### Open Question 3
How can the optimal weight hyperparameter λ be determined for different modules trained from different datasets? The paper mentions that different modules trained from different datasets may have different optimal weight hyperparameters λ during composition, but does not provide a method for finding the optimal value. Developing and evaluating methods for automatically determining the optimal weight hyperparameter λ for various modules would help improve the approach's accuracy and efficiency.

## Limitations
- The vector projection mechanism for separating general and deficiency capabilities relies on high-dimensional geometry assumptions that lack empirical validation
- The anti-expert PEM generation method using ChatGPT prompts is not fully specified, making exact reproduction difficult
- The computational overhead of storing full LoRA matrices reduces the parameter efficiency benefits

## Confidence

**High Confidence**: The core mathematical framework for vector projection and hyperplane operations is sound and well-established in linear algebra. The improvement in truthfulness and toxicity metrics on standard benchmarks is empirically demonstrated.

**Medium Confidence**: The mechanism by which vector projection successfully separates general and deficiency capabilities in high-dimensional LoRA weight space is plausible but not rigorously proven. The assumption that deficiency capability is orthogonal to general capability may not hold for all types of undesirable behaviors.

**Low Confidence**: The claim that anti-expert PEMs inherently contain valuable general capabilities due to their ability to generate coherent fabricated content lacks strong empirical support. The effectiveness of compositional unlearning across multiple deficiency types has not been thoroughly validated.

## Next Checks

1. **Vector Space Analysis**: Conduct ablation studies to verify that the extracted deficiency vectors are truly orthogonal to the general capability hyperplane by measuring the cosine similarity between these vector components. This would validate the fundamental assumption underlying the extraction mechanism.

2. **Generalization Testing**: Apply the Ext-Sub method to unlearning different types of deficiency capabilities (e.g., biased reasoning, harmful stereotypes) beyond truthfulness and toxicity, and measure whether the same vector projection approach successfully isolates these capabilities.

3. **Hyperparameter Sensitivity**: Systematically vary the subtraction weight λ across multiple orders of magnitude and measure the trade-off curve between truthfulness improvement and fundamental ability preservation to identify optimal values for different task domains.