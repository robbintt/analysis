---
ver: rpa2
title: Training A Multi-stage Deep Classifier with Feedback Signals
arxiv_id: '2311.06823'
source_url: https://arxiv.org/abs/2311.06823
tags:
- training
- samples
- main-classifier
- pre-classifier
- classifiers
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a novel training framework, named Feedback Training,
  for two-stage binary classification systems. Instead of training classifiers independently
  or sequentially, the method trains them in reverse order, using the later-stage
  classifier to guide the initial-stage classifier through a sample weighting approach.
---

# Training A Multi-stage Deep Classifier with Feedback Signals

## Quick Facts
- arXiv ID: 2311.06823
- Source URL: https://arxiv.org/abs/2311.06823
- Reference count: 7
- Primary result: Feedback Training framework trains classifiers in reverse order using sample weighting, significantly improving performance especially in few-shot scenarios

## Executive Summary
This paper proposes Feedback Training, a novel framework for training two-stage binary classification systems. Instead of the conventional approach of training classifiers independently or sequentially, Feedback Training trains them in reverse order - first the later-stage classifier, then using its predictions to guide the initial-stage classifier through a sample weighting approach. The method assigns different attention weights to samples based on the later-stage classifier's predictions, allowing the initial-stage classifier to learn the preferences of the later-stage classifier. Experiments on two datasets demonstrate significant improvements over baseline methods, particularly in few-shot learning scenarios where training data for the initial-stage classifier is limited.

## Method Summary
The Feedback Training framework addresses two-stage binary classification by first training the main (later-stage) classifier independently on the full dataset using cross-entropy loss. A sample weighting function parameterized by sigmoid curves is then optimized using a genetic algorithm to maximize end-to-end pipeline F1. The initial-stage pre-classifier is trained using weighted cross-entropy loss where weights are determined by the main classifier's predictions - higher weights for samples the main classifier is confident about. This allows the pre-classifier to learn which samples to pass to the main classifier for optimal overall performance. The approach is particularly effective when training data is scarce for the pre-classifier, as it leverages the knowledge learned by the main classifier.

## Key Results
- Feedback Training outperforms independent and sequential training baselines across two datasets
- The approach shows significant improvements in few-shot learning scenarios
- Sample weighting based on main classifier predictions reduces the requirement for training samples for the initial-stage classifier
- End-to-end pipeline F1 consistently improves compared to standard training approaches

## Why This Works (Mechanism)

### Mechanism 1
Training classifiers in reverse order allows the initial-stage classifier to learn the preferences of the later-stage classifier, improving overall pipeline performance. The later-stage classifier guides the initial-stage classifier through a sample weighting method that assigns different attention weights to samples based on the later-stage classifier's predictions. The core assumption is that the later-stage classifier has learned useful preferences about which samples are easier/harder to classify, and these preferences can be effectively communicated to the initial-stage classifier through weighted training. This could break if the later-stage classifier's preferences are not well-calibrated or do not generalize to the initial-stage classifier's task.

### Mechanism 2
The sample weighting approach creates stronger collaboration between classifiers by addressing the "dual funnel" problem where the main classifier overfits to a biased dataset. By weighting samples based on the main classifier's predictions, the pre-classifier learns to pass samples that the main classifier can handle well while filtering out harder samples that would otherwise cause overfitting. The core assumption is that the main classifier's predictions contain useful information about sample difficulty that can guide the pre-classifier's training process. This could break if the sample weighting becomes too extreme, creating a new bias that harms the pre-classifier's ability to generalize.

### Mechanism 3
Feedback training is particularly effective in few-shot scenarios because it allows the pre-classifier to leverage the main classifier's knowledge even when training data is scarce. The weighted training objective helps the pre-classifier focus on the most valuable samples for the overall pipeline performance, compensating for limited training data. The core assumption is that even with limited training data, the main classifier's learned preferences remain useful for guiding the pre-classifier. This could break if the main classifier is poorly trained due to limited data, making its guidance unreliable and potentially harming the pre-classifier's learning.

## Foundational Learning

- Binary classification with neural networks: The entire framework is built around two-stage binary classification systems using neural networks. Quick check: What loss function is used for training binary classifiers in this framework?

- Cross-entropy loss and sample weighting: The core innovation involves modifying the standard cross-entropy loss with sample weights based on the main classifier's predictions. Quick check: How does the sample weighting scheme differ for positive vs negative samples?

- Two-stage classification systems: The framework specifically targets scenarios where an initial lightweight classifier filters samples for a heavier subsequent classifier. Quick check: What problem does the "dual funnel" issue create in standard two-stage systems?

## Architecture Onboarding

- Component map: Pre-classifier (Logistic Regression) -> Main-classifier (12-layer Transformer) -> Sample weighting module (GA-optimized parameters) -> Pipeline controller

- Critical path: 1) Train main classifier independently on full dataset, 2) Optimize sample weighting parameters using genetic algorithm, 3) Train pre-classifier using weighted loss based on main classifier predictions, 4) Deploy with consistent PassRate across comparisons

- Design tradeoffs: Simplicity vs performance (independent training is simpler but less effective), Training time vs accuracy (feedback training requires more computation but achieves better results), Model capacity vs latency (pre-classifier must be lightweight enough for real-time use)

- Failure signatures: Pre-classifier recall drops significantly with feedback training (overly aggressive filtering), Main classifier performance degrades (inappropriate sample weighting), GA optimization fails to converge (poor parameter initialization)

- First 3 experiments: 1) Compare independent vs sequential vs feedback training on Task Extraction dataset, 2) Vary PassRate to test robustness of feedback training across different filtering thresholds, 3) Test few-shot performance by training pre-classifier with 1-10% of available data

## Open Questions the Paper Calls Out

### Open Question 1
The paper concludes by stating that further work should be carried out to extend the Feedback Training approach to multi-stage multi-classification scenarios. The paper only addresses two-stage binary classification and does not provide a framework for handling more complex classification tasks with multiple stages and classes. Development and testing of a generalized version of Feedback Training that can handle multi-stage, multi-class classification, with experimental results showing its effectiveness compared to existing methods, would resolve this question.

### Open Question 2
The paper discusses the use of attention intensity and temperature parameters in the sample weighting approach but does not explore their impact on the model's performance in detail. The paper does not provide a comprehensive analysis of how changes in these parameters affect the classification results, leaving a gap in understanding their optimal configuration. Systematic experiments varying the attention intensity and temperature parameters, with a detailed analysis of their effects on model performance, to determine optimal settings, would resolve this question.

### Open Question 3
The paper focuses on controlled experimental settings and does not address the method's robustness to changes in data distribution over time. Real-world applications often involve non-stationary data, and the paper does not explore how the Feedback Training method adapts to such scenarios. Longitudinal studies applying the Feedback Training method to real-world datasets with changing distributions, evaluating its adaptability and performance over time, would resolve this question.

## Limitations
- Framework effectiveness heavily depends on the quality of the later-stage classifier's predictions, which could mislead the pre-classifier if poorly trained
- Genetic algorithm optimization of weighting parameters may converge to local optima that don't generalize well across different datasets or task types
- The assumption that sigmoid-based weighting with temperature parameters is optimal for all scenarios remains unverified

## Confidence

**High Confidence**: The experimental results showing feedback training outperforms independent and sequential training methods across both datasets

**Medium Confidence**: The claim that feedback training is particularly effective for few-shot scenarios, as this is supported by fewer experiments and could depend heavily on specific dataset characteristics

**Medium Confidence**: The mechanism explanation about reducing "dual funnel" overfitting, as this is theoretically sound but could have alternative explanations

## Next Checks

1. Test feedback training on datasets where the main classifier is intentionally trained with limited or noisy data to assess robustness when guidance quality degrades

2. Compare different weighting function forms (beyond sigmoid) to determine if the specific functional form is critical to performance gains

3. Evaluate the framework with different pre-classifier architectures (beyond logistic regression) to assess whether the benefits generalize across model types