---
ver: rpa2
title: 'DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context
  Learning'
arxiv_id: '2310.02954'
source_url: https://arxiv.org/abs/2310.02954
tags:
- cups
- flour
- exemplars
- more
- arxiv
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DQ-LoRe introduces a dual-query framework for in-context learning
  that first generates chain-of-thought reasoning for a question, then retrieves exemplars
  using both the question and CoT, and finally applies PCA-based low-rank approximation
  to re-rank exemplars. This approach addresses the instability and inefficiency of
  exemplar selection in few-shot learning by leveraging richer reasoning context and
  filtering redundant information.
---

# DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning

## Quick Facts
- arXiv ID: 2310.02954
- Source URL: https://arxiv.org/abs/2310.02954
- Reference count: 30
- Key result: Achieves 94.2% accuracy on GPT-4, improving over 92.5% baseline

## Executive Summary
DQ-LoRe addresses the challenge of exemplar selection in in-context learning by introducing a dual-query framework that first generates chain-of-thought reasoning, then retrieves exemplars using both the question and CoT, and finally applies PCA-based low-rank approximation to re-rank exemplars. The approach significantly improves performance on multi-step reasoning tasks by capturing richer reasoning context and filtering redundant information. Experiments on GSM8K, AQUA, and SVAMP demonstrate state-of-the-art results with GPT-4 accuracy reaching 94.2%.

## Method Summary
DQ-LoRe improves in-context learning exemplar selection through a three-stage process: (1) Generate chain-of-thought reasoning for the input question using a large language model, (2) Retrieve exemplars using a CoT-aware retriever trained with contrastive learning to measure reasoning similarity, and (3) Apply PCA-based dimensionality reduction to re-rank exemplars and filter out redundant information. The dual-query framework enriches retrieval context with intermediate reasoning steps, while the low-rank approximation ensures that exemplars align closely with the reasoning patterns needed to solve the problem.

## Key Results
- GPT-4 accuracy improves from 92.5% to 94.2% on GSM8K
- DQ-LoRe achieves state-of-the-art performance on AQUA and SVAMP datasets
- Demonstrates robustness in distribution-shift settings where baseline methods fail
- Ablation studies confirm the effectiveness of both dual-query retrieval and PCA re-ranking components

## Why This Works (Mechanism)

### Mechanism 1: Dual-query framework enriches context with CoT
The dual-query approach generates CoT for the question first, then uses both the question and CoT for exemplar retrieval. This captures intermediate reasoning steps that pure question similarity cannot represent. The enriched context allows retrieval of exemplars that align better with the reasoning logic needed to solve the problem.

### Mechanism 2: PCA-based low-rank approximation filters redundant information
After retrieving M exemplars, PCA reduces the dimensionality of their embeddings. This filtering distinguishes between exemplars with genuine logical relevance versus those with spurious correlations based on word co-occurrence. The dimensionality reduction helps identify exemplars that truly capture the reasoning patterns needed for the task.

### Mechanism 3: Contrastive learning trained retriever captures CoT-exemplar similarity
The retriever is trained using contrastive learning with positive exemplars that are semantically similar to the CoT and negative exemplars that are less related. This creates an encoder that measures similarity based on reasoning alignment rather than surface features, ensuring exemplars match the logical structure of the problem.

## Foundational Learning

- **Concept**: Chain-of-thought reasoning
  - Why needed here: Provides intermediate reasoning steps that capture logical structure needed for complex problems
  - Quick check question: Given a math word problem, can you generate a step-by-step reasoning trace that explains how to solve it?

- **Concept**: Principal Component Analysis (PCA) for dimensionality reduction
  - Why needed here: Removes redundant information from high-dimensional embeddings to distinguish genuine semantic similarity
  - Quick check question: If you have 10 exemplars with 768-dimensional embeddings each, how would you use PCA to reduce them to 256 dimensions while preserving most variance?

- **Concept**: Contrastive learning for similarity measurement
  - Why needed here: Trains an encoder to distinguish between similar and dissimilar pairs for reasoning-based exemplar matching
  - Quick check question: How would you construct positive and negative pairs for training a retriever that matches CoT with exemplars?

## Architecture Onboarding

- **Component map**: Question → CoT generation → Dual-query retrieval → PCA re-ranking → LLM inference
- **Critical path**: Question → CoT generation → Dual-query retrieval → PCA re-ranking → LLM inference
- **Design tradeoffs**: Dual-query adds latency but improves exemplar quality; PCA filtering adds computation but reduces spurious correlations; contrastive training requires labeled CoT-exemplar pairs
- **Failure signatures**: Poor CoT generation → irrelevant exemplars; Ineffective PCA → no performance gain; Weak contrastive training → retriever doesn't learn reasoning similarity
- **First 3 experiments**:
  1. Run dual-query retrieval without PCA re-ranking to measure baseline improvement from CoT enrichment alone
  2. Apply PCA re-ranking to a baseline retriever without dual-query to test whether dimensionality reduction alone helps
  3. Test with different numbers of exemplars (M=16, 32, 64) and PCA dimensions (ε=128, 256, 512) to find optimal configuration

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does performance vary with different values of the LoRe parameter M (number of exemplars before PCA re-ranking)?
- Basis in paper: The paper mentions that LoRe parameter M was searched in {16, 32, 64} during experiments.
- Why unresolved: The paper does not provide detailed analysis of how different M values affect performance.
- What evidence would resolve it: A comprehensive ablation study showing accuracy on various datasets for different M values.

### Open Question 2
- Question: How does DQ-LoRe perform when using other dimensionality reduction techniques beyond PCA, such as autoencoders or t-SNE?
- Basis in paper: The paper mentions PCA specifically but acknowledges other methods exist (SVD, low-rank approximation, parameter-based training methods).
- Why unresolved: The paper only uses PCA and does not explore alternative dimensionality reduction approaches.
- What evidence would resolve it: Experiments comparing DQ-LoRe performance using different dimensionality reduction techniques on the same datasets.

### Open Question 3
- Question: What is the computational overhead of the dual-query framework compared to single-query approaches, and how does this scale with dataset size?
- Basis in paper: The paper mentions "speed and effectiveness" benefits from dimensionality reduction but does not provide runtime analysis.
- Why unresolved: The paper focuses on accuracy improvements but lacks empirical analysis of computational efficiency.
- What evidence would resolve it: Runtime comparisons between DQ-LoRe and baseline methods across different dataset sizes, including memory usage metrics.

## Limitations

- The contrastive learning framework's effectiveness depends heavily on the quality of positive/negative exemplar selection, which isn't fully specified
- The dual-query approach introduces significant computational overhead through the initial CoT generation step, which isn't adequately characterized in terms of latency or resource requirements
- The PCA-based re-ranking assumes that dimensionality reduction will consistently filter spurious correlations, but this may not hold across different domains or exemplar distributions

## Confidence

**High Confidence**: The core claim that dual-query retrieval improves exemplar selection is well-supported by empirical results across three different datasets. The mechanism of using CoT to enrich retrieval context is theoretically sound and the experimental improvements (particularly the 1.7% boost on GPT-4) are substantial and consistent.

**Medium Confidence**: The effectiveness of PCA-based re-ranking is demonstrated through ablation studies, but the underlying assumption that dimensionality reduction consistently improves exemplar quality across different contexts needs further validation.

**Low Confidence**: The claim that contrastive learning specifically trained on CoT-exemplar similarity provides substantial benefits over simpler retrieval approaches is the weakest link. The training methodology and hyperparameters are underspecified.

## Next Checks

1. **Ablation on CoT Quality**: Test the system's performance when using CoT generated by different models (e.g., GPT-3.5 vs GPT-4) or when using no CoT at all, to isolate the contribution of CoT quality to the dual-query advantage.

2. **Generalization Beyond Math**: Evaluate DQ-LoRe on non-mathematical reasoning tasks (e.g., commonsense reasoning or logical inference) to test whether the CoT-exemplar matching approach generalizes beyond its current domain.

3. **Scalability Analysis**: Measure the computational overhead introduced by dual-query generation and PCA re-ranking across different batch sizes and exemplar counts to understand practical deployment constraints.