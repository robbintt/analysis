---
ver: rpa2
title: 'Fairness in Image Search: A Study of Occupational Stereotyping in Image Retrieval
  and its Debiasing'
arxiv_id: '2305.03881'
source_url: https://arxiv.org/abs/2305.03881
tags:
- search
- image
- gender
- images
- bias
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study examines gender stereotypes in occupational image search
  results, where certain professions are over- or under-represented by specific genders.
  The authors first explore open-source and proprietary APIs for gender identification
  from images, finding that existing systems struggle with non-frontal face images
  common in web search results.
---

# Fairness in Image Search: A Study of Occupational Stereotyping in Image Retrieval and its Debiasing

## Quick Facts
- arXiv ID: 2305.03881
- Source URL: https://arxiv.org/abs/2305.03881
- Authors: 
- Reference count: 15
- Key outcome: Fairness-aware re-ranking algorithm improves gender fairness in occupational image search while maintaining relevance

## Executive Summary
This study addresses gender stereotyping in occupational image search results, where certain professions are over- or under-represented by specific genders. The authors propose a post-hoc re-ranking algorithm that balances relevance and gender fairness by combining cosine similarity of image labels with query terms and KL divergence of gender distributions. Experimental results demonstrate that the re-ranking approach produces fairer results with competitive relevance scores compared to baselines. The work also highlights the significant challenge of accurate gender detection from non-frontal face images common in web search results, pointing to a need for improved detection models.

## Method Summary
The authors collect 100 top-ranked images for 10 occupational keywords from Google Image Search and manually annotate gender labels. They implement a fairness-aware re-ranking algorithm that optimizes both relevance (using cosine distance between image labels and query terms) and gender fairness (using KL divergence of gender distributions). The method involves detecting faces in images, classifying gender, extracting object labels using Amazon Rekognition, computing semantic relevance via GloVe embeddings, and re-ranking based on a composite cost function. The system is evaluated using bucket ranking accuracy for relevance and Normalized Discounted KL Divergence for fairness.

## Key Results
- The proposed re-ranking algorithm produces rankings with better fairness scores and competitive relevance scores compared to random re-ranking and relevance-only baselines
- Existing gender detection models perform poorly on non-frontal face images common in web search results
- The system demonstrates the feasibility of post-hoc re-ranking to improve fairness without significantly degrading relevance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Post-hoc re-ranking can improve fairness in image search without degrading relevance
- Mechanism: The proposed re-ranking algorithm combines cosine distance between image labels and query terms (relevance) with KL divergence of gender distributions (fairness) to produce a composite cost that selects images optimizing both criteria
- Core assumption: Relevance and fairness can be modeled as separate components that can be combined additively with tunable weights
- Evidence anchors:
  - [abstract]: "fairness-aware re-ranking algorithm that optimizes (a) relevance of the search result with the keyword and (b) fairness w.r.t genders identified"
  - [section]: "We propose a fairness ranking algorithm for images incorporating both relevance and fairness with respect to the gender distribution for the given search query"
  - [corpus]: Weak evidence - related papers focus on text/image generation rather than re-ranking mechanisms
- Break condition: If relevance and fairness are fundamentally antagonistic (i.e., improving one always worsens the other), the additive combination will fail to find good solutions

### Mechanism 2
- Claim: Gender detection from web search images is significantly harder than from frontal face images
- Mechanism: Existing gender detection models trained on frontal face datasets (ImageNet, UTKFace) perform poorly on non-frontal, partially visible, or occluded faces common in web search results
- Core assumption: The performance gap between frontal and non-frontal face gender detection is due to the training data distribution mismatch
- Evidence anchors:
  - [section]: "existing models exhibit superior/acceptable performance on the frontal face... Their performance though reduces when the environment becomes unconstrained, such as in the case of web-search retrieved images"
  - [section]: "Images with varying degree of quality and resolutions... Interference of objects... Face/body partially visible and/or misaligned"
  - [corpus]: Weak evidence - related papers focus on bias in generated images rather than detection challenges
- Break condition: If new models can be trained on diverse, real-world web image datasets that capture the full range of face orientations and occlusions

### Mechanism 3
- Claim: Reinforcement learning-based re-ranking can outperform static re-ranking by adapting to user feedback
- Mechanism: Multi-page search processes can be modeled as Markov Decision Processes where the system learns to select documents based on user click feedback to optimize ranking accuracy
- Core assumption: User click patterns provide reliable signals about document relevance that can be learned through reinforcement learning
- Evidence anchors:
  - [section]: "The multi-page search process is an interactive process between the user and the search engine... Zeng et al. proposed a technical schema to use user feedback from the top-ranked documents to generate re-ranking for the remaining documents"
  - [section]: "Zhou et al. proposed a De-biased Reinforcement Learning Click model (DRLC) that ignores previously made assumptions about the users' examination behavior and resulting latent bias"
  - [corpus]: Weak evidence - related papers focus on bias in generated images rather than interactive re-ranking
- Break condition: If user click data is too noisy or biased to provide reliable learning signals, or if the state space becomes too large for practical RL training

## Foundational Learning

- Concept: KL divergence as a fairness metric
  - Why needed here: To measure how much the gender distribution in the ranked results deviates from the overall corpus distribution
  - Quick check question: What does a KL divergence of 0 indicate about two distributions?
- Concept: Cosine similarity for semantic relevance
  - Why needed here: To measure how semantically similar the objects detected in an image are to the query term
  - Quick check question: If two word vectors have a cosine similarity of 1.0, what does that tell us about their semantic relationship?
- Concept: Reinforcement learning basics (MDP, policy gradient)
  - Why needed here: To understand how future re-ranking systems might learn from user feedback rather than using static cost functions
  - Quick check question: In a Markov Decision Process, what does the policy represent?

## Architecture Onboarding

- Component map:
  - Query submission -> Image retrieval (Google Search API) -> Gender detection (face detection + gender classification) -> Object detection and embedding extraction (Amazon Rekognition + GloVe) -> Re-ranking algorithm (cost function with relevance and fairness terms) -> Evaluation metrics (relevance accuracy, NDKL for fairness)

- Critical path:
  1. Query submission â†’ image retrieval
  2. Gender detection on retrieved images
  3. Object detection and embedding extraction
  4. Compute relevance and fairness costs
  5. Re-rank based on composite cost
  6. Output re-ranked results

- Design tradeoffs:
  - Open-source vs proprietary gender detection (accuracy vs transparency)
  - Relevance vs fairness weight tuning (depends on application requirements)
  - Real-time vs batch processing (computational constraints)

- Failure signatures:
  - Gender detection accuracy drops significantly on non-frontal faces
  - Re-ranking produces results with very low relevance scores
  - Fairness metric shows no improvement over random ranking
  - High variance in results across different queries

- First 3 experiments:
  1. Compare open-source gender detection pipelines (MTCNN+Facelib vs Detectron2+Facelib) on the challenge dataset
  2. Test re-ranking with different weight combinations (wr, wg) on a subset of occupations
  3. Evaluate the impact of object detection quality on relevance scoring by comparing results with/without object detection

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can gender detection models be improved to handle the diverse, real-world images found in web search results rather than just frontal face images?
- Basis in paper: [explicit] The authors note that existing gender detection models struggle with non-frontal face images common in web search results and suggest training on large-scale open-ended images and considering architectural changes to capture non-facial features.
- Why unresolved: While the paper identifies the need for improved gender detection models, it does not provide specific solutions or evaluate potential approaches for handling diverse image search results.
- What evidence would resolve it: Experimental results comparing the performance of different gender detection models (including those trained on diverse image datasets and incorporating non-facial features) on a large-scale challenge dataset of web search images.

### Open Question 2
- Question: How effective are joint language and vision models, like VisualBERT, compared to word embedding-based methods for measuring relevance between image labels and query terms in the context of re-ranking image search results?
- Basis in paper: [inferred] The authors suggest considering joint language and vision models like VisualBERT to compute relevance scores, implying that this approach may be more effective than the word embedding-based method used in their experiments.
- Why unresolved: The paper does not provide any experimental results or comparisons between the word embedding-based method and joint language and vision models for measuring relevance in image search re-ranking.
- What evidence would resolve it: Comparative experiments evaluating the performance of different relevance scoring methods (including word embedding-based and joint language and vision models) in terms of both relevance and fairness metrics on a large-scale image search dataset.

### Open Question 3
- Question: How can reinforcement learning be used to optimize the ranking procedure itself, rather than just re-ranking retrieved results, to improve the fairness and relevance of image search results over time?
- Basis in paper: [explicit] The authors mention that their proposed re-ranking algorithm does not improve the search over time and suggest using reinforcement learning to optimize the ranking procedure itself.
- Why unresolved: While the paper identifies the potential of reinforcement learning for improving the ranking procedure, it does not provide any specific implementation details or experimental results for this approach.
- What evidence would resolve it: Implementation and evaluation of a reinforcement learning-based ranking algorithm that learns to optimize both relevance and fairness metrics over time, compared to the re-ranking approach used in the paper and baseline methods.

## Limitations
- The fundamental challenge of accurate gender detection from non-frontal face images common in web search results
- The assumption that relevance and fairness can be combined additively without antagonistic effects
- Limited evaluation to only 10 occupations, which may not represent the full spectrum of gender stereotypes

## Confidence

- **High Confidence**: The observation that existing gender detection models perform poorly on non-frontal faces from web search results is well-supported by empirical evidence in the paper
- **Medium Confidence**: The proposed re-ranking algorithm's effectiveness is demonstrated through controlled experiments, but real-world performance may vary depending on gender detection accuracy
- **Low Confidence**: The assumption that relevance and fairness can be combined additively without antagonistic effects is not thoroughly validated, particularly for occupations with strong gender associations

## Next Checks

1. **External Validation on New Occupations**: Test the re-ranking algorithm on a broader set of 20-30 occupations beyond the initial 10 to assess generalizability across different gender stereotype strengths

2. **Human Evaluation of Gender Detection**: Conduct a user study where human annotators evaluate the same images used for gender detection to quantify the gap between automated and human gender classification accuracy

3. **Real-time Performance Testing**: Implement the system in a live search environment to measure the computational overhead and user interaction patterns, particularly the impact of post-hoc re-ranking on search latency and user satisfaction