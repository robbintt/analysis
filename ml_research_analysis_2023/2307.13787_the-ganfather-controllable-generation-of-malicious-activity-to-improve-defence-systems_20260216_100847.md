---
ver: rpa2
title: 'The GANfather: Controllable generation of malicious activity to improve defence
  systems'
arxiv_id: '2307.13787'
source_url: https://arxiv.org/abs/2307.13787
tags:
- data
- detection
- system
- malicious
- systems
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces The GANfather, a method to generate synthetic
  malicious activity and train detection systems without labeled data. It combines
  a GAN-like generator with a malicious optimization objective to produce realistic
  attacks, and a discriminator to detect them.
---

# The GANfather: Controllable generation of malicious activity to improve defence systems

## Quick Facts
- arXiv ID: 2307.13787
- Source URL: https://arxiv.org/abs/2307.13787
- Reference count: 38
- One-line primary result: Novel GAN-based method generates synthetic malicious activity to train detection systems without labeled data

## Executive Summary
The paper introduces The GANfather, a method to generate synthetic malicious activity and train detection systems without labeled data. It combines a GAN-like generator with a malicious optimization objective to produce realistic attacks, and a discriminator to detect them. Evaluated on anti-money laundering and recommendation system use-cases, it successfully generated attacks moving $350,000 through accounts undetected and influenced item recommendations with 0.5% fake users. The trained discriminators achieved near-perfect detection of synthetic attacks, demonstrating effectiveness in improving defense systems. Limitations include reliance on mostly legitimate data and differentiable objectives. The approach provides a novel way to enhance security by simulating and detecting previously unseen attacks.

## Method Summary
The GANfather method combines a generator and discriminator architecture with a malicious optimization objective. Starting from unlabelled data assumed to be predominantly legitimate, the generator learns to create malicious activity that satisfies specific malicious goals (e.g., high transaction amounts in AML, or promoting a target item in recommender systems). The discriminator is trained to distinguish between real legitimate data and synthetic malicious data. Optionally, an existing detection system can be incorporated as a differentiable proxy to teach the generator to bypass current defenses. The method was evaluated on real-world anti-money laundering and MovieLens 1M recommendation system datasets.

## Key Results
- Successfully generated synthetic attacks moving $350,000 through accounts undetected in AML use-case
- Achieved 0.5% fake user rate in influencing item recommendations in recommender system
- Trained discriminators achieved near-perfect detection of synthetic attacks
- Demonstrated effectiveness in improving defense systems against previously unseen attacks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The generator learns to produce realistic malicious samples without needing labelled data.
- Mechanism: By adding a malicious optimisation objective to the GAN loss, the generator is rewarded for producing samples that satisfy the malicious goal (e.g., high transaction amounts in AML, or promoting a target item in recommender systems).
- Core assumption: The unlabelled data is predominantly legitimate, so the generator can start from this base and learn deviations that match malicious patterns.
- Evidence anchors:
  - [abstract] "We propose The GANfather, a method to generate samples with properties of malicious activity, without label requirements."
  - [section 2.1] "Starting from unlabelled data, which we assume to be predominantly legitimate, the proposed method leverages a GAN-like setup [...] to train a generator which learns to create malicious activity"
- Break condition: If the unlabelled data contains significant amounts of already malicious activity, the generator may not learn clear deviations.

### Mechanism 2
- Claim: The discriminator trained on synthetic malicious vs real data can generalize to detect real malicious activity.
- Mechanism: The discriminator learns to distinguish between real legitimate data and synthetic malicious data generated by the generator. Since the synthetic malicious data is designed to mimic real malicious behaviour, the discriminator can generalize this knowledge to detect unseen real attacks.
- Core assumption: The synthetic malicious samples share sufficient properties with real malicious samples for the discriminator to generalize.
- Evidence anchors:
  - [abstract] "the trained discriminators achieved near-perfect detection of synthetic attacks, demonstrating effectiveness in improving defense systems"
  - [section 2.4] "the generator subject to Equation 1 will generate data increasingly out of distribution for larger ð›¼. Therefore, we do not require the discriminator accuracy to fall to chance level at training convergence, as is usual with GANs."
- Break condition: If the synthetic malicious samples are too different from real malicious samples, the discriminator may not generalize well.

### Mechanism 3
- Claim: Incorporating an existing detection system as a differentiable proxy allows the generator to learn to bypass it, revealing weaknesses for the discriminator to correct.
- Mechanism: The existing detection system is mimicked by a differentiable neural network. The generator is penalized for triggering this proxy system, so it learns to produce samples that avoid detection. The discriminator then learns to detect these previously unseen attacks.
- Core assumption: A differentiable proxy of the existing detection system can be constructed.
- Evidence anchors:
  - [section 2.2] "In AML, it is common to have rule-based detection systems. [...] Hence, we construct a deep learning model as a proxy for the rules system. We hard-code a neural network mimicking the rules' logic operations by choosing the weights, biases and activation functions appropriately."
- Break condition: If the existing detection system is too complex or non-differentiable to proxy accurately, this mechanism fails.

## Foundational Learning

- Concept: Generative Adversarial Networks (GANs)
  - Why needed here: The GANfather is built upon the GAN framework, using a generator to create synthetic data and a discriminator to distinguish it from real data.
  - Quick check question: What are the typical loss functions used for the generator and discriminator in a GAN?
- Concept: Adversarial attacks and defenses
  - Why needed here: The paper deals with generating adversarial examples (malicious activity) and training a defense system to detect them.
  - Quick check question: What is the difference between an evasion attack and a poisoning attack?
- Concept: Representation of dynamic graphs as tensors
  - Why needed here: The AML use case represents transaction data as a 3D tensor to capture the dynamic graph of transactions over time.
  - Quick check question: How does the 3D tensor representation capture the time dimension of the transaction data?

## Architecture Onboarding

- Component map:
  - Generator -> Discriminator -> Detection System Improvement
- Critical path: Generator creates synthetic malicious activity â†’ Discriminator learns to distinguish real from synthetic â†’ Detection system improves ability to catch real attacks
- Design tradeoffs:
  - Balancing the GAN loss with the malicious objective: Too much emphasis on the malicious objective can make the synthetic data too different from real data.
  - Using an existing detection system: Provides more realistic attacks but requires a differentiable proxy.
- Failure signatures:
  - Discriminator not improving: The generator may be producing samples too different from real data.
  - Generator not producing malicious samples: The malicious objective may be too weak or the unlabelled data may not contain sufficient legitimate data.
- First 3 experiments:
  1. Train a standard GAN on the unlabelled data to ensure the generator and discriminator are working correctly.
  2. Add a simple malicious objective and observe if the generator produces samples that satisfy it.
  3. Introduce an existing detection system (or its proxy) and verify the generator learns to bypass it.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How robust is the method against adversarial defenses that evolve over time, and what are the implications for long-term deployment?
- Basis in paper: [inferred] The paper discusses the adversarial nature of illicit activities and the need for robust detection systems, but does not explore the long-term dynamics of such systems.
- Why unresolved: The paper focuses on the initial effectiveness of the method in generating and detecting attacks but does not address how the system would perform as adversaries adapt over time.
- What evidence would resolve it: Longitudinal studies comparing the method's performance against evolving adversarial strategies over extended periods.

### Open Question 2
- Question: What are the computational costs associated with scaling the method to larger datasets, and how do these costs impact its practicality?
- Basis in paper: [inferred] The paper demonstrates the method's effectiveness on specific datasets but does not discuss scalability or computational efficiency.
- Why unresolved: The paper does not provide insights into how the method performs with larger datasets or the computational resources required for scaling.
- What evidence would resolve it: Performance benchmarks and resource usage analysis for the method applied to larger datasets.

### Open Question 3
- Question: How does the method handle cases where the unlabelled data contains a significant proportion of malicious activity, and what are the implications for its accuracy?
- Basis in paper: [explicit] The paper assumes unlabelled data is predominantly legitimate and does not address scenarios where this assumption is violated.
- Why unresolved: The paper does not explore the method's performance in scenarios where the assumption of predominantly legitimate data is not met.
- What evidence would resolve it: Experimental results showing the method's accuracy and reliability when applied to datasets with varying proportions of malicious activity.

## Limitations
- Reliance on unlabelled data being predominantly legitimate - if data contains significant malicious patterns, generator may amplify rather than create novel attacks
- Dependence on differentiable optimization objectives - may constrain applicability to complex, non-differentiable real-world detection systems
- Limited validation - effectiveness demonstrated only on specific use cases, may not generalize to all malicious activity types

## Confidence
- High Confidence: The core GAN architecture and basic training procedure are well-established and properly implemented
- Medium Confidence: The malicious optimization objectives produce realistic synthetic attacks, though validation is limited to specific use cases
- Medium Confidence: The discriminator's ability to generalize to unseen real attacks based on synthetic training data, with limited ablation studies

## Next Checks
1. Test the approach on datasets with varying proportions of pre-existing malicious activity (0%, 5%, 20%) to measure performance degradation
2. Implement a non-differentiable baseline detection system and compare transferability of synthetic attacks versus the differentiable proxy approach
3. Conduct temporal validation by testing whether discriminators trained on synthetic attacks from one time period detect real attacks from subsequent periods