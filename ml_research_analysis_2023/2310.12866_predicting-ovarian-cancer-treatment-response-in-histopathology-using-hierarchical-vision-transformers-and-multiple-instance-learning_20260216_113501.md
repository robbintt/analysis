---
ver: rpa2
title: Predicting Ovarian Cancer Treatment Response in Histopathology using Hierarchical
  Vision Transformers and Multiple Instance Learning
arxiv_id: '2310.12866'
source_url: https://arxiv.org/abs/2310.12866
tags:
- cancer
- were
- ovarian
- learning
- treatment
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study evaluated deep learning models for predicting ovarian
  cancer treatment response using histopathology whole slide images. The approach
  combined a pretrained Hierarchical Image Pyramid Transformer (HIPT) for region-level
  feature extraction with an attention-based multiple instance learning (ABMIL) model
  for slide-level classification.
---

# Predicting Ovarian Cancer Treatment Response in Histopathology using Hierarchical Vision Transformers and Multiple Instance Learning

## Quick Facts
- arXiv ID: 2310.12866
- Source URL: https://arxiv.org/abs/2310.12866
- Reference count: 17
- This study evaluated deep learning models for predicting ovarian cancer treatment response using histopathology whole slide images, achieving 60.2% ±2.9% balanced accuracy and AUC of 0.646 ±0.033 on internal 5-fold cross-validation, but failed to generalize to tissue microarray data.

## Executive Summary
This study evaluated deep learning approaches for predicting ovarian cancer treatment response from histopathology whole slide images. The researchers developed a pipeline combining Hierarchical Image Pyramid Transformers (HIPT) for region-level feature extraction with Attention-based Multiple Instance Learning (ABMIL) for slide-level classification. While the optimal HIPT-ABMIL model achieved modest performance on internal cross-validation, it failed to generalize to external tissue microarray validation data. The authors found that histopathology-specific model pretraining was beneficial, though hierarchical transformers did not outperform standard ResNet-based approaches. The study highlights the challenges of developing predictive models from small, heterogeneous datasets and raises questions about whether ovarian cancer whole slide images contain sufficient prognostic information for accurate treatment response prediction.

## Method Summary
The study used whole slide images (WSIs) from 78 ovarian cancer patients (282 slides) to train deep learning models for predicting treatment response to bevacizumab therapy. The pipeline involved tissue segmentation using Otsu thresholding, extraction of 4096x4096 non-overlapping tissue regions, and feature extraction using either HIPT or ResNet architectures. These region-level features were then aggregated using Attention-based Multiple Instance Learning (ABMIL) to classify whole slides as treatment responders or non-responders. The models were pretrained on large histopathology datasets (DINO for HIPT, SimCLR for ResNet) and evaluated using 5-fold cross-validation with balanced accuracy, AUC, and F1 score as metrics. External validation was performed on 180 tissue microarray images.

## Key Results
- HIPT-ABMIL achieved 60.2% ±2.9% balanced accuracy and AUC of 0.646 ±0.033 on internal 5-fold cross-validation test set
- Model performance was highly variable across folds with some showing extreme differences between validation and test set performance
- HIPT-ABMIL failed to generalize to tissue microarray data, with accuracy worse than random chance
- Histopathology-specific model pretraining was beneficial, with histopathology-pretrained models outperforming ImageNet-pretrained ResNet-ABMIL (52.7% balanced accuracy)

## Why This Works (Mechanism)

### Mechanism 1
Pretraining feature extractors on large histopathology datasets improves classification performance for ovarian cancer treatment response prediction. Histopathology-specific pretraining enables the model to learn domain-specific visual patterns and tissue characteristics that are relevant for distinguishing treatment response, which general image pretraining may not capture.

### Mechanism 2
Hierarchical transformers can capture spatial relationships in histopathology images that are relevant for treatment response prediction. By processing image features at multiple scales (cell-level to patch-level to region-level), hierarchical transformers can learn spatial patterns and arrangements that correlate with treatment response.

### Mechanism 3
Attention-based multiple instance learning can effectively aggregate region-level features to classify whole slide images for treatment response prediction. ABMIL allows the model to focus on the most relevant regions within a whole slide image, learning which regions are most indicative of treatment response while ignoring less relevant areas.

## Foundational Learning

- Concept: Understanding of vision transformers and their self-attention mechanism
  - Why needed here: The HIPT-ABMIL model uses vision transformers for feature extraction, so understanding how self-attention works in this context is crucial for interpreting model behavior and potential improvements.
  - Quick check question: How does the self-attention mechanism in vision transformers differ from that in language transformers, and why is this difference important for image processing?

- Concept: Multiple instance learning (MIL) and its application to whole slide image classification
  - Why needed here: ABMIL is used to aggregate region-level features into slide-level predictions, so understanding the MIL framework is essential for grasping how the model makes final classifications.
  - Quick check question: In the context of whole slide image classification, what is the "bag" and what are the "instances" in the MIL framework, and how does attention help in this scenario?

- Concept: Domain-specific pretraining vs. general pretraining in computer vision
  - Why needed here: The paper compares histopathology-pretrained models with ImageNet-pretrained models, so understanding the benefits and limitations of domain-specific pretraining is important for interpreting the results.
  - Quick check question: What are the potential advantages and disadvantages of using domain-specific pretraining versus general pretraining for medical image analysis tasks?

## Architecture Onboarding

- Component map: WSI -> tissue segmentation -> region extraction (4096x4096) -> feature extraction (HIPT/ResNet) -> ABMIL aggregation -> binary classification
- Critical path: WSI → tissue segmentation → region extraction → feature extraction → ABMIL aggregation → classification
- Design tradeoffs:
  - Using hierarchical transformers vs. standard ResNets: Hierarchical transformers can capture spatial relationships at multiple scales but may be more computationally intensive
  - Tissue segmentation quality: Affects the regions used for modeling and can introduce confounding if not done carefully
  - Region size (4096x4096): Balances computational efficiency with capturing sufficient context, but may miss fine-grained details
- Failure signatures:
  - Low balanced accuracy and AUC: Indicates the model is not effectively learning to distinguish treatment responders from non-responders
  - Large differences between validation and test set performance: Suggests overfitting or data heterogeneity issues
  - Poor generalization to TMA data: Indicates the model may be overfitting to specific characteristics of the training WSIs
- First 3 experiments:
  1. Evaluate the impact of tissue segmentation quality on model performance by comparing results using different segmentation parameters
  2. Compare the performance of histopathology-pretrained vs. ImageNet-pretrained feature extractors to quantify the benefit of domain-specific pretraining
  3. Analyze the attention heatmaps to identify potential confounding factors or regions that the model is focusing on for classification

## Open Questions the Paper Calls Out

### Open Question 1
Do ovarian cancer whole slide images contain sufficient prognostic information to accurately predict treatment response? The authors state "It is not yet clear whether ovarian cancer WSIs contain information that can be used to accurately predict treatment response" and note that their model did not generalize well to tissue microarrays, with accuracy worse than random chance.

### Open Question 2
Do hierarchical vision transformers provide better performance than standard ResNet-based approaches for ovarian cancer treatment response prediction? The authors found "did not find transformer-based models to outperform ResNet-based models" despite histopathology-specific pretraining being beneficial.

### Open Question 3
What is the optimal definition of treatment response that should be used for predicting ovarian cancer treatment effectiveness from histopathology? The authors note that "the clinical utility of these models would benefit from a more precise and clinically relevant definition of outcome" and that their binary classification grouped patients with relapse after just over 6 months together with those who never relapsed.

## Limitations
- Small sample size (282 WSIs from 78 patients) combined with high data heterogeneity led to unstable model performance across cross-validation folds
- Model failed to generalize to tissue microarray data, suggesting overfitting to specific characteristics of the training whole slide images
- The binary classification of treatment response (progression within 6 months) may be too simplistic and not clinically meaningful

## Confidence
- Low confidence: The claim that hierarchical transformers outperform standard approaches - the study found no significant improvement over ResNet-based models
- Medium confidence: The benefit of histopathology-specific pretraining - supported by internal validation but requires larger studies for confirmation
- Low confidence: The overall clinical utility of WSI-based treatment response prediction - poor external validation performance raises questions about real-world applicability

## Next Checks
1. External validation with matched cohorts: Test the model on larger, more diverse ovarian cancer datasets with standardized tissue preparation protocols to assess true generalization capability.

2. Feature importance analysis: Conduct ablation studies to determine which histopathology features the model actually uses for prediction, particularly examining whether spatial relationships or individual cell morphology drive predictions.

3. Clinical correlation study: Compare model predictions against established clinical biomarkers and patient outcomes to determine whether the model captures biologically meaningful patterns or artifacts.