---
ver: rpa2
title: 'Rethinking Data Distillation: Do Not Overlook Calibration'
arxiv_id: '2307.12463'
source_url: https://arxiv.org/abs/2307.12463
tags:
- data
- ddnns
- distillation
- calibration
- more
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the calibration problem in neural networks
  trained on distilled datasets, which often produce overconfident outputs. The authors
  identify that existing calibration methods fail for such networks due to the condensed
  information and loss of semantically meaningful but non-classification-related data
  in distilled datasets.
---

# Rethinking Data Distillation: Do Not Overlook Calibration

## Quick Facts
- arXiv ID: 2307.12463
- Source URL: https://arxiv.org/abs/2307.12463
- Reference count: 40
- Primary result: Proposed MTS and MDT techniques reduce ECE by up to 91.05% while maintaining accuracy on distilled datasets

## Executive Summary
This paper addresses a critical limitation in neural networks trained on distilled datasets: they often produce overconfident predictions that cannot be effectively calibrated using existing methods. The authors identify that this occurs because dataset distillation optimizes for classification accuracy at the expense of retaining diverse semantic information. They propose two novel techniques - Masked Temperature Scaling (MTS) and Masked Distillation Training (MDT) - which introduce controlled perturbation to improve output diversity and encoding capacity. Experiments across multiple benchmark datasets demonstrate significant ECE reduction while maintaining comparable accuracy.

## Method Summary
The authors propose two complementary techniques to improve calibration of neural networks trained on distilled data. Masked Temperature Scaling (MTS) applies binary masking to validation data during temperature scaling to force more diverse logit outputs. Masked Distillation Training (MDT) applies binary masking to synthetic data during the distillation process to compel the model to extract richer, more semantically complete information from the source dataset. Both methods require minimal computational overhead and work with various dataset distillation backbones.

## Key Results
- MTS and MDT reduce Expected Calibration Error by up to 91.05% compared to baseline calibration methods
- Methods maintain comparable accuracy to standard calibration approaches
- Particularly effective in extreme compression settings (e.g., 1 image per class)
- MDT produces distilled data with more evenly distributed information content, making it harder to decompose

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distilled data lacks semantically meaningful but non-classification-related information, leading to overconfident predictions.
- Mechanism: Dataset distillation optimizes for classification accuracy at the expense of retaining diverse semantic information, causing the resulting model to be overconfident in its predictions.
- Core assumption: The distillation process inherently discards information not directly relevant to classification tasks.
- Evidence anchors:
  - [abstract] "distilled data lead to networks that are not calibratable due to (i) a more concentrated distribution of the maximum logits and (ii) the loss of information that is semantically meaningful but unrelated to classification tasks."
  - [section 3.2] "distilled data is 'simpler' than source full data, such that dropping the same amount of information from distilled datasets should hurt the training performance worse than it does on full data."

### Mechanism 2
- Claim: Masked Temperature Scaling (MTS) improves calibration by introducing controlled perturbation to the validation data.
- Mechanism: By applying a binary mask to the validation data during temperature scaling, MTS forces the model to produce more diverse and smaller logit values, making it more calibratable.
- Core assumption: Perturbing the validation data can help the model output more varied logit values, improving calibration.
- Evidence anchors:
  - [abstract] "We propose Masked Temperature Scaling (MTS) and Masked Distillation Training (MDT) which mitigate the limitations of distilled data and achieve better calibration results while maintaining the efficiency of dataset distillation."
  - [section 4.1] "We seek to overcome this source of difficulty in calibration by perturbing the validation data such that the model could output more various and smaller logit values."

### Mechanism 3
- Claim: Masked Distillation Training (MDT) enhances the encoding capacity of the model by forcing it to extract richer information from the source dataset.
- Mechanism: By applying a binary mask to the synthetic data during the distillation process, MDT compels the distillation model to focus on other structurally and semantically meaningful information, leading to better encoding abilities and thus better calibration.
- Core assumption: Masking some of the synthetic data makes it harder to collect easily reachable information from the source dataset, forcing the distillation to focus on other meaningful information.
- Evidence anchors:
  - [abstract] "We propose Masked Temperature Scaling (MTS) and Masked Distillation Training (MDT) which mitigate the limitations of distilled data and achieve better calibration results while maintaining the efficiency of dataset distillation."
  - [section 4.2] "We avoid over-concentration of distillation data on easily identifiable information in the source complete data by perturbing the binary mask during distillation, so that the distillation data also contain more semantically complete information."

## Foundational Learning

- Concept: Expected Calibration Error (ECE)
  - Why needed here: ECE is a common metric to quantitatively measure the difference between confidence and accuracy, which is crucial for evaluating the calibration of neural networks.
  - Quick check question: What does a lower ECE value indicate about the calibration of a neural network?

- Concept: Temperature Scaling
  - Why needed here: Temperature scaling is an after-training calibration method that scales the output logits to improve calibration, which is relevant to the proposed Masked Temperature Scaling (MTS) method.
  - Quick check question: How does temperature scaling modify the output logits to improve calibration?

- Concept: Singular Value Decomposition (SVD)
  - Why needed here: SVD is used to analyze the information diversity and significance of data components, which helps in understanding the differences between distilled and full data.
  - Quick check question: What does a more concentrated distribution of singular values in distilled data indicate about its information content?

## Architecture Onboarding

- Component map:
  Input data -> Dataset Distillation Backbones (MTT, RTP, DC, DSA) -> Masked Distillation Training (MDT) -> Neural network trained on distilled data -> Masked Temperature Scaling (MTS) -> Evaluation metrics (ECE, accuracy)

- Critical path:
  1. Apply MDT during the distillation process to enhance the encoding capacity of the model.
  2. Train the neural network on the resulting distilled data.
  3. Apply MTS after training to improve calibration by introducing controlled perturbation to the validation data.

- Design tradeoffs:
  - Masking ratio in MDT: Higher ratios may lead to better calibration but could also result in loss of important information or overfitting.
  - Masking ratio in MTS: Higher ratios may improve calibration but could also lead to underfitting or loss of important information.
  - Computational cost: Applying MDT and MTS may increase the computational cost compared to standard distillation and calibration methods.

- Failure signatures:
  - Over-calibration: The model becomes under-confident in its predictions.
  - Under-calibration: The model remains overconfident in its predictions.
  - Loss of important information: The masking ratios are set too high, leading to a significant drop in accuracy.

- First 3 experiments:
  1. Apply MTS with different masking ratios (e.g., 0.1, 0.3, 0.5) on a distilled dataset and evaluate the resulting ECE and accuracy.
  2. Apply MDT with different masking ratios (e.g., 0.1, 0.3, 0.5) during the distillation process and evaluate the resulting distilled dataset's information diversity using SVD.
  3. Combine MDT and MTS on a distilled dataset and evaluate the resulting ECE and accuracy, comparing it to the individual methods.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the masking ratio in Masked Temperature Scaling affect calibration performance across different datasets and model architectures?
- Basis in paper: [explicit] The paper discusses the effects of different masking ratios (r) on ECE in Figures 8 and 9, but does not provide a comprehensive analysis of optimal ratios for various datasets and architectures.
- Why unresolved: The paper only provides specific masking ratios for a few datasets and does not explore a wide range of ratios or architectures.
- What evidence would resolve it: A systematic study varying the masking ratio across multiple datasets, model architectures, and distillation backbones would provide insights into the optimal masking ratio for different scenarios.

### Open Question 2
- Question: How does the performance of Masked Distillation Training (MDT) compare to other data augmentation techniques in terms of calibration and accuracy?
- Basis in paper: [inferred] The paper mentions that MDT can be viewed as a new version of dropout on the input, but does not directly compare its performance to other data augmentation techniques like Mixup or CutMix.
- Why unresolved: The paper focuses on the comparison of MDT with other calibration methods, but does not explore its effectiveness as a data augmentation technique.
- What evidence would resolve it: A comparative study of MDT against other data augmentation techniques, evaluating both calibration performance and accuracy on various datasets and model architectures, would provide insights into its relative effectiveness.

### Open Question 3
- Question: How does the calibration of DDNNs trained on extremely compressed datasets (e.g., image-per-class = 1) compare to those trained on less compressed datasets?
- Basis in paper: [explicit] The paper mentions that calibration in lower accuracy settings is challenging, and provides results for IPC=1 in Table 5.
- Why unresolved: The paper only provides results for IPC=1 on a single dataset (CIFAR10) and does not explore the calibration performance of DDNNs trained on extremely compressed datasets across multiple datasets and architectures.
- What evidence would resolve it: A comprehensive study of DDNNs trained on extremely compressed datasets across multiple datasets, model architectures, and distillation backbones would provide insights into the calibration challenges and potential solutions in these scenarios.

### Open Question 4
- Question: How does the calibration of DDNNs trained on imbalanced datasets compare to those trained on balanced datasets?
- Basis in paper: [inferred] The paper does not explicitly discuss the impact of dataset imbalance on DDNN calibration, but it is a common challenge in machine learning that could affect calibration performance.
- Why unresolved: The paper focuses on calibration of DDNNs trained on balanced datasets and does not explore the impact of dataset imbalance on calibration performance.
- What evidence would resolve it: A study of DDNN calibration performance on imbalanced datasets, comparing it to calibration on balanced datasets, would provide insights into the challenges and potential solutions for calibrating DDNNs in imbalanced scenarios.

## Limitations

- The optimal masking ratios are not systematically explored across different dataset sizes and architectures, potentially limiting generalizability
- The semantic completeness claims for MDT-produced data rely primarily on SVD analysis rather than direct semantic content measurement
- The effectiveness on larger model architectures (ResNet-50, Vision Transformers) remains untested

## Confidence

- **High Confidence**: The core observation that distilled datasets produce overconfident models due to condensed information is well-supported by multiple experiments across different datasets and distillation backbones. The MTS method's effectiveness in reducing ECE by up to 91.05% is convincingly demonstrated.
- **Medium Confidence**: The mechanism explanation for why masking improves calibration is reasonable but could benefit from more theoretical grounding. The claim about MDT producing more semantically complete information is supported empirically but lacks direct semantic validation.
- **Low Confidence**: The generalizability of specific masking ratios across different dataset sizes and architectures is uncertain without broader experimental validation.

## Next Checks

1. **Masking Ratio Sensitivity Analysis**: Systematically vary masking ratios (0.1 to 0.9) for both MTS and MDT across multiple dataset sizes to establish optimal ranges and identify breaking points where calibration improvement degrades into accuracy loss.

2. **Semantic Content Validation**: Apply semantic segmentation or feature attribution methods to compare the information content of MDT-produced distilled data versus standard distillation, directly measuring semantic completeness rather than relying solely on SVD decomposition.

3. **Cross-Architecture Generalization**: Test MTS and MDT effectiveness on transformer-based architectures and larger models (ResNet-50, Vision Transformers) to validate whether the calibration improvements scale beyond the small ConvNet architectures used in the paper.