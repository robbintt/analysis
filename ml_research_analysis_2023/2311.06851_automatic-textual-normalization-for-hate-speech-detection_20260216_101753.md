---
ver: rpa2
title: Automatic Textual Normalization for Hate Speech Detection
arxiv_id: '2311.06851'
source_url: https://arxiv.org/abs/2311.06851
tags:
- normalization
- textual
- social
- dataset
- media
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of normalizing Vietnamese social
  media text, which often contains non-standard words (NSW) like abbreviations and
  slang that hinder natural language processing (NLP) tasks. The authors propose using
  a sequence-to-sequence (Seq2Seq) model to automatically convert non-standard text
  into a standard form.
---

# Automatic Textual Normalization for Hate Speech Detection

## Quick Facts
- arXiv ID: 2311.06851
- Source URL: https://arxiv.org/abs/2311.06851
- Authors: 
- Reference count: 18
- This paper addresses the challenge of normalizing Vietnamese social media text, which often contains non-standard words (NSW) like abbreviations and slang that hinder natural language processing (NLP) tasks.

## Executive Summary
This paper addresses the challenge of normalizing Vietnamese social media text, which often contains non-standard words (NSW) like abbreviations and slang that hinder natural language processing (NLP) tasks. The authors propose using a sequence-to-sequence (Seq2Seq) model to automatically convert non-standard text into a standard form. They created a dataset of 2,181 human-annotated comments with an inter-annotator agreement of 0.9014. The Seq2Seq model achieved an accuracy of just under 70%, which, while not perfect, still improved the accuracy of a downstream hate speech detection (HSD) task by approximately 2%. This demonstrates the potential of textual normalization to enhance the performance of complex NLP tasks, even with imperfect normalization.

## Method Summary
The authors employ sequence-to-sequence (Seq2Seq) models, specifically the S2S, S2SSelf, and S2SMulti variants, to normalize non-standard Vietnamese social media text. The task is treated as a machine translation problem, mapping non-standard tokens to their standard equivalents using an encoder-decoder framework with attention. The models are trained on a dataset of 2,181 human-annotated comments collected from social media platforms like Facebook and YouTube. The best-performing model is then used to preprocess text for the hate speech detection task, improving its accuracy by approximately 2%.

## Key Results
- Seq2Seq model achieved normalization accuracy of just under 70%
- Textual normalization improved hate speech detection accuracy by approximately 2%
- S2SMulti variant outperformed other Seq2Seq models in normalization tasks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sequence-to-sequence models can learn to normalize non-standard Vietnamese social media text into a standard form.
- Mechanism: The Seq2Seq model treats lexical normalization as a machine translation problem, mapping non-standard tokens to their standard equivalents using an encoder-decoder framework with attention.
- Core assumption: Social media non-standard words follow consistent transformation patterns that can be learned from annotated examples.
- Evidence anchors:
  - [abstract] "Our approach is straightforward, employing solely a sequence-to-sequence (Seq2Seq) model"
  - [section 4.1] "We defined the lexical normalization task as a machine translation problem involving translating a non-standard sentence into a standard one"
  - [corpus] Weak evidence - corpus contains hate speech detection papers but no direct validation of Seq2Seq for Vietnamese lexical normalization
- Break condition: If the transformation patterns are too context-dependent or if non-standard words lack consistent mappings, the model's accuracy will remain below 70% as observed.

### Mechanism 2
- Claim: Textual normalization improves downstream NLP task performance even with imperfect normalization.
- Mechanism: Normalized text reduces vocabulary variation and standardizes word forms, making it easier for downstream models like Text-CNN and GRU to detect patterns for hate speech classification.
- Core assumption: Standardizing text provides more consistent features for NLP models than raw non-standard text.
- Evidence anchors:
  - [abstract] "textual normalization enhances the accuracy of the Hate Speech Detection (HSD) task by approximately 2%"
  - [section 4.6] "using textual normalization improves the accuracy of HSD tasks by 2% on F1-micro and Accuracy"
  - [corpus] Weak evidence - corpus contains hate speech detection research but lacks direct comparison of normalized vs unnormalized text performance
- Break condition: If normalization introduces more errors than it corrects, or if downstream models can handle non-standard text effectively, the performance improvement may not materialize.

### Mechanism 3
- Claim: The S2SMulti variant outperforms other Seq2Seq models for this task.
- Mechanism: S2SMulti first converts tokens with single interpretations, then handles tokens with multiple possible normalizations, reducing ambiguity in the learning process.
- Core assumption: Some tokens have multiple valid standard forms, and handling them separately improves overall normalization accuracy.
- Evidence anchors:
  - [section 4.4] "The S2SMulti model has the best ability in textual normalization, as its F1-score and BLEU-4 on the validation and test sets are the highest"
  - [section 4.1] "S2SMulti model: To begin, we convert tokens with a single normalized format, and then translate tokens with many adjustments using the S2S model"
  - [corpus] Weak evidence - corpus lacks specific validation of S2SMulti variant performance
- Break condition: If most tokens have single interpretations or if the two-stage approach adds unnecessary complexity, simpler models may perform equally well.

## Foundational Learning

- Concept: Sequence-to-sequence modeling with attention mechanisms
  - Why needed here: The core task uses Seq2Seq to map non-standard to standard text, requiring understanding of encoder-decoder architectures and attention
  - Quick check question: How does the attention mechanism help the decoder focus on relevant parts of the input sequence during token generation?

- Concept: Vietnamese text segmentation and syllable-level processing
  - Why needed here: Vietnamese words are written as continuous strings without spaces, requiring syllable-level tokenization for the Seq2Seq model
  - Quick check question: Why are Vietnamese syllables treated as the smallest processing unit rather than words in this approach?

- Concept: Inter-annotator agreement and dataset quality assessment
  - Why needed here: The dataset creation process relies on human annotation with quality measured by Cohen's Kappa coefficient
  - Quick check question: What does a Cohen's Kappa value of 0.9014 indicate about the consistency of human annotations?

## Architecture Onboarding

- Component map: Data preprocessing -> Model training -> Normalization -> Downstream task evaluation
- Critical path: Data preprocessing → Model training → Normalization → Downstream task evaluation
- Design tradeoffs:
  - Simple Seq2Seq vs multi-stage approaches: Simpler models are easier to train but may handle ambiguous tokens poorly
  - Token-level vs character-level processing: Token-level preserves meaning but requires good segmentation
  - Dataset size vs annotation quality: Smaller high-quality dataset vs larger potentially noisier dataset
- Failure signatures:
  - Low F1-score (< 50%) indicates the model cannot learn effective normalization patterns
  - High BLEU-4 but low F1-score suggests the model generates fluent text but misses many normalization targets
  - Downstream task performance similar with/without normalization suggests normalization provides little benefit
- First 3 experiments:
  1. Train S2S model on 80% of dataset, evaluate F1-score and BLEU-4 on validation set
  2. Compare S2S, S2SSelf, and S2SMulti variants on same validation set to identify best architecture
  3. Apply best normalization model to downstream hate speech detection task and measure performance change

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would increasing the dataset size impact the performance of Seq2Seq models for Vietnamese textual normalization?
- Basis in paper: [explicit] The paper mentions that "the dataset size is relatively small, which may cause a limitation in lexical normalization" and plans to enlarge the dataset in future work.
- Why unresolved: The current dataset contains only 2,181 comments, which may not be sufficient for training robust Seq2Seq models. The paper acknowledges this limitation but does not provide experimental evidence of the impact of dataset size on model performance.
- What evidence would resolve it: Training and evaluating Seq2Seq models on progressively larger datasets (e.g., 5,000, 10,000, 50,000 comments) and comparing their performance metrics (F1-score, BLEU-4) to determine the relationship between dataset size and model accuracy.

### Open Question 2
- Question: Would alternative neural architectures (e.g., BERT-based models) outperform Seq2Seq models for Vietnamese textual normalization?
- Basis in paper: [explicit] The paper uses Seq2Seq models and acknowledges that "the accuracy of textual normalization is not very high (less than 70%)" and plans to explore other deep learning methods in future work.
- Why unresolved: The paper only experiments with Seq2Seq models and does not compare their performance to other neural architectures that have shown success in similar NLP tasks.
- What evidence would resolve it: Implementing and evaluating BERT-based models or other state-of-the-art architectures for Vietnamese textual normalization and comparing their performance metrics to those of Seq2Seq models on the same dataset.

### Open Question 3
- Question: How does textual normalization affect the performance of other Vietnamese NLP tasks beyond hate speech detection?
- Basis in paper: [explicit] The paper demonstrates that textual normalization improves hate speech detection accuracy by 2% and states that it "strengthens the supporting role of lexical normalization in multiple NLP applications."
- Why unresolved: The paper only tests the impact of textual normalization on one downstream task (hate speech detection) and does not provide evidence of its benefits for other Vietnamese NLP tasks.
- What evidence would resolve it: Applying textual normalization as a preprocessing step for various Vietnamese NLP tasks (e.g., sentiment analysis, named entity recognition, machine translation) and measuring the performance improvement in each task compared to using unnormalized text.

## Limitations
- Dataset generalizability: The dataset contains only 2,181 annotated comments from social media platforms, which may not capture the full diversity of Vietnamese non-standard text patterns.
- Model architecture specificity: The paper lacks detailed specification of model hyperparameters, attention mechanism configurations, and exact preprocessing steps for Vietnamese text.
- Downstream task evaluation: The 2% improvement in hate speech detection accuracy may not be practically significant depending on the baseline model performance.

## Confidence
- **High confidence**: The sequence-to-sequence approach for lexical normalization is technically sound and represents a reasonable methodology for this task.
- **Medium confidence**: The specific implementation details for Vietnamese text processing and the relative performance of different Seq2Seq variants are less certain due to incomplete methodological specifications.
- **Low confidence**: The generalizability of results to other languages or different social media contexts remains highly uncertain.

## Next Checks
1. **Replication study with extended dataset**: Collect an additional 2,000-3,000 annotated Vietnamese social media comments from different sources and platforms, then retrain the S2SMulti model to verify if the normalization accuracy remains stable or improves with more training data.

2. **Error analysis of downstream impact**: Conduct a detailed error analysis comparing hate speech detection performance on normalized vs. unnormalized text, categorizing errors by type (false positives, false negatives) and by normalization quality (correctly normalized, incorrectly normalized, unchanged) to understand where the 2% improvement comes from.

3. **Cross-linguistic validation**: Apply the same Seq2Seq normalization approach to another language with similar non-standard text challenges (e.g., Thai or Indonesian) to test whether the methodology generalizes beyond Vietnamese and whether the S2SMulti variant consistently outperforms simpler approaches across languages.