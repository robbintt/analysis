---
ver: rpa2
title: 'PAXQA: Generating Cross-lingual Question Answering Examples at Training Scale'
arxiv_id: '2304.12206'
source_url: https://arxiv.org/abs/2304.12206
tags:
- cross-lingual
- question
- english
- datasets
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PAXQA proposes a method for generating large-scale cross-lingual
  QA datasets by combining English question generation with word alignment-informed
  machine translation. The approach uses parallel corpora with word alignments to
  project answers and applies lexically-constrained MT to improve question translation
  quality.
---

# PAXQA: Generating Cross-lingual Question Answering Examples at Training Scale

## Quick Facts
- arXiv ID: 2304.12206
- Source URL: https://arxiv.org/abs/2304.12206
- Reference count: 27
- Generated 662K QA examples across 4 languages

## Executive Summary
PAXQA introduces a method for generating large-scale cross-lingual QA datasets by combining English question generation with word alignment-informed machine translation. The approach decomposes cross-lingual QA into two stages: first generating English QA pairs, then projecting answers using word alignments and translating questions using lexically-constrained MT. Models trained on these synthetic datasets significantly outperformed zero-shot baselines and achieved state-of-the-art results on the MLQA benchmark, with the largest gains for directions involving non-English questions and English contexts.

## Method Summary
PAXQA generates cross-lingual QA data through a two-stage process. First, it applies a question generation model to the English side of parallel corpora to create English QA pairs. Second, it uses word alignments to project answer spans from English to target languages and applies machine translation to convert questions, with lexically-constrained MT to preserve named entities. The method requires no non-English QA supervision, making it extensible to low-resource languages. The approach was evaluated on Chinese, Arabic, Russian, and English, generating 662K QA examples.

## Key Results
- Achieved state-of-the-art results on MLQA benchmark
- Outperformed zero-shot baselines by 10-15 F1 points
- Largest gains observed for non-English question + English context directions
- Demonstrated robustness to automatic word alignment noise

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Word alignment-informed translation improves answer projection accuracy from source to target language.
- Mechanism: When a QA pair is generated from an English sentence, the answer is a span of tokens. By leveraging word alignments between the English source and target language sentence, these answer tokens can be projected directly without requiring a full MT system.
- Core assumption: Word alignments correctly identify corresponding tokens between parallel sentences.

### Mechanism 2
- Claim: Lexically-constrained MT improves question translation quality by preserving named entities and specific terms.
- Mechanism: Extract noun phrases from the English context sentence as lexical constraints, then apply these constraints during MT of the generated English question to the target language.
- Core assumption: Named entities and specific terms in questions are more likely to be preserved as noun phrases in the original context.

### Mechanism 3
- Claim: Decomposing cross-lingual QG into English QG + MT stages allows leveraging existing high-quality models without requiring non-English QA supervision.
- Mechanism: First generate QA pairs in English using a strong English QG model, then translate to target languages using MT systems.
- Core assumption: High-quality English QG models exist and can generate useful QA pairs for downstream training.

## Foundational Learning

- Concept: Word alignment
  - Why needed here: Essential for projecting answer spans from source to target language without full MT
  - Quick check question: How do you determine which words in a target sentence correspond to words in a source sentence?

- Concept: Lexical constraints in MT
  - Why needed here: Improves translation of specific terms and named entities in questions
  - Quick check question: What happens when you provide a phrase and its desired translation as a constraint to an MT system?

- Concept: Question generation as dual of QA
  - Why needed here: Enables synthetic data generation by reversing the QA task
  - Quick check question: How can you train a model to generate questions given an answer and context?

## Architecture Onboarding

- Component map:
  - English QG model (T5-based multitask) -> Word alignment system (awesome-align) -> MT systems (vanilla Transformer, Google Translate, lexically-constrained NMT) -> QA model (XLM-R fine-tuned) -> Human evaluation interface

- Critical path:
  1. Generate English QA pairs from parallel corpus
  2. Apply word alignments to project answers
  3. Translate questions using MT with constraints
  4. Train QA model on synthetic data
  5. Evaluate on downstream QA tasks

- Design tradeoffs:
  - English-centric approach vs. direct multilingual generation
  - Quality of word alignments vs. need for full MT
  - Constraint extraction complexity vs. translation accuracy
  - Synthetic data quantity vs. quality

- Failure signatures:
  - Low alignment quality → missing or incorrect answers
  - Poor QG quality → irrelevant or unanswerable questions
  - MT errors → mistranslated questions
  - Overfitting to synthetic data → poor generalization

- First 3 experiments:
  1. Generate QA pairs on a small parallel corpus and manually inspect answer projection quality
  2. Compare vanilla MT vs. lexically-constrained MT on a sample of questions
  3. Train a QA model on synthetic data and evaluate on a small gold dataset

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does PAXQA's performance compare to human-translated cross-lingual QA datasets in terms of both quality and annotation efficiency?
- Basis in paper: [inferred] The paper discusses the quality of PAXQA's synthetic data generation method and its comparison to zero-shot baselines and prior synthetic data generation models, but does not directly compare to human-translated datasets.
- Why unresolved: The paper focuses on the effectiveness of PAXQA compared to existing methods, but does not explore the potential benefits of human-translated datasets.
- What evidence would resolve it: A direct comparison of PAXQA-generated data with human-translated cross-lingual QA datasets, evaluating both the quality of the generated data and the efficiency of the annotation process.

### Open Question 2
- Question: What is the impact of using different question generation models in PAXQA's first stage on the overall performance of the downstream QA task?
- Basis in paper: [explicit] The paper mentions that PAXQA uses a specific question generation model (Dugan et al., 2022) but states that the methodology supports drop-in replacements.
- Why unresolved: The paper does not explore the effects of using alternative question generation models on the final QA performance.
- What evidence would resolve it: Experiments comparing the performance of PAXQA using different question generation models, analyzing the impact on the quality of the generated data and the downstream QA task.

### Open Question 3
- Question: How does PAXQA's performance vary across different language pairs, particularly for low-resource languages with limited parallel corpora?
- Basis in paper: [explicit] The paper applies PAXQA to four languages (Chinese, Arabic, Russian, and English) and discusses its potential applicability to low-resource languages.
- Why unresolved: The paper does not provide a comprehensive analysis of PAXQA's performance across a wide range of language pairs, especially for low-resource languages.
- What evidence would resolve it: Extensive experiments applying PAXQA to various language pairs, including low-resource languages, and analyzing the performance differences based on the availability of parallel corpora and other factors.

## Limitations

- **Word alignment quality dependence**: Method's success heavily depends on word alignment quality, with no quantification of how alignment errors affect QA performance across different language pairs.

- **Synthetic data quality variability**: Limited analysis of quality distribution across generated 662K examples, with filtering heuristics not fully specified.

- **Zero-shot baseline fairness**: Comparison to zero-shot baselines may not represent fairest baseline as models weren't trained for cross-lingual scenarios.

## Confidence

**High confidence**: The decomposition approach of separating English QG from MT stages is sound and well-supported by empirical results showing significant improvements over zero-shot baselines.

**Medium confidence**: The claimed state-of-the-art results on MLQA are supported by experiments, but improvement magnitude depends on specific zero-shot baseline chosen.

**Low confidence**: Claims about extensibility to low-resource languages are largely theoretical, as experiments only cover four relatively high-resource languages.

## Next Checks

1. **Alignment quality impact study**: Systematically vary word alignment error rate and measure corresponding impact on QA performance across all four target languages.

2. **Synthetic data quality analysis**: Conduct human evaluation on stratified samples of generated QA pairs across all languages, measuring answer correctness, question relevance, and translation quality.

3. **Cross-lingual generalization test**: Evaluate models trained on PAXQA data on out-of-domain cross-lingual QA tasks or on language pairs not seen during training.