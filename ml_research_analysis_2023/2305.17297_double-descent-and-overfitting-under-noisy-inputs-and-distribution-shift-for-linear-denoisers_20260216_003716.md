---
ver: rpa2
title: Double Descent and Overfitting under Noisy Inputs and Distribution Shift for
  Linear Denoisers
arxiv_id: '2305.17297'
source_url: https://arxiv.org/abs/2305.17297
tags:
- data
- error
- generalization
- training
- test
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper provides theoretical analysis for denoising low-dimensional
  data embedded in high-dimensional space, removing common assumptions like independence
  and identical distribution of data. The authors derive data-dependent expressions
  for test error in both denoising and noisy-input regression under distribution shift,
  studying when overfitting is benign, tempered, or catastrophic.
---

# Double Descent and Overfitting under Noisy Inputs and Distribution Shift for Linear Denoisers

## Quick Facts
- arXiv ID: 2305.17297
- Source URL: https://arxiv.org/abs/2305.17297
- Reference count: 40
- This paper provides theoretical analysis for denoising low-dimensional data embedded in high-dimensional space, removing common assumptions like independence and identical distribution of data.

## Executive Summary
This paper presents a theoretical framework for analyzing linear denoisers when data has low-rank structure and is embedded in high-dimensional space. The authors derive data-dependent expressions for test error that don't require I.I.D. assumptions, studying how overfitting behaves under noisy inputs and distribution shift. They show that test error exhibits double descent behavior and provide bounds on the difference between in-distribution and out-of-distribution risks. The theory is validated on real datasets with less than 1% mean squared error error for low-rank data.

## Method Summary
The method involves projecting high-dimensional data onto a low-rank subspace and computing an optimal linear denoiser using minimum norm solutions to least squares problems. The theoretical analysis uses random matrix theory to derive asymptotic expressions for generalization error, accounting for both in-subspace and out-of-subspace distributional shifts. The framework models training and test data that may have different distributions while sharing the same low-rank structure, with noise satisfying rotational bi-invariance assumptions.

## Key Results
- Derived data-dependent expressions for test error that work without I.I.D. assumptions
- Showed test error exhibits double descent under general distribution shift
- Proved strong correlation between in-distribution and out-of-distribution risks

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Low-rank structure enables decoupling of training and test data assumptions
- Mechanism: By assuming data lies in a low-dimensional subspace, the paper can express both training and test data in terms of shared basis vectors. This allows analytical formulas to be derived without needing identical or independent distributions between train and test sets.
- Core assumption: Data matrices are low-rank with bounded singular values, and noise satisfies rotational bi-invariance.
- Evidence anchors:
  - [abstract]: "We look at data that is not I.I.D. but has a low-rank structure... Theorem 1 provides the generalization error without needing assumptions involving the independence or identical distribution of either the training or test data."
  - [section]: "For any test data Xtst that lives in V... the mean squared generalization error... is given by the following, with L := U^T Xtst"
  - [corpus]: Weak evidence; no direct match, but supports double descent analysis under general conditions.
- Break condition: If data does not lie in a low-rank subspace or if noise violates rotational bi-invariance assumptions.

### Mechanism 2
- Claim: Double descent occurs due to implicit regularization from noise
- Mechanism: Training with noisy inputs acts as implicit regularization, which can reduce overfitting in certain regimes. The interaction between model complexity and noise level creates the characteristic double descent curve.
- Core assumption: Noise follows Assumptions 2, 3, and 4 (zero-mean, variance scaling, rotational bi-invariance).
- Evidence anchors:
  - [abstract]: "We show that the test error exhibits double descent under general distribution shift"
  - [section]: "We establish a link between the optimal denoiser and solving linear regression problems in the presence of input noise"
  - [corpus]: Moderate evidence; several related papers on double descent but focused on different mechanisms.
- Break condition: If noise distribution deviates significantly from assumptions or if noise level is too high relative to signal.

### Mechanism 3
- Claim: Strong correlation between in-distribution and out-of-distribution risks
- Mechanism: The bound on risk difference depends only on alignment between test data subspaces, not on training data itself. This creates a stable relationship between risks across distributions.
- Core assumption: Test data can be decomposed into subspace component and orthogonal residual with bounded norm.
- Evidence anchors:
  - [abstract]: "We bound the difference between in-distribution and out-of-distribution expected risk... strong correlation between the two risks"
  - [section]: "Theorem 2 provides a reasonable bound and shows a strong correlation between the two risks"
  - [corpus]: No direct evidence; weak support for correlation claims.
- Break condition: If test data has large orthogonal component or if alignment terms vary significantly across distributions.

## Foundational Learning

- Concept: Random matrix theory and Marchenko-Pastur distribution
  - Why needed here: Used to derive asymptotic expressions for spectral properties of noise-corrupted data matrices
  - Quick check question: Can you explain how the Marchenko-Pastur distribution describes the eigenvalue spectrum of a random matrix?

- Concept: Singular value decomposition and low-rank matrix approximation
  - Why needed here: Essential for expressing data in terms of subspace basis and deriving generalization error formulas
  - Quick check question: How does the SVD of a low-rank matrix differ from that of a full-rank matrix?

- Concept: Bias-variance decomposition in generalization error
  - Why needed here: The paper separates generalization error into bias and variance terms that depend differently on model complexity
  - Quick check question: What is the difference between bias and variance terms in the context of generalization error?

## Architecture Onboarding

- Component map: Data preprocessing -> Noise addition -> Optimal denoiser computation -> Theoretical error calculation -> Empirical validation
- Critical path:
  1. Load and project data onto low-rank subspace
  2. Add noise according to specified distribution
  3. Compute optimal denoiser W
  4. Calculate theoretical generalization error using derived formulas
  5. Validate against empirical measurements
- Design tradeoffs:
  - Low-rank assumption vs. model expressiveness
  - Noise level: too little provides no regularization, too much obscures signal
  - Rank selection: higher rank captures more structure but increases computational cost
- Failure signatures:
  - Poor fit between theory and experiment: likely violation of low-rank or noise assumptions
  - Numerical instability in matrix inversions: singular values too close to zero
  - Unexpected generalization behavior: check noise distribution assumptions
- First 3 experiments:
  1. Verify double descent curve shape with synthetic low-rank data under varying noise levels
  2. Test correlation between in-distribution and out-of-distribution risks using different test datasets
  3. Implement data augmentation via noisy copies and measure impact on generalization error

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the generalization error behave under distribution shift when the test data has a non-linear structure within the low-dimensional subspace?
- Basis in paper: [explicit] The paper discusses in-subspace and out-of-subspace distributional shifts but assumes a linear structure within the subspace.
- Why unresolved: The theoretical results are derived under linear assumptions, and extending them to non-linear cases would require new mathematical tools and analysis.
- What evidence would resolve it: Empirical experiments on real data with non-linear structures and theoretical extensions of the current results to non-linear settings.

### Open Question 2
- Question: What is the impact of different noise distributions on the generalization error beyond the rotationally bi-invariant assumption?
- Basis in paper: [explicit] The paper assumes rotationally bi-invariant noise distributions but does not explore other types of noise.
- Why unresolved: The current theoretical framework is tailored to rotationally bi-invariant noise, and analyzing other distributions would require different techniques.
- What evidence would resolve it: Empirical studies comparing generalization errors under various noise distributions and theoretical analysis extending the results to other noise types.

### Open Question 3
- Question: How does the generalization error scale with the number of classes in classification tasks using the denoising framework?
- Basis in paper: [inferred] The paper focuses on regression and denoising, but classification is a common application where the number of classes can affect generalization.
- Why unresolved: The theoretical results are derived for continuous outputs, and extending them to classification would require new analysis.
- What evidence would resolve it: Empirical experiments on multi-class classification tasks and theoretical extensions of the results to classification settings.

### Open Question 4
- Question: What is the effect of regularization techniques (e.g., dropout, batch normalization) on the generalization error in the denoising framework?
- Basis in paper: [inferred] The paper discusses data augmentation and noise as implicit regularization but does not explore other regularization methods.
- Why unresolved: The theoretical framework does not account for explicit regularization techniques, and their impact would need separate analysis.
- What evidence would resolve it: Empirical studies comparing generalization errors with and without different regularization techniques and theoretical analysis incorporating these methods.

## Limitations
- The framework relies heavily on the low-rank data assumption, which may not hold for many real-world datasets
- Theoretical results assume specific noise properties (rotational bi-invariance) that may not match all practical scenarios
- The analysis focuses on linear denoisers, limiting applicability to more complex nonlinear models

## Confidence
- Low-rank generalization theory: High confidence
- Double descent under distribution shift: Medium confidence
- Correlation between in-distribution and out-of-distribution risks: Medium confidence

## Next Checks
1. Test the theoretical predictions on datasets with varying degrees of low-rank structure (not just the assumed exact low-rank case) to assess robustness of the formulas.

2. Conduct systematic experiments varying the noise distribution parameters beyond the assumed Gaussian case to evaluate sensitivity to noise assumptions.

3. Validate the risk correlation bounds using multiple test distributions with different subspace alignments to verify the practical utility of the theoretical bounds.