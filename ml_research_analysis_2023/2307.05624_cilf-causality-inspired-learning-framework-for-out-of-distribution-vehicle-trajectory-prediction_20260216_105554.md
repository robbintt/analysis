---
ver: rpa2
title: CILF:Causality Inspired Learning Framework for Out-of-Distribution Vehicle
  Trajectory Prediction
arxiv_id: '2307.05624'
source_url: https://arxiv.org/abs/2307.05624
tags:
- causal
- domain
- prediction
- feature
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'The paper addresses the problem of out-of-distribution (OOD) generalization
  in vehicle trajectory prediction for autonomous driving. It proposes an Out-of-Distribution
  Causal Graph (OOD-CG) that explicitly defines the underlying causal structure of
  trajectory data with three entangled latent features: domain-invariant causal feature
  (IC), domain-variant causal feature (VC), and domain-variant non-causal feature
  (VN).'
---

# CILF:Causality Inspired Learning Framework for Out-of-Distribution Vehicle Trajectory Prediction

## Quick Facts
- **arXiv ID:** 2307.05624
- **Source URL:** https://arxiv.org/abs/2307.05624
- **Reference count:** 33
- **Key outcome:** CILF improves prediction accuracy for both source and target domains in single-scenario, cross-scenario, and cross-dataset settings, with 4.73% to 5.47% ADE improvement and 2.53% to 3.17% FDE improvement in cross-scenario domain generalization.

## Executive Summary
This paper addresses out-of-distribution (OOD) generalization in vehicle trajectory prediction by proposing a Causality Inspired Learning Framework (CILF) that explicitly models the underlying causal structure of trajectory data. The framework introduces an Out-of-Distribution Causal Graph (OOD-CG) that decomposes latent features into three categories: domain-invariant causal features (IC), domain-variant causal features (VC), and domain-variant non-causal features (VN). CILF employs a three-step approach using invariant risk minimization, domain contrastive learning, and domain adversarial learning to extract and leverage these causal features for improved prediction accuracy across source and target domains.

## Method Summary
CILF addresses OOD generalization in vehicle trajectory prediction through a three-step causal feature extraction process. First, it uses invariant risk minimization (IRM) to extract domain-invariant causal features (IC) that remain consistent across domains. Second, it applies domain contrastive learning to capture domain-variant features (V). Third, it employs a mask generator with Gumbel-Softmax to separate V into domain-variant causal (VC) and non-causal (VN) features. The framework combines these features through a fusion module to predict future trajectories, with the causal graph explicitly blocking backdoor paths to ensure direct causal effects mediate predictions.

## Key Results
- CILF improves prediction accuracy for both source and target domains across three experimental settings: single-scenario, cross-scenario, and cross-dataset domain generalization
- In cross-scenario domain generalization, CILF achieves 4.73% to 5.47% ADE improvement and 2.53% to 3.17% FDE improvement compared to vanilla training across different prediction models
- The framework demonstrates consistent performance gains across multiple baseline models including S-LSTM, CS-LSTM, and MFP

## Why This Works (Mechanism)

### Mechanism 1
- Claim: OOD-CG explicitly defines three latent feature categories (IC, VC, VN) to capture causal structure of trajectory data.
- Mechanism: The causal graph disentangles domain-invariant causal features (IC), domain-variant causal features (VC), and domain-variant non-causal features (VN) through backdoor confounder C and domain selector D.
- Core assumption: The Common Causal Principle holds, meaning correlations can be decomposed into causal mechanisms.
- Evidence anchors:
  - [abstract] "OOD-CG divides the latent features into three categories: 1) Domain-invariant Causal Feature (IC), 2) Domain-variant Causal Feature (VC), and 3) Domain-variant Non-causal Feature (VN)."
  - [section] "We divide these backdoor features into three classes: (1) Domain-Invariant Causal Feature (IC), (2) Domain-Variant Causal Feature (VC), and (3) Domain-Variant Non-causal Feature (VN)."
  - [corpus] Weak - corpus contains related causality work but no direct confirmation of OOD-CG's specific tripartite structure.
- Break condition: If the Common Causal Principle fails or features cannot be reliably disentangled.

### Mechanism 2
- Claim: CILF uses three-step process to extract and leverage causal features for prediction.
- Mechanism: (1) IRM loss extracts domain-invariant causal feature IC, (2) Domain contrastive learning extracts domain variant feature V, (3) Domain adversarial learning separates VC and VN.
- Core assumption: Each extraction method effectively isolates its target feature type.
- Evidence anchors:
  - [abstract] "CILF includes three steps: 1) extracting domain-invariant causal feature by means of an invariance loss, 2) extracting domain variant feature by domain contrastive learning, and 3) separating domain-variant causal and non-causal feature by encouraging causal sufficiency."
  - [section] "CILF includes three parts to block the backdoor paths associated with IC, VC, and VN."
  - [corpus] Moderate - corpus shows similar causality-inspired approaches but not this specific three-step architecture.
- Break condition: If IRM, contrastive learning, or adversarial methods fail to isolate features as intended.

### Mechanism 3
- Claim: Blocking backdoor paths enables causal features to mediate prediction effects.
- Mechanism: By blocking backdoor paths of IC and VN, VC serves as mediator in causal effects from D and C to Y, enabling direct causal prediction.
- Core assumption: Causal sufficiency is achieved through the mask generator's Gumbel-Softmax technique.
- Evidence anchors:
  - [section] "In order to extract domain-invariant causal mechanisms P(Y|VC), P(Y|IC) for prediction, it is necessary to block the backdoor paths connecting these entangled features."
  - [section] "CILF introduces a neural network based mask generator M(.) that produces a causally sufficient mask [16] using the Gumbel-Softmax technique."
  - [corpus] Weak - corpus mentions causal sufficiency but not in the specific context of this mask-based approach.
- Break condition: If mask generator fails to achieve causal sufficiency or backdoor paths remain unblocked.

## Foundational Learning

- Concept: Causal representation learning using Structure Causal Model (SCM)
  - Why needed here: CILF relies on SCM to model the causal structure of trajectory data and identify backdoor paths.
  - Quick check question: What are the three main components of an SCM and how do they relate to the OOD-CG?

- Concept: Domain generalization techniques (IRM, contrastive learning, adversarial learning)
  - Why needed here: Each technique addresses a specific aspect of feature extraction in the CILF pipeline.
  - Quick check question: How does invariant risk minimization encourage domain invariance in feature representations?

- Concept: Gumbel-Softmax technique for discrete sampling
  - Why needed here: Used by mask generator to identify causal dimensions from domain-variant features.
  - Quick check question: What is the advantage of using Gumbel-Softmax over standard softmax for categorical sampling in this context?

## Architecture Onboarding

- Component map: Input → Φic(.) → IRM Loss → Φv(.) → Contrastive Loss → M(.) → VC/VN separation → F(.) → Θ(.) → Output
- Critical path: History trajectories → IC encoder (IRM) → Domain-variant encoder (contrastive) → Mask generator (Gumbel-Softmax) → Fusion module → Decoder → Future trajectories
- Design tradeoffs: Balancing between feature extraction quality and computational efficiency, choosing appropriate hyperparameters for IRM, contrastive learning, and adversarial training.
- Failure signatures: Poor domain generalization performance, feature entanglement, unstable training due to adversarial components.
- First 3 experiments:
  1. Verify IRM loss successfully extracts domain-invariant features by testing performance across source domains.
  2. Test contrastive learning's ability to capture domain variance by examining feature similarity within vs. across domains.
  3. Validate mask generator's causal sufficiency by measuring prediction performance with and without VC feature separation.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed three latent features (IC, VC, VN) interact with each other in different driving scenarios and what is the precise contribution of each feature to prediction accuracy?
- Basis in paper: [explicit] The paper proposes OOD-CG which explicitly defines the underlying causal structure of trajectory data with three entangled latent features: domain-invariant causal feature (IC), domain-variant causal feature (VC), and domain-variant non-causal feature (VN).
- Why unresolved: While the paper proposes the three features and demonstrates their effectiveness, it does not provide detailed analysis of how these features interact in different scenarios or their individual contributions to prediction accuracy.
- What evidence would resolve it: Controlled experiments isolating the effect of each feature on prediction accuracy across different scenarios, and analysis of feature interaction patterns in various driving conditions.

### Open Question 2
- Question: What is the optimal balance between invariant risk minimization and domain contrastive learning for extracting domain-invariant and domain-variant features respectively?
- Basis in paper: [explicit] The paper proposes CILF which uses invariant risk minimization to extract domain-invariant causal feature and domain contrastive learning to extract domain variant feature, but does not discuss the optimal balance between these two methods.
- Why unresolved: The paper uses these methods but does not explore the sensitivity of the model to different balance parameters or investigate whether different scenarios might require different balances.
- What evidence would resolve it: Systematic ablation studies varying the balance parameters and analyzing their impact on prediction accuracy across different scenarios and datasets.

### Open Question 3
- Question: How can the mask generator be improved to better separate domain-variant causal and non-causal features, especially in scenarios with high levels of sensor noise?
- Basis in paper: [explicit] The paper proposes a mask generator using Gumbel-SoftMax technique to separate domain-variant causal and non-causal features, but acknowledges that domain-variant features do not naturally carry causality and need to be filtered.
- Why unresolved: The paper does not explore alternative techniques for feature separation or investigate the performance of the mask generator in high-noise scenarios.
- What evidence would resolve it: Comparison of the Gumbel-SoftMax technique with alternative feature separation methods in scenarios with varying levels of sensor noise, and analysis of the mask generator's performance in these conditions.

## Limitations
- The specific architectural details of the fusion module F(.) and how CF and SF are combined are not fully specified
- The mask generator M(.) implementation details and exact Gumbel-Softmax application are underspecified
- Limited validation beyond NGSIM and INTERACTION datasets without broader testing across diverse driving scenarios

## Confidence
- **High Confidence**: The three-step CILF framework structure and its connection to OOD generalization (supported by established IRM, contrastive learning, and adversarial training literature)
- **Medium Confidence**: The specific implementation details of feature separation and causal sufficiency claims (partially supported by related causality work but lacks direct validation)
- **Low Confidence**: The universal applicability of the OOD-CG structure across different driving scenarios (limited to tested datasets without broader validation)

## Next Checks
1. Conduct ablation studies removing each CILF component (IRM, contrastive learning, mask generator) to verify their individual contributions to performance gains
2. Test the framework's generalization to additional driving datasets beyond NGSIM and INTERACTION to validate the causal graph assumptions
3. Perform feature visualization and correlation analysis to empirically verify the separation of domain-invariant causal, domain-variant causal, and domain-variant non-causal features