---
ver: rpa2
title: 'LibriWASN: A Data Set for Meeting Separation, Diarization, and Recognition
  with Asynchronous Recording Devices'
arxiv_id: '2308.10682'
source_url: https://arxiv.org/abs/2308.10682
tags:
- data
- devices
- meeting
- speech
- recording
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: LibriWASN is a new data set for meeting separation, diarization,
  and recognition using asynchronous recording devices. It closely follows the LibriCSS
  design but is recorded with nine different devices, including five smartphones and
  four microphone arrays, for a total of 29 channels.
---

# LibriWASN: A Data Set for Meeting Separation, Diarization, and Recognition with Asynchronous Recording Devices

## Quick Facts
- arXiv ID: 2308.10682
- Source URL: https://arxiv.org/abs/2308.10682
- Reference count: 27
- A new dataset for meeting transcription with 29 channels from 9 asynchronous devices

## Executive Summary
LibriWASN is a new dataset for meeting speech separation, diarization, and recognition using asynchronous recording devices. It follows the LibriCSS design but records with nine different devices (five smartphones and four microphone arrays) for 29 channels total. The devices are randomly positioned on a meeting table with unsynchronized sampling clocks, introducing sampling rate offsets. The dataset includes 20 hours of transcribed audio recorded in two acoustically different rooms, with ground-truth diarization information. A reference meeting transcription pipeline is provided, demonstrating that multi-device beamforming improves performance, especially in reverberant environments.

## Method Summary
The paper introduces LibriWASN, a dataset for meeting transcription with asynchronous recording devices. The dataset contains 20 hours of audio recorded in two rooms with different reverberation times using nine devices (five smartphones and four microphone arrays), totaling 29 channels. A reference pipeline is provided that includes SRO compensation using dynamic weighted average coherence drift (DWACD) estimation, mask-based beamforming with complex Angular Central Gaussian Mixture Model (cACGMM), and ASR using a pretrained ESPnet transformer model. The system compensates for sampling rate offsets before beamforming, uses cACGMM to estimate masks for individual speakers, and evaluates performance using word error rate (WER) and concatenated minimum-permutation word error rate (cpWER).

## Key Results
- Using multiple devices for beamforming improves performance, especially in reverberant environments
- SRO compensation is essential for coherent beamforming across asynchronous devices
- The dataset enables research on multi-channel source separation and meeting transcription tasks using asynchronous audio streams

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Sampling rate offset (SRO) compensation is essential for coherent beamforming across asynchronous devices
- Mechanism: SROs introduce time-varying delays between channels, which distort the inter-microphone phase relationships required for spatial filtering. The paper compensates SROs using dynamic weighted average coherence drift (DWACD) estimation followed by STFT-resampling
- Core assumption: SROs are stable enough over short frames to allow coherent processing after compensation
- Evidence anchors: [abstract]: "SRO compensation, mask-based beamforming, and ASR"; [section]: "In order to extract the single speakers' signals, mask-based beamforming is utilized. ... we firstly compensate for SROs"
- Break condition: If SROs drift too fast relative to STFT frame length, phase relationships become unreliable, degrading beamforming performance

### Mechanism 2
- Claim: Multi-channel cACGMM mask estimation initialized via SCM clustering improves diarization accuracy in overlapping speech
- Mechanism: The meeting is divided into segments; SCMs are estimated per segment, approximated to rank-1, and clustered based on correlation matrix distance to identify dominant speaker activity. These clusters initialize the cACGMM for mask estimation
- Core assumption: Each segment contains at most one dominant speaker, and SCM clustering can separate speakers based on spatial coherence
- Evidence anchors: [section]: "A complex Angular Central Gaussian Mixture Model (cACGMM) ... is used to estimate a mask for each of the speakers ... The initialization of the cACGMM is based on the idea to divide the meeting into segments consisting of multiple frames, which are clustered afterwards"
- Break condition: If segments contain heavy overlapping speech or the SCM approximation fails, clustering may merge different speakers, leading to incorrect masks

### Mechanism 3
- Claim: Using multiple distributed microphones for beamforming improves speech extraction in reverberant environments
- Mechanism: Minimum variance distortionless response (MVDR) beamforming combines spatial diversity from multiple devices, yielding better directivity and noise suppression than single-array beamforming
- Core assumption: Inter-device time differences of arrival (TDOAs) are preserved after STO reduction and can be used for coherent combination
- Evidence anchors: [abstract]: "Experimental results show that using multiple devices for beamforming improves performance, especially in more reverberant environments"; [section]: "If the masks are still estimated using a single array but all devices are used for beamforming (Sys-3), the results for both subsets of LibriWASN can be improved"
- Break condition: If synchronization errors remain after STO reduction, beamforming gains will degrade

## Foundational Learning

- Concept: Sampling rate offset and its compensation
  - Why needed here: Asynchronous recording devices introduce SROs that corrupt inter-channel phase coherence; compensation is required before beamforming
  - Quick check question: What is the typical range of SROs in consumer smartphones, and how does it affect audio processing?

- Concept: Spatial covariance matrix (SCM) and its rank-1 approximation
  - Why needed here: SCMs summarize the spatial characteristics of each speaker in a segment; rank-1 approximation simplifies clustering by assuming single-source dominance
  - Quick check question: Why is the ratio of largest to second largest eigenvalue used as an indicator of single-speaker dominance?

- Concept: Minimum variance distortionless response (MVDR) beamforming
  - Why needed here: MVDR uses spatial covariance information to steer the beam toward the target speaker while suppressing interference, critical for multi-microphone setups
  - Quick check question: How does the MVDR formulation differ when applied to distributed arrays versus a single array?

## Architecture Onboarding

- Component map: Data capture (9 devices, 29 channels) -> Preprocessing (high-pass filtering, downsampling, STO reduction) -> Synchronization (DWACD SRO estimation -> STFT-resampling) -> Separation (cACGMM mask estimation -> MVDR beamforming) -> Recognition (pretrained ASR)
- Critical path: Synchronization -> Mask estimation -> Beamforming -> ASR
- Design tradeoffs: Using multiple devices improves spatial diversity but increases computational load and synchronization complexity; rank-1 SCM approximation simplifies clustering but may fail in heavy overlap; STFT-resampling is computationally efficient but may introduce minor artifacts
- Failure signatures: High cpWER on overlapping conditions -> likely mask estimation errors; degraded performance when using all devices for both mask estimation and beamforming -> possible initialization divergence in cACGMM; sudden cpWER spikes in a few sessions -> possible SRO compensation inaccuracies or clustering errors
- First 3 experiments: 1) Run Sys-2 (single-array cACGMM + MVDR) on LibriWASN200 to verify baseline performance; 2) Compare Sys-3 vs Sys-4 to quantify benefits of spatial diversity vs. potential cACGMM divergence; 3) Test the effect of disabling SRO compensation on beamforming performance to confirm its necessity

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of multi-channel source separation and meeting transcription systems degrade when devices are not synchronized, and what is the optimal synchronization method to mitigate this degradation?
- Basis in paper: [explicit] The paper discusses the impact of sampling rate offsets (SROs) on the performance of meeting transcription systems and proposes a reference system that compensates for SROs using the dynamic weighted average coherence drift (DWACD) method
- Why unresolved: While the paper provides a reference system that compensates for SROs, it does not explicitly explore the performance degradation without synchronization or compare different synchronization methods to determine the optimal one
- What evidence would resolve it: Experimental results comparing the performance of meeting transcription systems with and without synchronization, and evaluating different synchronization methods, would provide insights into the impact of synchronization on system performance and help identify the optimal method

### Open Question 2
- Question: How does the spatial diversity of distributed recording devices affect the performance of mask-based beamforming in multi-channel source separation, and what is the optimal configuration of devices for achieving the best separation performance?
- Basis in paper: [explicit] The paper presents a reference system that utilizes mask-based beamforming for source separation and investigates the impact of using multiple devices for beamforming. It shows that using multiple devices can improve performance, especially in more reverberant environments
- Why unresolved: While the paper demonstrates the benefits of using multiple devices for beamforming, it does not explicitly explore the optimal configuration of devices or investigate the impact of spatial diversity on the performance of mask-based beamforming
- What evidence would resolve it: Experimental results comparing the performance of mask-based beamforming with different configurations of devices, including variations in their spatial distribution, would provide insights into the optimal configuration for achieving the best separation performance

### Open Question 3
- Question: How does the reverberation time of the recording environment affect the performance of multi-channel source separation and meeting transcription systems, and what techniques can be employed to improve performance in highly reverberant environments?
- Basis in paper: [explicit] The paper presents two subsets of the LibriWASN data set recorded in rooms with different reverberation times (T60 ≈ 200ms and T60 ≈ 800ms) and evaluates the performance of the reference system in these environments. It shows that the performance degrades in more reverberant environments
- Why unresolved: While the paper demonstrates the impact of reverberation on system performance, it does not explicitly explore techniques to improve performance in highly reverberant environments or investigate the optimal strategies for handling reverberation
- What evidence would resolve it: Experimental results evaluating the performance of multi-channel source separation and meeting transcription systems in highly reverberant environments, along with techniques to mitigate the effects of reverberation, would provide insights into improving performance in such environments

## Limitations

- Dataset scope limited to single table configuration with nine devices, not addressing diverse spatial arrangements
- SRO compensation assumes stable offsets over processing frames without quantifying maximum tolerable drift rate
- Rank-1 SCM approximation may fail in complex overlap scenarios, but performance degradation patterns are not thoroughly characterized

## Confidence

**High Confidence Claims**:
- The dataset construction methodology and its similarity to LibriCSS is well-documented and reproducible
- Multi-device beamforming consistently improves performance over single-device approaches, particularly in reverberant environments
- The cpWER metric appropriately captures the challenges of overlapping speech in meeting scenarios

**Medium Confidence Claims**:
- The specific SRO compensation procedure using DWACD is necessary for coherent beamforming, though the exact thresholds and parameter sensitivity are not fully explored
- The cACGMM initialization strategy based on SCM clustering is effective, but its robustness to varying overlap conditions requires further validation

**Low Confidence Claims**:
- The relative performance differences between systems (Sys-2 vs Sys-3 vs Sys-4) may depend heavily on the specific device placement and acoustic conditions, limiting generalization to other setups

## Next Checks

1. Systematically vary the SRO drift rate in simulated data to determine the maximum tolerable drift before beamforming performance degrades significantly

2. Test the cACGMM initialization with varying segment lengths and overlap conditions to identify the operational limits of the SCM clustering approach

3. Evaluate system performance across multiple device placement configurations beyond the single table setup to assess the robustness of multi-device benefits