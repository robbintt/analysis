---
ver: rpa2
title: 'Hexa: Self-Improving for Knowledge-Grounded Dialogue System'
arxiv_id: '2310.06404'
source_url: https://arxiv.org/abs/2310.06404
tags:
- hexa
- response
- knowledge
- dialogue
- responses
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Hexa introduces a self-improving method for knowledge-grounded
  dialogue systems that lack ground truth data for intermediate modules. It uses a
  bootstrapping scheme where the model generates intermediate steps (e.g., search
  queries, knowledge extraction) and responses, then iteratively refines them using
  a guided prompt that includes both ground truth and past unmatched responses.
---

# Hexa: Self-Improving for Knowledge-Grounded Dialogue System

## Quick Facts
- arXiv ID: 2310.06404
- Source URL: https://arxiv.org/abs/2310.06404
- Reference count: 38
- Primary result: Hexa achieves higher F1 and ROUGE-L scores than supervised learning and prior self-improving methods across multiple dialogue tasks

## Executive Summary
Hexa introduces a self-improving method for knowledge-grounded dialogue systems that lack ground truth data for intermediate modules. The approach uses a bootstrapping scheme where the model generates intermediate steps (e.g., search queries, knowledge extraction) and responses, then iteratively refines them using a guided prompt that includes both ground truth and past unmatched responses. Experiments across QA, knowledge-grounded, open-domain, and task-oriented dialogue tasks show Hexa consistently outperforms supervised learning and prior self-improving methods.

## Method Summary
Hexa employs a bootstrapping scheme with guided prompts and a modified loss function to enhance diversity in self-generated responses. The model generates intermediate steps and responses, collects self-generated samples based on a similarity threshold, and iteratively finetunes on the bootstrapped dataset. The guided prompt includes both ground truth and unmatched responses to prevent model collapse to ground truth copying.

## Key Results
- Hexa consistently outperforms supervised learning and prior self-improving methods (e.g., STaR)
- Achieves higher F1 and ROUGE-L scores on both seen and unseen datasets
- Human evaluation confirms improvements in fluency, relevance, and faithfulness
- Ablation studies validate the effectiveness of guided prompt and threshold selection

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Guided prompting with unmatched responses improves intermediate module generation by preventing collapse to ground truth copying
- Mechanism: Augments prompts with ground truth and previously unmatched responses in alphabetical list format, encouraging diverse intermediate steps faithful to dialogue context
- Core assumption: Alphabetical list format is interpreted as possible answers rather than a single target
- Evidence: Abstract mentions guided prompt for diversity; section describes adding unmatched responses to compose guided prompt
- Break condition: Guided prompt format becomes too long or unmatched responses consistently mislead model

### Mechanism 2
- Claim: Modified loss function with similarity-based matching improves learning signal quality for one-to-many dialogue responses
- Mechanism: Replaces exact matching with thresholded similarity function (ROUGE-L/BLEU), allowing learning from semantically similar but not identical responses
- Core assumption: Dialogue responses have inherent variability, exact matching is too strict
- Evidence: Abstract mentions modified loss function; section describes changing indicator function from dirac delta to similarity threshold
- Break condition: Threshold too low includes irrelevant responses; too high limits bootstrap samples

### Mechanism 3
- Claim: Iterative bootstrapping with increasing sample size progressively expands training set with diverse correct responses
- Mechanism: Starts with small bootstrap set, linearly increases samples each iteration, allowing discovery of new valid response patterns
- Core assumption: Model performance improves over iterations, enabling generation of more correct and diverse responses
- Evidence: Abstract mentions iterative training; section describes collecting samples and finetuning on bootstrapped dataset
- Break condition: Model converges too quickly or generates repetitive patterns

## Foundational Learning

- Concept: Modular dialogue systems with intermediate steps (search query, knowledge extraction, response generation)
  - Why needed here: Hexa explicitly generates and trains intermediate steps without ground truth data
  - Quick check: Can you trace data flow from dialogue context through search query generation to final response in Hexa architecture?

- Concept: Self-improving methods and bootstrapping in machine learning
  - Why needed here: Hexa uses bootstrapping scheme where model generates its own training data
  - Quick check: How does matching function in Hexa determine which self-generated responses are added to bootstrap set?

- Concept: Policy gradient methods and reinforcement learning in NLP
  - Why needed here: Loss function formulation resembles policy gradient with reward-based learning
  - Quick check: What is relationship between Hexa objective function and standard policy gradient formulations?

## Architecture Onboarding

- Component map: Dialogue context → Search query generation → Knowledge extraction → Response generation → Matching function → Bootstrapped data → Model finetuning
- Critical path: Dialogue context → Intermediate modules → Response generation → Matching function → Bootstrapped data → Model finetuning
- Design tradeoffs:
  - Guided prompt complexity vs. model performance
  - Threshold selection: quality vs. diversity tradeoff
  - Iteration count vs. overfitting risk
- Failure signatures:
  - Model collapse: All intermediate steps copy ground truth
  - Bootstrap stagnation: Few samples pass matching threshold
  - Overfitting: Performance improves on training but degrades on unseen tasks
- First 3 experiments:
  1. Run single iteration with very low threshold (0.1) to verify bootstrapping mechanism
  2. Test different guided prompt formats on small validation set
  3. Compare Hexa with and without ground truth in guided prompt

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does Hexa's effectiveness scale with model size, particularly comparing 3B models to LLMs like OPT-175B?
- Basis: Authors note uncertainty about generalization to LLMs, citing mixed evidence from OPT-175B performance
- Why unresolved: Authors leave investigation of Hexa's effectiveness on LLMs as future work
- Evidence needed: Direct comparison of Hexa on various LLM sizes measuring performance gains

### Open Question 2
- Question: What is optimal threshold selection strategy across diverse dialogue tasks, and can universal threshold outperform task-specific thresholds?
- Basis: Authors find task-specific thresholds outperform fixed thresholds but don't explore universal strategies
- Why unresolved: Study only tests limited fixed thresholds, doesn't investigate single universal threshold
- Evidence needed: Experiments comparing task-specific vs universal thresholds with cross-validation

### Open Question 3
- Question: How can Hexa be extended to handle multi-turn conversations with internal knowledge modules more effectively?
- Basis: Authors exclude memory-related modules from evaluation due to comparison impossibility across turns
- Why unresolved: Paper focuses on single-turn dialogue, doesn't address multi-turn functionality
- Evidence needed: Implementation and evaluation on multi-turn dialogue datasets measuring coherence improvements

## Limitations
- Architecture specificity: BB3 model details not fully specified, creating reproduction uncertainty
- Threshold sensitivity: Method effectiveness depends heavily on proper threshold selection without systematic sensitivity analysis
- Human evaluation limitations: Protocol, rater training, and agreement metrics not specified for subjective measurements

## Confidence
- High Confidence: Guided prompting with unmatched responses mechanism
- Medium Confidence: Modified loss function with similarity-based matching
- Medium Confidence: Overall experimental results

## Next Checks
1. Run Hexa with multiple similarity threshold values (0.2, 0.4, 0.6, 0.8) on single dataset to determine threshold sensitivity effects
2. Implement and test alternative guided prompt formats (bulleted, numbered lists) alongside alphabetical format
3. Implement complete ablation study: without ground truth in prompt, without modified loss function, without iterative bootstrapping