---
ver: rpa2
title: 'OpenGSL: A Comprehensive Benchmark for Graph Structure Learning'
arxiv_id: '2306.10280'
source_url: https://arxiv.org/abs/2306.10280
tags:
- structure
- methods
- graph
- uni000003ec
- learning
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents OpenGSL, the first comprehensive benchmark
  for Graph Structure Learning (GSL) methods. The authors evaluate twelve state-of-the-art
  GSL algorithms across ten diverse datasets, addressing issues of inconsistent experimental
  protocols in prior work.
---

# OpenGSL: A Comprehensive Benchmark for Graph Structure Learning

## Quick Facts
- arXiv ID: 2306.10280
- Source URL: https://arxiv.org/abs/2306.10280
- Reference count: 40
- Key outcome: First comprehensive benchmark for Graph Structure Learning methods, revealing that GSL methods don't consistently outperform vanilla GNNs

## Executive Summary
OpenGSL presents the first comprehensive benchmark for Graph Structure Learning (GSL) methods, evaluating twelve state-of-the-art algorithms across ten diverse datasets. The study addresses the lack of standardized evaluation protocols in GSL research by implementing consistent experimental settings across all methods. Through systematic experimentation, the authors reveal surprising findings that challenge common assumptions about the benefits of structure learning, while also highlighting computational efficiency challenges that limit practical deployment of these methods.

## Method Summary
The OpenGSL benchmark implements twelve GSL methods with consistent hyperparameters and data splits across all experiments. The evaluation framework includes three GNN backbones (GCN, GAT, GraphSAGE) to assess structure generalizability, with each experiment repeated five times using different random seeds. The benchmark measures classification accuracy, ROC AUC for binary tasks, and tracks computational time and memory usage on NVIDIA A800 GPUs. All datasets are sourced from PyTorch Geometric or specified repositories, with experiments following a standardized pipeline of data loading, model initialization, training, and evaluation.

## Key Results
- GSL methods do not consistently outperform vanilla GNNs across diverse datasets
- Learned graph structures demonstrate strong generalizability across different GNN backbones
- Weak correlation exists between learned structure homophily and task performance
- Most GSL methods require orders of magnitude more computational resources than vanilla GNNs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Graph Structure Learning (GSL) methods do not consistently outperform vanilla GNNs because the learned structures often do not improve homophily beyond the original graph.
- Mechanism: GSL methods attempt to optimize the graph structure by refining or learning new edges, with the implicit assumption that increasing homophily (the tendency of connected nodes to share labels) will improve downstream task performance. However, empirical results show that the homophily of learned structures is not significantly different from the original structure on homophilous datasets, and in some cases, even lower.
- Core assumption: Higher homophily in the graph structure leads to better performance in GNNs.
- Evidence anchors:
  - [abstract]: "empirical results show that GSL methods do not consistently outperform vanilla GNNs, challenging common assumptions about structure learning benefits"
  - [section]: "Contrary to the common belief in the homophily assumption, increasing the homophily of the structure does not necessarily translate into improved performance"
- Break condition: If the learned structures consistently showed higher homophily and improved performance, this mechanism would be invalidated.

### Mechanism 2
- Claim: Learned graph structures demonstrate strong generalizability across different GNN backbones.
- Mechanism: The graph structures learned by GSL methods can be used as inputs for different GNN models, often resulting in improved performance compared to using the original graph structure. This suggests that the learned structures capture generalizable patterns that are beneficial for various GNN architectures.
- Core assumption: The learned structures contain generalizable information that can benefit different GNN models.
- Evidence anchors:
  - [abstract]: "the learned graph structure demonstrates strong generalizability across different GNN backbones"
  - [section]: "the structures learned by GSL methods exhibit strong generalizability. The results in Table 4 and 5 demonstrate that many GNN backbones show improved performance on the learned structure"
- Break condition: If the learned structures only improved performance for specific GNN models or failed to generalize, this mechanism would be invalidated.

### Mechanism 3
- Claim: GSL methods are computationally expensive, often requiring significantly more resources than vanilla GNNs.
- Mechanism: GSL methods involve optimizing both the graph structure and the GNN model parameters simultaneously, which increases the computational complexity and memory requirements compared to vanilla GNNs that use a fixed graph structure.
- Core assumption: Joint optimization of graph structure and GNN parameters inherently requires more computational resources.
- Evidence anchors:
  - [abstract]: "high computational and space consumption"
  - [section]: "Most GSL methods are time- and memory-inefficient, some of which require orders of magnitudes more resources than vanilla GNNs"
- Break condition: If efficient GSL methods were developed that could match the performance of existing methods without the high computational cost, this mechanism would be invalidated.

## Foundational Learning

- Concept: Graph Neural Networks (GNNs) and their role in representation learning on graph-structured data.
  - Why needed here: Understanding GNNs is essential to grasp the motivation behind GSL and how it aims to improve upon them.
  - Quick check question: What is the primary function of GNNs in the context of graph-structured data?

- Concept: Homophily and heterophily in graphs.
  - Why needed here: These concepts are central to understanding the assumptions and limitations of GSL methods, particularly the belief that higher homophily leads to better performance.
  - Quick check question: How is homophily measured in a graph, and why is it assumed to be beneficial for GNNs?

- Concept: Graph Structure Learning (GSL) and its training strategies.
  - Why needed here: Understanding the different approaches to GSL (pre-training, co-training, iter-training) is crucial for evaluating their effectiveness and generalizability.
  - Quick check question: What are the three main training strategies for GSL methods, and how do they differ in their approach to optimizing graph structure and GNN parameters?

## Architecture Onboarding

- Component map: Data Module -> Method Module -> ExpManager Module -> Config Module
- Critical path:
  1. Load and preprocess dataset
  2. Initialize GNN or GSL model with specified hyperparameters
  3. Train model on dataset
  4. Evaluate model performance on test set
  5. Repeat for multiple independent runs and record results
- Design tradeoffs:
  - Accuracy vs. Efficiency: GSL methods often achieve higher accuracy but at the cost of increased computational resources and time
  - Homophily vs. Heterophily: Some GSL methods focus on increasing homophily, while others may benefit from preserving heterophilous patterns
- Failure signatures:
  - Out of memory errors on large datasets
  - Inconsistent performance across different datasets or GNN backbones
  - Lack of improvement over vanilla GNNs despite high computational cost
- First 3 experiments:
  1. Compare the performance of a GSL method with a vanilla GNN on a homophilous dataset
  2. Evaluate the generalizability of a learned structure by applying it to different GNN models
  3. Measure the computational efficiency of a GSL method compared to a vanilla GNN on a medium-sized dataset

## Open Questions the Paper Calls Out

- Question: Why do GSL methods show no consistent performance improvement over vanilla GNNs across diverse datasets?
- Basis in paper: [explicit] The paper states "empirical results reveal that GSL methods do not consistently outperform the vanilla GNNs."
- Why unresolved: The paper identifies this as a key finding but doesn't provide a definitive explanation for the lack of consistent improvement.
- What evidence would resolve it: Systematic ablation studies isolating different components of GSL methods, or theoretical analysis explaining when structure learning should help.

- Question: What structural properties beyond homophily should GSL methods optimize for?
- Basis in paper: [inferred] The paper questions "homophily is not a proper guidance for structure learning" and suggests exploring alternative properties.
- Why unresolved: While the paper identifies the inadequacy of homophily, it doesn't propose specific alternative structural properties to optimize.
- What evidence would resolve it: Empirical studies comparing GSL performance when optimizing different structural metrics (e.g., conductance, density, centrality measures).

- Question: How can GSL methods be made efficient enough for large-scale graphs?
- Basis in paper: [explicit] The paper highlights that "most GSL methods are time- and memory-inefficient" and consume "orders of magnitudes more resources than vanilla GNNs."
- Why unresolved: The paper identifies efficiency as a critical issue but doesn't propose specific solutions for scaling GSL to large graphs.
- What evidence would resolve it: Demonstration of GSL methods that maintain performance while reducing computational complexity from O(nÂ²) to O(n log n) or better.

## Limitations
- Benchmark focuses on specific dataset types and may not capture all real-world graph learning scenarios
- Computational efficiency measurements are limited to GPU-based experiments
- The study doesn't extensively explore alternative structural properties beyond homophily

## Confidence

- High confidence: The benchmark methodology and implementation are sound, and the observation that GSL methods don't consistently outperform vanilla GNNs is well-supported by empirical evidence.
- Medium confidence: The generalizability of learned structures across GNN backbones is demonstrated, but the extent of this generalizability may vary with different datasets and model architectures.
- Low confidence: The weak correlation between learned structure homophily and task performance challenges assumptions, but the reasons for this disconnect are not fully explored.

## Next Checks

1. Evaluate GSL methods on additional datasets, particularly those with known heterophily, to test the robustness of findings.
2. Investigate the impact of different structural assumptions (e.g., low-rank, sparsity) on the performance and generalizability of learned structures.
3. Conduct ablation studies to isolate the contributions of learned structures versus other components (e.g., GNN architecture, training procedures) to performance improvements.