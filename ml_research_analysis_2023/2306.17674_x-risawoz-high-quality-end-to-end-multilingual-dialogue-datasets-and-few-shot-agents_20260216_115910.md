---
ver: rpa2
title: 'X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot
  Agents'
arxiv_id: '2306.17674'
source_url: https://arxiv.org/abs/2306.17674
tags:
- dialogue
- language
- translation
- data
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work introduces X-RiSAWOZ, a high-quality, end-to-end multilingual
  task-oriented dialogue dataset created by translating the Chinese RiSAWOZ dataset
  into English, French, Hindi, Korean, and English-Hindi code-mixed languages. To
  reduce translation and post-editing costs, the authors develop a toolset that improves
  machine translation with hybrid entity alignment (combining neural and dictionary-based
  methods) and provides automated validation checks.
---

# X-RiSAWOZ: High-Quality End-to-End Multilingual Dialogue Datasets and Few-shot Agents

## Quick Facts
- arXiv ID: 2306.17674
- Source URL: https://arxiv.org/abs/2306.17674
- Authors: 
- Reference count: 22
- Primary result: Creation of X-RiSAWOZ, a multilingual task-oriented dialogue dataset with strong few-shot baselines

## Executive Summary
This work introduces X-RiSAWOZ, a high-quality multilingual task-oriented dialogue dataset created by translating the Chinese RiSAWOZ dataset into English, French, Hindi, Korean, and English-Hindi code-mixed languages. The authors develop a toolset that improves machine translation quality through hybrid entity alignment (combining neural and dictionary-based methods) and provides automated validation checks to reduce post-editing costs. They establish strong baselines for the dataset by training dialogue agents in zero- and few-shot settings, demonstrating effective cross-lingual transfer with limited target language data.

## Method Summary
The methodology involves translating the Chinese RiSAWOZ dataset to English, then to target languages (French, Hindi, Korean, English-Hindi), followed by manual post-editing for fluency and correctness. A hybrid entity alignment technique combines neural and dictionary-based methods to improve translation quality and consistency. Automated validation checks detect annotation errors. Dialogue agents are trained using mBART/m2m100 models in zero-shot (only translated data) and few-shot (translated + 100 manual target language dialogues) settings, with performance evaluated across DST, DA, and RG tasks.

## Key Results
- Dataset contains over 18,000 human-verified utterances per language across 12 domains
- Few-shot models achieve 60.7-84.6% accuracy for Dialogue State Tracking across languages
- Few-shot models achieve 38.0-70.5% accuracy for Dialogue Act Generation across languages
- Few-shot models achieve 28.5-46.4% BLEU score for Response Generation across languages

## Why This Works (Mechanism)

### Mechanism 1
Hybrid entity alignment combining neural and dictionary-based methods improves translation quality by ensuring entity consistency across utterances and annotations. The approach first attempts dictionary alignment using on-the-fly translation of individual entities, falling back to neural alignment if no match is found.

### Mechanism 2
Manual post-editing of automatically translated data is effective for creating high-quality multilingual dialogue datasets. Professional translators manually edit machine-translated dialogue utterances and annotations, ensuring fluency and correctness while maintaining semantic consistency.

### Mechanism 3
Zero-shot and few-shot learning techniques enable effective cross-lingual transfer for task-oriented dialogue agents. Models trained on source language data (with automatic translation) can be fine-tuned on small amounts of target language data to achieve reasonable performance.

## Foundational Learning

- **Task-oriented dialogue systems**: Understanding components and subtasks (DST, DA, RG) is crucial for implementing and evaluating X-RiSAWOZ. Quick check: Can you list the four subtasks that make up a task-oriented dialogue system?

- **Machine translation and alignment techniques**: Knowledge of translation methods and entity alignment is essential for understanding the data creation process and hybrid alignment approach. Quick check: What is the difference between dictionary alignment and neural alignment, and why is a hybrid approach proposed?

- **Zero-shot and few-shot learning**: Understanding these learning paradigms is crucial for interpreting experimental results and cross-lingual transfer effectiveness. Quick check: How do zero-shot and few-shot learning differ in terms of target language data used during training?

## Architecture Onboarding

- **Component map**: Chinese RiSAWOZ → English translation → Other language translation → Post-editing → Alignment → Model training
- **Critical path**: 1) Translate RiSAWOZ to English, 2) Translate English to target languages, 3) Post-edit translations, 4) Create entity alignments, 5) Train dialogue agents, 6) Evaluate performance
- **Design tradeoffs**: Translation quality vs. cost (open-source vs. commercial), post-editing effort vs. data quality (manual vs. automatic), zero-shot vs. few-shot (leveraging more data vs. target language supervision)
- **Failure signatures**: Low BLEU scores indicate translation/post-editing issues, high slot error rates suggest alignment problems, poor dialogue success rates imply cross-lingual transfer issues
- **First 3 experiments**: 1) Implement hybrid entity alignment and compare to pure neural alignment, 2) Train zero-shot dialogue agent and evaluate on validation set, 3) Fine-tune zero-shot model on few-shot data and compare to few-shot only baseline

## Open Questions the Paper Calls Out
The paper notes that the impact of few-shot data is greater when pretraining data quality is lower, related to translation model quality between Chinese and target language. However, it does not provide detailed analysis of how different translation quality levels affect few-shot performance across various languages.

## Limitations
- No quantitative comparison between hybrid entity alignment and pure neural or dictionary alignment methods
- Limited evaluation of post-editing quality - no assessment of improvement over raw machine translation
- Only 100 dialogues per language used for few-shot training, potentially insufficient for robust results

## Confidence

**High Confidence** (Strong empirical support):
- Translation and post-editing pipeline successfully creates multilingual datasets with consistent annotations
- Zero-shot and few-shot learning approach demonstrates reasonable performance across multiple languages
- Dataset creation methodology is reproducible given access to RiSAWOZ

**Medium Confidence** (Moderate empirical support):
- Hybrid entity alignment approach improves translation quality (no direct quantitative comparison)
- Post-editing process effectively improves translation quality (no quantitative evaluation)
- Few-shot learning results are competitive with other approaches (no comparison to non-transfer baselines)

**Low Confidence** (Weak empirical support):
- Specific improvements of hybrid alignment over other methods (no ablation studies)
- Optimal amount of few-shot data needed (only one data size tested)
- Generalizability to other language pairs or dialogue domains (only tested on specific languages and domains)

## Next Checks

1. Implement controlled comparison of alignment methods: Create experiment comparing pure neural alignment, pure dictionary alignment, and hybrid approach on 50-100 utterances. Measure entity consistency, translation quality (BLEU), and annotation preservation.

2. Ablation study of post-editing: Train dialogue agents using three data variants (raw machine translation, machine translation with post-editing, professional human translation for small subset). Compare performance on DST, DA, and RG tasks.

3. Few-shot data sensitivity analysis: Repeat few-shot experiments with varying amounts of training data (25, 50, 100, 200 dialogues) to understand learning curve and determine minimum effective training data size.