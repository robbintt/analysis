---
ver: rpa2
title: How Much Consistency Is Your Accuracy Worth?
arxiv_id: '2310.13781'
source_url: https://arxiv.org/abs/2310.13781
tags:
- consistency
- accuracy
- relative
- bundles
- instances
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces relative consistency as a complementary metric
  to standard consistency in evaluating NLP models on contrast sets. Relative consistency
  measures the probability that an equally accurate model would surpass the consistency
  of a given model, given the distribution of possible consistencies for that accuracy.
---

# How Much Consistency Is Your Accuracy Worth?

## Quick Facts
- arXiv ID: 2310.13781
- Source URL: https://arxiv.org/abs/2310.13781
- Authors: 
- Reference count: 15
- One-line primary result: Introduces relative consistency as a metric that measures the probability an equally accurate model would surpass a given model's consistency on contrast sets.

## Executive Summary
This paper introduces relative consistency as a complementary metric to standard consistency for evaluating NLP models on contrast sets. Relative consistency measures the probability that an equally accurate model would achieve higher consistency than the given model, providing a probabilistic interpretation of a model's consistency performance. The authors demonstrate through simulations and meta-analysis that relative consistency can reveal insights about a model's tendency to produce consistent responses that are not apparent from standard consistency alone, particularly when comparing models with different accuracy levels.

## Method Summary
The method computes relative consistency by first determining the distribution of achievable consistencies for a given accuracy using combinatorial formulas that count the number of ways to achieve specific accuracy and consistency combinations. This distribution is then used to calculate the cumulative probability that an equally accurate model would achieve higher consistency than the observed model. The approach is specifically designed for contrast sets with binary bundles (pairs of minimally different examples), though the authors note the formulas can be extended to larger bundle sizes.

## Key Results
- Relative consistency provides a probabilistic interpretation of model consistency that reveals whether a model has reached its consistency ceiling given its accuracy
- Models with similar standard consistency scores can have different relative consistencies, indicating different tendencies to respond consistently
- The metric can guide model improvement strategies by identifying whether consistency or accuracy should be prioritized

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Relative consistency identifies whether a model has achieved its consistency ceiling given its accuracy.
- Mechanism: By computing the cumulative probability that an equally accurate model would outperform the observed consistency, relative consistency distinguishes between models that are "consistency-optimal" (RC=100%) and those that are below chance (RC<50%).
- Core assumption: The distribution of achievable consistencies for a given accuracy follows the combinatorial model defined in the paper (Eq. 5-7).
- Evidence anchors:
  - [abstract]: "Models with 100% relative consistency have reached a consistency peak for their accuracy."
  - [section 2.3]: "RC(c, a) indicates how likely the model's consistency is to outperform an equally accurate model relative to the distribution of achievable consistencies defined in (5)."
  - [corpus]: Weak evidence - the corpus neighbors discuss related consistency and accuracy concepts but don't directly address the probabilistic formulation.
- Break condition: If the underlying distribution of consistencies for a given accuracy deviates significantly from the combinatorial model (e.g., due to varying instance difficulty or model biases), the relative consistency scores become unreliable.

### Mechanism 2
- Claim: Relative consistency enables nuanced comparison between models with different accuracy levels.
- Mechanism: By contextualizing consistency within the distribution of achievable consistencies for a given accuracy, relative consistency reveals insights about a model's tendency to produce consistent responses that standard consistency alone cannot capture.
- Core assumption: The probabilistic interpretation of relative consistency provides meaningful information about model behavior beyond simple consistency scores.
- Evidence anchors:
  - [section 3]: "This insight, that one model is below chance consistency, while another is well above, is made possible by the probabilistic interpretation of RC."
  - [section 4.1]: Analysis of UD parsing vs. ROPES models with similar consistency but different relative consistencies.
  - [corpus]: Weak evidence - the corpus contains related work on consistency measurement but doesn't specifically address relative consistency as a comparative metric.
- Break condition: If practitioners don't understand or utilize the probabilistic interpretation, they may misinterpret relative consistency scores and draw incorrect conclusions.

### Mechanism 3
- Claim: Relative consistency guides effective model improvement strategies.
- Mechanism: By identifying whether a model is below, at, or above chance consistency for its accuracy, relative consistency indicates whether improving consistency is a viable optimization target or if accuracy improvement should be prioritized.
- Core assumption: The relationship between accuracy and achievable consistency follows predictable patterns that can guide training decisions.
- Evidence anchors:
  - [section 4.2]: "Combining contrastive estimation (CE; Smith and Eisner, 2005), or unlikelihood training (UL; Welleck et al., 2020), with MLE not only improves the accuracy and consistency but also does so in a way that does not lower the relative consistency, which is desired."
  - [section 4.3]: Analysis showing that hyperparameter choices affect model consistency behavior as revealed by relative consistency.
  - [corpus]: Weak evidence - the corpus contains related work on model improvement but doesn't specifically address the role of relative consistency in guiding these decisions.
- Break condition: If the relationship between accuracy and achievable consistency is non-monotonic or highly irregular, relative consistency may not provide reliable guidance for improvement strategies.

## Foundational Learning

- Concept: Probability distributions and cumulative distribution functions
  - Why needed here: Relative consistency is fundamentally a probabilistic measure that requires understanding how to compute and interpret cumulative probability distributions.
  - Quick check question: Given a discrete probability distribution P(c|a) for consistency c at accuracy a, how would you compute the probability that a model achieves consistency less than or equal to a specific value?

- Concept: Combinatorial mathematics and counting principles
  - Why needed here: The distribution of achievable consistencies is derived using combinatorial formulas that count the number of ways to achieve specific accuracy and consistency combinations.
  - Quick check question: For a dataset with n bundles of 2 instances each, how many ways can a model achieve accuracy a=3 and consistency c=1?

- Concept: Contrast sets and bundle-based evaluation
  - Why needed here: Relative consistency is specifically designed to evaluate model behavior on contrast sets, which require understanding the structure and purpose of these evaluation methodologies.
  - Quick check question: What distinguishes a contrast set from a standard test set, and why is this distinction important for measuring consistency?

## Architecture Onboarding

- Component map: Data preparation -> Accuracy/consistency calculation -> Distribution computation -> Relative consistency calculation -> Visualization
- Critical path: For a given model evaluation, the critical path is: compute observed accuracy and consistency → compute distribution of achievable consistencies → calculate relative consistency → interpret results in context.
- Design tradeoffs: The current implementation assumes uniform instance difficulty and ignores model/dataset-specific biases. A more sophisticated version could incorporate instance difficulty weights or learn the distribution empirically from data.
- Failure signatures: Common failure modes include numerical instability when computing large combinatorial values, misinterpretation of relative consistency scores without understanding their probabilistic meaning, and incorrect application to non-contrast set evaluation scenarios.
- First 3 experiments:
  1. Verify the relative consistency calculation on a simple synthetic dataset with known ground truth distributions.
  2. Compare relative consistency scores across different models on a standard contrast set benchmark to validate that the metric provides meaningful differentiation.
  3. Test the sensitivity of relative consistency to variations in instance difficulty by introducing controlled noise into the evaluation dataset.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the distribution of achievable consistencies change for contrast sets with bundle sizes larger than 2?
- Basis in paper: [explicit] The paper mentions that formulas can be extended for bundle sizes above 2 but notes that these distributions are less intuitive, more expensive to compute, and may have drawbacks for bundle sizes above 2.
- Why unresolved: The paper provides formulas for bundle sizes greater than 2 but does not provide empirical evidence or examples to show how the distribution changes and what impact this has on relative consistency scores.
- What evidence would resolve it: Empirical studies comparing relative consistency scores for contrast sets with different bundle sizes, especially for sizes larger than 2, would provide evidence on how the distribution changes and its impact on relative consistency.

### Open Question 2
- Question: How does the assumption of equal instance difficulty affect the accuracy of relative consistency as a metric?
- Basis in paper: [explicit] The paper states that the formulation assumes all instances are equally difficult, which is known not to be the case in practice.
- Why unresolved: The paper acknowledges this limitation but does not provide empirical evidence or methods to account for varying instance difficulty in the calculation of relative consistency.
- What evidence would resolve it: Studies that modify the relative consistency formula to account for varying instance difficulty and compare the results with the original formula would provide evidence on the impact of this assumption.

### Open Question 3
- Question: How do inductive biases of models and datasets skew the distribution of achievable consistencies?
- Basis in paper: [explicit] The paper mentions that it disregards any inductive biases of models/datasets that could skew the distribution.
- Why unresolved: The paper does not provide empirical evidence or methods to quantify the impact of inductive biases on the distribution of achievable consistencies.
- What evidence would resolve it: Studies that analyze the impact of different model architectures and dataset characteristics on the distribution of achievable consistencies would provide evidence on how inductive biases affect relative consistency scores.

## Limitations

- The method assumes uniform instance difficulty across all examples, which is known not to be the case in practice
- The current formulation is limited to contrast sets with binary bundles, with extension to larger bundle sizes being less intuitive and computationally expensive
- The approach disregards potential inductive biases from models and datasets that could skew the distribution of achievable consistencies

## Confidence

- High confidence: The mathematical formulation of relative consistency and its relationship to standard consistency measures is sound and well-defined.
- Medium confidence: The claim that relative consistency provides additional insights beyond standard consistency is supported by simulations and meta-analysis, but real-world validation across diverse NLP tasks is limited.
- Medium confidence: The assertion that relative consistency can guide effective model improvement strategies is supported by specific examples but requires broader empirical validation.

## Next Checks

1. **Distribution validation**: Test whether the combinatorial model accurately predicts the distribution of achievable consistencies across diverse NLP tasks and model architectures by comparing theoretical predictions with empirical observations.
2. **Interpretability study**: Conduct a user study with NLP practitioners to assess whether they can correctly interpret and apply relative consistency scores in model selection and improvement decisions.
3. **Cross-domain applicability**: Evaluate the effectiveness of relative consistency as a metric for consistency evaluation in non-NLP domains (e.g., computer vision) to test the generalizability of the approach.