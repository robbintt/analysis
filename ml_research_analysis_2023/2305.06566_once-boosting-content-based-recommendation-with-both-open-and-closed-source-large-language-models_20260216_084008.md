---
ver: rpa2
title: 'ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source
  Large Language Models'
arxiv_id: '2305.06566'
source_url: https://arxiv.org/abs/2305.06566
tags:
- news
- user
- recommendation
- data
- personalized
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a framework called GENRE that leverages large
  language models (LLMs) to enhance content-based news recommendation. The framework
  utilizes both open-source and closed-source LLMs to generate synthetic news articles
  and enrich user profiles.
---

# ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models

## Quick Facts
- arXiv ID: 2305.06566
- Source URL: https://arxiv.org/abs/2305.06566
- Reference count: 40
- Primary result: Up to 19.32% relative improvement in recommendation performance using LLM-generated data

## Executive Summary
ONCE (Open and Closed-source Large Language Models Enhanced Recommendation) is a framework that leverages large language models (LLMs) to enhance content-based news recommendation systems. The framework uses both open-source and closed-source LLMs to generate synthetic news articles, enhance news titles, and enrich user profiles. By augmenting training data with LLM-generated content, ONCE addresses challenges like cold-start problems and limited user interaction data, achieving significant improvements over state-of-the-art recommendation models.

## Method Summary
The framework integrates LLM capabilities into traditional news recommendation pipelines by generating enhanced content at multiple levels. ChatGPT is used to rephrase sparse news titles into richer semantic content, generate user profiles from browsing histories, and create personalized news articles for cold-start users. These augmented data points are incorporated into the news encoder, user encoder, and interaction module respectively. The approach combines both open-source and closed-source LLM strategies, with closed-source models like ChatGPT used for data generation and open-source models for content encoding, creating a hybrid system that leverages the strengths of both approaches.

## Key Results
- Up to 19.32% relative improvement in recommendation performance compared to state-of-the-art models
- Enhanced news titles improve semantic understanding in news encoders
- LLM-generated user profiles provide explicit interest features for better user modeling
- Personalized news generation effectively addresses cold-start problems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLM-generated news titles improve news encoder performance by providing richer semantic content
- Mechanism: ChatGPT rephrases original news titles into more informative, complete versions that capture deeper semantics
- Core assumption: Original news titles are too sparse for effective semantic extraction
- Evidence anchors: Abstract mentions using LLM deep layers as content encoders; section describes producing more informative titles that highlight main topics
- Break condition: Enhanced titles introduce noise or misrepresent original content

### Mechanism 2
- Claim: LLM-generated user profiles improve recommendation performance by providing explicit user interest features
- Mechanism: ChatGPT analyzes browsing history to generate profiles containing interested topics and regions
- Core assumption: Anonymized datasets lack explicit user profile information due to privacy concerns
- Evidence anchors: Abstract mentions enriching training data at token level; section describes producing user profiles with interested topics and regions
- Break condition: Generated profiles are inaccurate or don't reflect true user interests

### Mechanism 3
- Claim: LLM-generated personalized news articles alleviate cold-start problems by enriching new users' interaction data
- Mechanism: ChatGPT generates synthetic news articles aligned with new users' potential interests based on limited browsing history
- Core assumption: New users have insufficient interaction data for effective user encoder learning
- Evidence anchors: Abstract mentions 19.32% improvement over state-of-the-art models; section describes modeling distribution of user-interested news with limited historical data
- Break condition: Generated news articles don't align with actual user interests

## Foundational Learning

- Concept: News recommendation models
  - Why needed here: Understanding the three-component architecture (news encoder, user encoder, interaction module) is crucial for grasping how GENRE enhances these models
  - Quick check question: What are the three main components of a typical news recommendation model, and how do they interact?

- Concept: Large language models (LLMs)
  - Why needed here: GENRE leverages LLM capabilities for tasks like news summarization, user profiling, and personalized news generation
  - Quick check question: What are the key capabilities of LLMs that make them suitable for tasks like news summarization, user profiling, and personalized news generation?

- Concept: Data augmentation
  - Why needed here: GENRE uses LLMs to augment training data by generating enhanced news titles, user profiles, and personalized news articles
  - Quick check question: How does data augmentation help improve the performance of machine learning models, particularly in recommendation systems?

## Architecture Onboarding

- Component map: News encoder (multimodal features) -> User encoder (browsing history) -> Interaction module (click-through probability) -> LLM integration (enhanced data generation)
- Critical path: 1) Collect original news and user data 2) Generate enhanced data using ChatGPT 3) Incorporate into recommendation model 4) Train with augmented data 5) Evaluate on test set
- Design tradeoffs: Additional computational cost and API expenses vs. performance gains; quality vs. quantity of generated data; potential privacy concerns
- Failure signatures: Decreased performance from low-quality generated data; increased computational costs; privacy issues from sensitive information leakage
- First 3 experiments: 1) Compare models with original vs. enhanced news titles 2) Measure improvement from incorporating generated user profiles 3) Analyze cold-start performance with vs. without personalized news articles

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the long-term effects of using LLM-generated content on user engagement and satisfaction in news recommendation systems?
- Basis in paper: The paper discusses using LLMs to generate synthetic news content and enhance user profiles but doesn't address potential long-term impacts on engagement and satisfaction
- Why unresolved: Focus on immediate performance improvements rather than sustainability or potential drawbacks over extended periods
- What evidence would resolve it: Long-term user studies measuring engagement metrics and satisfaction surveys comparing LLM-generated vs. traditional content exposure

### Open Question 2
- Question: How does the cost-effectiveness of using LLMs for news recommendation scale with increasing dataset sizes and user bases?
- Basis in paper: The paper mentions ChatGPT API costs but doesn't explore scalability with larger datasets or user bases
- Why unresolved: Initial cost estimates provided without analysis of scalability or comparison to benefits in larger-scale applications
- What evidence would resolve it: Detailed cost-benefit analysis comparing LLM costs to performance improvements across various dataset sizes and user bases

### Open Question 3
- Question: What are the ethical implications of using LLM-generated content in news recommendation systems, particularly regarding misinformation and bias?
- Basis in paper: The paper doesn't discuss ethical considerations of using LLM-generated content that could introduce or amplify biases and misinformation
- Why unresolved: Technical performance focus leaves ethical implications unexplored
- What evidence would resolve it: Analysis of LLM-generated content for potential biases, misinformation, or ethical concerns with mitigation guidelines

## Limitations
- Relies heavily on ChatGPT APIs, introducing cost and availability constraints that may limit real-world deployment
- Quality of generated data depends entirely on prompt engineering, with limited detailed prompt formulations provided
- Absolute performance gains not discussed in detail, making practical significance difficult to assess
- Study focuses exclusively on news recommendation, unclear whether approaches transfer to other domains

## Confidence

- High Confidence: Core mechanism of using LLMs for data augmentation in recommendation systems is well-supported by experimental results and aligns with established machine learning principles
- Medium Confidence: Specific claim that ChatGPT-generated enhanced news titles improve news encoder performance has strong theoretical grounding but limited direct empirical validation
- Medium Confidence: Effectiveness of LLM-generated user profiles for improving recommendations is demonstrated but lacks extensive analysis of profile accuracy or privacy implications
- Medium Confidence: Cold-start problem alleviation through personalized news generation shows promising results but focuses on relative rather than absolute performance metrics

## Next Checks
1. **Prompt Quality Analysis**: Conduct ablation studies to evaluate how different prompt formulations affect generated data quality, including automated evaluation metrics for content coherence and relevance
2. **Cost-Benefit Analysis**: Measure computational and API cost overhead against performance improvements, analyzing token usage patterns and cost per user
3. **Domain Transferability Study**: Test GENRE framework on different recommendation domains (product recommendations, music streaming) to assess generalizability beyond news recommendation contexts