---
ver: rpa2
title: Faithful Path Language Modeling for Explainable Recommendation over Knowledge
  Graph
arxiv_id: '2310.16452'
source_url: https://arxiv.org/abs/2310.16452
tags:
- paths
- knowledge
- path
- recommendation
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: PEARLM is a novel explainable recommendation method that leverages
  language modelling over knowledge graphs. It addresses limitations of existing approaches
  by learning token embeddings directly from sampled KG paths, unifying entity and
  relation prediction in a single optimisation space, and incorporating graph constraints
  to ensure faithful path generation.
---

# Faithful Path Language Modeling for Explainable Recommendation over Knowledge Graph

## Quick Facts
- arXiv ID: 2310.16452
- Source URL: https://arxiv.org/abs/2310.16452
- Reference count: 40
- Key outcome: PEARLM achieves NDCG of 0.44 vs 0.31 for KGAT on MovieLens, with improved coverage, novelty, and guaranteed path faithfulness.

## Executive Summary
PEARLM introduces a novel explainable recommendation method that leverages language modeling over knowledge graphs to address limitations in existing approaches. By learning token embeddings directly from sampled KG paths and unifying entity and relation prediction in a single optimization space, PEARLM eliminates reliance on pre-trained KG embeddings while ensuring all generated paths are valid with respect to the underlying graph. The method significantly outperforms state-of-the-art baselines on two datasets (MovieLens and LastFM), achieving substantial improvements in recommendation utility (e.g., NDCG of 0.44 vs 0.31 for KGAT on MovieLens) and beyond-accuracy metrics such as coverage and novelty, while guaranteeing faithful explanations.

## Method Summary
PEARLM uses a causal language model trained on user-centric paths sampled from a knowledge graph via random walk. The model learns token embeddings directly from these paths, unifying entities and relations in the same optimization space. During generation, graph constraint decoding ensures path faithfulness by only allowing tokens reachable according to the KG. The system generates top-k recommendations with explanations by ranking candidate paths. PEARLM operates on datasets like MovieLens1M and LastFM1M, where it samples 3-hop and 5-hop paths, learns from them using a distilgpt2 or gpt2 architecture, and evaluates using metrics including NDCG, MMR, Precision, Recall, Coverage, Serendipity, Diversity, and Novelty.

## Key Results
- PEARLM achieves NDCG of 0.44 on MovieLens compared to 0.31 for KGAT
- Substantial improvements in beyond-accuracy metrics: coverage and novelty
- All generated paths are guaranteed to be valid with respect to the underlying knowledge graph

## Why This Works (Mechanism)

### Mechanism 1
- Claim: PEARLM learns token embeddings directly from sampled KG paths, eliminating reliance on pre-trained KG embeddings.
- Mechanism: By sampling paths from the KG and using them as training sequences, PEARLM dynamically constructs embeddings that reflect richer context and interdependencies between entities and relations.
- Core assumption: There are enough sampled paths to capture the semantic relationships needed for effective recommendation.
- Evidence anchors:
  - [abstract]: "With our approach, knowledge graph embeddings are directly learned from paths over the KG by the language model, which also unifies entities and relations in the same optimisation space."
  - [section 3.1]: "We employ a standard random walk algorithm fixing each time the desired maximum number of hops set to N âˆˆ { 3, 5}."
- Break condition: If the KG is too sparse, sampled paths may not cover sufficient semantic variations, leading to poor embeddings.

### Mechanism 2
- Claim: Unifying entity and relation prediction in a single optimization space improves recommendation quality.
- Mechanism: Instead of using separate heads for entities and relations, PEARLM uses a single causal language model that conditions next token prediction on all previous tokens, capturing interdependencies.
- Core assumption: Interleaving entities and relations in the same optimization space allows the model to better capture contextual nuances.
- Evidence anchors:
  - [abstract]: "Secondly, token prediction relies on a single head (instead of two) as part of the language model, unifying entities and relations in the same optimisation space."
  - [section 4.2]: "PEARLM, and similar Causal Language Models (CLM), depart from this breadth-oriented approach... Their strategy can be likened to a Depth-First Search (DFS)."
- Break condition: If the model architecture cannot effectively learn from the unified space, it may underperform compared to specialized heads.

### Mechanism 3
- Claim: Graph Constraint Decoding ensures all generated paths are faithful to the KG, preventing hallucination.
- Mechanism: During decoding, PEARLM only allows tokens that are reachable according to the KG, setting probabilities of invalid tokens to negative infinity.
- Core assumption: The KG contains sufficient connectivity information to guide valid path generation.
- Evidence anchors:
  - [abstract]: "Constraints on the sequence decoding additionally guarantee path faithfulness with respect to the KG."
  - [section 3.2]: "If the next token ð‘¡ð‘˜ is not reachable from the previous tokens, its probability is set to negative infinity, effectively preventing the model from generating such a token."
- Break condition: If the KG is incomplete or noisy, the model may be overly constrained and unable to generate diverse or useful paths.

## Foundational Learning

- Concept: Autoregressive path generation via causal language modeling
  - Why needed here: It allows the model to generate coherent sequences of entities and relations that correspond to valid paths in the KG.
  - Quick check question: How does the model ensure that the generated sequences alternate between entities and relations?

- Concept: Knowledge Graph embeddings and their limitations
  - Why needed here: Understanding why pre-trained KG embeddings are insufficient motivates the design of PEARLM's direct learning approach.
  - Quick check question: What are the key differences between KGE methods and PEARLM's path-based learning?

- Concept: Graph constraint decoding and its role in faithfulness
  - Why needed here: Ensures that the explanations provided by the system are verifiable against the underlying KG.
  - Quick check question: How does the graph constraint decoding mechanism prevent the generation of invalid paths?

## Architecture Onboarding

- Component map: Path sampling module -> Tokenizer -> Embedding layer -> Causal language model -> Graph constraint decoder -> Ranking module
- Critical path:
  1. Sample paths from KG using random walk
  2. Tokenize and embed paths
  3. Train causal language model on paths
  4. Generate candidate paths using graph constraint decoding
  5. Rank and select top-k paths for output
- Design tradeoffs:
  - Path length vs. interpretability: Longer paths capture more context but may be harder to explain
  - Sample size vs. coverage: More sampled paths improve coverage but increase computational cost
  - Model size vs. scalability: Larger models may perform better but require more resources
- Failure signatures:
  - Low path coverage: Indicates insufficient path sampling or a sparse KG
  - High hallucination rate: Suggests graph constraint decoding is not working properly
  - Poor recommendation utility: May indicate suboptimal embeddings or model architecture
- First 3 experiments:
  1. Verify path sampling: Check that sampled paths cover all products and user interactions adequately
  2. Validate graph constraint decoding: Ensure that generated paths are valid according to the KG
  3. Benchmark recommendation utility: Compare PEARLM's performance against baseline models on NDCG and other metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the precise scaling laws for PEARLM performance as model size and training data increase?
- Basis in paper: [explicit] The paper states this is beyond the scope of the current work and will be investigated in future work.
- Why unresolved: The paper only provides preliminary evidence that larger models and sample sizes slightly elevate NDCG, but does not systematically explore the relationship between model capacity, dataset size, and performance.
- What evidence would resolve it: Comprehensive experiments varying model size (e.g., distilgpt2, gpt2, gpt2-large, LLMs) and training data size, while keeping other factors constant, to empirically determine the scaling laws.

### Open Question 2
- Question: How does the quality and completeness of the knowledge graph affect PEARLM's recommendation performance and explainability?
- Basis in paper: [explicit] The paper mentions that PEARLM's approach introduces a dependency on the completeness and accuracy of the knowledge graph, and highlights the criticality of possessing robust and comprehensive graph data.
- Why unresolved: The paper does not investigate the impact of knowledge graph quality on PEARLM's performance or explore methods to improve graph data.
- What evidence would resolve it: Experiments systematically degrading the knowledge graph (e.g., removing edges, adding noise) and measuring the impact on PEARLM's recommendation quality and explanation faithfulness.

### Open Question 3
- Question: Can PEARLM's path generation be integrated with template creation to generate a broader palette of explanations catering to diverse stakeholder preferences?
- Basis in paper: [explicit] The paper envisions an integration of path generation with template creation to curate a broader palette of explanations.
- Why unresolved: The paper does not provide any implementation or evaluation of this integration.
- What evidence would resolve it: A system that generates explanations using both PEARLM-generated paths and various templates, with user studies to assess the quality and preference of different explanation styles.

## Limitations
- The paper relies on random walk sampling which may be insufficient for capturing semantic relationships in sparse knowledge graphs
- Hyperparameter details (learning rate, batch size, iterations) are not specified, making reproduction difficult
- Limited evaluation on only two datasets (MovieLens1M and LastFM1M) reduces generalizability

## Confidence

- **High Confidence**: The problem of explainable recommendation over knowledge graphs and need for faithful path generation is clearly articulated, with well-founded overall framework
- **Medium Confidence**: The approach of learning token embeddings from sampled paths and unifying entity/relation prediction is innovative, though implementation details are lacking
- **Low Confidence**: Significant performance improvements are claimed but without detailed ablation studies or validation on diverse datasets

## Next Checks
1. Verify path sampling coverage by analyzing sampled paths against total KG entities and relations
2. Implement and test graph constraint decoding to ensure generated paths are valid according to the KG
3. Evaluate PEARLM on additional datasets beyond MovieLens1M and LastFM1M to assess generalizability