---
ver: rpa2
title: On the Aggregation of Rules for Knowledge Graph Completion
arxiv_id: '2309.00306'
source_url: https://arxiv.org/abs/2309.00306
tags:
- rules
- rule
- aggregation
- knowledge
- which
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work formalizes the rule aggregation problem for knowledge
  graph completion, showing that existing aggregation strategies like Max and Noisy-or
  can be derived from probabilistic models over rule truth values. We demonstrate
  that Max-aggregation corresponds to assuming maximal correlation between rules,
  while Noisy-or assumes mutual independence.
---

# On the Aggregation of Rules for Knowledge Graph Completion

## Quick Facts
- **arXiv ID**: 2309.00306
- **Source URL**: https://arxiv.org/abs/2309.00306
- **Reference count**: 40
- **Key outcome**: Noisy-or top-h achieves competitive performance with significantly lower runtime compared to more complex approaches like SAFRAN and supervised aggregators.

## Executive Summary
This work formalizes the rule aggregation problem for knowledge graph completion by showing that existing aggregation strategies like Max and Noisy-or can be derived from probabilistic models over rule truth values. The paper demonstrates that Max-aggregation corresponds to assuming maximal correlation between rules, while Noisy-or assumes mutual independence. Based on these insights, the authors propose Noisy-or top-h, an efficient baseline that combines aspects of both strategies by applying the Noisy-or product only to the top h predicting rules per candidate. Experiments on four standard datasets show that Noisy-or top-h achieves competitive performance with significantly lower runtime compared to more complex approaches.

## Method Summary
The method involves mining rules from knowledge graphs using AnyBURL and AMIE3, then applying these rules to predict missing facts. The key innovation is the Noisy-or top-h aggregation strategy, which computes the probability that at least one of the top h rules (by confidence) is true. This is formalized through probabilistic inference over a joint distribution of rule truth values, with the top-h selection interpolating between Max-aggregation (h=1) and full Noisy-or (h=k). The approach is evaluated on standard KGs (FB15k-237, WNRR, Codex-M, Yago3-10) using filtered MRR and Hits@X metrics.

## Key Results
- Noisy-or top-h achieves competitive performance with significantly lower runtime compared to more complex approaches like SAFRAN and supervised aggregators
- Max-aggregation and Noisy-or can be recovered as special cases of probabilistic inference under specific correlation assumptions
- The probabilistic framework provides theoretical justification for existing aggregation strategies and enables the development of new baselines

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Max-aggregation can be derived as a probabilistic inference strategy under maximal correlation between rules.
- **Mechanism**: The paper shows that when the correlation matrix between rule truth values is set to the Fréchet-Hoeffding upper bound, the marginal inference over the joint distribution yields exactly the Max-aggregation score.
- **Core assumption**: The joint distribution over rules exists and is unique, and rule marginals are approximated by rule confidences.
- **Evidence anchors**:
  - [abstract]: "We demonstrate that existing aggregation approaches can be expressed as marginal inference operations over the predicting rules... the common Max-aggregation strategy, which scores candidates based on the rule with the highest confidence, has a probabilistic interpretation."
  - [section]: Theorem 4.5 shows the derivation using the upper Fréchet-Hoeffding bound for correlation.
  - [corpus]: Weak. Only 1/5 related papers mention rule aggregation directly; the rest focus on probabilistic circuits or subgraph-informed learning.
- **Break condition**: If rule marginals are not well-approximated by confidences, or if the joint distribution is not unique, the Max-aggregation recovery fails.

### Mechanism 2
- **Claim**: Noisy-or aggregation corresponds to assuming mutual independence between rules.
- **Mechanism**: Under mutual independence of rules, the probability that at least one rule is true (i.e., the query probability) simplifies to the Noisy-or product over rule confidences.
- **Core assumption**: All rules predicting a candidate are mutually independent.
- **Evidence anchors**:
  - [abstract]: "Noisy-or assumes mutual independence."
  - [section]: Proposition 4.7 proves that mutual independence leads to Noisy-or aggregation.
  - [corpus]: Weak. None of the related papers explicitly discuss the independence assumption in Noisy-or aggregation.
- **Break condition**: When rules are correlated (common in learned rule sets), Noisy-or will underestimate the true probability.

### Mechanism 3
- **Claim**: Noisy-or top-h aggregation combines both maximal correlation and independence assumptions, providing a practical middle ground.
- **Mechanism**: By applying Noisy-or only to the top h rules by confidence, the method interpolates between Max (h=1) and full Noisy-or (h=k), adapting to the degree of redundancy in the rule set.
- **Core assumption**: The most confident rules dominate the prediction, and less confident rules add diminishing returns.
- **Evidence anchors**:
  - [abstract]: "We propose an efficient baseline called Noisy-or top-h, which combines aspects of both strategies by applying the Noisy-or product only to the top h predicting rules per candidate."
  - [section]: Proposition 4.9 formalizes that Max ≤ Noisy-or top-h ≤ Noisy-or, with equalities at h=1 and h=k.
  - [corpus]: Weak. No related work directly discusses this hybrid approach.
- **Break condition**: If redundancy among rules is not top-heavy, or if lower-confidence rules are actually important, top-h may miss predictive signal.

## Foundational Learning

- **Concept**: Marginal inference over joint distributions
  - Why needed here: The paper frames rule aggregation as computing the probability that at least one rule is true, which requires marginalizing over all possible truth assignments of rules.
  - Quick check question: If two rules have confidences 0.8 and 0.6 and are independent, what is the Noisy-or score? (Answer: 1 - (1-0.8)(1-0.6) = 0.92)

- **Concept**: Fréchet-Hoeffding bounds for correlation
  - Why needed here: These bounds are used to derive the correlation matrix that yields Max-aggregation under the probabilistic model.
  - Quick check question: What is the upper bound on correlation when p_i=0.8 and p_j=0.6? (Compute U(i,j) using the formula.)

- **Concept**: One-step entailment vs model-theoretic entailment
  - Why needed here: The paper explicitly restricts to one-step entailment for computational feasibility, which changes the probabilistic formulation.
  - Quick check question: Why does one-step entailment allow focusing only on rules that predict the target, rather than all rules? (Because only those can affect the query.)

## Architecture Onboarding

- **Component map**: Rule learner (AnyBURL/AMIE3) → produces rules with confidences → Aggregation module → applies Max, Noisy-or, or Noisy-or top-h → Evaluation pipeline → ranks candidates and computes MRR/Hits@X
- **Critical path**: Rule application → aggregation → ranking → evaluation
- **Design tradeoffs**:
  - Max: Fast, interpretable, assumes maximal correlation (may overestimate)
  - Noisy-or: Assumes independence (may underestimate)
  - Noisy-or top-h: Balances speed and accuracy, adapts to redundancy
- **Failure signatures**:
  - Max: Overconfident predictions when rules are redundant
  - Noisy-or: Underconfident predictions when rules are correlated
  - Noisy-or top-h: Degrades if h is set too low/high relative to redundancy structure
- **First 3 experiments**:
  1. Run all three aggregation methods (Max, Noisy-or, Noisy-or top-h with h=5) on a small dataset (e.g., WNRR) and compare MRR.
  2. Vary h in Noisy-or top-h and plot performance vs runtime to find optimal h.
  3. Measure rule redundancy (e.g., pairwise Jaccard similarity) and correlate with best h choice.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the correlation structure between rules affect the accuracy of the Noisy-or top-h aggregation method, and what is the optimal value of h for different types of knowledge graphs?
- Basis in paper: [inferred] The paper discusses the impact of rule correlation on aggregation methods and proposes Noisy-or top-h as a baseline, but does not provide a detailed analysis of how different correlation structures affect the performance of Noisy-or top-h or how to determine the optimal h.
- Why unresolved: The paper focuses on the theoretical foundations of rule aggregation and the efficiency of Noisy-or top-h, but does not delve into the specifics of how correlation structures influence the performance of Noisy-or top-h or how to choose the best h value.
- What evidence would resolve it: Experimental results comparing the performance of Noisy-or top-h with different h values on knowledge graphs with varying correlation structures, and an analysis of the relationship between correlation and optimal h.

### Open Question 2
- Question: Can the probabilistic interpretation of Max-aggregation be extended to other rule aggregation strategies, and what are the implications for knowledge graph completion?
- Basis in paper: [explicit] The paper shows that Max-aggregation can be derived from a probabilistic model when the correlation matrix of rules is set to the upper Fréchet-Hoeffding bound, suggesting that other aggregation strategies might also have probabilistic interpretations.
- Why unresolved: The paper only discusses the probabilistic interpretation of Max-aggregation and does not explore the possibility of extending this interpretation to other aggregation strategies or the potential implications for knowledge graph completion.
- What evidence would resolve it: A study that derives probabilistic interpretations for other rule aggregation strategies and evaluates their performance on knowledge graph completion tasks.

### Open Question 3
- Question: How can the joint distribution over rules be efficiently estimated from data, and what are the trade-offs between different estimation methods?
- Basis in paper: [inferred] The paper discusses the importance of the joint distribution over rules for rule aggregation but does not provide a detailed analysis of how to estimate this distribution from data or the trade-offs between different estimation methods.
- Why unresolved: The paper focuses on the theoretical foundations of rule aggregation and the efficiency of Noisy-or top-h, but does not delve into the specifics of how to estimate the joint distribution over rules or the trade-offs between different estimation methods.
- What evidence would resolve it: A study that compares the performance of different methods for estimating the joint distribution over rules and evaluates their trade-offs in terms of accuracy and computational efficiency.

## Limitations

- The theoretical framework relies on approximating rule marginals with rule confidences, which may not hold for noisy or sparse rule sets
- Runtime comparisons with SAFRAN and SV are based on rough estimates rather than direct measurements
- The effectiveness of Noisy-or top-h depends heavily on selecting an appropriate value of h, which may vary across datasets

## Confidence

- **High Confidence**: The mathematical derivations linking Max-aggregation to maximal correlation and Noisy-or to mutual independence are rigorously proven and internally consistent
- **Medium Confidence**: The empirical superiority of Noisy-or top-h over other aggregation methods is demonstrated, but results may be sensitive to rule mining hyperparameters and dataset characteristics
- **Low Confidence**: Runtime efficiency claims relative to SAFRAN and SV are based on rough estimates rather than direct measurements, making quantitative comparisons uncertain

## Next Checks

1. **Runtime Measurement**: Implement and run SAFRAN and SV approaches directly on the same hardware to obtain accurate runtime comparisons with Noisy-or top-h
2. **Rule Redundancy Analysis**: Quantify the redundancy structure of rule sets across datasets and analyze how this correlates with optimal h values for Noisy-or top-h
3. **Marginals vs Confidences**: Conduct experiments to measure the discrepancy between actual rule marginals and the confidences used as proxies, and assess the impact on aggregation performance