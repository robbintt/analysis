---
ver: rpa2
title: Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction
arxiv_id: '2308.00279'
source_url: https://arxiv.org/abs/2308.00279
tags:
- learning
- samples
- unlabeled
- training
- data
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes Robust-PU, a novel training strategy for positive-unlabeled
  (PU) learning inspired by curriculum learning. The key idea is to dynamically assign
  sample weights based on a "hardness" measure and an iterative training scheduler
  to progressively include harder samples.
---

# Robust Positive-Unlabeled Learning via Noise Negative Sample Self-correction

## Quick Facts
- arXiv ID: 2308.00279
- Source URL: https://arxiv.org/abs/2308.00279
- Reference count: 40
- Key outcome: Robust-PU achieves state-of-the-art performance in PU learning with up to 1.7% lower error rates than baseline methods

## Executive Summary
This paper introduces Robust-PU, a novel training strategy for positive-unlabeled (PU) learning that addresses the challenge of noisy negative samples. The method uses dynamic sample weighting based on a "hardness" measure and an iterative training scheduler to progressively include harder samples. By treating all unlabeled data as negative initially and converting PU learning to weighted supervised learning, Robust-PU achieves state-of-the-art performance on 8 benchmark datasets, particularly when the proportion of positive samples in unlabeled data increases.

## Method Summary
Robust-PU is an iterative training strategy for PU learning that converts the problem into weighted supervised learning. It operates through three stages per iteration: (1) hardness measurement using classification loss to identify noisy samples, (2) sample weighting using an exponential decay function based on hardness and a dynamic threshold, and (3) weighted supervised training treating all unlabeled as negative. The threshold increases gradually through training schedulers (linear, convex, concave, or exponential), implementing a curriculum-style progression from easy to hard samples. The method is evaluated on 8 datasets with varying class prior distributions.

## Key Results
- Robust-PU achieves state-of-the-art performance with up to 1.7% lower error rates than best baseline methods
- Particularly effective when the proportion of positive samples in unlabeled data increases
- Outperforms baselines on CIFAR-10, STL-10, MNIST, F-MNIST, Alzheimer's Dataset, mushrooms, shuttle, and spambase

## Why This Works (Mechanism)

### Mechanism 1
Dynamic sample weighting based on hardness measurement reduces overfitting to noisy negatives. Samples are assigned weights using an exponential decay function of their hardness (measured by classification loss), with the threshold controlling weight assignment increasing gradually through a training scheduler. This implements a curriculum-style progression from easy to hard samples.

### Mechanism 2
Iterative training with progressively relaxed thresholds improves model robustness. The method performs multiple training iterations where the threshold for including samples increases over time, focusing early iterations on samples with high confidence of being negative and incorporating harder samples in later iterations.

### Mechanism 3
Converting PU learning to weighted supervised learning enables use of standard training methods. By treating all unlabeled samples as negative initially and assigning them dynamic weights, the problem becomes standard binary classification with weighted samples.

## Foundational Learning

- **Concept: Curriculum learning** - The idea that models learn better when trained on easier examples first. Why needed here: PU learning involves significant label noise, and curriculum learning principles help the model avoid overfitting to mislabeled samples early in training. Quick check: What is the key difference between traditional curriculum learning and how it's applied in Robust-PU?

- **Concept: Self-paced learning** - A framework for dynamically adjusting sample weights based on model confidence. Why needed here: The hardness-weight mapping function is based on self-paced learning principles, allowing the model to progressively include harder samples. Quick check: How does the hardness-weight mapping function in Robust-PU relate to the regularizer in self-paced learning?

- **Concept: Positive-unlabeled learning** - Learning from positive samples and unlabeled data where unlabeled data contains both positive and negative samples. Why needed here: This is the fundamental problem being addressed; understanding the challenges of PU learning is essential for appreciating the proposed solution. Quick check: What is the main challenge that makes PU learning different from semi-supervised learning?

## Architecture Onboarding

- **Component map:** Hardness measurement -> Sample weighting -> Weighted supervised training -> Threshold update
- **Critical path:** The iterative loop where each iteration: measures hardness → calculates weights → performs weighted training → updates threshold for next iteration
- **Design tradeoffs:** Uses multiple iterations with dynamic thresholds vs. single-pass approaches; includes complexity of scheduler selection but gains robustness; treats all unlabeled as negative vs. attempting to identify true negatives
- **Failure signatures:** High variance in results across runs (indicates threshold scheduling issues); performance degradation as proportion of positives in unlabeled data increases (indicates hardness measurement failure); overfitting to noisy negatives (indicates insufficient early-stage filtering)
- **First 3 experiments:**
  1. Implement basic pipeline with logistic loss for hardness measurement and linear scheduler, test on MNIST with varying π
  2. Compare different hardness metric functions (logistic vs sigmoid loss) on CIFAR-10
  3. Test different training schedulers (linear, convex, concave) on mushroom dataset to identify best scheduler for that dataset type

## Open Questions the Paper Calls Out

### Open Question 1
How does the choice of hardness metric function (sigmoid vs logistic loss) impact the performance of Robust-PU across different dataset sizes and class prior distributions? While the paper provides experimental results comparing these functions, it lacks a detailed analysis of why one performs better than the other in specific scenarios.

### Open Question 2
What is the optimal temperature parameter (τ) for different datasets and class prior distributions, and how does it influence the robustness of Robust-PU? The paper investigates temperature scaling effects but doesn't provide clear guidelines for selecting the optimal temperature parameter across various scenarios.

### Open Question 3
How does the number of epochs (E) in the weighted supervised training stage affect the performance and robustness of Robust-PU, and what is the optimal value for different datasets? The paper conducts experiments on this but doesn't offer definitive recommendations for the optimal number of epochs across different datasets.

## Limitations
- The hardness measurement relies on loss values that may not reliably distinguish true negatives from mislabeled positives
- Training schedulers are heuristic without theoretical guarantees for optimal progression
- Conversion to weighted supervised learning assumes the weighting scheme can fully compensate for label uncertainty

## Confidence
- Claims about state-of-the-art performance: Medium (based on error rates only)
- Claims about avoiding overfitting to noisy negatives: Medium (mechanism plausible but not rigorously validated)
- Claims about iterative training benefits: Low (limited ablation studies)

## Next Checks
1. Conduct ablation studies comparing Robust-PU with and without the iterative training scheduler to quantify its contribution
2. Test Robust-PU on datasets with varying proportions of label noise to evaluate robustness boundaries
3. Implement an oracle baseline where true negative labels are known to establish upper performance bounds