---
ver: rpa2
title: 'Multimodal Fusion Interactions: A Study of Human and Automatic Quantification'
arxiv_id: '2306.04125'
source_url: https://arxiv.org/abs/2306.04125
tags:
- information
- multimodal
- modality
- modalities
- interactions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper compares three approaches to quantifying multimodal
  interactions: partial labels (different annotators predict the label from each modality
  and both together), counterfactual labels (same annotator predicts from one modality
  then re-predicts after seeing the other), and information decomposition (annotators
  rate redundancy, uniqueness, and synergy when viewing both modalities and the label).
  The authors propose a method to automatically convert partial or counterfactual
  labels to information decomposition values using convex programming with linear
  constraints.'
---

# Multimodal Fusion Interactions: A Study of Human and Automatic Quantification

## Quick Facts
- arXiv ID: 2306.04125
- Source URL: https://arxiv.org/abs/2306.04125
- Reference count: 40
- Compares three approaches to quantifying multimodal interactions using human annotations and automatic conversion

## Executive Summary
This paper investigates how humans quantify multimodal interactions across three annotation schemes: partial labels, counterfactual labels, and direct information decomposition ratings. The authors propose a method to automatically convert partial and counterfactual labels into information decomposition values using convex programming. Experiments across five diverse datasets reveal that counterfactual labeling yields higher annotator agreement than random assignment, and that the automatic conversion produces consistent interaction estimates aligned with direct human annotations. The study provides empirical evidence that information decomposition directly annotated performs well for objective tasks, while automatic conversion offers particular value for subjective multimodal tasks.

## Method Summary
The authors compare three human annotation approaches for quantifying multimodal interactions: (1) partial labels where different annotators predict from each modality separately, (2) counterfactual labels where the same annotator predicts from one modality then re-predicts after seeing the other, and (3) direct information decomposition where annotators rate redundancy, uniqueness, and synergy when viewing both modalities and the label. They propose a convex programming method to automatically convert partial and counterfactual labels into information decomposition values by solving for a joint distribution that satisfies marginal constraints. The approach is evaluated across five datasets (VQA, CLEVR, MOSEI, UR-FUNNY, MUStARD) using Krippendorff's alpha for inter-annotator agreement and confidence scores.

## Key Results
- Counterfactual label agreement (0.74 Krippendorff's alpha) is higher than randomized label agreement (0.58)
- Direct human annotation of information decomposition shows high agreement (roughly 0.7) for objective tasks
- Automatic conversion of partial/counterfactual labels to information decomposition produces consistent estimates aligned with direct annotations

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual labeling yields higher annotator agreement than random assignment.
- Mechanism: Same annotator observes both modalities sequentially, reducing variance in judgment across individuals and allowing explicit reasoning about modality contribution.
- Core assumption: Annotators can reliably detect and articulate changes in their predictions after seeing the second modality.
- Evidence anchors:
  - [abstract] "counterfactual labeling yields higher annotator agreement and confidence than random assignment"
  - [section 5.2] "Counterfactual label agreement (0.74) is higher than randomized label agreement (0.58)"
- Break condition: If annotators fail to perceive or articulate changes, agreement drops back to random assignment levels.

### Mechanism 2
- Claim: Information decomposition provides a principled normalization framework for multimodal interactions.
- Mechanism: By treating partial/counterfactual labels as samples from a joint distribution, convex programming enforces marginal consistency, yielding comparable redundancy, uniqueness, and synergy values.
- Core assumption: The joint label distribution can be approximated from partial predictions and marginals.
- Evidence anchors:
  - [section 4.1] "convex programming with linear constraints" for conversion
  - [section 4.2] "CVXPY returns the exact answer Q* efficiently"
- Break condition: If label space is large or continuous without discretization, the tensor representation becomes intractable.

### Mechanism 3
- Claim: Direct human annotation of information decomposition works well for objective tasks.
- Mechanism: Annotators rate redundancy, uniqueness, and synergy directly from both modalities and the label, bypassing need for automatic conversion.
- Core assumption: Annotators understand and can consistently apply definitions of redundancy, uniqueness, and synergy.
- Evidence anchors:
  - [section 5.3] "Krippendorff's alpha for inter-annotator agreement in directly annotating the interactions is quite high (roughly 0.7)"
  - [section 5.3] "average confidence scores are also quite high (above 4 for each interaction)"
- Break condition: If task is subjective (e.g., humor, sarcasm), annotator agreement drops due to ambiguous definitions.

## Foundational Learning

- Concept: Information theory and mutual information
  - Why needed here: Underpins the definition of redundancy, uniqueness, and synergy in information decomposition
  - Quick check question: Can you write the formula for mutual information between two variables?

- Concept: Convex optimization with linear constraints
  - Why needed here: Used to solve for the joint distribution Q* that satisfies marginal constraints and maximizes conditional entropy
  - Quick check question: What is the objective function in the convex program for estimating information decomposition?

- Concept: Krippendorff's alpha for inter-annotator agreement
  - Why needed here: Quantifies reliability of human annotations across different labeling schemes
  - Quick check question: What does a Krippendorff's alpha of 0.7 indicate about annotator agreement?

## Architecture Onboarding

- Component map:
  Human annotation interface -> Data collection pipeline -> Automatic conversion module -> Evaluation module

- Critical path:
  1. Collect partial/counterfactual labels from annotators
  2. Convert to information decomposition via convex optimization
  3. Evaluate agreement and consistency of interaction estimates

- Design tradeoffs:
  - Random assignment vs same annotator: variance vs consistency
  - Direct annotation vs automatic conversion: scalability vs objectivity
  - Discrete vs continuous label space: tractable vs flexible

- Failure signatures:
  - Low agreement scores (<0.5) indicate ambiguous or subjective task
  - Failed convergence in convex program suggests ill-conditioned marginals
  - High confidence but low agreement suggests overconfidence or misunderstanding

- First 3 experiments:
  1. Run partial labeling on a small VQA subset, convert via PID, compare with human-annotated decomposition
  2. Compare counterfactual labeling agreement across datasets with varying subjectivity
  3. Test convex program on synthetic data where ground-truth interactions are known

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Can the proposed method for converting partial and counterfactual labels to information decomposition values be extended to handle regression tasks or text answers without requiring approximate discretization?
- Basis in paper: [inferred] The paper mentions that the automatic conversion method requires the label space to be small and discrete for classification, and does not yet extend to regression or text answers.
- Why unresolved: The paper does not provide any details on how to extend the method to handle regression or text answers.
- What evidence would resolve it: Experiments demonstrating the extension of the method to handle regression tasks or text answers without requiring discretization, and a comparison of the results with the original method.

### Open Question 2
- Question: How does the subjectivity of the modalities and tasks affect the quality and consistency of the human annotations, and can this be quantified?
- Basis in paper: [explicit] The paper mentions that the annotation schemes are limited by the subjectivity of the modalities and task, and provides examples of subjective datasets like humor and sarcasm.
- Why unresolved: The paper does not provide a quantitative measure of how subjectivity affects annotation quality and consistency.
- What evidence would resolve it: A study quantifying the relationship between modality/task subjectivity and annotation agreement, confidence, and information decomposition values.

### Open Question 3
- Question: Can the proposed method for quantifying multimodal interactions be applied to more complex fusion tasks, such as multimodal machine translation or visual dialog, and how does it compare to existing methods?
- Basis in paper: [inferred] The paper focuses on sentiment analysis, humor detection, sarcasm detection, and question answering tasks, but does not explore more complex fusion tasks.
- Why unresolved: The paper does not provide any experiments or comparisons with existing methods on more complex fusion tasks.
- What evidence would resolve it: Experiments applying the proposed method to multimodal machine translation or visual dialog tasks, and a comparison of the results with existing methods for these tasks.

## Limitations

- The convex programming conversion approach requires discrete label spaces and may not scale well to continuous or high-dimensional outputs
- The study relies on crowdsourced annotations without extensive validation of annotator expertise or domain knowledge
- Generalizability of annotation agreement metrics across diverse subjective tasks remains unclear, with significant variation observed between objective and subjective tasks

## Confidence

- High confidence: Counterfactual labeling yields higher agreement than random assignment (0.74 vs 0.58 Krippendorff's alpha) based on direct experimental results
- Medium confidence: Information decomposition works well for objective tasks with clear definitions, though this requires further validation across more subjective domains
- Medium confidence: Automatic conversion produces consistent estimates aligned with direct annotations, though this depends on task characteristics and label space properties

## Next Checks

1. Test the automatic conversion pipeline on synthetic datasets with known ground-truth information decomposition values to validate accuracy across different interaction patterns
2. Compare agreement metrics across multiple crowdsourcing platforms to assess robustness to annotator pool differences and instructions
3. Extend experiments to multimodal tasks with continuous or high-dimensional outputs to evaluate scalability limitations of the convex programming approach