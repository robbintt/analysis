---
ver: rpa2
title: 'NoisyNN: Exploring the Impact of Information Entropy Change in Learning Systems'
arxiv_id: '2309.10625'
source_url: https://arxiv.org/abs/2309.10625
tags:
- noise
- positive
- image
- deep
- linear
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work investigates the impact of entropy change in deep learning
  systems by noise injection at different levels, including the embedding space and
  the image. The series of models that employ our methodology are collectively known
  as Noisy Neural Networks (NoisyNN), with examples such as NoisyViT and NoisyCNN.
---

# NoisyNN: Exploring the Impact of Information Entropy Change in Learning Systems

## Quick Facts
- **arXiv ID:** 2309.10625
- **Source URL:** https://arxiv.org/abs/2309.10625
- **Reference count:** 40
- **Primary result:** Achieved 95% top-1 accuracy on ImageNet using positive noise injection

## Executive Summary
This work introduces Noisy Neural Networks (NoisyNN), a methodology that explores the impact of entropy change in deep learning through strategic noise injection. The authors propose categorizing noise into positive noise (PN) that reduces task complexity and harmful noise (HN) that increases it, based on information entropy metrics. Through extensive experiments with CNNs and ViTs, they demonstrate that proactive injection of positive noise can significantly improve model performance, achieving unprecedented 95% top-1 accuracy on ImageNet.

## Method Summary
The method involves injecting structured noise into the latent feature space of deep learning models using linear transform matrices. The noise injection occurs at specific layers (typically the last layer) through a quality matrix Q that modifies the identity matrix to create positive noise. The noise strength parameter α controls the magnitude of perturbation. The approach is tested on both ViT and ResNet architectures across multiple datasets including ImageNet, TinyImageNet, Office-Home, and VisDA2017.

## Key Results
- Achieved 95% top-1 accuracy on ImageNet using NoisyViT
- Demonstrated 10-15% performance improvement for ResNet-50 models
- Showed consistent improvements across CNNs and ViTs with positive noise injection
- Validated that harmful noise (Gaussian, salt-and-pepper) impairs model performance

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear transform noise can reduce task complexity by modifying the latent feature distribution in a way that increases mutual information between features and labels.
- Mechanism: Injecting linear transform noise in the latent space effectively perturbs the feature matrix in a structured way (via row-equivalent transformation) that alters the covariance structure between features and labels. This change can increase the conditional entropy ratio in Equation 14, making the transformation beneficial.
- Core assumption: The noise transformation Q is chosen such that the rank of (I + Q) is preserved and the transformation satisfies the constraints (row equivalence, norm preservation, dominance of informative features).
- Evidence anchors:
  - [abstract]: "We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy"
  - [section 3]: "The key to determining whether the linear transform is positive noise or not lies in the matrix of Q. The most important step is to ensure that I + Q is reversible"
  - [corpus]: Weak evidence; no related papers directly discuss structured noise injections improving mutual information.
- Break condition: If Q causes rank deficiency or violates the norm and dominance constraints, mutual information drops below zero and performance degrades.

### Mechanism 2
- Claim: Gaussian noise injected at the image level increases conditional entropy, thus increasing task complexity and harming performance.
- Mechanism: Gaussian noise adds variance to the input distribution. The derivation in Equation 50 shows that the mutual information term is reduced by a factor involving the variance of the noise and the inverse variances of the original features. Since the term is negative, the noise increases task complexity.
- Core assumption: The noise is independent of both input and label distributions, and the data/label distributions are approximately normal.
- Evidence anchors:
  - [section A.1.1]: Derivation of M I(T, ϵ) < 0 for Gaussian noise at image level
  - [abstract]: "while the traditionally perceived harmful noise indeed impairs deep learning models"
  - [corpus]: Weak evidence; no papers specifically analyze Gaussian noise harm via information-theoretic metrics.
- Break condition: If the Gaussian noise is structured or correlated with informative features, the independence assumption fails and the harm may be reduced.

### Mechanism 3
- Claim: Salt-and-pepper noise is inherently harmful because it reduces mutual information by increasing label uncertainty without providing useful structure.
- Mechanism: The analysis in Equation 76 shows that mutual information becomes -H(ϵ), which is always negative, implying increased task complexity. This is because salt-and-pepper noise randomly corrupts pixel values without any informative structure.
- Core assumption: Salt-and-pepper noise is multiplicative and independent of the image content.
- Evidence anchors:
  - [section A.3.2]: Derivation M I(T, ϵ) = -H(ϵ) < 0
  - [abstract]: "extensive experiments of CNNs and ViTs have shown performance improvements by proactively injecting positive noise, while the traditionally perceived harmful noise indeed impairs deep learning models"
  - [corpus]: Weak evidence; related papers do not discuss salt-and-pepper noise harm via entropy metrics.
- Break condition: If the noise probability is tuned to mimic natural image corruption patterns, it might reduce harm, but still remains harmful under the model.

## Foundational Learning

- Concept: Information entropy as a measure of task complexity
  - Why needed here: The paper uses entropy to quantify how "hard" a classification task is, and noise that reduces entropy is beneficial.
  - Quick check question: If a dataset has perfectly separable classes, what is its entropy? (Answer: zero)

- Concept: Mutual information between task and noise
  - Why needed here: The sign of mutual information determines whether noise is positive or harmful; positive noise reduces task complexity.
  - Quick check question: If MI(T, ϵ) > 0, what does that imply about the conditional entropy H(T|ϵ)? (Answer: H(T|ϵ) < H(T))

- Concept: Row equivalence and elementary matrix operations
  - Why needed here: Linear transform noise is generated by applying elementary row operations to the identity matrix; understanding this is key to designing beneficial Q.
  - Quick check question: What property must I + Q have to be invertible? (Answer: Full rank, determinant ≠ 0)

## Architecture Onboarding

- Component map: Input → Latent representation → Noise injection layer → Remaining layers → Classifier
- Critical path: Noise injection at chosen layer → Mutual information change → Task complexity reduction → Improved classification
- Design tradeoffs: Injecting noise too early may disrupt feature learning; injecting too late may not provide enough regularization. Balance depends on model depth.
- Failure signatures: Performance drops if noise violates constraints (e.g., rank deficiency), or if injected at wrong layer.
- First 3 experiments:
  1. Baseline: Train ViT-B on ImageNet without noise.
  2. Inject positive linear transform noise at the last layer with strength α=0.3.
  3. Compare with Gaussian noise injection at the same layer.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal quality matrix for linear transform noise across different types of deep learning architectures beyond CNNs and ViTs?
- Basis in paper: Explicit - The paper discusses the optimal quality matrix for linear transform noise and its impact on task complexity reduction.
- Why unresolved: The paper only explores the optimal quality matrix for linear transform noise in the context of CNNs and ViTs. Its applicability to other architectures remains unexplored.
- What evidence would resolve it: Empirical studies applying the optimal quality matrix to various deep learning architectures and measuring their performance improvements.

### Open Question 2
- Question: How does the scale of the dataset affect the efficacy of positive noise injection in deep learning models?
- Basis in paper: Explicit - The paper mentions that larger datasets may yield better results with positive noise injection, but does not provide a detailed analysis.
- Why unresolved: The relationship between dataset scale and positive noise efficacy is mentioned but not thoroughly investigated.
- What evidence would resolve it: Systematic experiments across datasets of varying scales to determine the threshold at which positive noise becomes most effective.

### Open Question 3
- Question: Can the principles of positive noise injection be extended to other deep learning tasks beyond image classification and domain adaptation?
- Basis in paper: Explicit - The paper suggests potential applications in other deep learning tasks within computer vision and natural language processing.
- Why unresolved: The paper focuses on image classification and domain adaptation, leaving the broader applicability of positive noise injection unexplored.
- What evidence would resolve it: Implementation of positive noise injection in various deep learning tasks and evaluation of its impact on model performance.

## Limitations

- The theoretical claims about mutual information and entropy reduction rely on normality and independence assumptions that may not hold in practice
- The optimal Q matrix design lacks explicit guidelines for ensuring constraints across different architectures
- The ablation studies are limited with only three suggested experiments, insufficient to fully validate robustness

## Confidence

- **High Confidence**: The general principle that structured noise can improve learning through regularization effects
- **Medium Confidence**: The specific theoretical framework linking mutual information changes to performance improvements
- **Low Confidence**: The claimed unprecedented 95% ImageNet accuracy for NoisyViT

## Next Checks

1. **Constraint Verification**: Implement automated checks during training to verify that the Q matrix maintains full rank and satisfies the dominance constraints ([I+Q]ii ≥ [I+Q]ij for all i≠j). Monitor how often these constraints are violated during training.

2. **Layer Sensitivity Analysis**: Systematically test noise injection at different layers (early, middle, late) across multiple model depths to determine optimal injection points and understand the relationship between depth and noise effectiveness.

3. **Cross-Architecture Generalization**: Apply the same noise injection methodology to architectures not mentioned in the paper (e.g., ConvNeXt, Swin Transformer) to test whether the 2-15% improvement range holds or if performance gains are architecture-specific.