---
ver: rpa2
title: 'DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph Index
  using Query-sensitivity Entry Vertex'
arxiv_id: '2310.00402'
source_url: https://arxiv.org/abs/2310.00402
tags:
- vertex
- page
- diskann
- search
- graph
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DiskANN++ addresses the I/O bottleneck in DiskANN, a graph-based
  Approximate Nearest Neighbor Search (ANNS) method that uses a hybrid memory-SSD
  architecture. DiskANN suffers from long routing paths from a static entry vertex
  to queries' neighborhoods and redundant SSD I/O requests during the search process.
---

# DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph Index using Query-sensitivity Entry Vertex

## Quick Facts
- arXiv ID: 2310.00402
- Source URL: https://arxiv.org/abs/2310.00402
- Reference count: 40
- Primary result: DiskANN++ achieves 1.5x to 2.2x improvement in Queries Per Second (QPS) compared to DiskANN while maintaining same search accuracy

## Executive Summary
DiskANN++ addresses the I/O bottleneck in DiskANN, a graph-based Approximate Nearest Neighbor Search method that uses hybrid memory-SSD architecture. The paper introduces three key optimizations: query-sensitive entry vertex selection that dynamically chooses the closest entry point to each query, isomorphic mapping that optimizes SSD layout by grouping vertices with high closeness, and pagesearch algorithm that utilizes CPU idle resources during SSD I/O. Comprehensive experiments on eight real-world datasets demonstrate significant QPS improvements while maintaining the same recall@100 accuracy.

## Method Summary
DiskANN++ improves I/O efficiency of DiskANN through three key optimizations: (1) clustering the dataset into Ncluster partitions and selecting the nearest neighbor to each centroid as entry vertex candidates, then dynamically choosing the nearest candidate for each query; (2) applying star packing followed by bin packing (FFD) to assign vertices with high closeness to the same SSD page while preserving graph topology; and (3) implementing pagesearch with page heap and asynchronous page expansion that leverages CPU idle cycles during SSD I/O to reduce redundant requests. The method maintains the same recall@100 accuracy while achieving 1.5x to 2.2x QPS improvement.

## Key Results
- Achieves 1.5x to 2.2x improvement in QPS compared to DiskANN
- Maintains same recall@100 accuracy (target: 97%)
- Validated on eight real-world datasets ranging from 100M to 1B vectors
- Demonstrates effectiveness across varying vector dimensions and local intrinsic dimensionality

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Query-sensitive entry vertex selection reduces routing path length compared to static graph-central entry vertex.
- Mechanism: The algorithm clusters the dataset into Ncluster partitions, finds the nearest neighbor to each centroid, and for each query selects the nearest candidate from this set as the entry point. This dynamic selection shortens the distance from entry to query neighborhood.
- Core assumption: Monotonic Search Network (MSNET) properties hold for the graph, ensuring that the upper bound on path length is smaller with query-sensitive entry vertex.
- Evidence anchors:
  - [abstract]: "we present a query-sensitive entry vertex selection strategy to replace DiskANN's static graph-central entry vertex by a dynamically determined entry vertex that is close to the query."
  - [section]: "We leverage MSNET's monotonicity to complete our analysis... the following inequality holds for j in 1 to Ncluster: |MP(vc j , vq*)| ‚â§ |MP(vc0, vq*)|"
  - [corpus]: No direct evidence found in corpus; claim is theoretical from paper.
- Break condition: If MSNET monotonicity fails or clustering is poor, the theoretical bound may not hold and path length gains could be negligible.

### Mechanism 2
- Claim: Isomorphic mapping increases data value of each SSD I/O request by placing vertices with high closeness in the same SSD page.
- Mechanism: The paper applies a two-step mapping: first star packing assigns each vertex and its b-1 nearest neighbors to the same page, then bin packing merges non-full pages while preserving topology. This ensures each page contains a connected subgraph.
- Core assumption: Star packing + bin packing produces a bijection preserving graph edges and locality.
- Evidence anchors:
  - [abstract]: "we present an isomorphic mapping on DiskANN's graph index to optimize the SSD layout"
  - [section]: "Given a vertex v, we assign its b-1 neighbors to the same page of v... the induced graph of them is a typical star-derived graph"
  - [corpus]: No direct evidence found in corpus; claim is theoretical from paper.
- Break condition: If bin packing cannot merge pages efficiently or if graph topology changes too much, page compactness and I/O efficiency gains may be lost.

### Mechanism 3
- Claim: Pagesearch with page heap and asynchronous page expansion reduces redundant I/O requests and utilizes CPU idle time.
- Mechanism: Pagesearch caches accessed pages in a page heap, uses Update() to maintain a min-heap of candidates, and performs page expansion (Pop() + NeighborExpansion) during SSD I/O stalls, allowing more candidates to be processed before new I/O is issued.
- Core assumption: CPU idle cycles during SSD I/O can be productively used for page expansion without blocking I/O.
- Evidence anchors:
  - [abstract]: "propose an asynchronously optimized Pagesearch based on the optimized SSD layout as an alternative to DiskANN's beamsearch"
  - [section]: "We leverage the CPU's stall cycle... to perform the proposed page expansion asynchronously, when the SSD I/O requests are processing at the same time."
  - [corpus]: No direct evidence found in corpus; claim is theoretical from paper.
- Break condition: If page heap overhead or synchronization costs outweigh gains, or if SSD I/O is too fast for CPU to catch up, QPS improvement may be minimal.

## Foundational Learning

- Concept: Product Quantization (PQ) for memory-efficient distance approximation.
  - Why needed here: DiskANN++ relies on PQ to store low-dimensional vectors in memory and high-dimensional originals on SSD; understanding PQ compression ratios and precision loss is key to parameter tuning.
  - Quick check question: What is the typical compression ratio of PQ from fp32 to int8, and how does it affect recall@100?

- Concept: Monotonic Search Network (MSNET) properties and path monotonicity.
  - Why needed here: The theoretical proof for query-sensitive entry vertex relies on MSNET monotonicity; knowing what makes a graph MSNET helps validate assumptions.
  - Quick check question: What condition must hold for a graph to be an MSNET, and how does it guarantee monotonic path lengths?

- Concept: Graph partitioning and isomorphic mapping in SSD layout.
  - Why needed here: The isomorphic mapping step transforms the logical layout; understanding injection vs surjection and preservation of adjacency is critical for correctness.
  - Quick check question: In an isomorphic mapping, why must both the injection and surjection preserve edges, and what breaks if they don't?

## Architecture Onboarding

- Component map: Entry vertex selection module -> Isomorphic mapping engine -> Page heap cache -> Pagesearch algorithm
- Critical path: Query ‚Üí entry vertex selection ‚Üí SSD I/O preparation ‚Üí page expansion ‚Üí node expansion ‚Üí result
- Design tradeoffs: Larger Ncluster improves entry vertex quality but increases selection overhead; more aggressive PQ compression saves memory but hurts recall; bigger beam size speeds convergence but hurts load balancing
- Failure signatures: Sudden QPS drop indicates page heap sync bottleneck; recall@100 drop suggests mapping broke graph topology; high SSD I/O indicates mapping or entry vertex selection ineffective
- First 3 experiments:
  1. Run DiskANN++ vs DiskANN on a small dataset with Ncluster=1 to confirm baseline speedup
  2. Vary Ncluster from 16 to 65536 on deep100M and measure entry vertex hop reduction and QPS
  3. Enable/disable isomorphic mapping and measure SSD I/O request count and recall@100

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the query-sensitive entry vertex selection strategy perform under varying cluster sizes (ùëÅcluster) when the dataset has a very high local intrinsic dimensionality (LID)?
- Basis in paper: [explicit] The paper mentions that the cluster size ùëÅcluster significantly impacts the performance of the query-sensitive entry vertex selection strategy and shows experimental results with different ùëÅcluster values under different I/O bandwidths.
- Why unresolved: The paper does not explore the performance of the query-sensitive entry vertex selection strategy under varying cluster sizes when the dataset has a very high local intrinsic dimensionality (LID), which could affect the effectiveness of the strategy.
- What evidence would resolve it: Experiments comparing the performance of the query-sensitive entry vertex selection strategy under varying cluster sizes when the dataset has a very high LID, showing how the strategy adapts to different levels of dataset complexity.

### Open Question 2
- Question: What is the impact of increasing the beam size ùêµ on the overall search efficiency and accuracy in DiskANN++?
- Basis in paper: [explicit] The paper mentions that increasing the beam size ùêµ can expand the width of node expansion, allowing more data blocks from the page heap to be processed in each iteration. However, it also notes that continuously increasing the beam size is not conducive to load balancing for SSD across different queries.
- Why unresolved: The paper does not provide a detailed analysis of how increasing the beam size ùêµ affects the overall search efficiency and accuracy in DiskANN++. It only mentions that a larger beam size can lead to fewer unprocessed data blocks in the page heap, which could impact the search process.
- What evidence would resolve it: Experimental results showing the impact of increasing the beam size ùêµ on the overall search efficiency and accuracy in DiskANN++, including metrics such as QPS, recall@100, and the number of SSD I/O requests.

### Open Question 3
- Question: How does the isomorphic mapping on Vamana affect the search performance when the dataset has a high vector dimensionality (e.g., 960 dimensions as in the gist dataset)?
- Basis in paper: [explicit] The paper mentions that the isomorphic mapping on Vamana increases the data value of each SSD page by assigning vertices with great closeness to the same SSD page. However, it also notes that the effectiveness of the pagesearch may be limited when the dataset has a high vector dimensionality, as in the case of the gist dataset.
- Why unresolved: The paper does not provide a detailed analysis of how the isomorphic mapping on Vamana affects the search performance when the dataset has a high vector dimensionality. It only mentions that the effectiveness of the pagesearch may be limited in such cases.
- What evidence would resolve it: Experimental results comparing the search performance of DiskANN++ with and without the isomorphic mapping on Vamana when the dataset has a high vector dimensionality, showing how the mapping affects metrics such as QPS, recall@100, and the number of SSD I/O requests.

## Limitations
- Theoretical claims rely heavily on MSNET properties without extensive empirical validation
- Isomorphic mapping's topology preservation is assumed but not explicitly verified
- CPU-IO overlap benefits may vary significantly with hardware configurations
- No detailed analysis of beam size impact on overall search efficiency

## Confidence
- Query-sensitive entry vertex mechanism: Medium confidence - theoretical proof exists but real-world gains depend on clustering quality and MSNET properties
- Isomorphic mapping benefits: Low-Medium confidence - the approach is theoretically sound but requires empirical validation of topology preservation and I/O reduction
- Pagesearch algorithm: Medium confidence - asynchronous expansion is a reasonable optimization, but CPU-IO overlap benefits may vary by system

## Next Checks
1. Test MSNET monotonicity preservation: Measure actual routing path lengths with static vs query-sensitive entry vertices across multiple datasets to verify the theoretical bound
2. Validate isomorphic mapping integrity: Compare graph connectivity and search accuracy before/after isomorphic mapping to ensure topology preservation
3. Benchmark CPU-IO overlap efficiency: Measure CPU idle time during SSD I/O and correlate with QPS improvements to validate the pagesearch optimization's effectiveness across different hardware configurations