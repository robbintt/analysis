---
ver: rpa2
title: Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for HAR
arxiv_id: '2311.12674'
source_url: https://arxiv.org/abs/2311.12674
tags:
- data
- contrastive
- learning
- left
- right
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a self-supervised learning method for human
  activity recognition (HAR) that leverages the symmetry present in activities by
  contrasting left and right wrist or leg-worn IMU data. The method uses a contrastive
  loss to make representations of co-occurring sensor data more similar and those
  of non-co-occurring sensor data more different.
---

# Contrastive Left-Right Wearable Sensors (IMUs) Consistency Matching for HAR

## Quick Facts
- arXiv ID: 2311.12674
- Source URL: https://arxiv.org/abs/2311.12674
- Reference count: 0
- This paper proposes a self-supervised learning method for human activity recognition (HAR) that leverages the symmetry present in activities by contrasting left and right wrist or leg-worn IMU data.

## Executive Summary
This paper introduces a self-supervised learning approach for human activity recognition using wearable IMUs that exploits the symmetry present in human movements. The method uses a contrastive loss to make representations of synchronized left-right sensor data more similar while pushing non-synchronized pairs apart. Evaluated on MM-Fit and Opportunity datasets, the approach significantly outperforms both supervised baselines and other self-supervised methods like SimCLR, particularly when limited labeled data is available.

## Method Summary
The proposed method uses a Siamese network architecture where left and right sensor streams from synchronized IMUs pass through a shared 3-layer 1D CNN encoder followed by a projection head. During pretraining, a modified NT-Xent contrastive loss enforces similarity between synchronized left-right pairs while pushing apart non-synchronized pairs. The encoder is then frozen (except the last layer) and fine-tuned with a small MLP classifier on labeled data. The approach eliminates the need for data augmentation by directly using raw sensor symmetry as the supervisory signal.

## Key Results
- On MM-Fit dataset, achieves 8% improvement in macro F1 score over both baseline supervised and SimCLR methods
- On Opportunity dataset, significantly improves over supervised baseline and shows slight improvement compared to SimCLR
- Achieves approximately 0.7 macro F1 score on MM-Fit using only 100 annotated samples per class

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Left-right wrist IMU symmetry in human activity enables self-supervised contrastive learning without transformations.
- Mechanism: Co-occurring sensor data from symmetrical body parts (e.g., left and right wrist) share latent structure. By enforcing similarity on left-right pairs and dissimilarity on non-paired samples, the encoder learns robust activity representations.
- Core assumption: Activities that engage both sides of the body produce symmetric or strongly correlated IMU signals.
- Evidence anchors:
  - [abstract]: "by taking advantage of the symmetry present in the activities"
  - [section]: "taking advantage of the symmetry present in the activities"
  - [corpus]: No direct corpus mention of left-right symmetry; evidence is internal.
- Break condition: Activities that are unilateral or asymmetric (e.g., one-arm lifts) degrade performance.

### Mechanism 2
- Claim: Contrastive learning on raw sensor data removes need for hand-crafted data augmentation.
- Mechanism: The encoder directly learns from synchronized left-right sensor streams, avoiding augmentation approximations. The temperature-scaled NT-Xent loss pulls positive pairs close in latent space and pushes negatives apart.
- Core assumption: Raw sensor symmetry contains sufficient signal for contrastive learning.
- Evidence anchors:
  - [section]: "The stochastic data augmentations used in other contrastive methods reflect an approximation of sensor properties. Using directly raw sensor data as views allows learning the sensor properties directly"
  - [corpus]: No corpus support for the direct raw-data claim; evidence is internal.
- Break condition: If data noise dominates signal, or sensors drift out of sync, contrastive loss may fail.

### Mechanism 3
- Claim: Pretraining on unlabeled data improves performance with few labeled examples.
- Mechanism: Encoder trained on contrastive task captures general activity structure. Fine-tuning on small labeled set adapts these features for classification, achieving high accuracy with ≤100 samples per class.
- Core assumption: Representations learned from left-right pairs transfer to single-sensor inference.
- Evidence anchors:
  - [section]: "We observed that our method does not need a large minibatch, in contrast to other contrastive learning frameworks based on transformations"
  - [section]: "achieves around a 0.7 macro f1 score on MM-Fit using only 100 annotated samples per class"
  - [corpus]: No direct corpus evidence of few-shot gains; relies on internal evaluation.
- Break condition: If downstream classes are too dissimilar from pretraining distribution, fine-tuning gains vanish.

## Foundational Learning

- Concept: Self-supervised contrastive learning
  - Why needed here: Avoids costly labeling by using left-right sensor symmetry as a supervisory signal.
  - Quick check question: What is the role of temperature τ in NT-Xent loss?

- Concept: Siamese network architecture
  - Why needed here: Two views (left/right) pass through a shared encoder, enforcing aligned representations.
  - Quick check question: Why share weights between left and right encoders?

- Concept: Transfer learning / pretrain-then-finetune
  - Why needed here: Enables good performance with very few labeled samples after contrastive pretraining.
  - Quick check question: What changes between pretraining and fine-tuning phases?

## Architecture Onboarding

- Component map: Raw sensor data → Shared 1D-CNN encoder → Projection head (dense layers) → NT-Xent loss; for inference: Encoder → MLP classifier
- Critical path: Sensor sync → Encoder training → Projection head loss → Frozen encoder → MLP fine-tune → Classification
- Design tradeoffs: Simpler model (single encoder) vs. flexibility (two encoders). No data augmentation vs. potential robustness loss.
- Failure signatures: Degraded macro F1 on asymmetric activities, batch size insensitivity, high variance across runs.
- First 3 experiments:
  1. Train baseline supervised model on left sensor only; measure macro F1.
  2. Run contrastive pretraining on synchronized left-right pairs; fine-tune on labeled subset; compare macro F1.
  3. Vary batch size (32, 64, 128) during pretraining; measure effect on downstream accuracy.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Under what specific conditions (types of activities, symmetry requirements, etc.) does the left-right contrastive learning approach provide the most significant improvements for human activity recognition?
- Basis in paper: [explicit] The authors state "Future work should explore under which conditions our method is beneficial for human activity recognition systems" and discuss limitations with non-symmetric activities.
- Why unresolved: The paper only tested on MM-Fit (symmetric activities) and Opportunity (mixed activities), showing varying levels of improvement. The relationship between activity type and method effectiveness is not fully characterized.
- What evidence would resolve it: Systematic testing across datasets with varying levels of activity symmetry, and statistical analysis of performance correlation with symmetry metrics.

### Open Question 2
- Question: How does the proposed method compare to other self-supervised learning approaches when dealing with highly imbalanced datasets, beyond just showing improvements over supervised baselines?
- Basis in paper: [explicit] The authors mention that "MM-Fit is an unbalanced dataset" and show performance across classes in the confusion matrix, but don't compare their method's robustness to other SSL approaches.
- Why unresolved: While the paper shows the method works on imbalanced data, it doesn't benchmark against other SSL methods specifically for handling class imbalance.
- What evidence would resolve it: Head-to-head comparison of the proposed method against other SSL methods on multiple imbalanced datasets, measuring performance across minority and majority classes.

### Open Question 3
- Question: What is the minimum amount of labeled data required for the method to show significant improvement over fully supervised training from scratch, and how does this vary across different activity recognition tasks?
- Basis in paper: [explicit] The authors show results with 1, 5, 10, 50, and 100 samples per class on MM-Fit, achieving 0.7 macro F1 with 100 samples, but don't explore the threshold for significant improvement.
- Why unresolved: The paper demonstrates the method works with limited data but doesn't determine the exact point where it becomes more effective than supervised learning.
- What evidence would resolve it: Testing the method with progressively smaller labeled datasets across multiple activity recognition tasks, and statistical comparison to supervised baselines at each level.

## Limitations
- The method's performance depends on the symmetry of activities, potentially degrading for asymmetric or unilateral movements
- Absolute performance levels remain moderate (macro F1 around 0.7 on MM-Fit with 100 samples per class)
- The approach requires synchronized left-right sensor data, limiting applicability when only single-sensor data is available

## Confidence

- **High confidence**: The mechanism of using synchronized left-right sensor data for contrastive learning is technically sound and well-implemented
- **Medium confidence**: The claim that contrastive pretraining improves few-shot learning performance is supported by the experiments, though absolute performance could be higher
- **Medium confidence**: The assertion that this approach eliminates need for data augmentation is reasonable given the symmetry exploitation, but not extensively validated

## Next Checks

1. Test the method on activities known to be asymmetric (one-arm exercises, unilateral movements) to quantify symmetry dependency
2. Compare performance with and without the projection head in the contrastive learning pipeline to isolate its contribution
3. Evaluate robustness to sensor synchronization errors by introducing controlled time offsets between left-right streams