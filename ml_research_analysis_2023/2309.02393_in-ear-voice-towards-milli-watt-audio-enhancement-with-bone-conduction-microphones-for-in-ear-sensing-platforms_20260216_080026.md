---
ver: rpa2
title: 'In-Ear-Voice: Towards Milli-Watt Audio Enhancement With Bone-Conduction Microphones
  for In-Ear Sensing Platforms'
arxiv_id: '2309.02393'
source_url: https://arxiv.org/abs/2309.02393
tags:
- speech
- conduction
- power
- bone
- https
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents the design of a custom low-power wireless earbud
  with novel MEMS bone-conduction microphones for improved voice activity detection.
  The platform features an ultra-low-power personalized voice activity detection algorithm
  based on a recurrent neural network running on a state-of-the-art Ambiq Apollo 4
  Blue SoC.
---

# In-Ear-Voice: Towards Milli-Watt Audio Enhancement With Bone-Conduction Microphones for In-Ear Sensing Platforms

## Quick Facts
- arXiv ID: 2309.02393
- Source URL: https://arxiv.org/abs/2309.02393
- Reference count: 40
- Custom low-power wireless earbud with MEMS bone-conduction microphones achieves 95% binary accuracy in voice activity detection at 2.64mW power consumption

## Executive Summary
This paper presents a novel low-power in-ear sensing platform that leverages bone-conduction microphones for personalized voice activity detection (pVAD). The system achieves 95% binary accuracy in detecting speech within 12.8ms while consuming only 2.64mW of power, enabling a theoretical battery life of 43 hours on a 32mAh battery. By using bone-conduction microphones that provide an additional 15dB of signal-to-noise ratio compared to traditional air-conduction microphones, the platform can function effectively in extremely noisy environments where conventional approaches fail. The system runs a recurrent neural network on a state-of-the-art Ambiq Apollo 4 Blue SoC, demonstrating the feasibility of sophisticated audio processing in ultra-low-power wearable devices.

## Method Summary
The method involves a custom wireless earbud platform featuring MEMS bone-conduction microphones (VPU14DB01) coupled with an ultra-low-power pVAD algorithm implemented on an Ambiq Apollo 4 Blue SoC. The algorithm uses a recurrent neural network architecture that processes 32-dimensional Mel-scale features extracted from 20ms frames of bone-conduction audio. The model is trained on a custom dataset collected from 20 participants across 5 languages, with data augmentation using the DNS challenge dataset to simulate various noise conditions. Post-training quantization to 8-bit precision enables real-time inference while maintaining 95% accuracy. The system's power efficiency is achieved through hardware-optimized preprocessing using CMSIS-DSP libraries and TFLite Micro deployment on the Apollo 4 Blue platform.

## Key Results
- Achieves 95% binary accuracy in voice activity detection within 12.8ms latency
- Consumes only 2.64mW power, enabling 43 hours of theoretical battery life on 32mAh battery
- Provides 15dB higher SNR than air-conduction microphones in the same environment
- Maintains 95% accuracy at SNR 10dB compared to 20% accuracy for air-conduction approach

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Bone conduction microphones capture speech with ~15dB higher SNR than air conduction microphones in the same environment.
- Mechanism: Bone conduction microphones directly couple to the skull, bypassing ambient air transmission. This coupling preferentially transmits the wearer's voice while rejecting environmental noise that travels through air.
- Core assumption: The bone conduction microphone maintains consistent coupling with the wearer's head across different users and sessions.
- Evidence anchors:
  - [abstract] "Compared to traditional air-conduction microphone based approaches, the bone-conduction microphone provides an additional 15dB of SNR"
  - [section] "On average, the bone-conduction microphone is capable of capturing the wearer's speech with an additional 15.01dB of SNR"
  - [corpus] Weak corpus support - no directly relevant papers found on SNR differences
- Break condition: Poor earbud fit, significant head movement, or severe environmental vibrations that couple through the skull.

### Mechanism 2
- Claim: Bone conduction recordings provide discriminative features for personalized voice activity detection without requiring enrollment data.
- Mechanism: The bone conduction signal contains unique coupling characteristics between the speaker's voice and their skull. This coupling pattern is distinct from external speakers, enabling the neural network to distinguish target speech from interference based on physical transmission differences rather than learned voice patterns.
- Core assumption: The bone conduction signal preserves enough speaker-specific characteristics while maintaining sufficient isolation from external sources.
- Evidence anchors:
  - [abstract] "enabling personalized voice activity detection and further audio enhancement applications"
  - [section] "the bone conduction system, achieving detection of speech within 12.8ms at an accuracy of 95%"
  - [corpus] Weak corpus support - related papers focus on bone conduction for speech enhancement but not VAD
- Break condition: Similar bone conduction coupling between target speaker and interfering speakers, or significant environmental vibrations.

### Mechanism 3
- Claim: The proposed TinyML architecture achieves 95% accuracy at 2.64mW power consumption through efficient preprocessing and quantization.
- Mechanism: Hardware-optimized preprocessing (PDM-to-PCM, FFT using CMSIS-DSP) reduces input dimensionality before neural network inference. 8-bit quantization reduces computational requirements while maintaining accuracy. The GRU-based architecture captures temporal dependencies with minimal parameters.
- Core assumption: The quantized model maintains sufficient accuracy for practical applications.
- Evidence anchors:
  - [abstract] "achieving detection of speech within 12.8ms at an accuracy of 95%"
  - [section] "averaged over 1024 frames, 1.21mW are consumed during sleep... During computation the Apollo requires an additional 5.01mW, for a total consumption of 5.11mW"
  - [section] "Using Tensorflow, the model was quantized to 8bit precision, with a representative data set used to set internal gains and limit quantization error. Post quantization, the network lost at most 4% of its original binary accuracy"
- Break condition: If quantization error exceeds acceptable thresholds for the application, or if hardware acceleration libraries are unavailable.

## Foundational Learning

- Concept: Voice Activity Detection (VAD) fundamentals
  - Why needed here: Understanding the distinction between general VAD and personalized VAD is critical for grasping the problem space and why bone conduction microphones are beneficial.
  - Quick check question: What is the key limitation of traditional VAD approaches when applied to hearables in noisy environments?

- Concept: Bone conduction vs. air conduction microphone principles
  - Why needed here: Essential for understanding why bone conduction provides SNR advantages and how this enables the personalized detection approach.
  - Quick check question: How does the physical coupling mechanism of bone conduction microphones differ from air conduction microphones?

- Concept: TinyML optimization techniques
  - Why needed here: Critical for understanding how the model achieves real-time inference on resource-constrained devices.
  - Quick check question: What are the primary techniques used to reduce model size and computational requirements in TinyML applications?

## Architecture Onboarding

- Component map: Bone conduction microphone (VPU14DB01) → PDM interface → Hardware PDM-to-PCM filter → 16kHz 16-bit audio stream → Preprocessing pipeline → Neural network → VAD decision
- Critical path: Audio capture → Preprocessing → Neural network inference → VAD decision
- Design tradeoffs:
  - SNR vs. audio quality: Bone conduction provides isolation but unnatural sound
  - Model complexity vs. accuracy: 5K parameters balances performance with resource constraints
  - Power vs. latency: Hardware acceleration reduces latency but increases power consumption
  - Quantization vs. accuracy: 8-bit quantization significantly reduces power but may impact accuracy
- Failure signatures:
  - High false negatives: Bone conduction coupling issues or model quantization error
  - High false positives: Environmental vibrations coupling to bone conduction microphone
  - Excessive power consumption: Inefficient preprocessing or model architecture
  - Latency issues: Insufficient hardware acceleration or inefficient implementation
- First 3 experiments:
  1. Baseline performance test: Run unquantized model on Apollo 4 Blue with clean speech to establish maximum accuracy
  2. Quantization impact analysis: Compare quantized vs. unquantized model performance on test dataset at various SNR levels
  3. Power profiling: Measure power consumption during different operational states (sleep, preprocessing, inference) to identify optimization opportunities

## Open Questions the Paper Calls Out
- How does the pVAD performance vary across different languages and accents beyond the limited set tested in the paper?
- Can the bone-conduction microphone effectively capture speech in extremely noisy environments where air conduction fails completely?
- What is the impact of different earbud fit and placement variations on the bone-conduction microphone's performance?

## Limitations
- Custom bone-conduction microphone (VPU14DB01) may not be readily available for replication
- Custom dataset collection involved 20 participants in 5 languages, which may not capture sufficient diversity
- SNR advantage of 15dB measured in controlled conditions may degrade with poor earbud fit
- 95% accuracy claim based on simulated mixtures at specific SNR levels, not real-world deployment

## Confidence
- High Confidence: Power consumption measurements (2.64mW) and battery life calculations (43h)
- Medium Confidence: Binary accuracy (95%) and AUC (0.98) claims
- Low Confidence: Generalization to real-world noisy environments

## Next Checks
1. Cross-device validation: Test the trained model on different bone-conduction microphones and hardware platforms to verify algorithm portability
2. Real-world deployment testing: Deploy the system in actual noisy environments with diverse users to validate the 15dB SNR advantage and 95% accuracy claims
3. Long-term stability assessment: Evaluate model performance over extended periods with the same user to verify that bone-conduction coupling characteristics remain consistent