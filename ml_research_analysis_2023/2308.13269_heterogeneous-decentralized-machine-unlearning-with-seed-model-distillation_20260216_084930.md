---
ver: rpa2
title: Heterogeneous Decentralized Machine Unlearning with Seed Model Distillation
arxiv_id: '2308.13269'
source_url: https://arxiv.org/abs/2308.13269
tags:
- unlearning
- learning
- client
- data
- seed
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes HDUS, a heterogeneous decentralized machine
  unlearning framework using seed model distillation. HDUS enables exact unlearning
  in decentralized learning by introducing lightweight seed models trained via knowledge
  distillation from neighbors, allowing seamless removal of user contributions without
  retraining.
---

# Heterogeneous Decentralized Machine Unlearning with Seed Model Distillation

## Quick Facts
- **arXiv ID**: 2308.13269
- **Source URL**: https://arxiv.org/abs/2308.13269
- **Reference count**: 0
- **Primary result**: HDUS achieves up to 99% accuracy in homogeneous settings and 98.7% in heterogeneous settings while enabling exact unlearning without retraining

## Executive Summary
This paper introduces HDUS, a heterogeneous decentralized machine unlearning framework that enables exact unlearning in collaborative learning environments. HDUS uses lightweight seed models trained via knowledge distillation from neighbors, allowing seamless removal of user contributions without retraining the entire system. The framework addresses critical challenges in decentralized machine unlearning including privacy preservation, heterogeneous model compatibility, and exact unlearning capability. Experiments on three datasets demonstrate HDUS outperforms state-of-the-art baselines in both learning effectiveness and unlearning efficiency.

## Method Summary
HDUS introduces a novel framework where each client maintains a main model trained on local data and generates seed models through knowledge distillation using a reference dataset. Seed models are exchanged with neighbors and stored in a repository, forming an ensemble with the main model for inference. When a client leaves, its corresponding seed models can be removed from all neighboring ensembles without retraining, achieving exact unlearning. The framework supports heterogeneous model architectures by circumventing traditional parameter sharing through knowledge distillation, enabling collaboration between models of different structures while preserving privacy.

## Key Results
- Achieves 99% accuracy in homogeneous settings and 98.7% in heterogeneous settings
- Outperforms baselines (ISGD, SISA-A, FedUnl, DSGD) in both learning effectiveness and unlearning efficiency
- Enables exact unlearning by simply removing seed models from ensembles without retraining
- Supports heterogeneous model architectures through knowledge distillation instead of parameter sharing

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Seed models act as secure intermediaries that enable knowledge transfer without exposing raw data or main model parameters.
- Mechanism: Each client distills knowledge from its main model into a lightweight seed model using a reference dataset that contains no client-specific data. This seed model is then shared with neighbors, allowing knowledge transfer while preserving privacy.
- Core assumption: The reference dataset can be constructed such that it contains no client-specific information while still enabling effective knowledge distillation.
- Evidence anchors:
  - [abstract] "The reference dataset only needs to follow the format of local client data and contain no client-specific data points (e.g., constructed with simulation/public data)"
  - [section II.C] "Instead of designing supervised tasks to learn θseed i, the seed model f(θseed i, ·) distills knowledge from the main model f(θi, ·) by minimizing..."
- Break condition: If the reference dataset inadvertently contains client-specific information or if the distillation process leaks information from the main model.

### Mechanism 2
- Claim: The ensemble architecture allows for exact unlearning by simply removing the corresponding seed model from the ensemble.
- Mechanism: Each client maintains an ensemble model consisting of its main model and seed models from neighbors. When a client leaves, its seed model can be removed from all neighboring ensembles without retraining, achieving exact unlearning.
- Core assumption: The seed models are sufficiently independent that removing one doesn't require adjusting the remaining components.
- Evidence anchors:
  - [abstract] "The main model and seed models in the client constitute an ensemble model, so as to provide stronger performance and generalizability."
  - [section II.C] "Since all the knowledge from neighbor bi j is contained and only contained by si j, Eq.(3) can be regarded as an exact unlearning process."
- Break condition: If the seed models are not truly independent or if the ensemble performance heavily depends on the removed component.

### Mechanism 3
- Claim: Heterogeneous model support is achieved by replacing parameter sharing with knowledge distillation.
- Mechanism: Instead of exchanging model parameters (which requires homogeneous architectures), clients exchange distilled seed models that can work with any main model architecture, enabling collaboration between heterogeneous models.
- Core assumption: Knowledge distillation can effectively transfer knowledge between models of different architectures.
- Evidence anchors:
  - [abstract] "By circumventing traditional parameter sharing across client models, HDUS's design is compatible with heterogeneous model architectures"
  - [section I] "The surge of edge computing and big data brings people personalized services in various domains... users are more likely to possess devices with various hardware configurations, hence requiring different model structures for optimized performance"
- Break condition: If knowledge distillation between heterogeneous architectures proves ineffective or if the performance gap between architectures becomes too large.

## Foundational Learning

- **Knowledge Distillation**
  - Why needed here: Enables transfer of knowledge from main models to seed models without sharing parameters, supporting both privacy and heterogeneous collaboration
  - Quick check question: How does knowledge distillation differ from parameter sharing in terms of privacy preservation?

- **Ensemble Learning**
  - Why needed here: Allows combining multiple models (main + seed models) to improve performance while enabling exact unlearning by component removal
  - Quick check question: What are the key benefits of using ensemble methods in the context of machine unlearning?

- **Decentralized Learning**
  - Why needed here: Provides the framework for direct client-to-client communication without central servers, enabling both collaboration and unlearning
  - Quick check question: How does fully decentralized learning differ from federated learning in terms of communication patterns?

## Architecture Onboarding

- **Component map**: Main Model -> Seed Model (via knowledge distillation) -> Seed Model Repository -> Ensemble (Main + Seed Models)
- **Critical path**: 
  1. Train main model on local data
  2. Distill knowledge to seed model using reference dataset
  3. Exchange seed models with neighbors
  4. Store received seed models in repository
  5. Perform inference using ensemble of main model + seed models
- **Design tradeoffs**:
  - Seed model size vs. distillation effectiveness
  - Number of neighbors vs. communication overhead
  - Reference dataset size vs. distillation quality
  - Ensemble weight λ vs. performance and unlearning capability
- **Failure signatures**:
  - Poor performance: Seed models not effectively capturing main model knowledge
  - Privacy breach: Information leakage through reference dataset or seed models
  - Unlearning failure: Residual influence of removed client after unlearning
  - Communication breakdown: Failed seed model exchange between neighbors
- **First 3 experiments**:
  1. Train main model and distill seed model, verify seed model performance vs. main model
  2. Exchange seed models between two clients, verify ensemble performance
  3. Perform unlearning simulation by removing seed model, verify exact unlearning and performance recovery

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HDUS scale with increasing numbers of clients and heterogeneous model sizes in real-world deployments?
- Basis in paper: [inferred] The paper demonstrates HDUS effectiveness on three datasets with 6-6-5 clients and three model sizes (small, medium, large), but does not explore scaling beyond these configurations or examine performance degradation with larger, more diverse client networks.
- Why unresolved: The experimental setup focuses on controlled scenarios with limited client counts and predefined model architectures. Real-world IoT deployments could involve hundreds or thousands of heterogeneous devices with varying capabilities.
- What evidence would resolve it: Large-scale simulations or field tests showing HDUS performance metrics (accuracy, communication overhead, unlearning latency) across different client counts (e.g., 10, 50, 100+) and diverse model architectures beyond the three tested configurations.

### Open Question 2
- Question: What is the impact of malicious or low-quality seed models on the overall ensemble performance and unlearning effectiveness in HDUS?
- Basis in paper: [explicit] The paper mentions that poisoning attacks amplify the need for unlearning clients with malicious or low-quality data, but does not evaluate how such compromised seed models affect HDUS performance or whether additional defenses are needed.
- Why unresolved: While HDUS provides exact unlearning, the paper does not address robustness against adversarial seed models during the learning phase or whether unlearning alone is sufficient to mitigate such attacks.
- What evidence would resolve it: Experiments introducing poisoned seed models into HDUS ensembles and measuring performance degradation, along with evaluation of unlearning effectiveness in removing malicious contributions and potential need for detection mechanisms.

### Open Question 3
- Question: How does the reference dataset construction strategy affect HDUS performance, particularly when clients use different simulation/public data sources?
- Basis in paper: [explicit] The paper states that reference datasets "only need to follow the format of local client data and contain no client-specific data points" and can be constructed with simulation/public data, but does not evaluate different construction strategies or their impact on distillation quality.
- Why unresolved: The paper uses a single reference dataset approach without exploring whether dataset diversity, size variations, or different construction methodologies (e.g., synthetic vs. public datasets) affect seed model quality and overall framework performance.
- What evidence would resolve it: Comparative experiments using different reference dataset construction methods (varying sizes, sources, and diversity) and measuring resulting HDUS performance across all three benchmark datasets to identify optimal construction strategies.

## Limitations
- Limited validation of knowledge distillation effectiveness across diverse heterogeneous architecture combinations beyond three MobileNet variants
- No rigorous analysis of potential information leakage through reference datasets or seed models
- Performance scalability to large-scale deployments with hundreds of heterogeneous clients remains unexplored

## Confidence
- **High confidence**: Ensemble learning mechanism and basic unlearning process (supported by clear algorithmic description and mathematical formulation)
- **Medium confidence**: Heterogeneous architecture support (theoretical soundness but limited empirical validation across diverse architecture combinations)
- **Medium confidence**: Privacy guarantees (seed models are claimed to preserve privacy, but potential information leakage through distillation is not rigorously analyzed)

## Next Checks
1. Test unlearning robustness by attempting to recover client data from seed models using membership inference attacks
2. Evaluate knowledge distillation effectiveness across a broader range of heterogeneous architecture pairs (beyond the three MobileNet variants)
3. Measure performance degradation when varying the reference dataset quality and composition to assess sensitivity to this critical component