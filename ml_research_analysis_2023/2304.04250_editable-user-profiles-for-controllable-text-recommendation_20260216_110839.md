---
ver: rpa2
title: Editable User Profiles for Controllable Text Recommendation
arxiv_id: '2304.04250'
source_url: https://arxiv.org/abs/2304.04250
tags:
- user
- lace
- users
- concepts
- recommendations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LACE, a concept bottleneck model for controllable
  text recommendations. LACE constructs user profiles by retrieving interpretable
  concepts from user-interacted documents and computes personalized concept values
  using optimal transport.
---

# Editable User Profiles for Controllable Text Recommendation

## Quick Facts
- arXiv ID: 2304.04250
- Source URL: https://arxiv.org/abs/2304.04250
- Reference count: 40
- This paper introduces LACE, a concept bottleneck model for controllable text recommendations. LACE constructs user profiles by retrieving interpretable concepts from user-interacted documents and computes personalized concept values using optimal transport. The model supports intuitive interactions like concept selection and editing. In offline evaluations across six datasets and three recommendation tasks, LACE outperforms baseline models in warm-start, cold-start, and zero-shot settings. A user study shows that users can significantly improve their recommendations through interactions with the editable profile, with gains of 20-47% in ranking metrics. LACE provides both strong performance and controllability in text recommendation.

## Executive Summary
This paper presents LACE, a novel approach to controllable text recommendation that constructs interpretable user profiles through concept retrieval and optimal transport-based personalization. The model represents users with human-readable concepts extracted from their interacted documents, allowing for intuitive interactions such as concept selection and editing. LACE demonstrates strong performance across multiple recommendation tasks and settings, while providing users with meaningful control over their recommendations through an editable profile interface.

## Method Summary
LACE is a retrieval-enhanced concept bottleneck model that builds user profiles by extracting interpretable concepts from user-interacted documents. It uses a pre-trained language model to retrieve concepts from a large inventory and computes personalized concept values through optimal transport assignments between document sentences and profile concepts. The model represents both users and candidate documents as sets of vectors, enabling ranking through Wasserstein distance calculations. LACE supports user interactions by allowing edits to concepts, which trigger recomputation of personalized concept values and update recommendations accordingly.

## Key Results
- LACE outperforms baseline models across six datasets in warm-start, cold-start, and zero-shot recommendation settings
- User study demonstrates 20-47% improvement in ranking metrics (NDCG@20, Recall@20, MRR) through profile interactions
- LACE maintains strong performance while providing interpretable, editable user profiles for controllability

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LACE enables interpretable user profiles through concept retrieval
- Mechanism: LACE uses a pre-trained language model to retrieve human-readable concepts from a large inventory based on user-interacted documents. These concepts form a transparent profile that users can understand and edit.
- Core assumption: The retrieved concepts accurately capture the topical content of user documents and are interpretable by users
- Evidence anchors:
  - [abstract] "LACE represents each user with a succinct set of human-readable concepts through retrieval given user-interacted documents"
  - [section] "we leverage pre-trained language model encoders to retrieve concepts from a concept inventory K to describe the user documents"
  - [corpus] Weak - no direct corpus evidence supporting this specific retrieval mechanism
- Break condition: If the concept inventory lacks coverage of user interests or if the retrieval model cannot capture semantic meaning accurately, the profile becomes opaque or inaccurate

### Mechanism 2
- Claim: Personalized concept values improve recommendation quality
- Mechanism: LACE computes personalized concept values by optimally assigning user document sentences to profile concepts using Optimal Transport. This creates multi-vector user representations grounded in user content.
- Core assumption: The optimal transport assignment accurately captures which user content is most relevant to each concept
- Evidence anchors:
  - [abstract] "learns personalized representations of the concepts based on user documents"
  - [section] "To leverage features of user documents in representing the profile concepts, each concept is represented with a personalized concept value"
  - [corpus] Weak - no direct corpus evidence showing this assignment method specifically improves performance
- Break condition: If the optimal transport solution is unstable or the assignment doesn't reflect true relevance, personalization fails and recommendation quality degrades

### Mechanism 3
- Claim: User edits to concepts directly influence recommendations through concept-value coupling
- Mechanism: Since concept values are computed from concept embeddings, any user edits (add, remove, rename) trigger recomputation of personalized concept values, which updates the multi-vector user representation and downstream recommendations
- Core assumption: The concept encoder can effectively update concept embeddings based on user edits while maintaining semantic consistency
- Evidence anchors:
  - [abstract] "This design affords control over the recommendations through a number of intuitive interactions with a transparent user profile"
  - [section] "any user edits to the concept also update the personalized concept value"
  - [corpus] Weak - no direct corpus evidence showing the edit-to-recommendation pipeline works as described
- Break condition: If the concept encoder cannot properly update embeddings for new or edited concepts, or if the assignment mechanism doesn't adapt quickly enough, user edits won't effectively influence recommendations

## Foundational Learning

- Optimal Transport
  - Why needed here: Used to compute sparse assignments between user documents and profile concepts, and between user and candidate document representations
  - Quick check question: What is the primary objective function being optimized when using optimal transport to align two sets of vectors?
  - Answer: Minimize the total transport cost (typically sum of pairwise distances weighted by transport plan)

- Contrastive Learning
  - Why needed here: Used to train the document and concept encoders by maximizing similarity between related documents while pushing apart unrelated ones
  - Quick check question: In the recommendation loss function Lrec, what serves as the positive example when training on user u?
  - Answer: One of user u's interacted documents (treating it as a positive document for ranking)

- Sentence-level document representation
  - Why needed here: Documents are represented as sets of sentence vectors to capture finer-grained information, which then enables the concept-value bottleneck structure
  - Quick check question: Why does LACE represent documents as sets of sentence vectors rather than single document embeddings?
  - Answer: To capture more granular topical information that can be effectively assigned to specific concepts

## Architecture Onboarding

- Component map:
  - Document encoder (Enc_d) -> sentence vectors
  - Concept encoder (Enc_q) -> concept embeddings and user edits
  - Profile construction module -> retrieves concepts and computes personalized concept values
  - Ranking module -> computes Wasserstein distances between user and candidate document representations
  - Interaction interface -> handles user edits and positive/negative selections

- Critical path:
  1. User documents → Enc_d → sentence vectors
  2. Profile concepts → Enc_q → concept embeddings
  3. Optimal transport assignment → personalized concept values
  4. Candidate documents → Enc_d → sentence vectors
  5. Optimal transport ranking → recommendation scores

- Design tradeoffs:
  - Using sentence-level representations increases granularity but adds computational overhead
  - Optimal transport provides sparse, interpretable assignments but is more expensive than dot products
  - Separate concept and document encoders allow user edits but require careful alignment during training

- Failure signatures:
  - Profile concepts don't match user interests → check concept retrieval step and inventory coverage
  - Recommendations don't change after edits → check concept encoder update and value recomputation
  - Slow inference times → check optimal transport computation and consider ANN approximations

- First 3 experiments:
  1. Test profile construction: Given a small set of documents, verify that the retrieved concepts accurately capture their topics and that the profile changes appropriately with document edits
  2. Test concept personalization: With a fixed profile, verify that concept values change meaningfully when document content changes and that different users with same profile get different values
  3. Test interaction pipeline: Make edits to profile concepts and verify that recommendations update appropriately and that positive/negative selections work as expected

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different user interaction patterns with LACE's concept-based profile affect the quality and diversity of recommendations over time?
- Basis in paper: [explicit] The paper mentions that users can interact with LACE through positive/negative selection of concepts and profile edits, and that the study gathered tuning actions and recommended lists from users.
- Why unresolved: The paper's user study focused on short-term improvements in recommendation quality through interactions, but did not examine long-term patterns of how different interaction styles might affect recommendation diversity or user satisfaction over extended periods.
- What evidence would resolve it: Longitudinal studies tracking users' interaction patterns with LACE over weeks or months, measuring changes in recommendation diversity, novelty, and user satisfaction scores across different interaction styles.

### Open Question 2
- Question: How does the concept inventory size and quality affect LACE's performance across different domains and recommendation tasks?
- Basis in paper: [explicit] The paper mentions using different concept inventories per dataset (categories for TED Talks, user-contributed concepts for OpenReview, and extracted scientific concepts for CiteULike) and notes performance variations.
- Why unresolved: The paper does not systematically examine how the size, quality, or construction method of concept inventories impacts LACE's performance, leaving questions about optimal inventory design for different domains.
- What evidence would resolve it: Controlled experiments varying concept inventory sizes and construction methods across multiple domains, measuring LACE's recommendation performance and controllability metrics.

### Open Question 3
- Question: What are the computational trade-offs between using LACE as a full-ranker versus a re-ranker in large-scale production systems?
- Basis in paper: [explicit] The paper mentions that LACE can be used as a re-ranker for existing matrix factorization systems and briefly discusses the potential for ANN methods for Wasserstein distances.
- Why unresolved: While the paper demonstrates LACE's effectiveness, it does not provide a detailed analysis of the computational costs and trade-offs between using LACE as a primary ranker versus a re-ranker in real-world, large-scale systems.
- What evidence would resolve it: Comparative performance and latency analysis of LACE as both a full-ranker and re-ranker on large-scale datasets, including computational resource requirements and recommendation quality metrics.

## Limitations

- The concept retrieval mechanism lacks direct corpus validation for accuracy across diverse user interests
- The optimal transport assignment quality and its impact on personalization is not empirically validated
- The edit-to-recommendation pipeline responsiveness and robustness to various edit types remains unverified

## Confidence

- **High confidence**: The offline evaluation results showing LACE's superior performance across multiple recommendation tasks and settings (warm-start, cold-start, zero-shot) are well-supported by quantitative metrics
- **Medium confidence**: The user study demonstrating 20-47% improvement in ranking metrics through interactions is compelling but limited in scale and generalizability
- **Low confidence**: The claims about interpretability and controllability rely heavily on the assumption that retrieved concepts accurately capture user interests and that user edits effectively influence recommendations, which lacks direct corpus validation

## Next Checks

1. Verify concept retrieval coverage: Test whether the concept inventory can adequately represent diverse user interests by analyzing retrieval performance across different domains and user segments
2. Validate optimal transport assignment quality: Compare the learned concept assignments against human judgments of document-concept relevance to ensure the personalization captures true user interests
3. Test edit pipeline robustness: Systematically measure how different types of user edits (adding/removing concepts, editing concept names) affect recommendation quality and profile stability across multiple iterations