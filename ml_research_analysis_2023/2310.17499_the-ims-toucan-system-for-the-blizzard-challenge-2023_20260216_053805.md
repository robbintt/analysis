---
ver: rpa2
title: The IMS Toucan System for the Blizzard Challenge 2023
arxiv_id: '2310.17499'
source_url: https://arxiv.org/abs/2310.17499
tags:
- speech
- system
- challenge
- data
- french
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: We improved on our Blizzard Challenge 2021 system by adding a rule-based
  homograph disambiguation component for French. Our approach uses a text-to-phoneme
  module with rule-based disambiguation, a Conformer encoder and Glow decoder for
  spectrogram generation, and a GAN-based vocoder.
---

# The IMS Toucan System for the Blizzard Challenge 2023

## Quick Facts
- arXiv ID: 2310.17499
- Source URL: https://arxiv.org/abs/2310.17499
- Reference count: 0
- Key outcome: IMS Toucan system achieved 84% top-5 accuracy in French homograph disambiguation while ranking low in naturalness

## Executive Summary
The IMS Toucan system participated in the Blizzard Challenge 2023, focusing on building a French text-to-speech system with particular attention to homograph disambiguation. The system uses a rule-based approach for text-to-phoneme conversion with explicit homograph disambiguation, followed by a two-step spectrogram synthesis process using Conformer encoder and Glow decoder, and a GAN-based vocoder. While the system achieved high accuracy in homograph disambiguation (84%), it ranked low in naturalness evaluations, likely due to the deterministic prosody predictors and two-step synthesis process.

## Method Summary
The IMS Toucan system employs a rule-based text-to-phoneme processing approach with homograph disambiguation using espeak-ng and Wiktionary, followed by Conformer encoder and Glow decoder for spectrogram generation, and BigVGAN vocoder for waveform synthesis. The system includes pretraining on large female French datasets (MLS, SIWIS) followed by finetuning on challenge data, with explicit prosody modeling (pitch, energy, duration) per phone. Data processing includes text normalization, punctuation preservation, and speech enhancement on the AD dataset using a proprietary tool.

## Key Results
- Achieved top 5 accuracy of 84% in French homograph disambiguation
- Ranked low in naturalness evaluations despite high homograph disambiguation accuracy
- Demonstrated effectiveness of rule-based approach for homograph disambiguation in French

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Rule-based homograph disambiguation achieves high accuracy with simple linguistic knowledge
- Mechanism: Uses pre-built dictionary of French homographs with POS-tagged pronunciations combined with POET tagger for POS annotation during inference, enriched with morphological information and regex patterns for frequent words
- Core assumption: Most French homographs have distinct pronunciations correlating with POS tags or morphological features
- Evidence anchors: [abstract] rule-based text-to-phoneme processing with homograph disambiguation; [section 2.1] implementation details with espeak and Wiktionary; [section 3.6] 84% top-5 accuracy ranking

### Mechanism 2
- Claim: Two-step spectrogram synthesis with explicit prosody modeling provides data efficiency at the cost of naturalness
- Mechanism: Text-to-phonemes conversion followed by Conformer encoder/decoder with Glow postnet for spectrogram generation, then BigVGAN vocoder; prosody explicitly modeled per phone using averaged pitch, energy, duration values
- Core assumption: Spectrograms are sufficient intermediate representations and explicit prosody modeling is easier to learn than end-to-end approaches
- Evidence anchors: [abstract] transforms phonemes to spectrograms as intermediate representations; [section 2.4] FastSpeech 2 structure; [section 6] two-step procedure is data efficient but less natural

### Mechanism 3
- Claim: Pretraining on diverse female French speakers improves performance on low-resource single speaker tasks
- Mechanism: Pretrains on large female-only French datasets (MLS, SIWIS, etc.) then finetunes on challenge data, leveraging transfer learning to overcome data scarcity
- Core assumption: Speech characteristics are transferable between female French speakers and pretraining helps learn general patterns
- Evidence anchors: [section 3.5] female-only subset in pretraining data; [section 4] pretraining on large French datasets followed by finetuning; [section 7] performs best with cleanest data

## Foundational Learning

- Concept: Text-to-phoneme conversion with homograph disambiguation
  - Why needed here: French has many homographs with different pronunciations based on context, requiring accurate disambiguation for natural speech
  - Quick check question: What POS tag would "plus" likely have in the phrase "plus que jamais"?

- Concept: Spectrogram-based speech synthesis
  - Why needed here: Spectrograms provide interpretable intermediate representations that are easier to model than raw waveforms
  - Quick check question: What is the main advantage of using spectrograms over end-to-end approaches?

- Concept: Prosody modeling (pitch, energy, duration)
  - Why needed here: Natural speech requires varying prosody, which must be explicitly modeled when not using end-to-end approaches
  - Quick check question: Why does the system average pitch and energy values per phone rather than per frame?

## Architecture Onboarding

- Component map: Text → Phonemizer (espeak-ng) → Homograph Disambiguator → Articulatory Features → Conformer Encoder → Prosody Predictors → Conformer Decoder → PostNet (Flow) → Spectrogram → BigVGAN Vocoder → Waveform
- Critical path: Text → Phonemes → Spectrogram → Waveform (complete synthesis pipeline)
- Design tradeoffs:
  - Data efficiency vs. naturalness (explicit vs. end-to-end modeling)
  - Speed vs. quality (fully parallel vs. autoregressive)
  - Controllability vs. simplicity (explicit prosody vs. learned)
  - Rule-based vs. neural disambiguation (accuracy vs. flexibility)
- Failure signatures:
  - Poor naturalness: Check deterministic prosody predictors and two-step synthesis
  - Pronunciation errors: Check homograph disambiguation rules and phonemizer
  - Low similarity scores: Check speaker embedding selection and speech enhancement
  - Slow inference: Check GPU utilization and batching
- First 3 experiments:
  1. Test homograph disambiguation accuracy on held-out French text
  2. Compare spectrogram quality with different prosody predictor settings
  3. Evaluate vocoder quality with different training data configurations

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How much of the naturalness gap between the IMS Toucan system and end-to-end TTS models is due to the two-step synthesis process versus the deterministic prosody predictors?
- Basis in paper: The authors state that the two-step synthesis procedure using spectrograms as intermediate representations is known to be less natural than fully end-to-end systems, and that deterministic prosody predictors are a major bottleneck for naturalness.
- Why unresolved: The authors plan to address both shortcomings in future work but have not yet separated their individual contributions to the naturalness gap.
- What evidence would resolve it: A/B testing comparing the current system to versions with either neural audio codecs replacing spectrograms or stochastic variance predictors, while keeping other components constant.

### Open Question 2
- Question: Would a speech enhancement model that meets Blizzard Challenge rules (i.e., open-source and accessible via API) significantly improve the naturalness scores of the IMS Toucan system?
- Basis in paper: The authors used a proprietary speech enhancement tool on the AD dataset, which improved naturalness but may have slightly altered the voice. They tried open-source alternatives but found none satisfactory.
- Why unresolved: The authors did not find an open-source enhancement model with satisfactory results, but new models like Miipher have since been developed.
- What evidence would resolve it: Testing the IMS Toucan system with a high-quality open-source speech enhancement model on both datasets and comparing naturalness scores to the current system.

### Open Question 3
- Question: Can the IMS Toucan system's rule-based homograph disambiguation approach be effectively extended to other languages with complex homograph resolution requirements?
- Basis in paper: The authors achieved top 5 accuracy (84%) in French homograph disambiguation using a rule-based system built on linguistic expert knowledge, suggesting that simple systems can handle this task well if sufficient linguistic knowledge is available.
- Why unresolved: The paper only demonstrates the approach on French. Extending it to other languages would require adapting the rules and dictionaries to each language's specific homograph patterns.
- What evidence would resolve it: Implementing and testing the rule-based approach on another language with complex homograph resolution (e.g., English, German, or Chinese) and comparing accuracy to neural approaches.

## Limitations

- Major performance gap in naturalness compared to end-to-end systems, attributed to two-step synthesis and deterministic prosody predictors
- Reliance on proprietary speech enhancement tool for the AD dataset, limiting reproducibility
- Lack of empirical validation for pretraining benefits and specific architectural choices

## Confidence

- High Confidence: Rule-based homograph disambiguation mechanism (84% accuracy with clear implementation details)
- Medium Confidence: Two-step spectrogram synthesis approach (described but performance trade-offs based on general knowledge)
- Low Confidence: Pretraining benefits (logical but lacks direct experimental support)

## Next Checks

1. **Homograph Disambiguation Accuracy Validation**: Implement the described rule-based disambiguation system and evaluate its accuracy on a held-out French text corpus with known homograph pronunciations. Compare results with end-to-end neural approaches for the same task.

2. **Spectrogram Quality vs. End-to-End Comparison**: Train an end-to-end TTS model using the same pretraining data and compare naturalness scores with the two-step spectrogram approach. This would quantify the trade-off between data efficiency and naturalness claimed in the paper.

3. **Speaker Embedding Impact Analysis**: Evaluate the impact of the speaker embedding selection process on similarity scores by systematically varying the reference speaker embeddings used during inference and measuring the correlation with speaker similarity MOS scores.