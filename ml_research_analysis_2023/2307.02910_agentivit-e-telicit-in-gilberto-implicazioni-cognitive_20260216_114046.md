---
ver: rpa2
title: "Agentivit\xE0 e telicit\xE0 in GilBERTo: implicazioni cognitive"
arxiv_id: '2307.02910'
source_url: https://arxiv.org/abs/2307.02910
tags:
- modello
- task
- dell
- verbi
- parlanti
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This study investigated whether GilBERTo, an Italian transformer-based
  language model, can infer lexical semantics (telicity, agentivity) and use this
  information for morphosyntactic pattern completion. Behavioral data were collected
  from 65 Italian native speakers completing cloze tasks, and model outputs were compared
  to these human judgments.
---

# Agentività e telicità in GilBERTo: implicazioni cognitive

## Quick Facts
- arXiv ID: 2307.02910
- Source URL: https://arxiv.org/abs/2307.02910
- Reference count: 4
- GilBERTo correctly processes telicity as a scalar property but fails to capture context-dependent semantic phenomena like agentivity and argument individuation

## Executive Summary
This study investigates whether GilBERTo, an Italian transformer-based language model, can infer lexical semantics (telicity, agentivity) and use this information for morphosyntactic pattern completion. Behavioral data from 65 Italian native speakers completing cloze tasks were compared to model outputs. Results show that while GilBERTo correctly processes telicity as a scalar property consistent with linguistic theory, it fails to account for contextual influences such as argument individuation and consistently selects "inadvertently" regardless of verb type for agentivity detection, unlike human speakers who distinguish agentive from non-agentive contexts.

## Method Summary
GilBERTo, an Italian RoBERTa-based model trained on 71GB of Italian text (OSCAR corpus) with 32k BPE subwords, was evaluated on three cloze tasks using 60 sentences each. The first task tested telicity through preposition choice ("in" vs "per"), the second combined telicity with argument individuation in a factorial design, and the third tested agentivity through adverb selection ("inavvertitamente" vs "intenzionalmente"). Model predictions were compared against behavioral data from 65 Italian native speakers using median probability for model choices and top-5 predictions with probabilities for the first two tasks.

## Key Results
- GilBERTo correctly processes telicity as a scalar property, consistent with linguistic theory
- Model fails to account for contextual influences like argument individuation
- GilBERTo consistently selects "inadvertently" regardless of verb type for agentivity detection, unlike human speakers

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GilBERTo captures telicity as a scalar property through context-dependent lexical representation
- Mechanism: The model encodes verb semantics into distributed vectors where telicity emerges from co-occurrence patterns rather than explicit morphological marking
- Core assumption: Semantic properties like telicity are implicitly represented in the model's internal representations via distributional learning
- Evidence anchors:
  - [abstract] Results showed that GilBERTo correctly processed telicity as a scalar property, consistent with linguistic theory
  - [section] The comparison between the two groups of data allows us to investigate to what extent neural language models capture significant aspects of human semantic competence
  - [corpus] Weak: No direct citations or references to similar telicity modeling work in neighbors
- Break condition: If the model fails to differentiate telic vs atelic contexts beyond simple verb type classification, suggesting representation collapse

### Mechanism 2
- Claim: GilBERTo does not encode context-dependent semantic phenomena like argument individuation or agentivity
- Mechanism: The model relies primarily on lexical-level distributional patterns and cannot integrate sentence-level contextual cues that modify inherent verb semantics
- Core assumption: Neural language models trained on next-token prediction capture local lexical associations but struggle with global compositional semantics
- Evidence anchors:
  - [abstract] the model consistently selected "inadvertently" regardless of verb type, unlike human speakers who distinguished agentive from non-agentive contexts
  - [section] the model does not show the same sensitivity [to individuation] as human speakers
  - [corpus] Weak: Neighbors focus on semantic subdimensions and grounding but don't directly address argument structure sensitivity
- Break condition: If performance drops significantly when context-dependent modifiers are introduced beyond simple telicity tests

### Mechanism 3
- Claim: The model's morphosyntactic pattern completion relies on statistical regularities rather than true semantic inference
- Mechanism: GilBERTo matches input patterns to learned distributional templates without deep semantic reasoning about event structure or argument roles
- Core assumption: Cloze tasks measure pattern matching ability rather than genuine semantic understanding in transformer models
- Evidence anchors:
  - [section] The comparison between the two groups of data allows us to investigate to what extent neural language models capture significant aspects of human semantic competence
  - [section] the model does not show the same sensitivity [to individuation] as human speakers
  - [corpus] Weak: No direct evidence from neighbors about pattern completion vs semantic inference
- Break condition: If the model shows perfect performance on all cloze variants regardless of semantic complexity

## Foundational Learning

- Concept: Telicity as a scalar property
  - Why needed here: Understanding telicity as a continuum rather than binary is crucial for interpreting model behavior with configurational verbs
  - Quick check question: Can you explain why "disegnare" (to draw) might be telic in one context but atelic in another?

- Concept: Interface between semantics and syntax
  - Why needed here: Both telicity and agentivity act at the semantics-syntax interface, affecting morphosyntactic patterns
  - Quick check question: How does the choice between "in" vs "per" temporal expressions relate to telicity?

- Concept: Argument individuation
  - Why needed here: Individuation influences telicity interpretation and is a key difference between human and model performance
  - Quick check question: What properties make an argument "individuated" and how does this affect telicity?

## Architecture Onboarding

- Component map: Input sentences → tokenization → transformer layers → contextualized embeddings → output distribution over vocabulary for cloze completion
- Critical path: Masked sentence input → BPE tokenization → 12 RoBERTa transformer layers → final layer representations → vocabulary probability distribution for masked token
- Design tradeoffs: Larger vocabulary size enables better handling of Italian morphology but increases computational cost; masked LM objective captures local context but may miss global compositional semantics
- Failure signatures: Consistent selection of "inadvertently" regardless of verb type; failure to distinguish telic vs atelic contexts when argument individuation varies; perfect performance on inherently telic/atelic verbs but random selection for configurational verbs
- First 3 experiments:
  1. Test telicity discrimination with verbs where telicity is determined solely by context (no inherent telicity) to isolate context sensitivity
  2. Vary argument individuation systematically while keeping verb semantics constant to measure individuation effects
  3. Test agentivity detection with verbs that can be both agentive and non-agentive depending on context to probe context-dependent semantics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the precise nature of the semantic information encoded in distributional models regarding telicity and agentivity, and how does this encoding differ from human semantic processing?
- Basis in paper: [explicit] The paper discusses how GilBERTo captures telicity as a scalar property but fails to account for contextual influences like argument individuation and agentivity
- Why unresolved: The paper shows that while GilBERTo processes telicity in a way consistent with linguistic theory, it lacks sensitivity to context-dependent semantic phenomena. The exact nature of the semantic information encoded in distributional models and how it differs from human processing is not fully elucidated
- What evidence would resolve it: Comparative studies using different types of semantic tasks, including those that test context-dependent phenomena, could provide more insight into the nature of semantic information encoded in distributional models and how it compares to human processing

### Open Question 2
- Question: How do different architectures of transformer-based models (e.g., BERT, RoBERTa) affect the processing of telicity and agentivity?
- Basis in paper: [inferred] The paper mentions using GilBERTo, an Italian model based on RoBERTa, and FitBERT for the agentivity task. It suggests that the results might be influenced by the type of task or the use of FitBERT
- Why unresolved: The paper does not compare the performance of different transformer-based models on the same tasks, leaving open the question of how architecture influences the processing of these semantic properties
- What evidence would resolve it: Conducting the same experiments with different transformer-based models and comparing their performance on telicity and agentivity tasks would clarify the impact of architecture on semantic processing

### Open Question 3
- Question: How does the aspect of the verb (perfective vs. imperfective) influence the interpretation of telicity and agentivity in distributional models?
- Basis in paper: [explicit] The paper suggests that future work could include studying the influence of verbal aspect on sentence interpretation, noting that some languages grammaticalize telicity through aspectual opposition
- Why unresolved: The current study only considers verbs in the perfective aspect, and the influence of aspect on telicity and agentivity interpretation is not explored
- What evidence would resolve it: Including verbs in both perfective and imperfective aspects in the tasks and analyzing the model's performance on these tasks would provide insights into the role of aspect in semantic processing

## Limitations
- Lack of direct comparison with other neural language models makes findings unclear whether they are specific to GilBERTo or generalizable to transformer architectures
- FitBERT implementation for agentivity task introduces potential confounds regarding library compatibility with RoBERTa-based models
- Results may reflect distributional data sparsity rather than fundamental semantic gaps for configurational verbs

## Confidence
- High Confidence: The model's correct processing of telicity as a scalar property, consistent with linguistic theory and supported by direct behavioral comparisons
- Medium Confidence: The failure to capture argument individuation effects, as this finding is based on a factorial design but lacks replication with alternative semantic phenomena
- Low Confidence: The consistent selection of "inadvertently" for agentivity detection, as this could be an artifact of the FitBERT library implementation rather than a fundamental limitation of the model's semantic representations

## Next Checks
1. **Cross-model validation**: Replicate the telicity and agentivity experiments with multiple transformer architectures (BERT, GPT, mBERT) to determine if findings are model-specific or architecture-general
2. **Alternative implementation**: Implement the agentivity task using standard MLM inference rather than FitBERT to isolate whether the "inadvertently" bias stems from the model or the inference method
3. **Controlled generalization**: Test the model on novel verb types with explicit semantic annotations to determine whether performance degradation on configurational verbs reflects genuine semantic gaps or distributional data sparsity