---
ver: rpa2
title: Fixing the problems of deep neural networks will require better training data
  and learning algorithms
arxiv_id: '2311.12819'
source_url: https://arxiv.org/abs/2311.12819
tags:
- dnns
- vision
- neural
- biological
- visual
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Bowers et al. argued that deep neural networks (DNNs) are poor
  models of biological vision because they often learn to rival human accuracy by
  relying on strategies that differ markedly from those of humans.
---

# Fixing the problems of deep neural networks will require better training data and learning algorithms

## Quick Facts
- arXiv ID: 2311.12819
- Source URL: https://arxiv.org/abs/2311.12819
- Reference count: 31
- DNNs increasingly rely on strategies misaligned with human vision as they become larger and more accurate.

## Executive Summary
Deep neural networks have achieved human-level performance on object recognition tasks but often rely on visual features and strategies that differ significantly from those used by humans. As DNNs become larger and more accurate, their visual features and strategies become increasingly misaligned with human perception. The ClickMe paradigm reveals that humans categorize animals by faces and objects by diagnostic features like wheels and headlights, while DNNs often rely on background shortcuts. To address this issue, we propose methods including biologically-inspired data diets, objective functions like slow feature analysis, and integration of human-annotated feature importance maps into training objectives.

## Method Summary
The study employs the ClickMe paradigm to collect human feature importance maps for object recognition. These maps are integrated into DNN training through a "neural harmonizer" approach that weights the loss function based on human-selected diagnostic features. Additionally, the authors propose using biologically-inspired data diets generated through methods like Neural Radiance Fields and optimizing for objective functions that mimic biological vision constraints such as slow feature analysis and predictive coding. The approach aims to shift optimization away from background shortcuts toward features humans use for categorization.

## Key Results
- DNNs achieve human-level accuracy on ImageNet but rely on background features rather than diagnostic object features
- As DNNs become larger and more accurate, their visual features become increasingly misaligned with human strategies
- Humans categorize animals by faces and objects by diagnostic parts (wheels, headlights), while DNNs often use background shortcuts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: ClickMe data aligns DNNs with human visual strategies by forcing models to prioritize human-selected diagnostic features
- Mechanism: Human-annotated importance maps are integrated into training objectives, shifting optimization away from background shortcuts toward face/shape features
- Core assumption: The human-selected features are optimal for human-like generalization, not just human-annotated accuracy
- Evidence anchors:
  - "Our systematic evaluation using the ClickMe paradigm revealed that as DNNs become more accurate, their visual features and strategies become increasingly misaligned with those of humans"
  - "Our work indicates that the mismatch between DNN and biological vision identified by Bowers and colleagues is pervasive and worsening"
  - Weak or missing evidence
- Break condition: If human feature selection does not generalize beyond the ClickMe dataset or introduces biases that hurt real-world performance

### Mechanism 2
- Claim: Biologically-inspired data diets and objective functions can replace ClickMe data by embedding similar constraints during training
- Mechanism: Datasets that simulate first-person vision and objectives like slow feature analysis or predictive coding enforce temporal/spatial coherence akin to biological vision
- Core assumption: The temporal and multisensory integration present in biological vision can be approximated in artificial training environments
- Evidence anchors:
  - "We believe that the power of DNNs for biological vision is from their ability to generate computational- and algorithmic-level hypotheses about vision, which will guide experiments to identify plausible circuits"
  - "An alternative approach is to utilize advances in 3D computer vision, like Neural Radiance Fields, to generate spatiotemporal (stereo) datasets for training DNNs that are infinitely scalable and can be integrated with other modalities"
  - Weak or missing evidence
- Break condition: If the synthetic datasets fail to capture the richness of real-world visual experience or if the chosen objective functions do not converge to human-like representations

### Mechanism 3
- Claim: The increasing misalignment between DNN and human vision is a consequence of the engineering-driven optimization on static datasets that do not reflect ecological visual experience
- Mechanism: ImageNet and similar datasets reward background and texture shortcuts that maximize classification accuracy but diverge from biological feature selection
- Core assumption: Biological vision evolved under constraints and learning objectives that differ fundamentally from those used in standard DNN training
- Evidence anchors:
  - "For example, while humans categorize animals by their faces and inanimate objects like cars by their wheels and headlights, DNNs often rely on 'shortcuts' such as background features for object recognition"
  - "Our systematic evaluation using the ClickMe paradigm revealed that as DNNs become more accurate, their visual features and strategies become increasingly misaligned with those of humans"
  - Weak or missing evidence
- Break condition: If future datasets or architectures demonstrate that the observed misalignment is an artifact of current benchmarks rather than a fundamental limitation

## Foundational Learning

- Concept: Object recognition via diagnostic features
  - Why needed here: The paper's core observation is that humans and DNNs rely on qualitatively different features; understanding what makes a feature "diagnostic" is essential
  - Quick check question: Why do humans categorize animals by faces but DNNs by backgrounds?

- Concept: Training objective alignment
  - Why needed here: The paper proposes shifting from accuracy-maximizing objectives to those that mimic biological constraints
  - Quick check question: How does incorporating ClickMe data change the loss landscape compared to standard ImageNet training?

- Concept: Shortcut learning in neural networks
  - Why needed here: The paper attributes misalignment to shortcuts; understanding this phenomenon is key to diagnosing failures
  - Quick check question: What is a shortcut in DNNs and why do they emerge during training?

## Architecture Onboarding

- Component map:
  Input preprocessing -> Feature importance integration module -> Standard CNN backbone (e.g., ResNet/ViT) -> ClickMe-weighted loss -> Output classifier

- Critical path:
  Human-annotated ClickMe maps -> Loss weighting -> Feature map alignment -> Improved human-like representations

- Design tradeoffs:
  - Adding ClickMe data increases annotation burden but may improve alignment
  - Biologically-inspired datasets may reduce annotation cost but require complex simulation pipelines
  - Balancing between ImageNet accuracy and human feature alignment

- Failure signatures:
  - Model accuracy drops significantly when ClickMe data is incorporated
  - Human feature importance maps do not transfer to new object categories
  - The model still relies on background shortcuts despite ClickMe integration

- First 3 experiments:
  1. Train a baseline ResNet on ImageNet, then measure human vs. DNN feature alignment with ClickMe
  2. Fine-tune the same ResNet with ClickMe data and re-evaluate alignment
  3. Replace ImageNet with a Neural Radiance Fields-based dataset and compare alignment metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What are the most effective biologically-inspired objective functions that could replace standard training routines in DNNs to better align their visual strategies with human perception?
- Basis in paper: The authors propose optimizing for slow feature analysis and predictive coding as promising directions to help align DNNs with humans without relying on ClickMe data
- Why unresolved: Current objective functions are guided by engineering goals rather than biological plausibility, leading to misalignments between DNN and human visual strategies
- What evidence would resolve it: Comparative studies demonstrating improved alignment between human and DNN visual strategies when trained with biologically-inspired objective functions versus standard ImageNet-based training

### Open Question 2
- Question: How can we effectively scale up biologically-plausible data generation (e.g., using Neural Radiance Fields) to create sufficiently large and diverse training datasets that can improve DNN alignment with biological vision?
- Basis in paper: The authors suggest using Neural Radiance Fields to generate spatiotemporal datasets for training DNNs that are infinitely scalable and can be integrated with other modalities
- Why unresolved: While promising, there are technical challenges in scaling up biologically-plausible data generation methods and ensuring they capture the full complexity of human visual experience
- What evidence would resolve it: Successful demonstrations of DNNs trained on large-scale biologically-plausible datasets showing significantly improved alignment with human visual strategies and features

### Open Question 3
- Question: What specific architectural modifications inspired by neuroscience can be implemented in DNNs to improve their alignment with biological vision, beyond current methods like predictive coding and slow feature analysis?
- Basis in paper: The authors mention that mechanisms inspired by neuroscience can improve DNN capabilities, such as perceptual grouping, visual reasoning, and robust object recognition
- Why unresolved: While some neuroscience-inspired mechanisms have been proposed, there is a lack of comprehensive understanding of which specific architectural features would most effectively align DNNs with biological vision
- What evidence would resolve it: Empirical studies comparing the performance and biological alignment of DNNs with various neuroscience-inspired architectural modifications, identifying the most effective approaches

## Limitations
- The evidence linking larger, more accurate DNNs to increased misalignment is indirect and lacks direct longitudinal evidence across model generations
- ClickMe human feature importance maps cover only approximately 25% of ImageNet, limiting generalizability across all object categories
- Proposed solutions show theoretical promise but lack comprehensive validation demonstrating improved biological plausibility without sacrificing performance

## Confidence
- High confidence: The observation that humans and DNNs use different diagnostic features for object recognition (faces vs. backgrounds) is well-established and consistently supported
- Medium confidence: The claim that this misalignment is worsening with model scale, while intuitively compelling, lacks direct longitudinal evidence across model generations
- Medium confidence: The proposed solutions (ClickMe integration, biologically-inspired datasets) show theoretical promise but lack comprehensive validation demonstrating improved biological plausibility without sacrificing performance

## Next Checks
1. Conduct a systematic analysis of feature alignment across multiple model scales (small, medium, large DNNs) trained on identical datasets to directly test whether misalignment increases with scale
2. Perform ablation studies on the ClickMe integration method to determine the minimum human annotation burden required for meaningful alignment improvements
3. Test the proposed biologically-inspired data diets (Neural Radiance Fields) on established neural alignment benchmarks (e.g., Brain-Score) to quantify improvements in modeling biological vision beyond human feature correlation