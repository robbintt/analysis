---
ver: rpa2
title: Towards Generalization in Subitizing with Neuro-Symbolic Loss using Holographic
  Reduced Representations
arxiv_id: '2312.15310'
source_url: https://arxiv.org/abs/2312.15310
tags:
- loss
- images
- subitizing
- saliency
- object
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of subitizing, the cognitive
  ability to quickly and accurately recognize small counts of objects. Current deep
  learning models like CNNs and ViTs struggle with this task when using standard cross-entropy
  loss.
---

# Towards Generalization in Subitizing with Neuro-Symbolic Loss using Holographic Reduced Representations

## Quick Facts
- arXiv ID: 2312.15310
- Source URL: https://arxiv.org/abs/2312.15310
- Reference count: 12
- Primary result: HRR loss improves subitizing generalization compared to cross-entropy loss, particularly for CNNs

## Executive Summary
This paper addresses the challenge of subitizing - the cognitive ability to quickly and accurately recognize small counts of objects. Current deep learning models like CNNs and ViTs struggle with this task when using standard cross-entropy loss. To improve subitizing generalization, the authors propose a novel loss function based on Holographic Reduced Representations (HRRs), a tool from Cognitive Science. The HRR loss treats network logits as vectors and uses key-value pairs to represent classes, enabling more robust generalization. Experiments on carefully crafted tasks involving object size, shape, color, and boundary representation show that the HRR loss improves subitizing performance compared to cross-entropy loss, particularly for CNNs. ViTs also benefit, though to a lesser extent. Saliency maps reveal that HRR-based models focus on object boundaries, while cross-entropy models often activate on non-informative regions. While not a complete solution, the HRR loss demonstrates promise in enhancing subitizing generalization in deep learning models.

## Method Summary
The paper proposes using Holographic Reduced Representations (HRRs) as a loss function for subitizing tasks. Instead of predicting logits and using cross-entropy loss, the network predicts HRR vectors for each class. The loss function is defined by binding these predicted vectors to class-specific key vectors and comparing the result to value vectors. This approach treats the classification problem as a vector binding/unbinding task rather than a softmax approximation, theoretically enabling better generalization by learning compositional representations. The method is tested on both CNN and ViT architectures with synthetic datasets containing circles, triangles, and squares in varying configurations.

## Key Results
- HRR loss improves subitizing accuracy compared to cross-entropy loss, especially for CNNs
- HRR-based models show better generalization across size, shape, and color variations
- Saliency maps indicate HRR models focus on object boundaries while CE models activate on non-informative regions
- Performance improvement is more pronounced for CNNs than for ViTs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The HRR loss function improves subitizing generalization by treating network logits as vectors and binding them to class-specific key-value pairs.
- Mechanism: Instead of approximating one-hot encodings with softmax cross-entropy, the HRR loss interprets logits as holographic vectors. Each class count is associated with a unique key-value pair, and the network learns to predict the bound vector. Unbinding the predicted vector with the class key should yield the correct value, enabling symbolic-like manipulation while retaining differentiability.
- Core assumption: The binding and unbinding operations of HRRs are numerically stable and sufficient for representing class distinctions in a continuous vector space.
- Evidence anchors:
  - [abstract] "The HRR loss treats network logits as vectors and uses key-value pairs to represent classes"
  - [section] "To make sure that the network predicts the linked key-value pair associated with the input class of the image, the loss function is defined by Equation 1"
  - [corpus] Weak: No direct evidence of HRR binding/unbinding improving generalization in other papers in the corpus

### Mechanism 2
- Claim: The HRR loss function encourages attention to object boundaries rather than internal regions or background, improving generalization.
- Mechanism: The binding/unbinding process in HRRs may implicitly force the network to encode spatial or structural information that is more robust to changes in object appearance (size, shape, color). Saliency maps show HRR-based models focus on boundaries, while cross-entropy models activate on non-informative regions.
- Core assumption: The structure of the HRR binding operation captures boundary-relevant features better than standard classification losses.
- Evidence anchors:
  - [abstract] "Saliency maps reveal that HRR-based models focus on object boundaries, while cross-entropy models often activate on non-informative regions"
  - [section] "Consistently, the HRR loss puts strict focus on the edges of the objects whereas the CE loss spreads attention throughout the image"
  - [corpus] Missing: No corpus papers directly test boundary-focused saliency maps

### Mechanism 3
- Claim: The HRR loss function provides a continuous, differentiable alternative to symbolic reasoning, bridging connectionist and symbolic AI approaches.
- Mechanism: By representing classes as distributed holographic vectors, the HRR loss allows the network to learn compositional representations that can be manipulated symbolically (via binding/unbinding) while still being trained with gradient descent. This enables the network to generalize better to out-of-distribution cases.
- Core assumption: The compositional properties of HRRs (commutativity, associativity) are preserved during learning and are beneficial for the task.
- Evidence anchors:
  - [section] "Most VSAs use a fixed feature space for their representation, and thus necessarily introduce noise as more items are bound/unbound"
  - [section] "Many such VSAs exist today... For example, given vectors representing running, sleeping, cat, and dog, one can compose a vector x = bind(running, cat) + bind( sleeping, dog), and then generally determine which animal was sleeping by computing unbind(x, sleeping) â‰ˆ dog"
  - [corpus] Weak: Only one corpus paper mentions HRRs in the context of self-attention, not classification

## Foundational Learning

- Concept: Holographic Reduced Representations (HRRs)
  - Why needed here: The HRR is the core mechanism for the proposed loss function, enabling symbolic-like manipulation of distributed representations.
  - Quick check question: How does the binding operation in HRRs differ from simple vector addition?

- Concept: Vector Symbolic Architectures (VSAs)
  - Why needed here: HRRs are a type of VSA, and understanding the broader context of VSAs helps in appreciating the motivation for using HRRs.
  - Quick check question: What are the key properties that make VSAs suitable for combining connectionist and symbolic AI approaches?

- Concept: Saliency maps and their interpretation
  - Why needed here: Saliency maps are used to understand why the HRR loss function improves generalization, by revealing where the network focuses its attention.
  - Quick check question: How can you distinguish between spurious and informative attention in a saliency map?

## Architecture Onboarding

- Component map: Input images -> CNN/ViT backbone -> HRR prediction layer (tanh activation) -> HRR loss function (binding/unbinding with key-value pairs) -> Saliency map analysis

- Critical path:
  1. Preprocess input images
  2. Extract features with CNN/ViT backbone
  3. Predict HRR vectors in final layer
  4. Compute HRR loss based on key-value pairs
  5. Backpropagate gradients and update network
  6. Evaluate with saliency maps and accuracy

- Design tradeoffs:
  - Using HRR vectors instead of logits adds complexity but may improve generalization
  - Focusing on boundary attention may not always be beneficial
  - The HRR loss function requires careful initialization of key-value pairs

- Failure signatures:
  - Poor accuracy on in-distribution or out-of-distribution test sets
  - Saliency maps showing attention to non-informative regions
  - Numerical instability in binding/unbinding operations

- First 3 experiments:
  1. Train and evaluate on MNIST-like dataset with circles, test on same dataset (baseline)
  2. Train on circles, test on triangles (shape generalization)
  3. Train on circles, test on 50% larger circles (size generalization)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of HRR-based loss compare to other alternative loss functions for subitizing tasks?
- Basis in paper: [inferred] The paper compares HRR loss to standard cross-entropy loss but does not explore other potential loss functions.
- Why unresolved: The study focuses specifically on HRR as a neuro-symbolic approach but does not benchmark against other methods.
- What evidence would resolve it: Comparative experiments using alternative loss functions (e.g., focal loss, triplet loss) on the same subitizing tasks.

### Open Question 2
- Question: Can the HRR approach be extended to handle larger numbers of objects beyond 6?
- Basis in paper: [explicit] The paper mentions that performance decreases after 5 objects but does not explore scalability to higher counts.
- Why unresolved: The experiments are limited to 6 classes, leaving the upper bounds of HRR's effectiveness unexplored.
- What evidence would resolve it: Testing HRR-based models on datasets with more than 6 object classes and analyzing performance trends.

### Open Question 3
- Question: What is the impact of different HRR vector dimensions (H) on subitizing performance?
- Basis in paper: [explicit] The paper uses H=64 but does not systematically explore how varying this parameter affects results.
- Why unresolved: The choice of H=64 is arbitrary and not justified through experimentation.
- What evidence would resolve it: Experiments varying H across a range of values and analyzing the trade-off between model capacity and generalization.

### Open Question 4
- Question: How does the HRR approach perform on real-world subitizing tasks with natural images?
- Basis in paper: [inferred] All experiments use synthetic images with controlled properties, leaving real-world applicability unexplored.
- Why unresolved: The paper's focus on controlled experiments limits conclusions about real-world performance.
- What evidence would resolve it: Testing HRR-based models on natural image datasets with subitizing tasks (e.g., counting animals, vehicles).

## Limitations
- Limited evaluation scope with simple synthetic datasets and only 6 object classes
- No ablation studies to isolate specific contributions of HRR loss components
- Unclear whether boundary focus represents genuine understanding or overfitting

## Confidence
- High: The proposed HRR loss function improves subitizing performance compared to cross-entropy loss on the evaluated tasks.
- Medium: The HRR loss function encourages attention to object boundaries rather than internal regions or background, improving generalization.
- Low: The HRR loss function provides a continuous, differentiable alternative to symbolic reasoning, bridging connectionist and symbolic AI approaches.

## Next Checks
1. Evaluate on a more complex dataset with larger number of classes and more diverse object types
2. Perform ablation studies to isolate specific contributions of HRR loss components
3. Analyze saliency maps for different datasets to understand generalizability of boundary focus phenomenon