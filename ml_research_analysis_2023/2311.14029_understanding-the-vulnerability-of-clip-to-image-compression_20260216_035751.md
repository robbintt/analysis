---
ver: rpa2
title: Understanding the Vulnerability of CLIP to Image Compression
arxiv_id: '2311.14029'
source_url: https://arxiv.org/abs/2311.14029
tags:
- quality
- image
- clip
- gradients
- airplane
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: CLIP, a widely used vision-language model, is surprisingly sensitive
  to image compression, with its zero-shot recognition accuracy decreasing as image
  quality degrades. The authors use Integrated Gradients, an attribution method, to
  analyze how compression affects CLIP's predictions.
---

# Understanding the Vulnerability of CLIP to Image Compression

## Quick Facts
- arXiv ID: 2311.14029
- Source URL: https://arxiv.org/abs/2311.14029
- Reference count: 20
- Key outcome: CLIP's zero-shot recognition accuracy decreases significantly with image compression quality, with Integrated Gradients revealing pixel-level attribution changes

## Executive Summary
This paper investigates CLIP's surprising sensitivity to image compression quality in zero-shot image recognition tasks. Using Integrated Gradients, an attribution method, the authors analyze how JPEG compression affects CLIP's predictions across CIFAR-10 and STL-10 datasets. The study reveals that CLIP's precision scores decrease substantially as image quality degrades, with larger drops observed on CIFAR-10 compared to STL-10. The Integrated Gradients method provides both quantitative and qualitative insights into how compression impacts model predictions, offering a framework for understanding and potentially mitigating CLIP's vulnerability to image quality degradation.

## Method Summary
The authors evaluate CLIP's zero-shot classification performance on CIFAR-10 and STL-10 datasets using compressed images at quality factors of 75, 50, and 25. They employ Integrated Gradients to compute path integrals of cross-entropy loss between baseline (original quality) and compressed images, using a 50-step trapezoidal approximation. The method quantifies pixel-level attribution changes and visualizes them through overlays with red/green channels representing negative/positive gradient contributions. Precision scores are computed across different image encoders (ResNet variants and ViT) to assess architectural differences in compression robustness.

## Key Results
- CLIP's precision scores decrease significantly as image quality degrades, with larger drops observed for CIFAR-10 (from 87.44% to 70.41% at quality 25) compared to STL-10
- Integrated Gradients provides accurate approximations of changes in loss, with values correlating well with actual precision score decreases
- Visual overlays using Integrated Gradients effectively highlight regions of the image most affected by compression, with red indicating increased loss and green indicating decreased loss

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Integrated Gradients provides an accurate approximation of the change in loss due to image compression.
- Mechanism: By integrating the gradient of the loss function along a path from a baseline image (original quality) to a compressed target image, Integrated Gradients captures the pixel-level contribution to the loss change.
- Core assumption: The loss function is differentiable almost everywhere, and the path integral approximation is sufficiently accurate with a finite number of steps.
- Evidence anchors:
  - [abstract]: "We are able to better understand both quantitatively and qualitatively exactly the nature in which the compression affects the zero-shot recognition accuracy of this model."
  - [section]: "The formula (4) provides an approximation to the theoretic value of integrated gradients whose error is determined by the step size. We can observe from the values in Table 1 and 2 that the integrated gradients provide accurate approximations to changes in the loss."
- Break condition: If the loss function is not differentiable or the approximation error is too large with the chosen number of steps.

### Mechanism 2
- Claim: The visual overlay of Integrated Gradients highlights the regions of the image most affected by compression.
- Mechanism: By computing a weighted average of the image and the Integrated Gradients, with negative gradients shown in red and positive in green, the visualization reveals which pixels contribute most to the loss change.
- Core assumption: The color intensity accurately reflects the magnitude of the gradient, and the human visual system can interpret the overlay meaningfully.
- Evidence anchors:
  - [abstract]: "Using this attribution method, we are able to better understand both quantitatively and qualitatively exactly the nature in which the compression affects the zero-shot recognition accuracy of this model."
  - [section]: "We plot gradients with negative polarity using the red channel and those with the positive one using the green channel. Thus, red at a pixel location means that the reduction in the quality increases loss at this location, and similarly green means reduction in loss at this location."
- Break condition: If the overlay visualization is not interpretable or the color scheme does not accurately represent the gradient magnitude.

### Mechanism 3
- Claim: CLIP's vulnerability to image compression is encoder-dependent, with transformer-based encoders showing different robustness than ResNet-based encoders.
- Mechanism: The authors compare the precision scores across different image encoders (ResNet variants and ViT) and observe varying degrees of sensitivity to compression.
- Core assumption: The differences in precision scores are due to the architectural differences between the encoders, not other factors like training data or implementation details.
- Evidence anchors:
  - [abstract]: "We evaluate this extensively on CIFAR-10 and STL-10."
  - [section]: "We can observe that in the CIFAR-10 test, the precision scores decrease significantly as the image quality degrades in each case of the image encoder."
- Break condition: If the precision score differences are due to factors other than the encoder architecture, such as implementation details or training data.

## Foundational Learning

- Concept: Path integrals in calculus
  - Why needed here: Integrated Gradients is defined as a path integral of the model's output from a baseline input to a target input.
  - Quick check question: What is the fundamental theorem of calculus, and how does it relate to path integrals?

- Concept: Image compression and its effects on visual features
  - Why needed here: Understanding how JPEG compression degrades image quality is crucial to interpreting the results of the experiments.
  - Quick check question: How does the quantization step in JPEG compression affect the high-frequency components of an image?

- Concept: Attribution methods in deep learning
  - Why needed here: Integrated Gradients is an attribution method used to understand the contribution of input features to a model's prediction.
  - Quick check question: What are the axioms of sensitivity and implementation invariance, and why are they important for attribution methods?

## Architecture Onboarding

- Component map:
  - CLIP model: Consists of an image encoder (ResNet or ViT) and a text encoder
  - Image encoder: Processes the input image and produces a feature vector
  - Text encoder: Processes the text prompt and produces a feature vector
  - Contrastive loss: Measures the similarity between the image and text feature vectors

- Critical path:
  1. Load the image and apply JPEG compression at different quality levels
  2. Pass the compressed image through the image encoder to obtain feature vectors
  3. Pass the text prompt through the text encoder to obtain feature vectors
  4. Compute the dot product between the image and text feature vectors
  5. Select the label with the highest dot product as the predicted class
  6. Compute the precision score based on the predicted and true labels

- Design tradeoffs:
  - Using a fixed text prompt simplifies the evaluation but may not fully capture CLIP's capabilities
  - Resizing images to 224x224x3 ensures compatibility with CLIP but may introduce artifacts
  - Using a limited number of compression quality levels provides a clear trend but may miss intermediate effects

- Failure signatures:
  - Precision scores do not decrease as expected with lower image quality
  - Integrated Gradients values do not correlate with the change in loss
  - Visual overlays do not highlight the expected regions of the image

- First 3 experiments:
  1. Reproduce the precision score results for a single image encoder (e.g., ResNet50) on CIFAR-10
  2. Compute Integrated Gradients for a single image with different compression levels and visualize the results
  3. Compare the precision scores and Integrated Gradients results across multiple image encoders (e.g., ResNet50 and ViT-B/32) on CIFAR-10

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does CLIP's vulnerability to image compression vary across different model architectures (e.g., ResNet, ViT)?
- Basis in paper: [explicit] The authors demonstrate CLIP's sensitivity to image quality degradation across different image encoders (ResNet50, ResNet101, ViT-B/32, etc.) on CIFAR-10 and STL-10 datasets.
- Why unresolved: While the paper shows that precision scores decrease as image quality degrades, it doesn't provide a detailed comparative analysis of how different architectures respond to compression.
- What evidence would resolve it: A comprehensive study comparing the robustness of different CLIP architectures to image compression, including quantitative metrics and visual analysis.

### Open Question 2
- Question: Can the Integrated Gradients method be extended to analyze CLIP's vulnerability to other types of image perturbations (e.g., noise, blur, adversarial attacks)?
- Basis in paper: [explicit] The authors propose using Integrated Gradients to understand how changes in image quality affect CLIP's predictions, but they only focus on JPEG compression.
- Why unresolved: The paper does not explore the applicability of Integrated Gradients to other types of image perturbations.
- What evidence would resolve it: Experiments applying Integrated Gradients to various image perturbations and analyzing the resulting attributions to understand CLIP's vulnerability.

### Open Question 3
- Question: What are the underlying reasons for CLIP's vulnerability to image compression, and how can it be mitigated?
- Basis in paper: [inferred] The authors demonstrate CLIP's sensitivity to image quality degradation and use Integrated Gradients to analyze the impact of compression on predictions. However, they do not provide a detailed explanation for the observed vulnerability or propose mitigation strategies.
- Why unresolved: The paper focuses on analyzing the impact of compression on CLIP's predictions but does not delve into the underlying reasons or propose solutions.
- What evidence would resolve it: A study investigating the factors contributing to CLIP's vulnerability to compression and proposing techniques (e.g., data augmentation, architectural modifications) to improve its robustness.

## Limitations

- The evaluation focuses on only two datasets (CIFAR-10 and STL-10) with relatively small image sizes, which may not generalize to larger-scale or more diverse datasets.
- The study uses a fixed text prompt template rather than exploring prompt tuning or multiple prompt variants, potentially underestimating CLIP's robustness.
- The Integrated Gradients analysis relies on a finite-step approximation (50 steps) whose accuracy is not rigorously validated against theoretical convergence bounds.

## Confidence

**High Confidence**: The core finding that CLIP's zero-shot precision decreases with image compression quality is well-supported by the extensive experimental results across multiple image encoders and datasets. The quantitative precision score trends are robust and clearly documented.

**Medium Confidence**: The Integrated Gradients attribution method effectively approximates loss changes due to compression. While the method is theoretically sound and the implementation details are provided, the approximation error bounds are not rigorously evaluated.

**Low Confidence**: The claim that transformer-based encoders show different robustness than ResNet-based encoders requires more systematic investigation. The current analysis compares a limited set of encoders without controlling for other architectural differences or training variations.

## Next Checks

1. **Dataset Generalization**: Reproduce the precision score analysis on larger-scale datasets (ImageNet-1K or OpenImages) with varying image resolutions to test if the compression sensitivity pattern holds across more diverse visual domains.

2. **Prompt Robustness**: Evaluate CLIP's compression sensitivity using multiple prompt templates and prompt tuning approaches to determine if the observed vulnerability is consistent across different zero-shot classification strategies.

3. **Attribution Accuracy**: Validate the Integrated Gradients approximation by comparing the 50-step trapezoidal estimates against higher-step counts (e.g., 200 steps) and exact loss differences where computable, establishing error bounds for the attribution method.