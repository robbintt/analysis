---
ver: rpa2
title: 'SAGE: Smart home Agent with Grounded Execution'
arxiv_id: '2311.00772'
source_url: https://arxiv.org/abs/2311.00772
tags:
- tool
- device
- agent
- user
- sage
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces SAGE, a framework that integrates personal
  preferences, device states, and external information to perform complex tasks in
  a smart home setting. SAGE uses a hierarchical autonomous agent powered by large
  language models to coordinate a collection of tools.
---

# SAGE: Smart home Agent with Grounded Execution

## Quick Facts
- arXiv ID: 2311.00772
- Source URL: https://arxiv.org/abs/2311.00772
- Reference count: 32
- One-line primary result: SAGE achieves 51% success rate on complex smart home tasks, outperforming baselines at 30% success rate

## Executive Summary
This paper introduces SAGE, a hierarchical autonomous agent framework for smart home environments that integrates personal preferences, device states, and external information to perform complex tasks. SAGE uses a collection of specialized tools coordinated by a top-level LLM agent to handle device interactions, personalization, and persistent command execution. The system is evaluated on 43 challenging tasks, demonstrating significant improvements over existing LLM-based baselines in handling personalized, persistent, and multi-step smart home commands.

## Method Summary
SAGE implements a hierarchical autonomous agent architecture where a top-level agent coordinates specialized tools for device interaction, personalization, and condition code writing. The system integrates long-term memory of user interactions, dynamic user profiles, and on-demand API documentation retrieval to ground its responses in real device states and user preferences. The framework uses LLM prompts to orchestrate tool selection and execution, with each tool agent capable of accessing specific knowledge sources or external APIs to complete its designated function.

## Key Results
- SAGE achieves 51% success rate on 43 challenging smart home tasks, significantly outperforming baselines at 30% success rate
- Shows particular strength in personalized command execution and device disambiguation tasks
- Demonstrates capability for persistent command handling through generated monitoring code, though with lower success rates in this area

## Why This Works (Mechanism)

### Mechanism 1
- Claim: SAGE achieves higher success rates by integrating multiple grounded information sources through hierarchical agent architecture
- Mechanism: Top-level agent coordinates specialized tools for personalization, device interaction, and persistent command handling, with each tool accessing specific knowledge and returning structured outputs
- Core assumption: LLM can effectively orchestrate tools when provided with clear descriptions and structured prompts
- Evidence anchors: [abstract] hierarchical agent powered by LLMs to coordinate tools; [section 4] system implemented as hierarchical autonomous agent with LLM prompt templates and tool collections
- Break condition: If LLM cannot parse tool descriptions correctly or tool outputs are not structured in expected formats

### Mechanism 2
- Claim: Personalization achieved through hierarchical memory system retrieving relevant user interactions and maintaining dynamic profile
- Mechanism: Long-term memory stores chronological interactions as embeddings, user profiler aggregates daily summaries into global profile, personalization tool queries both to answer preference-based questions
- Core assumption: Dense retrieval embedding model can find relevant memories, LLM can synthesize information from memories and profile
- Evidence anchors: [section 5.1.1] Long-term memory stores user's past interactions and behavior; [section 5.1.2] user profile provides high-level summary of interactions to build dynamic understanding of preferences
- Break condition: If embedding model fails to retrieve relevant memories or LLM cannot synthesize information effectively

### Mechanism 3
- Claim: Flexible device interaction enabled by agent generating plans and retrieving API documentation on-demand
- Mechanism: Device interaction agent uses planner tool to generate steps, retrieves documentation for required capabilities, uses specialized tools to execute API calls, avoiding prompt length limitations
- Core assumption: LLM can generate reasonable plans from high-level descriptions and correctly format API calls when provided with retrieved documentation
- Evidence anchors: [section 5.2] device interaction tool implemented as agent generating high-level plan using device descriptions, retrieving detailed documentation for required capabilities; [section 5.2] format tool as wrapper around SmartThings REST API to query device state
- Break condition: If LLM cannot generate valid plans or documentation retrieval fails to provide necessary information

## Foundational Learning

- Concept: Hierarchical agent architecture
  - Why needed here: Enables modular integration of different capabilities while keeping prompts manageable
  - Quick check question: How does hierarchical structure differ from flat agent design, and what are the trade-offs?

- Concept: Tool description and prompt engineering
  - Why needed here: Tools must be described in way that allows LLM to understand when and how to use them effectively
  - Quick check question: What are key elements that should be included in tool description for optimal LLM usage?

- Concept: Memory-augmented LLM systems
  - Why needed here: Personalization requires storing and retrieving user preferences over time, beyond LLM's static knowledge
  - Quick check question: How does hierarchical memory system (short-term vs long-term) improve personalization compared to simple memory store?

## Architecture Onboarding

- Component map: Top-level SAGE agent → Tool coordination layer → Specialized agents (device interaction, personalization, condition code writing) → External APIs and data sources
- Critical path: User command → Top-level agent parsing → Tool selection → Specialized agent execution → API calls or data retrieval → Result aggregation → User response
- Design tradeoffs: Flexibility vs. complexity - adding more tools increases capability but requires more prompt engineering and coordination logic
- Failure signatures: Tool coordination failures (wrong tool selection), API interaction failures (incorrect parameter formatting), memory retrieval failures (irrelevant or no results)
- First 3 experiments:
  1. Test basic device control with simple commands to verify device interaction agent works
  2. Test personalization queries to verify memory and profile systems function correctly
  3. Test persistent command to verify condition code writing and polling mechanism works

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can performance of condition code writing tool be improved to reduce high failure rate in persistent command handling?
- Basis in paper: [explicit] Paper identifies condition code writing tool as least reliable component, contributing to lowest success rate in persistent commands
- Why unresolved: Paper suggests issue may be related to prompt length and degradation of model reasoning abilities as code complexity increases, but does not provide definitive solution
- What evidence would resolve it: Experimental results showing improved success rates in persistent commands after implementing strategies to manage prompt length or enhance code reasoning capabilities

### Open Question 2
- Question: What are potential benefits and challenges of integrating "code search" functionality to allow code-writing agent to interactively access documentation for thousands of open APIs?
- Basis in paper: [explicit] Paper suggests integrating "code search" functionality could greatly expand capability of code-writing approach
- Why unresolved: Paper does not explore practical implementation or impact of such feature on system's performance
- What evidence would resolve it: Comparative studies showing impact of code search functionality on success rates of complex tasks requiring diverse API interactions

### Open Question 3
- Question: How can device disambiguation process be improved to enhance accuracy and reliability?
- Basis in paper: [explicit] Paper identifies device disambiguation as area needing improvement, suggesting better CLIP models or captioning-based solutions
- Why unresolved: Paper does not provide specific methodologies or results for improving device disambiguation process
- What evidence would resolve it: Experimental results demonstrating improved success rates in device resolution tasks after implementing advanced disambiguation techniques

## Limitations

- Evaluation relies on single benchmark of 43 tasks that may not represent real-world complexity or edge cases
- Hierarchical agent architecture introduces multiple potential failure points where any specialized tool failure degrades overall performance
- Device disambiguation tool's reliance on visual language models introduces uncertainty about robustness across different device types and lighting conditions

## Confidence

- **High Confidence**: Basic architecture and tool coordination mechanism is well-described and implementable; hierarchical agent design with specialized tools is clearly articulated with transparent evaluation methodology
- **Medium Confidence**: Personalization mechanism and device interaction capabilities show promise, but lack of detailed prompt templates and tool descriptions makes exact replication challenging; memory-augmented personalization system is conceptually sound but implementation details are sparse
- **Low Confidence**: Device disambiguation tool and condition code writing mechanisms have least supporting detail; VLM-based device identification and persistent command polling infrastructure are described at high level without implementation specifics

## Next Checks

1. **Prompt Template Validation**: Extract and test actual prompt templates and tool descriptions used by SAGE against held-out set of smart home commands to verify LLM can correctly parse and execute intended tool coordination

2. **Device Disambiguation Robustness**: Conduct controlled experiments testing device disambiguation tool across varying lighting conditions, device orientations, and device types to quantify accuracy and identify failure patterns in visual language model component

3. **Memory System Effectiveness**: Design experiments comparing SAGE's hierarchical memory system against simpler alternatives (flat memory storage, no memory) on personalization tasks to quantify actual contribution of long-term memory and user profile components to task success rates