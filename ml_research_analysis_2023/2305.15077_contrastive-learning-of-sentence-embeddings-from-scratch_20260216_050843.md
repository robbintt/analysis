---
ver: rpa2
title: Contrastive Learning of Sentence Embeddings from Scratch
arxiv_id: '2305.15077'
source_url: https://arxiv.org/abs/2305.15077
tags:
- sentences
- sentence
- data
- simcse
- syncse-scratch
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'SynCSE proposes a contrastive learning framework that trains sentence
  embeddings using synthesized data from large language models (LLMs) like ChatGPT.
  It explores two approaches: (1) generating positive and negative annotations for
  existing sentences (SynCSE-partial), and (2) generating complete sentence triplets
  from scratch (SynCSE-scratch).'
---

# Contrastive Learning of Sentence Embeddings from Scratch

## Quick Facts
- arXiv ID: 2305.15077
- Source URL: https://arxiv.org/abs/2305.15077
- Reference count: 40
- Authors: -
- Key outcome: SynCSE achieves unsupervised performance on STS benchmarks comparable to supervised methods by generating synthetic contrastive pairs with ChatGPT

## Executive Summary
This paper introduces SynCSE, a novel approach to unsupervised sentence embedding learning that leverages large language models to synthesize training data. Instead of relying on human-annotated datasets or standard unsupervised contrastive methods, SynCSE prompts ChatGPT to generate positive and negative sentence pairs that preserve semantic relationships. The framework includes two variants: SynCSE-partial, which generates annotations for existing sentences, and SynCSE-scratch, which creates complete sentence triplets from scratch. Experimental results show that both approaches significantly outperform existing unsupervised baselines and that SynCSE-partial matches the performance of supervised models on the STS benchmark, marking the first time an unsupervised method achieves this level of performance.

## Method Summary
SynCSE builds on the SimCSE contrastive learning framework but replaces human-annotated data with synthetic data generated by ChatGPT. The method works by prompting the LLM to create positive (entailment) and negative (contradiction) pairs from either existing unlabeled sentences (SynCSE-partial) or from scratch based on specified genres and topics (SynCSE-scratch). The framework employs prompt pools and example pools to enhance diversity in the generated data, mitigating redundancy. The synthetic data is then used to train sentence encoders using the standard contrastive loss function. Evaluation is performed on STS benchmarks, reranking tasks, and transfer learning tasks to assess the quality of the learned embeddings.

## Key Results
- SynCSE-partial and SynCSE-scratch both significantly outperform unsupervised baselines on STS benchmarks
- SynCSE-partial achieves performance comparable to supervised models on STS benchmarks, representing the first unsupervised method to do so
- SynCSE models show strong performance on reranking tasks including AskUbuntuDupQuestions, MindSmallReranking, SciDocsRR, and StackOverflowDupQuestions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LLMs can generate high-quality positive and negative sentence pairs for contrastive learning without human annotation
- Mechanism: ChatGPT is prompted to generate entailment (positive) and contradiction (negative) pairs from either existing sentences or from scratch, leveraging its strong semantic understanding from pre-training
- Core assumption: ChatGPT's pre-training provides it with sufficient world knowledge and reasoning ability to create meaningful sentence pairs that preserve or invert semantic relationships
- Evidence anchors:
  - [abstract] "We propose to prompt large language models (LLMs) such as ChatGPT to synthesize the samples needed for contrastive learning."
  - [section 2.2] "We propose to prompt ChatGPT...to synthesize the required data in contrastive learning."
- Break condition: If ChatGPT lacks domain-specific knowledge or if the prompt engineering is poor, the generated pairs may not be semantically meaningful, breaking the contrastive learning assumption

### Mechanism 2
- Claim: Using prompt and example pools increases the diversity of synthetic data and mitigates redundancy
- Mechanism: By randomly sampling different prompts and few-shot examples for each generation, the framework introduces variation in outputs even for the same input, mimicking annotator diversity
- Core assumption: Variation in prompts and examples leads to diverse outputs, reducing the risk of overfitting to a single style or pattern
- Evidence anchors:
  - [section 2.3] "we employ example pools and prompt pools... to enhance the overall diversity of the dataset."
  - [section 2.4] "we employ a strategy that specifies the genres and topics when generation, combined with the utilization of example and prompt pools."
- Break condition: If the prompt and example pools are too small or too similar, the diversity gain is minimal, and the synthetic data may still be redundant

### Mechanism 3
- Claim: SynCSE-scratch enables training on domains with no available unlabeled data by generating both sentences and annotations from scratch
- Mechanism: ChatGPT is first prompted to generate unlabeled sentences based on specified genres and topics, then these sentences are annotated with positive and negative pairs
- Core assumption: The generated sentences are realistic and representative enough of the target domain to serve as valid training data
- Evidence anchors:
  - [abstract] "SynCSE-scratch, where large-scale unlabeled sentences are not available, prompting LLMs to generate sentences and their corresponding annotations from scratch."
  - [section 2.4] "Creating a synthetic dataset from scratch... presents a substantial challenge. We address this problem in two stages..."
- Break condition: If the generated sentences do not match the true data distribution, the model may learn spurious patterns and fail on real data

## Foundational Learning

- Concept: Contrastive learning in sentence embeddings
  - Why needed here: SynCSE builds directly on contrastive learning frameworks like SimCSE, using positive and negative pairs to train sentence embeddings
  - Quick check question: In contrastive learning, what is the goal of pulling positive pairs together and pushing negative pairs apart in embedding space?

- Concept: Few-shot prompting with LLMs
  - Why needed here: SynCSE uses few-shot examples to guide ChatGPT in generating semantically consistent positive and negative sentence pairs
  - Quick check question: Why is providing a few examples in the prompt important when asking an LLM to generate data with specific properties?

- Concept: Domain adaptation in representation learning
  - Why needed here: SynCSE-scratch addresses scenarios where in-domain unlabeled data is unavailable, requiring synthetic data to adapt models to new domains
  - Quick check question: What challenge does SynCSE-scratch solve that traditional unsupervised contrastive learning cannot?

## Architecture Onboarding

- Component map:
  - Unlabeled sentences or genre/topic specifications -> ChatGPT API with sampled prompts/examples -> Synthetic positive/negative pairs or complete triplets -> SimCSE-based contrastive learning trainer -> Sentence encoder model -> STS benchmarks, reranking tasks, transfer learning tasks

- Critical path:
  1. Generate synthetic data via LLM (either partial or scratch)
  2. Train sentence encoder using contrastive loss on synthetic data
  3. Evaluate embeddings on downstream tasks

- Design tradeoffs:
  - Using LLM-generated data vs human-labeled data: lower cost but potential quality variance
  - Prompt pool size vs generation efficiency: larger pools increase diversity but require more engineering
  - SynCSE-partial vs SynCSE-scratch: partial needs existing data but may be more domain-aligned; scratch works without data but may be less representative

- Failure signatures:
  - Poor STS/Spearman correlation scores indicate synthetic data quality issues
  - Low MAP in reranking tasks suggests domain mismatch
  - High variance in repeated runs may indicate unstable prompt sampling

- First 3 experiments:
  1. Generate a small synthetic dataset using SynCSE-partial and train a model; evaluate on STS benchmark to verify basic functionality
  2. Compare SynCSE-partial vs SynCSE-scratch on a domain with available unlabeled data to measure relative performance
  3. Vary the prompt pool size and example diversity; measure impact on STS scores to optimize data synthesis quality

## Open Questions the Paper Calls Out

- Question: How does the performance of SynCSE scale with the size of the synthetic dataset? Is there a point of diminishing returns?
- Basis in paper: [inferred] The paper mentions that SynCSE can easily scale up the dataset, but only ensures the data volume used for SynCSE-scratch and SynCSE-partial is equivalent to that of SimCSE_NLI for a fair comparison. It also notes that the performance of SynCSE-scratch ceases to increase after a certain amount of data is added.
- Why unresolved: The paper does not provide experiments that vary the amount of synthetic data used for training SynCSE. It only mentions the performance when using the same amount of data as SimCSE_NLI.

- Question: How does the diversity of the synthetic dataset affect the performance of SynCSE? Is there an optimal level of diversity?
- Basis in paper: [inferred] The paper mentions that diversity is a significant challenge in creating synthetic datasets and that it employs example and prompt pools to enhance diversity. It also notes that the combination of SynCSE-scratch with manually annotated datasets still facilitates further performance enhancement, suggesting that the synthetic data is complementary to real-world data.
- Why unresolved: The paper does not provide experiments that systematically vary the diversity of the synthetic dataset and measure the resulting performance. It also does not provide a clear definition or quantification of diversity.

- Question: How does the choice of prompts and examples affect the quality of the synthetic dataset and the performance of SynCSE?
- Basis in paper: [explicit] The paper mentions that it uses example and prompt pools to generate synthetic data and that it employs four types of positive/hard negative prompts and 18 few-shot exemplars.
- Why unresolved: The paper does not provide experiments that systematically vary the choice of prompts and examples and measure the resulting performance. It also does not provide a detailed analysis of how different prompts and examples affect the quality of the synthetic dataset.

## Limitations

- The quality and diversity of synthetic data heavily depends on prompt engineering and example pools, which are not fully specified in the paper
- The long-term stability and generalization of models trained on LLM-generated data remains unproven beyond the reported benchmarks
- The computational cost and latency of using ChatGPT for large-scale data synthesis is not discussed

## Confidence

- **High confidence**: The basic claim that LLM-synthesized data can improve contrastive learning for sentence embeddings is supported by strong experimental results
- **Medium confidence**: The specific mechanisms for ensuring data diversity through prompt pools are plausible but not empirically validated
- **Medium confidence**: The claim that SynCSE-partial matches supervised performance on STS is supported by results, but the comparison conditions need careful verification

## Next Checks

1. **Reproduce with smaller scale**: Generate a small synthetic dataset (e.g., 10k sentences) using SynCSE-partial and train a baseline model to verify the core approach works before scaling up
2. **Ablation on prompt diversity**: Systematically vary the prompt pool size and measure the impact on STS scores to quantify the benefit of diversity mechanisms
3. **Cross-domain generalization test**: Train on one domain using SynCSE-scratch and evaluate on a different but related domain to assess the quality and generality of the generated sentences