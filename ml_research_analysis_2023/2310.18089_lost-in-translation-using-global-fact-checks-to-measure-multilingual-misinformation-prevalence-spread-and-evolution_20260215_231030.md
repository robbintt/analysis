---
ver: rpa2
title: 'Lost in translation: using global fact-checks to measure multilingual misinformation
  prevalence, spread, and evolution'
arxiv_id: '2310.18089'
source_url: https://arxiv.org/abs/2310.18089
tags:
- misinformation
- claims
- fact-checks
- languages
- fact-checking
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper examines the prevalence and dynamics of multilingual
  misinformation through analysis of over 250,000 fact-checks in 95 languages. The
  authors use multilingual sentence embeddings to cluster semantically similar claims
  and analyze their evolution over time and across languages.
---

# Lost in translation: using global fact-checks to measure multilingual misinformation prevalence, spread, and evolution

## Quick Facts
- arXiv ID: 2310.18089
- Source URL: https://arxiv.org/abs/2310.18089
- Reference count: 40
- Primary result: Multilingual misinformation analysis reveals strong language homophily and greater semantic drift when claims cross language boundaries

## Executive Summary
This paper examines the prevalence and dynamics of multilingual misinformation through analysis of over 250,000 fact-checks in 95 languages. The authors use multilingual sentence embeddings to cluster semantically similar claims and analyze their evolution over time and across languages. They find that while most misinformation claims are only fact-checked once, 11.7% are checked multiple times, and 33% of repeated claims cross language barriers. Misinformation spreads predominantly within the same language, showing strong language homophily. The authors also show that misinformation claims change over time, with greater alteration when traversing languages. These findings advocate for expanded information sharing between fact-checkers globally while underscoring the importance of localized verification.

## Method Summary
The study combines 251,590 unique fact-checks from Google Fact-Check Explorer and IFCN-certified fact-checking organizations, covering March 2020 to March 2022. Fact-checks are embedded using LaBSE multilingual sentence embeddings, clustered based on cosine similarity, and analyzed as a graph where semantically similar claims are linked. The authors examine connected components to identify repeated claims, analyze shortest paths to measure evolution, and study language family patterns to understand cross-lingual spread.

## Key Results
- 11.7% of misinformation claims are fact-checked multiple times
- 33% of repeated claims cross language barriers
- 80.7% of multilingual claims occur within the same language family
- Claims undergo greater semantic drift when crossing language boundaries
- Misinformation spreads predominantly within the same language (strong homophily)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Multilingual fact-checks can be clustered and matched across languages using sentence embeddings.
- Mechanism: LaBSE multilingual sentence embeddings map semantically similar claims into a shared vector space, enabling cosine similarity-based clustering regardless of language.
- Core assumption: Claims in different languages about the same misinformation share enough semantic similarity to be mapped close in embedding space.
- Evidence anchors:
  - [abstract] "We represent fact-checks with multilingual sentence embeddings and build a graph where semantically similar claims are linked."
  - [section 4] "To compare misinformation spread across languages, we embedded all fact-checks with Language-agnostic BERT Sentence Embedding (LaBSE) [12]."
  - [corpus] "Multilingual vs Crosslingual Retrieval of Fact-Checked Claims: A Tale of Two Approaches" supports crosslingual claim retrieval methods.
- Break condition: If LaBSE fails to capture nuanced meaning differences across languages, semantically similar claims may be embedded far apart, breaking clustering.

### Mechanism 2
- Claim: Misinformation changes more when crossing language boundaries.
- Mechanism: Claims undergo greater semantic drift along cross-lingual paths in the similarity graph due to cultural or linguistic reframing, resulting in higher dissimilarity between multilingual versions.
- Core assumption: Language switches introduce additional transformation steps beyond temporal evolution, amplifying semantic changes.
- Evidence anchors:
  - [abstract] "We analyze connected components and shortest paths connecting different versions of a claim finding that claims gradually drift over time and undergo greater alteration when traversing languages."
  - [section 5.3] "Both the number of unique languages and the number of language switches are highly significant predictors of change in the cosine similarity."
  - [corpus] "A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification" indicates translation affects claim fidelity.
- Break condition: If cultural or linguistic reframing does not significantly alter semantic content, cross-lingual drift may be indistinguishable from temporal drift.

### Mechanism 3
- Claim: Most misinformation spreads within the same language, showing strong homophily.
- Mechanism: Network analysis of fact-check clusters reveals higher edge density within languages than between languages, indicating language-based assortativity.
- Core assumption: Misinformation diffusion patterns mirror language-based social network structures, leading to stronger intra-language connectivity.
- Evidence anchors:
  - [abstract] "However, spreading patterns exhibit strong assortativity, with misinformation more likely to spread within the same language or language family."
  - [section 5.2] "We find that 33.79% of misinformation claims that are fact-checked more than once are checked in multiple languages. Nevertheless, misinformation still diffuses predominantly within the same language."
  - [corpus] Corpus neighbors include "WhatsApp Tiplines and Multilingual Claims in the 2021 Indian Assembly Elections," showing multilingual claim analysis.
- Break condition: If misinformation spreads via cross-language platforms or bilingual users at scale, language homophily may weaken.

## Foundational Learning

- Concept: Multilingual sentence embeddings and cosine similarity.
  - Why needed here: Enables clustering and comparison of claims across 95 languages in a unified vector space.
  - Quick check question: What embedding model was chosen and why?
- Concept: Graph clustering via connected components.
  - Why needed here: Groups semantically similar fact-checks into clusters representing the same misinformation claim.
  - Quick check question: How are clusters extracted from the similarity graph?
- Concept: Language family mapping.
  - Why needed here: Distinguishes intra-family from inter-family cross-lingual spread patterns.
  - Quick check question: How are languages assigned to families in the analysis?

## Architecture Onboarding

- Component map: Data ingestion → preprocessing → LaBSE embedding → approximate nearest neighbor search (LSH/ANNOY) → similarity thresholding → connected component extraction → analysis modules (temporal, cross-lingual, token frequency)
- Critical path: Embed fact-checks → build similarity graph → extract clusters → analyze evolution and cross-lingual spread
- Design tradeoffs: High cosine threshold (0.875) favors precision over recall; using LaBSE over smaller multilingual models covers more low-resource languages but may sacrifice some semantic granularity
- Failure signatures: High singleton ratio suggests embeddings are too strict; low inter-cluster distances indicate embeddings collapse distinct claims
- First 3 experiments:
  1. Run clustering with cosine threshold 0.75, 0.875, 0.95 and compare cluster sizes and intra-cluster variance
  2. Measure change in cosine similarity over time for monolingual vs multilingual paths
  3. Analyze token frequency differences between singleton and non-singleton clusters

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the specific language families and their associated misinformation claims interact, and are there unique patterns of misinformation spread within certain language families that are not present in others?
- Basis in paper: [explicit] The paper mentions that 80.7% of multilingual claims were found within languages belonging to the same language family, indicating a potential interaction between language families and misinformation spread.
- Why unresolved: The paper provides a general observation of language family influence but does not delve into the specific interactions and patterns within each language family.
- What evidence would resolve it: A detailed analysis of misinformation claims within each language family, identifying unique patterns and interactions, and comparing these patterns across different language families.

### Open Question 2
- Question: What are the underlying mechanisms that drive the evolution of misinformation claims over time, and how do these mechanisms differ when claims spread across languages?
- Basis in paper: [explicit] The paper shows that misinformation claims change over time and undergo greater alteration when traversing languages, but the specific mechanisms behind this evolution are not explored.
- Why unresolved: The paper identifies the phenomenon of claim evolution but does not investigate the underlying reasons or mechanisms causing these changes.
- What evidence would resolve it: Research into the specific factors and processes that influence the evolution of misinformation claims, including a comparative study of evolution within the same language versus across different languages.

### Open Question 3
- Question: How effective are current fact-checking practices in addressing multilingual misinformation, and what improvements can be made to enhance their effectiveness across different languages and cultures?
- Basis in paper: [inferred] The paper highlights the importance of local fact-checkers and global cooperation, suggesting that current practices may have limitations in addressing multilingual misinformation effectively.
- Why unresolved: The paper discusses the need for improved fact-checking practices but does not evaluate the effectiveness of current methods or propose specific improvements.
- What evidence would resolve it: An evaluation of current fact-checking practices across different languages and cultures, identifying their strengths and weaknesses, and developing strategies to enhance their effectiveness in a multilingual context.

## Limitations
- Fact-check dataset may have selection bias, as not all misinformation is fact-checked and coverage varies across languages and regions
- Clustering approach using cosine similarity thresholds may miss nuanced variations in claims or create false connections between semantically distinct misinformation
- Study focuses on fact-checked claims rather than all misinformation, limiting generalizability to the full misinformation ecosystem

## Confidence
- Language homophily findings: Medium
- Cross-lingual claim evolution: High  
- Temporal drift patterns: Medium
- Multilingual clustering accuracy: Low-Medium

## Next Checks
1. Validate clustering results by manually reviewing a random sample of cross-lingual claim pairs to assess semantic similarity accuracy
2. Test robustness of findings using alternative embedding models (e.g., XLM-R) and varying cosine similarity thresholds
3. Conduct sensitivity analysis on temporal drift measurements by comparing results across different time window sizes and claim age ranges