---
ver: rpa2
title: 'ULTRA-DP: Unifying Graph Pre-training with Multi-task Graph Dual Prompt'
arxiv_id: '2310.14845'
source_url: https://arxiv.org/abs/2310.14845
tags:
- task
- pre-training
- graph
- node
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes ULTRA-DP, a unified graph pre-training framework
  that addresses the semantic gap between pre-training and downstream tasks. It introduces
  a dual prompt mechanism with task and position embeddings to guide GNNs in learning
  task-specific and position-specific knowledge.
---

# ULTRA-DP: Unifying Graph Pre-training with Multi-task Graph Dual Prompt

## Quick Facts
- **arXiv ID**: 2310.14845
- **Source URL**: https://arxiv.org/abs/2310.14845
- **Reference count**: 40
- **Primary result**: Achieves average relative performance gains of 1.9%–4.4% over baselines on five datasets

## Executive Summary
ULTRA-DP addresses the semantic gap between graph pre-training and downstream tasks by introducing a unified framework with a dual prompt mechanism. The approach uses virtual prompt nodes carrying task and position embeddings to guide GNNs in learning task-specific and position-specific knowledge. By combining edge prediction with a novel k-NN similarity prediction task, ULTRA-DP captures multi-grained structural knowledge. The framework includes a prompt-based transferability test to identify the most relevant pre-training task for downstream fine-tuning. Extensive experiments on five datasets demonstrate significant performance improvements over existing methods.

## Method Summary
ULTRA-DP introduces a unified graph pre-training framework that injects task identification and position identification into GNNs through a dual prompt mechanism. For each input graph, virtual prompt nodes are attached as task tokens, where the feature represents a trainable task embedding determined by the type of pre-training task. The framework combines classical edge prediction (node-node level) with a novel k-NN similarity prediction task (node-group level) to learn richer multi-grained structural knowledge. A prompt-based transferability test identifies the most relevant pretext task to reduce semantic gap. The approach is agnostic to specific GNN architectures and supports various pre-training tasks.

## Key Results
- ULTRA-DP achieves average relative performance gains of 1.9%–4.4% over baselines across five datasets
- The dual prompt mechanism effectively reduces semantic interference between different pretext tasks
- k-NN similarity prediction complements edge prediction by capturing broader structural patterns
- Performance improves with larger training sets, demonstrating the framework's scalability

## Why This Works (Mechanism)

### Mechanism 1
Dual prompt nodes enable GNNs to distinguish task-specific and position-specific knowledge during pre-training, reducing semantic interference between different pretext tasks. The virtual prompt nodes carry task embeddings and position embeddings that guide the GNN to condition its representations on specific pretext tasks and node positions. This separation allows the GNN to learn task-independent global knowledge while preserving task-specific patterns. The core assumption is that task and position information can be effectively encoded in virtual nodes without disrupting the GNN's neighborhood aggregation process.

### Mechanism 2
The k-NN similarity prediction task at the node-group level complements edge prediction at the node-node level, enabling the learning of richer multi-grained structural knowledge. By maximizing similarity between a node and its k nearest neighbors while minimizing similarity to other k further nodes, the framework captures both local and broader structural patterns. This multi-scale approach provides a more comprehensive understanding of graph structure than single-scale tasks alone. The core assumption is that combining tasks at different scales can provide richer structural insights.

### Mechanism 3
Prompt-based transferability test identifies the most relevant pre-training task for a given downstream task, reducing the semantic gap and improving fine-tuning performance. The test uses each pre-trained task embedding to initialize the one for the downstream task, fine-tunes the model on the training set, and selects the best initialization based on validation performance. The core assumption is that task embeddings learned during pre-training contain transferable knowledge that can be leveraged for downstream tasks.

## Foundational Learning

- **Graph Neural Networks (GNNs) and message-passing**: ULTRA-DP builds upon GNNs and leverages their ability to aggregate neighborhood information. Understanding how GNNs aggregate information from a node's neighborhood is crucial for grasping the prompt node mechanism. *Quick check: How do GNNs aggregate information from a node's neighborhood, and what are the key components of this process?*

- **Self-supervised learning and pretext tasks**: ULTRA-DP uses self-supervised learning to capture transferable graph semantics. Familiarity with pretext tasks like edge prediction and contrastive learning is essential for understanding the proposed k-NN similarity prediction task. *Quick check: What are some common pretext tasks used in graph pre-training, and how do they help the model learn useful representations?*

- **Prompt tuning in NLP**: ULTRA-DP is inspired by prompt tuning in NLP. Understanding how prompts work in NLP and how they guide pre-trained models to focus on specific tasks is important for grasping the concept of prompt nodes. *Quick check: How do prompts in NLP help bridge the gap between upstream and downstream tasks, and what are the different types of prompts used?*

## Architecture Onboarding

- **Component map**: Input graph with node features -> Virtual prompt nodes (task and position embeddings) -> GNN backbone (e.g., GAT, GCN, SAGE) -> Pre-training tasks (edge prediction, k-NN similarity prediction) -> Prompt-based transferability test -> Fine-tuning head (similarity prediction for node classification)

- **Critical path**: 1) Pre-train GNN with ULTRA-DP framework using hybrid tasks 2) Perform prompt-based transferability test to select the best task embedding 3) Fine-tune GNN on downstream task using the selected task embedding

- **Design tradeoffs**: Complexity vs. performance (additional components vs. better performance), Flexibility vs. specificity (framework agnostic to GNN architecture but requires hyperparameter tuning)

- **Failure signatures**: Poor downstream performance (prompt nodes not effectively guiding GNN), High variance in results (position encoding or k-NN similarity prediction not stable across graph structures)

- **First 3 experiments**: 1) Implement ULTRA-DP with edge prediction only and compare to vanilla edge prediction on Cora 2) Add k-NN similarity prediction and evaluate impact on downstream performance 3) Perform prompt-based transferability test on validation set and verify it selects best task embedding

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the framework's limitations and the broader research context, several open questions emerge regarding scalability to larger graphs, extension to dynamic graphs, and comprehensive evaluation across diverse GNN architectures.

## Limitations
- Additional computational overhead from prompt nodes and transferability tests compared to simpler pre-training approaches
- Effectiveness heavily depends on proper hyperparameter tuning, particularly for position encoding and k-NN parameters
- Results may not generalize to graphs with significantly different characteristics beyond the five benchmark datasets
- Limited ablation studies on the sensitivity of downstream performance to pre-training task selection

## Confidence

**High Confidence**: The core mechanism of dual prompt nodes (task and position embeddings) is well-supported by the paper's theoretical framework and experimental results. The improvement over baseline methods across multiple datasets is statistically significant.

**Medium Confidence**: The transferability test mechanism shows promise, but the paper provides limited ablation studies on how sensitive downstream performance is to the choice of pre-training task.

**Medium Confidence**: The k-NN similarity prediction task is novel and shows improvement, but the paper does not provide extensive ablation studies on how the reachability step affects performance across different graph structures.

## Next Checks

1. **Ablation on Prompt Components**: Remove either the task prompt or position prompt from ULTRA-DP and measure the impact on downstream performance to quantify the contribution of each component.

2. **Sensitivity Analysis on k-NN Parameters**: Systematically vary the reachability step and number of anchors in the k-NN similarity prediction task to determine the optimal configuration for different graph types.

3. **Generalization Test**: Evaluate ULTRA-DP on a dataset with significantly different characteristics (e.g., citation graphs vs. social networks) to assess the framework's robustness across graph domains.