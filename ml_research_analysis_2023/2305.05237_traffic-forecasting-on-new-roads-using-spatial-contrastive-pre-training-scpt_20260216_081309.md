---
ver: rpa2
title: Traffic Forecasting on New Roads Using Spatial Contrastive Pre-Training (SCPT)
arxiv_id: '2305.05237'
source_url: https://arxiv.org/abs/2305.05237
tags:
- spatial
- roads
- forecasting
- data
- training
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of forecasting traffic on new
  roads not seen during training. The authors introduce a novel setup called a spatio-temporal
  (ST) split to evaluate models' capabilities on unseen roads.
---

# Traffic Forecasting on New Roads Using Spatial Contrastive Pre-Training (SCPT)

## Quick Facts
- arXiv ID: 2305.05237
- Source URL: https://arxiv.org/abs/2305.05237
- Reference count: 40
- Key outcome: Introduces SCPT framework for traffic forecasting on unseen roads, showing consistent improvements across four real-world datasets

## Executive Summary
This paper addresses the challenge of forecasting traffic on new roads not seen during training by introducing a novel setup called spatio-temporal (ST) split. The authors propose a framework called Spatial Contrastive Pre-Training (SCPT) that uses contrastive learning to extract latent features from unseen roads during inference. By decoupling traffic signals into periodic and Markovian components and integrating learned spatial features through a spatially gated addition (SGA) layer, SCPT demonstrates significant improvements in forecasting performance on unseen roads, with greater benefits for longer forecasting horizons.

## Method Summary
The paper introduces a spatio-temporal split evaluation setup where models are trained on some roads and tested on entirely new roads. SCPT employs a spatial encoder pre-trained with contrastive learning to extract meaningful spatial representations from historical traffic data. This encoder is frozen and used during inference to generate latent features for unseen roads. The framework incorporates an SGA layer to effectively integrate spatial information with the backbone model while decoupling traffic signals into periodic (modeled by DCT) and Markovian components to focus on difficult-to-capture patterns.

## Key Results
- SCPT consistently outperforms baseline models on all four real-world datasets (METR-LA, PeMS-BAY, PeMS-D7(m), PeMS-11k(s))
- Improvements are more pronounced for longer forecasting horizons
- The framework demonstrates robust generalization to unseen roads with at least 2 days of historical data
- Ablation studies show the importance of each component (spatial encoder, SGA layer, signal decoupling)

## Why This Works (Mechanism)

### Mechanism 1: Contrastive Pre-training for Generalization
The spatial encoder learns robust latent representations through contrastive learning on historical traffic data. By maximizing agreement between stochastic views of the same sensor's data while ensuring dissimilarity between different sensors, the encoder captures meaningful spatial patterns that transfer to unseen roads. This mechanism relies on the assumption that contrastive learning can effectively learn generalizable spatial representations from limited historical data.

### Mechanism 2: Spatially Gated Addition Layer
The SGA layer enables effective integration of learned spatial features with the backbone model by modulating the amount of spatial information injected at each layer. Using a gating mechanism with per-sensor scalars, the SGA layer prevents the naive summation problem where the same amount of spatial information is injected uniformly. This allows different layers to receive appropriate amounts of spatial context based on their specific needs.

### Mechanism 3: Signal Decoupling for Focused Learning
By decoupling traffic signals into periodic (trivial-to-capture) and Markovian (difficult-to-capture) components using DCT, the spatial encoder can focus on learning complex temporal dependencies rather than periodic patterns. This is particularly valuable for unseen roads with limited data, as it ensures the encoder learns the more challenging aspects of traffic patterns without being distracted by easily modelable periodic components.

## Foundational Learning

- **Spatio-temporal graph representation**: Traffic networks are modeled as graphs with sensors as nodes and adjacency matrices representing topological connectivity. This is fundamental to how traffic forecasting models capture spatial relationships between different road segments.
  - Quick check: How would you represent a traffic network with 100 sensors as a spatio-temporal graph, and what would the adjacency matrix look like?

- **Contrastive learning and InfoNCE loss**: The spatial encoder is pre-trained using contrastive learning with NT-Xent (InfoNCE) loss to learn meaningful spatial representations. This technique maximizes agreement between different views of the same data while pushing apart representations of different data points.
  - Quick check: What is the difference between NT-Xent loss and other contrastive loss functions, and why is temperature scaling important in NT-Xent?

- **Discrete Cosine Transform for signal decomposition**: DCT is used to separate periodic traffic patterns from Markovian components, allowing the spatial encoder to focus on complex temporal dependencies. This mathematical technique transforms time series data into frequency domain components.
  - Quick check: How does DCT decompose a time series into frequency components, and how would you determine which coefficients to keep for periodic signal reconstruction?

## Architecture Onboarding

- **Component map**: Spatial Encoder -> SGA Layer -> Backbone Model (GWN) -> Forecasting Output
- **Critical path**:
  1. Pre-train spatial encoder using contrastive loss on historical data from training roads
  2. Freeze spatial encoder weights and use it to generate latent representations for unseen roads
  3. During inference, combine backbone model with spatial encoder outputs via SGA layers
  4. Use inferred node embeddings from spatial encoder for adaptive adjacency matrix construction

- **Design tradeoffs**:
  - Simple WaveNet encoder vs. more sophisticated architectures (better performance vs. complexity)
  - 2-day minimum data requirement for unseen roads (practical vs. potential performance limitations)
  - Uniform sampling in ST split vs. stratified sampling (simplicity vs. potential bias)

- **Failure signatures**:
  - Performance degradation on unseen roads indicates poor generalization of spatial encoder
  - Overfitting to training roads suggests insufficient regularization or too few training samples
  - Unstable training with contrastive loss indicates improper temperature or batch size

- **First 3 experiments**:
  1. Baseline GWN performance on ST split without SCPT to establish baseline degradation on unseen roads
  2. SCPT with all components enabled to verify overall performance improvement
  3. Ablation study removing SGA layer to quantify its contribution to performance

## Open Questions the Paper Calls Out

### Open Question 1: Spatial Encoder Architecture
How would the performance of SCPT change if we used a more sophisticated spatial encoder architecture, such as ts2vec or r-drop? The paper states that SCPT is agnostic to the exact architecture of the spatial encoder and suggests exploring more sophisticated encoders like ts2vec and r-drop in future work. This remains unresolved because the paper only implemented a simple WaveNet-based encoder.

### Open Question 2: Generalization to Other Domains
Can SCPT generalize to other multivariate time series domains beyond traffic forecasting, such as electricity or gas usage? The paper mentions that forecasting using SCPT can be generalized to any multivariate time series beyond just traffic and suggests that more research is required in this direction. This remains unresolved because the paper only evaluated SCPT on traffic datasets.

### Open Question 3: Sampling Strategy Optimization
How would the performance of SCPT change if we used a different sampling strategy for the spatio-temporal split, such as stratified sampling or clustering-based sampling? The paper used uniform random sampling for the spatio-temporal split and mentioned that a more sophisticated sampling strategy might further improve performance. This remains unresolved because the paper only tested uniform random sampling.

## Limitations
- Requires at least 2 days of historical data for unseen roads, which may not always be available in real-world scenarios
- Evaluation focuses primarily on performance metrics without extensive analysis of computational overhead or real-time applicability
- Ablation studies could be more comprehensive to isolate the contributions of individual components

## Confidence
- **High confidence**: Effectiveness of contrastive pre-training for unseen road generalization (supported by consistent improvements across all datasets)
- **Medium confidence**: SGA layer's contribution (while ablation shows benefit, the mechanism could be better explained)
- **Medium confidence**: Decoupling approach (DCT-based periodic signal extraction is standard, but its specific implementation for this task lacks detailed validation)

## Next Checks
1. Evaluate the minimum data requirement for unseen roads by testing performance with varying amounts of historical data (less than 2 days)
2. Conduct stress tests with extreme scenarios such as roads with highly irregular traffic patterns or during special events
3. Compare computational overhead of SCPT against baseline models to assess practical deployment feasibility