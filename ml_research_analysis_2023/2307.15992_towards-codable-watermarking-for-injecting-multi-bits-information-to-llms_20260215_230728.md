---
ver: rpa2
title: Towards Codable Watermarking for Injecting Multi-bits Information to LLMs
arxiv_id: '2307.15992'
source_url: https://arxiv.org/abs/2307.15992
tags:
- text
- watermarking
- watermark
- message
- information
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the limitation of existing LLM watermarking
  methods which can only encode 1 bit of information, by introducing the first systematic
  study on Codable Text Watermarking for LLMs (CTWL). The core idea is to use a proxy
  language model to split the vocabulary into probability-balanced parts, thereby
  effectively maintaining the quality of the watermarked text.
---

# Towards Codable Watermarking for Injecting Multi-bits Information to LLMs

## Quick Facts
- arXiv ID: 2307.15992
- Source URL: https://arxiv.org/abs/2307.15992
- Authors: 
- Reference count: 12
- Key outcome: Introduces the first systematic study on Codable Text Watermarking for LLMs (CTWL), achieving better performance in watermarking success rate, robustness, and text quality compared to direct baseline.

## Executive Summary
This paper addresses the fundamental limitation of existing LLM watermarking methods that can only encode 1 bit of information by introducing a novel Codable Text Watermarking approach. The key innovation is Balance-Marking, which uses a proxy language model to create probability-balanced vocabulary partitions, enabling multi-bit watermark encoding while maintaining text quality. The method demonstrates superior performance across multiple evaluation metrics including success rate, robustness against various attacks, and text quality preservation.

## Method Summary
The proposed method uses a proxy language model (e.g., GPT-2) to split vocabulary into probability-balanced parts based on accumulated probability thresholds. For each token position, the method selects a subset of tokens likely to contain high model logits, ensuring both watermark encoding capability and text quality maintenance. The encoding algorithm can automatically bypass low-entropy text segments, improving efficiency. Different messages are encoded using hash functions that create distinguishable probability distributions across vocabulary subsets, enabling multi-bit information injection while preserving the fluency and coherence of generated text.

## Key Results
- Balance-Marking achieves higher watermarking success rates compared to baseline methods
- The method demonstrates improved robustness against substitution, copy-paste, and paraphrasing attacks
- Text quality (measured by perplexity) is better maintained compared to random vocabulary partitioning approaches
- The approach successfully encodes multi-bit information while preserving text fluency

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Balance-Marking method improves text quality by using a proxy language model to create probability-balanced vocabulary partitions.
- Mechanism: Instead of randomly splitting vocabulary as in Vanilla-Marking, Balance-Marking uses a proxy-LM to select tokens whose accumulated probability exceeds a threshold (σ = 0.5), ensuring both high model logits and message logits are present.
- Core assumption: The proxy-LM's probability distribution approximates the original LLM's distribution closely enough to maintain text quality.
- Evidence anchors:
  - [abstract]: "The core idea of our method is to use a proxy language model to split the vocabulary into probability-balanced parts, thereby effectively maintaining the quality of the watermarked text."
  - [section 4.2.2]: "To accomplish this, we are motivated to utilize the model logit distributionPLLM(xprompt, t:(l−1)) as prior knowledge, and select a subset of tokens that is likely to contain some token v with a high model logit in advance."

### Mechanism 2
- Claim: The watermark encoding algorithm can bypass low-entropy text segments automatically.
- Mechanism: When a token has near-certain prediction probability (close to 1.0), it will be included in the available token list for all messages, effectively skipping watermark encoding in deterministic sections.
- Core assumption: Low-entropy segments are predictable and don't need watermarking, so skipping them improves efficiency without sacrificing information capacity.
- Evidence anchors:
  - [section 4.2.3]: "This may implicitly help the watermark algorithm to skip low-entropy segments of text... which further ensures the robustness and text quality of our method."
  - [section 4.2.3]: "For example, consider a special situation in which there is only one reasonable token candidate, whose predicted probability by proxy-LM is almost 1.0."

### Mechanism 3
- Claim: The message function Pw design allows encoding multi-bit information by creating distinguishable distributions across messages.
- Mechanism: The method assigns different subsets of vocabulary to different messages using hash functions, creating sufficiently different Pw distributions so that the message logits can effectively encode information.
- Core assumption: The hash function creates sufficiently diverse token subsets across different messages to maintain distinguishability.
- Evidence anchors:
  - [section 4.2.1]: "To ensure such differences in Pw(m, t:(l−1)) with different m, we can assign random values for Pw(m, t:(l−1)) based on the random seeds directly decided by their own m"
  - [section 4.2.2]: "the case when all{PLLM(v|xprompt, t:(l−1))|v ∈ Vm,t:(l−1) } values tend to be small, yet still sum to σ, is very unlikely to occur"

## Foundational Learning

- Concept: Lagrange Multipliers for constrained optimization
  - Why needed here: The watermark encoding problem requires balancing text quality (measured by perplexity) with message encoding success, which is a constrained optimization problem.
  - Quick check question: What does the dual variable λ represent in the Lagrange formulation for watermark encoding?

- Concept: Perplexity as text quality metric
  - Why needed here: The method uses perplexity to ensure watermarked text quality remains comparable to original text, serving as the constraint in optimization.
  - Quick check question: How does the method ensure that PPL(t|xprompt) ≤ PPL(tori|xprompt) + ϵ during encoding?

- Concept: Vocabulary partitioning for watermarking
  - Why needed here: The core technique involves splitting vocabulary into available/unavailable parts to encode watermark information without degrading text quality.
  - Quick check question: Why does probability-balanced partitioning perform better than random partitioning for text quality?

## Architecture Onboarding

- Component map: LLM (OPT-1.3B) -> Text Generation -> Proxy-LM (GPT2) -> Vocabulary Partitioning -> Token Selection -> Watermarked Text Output

- Critical path: Prompt → LLM generation with watermarking → Proxy-LM vocabulary partitioning → Token selection with message logits → Watermarked text output

- Design tradeoffs:
  - Higher coding rate vs text quality degradation
  - Stronger watermark vs increased computational cost
  - Proxy-LM accuracy vs efficiency
  - Message space size vs decoding complexity

- Failure signatures:
  - High perplexity indicating poor text quality
  - Low Successm indicating watermark detection failure
  - Long encoding/decoding times indicating inefficiency
  - High substitution attack impact indicating poor robustness

- First 3 experiments:
  1. Compare Balance-Marking vs Vanilla-Marking on text quality (perplexity) under fixed coding rate
  2. Test robustness against substitution attacks with varying substitution ratios
  3. Measure encoding/decoding time overhead with different proxy-LM sizes

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of CTWL methods scale with larger LLMs and different model architectures?
- Basis in paper: [explicit] The authors note that their experimental base models do not cover all model scales, and conclusions may be affected by the scaling law. They plan to supplement more experimental results on models of different sizes and structures in future versions.
- Why unresolved: The current study only uses OPT-1.3B for experiments. Larger and more diverse models like GPT-4 or different architectures may exhibit different watermarking behaviors and challenges.
- What evidence would resolve it: Conducting experiments on a range of LLMs with varying sizes (e.g., 7B, 30B, 175B parameters) and architectures (e.g., transformer variants, recurrent models) to compare watermarking success rates, robustness, and text quality impacts.

### Open Question 2
- Question: What are the limitations of CTWL methods in handling paraphrase attacks, and how can these be overcome?
- Basis in paper: [explicit] The authors acknowledge that their method performs poorly against paraphrase attacks, which is a significant threat to all watermarking methods. They express interest in developing watermarking algorithms that can resist paraphrase attacks.
- Why unresolved: Paraphrase attacks can completely reconstruct the original text, potentially destroying the watermark patterns. Current CTWL methods rely on specific token choices and vocabulary partitions that may not survive paraphrasing.
- What evidence would resolve it: Developing and testing new CTWL algorithms that incorporate semantic embeddings or contextual features to maintain watermark integrity across paraphrased versions of the text. Evaluating these methods against various paraphrasing techniques and measuring their success rates.

### Open Question 3
- Question: How can CTWL methods be extended to non-natural language domains like code, logic problems, and structured data?
- Basis in paper: [explicit] The authors mention that their current evaluation datasets are limited to the natural text domain. They plan to explore and construct more diverse watermarking evaluation benchmarks, including code segments, logic problems, and more fine-grained natural texts in future versions.
- Why unresolved: Natural language has different statistical properties and generation patterns compared to code or structured data. Existing CTWL methods may not be directly applicable or effective in these domains.
- What evidence would resolve it: Creating domain-specific CTWL algorithms tailored to the unique characteristics of code (e.g., syntax, semantics), logic problems (e.g., formal structures, reasoning patterns), and structured data (e.g., schema adherence, data types). Testing these algorithms on representative datasets from each domain and comparing their performance to baseline methods.

## Limitations

- Heavy dependence on proxy-LM accuracy for vocabulary partitioning, with no validation of sensitivity to proxy-LM mismatch
- Limited evaluation scope to OPT-1.3B model and natural text domain, lacking scalability analysis for larger models and longer sequences
- Poor performance against paraphrase attacks, which can completely reconstruct original text and destroy watermark patterns

## Confidence

**High Confidence**: The theoretical framework of using Lagrange multipliers for constrained optimization and the basic vocabulary partitioning concept. The mathematical foundations are sound and well-established in the watermarking literature.

**Medium Confidence**: The empirical results showing Balance-Marking outperforming Vanilla-Marking. While the experimental setup appears rigorous, the relatively small scale (OPT-1.3B, limited datasets) and lack of ablation studies on critical hyperparameters (σ, proxy-LM architecture) reduce confidence in the generalizability of the findings.

**Low Confidence**: Claims about real-world applicability and performance on longer sequences or more complex LLM architectures. The paper doesn't provide evidence beyond the tested configuration, making it difficult to assess practical deployment scenarios.

## Next Checks

1. **Proxy-LM Sensitivity Analysis**: Systematically test the method's performance using different proxy-LMs (varying sizes, architectures, and training data) to quantify how much proxy-LM mismatch degrades text quality and watermark success rate. Measure the correlation between proxy-LM accuracy metrics and watermarking performance.

2. **Long Sequence and Large Message Space Scaling**: Evaluate the encoding/decoding time complexity and watermark success rate for sequences 10x longer than tested and message spaces 100x larger. Measure memory usage and identify the practical limits of the current implementation.

3. **Adversarial Attack Resistance**: Design and test targeted attacks that specifically attempt to remove or corrupt watermarks while preserving text semantics. Include model fine-tuning attacks where the adversary fine-tunes the LLM on watermarked text to learn to generate unwatermarked outputs, measuring the watermark's resilience to such training-based removal attempts.