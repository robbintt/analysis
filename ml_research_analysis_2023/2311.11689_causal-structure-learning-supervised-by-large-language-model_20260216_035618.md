---
ver: rpa2
title: Causal Structure Learning Supervised by Large Language Model
arxiv_id: '2311.11689'
source_url: https://arxiv.org/abs/2311.11689
tags:
- causal
- constraints
- data
- prior
- causality
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses causal structure learning (CSL) from observational
  data, focusing on deriving causal Directed Acyclic Graphs (DAGs) from data. It tackles
  challenges like vast DAG spaces and data sparsity.
---

# Causal Structure Learning Supervised by Large Language Model

## Quick Facts
- **arXiv ID**: 2311.11689
- **Source URL**: https://arxiv.org/abs/2311.11689
- **Reference count**: 34
- **Primary result**: Iterative LLM Supervised Causal Structure Learning (ILS-CSL) outperforms existing LLM-driven CSL methods across eight real-world datasets, particularly as the number of variables increases.

## Executive Summary
This paper addresses the challenge of causal structure learning (CSL) from observational data by introducing an innovative framework that integrates Large Language Models (LLMs) into the learning process. The proposed method, ILS-CSL, iteratively refines causal Directed Acyclic Graphs (DAGs) using LLM feedback to validate edge accuracy. By focusing LLM supervision only on the edges of learned DAGs, ILS-CSL efficiently reduces erroneous constraints and generates more robust structural constraints compared to previous methodologies. The approach demonstrates superior performance across eight real-world datasets, particularly excelling as network complexity increases.

## Method Summary
ILS-CSL is an iterative framework that combines score-based causal structure learning algorithms (MINOBSx or CaMML) with LLM supervision. The method learns an initial DAG from observational data, then uses LLMs to validate each edge in the learned structure. LLM responses are converted into structural constraints (edge existence, absence, or directionality), which are applied to refine the DAG in subsequent iterations. The process continues until no new constraints are added. The framework offers both hard constraints (guaranteeing compliance) and soft constraints (robust to errors) approaches, with edge-level constraints proving more powerful than ancestral constraints for improving CSL quality.

## Key Results
- ILS-CSL consistently outperforms existing LLM-driven CSL methods across eight real-world datasets
- The method demonstrates superior scalability as the number of variables increases
- Scaled Structural Hamming Distance (SHD) improves over iterations, with most substantial improvement occurring in the first round
- Edge-level constraints from LLMs prove more effective than ancestral constraints for refining causal structures

## Why This Works (Mechanism)

### Mechanism 1
ILS-CSL reduces erroneous constraints by focusing LLM supervision only on edges of the learned DAG rather than performing full pairwise variable inference. This reduces LLM calls by a factor of ~1.8(N-1) compared to full pairwise inference, assuming the learned DAG is sparse and contains mostly correct edges.

### Mechanism 2
Edge-level constraints are more powerful than ancestral constraints for improving CSL because they directly specify edge existence or absence, eliminating more incorrect structures in the search space. Ancestral constraints only constrain paths and may still allow erroneous edges.

### Mechanism 3
Iterative refinement with LLM feedback improves learned DAG quality by progressively adding constraints that correct edge directionality or remove spurious relationships. The process converges when no new constraints are added, with most improvement occurring in the first iteration.

## Foundational Learning

- **Concept**: Causal Bayesian Networks (CBNs) and their distinction from standard Bayesian Networks
  - Why needed here: Understanding that edges in CBNs represent causal relationships (not just probabilistic dependencies) is fundamental to the task of causal structure learning and why LLM supervision is valuable.
  - Quick check question: What additional requirement does a CBN have compared to a standard BN, and why is this important for causal inference?

- **Concept**: Constraint-based vs. score-based causal structure learning
  - Why needed here: ILS-CSL uses a score-based approach (MINOBSx and CaMML) as its backbone, so understanding how these methods work and differ from constraint-based methods is important for grasping the framework.
  - Quick check question: How do score-based methods optimize the DAG structure, and what role do prior constraints play in this optimization?

- **Concept**: Structural constraints in causal discovery (edge existence, ordering, ancestral)
  - Why needed here: ILS-CSL converts LLM inferences into edge-level structural constraints. Understanding the different types of constraints and their relative strengths is crucial for understanding the methodology.
  - Quick check question: Why are edge existence constraints more powerful than ancestral constraints, and what is the implication chain for different constraint types?

## Architecture Onboarding

- **Component map**: Observed data and textual descriptions -> Score-based CSL algorithm -> LLM validation -> Constraint application -> Iterative loop

- **Critical path**:
  1. Learn initial DAG from data using score-based CSL
  2. For each edge in DAG, query LLM to validate causal relationship
  3. Convert LLM responses into structural constraints
  4. Re-learn DAG using constraints (hard or soft approach)
  5. Repeat until no new constraints are added

- **Design tradeoffs**:
  - Hard constraints vs. soft constraints: Hard constraints guarantee compliance but are brittle to errors; soft constraints are more robust but may not always be satisfied
  - Number of iterations: More iterations could lead to better DAGs but increase computational cost
  - LLM inference quality vs. efficiency: Restricting inference to edges reduces errors but might miss some causal information

- **Failure signatures**:
  - Non-convergence: Iterative process continues indefinitely or oscillates between DAGs
  - Performance degradation: Scaled SHD increases over iterations
  - Excessive constraints: Too many constraints make the search space empty or very small

- **First 3 experiments**:
  1. Run ILS-CSL on a small dataset (e.g., Cancer with 250 samples) and verify that it improves upon data-based CSL (MINOBSx or CaMML)
  2. Compare the number of LLM inferences required by ILS-CSL vs. full pairwise inference on a medium-sized dataset
  3. Test ILS-CSL with both hard and soft constraint approaches on a dataset and compare their performance

## Open Questions the Paper Calls Out

- **Open Question 1**: What is the optimal number of iterations for ILS-CSL to converge in different datasets and sizes?
  - Basis: The paper discusses iterative trends of scaled SHD and TPR, noting that most cases require a limited number of iterations and that the most substantial improvement occurs in the first round.
  - Why unresolved: The paper does not specify an exact number of iterations for convergence, and it varies across different datasets and sizes.
  - What evidence would resolve it: Empirical studies showing the convergence point of ILS-CSL across various datasets and sizes.

- **Open Question 2**: How does the performance of ILS-CSL scale with the increase in the number of variables beyond the tested datasets?
  - Basis: The paper mentions that ILS-CSL demonstrates superior performance, especially as the number of variables increases, but does not provide results for datasets with more variables than tested.
  - Why unresolved: The experiments are limited to datasets with up to 48 variables, and the paper does not discuss scalability beyond this point.
  - What evidence would resolve it: Experiments with datasets containing a larger number of variables to test the scalability of ILS-CSL.

- **Open Question 3**: What are the potential biases introduced by LLM-based causal inferences, and how can they be mitigated?
  - Basis: The paper discusses the reduction of erroneous constraints by ILS-CSL but does not delve into the nature of biases that LLMs might introduce.
  - Why unresolved: While the paper addresses the reduction of errors, it does not explore the underlying biases of LLM inferences and their implications.
  - What evidence would resolve it: Analysis of LLM inferences across various domains to identify and quantify biases, followed by strategies to mitigate them.

## Limitations

- The framework relies heavily on LLM inference accuracy, which may vary across domains and introduce cascading errors
- Computational overhead remains significant for very large networks despite reduced LLM calls compared to full pairwise inference
- The method assumes sparsity of learned DAGs and accuracy of edge-level LLM inference, which may not hold in all real-world scenarios

## Confidence

- **High Confidence**: The mathematical analysis of constraint reduction and the fundamental advantage of edge constraints over ancestral constraints
- **Medium Confidence**: The iterative refinement mechanism and overall performance improvements shown in experimental results
- **Low Confidence**: The generalizability of LLM-based causal inference across different domains and long-term stability of iterative processes

## Next Checks

1. **Edge Error Propagation Analysis**: Conduct controlled experiments where known incorrect edges are introduced into the learned DAG, then track how these errors propagate through subsequent LLM queries and iterations.

2. **Constraint Type Comparison**: Systematically compare ILS-CSL's edge-level constraints against ancestral and ordering constraints across identical datasets and iterations.

3. **Domain Transfer Testing**: Apply ILS-CSL to datasets from domains not represented in the current evaluation (e.g., social sciences, economics, or environmental systems) to assess generalizability of LLM-based causal inference.