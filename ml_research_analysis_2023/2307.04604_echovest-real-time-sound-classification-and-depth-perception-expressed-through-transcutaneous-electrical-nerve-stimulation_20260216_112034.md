---
ver: rpa2
title: 'EchoVest: Real-Time Sound Classification and Depth Perception Expressed through
  Transcutaneous Electrical Nerve Stimulation'
arxiv_id: '2307.04604'
source_url: https://arxiv.org/abs/2307.04604
tags:
- sound
- classification
- hearing
- noise
- echovest
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: EchoVest is a cost-effective wearable device that helps individuals
  with hearing impairments become more aware of their surroundings by providing sound
  localization, depth perception, and classification through electrical stimulation
  and LEDs. The device uses a Raspberry Pi, a 4-mic array, and TENS electrodes integrated
  into a mesh vest to process and transmit sound information.
---

# EchoVest: Real-Time Sound Classification and Depth Perception Expressed through Transcutaneous Electrical Nerve Stimulation

## Quick Facts
- arXiv ID: 2307.04604
- Source URL: https://arxiv.org/abs/2307.04604
- Reference count: 18
- Primary result: 95.7% accuracy on ESC-50 dataset using Audio Spectrogram Transformers with FFT+Otsu noise reduction

## Executive Summary
EchoVest is a wearable device that provides hearing-impaired individuals with real-time sound awareness through electrical stimulation and LEDs. The system uses a Raspberry Pi, 4-mic array, and TENS electrodes integrated into a mesh vest to process environmental sounds and convey their location, distance, and classification through haptic feedback. The device achieves 95.7% accuracy on environmental sound classification while providing directional and depth information through transcutaneous electrical nerve stimulation. At $98.90 in materials cost, EchoVest offers a significantly more affordable alternative to traditional hearing aids and cochlear implants.

## Method Summary
The system captures audio through a 4-microphone ReSpeaker array connected to a Raspberry Pi. Sound localization is achieved using Time Difference of Arrival (TDoA) with GCC-PHAT algorithms to compute source angle and distance. Blind Source Separation (BSS) using PCA, NMF, and ICA separates multiple simultaneous sounds for individual localization. Audio preprocessing combines FFT with Otsu's Method for noise reduction before feeding log-mel spectrograms to an Audio Spectrogram Transformer (AST) model for classification. The Raspberry Pi controls TENS electrodes and LEDs to convey sound information through haptic and visual feedback.

## Key Results
- 95.7% accuracy on ESC-50 environmental sound classification dataset
- PSNR of 57.5 dB for noise reduction using FFT with Otsu's Method
- Manufacturing cost of $98.90, significantly lower than traditional hearing aids
- Real-time processing capable of handling multiple simultaneous sound sources

## Why This Works (Mechanism)

### Mechanism 1
- Claim: EchoVest's sound localization is accurate enough to drive TENS stimulation placement and intensity.
- Mechanism: Time Difference of Arrival (TDoA) using Generalized Cross-Correlation with Phase Transform (GCC-PHAT) computes relative delay between microphones. These delays are converted to source angle and distance via geometric triangulation. Higher distance → stronger TENS current → larger perceived vibration amplitude.
- Core assumption: Microphone spacing is known, sound is impulsive or broadband, and environmental reflections are minimal.
- Evidence anchors: [section] "We utilized Time Difference of Arrival (TDoA) with Generalized Cross-Correlation with Phase Transforms (GCC-PHAT) to calculate the distance from the sound source to the microphones in real time." [abstract] "In order to calculate direction and depth accurately, we applied Complex Time Difference of Arrival algorithms and SOTA localization."
- Break condition: Reflections or noise cause GCC-PHAT peaks to shift → incorrect angle/depth → misplaced/incorrect intensity stimulation.

### Mechanism 2
- Claim: Blind Source Separation (BSS) enables EchoVest to isolate multiple simultaneous sounds for individual localization.
- Mechanism: PCA + NMF reduce dimensionality of mixed audio, ICA separates independent components. Each component is then associated with a microphone pair using cross-correlation matrices and TDoA. This yields distinct directional/distance estimates for each source.
- Core assumption: Sound sources are statistically independent and non-Gaussian; microphone array captures sufficient spatial diversity.
- Evidence anchors: [section] "We utilized a Blind Source Separation (BSS) approach that combined Principal Component Analysis (PCA), Non-Negative Matrix Factorization (NMF), and Independent Component Analysis (ICA) to separate the combined sound file from the microphone array into individual sound files for each microphone." [section] "The cross-correlation matrix and TDOA values from sound localization allowed us to identify each sound with its corresponding microphone, resulting in enhanced sound localization and depth perception."
- Break condition: Sources are too correlated or overlapping in spectrum → ICA fails to separate → ghost or missing sound cues.

### Mechanism 3
- Claim: FFT with Otsu's Method noise reduction preserves classification accuracy while lowering computational load vs CNN.
- Mechanism: FFT converts audio to frequency domain → Otsu's thresholding removes spectral bins dominated by background noise → clean spectrogram fed to AST → 95.7% ESC-50 accuracy. Higher PSNR (57.5 dB) vs other denoising methods indicates better signal preservation.
- Core assumption: Noise is stationary and spectrally separable from signal; Otsu's threshold is optimal for the dataset.
- Evidence anchors: [section] "We employed a signal processing approach that combined Fast Fourier Transforms (FFTs) with Otsu's method to effectively remove background noise from our sound input and enhance the sound classification accuracy." [section] "FFT with Otsu's Method is an uncommon technique for noise reduction, but it proved to be more effective than each of the other algorithms due to its higher PSNR value."
- Break condition: Non-stationary noise or signal overlap with noise spectrum → threshold misclassifies bins → loss of key features → AST accuracy drops.

## Foundational Learning

- Concept: Cross-correlation and time delay estimation
  - Why needed here: TDoA algorithms rely on measuring lag of maximum cross-correlation between microphone pairs to infer source location.
  - Quick check question: If two microphones are 0.1 m apart and a sound arrives from the side, what is the expected time delay at 343 m/s sound speed?

- Concept: Independent Component Analysis (ICA)
  - Why needed here: ICA separates mixed audio into statistically independent sources so each can be localized individually.
  - Quick check question: ICA assumes source signals are non-Gaussian and independent—what happens if two sources have identical spectra?

- Concept: Spectrogram representation and mel filterbanks
  - Why needed here: AST expects log-mel spectrograms as input; incorrect framing or windowing distorts the features it learns from.
  - Quick check question: How does a 25 ms Hamming window with 10 ms hop affect time-frequency resolution in the resulting spectrogram?

## Architecture Onboarding

- Component map: 4-mic ReSpeaker array → GCC-PHAT TDoA module → angle/distance estimator → BSS (PCA+NMF+ICA) → separate sources → repeat TDoA per source → Raspberry Pi GPIO → TENS driver circuit → vest electrodes/LEDs
- Critical path: Audio capture → denoising → classification → localization → stimulation mapping. Latency must stay < 200 ms for real-time feel.
- Design tradeoffs: More mics → better spatial resolution but higher computational load and wiring complexity. Higher TENS current → stronger haptic cue but increased safety risk and battery drain. AST vs CNN → higher accuracy but heavier model; mitigated here by efficient FFT+Otsu preprocessing.
- Failure signatures: Misaligned stimulation → TDoA angle/distance errors or electrode mapping bug. Missed sounds → BSS fails to separate overlapping sources. Low classification accuracy → denoising threshold too aggressive or model mismatch.
- First 3 experiments: 1) Static sound source test: place phone 1 m away at known angle, verify electrode activation and classification. 2) Multi-source test: play two sounds from different angles, confirm BSS isolates and localizes both. 3) Noise robustness test: add controlled white/babble noise, measure PSNR and AST accuracy vs baseline.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal TENS electrode current level for different users, considering individual differences in nerve sensitivity and skin resistance?
- Basis in paper: [explicit] The paper mentions that the maximum current output of the Raspberry Pi is 50 hertz through the 5V pin-outs, and the intensity of the electrical current expelled from the TENS electrodes is directly related to the current from the Raspberry Pi. However, it also states that the current is under-powered for typical TENS electrodes (50 Hertz), but still high enough to be felt and guarantee user safety.
- Why unresolved: The paper does not provide information on how to determine the optimal current level for different users, considering individual differences in nerve sensitivity and skin resistance.
- What evidence would resolve it: A study that tests different current levels on a diverse group of users and measures their perception and comfort levels could provide insights into the optimal current levels for different individuals.

### Open Question 2
- Question: How does the performance of EchoVest's sound classification and localization algorithms vary in different real-world environments, such as noisy urban areas or quiet rural settings?
- Basis in paper: [inferred] The paper mentions that EchoVest's algorithms were tested with white noise, including people talking, laughter, and the air conditioner running. However, it does not provide information on how the algorithms perform in various real-world environments.
- Why unresolved: The paper does not discuss the performance of EchoVest's algorithms in different real-world environments, which could impact the device's effectiveness in helping individuals with hearing impairments.
- What evidence would resolve it: Testing EchoVest's algorithms in various real-world environments and comparing their performance could provide insights into the device's effectiveness in different settings.

### Open Question 3
- Question: How can EchoVest be further improved to better assist individuals with hearing impairments in their daily lives?
- Basis in paper: [inferred] The paper discusses the development and testing of EchoVest, but it does not explore potential improvements or future directions for the device.
- Why unresolved: The paper does not provide information on potential improvements or future directions for EchoVest, which could help enhance its effectiveness in assisting individuals with hearing impairments.
- What evidence would resolve it: A comprehensive analysis of user feedback, potential technological advancements, and collaboration with experts in the field could help identify areas for improvement and future development of EchoVest.

## Limitations

- Real-world performance may degrade significantly in reverberant environments and with overlapping sound sources
- No user study data on long-term comfort, adaptation time, or safety of TENS stimulation
- Cost advantage assumes mass production; current BOM does not include enclosure, regulatory testing, or support infrastructure
- End-to-end latency measurements are not provided, which is critical for real-time haptic feedback

## Confidence

- High Confidence: Audio preprocessing with FFT+Otsu's Method effectively reduces noise while preserving classification-relevant features
- Medium Confidence: AST model achieves state-of-the-art classification accuracy on ESC-50 when properly preprocessed
- Medium Confidence: TDoA with GCC-PHAT provides accurate directional localization in controlled conditions
- Low Confidence: Blind Source Separation successfully isolates multiple simultaneous sources for individual localization
- Low Confidence: TENS stimulation provides intuitive, comfortable, and safe haptic feedback for extended wear

## Next Checks

1. Real-world acoustic robustness test: Deploy EchoVest in environments with measured reverberation times (T60) from 200 ms to 1000 ms and overlapping sound sources at varying SNRs. Quantify degradation in classification accuracy and localization error compared to controlled lab conditions.

2. End-to-end latency measurement: Instrument the full processing pipeline and measure total system latency from sound arrival to TENS activation. Verify that end-to-end latency remains under 200 ms across all operational modes.

3. User adaptation and comfort study: Conduct a controlled trial with hearing-impaired participants wearing EchoVest for 2+ hours across multiple sessions. Measure: (a) time to achieve reliable sound source identification, (b) reported comfort and any skin irritation from TENS, (c) battery life under continuous operation with stimulation enabled.