---
ver: rpa2
title: 'DCFL: Non-IID awareness Data Condensation aided Federated Learning'
arxiv_id: '2312.14219'
source_url: https://arxiv.org/abs/2312.14219
tags:
- data
- client
- clients
- training
- local
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: DCFL addresses the challenge of non-IID data in federated learning
  by proposing a novel framework that utilizes data condensation and CKA-based client
  grouping to improve model performance and reduce communication rounds. The method
  divides clients into groups based on CKA similarity, then uses condensed data from
  complementary clients to fine-tune local models.
---

# DCFL: Non-IID awareness Data Condensation aided Federated Learning

## Quick Facts
- arXiv ID: 2312.14219
- Source URL: https://arxiv.org/abs/2312.14219
- Reference count: 32
- Improves federated learning accuracy by 1.01%-18.34% while reducing communication rounds by 15-20x

## Executive Summary
DCFL addresses the challenge of non-IID data in federated learning by proposing a novel framework that utilizes data condensation and CKA-based client grouping to improve model performance and reduce communication rounds. The method divides clients into groups based on CKA similarity, then uses condensed data from complementary clients to fine-tune local models. Experimental results on MNIST, FashionMNIST, SVHN, and CIFAR-10 show DCFL outperforms traditional FL methods by 1.01%-18.34% in accuracy and reduces communication rounds by 15-20x.

## Method Summary
DCFL introduces a novel federated learning framework that leverages dataset condensation and CKA-based client grouping to address non-IID data challenges. The method first groups clients using CKA similarity between their model representations, then generates condensed data from each client's private dataset. Clients receive condensed data from complementary groups and fine-tune their models using both local and condensed data. The framework incorporates DSA augmentation and carefully calibrated learning rates for the fine-tuning phase, enabling effective knowledge transfer while maintaining privacy constraints.

## Key Results
- Achieves 1.01%-18.34% higher accuracy compared to traditional FL methods on benchmark datasets
- Reduces communication rounds by 15-20x while maintaining or improving model performance
- Demonstrates effective mitigation of data heterogeneity through CKA-based client grouping and condensed data sharing

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** CKA-based client grouping enables effective identification of data complementarity without direct access to private data.
- **Mechanism:** The framework uses Centered Kernel Alignment (CKA) to measure similarity between client model representations. Clients with high CKA values are grouped together, indicating similar data distributions. This allows the server to identify complementary clients whose condensed data can improve model performance when shared.
- **Core assumption:** CKA similarity between classifier layers reliably reflects underlying data distribution similarity between clients.
- **Evidence anchors:**
  - [abstract]: "DCFL divides clients into groups by using the Centered Kernel Alignment (CKA) method"
  - [section]: "We perform an experimental study on clients with heterogeneous datasets... We can find out that client belonging to the same group have symmetrical and relatively high EMD valuations"
  - [corpus]: Weak evidence - corpus papers discuss related concepts but don't specifically validate CKA for client grouping in FL
- **Break condition:** If CKA similarity does not correlate with actual data distribution complementarity, the grouping mechanism fails and clients receive non-beneficial condensed data.

### Mechanism 2
- **Claim:** Dataset condensation provides informative synthetic data that maintains privacy while improving model training.
- **Mechanism:** Instead of sharing raw data, clients generate condensed data representations using data condensation methods. These condensed data points capture the essential features of the original dataset while being much smaller in size and privacy-preserving.
- **Core assumption:** Condensed data retains sufficient information about the original data distribution to improve model training when shared between complementary clients.
- **Evidence anchors:**
  - [abstract]: "dataset condensation methods with non-IID awareness to complete clients"
  - [section]: "motivated by condensed data obtained by data condensation methods owns informative, representative, small quantity features and no fear of privacy violation"
  - [corpus]: Moderate evidence - related works exist on dataset condensation but specific validation for FL with non-IID data is limited
- **Break condition:** If condensed data loses critical distributional information or fails to generalize to the original data space, the auxiliary training signal becomes ineffective.

### Mechanism 3
- **Claim:** Fine-tuning with condensed data and DSA augmentation stabilizes training and improves convergence speed.
- **Mechanism:** Clients first train on their local data, then fine-tune using the received condensed data from complementary clients with a smaller learning rate. DSA (Differentiable Siamese Augmentation) is applied to both local and condensed data to enhance robustness.
- **Core assumption:** Fine-tuning with complementary condensed data provides additional training signal without disrupting the local data's influence on the model.
- **Evidence anchors:**
  - [abstract]: "CKA-guided client selection strategy, filtering mechanisms, and data enhancement techniques are incorporated to efficiently and precisely utilize the condensed data"
  - [section]: "DCFL utilizes condensed data effectively while stabilizing and improving the model performance via applying fine-tuning"
  - [corpus]: Weak evidence - limited corpus support for this specific fine-tuning strategy in federated learning context
- **Break condition:** If the fine-tuning process overfits to the condensed data or the learning rate ratio between local and condensed data is poorly calibrated, model performance degrades.

## Foundational Learning

- **Federated Learning with Non-IID Data:**
  - Why needed here: The entire framework addresses the challenge of non-IID data distributions across clients, which is the primary motivation for DCFL
  - Quick check question: What happens to FedAvg performance when clients have highly skewed label distributions?

- **Centered Kernel Alignment (CKA):**
  - Why needed here: CKA is the core mechanism for measuring model representation similarity between clients without accessing private data
  - Quick check question: How does CKA differ from other similarity metrics like linear centered kernel alignment (CKA) in measuring neural network representations?

- **Dataset Condensation:**
  - Why needed here: Condensed data serves as the privacy-preserving auxiliary data that enables knowledge sharing between complementary clients
  - Quick check question: What is the trade-off between condensation quality and the computational cost of generating condensed data?

## Architecture Onboarding

- **Component map:**
  - Server components: CKA calculator, client grouping module, condensed data aggregator, model aggregator, client selector
  - Client components: Local trainer, dataset condenser, condensed data receiver, fine-tuner
  - Communication channels: Model parameters, condensed data, CKA scores

- **Critical path:** Server → CKA calculation → Client grouping → Condensed data collection → Client selection → Condensed data distribution → Local training + fine-tuning → Model aggregation

- **Design tradeoffs:**
  - Communication vs. computation: Generating condensed data locally increases client computational burden but reduces communication volume
  - Privacy vs. performance: More condensed data improves performance but may leak information
  - Group size vs. diversity: Larger groups provide more complementary data but may include less relevant clients

- **Failure signatures:**
  - Stagnant accuracy despite many communication rounds indicates poor client grouping or ineffective condensed data
  - Sudden accuracy drops suggest overfitting to condensed data during fine-tuning
  - High variance in client performance indicates imbalanced condensed data distribution

- **First 3 experiments:**
  1. Validate CKA correlation: Run experiments measuring CKA similarity between clients with known data distributions to confirm CKA reflects data complementarity
  2. Baseline condensation quality: Test dataset condensation methods independently to establish baseline performance before integrating with FL
  3. Group size optimization: Experiment with different group sizes to find the optimal balance between diversity and relevance of condensed data

## Open Questions the Paper Calls Out

The paper does not explicitly call out open questions, but several remain unaddressed based on the analysis.

## Limitations

- CKA implementation uncertainty: Exact methodology for calculating CKA between clients is not fully specified
- Condensation quality dependence: Performance heavily relies on quality of generated condensed data
- Group size sensitivity: Framework's effectiveness may degrade with inappropriate group sizes

## Confidence

- CKA-based grouping mechanism: Medium confidence - methodology described but implementation details unclear
- Dataset condensation effectiveness: Medium confidence - relies on existing condensation methods without novel contributions
- Fine-tuning strategy: Low confidence - limited validation of specific fine-tuning approach

## Next Checks

1. **Ablation study on CKA layers:** Systematically test which model layers provide the most effective similarity measurements for client grouping
2. **Condensation robustness testing:** Evaluate DCFL performance across different dataset condensation algorithms and quality thresholds
3. **Group size sensitivity analysis:** Measure performance variation across different client group sizes to identify optimal configurations for various dataset scenarios