---
ver: rpa2
title: Unsupervised Translation Quality Estimation Exploiting Synthetic Data and Pre-trained
  Multilingual Encoder
arxiv_id: '2311.05117'
source_url: https://arxiv.org/abs/2311.05117
tags:
- translation
- data
- concat
- directions
- synthetic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper extensively investigates the usefulness of synthetic
  TQE data and pre-trained multilingual encoders in unsupervised sentence-level TQE,
  both of which have been proven effective in the supervised training scenarios. Our
  experiment on WMT20 and WMT21 datasets revealed that this approach can outperform
  other unsupervised TQE methods on high- and low-resource translation directions
  in predicting post-editing effort and human evaluation score, and some zero-resource
  translation directions in predicting post-editing effort.
---

# Unsupervised Translation Quality Estimation Exploiting Synthetic Data and Pre-trained Multilingual Encoder

## Quick Facts
- arXiv ID: 2311.05117
- Source URL: https://arxiv.org/abs/2311.05117
- Authors: 
- Reference count: 11
- This paper investigates synthetic TQE data and pre-trained multilingual encoders for unsupervised sentence-level TQE, outperforming other unsupervised methods on high- and low-resource directions in predicting post-editing effort and human evaluation scores.

## Executive Summary
This paper explores unsupervised sentence-level Translation Quality Estimation (TQE) by leveraging synthetic data generated from bilingual parallel corpora and pre-trained multilingual encoders. The approach generates synthetic TQE data by translating source sentences using an MT system and computing TER against reference translations, assuming TER approximates HTER. The study evaluates multiple pre-trained models (XLM-R, INFOXLM, LaBSE) with different encoding strategies ("concat" vs "split") on WMT20 and WMT21 datasets, demonstrating competitive performance without human-labeled training data.

## Method Summary
The method generates synthetic TQE data by translating source sentences from bilingual parallel corpora using M2M-100 and computing TER scores between MT outputs and reference translations. Pre-trained multilingual encoders (XLM-RBase, XLM-RLarge, INFOXLM Base, LaBSE) with additional MLP layers are fine-tuned on this synthetic data. Two encoding approaches are compared: "split" (separate encoding of source and MT output) and "concat" (joint encoding with [CLS] and [SEP] tokens). Models are trained using AdamW optimizer with early stopping, and performance is evaluated using Pearson correlation with gold HTER and DA scores on WMT test sets.

## Key Results
- TQE models trained on synthetic data outperform other unsupervised methods on high-resource directions in predicting both HTER and DA scores
- The "concat" encoding method consistently outperforms "split" encoding across all pre-trained models
- Multi-directional training on synthetic data improves generalization compared to single-direction training
- Performance degrades for medium-resource translation directions (Ro→En, Et→En) despite success on high- and low-resource pairs

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Synthetic TER scores approximate HTER when MT outputs are compared to human translations in parallel corpora
- Mechanism: TER between MT output and reference translation serves as proxy for HTER since both measure edit distance from reference. When MT system trained on same parallel corpus, TER approximates post-editing effort needed.
- Core assumption: TER-HTER correlation holds even when MT output and reference are separately generated
- Evidence anchors: Abstract assumption that TER approximates HTER; section confirmation that "TER would approximate HTER even though y and y′ are separately generated"
- Break condition: Correlation breaks if MT trained on different data than parallel corpus or severe domain mismatch

### Mechanism 2
- Claim: Concatenating source and MT output during encoding captures cross-lingual token-level correspondences better than separate encoding
- Mechanism: Joint encoding with [CLS] and [SEP] tokens enables transformer to learn attention patterns between corresponding tokens across languages for better quality estimation
- Core assumption: Cross-lingual token-level correspondences contain critical information for quality estimation not recoverable from separate encodings
- Evidence anchors: Section showing "concat" model consistently superior to "split" model using same pre-trained models
- Break condition: If quality estimation relies primarily on global semantic similarity rather than fine-grained alignment

### Mechanism 3
- Claim: Training TQE models on multi-directional synthetic data improves generalization compared to single-direction training
- Mechanism: Multi-directional training exposes model to diverse translation quality patterns across language pairs, creating more robust quality estimation representation
- Core assumption: Quality estimation patterns transferable across language pairs when trained on synthetic data
- Evidence anchors: Table 8 comparison showing multi-directional (#TD=6) training outperforms single-direction (#TD=1) training
- Break condition: If language pairs too dissimilar or translation quality patterns highly language-specific

## Foundational Learning

- Concept: Translation Edit Rate (TER) and Human-targeted Translation Edit Rate (HTER)
  - Why needed here: Understanding TER-HTER relationship crucial since paper uses TER as proxy for HTER in synthetic data generation
  - Quick check question: If MT output has TER of 0.2 with respect to reference, what does this mean in terms of edit operations per reference word?

- Concept: Pre-trained multilingual encoders and their adaptation for downstream tasks
  - Why needed here: Paper investigates how pre-trained models like LaBSE, XLM-R, and INFOXLM can be fine-tuned on synthetic TQE data
  - Quick check question: What is key difference between XLM-R and LaBSE in terms of their pre-training objectives?

- Concept: Synthetic data generation for quality estimation
  - Why needed here: Entire approach relies on generating synthetic TQE data from parallel corpora using MT systems
  - Quick check question: What is main assumption when using TER between MT output and reference translation as proxy for HTER?

## Architecture Onboarding

- Component map: Parallel corpus -> MT system -> TER calculation -> Synthetic TQE tuples -> Pre-trained encoder -> [CLS] embedding -> MLP regression -> Quality score -> Pearson correlation evaluation
- Critical path: Synthetic data generation -> Model training -> Evaluation on test sets. Quality of synthetic data directly impacts model performance, making data generation most critical component.
- Design tradeoffs:
  - Parallel corpus size vs. synthetic data quality: Larger corpora provide more data but may include lower quality translations
  - Pre-trained model size vs. training efficiency: Larger models may perform better but require more computation
  - Joint vs. separate encoding: Joint encoding captures cross-lingual alignment but increases computational cost
- Failure signatures:
  - Low correlation with gold scores despite high training correlation: Likely synthetic data quality issues
  - Poor performance on medium-resource directions: May indicate domain mismatch between synthetic data and test data
  - Large gap between training and validation performance: Overfitting to synthetic data distribution
- First 3 experiments:
  1. Train INFOXLM Base+MLP (concat) on En→De synthetic data and evaluate on WMT20 En→De test set to establish baseline performance
  2. Compare joint vs. separate encoding by training identical models with "concat" and "split" settings on same synthetic data
  3. Test multi-directional training by training on all six translation directions simultaneously and comparing to single-direction models

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but several areas warrant further investigation based on the results and discussion.

## Limitations
- Synthetic data generation relies on TER-HTER correlation assumption that may break down for low-resource languages with inconsistent MT quality
- Performance degradation observed for medium-resource translation directions (Ro→En, Et→En) despite success on other directions
- Limited analysis of how synthetic data quality impacts downstream performance across different resource levels

## Confidence
- **High Confidence**: Superiority of joint ("concat") encoding over separate encoding for pre-trained multilingual encoders
- **Medium Confidence**: Effectiveness of synthetic data generation using TER as HTER proxy for high-resource directions
- **Medium Confidence**: Generalization benefits of multi-directional training for TQE models
- **Low Confidence**: Performance claims for zero-resource translation directions, as synthetic data generation for truly zero-resource pairs is not addressed

## Next Checks
1. Test TER-HTER correlation stability across different MT model qualities and domains by generating synthetic data with varying MT system strengths and measuring correlation decay
2. Conduct ablation studies on synthetic data quality by filtering generated translations based on MT confidence scores and measuring impact on TQE performance
3. Evaluate model robustness to domain shift by training on one domain (e.g., news) and testing on another (e.g., subtitles) to identify failure patterns