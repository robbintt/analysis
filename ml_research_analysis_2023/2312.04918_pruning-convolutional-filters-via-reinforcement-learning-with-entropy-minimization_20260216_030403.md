---
ver: rpa2
title: Pruning Convolutional Filters via Reinforcement Learning with Entropy Minimization
arxiv_id: '2312.04918'
source_url: https://arxiv.org/abs/2312.04918
tags:
- entropy
- pruning
- neural
- network
- accuracy
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes a novel information-theoretic reward function
  for reinforcement learning-based network pruning that minimizes the spatial entropy
  of convolutional activations. Unlike previous approaches that directly optimize
  accuracy, the authors show that entropy minimization can act as a proxy for preserving
  accuracy during pruning.
---

# Pruning Convolutional Filters via Reinforcement Learning with Entropy Minimization

## Quick Facts
- arXiv ID: 2312.04918
- Source URL: https://arxiv.org/abs/2312.04918
- Authors: 
- Reference count: 40
- Key outcome: Novel information-theoretic reward function for RL-based network pruning that minimizes spatial entropy of convolutional activations, achieving 5-10x FLOPS reduction with minimal accuracy loss across VGG-16, MobileNetV2, and ResNet50 architectures.

## Executive Summary
This paper introduces a novel approach to neural network pruning that uses entropy minimization as a proxy for preserving accuracy during reinforcement learning-based pruning. The authors demonstrate that minimizing spatial entropy of convolutional activations can achieve comparable results to accuracy-based pruning while establishing an interesting connection between information theory and neural pruning. Using the AMC framework with a DDPG agent, they successfully reduced FLOPS by 5-10x across multiple architectures with minimal or no performance drop.

## Method Summary
The method modifies the AMC (AutoML for Model Compression) framework by replacing the accuracy-based reward function with an entropy minimization objective. The approach computes spatial entropy of convolutional activations using Aura Matrix Entropy (AME) approximation, which is more computationally efficient than full Spatial Disorder Entropy calculation. A DDPG agent learns to select layer-wise sparsity levels that minimize the average spatial entropy across convolutional layers. The pruning process involves magnitude-based filter removal followed by least squares regression and fine-tuning to restore accuracy.

## Key Results
- Achieved 5-10x reduction in total FLOPS across VGG-16, MobileNetV2, and ResNet50 architectures
- Maintained accuracy within 1% of baseline models despite aggressive pruning
- Demonstrated comparable performance to accuracy-based pruning methods
- Showed robustness across different quantization bin sizes (32, 64, 128, 256, 512)
- Outperformed other pruning methods in terms of FLOPS reduction while maintaining accuracy

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Minimizing spatial entropy of convolutional activations serves as a proxy for preserving model accuracy during pruning.
- Mechanism: Lower spatial entropy indicates more structured, predictable activation patterns, which correlates with retaining informative features while removing redundant ones.
- Core assumption: There exists an implicit relationship between spatial entropy reduction and preservation of essential network information.
- Evidence anchors:
  - [abstract] "Our method shows that there is another possibility to preserve accuracy without the need to directly optimize it in the agent's reward function."
  - [section] "Our hypothesis is that by minimizing the spatial entropy, we can achieve on par or better results than when the goal is to maximize the accuracy."
  - [corpus] Weak evidence - related papers focus on mutual information or magnitude-based pruning but do not explicitly explore entropy minimization as a reward proxy.
- Break condition: If entropy minimization consistently leads to accuracy degradation compared to accuracy-based pruning across architectures.

### Mechanism 2
- Claim: The AMC framework can be adapted to use entropy minimization instead of accuracy maximization as the reward signal for the DDPG agent.
- Mechanism: The DDPG agent learns to select layer-wise sparsity levels that minimize the average spatial entropy across convolutional layers, indirectly preserving model performance.
- Core assumption: The AutoML framework's pruning pipeline remains effective when optimizing for entropy instead of accuracy.
- Evidence anchors:
  - [section] "We modify the accuracy based reward by introducing a function which minimizes the average of the spatial entropies of convolutional activations."
  - [section] "Our goal is to observe if entropy minimization can be used as a criterion in place of directly computing accuracy."
  - [corpus] Weak evidence - related work uses mutual information but not entropy minimization within RL-based pruning frameworks.
- Break condition: If the DDPG agent fails to converge or produces unstable pruning strategies under entropy-based rewards.

### Mechanism 3
- Claim: Spatial entropy can be computed efficiently using the Aura Matrix Entropy (AME) approximation, enabling practical deployment in AutoML pipelines.
- Mechanism: AME reduces computational complexity by focusing on second-order neighbor interactions rather than full bivariate entropy calculations.
- Core assumption: AME provides a sufficiently accurate estimate of spatial entropy for guiding pruning decisions.
- Evidence anchors:
  - [section] "Since the complexity of SDE computation is high, we decided to use a simplified version - the Aura Matrix Entropy (AME, see [38])"
  - [section] "To compute the mean value (per layer) of the spatial entropy, we use the convolutional outputs from 100 samples"
  - [corpus] Weak evidence - related papers mention spatial entropy but do not detail AME-based approximations.
- Break condition: If AME-based entropy estimates fail to correlate with pruning effectiveness across different network architectures.

## Foundational Learning

- Concept: Spatial entropy and Aura Matrix Entropy (AME) computation
  - Why needed here: Understanding how spatial entropy is calculated and approximated is essential for implementing the reward function in the AMC framework.
  - Quick check question: How does the Aura Matrix Entropy (AME) simplify the computation of spatial entropy compared to the full Spatial Disorder Entropy (SDE)?

- Concept: Reinforcement Learning with DDPG agents
  - Why needed here: The AMC framework uses a DDPG agent to select layer-wise sparsity levels, so understanding DDPG is crucial for adapting the reward function.
  - Quick check question: What role does the DDPG agent play in the AMC framework, and how does it use the reward signal to guide pruning decisions?

- Concept: Structured pruning vs. unstructured pruning
  - Why needed here: The method focuses on structured pruning (removing entire filters), which has different efficiency implications than unstructured pruning.
  - Quick check question: Why is structured pruning more efficient than unstructured pruning when deploying models on specialized hardware?

## Architecture Onboarding

- Component map:
  - DDPG agent -> AMC framework -> Spatial entropy calculator -> Calibration dataset -> Magnitude-based pruning -> Least squares regression -> Fine-tuning

- Critical path:
  1. Forward pass calibration samples through the network
  2. Compute spatial entropy for each convolutional layer
  3. DDPG agent selects sparsity levels to minimize average entropy
  4. Magnitude-based pruning removes selected filters
  5. Least squares regression adjusts remaining weights
  6. Fine-tuning to restore accuracy

- Design tradeoffs:
  - Entropy vs. accuracy optimization: Entropy minimization may be more stable but less directly tied to final performance
  - Bin size selection: Affects entropy computation accuracy and speed
  - Sample size for entropy estimation: Balances computational cost with estimation quality

- Failure signatures:
  - DDPG agent fails to converge under entropy-based rewards
  - Pruning leads to accuracy collapse despite entropy minimization
  - Entropy estimates become unstable with different quantization bin sizes

- First 3 experiments:
  1. Implement AME computation and verify it matches spatial entropy estimates on sample feature maps
  2. Integrate entropy-based reward into AMC framework and test on small CNN (e.g., VGG-11) with CIFAR-10
  3. Compare entropy-minimized pruning vs. accuracy-maximized pruning on MobileNetV2 with 50% FLOPS reduction target

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does entropy minimization work as well for other types of neural networks beyond CNNs, such as transformers or recurrent networks?
- Basis in paper: [inferred] The paper focuses on CNNs and suggests that entropy minimization can be used as an alternative to accuracy-based pruning. The authors note that their results are "on par" with accuracy-based methods but do not explore other network architectures.
- Why unresolved: The paper only tested entropy minimization on convolutional neural networks (VGG-16, MobileNetV2, ResNet50). There is no evidence that the method would generalize to other types of networks.
- What evidence would resolve it: Experiments applying the entropy minimization approach to transformers, RNNs, or other non-convolutional architectures to compare performance against accuracy-based pruning.

### Open Question 2
- Question: What is the theoretical connection between spatial entropy minimization and improved generalization in neural networks?
- Basis in paper: [explicit] The authors propose that entropy minimization acts as a proxy for maintaining accuracy and note an "interesting connection between information theory and neural pruning." However, they do not provide a rigorous theoretical explanation for why this connection exists.
- Why unresolved: While the authors demonstrate empirical results showing that entropy minimization correlates with accuracy preservation, they do not establish a formal theoretical framework explaining this relationship or its implications for generalization.
- What evidence would resolve it: A theoretical analysis connecting spatial entropy, information bottleneck principles, and generalization bounds, potentially building on the semiotic aggregation framework mentioned in related work.

### Open Question 3
- Question: How does the spatial entropy of hidden layers relate to the entropy of the final output layer during training?
- Basis in paper: [inferred] The authors note that "an ideal entropy value for the final output of the network is 0" and that their method "explicitly forced the spatial entropy of internal convolutional activations to decrease." This suggests a relationship between internal layer entropy and final output entropy, but this relationship is not explored.
- Why unresolved: The paper focuses on using spatial entropy of internal layers as a pruning criterion but does not investigate how this entropy evolves during training or how it relates to the final output entropy or classification confidence.
- What evidence would resolve it: Analysis of the temporal evolution of spatial entropy across layers during training, examining whether minimizing spatial entropy leads to more confident (lower entropy) predictions at the output layer.

## Limitations
- The method's effectiveness depends heavily on the quality of the spatial entropy approximation (AME), which may not capture all relevant information in complex feature maps.
- The relationship between entropy minimization and accuracy preservation, while demonstrated empirically, lacks rigorous theoretical grounding.
- Experiments were conducted primarily on image classification tasks with standard architectures, limiting generalizability to other domains.

## Confidence

- Entropy as accuracy proxy: Medium - empirical evidence is promising but theoretical justification is limited
- AMC framework adaptation: Medium - method works but specific implementation details are unclear
- FLOPS reduction claims: High - well-validated through multiple experiments

## Next Checks

1. Conduct ablation studies comparing different entropy approximation methods (including full SDE computation) to verify AME's effectiveness
2. Test the approach on non-image classification tasks (e.g., NLP or speech recognition) to assess generalizability
3. Analyze the correlation between entropy reduction and accuracy preservation across different pruning ratios to identify potential failure thresholds