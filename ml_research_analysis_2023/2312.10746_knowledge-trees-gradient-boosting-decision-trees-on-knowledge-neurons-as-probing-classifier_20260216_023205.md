---
ver: rpa2
title: 'Knowledge Trees: Gradient Boosting Decision Trees on Knowledge Neurons as
  Probing Classifier'
arxiv_id: '2312.10746'
source_url: https://arxiv.org/abs/2312.10746
tags:
- knowledge
- trees
- probing
- vector
- logistic
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: Probing classifiers are used to understand how well large language
  models capture syntactic features, but their accuracy is critical for correct interpretation.
  Low accuracy may stem from the model not capturing the property or the classifier
  failing to adequately capture characteristics in the model's internal representations.
---

# Knowledge Trees: Gradient Boosting Decision Trees on Knowledge Neurons as Probing Classifier

## Quick Facts
- **arXiv ID**: 2312.10746
- **Source URL**: https://arxiv.org/abs/2312.10746
- **Reference count**: 15
- **Primary result**: Knowledge Trees (gradient boosting on Knowledge Neurons) outperform logistic regression on transformer outputs for syntactic probing, with 9-54% error rate reductions.

## Executive Summary
This paper introduces Knowledge Trees, a probing classifier approach that applies gradient boosting decision trees to Knowledge Neurons - the hidden layer representations of transformer feed-forward networks. The method demonstrates significant advantages over traditional logistic regression on transformer output representations for recognizing parts of sentences, particularly for complex syntactic structures on medium-sized datasets. The study shows error rate improvements ranging from 9-54% across different tasks and dataset constraints, with CatBoost-based Knowledge Trees showing particular promise. The research also identifies scenarios where Support Vector Machines become competitive on large datasets.

## Method Summary
The method involves extracting Knowledge Neurons from the hidden layer of the feed-forward network in transformer models, specifically using the 4th layer's FFN matrix multiplication. These Knowledge Neurons are then used as input features for gradient boosting decision trees (CatBoost, XGBoost, and Sklearn implementations), which are compared against logistic regression baselines trained on transformer output representations. The approach is evaluated on the Universal Dependencies dataset "en lines" with 32 parts of speech categories, testing across varying dataset sizes and syntactic task complexities.

## Key Results
- Knowledge Trees achieve 9-54% error rate reduction compared to logistic regression baselines
- CatBoost-based Knowledge Trees show significant advantages for complex syntactic structures on medium-sized datasets
- Support Vector Machines become competitive on large datasets for syntactic probing tasks
- Shallow trees (depth 1-2) work better for complex tasks on medium datasets, while deeper trees (2-3 levels) are preferred for large datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Gradient boosting decision trees applied to Knowledge Neurons reduce overfitting compared to logistic regression on transformer layer outputs.
- Mechanism: Knowledge Neurons are individual coordinates in the hidden layer of the feed-forward network, each encoding interpretable real-world concepts. Gradient boosting operates on these interpretable, sparse features rather than dense vector representations, leading to better generalization on small datasets.
- Core assumption: The FFN hidden layer vector components are well-interpretable as "knowledge neurons" and contain sufficient discriminative information for syntactic parsing.
- Evidence anchors:
  - [abstract] "using gradient boosting decision trees at the Knowledge Neuron layer, i.e., at the hidden layer of the feed-forward network of the transformer as a probing classifier"
  - [section] "The initial embeddings of tokens, the output representations of any of the transformer layers, and any intermediate representations within the transformer layer can be probed... But we will consider intermediate representations inside the feed-forward network block (FFN-block) in more detail."
  - [corpus] Weak - corpus neighbors focus on general boosting/classifier topics but don't mention Knowledge Neurons specifically.
- Break condition: If Knowledge Neurons do not encode interpretable or discriminative features, or if the dataset is large enough that overfitting is not a concern, logistic regression may perform comparably.

### Mechanism 2
- Claim: Knowledge Trees (CatBoost-based with shallow depth) outperform other methods on medium-sized datasets for complex syntactic tasks.
- Mechanism: CatBoost uses symmetric trees and ordered boosting, which reduces overfitting and handles categorical features better. On medium-sized datasets with complex syntactic structures, these properties give Knowledge Trees a significant accuracy advantage.
- Core assumption: Medium-sized datasets are the optimal range where Knowledge Trees balance model complexity and data availability.
- Evidence anchors:
  - [abstract] "The gain in error rate, depending on the preset, ranges from 9-54%"
  - [section] "Knowledge Trees, especially when applied to complex syntactic structures on medium-sized datasets, show significant advantages over traditional methods."
  - [corpus] Weak - corpus neighbors discuss boosting but not specifically medium dataset performance or syntactic tasks.
- Break condition: If datasets are too small (patterns cannot be learned) or too large (overfitting is not the primary concern), other methods may become competitive.

### Mechanism 3
- Claim: Support Vector Machines become competitive on large datasets for syntactic probing tasks.
- Mechanism: SVMs with appropriate kernels can capture complex decision boundaries in high-dimensional space. As dataset size increases, the computational cost becomes less prohibitive relative to accuracy gains.
- Core assumption: The computational cost of SVMs on large datasets is justified by accuracy improvements over other methods.
- Evidence anchors:
  - [abstract] "The results indicate that Knowledge Trees, especially for complex syntactic structures on medium-sized datasets, outperform traditional methods... The study also highlights the effectiveness of CatBoost-based Knowledge Trees and the potential of Support Vector Machines in certain scenarios."
  - [section] "In all graphs, we observe that methods from the Knowledge Trees group are always part of the non-dominated set of methods. Sometimes they completely fill the non-dominated set, and sometimes they are accompanied by another method, the Support Vector Machine (SVC) classifier."
  - [corpus] Weak - corpus neighbors do not discuss SVMs in the context of syntactic probing or large datasets.
- Break condition: If computational resources are limited or if dataset size does not justify the additional complexity, SVMs may not be practical despite potential accuracy gains.

## Foundational Learning

- **Transformer architecture and feed-forward networks**: Understanding where Knowledge Neurons exist and how they differ from output representations is crucial for implementing the proposed method
  - Quick check: What is the difference between the output representation of a transformer layer and the hidden layer representation of the feed-forward network within that layer?

- **Gradient boosting and tree-based ensemble methods**: The proposed method relies on gradient boosting decision trees, so understanding how they work and their advantages over other methods is essential
  - Quick check: How does gradient boosting reduce overfitting compared to single decision trees or logistic regression?

- **Probing classifiers and syntactic parsing**: The goal is to understand how well language models capture syntactic features, which requires knowledge of probing methodology and syntactic structures
  - Quick check: What is the purpose of a probing classifier in the context of analyzing language model representations?

## Architecture Onboarding

- **Component map**: Text sentences -> DistilBERT model (token representations and Knowledge Neurons) -> Probing classifiers (Logistic regression, MLP, Random Forest, KNN, SVC, Naive Bayes, various gradient boosting implementations) -> Classification of parts of speech (32 categories)

- **Critical path**: 
  1. Preprocess text and tokenize using DistilBERT tokenizer
  2. Pass tokens through DistilBERT to obtain representations
  3. Extract Knowledge Neurons (FFN hidden layer) and output representations
  4. Train and evaluate multiple probing classifiers on balanced datasets
  5. Compare accuracy and error rates across methods and dataset constraints

- **Design tradeoffs**:
  - Dataset size: Small datasets favor Knowledge Trees due to reduced overfitting; large datasets may favor SVMs
  - Model complexity: Shallow trees (depth 1-2) work better for complex tasks on medium datasets; deeper trees may be needed for large datasets
  - Computational cost: SVMs are slow on large datasets; gradient boosting methods have varying computational requirements

- **Failure signatures**:
  - Logistic regression underperforms: May indicate the need for more complex models or that the task is too complex for linear separation
  - Knowledge Trees show no advantage: Could suggest the dataset is too small or too large, or that the task is not complex enough
  - SVMs are too slow: May indicate the dataset is too large for practical SVM use

- **First 3 experiments**:
  1. Train logistic regression on output representations and Knowledge Neurons for a simple part-of-speech category; compare error rates
  2. Train CatBoost-based Knowledge Trees with depth 1-2 on medium-sized dataset for a complex syntactic category; compare to logistic regression
  3. Train SVM on large dataset for a moderately complex syntactic category; compare accuracy and training time to Knowledge Trees

## Open Questions the Paper Calls Out

- **How much less training data would Knowledge Trees require to achieve the same accuracy as traditional methods like logistic regression?**
  - Basis in paper: [explicit] The paper mentions this as an interesting direction for future research, stating it would be interesting to establish how much less training data Knowledge Trees would require to achieve the same accuracy as traditional methods.
  - Why unresolved: This question is not addressed in the current study and would require further experimentation with different dataset sizes to determine the optimal data efficiency of Knowledge Trees.
  - What evidence would resolve it: Comparative experiments training both Knowledge Trees and traditional methods (e.g., logistic regression) on datasets of varying sizes and measuring their accuracy would provide evidence to answer this question.

- **Why are Symmetric Knowledge Trees so effective compared to Asymmetric ones?**
  - Basis in paper: [explicit] The paper notes that Symmetric Knowledge Trees are consistently part of the non-dominated set in all cases studied, while Asymmetric ones are only included in 2 out of 5 cases. The authors suggest this requires further study to understand the specific benefits of symmetry in gradient boosting decision trees.
  - Why unresolved: The current study does not provide a detailed analysis of the impact of symmetry on the performance of Knowledge Trees. Further research is needed to investigate the underlying reasons for this observed difference.
  - What evidence would resolve it: A thorough comparison of Symmetric and Asymmetric Knowledge Trees, including experiments with varying tree depths and dataset sizes, could provide insights into the specific advantages of symmetry in this context.

- **What is the optimal depth for Knowledge Trees when probing different parts of speech?**
  - Basis in paper: [explicit] The paper observes that shallow trees (1-2 levels) perform well for complex tasks and medium-sized datasets, while deeper trees (2-3 levels) are preferred for large datasets. However, the optimal depth may vary depending on the specific part of speech being probed.
  - Why unresolved: The current study does not provide a detailed analysis of the relationship between tree depth and probing performance for different parts of speech. Further research is needed to determine the optimal depth for each specific case.
  - What evidence would resolve it: Experiments training Knowledge Trees with varying depths on datasets corresponding to different parts of speech and measuring their accuracy would provide evidence to determine the optimal depth for each case.

## Limitations

- The effectiveness of Knowledge Neurons as interpretable features is based on prior work rather than direct validation within this study
- Results are derived from a single dataset (Universal Dependencies "en lines"), which may not generalize to other languages or domains
- Computational cost analysis is limited, particularly for SVMs on large datasets where training times could become prohibitive
- The study does not explore the interpretability of the resulting Knowledge Trees or compare their decision boundaries to those of logistic regression

## Confidence

- **High confidence**: The claim that gradient boosting on Knowledge Neurons outperforms logistic regression on output representations for medium-sized datasets with complex syntactic structures
- **Medium confidence**: The mechanism explanation that Knowledge Neurons reduce overfitting due to their interpretability and sparsity
- **Low confidence**: The claim that SVMs are competitive on large datasets

## Next Checks

1. **Dataset generalization test**: Replicate the experiments on multiple Universal Dependencies datasets (different languages) to verify that Knowledge Trees consistently outperform logistic regression across linguistic variations.

2. **Interpretability validation**: Extract and visualize the decision trees from the Knowledge Trees approach to verify that they produce interpretable rules corresponding to known syntactic patterns.

3. **Computational cost analysis**: Measure training and inference times for all methods (especially SVMs) on progressively larger subsets of the dataset to quantify the practical limitations mentioned in the paper.