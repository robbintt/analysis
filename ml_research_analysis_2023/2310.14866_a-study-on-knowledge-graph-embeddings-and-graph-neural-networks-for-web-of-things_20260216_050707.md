---
ver: rpa2
title: A Study on Knowledge Graph Embeddings and Graph Neural Networks for Web Of
  Things
arxiv_id: '2310.14866'
source_url: https://arxiv.org/abs/2310.14866
tags:
- graph
- knowledge
- embeddings
- data
- node
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper investigates knowledge graph embeddings (KGE) and graph
  neural networks (GNN) for refining a Web of Things (WoT) knowledge graph called
  "Thing in the future". The authors explore multiple KGE methods (TransR, TransE,
  DistMult, RotatE) and GNN architectures (GCN, ChebNet, GAT, R-GCN) on several sub-graphs
  from the WoT platform to tackle node classification, link prediction, and triple
  classification tasks.
---

# A Study on Knowledge Graph Embeddings and Graph Neural Networks for Web Of Things

## Quick Facts
- **arXiv ID:** 2310.14866
- **Source URL:** https://arxiv.org/abs/2310.14866
- **Reference count:** 30
- **Primary result:** KGE methods achieve over 80% accuracy on node classification and over 90% on triple classification, while GNN approaches outperform on link prediction tasks.

## Executive Summary
This paper investigates knowledge graph embeddings (KGE) and graph neural networks (GNN) for refining a Web of Things (WoT) knowledge graph called "Thing in the future". The authors explore multiple KGE methods (TransR, TransE, DistMult, RotatE) and GNN architectures (GCN, ChebNet, GAT, R-GCN) on several sub-graphs from the WoT platform to tackle node classification, link prediction, and triple classification tasks. Results show that KGE methods achieve over 80% accuracy on node classification and over 90% on triple classification, while GNN approaches outperform on link prediction tasks.

## Method Summary
The study evaluates KGE methods (TransR, TransE, DistMult, RotatE) and GNN architectures (GCN, ChebNet, GAT, R-GCN) on 8 sub-graphs from the Thing'in WoT platform with varying sizes (530-17,506 nodes). KGE embeddings are generated using PyKEEN and used as initial node representations for GNNs. The evaluation covers three tasks: node classification (using SVM and GNNs), link prediction (using threshold-based AP for KGE and score-based AP for GNNs), and triple classification (using accuracy and F1 scores). Hyperparameters are optimized via Optuna, and results are compared against centrality-based and DeepWalk baselines.

## Key Results
- KGE methods achieve over 80% accuracy on node classification tasks
- KGE methods achieve over 90% accuracy on triple classification tasks
- GNN approaches outperform KGE on link prediction tasks

## Why This Works (Mechanism)

### Mechanism 1
- **Claim:** KGE methods capture relational structure in WoT graphs by learning low-dimensional vector embeddings of entities and relations.
- **Mechanism:** KGE models like TransR map entities and relations into separate spaces and project entities into relation-specific spaces, allowing the model to compute a scoring function that measures plausibility of triples based on vector distances.
- **Core assumption:** The relational structure of the graph can be preserved in a lower-dimensional embedding space where similarity reflects valid relationships.
- **Evidence anchors:**
  - [abstract] "explore state-of-the-art knowledge graph embedding (KGE) methods to learn numerical representations of the graph entities"
  - [section] "TransR changes the way relation vectors are handled. TransE does not take into account the heterogenity of the entities and relations while TransR tries to fix it by separating entity and relation spaces"
  - [corpus] Weak evidence - corpus does not directly discuss TransR or WoT embedding quality.
- **Break condition:** If the embedding dimension is too small, critical relational patterns are lost, degrading performance on downstream tasks like link prediction and node classification.

### Mechanism 2
- **Claim:** GNNs outperform KGE on link prediction because they propagate neighborhood information through message passing, capturing local graph structure more effectively.
- **Mechanism:** GNNs use neural message passing where node representations are updated by aggregating transformed neighbor information across layers, allowing them to learn representations that encode both node features and graph topology.
- **Core assumption:** Local neighborhood structure in the graph is informative for predicting missing links, and iterative aggregation captures this structure better than static embeddings.
- **Evidence anchors:**
  - [abstract] "superiority of GNN approaches in the link prediction task"
  - [section] "GNNs use a technique called Neural Message Passing by which the information is propagated on the network based on the graph structure"
  - [corpus] Weak evidence - corpus neighbors do not directly compare GNN vs KGE on link prediction.
- **Break condition:** If the graph has very sparse neighborhoods or the aggregation function fails to preserve discriminative features, GNN performance degrades relative to KGE.

### Mechanism 3
- **Claim:** Combining KGE-generated embeddings as initial node features for GNNs improves node classification accuracy over using only centrality-based features.
- **Mechanism:** KGE embeddings encode global graph structure and semantic relationships, providing richer initial representations than simple degree or coloring features, which are then refined by GNN layers through local message passing.
- **Core assumption:** Initial node representations that capture global relational patterns help GNNs learn more discriminative node-level features for classification.
- **Evidence anchors:**
  - [abstract] "GNN approaches outperform on link prediction tasks" and "KGE methods achieve over 80% accuracy on node classification"
  - [section] "Initial numerical representations for every node in the graph are important to build a graph neural network model. Since we did not have any useful representations for our graph data, we experimented with different representation methods: Graph centrality based methods, i.e. In-degree and Coloring number, and Learning based methods, i.e. Knowledge graph embeddings"
  - [corpus] Weak evidence - corpus does not discuss initialization of GNNs with KGE embeddings.
- **Break condition:** If KGE embeddings are of poor quality (e.g., from very small graphs), initializing GNNs with them may hurt performance compared to using strong centrality features.

## Foundational Learning

- **Concept:** Knowledge graph embedding (KGE) fundamentals
  - **Why needed here:** KGE is the core method for transforming non-Euclidean graph data into numerical vectors usable by machine learning algorithms.
  - **Quick check question:** How does TransR differ from TransE in handling entity and relation spaces?

- **Concept:** Graph neural networks and message passing
  - **Why needed here:** GNNs are the primary architecture for leveraging both node features and graph structure to perform link prediction and node classification in WoT graphs.
  - **Quick check question:** What is the role of the aggregation function in the neural message passing framework?

- **Concept:** Multi-relational graph modeling
  - **Why needed here:** Thing'in is a multi-relational knowledge graph, so models must account for different edge types; R-GCN is explicitly designed for this.
  - **Quick check question:** How does R-GCN modify the standard GCN to handle multiple relation types?

## Architecture Onboarding

- **Component map:** ArangoDB graph storage -> sampled subgraphs -> PyKEEN KGE generation -> initial node features -> DGL GNN models -> evaluation metrics
- **Critical path:** Sample subgraphs from Thing'in -> Generate KGE embeddings using PyKEEN -> Use KGE as initial features for GNNs -> Train and evaluate GNN models on link prediction and node classification -> Compare GNN results with KGE-only and centrality-only baselines
- **Design tradeoffs:** Embedding dimension vs. computational cost; KGE vs. GNN (speed vs. expressiveness); Centrality vs. learning-based features (speed vs. informativeness)
- **Failure signatures:** Low accuracy in node classification despite high embedding quality; GNN overfitting on small graphs; Link prediction performance gap between KGE and GNN narrows
- **First 3 experiments:** Train TransR embeddings on a small subgraph and evaluate on link prediction using threshold-based AP; Initialize GCN with TransR embeddings and compare node classification F1 vs. using degree features; Train R-GCN on the same subgraph and compare link prediction AP to standard GCN with TransR features

## Open Questions the Paper Calls Out

### Open Question 1
- **Question:** How do different sub-graph sizes and application domains impact the performance of KGE and GNN methods for WoT knowledge graphs?
- **Basis in paper:** [explicit] "One of our objectives is to detect if application domain has a significant impact on the performance of learning tasks" and the paper experiments with sub-graphs of varying sizes and domains
- **Why unresolved:** The paper shows some performance variation across different sub-graphs but doesn't provide systematic analysis of how size and domain characteristics affect performance
- **What evidence would resolve it:** Comprehensive experiments varying sub-graph sizes and domains, with statistical analysis of performance correlations with graph properties

### Open Question 2
- **Question:** Can combining KGE embeddings with GNN architectures provide better performance than using either approach alone for WoT knowledge graphs?
- **Basis in paper:** [inferred] The paper explores both KGE and GNN methods separately but doesn't investigate their combination
- **Why unresolved:** The paper treats KGE and GNN as separate approaches and doesn't explore hybrid architectures that could leverage benefits of both
- **What evidence would resolve it:** Experiments comparing standalone KGE/GNN methods against hybrid architectures using KGE embeddings as initial node representations for GNNs

### Open Question 3
- **Question:** How do different KGE scoring functions and loss functions affect performance on WoT knowledge graphs compared to traditional benchmark datasets?
- **Basis in paper:** [explicit] The paper mentions "a scoring function (which takes triples as input and outputs a numerical value), a loss function, an optimizer and a strategy to generate negatives" and experiments with multiple KGE methods
- **Why unresolved:** The paper evaluates multiple KGE methods but doesn't analyze how specific scoring/loss function choices affect WoT-specific performance
- **What evidence would resolve it:** Systematic comparison of different scoring and loss functions on WoT knowledge graphs versus standard benchmark datasets

### Open Question 4
- **Question:** What is the optimal approach for handling multi-label nodes in WoT knowledge graphs for node classification tasks?
- **Basis in paper:** [explicit] "In Thing'in, entities can be multi-labeled, thus node classification can be used to predict additional nodes labels for existing nodes"
- **Why unresolved:** The paper treats node classification as a multi-class problem without specifically addressing the multi-label nature of WoT entities
- **What evidence would resolve it:** Experiments comparing multi-class versus multi-label classification approaches, including threshold-based and ranking-based evaluation methods for multi-label prediction

## Limitations

- Unknown preprocessing steps for converting ArangoDB JSON exports to knowledge graph triples
- Lack of detailed hyperparameter specifications for KGE and GNN models, particularly Optuna optimization configurations
- Different evaluation metrics used for KGE (threshold-based) versus GNN (score-based) may affect direct performance comparisons

## Confidence

- **High confidence:** KGE effectiveness for node classification and triple classification tasks (>80% and >90% accuracy claims)
- **Medium confidence:** GNN superiority for link prediction (supported by abstract claims but limited detailed comparison)
- **Low confidence:** Initializing GNNs with KGE embeddings outperforms centrality features (weak supporting evidence)

## Next Validation Checks

1. Reconstruct the ArangoDB-to-KG pipeline to verify that sampling methodology preserves critical relational patterns and class distributions across the 8 subgraphs
2. Perform ablation studies comparing GNN performance with KGE-initialized features versus randomly initialized features to isolate the contribution of KGE pretraining
3. Conduct statistical significance tests on the performance differences between KGE and GNN methods across all three tasks to validate the claimed superiority of GNNs in link prediction