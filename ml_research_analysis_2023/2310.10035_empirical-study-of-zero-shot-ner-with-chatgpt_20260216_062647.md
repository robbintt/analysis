---
ver: rpa2
title: Empirical Study of Zero-Shot NER with ChatGPT
arxiv_id: '2310.10035'
source_url: https://arxiv.org/abs/2310.10035
tags:
- syntactic
- tree
- reasoning
- label
- text
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper explores zero-shot NER with ChatGPT by adapting reasoning
  methods from other tasks. The authors propose decomposing the NER task by label
  and applying syntactic augmentation through prompting or tool-provided information.
---

# Empirical Study of Zero-Shot NER with ChatGPT

## Quick Facts
- **arXiv ID**: 2310.10035
- **Source URL**: https://arxiv.org/abs/2310.10035
- **Reference count**: 16
- **Primary result**: Proposed methods significantly improve zero-shot NER performance, with F1 score gains of up to 9.22% across seven benchmarks including Chinese and English datasets.

## Executive Summary
This paper explores zero-shot named entity recognition (NER) with ChatGPT by adapting reasoning methods from other tasks. The authors propose decomposing the NER task by label and applying syntactic augmentation through prompting or tool-provided information. They also adapt self-consistency with a two-stage voting strategy for mentions then types. Across seven benchmarks including Chinese and English, and domain-specific and general datasets, the proposed methods significantly improve zero-shot NER performance, with F1 score gains of up to 9.22%. The methods also show improvements in few-shot settings and on other LLMs like GPT-3 and Llama2.

## Method Summary
The paper proposes three main strategies to improve zero-shot NER with ChatGPT: Decomposed-QA breaks down the NER task into simpler subproblems by processing one entity type at a time, syntactic augmentation provides linguistic structure through either prompting (encouraging the model to analyze syntax) or tool augmentation (providing POS tags and dependency trees), and a two-stage majority voting strategy for self-consistency that first votes for the most consistent mentions, then for the most consistent types. These methods are evaluated across seven benchmarks including domain-specific Chinese datasets and general-domain English datasets, with experiments on additional datasets to verify generalizability.

## Key Results
- Decomposed-QA strategy improves F1 scores by breaking complex multi-label NER into simpler single-label subproblems
- Syntactic augmentation through prompting or tool-provided information guides ChatGPT's reasoning process
- Two-stage majority voting for self-consistency effectively filters inconsistent predictions and improves robustness

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Decomposing the NER task by labels makes it more manageable for ChatGPT by reducing cognitive load and allowing focused attention on one entity type at a time.
- Mechanism: The Decomposed-QA paradigm breaks down the multi-label extraction problem into a series of simpler single-label subproblems, enabling the model to concentrate its reasoning on recognizing entities of a specific type in each turn.
- Core assumption: ChatGPT can effectively recognize entities when the task is simplified to focus on one label at a time, rather than attempting to identify all entity types simultaneously.
- Evidence anchors:
  - [abstract]: "we adapt the prevalent reasoning methods to NER and propose reasoning strategies tailored for NER. First, we explore a decomposed question-answering paradigm by breaking down the NER task into simpler subproblems by labels."
  - [section 3.1]: "we improve zero-shot NER by decomposing the task into a set of simpler questions. Recognizing entities of all labels at one time may be too challenging for ChatGPT..."
  - [corpus]: Weak evidence - no direct corpus neighbor discusses task decomposition for NER.
- Break condition: If the label order is poorly chosen or if the model struggles with distinguishing between similar entity types, the decomposition may not provide significant benefits.

### Mechanism 2
- Claim: Providing syntactic information (through prompting or tool augmentation) guides ChatGPT to perform step-by-step syntactic analysis, which improves entity recognition by leveraging linguistic structure.
- Mechanism: Syntactic augmentation encourages the model to first analyze the syntactic structure of the input text (e.g., POS tags, dependency trees) and then use this structure to identify named entities, mimicking human-like reasoning.
- Core assumption: ChatGPT's reasoning capabilities can be enhanced by explicit syntactic cues, and the model can effectively utilize syntactic information to improve entity recognition.
- Evidence anchors:
  - [abstract]: "we propose syntactic augmentation to stimulate the modelâ€™s intermediate thinking in two ways: syntactic prompting, which encourages the model to analyze the syntactic structure itself, and tool augmentation, which provides the model with the syntactic information generated by a parsing tool."
  - [section 3.2]: "we encourage ChatGPT to first grasp the syntactic structure of the input text and then leverage this syntactic structure to extract relevant information."
  - [corpus]: Weak evidence - no direct corpus neighbor discusses syntactic augmentation for NER with LLMs.
- Break condition: If the syntactic information is inaccurate or if the model fails to effectively integrate syntactic cues into its reasoning process, the augmentation may not yield improvements.

### Mechanism 3
- Claim: Self-consistency with a two-stage majority voting strategy improves the robustness of zero-shot NER by filtering out inconsistent predictions and selecting the most agreed-upon entities and types.
- Mechanism: By sampling multiple responses from the model and applying a two-stage voting process (first for mentions, then for types), the method identifies the most consistent predictions, reducing errors due to variability in the model's outputs.
- Core assumption: Multiple samples from the model will contain a subset of correct predictions, and majority voting can effectively identify these correct predictions by consensus.
- Evidence anchors:
  - [abstract]: "we adapt self-consistency to NER by proposing a two-stage majority voting strategy, which first votes for the most consistent mentions, then the most consistent types."
  - [section 3.3]: "we sample multiple responses from the model and select the most acknowledged answers as the final prediction. We design a two-stage majority voting for NER..."
  - [corpus]: Weak evidence - no direct corpus neighbor discusses self-consistency for NER, though some discuss LLMs for NER.
- Break condition: If the model's outputs are highly inconsistent or if there is no clear consensus among the sampled responses, the voting strategy may not effectively improve performance.

## Foundational Learning

- Concept: Task Decomposition
  - Why needed here: Breaking down complex tasks into simpler subproblems can make them more manageable for LLMs, which may have limitations in handling multi-faceted reasoning in a single pass.
  - Quick check question: How does decomposing the NER task by labels simplify the problem for ChatGPT?

- Concept: Syntactic Analysis
  - Why needed here: Understanding the syntactic structure of sentences can provide valuable cues for identifying named entities, as entities often correspond to specific syntactic patterns.
  - Quick check question: Why might providing POS tags or dependency trees help ChatGPT recognize named entities more accurately?

- Concept: Ensemble Methods
  - Why needed here: Using multiple model outputs and aggregating them through voting can improve robustness and reduce the impact of individual prediction errors.
  - Quick check question: How does self-consistency with majority voting help in selecting the most reliable predictions from multiple model samples?

## Architecture Onboarding

- Component map: Input text -> Decomposed-QA (label-by-label processing) -> Syntactic Augmentation (prompting or tool-based) -> Self-Consistency (sampling + two-stage voting) -> Output recognized entities

- Critical path:
  1. Input text is processed
  2. Task is decomposed by labels (Decomposed-QA)
  3. Syntactic information is provided (Syntactic Augmentation)
  4. Model generates multiple responses (Self-Consistency)
  5. Two-stage voting selects final predictions

- Design tradeoffs:
  - Decomposing the task increases the number of interactions but simplifies each step.
  - Providing syntactic information adds complexity but can guide reasoning.
  - Sampling multiple responses increases computational cost but improves robustness.

- Failure signatures:
  - Poor performance on domain-specific datasets may indicate the need for better label ordering or more accurate syntactic information.
  - High inconsistency in model outputs may suggest the need for more samples or alternative voting strategies.

- First 3 experiments:
  1. Evaluate the impact of task decomposition on a simple dataset without syntactic augmentation or self-consistency.
  2. Assess the effectiveness of syntactic prompting alone on a dataset with known syntactic patterns.
  3. Test self-consistency with two-stage voting on a dataset where the model's outputs are expected to vary.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do combinations of different syntactic information types (e.g., word segmentation + POS tags + dependency trees) affect zero-shot NER performance compared to individual syntactic augmentations?
- Basis in paper: [explicit] The paper states "We explore the effect of increasing sampled responses in SC, which are shown in Fig. 4. We sample up to 30 responses for cost saving. As seen in the figure, sampling a higher number of responses improves the performance. We conjecture that combining diverse syntactic information may further benefit SC on NER."
- Why unresolved: The authors mention this as a cost-saving decision but do not actually test combinations of syntactic information types.
- What evidence would resolve it: Experimental results comparing single syntactic information types against their combinations would show whether synergistic effects exist.

### Open Question 2
- Question: What is the optimal number of responses to sample in the two-stage majority voting for self-consistency, and how does this vary across different datasets and domain types?
- Basis in paper: [explicit] "We explore the effect of increasing sampled responses in SC, which are shown in Fig. 4. We sample up to 30 responses for cost saving." and "As seen in the figure, sampling a higher number of responses improves the performance."
- Why unresolved: The paper only samples up to 30 responses and does not explore whether there is a diminishing return point or optimal number that varies by dataset characteristics.
- What evidence would resolve it: Systematic experiments varying the number of sampled responses across multiple datasets would reveal the optimal range and whether it differs by domain or dataset complexity.

### Open Question 3
- Question: How does the proposed decomposed-QA approach compare to other task decomposition methods for NER, such as type-then-mention approaches or multi-stage reasoning frameworks?
- Basis in paper: [inferred] The paper proposes decomposing NER by label but does not compare against alternative decomposition strategies like first identifying mention spans then classifying types, or other multi-stage reasoning approaches.
- Why unresolved: The paper focuses on one specific decomposition method without benchmarking against other possible task decomposition strategies that might be more effective.
- What evidence would resolve it: Direct comparisons between different NER decomposition strategies (label-by-label, type-then-mention, mention-then-type) on the same benchmarks would reveal the most effective approach.

## Limitations

- Syntactic augmentation's effectiveness varies significantly across datasets, with complex structures like dependency trees sometimes reducing performance
- The paper does not fully specify prompt formulations, label ordering strategies, and self-consistency sampling parameters
- Limited ablation studies on individual components make it difficult to isolate the contribution of each proposed method

## Confidence

- High confidence in the general effectiveness of task decomposition for simplifying complex NER problems
- Medium confidence in syntactic augmentation's benefits, given dataset-specific variations
- Medium confidence in the two-stage self-consistency approach, pending more detailed analysis of voting strategies

## Next Checks

1. Conduct ablation studies isolating the impact of each syntactic information type (word segmentation, POS tags, constituency trees, dependency trees) to identify which syntactic cues provide consistent benefits
2. Perform controlled experiments varying the number of self-consistency samples and temperature settings to optimize the trade-off between robustness and computational cost
3. Test the proposed methods on additional diverse NER datasets, particularly those with nested entities and overlapping spans, to assess generalizability beyond the current benchmarks