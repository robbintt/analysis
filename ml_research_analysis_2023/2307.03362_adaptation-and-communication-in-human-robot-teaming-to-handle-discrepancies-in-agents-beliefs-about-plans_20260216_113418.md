---
ver: rpa2
title: Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies
  in Agents' Beliefs about Plans
arxiv_id: '2307.03362'
source_url: https://arxiv.org/abs/2307.03362
tags:
- agent
- action
- execution
- agents
- actions
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the challenge of human-robot teaming when
  agents may have differing beliefs about task plans. The authors extend conditional
  doxastic logic to represent agents' nested beliefs about feasible plans and develop
  an online execution algorithm using Monte Carlo Tree Search.
---

# Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents' Beliefs about Plans

## Quick Facts
- arXiv ID: 2307.03362
- Source URL: https://arxiv.org/abs/2307.03362
- Reference count: 8
- Key outcome: EPike achieves higher success rates and lower failure rates compared to baseline Pike, especially as task complexity increases

## Executive Summary
This paper addresses the challenge of human-robot teaming when agents may have differing beliefs about task plans. The authors extend conditional doxastic logic to represent agents' nested beliefs about feasible plans and develop an online execution algorithm using Monte Carlo Tree Search. The approach allows agents to adapt their actions or communicate (e.g., explain constraints, announce intent, ask questions) to resolve discrepancies. Experiments show that EPike outperforms the baseline Pike algorithm in success rate and failure rate, particularly on complex tasks, while being conservative to avoid rash incorrect actions when uncertain.

## Method Summary
The method extends conditional doxastic logic to model agents' nested beliefs about feasible plans, encoding these as knowledge bases (CSPs) within plausibility models. An online execution algorithm based on Monte Carlo Tree Search enables agents to plan actions considering others' potential actions and belief states. Agents can execute actions, announce intent, explain constraints, or ask questions to resolve belief discrepancies. The approach uses z3 for constraint satisfaction checking and incorporates communication costs into the utility function to balance adaptation versus communication.

## Key Results
- EPike achieves higher success rates and lower failure rates compared to baseline Pike algorithm
- Performance gap increases with task complexity (number of constraints)
- EPike demonstrates conservative behavior by avoiding rash incorrect actions when uncertain
- Runtime scales reasonably with task size but increases with number of differing constraints between agents

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The system can detect and resolve belief discrepancies by modeling nested beliefs using conditional doxastic logic.
- Mechanism: Agents maintain a plausibility model where each world encodes a knowledge base (set of constraints). Actions (execution, intent announcement, explanation, questions) update these models via plausibility action models, allowing agents to revise their beliefs when others act unexpectedly.
- Core assumption: Actions are public and agents can observe all teammate actions.
- Evidence anchors:
  - [abstract] "leverage epistemic logic to enable agents to understand the discrepancy in each other’s beliefs about feasible plans"
  - [section] "Our key insight is to extend conditional doxastic logic to describe knowledge bases"
  - [corpus] No direct evidence found in corpus; relies on epistemic logic literature.
- Break condition: If actions are not public or observations are incomplete, the belief revision mechanism fails.

### Mechanism 2
- Claim: The Monte Carlo Tree Search (MCTS) algorithm enables dynamic planning that accounts for others' potential actions and belief states.
- Mechanism: MCTS simulates forward k steps, considering execution and communication actions from all agents. It uses utility scores based on success probability and communication penalties, and can predict others' actions using recursive perspective-taking.
- Core assumption: Agents are rational and will take actions they believe are feasible from their perspective.
- Evidence anchors:
  - [abstract] "We provide an online execution algorithm based on Monte Carlo Tree Search for the agent to plan its action"
  - [section] "Our MCTS algorithm can be configured on... the termination conditions, including the horizon k"
  - [corpus] No direct evidence found in corpus; MCTS is standard technique.
- Break condition: If agents behave irrationally or have unpredictable communication patterns, MCTS predictions become unreliable.

### Mechanism 3
- Claim: Communication actions (explanations, intent announcements, questions) resolve belief discrepancies by adding/removing constraints from knowledge bases.
- Mechanism: Each communication action has a plausibility action model with preconditions (agent must believe the statement) and postconditions (modify knowledge base). This allows agents to explicitly state constraints or beliefs that resolve misunderstandings.
- Core assumption: Agents can only communicate what they currently believe to be true.
- Evidence anchors:
  - [abstract] "including communication actions to explain the feasibility of plans, announce intent, and ask questions"
  - [section] "The postcondition is restricted to a conjunction of in(c), which adds constraint c to the knowledge base"
  - [corpus] No direct evidence found in corpus; communication mechanisms are standard in epistemic logic.
- Break condition: If agents communicate false beliefs or lie, the belief resolution mechanism fails.

## Foundational Learning

- Epistemic Logic
  - Why needed here: Provides formal framework to represent agents' nested beliefs and belief revision when communication occurs
  - Quick check question: What does Baφ mean in conditional doxastic logic?
- Constraint Satisfaction Problems (CSP)
  - Why needed here: Knowledge bases are CSPs that encode feasible plans; solving them determines task success/failure
  - Quick check question: How does adding a constraint to the knowledge base affect plan feasibility?
- Monte Carlo Tree Search
  - Why needed here: Enables online planning that considers multiple agents' actions and belief states over future horizons
  - Quick check question: What is the role of the horizon parameter k in this MCTS implementation?

## Architecture Onboarding

- Component map:
  Plausibility Model -> Knowledge Base -> Action Models -> MCTS Planner -> Constraint Solver (z3)

- Critical path:
  1. Observe teammate action → update plausibility model
  2. MCTS simulates future actions and communication
  3. Select action (execution or communication) based on utility
  4. Take action → update knowledge base
  5. Repeat until success or failure

- Design tradeoffs:
  - Communication vs. Adaptation: Agent can either adapt to others' actions or communicate to align beliefs
  - Communication Cost: Penalized in MCTS to avoid excessive communication
  - Belief Revision: Conservative approach (zero score for unexpected actions) prevents rash decisions

- Failure signatures:
  - MCTS timeouts without finding feasible actions
  - Knowledge base becomes inconsistent (⊥)
  - Agents stuck in deadlock (all prefer noop)
  - Communication fails to resolve discrepancies

- First 3 experiments:
  1. Test basic task execution with shared beliefs (no communication needed)
  2. Test task with one constraint difference between agents (requires explanation)
  3. Test task with partial observability (requires questions to distinguish intent)

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the runtime performance of EPike scale with the number of agents beyond the 2-agent case studied in the paper?
- Basis in paper: [explicit] The paper states "we assume a task involves two agents (e.g. robot and human), though there is no theoretical barrier to applying it to more agents."
- Why unresolved: The experiments were only conducted with 2 agents, so the impact of increasing the number of agents on runtime and scalability is unknown.
- What evidence would resolve it: Running experiments with EPike on tasks involving 3 or more agents and measuring the runtime and success rates to compare against the 2-agent results.

### Open Question 2
- Question: How would EPike perform in scenarios with partially observable actions, where agents cannot fully observe each other's actions?
- Basis in paper: [explicit] The conclusion states "A natural next step is to consider cases where actions are partially observable."
- Why unresolved: The current EPike algorithm assumes all actions are public and fully observable, so its behavior and effectiveness in partially observable scenarios is untested.
- What evidence would resolve it: Modifying EPike to handle partial observability of actions and evaluating its performance on tasks where agents' actions are not fully observable to each other.

### Open Question 3
- Question: What is the impact of using different exploration parameters and horizons in the MCTS algorithm on EPike's performance?
- Basis in paper: [explicit] The paper mentions using specific exploration parameters and horizons, but does not explore the impact of varying them.
- Why unresolved: The chosen exploration parameters and horizons may not be optimal, and their impact on success rates and runtime is unknown.
- What evidence would resolve it: Conducting experiments with EPike using different combinations of exploration parameters and horizons to determine their effect on performance metrics.

## Limitations

- The experimental evaluation relies on synthetic test cases without real-world human-in-the-loop validation
- Runtime scalability analysis is limited to specific constraint generation method; performance with larger, more complex tasks remains untested
- Communication cost penalty is treated as a tunable parameter without clear justification for chosen values

## Confidence

- High confidence in the basic MCTS framework for online planning with multiple agents
- Medium confidence in the belief representation using conditional doxastic logic extensions
- Low confidence in the scalability claims and effectiveness of communication mechanisms in realistic scenarios

## Next Checks

1. Implement a simplified version of the plausibility action models and test belief revision with human subjects to validate the communication mechanisms actually resolve discrepancies as intended
2. Conduct experiments with varying communication cost parameters to determine the sensitivity of success rates to these values and identify optimal configurations
3. Test the approach on tasks with heterogeneous agent capabilities and unpredictable human behavior patterns to evaluate robustness beyond the synthetic test cases presented