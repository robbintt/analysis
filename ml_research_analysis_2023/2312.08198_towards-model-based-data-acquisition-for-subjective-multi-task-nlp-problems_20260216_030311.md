---
ver: rpa2
title: Towards Model-Based Data Acquisition for Subjective Multi-Task NLP Problems
arxiv_id: '2312.08198'
source_url: https://arxiv.org/abs/2312.08198
tags:
- data
- dataset
- labels
- text
- annotations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper tackles the expensive and time-consuming process of
  annotating subjective NLP tasks like offensiveness or emotion detection. To minimize
  annotation costs, the authors propose a novel model-based approach that selects
  which tasks to annotate individually for each text in a multi-task scenario.
---

# Towards Model-Based Data Acquisition for Subjective Multi-Task NLP Problems

## Quick Facts
- arXiv ID: 2312.08198
- Source URL: https://arxiv.org/abs/2312.08198
- Reference count: 40
- Key outcome: Model-based approach reduces annotation effort by up to 40% for subjective multi-task NLP with negligible knowledge loss

## Executive Summary
This paper addresses the expensive process of annotating subjective NLP tasks like offensiveness and emotion detection by proposing a novel model-based data acquisition approach. The method uses a small set of human annotations to train a model that predicts Valuable Text Label (VTL) scores, indicating which labels are worth annotating for each text. By focusing human annotation effort on high-value labels and using model predictions for low-value ones, the approach significantly reduces annotation costs while maintaining knowledge quality.

## Method Summary
The method trains a model on initial human annotations to predict VTL scores for each label and text combination. These scores indicate the likelihood of a label being valuable (having non-zero annotations above threshold t). Labels with low VTL scores are automatically annotated by the model, while high VTL labels are assigned to human annotators. The approach uses pre-trained transformers (HerBERT for Polish, XLM-RoBERTa for English) and evaluates performance in both single-task and multi-task scenarios across three datasets with dozens of NLP tasks.

## Key Results
- Up to 40% reduction in annotation effort with negligible knowledge loss
- Effective performance across three datasets with 23, 8, and 10 tasks respectively
- Multi-task learning shows improved performance compared to single-task approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Training a small initial model on a few human annotations can predict Valuable Text Label (VTL) scores that indicate which labels are worth annotating for each text.
- Mechanism: The model learns the correlation between text features and the distribution of human annotations per label, enabling it to predict which labels will likely have high agreement among future annotators.
- Core assumption: There exists a learnable relationship between text characteristics and the likelihood of a label being valuable (non-zero annotations above threshold t).
- Evidence anchors:
  - [abstract] "To minimize these costs, we propose a new model-based approach that allows the selection of tasks annotated individually for each text in a multi-task scenario."
  - [section] "To estimate how valuable the label l (problem, task) should be considered for text d, we developed a new measure called the Valuable Text Label (VTL)."
  - [corpus] Weak - the related papers focus on multi-task learning and subjective annotation but do not specifically address VTL prediction.
- Break condition: If the relationship between text features and label value is too complex or inconsistent across datasets, the model's VTL predictions become unreliable.

### Mechanism 2
- Claim: Using the model's VTL predictions to filter labels reduces annotation effort without significant loss of knowledge.
- Mechanism: Labels predicted as non-valuable (VTL = 0) are automatically set to zero, freeing annotators to focus on high-value labels, while self-supervised training on the model's predictions can act as regularization.
- Core assumption: The cost savings from skipping low-value labels outweighs the potential loss from incorrect predictions.
- Evidence anchors:
  - [abstract] "The experiments carried out on three datasets, dozens of NLP tasks, and thousands of annotations show that our method allows up to 40% reduction in the number of annotations with negligible loss of knowledge."
  - [section] "The VTL values received from the model are used to decide whether the label should be annotated by humans ( ˆy ∈ { 1}) or should it be done automatically by the model ( ˆy ∈ { 0})."
  - [corpus] Weak - related work discusses annotation efficiency but not the specific model-based filtering approach.
- Break condition: If the model's false negative rate for valuable labels is too high, significant knowledge is lost despite effort reduction.

### Mechanism 3
- Claim: Multi-task learning with VTL prediction improves performance on subjective NLP tasks compared to single-task approaches.
- Mechanism: Simultaneously predicting VTL for multiple labels allows the model to learn inter-task relationships and shared representations, improving overall accuracy.
- Core assumption: Subjective tasks share underlying linguistic patterns that can be jointly learned.
- Evidence anchors:
  - [abstract] "We also focused on measuring the relation between subjective tasks by evaluating the model in single-task and multi-task scenarios."
  - [section] "In this way, we are able to select texts that are more relevant to individual tasks, which is very important in multi-task scenarios."
  - [corpus] Weak - related papers discuss multi-task learning but not specifically for VTL prediction or subjective tasks.
- Break condition: If tasks are too dissimilar, joint learning may hurt performance on individual tasks.

## Foundational Learning

- Concept: VTL (Valuable Text Label) metric
  - Why needed here: Provides a quantitative measure to decide if a label is worth annotating for a specific text based on historical annotation patterns.
  - Quick check question: How is VTL calculated and what does it represent?

- Concept: Self-supervised learning with predicted labels
  - Why needed here: Allows the model to improve by treating its own VTL predictions as pseudo-labels, acting as regularization.
  - Quick check question: What is the purpose of training the model on labels it predicted itself?

- Concept: Multi-task learning benefits
  - Why needed here: Enables the model to learn shared representations and inter-task relationships between subjective NLP tasks.
  - Quick check question: How does training on multiple tasks simultaneously improve performance compared to training separately?

## Architecture Onboarding

- Component map: Input text → Preprocessing → VTL prediction model (HerBERT/XLM-RoBERTa) → Output VTL scores → Annotation decision (human vs. model) → Final labeled dataset
- Critical path: Model training on initial annotations → VTL prediction for new texts → Annotation effort reduction decision
- Design tradeoffs: More complex model architecture vs. annotation efficiency gains; threshold t value selection impacts precision-recall tradeoff
- Failure signatures: High false negative rate (missing valuable labels), model overfitting to initial dataset, threshold t too conservative/aggressive
- First 3 experiments:
  1. Train VTL prediction model on small initial dataset and evaluate on held-out validation set
  2. Apply model to new texts and measure AER (Annotation Effort Reduction) vs. AAL (Absolute Annotation Loss)
  3. Compare single-task vs. multi-task performance on subjective NLP tasks using VTL-filtered data

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do the proposed metrics (AER, AAL, MLRAL, MB) perform in different subjective NLP tasks beyond those evaluated in the paper?
- Basis in paper: [explicit] The authors propose these metrics and evaluate them on three datasets (Doccano 1.0, UC, MHS) for various subjective tasks like offensiveness, emotions, and humor.
- Why unresolved: The evaluation is limited to a specific set of tasks and datasets. The performance of these metrics in other subjective NLP tasks or domains is unknown.
- What evidence would resolve it: Apply the proposed metrics to a diverse range of subjective NLP tasks and datasets to assess their generalizability and effectiveness in different contexts.

### Open Question 2
- Question: How does the model-based data acquisition approach handle evolving subjective NLP tasks and shifting human perceptions over time?
- Basis in paper: [inferred] The authors assume a static annotation process and do not address how the approach adapts to changes in subjective task definitions or human perceptions.
- Why unresolved: Subjective NLP tasks and human perceptions can evolve, leading to potential drift in the effectiveness of the model-based approach. The paper does not discuss how to handle such changes.
- What evidence would resolve it: Conduct longitudinal studies to evaluate the model-based approach's performance over time and investigate techniques to adapt to evolving subjective tasks and shifting human perceptions.

### Open Question 3
- Question: What is the impact of the model-based data acquisition approach on the diversity and representativeness of the annotated data?
- Basis in paper: [inferred] The authors focus on reducing annotation effort but do not explicitly discuss the impact on data diversity and representativeness.
- Why unresolved: Reducing annotation effort through model predictions may lead to biased or less diverse data, potentially affecting the model's performance and generalizability. The paper does not address this concern.
- What evidence would resolve it: Analyze the diversity and representativeness of the data annotated using the model-based approach compared to traditional annotation methods. Investigate techniques to ensure diversity and representativeness while reducing annotation effort.

## Limitations
- The exact neural architecture for VTL prediction is underspecified beyond mentioning pre-trained transformers
- Threshold t for determining "valuable" annotations is critical but its optimal selection methodology is not clearly detailed
- The claim of 40% annotation reduction with "negligible" knowledge loss lacks precise quantification

## Confidence
- **High Confidence**: The overall framework of using model predictions to reduce annotation effort in multi-task subjective NLP is well-founded and theoretically sound
- **Medium Confidence**: The specific claim of 40% reduction with negligible loss is supported by experiments but the precise methodology for measuring "negligible" could be more rigorous
- **Low Confidence**: The self-supervised learning component's contribution to performance gains is not clearly isolated from other factors in the experimental results

## Next Checks
1. Conduct ablation studies to quantify the exact contribution of self-supervised learning on predicted labels versus traditional training approaches
2. Test the robustness of VTL predictions across different threshold values (t) and analyze the precision-recall tradeoff in annotation decisions
3. Validate the multi-task learning benefits by comparing against a carefully designed single-task baseline with equivalent model capacity