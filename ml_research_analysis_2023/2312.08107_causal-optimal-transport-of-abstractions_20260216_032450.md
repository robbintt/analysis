---
ver: rpa2
title: Causal Optimal Transport of Abstractions
arxiv_id: '2312.08107'
source_url: https://arxiv.org/abs/2312.08107
tags:
- cota
- causal
- abstraction
- transport
- optimal
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes COTA, the first method to learn causal abstractions
  from observational and interventional data without assuming complete knowledge of
  underlying SCMs. The authors formulate causal abstraction learning as a multi-marginal
  optimal transport problem with do-calculus constraints and a causally-informed cost
  function.
---

# Causal Optimal Transport of Abstractions

## Quick Facts
- arXiv ID: 2312.08107
- Source URL: https://arxiv.org/abs/2312.08107
- Authors: 
- Reference count: 40
- Primary result: First method to learn causal abstractions from observational and interventional data without assuming complete knowledge of underlying SCMs, outperforming non-causal baselines and state-of-the-art causal abstraction learning frameworks.

## Executive Summary
This paper introduces COTA, a novel method for learning causal abstractions from observational and interventional data without requiring complete specification of underlying structural causal models (SCMs). The approach formulates causal abstraction learning as a multi-marginal optimal transport problem with do-calculus constraints and a causally-informed cost function. COTA demonstrates superior performance compared to non-causal baselines and existing causal abstraction frameworks on both synthetic and real-world problems, marking a significant advancement in causal representation learning.

## Method Summary
COTA learns causal abstractions by treating observational and interventional distributions as marginals in a multi-marginal optimal transport problem. The method jointly learns a transport plan that satisfies do-calculus constraints across all marginals while using a causally-informed cost function that discounts transport costs based on intervention compatibility. The optimization problem is jointly convex, guaranteeing an optimal solution. The framework operates on SCMs at different granularities, leveraging interventional data to enforce causal consistency between base and abstracted models.

## Key Results
- COTA outperforms non-causal baselines and state-of-the-art causal abstraction frameworks that assume fully specified SCMs
- The causally-informed cost function cω provides more relevant information for learning abstractions compared to conventional costs
- The method achieves superior performance on both synthetic SCMs and real-world problems including STC, LUCAS, and EBM datasets

## Why This Works (Mechanism)

### Mechanism 1
Causal abstraction learning is cast as a multi-marginal optimal transport problem where observational and interventional distributions act as marginals. By treating each intervention-abstracted pair as a marginal in a Kantorovich OT problem, the method jointly learns a single transport plan that satisfies do-calculus constraints across all marginals. The intervention sets from base and abstracted models must be related by an order-preserving map ω, and samples from these interventions must be available.

### Mechanism 2
A causally-informed cost function cω discounts transport cost between samples based on their compatibility under interventions. The cost is defined as cω(x,x') = |I| − Σᵢ 1[Cmp(x,ι) ∧ Cmp(x',ω(ι))], rewarding low cost for pairs consistent with multiple intervention pairs. This requires an intervention set that is sufficiently rich and diverse to encode meaningful compatibility relations between base and abstracted model samples.

### Mechanism 3
The objective function is jointly convex in the transport plans, guaranteeing an optimal solution. Joint convexity follows from convexity of the inner product, joint convexity of the Bregman divergence term, and strict convexity of the entropy regularizer. The transport plans must lie in the convex set of stochastic matrices with given marginals, and Bregman divergences must be jointly convex in their arguments.

## Foundational Learning

- Concept: Structural Causal Models (SCMs)
  - Why needed here: The entire framework operates on SCMs at different granularities and assumes knowledge of their DAGs.
  - Quick check question: Given an SCM M = ⟨X,U,F,P(U)⟩, what does the set F represent and how does it define the DAG?

- Concept: Do-calculus and interventional distributions
  - Why needed here: The method uses do-calculus constraints to relate interventional distributions across models and enforce causal consistency.
  - Quick check question: For interventions ι = do(A=a) and η = do(B=b) with ι ⪯ η, how does the g-formula relate PM_ι and PM_η?

- Concept: Optimal Transport theory (Kantorovich formulation)
  - Why needed here: The learning problem is formulated as a multi-marginal OT problem where marginals are interventional distributions.
  - Quick check question: In the Kantorovich formulation, what set U(α,β) represents and what constraints define it?

## Architecture Onboarding

- Component map: Data ingestion -> Cost matrix construction -> Multi-marginal OT solver -> Plan aggregation -> Evaluation
- Critical path: Sample collection → Cost matrix construction → Multi-marginal OT optimization → Plan aggregation → Abstraction evaluation
- Design tradeoffs:
  - Entropy regularization ϵ: Higher values speed computation (Sinkhorn) but reduce fidelity to true OT
  - Intervention set size: Larger sets improve ω-cost informativeness but increase computational complexity
  - Constraint weighting λ: Balancing causal constraints vs transport fidelity affects abstraction quality
- Failure signatures:
  - Poor abstraction error: Often indicates weak intervention set or inappropriate cost function
  - Non-convergence: May result from improper entropy regularization or ill-conditioned cost matrices
  - High variance across runs: Suggests sensitivity to initialization or insufficient sample size
- First 3 experiments:
  1. Simple chain SCM with known abstraction (e.g., Smoking → Tar → Cancer, abstract to remove Tar) to verify basic functionality
  2. Vary intervention set size and diversity to test ω-cost sensitivity
  3. Compare COTA against independent OT baseline on synthetic SCMs with ground truth abstractions

## Open Questions the Paper Calls Out

### Open Question 1
How does the performance of COTA scale with the size and diversity of the intervention set? The authors discuss the sensitivity of the ω-cost function to intervention set size and diversity, noting that a larger and more diverse set leads to better performance. A systematic study varying these parameters across multiple datasets would resolve this question.

### Open Question 2
Can COTA be extended to handle semi-Markovian SCMs where the causal sufficiency assumption is violated? The authors mention that extending COTA to semi-Markovian SCMs presents significant challenges due to potential unidentifiability of certain causal constraints. A theoretical analysis of identifiability in this setting and a modified COTA algorithm would be needed.

### Open Question 3
How does COTA compare to other state-of-the-art causal abstraction learning methods in terms of computational efficiency and scalability? The paper provides limited comparison in terms of computational properties. A systematic evaluation of COTA's computational efficiency and scalability against other methods on benchmark datasets would address this gap.

## Limitations
- The method assumes intervention sets are related by an order-preserving map ω, which may not hold in real-world scenarios with complex intervention structures
- Performance claims lack extensive ablation studies on intervention set characteristics
- The intervention-aware cost function's effectiveness without a sufficiently rich intervention set is not fully characterized

## Confidence
- High confidence: The basic formulation as a multi-marginal OT problem; the theoretical framework connecting do-calculus to transport constraints
- Medium confidence: The effectiveness of cω in practice; the scalability to real-world SCMs
- Low confidence: Performance claims without extensive ablation studies on intervention set characteristics; generalization to non-chain-like DAG structures

## Next Checks
1. Conduct controlled experiments varying intervention set size and diversity to quantify the sensitivity of cω and overall COTA performance to these factors
2. Implement a simplified version of COTA using Hamming distance instead of cω to test whether the intervention-aware cost provides meaningful improvement
3. Test COTA on SCMs with more complex DAG structures (e.g., v-structures, undirected cycles) to evaluate robustness beyond chain-like relationships