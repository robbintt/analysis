---
ver: rpa2
title: 'RoCar: A Relationship Network-based Evaluation Method for Large Language Models'
arxiv_id: '2307.15997'
source_url: https://arxiv.org/abs/2307.15997
tags:
- evaluation
- llms
- graph
- task
- tasks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces RoCar, a graph-based evaluation method for
  large language models (LLMs) designed to assess reasoning and memory capabilities.
  RoCar constructs randomized social network task graphs using 27 predefined relationship
  schemas, ensuring fairness by preventing models from pre-learning evaluation tasks.
---

# RoCar: A Relationship Network-based Evaluation Method for Large Language Models

## Quick Facts
- arXiv ID: 2307.15997
- Source URL: https://arxiv.org/abs/2307.15997
- Reference count: 23
- Primary result: Graph-based evaluation method for LLMs using random social network task graphs

## Executive Summary
This paper introduces RoCar, a graph-based evaluation method designed to assess reasoning and memory capabilities of large language models. RoCar constructs randomized social network task graphs using 27 predefined relationship schemas, ensuring fairness by preventing models from pre-learning evaluation tasks. The method evaluates LLMs on tasks derived from these graphs, with Claude achieving the highest overall performance and ChatGPT showing relatively poor reasoning task performance, likely due to lower Chinese comprehension.

## Method Summary
RoCar constructs task graphs from 27 relationship schemas, generating natural language evaluation tasks to test LLMs on reasoning and memory capabilities. The method randomly selects and splices basic relationship schemas to create task graphs, then converts these into prompts for evaluation. Tasks are weighted based on graph distance for reasoning and step count for memory assessment. The evaluation focuses on Chinese-language models and tasks.

## Key Results
- Claude achieved the highest overall performance in RoCar evaluation
- ChatGPT performed poorly in reasoning tasks, likely due to lower Chinese comprehension
- RoCar demonstrated potential for fair, randomized LLM evaluation
- Method showed effectiveness in distinguishing LLM capabilities across reasoning and memory dimensions

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Random graph generation ensures fairness by preventing pre-training bias in evaluation tasks.
- Mechanism: RoCar constructs evaluation tasks from randomly generated social network graphs using predefined relationship schemas, making it unlikely that any LLM has encountered these specific task configurations during training.
- Core assumption: The random construction process produces sufficiently diverse and novel task graphs that are not present in LLM training corpora.
- Evidence anchors:
  - [abstract]: "Due to the very large randomness of the task construction process, it is possible to ensure that none of the LLMs to be tested has directly learned the evaluation tasks, guaranteeing the fairness of the evaluation method."
  - [section 2.2]: "For this set of basic schemas, we first perform a random ordering... For each selected basic schema, we randomly chose a relationship in the constructed task graph for splicing."
- Break condition: If the random generation process produces repetitive patterns or if the predefined relationship schemas are too common in existing datasets.

### Mechanism 2
- Claim: Task graph complexity correlates with reasoning and memory capability assessment.
- Mechanism: RoCar evaluates LLMs by varying the distance between nodes in the task graph, with longer distances requiring more complex reasoning and memory retention, weighted accordingly in scoring.
- Core assumption: Graph distance effectively captures the complexity of reasoning and memory requirements.
- Evidence anchors:
  - [section 3.1]: "For the evaluation of reasoning ability, we divided the evaluation tasks into groups according to the distance between the two people in the evaluation tasks on the task graph... the longer the distance the greater the weight of the evaluation task."
  - [section 3.1]: "For the memory capability evaluation... we informed the LLMs about the task graph in multiple steps... The higher the number of steps, the higher the weight of the corresponding test result."
- Break condition: If LLMs can bypass distance-based complexity through pattern matching or if certain graph configurations don't increase actual cognitive load.

### Mechanism 3
- Claim: Multi-modal evaluation (reasoning and memory) provides comprehensive LLM capability assessment.
- Mechanism: RoCar separately evaluates reasoning (graph traversal inference) and memory (information retention over multiple steps), combining both scores for overall capability assessment.
- Core assumption: Reasoning and memory are distinct capabilities that together provide a complete picture of LLM performance.
- Evidence anchors:
  - [abstract]: "We propose the RoCar method, which utilizes the defined basic schemas to randomly construct a task graph and generates natural language evaluation tasks based on the task graph to evaluate the reasoning and memory abilities of LLMs respectively."
  - [section 3.1]: "Our work focuses on evaluating LLMs in terms of both reasoning and memory capabilities."
- Break condition: If reasoning and memory capabilities are too interdependent to assess separately or if other capabilities (like planning) are more important.

## Foundational Learning

- Concept: Graph theory and network topology
  - Why needed here: Understanding how relationships form networks and how distance between nodes affects traversal complexity is crucial for interpreting RoCar's evaluation methodology.
  - Quick check question: How does increasing the distance between two nodes in a graph typically affect the computational complexity of finding a path between them?

- Concept: Randomization in evaluation methodology
  - Why needed here: The fairness of RoCar depends on understanding how randomization prevents bias and ensures novel task generation.
  - Quick check question: What statistical properties should a good randomization process have to ensure fair and unbiased evaluation?

- Concept: Natural language processing evaluation metrics
  - Why needed here: Understanding how to score LLM responses for correctness, especially when dealing with complex relational reasoning and memory tasks.
  - Quick check question: What are the challenges in creating objective evaluation metrics for subjective tasks like relationship reasoning?

## Architecture Onboarding

- Component map:
  - Schema Definition: 27 relationship types with gender, order, and direction attributes
  - Graph Generator: Random task graph construction using basic schemas
  - Prompt Converter: Transforms graph structures into natural language prompts
  - Evaluation Engine: Tests LLMs on reasoning and memory tasks
  - Scoring System: Weights results based on task complexity and distance

- Critical path: Schema Definition → Graph Generator → Prompt Converter → Evaluation Engine → Scoring System

- Design tradeoffs:
  - Randomness vs. control: More randomness increases fairness but reduces reproducibility
  - Complexity vs. tractability: More complex graphs better test capabilities but may exceed LLM limits
  - Language specificity vs. generality: Chinese-focused evaluation may not generalize to other languages

- Failure signatures:
  - Inconsistent scoring across similar tasks (suggests randomness issues)
  - LLMs performing poorly on all tasks (suggests task complexity too high)
  - Certain relationship types consistently causing failures (suggests schema bias)

- First 3 experiments:
  1. Generate 10 random task graphs and verify they meet basic validity constraints (no circular references, proper gender matching)
  2. Test a simple LLM on distance-2 reasoning tasks to establish baseline performance
  3. Compare reasoning vs. memory performance on identical graph structures to validate separation of capabilities

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the number of relationship types in the RoCar method be expanded to better reflect real-world social networks?
- Basis in paper: [explicit] The paper suggests combining social networks with other types of graphs to construct more realistic and complex task graphs.
- Why unresolved: The current implementation uses a limited set of 27 relationship types, which may not fully capture the complexity of real-world social networks.
- What evidence would resolve it: Evidence would include empirical results showing improved evaluation accuracy when using a larger and more diverse set of relationship types.

### Open Question 2
- Question: What impact do relationships that exist in reality but are not in line with naive values have on the evaluation of LLMs?
- Basis in paper: [explicit] The paper suggests adding relationships that exist in reality but are not in line with naive values to evaluate LLMs in terms of values alignment, bias, and harmfulness.
- Why unresolved: The current implementation does not include such relationships, which may limit the evaluation's ability to assess LLMs' ethical considerations.
- What evidence would resolve it: Evidence would include results showing how LLMs perform on tasks involving these complex relationships, highlighting potential biases or ethical issues.

### Open Question 3
- Question: How does the sensitivity of different LLMs to the types and formats of prompts affect their evaluation scores?
- Basis in paper: [explicit] The paper suggests enriching the types and formats of prompts and validating the sensitivity of different LLMs to the prompts.
- Why unresolved: The current evaluation method may not account for variations in how different LLMs respond to different prompt formats, potentially affecting fairness.
- What evidence would resolve it: Evidence would include comparative studies showing how changes in prompt formats influence the evaluation scores of different LLMs.

## Limitations
- Limited validation of fairness claims through randomization
- Potential language-specific bias in evaluation (Chinese-focused)
- Theoretical assumptions about graph complexity not empirically validated

## Confidence
- RoCar's overall methodology (Medium): The approach is well-structured but relies heavily on theoretical assumptions about randomness and graph complexity
- Fairness claims (Low): Insufficient empirical validation that random generation produces genuinely novel tasks
- Multi-modal evaluation effectiveness (Medium): Separate reasoning and memory assessment is logical but lacks comparative validation
- Performance rankings (Medium): Results show clear differences but may reflect language-specific biases

## Next Checks
1. Schema Coverage Analysis: Analyze whether the 27 relationship schemas are sufficiently diverse and whether they appear in common LLM training datasets to validate the fairness assumption

2. Complexity Metric Validation: Compare RoCar's graph distance metric against alternative complexity measures (such as branching factor or relationship density) to confirm it accurately captures reasoning difficulty

3. Cross-Lingual Testing: Evaluate RoCar on LLMs trained on different language datasets to determine whether the method's effectiveness is language-dependent or generalizes across linguistic contexts