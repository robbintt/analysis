---
ver: rpa2
title: Unsupervised Lexical Simplification with Context Augmentation
arxiv_id: '2311.00310'
source_url: https://arxiv.org/abs/2311.00310
tags:
- context
- gpt-3
- lexical
- target
- word
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes an unsupervised lexical simplification method
  using monolingual data and pre-trained language models. The approach generates substitutes
  by combining predictions from the target context with additional contexts sampled
  from monolingual data, and reranking using embedding similarity, LM perplexity,
  word frequency, and context augmentation scores.
---

# Unsupervised Lexical Simplification with Context Augmentation

## Quick Facts
- arXiv ID: 2311.00310
- Source URL: https://arxiv.org/abs/2311.00310
- Reference count: 18
- State-of-the-art results on TSAR-2022 shared task and SWORDS lexical substitution dataset

## Executive Summary
This paper introduces an unsupervised approach to lexical simplification that generates substitutes by combining predictions from the target context with additional contexts sampled from monolingual data. The method clusters these augmented contexts, aggregates substitutes within each cluster, and reranks candidates using embedding similarity, language model perplexity, word frequency, and context augmentation scores. Evaluated across English, Portuguese, and Spanish, the model substantially outperforms other unsupervised systems and achieves state-of-the-art results when ensembled with GPT-3.5.

## Method Summary
The method generates lexical simplification substitutes through a two-stage process. First, it generates initial substitutes from the target context using a masked language model approach. Second, it samples 300 sentences containing the target word from monolingual data, clusters them into 4 groups using K-means, and generates substitutes for each cluster. These substitutes are then weighted based on semantic relevance to the target context and combined with the initial substitutes. A four-metric reranking (embedding similarity, LM perplexity, word frequency, context augmentation score) produces the final ranked list of candidates.

## Key Results
- Outperforms all other unsupervised systems on TSAR-2022 shared task in English, Portuguese, and Spanish
- Establishes new state-of-the-art on SWORDS lexical substitution dataset
- When ensembled with GPT-3.5-turbo, achieves top performance across all languages and datasets
- Demonstrates that context augmentation significantly improves substitution quality, especially for ambiguous or rare words

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Context augmentation improves lexical simplification by providing additional semantic contexts for target words.
- Mechanism: The model samples sentences containing the target word from monolingual data, clusters them by semantic similarity, and uses the augmented contexts to generate more accurate substitutes through weighted aggregation.
- Core assumption: Target words have multiple senses across different contexts, and the target context may not always be discriminative enough to capture the correct sense.
- Evidence anchors: Abstract states method generates substitutes from target context and additional contexts from monolingual data; section notes difficulty predicting substitutes when context is not specific.

### Mechanism 2
- Claim: Combining static embeddings with contextual embeddings improves representation quality for rare or subword-tokenized words.
- Mechanism: When the target word is segmented into multiple tokens, the model adds a term based on static fastText embeddings to complement the averaged subword embeddings from the contextual model.
- Core assumption: Static embeddings trained on larger vocabularies capture better semantic representations for rare words than averaged subword embeddings.
- Evidence anchors: Section explains that static embeddings pre-trained with large vocabulary (e.g., 200k words) tend to represent semantics of rare words better than averaging subword embeddings.

### Mechanism 3
- Claim: Weighted aggregation of cluster-based substitutes based on semantic relevance to target context improves substitute quality.
- Mechanism: The model clusters augmented contexts, aggregates substitutes within each cluster, and weights them based on overlap with substitutes from the target context.
- Core assumption: Clusters represent different senses of the target word, and some clusters are more semantically relevant to the target context than others.
- Evidence anchors: Section states that wk roughly corresponds to semantic relevance of cluster k to target context; Table 4 shows example where clustering plays crucial role.

## Foundational Learning

- Concept: Masked Language Models (MLMs) and their limitations for lexical simplification
  - Why needed here: Understanding why the paper moves beyond standard MLM approaches is crucial for grasping the novelty
  - Quick check question: Why might standard MLM prediction fail when the target context is not very discriminative?

- Concept: Context augmentation and its role in semantic disambiguation
  - Why needed here: The core innovation relies on augmenting target contexts with additional semantic contexts
  - Quick check question: How does sampling additional contexts help when the original context is ambiguous or rare?

- Concept: Static vs. contextual embeddings and their complementary strengths
  - Why needed here: The model combines these embedding types to handle rare words and subword tokenization issues
  - Quick check question: What are the trade-offs between static embeddings (trained on large vocabularies) and contextual embeddings?

## Architecture Onboarding

- Component map:
  Input -> Target context substitute generation -> Monolingual data sampling -> Clustering -> Augmented context substitute generation -> Weighted aggregation -> Reranking (4 metrics) -> Output

- Critical path:
  1. Generate initial substitutes from target context
  2. Sample and cluster augmented contexts
  3. Generate substitutes from augmented contexts
  4. Rerank combined candidates using four metrics
  5. Output final ranked list

- Design tradeoffs:
  - Monolingual data sampling vs. computational cost
  - Cluster number (K=4) vs. granularity of sense distinctions
  - Weight tuning for reranking metrics vs. generality across languages
  - FastText vs. other static embeddings for rare word handling

- Failure signatures:
  - Poor performance on words with very few occurrences in monolingual data
  - Over-reliance on target context when it's not discriminative
  - Cluster assignments that don't reflect true semantic distinctions
  - Reranking that favors frequency over semantic fit

- First 3 experiments:
  1. Test context augmentation alone vs. target context generation to isolate its contribution
  2. Vary the number of clusters (K) to find optimal balance between specificity and coverage
  3. Compare different static embeddings (fastText vs. GloVe) for rare word handling

## Open Questions the Paper Calls Out

The paper raises several important questions about lexical simplification datasets and evaluation. It notes that GPT-3.5 performs very well even without access to the target context, suggesting that most instances in current datasets are not very context-dependent. This raises questions about the goal of lexical simplification/substitution and its annotation schemes. The paper also suggests that incorporating POS tagging could help address errors where the model predicts semantically inappropriate substitutions, but does not implement this experimentally.

## Limitations

- Performance may degrade for rare words with insufficient occurrences in monolingual data
- Heavy dependence on careful tuning of reranking weights and quality of monolingual corpora
- Fixed cluster number (K=4) may not optimally capture sense distinctions for all words
- Limited exploration of alternative static embeddings or adaptive clustering approaches

## Confidence

- Context augmentation effectiveness: Medium - Strong experimental results but limited analysis of edge cases with sparse monolingual data
- Static + contextual embedding combination: Medium - Theoretically sound but relies on fastText quality across languages
- Cluster-based weighting: Medium - K=4 choice lacks sensitivity analysis and systematic validation across word types
- Reranking mechanism: Medium - Performance depends heavily on weight tuning and metric quality

## Next Checks

1. **Monolingual Data Coverage Analysis**: Systematically evaluate model performance as a function of the number of sampled sentences (e.g., 50, 100, 200, 300, 500) to determine the minimum effective context augmentation threshold and identify failure points.

2. **Cluster Sensitivity Testing**: Conduct experiments varying the number of clusters (K=2, 3, 4, 5, 6) across different word types to determine if the fixed K=4 choice is optimal or if adaptive clustering would improve results.

3. **Static Embedding Ablation**: Replace fastText with alternative static embeddings (e.g., GloVe, Word2Vec) and evaluate the impact on rare word performance to validate the claimed advantage of static embeddings for subword-tokenized words.