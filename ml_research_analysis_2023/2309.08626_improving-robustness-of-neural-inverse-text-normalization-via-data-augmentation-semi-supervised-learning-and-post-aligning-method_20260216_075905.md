---
ver: rpa2
title: Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation,
  Semi-Supervised Learning, and Post-Aligning Method
arxiv_id: '2309.08626'
source_url: https://arxiv.org/abs/2309.08626
tags:
- text
- written
- spoken
- neural
- type
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses the performance degradation of neural inverse
  text normalization (ITN) when applied to automatic speech recognition (ASR)-generated
  text due to the out-of-domain problem between training data and ASR-generated text.
  To resolve this, the authors propose a direct training approach that utilizes ASR-generated
  written or spoken text, with pairs augmented through ASR linguistic context emulation
  and a semi-supervised learning method enhanced by a large language model, respectively.
---

# Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method

## Quick Facts
- arXiv ID: 2309.08626
- Source URL: https://arxiv.org/abs/2309.08626
- Reference count: 0
- Key outcome: Proposed methods improved ITN performance with 95.18% relative improvement in CER on ASR test sets

## Executive Summary
This paper addresses the challenge of domain mismatch between neural inverse text normalization (ITN) training data and automatic speech recognition (ASR) output, which causes performance degradation when applying ITN to ASR-generated text. The authors propose a direct training approach using ASR-generated written and spoken text, augmented through linguistic context emulation and semi-supervised learning enhanced by a large language model (LLM). Additionally, they introduce a post-aligning method to manage unpredictable errors and improve ITN reliability. The proposed methods demonstrated remarkable performance improvements across various ASR scenarios.

## Method Summary
The proposed method combines three approaches: data augmentation (DA) that emulates ASR linguistic context by applying noise to written text and multi-text normalization to generate pseudo-spoken text; semi-supervised learning (SSL) that leverages unlabeled ASR-generated text through a teacher-student model with LLM-based confidence scoring to filter pseudo-written text; and a post-aligning (PA) method that analyzes multiple ITN hypotheses to detect and correct discrepancies. The system uses a transformer-based seq2seq architecture with 12 encoder and 1 decoder layer, trained on Korean spoken-written text pairs with various noise types including repetition, number substitution, and spacing noise.

## Key Results
- 95.18% relative improvement in character error rate (CER) on ASR test sets with ITN labels
- Significant improvements in both I-CER (ITN CER) and NI-CER (Non-ITN CER) across multiple ASR scenarios
- Post-aligning method consistently improved performance in both ASR-TEL and ASR-BCN test sets
- Data augmentation and semi-supervised learning approaches showed complementary benefits when combined

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Direct training on ASR-generated text reduces domain mismatch between ITN training data and ASR output.
- Mechanism: The proposed data augmentation and semi-supervised learning pipelines generate spoken-written text pairs directly from ASR output, allowing the neural ITN to learn the specific linguistic patterns and errors characteristic of ASR-generated text.
- Core assumption: ASR-generated spoken text has distinct linguistic patterns (e.g., irregular interjections, spacing errors) compared to general spoken text used in traditional ITN training.
- Evidence anchors:
  - [abstract] "These challenges arise from the out-of-domain problem between training data and ASR-generated text."
  - [section 2.1] "DA emulates the linguistic context of ASR-generated spoken text to enhance the robustness of neural ITN"
  - [corpus] Weak evidence; corpus neighbors don't directly address domain adaptation for ASR-generated text.
- Break condition: If ASR-generated text does not exhibit distinct linguistic patterns from general spoken text, the domain adaptation benefit would diminish.

### Mechanism 2
- Claim: Confidence scoring using a large language model (LLM) improves the quality of pseudo-written text in semi-supervised learning.
- Mechanism: The LLM-based confidence scoring evaluates the naturalness of pseudo-written text generated by the ITN model, filtering out unnatural or incorrect conversions that traditional likelihood-based methods might miss.
- Core assumption: LLMs trained on vast natural language data can effectively discriminate linguistically unnatural sentences.
- Evidence anchors:
  - [section 2.2] "LLMs have the potential to assess naturalness effectively... Considering that LLMs are trained on a vast amount of natural language data, and naturalness can be defined by expressions commonly used by people, LLMs have the potential to discriminate linguistically unnatural sentences."
  - [section 4.2] "The ideal confidence scoring method for ITN should assess the naturalness of written text converted by neural ITN"
  - [corpus] Weak evidence; corpus neighbors don't directly address LLM-based confidence scoring for ITN.
- Break condition: If the LLM fails to accurately assess naturalness or if the pseudo-written text is too dissimilar from the LLM's training data, the filtering process may not effectively improve ITN training.

### Mechanism 3
- Claim: The post-aligning (PA) method reduces unpredictable errors by leveraging multiple ITN hypotheses and targeted replacements.
- Mechanism: PA detects discrepancies between spoken text and ITN hypotheses, making targeted replacements based on normalization pairs derived from multiple hypotheses, not just the top-ranked one.
- Core assumption: Multiple ITN hypotheses contain useful information for improving normalization accuracy, and discrepancies between spoken and written text can be effectively identified and corrected.
- Evidence anchors:
  - [section 3] "PA detects discrepancies between spoken and neural ITN hypotheses, making targeted replacements. It also utilizes all neural ITN hypotheses, not just the top-ranked one, for enhanced performance."
  - [section 4.2] "PA consistently improved performance in both I-CER and NI-CER in ASR-TEL and ASR-BCN"
  - [corpus] Weak evidence; corpus neighbors don't directly address multi-hypothesis utilization for error correction in ITN.
- Break condition: If the alignment process fails to accurately identify discrepancies or if the normalization pairs derived from multiple hypotheses are not reliable, the PA method may not effectively reduce errors.

## Foundational Learning

- Concept: Sequence-to-sequence (seq2seq) models
  - Why needed here: Neural ITN models are based on seq2seq architectures, which learn to map spoken-form text to written-form text.
  - Quick check question: How does a transformer-based seq2seq model handle variable-length input and output sequences in ITN tasks?

- Concept: Data augmentation techniques
  - Why needed here: Data augmentation is used to generate synthetic ASR-like text from written text, addressing the lack of ASR-generated text in training data.
  - Quick check question: What are the key differences between general text augmentation techniques and those specifically designed to emulate ASR linguistic context?

- Concept: Semi-supervised learning
  - Why needed here: Semi-supervised learning leverages unlabeled ASR-generated text to improve ITN performance without requiring manual annotation.
  - Quick check question: How does the teacher-student model framework work in semi-supervised learning for ITN, and what role does the LLM-based confidence scoring play?

## Architecture Onboarding

- Component map: Written text → Data Augmentation → Pseudo-spoken text → ITN model → Pseudo-written text → LLM Confidence Scoring → Filtered pseudo-written text → Student ITN training

- Critical path: ASR-generated text → Data Augmentation/Semi-Supervised Learning → ITN Training → Post-Aligning → Final Output

- Design tradeoffs:
  - Using LLM for confidence scoring adds computational overhead but improves pseudo-written text quality.
  - The post-aligning method increases inference time but reduces unpredictable errors.
  - Semi-supervised learning requires multiple training epochs but leverages unlabeled data effectively.

- Failure signatures:
  - High NI-CER indicates the ITN model is distorting the original text.
  - Inconsistent performance across different ASR scenarios suggests domain mismatch issues.
  - Low improvement in I-CER with data augmentation implies the augmentation techniques are not effectively simulating ASR linguistic context.

- First 3 experiments:
  1. Evaluate the impact of different noise augmentation techniques on ITN performance using a small ASR test set.
  2. Compare LLM-based confidence scoring with traditional likelihood-based scoring in terms of pseudo-written text quality.
  3. Assess the effectiveness of the post-aligning method by comparing ITN performance with and without PA on a diverse set of ASR-generated text.

## Open Questions the Paper Calls Out
The paper does not explicitly call out open questions, but based on the methodology and results, several questions emerge regarding the generalizability and limitations of the proposed approaches.

## Limitations
- The LLM-based confidence scoring relies on theoretical justification rather than comparative empirical validation against established scoring methods.
- The post-aligning method's effectiveness on complex linguistic phenomena beyond simple deletion cases requires further validation.
- Performance evaluation is limited to Korean language, raising questions about generalizability to morphologically rich languages.

## Confidence
- High confidence: The core finding that domain adaptation through direct training on ASR-generated text improves ITN performance is well-supported by the significant CER improvements (95.18% relative improvement) and consistent results across multiple test sets.
- Medium confidence: The effectiveness of the post-aligning method is supported by consistent performance gains, though the mechanism's robustness across diverse linguistic contexts requires further validation.
- Low confidence: The LLM-based confidence scoring claims rely heavily on theoretical justification rather than comparative empirical evidence against established scoring methods.

## Next Checks
1. Conduct ablation studies comparing LLM-based confidence scoring with traditional likelihood-based scoring methods on the same semi-supervised learning pipeline to quantify the actual contribution of LLM-based filtering.

2. Evaluate the post-aligning algorithm's performance on edge cases involving complex Korean linguistic phenomena (e.g., honorifics, compound words) to identify potential failure modes not captured in standard test sets.

3. Test the domain adaptation effectiveness by measuring ITN performance degradation when models trained with DA/SSL are applied to non-ASR spoken text, quantifying the tradeoff between ASR robustness and general spoken text handling.