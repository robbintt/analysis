---
ver: rpa2
title: 'Multi-modality Meets Re-learning: Mitigating Negative Transfer in Sequential
  Recommendation'
arxiv_id: '2309.10195'
source_url: https://arxiv.org/abs/2309.10195
tags:
- item
- task
- target
- tasks
- recommendation
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the problem of negative transfer in sequential
  recommendation, where pre-training on auxiliary tasks can hurt performance on the
  target task. The authors propose ANT, a method that incorporates multi-modality
  item information (texts, images, prices) and a re-learning-based adaptation strategy
  to mitigate negative transfer.
---

# Multi-modality Meets Re-learning: Mitigating Negative Transfer in Sequential Recommendation

## Quick Facts
- arXiv ID: 2309.10195
- Source URL: https://arxiv.org/abs/2309.10195
- Reference count: 40
- Primary result: ANT achieves up to 15.2% improvement in Recall@10 over baselines while avoiding negative transfer

## Executive Summary
The paper addresses negative transfer in sequential recommendation, where pre-training on auxiliary tasks can degrade performance on target tasks. ANT introduces a method that combines multi-modal item information (texts, images, prices) with a re-learning-based adaptation strategy. By relearning task-specific parameters from scratch rather than fine-tuning pre-trained ones, and incorporating complementary information from multiple item modalities, ANT significantly outperforms eight state-of-the-art baselines across five target tasks. The method achieves up to 15.2% improvement in Recall@10 while successfully mitigating negative transfer that plagues existing pre-training approaches.

## Method Summary
ANT addresses negative transfer in sequential recommendation through a two-phase approach: pre-training on auxiliary tasks using multi-modal item embeddings, followed by re-learning-based adaptation on target tasks. The method processes item texts with BERT, images with SWIN, and prices with sinusoidal encoding, then transforms these through a parametric whitening layer and Mixture-of-Experts (MoE) transformation with Gaussian routing. During adaptation, instead of fine-tuning, ANT relearns position embeddings and item representation parameters from scratch while keeping the user intent model fixed, creating task-specific representations that better capture target task characteristics without suffering from negative transfer.

## Key Results
- ANT achieves up to 15.2% improvement in Recall@10 compared to state-of-the-art baselines
- Outperforms UniSRec by 5.6% in NDCG@10 on average across five target tasks
- Successfully avoids negative transfer on all target tasks, unlike UniSRec which underperforms training-from-scratch baselines

## Why This Works (Mechanism)

### Mechanism 1: Multi-modality Improves Transferability
Different item modalities carry complementary information with varying transferability across tasks. Text embeddings show high task sensitivity (up to 0.99 classification accuracy), while image and price embeddings demonstrate lower separability, indicating more transferable representations. This suggests that visual and price information are less domain-specific than textual descriptions, making them valuable for cross-task knowledge transfer.

### Mechanism 2: Re-learning Adaptation Mitigates Negative Transfer
Instead of fine-tuning pre-trained parameters, ANT relearns item representation parameters (Φ*IRL) and position embeddings (Θ*P) from scratch in the target task. This creates more task-specific representations while preserving general knowledge in the user intent model (Θ◦SASRec-P). The approach prevents negative transfer by allowing the model to build task-specific representations without being constrained by potentially incompatible pre-trained parameters.

### Mechanism 3: Gaussian Routing in MoE Improves Generalization
Gaussian routing models uncertainty in expert selection by sampling weights from a Gaussian distribution parameterized by mean (µx_i) and standard deviation (σx_i). This probabilistic approach captures the uncertainty in the weight generation process, improving model generalizability compared to deterministic linear or cosine routing methods. The uncertainty modeling allows for more robust adaptation to diverse target tasks.

## Foundational Learning

- **Concept: Transfer learning and negative transfer**
  - Why needed here: The paper addresses negative transfer where pre-training on auxiliary tasks can hurt target task performance
  - Quick check question: What distinguishes negative transfer from no transfer in sequential recommendation?

- **Concept: Multi-modal representation learning**
  - Why needed here: ANT incorporates text, image, and price embeddings to create comprehensive item representations
  - Quick check question: How do you evaluate cross-task transferability of different item modalities?

- **Concept: Attention mechanisms and self-attention in sequential models**
  - Why needed here: The paper uses SASRec with self-attention layers for user intent modeling
  - Quick check question: What role do position embeddings play in self-attention-based sequential recommendation?

## Architecture Onboarding

- **Component map:** Item texts/images/prices → BERT/SWIN/sinusoidal encoding → parametric whitening → MoE transformation → modality fusion → SASRec with re-learned position embeddings → Top-K recommendations
- **Critical path:** Item embedding generation → User intent modeling → Recommendation scoring
- **Design tradeoffs:**
  - Fixed pre-trained encoders (BERT, SWIN) vs. fine-tuning: Trade-off between efficiency and task-specific optimization
  - Re-learning vs. fine-tuning: Better task-specificity vs. parameter efficiency
  - MoE with Gaussian routing vs. simpler routing: Better uncertainty modeling vs. computational complexity
- **Failure signatures:**
  - Negative transfer: Target task performance worse than training from scratch
  - Overfitting: Poor generalization to validation/test sets
  - Mode collapse: All items receive similar recommendation scores
- **First 3 experiments:**
  1. Implement ANT without multi-modality (text-only) and compare to UniSRec to validate modality contribution
  2. Test fine-tuning vs. re-learning adaptation strategies on a simple target task
  3. Evaluate Gaussian routing vs. linear routing in MoE transformation component

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How would ANT perform with different pre-trained vision models (e.g., CLIP, ViT) instead of SWIN for image embedding generation?
- Basis in paper: [explicit] The authors state that they empirically observed SWIN outperforms other popular pre-trained vision models like CLIP and ViT, but do not provide detailed comparisons.
- Why unresolved: The paper does not include ablation studies comparing different vision models or their impact on ANT's performance.
- What evidence would resolve it: Systematic experiments comparing ANT's performance using different pre-trained vision models (SWIN, CLIP, ViT) on the same datasets and metrics.

### Open Question 2
- Question: Would incorporating additional item modalities beyond text, image, and price (e.g., audio descriptions, video trailers) further improve ANT's recommendation performance?
- Basis in paper: [inferred] The authors demonstrate that incorporating multiple modalities (text, image, price) improves performance over single-modality approaches, suggesting potential benefits from additional modalities.
- Why unresolved: The paper only considers three modalities and does not explore the potential benefits of incorporating additional modalities.
- What evidence would resolve it: Experiments testing ANT with additional item modalities (e.g., audio, video) and comparing performance to the three-modality baseline.

### Open Question 3
- Question: How does the re-learning-based adaptation strategy in ANT compare to other adaptation methods like meta-learning or domain adaptation techniques?
- Basis in paper: [explicit] The authors highlight their re-learning-based adaptation strategy as superior to fine-tuning for capturing task-specific knowledge, but do not compare it to other adaptation methods.
- Why unresolved: The paper only compares their re-learning strategy to fine-tuning and does not explore other adaptation approaches.
- What evidence would resolve it: Comparative experiments between ANT's re-learning strategy and other adaptation methods (meta-learning, domain adaptation) on the same tasks and metrics.

## Limitations

- Weak external validation for modality-specific transferability claims (average citations=0.0 in corpus evidence)
- Specific implementation details of MoE-based embedding transformation parameters not fully specified
- Unclear distinction between re-learning and fine-tuning in adaptation phase requires clarification

## Confidence

- **High Confidence:** The general problem formulation of negative transfer in sequential recommendation and the superiority of ANT over baselines
- **Medium Confidence:** The mechanism by which multi-modality improves transferability (supported by internal evidence but weak external validation)
- **Low Confidence:** The specific implementation details of the Gaussian routing mechanism and its superiority over linear/cosine routing

## Next Checks

1. Implement a simplified ANT variant using only text embeddings and compare against UniSRec to isolate the contribution of multi-modality
2. Create controlled experiments varying the similarity between auxiliary and target tasks to test the negative transfer boundary conditions
3. Benchmark Gaussian routing against linear routing in the MoE transformation component using the same experimental setup to validate the routing mechanism claims