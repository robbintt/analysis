---
ver: rpa2
title: Gradient Descent with Polyak's Momentum Finds Flatter Minima via Large Catapults
arxiv_id: '2311.15051'
source_url: https://arxiv.org/abs/2311.15051
tags:
- learning
- sharpness
- loss
- momentum
- rate
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: "This paper empirically studies Polyak\u2019s heavy-ball momentum\
  \ (PHB) gradient descent on diagonal linear networks and nonlinear neural networks.\
  \ The authors find that when PHB is combined with a large learning rate and learning\
  \ rate warmup, it exhibits a \u201Ccatapult\u201D effect, leading to a sharp decrease\
  \ in sharpness (i.e., driving the iterates towards flatter minima) compared to gradient\
  \ descent (GD)."
---

# Gradient Descent with Polyak's Momentum Finds Flatter Minima via Large Catapults

## Quick Facts
- arXiv ID: 2311.15051
- Source URL: https://arxiv.org/abs/2311.15051
- Reference count: 40
- Key outcome: PHB with large learning rate and warmup induces "catapult" effect driving iterates to flatter minima

## Executive Summary
This paper investigates Polyak's heavy-ball momentum (PHB) gradient descent on diagonal linear networks and nonlinear neural networks. The authors demonstrate that PHB, when combined with a large learning rate and learning rate warmup, exhibits a "catapult" effect that leads to a sharp decrease in sharpness compared to standard gradient descent. This effect drives the optimization trajectory towards flatter minima, which are often associated with better generalization. The study provides both theoretical intuitions and experimental evidence supporting the hypothesis that momentum amplifies the self-stabilization effect observed in gradient descent, resulting in more stable training dynamics and flatter minima.

## Method Summary
The authors empirically study Polyak's heavy-ball momentum (PHB) gradient descent on linear diagonal networks and nonlinear neural networks. They use learning rate warmup, starting from a small initial learning rate (ηi = 10^-8) and increasing it to a final learning rate (ηf) over a specified number of steps (10^6). The momentum parameter β is set to 0.9 (and 0.99 in additional experiments). They compare PHB with standard gradient descent (GD) in terms of sharpness reduction, test loss, and training dynamics. The experiments include linear diagonal networks, fully connected networks, and ResNet20 on CIFAR10.

## Key Results
- PHB with large learning rate and warmup exhibits a "catapult" effect, driving iterates towards flatter minima than GD
- The catapult effect is characterized by a sharp decrease in sharpness when the maximum stable sharpness (MSS) is exceeded
- Momentum amplifies the self-stabilization effect, prolonging the decrease in sharpness and leading to more stable training dynamics
- Similar catapult behavior is observed in nonlinear neural networks, with PHB showing more stable training dynamics compared to GD

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Polyak's heavy-ball momentum (PHB) combined with large learning rate and warmup induces a "catapult" effect that drives iterates towards flatter minima than gradient descent (GD).
- Mechanism: Momentum amplifies the self-stabilization effect observed in GD. When sharpness exceeds the maximum stable sharpness (MSS), momentum prolongs the sharp decrease in sharpness by continuing to propagate iterates along the direction that decreases sharpness even after the initial stabilization.
- Core assumption: The learning rate warmup ensures that iterates start near a stable minimum and then increase until the minimum becomes unstable but not so unstable that training diverges.
- Evidence anchors:
  - [abstract] "momentum gradient descent with a large learning rate displays large catapults, driving the iterates towards much flatter minima than those found by gradient descent"
  - [section 3] "momentum "prolonging" the self-stabilization effect (Damian et al., 2023)"
  - [corpus] Weak evidence - no directly relevant citations found
- Break condition: If the learning rate increases too much during warmup causing training to diverge, or if the momentum parameter is set too high causing instability throughout training.

### Mechanism 2
- Claim: The specific form of learning rate warmup (linear vs step) is not essential for inducing catapults as long as the two criteria are met.
- Mechanism: The two criteria are: (1) iterates are in a neighborhood of a stable minimum, and (2) learning rate increases until the minimum is unstable but not so unstable that training diverges. Linear warmup satisfies these by stably moving iterates towards a minimum under low learning rate then finding a suitable large learning rate.
- Core assumption: As long as the two criteria are met, the specific form of warmup is secondary to its effect on learning rate progression.
- Evidence anchors:
  - [section 2] "we emphasize that linear warmup is not necessary to induce the catapults. We claim that the main criteria for inducing the catapults are..."
  - [section 2] "Step warmup is used instead of linear warmup... this setting also induces a catapult despite not using linear warmup"
  - [corpus] Weak evidence - no directly relevant citations found
- Break condition: If the warmup schedule fails to meet either criterion, such as increasing too quickly and causing divergence or too slowly and not reaching the unstable regime.

### Mechanism 3
- Claim: Momentum provides extra stabilization in the direction orthogonal to the manifold of global minima, inducing damped oscillations and forcing convergence.
- Mechanism: During the catapult, momentum causes the iterates to oscillate in the direction orthogonal to the minima manifold while moving along the direction that decreases sharpness. This oscillation damps out as sharpness decreases below MSS, forcing convergence.
- Core assumption: The loss function has a manifold of global minima and the dynamics can be approximated as slow-fast where one direction changes much more slowly than the other.
- Evidence anchors:
  - [section 3] "the x-direction is orthogonal to both the manifold of global minima and the direction of sharpness decrease... momentum provides extra stabilization in the x-direction, inducing damped oscillations"
  - [section 3] "momentum prolongs the effect of self-stabilization and continues to propagate the iterates along the y-direction, resulting in a prolonged decrease in sharpness until the momentum term decays to zero"
  - [corpus] Weak evidence - no directly relevant citations found
- Break condition: If the loss function does not have a clear manifold structure or if the initialization is too far from any minimum to exhibit the required slow-fast dynamics.

## Foundational Learning

- Concept: Gradient descent with momentum (Polyak's heavy-ball method)
  - Why needed here: Understanding how momentum modifies the basic gradient descent update rule is fundamental to grasping why it induces different behavior than GD alone
  - Quick check question: How does the Polyak momentum update rule differ from standard gradient descent, and what role does the momentum parameter β play?

- Concept: Sharpness and maximum stable sharpness (MSS)
  - Why needed here: The catapult phenomenon occurs when sharpness exceeds MSS, and understanding these concepts is crucial for interpreting the experimental results
  - Quick check question: How is sharpness defined in this context, and what is the relationship between sharpness and the maximum stable sharpness for momentum methods?

- Concept: Self-stabilization effect in gradient descent
  - Why needed here: The paper's main hypothesis is that momentum amplifies this effect, so understanding the mechanism is essential
  - Quick check question: What are the four stages of self-stabilization in gradient descent, and how does momentum modify this process?

## Architecture Onboarding

- Component map: Linear diagonal network -> FCN -> ResNet20
- Critical path: 1) Initialize parameters and learning rate, 2) Compute gradient, 3) Update parameters with momentum, 4) Calculate sharpness, 5) Adjust learning rate according to warmup schedule, 6) Monitor sharpness relative to MSS, 7) Observe catapult behavior when sharpness crosses MSS
- Design tradeoffs: Using larger momentum parameters (e.g., β=0.99 vs 0.9) amplifies the catapult effect but can cause instability. Linear warmup provides smoother learning rate progression than step warmup but requires more iterations. The tradeoff is between achieving the desired catapult behavior and maintaining training stability.
- Failure signatures: If the learning rate increases too quickly during warmup, training may diverge. If momentum is too high, the iterates may become unstable throughout training rather than just during the catapult. If the initialization scale is too large or too small, the catapult may not occur at all.
- First 3 experiments:
  1. Replicate the linear diagonal network experiment with varying initialization scales α and learning rates ηf to observe the threshold behavior where test loss sharply drops for PHB but not GD
  2. Test different warmup schedules (linear vs step) on the toy example to verify that the specific form of warmup is not essential as long as the two criteria are met
  3. Apply the same PHB + warmup combination to a simple nonlinear network (e.g., 2-layer fully connected) to verify that the catapult behavior extends beyond linear models

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the momentum-induced catapult effect generalize to other optimization problems beyond linear and diagonal networks?
- Basis in paper: [explicit] The paper shows the effect on linear diagonal networks and nonlinear neural networks, but does not explore other problem types.
- Why unresolved: The authors focus on specific architectures and do not provide theoretical guarantees for broader classes of problems.
- What evidence would resolve it: Empirical studies on diverse optimization problems (e.g., non-convex problems, different loss functions) demonstrating similar catapult behavior.

### Open Question 2
- Question: What is the precise relationship between the magnitude of the catapult effect and the generalization performance of the resulting model?
- Basis in paper: [inferred] The paper observes that flatter minima (achieved via larger catapults) may not necessarily lead to better generalization.
- Why unresolved: The authors do not provide a quantitative analysis of the relationship between catapult magnitude and generalization.
- What evidence would resolve it: Experiments correlating catapult magnitude with test error across different architectures and datasets.

### Open Question 3
- Question: Can the theoretical insights from the toy example be extended to explain the catapult behavior in more complex models?
- Basis in paper: [explicit] The authors provide theoretical intuitions for the toy example but acknowledge the difficulty in extending to realistic scenarios.
- Why unresolved: The toy example is highly simplified, and the authors note that rigorous theoretical characterization for complex models is challenging.
- What evidence would resolve it: Theoretical analysis or empirical evidence showing how the principles observed in the toy example scale to larger, more complex models.

## Limitations

- The paper's empirical nature and the complexity of the optimization landscape in nonlinear neural networks limit the theoretical understanding of the catapult phenomenon.
- The authors provide theoretical intuitions for the catapult in a simplified toy example, but extending these intuitions to general nonlinear networks involves significant assumptions about the loss surface structure and dynamics.
- The paper does not rigorously prove that momentum amplifies the self-stabilization effect or explain why this leads to flatter minima in all cases.

## Confidence

- **Confidence in the main claims about the catapult effect is Medium**: The experimental evidence across multiple architectures (linear diagonal networks, fully connected networks, ResNet20) consistently shows sharper decreases in sharpness for PHB compared to GD, and the test loss improves correspondingly. However, the theoretical understanding is limited to a simple toy example, and the generalization to complex neural networks involves extrapolation.
- **Confidence in the theoretical mechanisms is Low**: While the authors provide plausible intuitions based on the toy example, these are not rigorously proven or empirically validated for the general case. The claims about momentum prolonging the self-stabilization effect and inducing damped oscillations rely on assumptions about the loss surface structure that may not hold in practice.

## Next Checks

1. **Test different momentum parameters**: Experiment with β ∈ {0.7, 0.8, 0.95} to verify the relationship between momentum strength and the magnitude of the catapult effect, as well as the onset of instability.
2. **Analyze sharpness along the training trajectory**: Plot sharpness vs. iteration for both PHB and GD, focusing on the evolution before, during, and after the catapult to better understand the dynamics.
3. **Extend to additional architectures**: Apply the PHB + warmup combination to other network architectures (e.g., convolutional networks, recurrent networks) and tasks (e.g., image classification, language modeling) to test the generalizability of the findings.