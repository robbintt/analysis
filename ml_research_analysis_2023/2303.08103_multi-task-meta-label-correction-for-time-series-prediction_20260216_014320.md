---
ver: rpa2
title: Multi-task Meta Label Correction for Time Series Prediction
arxiv_id: '2303.08103'
source_url: https://arxiv.org/abs/2303.08103
tags:
- data
- learning
- label
- time
- meta
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper proposes a method to address the problem of inaccurate
  or corrupted labels in time series classification, particularly in financial time
  series data. The core method idea is to combine meta-learning and contrastive learning
  in a multi-task framework to iteratively generate correct labels for noisy time
  series patterns and improve classification performance.
---

# Multi-task Meta Label Correction for Time Series Prediction

## Quick Facts
- arXiv ID: 2303.08103
- Source URL: https://arxiv.org/abs/2303.08103
- Reference count: 36
- The paper proposes a method to address the problem of inaccurate or corrupted labels in time series classification, particularly in financial time series data.

## Executive Summary
This paper addresses the critical challenge of label noise in time series classification, particularly in financial time series where accurate labeling is expensive and time-consuming. The proposed method combines meta-learning and contrastive learning in a multi-task framework to iteratively generate correct labels for noisy time series patterns and improve classification performance. By transforming time series data into images using Gramian Angular Summation Fields (GASF) and leveraging a label generator with triplet regulize loss, the approach achieves significant improvements over baseline models. The method demonstrates strong performance on financial datasets (XOM, S&P500, SZ50), achieving 57% accuracy and 70% F1-score with a 10-day prediction horizon.

## Method Summary
The proposed method transforms financial time series into images using GASF and relative ratios, then employs a meta-contrastive learning framework to iteratively correct noisy labels. The approach uses a label generator based on triplet regulize loss (combining triplet loss and cross-entropy) to estimate correct labels, which are then used to train a classification model. The outer loop optimizes label quality using clean validation data, while the inner loop updates the classification model. A multi-task learning framework is applied for parallel prediction across different time horizons (10, 13, and 15 days), with the 10-day prediction showing optimal performance.

## Key Results
- Achieves 20% improvement in accuracy and 100% improvement in F1-score compared to baseline model
- Best prediction day identified as 10 days, achieving 57% accuracy and 70% F1-score
- Outperforms existing label correction techniques on financial datasets (XOM, S&P500, SZ50)

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The method improves label quality by iteratively refining noisy labels through a meta-contrastive learning loop.
- Mechanism: The outer loop uses contrastive learning with triplet regulize loss to estimate correct labels, while the inner loop updates the classification model with these refined labels. This iterative process progressively improves both label quality and model performance.
- Core assumption: The initial set of clean labels is representative enough to bootstrap the contrastive learning process.
- Evidence anchors:
  - [abstract] "combine meta-learning and contrastive learning in a multi-task framework to iteratively generate correct labels"
  - [section] "We make use of the triplet regulize loss... which includes the Resnet18 neural network h for encoding and MLP network I for labeling"
  - [corpus] Weak - related papers focus on meta-learning for label correction but don't specifically address the contrastive component
- Break condition: If the initial clean labels are not representative of the underlying data distribution, the iterative refinement may converge to incorrect label assignments.

### Mechanism 2
- Claim: Converting time series to images using GASF captures both temporal dependencies and spatial patterns that are useful for classification.
- Mechanism: GASF transforms univariate time series into 2D images where temporal correlations are encoded in the angular relationships between data points. This allows standard image-based deep learning architectures to extract meaningful features.
- Core assumption: The spatial representation of temporal data preserves sufficient information for accurate classification.
- Evidence anchors:
  - [section] "GASF includes two method called Gramian Summation Angular Field (GASF) and Gramian Difference Angular Field (GDAF), which represent time series in a polar coordinate system with the cosine and sine functions"
  - [section] "By leveraging the information from image data, we can also utilize the intrinsic patterns of time series data more efficiently"
  - [corpus] Weak - related papers mention image transformations but don't specifically discuss GASF for financial time series
- Break condition: If the temporal patterns in the time series are not well-represented by angular relationships, the image transformation may lose critical information.

### Mechanism 3
- Claim: The multi-task learning framework enables simultaneous prediction across different time horizons, with the 10-day prediction showing optimal performance.
- Mechanism: Separate tasks are created for different prediction horizons (10, 13, and 15 days), and the model learns shared representations across these tasks. The 10-day horizon achieves the best balance between signal strength and noise.
- Core assumption: Shorter prediction horizons retain more predictable patterns while longer horizons introduce excessive noise.
- Evidence anchors:
  - [section] "We apply a multi-task learning framework on the outside of the model. Based on the predicted days of 10, 13, and 15 days, we created three separate tasks for parallel computation"
  - [section] "Table 4 shows that the best number of prediction day is ten, which the accuracy achieves 57% and the F1-score reaches 70%"
  - [corpus] Weak - related papers discuss meta-learning and time series but don't specifically address multi-task prediction horizons
- Break condition: If the optimal prediction horizon varies significantly across different financial instruments or market conditions, the fixed multi-task approach may underperform.

## Foundational Learning

- Concept: Contrastive learning with triplet loss
  - Why needed here: To create a robust labeling mechanism that can distinguish between similar and dissimilar time series patterns without relying on large amounts of labeled data
  - Quick check question: How does the triplet regulize loss differ from standard triplet loss, and why is this modification important for this application?

- Concept: Meta-learning with bi-level optimization
  - Why needed here: To enable the model to learn how to correct labels across different financial time series datasets, not just memorize patterns from a single dataset
  - Quick check question: What is the role of the clean validation set in the outer loop optimization, and how does it prevent the model from reinforcing noisy labels?

- Concept: Time series to image transformation (GASF)
  - Why needed here: To leverage powerful image-based deep learning architectures for time series classification while preserving temporal dependencies
  - Quick check question: How does the polar coordinate transformation in GASF capture temporal relationships differently from raw time series values?

## Architecture Onboarding

- Component map:
  Data preprocessing pipeline (time series ‚Üí GASF images + pixel maps) ‚Üí Label generator network (ResNet18 + MLP with triplet regulize loss) ‚Üí Classifier network (ResNet18) ‚Üí Multi-task prediction layer (separate heads for 10, 13, 15-day predictions) ‚Üí Meta-learning coordinator (bi-level optimization with clean data feedback)

- Critical path: Data preprocessing ‚Üí Label generator (outer loop) ‚Üí Classifier training (inner loop) ‚Üí Multi-task prediction ‚Üí Evaluation

- Design tradeoffs:
  - GASF vs raw time series: GASF enables use of image-based architectures but may lose some temporal resolution
  - Number of clean labels: More clean labels improve initialization but reduce the problem's practical value
  - Prediction horizon length: Longer horizons capture more meaningful trends but increase noise and uncertainty

- Failure signatures:
  - Label generator divergence: If triplet loss optimization fails, labels may become random or biased
  - Overfitting to clean data: Classifier may memorize the small clean set rather than generalize
  - Multi-task interference: Tasks with different optimal horizons may degrade each other's performance

- First 3 experiments:
  1. Ablation study: Compare model performance with and without the label generator to quantify the benefit of automatic label correction
  2. Clean label sensitivity: Vary the number of initial clean labels (10, 50, 100) to understand the minimum required for effective bootstrapping
  3. Prediction horizon analysis: Test additional horizons (5, 7, 12 days) to confirm 10 days is optimal across different market conditions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the theoretical justification for the superiority of triplet regulize loss over standard triplet loss in this context?
- Basis in paper: [explicit] The paper introduces triplet regulize loss (TRL) as a combination of triplet loss and cross-entropy loss, claiming it helps mitigate overfitting.
- Why unresolved: The paper does not provide a rigorous theoretical analysis or ablation study to compare the performance of TRL with standard triplet loss in their specific setting.
- What evidence would resolve it: A theoretical analysis explaining why TRL would perform better than standard triplet loss, or an ablation study comparing the two loss functions.

### Open Question 2
- Question: How sensitive is the model to the choice of hyperparameters, such as the boundary value ùìã for manual labeling and the margin ùõø in the triplet loss?
- Basis in paper: [inferred] The paper mentions that hyperparameter selection is a challenge and that certain hyperparameters need to be accurately selected with scientific basis.
- Why unresolved: The paper does not provide a systematic study on the sensitivity of the model to different hyperparameter choices.
- What evidence would resolve it: A sensitivity analysis showing how changes in key hyperparameters affect the model's performance.

### Open Question 3
- Question: What is the optimal prediction horizon for financial time series forecasting, and how does it vary across different stocks or market conditions?
- Basis in paper: [explicit] The paper finds that the best prediction day is 10 days, achieving 57% accuracy and 70% F1-score, but also notes that accuracy and F1-score drop as prediction days increase.
- Why unresolved: The paper does not explore the optimal prediction horizon in depth or investigate how it might vary across different stocks or market conditions.
- What evidence would resolve it: A comprehensive study examining the optimal prediction horizon across various stocks and market conditions, potentially including a dynamic adjustment mechanism based on market state.

### Open Question 4
- Question: How does the proposed method handle non-stationary financial time series, where the underlying distribution may change over time?
- Basis in paper: [inferred] The paper mentions the challenge of non-stationary time series and the need for adaptive labeling, but does not explicitly address how the method handles this issue.
- Why unresolved: The paper does not provide a detailed discussion on the method's ability to adapt to changing distributions in financial time series.
- What evidence would resolve it: An analysis of the method's performance on non-stationary financial data, potentially including a comparison with other methods designed to handle concept drift.

## Limitations
- Performance improvements are based on limited datasets (three financial datasets), restricting generalizability to other domains
- The method requires an initial clean validation set (6% of data), which may not be available in all practical scenarios
- The image transformation via GASF may not optimally preserve all temporal dependencies for complex financial patterns

## Confidence

- High confidence: The multi-task learning framework for different prediction horizons is well-established and the observed performance differences between horizons (10 vs 13 vs 15 days) appear consistent
- Medium confidence: The iterative meta-contrastive learning mechanism shows theoretical soundness, but the empirical validation is limited to financial datasets with specific characteristics
- Low confidence: The generalization of the 10-day optimal prediction horizon across different market conditions and asset classes requires further validation

## Next Checks

1. **Cross-domain testing**: Evaluate the method on non-financial time series datasets (e.g., medical, sensor data) to assess domain transferability of the label correction approach
2. **Clean label sensitivity analysis**: Systematically vary the proportion of clean labels (1%, 3%, 6%, 10%) to determine the minimum threshold for effective bootstrapping and identify potential failure modes
3. **Alternative image transformations**: Compare GASF performance against other time series image transformations (Recurrence Plots, Markov Transition Fields) to quantify the contribution of the specific transformation choice to overall performance