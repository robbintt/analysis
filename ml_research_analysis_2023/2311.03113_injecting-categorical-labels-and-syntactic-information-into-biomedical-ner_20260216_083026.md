---
ver: rpa2
title: Injecting Categorical Labels and Syntactic Information into Biomedical NER
arxiv_id: '2311.03113'
source_url: https://arxiv.org/abs/2311.03113
tags:
- attributes
- labels
- information
- label
- categorical
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents two approaches to improve biomedical named
  entity recognition (NER) by incorporating categorical labels and Part-of-Speech
  (POS) information. The first approach uses a pipeline method where a sentence-level
  classifier is trained to obtain categorical labels, which are then injected into
  the NER model along with POS tags.
---

# Injecting Categorical Labels and Syntactic Information into Biomedical NER

## Quick Facts
- arXiv ID: 2311.03113
- Source URL: https://arxiv.org/abs/2311.03113
- Reference count: 14
- Primary result: Improved biomedical NER F1 scores: 85.02 (BC2GM), 86.91 (BC5CDR-disease), 88.99 (NCBI-disease)

## Executive Summary
This paper presents two approaches to enhance biomedical named entity recognition by incorporating categorical labels and Part-of-Speech (POS) information. The first approach uses a pipeline method where a sentence-level classifier generates categorical labels through a textual entailment reformulation, which are then injected into the NER model along with POS tags. The second approach jointly learns categorical labels and NER labels while also incorporating POS tags. Both methods significantly outperform baseline BERT-based models on three benchmark biomedical datasets, demonstrating the effectiveness of leveraging categorical and syntactic information for improved entity recognition.

## Method Summary
The paper proposes two attribute injection methods for biomedical NER. The first method reformulates text classification as a textual entailment task to improve categorical label generation, then injects these labels and POS tags into a BioBERT-based NER model at various architectural locations. The second method jointly trains the model on both categorical label classification and NER tasks, incorporating POS tags to provide additional syntactic context. Both approaches use off-the-shelf NLP tools for POS tagging and leverage the entailment reformulation to generate more accurate categorical labels at the sentence level.

## Key Results
- Pipeline approach achieves F1 scores of 85.02, 86.91, and 88.99 on BC2GM, BC5CDR-disease, and NCBI-disease datasets respectively
- Joint training approach with POS injection demonstrates superior performance compared to baseline BioBERT models
- Attribute injection methods show consistent improvements across all three benchmark biomedical NER datasets

## Why This Works (Mechanism)

### Mechanism 1
Reformulating text classification as entailment improves categorical label accuracy by reducing the gap between pre-training and fine-tuning. By converting class labels into natural language templates that describe the tag, the model evaluates input sentences for entailment with tag descriptions. This alignment with pre-training objectives makes the model more effective at understanding sentence-level categorical labels for NER.

### Mechanism 2
Injecting categorical labels and POS attributes into different parts of the BERT architecture improves NER performance by providing additional syntactic and semantic context. These attributes are injected as bias terms or concatenated embeddings, biasing the probability of words belonging to certain classes and enhancing the model's understanding of syntactic structure.

### Mechanism 3
Jointly learning categorical labels and NER labels while injecting POS tags enhances performance by leveraging sentence-level context and syntactic information. The model predicts both sentence-level categories and token-level NER labels simultaneously, using sentence-level information to guide token-level predictions and vice versa.

## Foundational Learning

- **Textual entailment**: Understanding whether one text logically follows from another; needed here to reformulate text classification for better categorical label generation. Quick check: What distinguishes entailment from traditional classification?

- **Part-of-Speech (POS) tagging**: Assigning grammatical categories to words; needed here as syntactic features to inject into the NER model. Quick check: How do POS tags help in identifying named entities?

- **Joint training of multiple tasks**: Simultaneously optimizing multiple related objectives; needed here to leverage shared information between categorical label classification and NER. Quick check: What are the benefits and challenges of multi-task learning?

## Architecture Onboarding

- **Component map**: Sentence-level classifier (textual entailment model) -> Attribute-injected NER model (BioBERT) -> POS tag generator (external tool) -> Joint training framework (optional)

- **Critical path**: 1) Generate categorical labels using entailment classifier, 2) Generate POS tags using external tool, 3) Inject attributes into NER model at specified locations, 4) Train/fine-tune NER model with attribute injection

- **Design tradeoffs**: Injection location choice affects performance and complexity; joint training may improve performance but increases model complexity and training time; external POS generation introduces dependency but provides accurate syntactic information

- **Failure signatures**: No improvement or degradation in NER performance after attribute injection; overfitting due to excessive attribute information or insufficient training data; instability in joint training if objectives are not well-aligned

- **First 3 experiments**: 1) Train baseline BioBERT model on NER without attribute injection, 2) Inject categorical labels into embedding layer and evaluate performance, 3) Jointly train on categorical labels and NER with POS injection, comparing to baseline

## Open Questions the Paper Calls Out

### Open Question 1
How does performance compare when using different syntactic information beyond POS tags, such as dependency relations or chunking? The paper only experiments with POS tags and does not explore other syntactic features.

### Open Question 2
What is the impact of using more advanced entailment models for the sentence-level classifier compared to the basic approach described? The paper does not investigate whether sophisticated entailment models could further improve performance.

### Open Question 3
How does the joint training approach perform when incorporating additional biomedical knowledge sources like ontologies or knowledge graphs? The paper mentions this enhancement but does not experiment with it.

### Open Question 4
What is the effect of varying training data size and quality on attribute injection method performance? The paper does not investigate how performance changes with different amounts of training data or with noisy/incomplete data.

## Limitations

- The entailment reformulation introduces dependency on natural language template quality, which is not specified in the paper
- Attribute injection mechanisms lack detailed implementation specifications, making it difficult to reproduce optimal strategies
- Joint training approach adds complexity without clear evidence that it outperforms the simpler pipeline approach
- No ablation studies to determine which components contribute most to performance improvements

## Confidence

**High confidence** in baseline BioBERT performance and overall experimental methodology due to standard benchmark datasets and F1 metrics.

**Medium confidence** in attribute injection effectiveness, as results show improvements but lack detailed implementation specifications and systematic comparisons.

**Low confidence** in generalizability of entailment reformulation approach due to unspecified natural language templates and absence of comparison with alternative classification methods.

## Next Checks

1. Conduct template ablation study by systematically varying natural language templates in entailment reformulation and measuring impact on both categorical label accuracy and downstream NER performance.

2. Implement and compare multiple attribute injection strategies (embedding layer, attention mechanism, classifier layer) while holding all other variables constant to identify optimal injection locations.

3. Perform detailed ablation study on joint training approach by gradually removing the joint objective and measuring performance impact at each step to clarify whether additional complexity provides measurable benefits.