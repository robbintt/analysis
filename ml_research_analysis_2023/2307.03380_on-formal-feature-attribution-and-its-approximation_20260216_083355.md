---
ver: rpa2
title: On Formal Feature Attribution and Its Approximation
arxiv_id: '2307.03380'
source_url: https://arxiv.org/abs/2307.03380
tags:
- feature
- lime
- shap
- formal
- attribution
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces formal feature attribution (FFA), a novel
  method for feature attribution in machine learning models. FFA is defined as the
  proportion of abductive explanations (AXp's) in which a given feature occurs.
---

# On Formal Feature Attribution and Its Approximation

## Quick Facts
- arXiv ID: 2307.03380
- Source URL: https://arxiv.org/abs/2307.03380
- Reference count: 40
- Primary result: Introduces Formal Feature Attribution (FFA) and proposes an efficient approximation technique that outperforms LIME and SHAP on feature importance and relative order

## Executive Summary
This paper introduces Formal Feature Attribution (FFA), a novel method for feature attribution in machine learning models. FFA is defined as the proportion of abductive explanations (AXp's) in which a given feature occurs, providing a strict and formal definition of feature importance. The authors propose an efficient technique for approximating exact FFA by leveraging the anytime property of MARCO-like algorithms and the hitting set duality between AXp's and CXp's. Experimental results demonstrate that the proposed approach is effective in practice and outperforms existing feature attribution algorithms like LIME and SHAP in terms of feature importance and relative order on various tabular and image datasets.

## Method Summary
The paper proposes Formal Feature Attribution (FFA) as the proportion of abductive explanations (AXp's) containing a given feature. To make FFA computationally tractable, the authors introduce an approximation technique that leverages the hitting set duality between AXp's and CXp's. By targeting CXp enumeration with MARCO-like algorithms, the method collects AXp's "for free" as dual explanations during the initial phase. This approach quickly builds a representative sample of the explanation space before computing the target explanations, enabling efficient FFA approximation. The method is evaluated against LIME and SHAP using Kendall's Tau and RBO metrics on various datasets.

## Key Results
- FFA provides a strict, formal definition of feature importance based on logical reasoning over the complete feature space
- The CXp-targeting approximation approach converges quickly to exact FFA values in practice
- Experimental results show FFA outperforms LIME and SHAP in terms of feature importance and relative order on tabular and image datasets

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Formal Feature Attribution (FFA) captures feature importance by computing the proportion of abductive explanations (AXp's) in which a feature occurs.
- Mechanism: FFA is defined as the ratio of AXp's containing a given feature to the total number of AXp's. This provides a strict, formal definition of feature importance grounded in logical reasoning over the complete feature space.
- Core assumption: Exhaustive enumeration of all AXp's is feasible or can be approximated effectively.
- Evidence anchors:
  - [abstract] "FFA is defined as the proportion of abductive explanations (AXp's) in which a given feature occurs."
  - [section] "Formal feature attribution (FFA) of a feature i ∈ F to an instance (v, c) for machine learning model κ is ffaκ(i, (v, c)) = |{X | X ∈ Aκ(v, c), i ∈ X )}| / |Aκ(v, c)|"
  - [corpus] Weak - no direct corpus evidence found for this specific mechanism.
- Break condition: If AXp enumeration becomes intractable due to exponential complexity, the FFA definition loses practical utility.

### Mechanism 2
- Claim: The proposed CXp-targeting approach in Algorithm 1 provides efficient FFA approximation by leveraging the anytime property of MARCO-like algorithms.
- Mechanism: By enumerating CXp's instead of AXp's directly, the algorithm collects dual AXp's "for free" during the initial phase, quickly building a representative sample of the explanation space before computing the target explanations.
- Core assumption: The CXp enumeration phase provides sufficient AXp coverage for good approximation before the target explanations are computed.
- Evidence anchors:
  - [section] "One of the properties of MARCO used in our approximation approach is that it is an anytime algorithm... we propose to target CXp enumeration with AXp's as dual explanations computed 'unintentionally'."
  - [section] "Our experimental results demonstrate the effectiveness of this strategy in terms of monotone convergence of approximate FFA to the exact FFA with the increase of the time limit."
  - [corpus] Weak - no direct corpus evidence found for this specific mechanism.
- Break condition: If the CXp enumeration fails to produce representative AXp samples, the approximation quality degrades significantly.

### Mechanism 3
- Claim: FFA provides more reliable feature importance than heuristic methods like LIME and SHAP because it's grounded in formal logic rather than statistical sampling.
- Mechanism: FFA computes exact feature importance based on logical proofs of sufficiency, while LIME and SHAP rely on local approximations that can be sensitive to sampling artifacts and distribution assumptions.
- Core assumption: The formal guarantees of FFA translate to practical superiority in feature attribution accuracy.
- Evidence anchors:
  - [abstract] "The paper also proposes an efficient technique for approximating exact FFA, which is shown to be effective in practice and to outperform existing feature attribution algorithms like LIME and SHAP in terms of feature importance and relative order."
  - [section] "Our experimental results demonstrate the effectiveness of the proposed approach in practice and its advantage over SHAP and LIME given publicly available tabular and image datasets."
  - [corpus] Weak - no direct corpus evidence found for this specific mechanism.
- Break condition: If the formal reasoning overhead outweighs the benefits in practical scenarios, the approach becomes less attractive than heuristic methods.

## Foundational Learning

- Concept: Abductive Explanations (AXp's)
  - Why needed here: AXp's form the foundation of FFA by providing subset-minimal feature sets that formally guarantee a prediction.
  - Quick check question: What makes an AXp different from a regular feature subset explanation?

- Concept: Hitting Set Duality
  - Why needed here: The duality between AXp's and CXp's enables efficient enumeration by allowing the algorithm to target one type while collecting the other "for free."
  - Quick check question: How does the hitting set duality relation enable the CXp-targeting strategy for FFA approximation?

- Concept: Polynomial Hierarchy Complexity
  - Why needed here: Understanding that FFA is hard for the second level of the polynomial hierarchy explains why exact computation is challenging and approximation is necessary.
  - Quick check question: What does it mean for a problem to be "hard for the second level of the polynomial hierarchy"?

## Architecture Onboarding

- Component map: Formal reasoner -> Explanation enumerator -> Approximation engine -> Comparison module
- Critical path: 1. Encode boosted tree model in logical representation 2. Initialize MARCO enumerator targeting CXp's 3. Collect AXp's as dual explanations during enumeration 4. Compute FFA from collected AXp's 5. Compare with baseline methods
- Design tradeoffs:
  - Exhaustive vs. anytime AXp enumeration: Exhaustive gives exact FFA but is often intractable; anytime provides approximations with controllable runtime.
  - CXp vs. AXp targeting: CXp targeting collects AXp's faster but may bias the sample; direct AXp targeting is slower but more representative.
  - Feature space assumptions: Uniform feature independence assumption enables formal reasoning but may not reflect real data distributions.
- Failure signatures:
  - Slow convergence: Indicates poor CXp-to-AXp sampling ratio, suggesting model structure that's hard to explain via duality
  - High approximation error: Suggests insufficient AXp coverage or model complexity exceeding practical enumeration limits
  - Poor comparison metrics: Indicates potential issues with the formal encoding or algorithm implementation
- First 3 experiments:
  1. Implement AXp enumeration for a simple decision tree on tabular data and verify FFA computation
  2. Add CXp-targeting mode and measure convergence speed vs. direct AXp enumeration
  3. Compare FFA results with LIME/SHAP on a benchmark dataset using Kendall's Tau and RBO metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Does the convergence of FFA and WFFA approximations to their exact values hold for all machine learning models and datasets?
- Basis in paper: [inferred] The paper states that FFA and WFFA approximations quickly converge to exact values, but does not provide a general proof or extensive empirical evidence across diverse models and datasets.
- Why unresolved: The paper's experimental results are limited to specific datasets and models (gradient boosted trees, logistic regression), and a comprehensive study across various ML models and datasets is needed to confirm the convergence property.
- What evidence would resolve it: A large-scale study evaluating FFA and WFFA approximations across diverse ML models (e.g., neural networks, random forests) and datasets, demonstrating consistent convergence to exact values.

### Open Question 2
- Question: How does the computational complexity of exact FFA and WFFA compare to approximate methods in practice?
- Basis in paper: [explicit] The paper mentions that exact FFA computation can be challenging due to the problem's complexity and proposes approximate methods. However, it does not provide a detailed comparison of the computational resources required for exact vs. approximate methods.
- Why unresolved: The paper focuses on the effectiveness of approximate methods but does not quantify the trade-off between accuracy and computational efficiency compared to exact methods.
- What evidence would resolve it: A comprehensive analysis comparing the runtime and memory usage of exact FFA/WFFA computation versus various approximate methods across different ML models and datasets.

### Open Question 3
- Question: Can FFA and WFFA be extended to handle non-independent features or feature interactions?
- Basis in paper: [inferred] The paper defines FFA and WFFA based on the proportion of abductive explanations, which implicitly assumes feature independence. However, real-world datasets often contain dependent features or feature interactions.
- Why unresolved: The paper does not address how to adapt FFA and WFFA to account for feature dependencies or interactions, which could impact the accuracy and interpretability of the feature attributions.
- What evidence would resolve it: A theoretical framework and empirical evaluation of FFA and WFFA extensions that can handle feature dependencies or interactions, demonstrating improved accuracy and interpretability in such scenarios.

## Limitations
- The formal definition of FFA assumes that abductive explanation enumeration is tractable, but the paper acknowledges this is "hard for the second level of the polynomial hierarchy," suggesting significant computational limits for complex models.
- The experimental comparison relies on relative ordering metrics (Kendall's Tau, RBO) rather than absolute accuracy, making it difficult to assess whether FFA actually captures "true" feature importance versus just outperforming heuristics.
- The CXp-targeting approximation strategy depends heavily on the hitting set duality, but the paper provides limited analysis of when this duality breaks down for complex model structures.

## Confidence
- High confidence: The formal definition of FFA and its relationship to abductive explanations is mathematically sound and well-defined.
- Medium confidence: The experimental results showing FFA outperforming LIME/SHAP are methodologically sound but limited in scope (primarily tabular data with small decision trees).
- Low confidence: The claim that FFA provides "strict and formal definition of feature importance" translates to practical superiority in real-world applications, as this depends heavily on problem-specific factors not fully explored.

## Next Checks
1. Test FFA computation on larger, deeper decision trees (depth > 3) to evaluate the practical limits of the CXp-targeting approximation strategy.
2. Conduct ablation studies comparing CXp-targeting versus direct AXp enumeration to quantify the sampling bias introduced by the duality-based approach.
3. Evaluate FFA on non-tabular domains (time series, text) where feature independence assumptions may break down more severely.