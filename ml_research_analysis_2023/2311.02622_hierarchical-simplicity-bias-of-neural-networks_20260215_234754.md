---
ver: rpa2
title: Hierarchical Simplicity Bias of Neural Networks
arxiv_id: '2311.02622'
source_url: https://arxiv.org/abs/2311.02622
tags:
- label
- mnist
- neural
- predicted
- digit
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper demonstrates that neural networks exhibit a hierarchical
  simplicity bias, making predictions that align with the ascending complexity of
  features based on their correlation with training labels, irrespective of actual
  predictive power. Through experiments with synthetic datasets, the authors show
  that networks prioritize simpler features like patches over MNIST digits, and MNIST
  digits over CIFAR-10 images, creating a decision-tree-like behavior.
---

# Hierarchical Simplicity Bias of Neural Networks

## Quick Facts
- arXiv ID: 2311.02622
- Source URL: https://arxiv.org/abs/2311.02622
- Authors: 
- Reference count: 40
- Key outcome: Neural networks exhibit hierarchical simplicity bias, prioritizing simpler features over more complex ones based on their correlation with training labels, regardless of actual predictive power.

## Executive Summary
This paper demonstrates that neural networks exhibit a hierarchical simplicity bias, where they make predictions aligned with the ascending complexity of features based on their correlation with training labels, irrespective of actual predictive power. Through experiments with synthetic datasets like MNIST-CIFAR-10, the authors show that networks prioritize simpler features (patches, MNIST digits) over more complex ones (CIFAR-10 images), creating decision-tree-like behavior. This leads to misclassification patterns where spurious features can cause most cats to be misclassified as dogs and trucks as automobiles. While Deep Feature Reweighting improves performance from 49.24% to 68.12% accuracy, it remains insufficient to fully recover core features when spurious features are perfectly correlated with target labels.

## Method Summary
The paper investigates hierarchical simplicity bias through synthetic datasets constructed with imbalanced label coupling, where specific features are perfectly correlated with labels in training but not in testing. Experiments use ResNet-18 architecture (with channel adjustments for concatenated inputs) trained on datasets like MNIST-CIFAR-10, CIFAR-MNIST, Patch-MNIST, and others. Training follows standard procedures with SGD optimizer (momentum 0.9, batch size 128) for 150 epochs with learning rate decay. The study evaluates classification accuracy, confusion matrices, and semantic accuracy (broader category distinctions), and tests Deep Feature Reweighting as a mitigation strategy by retraining the last layer with target distribution data.

## Key Results
- Neural networks consistently prioritize simpler features (like MNIST digits) over more complex ones (like CIFAR-10 images) based on their correlation with labels, regardless of predictive power
- In CIFAR-10 experiments, spurious features cause most cats to be misclassified as dogs and trucks as automobiles
- Deep Feature Reweighting improves performance from 49.24% to 68.12% accuracy but falls short of baseline accuracy of 87.75%
- Semantic accuracy (distinguishing between vehicles vs animals) remains high even when standard accuracy drops

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Neural networks exhibit hierarchical simplicity bias by prioritizing features based on their correlation with labels, independent of actual predictive power.
- Mechanism: The network learns to make predictions in alignment with ascending complexity of input features according to how they correlate with labels in the training set, irrespective of underlying predictive power.
- Core assumption: Simpler features can be perfectly correlated with labels in certain subgroups, creating a hierarchical decision-making process.
- Evidence anchors:
  - [abstract] "trained networks sequentially consider features of increasing complexity based on their correlation with labels in the training set, regardless of their actual predictive power"
  - [section] "The neural network consistently gives priority to MNIST regardless of its predictive power"
  - [corpus] Weak - the corpus mentions simplicity bias but doesn't specifically address hierarchical feature complexity ordering
- Break condition: If spurious features are not perfectly correlated with target labels, or if multiple features have similar correlation strengths, the hierarchical bias may break down.

### Mechanism 2
- Claim: Deep Feature Reweighting (DFR) can partially recover core features but cannot fully overcome spurious correlations when they are perfectly aligned with target labels.
- Mechanism: Retraining the last layer with target distribution data improves performance from 49.24% to 68.12% accuracy, but falls short of baseline accuracy of 87.75%.
- Core assumption: Some core feature information may be lost in intermediate layers, limiting the effectiveness of last-layer retraining.
- Evidence anchors:
  - [section] "Deep Feature Reweighting improves performance from 49.24% to 68.12% accuracy, showing effectiveness in mitigating the effects of spurious correlations to a certain degree"
  - [section] "Yet, it falls short of the baseline accuracy of 87.75%, indicating that DFR alone may not completely overcome the challenges posed by spurious features"
  - [corpus] Moderate - corpus papers discuss simplicity bias mitigation but don't specifically address DFR limitations with perfect spurious correlations
- Break condition: When spurious features are not perfectly correlated with target labels, or when core features are strongly represented in intermediate layers.

### Mechanism 3
- Claim: Neural networks can capture semantic information at higher abstraction levels even in the presence of spurious correlations.
- Mechanism: While standard accuracy drops due to spurious features, semantic accuracy (distinguishing between broader categories like vehicles vs animals) remains high.
- Core assumption: The model is capable of identifying broader categorical distinctions even when finer-grained class distinctions are affected.
- Evidence anchors:
  - [section] "semantic accuracy (distinguishing between vehicles vs animals) remains high even when standard accuracy drops"
  - [section] "Interestingly, the spurious features do not override the core features associated with these broader categories"
  - [corpus] Weak - corpus doesn't specifically address semantic vs standard accuracy distinctions
- Break condition: When spurious features are designed to confuse semantic categories, not just class distinctions.

## Foundational Learning

- Concept: Feature correlation vs predictive power distinction
  - Why needed here: The paper's central finding relies on understanding that networks prioritize features based on correlation with labels, not actual predictive power
  - Quick check question: If a simple feature is perfectly correlated with labels in 50% of the data but has zero predictive power for the other 50%, will the network still prioritize it?

- Concept: Hierarchical decision-making in neural networks
  - Why needed here: The paper demonstrates that networks make predictions through several implicit stages, resembling decision trees
  - Quick check question: In the MNIST-CIFAR experiment, why does the network first check the MNIST digit before considering the CIFAR image?

- Concept: Spurious correlation vs core feature distinction
  - Why needed here: The paper's experiments rely on creating datasets where certain features are spurious correlations but others are core features
  - Quick check question: How can you determine whether a feature is a spurious correlation or a core feature in a real-world dataset?

## Architecture Onboarding

- Component map: Data preprocessing → Concatenation of features → ResNet-18 training → Analysis of confusion matrices → Deep Feature Reweighting
- Critical path: Data preprocessing → Concatenation of features → Network training → Analysis of confusion matrices → Application of DFR
- Design tradeoffs: Using synthetic datasets allows precise control over feature correlations but may not generalize to real-world scenarios
- Failure signatures: Random classification within subgroups, complete reliance on spurious features, or inability to learn any hierarchical structure
- First 3 experiments:
  1. Replicate MNIST-CIFAR experiment with ResNet-18 to verify hierarchical simplicity bias
  2. Apply Deep Feature Reweighting to the trained model and compare standard vs semantic accuracy
  3. Test the same architecture on corrupted CIFAR-10 dataset to verify background/corruption hierarchy

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the hierarchical simplicity bias manifest in more complex real-world datasets beyond synthetic ones?
- Basis in paper: [inferred] The paper acknowledges limitations in observing extreme hierarchical relationships in practice and suggests future research should extend findings to real-world situations.
- Why unresolved: The study primarily uses synthetic datasets designed to highlight specific behaviors in controlled settings, which may not reflect real-world complexity.
- What evidence would resolve it: Experiments on diverse real-world datasets showing hierarchical decision-making patterns across multiple levels of feature complexity.

### Open Question 2
- Question: What theoretical framework could explain the mechanism behind hierarchical simplicity bias in neural networks?
- Basis in paper: [inferred] The paper notes that understanding neural network behavior requires looking beyond overall accuracy and considering different levels of abstraction, but doesn't provide a theoretical model.
- Why unresolved: The paper demonstrates the phenomenon empirically but doesn't develop a theoretical explanation for why networks prioritize features hierarchically based on complexity.
- What evidence would resolve it: A mathematical framework or computational model that predicts when and how hierarchical simplicity bias emerges during training.

### Open Question 3
- Question: Can we develop mitigation strategies that specifically target hierarchical simplicity bias without compromising other beneficial aspects of neural network learning?
- Basis in paper: [explicit] The paper concludes by suggesting strategies to mitigate adverse effects of this bias and notes that DFR alone may not completely overcome challenges posed by spurious features.
- Why unresolved: While the paper shows that last-layer retraining improves performance somewhat, it remains insufficient, and the paper doesn't propose alternative strategies targeting this specific bias.
- What evidence would resolve it: New training methods or architectural modifications that reduce hierarchical bias while maintaining or improving generalization performance.

## Limitations

- The findings are based primarily on synthetic datasets, which may not fully capture the complexity of real-world spurious correlations
- The study focuses on ResNet-18 architecture, limiting understanding of how this bias manifests across different network designs
- Deep Feature Reweighting shows only partial effectiveness, suggesting fundamental limitations in current mitigation approaches

## Confidence

- **High confidence**: The hierarchical decision-making mechanism and the core observation that networks prioritize features based on correlation rather than predictive power
- **Medium confidence**: The effectiveness of Deep Feature Reweighting as a mitigation strategy, given the partial improvement but incomplete resolution
- **Low confidence**: The generalizability of findings to real-world datasets and diverse network architectures beyond ResNet-18

## Next Checks

1. **Architecture Transferability Test**: Replicate the core experiments using different network architectures (e.g., Vision Transformers, EfficientNet) to assess whether hierarchical simplicity bias is architecture-dependent or a general phenomenon across neural network designs.

2. **Real-World Dataset Validation**: Apply the methodology to real-world datasets with known spurious correlations (e.g., gender bias in medical imaging, background artifacts in satellite imagery) to test whether the hierarchical simplicity bias extends beyond synthetic constructions.

3. **Intermediate Layer Analysis**: Conduct detailed analysis of feature representations at intermediate layers to understand how core features and spurious features are encoded throughout the network, not just in the final layer, to better understand information loss mechanisms.