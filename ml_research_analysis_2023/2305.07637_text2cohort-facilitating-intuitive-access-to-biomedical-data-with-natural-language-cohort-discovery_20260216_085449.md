---
ver: rpa2
title: 'Text2Cohort: Facilitating Intuitive Access to Biomedical Data with Natural
  Language Cohort Discovery'
arxiv_id: '2305.07637'
source_url: https://arxiv.org/abs/2305.07637
tags:
- collection
- count
- dicom
- current
- select
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper presents Text2Cohort, a large language model (LLM)-powered
  toolkit for facilitating natural language cohort discovery in the Imaging Data Commons
  (IDC) database. The method translates user input into IDC queries using prompt engineering
  and grounding techniques, returning the query's response.
---

# Text2Cohort: Facilitating Intuitive Access to Biomedical Data with Natural Language Cohort Discovery

## Quick Facts
- arXiv ID: 2305.07637
- Source URL: https://arxiv.org/abs/2305.07637
- Authors: 
- Reference count: 40
- Text2Cohort achieved 88% accuracy and 0.94 F1 score in translating natural language to IDC queries

## Executive Summary
This paper introduces Text2Cohort, an LLM-powered toolkit that enables researchers to discover and curate cohorts in the Imaging Data Commons (IDC) database using natural language queries. The system leverages GPT-3.5's zero-shot prompting capability to translate user inputs into valid BigQuery SQL queries, with an autocorrection pipeline that resolves syntax and semantic errors through recursive interpretation of error messages. The toolkit was evaluated on 50 diverse natural language inputs, demonstrating its ability to handle both simple information extraction and complex cohort discovery tasks with high accuracy.

## Method Summary
Text2Cohort uses GPT-3.5 to translate natural language into IDC queries through prompt engineering and grounding techniques. The system employs a four-step process: prompt engineering to prime the model, BigQuery query generation, an autocorrection pipeline that handles syntax and semantic errors by interpreting error messages and regenerating queries up to 10 times, and cohort extraction to convert results into Pandas dataframes. The toolkit was evaluated on 50 natural language inputs ranging from simple information extraction to complex cohort discovery tasks.

## Key Results
- Generated responses with 88% accuracy across 50 diverse natural language inputs
- Achieved 0.94 F1 score in correctly translating natural language to valid IDC queries
- Successfully handled both information extraction and cohort discovery query types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: GPT-3.5's zero-shot prompting capability translates natural language into valid SQL queries
- Core assumption: GPT-3.5's training includes sufficient exposure to structured query patterns
- Evidence anchors: [abstract] translation using grounding techniques, [section] prompt engineering template
- Break condition: Model lacks understanding of target schema or prompt engineering fails

### Mechanism 2
- Claim: Recursive autocorrection resolves syntax and semantic errors through error message interpretation
- Core assumption: GPT-3.5 can interpret BigQuery error messages and modify queries accordingly
- Evidence anchors: [abstract] autocorrection resolves errors by passing them back to the model, [section] weak supervision approach
- Break condition: Semantic errors persist beyond attempt limit or error messages are ambiguous

### Mechanism 3
- Claim: High accuracy (88%) achieved through combination of prompt engineering, autocorrection, and schema awareness
- Core assumption: Consistent and well-documented data schema enables high-probability valid query generation
- Evidence anchors: [abstract] 88% accuracy and 0.94 F1 score, [section] occasional failures due to schema misunderstanding
- Break condition: Frequent schema changes or excessive complexity without fine-tuning

## Foundational Learning

- Concept: Natural language processing (NLP) and prompt engineering
  - Why needed here: System relies on GPT-3.5's ability to understand and translate natural language into structured queries
  - Quick check question: Can you explain how zero-shot prompting differs from few-shot or fine-tuning approaches?

- Concept: SQL and BigQuery schema understanding
  - Why needed here: LLM must generate syntactically correct and semantically valid queries against IDC database schema
  - Quick check question: What are the key differences between BigQuery and traditional SQL dialects that could impact query generation?

- Concept: Error handling and recursive correction logic
  - Why needed here: Autocorrect pipeline must interpret error messages and regenerate queries effectively
  - Quick check question: How would you design a system to detect when autocorrection is no longer making progress?

## Architecture Onboarding

- Component map: User Input -> Prompt Engineering Module -> LLM Query Generation -> BigQuery Generation -> Error Detection -> Autocorrect Pipeline (if needed) -> Cohort Extraction -> User Output

- Critical path: 1) User input → Prompt Engineering → LLM query generation 2) Query execution → Error detection → Autocorrect (if needed) 3) Result extraction → User output

- Design tradeoffs:
  - Autocorrect recursion depth vs. token limits: Balancing thoroughness with API constraints
  - Prompt complexity vs. generation speed: More detailed prompts may improve accuracy but increase latency
  - Schema knowledge vs. generalization: Incorporating more schema details improves accuracy but reduces flexibility

- Failure signatures:
  - High autocorrection attempts without success: Indicates semantic misunderstanding
  - Repeated syntax errors: Suggests prompt engineering issues
  - Low accuracy on specific query types: May require targeted prompt adjustments

- First 3 experiments:
  1. Test prompt variations on a small set of queries to measure impact on accuracy
  2. Evaluate autocorrection effectiveness by injecting known errors and measuring resolution rate
  3. Benchmark performance across different query types (information extraction vs. cohort discovery) to identify bottlenecks

## Open Questions the Paper Calls Out

- Question: What is the impact of incorporating in-context learning techniques on Text2Cohort's ability to handle semantic errors without requiring expert intervention?
- Basis in paper: [explicit] Authors intend to explore in-context learning techniques for addressing limitations
- Why unresolved: Paper does not provide results or implementation details of using in-context learning for error correction
- What evidence would resolve it: Comparative experiments showing performance with and without in-context learning

- Question: How does Text2Cohort's performance vary across different types of natural language queries?
- Basis in paper: [inferred] Evaluation includes 50 diverse inputs but lacks breakdown by query type
- Why unresolved: Only provides overall accuracy and F1 score without analyzing performance differences
- What evidence would resolve it: Detailed performance metrics for each category of queries

- Question: What are the limitations of Text2Cohort when dealing with queries requiring understanding of relationships between multiple fields or collections?
- Basis in paper: [explicit] Mentions incorrect responses due to poor understanding of data schema
- Why unresolved: Does not provide specific examples or quantify frequency of schema-related errors
- What evidence would resolve it: Case studies of failed queries due to misunderstanding relationships

## Limitations

- Small evaluation sample (50 inputs) may not capture full complexity of real-world biomedical research queries
- Accuracy results potentially inflated by use of two computer scientists for ground truth validation
- Autocorrection pipeline may struggle with ambiguous or complex error messages requiring deep domain expertise

## Confidence

High confidence in core mechanism: GPT-3.5 can successfully generate SQL queries from natural language inputs with appropriate prompt engineering and schema context
Medium confidence in autocorrection pipeline: Effectiveness may vary depending on error complexity and LLM's interpretation abilities
Low confidence in generalizability: Small sample size and lack of diverse query types limit extrapolation to broader use cases

## Next Checks

1. Conduct larger-scale evaluation using 200+ diverse natural language queries across different biomedical research domains
2. Implement ablation study to measure individual contributions of prompt engineering, autocorrection, and schema context
3. Test system resilience to schema changes by introducing controlled modifications to IDC database structure