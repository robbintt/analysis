---
ver: rpa2
title: Data-driven Crop Growth Simulation on Time-varying Generated Images using Multi-conditional
  Generative Adversarial Networks
arxiv_id: '2312.03443'
source_url: https://arxiv.org/abs/2312.03443
tags:
- image
- images
- growth
- crop
- biomass
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This work presents a framework for predicting future crop growth
  stages using multi-conditional generative adversarial networks (GANs). The framework
  consists of two independently trained models: an image prediction model and a growth
  estimation model.'
---

# Data-driven Crop Growth Simulation on Time-varying Generated Images using Multi-conditional Generative Adversarial Networks

## Quick Facts
- arXiv ID: 2312.03443
- Source URL: https://arxiv.org/abs/2312.03443
- Reference count: 40
- Key outcome: A framework using multi-conditional GANs to predict future crop growth stages from time-series images, integrating process-based biomass simulations to improve trait accuracy.

## Executive Summary
This paper presents a two-stage framework for data-driven crop growth simulation that generates realistic time-varying images of future plant growth stages using multi-conditional generative adversarial networks. The approach integrates multiple conditions including time points, treatment information, and process-based simulated biomass into a conditional Wasserstein GAN with conditional batch normalization. Experiments on three datasets demonstrate the framework's ability to produce realistic image predictions while maintaining sharp details, with added biomass conditioning shown to improve the accuracy of derived phenotypic traits. The modular design provides an interface between image-based and process-based crop growth models, offering insights into how growth-influencing factors relate to crop appearances.

## Method Summary
The framework consists of two independently trained models: an image prediction model (conditional Wasserstein GAN) and a growth estimation model. The image prediction model uses conditional batch normalization layers to integrate multiple conditions of different types (images, time points, treatment information, and simulated biomass) while preserving model stochasticity. The growth estimation model, which can be either instance segmentation for leaf area or regression for biomass, derives plant-specific traits from generated images and compares them with real reference images. The models are trained on three datasets with varying complexity, and image quality is evaluated using MS-SSIM, LPIPS, and FID metrics, while trait accuracy is measured through projected leaf area or biomass estimation.

## Key Results
- The framework successfully generates realistic, sharp time-varying crop images with a slight quality loss from short-term to long-term predictions
- Adding process-based simulated biomass as a condition increases the accuracy of derived phenotypic traits from predicted images
- The modular design provides a flexible interface between image- and process-based crop growth models
- The approach demonstrates potential for simulating varying growth-influencing conditions, particularly useful in complex crop mixture systems

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The conditional batch normalization (CBN) layers in both encoder and decoder allow effective integration of multiple conditions of different types (images, time, treatment, biomass) while preserving model stochasticity.
- Mechanism: CBN layers replace standard batch normalization and learn affine parameters conditioned on auxiliary embeddings. Each condition type is embedded separately and concatenated, enabling the generator to produce realistic images dependent on multiple influencing factors without collapsing into deterministic outputs.
- Core assumption: The auxiliary embeddings can capture the semantic meaning of each condition type and that concatenating them maintains their individual effects.
- Evidence anchors:
  - [abstract] "In the generator of this model, conditional batch normalization (CBN) is used to integrate different conditions along with the input image."
  - [section] "To integrate the conditions, all batch normalization layers are replaced by conditional batch normalization layers (CBN) [...] This enables the generator to produce realistic images dependent on multiple influencing factors without collapsing into deterministic outputs."
- Break condition: If the embeddings fail to capture condition semantics, the generator will produce unrealistic or mode-collapsed images.

### Mechanism 2
- Claim: The two-stage architecture (image prediction + growth estimation) enables evaluation of image quality through plant-specific traits rather than relying solely on traditional GAN metrics.
- Mechanism: The image prediction model generates synthetic images conditioned on various factors. These images are then processed by an independently trained growth estimation model to derive plant traits. Comparing these traits between real and generated images provides a more meaningful evaluation of prediction quality.
- Core assumption: The growth estimation model is sufficiently accurate on real images and can generalize to generated images with minor artifacts.
- Evidence anchors:
  - [abstract] "The growth estimation model derives plant-specific traits from these images and compares them with those of non-artificial (real) reference images."
  - [section] "To evaluate the quality of generated images, we use a well-established set of GAN evaluation metrics. [...] we use growth estimation models, which determine leaf area (Sec. 2.3.1) and biomass (Sec. 2.3.2) from the generated images."
- Break condition: If the growth estimation model is not robust to artifacts in generated images, trait comparison will be misleading.

### Mechanism 3
- Claim: Including process-based simulated biomass as a condition improves the accuracy of derived phenotypic traits from predicted images.
- Mechanism: The image prediction model is trained with biomass values simulated by a process-based crop growth model as an additional condition. This provides the generator with information about expected plant size/development, leading to more accurate spatial representations. Consequently, the growth estimation model derives more accurate traits from these images.
- Core assumption: The process-based biomass simulation correlates well with actual plant development and can be effectively encoded into the image generation process.
- Evidence anchors:
  - [abstract] "Further results show that adding process-based simulated biomass as a condition increases the accuracy of the derived phenotypic traits from the predicted images."
  - [section] "Notably, we use the same simulated biomass values that are used as conditions in the image prediction part of the framework."
- Break condition: If the process-based biomass simulation is inaccurate or poorly correlated with image features, including it as a condition may degrade image quality.

## Foundational Learning

- Concept: Conditional Generative Adversarial Networks (cGANs)
  - Why needed here: The framework relies on cGANs to generate realistic crop images conditioned on multiple growth-influencing factors.
  - Quick check question: How does a cGAN differ from a standard GAN in terms of input and output generation?

- Concept: Conditional Batch Normalization (CBN)
  - Why needed here: CBN is used to integrate multiple conditions of different types (images, time, treatment, biomass) into the generator while maintaining stochasticity.
  - Quick check question: What role do the learnable affine parameters in CBN play in conditioning the batch normalization layers?

- Concept: Instance Segmentation and Image Regression for Phenotyping
  - Why needed here: These methods are used in the growth estimation stage to derive plant-specific traits (leaf area, biomass) from both real and generated images for evaluation.
  - Quick check question: How do instance segmentation and image regression differ in terms of their output and application to plant phenotyping?

## Architecture Onboarding

- Component map: Input conditions → Image Prediction Model (CWGAN-GP with CBN) → Generated images → Growth Estimation Model (Mask R-CNN/ResNet-18) → Derived plant traits → Evaluation

- Critical path: Input conditions → Image Prediction Model → Generated images → Growth Estimation Model → Derived plant traits → Evaluation

- Design tradeoffs:
  - Using CBN allows integration of multiple conditions but adds complexity to the model architecture.
  - Training the image prediction and growth estimation models independently provides modularity but may lead to suboptimal trait estimation if the growth model is not robust to artifacts in generated images.
  - Including process-based biomass as a condition improves trait accuracy but relies on the accuracy of the biomass simulation.

- Failure signatures:
  - Poor image quality (low MS-SSIM, high LPIPS, high FID) indicates issues with the image prediction model.
  - Inaccurate trait estimation (high MAE, ME) suggests problems with either the image prediction model or the growth estimation model's robustness to generated image artifacts.
  - Mode collapse or deterministic outputs point to issues with the conditioning mechanism or training process.

- First 3 experiments:
  1. Train the image prediction model on a single condition (time) and evaluate image quality and trait estimation on the test set.
  2. Add treatment information as an additional condition and retrain the image prediction model. Evaluate the impact on image quality and trait estimation.
  3. Include process-based simulated biomass as a condition and retrain the image prediction model. Assess the effect on trait estimation accuracy compared to using only time and treatment conditions.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the uncertainty in the image prediction model be better integrated for long-term growth predictions, especially considering the overconfidence observed at large temporal prediction distances?
- Basis in paper: [explicit] The paper discusses the issue of overconfidence in long-term predictions and suggests that the noise-input ratio should be adaptively controlled depending on the growth prediction step.
- Why unresolved: The paper identifies the problem but does not provide a concrete solution or methodology for implementing adaptive noise-input ratio control.
- What evidence would resolve it: A detailed experimental study demonstrating the effectiveness of different adaptive noise-input ratio control strategies in reducing overconfidence and improving prediction accuracy for long-term growth stages.

### Open Question 2
- Question: What are the potential benefits and challenges of adding site-dependent context variables as additional conditions in the image-prediction model to improve generalizability across different experimental sites?
- Basis in paper: [explicit] The paper suggests that adding style as an additional condition or more generally, site-dependent context variables, could ensure better transferability and merge multiple plant time series into a more generic data-driven crop growth model.
- Why unresolved: While the paper proposes this idea, it does not explore the practical implementation, benefits, or challenges of incorporating site-dependent context variables.
- What evidence would resolve it: A comparative study showing the performance of models with and without site-dependent context variables across multiple experimental sites, highlighting improvements in transferability and generalizability.

### Open Question 3
- Question: How can the integration of process-based model output into a data-driven crop growth model be optimized to improve the calibration of process-based models and bring them closer to image-based field observations?
- Basis in paper: [explicit] The paper demonstrates the capability of including dynamic output variables of a process-based crop growth model in the framework and suggests that this analysis can serve to improve the calibration of the process-based model.
- Why unresolved: The paper provides initial insights but does not explore the optimization strategies for integrating process-based model output or the extent to which this integration can improve model calibration.
- What evidence would resolve it: A comprehensive study evaluating different integration strategies and their impact on the calibration accuracy of process-based models, supported by case studies from various crop types and growth conditions.

## Limitations
- The framework's performance heavily depends on the quality and representativeness of the process-based biomass simulation used as a conditioning variable.
- The independence of the image prediction and growth estimation models creates potential evaluation inconsistencies and may lead to suboptimal trait estimation.
- The effectiveness of conditional batch normalization for integrating multiple heterogeneous conditions relies on the assumption that simple embedding concatenation adequately captures complex interactions between variables.

## Confidence
- **High confidence**: The framework architecture and training methodology are well-defined, with clear implementation details for the conditional GAN and growth estimation components.
- **Medium confidence**: The reported improvements from adding biomass conditioning are promising but rely on a single process-based simulation model whose accuracy is not independently validated.
- **Low confidence**: The generalization capability of the framework to different crop types and growth conditions beyond the tested datasets remains uncertain.

## Next Checks
1. **Cross-validation of biomass simulation**: Compare the process-based biomass simulation with ground truth measurements across different crop types and growth conditions to assess conditioning reliability.
2. **Ablation study on condition integration**: Systematically evaluate the impact of each conditioning variable (time, treatment, biomass) on image quality and trait estimation accuracy to understand their individual contributions.
3. **Robustness testing**: Evaluate the framework's performance when the growth estimation model is trained on a subset of conditions not present in the image prediction training data to assess generalization capability.