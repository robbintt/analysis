---
ver: rpa2
title: A Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic
  Data
arxiv_id: '2301.10053'
source_url: https://arxiv.org/abs/2301.10053
tags:
- data
- synthetic
- privacy
- dataset
- attack
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the vulnerability of synthetic tabular data
  to attribute inference attacks. It introduces a new privacy game and extends linear
  reconstruction attacks to synthetic data, targeting all records rather than just
  outliers.
---

# A Linear Reconstruction Approach for Attribute Inference Attacks against Synthetic Data

## Quick Facts
- arXiv ID: 2301.10053
- Source URL: https://arxiv.org/abs/2301.10053
- Reference count: 40
- Primary result: Linear reconstruction attacks can achieve up to 90% accuracy against synthetic tabular data by exploiting statistical query preservation

## Executive Summary
This work demonstrates a significant vulnerability in synthetic tabular data: attribute inference attacks that exploit the preservation of statistical queries. The authors introduce a linear reconstruction attack that targets all records in synthetic datasets, not just outliers, by constructing linear constraints from 3-way marginal queries. Experiments show the attack achieves up to 90% accuracy across various synthetic data generation algorithms, significantly outperforming prior approaches. The work reveals that both privacy and utility of synthetic data strongly depend on the number of synthetic records released, with larger datasets providing higher utility but also increasing privacy risks. Differential privacy mechanisms offer some protection but still exhibit similar privacy-utility tradeoffs.

## Method Summary
The attack exploits the fundamental property that synthetic data generation algorithms aim to preserve statistical queries from the original data. By constructing 3-way marginal queries on the synthetic data and comparing them to reconstructed queries, the adversary formulates a linear program that minimizes the error between these query sets. This linear reconstruction approach solves for the most likely vector of secret attributes. The attack is evaluated against multiple synthetic data generation algorithms (NonPrivate, BayNet, RAP, CTGAN, IndHist, PrivBayes) on real-world datasets (ACS Employment task, San Francisco Fire Department Calls for Service) with varying synthetic dataset sizes (m = 103 to 106). Attack accuracy is measured and compared against prior attacks including distance-based and machine learning inference approaches.

## Key Results
- Linear reconstruction attacks achieve up to 90% accuracy in inferring secret attributes from synthetic data
- Attack effectiveness strongly depends on synthetic dataset size, with larger datasets increasing vulnerability
- Different synthetic data generation algorithms show varying levels of resistance, with RAP and BayNet being most vulnerable while CTGAN and IndHist show stronger privacy
- Differential privacy mechanisms provide some protection but still exhibit similar privacy-utility tradeoffs as non-private methods

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Linear reconstruction attacks can exploit statistical query preservation in synthetic data to infer secret attributes.
- Mechanism: The attack constructs linear constraints from 3-way marginal queries on the synthetic data. By solving a linear program that minimizes the error between these synthetic queries and reconstructed queries, the adversary estimates the most likely vector of secret attributes.
- Core assumption: Synthetic data generation algorithms preserve 3-way marginal queries from the original data with low error.
- Evidence anchors:
  - [abstract]: "The attack exploits the preservation of statistical queries in synthetic data to reconstruct secret attributes."
  - [section]: "Synthetic data aims to serve as a safe replacement for original data while retaining the statistical properties of the original dataset. Therefore, we should expect that statistical queries on the synthetic data are reasonably accurate..."
- Break condition: If synthetic data generation algorithms add noise that destroys the coherence of marginal queries, the linear reconstruction approach fails.

### Mechanism 2
- Claim: Increasing synthetic data size improves utility but also increases vulnerability to attribute inference attacks.
- Mechanism: Larger synthetic datasets reduce sampling error, making marginal queries more accurate. This increased accuracy in query preservation strengthens the adversary's ability to solve the linear reconstruction problem.
- Core assumption: Sampling error is the primary source of noise in synthetic data marginal queries.
- Evidence anchors:
  - [abstract]: "Experiments on real-world datasets and various synthetic data generation algorithms show that the attack can achieve up to 90% accuracy... The work also reveals that both privacy and utility of synthetic data are strongly dependent on the number of synthetic records released..."
  - [section]: "We find that both the privacy and utility of synthetic data are strongly dependent on the number of synthetic records that are released... This effect might, however, not generalise to other attacks..."
- Break condition: If other sources of noise (e.g., differential privacy) dominate over sampling error, increasing synthetic data size may not improve attack accuracy.

### Mechanism 3
- Claim: Differentially private synthetic data generation provides better privacy-utility tradeoffs than non-private methods.
- Mechanism: Differential privacy adds calibrated noise to the synthetic data generation process, degrading the accuracy of marginal queries. This noise makes it harder for the adversary to solve the linear reconstruction problem accurately.
- Core assumption: Differential privacy noise is sufficient to obscure the statistical relationships needed for attribute inference.
- Evidence anchors:
  - [abstract]: "Differential privacy mechanisms offer some protection but still exhibit similar privacy-utility tradeoffs."
  - [section]: "We investigate the effectiveness of some differential privacy mechanisms as defense strategies and conclude that they do not provide a significantly better tradeoff."
- Break condition: If the privacy budget is too large or the synthetic data size is too small, differential privacy noise may not effectively protect against attribute inference attacks.

## Foundational Learning

- Concept: Linear reconstruction attacks
  - Why needed here: The attack extends this technique from interactive query systems to synthetic data context.
  - Quick check question: What is the key difference between linear reconstruction attacks on query systems versus synthetic data?

- Concept: Marginal queries and their role in synthetic data evaluation
  - Why needed here: The attack exploits the preservation of these statistics in synthetic data to infer secret attributes.
  - Quick check question: Why are 3-way marginal queries particularly important for this attack?

- Concept: Privacy-utility tradeoff in synthetic data generation
  - Why needed here: Understanding this tradeoff is crucial for interpreting the experimental results and their implications.
  - Quick check question: What happens to privacy and utility when the size of the synthetic dataset increases?

## Architecture Onboarding

- Component map:
  - Original dataset -> Target record selection -> Synthetic data generation -> Linear reconstruction attack
  - Adversary models: Linear reconstruction (Advrecon), distance-based (Advdcr), machine learning inference (Advinfer)
  - Evaluation metrics: Attack accuracy, total variation distance, mean relative error
  - Datasets: ACS Employment task, San Francisco Fire Department Calls for Service

- Critical path:
  1. Generate synthetic data from original dataset
  2. Apply attack to synthetic data to infer secret attribute
  3. Measure attack accuracy and utility metrics
  4. Analyze privacy-utility tradeoffs across different SDG algorithms and dataset sizes

- Design tradeoffs:
  - Query selection: 3-way marginals vs higher-order marginals (accuracy vs query error)
  - Synthetic data size: Larger size improves utility but increases privacy risk
  - Privacy mechanisms: Differential privacy improves privacy but degrades utility

- Failure signatures:
  - Low attack accuracy on certain SDG algorithms (CTGAN, IndHist) suggests strong privacy
  - High attack accuracy on RAP and BayNet indicates vulnerability
  - Inconsistent utility across dataset sizes indicates sampling error issues

- First 3 experiments:
  1. Implement linear reconstruction attack on synthetic data with varying dataset sizes
  2. Compare attack accuracy across different SDG algorithms (NonPrivate, BayNet, RAP, CTGAN, IndHist)
  3. Evaluate impact of differential privacy on attack accuracy and utility metrics

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How effective would higher-order marginal queries (4-way, 5-way) be in improving the accuracy of the linear reconstruction attack compared to the current 3-way queries?
- Basis in paper: [explicit] The authors mention that including higher-order marginal queries could potentially increase the overall number of queries available to the attack, thus increasing the amount of knowledge that can be exploited by the reconstruction attack. However, they also note that higher-order marginal queries have larger amounts of error even in the NonPrivate setting, which could reduce the overall power of the attack.
- Why unresolved: The authors state that they chose to use 3-way marginal queries for their attack and did not explore the use of higher-order queries. They leave this as future work.
- What evidence would resolve it: Empirical results comparing the accuracy of the linear reconstruction attack using 3-way, 4-way, and 5-way marginal queries on various synthetic datasets and SDG algorithms.

### Open Question 2
- Question: How would the attribute inference privacy game and the effectiveness of the linear reconstruction attack change if the adversary had access to quasi-identifiers for only a subset of users, or only for the target user?
- Basis in paper: [explicit] The authors discuss the possibility of relaxing the assumption of a partially informed adversary who has access to all quasi-identifiers in the original dataset. They suggest that considering a setting where the adversary has access to quasi-identifiers only for a subset of users, or only for the target user, could pose challenges both in terms of accuracy and computational feasibility.
- Why unresolved: The authors leave this as future work, stating that they did not explore this scenario in their experiments.
- What evidence would resolve it: Empirical results evaluating the accuracy of the linear reconstruction attack and the privacy-utility tradeoffs when the adversary has limited access to quasi-identifiers, compared to the current setting where the adversary has access to all quasi-identifiers.

### Open Question 3
- Question: How does the size of the synthetic dataset impact the effectiveness of other attribute inference attacks, such as the distance-based attack and the machine learning inference attack, compared to the linear reconstruction attack?
- Basis in paper: [explicit] The authors show that the size of the synthetic dataset is a strong determinant of the accuracy of the linear reconstruction attack. They also mention that the two prior attacks, the distance-based attack and the machine learning inference attack, may not be as affected by the size of the synthetic dataset.
- Why unresolved: The authors do not provide a direct comparison of the impact of synthetic dataset size on the effectiveness of the different attacks. They only show the impact on the linear reconstruction attack.
- What evidence would resolve it: Empirical results comparing the accuracy of the linear reconstruction attack, the distance-based attack, and the machine learning inference attack as a function of synthetic dataset size for various synthetic datasets and SDG algorithms.

## Limitations

- The attack's effectiveness varies significantly across different synthetic data generation algorithms, with some methods showing strong resistance that isn't fully explained
- The assumption that sampling error is the dominant source of noise may not generalize to scenarios with complex generative models or algorithmic noise
- Computational complexity of solving linear programs for large synthetic datasets presents practical limitations not fully quantified

## Confidence

- Core mechanism (statistical query preservation enabling attribute inference): High
- Differential privacy effectiveness claims: Medium
- Generalizability across all synthetic data generation methods: Medium
- Computational feasibility for very large datasets: Low

## Next Checks

1. Test the attack's effectiveness on synthetic data generated with higher-order marginal queries (4-way or 5-way) to determine if the linear reconstruction approach scales with query complexity.

2. Evaluate the attack against synthetic data generated from datasets with different attribute correlation structures (e.g., highly correlated vs. independent attributes) to assess robustness across data characteristics.

3. Implement and test alternative privacy mechanisms beyond differential privacy, such as membership inference-based defenses or query-based noise addition strategies, to compare their effectiveness against attribute inference attacks.