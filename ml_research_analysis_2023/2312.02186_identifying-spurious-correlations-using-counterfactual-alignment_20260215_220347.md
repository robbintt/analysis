---
ver: rpa2
title: Identifying Spurious Correlations using Counterfactual Alignment
arxiv_id: '2312.02186'
source_url: https://arxiv.org/abs/2312.02186
tags:
- classifier
- classifiers
- alignment
- spurious
- correlations
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper proposes the counterfactual alignment method to detect
  and quantify spurious correlations in black-box classifiers by generating counterfactual
  images with respect to one classifier and observing their impact on other classifiers.
  The relative change between classifier outputs is used to identify specific instances
  and aggregate trends of spurious correlations.
---

# Identifying Spurious Correlations using Counterfactual Alignment

## Quick Facts
- arXiv ID: 2312.02186
- Source URL: https://arxiv.org/abs/2312.02186
- Reference count: 40
- Primary result: Counterfactual alignment detects spurious correlations in black-box classifiers by comparing feature changes needed to flip different classifier predictions

## Executive Summary
This paper introduces a novel method for detecting spurious correlations in black-box classifiers by generating counterfactual images and analyzing how these perturbations affect multiple classifiers simultaneously. The approach measures relative changes in classifier outputs when exposed to the same counterfactual inputs, identifying cases where classifiers share unintended feature dependencies. Experiments on face attribute classification demonstrate the method's ability to uncover both intuitive and surprising spurious correlations, such as between "attractive" and "heavy makeup" attributes. The method further shows that composing classifiers with negative coefficients can reduce identified biases, successfully mitigating spurious correlations in 10 out of 12 tested classifiers.

## Method Summary
The counterfactual alignment method generates counterfactual images by perturbing latent representations of inputs to flip a base classifier's prediction, then measures how these same counterfactuals affect other classifiers. The core innovation is the relative change metric, which quantifies spurious correlations by comparing the magnitude of output changes across classifiers when exposed to identical counterfactual inputs. To rectify identified spurious correlations, the method composes classifiers by adding penalty terms that discourage the use of spurious features, optimizing coefficients through pseudo gradient descent. The approach works entirely with black-box classifiers, requiring only input-output pairs rather than access to model internals.

## Key Results
- The method successfully identifies spurious correlations in face attribute classifiers, including intuitive correlations (male-big nose) and unexpected ones (attractive-heavy makeup)
- Classifier composition reduces bias in 10 out of 12 tested classifiers, with average relative change reduction of 2.5%
- The relative change metric proves more effective than correlation for detecting spurious correlations, avoiding false positives when prediction changes are minimal

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Counterfactual alignment detects spurious correlations by comparing the feature changes needed to flip one classifier's prediction versus another's.
- Mechanism: Generate counterfactual images that flip the prediction of a "base" classifier. If these same counterfactuals also flip the prediction of a "downstream" classifier, they share spurious feature usage. The relative change metric quantifies this relationship by measuring how much each classifier's output changes when input with the counterfactual.
- Core assumption: Counterfactual images generated via gradient-based latent shift preserve realistic image features while isolating the specific features used by the classifier.
- Evidence anchors:
  - [abstract]: "Counterfactual images generated with respect to one classifier can be input into other classifiers to see if they also induce changes in the outputs of these classifiers."
  - [section]: "The relationship between these responses can be quantified and used to identify specific instances where a spurious correlation exists."
  - [corpus]: No direct evidence; the corpus mentions related work on counterfactuals and spurious correlations but doesn't specifically validate this alignment mechanism.
- Break condition: If the autoencoder used to generate counterfactuals poorly represents the data manifold, the counterfactuals may contain unrealistic features, leading to false spurious correlation detections.

### Mechanism 2
- Claim: Composing classifiers with coefficients can reduce spurious correlations by penalizing specific feature changes.
- Mechanism: Add a classifier that penalizes the spurious feature as a negative coefficient in the prediction. When generating counterfactuals to decrease the composed classifier's prediction, the spurious feature changes will be suppressed because they would increase the penalty term.
- Core assumption: The spurious correlation is unidirectional and can be modeled as an additive composition.
- Evidence anchors:
  - [section]: "Composing classifiers can change their response to specific samples that contain relevant features... By using this additive composition approach we avoid the variance of model training."
  - [section]: "fbiased(x) = fsmiling(x) + 0.3farched eyebrows (x)" demonstrates inducing a spurious correlation via composition, implying the reverse is possible.
  - [corpus]: No direct evidence; the corpus discusses spurious correlations but not classifier composition for rectification.
- Break condition: If the spurious correlation involves complex, non-linear interactions between features, simple additive composition may be insufficient to fully remove the bias.

### Mechanism 3
- Claim: Relative change metric is more effective than correlation for detecting spurious correlations because it accounts for the magnitude of prediction changes.
- Mechanism: Compute the ratio of output changes between two classifiers when given the same counterfactual input. This normalizes for classifiers with different output scales and sensitivities.
- Core assumption: A high relative change indicates shared feature usage, while a low relative change indicates independent feature usage.
- Evidence anchors:
  - [section]: "The relative change metric (Eq. 3) can be used to identify spurious correlations which may occur for a specific example or to identify trends over an entire dataset. We found correlation would produce false positives when there was only a slight change in the prediction of f1 compared to the base classifier fb."
  - [section]: Equation 3 defines relative change as the ratio of output differences.
  - [corpus]: No direct evidence; the corpus does not discuss relative change vs correlation.
- Break condition: If both classifiers have very small output changes for a given counterfactual, the relative change may be unstable or undefined, leading to unreliable spurious correlation detection.

## Foundational Learning

- Concept: Counterfactual explanations
  - Why needed here: The method relies on generating counterfactual images that minimally modify inputs to change classifier predictions, which is the core of counterfactual explanation techniques.
  - Quick check question: What is the key difference between counterfactual explanations and adversarial examples?

- Concept: Autoencoder latent spaces
  - Why needed here: The method uses a pre-trained autoencoder to encode images into a latent space where counterfactuals are generated via gradient-based perturbations, ensuring the generated images remain realistic.
  - Quick check question: Why is it important that the autoencoder and classifier are trained independently?

- Concept: Gradient-based attribution methods
  - Why needed here: The method compares its counterfactual alignment approach to saliency maps, which are gradient-based attribution methods, to demonstrate its advantages in detecting spurious correlations.
  - Quick check question: What is a limitation of saliency maps that counterfactual alignment aims to address?

## Architecture Onboarding

- Component map: Input image -> Autoencoder encoding -> Latent shift generation -> Counterfactual decoding -> Multiple classifiers -> Relative change calculation -> Analysis/rectification

- Critical path:
  1. Encode input image with autoencoder
  2. Generate counterfactual via gradient-based latent shift
  3. Decode counterfactual to image
  4. Run counterfactual through multiple classifiers
  5. Compute relative changes between classifier outputs
  6. Analyze relative changes to detect spurious correlations
  7. Optionally compose classifiers to rectify detected biases

- Design tradeoffs:
  - Using pre-trained classifiers enables black-box analysis but limits control over model architecture
  - Gradient-based counterfactual generation is efficient but may not capture all possible feature changes
  - Classifier composition for rectification is simple but may not fully eliminate complex spurious correlations

- Failure signatures:
  - High relative changes between all classifier pairs may indicate the autoencoder is not preserving realistic features
  - Failed convergence of classifier composition optimization may indicate the spurious correlation is too complex for simple additive composition
  - Inconsistent relative changes across train/validation/test sets may indicate overfitting during rectification

- First 3 experiments:
  1. Verify counterfactual generation works by checking that generated images flip the base classifier's prediction while remaining realistic
  2. Compute relative changes for a known spurious correlation (e.g., male and big nose) to validate the detection mechanism
  3. Test classifier composition rectification on a single example with a known spurious correlation to verify the bias reduction

## Open Questions the Paper Calls Out

The paper identifies three main limitations and open questions. First, the method's generalizability beyond face attribute classification remains untested, with authors noting they are "optimistic that our method will generalize to additional domains" but have only demonstrated results on face attributes. Second, the quality of the autoencoder used for counterfactual generation significantly impacts the fidelity and interpretability of generated counterfactuals, with authors suggesting that "improving the representational capability of the autoencoder may improve the fidelity of the CF generation." Third, while the method is presented for image classification, the authors acknowledge it could theoretically extend to other data types, though this remains unexplored.

## Limitations

- The method relies heavily on the quality of the autoencoder used for counterfactual generation, with poor reconstruction potentially leading to false spurious correlation detections
- Classifier composition for rectification assumes spurious correlations are simple, additive, and unidirectional, which may not capture complex feature interactions
- Experimental validation is limited to face attribute classification on the CelebA dataset, restricting generalizability to other domains

## Confidence

- **High Confidence**: The core mechanism of detecting spurious correlations through counterfactual alignment and relative change metric is well-supported by the experimental results and theoretical reasoning.
- **Medium Confidence**: The classifier composition approach for rectifying spurious correlations shows promising results but may not generalize to all types of spurious correlations, particularly those involving complex feature interactions.
- **Medium Confidence**: The assumption that relative change is superior to correlation for detecting spurious correlations is supported by experimental evidence but lacks extensive theoretical justification.

## Next Checks

1. Test the method on a diverse set of datasets beyond face attributes (e.g., medical imaging, object detection) to validate generalizability across domains.
2. Compare the relative change metric against alternative spurious correlation detection methods (e.g., feature importance analysis, causal inference approaches) to establish its effectiveness.
3. Investigate the method's sensitivity to autoencoder quality by systematically varying the reconstruction error threshold and measuring the impact on spurious correlation detection accuracy.