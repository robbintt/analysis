---
ver: rpa2
title: Human Conditional Reasoning in Answer Set Programming
arxiv_id: '2311.04412'
source_url: https://arxiv.org/abs/2311.04412
tags:
- answer
- program
- completion
- then
- notl
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: 'This paper proposes methods to realize human conditional reasoning
  in answer set programming (ASP). Given a conditional sentence "P=Q" (if P then Q)
  and respective facts, humans perform four types of inferences: affirming the antecedent
  (AA), affirming the consequent (AC), denying the antecedent (DA), and denying the
  consequent (DC).'
---

# Human Conditional Reasoning in Answer Set Programming

## Quick Facts
- arXiv ID: 2311.04412
- Source URL: https://arxiv.org/abs/2311.04412
- Reference count: 4
- Introduces eight completion types to model human conditional reasoning in ASP

## Executive Summary
This paper proposes methods to realize human conditional reasoning patterns in answer set programming (ASP). Humans perform four types of inferences with conditionals - affirming the antecedent (AA), affirming the consequent (AC), denying the antecedent (DA), and denying the consequent (DC) - though only AA and DC are logically valid. The paper introduces eight completion types (AC, DC, DA and their variants) that extend ASP programs with converse rules, enabling human-like reasoning patterns by simulating pragmatic bi-conditional interpretations.

## Method Summary
The method introduces eight completion types that transform standard ASP rules into bi-conditional-style inferences. Each completion type adds converse rules that enable backward reasoning - for example, AC completion adds rules that allow inferring the antecedent from the consequent. Default variants prevent contradictions by adding guarded rules with default negation. The completions can be applied selectively to subsets of rules for context-dependent reasoning. These mechanisms enable ASP to capture human reasoning patterns like affirming the consequent and denying the antecedent, which are logically invalid but commonly performed by humans.

## Key Results
- Eight completion types (AC, DC, DA and variants) successfully realize AC, DA, and DC inferences in ASP
- Default variants prevent contradictions while preserving human-like reasoning patterns
- Completions enable commonsense reasoning applications in AI
- Answer sets provide the semantics for all completion types

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Eight completion types capture human conditional reasoning patterns by transforming ASP rules into bi-conditional-style inferences.
- Mechanism: Each completion type adds converse rules that reverse inference direction, simulating backward reasoning.
- Core assumption: Humans interpret conditionals pragmatically as bi-conditionals.
- Evidence anchors: [abstract], [section], weak corpus match
- Break condition: If human reasoning doesn't follow bi-conditional interpretations

### Mechanism 2
- Claim: Default variants prevent contradiction by adding default-negation guards to completion rules.
- Mechanism: Each default rule is modified to include "not¬" literals in the body.
- Core assumption: Humans use pragmatic reasoning with fallback defaults when information is missing.
- Evidence anchors: [abstract], [section], no corpus mention
- Break condition: If guarded rules become too restrictive

### Mechanism 3
- Claim: Completions can be applied selectively to subsets of rules to simulate context-dependent reasoning.
- Mechanism: Neighborhood inference applies AC completion only to rules whose heads overlap with the request atom.
- Core assumption: Human reasoning is context-sensitive and only certain rules are interpreted as bi-conditionals depending on context.
- Evidence anchors: [abstract], [section], no corpus mention
- Break condition: If selective application creates inconsistent answer sets

## Foundational Learning

- Concept: Answer Set Programming (ASP) semantics and answer set computation
  - Why needed here: Completions define new rules whose semantics are interpreted via answer sets
  - Quick check question: What is the difference between an answer set and a minimal model in ASP?

- Concept: Default negation and explicit negation in logic programming
  - Why needed here: Paper distinguishes between default negation (not) and explicit negation (¬)
  - Quick check question: How does the reduct operation treat default negation in GEDP?

- Concept: Bi-conditional interpretation of conditionals
  - Why needed here: Core insight is that humans treat "if P then Q" as "P iff Q" in many contexts
  - Quick check question: In what psychological contexts do humans tend to interpret conditionals as bi-conditionals?

## Architecture Onboarding

- Component map: GEDP rule parser → completion rule generator (AC, DC, DA variants) → ASP solver (e.g., clingo) → answer set analyzer
- Critical path: 1) Parse input GEDP program and identify conditional rules 2) Generate completion rules according to selected completion type 3) Merge original and completion rules into new GEDP 4) Invoke ASP solver to compute answer sets 5) Analyze answer sets for target inference
- Design tradeoffs: Monotonic vs non-monotonic behavior, expressiveness vs complexity, context sensitivity vs generality
- Failure signatures: Incoherent program after completion, contradiction, missing expected inference
- First 3 experiments: 1) Apply AC completion to simple conditional program and verify backward inference 2) Test default AC completion on program with explicit negation 3) Implement neighborhood inference on travel query program and confirm alternative solutions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can the proposed completions be extended to handle more complex conditional statements beyond simple implications?
- Basis in paper: [inferred] Paper focuses on basic conditional sentences of the form "P => Q"
- Why unresolved: Paper doesn't explore how completions can be generalized to more complex structures
- What evidence would resolve it: Empirical studies demonstrating effectiveness on complex conditionals

### Open Question 2
- Question: How do the proposed completions compare to other approaches for modeling human conditional reasoning?
- Basis in paper: [explicit] Paper briefly mentions related work but doesn't provide detailed comparison
- Why unresolved: Paper doesn't conduct thorough comparison with other existing approaches
- What evidence would resolve it: Empirical studies comparing performance with other approaches

### Open Question 3
- Question: How can the proposed completions be integrated with other reasoning mechanisms?
- Basis in paper: [inferred] Paper introduces default completions, suggesting potential for integration
- Why unresolved: Paper doesn't explore integration with other reasoning mechanisms
- What evidence would resolve it: Theoretical frameworks or empirical studies demonstrating effective integration

## Limitations

- The proposed mechanisms rely heavily on the assumption that human conditional reasoning can be accurately modeled as pragmatic bi-conditional interpretation
- The selective application of completions (neighborhood inference) introduces context-dependency that may not scale well to larger knowledge bases
- The claim that these completions can be effectively applied to commonsense reasoning in AI is presented without sufficient demonstration of practical utility

## Confidence

- **High confidence**: Basic AC, DC, and DA completion mechanisms and their default variants are formally specified and can be implemented in ASP
- **Medium confidence**: Selective application of completions for context-sensitive reasoning is theoretically sound but lacks comprehensive empirical validation
- **Low confidence**: Claim that completions can be effectively applied to commonsense reasoning in AI lacks sufficient demonstration

## Next Checks

1. Implement the basic AC completion on a larger conditional reasoning dataset to verify that it produces expected human-like inferences beyond toy examples
2. Test the default variants (DAC, WDDA, SDDA) on programs containing explicit negation to measure whether they successfully prevent contradictions while preserving valid inferences
3. Apply the neighborhood inference approach to a real-world commonsense reasoning task (e.g., medical diagnosis or travel planning) and evaluate whether context-sensitive completion improves solution quality compared to global completion