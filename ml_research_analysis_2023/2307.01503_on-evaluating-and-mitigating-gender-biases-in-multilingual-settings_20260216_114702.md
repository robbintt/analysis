---
ver: rpa2
title: On Evaluating and Mitigating Gender Biases in Multilingual Settings
arxiv_id: '2307.01503'
source_url: https://arxiv.org/abs/2307.01503
tags:
- languages
- language
- computational
- biases
- association
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This work addresses the problem of evaluating and mitigating gender
  biases in multilingual language models, particularly for non-English and non-Western
  contexts where benchmarks are lacking. The authors create a benchmark for evaluating
  gender biases in 6 Indian languages by extending the DisCo metric with human-annotated
  templates, and extend debiasing methods like Counterfactual Data Augmentation and
  Self-Debiasing to work beyond English.
---

# On Evaluating and Mitigating Gender Biases in Multilingual Settings

## Quick Facts
- arXiv ID: 2307.01503
- Source URL: https://arxiv.org/abs/2307.01503
- Reference count: 20
- Primary result: Zero-shot debiasing from English provides limited bias reduction in multilingual models, while fine-tuning with language-specific counterfactuals from culturally similar languages leads to substantial improvements.

## Executive Summary
This paper addresses the challenge of evaluating and mitigating gender biases in multilingual language models, with a focus on non-English and non-Western contexts where benchmarks are lacking. The authors create a benchmark for evaluating gender biases in six Indian languages by extending the DisCo metric with human-annotated templates. They adapt debiasing methods like Counterfactual Data Augmentation and Self-Debiasing to work beyond English and evaluate these methods on state-of-the-art multilingual models. The study reveals that zero-shot debiasing from English provides limited bias reduction, while fine-tuning with language-specific counterfactuals from culturally similar languages leads to substantial improvements. Interestingly, Self-Debiasing, effective for monolingual models, often increases bias in multilingual models.

## Method Summary
The authors extend the DisCo metric to six Indian languages using human-annotated templates and create gender-balanced counterfactual examples through word replacements and translations. They adapt two debiasing methods - Counterfactual Data Augmentation (CDA) and Self-Debiasing - to work with multilingual data. For CDA, they fine-tune models with different setups: zero-shot (English only), few-shot (language-specific), few-shot with English, and multilingual debiasing excluding English. For Self-Debiasing, they prepend prompts to input text, testing both English prompts and language-specific translations. The models are evaluated using the DisCo metric (where scores closer to 0 indicate less bias) and the MBE metric.

## Key Results
- Zero-shot debiasing from English provides limited bias reduction compared to models without debiasing
- Fine-tuning with language-specific counterfactuals from culturally similar languages leads to substantial bias improvements
- Self-Debiasing, effective for monolingual models, often increases bias in multilingual models when using translated prompts
- Typologically and culturally similar languages aid each other in reducing gender bias more effectively than English-only approaches

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Zero-shot debiasing from English provides limited bias reduction because cultural context is not effectively transferred.
- Mechanism: The debiasing process relies on language-specific counterfactual data augmentation, but English-only data lacks the cultural and linguistic nuances present in non-Western languages, particularly Indian languages with gender-marked verbs and culturally specific surnames.
- Core assumption: Counterfactual data augmentation is the primary driver of bias reduction, and cultural context is essential for effective debiasing.
- Evidence anchors:
  - [abstract]: "we do observe that typologically and culturally similar languages aid each other in reducing gender bias"
  - [section 4]: "zero-shot transfer from English (CDA-{en}) results in some reduction in biases when compared to the models without any debiasing (OOB), most of the other fine-tuning setups that use language-specific counterfactuals incur better drops"
  - [corpus]: Weak evidence; corpus shows related work on fairness in non-English but no direct comparison of zero-shot vs. culturally specific debiasing.

### Mechanism 2
- Claim: Self-Debiasing increases bias in multilingual models because the prompts do not translate well across languages.
- Mechanism: Self-Debiasing relies on a prompt prepended to input text to identify and suppress biased predictions. When the English prompt is used for other languages (SD-en), it may not capture the same intent or cultural context, leading to unintended consequences in bias amplification.
- Core assumption: The effectiveness of Self-Debiasing is highly dependent on the prompt being culturally and linguistically appropriate.
- Evidence anchors:
  - [section 4]: "Self-Debiasing shows different bias mitigation trends for Indian languages. Table 1 shows that for both multilingual MLMs, the overall bias ends up increasing when Self-Debiasing is applied"
  - [section 3.2]: "We translate the English prompt... We also experiment with using English prompt for other languages (SD-en)"
  - [corpus]: Weak evidence; corpus shows related work on bias mitigation but no direct analysis of prompt translation effects.

### Mechanism 3
- Claim: Fine-tuning with language-specific counterfactuals from culturally similar languages leads to substantial bias reduction.
- Mechanism: When a model is fine-tuned with counterfactual data from languages that share cultural and linguistic features, it learns to recognize and mitigate biases more effectively. This is because the counterfactual examples are more representative of the cultural context in which the model will be used.
- Core assumption: Cultural similarity between languages is a key factor in the effectiveness of bias mitigation techniques.
- Evidence anchors:
  - [abstract]: "fine-tuning with language-specific counterfactuals from culturally similar languages leads to substantial improvements"
  - [section 4]: "few-shot debiasing (CDA-{l, en}) and multilingual-debiasing (CDA-L \ {en}) perform consistently the best"
  - [corpus]: Weak evidence; corpus shows related work on multilingual bias but no direct analysis of cultural similarity effects.

## Foundational Learning

- Concept: DisCo metric
  - Why needed here: It provides a template-based approach to measure bias in multilingual models, which is essential for evaluating the effectiveness of debiasing techniques.
  - Quick check question: How does the DisCo metric differ from other bias evaluation methods, and why is it suitable for multilingual settings?

- Concept: Counterfactual Data Augmentation (CDA)
  - Why needed here: CDA is a key technique for reducing biases in language models by augmenting the training data with counterfactual examples.
  - Quick check question: What are the challenges of generating counterfactuals for languages other than English, and how does the translation-based approach address these challenges?

- Concept: Cultural context in language models
  - Why needed here: Understanding the importance of cultural context is crucial for developing effective bias mitigation techniques in multilingual settings.
  - Quick check question: How does cultural context influence the biases present in language models, and why is it important to consider when evaluating and mitigating biases?

## Architecture Onboarding

- Component map: Data collection -> Bias evaluation (DisCo, MBE) -> Debiasing techniques (CDA, Self-Debiasing) -> Model training -> Evaluation
- Critical path: Data collection → Bias evaluation → Debiasing → Model training → Evaluation
- Design tradeoffs:
  - Using machine translation for counterfactual generation vs. native data collection
  - Zero-shot debiasing vs. language-specific debiasing
  - Prompt-based debiasing vs. data augmentation
- Failure signatures:
  - Limited bias reduction with zero-shot debiasing
  - Increased bias with Self-Debiasing
  - Ineffective counterfactual examples due to translation errors
- First 3 experiments:
  1. Compare DisCo and MBE metrics on a multilingual model to understand their strengths and weaknesses.
  2. Evaluate the effectiveness of zero-shot debiasing vs. language-specific debiasing on a multilingual model.
  3. Test the impact of culturally adapted prompts on the effectiveness of Self-Debiasing in multilingual models.

## Open Questions the Paper Calls Out

### Open Question 1
- Question: Why does Self-Debiasing increase gender bias in multilingual models while decreasing it in monolingual models?
- Basis in paper: [explicit] The authors observe that for both multilingual MLMs (XLMR and IndicBERT), Self-Debiasing leads to an increase in overall bias, which contrasts with past work showing it as an effective debiasing technique. They note this is intriguing and state "We leave the investigation of this phenomenon to future work."
- Why unresolved: The paper identifies the phenomenon but does not explain the underlying mechanisms causing this difference between multilingual and monolingual settings.
- What evidence would resolve it: Controlled experiments comparing the effects of Self-Debiasing prompts across monolingual and multilingual models, analyzing changes in likelihood distributions for gendered predictions, and examining whether the prompts are being interpreted differently in multilingual contexts.

### Open Question 2
- Question: How does the quality of machine-translated counterfactual data affect the effectiveness of CDA debiasing in low-resource languages?
- Basis in paper: [explicit] The authors acknowledge that translations are prone to errors and issues like Translationese, especially for lower-resource languages, which can lead to unreliability in the quality of generated counterfactuals. They use a translation-based approach to generate multilingual counterfactuals.
- Why unresolved: The paper uses translated counterfactuals but does not evaluate how translation quality impacts debiasing effectiveness or whether certain types of translation errors are more detrimental to bias reduction.
- What evidence would resolve it: Comparative studies measuring CDA effectiveness using counterfactuals generated through different methods (human translation vs machine translation vs direct generation in target languages) across languages with varying resource levels.

### Open Question 3
- Question: Can generative or editing models for automatic counterfactual generation scale debiasing to more languages while maintaining quality?
- Basis in paper: [explicit] The authors identify limitations with their translation-based approach and propose future work exploring "learning generative or editing models for automatically generating gender counterfactuals given text data in different languages" as a way to scale counterfactual generation while avoiding quality losses from machine translation.
- Why unresolved: The paper only proposes this direction but does not implement or evaluate such models, leaving open questions about their feasibility and effectiveness compared to translation-based approaches.
- What evidence would resolve it: Implementation and evaluation of generative counterfactual generation models across multiple languages, comparing their debiasing effectiveness, scalability, and quality to the current translation-based method.

## Limitations

- Data Quality and Representativeness: The paper relies heavily on machine-translated counterfactual data and human-annotated templates, which may contain translation errors or cultural misalignment that could impact debiasing effectiveness.
- Generalizability Beyond Indian Languages: Findings about zero-shot debiasing limitations and the effectiveness of culturally similar language pairs may not generalize to other language families.
- Metric Sensitivity: The DisCo metric may have blind spots and the paper doesn't compare results with alternative bias metrics or conduct sensitivity analysis.

## Confidence

**High Confidence**:
- Multilingual models exhibit gender bias in Indian languages
- Fine-tuning with language-specific counterfactuals reduces bias more effectively than zero-shot English-only approaches
- The extended DisCo metric is feasible for measuring bias in the six Indian languages studied

**Medium Confidence**:
- Typological and cultural similarity between languages improves cross-lingual debiasing effectiveness
- Self-Debiasing increases bias in multilingual models due to prompt translation issues
- Zero-shot debiasing from English provides limited bias reduction

**Low Confidence**:
- The specific mechanisms by which culturally similar languages aid each other in bias reduction
- The extent to which findings generalize beyond the six Indian languages studied
- The comparative effectiveness of different debiasing approaches across diverse language families

## Next Checks

1. **Translation Quality Validation**: Conduct human evaluation of the machine-translated counterfactual data to measure translation accuracy and cultural appropriateness. Compare debiasing results using professionally translated counterfactuals versus machine-translated ones for the same languages.

2. **Prompt Adaptation Experiment**: Systematically test culturally and linguistically adapted prompts for Self-Debiasing in each of the six Indian languages. Compare bias reduction effectiveness between English prompts, literal translations, and culturally adapted prompts.

3. **Cross-Linguistic Generalization Study**: Extend the debiasing experiments to a diverse set of language families (e.g., Romance, Slavic, East Asian) to test whether the observed patterns hold beyond the Indian language context. Focus particularly on testing the claim about cultural similarity aiding bias reduction.