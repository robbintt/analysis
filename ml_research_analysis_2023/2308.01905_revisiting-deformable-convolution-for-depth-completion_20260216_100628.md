---
ver: rpa2
title: Revisiting Deformable Convolution for Depth Completion
arxiv_id: '2308.01905'
source_url: https://arxiv.org/abs/2308.01905
tags:
- depth
- deformable
- completion
- convolution
- performance
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper addresses depth completion by generating high-quality
  dense depth maps from sparse depth maps. The authors propose an effective and efficient
  architecture that leverages deformable kernel convolution as a refinement module
  to address the challenges of fixed receptive field and multiple iterations required
  by existing methods.
---

# Revisiting Deformable Convolution for Depth Completion

## Quick Facts
- arXiv ID: 2308.01905
- Source URL: https://arxiv.org/abs/2308.01905
- Authors: 
- Reference count: 40
- Key outcome: Achieves state-of-the-art depth completion performance with RMSE of 728.31 mm on KITTI test set while significantly improving inference speed over prior methods

## Executive Summary
This paper addresses depth completion by generating high-quality dense depth maps from sparse depth maps using deformable convolution as a single-pass refinement module. The authors propose an effective and efficient architecture that leverages deformable kernel convolution to adaptively sample informative regions, addressing the fixed receptive field limitation of standard convolutions. The model achieves state-of-the-art performance on the KITTI dataset with superior accuracy and inference speed compared to prior work.

## Method Summary
The method uses a two-branch encoder-decoder backbone (PENet-based) that processes sparse depth and RGB images to produce a coarse depth map. A single-pass deformable kernel convolution refinement module then improves this coarse depth by learning adaptive sampling locations. The refinement module generates weights and offsets via 1x1 convolutions on concatenated features, then applies deformable interpolation to refine the depth map. The model is trained with combined L2 and L1 loss using Adam optimizer with cosine learning rate decay.

## Key Results
- Achieves RMSE of 728.31 mm, MAE of 204.60 mm, iRMSE of 2.05, and iMAE of 0.89 on KITTI test set
- Significantly outperforms PENet baseline in both accuracy and inference speed
- Single-pass deformable refinement matches or exceeds iterative refinement methods while being faster
- Ablation studies show optimal performance with deformable kernel size k=3

## Why This Works (Mechanism)

### Mechanism 1
- **Claim**: Deformable convolution can adaptively sample from sparse depth maps to focus on informative regions, addressing the fixed receptive field limitation of standard convolutions.
- **Mechanism**: The model learns offsets that dynamically adjust sampling locations within a regular grid, allowing it to "look around" the sparse depth input and find useful depth values even when they are far apart.
- **Core assumption**: With very sparse input (like KITTI's ~5% density), standard convolution's fixed grid misses informative depth values, while deformable offsets can bridge the gaps by learning where to sample.
- **Evidence anchors**:
  - [abstract] "Our key insight is that such a capability (i) is desirable for depth completion so as to adaptively attend to the most informative regions"
  - [section III-C] "Similar to [27], we add another 1 × 1 convolutional layer on feature Z to regress the offsets as well. It produces an output feature map of size 2k2 × 1 × 1 containing the relative offsets (both in x and y directions) we use to apply to sampled locations on a regular grid."
  - [corpus] Weak evidence: no direct citations comparing deformable vs fixed receptive field performance in this specific task.
- **Break condition**: If the input depth density is too low, even deformable offsets may not find enough valid neighbors to interpolate from, causing the model to fail.

### Mechanism 2
- **Claim**: Applying deformable convolution to a coarse depth map (rather than raw sparse input) provides sufficient density for the deformable sampling to work effectively.
- **Mechanism**: The backbone first produces a dense but coarse depth map. This intermediate result has enough valid depth values spread across the image for the deformable refinement module to operate meaningfully. The refinement then improves quality by adaptively focusing on regions needing correction.
- **Core assumption**: Deformable convolution needs a minimum density of valid depth values to function; raw sparse input is too sparse, but a coarse dense output from the backbone provides enough coverage.
- **Evidence anchors**:
  - [abstract] "Our study reveals that, different from prior work, deformable convolution needs to be applied on an estimated depth map with a relatively high density for better performance."
  - [section IV-C] "We thus conjecture that deformable kernel convolution requires a relatively high density for input depth maps to obtain good performance. Based on this result, (III) we further explore Variant 2... We observe that, when k = 5, the performance gets significantly degraded."
  - [corpus] No direct evidence; this is a novel finding from the ablation study.
- **Break condition**: If the backbone produces a coarse depth map that is too inaccurate or too sparse, the deformable refinement cannot recover sufficient quality.

### Mechanism 3
- **Claim**: Single-pass refinement with deformable convolution is sufficient, avoiding the iterative refinement overhead of previous methods.
- **Mechanism**: Because the deformable kernel can adaptively attend to the most informative regions in one pass, multiple refinement iterations are unnecessary. The model learns to make large corrections in a single forward pass.
- **Core assumption**: The adaptive sampling of deformable convolution captures enough context in one iteration to produce a high-quality result, unlike fixed receptive field methods that need multiple passes to propagate information.
- **Evidence anchors**:
  - [abstract] "We propose an effective and efficient architecture that leverages deformable kernel convolution as a single-pass refinement module, and empirically demonstrate its superiority."
  - [section I] "the propagation refinement module usually needs to refine the coarse depth map for several iterations to obtain satisfactory performance, which is not ideal for good hardware latency and memory footprint."
  - [section IV-A] "Notably, our approach clearly outperforms PENet, which our backbone is based on... Moreover, we include the comparison with methods like DSP and NLSPN which also use deformable convolution as part of their depth completion models. In addition to the superior accuracy, our model significantly surpasses them in terms of inference speed."
- **Break condition**: If the single pass cannot capture long-range dependencies or complex structures, performance may degrade compared to iterative methods.

## Foundational Learning

- **Concept: Deformable convolution**
  - Why needed here: Standard convolution uses a fixed grid to sample input features, which is problematic when input depth maps are extremely sparse. Deformable convolution learns offsets to adjust sampling locations, allowing the network to focus on informative depth values even when they are irregularly distributed.
  - Quick check question: What is the key difference between standard convolution and deformable convolution in terms of how they sample input features?

- **Concept: Depth completion task formulation**
  - Why needed here: Understanding that depth completion aims to generate dense depth maps from sparse inputs, often guided by RGB images, is essential to grasp why the model architecture combines a backbone (for initial dense prediction) with a refinement module (for quality improvement).
  - Quick check question: In depth completion, what are the two main data sources typically used to generate a dense depth map?

- **Concept: Single-pass vs iterative refinement**
  - Why needed here: Recognizing the trade-off between computational efficiency (single pass) and accuracy (iterative refinement) helps explain why this work's single-pass deformable refinement is a significant contribution.
  - Quick check question: Why might iterative refinement methods be less desirable for real-time applications compared to single-pass methods?

## Architecture Onboarding

- **Component map**: Sparse depth map + RGB image -> Backbone (two-branch encoder-decoder) -> Coarse depth map -> Refinement module (weights + offsets) -> Refined dense depth map

- **Critical path**: Backbone processes sparse depth and RGB to produce coarse depth → Features from backbone decoder are concatenated → Refinement module generates weights and offsets → Deformable interpolation refines coarse depth to final output

- **Design tradeoffs**:
  - Single-pass refinement vs iterative methods: Faster inference but requires the refinement to be powerful enough in one pass
  - Deformable kernel size k: Larger k captures more context but increases computation and may degrade performance if too large (as shown with k=5)
  - Interpolation technique: Nearest-neighbor interpolation on sparse input before refinement works best empirically, though the model ultimately learns a coarse depth instead

- **Failure signatures**:
  - If the coarse depth is too inaccurate, the refinement cannot recover (visible as large errors in final output)
  - If the backbone fails to produce sufficient density in coarse depth, deformable sampling has no valid neighbors to work with
  - If the offsets are not learned properly, the deformable sampling may focus on irrelevant regions

- **First 3 experiments**:
  1. Train backbone alone (without refinement) and compare RMSE/MAE to confirm the refinement adds value
  2. Train with k=3 (current) vs k=5 to verify the claim that larger kernels degrade performance
  3. Implement Variant 1 (direct deformable on sparse input) and Variant 2 (nearest-neighbor interpolated input) to reproduce the ablation results in Table I and validate the hypothesis about input density requirements

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How do different strategies for applying deformable convolution (e.g., directly on sparse input vs. after coarse depth generation) affect performance on depth completion tasks with varying input sparsity levels?
- Basis in paper: [explicit] The paper investigates variants of leveraging deformable convolution, showing that direct application on very sparse input performs poorly, while applying it to an intermediate coarse depth map yields better results.
- Why unresolved: The paper only tests these strategies on the KITTI dataset. It remains unclear how these strategies would generalize to datasets with different sparsity levels or depth completion scenarios.
- What evidence would resolve it: Experiments comparing these deformable convolution strategies on multiple depth completion datasets with varying input sparsity levels would provide clarity on their generalizability and optimal application scenarios.

### Open Question 2
- Question: What is the impact of deformable kernel size on depth completion performance, and how does it relate to the sparsity of input depth maps?
- Basis in paper: [explicit] The paper investigates the impact of kernel size (k=3 vs k=5) and observes that larger kernels lead to degraded performance. However, the relationship between kernel size and input sparsity is not explored.
- Why unresolved: The paper only tests two kernel sizes and does not explore the relationship between kernel size and input sparsity. It remains unclear how to choose the optimal kernel size for different levels of input sparsity.
- What evidence would resolve it: A systematic study varying both kernel size and input sparsity levels would reveal the optimal kernel size for different sparsity scenarios and provide insights into the underlying mechanisms.

### Open Question 3
- Question: How does the deformable refinement module compare to other refinement methods (e.g., iterative spatial propagation) in terms of accuracy, efficiency, and robustness to noise?
- Basis in paper: [explicit] The paper demonstrates that the deformable refinement module outperforms PENet, which uses iterative spatial propagation. However, a comprehensive comparison with other refinement methods is lacking.
- Why unresolved: The paper only compares the deformable refinement module to PENet. It remains unclear how it performs compared to other state-of-the-art refinement methods in terms of accuracy, efficiency, and robustness to noise.
- What evidence would resolve it: Experiments comparing the deformable refinement module to other refinement methods (e.g., CSPN, NLSPN) on multiple datasets and noise levels would provide a comprehensive understanding of its strengths and weaknesses.

## Limitations

- The claim that deformable convolution requires a coarse dense input rather than raw sparse input is supported by ablation results but lacks theoretical justification
- The exact density threshold where deformable convolution becomes effective is not quantified
- Comparison with prior deformable methods shows better speed but architectural differences beyond deformable convolution usage are not fully explored

## Confidence

- High confidence: State-of-the-art performance claims on KITTI metrics (RMSE 728.31 mm, MAE 204.60 mm) and inference speed comparisons
- Medium confidence: Mechanism that coarse depth input is necessary for deformable convolution effectiveness (supported by ablation but no theoretical explanation)
- Low confidence: Claim that single-pass refinement is sufficient for complex depth completion tasks (limited evidence beyond KITTI results)

## Next Checks

1. Test the model on datasets with different sparsity levels (e.g., NYU Depth V2) to verify the coarse depth requirement hypothesis across varying input densities
2. Compare against iterative refinement baselines with identical backbone architectures to isolate the benefit of single-pass deformable convolution
3. Conduct ablation studies on the exact minimum density threshold where deformable convolution outperforms standard convolution on coarse depth inputs