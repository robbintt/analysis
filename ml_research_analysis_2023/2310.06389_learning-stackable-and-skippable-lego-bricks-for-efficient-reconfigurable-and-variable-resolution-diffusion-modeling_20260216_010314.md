---
ver: rpa2
title: Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable,
  and Variable-Resolution Diffusion Modeling
arxiv_id: '2310.06389'
source_url: https://arxiv.org/abs/2310.06389
tags:
- lego
- diffusion
- training
- brick
- bricks
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper introduces LEGO bricks, a new network architecture for
  diffusion models that improves training and sampling efficiency while enabling variable-resolution
  image generation. LEGO bricks integrate local feature enrichment and global content
  orchestration, allowing them to be stacked into a reconfigurable backbone.
---

# Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling

## Quick Facts
- arXiv ID: 2310.06389
- Source URL: https://arxiv.org/abs/2310.06389
- Reference count: 40
- Primary result: LEGO bricks improve training efficiency, enable 60% sampling cost reduction, and support variable-resolution image generation (e.g., 2048x600 from 256x256 training).

## Executive Summary
This paper introduces LEGO bricks, a new network architecture for diffusion models that improves training and sampling efficiency while enabling variable-resolution image generation. LEGO bricks integrate local feature enrichment and global content orchestration, allowing them to be stacked into a reconfigurable backbone. The key advantages are: (1) Training efficiency: Using smaller patches and shorter attention spans significantly reduces FLOPs and training time compared to U-Net and ViT backbones. (2) Sampling efficiency: LEGO bricks can be selectively skipped during generation, reducing sampling cost by up to 60% while maintaining quality. (3) Variable resolution: The model can generate images at resolutions much higher than the training data (e.g., 2048x600 from 256x256 training images).

## Method Summary
LEGO-Diffusion uses a reconfigurable backbone composed of LEGO bricks that combine local-feature enrichment (MLP + patch embedding) with global-content orchestration (Transformer blocks). The architecture supports two spatial refinement strategies: progressive growth (PG) and progressive refinement (PR). Training uses sampled patches for efficiency, while sampling allows selective brick skipping based on timestep noise levels. The model supports both pixel-space training (64x64) and latent-space training (>64x64) using Stable Diffusion's VAE.

## Key Results
- LEGO achieves state-of-the-art FID scores on ImageNet with fewer training iterations and faster convergence than existing diffusion models.
- Training efficiency: Reduced FLOPs and training time through smaller patches and shorter attention spans.
- Sampling efficiency: Up to 60% reduction in sampling cost while maintaining generation quality through selective brick skipping.

## Why This Works (Mechanism)

### Mechanism 1
- Claim: LEGO bricks improve training efficiency by using smaller patches and shorter attention spans, reducing FLOPs and training time.
- Mechanism: By processing local patches instead of full images and using shorter attention spans (as short as 4 tokens), the computational complexity per brick is reduced. The model only needs to focus on local regions, which are computationally cheaper than global attention over the entire image.
- Core assumption: Local feature enrichment is sufficient for learning effective representations during training, even with reduced global context.
- Evidence anchors:
  - [abstract] "Using smaller patches and shorter attention spans significantly reduces FLOPs and training time compared to U-Net and ViT backbones."
  - [section] "Experimental results demonstrate that LEGO bricks enhance training efficiency, as evidenced by reduced FLOPs, faster convergence, and shorter training times..."
- Break condition: If local feature enrichment fails to capture necessary global context for the task, performance will degrade despite efficiency gains.

### Mechanism 2
- Claim: LEGO bricks enable sampling efficiency by allowing selective skipping of bricks during generation, reducing sampling cost by up to 60%.
- Mechanism: During sampling, when the timestep t is large (high noise), the global structure is uncertain, so bricks focused on local details can be skipped. When t is small (low noise), the global structure is stable, so bricks focused on global content can be skipped. This selective skipping reduces computation without significant quality loss.
- Core assumption: The order of spatial refinement (progressive growth vs. progressive refinement) determines which bricks can be safely skipped at different timesteps.
- Evidence anchors:
  - [abstract] "LEGO bricks can be selectively skipped during generation, reducing sampling cost by up to 60% while maintaining quality."
  - [section] "During sampling, LEGO bricks can also be selectively skipped at appropriate time steps without causing clear performance degradation..."
- Break condition: If the skipped bricks contain critical information for the current timestep, generation quality will suffer despite reduced computation.

### Mechanism 3
- Claim: LEGO bricks enable variable-resolution image generation, producing images much higher than training resolution (e.g., 2048x600 from 256x256 training).
- Mechanism: Each LEGO brick maintains full-resolution output while processing different patch sizes. This allows the model to progressively refine spatial information and scale up to higher resolutions during generation, even though it was trained on lower resolution images.
- Core assumption: The progressive refinement capability learned during training on lower resolution images can be generalized to higher resolution generation.
- Evidence anchors:
  - [abstract] "The model can generate images at resolutions much higher than the training data (e.g., 2048x600 from 256x256 training images)."
  - [section] "Furthermore, it empowers the model with the capability to generate images at significantly higher resolutions than those present in the training dataset..."
- Break condition: If the model fails to learn proper scaling relationships during training, higher resolution generation will produce artifacts or fail to maintain coherence.

## Foundational Learning

- Concept: Diffusion models and score-based generative modeling
  - Why needed here: Understanding how diffusion models work is essential to grasp why LEGO bricks improve efficiency and flexibility. The iterative refinement process and noise prediction mechanism are core to the architecture.
  - Quick check question: What is the key difference between training a diffusion model to predict clean images vs. predicting noise?

- Concept: Vision Transformers and local-global feature processing
  - Why needed here: LEGO bricks build on ViT concepts but modify them for efficiency. Understanding how ViT processes patches and uses attention is crucial for understanding LEGO's design choices.
  - Quick check question: How does ViT's approach to processing image patches differ from traditional convolutional networks?

- Concept: Progressive spatial refinement and multi-scale feature processing
  - Why needed here: LEGO bricks implement progressive spatial refinement through stacking bricks of different patch sizes. Understanding this concept is key to grasping how the architecture achieves both efficiency and quality.
  - Quick check question: In progressive growth vs. progressive refinement, which approach would be more suitable for tasks requiring strong global context early in generation?

## Architecture Onboarding

- Component map:
  Token Embedding Layer -> DiT Blocks -> Linear MLP with adaLN -> Output full-resolution image

- Critical path:
  1. Input image → patch extraction → token embedding
  2. Local feature enrichment via MLP mixing
  3. Global content orchestration via Transformer blocks
  4. Progressive refinement through stacked bricks
  5. Output full-resolution image

- Design tradeoffs:
  - Local vs. global processing: Shorter attention spans save computation but may miss global context
  - Patch size selection: Smaller patches increase detail but require more bricks
  - Layer allocation: Balancing layers between patch bricks and image bricks for optimal performance

- Failure signatures:
  - Training instability: If patch size is too small or attention span too short, training may fail to converge
  - Generation artifacts: Skipping wrong bricks or using inappropriate configurations can produce visual artifacts
  - Memory issues: Incorrect patch size or brick configuration can cause memory overflow during training

- First 3 experiments:
  1. Implement a single LEGO brick with 16x16 input and 8x8 local receptive fields, compare training FLOPs to DiT baseline
  2. Stack two LEGO bricks (4x4 and 16x16) in progressive growth configuration, test sampling efficiency with brick skipping
  3. Train LEGO on CelebA 64x64, compare FID score and training time to U-ViT and DiT baselines

## Open Questions the Paper Calls Out
- What is the optimal configuration of LEGO brick sizes and local receptive field sizes for different image resolutions and datasets?
- How can LEGO bricks be optimally skipped during sampling to balance computational efficiency and generation quality across different noise levels?
- Can LEGO bricks be effectively applied to text-guided image generation while maintaining their efficiency advantages?

## Limitations
- The paper lacks ablation studies on optimal patch sampling strategies during training, making efficiency claims potentially dataset-dependent.
- Variable-resolution generation capability beyond the demonstrated 2048x600 case remains untested, raising questions about scalability limits.
- The selective skipping mechanism relies on heuristic criteria without theoretical justification for optimal skipping patterns across different domains.

## Confidence
- High Confidence: The core architectural contributions and FLOPs reduction claims are well-specified and verifiable through computational analysis.
- Medium Confidence: Sampling efficiency claims are demonstrated but may not generalize across different diffusion model configurations or datasets.
- Low Confidence: Variable-resolution generation claims lack comprehensive evaluation and may not scale to extreme aspect ratios or much higher resolutions.

## Next Checks
1. **Patch Sampling Sensitivity Analysis**: Systematically vary the patch sampling ratio during training (0%, 25%, 50%, 75%, 100%) and measure the impact on training efficiency, convergence speed, and final generation quality.
2. **Extreme Resolution Generation Test**: Evaluate variable-resolution generation capability by attempting to generate images at 4096x1024 resolution (16x training resolution) from 256x256 training data.
3. **Cross-Dataset Sampling Efficiency**: Test the selective skipping mechanism on datasets with different content characteristics (e.g., LSUN bedrooms, COCO with text captions) to determine if the progressive growth vs. progressive refinement distinction holds across domains.