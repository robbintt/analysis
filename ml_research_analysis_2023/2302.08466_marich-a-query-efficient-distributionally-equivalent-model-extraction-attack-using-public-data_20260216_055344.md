---
ver: rpa2
title: 'Marich: A Query-efficient Distributionally Equivalent Model Extraction Attack
  using Public Data'
arxiv_id: '2302.08466'
source_url: https://arxiv.org/abs/2302.08466
tags:
- marich
- target
- extracted
- queries
- sampling
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper introduces Marich, a query-efficient black-box model
  extraction attack that uses public data to create an informative and distributionally
  equivalent replica of a target machine learning model. The core method involves
  a variational optimization problem that selects the most informative queries to
  maximize entropy and reduce the mismatch between the target and extracted models.
---

# Marich: A Query-efficient Distributionally Equivalent Model Extraction Attack using Public Data

## Quick Facts
- arXiv ID: 2302.08466
- Source URL: https://arxiv.org/abs/2302.08466
- Reference count: 40
- Primary result: 69-96% accuracy with 1,070-6,950 queries using public data

## Executive Summary
Marich is a novel black-box model extraction attack that leverages public datasets to create distributionally equivalent replicas of target machine learning models. The attack uses a variational optimization framework to select informative queries through three sequential sampling strategies: entropy sampling, entropy gradient sampling, and loss sampling. By maximizing prediction entropy and targeting model disagreements, Marich achieves high extraction accuracy while maintaining query efficiency. The extracted models demonstrate 2-4 times closer prediction distributions to targets compared to existing methods and remain vulnerable to membership inference attacks.

## Method Summary
Marich reduces model extraction to minimizing KL divergence between target and extracted model distributions over a public query dataset. The attack iteratively selects queries through three sampling strategies: entropy sampling identifies uncertain points, gradient sampling selects diverse queries from the entropy set, and loss sampling targets areas of model disagreement. The extracted model is trained on all collected queries in each round, with the sampling process repeating for T rounds. This approach achieves high extraction accuracy while using significantly fewer queries than random sampling methods.

## Key Results
- Extracts models with 69-96% accuracy of target model using 1,070-6,950 queries
- Prediction distributions are 2-4 times closer to target distribution compared to existing active sampling methods
- Leads to 84-96% membership inference accuracy, demonstrating vulnerability of extracted models

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Distributional equivalence reduces model extraction to a variational optimization problem.
- Mechanism: The attack defines a query generating distribution DQ and optimizes for extracted model parameters to minimize KL divergence between target and extracted model joint distributions.
- Core assumption: Both models can be treated as probabilistic mappings where their joint distributions over queries and predictions can be compared.
- Evidence anchors:
  - [abstract] "First, we define distributionally equivalent and Max-Information model extraction attacks, and reduce them into a variational optimisation problem."
  - [section] "If we assume that the extracted model is also a parametric function, i.e.fEω with parametersω ∈ Ω, we can solve the query-efﬁcient distributionally equivalent extraction by computing (ω∗DEq, DQmin) ≜ arg minω∈Ω arg minDQ D(Pr(fTθ∗(Q),Q)∥ Pr(fEω(Q),Q)) (1)"

### Mechanism 2
- Claim: Entropy sampling selects the most informative queries by maximizing prediction entropy.
- Mechanism: For each query point, the extracted model's prediction entropy is computed, and points with highest entropy are selected as they indicate the model is most uncertain.
- Core assumption: Higher entropy in predictions indicates more informative queries for improving the extracted model.
- Evidence anchors:
  - [section] "In ENTROPY SAMPLING, we compute the output probability vectors fromfE t−1 for all the query points in DQ \Qtrain t−1 and then select topB points with highest entropy:Qentropy ← arg maxX⊂Xin,|X|=BH(fE(Xin))."

### Mechanism 3
- Claim: Loss sampling targets queries where target and extracted models disagree most.
- Mechanism: The loss between target and extracted model predictions is computed for all previously selected queries, top-k points with highest loss are identified, and new queries closest to these points are selected.
- Core assumption: The model mismatch is highest at points where loss between predictions is highest, and selecting queries near these points forces alignment.
- Evidence anchors:
  - [section] "In this step, we select points fromQgradt for which the predictions offTθ∗ andfE t−1 are most dissimilar."

## Foundational Learning

- Concept: Variational optimization for probabilistic model comparison
  - Why needed here: The paper reduces model extraction to minimizing KL divergence between joint distributions, which is a variational optimization problem.
  - Quick check question: What is the relationship between minimizing KL divergence and maximizing the lower bound involving entropy and loss terms?

- Concept: Information-theoretic measures (entropy, mutual information)
  - Why needed here: The attack uses entropy to select informative queries and mutual information to quantify information leakage between target and extracted models.
  - Quick check question: How does maximizing prediction entropy help in selecting queries that improve the extracted model?

- Concept: Active learning sampling strategies
  - Why needed here: The paper employs three sequential sampling strategies (entropy, gradient, loss) to select informative queries efficiently.
  - Quick check question: Why does the algorithm use gradient sampling between entropy and loss sampling, and what problem does it solve?

## Architecture Onboarding

- Component map:
  - Target model fT (black-box API)
  - Extracted model fE (trainable replica)
  - Query dataset DQ (publicly available data)
  - Three sampling modules: EntropySampling, GradientSampling, LossSampling
  - Training loop with adaptive query selection

- Critical path:
  1. Initialize with random n0 queries and train initial fE
  2. For each round t:
     - Entropy sampling: Select B queries with highest prediction entropy
     - Gradient sampling: Select γ1B diverse queries from entropy set
     - Loss sampling: Select γ1γ2B queries closest to top-k high-loss points
     - Query target model with selected queries
     - Train fE on all collected queries
  3. Return final extracted model fE

- Design tradeoffs:
  - Query efficiency vs. model fidelity: Fewer queries may lead to less accurate replicas
  - Sampling strategy complexity vs. runtime: More sophisticated sampling increases computational cost
  - Model class mismatch: Using different model classes for fT and fE can affect extraction quality

- Failure signatures:
  - Stagnant accuracy improvement across rounds
  - KL divergence not decreasing between target and extracted model distributions
  - Membership inference accuracy similar between extracted and random models

- First 3 experiments:
  1. Test entropy sampling alone on a simple logistic regression target to verify it selects uncertain points
  2. Compare accuracy of extracted models using only entropy sampling vs. the full three-strategy approach
  3. Test model extraction with different model classes (e.g., CNN target, LR extracted) to understand class mismatch effects

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How does the performance of MARICH change when using different model classes for the target and extracted models?
- Basis in paper: [explicit] The paper mentions that MARICH can handle model mismatches, but shows experiments only for specific cases.
- Why unresolved: The paper only explores a limited set of model class combinations and doesn't systematically investigate how different model architectures affect extraction performance.

### Open Question 2
- Question: What is the theoretical relationship between the number of queries and the accuracy of the extracted model under MARICH?
- Basis in paper: [inferred] The paper shows empirical results but doesn't provide a theoretical analysis of the query-accuracy relationship.
- Why unresolved: The paper focuses on empirical evaluation rather than theoretical analysis of the query complexity.

### Open Question 3
- Question: How does MARICH perform against more sophisticated privacy-preserving defenses beyond DP mechanisms?
- Basis in paper: [explicit] The paper evaluates MARICH against DP-SGD and output perturbation, but these are relatively basic defenses.
- Why unresolved: The paper doesn't explore more advanced privacy-preserving techniques that might be used in practice.

## Limitations

- Implementation details of the three sequential sampling strategies are not fully specified in the paper
- Performance across different model architectures and data domains remains uncertain without additional empirical validation
- Computational overhead of the three-stage sampling process compared to simpler alternatives is not quantified

## Confidence

- **High**: The theoretical framework reducing model extraction to variational optimization (Mechanism 1)
- **Medium**: The effectiveness of the three sequential sampling strategies in practice (Mechanisms 2 and 3)
- **Medium**: The claim that distributionally equivalent models are vulnerable to membership inference attacks (Key Outcome)

## Next Checks

1. **Mechanism Verification**: Implement and test each sampling strategy (entropy, gradient, loss) independently on a simple target model to verify they select queries as theoretically intended before combining them

2. **Sampling Strategy Ablation**: Compare model extraction accuracy using only entropy sampling versus the full three-strategy approach to quantify the marginal benefit of gradient and loss sampling

3. **Model Class Transferability**: Test extraction across different model classes (e.g., CNN target with LR extracted model, or vice versa) to understand how model architecture mismatches affect attack effectiveness