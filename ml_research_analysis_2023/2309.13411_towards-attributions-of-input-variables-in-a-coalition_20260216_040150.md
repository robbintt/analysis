---
ver: rpa2
title: Towards Attributions of Input Variables in a Coalition
arxiv_id: '2309.13411'
source_url: https://arxiv.org/abs/2309.13411
tags:
- variables
- input
- attribution
- value
- coalition
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: This paper studies the attribution of coalitions in AI models,
  i.e., how to explain the numerical effect of a group of input variables. It reformulates
  the Shapley value as the allocation of Harsanyi interactions encoded by the model.
---

# Towards Attributions of Input Variables in a Coalition

## Quick Facts
- arXiv ID: 2309.13411
- Source URL: https://arxiv.org/abs/2309.13411
- Reference count: 6
- This paper extends Shapley values to explain coalition attributions in AI models by reformulating them as allocations of Harsanyi interactions.

## Executive Summary
This paper addresses the challenge of explaining attributions of coalitions in AI models, particularly how to resolve conflicts between individual variables' attributions and their coalition's attribution. The authors reformulate the Shapley value as an allocation of Harsanyi interactions encoded by the model, then extend this to define coalition attributions that consider interactions covering all, partial, and no variables in the coalition. This unified treatment explains the source of attribution conflicts and provides a more faithful explanation of model behavior.

## Method Summary
The method reformulates Shapley values as allocations of Harsanyi AND and OR interactions between input variables, then extends this framework to define coalition attributions. The key insight is that conflicts arise from interactions containing partial variables in the coalition. The proposed approach computes coalition attributions by allocating effects from interactions covering all coalition variables while explaining differences through partial interactions. The method satisfies desirable properties like symmetry, additivity, and efficiency, and is validated through experiments on natural language processing tasks.

## Key Results
- Reformulates Shapley values as allocations of Harsanyi interactions encoded by AI models
- Extends Shapley values to define coalition attributions that explain conflicts through partial interactions
- Satisfies properties including symmetry, additivity, and efficiency
- Experiments on NLP tasks validate effectiveness in explaining coalition attributions and resolving conflicts

## Why This Works (Mechanism)

### Mechanism 1
- Claim: The Shapley value can be reformulated as an allocation of Harsanyi interactions encoded by the AI model.
- Mechanism: The reformulation shows that the Shapley value distributes the effects of non-linear interactions (both AND and OR types) between input variables. Each Shapley value ϕ(i) is computed as the sum over all interactions T containing variable i, with each interaction effect I(T) divided uniformly by |T|.
- Core assumption: The AI model's output can be fully decomposed into Harsanyi AND and OR interactions.
- Evidence anchors: Abstract states "First, we find that the Shapley value can be reformulated as the allocation of Harsanyi interactions encoded by the AI model." Theorem 2 provides the mathematical reformulation.

### Mechanism 2
- Claim: The conflict between individual variables' attributions and their coalition's attribution arises from interactions containing partial variables in the coalition.
- Mechanism: When computing coalition attribution φ(S), only interactions covering all variables in S are considered, but individual Shapley values include interactions with partial S. This discrepancy creates conflict. Theorem 7 formalizes this relationship.
- Core assumption: The AI model encodes interactions that may include subsets of coalition variables, affecting individual Shapley values but not coalition attributions.
- Evidence anchors: Abstract states "The key insight is that the conflict between individual variables' attributions and their coalition's attribution comes from interactions containing partial variables in the coalition." The lack of interactions covering partial variables in S is identified as responsible for conflicts.

### Mechanism 3
- Claim: The proposed coalition attribution φ(S) provides a faithful explanation of the conflict by considering all three types of interactions.
- Mechanism: The method computes φ(S) by allocating effects from interactions T⊇S with weight |S|/|T|, while Shapley values include additional allocations from interactions T⊇{i} for each i∈S. This unified treatment allows φ(S) to capture joint effects while explaining why individual Shapley values differ.
- Core assumption: A comprehensive attribution should account for all interaction types to explain observed conflicts.
- Evidence anchors: Abstract states "The proposed method faithfully explains this conflict by considering the interactions covering all, partial, and no variables in the coalition." The method aims to design a new attribution that well explains the essential factors causing attribution conflicts.

## Foundational Learning

- Concept: Harsanyi interactions (AND and OR types)
  - Why needed here: The entire theoretical framework rests on decomposing model outputs into these interaction terms, representing non-linear relationships between input variables.
  - Quick check question: Can you compute Iand(S) and Ior(S) for a simple model output v(L) using the formulas provided?

- Concept: Shapley value axioms (symmetry, dummy, additivity, efficiency)
  - Why needed here: The reformulation and extension of Shapley values rely on understanding these axioms to justify why the new coalition attribution maintains desirable properties.
  - Quick check question: Why does the uniform allocation of interaction effects to all variables in the interaction satisfy the symmetry axiom?

- Concept: Conflict of attributions across different partitions
  - Why needed here: The paper's motivation is to address this common problem where attributions computed under different variable partitions (individual vs. coalition) conflict, crucial for understanding NLP applications where words vs. tokens are different partitions.
  - Quick check question: Given a word containing two tokens with attributions ϕ(token1) and ϕ(token2), why might the word's attribution ϕ(word) not equal ϕ(token1) + ϕ(token2)?

## Architecture Onboarding

- Component map: Interaction computation module -> Shapley value calculator -> Coalition attribution calculator -> Conflict analysis module
- Critical path: 1) Precompute all Harsanyi interactions Iand(S) and Ior(S) for the model 2) Calculate individual Shapley values ϕ(i) for all variables 3) Compute coalition attributions φ(S) for target coalitions 4) Analyze and explain conflicts using Theorem 7
- Design tradeoffs: Computational cost vs. accuracy (exponential in variables), granularity vs. interpretability (smaller coalitions provide detail but increase conflict complexity), sparsity vs. faithfulness (sparse interactions improve interpretability but may lose faithfulness)
- Failure signatures: Missing interaction terms, numerical instability from alternating sums, partition sensitivity
- First 3 experiments: 1) Verify reformulation by comparing Shapley values using original and interaction-based formulas 2) Demonstrate conflict by creating a model where word attribution ≠ sum of token attributions 3) Test coalition attribution by computing φ(S) and verifying it explains conflicts through partial interactions

## Open Questions the Paper Calls Out

### Open Question 1
- Question: How can we quantitatively measure the extent of conflict between individual variables' attributions and their coalition's attribution in a principled way?
- Basis in paper: [explicit] The paper discusses the conflict between individual variables' attributions and their coalition's attribution as a core challenge but does not provide a quantitative measure for this conflict.
- Why unresolved: Quantifying the conflict requires a metric that can capture the degree of disagreement between the two attribution methods, accounting for complex interplay between individual variables and their coalitions.
- What evidence would resolve it: A concrete definition and formula for a conflict metric, along with experiments demonstrating its effectiveness in quantifying disagreement on various datasets and models.

### Open Question 2
- Question: Can the proposed method be extended to handle interactions involving more than two variables in a computationally efficient manner?
- Basis in paper: [inferred] The paper focuses on interactions between individual variables and coalitions but does not explicitly address interactions involving multiple variables beyond the coalition level.
- Why unresolved: Handling higher-order interactions is crucial for capturing complex dependencies, but computing and incorporating such interactions can be computationally expensive and challenging.
- What evidence would resolve it: An algorithm that efficiently computes and incorporates higher-order interactions into the coalition attribution method, with experiments demonstrating effectiveness and computational efficiency compared to existing methods.

### Open Question 3
- Question: How does the choice of the partition of input variables affect the attribution of coalitions, and is there an optimal way to define the partition?
- Basis in paper: [explicit] The paper acknowledges that different partitions of input variables can lead to conflicts in attributions but does not provide a principled way to define the optimal partition.
- Why unresolved: The partition of input variables is crucial for computing both individual and coalition attributions, but there is no universally accepted way to define the partition, and the choice can significantly impact resulting attributions.
- What evidence would resolve it: A method for automatically determining the optimal partition based on data and model characteristics, with experiments demonstrating the impact of different partitions on resulting attributions and the effectiveness of the proposed method.

## Limitations

- The theoretical framework depends critically on the assumption that AI model outputs can be fully decomposed into Harsanyi interactions, which may not hold for all model architectures.
- The exponential complexity of computing all interactions limits practical applicability to models with many input variables.
- The paper does not address how to handle continuous or high-dimensional input spaces where defining coalitions becomes ambiguous.

## Confidence

**High Confidence**: The reformulation of Shapley values as interaction allocations (Theorem 2) is mathematically sound given the Harsanyi decomposition assumption. The efficiency property for coalition attributions (Corollary 8) follows logically from the interaction-based framework.

**Medium Confidence**: The explanation of conflicts through partial interactions is theoretically convincing but may be difficult to verify empirically in complex models where interaction effects are hard to isolate and measure.

**Low Confidence**: The experimental validation on NLP tasks is insufficiently detailed to assess whether the method actually resolves attribution conflicts in practice. The paper claims effectiveness but does not provide quantitative metrics or ablation studies demonstrating practical benefits.

## Next Checks

1. **Implementation Verification**: For a simple feedforward neural network on synthetic data, implement both the original Shapley value calculation and the interaction-based formula, verifying they produce identical results across multiple inputs.

2. **Conflict Demonstration**: Create a controlled NLP example where a word consists of two tokens with different interaction patterns, showing that individual token Shapley values sum to a different value than the word's coalition attribution, then verify the proposed method correctly identifies and explains this conflict.

3. **Scalability Analysis**: Test the method on models with increasing numbers of input variables (e.g., 5, 10, 15 variables) to empirically measure how computation time scales with exponential growth in interaction calculations, and assess whether approximation techniques could maintain accuracy while improving efficiency.