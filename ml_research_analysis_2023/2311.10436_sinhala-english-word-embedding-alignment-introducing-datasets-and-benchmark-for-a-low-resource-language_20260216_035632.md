---
ver: rpa2
title: 'Sinhala-English Word Embedding Alignment: Introducing Datasets and Benchmark
  for a Low Resource Language'
arxiv_id: '2311.10436'
source_url: https://arxiv.org/abs/2311.10436
tags:
- alignment
- word
- have
- embedding
- dataset
- transformers
- self-attention
- retrieval-augmented-generation
- instruction-tuning
- parameter-efficient-finetuning
- mixture-of-experts
- chain-of-thought
core_contribution: The paper addresses the challenge of aligning monolingual word
  embeddings between Sinhala and English, which is crucial for multilingual natural
  language processing tasks but lacks available solutions for low-resource languages.
  The authors introduce benchmark datasets and evaluate several supervised and unsupervised
  alignment techniques, including Procrustes, CSLS, and RCSLS.
---

# Sinhala-English Word Embedding Alignment: Introducing Datasets and Benchmark for a Low Resource Language

## Quick Facts
- **arXiv ID**: 2311.10436
- **Source URL**: https://arxiv.org/abs/2311.10436
- **Reference count**: 14
- **Primary result**: Introduces benchmark datasets and evaluates alignment techniques for Sinhala-English word embeddings, finding RCSLS achieves highest accuracy despite lower performance than high-resource language pairs.

## Executive Summary
This paper addresses the challenge of aligning monolingual word embeddings between Sinhala and English, a critical step for enabling multilingual NLP tasks for low-resource languages. The authors introduce benchmark datasets created using statistical methods like PMI and conditional probability, and evaluate several supervised and unsupervised alignment techniques. Results show that RCSLS with spectral initialization outperforms other methods, though alignment quality remains lower than for high-resource language pairs. The work provides foundational resources and methods for Sinhala-English embedding alignment.

## Method Summary
The paper creates alignment datasets using statistical methods (PMI and conditional probability) on parallel corpora to generate anchor dictionaries. It evaluates supervised alignment techniques including Procrustes, CSLS, and RCSLS on FastText monolingual embeddings for both languages. The method involves centering and normalizing embeddings, applying alignment techniques to 200k most frequent words, and evaluating using nearest neighbor and CSLS retrieval with precision@k metrics on held-out test pairs.

## Key Results
- RCSLS achieves the highest alignment accuracy among evaluated methods
- Better performance in Si→En direction than En→Si, attributed to larger English embedding space
- Alignment results are lower than for high-resource language pairs but establish baseline performance
- CSLS retrieval generally outperforms nearest neighbor retrieval

## Why This Works (Mechanism)

### Mechanism 1
- Claim: Cross-lingual word embedding alignment is possible without parallel corpora by leveraging statistical word co-occurrence patterns.
- Mechanism: The paper uses pointwise mutual information (PMI) and conditional probability between word pairs in parallel corpora to identify likely translation pairs. These pairs serve as anchor points for supervised alignment methods like Procrustes or RCSLS.
- Core assumption: In parallel corpora, words that frequently co-occur are more likely to be translations of each other, and these statistical associations can approximate a bilingual dictionary.
- Evidence anchors:
  - [abstract] "introduce alignment datasets using statistical methods like PMI and conditional probability"
  - [section] "We used the PPMI measure between source and target word pairs...by applying a threshold to PPMI we tried to obtain the corresponding translation"
  - [corpus] Weak/no direct evidence in cited corpus; relies on internal experimental results
- Break condition: If the parallel corpus is too small or noisy, the statistical associations break down, leading to incorrect anchor pairs and poor alignment.

### Mechanism 2
- Claim: RCSLS (Relaxed CSLS) with spectral initialization provides better alignment than simpler Procrustes methods for low-resource language pairs.
- Mechanism: RCSLS extends CSLS by including the retrieval criterion directly into the training objective, reducing hubness and making training consistent with inference. Spectral initialization helps with faster convergence.
- Core assumption: Including the CSLS criterion in the loss stabilizes training and mitigates hubness, leading to more accurate nearest neighbor retrieval at test time.
- Evidence anchors:
  - [abstract] "RCSLS achieves the highest alignment accuracy"
  - [section] "RCSLS gives the best alignment"
  - [section] "RCSLS transfers some local information encoded in the CSLS criterion to the dot product"
- Break condition: If the embedding spaces are too dissimilar or the anchor dataset is low quality, even RCSLS cannot recover alignment.

### Mechanism 3
- Claim: Alignment quality is higher when mapping from a larger embedding space to a smaller one (e.g., En→Si) than the reverse.
- Mechanism: The larger source vocabulary increases the chance that a target word exists in the source space, reducing information loss during mapping.
- Core assumption: Embedding space size correlates with vocabulary coverage and representation richness; mapping large→small is less lossy than small→large.
- Evidence anchors:
  - [abstract] "better performance in the Si→En direction than En→Si, likely due to the larger size of English embeddings"
  - [section] "FatText English embedding space...is considerably larger than the Sinhala embedding space"
  - [section] "aligning a larger embedding space onto a smaller space is lossy than the other way around"
- Break condition: If the smaller space has higher morphological complexity (e.g., more inflected forms), the advantage may reverse.

## Foundational Learning

- Concept: Monolingual vs multilingual embeddings
  - Why needed here: The paper distinguishes between embeddings trained separately on monolingual data (requiring explicit alignment) and those trained jointly on multilingual data (with implicit alignment). Understanding this distinction is key to why alignment is necessary.
  - Quick check question: What is the difference between monolingual and multilingual embeddings in terms of alignment requirements?

- Concept: Supervised vs unsupervised alignment techniques
  - Why needed here: The paper experiments with both types, using a manually created anchor dictionary for supervised alignment and comparing to unsupervised methods like adversarial training or VecMap. Knowing when each is applicable is critical.
  - Quick check question: When would you choose unsupervised alignment over supervised alignment for low-resource languages?

- Concept: Evaluation metrics for embedding alignment (precision@k)
  - Why needed here: The paper evaluates alignment quality using precision at different cutoffs (P@1, P@5, P@10), which measures how often the correct translation appears in the top k retrieved neighbors. Understanding these metrics is essential for interpreting results.
  - Quick check question: Why might P@5 or P@10 be more informative than P@1 for evaluating alignment between morphologically rich and poor languages?

## Architecture Onboarding

- Component map: Parallel corpora -> Anchor dictionary generation (PMI/conditional probability) -> Train/test split -> FastText embeddings -> Alignment methods (Procrustes, CSLS, RCSLS) -> Evaluation (NN/CSLS retrieval, precision@k)

- Critical path:
  1. Build high-quality anchor dictionary (most frequent words, high coverage in FastText vocab)
  2. Center and normalize embeddings
  3. Apply RCSLS with spectral initialization on 200k most frequent words
  4. Evaluate using CSLS retrieval on 1.5k test queries
  5. Compare to baselines (Procrustes + NN/CSLS)

- Design tradeoffs:
  - Using wiki vs cc FastText: wiki has smaller vocab (Sinhala wiki ~79k vs cc ~808k), impacting coverage and alignment quality
  - Retrieval criterion choice: CSLS generally better than NN, but may vary by direction and language pair
  - Dataset size: Larger anchor dictionaries improve alignment but require more computational resources

- Failure signatures:
  - Low P@1/P@5 even after alignment: likely due to poor anchor dictionary quality or too dissimilar embedding spaces
  - High variance across runs: spectral initialization or random seed sensitivity
  - Disproportionate drop in En→Si vs Si→En: embedding size imbalance or morphological complexity mismatch

- First 3 experiments:
  1. Align cc-FastText embeddings using Procrustes + CSLS on En-Si-para-cc-5k; report P@1/P@5/P@10
  2. Repeat with RCSLS + spectral + CSLS; compare precision gains
  3. Swap retrieval criterion to NN; observe performance drop to confirm CSLS advantage

## Open Questions the Paper Calls Out

### Open Question 1
- Question: What is the optimal size and composition of alignment datasets for low-resource language pairs like Sinhala-English?
- Basis in paper: [explicit] The authors discuss creating alignment datasets using different statistical methods (PMI, conditional probability) and dataset adaptation, noting that using the most frequent words improves alignment results
- Why unresolved: The paper only tests with 5k unique source words and doesn't systematically explore how dataset size or composition affects alignment quality
- What evidence would resolve it: Experiments varying alignment dataset size and composition (e.g., word frequency distribution) while measuring alignment accuracy

### Open Question 2
- Question: How do unsupervised and semi-supervised alignment techniques perform for Sinhala-English compared to supervised methods?
- Basis in paper: [explicit] The authors mention that unsupervised techniques by Lample et al. (2018) and Grave et al. (2019) have shown competitive results with supervised techniques, but only test supervised methods
- Why unresolved: The paper focuses exclusively on supervised alignment techniques without exploring alternatives that might be more suitable for low-resource languages
- What evidence would resolve it: Implementing and comparing unsupervised/semi-supervised alignment techniques for Sinhala-English with the same evaluation metrics

### Open Question 3
- Question: What is the impact of morphological richness on word embedding alignment quality between morphologically rich and poor languages?
- Basis in paper: [explicit] The authors note that Sinhala is morphologically richer than English and that multiple morphological forms in Sinhala map to root words in English, potentially affecting alignment quality
- Why unresolved: The paper observes this effect but doesn't quantify or systematically investigate how morphological complexity affects alignment accuracy
- What evidence would resolve it: Controlled experiments comparing alignment quality across language pairs with varying morphological complexity, or analysis of alignment performance on different word forms within Sinhala

## Limitations
- Reliance on relatively small parallel corpora for anchor dictionary generation, limiting lexical diversity coverage
- Evaluation focuses solely on precision metrics without considering recall or other alignment quality measures
- Alignment results remain lower than for high-resource language pairs, indicating fundamental limitations in low-resource settings

## Confidence
- **High Confidence**: The observation that RCSLS outperforms Procrustes and CSLS in this setting, as this is directly supported by experimental results and aligns with broader literature on alignment methods.
- **Medium Confidence**: The claim that alignment quality is better in the Si→En direction due to English's larger embedding space, as this requires additional assumptions about embedding space characteristics that aren't fully validated.
- **Low Confidence**: The assertion that the specific statistical methods (PMI, conditional probability) are optimal for anchor dictionary generation in this language pair, as alternative approaches are not explored.

## Next Checks
1. **Cross-validation of anchor dictionary quality**: Create multiple anchor dictionaries using different statistical thresholds and frequency cutoffs, then measure alignment quality degradation to establish robustness bounds.
2. **Morphological analysis of alignment errors**: Analyze false positive and false negative cases to determine if alignment failures correlate with specific morphological phenomena in Sinhala (e.g., compound words, inflections).
3. **Scalability test with larger corpora**: Evaluate alignment quality using progressively larger parallel corpora to determine the minimum corpus size required for practical alignment performance.